[
  {
    "id": "arXiv:2302.00002",
    "title": "Differential Analysis for Networks Obeying Conservation Laws",
    "abstract": "Networked systems that occur in various domains, such as the power grid, the brain, and opinion networks, are known to obey conservation laws. For instance, electric networks obey Kirchoff's laws, and social networks display opinion consensus. Such conservation laws are often modeled as balance equations that relate appropriate injected flows and potentials at the nodes of the networks. A recent line of work considers the problem of estimating the unknown structure of such networked systems from observations of node potentials (and only the knowledge of the statistics of injected flows). Given the dynamic nature of the systems under consideration, an equally important task is estimating the change in the structure of the network from data -- the so called differential network analysis problem. That is, given two sets of node potential observations, the goal is to estimate the structural differences between the underlying networks. We formulate this novel differential network analysis problem for systems obeying conservation laws and devise a convex estimator to learn the edge changes directly from node potentials. We derive conditions under which the estimate is unique in the high-dimensional regime and devise an efficient ADMM-based approach to perform the estimation. Finally, we demonstrate the performance of our approach on synthetic and benchmark power network data. ",
    "url": "https://arxiv.org/abs/2302.00002",
    "authors": [
      "Anirudh Rayas",
      "Rajasekhar Anguluri",
      "Jiajun Cheng",
      "Gautam Dasarathy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2302.00004",
    "title": "Low Complexity Approaches for End-to-End Latency Prediction",
    "abstract": "Software Defined Networks have opened the door to statistical and AI-based techniques to improve efficiency of networking. Especially to ensure a certain Quality of Service (QoS) for specific applications by routing packets with awareness on content nature (VoIP, video, files, etc.) and its needs (latency, bandwidth, etc.) to use efficiently resources of a network. Predicting various Key Performance Indicators (KPIs) at any level may handle such problems while preserving network bandwidth. The question addressed in this work is the design of efficient and low-cost algorithms for KPI prediction, implementable at the local level. We focus on end-to-end latency prediction, for which we illustrate our approaches and results on a public dataset from the recent international challenge on GNN [1]. We propose several low complexity, locally implementable approaches, achieving significantly lower wall time both for training and inference, with marginally worse prediction accuracy compared to state-of-the-art global GNN solutions. ",
    "url": "https://arxiv.org/abs/2302.00004",
    "authors": [
      "Pierre Larrenie",
      "Jean-Fran\u00e7ois Bercher",
      "Olivier Venard",
      "Iyad Lahsen-Cherif"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.00032",
    "title": "Neuromechanical Autoencoders: Learning to Couple Elastic and Neural  Network Nonlinearity",
    "abstract": "Intelligent biological systems are characterized by their embodiment in a complex environment and the intimate interplay between their nervous systems and the nonlinear mechanical properties of their bodies. This coordination, in which the dynamics of the motor system co-evolved to reduce the computational burden on the brain, is referred to as ``mechanical intelligence'' or ``morphological computation''. In this work, we seek to develop machine learning analogs of this process, in which we jointly learn the morphology of complex nonlinear elastic solids along with a deep neural network to control it. By using a specialized differentiable simulator of elastic mechanics coupled to conventional deep learning architectures -- which we refer to as neuromechanical autoencoders -- we are able to learn to perform morphological computation via gradient descent. Key to our approach is the use of mechanical metamaterials -- cellular solids, in particular -- as the morphological substrate. Just as deep neural networks provide flexible and massively-parametric function approximators for perceptual and control tasks, cellular solid metamaterials are promising as a rich and learnable space for approximating a variety of actuation tasks. In this work we take advantage of these complementary computational concepts to co-design materials and neural network controls to achieve nonintuitive mechanical behavior. We demonstrate in simulation how it is possible to achieve translation, rotation, and shape matching, as well as a ``digital MNIST'' task. We additionally manufacture and evaluate one of the designs to verify its real-world behavior. ",
    "url": "https://arxiv.org/abs/2302.00032",
    "authors": [
      "Deniz Oktay",
      "Mehran Mirramezani",
      "Eder Medina",
      "Ryan P. Adams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00045",
    "title": "Neural Control of Parametric Solutions for High-dimensional Evolution  PDEs",
    "abstract": "We develop a novel computational framework to approximate solution operators of evolution partial differential equations (PDEs). By employing a general nonlinear reduced-order model, such as a deep neural network, to approximate the solution of a given PDE, we realize that the evolution of the model parameter is a control problem in the parameter space. Based on this observation, we propose to approximate the solution operator of the PDE by learning the control vector field in the parameter space. From any initial value, this control field can steer the parameter to generate a trajectory such that the corresponding reduced-order model solves the PDE. This allows for substantially reduced computational cost to solve the evolution PDE with arbitrary initial conditions. We also develop comprehensive error analysis for the proposed method when solving a large class of semilinear parabolic PDEs. Numerical experiments on different high-dimensional evolution PDEs with various initial conditions demonstrate the promising results of the proposed method. ",
    "url": "https://arxiv.org/abs/2302.00045",
    "authors": [
      "Nathan Gaby",
      "Xiaojing Ye",
      "Haomin Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.00049",
    "title": "Transformers Meet Directed Graphs",
    "abstract": "Transformers were originally proposed as a sequence-to-sequence model for text but have become vital for a wide range of modalities, including images, audio, video, and undirected graphs. However, transformers for directed graphs are a surprisingly underexplored topic, despite their applicability to ubiquitous domains including source code and logic circuits. In this work, we propose two direction- and structure-aware positional encodings for directed graphs: (1) the eigenvectors of the Magnetic Laplacian - a direction-aware generalization of the combinatorial Laplacian; (2) directional random walk encodings. Empirically, we show that the extra directionality information is useful in various downstream tasks, including correctness testing of sorting networks and source code understanding. Together with a data-flow-centric graph construction, our model outperforms the prior state of the art on the Open Graph Benchmark Code2 relatively by 14.7%. ",
    "url": "https://arxiv.org/abs/2302.00049",
    "authors": [
      "Simon Geisler",
      "Yujia Li",
      "Daniel Mankowitz",
      "Ali Taylan Cemgil",
      "Stephan G\u00fcnnemann",
      "Cosmin Paduraru"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00059",
    "title": "NASiam: Efficient Representation Learning using Neural Architecture  Search for Siamese Networks",
    "abstract": "Siamese networks are one of the most trending methods to achieve self-supervised visual representation learning (SSL). Since hand labeling is costly, SSL can play a crucial part by allowing deep learning to train on large unlabeled datasets. Meanwhile, Neural Architecture Search (NAS) is becoming increasingly important as a technique to discover novel deep learning architectures. However, early NAS methods based on reinforcement learning or evolutionary algorithms suffered from ludicrous computational and memory costs. In contrast, differentiable NAS, a gradient-based approach, has the advantage of being much more efficient and has thus retained most of the attention in the past few years. In this article, we present NASiam, a novel approach that uses for the first time differentiable NAS to improve the multilayer perceptron projector and predictor (encoder/predictor pair) architectures inside siamese-networks-based contrastive learning frameworks (e.g., SimCLR, SimSiam, and MoCo) while preserving the simplicity of previous baselines. We crafted a search space designed explicitly for multilayer perceptrons, inside which we explored several alternatives to the standard ReLU activation function. We show that these new architectures allow ResNet backbone convolutional models to learn strong representations efficiently. NASiam reaches competitive performance in both small-scale (i.e., CIFAR-10/CIFAR-100) and large-scale (i.e., ImageNet) image classification datasets while costing only a few GPU hours. We discuss the composition of the NAS-discovered architectures and emit hypotheses on why they manage to prevent collapsing behavior. Our code is available at https://github.com/aheuillet/NASiam. ",
    "url": "https://arxiv.org/abs/2302.00059",
    "authors": [
      "Alexandre Heuillet",
      "Hedi Tabia",
      "Hichem Arioui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00064",
    "title": "Evaluating Temporal Observation-Based Causal Discovery Techniques  Applied to Road Driver Behaviour",
    "abstract": "Autonomous robots are required to reason about the behaviour of dynamic agents in their environment. To this end, many approaches assume that causal models describing the interactions of agents are given a priori. However, in many application domains such models do not exist or cannot be engineered. Hence, the learning (or discovery) of high-level causal structures from low-level, temporal observations is a key problem in AI and robotics. However, the application of causal discovery methods to scenarios involving autonomous agents remains in the early stages of research. While a number of methods exist for performing causal discovery on time series data, these usually rely upon assumptions such as sufficiency and stationarity which cannot be guaranteed in interagent behavioural interactions in the real world. In this paper we are applying contemporary observation-based temporal causal discovery techniques to real world and synthetic driving scenarios from multiple datasets. Our evaluation demonstrates and highlights the limitations of state of the art approaches by comparing and contrasting the performance between real and synthetically generated data. Finally, based on our analysis, we discuss open issues related to causal discovery on autonomous robotics scenarios and propose future research directions for overcoming current limitations in the field. ",
    "url": "https://arxiv.org/abs/2302.00064",
    "authors": [
      "Rhys Howard",
      "Lars Kunze"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.00077",
    "title": "Personalized Privacy Auditing and Optimization at Test Time",
    "abstract": "A number of learning models used in consequential domains, such as to assist in legal, banking, hiring, and healthcare decisions, make use of potentially sensitive users' information to carry out inference. Further, the complete set of features is typically required to perform inference. This not only poses severe privacy risks for the individuals using the learning systems, but also requires companies and organizations massive human efforts to verify the correctness of the released information. This paper asks whether it is necessary to require \\emph{all} input features for a model to return accurate predictions at test time and shows that, under a personalized setting, each individual may need to release only a small subset of these features without impacting the final decisions. The paper also provides an efficient sequential algorithm that chooses which attributes should be provided by each individual. Evaluation over several learning tasks shows that individuals may be able to report as little as 10\\% of their information to ensure the same level of accuracy of a model that uses the complete users' information. ",
    "url": "https://arxiv.org/abs/2302.00077",
    "authors": [
      "Cuong Tran",
      "Ferdinando Fioretto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.00079",
    "title": "GANravel: User-Driven Direction Disentanglement in Generative  Adversarial Networks",
    "abstract": "Generative adversarial networks (GANs) have many application areas including image editing, domain translation, missing data imputation, and support for creative work. However, GANs are considered 'black boxes'. Specifically, the end-users have little control over how to improve editing directions through disentanglement. Prior work focused on new GAN architectures to disentangle editing directions. Alternatively, we propose GANravel a user-driven direction disentanglement tool that complements the existing GAN architectures and allows users to improve editing directions iteratively. In two user studies with 16 participants each, GANravel users were able to disentangle directions and outperformed the state-of-the-art direction discovery baselines in disentanglement performance. In the second user study, GANravel was used in a creative task of creating dog memes and was able to create high-quality edited images and GIFs. ",
    "url": "https://arxiv.org/abs/2302.00079",
    "authors": [
      "Noyan Evirgen",
      "Xiang 'Anthony' Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00082",
    "title": "Adaptive sparseness for correntropy-based robust regression via  automatic relevance determination",
    "abstract": "Sparseness and robustness are two important properties for many machine learning scenarios. In the present study, regarding the maximum correntropy criterion (MCC) based robust regression algorithm, we investigate to integrate the MCC method with the automatic relevance determination (ARD) technique in a Bayesian framework, so that MCC-based robust regression could be implemented with adaptive sparseness. To be specific, we use an inherent noise assumption from the MCC to derive an explicit likelihood function, and realize the maximum a posteriori (MAP) estimation with the ARD prior by variational Bayesian inference. Compared to the existing robust and sparse L1-regularized MCC regression, the proposed MCC-ARD regression can eradicate the troublesome tuning for the regularization hyper-parameter which controls the regularization strength. Further, MCC-ARD achieves superior prediction performance and feature selection capability than L1-regularized MCC, as demonstrated by a noisy and high-dimensional simulation study. ",
    "url": "https://arxiv.org/abs/2302.00082",
    "authors": [
      "Yuanhao Li",
      "Badong Chen",
      "Okito Yamashita",
      "Natsue Yoshimura",
      "Yasuharu Koike"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.00089",
    "title": "Mind the (optimality) Gap: A Gap-Aware Learning Rate Scheduler for  Adversarial Nets",
    "abstract": "Adversarial nets have proved to be powerful in various domains including generative modeling (GANs), transfer learning, and fairness. However, successfully training adversarial nets using first-order methods remains a major challenge. Typically, careful choices of the learning rates are needed to maintain the delicate balance between the competing networks. In this paper, we design a novel learning rate scheduler that dynamically adapts the learning rate of the adversary to maintain the right balance. The scheduler is driven by the fact that the loss of an ideal adversarial net is a constant known a priori. The scheduler is thus designed to keep the loss of the optimized adversarial net close to that of an ideal network. We run large-scale experiments to study the effectiveness of the scheduler on two popular applications: GANs for image generation and adversarial nets for domain adaptation. Our experiments indicate that adversarial nets trained with the scheduler are less likely to diverge and require significantly less tuning. For example, on CelebA, a GAN with the scheduler requires only one-tenth of the tuning budget needed without a scheduler. Moreover, the scheduler leads to statistically significant improvements in model quality, reaching up to $27\\%$ in Frechet Inception Distance for image generation and $3\\%$ in test accuracy for domain adaptation. ",
    "url": "https://arxiv.org/abs/2302.00089",
    "authors": [
      "Hussein Hazimeh",
      "Natalia Ponomareva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00094",
    "title": "The Impacts of Unanswerable Questions on the Robustness of Machine  Reading Comprehension Models",
    "abstract": "Pretrained language models have achieved super-human performances on many Machine Reading Comprehension (MRC) benchmarks. Nevertheless, their relative inability to defend against adversarial attacks has spurred skepticism about their natural language understanding. In this paper, we ask whether training with unanswerable questions in SQuAD 2.0 can help improve the robustness of MRC models against adversarial attacks. To explore that question, we fine-tune three state-of-the-art language models on either SQuAD 1.1 or SQuAD 2.0 and then evaluate their robustness under adversarial attacks. Our experiments reveal that current models fine-tuned on SQuAD 2.0 do not initially appear to be any more robust than ones fine-tuned on SQuAD 1.1, yet they reveal a measure of hidden robustness that can be leveraged to realize actual performance gains. Furthermore, we find that the robustness of models fine-tuned on SQuAD 2.0 extends to additional out-of-domain datasets. Finally, we introduce a new adversarial attack to reveal artifacts of SQuAD 2.0 that current MRC models are learning. ",
    "url": "https://arxiv.org/abs/2302.00094",
    "authors": [
      "Son Quoc Tran",
      "Phong Nguyen-Thuan Do",
      "Uyen Le",
      "Matt Kretchmar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00099",
    "title": "Learning noisy-OR Bayesian Networks with Max-Product Belief Propagation",
    "abstract": "Noisy-OR Bayesian Networks (BNs) are a family of probabilistic graphical models which express rich statistical dependencies in binary data. Variational inference (VI) has been the main method proposed to learn noisy-OR BNs with complex latent structures (Jaakkola & Jordan, 1999; Ji et al., 2020; Buhai et al., 2020). However, the proposed VI approaches either (a) use a recognition network with standard amortized inference that cannot induce ``explaining-away''; or (b) assume a simple mean-field (MF) posterior which is vulnerable to bad local optima. Existing MF VI methods also update the MF parameters sequentially which makes them inherently slow. In this paper, we propose parallel max-product as an alternative algorithm for learning noisy-OR BNs with complex latent structures and we derive a fast stochastic training scheme that scales to large datasets. We evaluate both approaches on several benchmarks where VI is the state-of-the-art and show that our method (a) achieves better test performance than Ji et al. (2020) for learning noisy-OR BNs with hierarchical latent structures on large sparse real datasets; (b) recovers a higher number of ground truth parameters than Buhai et al. (2020) from cluttered synthetic scenes; and (c) solves the 2D blind deconvolution problem from Lazaro-Gredilla et al. (2021) and variant - including binary matrix factorization - while VI catastrophically fails and is up to two orders of magnitude slower. ",
    "url": "https://arxiv.org/abs/2302.00099",
    "authors": [
      "Antoine Dedieu",
      "Guangyao Zhou",
      "Dileep George",
      "Miguel Lazaro-Gredilla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00112",
    "title": "Adding an Edge in a $P_4$-sparse Graph",
    "abstract": "The minimum completion (fill-in) problem is defined as follows: Given a graph family $\\mathcal{F}$ (more generally, a property $\\Pi$) and a graph $G$, the completion problem asks for the minimum number of non-edges needed to be added to $G$ so that the resulting graph belongs to the graph family $\\mathcal{F}$ (or has property $\\Pi$). This problem is NP-complete for many subclasses of perfect graphs and polynomial solutions are available only for minimal completion sets. We study the minimum completion problem of a $P_4$-sparse graph $G$ with an added edge. For any optimal solution of the problem, we prove that there is an optimal solution whose form is of one of a small number of possibilities. This along with the solution of the problem when the added edge connects two non-adjacent vertices of a spider or connects two vertices in different connected components of the graph enables us to present a polynomial-time algorithm for the problem. ",
    "url": "https://arxiv.org/abs/2302.00112",
    "authors": [
      "Anna Mpanti",
      "Stavros D. Nikolopoulos",
      "Leonidas Palios"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.00117",
    "title": "Real Estate Property Valuation using Self-Supervised Vision Transformers",
    "abstract": "The use of Artificial Intelligence (AI) in the real estate market has been growing in recent years. In this paper, we propose a new method for property valuation that utilizes self-supervised vision transformers, a recent breakthrough in computer vision and deep learning. Our proposed algorithm uses a combination of machine learning, computer vision and hedonic pricing models trained on real estate data to estimate the value of a given property. We collected and pre-processed a data set of real estate properties in the city of Boulder, Colorado and used it to train, validate and test our algorithm. Our data set consisted of qualitative images (including house interiors, exteriors, and street views) as well as quantitative features such as the number of bedrooms, bathrooms, square footage, lot square footage, property age, crime rates, and proximity to amenities. We evaluated the performance of our model using metrics such as Root Mean Squared Error (RMSE). Our findings indicate that these techniques are able to accurately predict the value of properties, with a low RMSE. The proposed algorithm outperforms traditional appraisal methods that do not leverage property images and has the potential to be used in real-world applications. ",
    "url": "https://arxiv.org/abs/2302.00117",
    "authors": [
      "Mahdieh Yazdani",
      "Maziar Raissi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2302.00123",
    "title": "Design and Implementation of A Soccer Ball Detection System with  Multiple Cameras",
    "abstract": "The detection of small and medium-sized objects in three dimensions has always been a frontier exploration problem. This technology has a very wide application in sports analysis, games, virtual reality, human animation and other fields. The traditional three-dimensional small target detection technology has the disadvantages of high cost, low precision and inconvenience, so it is difficult to apply in practice. With the development of machine learning and deep learning, the technology of computer vision algorithms is becoming more mature. Creating an immersive media experience is considered to be a very important research work in sports. The main work is to explore and solve the problem of football detection under the multiple cameras, aiming at the research and implementation of the live broadcast system of football matches. Using multi cameras detects a target ball and determines its position in three dimension with the occlusion, motion, low illumination of the target object. This paper designed and implemented football detection system under multiple cameras for the detection and capture of targets in real-time matches. The main work mainly consists of three parts, football detector, single camera detection, and multi-cameras detection. The system used bundle adjustment to obtain the three-dimensional position of the target, and the GPU to accelerates data pre-processing and achieve accurate real-time capture of the target. By testing the system, it shows that the system can accurately detect and capture the moving targets in 3D. In addition, the solution in this paper is reusable for large-scale competitions, like basketball and soccer. The system framework can be well transplanted into other similar engineering project systems. It has been put into the market. ",
    "url": "https://arxiv.org/abs/2302.00123",
    "authors": [
      "Lei Li",
      "Tianfang Zhang",
      "Zhongfeng Kang",
      "Wenhan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00133",
    "title": "Sublinear Approximation Schemes for Scheduling Precedence Graphs of  Bounded Depth",
    "abstract": "We study the classical scheduling problem on parallel machines %with precedence constraints where the precedence graph has the bounded depth $h$. Our goal is to minimize the maximum completion time. We focus on developing approximation algorithms that use only sublinear space or sublinear time. We develop the first one-pass streaming approximation schemes using sublinear space when all jobs' processing times differ no more than a constant factor $c$ and the number of machines $m$ is at most $\\tfrac {2n \\epsilon}{3 h c }$. This is so far the best approximation we can have in terms of $m$, since no polynomial time approximation better than $\\tfrac{4}{3}$ exists when $m = \\tfrac{n}{3}$ unless P=NP. %the problem cannot be approximated within a factor of $\\tfrac{4}{3}$ when $m = \\tfrac{n}{3}$ even if all jobs have equal processing time. The algorithms are then extended to the more general problem where the largest $\\alpha n$ jobs have no more than $c$ factor difference. % for some constant $0 < \\alpha \\le 1$. We also develop the first sublinear time algorithms for both problems. For the more general problem, when $ m \\le \\tfrac { \\alpha n \\epsilon}{20 c^2 \\cdot h } $, our algorithm is a randomized $(1+\\epsilon)$-approximation scheme that runs in sublinear time. This work not only provides an algorithmic solution to the studied problem under big data % and cloud computing environment, but also gives a methodological framework for designing sublinear approximation algorithms for other scheduling problems. ",
    "url": "https://arxiv.org/abs/2302.00133",
    "authors": [
      "Bin Fu",
      "Yumei Huo",
      "Hairong Zhao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.00164",
    "title": "Detection of Tomato Ripening Stages using Yolov3-tiny",
    "abstract": "One of the most important agricultural products in Mexico is the tomato (Solanum lycopersicum), which occupies the 4th place national most produced product . Therefore, it is necessary to improve its production, building automatic detection system that detect, classify an keep tacks of the fruits is one way to archieve it. So, in this paper, we address the design of a computer vision system to detect tomatoes at different ripening stages. To solve the problem, we use a neural network-based model for tomato classification and detection. Specifically, we use the YOLOv3-tiny model because it is one of the lightest current deep neural networks. To train it, we perform two grid searches testing several combinations of hyperparameters. Our experiments showed an f1-score of 90.0% in the localization and classification of ripening stages in a custom dataset. ",
    "url": "https://arxiv.org/abs/2302.00164",
    "authors": [
      "Gerardo Antonio Alvarez Hern\u00e1ndez",
      "Juan Carlos Olguin",
      "Juan Irving Vasquez",
      "Abril Valeria Uriarte",
      "Maria Claudia Villica\u00f1a Torres"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00190",
    "title": "Neural Wavelet-domain Diffusion for 3D Shape Generation, Inversion, and  Manipulation",
    "abstract": "This paper presents a new approach for 3D shape generation, inversion, and manipulation, through a direct generative modeling on a continuous implicit representation in wavelet domain. Specifically, we propose a compact wavelet representation with a pair of coarse and detail coefficient volumes to implicitly represent 3D shapes via truncated signed distance functions and multi-scale biorthogonal wavelets. Then, we design a pair of neural networks: a diffusion-based generator to produce diverse shapes in the form of the coarse coefficient volumes and a detail predictor to produce compatible detail coefficient volumes for introducing fine structures and details. Further, we may jointly train an encoder network to learn a latent space for inverting shapes, allowing us to enable a rich variety of whole-shape and region-aware shape manipulations. Both quantitative and qualitative experimental results manifest the compelling shape generation, inversion, and manipulation capabilities of our approach over the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2302.00190",
    "authors": [
      "Jingyu Hu",
      "Ka-Hei Hui",
      "Zhengzhe Liu",
      "Ruihui Li",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2302.00192",
    "title": "Density peak clustering using tensor network",
    "abstract": "Tensor networks, which have been traditionally used to simulate many-body physics, have recently gained significant attention in the field of machine learning due to their powerful representation capabilities. In this work, we propose a density-based clustering algorithm inspired by tensor networks. We encode classical data into tensor network states on an extended Hilbert space and train the tensor network states to capture the features of the clusters. Here, we define density and related concepts in terms of fidelity, rather than using a classical distance measure. We evaluate the performance of our algorithm on six synthetic data sets, four real world data sets, and three commonly used computer vision data sets. The results demonstrate that our method provides state-of-the-art performance on several synthetic data sets and real world data sets, even when the number of clusters is unknown. Additionally, our algorithm performs competitively with state-of-the-art algorithms on the MNIST, USPS, and Fashion-MNIST image data sets. These findings reveal the great potential of tensor networks for machine learning applications. ",
    "url": "https://arxiv.org/abs/2302.00192",
    "authors": [
      "Xiao Shi",
      "Yun Shang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2302.00193",
    "title": "$\\rm A^2Q$: Aggregation-Aware Quantization for Graph Neural Networks",
    "abstract": "As graph data size increases, the vast latency and memory consumption during inference pose a significant challenge to the real-world deployment of Graph Neural Networks (GNNs). While quantization is a powerful approach to reducing GNNs complexity, most previous works on GNNs quantization fail to exploit the unique characteristics of GNNs, suffering from severe accuracy degradation. Through an in-depth analysis of the topology of GNNs, we observe that the topology of the graph leads to significant differences between nodes, and most of the nodes in a graph appear to have a small aggregation value. Motivated by this, in this paper, we propose the Aggregation-Aware mixed-precision Quantization ($\\rm A^2Q$) for GNNs, where an appropriate bitwidth is automatically learned and assigned to each node in the graph. To mitigate the vanishing gradient problem caused by sparse connections between nodes, we propose a Local Gradient method to serve the quantization error of the node features as the supervision during training. We also develop a Nearest Neighbor Strategy to deal with the generalization on unseen graphs. Extensive experiments on eight public node-level and graph-level datasets demonstrate the generality and robustness of our proposed method. Compared to the FP32 models, our method can achieve up to a 18.6x (i.e., 1.70bit) compression ratio with negligible accuracy degradation. Morever, compared to the state-of-the-art quantization method, our method can achieve up to 11.4\\% and 9.5\\% accuracy improvements on the node-level and graph-level tasks, respectively, and up to 2x speedup on a dedicated hardware accelerator. ",
    "url": "https://arxiv.org/abs/2302.00193",
    "authors": [
      "Zeyu Zhu",
      "Fanrong Li",
      "Zitao Mo",
      "Qinghao Hu",
      "Gang Li",
      "Zejian Liu",
      "Xiaoyao Liang",
      "Jian Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00194",
    "title": "Free Lunch for Domain Adversarial Training: Environment Label Smoothing",
    "abstract": "A fundamental challenge for machine learning models is how to generalize learned models for out-of-distribution (OOD) data. Among various approaches, exploiting invariant features by Domain Adversarial Training (DAT) received widespread attention. Despite its success, we observe training instability from DAT, mostly due to over-confident domain discriminator and environment label noise. To address this issue, we proposed Environment Label Smoothing (ELS), which encourages the discriminator to output soft probability, which thus reduces the confidence of the discriminator and alleviates the impact of noisy environment labels. We demonstrate, both experimentally and theoretically, that ELS can improve training stability, local convergence, and robustness to noisy environment labels. By incorporating ELS with DAT methods, we are able to yield state-of-art results on a wide range of domain generalization/adaptation tasks, particularly when the environment labels are highly noisy. ",
    "url": "https://arxiv.org/abs/2302.00194",
    "authors": [
      "YiFan Zhang",
      "Xue Wang",
      "Jian Liang",
      "Zhang Zhang",
      "Liang Wang",
      "Rong Jin",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00195",
    "title": "Weight Prediction Boosts the Convergence of AdamW",
    "abstract": "In this paper, we introduce weight prediction into the AdamW optimizer to boost its convergence when training the deep neural network (DNN) models. In particular, ahead of each mini-batch training, we predict the future weights according to the update rule of AdamW and then apply the predicted future weights to do both forward pass and backward propagation. In this way, the AdamW optimizer always utilizes the gradients w.r.t. the future weights instead of current weights to update the DNN parameters, making the AdamW optimizer achieve better convergence. Our proposal is simple and straightforward to implement but effective in boosting the convergence of DNN training. We performed extensive experimental evaluations on image classification and language modeling tasks to verify the effectiveness of our proposal. The experimental results validate that our proposal can boost the convergence of AdamW and achieve better accuracy than AdamW when training the DNN models. ",
    "url": "https://arxiv.org/abs/2302.00195",
    "authors": [
      "Lei Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.00196",
    "title": "An Axiomatic Characterization of CFMMs and Equivalence to Prediction  Markets",
    "abstract": "Constant-function market makers (CFMMs), such as Uniswap, are automated exchanges offering trades among a set of assets. We study their technical relationship to another class of automated market makers, cost-function prediction markets. We first introduce axioms for market makers and show that CFMMs with concave potential functions characterize \"good\" market makers according to these axioms. We then show that every such CFMM on $n$ assets is equivalent to a cost-function prediction market for events with $n$ outcomes. Our construction directly converts a CFMM into a prediction market and vice versa. Conceptually, our results show that desirable market-making axioms are equivalent to desirable information-elicitation axioms, i.e., markets are good at facilitating trade if and only if they are good at revealing beliefs. For example, we show that every CFMM implicitly defines a \\emph{proper scoring rule} for eliciting beliefs; the scoring rule for Uniswap is unusual, but known. From a technical standpoint, our results show how tools for prediction markets and CFMMs can interoperate. We illustrate this interoperability by showing how liquidity strategies from both literatures transfer to the other, yielding new market designs. ",
    "url": "https://arxiv.org/abs/2302.00196",
    "authors": [
      "Rafael Frongillo",
      "Maneesha Papireddygari",
      "Bo Waggoner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.00207",
    "title": "Distributed Traffic Synthesis and Classification in Edge Networks: A  Federated Self-supervised Learning Approach",
    "abstract": "With the rising demand for wireless services and increased awareness of the need for data protection, existing network traffic analysis and management architectures are facing unprecedented challenges in classifying and synthesizing the increasingly diverse services and applications. This paper proposes FS-GAN, a federated self-supervised learning framework to support automatic traffic analysis and synthesis over a large number of heterogeneous datasets. FS-GAN is composed of multiple distributed Generative Adversarial Networks (GANs), with a set of generators, each being designed to generate synthesized data samples following the distribution of an individual service traffic, and each discriminator being trained to differentiate the synthesized data samples and the real data samples of a local dataset. A federated learning-based framework is adopted to coordinate local model training processes of different GANs across different datasets. FS-GAN can classify data of unknown types of service and create synthetic samples that capture the traffic distribution of the unknown types. We prove that FS-GAN can minimize the Jensen-Shannon Divergence (JSD) between the distribution of real data across all the datasets and that of the synthesized data samples. FS-GAN also maximizes the JSD among the distributions of data samples created by different generators, resulting in each generator producing synthetic data samples that follow the same distribution as one particular service type. Extensive simulation results show that the classification accuracy of FS-GAN achieves over 20% improvement in average compared to the state-of-the-art clustering-based traffic analysis algorithms. FS-GAN also has the capability to synthesize highly complex mixtures of traffic types without requiring any human-labeled data samples. ",
    "url": "https://arxiv.org/abs/2302.00207",
    "authors": [
      "Yong Xiao",
      "Rong Xia",
      "Yingyu Li",
      "Guangming Shi",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Dusit Niyato",
      "Marwan Krunz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.00210",
    "title": "Is Stubborn Mining Severe in Imperfect GHOST Bitcoin-like Blockchains?  Quantitative Analysis",
    "abstract": "GHOST, like the longest-chain protocol, is a chain selection protocol and its capability in resisting selfish mining attack has been validated in imperfect blockchains of Bitcoin and its variants (Bitcoin-like). This paper explores an analytical-model-based method to investigate the impact of stubborn mining attack in imperfect GHOST Bitcoin-like blockchains. We first quantify chain dynamics based on Markov chain and then derive the formulas of miner revenue and system throughput. We also propose a new metric, \"Hazard Index\", which can be used to compare attack severity and also assist attacker in determining whether it is profitable to conduct an attack. The experiment results show that 1) An attacker with more than 30% computing power can get huge profit and extremely downgrade system throughput by launching stubborn mining attack. 2) A rational attacker should not launch stubborn mining attack if it has less than 25% computing power. 3) Stubborn mining attack causes more damage than selfish mining attack under GHOST. Our work provides insight into stubborn mining attack and is helpful in designing countermeasures. ",
    "url": "https://arxiv.org/abs/2302.00210",
    "authors": [
      "Haoran Zhu",
      "Xiaolin Chang",
      "Jelena Mi\u0161i\u0107",
      "Vojislav B. Mi\u0161i\u0107",
      "Lei Han",
      "Zhi Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.00220",
    "title": "Efficient Scopeformer: Towards Scalable and Rich Feature Extraction for  Intracranial Hemorrhage Detection",
    "abstract": "The quality and richness of feature maps extracted by convolution neural networks (CNNs) and vision Transformers (ViTs) directly relate to the robust model performance. In medical computer vision, these information-rich features are crucial for detecting rare cases within large datasets. This work presents the \"Scopeformer,\" a novel multi-CNN-ViT model for intracranial hemorrhage classification in computed tomography (CT) images. The Scopeformer architecture is scalable and modular, which allows utilizing various CNN architectures as the backbone with diversified output features and pre-training strategies. We propose effective feature projection methods to reduce redundancies among CNN-generated features and to control the input size of ViTs. Extensive experiments with various Scopeformer models show that the model performance is proportional to the number of convolutional blocks employed in the feature extractor. Using multiple strategies, including diversifying the pre-training paradigms for CNNs, different pre-training datasets, and style transfer techniques, we demonstrate an overall improvement in the model performance at various computational budgets. Later, we propose smaller compute-efficient Scopeformer versions with three different types of input and output ViT configurations. Efficient Scopeformers use four different pre-trained CNN architectures as feature extractors to increase feature richness. Our best Efficient Scopeformer model achieved an accuracy of 96.94\\% and a weighted logarithmic loss of 0.083 with an eight times reduction in the number of trainable parameters compared to the base Scopeformer. Another version of the Efficient Scopeformer model further reduced the parameter space by almost 17 times with negligible performance reduction. Hybrid CNNs and ViTs might provide the desired feature richness for developing accurate medical computer vision models ",
    "url": "https://arxiv.org/abs/2302.00220",
    "authors": [
      "Yassine Barhoumi",
      "Nidhal C. Bouaynaya",
      "Ghulam Rasool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.00232",
    "title": "SPIDE: A Purely Spike-based Method for Training Feedback Spiking Neural  Networks",
    "abstract": "Spiking neural networks (SNNs) with event-based computation are promising brain-inspired models for energy-efficient applications on neuromorphic hardware. However, most supervised SNN training methods, such as conversion from artificial neural networks or direct training with surrogate gradients, require complex computation rather than spike-based operations of spiking neurons during training. In this paper, we study spike-based implicit differentiation on the equilibrium state (SPIDE) that extends the recently proposed training method, implicit differentiation on the equilibrium state (IDE), for supervised learning with purely spike-based computation, which demonstrates the potential for energy-efficient training of SNNs. Specifically, we introduce ternary spiking neuron couples and prove that implicit differentiation can be solved by spikes based on this design, so the whole training procedure, including both forward and backward passes, is made as event-driven spike computation, and weights are updated locally with two-stage average firing rates. Then we propose to modify the reset membrane potential to reduce the approximation error of spikes. With these key components, we can train SNNs with flexible structures in a small number of time steps and with firing sparsity during training, and the theoretical estimation of energy costs demonstrates the potential for high efficiency. Meanwhile, experiments show that even with these constraints, our trained models can still achieve competitive results on MNIST, CIFAR-10, CIFAR-100, and CIFAR10-DVS. Our code is available at https://github.com/pkuxmq/SPIDE-FSNN. ",
    "url": "https://arxiv.org/abs/2302.00232",
    "authors": [
      "Mingqing Xiao",
      "Qingyan Meng",
      "Zongpeng Zhang",
      "Yisen Wang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00236",
    "title": "Generative Adversarial Symmetry Discovery",
    "abstract": "Despite the success of equivariant neural networks in scientific applications, they require knowing the symmetry group a priori. However, it may be difficult to know the right symmetry to use as an inductive bias in practice and enforcing the wrong symmetry could hurt the performance. In this paper, we propose a framework, LieGAN, to automatically discover equivariances from a dataset using a paradigm akin to generative adversarial training. Specifically, a generator learns a group of transformations applied to the data, which preserves the original distribution and fools the discriminator. LieGAN represents symmetry as interpretable Lie algebra basis and can discover various symmetries such as rotation group $\\mathrm{SO}(n)$ and restricted Lorentz group $\\mathrm{SO}(1,3)^+$ in trajectory prediction and top quark tagging tasks. The learned symmetry can also be readily used in several existing equivariant neural networks to improve accuracy and generalization in prediction. ",
    "url": "https://arxiv.org/abs/2302.00236",
    "authors": [
      "Jianke Yang",
      "Robin Walters",
      "Nima Dehmamy",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00237",
    "title": "Bridging Physics-Informed Neural Networks with Reinforcement Learning:  Hamilton-Jacobi-Bellman Proximal Policy Optimization (HJBPPO)",
    "abstract": "This paper introduces the Hamilton-Jacobi-Bellman Proximal Policy Optimization (HJBPPO) algorithm into reinforcement learning. The Hamilton-Jacobi-Bellman (HJB) equation is used in control theory to evaluate the optimality of the value function. Our work combines the HJB equation with reinforcement learning in continuous state and action spaces to improve the training of the value network. We treat the value network as a Physics-Informed Neural Network (PINN) to solve for the HJB equation by computing its derivatives with respect to its inputs exactly. The Proximal Policy Optimization (PPO)-Clipped algorithm is improvised with this implementation as it uses a value network to compute the objective function for its policy network. The HJBPPO algorithm shows an improved performance compared to PPO on the MuJoCo environments. ",
    "url": "https://arxiv.org/abs/2302.00237",
    "authors": [
      "Amartya Mukherjee",
      "Jun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.00239",
    "title": "Filtering Context Mitigates Scarcity and Selection Bias in Political  Ideology Prediction",
    "abstract": "We propose a novel supervised learning approach for political ideology prediction (PIP) that is capable of predicting out-of-distribution inputs. This problem is motivated by the fact that manual data-labeling is expensive, while self-reported labels are often scarce and exhibit significant selection bias. We propose a novel statistical model that decomposes the document embeddings into a linear superposition of two vectors; a latent neutral \\emph{context} vector independent of ideology, and a latent \\emph{position} vector aligned with ideology. We train an end-to-end model that has intermediate contextual and positional vectors as outputs. At deployment time, our model predicts labels for input documents by exclusively leveraging the predicted positional vectors. On two benchmark datasets we show that our model is capable of outputting predictions even when trained with as little as 5\\% biased data, and is significantly more accurate than the state-of-the-art. Through crowd-sourcing we validate the neutrality of contextual vectors, and show that context filtering results in ideological concentration, allowing for prediction on out-of-distribution examples. ",
    "url": "https://arxiv.org/abs/2302.00239",
    "authors": [
      "Chen Chen",
      "Dylan Walker",
      "Venkatesh Saligrama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.00268",
    "title": "Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video  Relation Detection",
    "abstract": "Prompt tuning with large-scale pretrained vision-language models empowers open-vocabulary predictions trained on limited base categories, e.g., object classification and detection. In this paper, we propose compositional prompt tuning with motion cues: an extended prompt tuning paradigm for compositional predictions of video data. In particular, we present Relation Prompt (RePro) for Open-vocabulary Video Visual Relation Detection (Open-VidVRD), where conventional prompt tuning is easily biased to certain subject-object combinations and motion patterns. To this end, RePro addresses the two technical challenges of Open-VidVRD: 1) the prompt tokens should respect the two different semantic roles of subject and object, and 2) the tuning should account for the diverse spatio-temporal motion patterns of the subject-object compositions. Without bells and whistles, our RePro achieves a new state-of-the-art performance on two VidVRD benchmarks of not only the base training object and predicate categories, but also the unseen ones. Extensive ablations also demonstrate the effectiveness of the proposed compositional and multi-mode design of prompts. Code is available at https://github.com/Dawn-LX/OpenVoc-VidVRD. ",
    "url": "https://arxiv.org/abs/2302.00268",
    "authors": [
      "Kaifeng Gao",
      "Long Chen",
      "Hanwang Zhang",
      "Jun Xiao",
      "Qianru Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.00272",
    "title": "W2SAT: Learning to generate SAT instances from Weighted Literal  Incidence Graphs",
    "abstract": "The Boolean Satisfiability (SAT) problem stands out as an attractive NP-complete problem in theoretic computer science and plays a central role in a broad spectrum of computing-related applications. Exploiting and tuning SAT solvers under numerous scenarios require massive high-quality industry-level SAT instances, which unfortunately are quite limited in the real world. To address the data insufficiency issue, in this paper, we propose W2SAT, a framework to generate SAT formulas by learning intrinsic structures and properties from given real-world/industrial instances in an implicit fashion. To this end, we introduce a novel SAT representation called Weighted Literal Incidence Graph (WLIG), which exhibits strong representation ability and generalizability against existing counterparts, and can be efficiently generated via a specialized learning-based graph generative model. Decoding from WLIGs into SAT problems is then modeled as finding overlapping cliques with a novel hill-climbing optimization method termed Optimal Weight Coverage (OWC). Experiments demonstrate the superiority of our WLIG-induced approach in terms of graph metrics, efficiency, and scalability in comparison to previous methods. Additionally, we discuss the limitations of graph-based SAT generation for real-world applications, especially when utilizing generated instances for SAT solver parameter-tuning, and pose some potential directions. ",
    "url": "https://arxiv.org/abs/2302.00272",
    "authors": [
      "Weihuang Wen",
      "Tianshu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00288",
    "title": "CoderEval: A Benchmark of Pragmatic Code Generation with Generative  Pre-trained Models",
    "abstract": "Code generation models based on the pre-training and fine-tuning paradigm have been increasingly attempted by both academia and industry, resulting in well-known industrial models such as Codex, CodeGen, and PanGu-Coder. To validate the performance of these models, multiple existing benchmarks (e.g., AiXBench and HumanEval) are proposed, including only cases of generating a standalone function, i.e., a function that invokes or accesses only built-in functions and standard libraries. However, standalone functions constitute only about 30\\% of functions from real open-source projects. To assess a model's performance for pragmatic code generation (i.e., code generation for real settings of open source or proprietary code), in this paper, we propose a benchmark named CoderEval of pragmatic code generation with generative pre-trained models. Compared with the widely-used HumanEval benchmark from OpenAI, CoderEval can be used to assess the performance of models against pragmatic code generation beyond just generating standalone functions. Through the evaluation of three public available models (CodeGen, PanGu-Coder, and Codex) on CoderEval, we analyze and discuss the current progress and future directions of pragmatic code generation with a generative pre-trained model. ",
    "url": "https://arxiv.org/abs/2302.00288",
    "authors": [
      "Hao Yu",
      "Bo Shen",
      "Dezhi Ran",
      "Jiaxin Zhang",
      "Qi Zhang",
      "Yuchi Ma",
      "Guangtai Liang",
      "Ying Li",
      "Tao Xie",
      "Qianxiang Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.00290",
    "title": "Multispectral Pedestrian Detection via Reference Box Constrained Cross  Attention and Modality Balanced Optimization",
    "abstract": "Multispectral pedestrian detection is an important task for many around-the-clock applications, since the visible and thermal modalities can provide complementary information especially under low light conditions. To reduce the influence of hand-designed components in available multispectral pedestrian detectors, we propose a MultiSpectral pedestrian DEtection TRansformer (MS-DETR), which extends deformable DETR to multi-modal paradigm. In order to facilitate the multi-modal learning process, a Reference box Constrained Cross-Attention (RCCA) module is firstly introduced to the multi-modal Transformer decoder, which takes fusion branch together with the reference boxes as intermediaries to enable the interaction of visible and thermal modalities. To further balance the contribution of different modalities, we design a modality-balanced optimization strategy, which aligns the slots of decoders by adaptively adjusting the instance-level weight of three branches. Our end-to-end MS-DETR shows superior performance on the challenging KAIST and CVC-14 benchmark datasets. ",
    "url": "https://arxiv.org/abs/2302.00290",
    "authors": [
      "Yinghui Xing",
      "Song Wang",
      "Guoqiang Liang",
      "Qingyi Li",
      "Xiuwei Zhang",
      "Shizhou Zhang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.00293",
    "title": "A Survey of Methods, Challenges and Perspectives in Causality",
    "abstract": "The Causality field aims to find systematic methods for uncovering cause-effect relationships. Such methods can find applications in many research fields, justifying a great interest in this domain. Machine Learning models have shown success in a large variety of tasks by extracting correlation patterns from high-dimensional data but still struggle when generalizing out of their initial distribution. As causal engines aim to learn mechanisms that are independent from a data distribution, combining Machine Learning with Causality has the potential to bring benefits to the two fields. In our work, we motivate this assumption and provide applications. We first perform an extensive overview of the theories and methods for Causality from different perspectives. We then provide a deeper look at the connections between Causality and Machine Learning and describe the challenges met by the two domains. We show the early attempts to bring the fields together and the possible perspectives for the future. We finish by providing a large variety of applications for techniques from Causality. ",
    "url": "https://arxiv.org/abs/2302.00293",
    "authors": [
      "Ga\u00ebl Gendron",
      "Michael Witbrock",
      "Gillian Dobbie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.00302",
    "title": "A Deep Behavior Path Matching Network for Click-Through Rate Prediction",
    "abstract": "User behaviors on an e-commerce app not only contain different kinds of feedback on items but also sometimes imply the cognitive clue of the user's decision-making. For understanding the psychological procedure behind user decisions, we present the behavior path and propose to match the user's current behavior path with historical behavior paths to predict user behaviors on the app. Further, we design a deep neural network for behavior path matching and solve three difficulties in modeling behavior paths: sparsity, noise interference, and accurate matching of behavior paths. In particular, we leverage contrastive learning to augment user behavior paths, provide behavior path self-activation to alleviate the effect of noise, and adopt a two-level matching mechanism to identify the most appropriate candidate. Our model shows excellent performance on two real-world datasets, outperforming the state-of-the-art CTR model. Moreover, our model has been deployed on the Meituan food delivery platform and has accumulated 1.6% improvement in CTR and 1.8% improvement in advertising revenue. ",
    "url": "https://arxiv.org/abs/2302.00302",
    "authors": [
      "Jian Dong",
      "Yisong Yu",
      "Yapeng Zhang",
      "Yimin Lv",
      "Shuli Wang",
      "Beihong Jin",
      "Yongkang Wang",
      "Xingxing Wang",
      "Dong Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00325",
    "title": "Privacy Dashboards for Citizens and GDPR Services for Small Data  Holders: A Literature Review",
    "abstract": "Citizens have gained many rights with the GDPR, e.g. the right to get a copy of their personal data. In practice, however, this is fraught with problems for citizens and small data holders. We present a literature review on solutions promising relief in the form of privacy dashboards for citizens and GDPR services for small data holders. Covered topics are analyzed, categorized and compared. This is ought to be a step towards both enabling citizens to exercise their GDPR rights and supporting small data holders to comply with their GDPR duties. ",
    "url": "https://arxiv.org/abs/2302.00325",
    "authors": [
      "Nico Puhlmann",
      "Alex Wiesmaier",
      "Andreas Heinemann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.00338",
    "title": "A Robust Certificate Management System to Prevent Evil Twin Attacks in  IEEE 802.11 Networks",
    "abstract": "The evil twin attack is a major security threat to WLANs. An evil twin is a rogue AP installed by a malicious user to impersonate legitimate APs. It intends to attract victims in order to intercept their credentials, to steal their sensitive information, to eavesdrop on their data, etc. In this paper, we study the security mechanisms of wireless networks and we introduce the different authentication methods, including 802.1X authentication. We show that 802.1X has improved security through the use of digital certificates but does not define any practical technique for the user to check the network certificate. Therefore, it remains vulnerable to the evil twin attack. To repair this vulnerability, we introduce Robust Certificate Management System (RCMS) which takes advantage of the digital certificates of 802.1X to protect the users against rogue APs. RCMS defines a new verification code to allow the user device to check the network certificate. This practical verification combined with the reliability of digital certificates provides a perfect protection against rogue APs. RCMS requires a small software update on the user terminal and does not need any modification of IEEE 802.11. It has a significant flexibility since trusting a single AP is enough to trust all the APs of the extended network. This allows the administrators to extend their networks easily without the need to update any database of trusted APs on the user devices. ",
    "url": "https://arxiv.org/abs/2302.00338",
    "authors": [
      "Yousri Daldoul"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.00360",
    "title": "Faster maximal clique enumeration in large real-world link streams",
    "abstract": "Link streams offer a good model for representing interactions over time. They consist of links $(b,e,u,v)$, where $u$ and $v$ are vertices interacting during the whole time interval $[b,e]$. In this paper, we deal with the problem of enumerating maximal cliques in link streams. A clique is a pair $(C,[t_0,t_1])$, where $C$ is a set of vertices that all interact pairwise during the full interval $[t_0,t_1]$. It is maximal when neither its set of vertices nor its time interval can be increased. Some of the main works solving this problem are based on the famous Bron-Kerbosch algorithm for enumerating maximal cliques in graphs. We take this idea as a starting point to propose a new algorithm which matches the cliques of the instantaneous graphs formed by links existing at a given time $t$ to the maximal cliques of the link stream. We prove its validity and compute its complexity, which is better than the state-of-the art ones in many cases of interest. We also study the output-sensitive complexity, which is close to the output size, thereby showing that our algorithm is efficient. To confirm this, we perform experiments on link streams used in the state of the art, and on massive link streams, up to 100 million links. In all cases our algorithm is faster, mostly by a factor of at least 10 and up to a factor of $10^4$. Moreover, it scales to massive link streams for which the existing algorithms are not able to provide the solution. ",
    "url": "https://arxiv.org/abs/2302.00360",
    "authors": [
      "Alexis Baudin",
      "Cl\u00e9mence Magnien",
      "Lionel Tabourier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.00371",
    "title": "Simple yet Effective Gradient-Free Graph Convolutional Networks",
    "abstract": "Linearized Graph Neural Networks (GNNs) have attracted great attention in recent years for graph representation learning. Compared with nonlinear Graph Neural Network (GNN) models, linearized GNNs are much more time-efficient and can achieve comparable performances on typical downstream tasks such as node classification. Although some linearized GNN variants are purposely crafted to mitigate ``over-smoothing\", empirical studies demonstrate that they still somehow suffer from this issue. In this paper, we instead relate over-smoothing with the vanishing gradient phenomenon and craft a gradient-free training framework to achieve more efficient and effective linearized GNNs which can significantly overcome over-smoothing and enhance the generalization of the model. The experimental results demonstrate that our methods achieve better and more stable performances on node classification tasks with varying depths and cost much less training time. ",
    "url": "https://arxiv.org/abs/2302.00371",
    "authors": [
      "Yulin Zhu",
      "Xing Ai",
      "Qimai Li",
      "Xiao-Ming Wu",
      "Kai Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.00386",
    "title": "EfficientRep:An Efficient Repvgg-style ConvNets with Hardware-aware  Neural Network Design",
    "abstract": "We present a hardware-efficient architecture of convolutional neural network, which has a repvgg-like architecture. Flops or parameters are traditional metrics to evaluate the efficiency of networks which are not sensitive to hardware including computing ability and memory bandwidth. Thus, how to design a neural network to efficiently use the computing ability and memory bandwidth of hardware is a critical problem. This paper proposes a method how to design hardware-aware neural network. Based on this method, we designed EfficientRep series convolutional networks, which are high-computation hardware(e.g. GPU) friendly and applied in YOLOv6 object detection framework. YOLOv6 has published YOLOv6N/YOLOv6S/YOLOv6M/YOLOv6L models in v1 and v2 versions. ",
    "url": "https://arxiv.org/abs/2302.00386",
    "authors": [
      "Kaiheng Weng",
      "Xiangxiang Chu",
      "Xiaoming Xu",
      "Junshi Huang",
      "Xiaoming Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.00388",
    "title": "Short-term Prediction and Filtering of Solar Power Using State-Space  Gaussian Processes",
    "abstract": "Short-term forecasting of solar photovoltaic energy (PV) production is important for powerplant management. Ideally these forecasts are equipped with error bars, so that downstream decisions can account for uncertainty. To produce predictions with error bars in this setting, we consider Gaussian processes (GPs) for modelling and predicting solar photovoltaic energy production in the UK. A standard application of GP regression on the PV timeseries data is infeasible due to the large data size and non-Gaussianity of PV readings. However, this is made possible by leveraging recent advances in scalable GP inference, in particular, by using the state-space form of GPs, combined with modern variational inference techniques. The resulting model is not only scalable to large datasets but can also handle continuous data streams via Kalman filtering. ",
    "url": "https://arxiv.org/abs/2302.00388",
    "authors": [
      "Sean Nassimiha",
      "Peter Dudfield",
      "Jack Kelly",
      "Marc Peter Deisenroth",
      "So Takao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2302.00389",
    "title": "Multimodality Representation Learning: A Survey on Evolution,  Pretraining and Its Applications",
    "abstract": "Multimodality Representation Learning, as a technique of learning to embed information from different modalities and their correlations, has achieved remarkable success on a variety of applications, such as Visual Question Answering (VQA), Natural Language for Visual Reasoning (NLVR), and Vision Language Retrieval (VLR). Among these applications, cross-modal interaction and complementary information from different modalities are crucial for advanced models to perform any multimodal task, e.g., understand, recognize, retrieve, or generate optimally. Researchers have proposed diverse methods to address these tasks. The different variants of transformer-based architectures performed extraordinarily on multiple modalities. This survey presents the comprehensive literature on the evolution and enhancement of deep learning multimodal architectures to deal with textual, visual and audio features for diverse cross-modal and modern multimodal tasks. This study summarizes the (i) recent task-specific deep learning methodologies, (ii) the pretraining types and multimodal pretraining objectives, (iii) from state-of-the-art pretrained multimodal approaches to unifying architectures, and (iv) multimodal task categories and possible future improvements that can be devised for better multimodal learning. Moreover, we prepare a dataset section for new researchers that covers most of the benchmarks for pretraining and finetuning. Finally, major challenges, gaps, and potential research topics are explored. A constantly-updated paperlist related to our survey is maintained at https://github.com/marslanm/multimodality-representation-learning. ",
    "url": "https://arxiv.org/abs/2302.00389",
    "authors": [
      "Muhammad Arslan Manzoor",
      "Sarah Albarri",
      "Ziting Xian",
      "Zaiqiao Meng",
      "Preslav Nakov",
      "Shangsong Liang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00394",
    "title": "Toward a consistent performance evaluation for defect prediction models",
    "abstract": "In defect prediction community, many defect prediction models have been proposed and indeed more new models are continuously being developed. However, there is no consensus on how to evaluate the performance of a newly proposed model. In this paper, we aim to propose MATTER, a fraMework towArd a consisTenT pErformance compaRison, which makes model performance directly comparable across different studies. We take three actions to build a consistent evaluation framework for defect prediction models. First, we propose a simple and easy-to-use unsupervised baseline model ONE (glObal baseliNe modEl) to provide \"a single point of comparison\". Second, we propose using the SQA-effort-aligned threshold setting to make a fair comparison. Third, we suggest reporting the evaluation results in a unified way and provide a set of core performance indicators for this purpose, thus enabling an across-study comparison to attain real progress. The experimental results show that MATTER can serve as an effective framework to support a consistent performance evaluation for defect prediction models and hence can help determine whether a newly proposed defect prediction model is practically useful for practitioners and inform the real progress in the road of defect prediction. Furthermore, when applying MATTER to evaluate the representative defect prediction models proposed in recent years, we find that most of them (if not all) are not superior to the simple baseline model ONE in terms of the SQA-effort awareness prediction performance. This reveals that the real progress in defect prediction has been overestimated. We hence recommend that, in future studies, when any new defect prediction model is proposed, MATTER should be used to evaluate its actual usefulness (on the same benchmark test data sets) to advance scientific progress in defect prediction. ",
    "url": "https://arxiv.org/abs/2302.00394",
    "authors": [
      "Xutong Liu",
      "Shiran Liu",
      "Zhaoqiang Guo",
      "Peng Zhag",
      "Yibiao Yang",
      "Huihui Liu",
      "Hongmin Lu",
      "Yanhui Li",
      "Lin Chen",
      "Yuming Zhou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.00412",
    "title": "KNNs of Semantic Encodings for Rating Prediction",
    "abstract": "This paper explores a novel application of textual semantic similarity to user-preference representation for rating prediction. The approach represents a user's preferences as a graph of textual snippets from review text, where the edges are defined by semantic similarity. This textual, memory-based approach to rating prediction enables review-based explanations for recommendations. The method is evaluated quantitatively, highlighting that leveraging text in this way outperforms both strong memory-based and model-based collaborative filtering baselines. ",
    "url": "https://arxiv.org/abs/2302.00412",
    "authors": [
      "L\u00e9o Laugier",
      "Thomas Bonald",
      "Lucas Dixon",
      "Raghuram Vadapalli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.00419",
    "title": "For the Underrepresented in Gender Bias Research: Chinese Name Gender  Prediction with Heterogeneous Graph Attention Network",
    "abstract": "Achieving gender equality is an important pillar for humankind's sustainable future. Pioneering data-driven gender bias research is based on large-scale public records such as scientific papers, patents, and company registrations, covering female researchers, inventors and entrepreneurs, and so on. Since gender information is often missing in relevant datasets, studies rely on tools to infer genders from names. However, available open-sourced Chinese gender-guessing tools are not yet suitable for scientific purposes, which may be partially responsible for female Chinese being underrepresented in mainstream gender bias research and affect their universality. Specifically, these tools focus on character-level information while overlooking the fact that the combinations of Chinese characters in multi-character names, as well as the components and pronunciations of characters, convey important messages. As a first effort, we design a Chinese Heterogeneous Graph Attention (CHGAT) model to capture the heterogeneity in component relationships and incorporate the pronunciations of characters. Our model largely surpasses current tools and also outperforms the state-of-the-art algorithm. Last but not least, the most popular Chinese name-gender dataset is single-character based with far less female coverage from an unreliable source, naturally hindering relevant studies. We open-source a more balanced multi-character dataset from an official source together with our code, hoping to help future research promoting gender equality. ",
    "url": "https://arxiv.org/abs/2302.00419",
    "authors": [
      "Zihao Pan",
      "Kai Peng",
      "Shuai Ling",
      "Haipeng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00431",
    "title": "Do I Have Your Attention: A Large Scale Engagement Prediction Dataset  and Baselines",
    "abstract": "The degree of concentration, enthusiasm, optimism, and passion displayed by individual(s) while interacting with a machine is referred to as `user engagement'. Engagement comprises of behavioural, cognitive, and affect related cues. To create engagement predictions systems, which can work in real-world conditions it is quintessential to learn from rich diverse datasets. To this end, a large scale multi-faceted engagement in the wild dataset is proposed. 31 hours duration data of 127 participants representing different illumination conditions is recorded. Thorough experiments are performed exploring applicability of different features action units, eye gaze and head pose and transformers. To further validate the rich nature of the dataset, evaluation is also performed on the EngageWild dataset. The experiments show the usefulness of the proposed dataset. The code, models and dataset will be made publicly available. ",
    "url": "https://arxiv.org/abs/2302.00431",
    "authors": [
      "Monisha Singh",
      "Ximi Hoque",
      "Donghuo Zeng",
      "Yanan Wang",
      "Kazushi Ikeda",
      "Abhinav Dhall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.00438",
    "title": "On the Robustness of Code Generation Techniques: An Empirical Study on  GitHub Copilot",
    "abstract": "Software engineering research has always being concerned with the improvement of code completion approaches, which suggest the next tokens a developer will likely type while coding. The release of GitHub Copilot constitutes a big step forward, also because of its unprecedented ability to automatically generate even entire functions from their natural language description. While the usefulness of Copilot is evident, it is still unclear to what extent it is robust. Specifically, we do not know the extent to which semantic-preserving changes in the natural language description provided to the model have an effect on the generated code function. In this paper we present an empirical study in which we aim at understanding whether different but semantically equivalent natural language descriptions result in the same recommended function. A negative answer would pose questions on the robustness of deep learning (DL)-based code generators since it would imply that developers using different wordings to describe the same code would obtain different recommendations. We asked Copilot to automatically generate 892 Java methods starting from their original Javadoc description. Then, we generated different semantically equivalent descriptions for each method both manually and automatically, and we analyzed the extent to which predictions generated by Copilot changed. Our results show that modifying the description results in different code recommendations in ~46% of cases. Also, differences in the semantically equivalent descriptions might impact the correctness of the generated code ~28%. ",
    "url": "https://arxiv.org/abs/2302.00438",
    "authors": [
      "Antonio Mastropaolo",
      "Luca Pascarella",
      "Emanuela Guglielmi",
      "Matteo Ciniselli",
      "Simone Scalabrino",
      "Rocco Oliveto",
      "Gabriele Bavota"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.00457",
    "title": "Simplicity Bias in 1-Hidden Layer Neural Networks",
    "abstract": "Recent works have demonstrated that neural networks exhibit extreme simplicity bias(SB). That is, they learn only the simplest features to solve a task at hand, even in the presence of other, more robust but more complex features. Due to the lack of a general and rigorous definition of features, these works showcase SB on semi-synthetic datasets such as Color-MNIST, MNIST-CIFAR where defining features is relatively easier. In this work, we rigorously define as well as thoroughly establish SB for one hidden layer neural networks. More concretely, (i) we define SB as the network essentially being a function of a low dimensional projection of the inputs (ii) theoretically, we show that when the data is linearly separable, the network primarily depends on only the linearly separable ($1$-dimensional) subspace even in the presence of an arbitrarily large number of other, more complex features which could have led to a significantly more robust classifier, (iii) empirically, we show that models trained on real datasets such as Imagenette and Waterbirds-Landbirds indeed depend on a low dimensional projection of the inputs, thereby demonstrating SB on these datasets, iv) finally, we present a natural ensemble approach that encourages diversity in models by training successive models on features not used by earlier models, and demonstrate that it yields models that are significantly more robust to Gaussian noise. ",
    "url": "https://arxiv.org/abs/2302.00457",
    "authors": [
      "Depen Morwani",
      "Jatin Batra",
      "Prateek Jain",
      "Praneeth Netrapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.00485",
    "title": "Equivariant Message Passing Neural Network for Crystal Material  Discovery",
    "abstract": "Automatic material discovery with desired properties is a fundamental challenge for material sciences. Considerable attention has recently been devoted to generating stable crystal structures. While existing work has shown impressive success on supervised tasks such as property prediction, the progress on unsupervised tasks such as material generation is still hampered by the limited extent to which the equivalent geometric representations of the same crystal are considered. To address this challenge, we propose EMPNN a periodic equivariant message-passing neural network that learns crystal lattice deformation in an unsupervised fashion. Our model equivalently acts on lattice according to the deformation action that must be performed, making it suitable for crystal generation, relaxation and optimisation. We present experimental evaluations that demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2302.00485",
    "authors": [
      "Astrid Klipfel",
      "Olivier Peltre",
      "Najwa Harrati",
      "Ya\u00ebl Fregier",
      "Adlane Sayede",
      "Zied Bouraoui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00500",
    "title": "Serious Games and AI: Challenges and Opportunities for Computational  Social Science",
    "abstract": "The video game industry plays an essential role in the entertainment sphere of our society. However, from Monopoly to Flight Simulators, serious games have also been appealing tools for learning a new language, conveying values, or training skills. Furthermore, the resurgence of Artificial Intelligence (AI) and data science in the last decade has created a unique opportunity since the amount of data collected through a game is immense, as is the amount of data needed to feed such AI algorithms. This paper aims to identify relevant research lines using Serious Games as a novel research tool, especially in Computational Social Sciences. To contextualize, we also conduct a (non-systematic) literature review of this field. We conclude that the synergy between games and data can foster the use of AI for good and open up new strategies to empower humanity and support social research with novel computational tools. We also discuss the challenges and new opportunities that arise from aspiring to such lofty goals. ",
    "url": "https://arxiv.org/abs/2302.00500",
    "authors": [
      "Jaime P\u00e9rez",
      "Mario Castro",
      "Gregorio L\u00f3pez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.00504",
    "title": "Anomaly, reciprocity, and community detection in networks",
    "abstract": "Anomaly detection algorithms are a valuable tool in network science for identifying unusual patterns in a network. These algorithms have numerous practical applications, including detecting fraud, identifying network security threats, and uncovering significant interactions within a dataset. In this project, we propose a probabilistic generative approach that incorporates community membership and reciprocity as key factors driving regular behavior in a network, which can be used to identify potential anomalies that deviate from expected patterns. We model pairs of edges in a network with exact two-edge joint distributions. As a result, our approach captures the exact relationship between pairs of edges and provides a more comprehensive view of social networks. Additionally, our study highlights the role of reciprocity in network analysis and can inform the design of future models and algorithms. We also develop an efficient algorithmic implementation that takes advantage of the sparsity of the network. ",
    "url": "https://arxiv.org/abs/2302.00504",
    "authors": [
      "Hadiseh Safdari",
      "Martina Contisciani",
      "Caterina De Bacco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.00506",
    "title": "Decentralized Stream Runtime Verification for Timed Asynchronous  Networks",
    "abstract": "We study the problem of monitoring distributed systems where computers communicate using message passing and share an almost synchronized clock. This is a realistic scenario for networks where the speed of the monitoring is sufficiently slow (at the human scale) to permit efficient clock synchronization, where the clock deviations is small compared to the monitoring cycles. This is the case when monitoring human systems in wide area networks, the Internet or including large deployments. More concretely, we study how to monitor decentralized systems where monitors are expressed as stream runtime verification specifications, under a timed asynchronous network. Our monitors communicate using the network, where messages can take arbitrarily long but cannot be duplicated or lost. This communication setting is common in many cyber-physical systems like smart buildings and ambient living. Previous approaches to decentralized monitoring were limited to synchronous networks, which are not easily implemented in practice because of network failures. Even when networks failures are unusual, they can require several monitoring cycles to be repaired. In this work we propose a solution to the timed asynchronous monitoring problem and show that this problem generalizes the synchronous case. We study the specifications and conditions on the network behavior that allow the monitoring to take place with bounded resources, independently of the trace length. Finally, we report the results of an empirical evaluation of an implementation and verify the theoretical results in terms of effectiveness and efficiency. ",
    "url": "https://arxiv.org/abs/2302.00506",
    "authors": [
      "Luis Miguel Danielsson",
      "C\u00e9sar S\u00e1nchez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2302.00517",
    "title": "Synthesis-based Imaging-Differentiation Representation Learning for  Multi-Sequence 3D/4D MRI",
    "abstract": "Multi-sequence MRIs can be necessary for reliable diagnosis in clinical practice due to the complimentary information within sequences. However, redundant information exists across sequences, which interferes with mining efficient representations by modern machine learning or deep learning models. To handle various clinical scenarios, we propose a sequence-to-sequence generation framework (Seq2Seq) for imaging-differentiation representation learning. In this study, not only do we propose arbitrary 3D/4D sequence generation within one model to generate any specified target sequence, but also we are able to rank the importance of each sequence based on a new metric estimating the difficulty of a sequence being generated. Furthermore, we also exploit the generation inability of the model to extract regions that contain unique information for each sequence. We conduct extensive experiments using three datasets including a toy dataset of 20,000 simulated subjects, a brain MRI dataset of 1,251 subjects, and a breast MRI dataset of 2,101 subjects, to demonstrate that (1) our proposed Seq2Seq is efficient and lightweight for complex clinical datasets and can achieve excellent image quality; (2) top-ranking sequences can be used to replace complete sequences with non-inferior performance; (3) combining MRI with our imaging-differentiation map leads to better performance in clinical tasks such as glioblastoma MGMT promoter methylation status prediction and breast cancer pathological complete response status prediction. Our code is available at https://github.com/fiy2W/mri_seq2seq. ",
    "url": "https://arxiv.org/abs/2302.00517",
    "authors": [
      "Luyi Han",
      "Tao Tan",
      "Tianyu Zhang",
      "Yunzhi Huang",
      "Xin Wang",
      "Yuan Gao",
      "Jonas Teuwen",
      "Ritse Mann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.00537",
    "title": "Effectiveness of Moving Target Defenses for Adversarial Attacks in  ML-based Malware Detection",
    "abstract": "Several moving target defenses (MTDs) to counter adversarial ML attacks have been proposed in recent years. MTDs claim to increase the difficulty for the attacker in conducting attacks by regularly changing certain elements of the defense, such as cycling through configurations. To examine these claims, we study for the first time the effectiveness of several recent MTDs for adversarial ML attacks applied to the malware detection domain. Under different threat models, we show that transferability and query attack strategies can achieve high levels of evasion against these defenses through existing and novel attack strategies across Android and Windows. We also show that fingerprinting and reconnaissance are possible and demonstrate how attackers may obtain critical defense hyperparameters as well as information about how predictions are produced. Based on our findings, we present key recommendations for future work on the development of effective MTDs for adversarial attacks in ML-based malware detection. ",
    "url": "https://arxiv.org/abs/2302.00537",
    "authors": [
      "Aqib Rashid",
      "Jose Such"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00545",
    "title": "An Out-of-Domain Synapse Detection Challenge for Microwasp Brain  Connectomes",
    "abstract": "The size of image stacks in connectomics studies now reaches the terabyte and often petabyte scales with a great diversity of appearance across brain regions and samples. However, manual annotation of neural structures, e.g., synapses, is time-consuming, which leads to limited training data often smaller than 0.001\\% of the test data in size. Domain adaptation and generalization approaches were proposed to address similar issues for natural images, which were less evaluated on connectomics data due to a lack of out-of-domain benchmarks. ",
    "url": "https://arxiv.org/abs/2302.00545",
    "authors": [
      "Jingpeng Wu",
      "Yicong Li",
      "Nishika Gupta",
      "Kazunori Shinomiya",
      "Pat Gunn",
      "Alexey Polilov",
      "Hanspeter Pfister",
      "Dmitri Chklovskii",
      "Donglai Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2302.00557",
    "title": "Graph Neural Network Based Surrogate Model of Physics Simulations for  Geometry Design",
    "abstract": "Computational Intelligence (CI) techniques have shown great potential as a surrogate model of expensive physics simulation, with demonstrated ability to make fast predictions, albeit at the expense of accuracy in some cases. For many scientific and engineering problems involving geometrical design, it is desirable for the surrogate models to precisely describe the change in geometry and predict the consequences. In that context, we develop graph neural networks (GNNs) as fast surrogate models for physics simulation, which allow us to directly train the models on 2/3D geometry designs that are represented by an unstructured mesh or point cloud, without the need for any explicit or hand-crafted parameterization. We utilize an encoder-processor-decoder-type architecture which can flexibly make prediction at both node level and graph level. The performance of our proposed GNN-based surrogate model is demonstrated on 2 example applications: feature designs in the domain of additive engineering and airfoil design in the domain of aerodynamics. The models show good accuracy in their predictions on a separate set of test geometries after training, with almost instant prediction speeds, as compared to O(hour) for the high-fidelity simulations required otherwise. ",
    "url": "https://arxiv.org/abs/2302.00557",
    "authors": [
      "Jian Cheng Wong",
      "Chin Chun Ooi",
      "Joyjit Chattoraj",
      "Lucas Lestandi",
      "Guoying Dong",
      "Umesh Kizhakkinan",
      "David William Rosen",
      "Mark Hyunpong Jhon",
      "My Ha Dao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00559",
    "title": "Structured mutation inspired by evolutionary theory enriches population  performance and diversity",
    "abstract": "Grammar-Guided Genetic Programming (GGGP) employs a variety of insights from evolutionary theory to autonomously design solutions for a given task. Recent insights from evolutionary biology can lead to further improvements in GGGP algorithms. In this paper, we apply principles from the theory of Facilitated Variation and knowledge about heterogeneous mutation rates and mutation effects to improve the variation operators. We term this new method of variation Facilitated Mutation (FM). We test FM performance on the evolution of neural network optimizers for image classification, a relevant task in evolutionary computation, with important implications for the field of machine learning. We compare FM and FM combined with crossover (FMX) against a typical mutation regime to assess the benefits of the approach. We find that FMX in particular provides statistical improvements in key metrics, creating a superior optimizer overall (+0.48\\% average test accuracy), improving the average quality of solutions (+50\\% average population fitness), and discovering more diverse high-quality behaviors (+400 high-quality solutions discovered per run on average). Additionally, FM and FMX can reduce the number of fitness evaluations in an evolutionary run, reducing computational costs in some scenarios. ",
    "url": "https://arxiv.org/abs/2302.00559",
    "authors": [
      "Stefano Tiso",
      "Pedro Carvalho",
      "Nuno Louren\u00e7o",
      "Penousal Machado"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.00609",
    "title": "Zero Shot Transfer of Legal Judgement Prediction as Article-aware  Entailment for the European Court of Human Rights",
    "abstract": "In this paper, we cast Legal Judgment Prediction (LJP) from text on European Court of Human Rights cases as an entailment task, where the case outcome is classified from a combined input of case facts and convention articles. This configuration facilitates the model learning legal reasoning ability in mapping article text to specific fact text. It also provides the opportunity to evaluate the model's ability to generalize to zero-shot settings when asked to classify the case outcome with respect to articles not seen during training. We devise zero-shot LJP experiments and apply domain adaptation methods based on domain discriminator and Wasserstein distance. Our results demonstrate that the entailment architecture outperforms straightforward fact classification. We also find that domain adaptation methods improve zero-shot transfer performance, with article relatedness and encoder pre-training influencing the effect. ",
    "url": "https://arxiv.org/abs/2302.00609",
    "authors": [
      "Santosh T.Y.S.S",
      "Oana Ichim",
      "Matthias Grabmair"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.00617",
    "title": "Efficient Meta-Learning via Error-based Context Pruning for Implicit  Neural Representations",
    "abstract": "We introduce an efficient optimization-based meta-learning technique for learning large-scale implicit neural representations (INRs). Our main idea is designing an online selection of context points, which can significantly reduce memory requirements for meta-learning in any established setting. By doing so, we expect additional memory savings which allows longer per-signal adaptation horizons (at a given memory budget), leading to better meta-initializations by reducing myopia and, more crucially, enabling learning on high-dimensional signals. To implement such context pruning, our technical novelty is three-fold. First, we propose a selection scheme that adaptively chooses a subset at each adaptation step based on the predictive error, leading to the modeling of the global structure of the signal in early steps and enabling the later steps to capture its high-frequency details. Second, we counteract any possible information loss from context pruning by minimizing the parameter distance to a bootstrapped target model trained on a full context set. Finally, we suggest using the full context set with a gradient scaling scheme at test-time. Our technique is model-agnostic, intuitive, and straightforward to implement, showing significant reconstruction improvements for a wide range of signals. Code is available at https://github.com/jihoontack/ECoP ",
    "url": "https://arxiv.org/abs/2302.00617",
    "authors": [
      "Jihoon Tack",
      "Subin Kim",
      "Sihyun Yu",
      "Jaeho Lee",
      "Jinwoo Shin",
      "Jonathan Richard Schwarz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00623",
    "title": "Accordion: A Communication-Aware Machine Learning Framework for Next  Generation Networks",
    "abstract": "In this article, we advocate for the design of ad hoc artificial intelligence (AI)/machine learning (ML) models to facilitate their usage in future smart infrastructures based on communication networks. To motivate this, we first review key operations identified by the 3GPP for transferring AI/ML models through 5G networks and the main existing techniques to reduce their communication overheads. We also present a novel communication-aware ML framework, which we refer to as Accordion, that enables an efficient AI/ML model transfer thanks to an overhauled model training and communication protocol. We demonstrate the communication-related benefits of Accordion, analyse key performance trade-offs, and discuss potential research directions within this realm. ",
    "url": "https://arxiv.org/abs/2302.00623",
    "authors": [
      "Fadhel Ayed",
      "Antonio De Domenico",
      "Adrian Garcia-Rodriguez",
      "David Lopez-Perez"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.00633",
    "title": "Deep Dependency Networks for Multi-Label Classification",
    "abstract": "We propose a simple approach which combines the strengths of probabilistic graphical models and deep learning architectures for solving the multi-label classification task, focusing specifically on image and video data. First, we show that the performance of previous approaches that combine Markov Random Fields with neural networks can be modestly improved by leveraging more powerful methods such as iterative join graph propagation, integer linear programming, and $\\ell_1$ regularization-based structure learning. Then we propose a new modeling framework called deep dependency networks, which augments a dependency network, a model that is easy to train and learns more accurate dependencies but is limited to Gibbs sampling for inference, to the output layer of a neural network. We show that despite its simplicity, jointly learning this new architecture yields significant improvements in performance over the baseline neural network. In particular, our experimental evaluation on three video activity classification datasets: Charades, Textually Annotated Cooking Scenes (TACoS), and Wetlab, and three multi-label image classification datasets: MS-COCO, PASCAL VOC, and NUS-WIDE show that deep dependency networks are almost always superior to pure neural architectures that do not use dependency networks. ",
    "url": "https://arxiv.org/abs/2302.00633",
    "authors": [
      "Shivvrat Arya",
      "Yu Xiang",
      "Vibhav Gogate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.00647",
    "title": "Identification of an influence network using ensemble-based filtering  for Hawkes processes driven by count data",
    "abstract": "Many networks have event-driven dynamics (such as communication, social media and criminal networks), where the mean rate of the events occurring at a node in the network changes according to the occurrence of other events in the network. In particular, events associated with a node of the network could increase the rate of events at other nodes, depending on their influence relationship. Thus, it is of interest to use temporal data to uncover the directional, time-dependent, influence structure of a given network while also quantifying uncertainty even when knowledge of a physical network is lacking. Typically, methods for inferring the influence structure in networks require knowledge of a physical network or are only able to infer small network structures. In this paper, we model event-driven dynamics on a network by a multidimensional Hawkes process. We then develop a novel ensemble-based filtering approach for a time-series of count data (i.e., data that provides the number of events per unit time for each node in the network) that not only tracks the influence network structure over time but also approximates the uncertainty via ensemble spread. The method overcomes several deficiencies in existing methods such as existing methods for inferring multidimensional Hawkes processes are too slow to be practical for any network over ~50 nodes, can only deal with timestamp data (i.e. data on just when events occur not the number of events at each node), and that we do not need a physical network to start with. Our method is massively parallelizable, allowing for its use to infer the influence structure of large networks (~10,000 nodes). We demonstrate our method for large networks using both synthetic and real-world email communication data. ",
    "url": "https://arxiv.org/abs/2302.00647",
    "authors": [
      "Santitissadeekorn N.",
      "Delahaies S.",
      "Lloyd D.J.B"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2302.00648",
    "title": "Image-Based Vehicle Classification by Synergizing Features from  Supervised and Self-Supervised Learning Paradigms",
    "abstract": "This paper introduces a novel approach to leverage features learned from both supervised and self-supervised paradigms, to improve image classification tasks, specifically for vehicle classification. Two state-of-the-art self-supervised learning methods, DINO and data2vec, were evaluated and compared for their representation learning of vehicle images. The former contrasts local and global views while the latter uses masked prediction on multi-layered representations. In the latter case, supervised learning is employed to finetune a pretrained YOLOR object detector for detecting vehicle wheels, from which definitive wheel positional features are retrieved. The representations learned from these self-supervised learning methods were combined with the wheel positional features for the vehicle classification task. Particularly, a random wheel masking strategy was utilized to finetune the previously learned representations in harmony with the wheel positional features during the training of the classifier. Our experiments show that the data2vec-distilled representations, which are consistent with our wheel masking strategy, outperformed the DINO counterpart, resulting in a celebrated Top-1 classification accuracy of 97.2% for classifying the 13 vehicle classes defined by the Federal Highway Administration. ",
    "url": "https://arxiv.org/abs/2302.00648",
    "authors": [
      "Shihan Ma",
      "Jidong J. Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.00651",
    "title": "Ngram-LSTM Open Rate Prediction Model (NLORP) and Error_accuracy@C  metric: Simple effective, and easy to implement approach to predict open  rates for marketing email",
    "abstract": "Our generation has seen an exponential increase in digital tools adoption. One of the unique areas where digital tools have made an exponential foray is in the sphere of digital marketing, where goods and services have been extensively promoted through the use of digital advertisements. Following this growth, multiple companies have leveraged multiple apps and channels to display their brand identities to a significantly larger user base. This has resulted in products, worth billions of dollars to be sold online. Emails and push notifications have become critical channels to publish advertisement content, to proactively engage with their contacts. Several marketing tools provide a user interface for marketers to design Email and Push messages for digital marketing campaigns. Marketers are also given a predicted open rate for the entered subject line. For enabling marketers generate targeted subject lines, multiple machine learning techniques have been used in the recent past. In particular, deep learning techniques that have established good effectiveness and efficiency. However, these techniques require a sizable amount of labelled training data in order to get good results. The creation of such datasets, particularly those with subject lines that have a specific theme, is a challenging and time-consuming task. In this paper, we propose a novel Ngram and LSTM-based modeling approach (NLORPM) to predict open rates of entered subject lines that is easier to implement, has low prediction latency, and performs extremely well for sparse data. To assess the performance of this model, we also devise a new metric called 'Error_accuracy@C' which is simple to grasp and fully comprehensible to marketers. ",
    "url": "https://arxiv.org/abs/2302.00651",
    "authors": [
      "Shubham Joshi",
      "Indradumna Banerjee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.00657",
    "title": "Adding a Tail in Classes of Perfect Graphs",
    "abstract": "Consider a graph $G$ which belongs to a graph class ${\\cal C}$. We are interested in connecting a node $w \\not\\in V(G)$ to $G$ by a single edge $u w$ where $u \\in V(G)$; we call such an edge a \\emph{tail}. As the graph resulting from $G$ after the addition of the tail, denoted $G+uw$, need not belong to the class ${\\cal C}$, we want to compute a minimum ${\\cal C}$-completion of $G+w$, i.e., the minimum number of non-edges (excluding the tail $u w$) to be added to $G+uw$ so that the resulting graph belongs to ${\\cal C}$. In this paper, we study this problem for the classes of split, quasi-threshold, threshold, and $P_4$-sparse graphs and we present linear-time algorithms by exploiting the structure of split graphs and the tree representation of quasi-threshold, threshold, and $P_4$-sparse graphs. ",
    "url": "https://arxiv.org/abs/2302.00657",
    "authors": [
      "Anna Mpanti",
      "Stavros D. Nikolopoulos",
      "Leonidas Palios"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.00658",
    "title": "Graph Neural Operators for Classification of Spatial Transcriptomics  Data",
    "abstract": "The inception of spatial transcriptomics has allowed improved comprehension of tissue architectures and the disentanglement of complex underlying biological, physiological, and pathological processes through their positional contexts. Recently, these contexts, and by extension the field, have seen much promise and elucidation with the application of graph learning approaches. In particular, neural operators have risen in regards to learning the mapping between infinite-dimensional function spaces. With basic to deep neural network architectures being data-driven, i.e. dependent on quality data for prediction, neural operators provide robustness by offering generalization among different resolutions despite low quality data. Graph neural operators are a variant that utilize graph networks to learn this mapping between function spaces. The aim of this research is to identify robust machine learning architectures that integrate spatial information to predict tissue types. Under this notion, we propose a study incorporating various graph neural network approaches to validate the efficacy of applying neural operators towards prediction of brain regions in mouse brain tissue samples as a proof of concept towards our purpose. We were able to achieve an F1 score of nearly 72% for the graph neural operator approach which outperformed all baseline and other graph network approaches. ",
    "url": "https://arxiv.org/abs/2302.00658",
    "authors": [
      "Junaid Ahmed",
      "Alhassan S. Yasin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.00667",
    "title": "Does Vision Accelerate Hierarchical Generalization of Neural Language  Learners?",
    "abstract": "Neural language models (LMs) are arguably less data-efficient than humans -- why does this gap occur? In this study, we hypothesize that this gap stems from the learners' accessibility to modalities other than text, specifically, vision. We conducted two complementary experiments (using noisy, realistic data and a simplified, artificial one) toward the advantage of vision in the syntactic generalization of LMs. Our results showed that vision accelerated a proper linguistic generalization in the simplified, artificial setting, but LMs struggled with the noisy, realistic setting. These mixed results indicate several possibilities, e.g., vision can potentially boost language acquisition, but learners' additional visual/linguistic prior knowledge should be needed to robustly make use of raw images for efficient language acquisition. ",
    "url": "https://arxiv.org/abs/2302.00667",
    "authors": [
      "Tatsuki Kuribayashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.00156",
    "title": "Beam Selection for Energy-Efficient mmWave Network Using Advantage Actor  Critic Learning",
    "abstract": "The growing adoption of mmWave frequency bands to realize the full potential of 5G, turns beamforming into a key enabler for current and next-generation wireless technologies. Many mmWave networks rely on beam selection with Grid-of-Beams (GoB) approach to handle user-beam association. In beam selection with GoB, users select the appropriate beam from a set of pre-defined beams and the overhead during the beam selection process is a common challenge in this area. In this paper, we propose an Advantage Actor Critic (A2C) learning-based framework to improve the GoB and the beam selection process, as well as optimize transmission power in a mmWave network. The proposed beam selection technique allows performance improvement while considering transmission power improves Energy Efficiency (EE) and ensures the coverage is maintained in the network. We further investigate how the proposed algorithm can be deployed in a Service Management and Orchestration (SMO) platform. Our simulations show that A2C-based joint optimization of beam selection and transmission power is more effective than using Equally Spaced Beams (ESB) and fixed power strategy, or optimization of beam selection and transmission power disjointly. Compared to the ESB and fixed transmission power strategy, the proposed approach achieves more than twice the average EE in the scenarios under test and is closer to the maximum theoretical EE. ",
    "url": "https://arxiv.org/abs/2302.00156",
    "authors": [
      "Ycaro Dantas",
      "Pedro Enrique Iturria-Rivera",
      "Hao Zhou",
      "Majid Bavand",
      "Medhat Elsayed",
      "Raimundas Gaigalas",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.00205",
    "title": "Gradient Descent in Neural Networks as Sequential Learning in RKBS",
    "abstract": "The study of Neural Tangent Kernels (NTKs) has provided much needed insight into convergence and generalization properties of neural networks in the over-parametrized (wide) limit by approximating the network using a first-order Taylor expansion with respect to its weights in the neighborhood of their initialization values. This allows neural network training to be analyzed from the perspective of reproducing kernel Hilbert spaces (RKHS), which is informative in the over-parametrized regime, but a poor approximation for narrower networks as the weights change more during training. Our goal is to extend beyond the limits of NTK toward a more general theory. We construct an exact power-series representation of the neural network in a finite neighborhood of the initial weights as an inner product of two feature maps, respectively from data and weight-step space, to feature space, allowing neural network training to be analyzed from the perspective of reproducing kernel {\\em Banach} space (RKBS). We prove that, regardless of width, the training sequence produced by gradient descent can be exactly replicated by regularized sequential learning in RKBS. Using this, we present novel bound on uniform convergence where the iterations count and learning rate play a central role, giving new theoretical insight into neural network training. ",
    "url": "https://arxiv.org/abs/2302.00205",
    "authors": [
      "Alistair Shilton",
      "Sunil Gupta",
      "Santu Rana",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00250",
    "title": "Quickest Change Detection for Unnormalized Statistical Models",
    "abstract": "Classical quickest change detection algorithms require modeling pre-change and post-change distributions. Such an approach may not be feasible for various machine learning models because of the complexity of computing the explicit distributions. Additionally, these methods may suffer from a lack of robustness to model mismatch and noise. This paper develops a new variant of the classical Cumulative Sum (CUSUM) algorithm for the quickest change detection. This variant is based on Fisher divergence and the Hyv\\\"arinen score and is called the Score-based CUSUM (SCUSUM) algorithm. The SCUSUM algorithm allows the applications of change detection for unnormalized statistical models, i.e., models for which the probability density function contains an unknown normalization constant. The asymptotic optimality of the proposed algorithm is investigated by deriving expressions for average detection delay and the mean running time to a false alarm. Numerical results are provided to demonstrate the performance of the proposed algorithm. ",
    "url": "https://arxiv.org/abs/2302.00250",
    "authors": [
      "Suya Wu",
      "Enmao Diao",
      "Taposh Banerjee",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00267",
    "title": "InQuIR: Intermediate Representation for Interconnected Quantum Computers",
    "abstract": "Various physical constraints limit the number of qubits that can be implemented in a single quantum processor, and thus it is necessary to connect multiple quantum processors via quantum interconnects. While several compiler implementations for interconnected quantum computers have been proposed, there is no suitable representation as their compilation target. The lack of such representation impairs the reusability of compiled programs and makes it difficult to reason formally about the complicated behavior of distributed quantum programs. We propose InQuIR, an intermediate representation that can express communication and computation on distributed quantum systems. InQuIR has formal semantics that allows us to describe precisely the behaviors of distributed quantum programs. We give examples written in InQuIR to illustrate the problems arising in distributed programs, such as deadlock. We present a roadmap for static verification using type systems to deal with such a problem. We also provide software tools for InQuIR and evaluate the computational costs of quantum circuits under various conditions. Our tools are available at https://github.com/team-InQuIR/InQuIR. ",
    "url": "https://arxiv.org/abs/2302.00267",
    "authors": [
      "Shin Nishio",
      "Ryo Wakizaka"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2302.00273",
    "title": "Hardness of braided quantum circuit optimization in the surface code",
    "abstract": "Large-scale quantum information processing requires the use of quantum error correcting codes to mitigate the effects of noise in quantum devices. Topological error-correcting codes, such as surface codes, are promising candidates as they can be implemented using only local interactions in a two-dimensional array of physical qubits. Procedures such as defect braiding and lattice surgery can then be used to realize a fault-tolerant universal set of gates on the logical space of such topological codes. However, error correction also introduces a significant overhead in computation time, the number of physical qubits, and the number of physical gates. While optimizing fault-tolerant circuits to minimize this overhead is critical, the computational complexity of such optimization problems remains unknown. This ambiguity leaves room for doubt surrounding the most effective methods for compiling fault-tolerant circuits for a large-scale quantum computer. In this paper, we show that the optimization of a special subset of braided quantum circuits is NP-hard by a polynomial-time reduction of the optimization problem into a specific problem called Planar Rectilinear 3SAT. ",
    "url": "https://arxiv.org/abs/2302.00273",
    "authors": [
      "Kunihiro Wasa",
      "Shin Nishio",
      "Koki Suetsugu",
      "Michael Hanks",
      "Ashley Stephens",
      "Yu Yokoi",
      "Kae Nemoto"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2302.00281",
    "title": "Informationally Robust Cheap-Talk",
    "abstract": "We study the robustness of cheap-talk equilibria to infinitesimal private information of the receiver in a model with a binary state-space and state-independent sender-preferences. We show that the sender-optimal equilibrium is robust if and only if this equilibrium either reveals no information to the receiver or fully reveals one of the states with positive probability. We then characterize the actions that can be played with positive probability in any robust equilibrium. Finally, we fully characterize the optimal sender-utility under binary receiver's private information, and provide bounds for the optimal sender-utility under general private information. ",
    "url": "https://arxiv.org/abs/2302.00281",
    "authors": [
      "Itai Arieli",
      "Ronen Gradwohl",
      "Rann Smorodinsky"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.00341",
    "title": "Predicting CSI Sequences With Attention-Based Neural Networks",
    "abstract": "In this work, we consider the problem of multi-step channel prediction in wireless communication systems. In existing works, autoregressive (AR) models are either replaced or combined with feed-forward neural networks(NNs) or, alternatively, with recurrent neural networks (RNNs). This paper explores the possibility of using sequence-to-sequence (Seq2Seq) and transformer neural network (TNN) models for channel state information (CSI) prediction. Simulation results show that both, Seq2Seq and TNNs, represent an appealing alternative to RNNs and feed-forward NNs in the context of CSI prediction. Additionally, the TNN with a few adaptations can extrapolate better than other models to CSI sequences that are either shorter or longer than the ones the model saw during training. ",
    "url": "https://arxiv.org/abs/2302.00341",
    "authors": [
      "Valentina Rizzello",
      "Benedikt B\u00f6ck",
      "Michael Joham",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.00352",
    "title": "Flip-width: Cops and Robber on dense graphs",
    "abstract": "We define new graph parameters that generalize tree-width, degeneracy, and generalized coloring numbers for sparse graphs, and clique-width and twin-width for dense graphs. Those parameters are defined using variants of the Cops and Robber game, in which the robber has speed bounded by a fixed constant $r\\in\\mathbb N\\cup\\{\\infty\\}$, and the cops perform flips (or perturbations) of the considered graph. We propose a new notion of tameness of a graph class, called bounded flip-width, which is a dense counterpart of classes of bounded expansion of Ne\\v{s}et\\v{r}il and Ossona de Mendez, and includes classes of bounded twin-width of Bonnet, Kim, Thomass\\'e and Watrigant. We prove that boundedness of flip-width is preserved by first-order interpretations, or transductions, generalizing previous results concerning classes of bounded expansion and bounded twin-width. We provide an algorithm approximating the flip-width of a given graph, which runs in slicewise polynomial time (XP) in the size of the graph. We also propose a more general notion of tameness, called almost bounded flip-width, which is a dense counterpart of nowhere dense classes, and includes all structurally nowhere dense classes. We conjecture, and provide evidence, that classes with almost bounded flip-width coincide with monadically dependent classes, introduced by Shelah in model theory. ",
    "url": "https://arxiv.org/abs/2302.00352",
    "authors": [
      "Symon Toru\u0144czyk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2302.00364",
    "title": "The YODO algorithm: An efficient computational framework for sensitivity  analysis in Bayesian networks",
    "abstract": "Sensitivity analysis measures the influence of a Bayesian network's parameters on a quantity of interest defined by the network, such as the probability of a variable taking a specific value. Various sensitivity measures have been defined to quantify such influence, most commonly some function of the quantity of interest's partial derivative with respect to the network's conditional probabilities. However, computing these measures in large networks with thousands of parameters can become computationally very expensive. We propose an algorithm combining automatic differentiation and exact inference to efficiently calculate the sensitivity measures in a single pass. It first marginalizes the whole network once, using e.g. variable elimination, and then backpropagates this operation to obtain the gradient with respect to all input parameters. Our method can be used for one-way and multi-way sensitivity analysis and the derivation of admissible regions. Simulation studies highlight the efficiency of our algorithm by scaling it to massive networks with up to 100'000 parameters and investigate the feasibility of generic multi-way analyses. Our routines are also showcased over two medium-sized Bayesian networks: the first modeling the country-risks of a humanitarian crisis, the second studying the relationship between the use of technology and the psychological effects of forced social isolation during the COVID-19 pandemic. An implementation of the methods using the popular machine learning library PyTorch is freely available. ",
    "url": "https://arxiv.org/abs/2302.00364",
    "authors": [
      "Rafael Ballester-Ripoll",
      "Manuele Leonelli"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00370",
    "title": "How to select predictive models for causal inference?",
    "abstract": "Predictive models -- as with machine learning -- can underpin causal inference, to estimate the effects of an intervention at the population or individual level. This opens the door to a plethora of models, useful to match the increasing complexity of health data, but also the Pandora box of model selection: which of these models yield the most valid causal estimates? Classic machine-learning cross-validation procedures are not directly applicable. Indeed, an appropriate selection procedure for causal inference should equally weight both outcome errors for each individual, treated or not treated, whereas one outcome may be seldom observed for a sub-population. We study how more elaborate risks benefit causal model selection. We show theoretically that simple risks are brittle to weak overlap between treated and non-treated individuals as well as to heterogeneous errors between populations. Rather a more elaborate metric, the R-risk appears as a proxy of the oracle error on causal estimates, observable at the cost of an overlap re-weighting. As the R-risk is defined not only from model predictions but also by using the conditional mean outcome and the treatment probability, using it for model selection requires adapting cross validation. Extensive experiments show that the resulting procedure gives the best causal model selection. ",
    "url": "https://arxiv.org/abs/2302.00370",
    "authors": [
      "Doutreligne Matthieu",
      "Varoquaux Ga\u00ebl"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00374",
    "title": "HOAX: A Hyperparameter Optimization Algorithm Explorer for Neural  Networks",
    "abstract": "Computational chemistry has become an important tool to predict and understand molecular properties and reactions. Even though recent years have seen a significant growth in new algorithms and computational methods that speed up quantum chemical calculations, the bottleneck for trajectory-based methods to study photoinduced processes is still the huge number of electronic structure calculations. In this work, we present an innovative solution, in which the amount of electronic structure calculations is drastically reduced, by employing machine learning algorithms and methods borrowed from the realm of artificial intelligence. However, applying these algorithms effectively requires finding optimal hyperparameters, which remains a challenge itself. Here we present an automated user-friendly framework, HOAX, to perform the hyperparameter optimization for neural networks, which bypasses the need for a lengthy manual process. The neural network generated potential energy surfaces (PESs) reduces the computational costs compared to the ab initio-based PESs. We perform a comparative investigation on the performance of different hyperparameter optimiziation algorithms, namely grid search, simulated annealing, genetic algorithm, and bayesian optimizer in finding the optimal hyperparameters necessary for constructing the well-performing neural network in order to fit the PESs of small organic molecules. Our results show that this automated toolkit not only facilitate a straightforward way to perform the hyperparameter optimization but also the resulting neural networks-based generated PESs are in reasonable agreement with the ab initio-based PESs. ",
    "url": "https://arxiv.org/abs/2302.00374",
    "authors": [
      "Albert Thie",
      "Maximilian F. S. J. Menger",
      "Shirin Faraji"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00375",
    "title": "Optimal Learning of Deep Random Networks of Extensive-width",
    "abstract": "We consider the problem of learning a target function corresponding to a deep, extensive-width, non-linear neural network with random Gaussian weights. We consider the asymptotic limit where the number of samples, the input dimension and the network width are proportionally large. We derive a closed-form expression for the Bayes-optimal test error, for regression and classification tasks. We contrast these Bayes-optimal errors with the test errors of ridge regression, kernel and random features regression. We find, in particular, that optimally regularized ridge regression, as well as kernel regression, achieve Bayes-optimal performances, while the logistic loss yields a near-optimal test error for classification. We further show numerically that when the number of samples grows faster than the dimension, ridge and kernel methods become suboptimal, while neural networks achieve test error close to zero from quadratically many samples. ",
    "url": "https://arxiv.org/abs/2302.00375",
    "authors": [
      "Hugo Cui",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00422",
    "title": "Robust online active learning",
    "abstract": "In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data streams. Our study shows that the currently available query strategies are prone to sample outliers, whose inclusion in the training set eventually degrades the predictive performance of the models. To address this issue, we propose a solution that bounds the search area of a conditional D-optimal algorithm and uses a robust estimator. Our approach strikes a balance between exploring unseen regions of the input space and protecting against outliers. Through numerical simulations, we show that the proposed method is effective in improving the performance of online active learning in the presence of outliers, thus expanding the potential applications of this powerful tool. ",
    "url": "https://arxiv.org/abs/2302.00422",
    "authors": [
      "Davide Cacciarelli",
      "Murat Kulahci",
      "John S\u00f8lve Tyssedal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00453",
    "title": "Width and Depth Limits Commute in Residual Networks",
    "abstract": "We show that taking the width and depth to infinity in a deep neural network with skip connections, when branches are scaled by $1/\\sqrt{depth}$ (the only nontrivial scaling), result in the same covariance structure no matter how that limit is taken. This explains why the standard infinite-width-then-depth approach provides practical insights even for networks with depth of the same order as width. We also demonstrate that the pre-activations, in this case, have Gaussian distributions which has direct applications in Bayesian deep learning. We conduct extensive simulations that show an excellent match with our theoretical findings. ",
    "url": "https://arxiv.org/abs/2302.00453",
    "authors": [
      "Soufiane Hayou",
      "Greg Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00577",
    "title": "MB-DECTNet: A Model-Based Unrolled Network for Accurate 3D DECT  Reconstruction",
    "abstract": "Numerous dual-energy CT (DECT) techniques have been developed in the past few decades. Dual-energy CT (DECT) statistical iterative reconstruction (SIR) has demonstrated its potential for reducing noise and increasing accuracy. Our lab proposed a joint statistical DECT algorithm for stopping power estimation and showed that it outperforms competing image-based material-decomposition methods. However, due to its slow convergence and the high computational cost of projections, the elapsed time of 3D DECT SIR is often not clinically acceptable. Therefore, to improve its convergence, we have embedded DECT SIR into a deep learning model-based unrolled network for 3D DECT reconstruction (MB-DECTNet) that can be trained in an end-to-end fashion. This deep learning-based method is trained to learn the shortcuts between the initial conditions and the stationary points of iterative algorithms while preserving the unbiased estimation property of model-based algorithms. MB-DECTNet is formed by stacking multiple update blocks, each of which consists of a data consistency layer (DC) and a spatial mixer layer, where the spatial mixer layer is the shrunken U-Net, and the DC layer is a one-step update of an arbitrary traditional iterative method. Although the proposed network can be combined with numerous iterative DECT algorithms, we demonstrate its performance with the dual-energy alternating minimization (DEAM). The qualitative result shows that MB-DECTNet with DEAM significantly reduces noise while increasing the resolution of the test image. The quantitative result shows that MB-DECTNet has the potential to estimate attenuation coefficients accurately as traditional statistical algorithms but with a much lower computational cost. ",
    "url": "https://arxiv.org/abs/2302.00577",
    "authors": [
      "Tao Ge",
      "Maria Medrano",
      "Rui Liao",
      "David G. Politte",
      "Jeffrey F. Williamson",
      "Bruce R. Whiting",
      "Joseph A. O'Sullivan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00587",
    "title": "Molecular Graph Generation by Decomposition and Reassembling",
    "abstract": "Designing molecular structures with desired chemical properties is an essential task in drug discovery and material design. However, finding molecules with the optimized desired properties is still a challenging task due to combinatorial explosion of candidate space of molecules. Here we propose a novel \\emph{decomposition-and-reassembling} based approach, which does not include any optimization in hidden space and our generation process is highly interpretable. Our method is a two-step procedure: In the first decomposition step, we apply frequent subgraph mining to a molecular database to collect smaller size of subgraphs as building blocks of molecules. In the second reassembling step, we search desirable building blocks guided via reinforcement learning and combine them to generate new molecules. Our experiments show that not only can our method find better molecules in terms of two standard criteria, the penalized $\\log P$ and drug-likeness, but also generate drug molecules with showing the valid intermediate molecules. ",
    "url": "https://arxiv.org/abs/2302.00587",
    "authors": [
      "Masatsugu Yamada",
      "Mahito Sugiyama"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00662",
    "title": "Robust Fitted-Q-Evaluation and Iteration under Sequentially Exogenous  Unobserved Confounders",
    "abstract": "Offline reinforcement learning is important in domains such as medicine, economics, and e-commerce where online experimentation is costly, dangerous or unethical, and where the true model is unknown. However, most methods assume all covariates used in the behavior policy's action decisions are observed. This untestable assumption may be incorrect. We study robust policy evaluation and policy optimization in the presence of unobserved confounders. We assume the extent of possible unobserved confounding can be bounded by a sensitivity model, and that the unobserved confounders are sequentially exogenous. We propose and analyze an (orthogonalized) robust fitted-Q-iteration that uses closed-form solutions of the robust Bellman operator to derive a loss minimization problem for the robust Q function. Our algorithm enjoys the computational ease of fitted-Q-iteration and statistical improvements (reduced dependence on quantile estimation error) from orthogonalization. We provide sample complexity bounds, insights, and show effectiveness in simulations. ",
    "url": "https://arxiv.org/abs/2302.00662",
    "authors": [
      "David Bruns-Smith",
      "Angela Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2010.12909",
    "title": "Inductive Bias of Gradient Descent for Weight Normalized Smooth  Homogeneous Neural Nets",
    "abstract": " Comments: Accepted to ALT 2022 ",
    "url": "https://arxiv.org/abs/2010.12909",
    "authors": [
      "Depen Morwani",
      "Harish G. Ramaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.09151",
    "title": "Adversarial Driving: Attacking End-to-End Autonomous Driving",
    "abstract": " Comments: 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2103.09151",
    "authors": [
      "Han Wu",
      "Syed Yunas",
      "Sareh Rowlands",
      "Wenjie Ruan",
      "Johan Wahlstrom"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.10689",
    "title": "NeuS: Learning Neural Implicit Surfaces by Volume Rendering for  Multi-view Reconstruction",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2106.10689",
    "authors": [
      "Peng Wang",
      "Lingjie Liu",
      "Yuan Liu",
      "Christian Theobalt",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2106.12974",
    "title": "Tensor networks for unsupervised machine learning",
    "abstract": " Comments: v2 ",
    "url": "https://arxiv.org/abs/2106.12974",
    "authors": [
      "Jing Liu",
      "Sujie Li",
      "Jiang Zhang",
      "Pan Zhang"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.03702",
    "title": "BIGRoC: Boosting Image Generation via a Robust Classifier",
    "abstract": " Title: BIGRoC: Boosting Image Generation via a Robust Classifier ",
    "url": "https://arxiv.org/abs/2108.03702",
    "authors": [
      "Roy Ganz",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.06663",
    "title": "HCR-Net: A deep learning based script independent handwritten character  recognition network",
    "abstract": " Comments: 23 pages (double-column), 6 figures, 16 tables (under review) -- revised version ",
    "url": "https://arxiv.org/abs/2108.06663",
    "authors": [
      "Vinod Kumar Chauhan",
      "Sukhdeep Singh",
      "Anuj Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.02342",
    "title": "Automated Cardiac Resting Phase Detection Targeted on the Right Coronary  Artery",
    "abstract": " Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL ",
    "url": "https://arxiv.org/abs/2109.02342",
    "authors": [
      "Seung Su Yoon",
      "Elisabeth Preuhs",
      "Michaela Schmidt",
      "Christoph Forman",
      "Teodora Chitiboi",
      "Puneet Sharma",
      "Juliano Lara Fernandes",
      "Christoph Tillmanns",
      "Jens Wetzl",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2111.01097",
    "title": "Code2Snapshot: Using Code Snapshots for Learning Representations of  Source Code",
    "abstract": " Comments: The 21st IEEE International Conference on Machine Learning and Applications (ICMLA'22) ",
    "url": "https://arxiv.org/abs/2111.01097",
    "authors": [
      "Md Rafiqul Islam Rabin",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2204.01205",
    "title": "Model-Parallel Fourier Neural Operators as Learned Surrogates for  Large-Scale Parametric PDEs",
    "abstract": " Title: Model-Parallel Fourier Neural Operators as Learned Surrogates for  Large-Scale Parametric PDEs ",
    "url": "https://arxiv.org/abs/2204.01205",
    "authors": [
      "Thomas J. Grady II",
      "Rishi Khan",
      "Mathias Louboutin",
      "Ziyi Yin",
      "Philipp A. Witte",
      "Ranveer Chandra",
      "Russell J. Hewett",
      "Felix J. Herrmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.02458",
    "title": "Robust Active Visual Perching with Quadrotors on Inclined Surfaces",
    "abstract": " Title: Robust Active Visual Perching with Quadrotors on Inclined Surfaces ",
    "url": "https://arxiv.org/abs/2204.02458",
    "authors": [
      "Jeffrey Mao",
      "Stephen Nogar",
      "Christopher Kroninger",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.05731",
    "title": "Human Mobility Prediction with Causal and Spatial-constrained Multi-task  Network",
    "abstract": " Comments: Updated version ",
    "url": "https://arxiv.org/abs/2206.05731",
    "authors": [
      "Zongyuan Huang",
      "Shengyuan Xu",
      "Menghan Wang",
      "Hansi Wu",
      "Yanyan Xu",
      "Yaohui Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.09374",
    "title": "A robust and conservative dynamical low-rank algorithm",
    "abstract": " Title: A robust and conservative dynamical low-rank algorithm ",
    "url": "https://arxiv.org/abs/2206.09374",
    "authors": [
      "Lukas Einkemmer",
      "Alexander Ostermann",
      "Carmen Scalone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2206.12543",
    "title": "A Fast, Well-Founded Approximation to the Empirical Neural Tangent  Kernel",
    "abstract": " Title: A Fast, Well-Founded Approximation to the Empirical Neural Tangent  Kernel ",
    "url": "https://arxiv.org/abs/2206.12543",
    "authors": [
      "Mohamad Amin Mohamadi",
      "Danica J. Sutherland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05934",
    "title": "The wisdom_of_crowds: an efficient, philosophically-validated, social  epistemological network profiling toolkit",
    "abstract": " Comments: This is a preprint version of the manuscript. 13 pages, 3 figures. The final version will be published in \"Complex Networks & Their Applications XI: Proceedings of The Eleventh International Conference on Complex Networks and their Applications: COMPLEX NETWORKS 2022 - Volume 1\" ",
    "url": "https://arxiv.org/abs/2207.05934",
    "authors": [
      "Colin Klein",
      "Marc Cheong",
      "Marinus Ferreira",
      "Emily Sullivan",
      "Mark Alfano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.10170",
    "title": "Illusory Attacks: Detectability Matters in Adversarial Attacks on  Sequential Decision-Makers",
    "abstract": " Title: Illusory Attacks: Detectability Matters in Adversarial Attacks on  Sequential Decision-Makers ",
    "url": "https://arxiv.org/abs/2207.10170",
    "authors": [
      "Tim Franzmeyer",
      "Stephen McAleer",
      "Jo\u00e3o F. Henriques",
      "Jakob N. Foerster",
      "Philip H.S. Torr",
      "Adel Bibi",
      "Christian Schroeder de Witt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11378",
    "title": "Do Perceptually Aligned Gradients Imply Adversarial Robustness?",
    "abstract": " Title: Do Perceptually Aligned Gradients Imply Adversarial Robustness? ",
    "url": "https://arxiv.org/abs/2207.11378",
    "authors": [
      "Roy Ganz",
      "Bahjat Kawar",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.05516",
    "title": "Quality Not Quantity: On the Interaction between Dataset Design and  Robustness of CLIP",
    "abstract": " Comments: Oral paper at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2208.05516",
    "authors": [
      "Thao Nguyen",
      "Gabriel Ilharco",
      "Mitchell Wortsman",
      "Sewoong Oh",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.01962",
    "title": "Adversarial Detection: Attacking Object Detection in Real Time",
    "abstract": " Comments: 7 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2209.01962",
    "authors": [
      "Han Wu",
      "Syed Yunas",
      "Sareh Rowlands",
      "Wenjie Ruan",
      "Johan Wahlstrom"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.05935",
    "title": "Variational Causal Inference",
    "abstract": " Title: Variational Causal Inference ",
    "url": "https://arxiv.org/abs/2209.05935",
    "authors": [
      "Yulun Wu",
      "Layne C. Price",
      "Zichen Wang",
      "Vassilis N. Ioannidis",
      "Robert A. Barton",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2209.05948",
    "title": "Don't Complete It! Preventing Unhelpful Code Completion for Productive  and Sustainable Neural Code Completion Systems",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2209.05948",
    "authors": [
      "Zhensu Sun",
      "Xiaoning Du",
      "Fu Song",
      "Shangwen Wang",
      "Mingze Ni",
      "Li Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.09025",
    "title": "RAMP-Net: A Robust Adaptive MPC for Quadrotors via Physics-informed  Neural Network",
    "abstract": " Comments: This work has been accepted for presentation at the 2023 IEEE International Conference on Robotics and Automation (ICRA), May 29 - June 2, 2023, London, UK. arXiv version will be merged with the conference proceeding once available ",
    "url": "https://arxiv.org/abs/2209.09025",
    "authors": [
      "Sourav Sanyal",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.11820",
    "title": "Expanding the Deployment Envelope of Behavior Prediction via Adaptive  Meta-Learning",
    "abstract": " Comments: 12 pages, 13 figures, 2 tables. To appear at ICRA 2023 ",
    "url": "https://arxiv.org/abs/2209.11820",
    "authors": [
      "Boris Ivanovic",
      "James Harrison",
      "Marco Pavone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.15230",
    "title": "The Replicator Dynamic, Chain Components and the Response Graph",
    "abstract": " Comments: 22 pages, 2 figures. Accepted version. To appear in Algorithmic Learning Theory 2023 ",
    "url": "https://arxiv.org/abs/2209.15230",
    "authors": [
      "Oliver Biggar",
      "Iman Shames"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15264",
    "title": "Diffusion-based Image Translation using Disentangled Style and Content  Representation",
    "abstract": " Comments: ICLR 2023 camera ready ",
    "url": "https://arxiv.org/abs/2209.15264",
    "authors": [
      "Gihyun Kwon",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.02357",
    "title": "Image Masking for Robust Self-Supervised Monocular Depth Estimation",
    "abstract": " Comments: Accepted at 2023 IEEE International Conference on Robotics and Automation (ICRA) ",
    "url": "https://arxiv.org/abs/2210.02357",
    "authors": [
      "Hemang Chawla",
      "Kishaan Jeeveswaran",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03197",
    "title": "Modeling Memory Imprints Induced by Interactions in Social Networks",
    "abstract": " Comments: 11 pages, 2 tables ",
    "url": "https://arxiv.org/abs/2210.03197",
    "authors": [
      "James Flamino",
      "Ross DeVito",
      "Omar Lizardo",
      "Boleslaw K. Szymanski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.03314",
    "title": "Uniformly convex neural networks and non-stationary iterated network  Tikhonov (iNETT) method",
    "abstract": " Title: Uniformly convex neural networks and non-stationary iterated network  Tikhonov (iNETT) method ",
    "url": "https://arxiv.org/abs/2210.03314",
    "authors": [
      "Davide Bianchi",
      "Guanghao Lai",
      "Wenbin Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.05616",
    "title": "Neural Shape Deformation Priors",
    "abstract": " Comments: NeurIPS 2022 Spotlight ",
    "url": "https://arxiv.org/abs/2210.05616",
    "authors": [
      "Jiapeng Tang",
      "Lev Markhasin",
      "Bi Wang",
      "Justus Thies",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13537",
    "title": "Private Online Prediction from Experts: Separations and Faster Rates",
    "abstract": " Comments: Remove the results for the realizable setting which we will upload with additional results for that setting in a separate paper ",
    "url": "https://arxiv.org/abs/2210.13537",
    "authors": [
      "Hilal Asi",
      "Vitaly Feldman",
      "Tomer Koren",
      "Kunal Talwar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13681",
    "title": "BSDF Importance Baking: A Lightweight Neural Solution to Importance  Sampling General Parametric BSDFs",
    "abstract": " Title: BSDF Importance Baking: A Lightweight Neural Solution to Importance  Sampling General Parametric BSDFs ",
    "url": "https://arxiv.org/abs/2210.13681",
    "authors": [
      "Yaoyi Bai",
      "Songyin Wu",
      "Zheng Zeng",
      "Beibei Wang",
      "Ling-Qi Yan"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.15073",
    "title": "Hierarchical architecture representations for quantum convolutional  neural networks",
    "abstract": " Comments: 18 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2210.15073",
    "authors": [
      "Matt Lourens",
      "Ilya Sinayskiy",
      "Daniel K. Park",
      "Carsten Blank",
      "Francesco Petruccione"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.16940",
    "title": "FI-ODE: Certified and Robust Forward Invariance in Neural ODEs",
    "abstract": " Title: FI-ODE: Certified and Robust Forward Invariance in Neural ODEs ",
    "url": "https://arxiv.org/abs/2210.16940",
    "authors": [
      "Yujia Huang",
      "Ivan Dario Jimenez Rodriguez",
      "Huan Zhang",
      "Yuanyuan Shi",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00250",
    "title": "FADO: Feedback-Aware Double COntrolling Network for Emotional Support  Conversation",
    "abstract": " Comments: Accepted on Knowl. Based Syst. (SCI I) ",
    "url": "https://arxiv.org/abs/2211.00250",
    "authors": [
      "Wei Peng",
      "Ziyuan Qin",
      "Yue Hu",
      "Yuqiang Xie",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.02504",
    "title": "Geometry-Complete Perceptron Networks for 3D Molecular Graphs",
    "abstract": " Comments: 18 pages, 3 figures, 11 tables. Under review. Also accepted to DLG-AAAI 2023 and AI2ASE-AAAI 2023. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2211.02504",
    "authors": [
      "Alex Morehead",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.15608",
    "title": "Representation with Incomplete Votes",
    "abstract": " Title: Representation with Incomplete Votes ",
    "url": "https://arxiv.org/abs/2211.15608",
    "authors": [
      "Daniel Halpern",
      "Gregory Kehne",
      "Ariel D. Procaccia",
      "Jamie Tucker-Foltz",
      "Manuel W\u00fcthrich"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2211.16762",
    "title": "GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided  Distance Representation",
    "abstract": " Comments: 1 correct some unclear claim 2 add the results of DOG 3 redraw some figures ",
    "url": "https://arxiv.org/abs/2211.16762",
    "authors": [
      "Siyu Ren",
      "Junhui Hou",
      "Xiaodong Chen",
      "Ying He",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05613",
    "title": "A Study of Slang Representation Methods",
    "abstract": " Title: A Study of Slang Representation Methods ",
    "url": "https://arxiv.org/abs/2212.05613",
    "authors": [
      "Aravinda Kolla",
      "Filip Ilievski",
      "H\u00f4ng-\u00c2n Sandlin",
      "Alain Mermoud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.11696",
    "title": "Reversible Column Networks",
    "abstract": " Comments: Accepted by ICLR 2023 ",
    "url": "https://arxiv.org/abs/2212.11696",
    "authors": [
      "Yuxuan Cai",
      "Yizhuang Zhou",
      "Qi Han",
      "Jianjian Sun",
      "Xiangwen Kong",
      "Jun Li",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02764",
    "title": "Mathematical Models and Reinforcement Learning based Evolutionary  Algorithm Framework for Satellite Scheduling Problem",
    "abstract": " Comments: 12 pages. arXiv admin note: substantial text overlap with arXiv:2206.05694 ",
    "url": "https://arxiv.org/abs/2301.02764",
    "authors": [
      "Yanjie Song"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.06471",
    "title": "Towards social embodied cobots: The integration of an industrial cobot  with a social virtual agent",
    "abstract": " Title: Towards social embodied cobots: The integration of an industrial cobot  with a social virtual agent ",
    "url": "https://arxiv.org/abs/2301.06471",
    "authors": [
      "Matteo Lavit Nicora",
      "Sebastian Beyrodt",
      "Dimitra Tsovaltzi",
      "Fabrizio Nunnari",
      "Patrick Gebhard",
      "Matteo Malosio"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.11004",
    "title": "NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental  Health on Social Media",
    "abstract": " Comments: Will revise work ",
    "url": "https://arxiv.org/abs/2301.11004",
    "authors": [
      "Muskan Garg",
      "Chandni Saxena",
      "Usman Naseem",
      "Bonnie J Dorr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11223",
    "title": "CitationSum: Citation-aware Graph Contrastive Learning for Scientific  Paper Summarization",
    "abstract": " Comments: accepted to WWW2023 ",
    "url": "https://arxiv.org/abs/2301.11223",
    "authors": [
      "Zheheng Luo",
      "Qianqian Xie",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2301.11445",
    "title": "3DShape2VecSet: A 3D Shape Representation for Neural Fields and  Generative Diffusion Models",
    "abstract": " Comments: Project demo: this https URL ",
    "url": "https://arxiv.org/abs/2301.11445",
    "authors": [
      "Biao Zhang",
      "Jiapeng Tang",
      "Matthias Niessner",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2301.11494",
    "title": "Learning Vortex Dynamics for Fluid Inference and Prediction",
    "abstract": " Comments: ICLR 2023, project webpage: this https URL ",
    "url": "https://arxiv.org/abs/2301.11494",
    "authors": [
      "Yitong Deng",
      "Hong-Xing Yu",
      "Jiajun Wu",
      "Bo Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2301.12175",
    "title": "Bio-inspired Autonomous Exploration Policies with CNN-based Object  Detection on Nano-drones",
    "abstract": " Comments: 6 pages, 6 figures, 4 tables, conference: DATE: Design, Automation, and Test in Europe (2023) ",
    "url": "https://arxiv.org/abs/2301.12175",
    "authors": [
      "Lorenzo Lamberti",
      "Luca Bompani",
      "Victor Javier Kartsch",
      "Manuele Rusci",
      "Daniele Palossi",
      "Luca Benini"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12457",
    "title": "EvoX: A Distributed GPU-accelerated Library towards Scalable  Evolutionary Computation",
    "abstract": " Title: EvoX: A Distributed GPU-accelerated Library towards Scalable  Evolutionary Computation ",
    "url": "https://arxiv.org/abs/2301.12457",
    "authors": [
      "Beichen Huang",
      "Ran Cheng",
      "Yaochu Jin",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.13821",
    "title": "Complete Neural Networks for Euclidean Graphs",
    "abstract": " Comments: 19 pages, updated 3 figures ",
    "url": "https://arxiv.org/abs/2301.13821",
    "authors": [
      "Snir Hordan",
      "Tal Amir",
      "Steven J. Gortler",
      "Nadav Dym"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13869",
    "title": "Reverse engineering adversarial attacks with fingerprints from  adversarial examples",
    "abstract": " Comments: 8 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2301.13869",
    "authors": [
      "David Aaron Nicholson",
      "Vincent Emanuele"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  }
]