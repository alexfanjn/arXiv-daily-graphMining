[
  {
    "id": "arXiv:2302.03716",
    "title": "Mining Effective Features Using Quantum Entropy for Humor Recognition",
    "abstract": "Humor recognition has been extensively studied with different methods in the past years. However, existing studies on humor recognition do not understand the mechanisms that generate humor. In this paper, inspired by the incongruity theory, any joke can be divided into two components (the setup and the punchline). Both components have multiple possible semantics, and there is an incongruous relationship between them. We use density matrices to represent the semantic uncertainty of the setup and the punchline, respectively, and design QE-Uncertainty and QE-Incongruity with the help of quantum entropy as features for humor recognition. The experimental results on the SemEval2021 Task 7 dataset show that the proposed features are more effective than the baselines for recognizing humorous and non-humorous texts. ",
    "url": "https://arxiv.org/abs/2302.03716",
    "authors": [
      "Yang Liu",
      "Yuexian Hou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.03729",
    "title": "KENGIC: KEyword-driven and N-Gram Graph based Image Captioning",
    "abstract": "This paper presents a Keyword-driven and N-gram Graph based approach for Image Captioning (KENGIC). Most current state-of-the-art image caption generators are trained end-to-end on large scale paired image-caption datasets which are very laborious and expensive to collect. Such models are limited in terms of their explainability and their applicability across different domains. To address these limitations, a simple model based on N-Gram graphs which does not require any end-to-end training on paired image captions is proposed. Starting with a set of image keywords considered as nodes, the generator is designed to form a directed graph by connecting these nodes through overlapping n-grams as found in a given text corpus. The model then infers the caption by maximising the most probable n-gram sequences from the constructed graph. To analyse the use and choice of keywords in context of this approach, this study analysed the generation of image captions based on (a) keywords extracted from gold standard captions and (b) from automatically detected keywords. Both quantitative and qualitative analyses demonstrated the effectiveness of KENGIC. The performance achieved is very close to that of current state-of-the-art image caption generators that are trained in the unpaired setting. The analysis of this approach could also shed light on the generation process behind current top performing caption generators trained in the paired setting, and in addition, provide insights on the limitations of the current most widely used evaluation metrics in automatic image captioning. ",
    "url": "https://arxiv.org/abs/2302.03729",
    "authors": [
      "Brandon Birmingham",
      "Adrian Muscat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03731",
    "title": "MMA-RNN: A Multi-level Multi-task Attention-based Recurrent Neural  Network for Discrimination and Localization of Atrial Fibrillation",
    "abstract": "The automatic detection of atrial fibrillation based on electrocardiograph (ECG) signals has received wide attention both clinically and practically. It is challenging to process ECG signals with cyclical pattern, varying length and unstable quality due to noise and distortion. Besides, there has been insufficient research on separating persistent atrial fibrillation from paroxysmal atrial fibrillation, and little discussion on locating the onsets and end points of AF episodes. It is even more arduous to perform well on these two distinct but interrelated tasks, while avoiding the mistakes inherent from stage-by-stage approaches. This paper proposes the Multi-level Multi-task Attention-based Recurrent Neural Network for three-class discrimination on patients and localization of the exact timing of AF episodes. Our model captures three-level sequential features based on a hierarchical architecture utilizing Bidirectional Long and Short-Term Memory Network (Bi-LSTM) and attention layers, and accomplishes the two tasks simultaneously with a multi-head classifier. The model is designed as an end-to-end framework to enhance information interaction and reduce error accumulation. Finally, we conduct experiments on CPSC 2021 dataset and the result demonstrates the superior performance of our method, indicating the potential application of MMA-RNN to wearable mobile devices for routine AF monitoring and early diagnosis. ",
    "url": "https://arxiv.org/abs/2302.03731",
    "authors": [
      "Yifan Sun",
      "Jingyan Shen",
      "Yunfan Jiang",
      "Zhaohui Huang",
      "Minsheng Hao",
      "Xuegong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.03744",
    "title": "3D Neural Embedding Likelihood for Robust Sim-to-Real Transfer in  Inverse Graphics",
    "abstract": "A central challenge in 3D scene perception via inverse graphics is robustly modeling the gap between 3D graphics and real-world data. We propose a novel 3D Neural Embedding Likelihood (3DNEL) over RGB-D images to address this gap. 3DNEL uses neural embeddings to predict 2D-3D correspondences from RGB and combines this with depth in a principled manner. 3DNEL is trained entirely from synthetic images and generalizes to real-world data. To showcase this capability, we develop a multi-stage inverse graphics pipeline that uses 3DNEL for 6D object pose estimation from real RGB-D images. Our method outperforms the previous state-of-the-art in sim-to-real pose estimation on the YCB-Video dataset, and improves robustness, with significantly fewer large-error predictions. Unlike existing bottom-up, discriminative approaches that are specialized for pose estimation, 3DNEL adopts a probabilistic generative formulation that jointly models multi-object scenes. This generative formulation enables easy extension of 3DNEL to additional tasks like object and camera tracking from video, using principled inference in the same probabilistic model without task specific retraining. ",
    "url": "https://arxiv.org/abs/2302.03744",
    "authors": [
      "Guangyao Zhou",
      "Nishad Gothoskar",
      "Lirui Wang",
      "Joshua B. Tenenbaum",
      "Dan Gutfreund",
      "Miguel L\u00e1zaro-Gredilla",
      "Dileep George",
      "Vikash K. Mansinghka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03745",
    "title": "Structural Robustness of Complex Networks: A Survey of A Posteriori  Measures",
    "abstract": "Network robustness is critical for various industrial and social networks against malicious attacks, which has various meanings in different research contexts and here it refers to the ability of a network to sustain its functionality when a fraction of the network fail to work due to attacks. The rapid development of complex networks research indicates special interest and great concern about the network robustness, which is essential for further analyzing and optimizing network structures towards engineering applications. This comprehensive survey distills the important findings and developments of network robustness research, focusing on the a posteriori structural robustness measures for single-layer static networks. Specifically, the a posteriori robustness measures are reviewed from four perspectives: 1) network functionality, including connectivity, controllability and communication ability, as well as their extensions; 2) malicious attacks, including conventional and computation-based attack strategies; 3) robustness estimation methods using either analytical approximation or machine learning-based prediction; 4) network robustness optimization. Based on the existing measures, a practical threshold of network destruction is introduced, with the suggestion that network robustness should be measured only before reaching the threshold of destruction. Then, a posteriori and a priori measures are compared experimentally, revealing the advantages of the a posteriori measures. Finally, prospective research directions with respect to a posteriori robustness measures are recommended. ",
    "url": "https://arxiv.org/abs/2302.03745",
    "authors": [
      "Yang Lou",
      "Lin Wang",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.03750",
    "title": "Towards causally linking architectural parametrizations to algorithmic  bias in neural networks",
    "abstract": "Training dataset biases are by far the most scrutinized factors when explaining algorithmic biases of neural networks. In contrast, hyperparameters related to the neural network architecture, e.g., the number of layers or choice of activation functions, have largely been ignored even though different network parameterizations are known to induce different implicit biases over learned features. For example, convolutional kernel size has been shown to bias CNNs towards different frequencies. In order to study the effect of these hyperparameters, we designed a causal framework for linking an architectural hyperparameter to algorithmic bias. Our framework is experimental, in that several versions of a network are trained with an intervention to a specific hyperparameter, and the resulting causal effect of this choice on performance bias is measured. We focused on the causal relationship between sensitivity to high-frequency image details and face analysis classification performance across different subpopulations (race/gender). In this work, we show that modifying a CNN hyperparameter (convolutional kernel size), even in one layer of a CNN, will not only change a fundamental characteristic of the learned features (frequency content) but that this change can vary significantly across data subgroups (race/gender populations) leading to biased generalization performance even in the presence of a balanced dataset. ",
    "url": "https://arxiv.org/abs/2302.03750",
    "authors": [
      "Hao Liang",
      "Josue Ortega Caro",
      "Vikram Maheshri",
      "Ankit B. Patel",
      "Guha Balakrishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.03786",
    "title": "Analyzing the Performance of Deep Encoder-Decoder Networks as Surrogates  for a Diffusion Equation",
    "abstract": "Neural networks (NNs) have proven to be a viable alternative to traditional direct numerical algorithms, with the potential to accelerate computational time by several orders of magnitude. In the present paper we study the use of encoder-decoder convolutional neural network (CNN) as surrogates for steady-state diffusion solvers. The construction of such surrogates requires the selection of an appropriate task, network architecture, training set structure and size, loss function, and training algorithm hyperparameters. It is well known that each of these factors can have a significant impact on the performance of the resultant model. Our approach employs an encoder-decoder CNN architecture, which we posit is particularly well-suited for this task due to its ability to effectively transform data, as opposed to merely compressing it. We systematically evaluate a range of loss functions, hyperparameters, and training set sizes. Our results indicate that increasing the size of the training set has a substantial effect on reducing performance fluctuations and overall error. Additionally, we observe that the performance of the model exhibits a logarithmic dependence on the training set size. Furthermore, we investigate the effect on model performance by using different subsets of data with varying features. Our results highlight the importance of sampling the configurational space in an optimal manner, as this can have a significant impact on the performance of the model and the required training time. In conclusion, our results suggest that training a model with a pre-determined error performance bound is not a viable approach, as it does not guarantee that edge cases with errors larger than the bound do not exist. Furthermore, as most surrogate tasks involve a high dimensional landscape, an ever increasing training set size is, in principle, needed, however it is not a practical solution. ",
    "url": "https://arxiv.org/abs/2302.03786",
    "authors": [
      "J. Quetzalcoatl Toledo-Marin",
      "James A. Glazier",
      "Geoffrey Fox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ]
  },
  {
    "id": "arXiv:2302.03788",
    "title": "Toward a Theory of Causation for Interpreting Neural Code Models",
    "abstract": "Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly progressing from research prototypes to commercial developer tools. As such, understanding the capabilities and limitations of such models is becoming critical. However, the abilities of these models are typically measured using automated metrics that often only reveal a portion of their real-world performance. While, in general, the performance of NCMs appears promising, currently much is unknown about how such models arrive at decisions. To this end, this paper introduces $do_{code}$, a post-hoc interpretability methodology specific to NCMs that is capable of explaining model predictions. $do_{code}$ is based upon causal inference to enable programming language-oriented explanations. While the theoretical underpinnings of $do_{code}$ are extensible to exploring different model properties, we provide a concrete instantiation that aims to mitigate the impact of spurious correlations by grounding explanations of model behavior in properties of programming languages. To demonstrate the practical benefit of $do_{code}$, we illustrate the insights that our framework can provide by performing a case study on two popular deep learning architectures and nine NCMs. The results of this case study illustrate that our studied NCMs are sensitive to changes in code syntax and statistically learn to predict tokens related to blocks of code (e.g., brackets, parenthesis, semicolon) with less confounding bias as compared to other programming language constructs. These insights demonstrate the potential of $do_{code}$ as a useful model debugging mechanism that may aid in discovering biases and limitations in NCMs. ",
    "url": "https://arxiv.org/abs/2302.03788",
    "authors": [
      "David N. Palacio",
      "Nathan Cooper",
      "Alvaro Rodriguez",
      "Kevin Moran",
      "Denys Poshyvanyk"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.03790",
    "title": "GraphGUIDE: interpretable and controllable conditional graph generation  with discrete Bernoulli diffusion",
    "abstract": "Diffusion models achieve state-of-the-art performance in generating realistic objects and have been successfully applied to images, text, and videos. Recent work has shown that diffusion can also be defined on graphs, including graph representations of drug-like molecules. Unfortunately, it remains difficult to perform conditional generation on graphs in a way which is interpretable and controllable. In this work, we propose GraphGUIDE, a novel framework for graph generation using diffusion models, where edges in the graph are flipped or set at each discrete time step. We demonstrate GraphGUIDE on several graph datasets, and show that it enables full control over the conditional generation of arbitrary structural properties without relying on predefined labels. Our framework for graph diffusion can have a large impact on the interpretable conditional generation of graphs, including the generation of drug-like molecules with desired properties in a way which is informed by experimental evidence. ",
    "url": "https://arxiv.org/abs/2302.03790",
    "authors": [
      "Alex M. Tseng",
      "Nathaniel Diamant",
      "Tommaso Biancalani",
      "Gabriele Scalia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03793",
    "title": "Self-Supervised Unseen Object Instance Segmentation via Long-Term Robot  Interaction",
    "abstract": "We introduce a novel robotic system for improving unseen object instance segmentation in the real world by leveraging long-term robot interaction with objects. Previous approaches either grasp or push an object and then obtain the segmentation mask of the grasped or pushed object after one action. Instead, our system defers the decision on segmenting objects after a sequence of robot pushing actions. By applying multi-object tracking and video object segmentation on the images collected via robot pushing, our system can generate segmentation masks of all the objects in these images in a self-supervised way. These include images where objects are very close to each other, and segmentation errors usually occur on these images for existing object segmentation networks. We demonstrate the usefulness of our system by fine-tuning segmentation networks trained on synthetic data with real-world data collected by our system. We show that, after fine-tuning, the segmentation accuracy of the networks is significantly improved both in the same domain and across different domains. In addition, we verify that the fine-tuned networks improve top-down robotic grasping of unseen objects in the real world. ",
    "url": "https://arxiv.org/abs/2302.03793",
    "authors": [
      "Yangxiao Lu",
      "Ninad Khargonkar",
      "Zesheng Xu",
      "Charles Averill",
      "Kamalesh Palanisamy",
      "Kaiyu Hang",
      "Yunhui Guo",
      "Nicholas Ruozzi",
      "Yu Xiang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03807",
    "title": "A prototype-oriented clustering for domain shift with source privacy",
    "abstract": "Unsupervised clustering under domain shift (UCDS) studies how to transfer the knowledge from abundant unlabeled data from multiple source domains to learn the representation of the unlabeled data in a target domain. In this paper, we introduce Prototype-oriented Clustering with Distillation (PCD) to not only improve the performance and applicability of existing methods for UCDS, but also address the concerns on protecting the privacy of both the data and model of the source domains. PCD first constructs a source clustering model by aligning the distributions of prototypes and data. It then distills the knowledge to the target model through cluster labels provided by the source model while simultaneously clustering the target data. Finally, it refines the target model on the target domain data without guidance from the source model. Experiments across multiple benchmarks show the effectiveness and generalizability of our source-private clustering method. ",
    "url": "https://arxiv.org/abs/2302.03807",
    "authors": [
      "Korawat Tanwisuth",
      "Shujian Zhang",
      "Pengcheng He",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.03830",
    "title": "TetCNN: Convolutional Neural Networks on Tetrahedral Meshes",
    "abstract": "Convolutional neural networks (CNN) have been broadly studied on images, videos, graphs, and triangular meshes. However, it has seldom been studied on tetrahedral meshes. Given the merits of using volumetric meshes in applications like brain image analysis, we introduce a novel interpretable graph CNN framework for the tetrahedral mesh structure. Inspired by ChebyNet, our model exploits the volumetric Laplace-Beltrami Operator (LBO) to define filters over commonly used graph Laplacian which lacks the Riemannian metric information of 3D manifolds. For pooling adaptation, we introduce new objective functions for localized minimum cuts in the Graclus algorithm based on the LBO. We employ a piece-wise constant approximation scheme that uses the clustering assignment matrix to estimate the LBO on sampled meshes after each pooling. Finally, adapting the Gradient-weighted Class Activation Mapping algorithm for tetrahedral meshes, we use the obtained heatmaps to visualize discovered regions-of-interest as biomarkers. We demonstrate the effectiveness of our model on cortical tetrahedral meshes from patients with Alzheimer's disease, as there is scientific evidence showing the correlation of cortical thickness to neurodegenerative disease progression. Our results show the superiority of our LBO-based convolution layer and adapted pooling over the conventionally used unitary cortical thickness, graph Laplacian, and point cloud representation. ",
    "url": "https://arxiv.org/abs/2302.03830",
    "authors": [
      "Mohammad Farazi",
      "Zhangsihao Yang",
      "Wenhui Zhu",
      "Peijie Qiu",
      "Yalin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03837",
    "title": "Robust Digital Watermarking Method Based on Adaptive Feature Area  Extraction and Local Histogram Shifting",
    "abstract": "A new local watermarking method based on histogram shifting has been proposed in this paper to deal with various signal processing attacks (e.g. median filtering, JPEG compression and Gaussian noise addition) and geometric attacks (e.g. rotation, scaling and cropping). A feature detector is used to select local areas for embedding. Then stationary wavelet transform (SWT) is applied on each local area for denoising by setting the corresponding diagonal coefficients to zero. With the implementation of histogram shifting, the watermark is embedded into denoised local areas. Meanwhile, a secret key is used in the embedding process which ensures the security that the watermark cannot be easily hacked. After the embedding process, the SWT diagonal coefficients are used to reconstruct the watermarked image. With the proposed watermarking method, we can achieve higher image quality and less bit error rate (BER) in the decoding process even after some attacks. Compared with global watermarking methods, the proposed watermarking scheme based on local histogram shifting has the advantages of higher security and larger capacity. The experimental results show the better image quality as well as lower BER compared with the state-of-art watermarking methods. ",
    "url": "https://arxiv.org/abs/2302.03837",
    "authors": [
      "Zi-yu Jiang",
      "Chi-Man Pun",
      "Xiao-Chen Yuan",
      "Tong Liu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.03851",
    "title": "ED-Batch: Efficient Automatic Batching of Dynamic Neural Networks via  Learned Finite State Machines",
    "abstract": "Batching has a fundamental influence on the efficiency of deep neural network (DNN) execution. However, for dynamic DNNs, efficient batching is particularly challenging as the dataflow graph varies per input instance. As a result, state-of-the-art frameworks use heuristics that result in suboptimal batching decisions. Further, batching puts strict restrictions on memory adjacency and can lead to high data movement costs. In this paper, we provide an approach for batching dynamic DNNs based on finite state machines, which enables the automatic discovery of batching policies specialized for each DNN via reinforcement learning. Moreover, we find that memory planning that is aware of the batching policy can save significant data movement overheads, which is automated by a PQ tree-based algorithm we introduce. Experimental results show that our framework speeds up state-of-the-art frameworks by on average 1.15x, 1.39x, and 2.45x for chain-based, tree-based, and lattice-based DNNs across CPU and GPU. ",
    "url": "https://arxiv.org/abs/2302.03851",
    "authors": [
      "Siyuan Chen",
      "Pratik Fegade",
      "Tianqi Chen",
      "Phillip B. Gibbons",
      "Todd C. Mowry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.03857",
    "title": "Efficient Adversarial Contrastive Learning via Robustness-Aware Coreset  Selection",
    "abstract": "Adversarial contrastive learning (ACL) does not require expensive data annotations but outputs a robust representation that withstands adversarial attacks and also generalizes to a wide range of downstream tasks. However, ACL needs tremendous running time to generate the adversarial variants of all training data, which limits its scalability to large datasets. To speed up ACL, this paper proposes a robustness-aware coreset selection (RCS) method. RCS does not require label information and searches for an informative subset that minimizes a representational divergence, which is the distance of the representation between natural data and their virtual adversarial variants. The vanilla solution of RCS via traversing all possible subsets is computationally prohibitive. Therefore, we theoretically transform RCS into a surrogate problem of submodular maximization, of which the greedy search is an efficient solution with an optimality guarantee for the original problem. Empirically, our comprehensive results corroborate that RCS can speed up ACL by a large margin without significantly hurting the robustness and standard transferability. Notably, to the best of our knowledge, we are the first to conduct ACL efficiently on the large-scale ImageNet-1K dataset to obtain an effective robust representation via RCS. ",
    "url": "https://arxiv.org/abs/2302.03857",
    "authors": [
      "Xilie Xu",
      "Jingfeng Zhang",
      "Feng Liu",
      "Masashi Sugiyama",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.03862",
    "title": "CRAFT: Criticality-Aware Fault-Tolerance Enhancement Techniques for  Emerging Memories-Based Deep Neural Networks",
    "abstract": "Deep Neural Networks (DNNs) have emerged as the most effective programming paradigm for computer vision and natural language processing applications. With the rapid development of DNNs, efficient hardware architectures for deploying DNN-based applications on edge devices have been extensively studied. Emerging Non-Volatile Memories (NVMs), with their better scalability, non-volatility and good read performance, are found to be promising candidates for deploying DNNs. However, despite the promise, emerging NVMs often suffer from reliability issues such as stuck-at faults, which decrease the chip yield/memory lifetime and severely impact the accuracy of DNNs. A stuck-at cell can be read but not reprogrammed, thus, stuck-at faults in NVMs may or may not result in errors depending on the data to be stored. By reducing the number of errors caused by stuck-at faults, the reliability of a DNN-based system can be enhanced. This paper proposes CRAFT, i.e., Criticality-Aware Fault-Tolerance Enhancement Techniques to enhance the reliability of NVM-based DNNs in the presence of stuck-at faults. A data block remapping technique is used to reduce the impact of stuck-at faults on DNNs accuracy. Additionally, by performing bit-level criticality analysis on various DNNs, the critical-bit positions in network parameters that can significantly impact the accuracy are identified. Based on this analysis, we propose an encoding method which effectively swaps the critical bit positions with that of non-critical bits when more errors (due to stuck-at faults) are present in the critical bits. ",
    "url": "https://arxiv.org/abs/2302.03862",
    "authors": [
      "Thai-Hoang Nguyen",
      "Muhammad Imran",
      "Jaehyuk Choi",
      "Joon-Sung Yang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.03874",
    "title": "Participatory Systems for Personalized Prediction",
    "abstract": "Machine learning models are often personalized based on information that is protected, sensitive, self-reported, or costly to acquire. These models use information about people, but do not facilitate nor inform their \\emph{consent}. Individuals cannot opt out of reporting information that a model needs to personalize their predictions, nor tell if they would benefit from personalization in the first place. In this work, we introduce a new family of prediction models, called \\emph{participatory systems}, that allow individuals to opt into personalization at prediction time. We present a model-agnostic algorithm to learn participatory systems for supervised learning tasks where models are personalized with categorical group attributes. We conduct a comprehensive empirical study of participatory systems in clinical prediction tasks, comparing them to common approaches for personalization and imputation. Our results demonstrate that participatory systems can facilitate and inform consent in a way that improves performance and privacy across all groups who report personal data. ",
    "url": "https://arxiv.org/abs/2302.03874",
    "authors": [
      "Hailey James",
      "Chirag Nagpal",
      "Katherine Heller",
      "Berk Ustun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2302.03875",
    "title": "Neural Artistic Style Transfer with Conditional Adversaria",
    "abstract": "A neural artistic style transformation (NST) model can modify the appearance of a simple image by adding the style of a famous image. Even though the transformed images do not look precisely like artworks by the same artist of the respective style images, the generated images are appealing. Generally, a trained NST model specialises in a style, and a single image represents that style. However, generating an image under a new style is a tedious process, which includes full model training. In this paper, we present two methods that step toward the style image independent neural style transfer model. In other words, the trained model could generate semantically accurate generated image under any content, style image input pair. Our novel contribution is a unidirectional-GAN model that ensures the Cyclic consistency by the model architecture.Furthermore, this leads to much smaller model size and an efficient training and validation phase. ",
    "url": "https://arxiv.org/abs/2302.03875",
    "authors": [
      "P. N. Deelaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03881",
    "title": "On Generalized Degree Fairness in Graph Neural Networks",
    "abstract": "Conventional graph neural networks (GNNs) are often confronted with fairness issues that may stem from their input, including node attributes and neighbors surrounding a node. While several recent approaches have been proposed to eliminate the bias rooted in sensitive attributes, they ignore the other key input of GNNs, namely the neighbors of a node, which can introduce bias since GNNs hinge on neighborhood structures to generate node representations. In particular, the varying neighborhood structures across nodes, manifesting themselves in drastically different node degrees, give rise to the diverse behaviors of nodes and biased outcomes. In this paper, we first define and generalize the degree bias using a generalized definition of node degree as a manifestation and quantification of different multi-hop structures around different nodes. To address the bias in the context of node classification, we propose a novel GNN framework called Generalized Degree Fairness-centric Graph Neural Network (Deg-FairGNN). Specifically, in each GNN layer, we employ a learnable debiasing function to generate debiasing contexts, which modulate the layer-wise neighborhood aggregation to eliminate the degree bias originating from the diverse degrees among nodes. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our model on both accuracy and fairness metrics. ",
    "url": "https://arxiv.org/abs/2302.03881",
    "authors": [
      "Zemin Liu",
      "Trung-Kien Nguyen",
      "Yuan Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.03896",
    "title": "Auto-Learning: An Adversarial Process of Two Pre-trained Models for  Natural Language Generation",
    "abstract": "Pre-trained models have been used in many fields in recent years, ranging from natural language understanding to computer vision and natural language generation. However, the performance of these natural language generation models is overly dependent on the scale of the model and the size of the dataset. While the larger language model is excellent in some respects, it cannot learn up-to-date knowledge and is relatively difficult to relearn. In this paper, a new adversarial process learning method called Auto-Learning. This can improve the performance of any natural language generation model without the help of additional datasets. Auto-Learning includes two models: $G$ is a text generation model and $D$ can test whether the data generated by G is legitimate. Firstly, the fine-tuned $D$ model is used as the brain's knowledge base before the process. Then the text generated by the $G$ model is used as the input of $D$ to determine whether the text is legitimate or not. Finally, $G$ is fine-tuned according to the output of $D$. This adversarial process is like a self-escalation of the brain through some a priori knowledge. When this adversarial system wants to learn something new, simply fine-tune the $D$ model. Our approach applies to Autoregressive Language Modeling for all Transformer classes. The results are good in existing experimental tasks, including more grammatical text generation and better performance on some text comprehension tasks. ",
    "url": "https://arxiv.org/abs/2302.03896",
    "authors": [
      "Zhengqing Yuan",
      "Yuelin Lu",
      "Chao Zhang",
      "Huiwen Xue"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.03901",
    "title": "Guided Learning from Demonstration for Robust Transferability",
    "abstract": "Learning from demonstration (LfD) has the potential to greatly increase the applicability of robotic manipulators in modern industrial applications. Recent progress in LfD methods have put more emphasis in learning robustness than in guiding the demonstration itself in order to improve robustness. The latter is particularly important to consider when the target system reproducing the motion is structurally different to the demonstration system, as some demonstrated motions may not be reproducible. In light of this, this paper introduces a new guided learning from demonstration paradigm where an interactive graphical user interface (GUI) guides the user during demonstration, preventing them from demonstrating non-reproducible motions. The key aspect of our approach is determining the space of reproducible motions based on a motion planning framework which finds regions in the task space where trajectories are guaranteed to be of bounded length. We evaluate our method on two different setups with a six-degree-of-freedom (DOF) UR5 as the target system. First our method is validated using a seven-DOF Sawyer as the demonstration system. Then an extensive user study is carried out where several participants are asked to demonstrate, with and without guidance, a mock weld task using a hand held tool tracked by a VICON system. With guidance users were able to always carry out the task successfully in comparison to only 44% of the time without guidance. ",
    "url": "https://arxiv.org/abs/2302.03901",
    "authors": [
      "Fouad Sukkar",
      "Victor Hernandez Moreno",
      "Teresa Vidal-Calleja",
      "Jochen Deuse"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.03914",
    "title": "Generalized Few-Shot 3D Object Detection of LiDAR Point Cloud for  Autonomous Driving",
    "abstract": "Recent years have witnessed huge successes in 3D object detection to recognize common objects for autonomous driving (e.g., vehicles and pedestrians). However, most methods rely heavily on a large amount of well-labeled training data. This limits their capability of detecting rare fine-grained objects (e.g., police cars and ambulances), which is important for special cases, such as emergency rescue, and so on. To achieve simultaneous detection for both common and rare objects, we propose a novel task, called generalized few-shot 3D object detection, where we have a large amount of training data for common (base) objects, but only a few data for rare (novel) classes. Specifically, we analyze in-depth differences between images and point clouds, and then present a practical principle for the few-shot setting in the 3D LiDAR dataset. To solve this task, we propose a simple and effective detection framework, including (1) an incremental fine-tuning method to extend existing 3D detection models to recognize both common and rare objects, and (2) a sample adaptive balance loss to alleviate the issue of long-tailed data distribution in autonomous driving scenarios. On the nuScenes dataset, we conduct sufficient experiments to demonstrate that our approach can successfully detect the rare (novel) classes that contain only a few training data, while also maintaining the detection accuracy of common objects. ",
    "url": "https://arxiv.org/abs/2302.03914",
    "authors": [
      "Jiawei Liu",
      "Xingping Dong",
      "Sanyuan Zhao",
      "Jianbing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03916",
    "title": "QS-ADN: Quasi-Supervised Artifact Disentanglement Network for Low-Dose  CT Image Denoising by Local Similarity Among Unpaired Data",
    "abstract": "Deep learning has been successfully applied to low-dose CT (LDCT) image denoising for reducing potential radiation risk. However, the widely reported supervised LDCT denoising networks require a training set of paired images, which is expensive to obtain and cannot be perfectly simulated. Unsupervised learning utilizes unpaired data and is highly desirable for LDCT denoising. As an example, an artifact disentanglement network (ADN) relies on unparied images and obviates the need for supervision but the results of artifact reduction are not as good as those through supervised learning.An important observation is that there is often hidden similarity among unpaired data that can be utilized. This paper introduces a new learning mode, called quasi-supervised learning, to empower the ADN for LDCT image denoising.For every LDCT image, the best matched image is first found from an unpaired normal-dose CT (NDCT) dataset. Then, the matched pairs and the corresponding matching degree as prior information are used to construct and train our ADN-type network for LDCT denoising.The proposed method is different from (but compatible with) supervised and semi-supervised learning modes and can be easily implemented by modifying existing networks. The experimental results show that the method is competitive with state-of-the-art methods in terms of noise suppression and contextual fidelity. The code and working dataset are publicly available at https://github.com/ruanyuhui/ADN-QSDL.git. ",
    "url": "https://arxiv.org/abs/2302.03916",
    "authors": [
      "Yuhui Ruan",
      "Qiao Yuan",
      "Chuang Niu",
      "Chen Li",
      "Yudong Yao",
      "Ge Wang",
      "Yueyang Teng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03920",
    "title": "The Capacity Region of Distributed Multi-User Secret Sharing under The  Perfect Privacy Condition",
    "abstract": "We study the distributed multi-user secret sharing (DMUSS) problem under the perfect privacy condition. In a DMUSS problem, multiple secret messages are deployed and the shares are offloaded to the storage nodes. Moreover, the access structure is extremely incomplete, as the decoding collection of each secret message has only one set, and by the perfect privacy condition such collection is also the colluding collection of all other secret messages. The secret message rate is defined as the size of the secret message normalized by the size of a share. We characterize the capacity region of the DMUSS problem when given an access structure, defined as the set of all achievable rate tuples. In the achievable scheme, we assume all shares are mutually independent and then design the decoding function based on the fact that the decoding collection of each secret message has only one set. Then it turns out that the perfect privacy condition is equivalent to the full rank property of some matrices consisting of different indeterminates and zeros. Such a solution does exist if the field size is bigger than the number of secret messages. Finally with a matching converse saying that the size of the secret is upper bounded by the sum of sizes of non-colluding shares, we characterize the capacity region of DMUSS problem under the perfect privacy condition. ",
    "url": "https://arxiv.org/abs/2302.03920",
    "authors": [
      "Jiahong Wu",
      "Nan Liu",
      "Wei Kang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2302.03924",
    "title": "CCRep: Learning Code Change Representations via Pre-Trained Code Model  and Query Back",
    "abstract": "Representing code changes as numeric feature vectors, i.e., code change representations, is usually an essential step to automate many software engineering tasks related to code changes, e.g., commit message generation and just-in-time defect prediction. Intuitively, the quality of code change representations is crucial for the effectiveness of automated approaches. Prior work on code changes usually designs and evaluates code change representation approaches for a specific task, and little work has investigated code change encoders that can be used and jointly trained on various tasks. To fill this gap, this work proposes a novel Code Change Representation learning approach named CCRep, which can learn to encode code changes as feature vectors for diverse downstream tasks. Specifically, CCRep regards a code change as the combination of its before-change and after-change code, leverages a pre-trained code model to obtain high-quality contextual embeddings of code, and uses a novel mechanism named query back to extract and encode the changed code fragments and make them explicitly interact with the whole code change. To evaluate CCRep and demonstrate its applicability to diverse code-change-related tasks, we apply it to three tasks: commit message generation, patch correctness assessment, and just-in-time defect prediction. Experimental results show that CCRep outperforms the state-of-the-art techniques on each task. ",
    "url": "https://arxiv.org/abs/2302.03924",
    "authors": [
      "Zhongxin Liu",
      "Zhijie Tang",
      "Xin Xia",
      "Xiaohu Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.03933",
    "title": "Graph Signal Sampling for Inductive One-Bit Matrix Completion: a  Closed-form Solution",
    "abstract": "Inductive one-bit matrix completion is motivated by modern applications such as recommender systems, where new users would appear at test stage with the ratings consisting of only ones and no zeros. We propose a unified graph signal sampling framework which enjoys the benefits of graph signal analysis and processing. The key idea is to transform each user's ratings on the items to a function (signal) on the vertices of an item-item graph, then learn structural graph properties to recover the function from its values on certain vertices -- the problem of graph signal sampling. We propose a class of regularization functionals that takes into account discrete random label noise in the graph vertex domain, then develop the GS-IMC approach which biases the reconstruction towards functions that vary little between adjacent vertices for noise reduction. Theoretical result shows that accurate reconstructions can be achieved under mild conditions. For the online setting, we develop a Bayesian extension, i.e., BGS-IMC which considers continuous random Gaussian noise in the graph Fourier domain and builds upon a prediction-correction update algorithm to obtain the unbiased and minimum-variance reconstruction. Both GS-IMC and BGS-IMC have closed-form solutions and thus are highly scalable in large data. Experiments show that our methods achieve state-of-the-art performance on public benchmarks. ",
    "url": "https://arxiv.org/abs/2302.03933",
    "authors": [
      "Chao Chen",
      "Haoyu Geng",
      "Gang Zeng",
      "Zhaobing Han",
      "Hua Chai",
      "Xiaokang Yang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03939",
    "title": "Learning Interaction-aware Motion Prediction Model for Decision-making  in Autonomous Driving",
    "abstract": "Predicting the behaviors of other road users is crucial to safe and intelligent decision-making for autonomous vehicles (AVs). However, most motion prediction models ignore the influence of the AV's actions and the planning module has to treat other agents as unalterable moving obstacles. To address this problem, this paper proposes an interaction-aware motion prediction model that is able to predict other agents' future trajectories according to the ego agent's future plan, i.e., their reactions to the ego's actions. Specifically, we employ Transformers to effectively encode the driving scene and incorporate the AV's plan in decoding the predicted trajectories. To train the model to accurately predict the reactions of other agents, we develop an online learning framework, where the ego agent explores the environment and collects other agents' reactions to itself. We validate the decision-making and learning framework in three highly interactive simulated driving scenarios. The results reveal that our decision-making method significantly outperforms the reinforcement learning methods in terms of data efficiency and performance. We also find that using the interaction-aware model can bring better performance than the non-interaction-aware model and the exploration process helps improve the success rate in testing. ",
    "url": "https://arxiv.org/abs/2302.03939",
    "authors": [
      "Zhiyu Huang",
      "Haochen Liu",
      "Jingda Wu",
      "Wenhui Huang",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.03950",
    "title": "Improving (Dis)agreement Detection with Inductive Social Relation  Information From Comment-Reply Interactions",
    "abstract": "(Dis)agreement detection aims to identify the authors' attitudes or positions (\\textit{{agree, disagree, neutral}}) towards a specific text. It is limited for existing methods merely using textual information for identifying (dis)agreements, especially for cross-domain settings. Social relation information can play an assistant role in the (dis)agreement task besides textual information. We propose a novel method to extract such relation information from (dis)agreement data into an inductive social relation graph, merely using the comment-reply pairs without any additional platform-specific information. The inductive social relation globally considers the historical discussion and the relation between authors. Textual information based on a pre-trained language model and social relation information encoded by pre-trained RGCN are jointly considered for (dis)agreement detection. Experimental results show that our model achieves state-of-the-art performance for both the in-domain and cross-domain tasks on the benchmark -- DEBAGREEMENT. We find social relations can boost the performance of the (dis)agreement detection model, especially for the long-token comment-reply pairs, demonstrating the effectiveness of the social relation graph. We also explore the effect of the knowledge graph embedding methods, the information fusing method, and the time interval in constructing the social relation graph, which shows the effectiveness of our model. ",
    "url": "https://arxiv.org/abs/2302.03950",
    "authors": [
      "Yun Luo",
      "Zihan Liu",
      "Stan Z. Li",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.03954",
    "title": "Temporal Video-Language Alignment Network for Reward Shaping in  Reinforcement Learning",
    "abstract": "Designing appropriate reward functions for Reinforcement Learning (RL) approaches has been a significant problem, especially for complex environments such as Atari games. Utilizing natural language instructions to provide intermediate rewards to RL agents in a process known as reward shaping can help the agent in reaching the goal state faster. In this work, we propose a natural language-based reward shaping approach that maps trajectories from the Montezuma's Revenge game environment to corresponding natural language instructions using an extension of the LanguagE-Action Reward Network (LEARN) framework. These trajectory-language mappings are further used to generate intermediate rewards which are integrated into reward functions that can be utilized to learn an optimal policy for any standard RL algorithms. For a set of 15 tasks from Atari's Montezuma's Revenge game, the Ext-LEARN approach leads to the successful completion of tasks more often on average than the reward shaping approach that uses the LEARN framework and performs even better than the reward shaping framework without natural language-based rewards. ",
    "url": "https://arxiv.org/abs/2302.03954",
    "authors": [
      "Ziyuan Cao",
      "Reshma Anugundanahalli Ramachandra",
      "Kelin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.03956",
    "title": "Neural Congealing: Aligning Images to a Joint Semantic Atlas",
    "abstract": "We present Neural Congealing -- a zero-shot self-supervised framework for detecting and jointly aligning semantically-common content across a given set of images. Our approach harnesses the power of pre-trained DINO-ViT features to learn: (i) a joint semantic atlas -- a 2D grid that captures the mode of DINO-ViT features in the input set, and (ii) dense mappings from the unified atlas to each of the input images. We derive a new robust self-supervised framework that optimizes the atlas representation and mappings per image set, requiring only a few real-world images as input without any additional input information (e.g., segmentation masks). Notably, we design our losses and training paradigm to account only for the shared content under severe variations in appearance, pose, background clutter or other distracting objects. We demonstrate results on a plethora of challenging image sets including sets of mixed domains (e.g., aligning images depicting sculpture and artwork of cats), sets depicting related yet different object categories (e.g., dogs and tigers), or domains for which large-scale training data is scarce (e.g., coffee mugs). We thoroughly evaluate our method and show that our test-time optimization approach performs favorably compared to a state-of-the-art method that requires extensive training on large-scale datasets. ",
    "url": "https://arxiv.org/abs/2302.03956",
    "authors": [
      "Dolev Ofri-Amar",
      "Michal Geyer",
      "Yoni Kasten",
      "Tali Dekel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03969",
    "title": "Alamouti-Like Transmission Schemes in Distributed MIMO Networks",
    "abstract": "The purpose of the study is to investigate potential benefits of using Alamouti-like orthogonal space-time-frequency block codes (STFBC) in distributed multiple-input multiple-output (D-MIMO) systems to increase the diversity at the UE side when instantaneous channel state information (CSI) is not available at radio units (RUs). Most of the existing transmission techniques require instantaneous CSI to form precoders which can only be realized together with accurate and up-to-date channel knowledge. STFBC can increase the diversity at UE side without estimating the downlink channel. Under challenging channel conditions, the network can switch to a robust mode where a certain data rate is maintained for users even without knowing the channel coefficients by means of STFBC. In this study, it will be mainly focused on clustering of RUs and user equipment, where each cluster adopts a possibly different orthogonal code, so that overall spectral efficiency is optimized. Potential performance gains over known techniques that can be used when the channel is not known will be shown and performance gaps to sophisticated precoders making use of channel estimates will be identified. ",
    "url": "https://arxiv.org/abs/2302.03969",
    "authors": [
      "Fehmi Emre Kadan",
      "\u00d6mer Halilo\u011flu",
      "Andres Reial"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.03978",
    "title": "Structural hierarchical learning for energy networks",
    "abstract": "Many sectors nowadays require accurate and coherent predictions across their organization to effectively operate. Otherwise, decision-makers would be planning using disparate views of the future, resulting in inconsistent decisions across their sectors. To secure coherency across hierarchies, recent research has put forward hierarchical learning, a coherency-informed hierarchical regressor leveraging the power of machine learning thanks to a custom loss function founded on optimal reconciliation methods. While promising potentials were outlined, results exhibited discordant performances in which coherency information only improved hierarchical forecasts in one setting. This work proposes to tackle these obstacles by investigating custom neural network designs inspired by the topological structures of hierarchies. Results unveil that, in a data-limited setting, structural models with fewer connections perform overall best and demonstrate the coherency information value for both accuracy and coherency forecasting performances, provided individual forecasts were generated within reasonable accuracy limits. Overall, this work expands and improves hierarchical learning methods thanks to a structurally-scaled learning mechanism extension coupled with tailored network designs, producing a resourceful, data-efficient, and information-rich learning process. ",
    "url": "https://arxiv.org/abs/2302.03978",
    "authors": [
      "Julien Leprince",
      "Waqas Khan",
      "Henrik Madsen",
      "Jan Kloppenborg M\u00f8ller",
      "Wim Zeiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03987",
    "title": "Multiview Representation Learning from Crowdsourced Triplet Comparisons",
    "abstract": "Crowdsourcing has been used to collect data at scale in numerous fields. Triplet similarity comparison is a type of crowdsourcing task, in which crowd workers are asked the question ``among three given objects, which two are more similar?'', which is relatively easy for humans to answer. However, the comparison can be sometimes based on multiple views, i.e., different independent attributes such as color and shape. Each view may lead to different results for the same three objects. Although an algorithm was proposed in prior work to produce multiview embeddings, it involves at least two problems: (1) the existing algorithm cannot independently predict multiview embeddings for a new sample, and (2) different people may prefer different views. In this study, we propose an end-to-end inductive deep learning framework to solve the multiview representation learning problem. The results show that our proposed method can obtain multiview embeddings of any object, in which each view corresponds to an independent attribute of the object. We collected two datasets from a crowdsourcing platform to experimentally investigate the performance of our proposed approach compared to conventional baseline methods. ",
    "url": "https://arxiv.org/abs/2302.03987",
    "authors": [
      "Xiaotian Lu",
      "Jiyi Li",
      "Koh Takeuchi",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03992",
    "title": "Convolutional Neural Networks Trained to Identify Words Provide a Good  Account of Visual Form Priming Effects",
    "abstract": "A wide variety of orthographic coding schemes and models of visual word identification have been developed to account for masked priming data that provide a measure of orthographic similarity between letter strings. These models tend to include hand-coded orthographic representations with single unit coding for specific forms of knowledge (e.g., units coding for a letter in a given position or a letter sequence). Here we assess how well a range of these coding schemes and models account for the pattern of form priming effects taken from the Form Priming Project and compare these findings to results observed in with 11 standard deep neural network models (DNNs) developed in computer science. We find that deep convolutional networks perform as well or better than the coding schemes and word recognition models, whereas transformer networks did less well. The success of convolutional networks is remarkable as their architectures were not developed to support word recognition (they were designed to perform well on object recognition) and they classify pixel images of words (rather artificial encodings of letter strings). The findings add to the recent work of (Hannagan et al., 2021) suggesting that convolutional networks may capture key aspects of visual word identification. ",
    "url": "https://arxiv.org/abs/2302.03992",
    "authors": [
      "Dong Yin",
      "Valerio Biscione",
      "Jeffrey Bowers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03995",
    "title": "Regularity and numerical approximation of fractional elliptic  differential equations on compact metric graphs",
    "abstract": "The fractional differential equation $L^\\beta u = f$ posed on a compact metric graph is considered, where $\\beta>\\frac14$ and $L = \\kappa - \\frac{\\mathrm{d}}{\\mathrm{d} x}(H\\frac{\\mathrm{d}}{\\mathrm{d} x})$ is a second-order elliptic operator equipped with certain vertex conditions and sufficiently smooth and positive coefficients $\\kappa,H$. We demonstrate the existence of a unique solution for a general class of vertex conditions and derive the regularity of the solution in the specific case of Kirchhoff vertex conditions. These results are extended to the stochastic setting when $f$ is replaced by Gaussian white noise. For the deterministic and stochastic settings under generalized Kirchhoff vertex conditions, we propose a numerical solution based on a finite element approximation combined with a rational approximation of the fractional power $L^{-\\beta}$. For the resulting approximation, the strong error is analyzed in the deterministic case, and the strong mean squared error as well as the $L_2(\\Gamma\\times \\Gamma)$-error of the covariance function of the solution are analyzed in the stochastic setting. Explicit rates of convergences are derived for all cases. Numerical experiments for the example ${L = \\kappa^2 - \\Delta, \\kappa>0}$ are performed to illustrate the theoretical results. ",
    "url": "https://arxiv.org/abs/2302.03995",
    "authors": [
      "David Bolin",
      "Mih\u00e1ly Kov\u00e1cs",
      "Vivek Kumar",
      "Alexandre B. Simas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2302.03997",
    "title": "SimCGNN: Simple Contrastive Graph Neural Network for Session-based  Recommendation",
    "abstract": "Session-based recommendation (SBR) problem, which focuses on next-item prediction for anonymous users, has received increasingly more attention from researchers. Existing graph-based SBR methods all lack the ability to differentiate between sessions with the same last item, and suffer from severe popularity bias. Inspired by nowadays emerging contrastive learning methods, this paper presents a Simple Contrastive Graph Neural Network for Session-based Recommendation (SimCGNN). In SimCGNN, we first obtain normalized session embeddings on constructed session graphs. We next construct positive and negative samples of the sessions by two forward propagation and a novel negative sample selection strategy, and then calculate the constructive loss. Finally, session embeddings are used to give prediction. Extensive experiments conducted on two real-word datasets show our SimCGNN achieves a significant improvement over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2302.03997",
    "authors": [
      "Yuan Cao",
      "Xudong Zhang",
      "Fan Zhang",
      "Feifei Kou",
      "Josiah Poon",
      "Xiongnan Jin",
      "Yongheng Wang",
      "Jinpeng Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04012",
    "title": "Systematically Finding Security Vulnerabilities in Black-Box Code  Generation Models",
    "abstract": "Recently, large language models for code generation have achieved breakthroughs in several programming language tasks. Their advances in competition-level programming problems have made them an emerging pillar in AI-assisted pair programming. Tools such as GitHub Copilot are already part of the daily programming workflow and are used by more than a million developers. The training data for these models is usually collected from open-source repositories (e.g., GitHub) that contain software faults and security vulnerabilities. This unsanitized training data can lead language models to learn these vulnerabilities and propagate them in the code generation procedure. Given the wide use of these models in the daily workflow of developers, it is crucial to study the security aspects of these models systematically. In this work, we propose the first approach to automatically finding security vulnerabilities in black-box code generation models. To achieve this, we propose a novel black-box inversion approach based on few-shot prompting. We evaluate the effectiveness of our approach by examining code generation models in the generation of high-risk security weaknesses. We show that our approach automatically and systematically finds 1000s of security vulnerabilities in various code generation models, including the commercial black-box model GitHub Copilot. ",
    "url": "https://arxiv.org/abs/2302.04012",
    "authors": [
      "Hossein Hajipour",
      "Thorsten Holz",
      "Lea Sch\u00f6nherr",
      "Mario Fritz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.04018",
    "title": "A Survey on Event Prediction Methods from a Systems Perspective:  Bringing Together Disparate Research Areas",
    "abstract": "Event prediction is the ability of anticipating future events, i.e., future real-world occurrences, and aims to support the user in deciding on actions that change future events towards a desired state. An event prediction method learns the relation between features of past events and future events. It is applied to newly observed events to predict corresponding future events that are evaluated with respect to the user's desired future state. If the predicted future events do not comply with this state, actions are taken towards achieving desirable future states. Evidently, event prediction is valuable in many application domains such as business and natural disasters. The diversity of application domains results in a diverse range of methods that are scattered across various research areas which, in turn, use different terminology for event prediction methods. Consequently, sharing methods and knowledge for developing future event prediction methods is restricted. To facilitate knowledge sharing on account of a comprehensive classification, integration, and assessment of event prediction methods, we combine taxonomies and take a systems perspective to integrate event prediction methods into a single system, elicit requirements and assess existing work with respect to the requirements. Based on the assessment, we identify open challenges and discuss future research directions. ",
    "url": "https://arxiv.org/abs/2302.04018",
    "authors": [
      "Janik-Vasily Benzin",
      "Stefanie Rinderle-Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04025",
    "title": "WAT: Improve the Worst-class Robustness in Adversarial Training",
    "abstract": "Deep Neural Networks (DNN) have been shown to be vulnerable to adversarial examples. Adversarial training (AT) is a popular and effective strategy to defend against adversarial attacks. Recent works (Benz et al., 2020; Xu et al., 2021; Tian et al., 2021) have shown that a robust model well-trained by AT exhibits a remarkable robustness disparity among classes, and propose various methods to obtain consistent robust accuracy across classes. Unfortunately, these methods sacrifice a good deal of the average robust accuracy. Accordingly, this paper proposes a novel framework of worst-class adversarial training and leverages no-regret dynamics to solve this problem. Our goal is to obtain a classifier with great performance on worst-class and sacrifice just a little average robust accuracy at the same time. We then rigorously analyze the theoretical properties of our proposed algorithm, and the generalization error bound in terms of the worst-class robust risk. Furthermore, we propose a measurement to evaluate the proposed method in terms of both the average and worst-class accuracies. Experiments on various datasets and networks show that our proposed method outperforms the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2302.04025",
    "authors": [
      "Boqi Li",
      "Weiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04026",
    "title": "An Empirical Comparison of Pre-Trained Models of Source Code",
    "abstract": "While a large number of pre-trained models of source code have been successfully developed and applied to a variety of software engineering (SE) tasks in recent years, our understanding of these pre-trained models is arguably fairly limited. With the goal of advancing our understanding of these models, we perform the first systematic empirical comparison of 19 recently-developed pre-trained models of source code on 13 SE tasks. To gain additional insights into these models, we adopt a recently-developed 4-dimensional categorization of pre-trained models, and subsequently investigate whether there are correlations between different categories of pre-trained models and their performances on different SE tasks. ",
    "url": "https://arxiv.org/abs/2302.04026",
    "authors": [
      "Changan Niu",
      "Chuanyi Li",
      "Vincent Ng",
      "Dongxiao Chen",
      "Jidong Ge",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.04030",
    "title": "CrossCodeBench: Benchmarking Cross-Task Generalization of Source Code  Models",
    "abstract": "Despite the recent advances showing that a model pre-trained on large-scale source code data is able to gain appreciable generalization capability, it still requires a sizeable amount of data on the target task for fine-tuning. And the effectiveness of the model generalization is largely affected by the size and quality of the fine-tuning data, which is detrimental for target tasks with limited or unavailable resources. Therefore, cross-task generalization, with the goal of improving the generalization of the model to unseen tasks that have not been seen before, is of strong research and application value. In this paper, we propose a large-scale benchmark that includes 216 existing code-related tasks. Then, we annotate each task with the corresponding meta information such as task description and instruction, which contains detailed information about the task and a solution guide. This also helps us to easily create a wide variety of ``training/evaluation'' task splits to evaluate the various cross-task generalization capabilities of the model. Then we perform some preliminary experiments to demonstrate that the cross-task generalization of models can be largely improved by in-context learning methods such as few-shot learning and learning from task instructions, which shows the promising prospects of conducting cross-task learning research on our benchmark. We hope that the collection of the datasets and our benchmark will facilitate future work that is not limited to cross-task generalization. ",
    "url": "https://arxiv.org/abs/2302.04030",
    "authors": [
      "Changan Niu",
      "Chuanyi Li",
      "Vincent Ng",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04031",
    "title": "FR-LIO: Fast and Robust Lidar-Inertial Odometry by Tightly-Coupled  Iterated Kalman Smoother and Robocentric Voxels",
    "abstract": "This paper presents a fast lidar-inertial odometry (LIO) system that is robust to aggressive motion. To achieve robust tracking in aggressive motion scenes, we exploit the continuous scanning property of lidar to adaptively divide the full scan into multiple partial scans (named sub-frames) according to the motion intensity. And to avoid the degradation of sub-frames resulting from insufficient constraints, we propose a robust state estimation method based on a tightly-coupled iterated error state Kalman smoother (ESKS) framework. Furthermore, we propose a robocentric voxel map (RC-Vox) to improve the system's efficiency. The RC-Vox allows efficient maintenance of map points and k nearest neighbor (k-NN) queries by mapping local map points into a fixed-size, two-layer 3D array structure. Extensive experiments were conducted on 27 sequences from 4 public datasets and our own dataset. The results show that our system can achieve stable tracking in aggressive motion scenes that cannot be handled by other state-of-the-art methods, while our system can achieve competitive performance with these methods in general scenes. In terms of efficiency, the RC-Vox allows our system to achieve the fastest speed compared with the current advanced LIO systems. ",
    "url": "https://arxiv.org/abs/2302.04031",
    "authors": [
      "Xiaoyu Zhao",
      "Xiaolong Qian",
      "Yunzhou Zhang",
      "Yuezhang Lv",
      "Shiwen Liang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.04032",
    "title": "A Systematic Performance Analysis of Deep Perceptual Loss Networks  Breaks Transfer Learning Conventions",
    "abstract": "Deep perceptual loss is a type of loss function in computer vision that aims to mimic human perception by using the deep features extracted from neural networks. In recent years the method has been applied to great effect on a host of interesting computer vision tasks, especially for tasks with image or image-like outputs. Many applications of the method use pretrained networks, often convolutional networks, for loss calculation. Despite the increased interest and broader use, more effort is needed toward exploring which networks to use for calculating deep perceptual loss and from which layers to extract the features. This work aims to rectify this by systematically evaluating a host of commonly used and readily available, pretrained networks for a number of different feature extraction points on four existing use cases of deep perceptual loss. The four use cases are implementations of previous works where the selected networks and extraction points are evaluated instead of the networks and extraction points used in the original work. The experimental tasks are dimensionality reduction, image segmentation, super-resolution, and perceptual similarity. The performance on these four tasks, attributes of the networks, and extraction points are then used as a basis for an in-depth analysis. This analysis uncovers essential information regarding which architectures provide superior performance for deep perceptual loss and how to choose an appropriate extraction point for a particular task and dataset. Furthermore, the work discusses the implications of the results for deep perceptual loss and the broader field of transfer learning. The results break commonly held assumptions in transfer learning, which imply that deep perceptual loss deviates from most transfer learning settings or that these assumptions need a thorough re-evaluation. ",
    "url": "https://arxiv.org/abs/2302.04032",
    "authors": [
      "Gustav Grund Pihlgren",
      "Konstantina Nikolaidou",
      "Prakash Chandra Chhipa",
      "Nosheen Abid",
      "Rajkumar Saini",
      "Fredrik Sandin",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04035",
    "title": "Revisit the Algorithm Selection Problem for TSP with Spatial Information  Enhanced Graph Neural Networks",
    "abstract": "Algorithm selection is a well-known problem where researchers investigate how to construct useful features representing the problem instances and then apply feature-based machine learning models to predict which algorithm works best with the given instance. However, even for simple optimization problems such as Euclidean Traveling Salesman Problem (TSP), there lacks a general and effective feature representation for problem instances. The important features of TSP are relatively well understood in the literature, based on extensive domain knowledge and post-analysis of the solutions. In recent years, Convolutional Neural Network (CNN) has become a popular approach to select algorithms for TSP. Compared to traditional feature-based machine learning models, CNN has an automatic feature-learning ability and demands less domain expertise. However, it is still required to generate intermediate representations, i.e., multiple images to represent TSP instances first. In this paper, we revisit the algorithm selection problem for TSP, and propose a novel Graph Neural Network (GNN), called GINES. GINES takes the coordinates of cities and distances between cities as input. It is composed of a new message-passing mechanism and a local neighborhood feature extractor to learn spatial information of TSP instances. We evaluate GINES on two benchmark datasets. The results show that GINES outperforms CNN and the original GINE models. It is better than the traditional handcrafted feature-based approach on one dataset. The code and dataset will be released in the final version of this paper. ",
    "url": "https://arxiv.org/abs/2302.04035",
    "authors": [
      "Ya Song",
      "Laurens Bliek",
      "Yingqian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04052",
    "title": "Finding Short Signals in Long Irregular Time Series with Continuous-Time  Attention Policy Networks",
    "abstract": "Irregularly-sampled time series (ITS) are native to high-impact domains like healthcare, where measurements are collected over time at uneven intervals. However, for many classification problems, only small portions of long time series are often relevant to the class label. In this case, existing ITS models often fail to classify long series since they rely on careful imputation, which easily over- or under-samples the relevant regions. Using this insight, we then propose CAT, a model that classifies multivariate ITS by explicitly seeking highly-relevant portions of an input series' timeline. CAT achieves this by integrating three components: (1) A Moment Network learns to seek relevant moments in an ITS's continuous timeline using reinforcement learning. (2) A Receptor Network models the temporal dynamics of both observations and their timing localized around predicted moments. (3) A recurrent Transition Model models the sequence of transitions between these moments, cultivating a representation with which the series is classified. Using synthetic and real data, we find that CAT outperforms ten state-of-the-art methods by finding short signals in long irregular time series. ",
    "url": "https://arxiv.org/abs/2302.04052",
    "authors": [
      "Thomas Hartvigsen",
      "Jidapa Thadajarassiri",
      "Xiangnan Kong",
      "Elke Rundensteiner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04064",
    "title": "Weakly-supervised Representation Learning for Video Alignment and  Analysis",
    "abstract": "Many tasks in video analysis and understanding boil down to the need for frame-based feature learning, aiming to encapsulate the relevant visual content so as to enable simpler and easier subsequent processing. While supervised strategies for this learning task can be envisioned, self and weakly-supervised alternatives are preferred due to the difficulties in getting labeled data. This paper introduces LRProp -- a novel weakly-supervised representation learning approach, with an emphasis on the application of temporal alignment between pairs of videos of the same action category. The proposed approach uses a transformer encoder for extracting frame-level features, and employs the DTW algorithm within the training iterations in order to identify the alignment path between video pairs. Through a process referred to as ``pair-wise position propagation'', the probability distributions of these correspondences per location are matched with the similarity of the frame-level features via KL-divergence minimization. The proposed algorithm uses also a regularized SoftDTW loss for better tuning the learned features. Our novel representation learning paradigm consistently outperforms the state of the art on temporal alignment tasks, establishing a new performance bar over several downstream video analysis applications. ",
    "url": "https://arxiv.org/abs/2302.04064",
    "authors": [
      "Guy Bar-Shalom",
      "George Leifman",
      "Michael Elad",
      "Ehud Rivlin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04088",
    "title": "FFHR: Fully and Flexible Hyperbolic Representation for Knowledge Graph  Completion",
    "abstract": "Learning hyperbolic embeddings for knowledge graph (KG) has gained increasing attention due to its superiority in capturing hierarchies. However, some important operations in hyperbolic space still lack good definitions, making existing methods unable to fully leverage the merits of hyperbolic space. Specifically, they suffer from two main limitations: 1) existing Graph Convolutional Network (GCN) methods in hyperbolic space rely on tangent space approximation, which would incur approximation error in representation learning, and 2) due to the lack of inner product operation definition in hyperbolic space, existing methods can only measure the plausibility of facts (links) with hyperbolic distance, which is difficult to capture complex data patterns. In this work, we contribute: 1) a Full Poincar\\'{e} Multi-relational GCN that achieves graph information propagation in hyperbolic space without requiring any approximation, and 2) a hyperbolic generalization of Euclidean inner product that is beneficial to capture both hierarchical and complex patterns. On this basis, we further develop a \\textbf{F}ully and \\textbf{F}lexible \\textbf{H}yperbolic \\textbf{R}epresentation framework (\\textbf{FFHR}) that is able to transfer recent Euclidean-based advances to hyperbolic space. We demonstrate it by instantiating FFHR with four representative KGC methods. Extensive experiments on benchmark datasets validate the superiority of our FFHRs over their Euclidean counterparts as well as state-of-the-art hyperbolic embedding methods. ",
    "url": "https://arxiv.org/abs/2302.04088",
    "authors": [
      "Wentao Shi",
      "Junkang Wu",
      "Xuezhi Cao",
      "Jiawei Chen",
      "Wenqiang Lei",
      "Wei Wu",
      "Xiangnan He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.04098",
    "title": "Source Code Recommender Systems: The Practitioners' Perspective",
    "abstract": "The automatic generation of source code is one of the long-lasting dreams in software engineering research. Several techniques have been proposed to speed up the writing of new code. For example, code completion techniques can recommend to developers the next few tokens they are likely to type, while retrieval-based approaches can suggest code snippets relevant for the task at hand. Also, deep learning has been used to automatically generate code statements starting from a natural language description. While research in this field is very active, there is no study investigating what the users of code recommender systems (i.e., software practitioners) actually need from these tools. We present a study involving 80 software developers to investigate the characteristics of code recommender systems they consider important. The output of our study is a taxonomy of 70 \"requirements\" that should be considered when designing code recommender systems. For example, developers would like the recommended code to use the same coding style of the code under development. Also, code recommenders being \"aware\" of the developers' knowledge (e.g., what are the framework/libraries they already used in the past) and able to customize the recommendations based on this knowledge would be appreciated by practitioners. The taxonomy output of our study points to a wide set of future research directions for code recommenders. ",
    "url": "https://arxiv.org/abs/2302.04098",
    "authors": [
      "Matteo Ciniselli",
      "Luca Pascarella",
      "Emad Aghajani",
      "Simone Scalabrino",
      "Rocco Oliveto",
      "Gabriele Bavota"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.04106",
    "title": "Detecting Data Type Inconsistencies in a Property Graph Database",
    "abstract": "Some property graph databases do not have a fixed schema, which can result in data type inconsistencies for properties on nodes and relationships, especially when importing data into a running database. Here we present a tool which can rapidly produce a detailed report on every property in the graph. When executed on a large knowledge graph, it allowed us to debug a complex ETL process and enforce 100% data type consistency. ",
    "url": "https://arxiv.org/abs/2302.04106",
    "authors": [
      "Joshua R. Porter",
      "Michael N. Young",
      "Aleks Y. M. Ontman"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.04107",
    "title": "Can Physics-Informed Neural Networks beat the Finite Element Method?",
    "abstract": "Partial differential equations play a fundamental role in the mathematical modelling of many processes and systems in physical, biological and other sciences. To simulate such processes and systems, the solutions of PDEs often need to be approximated numerically. The finite element method, for instance, is a usual standard methodology to do so. The recent success of deep neural networks at various approximation tasks has motivated their use in the numerical solution of PDEs. These so-called physics-informed neural networks and their variants have shown to be able to successfully approximate a large range of partial differential equations. So far, physics-informed neural networks and the finite element method have mainly been studied in isolation of each other. In this work, we compare the methodologies in a systematic computational study. Indeed, we employ both methods to numerically solve various linear and nonlinear partial differential equations: Poisson in 1D, 2D, and 3D, Allen-Cahn in 1D, semilinear Schr\\\"odinger in 1D and 2D. We then compare computational costs and approximation accuracies. In terms of solution time and accuracy, physics-informed neural networks have not been able to outperform the finite element method in our study. In some experiments, they were faster at evaluating the solved PDE. ",
    "url": "https://arxiv.org/abs/2302.04107",
    "authors": [
      "Tamara G. Grossmann",
      "Urszula Julia Komorowska",
      "Jonas Latz",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04109",
    "title": "Explainable Label-flipping Attacks on Human Emotion Assessment System",
    "abstract": "This paper's main goal is to provide an attacker's point of view on data poisoning assaults that use label-flipping during the training phase of systems that use electroencephalogram (EEG) signals to evaluate human emotion. To attack different machine learning classifiers such as Adaptive Boosting (AdaBoost) and Random Forest dedicated to the classification of 4 different human emotions using EEG signals, this paper proposes two scenarios of label-flipping methods. The results of the studies show that the proposed data poison attacksm based on label-flipping are successful regardless of the model, but different models show different degrees of resistance to the assaults. In addition, numerous Explainable Artificial Intelligence (XAI) techniques are used to explain the data poison attacks on EEG signal-based human emotion evaluation systems. ",
    "url": "https://arxiv.org/abs/2302.04109",
    "authors": [
      "Zhibo Zhang",
      "Ahmed Y. Al Hammadi",
      "Ernesto Damiani",
      "Chan Yeob Yeun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04113",
    "title": "Cliques in High-Dimensional Geometric Inhomogeneous Random Graphs",
    "abstract": "A recent trend in the context of graph theory is to bring theoretical analyses closer to empirical observations, by focusing the studies on random graph models that are used to represent practical instances. There, it was observed that geometric inhomogeneous random graphs (GIRGs) yield good representations of complex real-world networks, by expressing edge probabilities as a function that depends on (heterogeneous) vertex weights and distances in some underlying geometric space that the vertices are distributed in. While most of the parameters of the model are understood well, it was unclear how the dimensionality of the ground space affects the structure of the graphs. In this paper, we complement existing research into the dimension of geometric random graph models and the ongoing study of determining the dimensionality of real-world networks, by studying how the structure of GIRGs changes as the number of dimensions increases. We prove that, in the limit, GIRGs approach non-geometric inhomogeneous random graphs and present insights on how quickly the decay of the geometry impacts important graph structures. In particular, we study the expected number of cliques of a given size as well as the clique number and characterize phase transitions at which their behavior changes fundamentally. Finally, our insights help in better understanding previous results about the impact of the dimensionality on geometric random graphs. ",
    "url": "https://arxiv.org/abs/2302.04113",
    "authors": [
      "Tobias Friedrich",
      "Andreas G\u00f6bel",
      "Maximilian Katzmann",
      "Leon Schiller"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2302.04116",
    "title": "Training-free Lexical Backdoor Attacks on Language Models",
    "abstract": "Large-scale language models have achieved tremendous success across various natural language processing (NLP) applications. Nevertheless, language models are vulnerable to backdoor attacks, which inject stealthy triggers into models for steering them to undesirable behaviors. Most existing backdoor attacks, such as data poisoning, require further (re)training or fine-tuning language models to learn the intended backdoor patterns. The additional training process however diminishes the stealthiness of the attacks, as training a language model usually requires long optimization time, a massive amount of data, and considerable modifications to the model parameters. In this work, we propose Training-Free Lexical Backdoor Attack (TFLexAttack) as the first training-free backdoor attack on language models. Our attack is achieved by injecting lexical triggers into the tokenizer of a language model via manipulating its embedding dictionary using carefully designed rules. These rules are explainable to human developers which inspires attacks from a wider range of hackers. The sparse manipulation of the dictionary also habilitates the stealthiness of our attack. We conduct extensive experiments on three dominant NLP tasks based on nine language models to demonstrate the effectiveness and universality of our attack. The code of this work is available at https://github.com/Jinxhy/TFLexAttack. ",
    "url": "https://arxiv.org/abs/2302.04116",
    "authors": [
      "Yujin Huang",
      "Terry Yue Zhuo",
      "Qiongkai Xu",
      "Han Hu",
      "Xingliang Yuan",
      "Chunyang Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.04126",
    "title": "Predicting the performance of hybrid ventilation in buildings using a  multivariate attention-based biLSTM Encoder-Decoder neural network",
    "abstract": "Hybrid ventilation (coupling natural and mechanical ventilation) is an energy-efficient solution to provide fresh air for most climates, given that it has a reliable control system. To operate such systems optimally, a high-fidelity control-oriented model is required. It should enable near-real time forecast of the indoor air temperature and humidity based on operational conditions such as window opening and HVAC schedules. However, widely used physics-based simulation models (i.e., white-box models) are labour-intensive and computationally expensive. Alternatively, black-box models based on artificial neural networks can be trained to be good estimators for building dynamics. This paper investigates the capabilities of a multivariate multi-head attention-based long short-term memory (LSTM) encoder-decoder neural network to predict indoor air conditions of a building equipped with hybrid ventilation. The deep neural network used for this study aims to predict indoor air temperature dynamics when a window is opened and closed, respectively. Training and test data were generated from detailed multi-zone office building model (EnergyPlus). The deep neural network is able to accurately predict indoor air temperature of five zones whenever a window was opened and closed. ",
    "url": "https://arxiv.org/abs/2302.04126",
    "authors": [
      "Gaurav Chaudhary",
      "Hicham Johra",
      "Laurent Georges",
      "Bj\u00f8rn Austb\u00f8"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.04129",
    "title": "Hyperspectral Image Compression Using Implicit Neural Representation",
    "abstract": "Hyperspectral images, which record the electromagnetic spectrum for a pixel in the image of a scene, often store hundreds of channels per pixel and contain an order of magnitude more information than a typical similarly-sized color image. Consequently, concomitant with the decreasing cost of capturing these images, there is a need to develop efficient techniques for storing, transmitting, and analyzing hyperspectral images. This paper develops a method for hyperspectral image compression using implicit neural representations where a multilayer perceptron network $\\Phi_\\theta$ with sinusoidal activation functions ``learns'' to map pixel locations to pixel intensities for a given hyperspectral image $I$. $\\Phi_\\theta$ thus acts as a compressed encoding of this image. The original image is reconstructed by evaluating $\\Phi_\\theta$ at each pixel location. We have evaluated our method on four benchmarks -- Indian Pines, Cuprite, Pavia University, and Jasper Ridge -- and we show the proposed method achieves better compression than JPEG, JPEG2000, PCA-DCT, and HVEC at low bitrates. ",
    "url": "https://arxiv.org/abs/2302.04129",
    "authors": [
      "Shima Rezasoltani",
      "Faisal Z. Qureshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.04132",
    "title": "Robustness to Spurious Correlations Improves Semantic  Out-of-Distribution Detection",
    "abstract": "Methods which utilize the outputs or feature representations of predictive models have emerged as promising approaches for out-of-distribution (OOD) detection of image inputs. However, these methods struggle to detect OOD inputs that share nuisance values (e.g. background) with in-distribution inputs. The detection of shared-nuisance out-of-distribution (SN-OOD) inputs is particularly relevant in real-world applications, as anomalies and in-distribution inputs tend to be captured in the same settings during deployment. In this work, we provide a possible explanation for SN-OOD detection failures and propose nuisance-aware OOD detection to address them. Nuisance-aware OOD detection substitutes a classifier trained via empirical risk minimization and cross-entropy loss with one that 1. is trained under a distribution where the nuisance-label relationship is broken and 2. yields representations that are independent of the nuisance under this distribution, both marginally and conditioned on the label. We can train a classifier to achieve these objectives using Nuisance-Randomized Distillation (NuRD), an algorithm developed for OOD generalization under spurious correlations. Output- and feature-based nuisance-aware OOD detection perform substantially better than their original counterparts, succeeding even when detection based on domain generalization algorithms fails to improve performance. ",
    "url": "https://arxiv.org/abs/2302.04132",
    "authors": [
      "Lily H. Zhang",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04168",
    "title": "Generalizing Neural Wave Functions",
    "abstract": "Recent neural network-based wave functions have achieved state-of-the-art accuracies in modeling ab-initio ground-state potential energy surface. However, these networks can only solve different spatial arrangements of the same set of atoms. To overcome this limitation, we present Graph-learned Orbital Embeddings (Globe), a neural network-based reparametrization method that can adapt neural wave functions to different molecules. We achieve this by combining a localization method for molecular orbitals with spatial message-passing networks. Further, we propose a locality-driven wave function, the Molecular Oribtal Network (Moon), tailored to solving Schr\\\"odinger equations of different molecules jointly. In our experiments, we find Moon requiring 8 times fewer steps to converge to similar accuracies as previous methods when trained on different molecules jointly while Globe enabling the transfer from smaller to larger molecules. Further, our analysis shows that Moon converges similarly to recent transformer-based wave functions on larger molecules. In both the computational chemistry and machine learning literature, we are the first to demonstrate that a single wave function can solve the Schr\\\"odinger equation of molecules with different atoms jointly. ",
    "url": "https://arxiv.org/abs/2302.04168",
    "authors": [
      "Nicholas Gao",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2302.04174",
    "title": "The Hardware Impact of Quantization and Pruning for Weights in Spiking  Neural Networks",
    "abstract": "Energy efficient implementations and deployments of Spiking neural networks (SNNs) have been of great interest due to the possibility of developing artificial systems that can achieve the computational powers and energy efficiency of the biological brain. Efficient implementations of SNNs on modern digital hardware are also inspired by advances in machine learning and deep neural networks (DNNs). Two techniques widely employed in the efficient deployment of DNNs -- the quantization and pruning of parameters, can both compress the model size, reduce memory footprints, and facilitate low-latency execution. The interaction between quantization and pruning and how they might impact model performance on SNN accelerators is currently unknown. We study various combinations of pruning and quantization in isolation, cumulatively, and simultaneously (jointly) to a state-of-the-art SNN targeting gesture recognition for dynamic vision sensor cameras (DVS). We show that this state-of-the-art model is amenable to aggressive parameter quantization, not suffering from any loss in accuracy down to ternary weights. However, pruning only maintains iso-accuracy up to 80% sparsity, which results in 45% more energy than the best quantization on our architectural model. Applying both pruning and quantization can result in an accuracy loss to offer a favourable trade-off on the energy-accuracy Pareto-frontier for the given hardware configuration. ",
    "url": "https://arxiv.org/abs/2302.04174",
    "authors": [
      "Clemens JS Schaefer",
      "Pooria Taheri",
      "Mark Horeni",
      "Siddharth Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04177",
    "title": "A Dynamic Graph CNN with Cross-Representation Distillation for  Event-Based Recognition",
    "abstract": "It is a popular solution to convert events into dense frame-based representations to use the well-pretrained CNNs in hand. Although with appealing performance, this line of work sacrifices the sparsity/temporal precision of events and usually necessitates heavy-weight models, thereby largely weakening the advantages and real-life application potential of event cameras. A more application-friendly way is to design deep graph models for learning sparse point-based representations from events. Yet, the efficacy of these graph models is far behind the frame-based counterpart with two key limitations: ($i$) simple graph construction strategies without carefully integrating the variant attributes (i.e., semantics, spatial and temporal coordinates) for each vertex, leading to biased graph representation; ($ii$) deficient learning because the lack of well pretraining models available. Here we solve the first problem by introducing a new event-based graph CNN (EDGCN), with a dynamic aggregation module to integrate all attributes of vertices adaptively. To alleviate the learning difficulty, we propose to leverage the dense representation counterpart of events as a cross-representation auxiliary to supply additional supervision and prior knowledge for the event graph. To this end, we form a frame-to-graph transfer learning framework with a customized hybrid distillation loss to well respect the varying cross-representation gaps across layers. Extensive experiments on multiple vision tasks validate the effectiveness and high generalization ability of our proposed model and distillation strategy (Core components of our codes are submitted with supplementary material and will be made publicly available upon acceptance) ",
    "url": "https://arxiv.org/abs/2302.04177",
    "authors": [
      "Yongjian Deng",
      "Hao Chen",
      "Bochen Xie",
      "Hai Liu",
      "Youfu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04178",
    "title": "DynGFN: Bayesian Dynamic Causal Discovery using Generative Flow Networks",
    "abstract": "Learning the causal structure of observable variables is a central focus for scientific discovery. Bayesian causal discovery methods tackle this problem by learning a posterior over the set of admissible graphs given our priors and observations. Existing methods primarily consider observations from static systems and assume the underlying causal structure takes the form of a directed acyclic graph (DAG). In settings with dynamic feedback mechanisms that regulate the trajectories of individual variables, this acyclicity assumption fails unless we account for time. We focus on learning Bayesian posteriors over cyclic graphs and treat causal discovery as a problem of sparse identification of a dynamical system. This imposes a natural temporal causal order between variables and captures cyclic feedback loops through time. Under this lens, we propose a new framework for Bayesian causal discovery for dynamical systems and present a novel generative flow network architecture (DynGFN) tailored for this task. Our results indicate that DynGFN learns posteriors that better encapsulate the distributions over admissible cyclic causal structures compared to counterpart state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2302.04178",
    "authors": [
      "Lazar Atanackovic",
      "Alexander Tong",
      "Jason Hartford",
      "Leo J. Lee",
      "Bo Wang",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04181",
    "title": "Attending to Graph Transformers",
    "abstract": "Recently, transformer architectures for graphs emerged as an alternative to established techniques for machine learning with graphs, such as graph neural networks. So far, they have shown promising empirical results, e.g., on molecular prediction datasets, often attributed to their ability to circumvent graph neural networks' shortcomings, such as over-smoothing and over-squashing. Here, we derive a taxonomy of graph transformer architectures, bringing some order to this emerging field. We overview their theoretical properties, survey structural and positional encodings, and discuss extensions for important graph classes, e.g., 3D molecular graphs. Empirically, we probe how well graph transformers can recover various graph properties, how well they can deal with heterophilic graphs, and to what extent they prevent over-squashing. Further, we outline open challenges and research direction to stimulate future work. Our code is available at https://github.com/luis-mueller/probing-graph-transformers. ",
    "url": "https://arxiv.org/abs/2302.04181",
    "authors": [
      "Luis M\u00fcller",
      "Mikhail Galkin",
      "Christopher Morris",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.04208",
    "title": "Exploratory Analysis of Federated Learning Methods with Differential  Privacy on MIMIC-III",
    "abstract": "Background: Federated learning methods offer the possibility of training machine learning models on privacy-sensitive data sets, which cannot be easily shared. Multiple regulations pose strict requirements on the storage and usage of healthcare data, leading to data being in silos (i.e. locked-in at healthcare facilities). The application of federated algorithms on these datasets could accelerate disease diagnostic, drug development, as well as improve patient care. Methods: We present an extensive evaluation of the impact of different federation and differential privacy techniques when training models on the open-source MIMIC-III dataset. We analyze a set of parameters influencing a federated model performance, namely data distribution (homogeneous and heterogeneous), communication strategies (communication rounds vs. local training epochs), federation strategies (FedAvg vs. FedProx). Furthermore, we assess and compare two differential privacy (DP) techniques during model training: a stochastic gradient descent-based differential privacy algorithm (DP-SGD), and a sparse vector differential privacy technique (DP-SVT). Results: Our experiments show that extreme data distributions across sites (imbalance either in the number of patients or the positive label ratios between sites) lead to a deterioration of model performance when trained using the FedAvg strategy. This issue is resolved when using FedProx with the use of appropriate hyperparameter tuning. Furthermore, the results show that both differential privacy techniques can reach model performances similar to those of models trained without DP, however at the expense of a large quantifiable privacy leakage. Conclusions: We evaluate empirically the benefits of two federation strategies and propose optimal strategies for the choice of parameters when using differential privacy techniques. ",
    "url": "https://arxiv.org/abs/2302.04208",
    "authors": [
      "Aron N. Horvath",
      "Matteo Berchier",
      "Farhad Nooralahzadeh",
      "Ahmed Allam",
      "Michael Krauthammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.04233",
    "title": "SkyEye: Self-Supervised Bird's-Eye-View Semantic Mapping Using Monocular  Frontal View Images",
    "abstract": "Bird's-Eye-View (BEV) semantic maps have become an essential component of automated driving pipelines due to the rich representation they provide for decision-making tasks. However, existing approaches for generating these maps still follow a fully supervised training paradigm and hence rely on large amounts of annotated BEV data. In this work, we address this limitation by proposing the first self-supervised approach for generating a BEV semantic map using a single monocular image from the frontal view (FV). During training, we overcome the need for BEV ground truth annotations by leveraging the more easily available FV semantic annotations of video sequences. Thus, we propose the SkyEye architecture that learns based on two modes of self-supervision, namely, implicit supervision and explicit supervision. Implicit supervision trains the model by enforcing spatial consistency of the scene over time based on FV semantic sequences, while explicit supervision exploits BEV pseudolabels generated from FV semantic annotations and self-supervised depth estimates. Extensive evaluations on the KITTI-360 dataset demonstrate that our self-supervised approach performs on par with the state-of-the-art fully supervised methods and achieves competitive results using only 1% of direct supervision in the BEV compared to fully supervised approaches. Finally, we publicly release both our code and the BEV datasets generated from the KITTI-360 and Waymo datasets. ",
    "url": "https://arxiv.org/abs/2302.04233",
    "authors": [
      "Nikhil Gosala",
      "K\u00fcrsat Petek",
      "Paulo L. J. Drews-Jr",
      "Wolfram Burgard",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.04237",
    "title": "Adversarial Prompting for Black Box Foundation Models",
    "abstract": "Prompting interfaces allow users to quickly adjust the output of generative models in both vision and language. However, small changes and design choices in the prompt can lead to significant differences in the output. In this work, we develop a black-box framework for generating adversarial prompts for unstructured image and text generation. These prompts, which can be standalone or prepended to benign prompts, induce specific behaviors into the generative process, such as generating images of a particular object or biasing the frequency of specific letters in the generated text. ",
    "url": "https://arxiv.org/abs/2302.04237",
    "authors": [
      "Natalie Maus",
      "Patrick Chao",
      "Eric Wong",
      "Jacob Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04246",
    "title": "Shortcut Detection with Variational Autoencoders",
    "abstract": "For real-world applications of machine learning (ML), it is essential that models make predictions based on well-generalizing features rather than spurious correlations in the data. The identification of such spurious correlations, also known as shortcuts, is a challenging problem and has so far been scarcely addressed. In this work, we present a novel approach to detect shortcuts in image and audio datasets by leveraging variational autoencoders (VAEs). The disentanglement of features in the latent space of VAEs allows us to discover correlations in datasets and semi-automatically evaluate them for ML shortcuts. We demonstrate the applicability of our method on several real-world datasets and identify shortcuts that have not been discovered before. Based on these findings, we also investigate the construction of shortcut adversarial examples. ",
    "url": "https://arxiv.org/abs/2302.04246",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Simon Roschmann",
      "Shahbaz Khan",
      "Philip Sperl",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04264",
    "title": "Nerfstudio: A Modular Framework for Neural Radiance Field Development",
    "abstract": "Neural Radiance Fields (NeRF) are a rapidly growing area of research with wide-ranging applications in computer vision, graphics, robotics, and more. In order to streamline the development and deployment of NeRF research, we propose a modular PyTorch framework, Nerfstudio. Our framework includes plug-and-play components for implementing NeRF-based methods, which make it easy for researchers and practitioners to incorporate NeRF into their projects. Additionally, the modular design enables support for extensive real-time visualization tools, streamlined pipelines for importing captured in-the-wild data, and tools for exporting to video, point cloud and mesh representations. The modularity of Nerfstudio enables the development of Nerfacto, our method that combines components from recent papers to achieve a balance between speed and quality, while also remaining flexible to future modifications. To promote community-driven development, all associated code and data are made publicly available with open-source licensing at https://nerf.studio. ",
    "url": "https://arxiv.org/abs/2302.04264",
    "authors": [
      "Matthew Tancik",
      "Ethan Weber",
      "Evonne Ng",
      "Ruilong Li",
      "Brent Yi",
      "Justin Kerr",
      "Terrance Wang",
      "Alexander Kristoffersen",
      "Jake Austin",
      "Kamyar Salahi",
      "Abhik Ahuja",
      "David McAllister",
      "Angjoo Kanazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2302.03907",
    "title": "DDeMON: Ontology-based function prediction by Deep Learning from Dynamic  Multiplex Networks",
    "abstract": "Biological systems can be studied at multiple levels of information, including gene, protein, RNA and different interaction networks levels. The goal of this work is to explore how the fusion of systems' level information with temporal dynamics of gene expression can be used in combination with non-linear approximation power of deep neural networks to predict novel gene functions in a non-model organism potato \\emph{Solanum tuberosum}. We propose DDeMON (Dynamic Deep learning from temporal Multiplex Ontology-annotated Networks), an approach for scalable, systems-level inference of function annotation using time-dependent multiscale biological information. The proposed method, which is capable of considering billions of potential links between the genes of interest, was applied on experimental gene expression data and the background knowledge network to reliably classify genes with unknown function into five different functional ontology categories, linked to the experimental data set. Predicted novel functions of genes were validated using extensive protein domain search approach. ",
    "url": "https://arxiv.org/abs/2302.03907",
    "authors": [
      "Jan Kralj",
      "Bla\u017e \u0160krlj",
      "\u017diva Ram\u0161ak",
      "Nada Lavra\u010d",
      "Kristina Gruden"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03991",
    "title": "Prediction approaches for partly missing multi-omics covariate data: A  literature review and an empirical comparison study",
    "abstract": "As the availability of omics data has increased in the last few years, more multi-omics data have been generated, that is, high-dimensional molecular data consisting of several types such as genomic, transcriptomic, or proteomic data, all obtained from the same patients. Such data lend themselves to being used as covariates in automatic outcome prediction because each omics type may contribute unique information, possibly improving predictions compared to using only one omics data type. Frequently, however, in the training data and the data to which automatic prediction rules should be applied, the test data, the different omics data types are not available for all patients. We refer to this type of data as block-wise missing multi-omics data. First, we provide a literature review on existing prediction methods applicable to such data. Subsequently, using a collection of 13 publicly available multi-omics data sets, we compare the predictive performances of several of these approaches for different block-wise missingness patterns. Finally, we discuss the results of this empirical comparison study and draw some tentative conclusions. ",
    "url": "https://arxiv.org/abs/2302.03991",
    "authors": [
      "Roman Hornung",
      "Frederik Ludwigs",
      "Jonas Hagenberg",
      "Anne-Laure Boulesteix"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2302.04161",
    "title": "Masking Kernel for Learning Energy-Efficient Speech Representation",
    "abstract": "Modern smartphones are equipped with powerful audio hardware and processors, allowing them to acquire and perform on-device speech processing at high sampling rates. However, energy consumption remains a concern, especially for resource-intensive DNNs. Prior mobile speech processing reduced computational complexity by compacting the model or reducing input dimensions via hyperparameter tuning, which reduced accuracy or required more training iterations. This paper proposes gradient descent for optimizing energy-efficient speech recording format (length and sampling rate). The goal is to reduce the input size, which reduces data collection and inference energy. For a backward pass, a masking function with non-zero derivatives (Gaussian, Hann, and Hamming) is used as a windowing function and a lowpass filter. An energy-efficient penalty is introduced to incentivize the reduction of the input size. The proposed masking outperformed baselines by 8.7% in speaker recognition and traumatic brain injury detection using 49% shorter duration, sampled at a lower frequency. ",
    "url": "https://arxiv.org/abs/2302.04161",
    "authors": [
      "Apiwat Ditthapron",
      "Emmanuel O. Agu",
      "Adam C. Lammert"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2302.04173",
    "title": "A Survey of Feature detection methods for localisation of plain sections  of Axial Brain Magnetic Resonance Imaging",
    "abstract": "Matching MRI brain images between patients or mapping patients' MRI slices to the simulated atlas of a brain is key to the automatic registration of MRI of a brain. The ability to match MRI images would also enable such applications as indexing and searching MRI images among multiple patients or selecting images from the region of interest. In this work, we have introduced robustness, accuracy and cumulative distance metrics and methodology that allows us to compare different techniques and approaches in matching brain MRI of different patients or matching MRI brain slice to a position in the brain atlas. To that end, we have used feature detection methods AGAST, AKAZE, BRISK, GFTT, HardNet, and ORB, which are established methods in image processing, and compared them on their resistance to image degradation and their ability to match the same brain MRI slice of different patients. We have demonstrated that some of these techniques can correctly match most of the brain MRI slices of different patients. When matching is performed with the atlas of the human brain, their performance is significantly lower. The best performing feature detection method was a combination of SIFT detector and HardNet descriptor that achieved 93% accuracy in matching images with other patients and only 52% accurately matched images when compared to atlas. ",
    "url": "https://arxiv.org/abs/2302.04173",
    "authors": [
      "Ji\u0159\u00ed Martin\u016f",
      "Jan Novotn\u00fd",
      "Karel Ad\u00e1mek",
      "Petr \u010cerm\u00e1k",
      "Ji\u0159\u00ed Kozel",
      "David \u0160koloud\u00edk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2004.14878",
    "title": "PreCNet: Next-Frame Video Prediction Based on Predictive Coding",
    "abstract": " Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS) ",
    "url": "https://arxiv.org/abs/2004.14878",
    "authors": [
      "Zdenek Straka",
      "Tomas Svoboda",
      "Matej Hoffmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2104.12868",
    "title": "Fuzzy Expert Systems for Prediction of ICU Admission in Patients with  COVID-19",
    "abstract": " Title: Fuzzy Expert Systems for Prediction of ICU Admission in Patients with  COVID-19 ",
    "url": "https://arxiv.org/abs/2104.12868",
    "authors": [
      "Ali Akbar Sadat Asl",
      "Mohammad Mahdi Ershadi",
      "Shahabeddin Sotudian",
      "Xingyu Li",
      "Scott Dick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.11299",
    "title": "Boundary Graph Neural Networks for 3D Simulations",
    "abstract": " Comments: accepted for presentation at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23) ",
    "url": "https://arxiv.org/abs/2106.11299",
    "authors": [
      "Andreas Mayr",
      "Sebastian Lehner",
      "Arno Mayrhofer",
      "Christoph Kloss",
      "Sepp Hochreiter",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.03778",
    "title": "Choiceless Polynomial Time, Symmetric Circuits and Cai-F\u00fcrer-Immerman  Graphs",
    "abstract": " Comments: replaced with a substantially improved and augmented version ",
    "url": "https://arxiv.org/abs/2107.03778",
    "authors": [
      "Benedikt Pago"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2201.02323",
    "title": "Distributed Nash Equilibrium Seeking over Time-Varying Directed  Communication Networks",
    "abstract": " Title: Distributed Nash Equilibrium Seeking over Time-Varying Directed  Communication Networks ",
    "url": "https://arxiv.org/abs/2201.02323",
    "authors": [
      "Duong Thuy Anh Nguyen",
      "Duong Tung Nguyen",
      "Angelia Nedi\u0107"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2201.12843",
    "title": "Graph Representation Learning via Aggregation Enhancement",
    "abstract": " Title: Graph Representation Learning via Aggregation Enhancement ",
    "url": "https://arxiv.org/abs/2201.12843",
    "authors": [
      "Maxim Fishman",
      "Chaim Baskin",
      "Evgenii Zheltonozhskii",
      "Almog David",
      "Ron Banner",
      "Avi Mendelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.13056",
    "title": "Automated Identification of Toxic Code Reviews Using ToxiCR",
    "abstract": " Title: Automated Identification of Toxic Code Reviews Using ToxiCR ",
    "url": "https://arxiv.org/abs/2202.13056",
    "authors": [
      "Jaydeb Sarker",
      "Asif Kamal Turzo",
      "Ming Dong",
      "Amiangshu Bosu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.10037",
    "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks",
    "abstract": " Title: DropMessage: Unifying Random Dropping for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2204.10037",
    "authors": [
      "Taoran Fang",
      "Zhiqing Xiao",
      "Chunping Wang",
      "Jiarong Xu",
      "Xuan Yang",
      "Yang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03638",
    "title": "Alternately Optimized Graph Neural Networks",
    "abstract": " Title: Alternately Optimized Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2206.03638",
    "authors": [
      "Haoyu Han",
      "Xiaorui Liu",
      "Haitao Mao",
      "MohamadAli Torkamani",
      "Feng Shi",
      "Victor Lee",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03698",
    "title": "What do we learn? Debunking the Myth of Unsupervised Outlier Detection",
    "abstract": " Title: What do we learn? Debunking the Myth of Unsupervised Outlier Detection ",
    "url": "https://arxiv.org/abs/2206.03698",
    "authors": [
      "Cosmin I. Bercea",
      "Daniel Rueckert",
      "Julia A. Schnabel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.08547",
    "title": "Texture Generation Using A Graph Generative Adversarial Network And  Differentiable Rendering",
    "abstract": " Comments: The final publication is available at Springer via this http URL ",
    "url": "https://arxiv.org/abs/2206.08547",
    "authors": [
      "Dharma KC",
      "Clayton T. Morrison",
      "Bradley Walls"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.12608",
    "title": "Adversarial Self-Attention for Language Understanding",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2206.12608",
    "authors": [
      "Hongqiu Wu",
      "Ruixue Ding",
      "Hai Zhao",
      "Pengjun Xie",
      "Fei Huang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14986",
    "title": "A Hierarchical Robust Control Strategy for Decentralized Signal-Free  Intersection Management",
    "abstract": " Comments: 14 pages, 9 figures, 3 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with arXiv:2203.16870 ",
    "url": "https://arxiv.org/abs/2206.14986",
    "authors": [
      "Xiao Pan",
      "Boli Chen",
      "Li Dai",
      "Stelios Timotheou",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.00449",
    "title": "Dissecting Self-Supervised Learning Methods for Surgical Computer Vision",
    "abstract": " Title: Dissecting Self-Supervised Learning Methods for Surgical Computer Vision ",
    "url": "https://arxiv.org/abs/2207.00449",
    "authors": [
      "Sanat Ramesh",
      "Vinkle Srivastav",
      "Deepak Alapatt",
      "Tong Yu",
      "Aditya Murali",
      "Luca Sestini",
      "Chinedu Innocent Nwoye",
      "Idris Hamoud",
      "Saurav Sharma",
      "Antoine Fleurentin",
      "Georgios Exarchakis",
      "Alexandros Karargyris",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04179",
    "title": "Transformer Neural Processes: Uncertainty-Aware Meta Learning Via  Sequence Modeling",
    "abstract": " Comments: International Conference on Machine Learning 2022 ",
    "url": "https://arxiv.org/abs/2207.04179",
    "authors": [
      "Tung Nguyen",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10985",
    "title": "NeurAR: Neural Uncertainty for Autonomous 3D Reconstruction with  Implicit Neural Representations",
    "abstract": " Comments: 8 pages, 6 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2207.10985",
    "authors": [
      "Yunlong Ran",
      "Jing Zeng",
      "Shibo He",
      "Lincheng Li",
      "Yingfeng Chen",
      "Gimhee Lee",
      "Jiming Chen",
      "Qi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.06987",
    "title": "The Causal Structure of Domain Invariant Supervised Representation  Learning",
    "abstract": " Title: The Causal Structure of Domain Invariant Supervised Representation  Learning ",
    "url": "https://arxiv.org/abs/2208.06987",
    "authors": [
      "Zihao Wang",
      "Victor Veitch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.07899",
    "title": "Versatile Skill Control via Self-supervised Adversarial Imitation of  Unlabeled Mixed Motions",
    "abstract": " Title: Versatile Skill Control via Self-supervised Adversarial Imitation of  Unlabeled Mixed Motions ",
    "url": "https://arxiv.org/abs/2209.07899",
    "authors": [
      "Chenhao Li",
      "Sebastian Blaes",
      "Pavel Kolev",
      "Marin Vlastelica",
      "Jonas Frey",
      "Georg Martius"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11354",
    "title": "Convolutional Learning on Multigraphs",
    "abstract": " Title: Convolutional Learning on Multigraphs ",
    "url": "https://arxiv.org/abs/2209.11354",
    "authors": [
      "Landon Butler",
      "Alejandro Parada-Mayorga",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.12528",
    "title": "Taming Client Dropout and Improving Efficiency for Distributed  Differential Privacy in Federated Learning",
    "abstract": " Comments: 20 pages, 13 figures, 4 tables, under anonymous submission ",
    "url": "https://arxiv.org/abs/2209.12528",
    "authors": [
      "Zhifeng Jiang",
      "Wei Wang",
      "Ruichuan Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2209.13620",
    "title": "Reconstruction-guided attention improves the robustness and shape  processing of neural networks",
    "abstract": " Comments: paper accepted to SVRHM, Neurips workshop 2022 ",
    "url": "https://arxiv.org/abs/2209.13620",
    "authors": [
      "Seoyoung Ahn",
      "Hossein Adeli",
      "Gregory J. Zelinsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.00006",
    "title": "A Graph Neural Network Approach to Automated Model Building in Cryo-EM  Maps",
    "abstract": " Comments: The Eleventh International Conference on Learning Representations ",
    "url": "https://arxiv.org/abs/2210.00006",
    "authors": [
      "Kiarash Jamali",
      "Dari Kimanius",
      "Sjors H.W. Scheres"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2210.00079",
    "title": "Causal Estimation for Text Data with (Apparent) Overlap Violations",
    "abstract": " Title: Causal Estimation for Text Data with (Apparent) Overlap Violations ",
    "url": "https://arxiv.org/abs/2210.00079",
    "authors": [
      "Lin Gui",
      "Victor Veitch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00139",
    "title": "Code Reviews in Open Source Projects : How Do Gender Biases Affect  Participation and Outcomes?",
    "abstract": " Title: Code Reviews in Open Source Projects : How Do Gender Biases Affect  Participation and Outcomes? ",
    "url": "https://arxiv.org/abs/2210.00139",
    "authors": [
      "Sayma Sultana",
      "Asif Kamal Turzo",
      "Amiangshu Bosu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.03466",
    "title": "Latent Neural ODEs with Sparse Bayesian Multiple Shooting",
    "abstract": " Title: Latent Neural ODEs with Sparse Bayesian Multiple Shooting ",
    "url": "https://arxiv.org/abs/2210.03466",
    "authors": [
      "Valerii Iakovlev",
      "Cagatay Yildiz",
      "Markus Heinonen",
      "Harri L\u00e4hdesm\u00e4ki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05484",
    "title": "Equivariance-aware Architectural Optimization of Neural Networks",
    "abstract": " Title: Equivariance-aware Architectural Optimization of Neural Networks ",
    "url": "https://arxiv.org/abs/2210.05484",
    "authors": [
      "Kaitlin Maile",
      "Dennis G. Wilson",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06331",
    "title": "RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims  on Social Media",
    "abstract": " Comments: Accepted to EACL 2023 ",
    "url": "https://arxiv.org/abs/2210.06331",
    "authors": [
      "Somin Wadhwa",
      "Vivek Khetan",
      "Silvio Amir",
      "Byron Wallace"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.09789",
    "title": "Anti-Symmetric DGN: a stable architecture for Deep Graph Networks",
    "abstract": " Comments: Accepted at ICLR 2023 (this https URL) ",
    "url": "https://arxiv.org/abs/2210.09789",
    "authors": [
      "Alessio Gravina",
      "Davide Bacciu",
      "Claudio Gallicchio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10454",
    "title": "Automated Content Moderation Increases Adherence to Community Guidelines",
    "abstract": " Comments: Accepted at TheWebConf 2023, please cite accordingly ",
    "url": "https://arxiv.org/abs/2210.10454",
    "authors": [
      "Manoel Horta Ribeiro",
      "Justin Cheng",
      "Robert West"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.16662",
    "title": "Global Optimization of Energy Efficiency in IRS-Aided Communication  Systems via Robust IRS-Element Activation",
    "abstract": " Comments: 8 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2210.16662",
    "authors": [
      "Christos N. Efrem",
      "Ioannis Krikidis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.05862",
    "title": "MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a  Study on Thyroid Cancer Diagnosis",
    "abstract": " Title: MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a  Study on Thyroid Cancer Diagnosis ",
    "url": "https://arxiv.org/abs/2211.05862",
    "authors": [
      "Michael Gadermayr",
      "Lukas Koller",
      "Maximilian Tschuchnig",
      "Lea Maria Stangassinger",
      "Christina Kreutzer",
      "Sebastien Couillard-Despres",
      "Gertie Janneke Oostingh",
      "Anton Hittmair"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.05913",
    "title": "Twitter Spam and False Accounts Prevalence, Detection and  Characterization: A Survey",
    "abstract": " Comments: Published on First Monday, 27(12), 2022 this https URL ",
    "url": "https://arxiv.org/abs/2211.05913",
    "authors": [
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.09027",
    "title": "LLEDA -- Lifelong Self-Supervised Domain Adaptation",
    "abstract": " Comments: 10 pages, 6 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2211.09027",
    "authors": [
      "Mamatha Thota",
      "Dewei Yi",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13015",
    "title": "Semantics-Preserving Sketch Embedding for Face Generation",
    "abstract": " Title: Semantics-Preserving Sketch Embedding for Face Generation ",
    "url": "https://arxiv.org/abs/2211.13015",
    "authors": [
      "Binxin Yang",
      "Xuejin Chen",
      "Chaoqun Wang",
      "Chi Zhang",
      "Zihan Chen",
      "Xiaoyan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14304",
    "title": "BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction",
    "abstract": " Comments: Revision with minors addressed. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.14304",
    "authors": [
      "German Barquero",
      "Sergio Escalera",
      "Cristina Palmero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16118",
    "title": "Inferring Attack Relations for Gradual Semantics",
    "abstract": " Title: Inferring Attack Relations for Gradual Semantics ",
    "url": "https://arxiv.org/abs/2211.16118",
    "authors": [
      "Nir Oren",
      "Bruno Yun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.14246",
    "title": "Robust representations of oil wells' intervals via sparse attention  mechanism",
    "abstract": " Title: Robust representations of oil wells' intervals via sparse attention  mechanism ",
    "url": "https://arxiv.org/abs/2212.14246",
    "authors": [
      "Alina Rogulina",
      "Nikita Baramiia",
      "Valerii Kornilov",
      "Sergey Petrakov",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.03180",
    "title": "Subset verification and search algorithms for causal DAGs",
    "abstract": " Comments: Accepted into AISTATS 2023 (this https URL) ",
    "url": "https://arxiv.org/abs/2301.03180",
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.07107",
    "title": "Mortality Prediction with Adaptive Feature Importance Recalibration for  Peritoneal Dialysis Patients: a deep-learning-based study on a real-world  longitudinal follow-up dataset",
    "abstract": " Title: Mortality Prediction with Adaptive Feature Importance Recalibration for  Peritoneal Dialysis Patients: a deep-learning-based study on a real-world  longitudinal follow-up dataset ",
    "url": "https://arxiv.org/abs/2301.07107",
    "authors": [
      "Liantao Ma",
      "Chaohe Zhang",
      "Junyi Gao",
      "Xianfeng Jiao",
      "Zhihao Yu",
      "Xinyu Ma",
      "Yasha Wang",
      "Wen Tang",
      "Xinju Zhao",
      "Wenjie Ruan",
      "Tao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.08792",
    "title": "Inherent Limits on Topology-Based Link Prediction",
    "abstract": " Title: Inherent Limits on Topology-Based Link Prediction ",
    "url": "https://arxiv.org/abs/2301.08792",
    "authors": [
      "Justus I. Hibshman",
      "Tim Weninger"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.08998",
    "title": "Syntax-guided Neural Module Distillation to Probe Compositionality in  Sentence Embeddings",
    "abstract": " Comments: EACL 2023 (camera-ready) ",
    "url": "https://arxiv.org/abs/2301.08998",
    "authors": [
      "Rohan Pandey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.09249",
    "title": "Exploring Active 3D Object Detection from a Generalization Perspective",
    "abstract": " Comments: To appear in ICLR 2023 ",
    "url": "https://arxiv.org/abs/2301.09249",
    "authors": [
      "Yadan Luo",
      "Zhuoxiao Chen",
      "Zijian Wang",
      "Xin Yu",
      "Zi Huang",
      "Mahsa Baktashmotlagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12400",
    "title": "HeroNet: A Hybrid Retrieval-Generation Network for Conversational Bots",
    "abstract": " Title: HeroNet: A Hybrid Retrieval-Generation Network for Conversational Bots ",
    "url": "https://arxiv.org/abs/2301.12400",
    "authors": [
      "Bolin Zhang",
      "Yunzhe Xu",
      "Zhiying Tu",
      "Dianhui Chu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13081",
    "title": "STAIR: Learning Sparse Text and Image Representation in Grounded Tokens",
    "abstract": " Title: STAIR: Learning Sparse Text and Image Representation in Grounded Tokens ",
    "url": "https://arxiv.org/abs/2301.13081",
    "authors": [
      "Chen Chen",
      "Bowen Zhang",
      "Liangliang Cao",
      "Jiguang Shen",
      "Tom Gunter",
      "Albin Madappally Jose",
      "Alexander Toshev",
      "Jonathon Shlens",
      "Ruoming Pang",
      "Yinfei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13487",
    "title": "Adversarial Training of Self-supervised Monocular Depth Estimation  against Physical-World Attacks",
    "abstract": " Comments: Accepted at ICLR2023 (Spotlight), add code link ",
    "url": "https://arxiv.org/abs/2301.13487",
    "authors": [
      "Zhiyuan Cheng",
      "James Liang",
      "Guanhong Tao",
      "Dongfang Liu",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00325",
    "title": "Privacy Dashboards for Citizens and GDPR Services for Small Data  Holders: A Literature Review",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2302.00325",
    "authors": [
      "Nico Puhlmann",
      "Alex Wiesmaier",
      "Andreas Heinemann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.00796",
    "title": "Unsupervised Entity Alignment for Temporal Knowledge Graphs",
    "abstract": " Comments: The Web Conference (WWW) 2023 Research Track ",
    "url": "https://arxiv.org/abs/2302.00796",
    "authors": [
      "Xiaoze Liu",
      "Junyang Wu",
      "Tianyi Li",
      "Lu Chen",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.02291",
    "title": "A Semantic Approach to Negation Detection and Word Disambiguation with  Natural Language Processing",
    "abstract": " Title: A Semantic Approach to Negation Detection and Word Disambiguation with  Natural Language Processing ",
    "url": "https://arxiv.org/abs/2302.02291",
    "authors": [
      "Izunna Okpala",
      "Guillermo Romera Rodriguez",
      "Andrea Tapia",
      "Shane Halse",
      "Jess Kropczynski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.02858",
    "title": "TR3D: Towards Real-Time Indoor 3D Object Detection",
    "abstract": " Title: TR3D: Towards Real-Time Indoor 3D Object Detection ",
    "url": "https://arxiv.org/abs/2302.02858",
    "authors": [
      "Danila Rukhovich",
      "Anna Vorontsova",
      "Anton Konushin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03098",
    "title": "One-shot Empirical Privacy Estimation for Federated Learning",
    "abstract": " Title: One-shot Empirical Privacy Estimation for Federated Learning ",
    "url": "https://arxiv.org/abs/2302.03098",
    "authors": [
      "Galen Andrew",
      "Peter Kairouz",
      "Sewoong Oh",
      "Alina Oprea",
      "H. Brendan McMahan",
      "Vinith Suriyakumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.03151",
    "title": "Fair Minimum Representation Clustering",
    "abstract": " Title: Fair Minimum Representation Clustering ",
    "url": "https://arxiv.org/abs/2302.03151",
    "authors": [
      "Connor Lawless",
      "Oktay Gunluk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.03248",
    "title": "Disentangled Causal Embedding With Contrastive Learning For Recommender  System",
    "abstract": " Comments: Accepted by WWW'23 ",
    "url": "https://arxiv.org/abs/2302.03248",
    "authors": [
      "Weiqi Zhao",
      "Dian Tang",
      "Xin Chen",
      "Dawei Lv",
      "Daoli Ou",
      "Biao Li",
      "Peng Jiang",
      "Kun Gai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.03269",
    "title": "PLACES: Prompting Language Models for Social Conversation Synthesis",
    "abstract": " Comments: In Findings of EACL 2023. 25 pages, 4 figures, 26 tables. Link to code forthcoming ",
    "url": "https://arxiv.org/abs/2302.03269",
    "authors": [
      "Maximillian Chen",
      "Alexandros Papangelis",
      "Chenyang Tao",
      "Seokhwan Kim",
      "Andy Rosenbaum",
      "Yang Liu",
      "Zhou Yu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  }
]