[
  {
    "id": "arXiv:2302.12301",
    "title": "An Aligned Multi-Temporal Multi-Resolution Satellite Image Dataset for  Change Detection Research",
    "abstract": "This paper presents an aligned multi-temporal and multi-resolution satellite image dataset for research in change detection. We expect our dataset to be useful to researchers who want to fuse information from multiple satellites for detecting changes on the surface of the earth that may not be fully visible in any single satellite. The dataset we present was created by augmenting the SpaceNet-7 dataset with temporally parallel stacks of Landsat and Sentinel images. The SpaceNet-7 dataset consists of time-sequenced Planet images recorded over 101 AOIs (Areas-of-Interest). In our dataset, for each of the 60 AOIs that are meant for training, we augment the Planet datacube with temporally parallel datacubes of Landsat and Sentinel images. The temporal alignments between the high-res Planet images, on the one hand, and the Landsat and Sentinel images, on the other, are approximate since the temporal resolution for the Planet images is one month -- each image being a mosaic of the best data collected over a month. Whenever we have a choice regarding which Landsat and Sentinel images to pair up with the Planet images, we have chosen those that had the least cloud cover. A particularly important feature of our dataset is that the high-res and the low-res images are spatially aligned together with our MuRA framework presented in this paper. Foundational to the alignment calculation is the modeling of inter-satellite misalignment errors with polynomials as in NASA's AROP algorithm. We have named our dataset MuRA-T for the MuRA framework that is used for aligning the cross-satellite images and \"T\" for the temporal dimension in the dataset. ",
    "url": "https://arxiv.org/abs/2302.12301",
    "authors": [
      "Rahul Deshmukh",
      "Constantine J. Roros",
      "Amith Kashyap",
      "Avinash C. Kak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.12304",
    "title": "Uncertainty Injection: A Deep Learning Method for Robust Optimization",
    "abstract": "This paper proposes a paradigm of uncertainty injection for training deep learning model to solve robust optimization problems. The majority of existing studies on deep learning focus on the model learning capability, while assuming the quality and accuracy of the inputs data can be guaranteed. However, in realistic applications of deep learning for solving optimization problems, the accuracy of inputs, which are the problem parameters in this case, plays a large role. This is because, in many situations, it is often costly or sometime impossible to obtain the problem parameters accurately, and correspondingly, it is highly desirable to develop learning algorithms that can account for the uncertainties in the input and produce solutions that are robust against these uncertainties. This paper presents a novel uncertainty injection scheme for training machine learning models that are capable of implicitly accounting for the uncertainties and producing statistically robust solutions. We further identify the wireless communications as an application field where uncertainties are prevalent in problem parameters such as the channel coefficients. We show the effectiveness of the proposed training scheme in two applications: the robust power loading for multiuser multiple-input-multiple-output (MIMO) downlink transmissions; and the robust power control for device-to-device (D2D) networks. ",
    "url": "https://arxiv.org/abs/2302.12304",
    "authors": [
      "Wei Cui",
      "Wei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12338",
    "title": "Tight Runtime Bounds for Static Unary Unbiased Evolutionary Algorithms  on Linear Functions",
    "abstract": "In a seminal paper in 2013, Witt showed that the (1+1) Evolutionary Algorithm with standard bit mutation needs time $(1+o(1))n \\ln n/p_1$ to find the optimum of any linear function, as long as the probability $p_1$ to flip exactly one bit is $\\Theta(1)$. In this paper we investigate how this result generalizes if standard bit mutation is replaced by an arbitrary unbiased mutation operator. This situation is notably different, since the stochastic domination argument used for the lower bound by Witt no longer holds. In particular, starting closer to the optimum is not necessarily an advantage, and OneMax is no longer the easiest function for arbitrary starting position. Nevertheless, we show that Witt's result carries over if $p_1$ is not too small and if the number of flipped bits has bounded expectation~$\\mu$. Notably, this includes some of the heavy-tail mutation operators used in fast genetic algorithms, but not all of them. We also give examples showing that algorithms with unbounded $\\mu$ have qualitatively different trajectories close to the optimum. ",
    "url": "https://arxiv.org/abs/2302.12338",
    "authors": [
      "Carola Doerr",
      "Duri Andrea Janett",
      "Johannes Lengler"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.12351",
    "title": "On the Hardness of Robustness Transfer: A Perspective from Rademacher  Complexity over Symmetric Difference Hypothesis Space",
    "abstract": "Recent studies demonstrated that the adversarially robust learning under $\\ell_\\infty$ attack is harder to generalize to different domains than standard domain adaptation. How to transfer robustness across different domains has been a key question in domain adaptation field. To investigate the fundamental difficulty behind adversarially robust domain adaptation (or robustness transfer), we propose to analyze a key complexity measure that controls the cross-domain generalization: the adversarial Rademacher complexity over {\\em symmetric difference hypothesis space} $\\mathcal{H} \\Delta \\mathcal{H}$. For linear models, we show that adversarial version of this complexity is always greater than the non-adversarial one, which reveals the intrinsic hardness of adversarially robust domain adaptation. We also establish upper bounds on this complexity measure. Then we extend them to the ReLU neural network class by upper bounding the adversarial Rademacher complexity in the binary classification setting. Finally, even though the robust domain adaptation is provably harder, we do find positive relation between robust learning and standard domain adaptation. We explain \\emph{how adversarial training helps domain adaptation in terms of standard risk}. We believe our results initiate the study of the generalization theory of adversarially robust domain adaptation, and could shed lights on distributed adversarially robust learning from heterogeneous sources, e.g., federated learning scenario. ",
    "url": "https://arxiv.org/abs/2302.12351",
    "authors": [
      "Yuyang Deng",
      "Nidham Gazagnadou",
      "Junyuan Hong",
      "Mehrdad Mahdavi",
      "Lingjuan Lyu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12357",
    "title": "Auto-HeG: Automated Graph Neural Network on Heterophilic Graphs",
    "abstract": "Graph neural architecture search (NAS) has gained popularity in automatically designing powerful graph neural networks (GNNs) with relieving human efforts. However, existing graph NAS methods mainly work under the homophily assumption and overlook another important graph property, i.e., heterophily, which exists widely in various real-world applications. To date, automated heterophilic graph learning with NAS is still a research blank to be filled in. Due to the complexity and variety of heterophilic graphs, the critical challenge of heterophilic graph NAS mainly lies in developing the heterophily-specific search space and strategy. Therefore, in this paper, we propose a novel automated graph neural network on heterophilic graphs, namely Auto-HeG, to automatically build heterophilic GNN models with expressive learning abilities. Specifically, Auto-HeG incorporates heterophily into all stages of automatic heterophilic graph learning, including search space design, supernet training, and architecture selection. Through the diverse message-passing scheme with joint micro-level and macro-level designs, we first build a comprehensive heterophilic GNN search space, enabling Auto-HeG to integrate complex and various heterophily of graphs. With a progressive supernet training strategy, we dynamically shrink the initial search space according to layer-wise variation of heterophily, resulting in a compact and efficient supernet. Taking a heterophily-aware distance criterion as the guidance, we conduct heterophilic architecture selection in the leave-one-out pattern, so that specialized and expressive heterophilic GNN architectures can be derived. Extensive experiments illustrate the superiority of Auto-HeG in developing excellent heterophilic GNNs to human-designed models and graph NAS models. ",
    "url": "https://arxiv.org/abs/2302.12357",
    "authors": [
      "Xin Zheng",
      "Miao Zhang",
      "Chunyang Chen",
      "Qin Zhang",
      "Chuan Zhou",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.12366",
    "title": "Less is More: Data Pruning for Faster Adversarial Training",
    "abstract": "Deep neural networks (DNNs) are sensitive to adversarial examples, resulting in fragile and unreliable performance in the real world. Although adversarial training (AT) is currently one of the most effective methodologies to robustify DNNs, it is computationally very expensive (e.g., 5-10X costlier than standard training). To address this challenge, existing approaches focus on single-step AT, referred to as Fast AT, reducing the overhead of adversarial example generation. Unfortunately, these approaches are known to fail against stronger adversaries. To make AT computationally efficient without compromising robustness, this paper takes a different view of the efficient AT problem. Specifically, we propose to minimize redundancies at the data level by leveraging data pruning. Extensive experiments demonstrate that the data pruning based AT can achieve similar or superior robust (and clean) accuracy as its unpruned counterparts while being significantly faster. For instance, proposed strategies accelerate CIFAR-10 training up to 3.44X and CIFAR-100 training to 2.02X. Additionally, the data pruning methods can readily be reconciled with existing adversarial acceleration tricks to obtain the striking speed-ups of 5.66X and 5.12X on CIFAR-10, 3.67X and 3.07X on CIFAR-100 with TRADES and MART, respectively. ",
    "url": "https://arxiv.org/abs/2302.12366",
    "authors": [
      "Yize Li",
      "Pu Zhao",
      "Xue Lin",
      "Bhavya Kailkhura",
      "Ryan Goldh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.12378",
    "title": "Cosmic Microwave Background Recovery: A Graph-Based Bayesian  Convolutional Network Approach",
    "abstract": "The cosmic microwave background (CMB) is a significant source of knowledge about the origin and evolution of our universe. However, observations of the CMB are contaminated by foreground emissions, obscuring the CMB signal and reducing its efficacy in constraining cosmological parameters. We employ deep learning as a data-driven approach to CMB cleaning from multi-frequency full-sky maps. In particular, we develop a graph-based Bayesian convolutional neural network based on the U-Net architecture that predicts cleaned CMB with pixel-wise uncertainty estimates. We demonstrate the potential of this technique on realistic simulated data based on the Planck mission. We show that our model accurately recovers the cleaned CMB sky map and resulting angular power spectrum while identifying regions of uncertainty. Finally, we discuss the current challenges and the path forward for deploying our model for CMB recovery on real observations. ",
    "url": "https://arxiv.org/abs/2302.12378",
    "authors": [
      "Jadie Adams",
      "Steven Lu",
      "Krzysztof M. Gorski",
      "Graca Rocha",
      "Kiri L. Wagstaff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ]
  },
  {
    "id": "arXiv:2302.12383",
    "title": "Generalization Analysis for Contrastive Representation Learning",
    "abstract": "Recently, contrastive learning has found impressive success in advancing the state of the art in solving various machine learning tasks. However, the existing generalization analysis is very limited or even not meaningful. In particular, the existing generalization error bounds depend linearly on the number $k$ of negative examples while it was widely shown in practice that choosing a large $k$ is necessary to guarantee good generalization of contrastive learning in downstream tasks. In this paper, we establish novel generalization bounds for contrastive learning which do not depend on $k$, up to logarithmic terms. Our analysis uses structural results on empirical covering numbers and Rademacher complexities to exploit the Lipschitz continuity of loss functions. For self-bounding Lipschitz loss functions, we further improve our results by developing optimistic bounds which imply fast rates in a low noise condition. We apply our results to learning with both linear representation and nonlinear representation by deep neural networks, for both of which we derive Rademacher complexity bounds to get improved generalization bounds. ",
    "url": "https://arxiv.org/abs/2302.12383",
    "authors": [
      "Yunwen Lei",
      "Tianbao Yang",
      "Yiming Ying",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12388",
    "title": "TrafFormer: A Transformer Model for Prediction Long-term Traffic",
    "abstract": "Traffic prediction is a flourishing research field due to its importance in human mobility in the urban space. Despite this, existing studies only focus on short-term prediction of up to few hours in advance, with most being up to one hour only. Long-term traffic prediction can enable more comprehensive, informed, and proactive measures against traffic congestion and is therefore an important task to explore. In this paper, we explore the task of long-term traffic prediction; where we predict traffic up to 24 hours in advance. We note the weaknesses of existing models--which are based on recurrent structures--for long-term traffic prediction and propose a modified Transformer model ``TrafFormer\". Experiments comparing our model with existing hybrid neural network models show the superiority of our model. ",
    "url": "https://arxiv.org/abs/2302.12388",
    "authors": [
      "David Alexander Tedjopurnomo",
      "Farhana M. Choudhury",
      "A. K. Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12403",
    "title": "Prioritized Trace Selection: Towards High-Performance DRL-based Network  Controllers",
    "abstract": "Deep Reinforcement Learning (DRL) based controllers offer high performance in a variety of network environments. However, simulator-based training of DRL controllers using highly skewed datasets of real-world traces often results in poor performance in the wild. In this paper, we put forward a generalizable solution for training high-performance DRL controllers in simulators -- Prioritized Trace Selection (PTS). PTS employs an automated three-stage process. First, we identify critical features that determine trace behavior. Second, we classify the traces into clusters. Finally, we dynamically identify and prioritize the salient clusters during training. PTS does not require any changes to the DRL workflow. It can work across both on-policy and off-policy DRL algorithms. We use Adaptive Bit Rate selection and Congestion Control as representative applications to show that PTS offers better performance in simulation and real-world, across multiple controllers and DRL algorithms. Our novel ABR controller, Gelato, trained with PTS outperforms state-of-the-art controllers on the real-world live-streaming platform, Puffer, reducing stalls by 59% and significantly improving average video quality. ",
    "url": "https://arxiv.org/abs/2302.12403",
    "authors": [
      "Sagar Patel",
      "Junyang Zhang",
      "Sangeetha Abdu Jyothi",
      "Nina Narodytska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.12407",
    "title": "HyperAttack: Multi-Gradient-Guided White-box Adversarial Structure  Attack of Hypergraph Neural Networks",
    "abstract": "Hypergraph neural networks (HGNN) have shown superior performance in various deep learning tasks, leveraging the high-order representation ability to formulate complex correlations among data by connecting two or more nodes through hyperedge modeling. Despite the well-studied adversarial attacks on Graph Neural Networks (GNN), there is few study on adversarial attacks against HGNN, which leads to a threat to the safety of HGNN applications. In this paper, we introduce HyperAttack, the first white-box adversarial attack framework against hypergraph neural networks. HyperAttack conducts a white-box structure attack by perturbing hyperedge link status towards the target node with the guidance of both gradients and integrated gradients. We evaluate HyperAttack on the widely-used Cora and PubMed datasets and three hypergraph neural networks with typical hypergraph modeling techniques. Compared to state-of-the-art white-box structural attack methods for GNN, HyperAttack achieves a 10-20X improvement in time efficiency while also increasing attack success rates by 1.3%-3.7%. The results show that HyperAttack can achieve efficient adversarial attacks that balance effectiveness and time costs. ",
    "url": "https://arxiv.org/abs/2302.12407",
    "authors": [
      "Chao Hu",
      "Ruishi Yu",
      "Binqi Zeng",
      "Yu Zhan",
      "Ying Fu",
      "Quan Zhang",
      "Rongkai Liu",
      "Heyuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.12416",
    "title": "A Convolutional Vision Transformer for Semantic Segmentation of  Side-Scan Sonar Data",
    "abstract": "Distinguishing among different marine benthic habitat characteristics is of key importance in a wide set of seabed operations ranging from installations of oil rigs to laying networks of cables and monitoring the impact of humans on marine ecosystems. The Side-Scan Sonar (SSS) is a widely used imaging sensor in this regard. It produces high-resolution seafloor maps by logging the intensities of sound waves reflected back from the seafloor. In this work, we leverage these acoustic intensity maps to produce pixel-wise categorization of different seafloor types. We propose a novel architecture adapted from the Vision Transformer (ViT) in an encoder-decoder framework. Further, in doing so, the applicability of ViTs is evaluated on smaller datasets. To overcome the lack of CNN-like inductive biases, thereby making ViTs more conducive to applications in low data regimes, we propose a novel feature extraction module to replace the Multi-layer Perceptron (MLP) block within transformer layers and a novel module to extract multiscale patch embeddings. A lightweight decoder is also proposed to complement this design in order to further boost multiscale feature extraction. With the modified architecture, we achieve state-of-the-art results and also meet real-time computational requirements. We make our code available at ~\\url{https://github.com/hayatrajani/s3seg-vit ",
    "url": "https://arxiv.org/abs/2302.12416",
    "authors": [
      "Hayat Rajani",
      "Nuno Gracias",
      "Rafael Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12417",
    "title": "Emotion Prediction Oriented method with Multiple Supervisions for  Emotion-Cause Pair Extraction",
    "abstract": "Emotion-cause pair extraction (ECPE) task aims to extract all the pairs of emotions and their causes from an unannotated emotion text. The previous works usually extract the emotion-cause pairs from two perspectives of emotion and cause. However, emotion extraction is more crucial to the ECPE task than cause extraction. Motivated by this analysis, we propose an end-to-end emotion-cause extraction approach oriented toward emotion prediction (EPO-ECPE), aiming to fully exploit the potential of emotion prediction to enhance emotion-cause pair extraction. Considering the strong dependence between emotion prediction and emotion-cause pair extraction, we propose a synchronization mechanism to share their improvement in the training process. That is, the improvement of emotion prediction can facilitate the emotion-cause pair extraction, and then the results of emotion-cause pair extraction can also be used to improve the accuracy of emotion prediction simultaneously. For the emotion-cause pair extraction, we divide it into genuine pair supervision and fake pair supervision, where the genuine pair supervision learns from the pairs with more possibility to be emotion-cause pairs. In contrast, fake pair supervision learns from other pairs. In this way, the emotion-cause pairs can be extracted directly from the genuine pair, thereby reducing the difficulty of extraction. Experimental results show that our approach outperforms the 13 compared systems and achieves new state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2302.12417",
    "authors": [
      "Guimin Hu",
      "Yi Zhao",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12420",
    "title": "An Iterative Classification and Semantic Segmentation Network for Old  Landslide Detection Using High-Resolution Remote Sensing Images",
    "abstract": "Huge challenges exist for old landslide detection because their morphology features have been partially or strongly transformed over a long time and have little difference from their surrounding. Besides, small-sample problem also restrict in-depth learning. In this paper, an iterative classification and semantic segmentation network (ICSSN) is developed, which can greatly enhance both object-level and pixel-level classification performance by iteratively upgrading the feature extractor shared by two network. An object-level contrastive learning (OCL) strategy is employed in the object classification sub-network featuring a siamese network to realize the global features extraction, and a sub-object-level contrastive learning (SOCL) paradigm is designed in the semantic segmentation sub-network to efficiently extract salient features from boundaries of landslides. Moreover, an iterative training strategy is elaborated to fuse features in semantic space such that both object-level and pixel-level classification performance are improved. The proposed ICSSN is evaluated on the real landslide data set, and the experimental results show that ICSSN can greatly improve the classification and segmentation accuracy of old landslide detection. For the semantic segmentation task, compared to the baseline, the F1 score increases from 0.5054 to 0.5448, the mIoU improves from 0.6405 to 0.6610, the landslide IoU improved from 0.3381 to 0.3743, and the object-level detection accuracy of old landslides is enhanced from 0.55 to 0.9. For the object classification task, the F1 score increases from 0.8846 to 0.9230, and the accuracy score is up from 0.8375 to 0.8875. ",
    "url": "https://arxiv.org/abs/2302.12420",
    "authors": [
      "Zili Lu",
      "Yuexing Peng",
      "Wei Li",
      "Junchuan Yu",
      "Daqing Ge",
      "Wei Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12432",
    "title": "Graph Neural Networks with Learnable and Optimal Polynomial Bases",
    "abstract": "Polynomial filters, a kind of Graph Neural Networks, typically use a predetermined polynomial basis and learn the coefficients from the training data. It has been observed that the effectiveness of the model is highly dependent on the property of the polynomial basis. Consequently, two natural and fundamental questions arise: Can we learn a suitable polynomial basis from the training data? Can we determine the optimal polynomial basis for a given graph and node features? In this paper, we propose two spectral GNN models that provide positive answers to the questions posed above. First, inspired by Favard's Theorem, we propose the FavardGNN model, which learns a polynomial basis from the space of all possible orthonormal bases. Second, we examine the supposedly unsolvable definition of optimal polynomial basis from Wang & Zhang (2022) and propose a simple model, OptBasisGNN, which computes the optimal basis for a given graph structure and graph signal. Extensive experiments are conducted to demonstrate the effectiveness of our proposed models. ",
    "url": "https://arxiv.org/abs/2302.12432",
    "authors": [
      "Yuhe Guo",
      "Zhewei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12442",
    "title": "Effective Graph-Neural-Network based Models for Discovering Structural  Hole Spanners in Large-Scale and Diverse Networks",
    "abstract": "A Structural Hole Spanner (SHS) is a set of nodes in a network that act as a bridge among different otherwise disconnected communities. Numerous solutions have been proposed to discover SHSs that generally require high run time on large-scale networks. Another challenge is discovering SHSs across different types of networks for which the traditional one-model-fit-all approach fails to capture the inter-graph difference, particularly in the case of diverse networks. Therefore, there is an urgent need of developing effective solutions for discovering SHSs in large-scale and diverse networks. Inspired by the recent advancement of graph neural network approaches on various graph problems, we propose graph neural network-based models to discover SHS nodes in large scale networks and diverse networks. We transform the problem into a learning problem and propose an efficient model GraphSHS, that exploits both the network structure and node features to discover SHS nodes in large scale networks, endeavouring to lessen the computational cost while maintaining high accuracy. To effectively discover SHSs across diverse networks, we propose another model Meta-GraphSHS based on meta-learning that learns generalizable knowledge from diverse training graphs (instead of directly learning the model) and utilizes the learned knowledge to create a customized model to identify SHSs in each new graph. We theoretically show that the depth of the proposed graph neural network model should be at least $\\Omega(\\sqrt{n}/\\log n)$ to accurately calculate the SHSs discovery problem. We evaluate the performance of the proposed models through extensive experiments on synthetic and real-world datasets. Our experimental results show that GraphSHS discovers SHSs with high accuracy and is at least 167.1 times faster than the comparative methods on large-scale real-world datasets. ",
    "url": "https://arxiv.org/abs/2302.12442",
    "authors": [
      "Diksha Goel",
      "Hong Shen",
      "Hui Tian",
      "Mingyu Guo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.12443",
    "title": "CoSec-RPL: detection of copycat attacks in RPL based 6LoWPANs using  outlier analysis",
    "abstract": "The IPv6 routing protocol for low-power and lossy networks (RPL) is the standard routing protocol for IPv6 based low-power wireless personal area networks (6LoWPANs). In RPL protocol, DODAG information object (DIO) messages are used to disseminate routing information to other nodes in the network. A malicious node may eavesdrop DIO messages of its neighbor nodes and later replay the captured DIO many times with fixed intervals. In this paper, we present and investigate one of the severe attacks named as a non-spoofed copycat attack, a type of replay based DoS attack against RPL protocol. It is shown that the non-spoofed copycat attack increases the average end-to-end delay (AE2ED) and packet delivery ratio of the network. Thus, to address this problem, an intrusion detection system (IDS) named CoSec-RPL is proposed in this paper. The attack detection logic of CoSec-RPL is primarily based on the idea of outlier detection (OD). CoSec-RPL significantly mitigates the effects of the non-spoofed copycat attack on the network's performance. The effectiveness of the proposed IDS is compared with the standard RPL protocol. The experimental results indicate that CoSec-RPL detects and mitigates non-spoofed copycat attack efficiently in both static and mobile network scenarios without adding any significant overhead to the nodes. To the best of our knowledge, CoSec-RPL is the first RPL specific IDS that utilizes OD for intrusion detection in 6LoWPANs. ",
    "url": "https://arxiv.org/abs/2302.12443",
    "authors": [
      "Abhishek Verma",
      "Virender Ranga"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.12449",
    "title": "SGL-PT: A Strong Graph Learner with Graph Prompt Tuning",
    "abstract": "Recently, much exertion has been paid to design graph self-supervised methods to obtain generalized pre-trained models, and adapt pre-trained models onto downstream tasks through fine-tuning. However, there exists an inherent gap between pretext and downstream graph tasks, which insufficiently exerts the ability of pre-trained models and even leads to negative transfer. Meanwhile, prompt tuning has seen emerging success in natural language processing by aligning pre-training and fine-tuning with consistent training objectives. In this paper, we identify the challenges for graph prompt tuning: The first is the lack of a strong and universal pre-training task across sundry pre-training methods in graph domain. The second challenge lies in the difficulty of designing a consistent training objective for both pre-training and downstream tasks. To overcome above obstacles, we propose a novel framework named SGL-PT which follows the learning strategy ``Pre-train, Prompt, and Predict''. Specifically, we raise a strong and universal pre-training task coined as SGL that acquires the complementary merits of generative and contrastive self-supervised graph learning. And aiming for graph classification task, we unify pre-training and fine-tuning by designing a novel verbalizer-free prompting function, which reformulates the downstream task in a similar format as pretext task. Empirical results show that our method surpasses other baselines under unsupervised setting, and our prompt tuning method can greatly facilitate models on biological datasets over fine-tuning methods. ",
    "url": "https://arxiv.org/abs/2302.12449",
    "authors": [
      "Yun Zhu",
      "Jianhao Guo",
      "Siliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.12452",
    "title": "Machine Learning Based Intrusion Detection Systems for IoT Applications",
    "abstract": "Internet of Things (IoT) and its applications are the most popular research areas at present. The characteristics of IoT on one side make it easily applicable to real-life applications, whereas on the other side expose it to cyber threats. Denial of Service (DoS) is one of the most catastrophic attacks against IoT. In this paper, we investigate the prospects of using machine learning classification algorithms for securing IoT against DoS attacks. A comprehensive study is carried on the classifiers which can advance the development of anomaly-based intrusion detection systems (IDSs). Performance assessment of classifiers is done in terms of prominent metrics and validation methods. Popular datasets CIDDS-001, UNSW-NB15, and NSL-KDD are used for benchmarking classifiers. Friedman and Nemenyi tests are employed to analyze the significant differences among classifiers statistically. In addition, Raspberry Pi is used to evaluate the response time of classifiers on IoT specific hardware. We also discuss a methodology for selecting the best classifier as per application requirements. The main goals of this study are to motivate IoT security researchers for developing IDSs using ensemble learning, and suggesting appropriate methods for statistical assessment of classifier's performance. ",
    "url": "https://arxiv.org/abs/2302.12452",
    "authors": [
      "Abhishek Verma",
      "Virender Ranga"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.12453",
    "title": "Inducing Neural Collapse in Deep Long-tailed Learning",
    "abstract": "Although deep neural networks achieve tremendous success on various classification tasks, the generalization ability drops sheer when training datasets exhibit long-tailed distributions. One of the reasons is that the learned representations (i.e. features) from the imbalanced datasets are less effective than those from balanced datasets. Specifically, the learned representation under class-balanced distribution will present the Neural Collapse (NC) phenomena. NC indicates the features from the same category are close to each other and from different categories are maximally distant, showing an optimal linear separable state of classification. However, the pattern differs on imbalanced datasets and is partially responsible for the reduced performance of the model. In this work, we propose two explicit feature regularization terms to learn high-quality representation for class-imbalanced data. With the proposed regularization, NC phenomena will appear under the class-imbalanced distribution, and the generalization ability can be significantly improved. Our method is easily implemented, highly effective, and can be plugged into most existing methods. The extensive experimental results on widely-used benchmarks show the effectiveness of our method ",
    "url": "https://arxiv.org/abs/2302.12453",
    "authors": [
      "Xuantong Liu",
      "Jianfeng Zhang",
      "Tianyang Hu",
      "He Cao",
      "Lujia Pan",
      "Yuan Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12464",
    "title": "RGI: robust GAN-inversion for mask-free image inpainting and  unsupervised pixel-wise anomaly detection",
    "abstract": "Generative adversarial networks (GANs), trained on a large-scale image dataset, can be a good approximator of the natural image manifold. GAN-inversion, using a pre-trained generator as a deep generative prior, is a promising tool for image restoration under corruptions. However, the performance of GAN-inversion can be limited by a lack of robustness to unknown gross corruptions, i.e., the restored image might easily deviate from the ground truth. In this paper, we propose a Robust GAN-inversion (RGI) method with a provable robustness guarantee to achieve image restoration under unknown \\textit{gross} corruptions, where a small fraction of pixels are completely corrupted. Under mild assumptions, we show that the restored image and the identified corrupted region mask converge asymptotically to the ground truth. Moreover, we extend RGI to Relaxed-RGI (R-RGI) for generator fine-tuning to mitigate the gap between the GAN learned manifold and the true image manifold while avoiding trivial overfitting to the corrupted input image, which further improves the image restoration and corrupted region mask identification performance. The proposed RGI/R-RGI method unifies two important applications with state-of-the-art (SOTA) performance: (i) mask-free semantic inpainting, where the corruptions are unknown missing regions, the restored background can be used to restore the missing content; (ii) unsupervised pixel-wise anomaly detection, where the corruptions are unknown anomalous regions, the retrieved mask can be used as the anomalous region's segmentation mask. ",
    "url": "https://arxiv.org/abs/2302.12464",
    "authors": [
      "Shancong Mou",
      "Xiaoyi Gu",
      "Meng Cao",
      "Haoping Bai",
      "Ping Huang",
      "Jiulong Shan",
      "Jianjun Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12465",
    "title": "PaGE-Link: Path-based Graph Neural Network Explanation for Heterogeneous  Link Prediction",
    "abstract": "Transparency and accountability have become major concerns for black-box machine learning (ML) models. Proper explanations for the model behavior increase model transparency and help researchers develop more accountable models. Graph neural networks (GNN) have recently shown superior performance in many graph ML problems than traditional methods, and explaining them has attracted increased interest. However, GNN explanation for link prediction (LP) is lacking in the literature. LP is an essential GNN task and corresponds to web applications like recommendation and sponsored search on web. Given existing GNN explanation methods only address node/graph-level tasks, we propose Path-based GNN Explanation for heterogeneous Link prediction (PaGE-Link) that generates explanations with connection interpretability, enjoys model scalability, and handles graph heterogeneity. Qualitatively, PaGE-Link can generate explanations as paths connecting a node pair, which naturally captures connections between the two nodes and easily transfer to human-interpretable explanations. Quantitatively, explanations generated by PaGE-Link improve AUC for recommendation on citation and user-item graphs by 9 - 35% and are chosen as better by 78.79% of responses in human evaluation. ",
    "url": "https://arxiv.org/abs/2302.12465",
    "authors": [
      "Shichang Zhang",
      "Jiani Zhang",
      "Xiang Song",
      "Soji Adeshina",
      "Da Zheng",
      "Christos Faloutsos",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.12480",
    "title": "Robust Weight Signatures: Gaining Robustness as Easy as Patching  Weights?",
    "abstract": "Given a robust model trained to be resilient to one or multiple types of distribution shifts (e.g., natural image corruptions), how is that \"robustness\" encoded in the model weights, and how easily can it be disentangled and/or \"zero-shot\" transferred to some other models? This paper empirically suggests a surprisingly simple answer: linearly - by straightforward model weight arithmetic! We start by drawing several key observations: (1)assuming that we train the same model architecture on both a clean dataset and its corrupted version, resultant weights mostly differ in shallow layers; (2)the weight difference after projection, which we call \"Robust Weight Signature\" (RWS), appears to be discriminative and indicative of different corruption types; (3)for the same corruption type, the RWSs obtained by one model architecture are highly consistent and transferable across different datasets. We propose a minimalistic model robustness \"patching\" framework that carries a model trained on clean data together with its pre-extracted RWSs. In this way, injecting certain robustness to the model is reduced to directly adding the corresponding RWS to its weight. We verify our proposed framework to be remarkably (1)lightweight. since RWSs concentrate on the shallowest few layers and we further show they can be painlessly quantized, storing an RWS is up to 13 x more compact than storing the full weight copy; (2)in-situ adjustable. RWSs can be appended as needed and later taken off to restore the intact clean model. We further demonstrate one can linearly re-scale the RWS to control the patched robustness strength; (3)composable. Multiple RWSs can be added simultaneously to patch more comprehensive robustness at once; and (4)transferable. Even when the clean model backbone is continually adapted or updated, RWSs remain as effective patches due to their outstanding cross-dataset transferability. ",
    "url": "https://arxiv.org/abs/2302.12480",
    "authors": [
      "Ruisi Cai",
      "Zhenyu Zhang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12493",
    "title": "SEO: Safety-Aware Energy Optimization Framework for Multi-Sensor Neural  Controllers at the Edge",
    "abstract": "Runtime energy management has become quintessential for multi-sensor autonomous systems at the edge for achieving high performance given the platform constraints. Typical for such systems, however, is to have their controllers designed with formal guarantees on safety that precede in priority such optimizations, which in turn limits their application in real settings. In this paper, we propose a novel energy optimization framework that is aware of the autonomous system's safety state, and leverages it to regulate the application of energy optimization methods so that the system's formal safety properties are preserved. In particular, through the formal characterization of a system's safety state as a dynamic processing deadline, the computing workloads of the underlying models can be adapted accordingly. For our experiments, we model two popular runtime energy optimization methods, offloading and gating, and simulate an autonomous driving system (ADS) use-case in the CARLA simulation environment with performance characterizations obtained from the standard Nvidia Drive PX2 ADS platform. Our results demonstrate that through a formal awareness of the perceived risks in the test case scenario, energy efficiency gains are still achieved (reaching 89.9%) while maintaining the desired safety properties. ",
    "url": "https://arxiv.org/abs/2302.12493",
    "authors": [
      "Mohanad Odema",
      "James Ferlez",
      "Yasser Shoukry",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12498",
    "title": "Scalable Unbalanced Sobolev Transport for Measures on a Graph",
    "abstract": "Optimal transport (OT) is a popular and powerful tool for comparing probability measures. However, OT suffers a few drawbacks: (i) input measures required to have the same mass, (ii) a high computational complexity, and (iii) indefiniteness which limits its applications on kernel-dependent algorithmic approaches. To tackle issues (ii)--(iii), Le et al. (2022) recently proposed Sobolev transport for measures on a graph having the same total mass by leveraging the graph structure over supports. In this work, we consider measures that may have different total mass and are supported on a graph metric space. To alleviate the disadvantages (i)--(iii) of OT, we propose a novel and scalable approach to extend Sobolev transport for this unbalanced setting where measures may have different total mass. We show that the proposed unbalanced Sobolev transport (UST) admits a closed-form formula for fast computation, and it is also negative definite. Additionally, we derive geometric structures for the UST and establish relations between our UST and other transport distances. We further exploit the negative definiteness to design positive definite kernels and evaluate them on various simulations to illustrate their fast computation and comparable performances against other transport baselines for unbalanced measures on a graph. ",
    "url": "https://arxiv.org/abs/2302.12498",
    "authors": [
      "Tam Le",
      "Truyen Nguyen",
      "Kenji Fukumizu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12505",
    "title": "Spatial Bias for Attention-free Non-local Neural Networks",
    "abstract": "In this paper, we introduce the spatial bias to learn global knowledge without self-attention in convolutional neural networks. Owing to the limited receptive field, conventional convolutional neural networks suffer from learning long-range dependencies. Non-local neural networks have struggled to learn global knowledge, but unavoidably have too heavy a network design due to the self-attention operation. Therefore, we propose a fast and lightweight spatial bias that efficiently encodes global knowledge without self-attention on convolutional neural networks. Spatial bias is stacked on the feature map and convolved together to adjust the spatial structure of the convolutional features. Therefore, we learn the global knowledge on the convolution layer directly with very few additional resources. Our method is very fast and lightweight due to the attention-free non-local method while improving the performance of neural networks considerably. Compared to non-local neural networks, the spatial bias use about 10 times fewer parameters while achieving comparable performance with 1.6 ~ 3.3 times more throughput on a very little budget. Furthermore, the spatial bias can be used with conventional non-local neural networks to further improve the performance of the backbone model. We show that the spatial bias achieves competitive performance that improves the classification accuracy by +0.79% and +1.5% on ImageNet-1K and cifar100 datasets. Additionally, we validate our method on the MS-COCO and ADE20K datasets for downstream tasks involving object detection and semantic segmentation. ",
    "url": "https://arxiv.org/abs/2302.12505",
    "authors": [
      "Junhyung Go",
      "Jongbin Ryu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.12510",
    "title": "DyBit: Dynamic Bit-Precision Numbers for Efficient Quantized Neural  Network Inference",
    "abstract": "To accelerate the inference of deep neural networks (DNNs), quantization with low-bitwidth numbers is actively researched. A prominent challenge is to quantize the DNN models into low-bitwidth numbers without significant accuracy degradation, especially at very low bitwidths (< 8 bits). This work targets an adaptive data representation with variable-length encoding called DyBit. DyBit can dynamically adjust the precision and range of separate bit-field to be adapted to the DNN weights/activations distribution. We also propose a hardware-aware quantization framework with a mixed-precision accelerator to trade-off the inference accuracy and speedup. Experimental results demonstrate that the inference accuracy via DyBit is 1.997% higher than the state-of-the-art at 4-bit quantization, and the proposed framework can achieve up to 8.1x speedup compared with the original model. ",
    "url": "https://arxiv.org/abs/2302.12510",
    "authors": [
      "Jiajun Zhou",
      "Jiajun Wu",
      "Yizhao Gao",
      "Yuhao Ding",
      "Chaofan Tao",
      "Boyu Li",
      "Fengbin Tu",
      "Kwang-Ting Cheng",
      "Hayden Kwok-Hay So",
      "Ngai Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12529",
    "title": "Time-aware Multiway Adaptive Fusion Network for Temporal Knowledge Graph  Question Answering",
    "abstract": "Knowledge graphs (KGs) have received increasing attention due to its wide applications on natural language processing. However, its use case on temporal question answering (QA) has not been well-explored. Most of existing methods are developed based on pre-trained language models, which might not be capable to learn \\emph{temporal-specific} presentations of entities in terms of temporal KGQA task. To alleviate this problem, we propose a novel \\textbf{T}ime-aware \\textbf{M}ultiway \\textbf{A}daptive (\\textbf{TMA}) fusion network. Inspired by the step-by-step reasoning behavior of humans. For each given question, TMA first extracts the relevant concepts from the KG, and then feeds them into a multiway adaptive module to produce a \\emph{temporal-specific} representation of the question. This representation can be incorporated with the pre-trained KG embedding to generate the final prediction. Empirical results verify that the proposed model achieves better performance than the state-of-the-art models in the benchmark dataset. Notably, the Hits@1 and Hits@10 results of TMA on the CronQuestions dataset's complex questions are absolutely improved by 24\\% and 10\\% compared to the best-performing baseline. Furthermore, we also show that TMA employing an adaptive fusion mechanism can provide interpretability by analyzing the proportion of information in question representations. ",
    "url": "https://arxiv.org/abs/2302.12529",
    "authors": [
      "Yonghao Liu",
      "Di Liang",
      "Fang Fang",
      "Sirui Wang",
      "Wei Wu",
      "Rui Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.12537",
    "title": "Why Target Networks Stabilise Temporal Difference Methods",
    "abstract": "Integral to recent successes in deep reinforcement learning has been a class of temporal difference methods that use infrequently updated target values for policy evaluation in a Markov Decision Process. Yet a complete theoretical explanation for the effectiveness of target networks remains elusive. In this work, we provide an analysis of this popular class of algorithms, to finally answer the question: `why do target networks stabilise TD learning'? To do so, we formalise the notion of a partially fitted policy evaluation method, which describes the use of target networks and bridges the gap between fitted methods and semigradient temporal difference algorithms. Using this framework we are able to uniquely characterise the so-called deadly triad - the use of TD updates with (nonlinear) function approximation and off-policy data - which often leads to nonconvergent algorithms. This insight leads us to conclude that the use of target networks can mitigate the effects of poor conditioning in the Jacobian of the TD update. Instead, we show that under mild regularity conditions and a well tuned target network update frequency, convergence can be guaranteed even in the extremely challenging off-policy sampling and nonlinear function approximation setting. ",
    "url": "https://arxiv.org/abs/2302.12537",
    "authors": [
      "Mattie Fellows",
      "Matthew J. A. Smith",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12538",
    "title": "UnbiasedNets: A Dataset Diversification Framework for Robustness Bias  Alleviation in Neural Networks",
    "abstract": "Performance of trained neural network (NN) models, in terms of testing accuracy, has improved remarkably over the past several years, especially with the advent of deep learning. However, even the most accurate NNs can be biased toward a specific output classification due to the inherent bias in the available training datasets, which may propagate to the real-world implementations. This paper deals with the robustness bias, i.e., the bias exhibited by the trained NN by having a significantly large robustness to noise for a certain output class, as compared to the remaining output classes. The bias is shown to result from imbalanced datasets, i.e., the datasets where all output classes are not equally represented. Towards this, we propose the UnbiasedNets framework, which leverages K-means clustering and the NN's noise tolerance to diversify the given training dataset, even from relatively smaller datasets. This generates balanced datasets and reduces the bias within the datasets themselves. To the best of our knowledge, this is the first framework catering to the robustness bias problem in NNs. We use real-world datasets to demonstrate the efficacy of the UnbiasedNets for data diversification, in case of both binary and multi-label classifiers. The results are compared to well-known tools aimed at generating balanced datasets, and illustrate how existing works have limited success while addressing the robustness bias. In contrast, UnbiasedNets provides a notable improvement over existing works, while even reducing the robustness bias significantly in some cases, as observed by comparing the NNs trained on the diversified and original datasets. ",
    "url": "https://arxiv.org/abs/2302.12538",
    "authors": [
      "Mahum Naseer",
      "Bharath Srinivas Prabakaran",
      "Osman Hasan",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12545",
    "title": "Hybrid machine-learned homogenization: Bayesian data mining and  convolutional neural networks",
    "abstract": "Beyond the generally deployed features for microstructure property prediction this study aims to improve the machine learned prediction by developing novel feature descriptors. Therefore, Bayesian infused data mining is conducted to acquire samples containing characteristics inexplicable to the current feature set, and suitable feature descriptors to describe these characteristics are proposed. The iterative development of feature descriptors resulted in 37 novel features, being able to reduce the prediction error by roughly one third. To further improve the predictive model, convolutional neural networks (Conv Nets) are deployed to generate auxiliary features in a supervised machine learning manner. The Conv Nets were able to outperform the feature based approach. A key ingredient for that is a newly proposed data augmentation scheme and the development of so-called deep inception modules. A combination of the feature based approach and the convolutional neural network leads to a hybrid neural network: A parallel deployment of the both neural network archetypes in a single model achieved a relative rooted mean squared error below 1%, more than halving the error compared to prior models operating on the same data. The hybrid neural network was found powerful enough to be extended to predict variable material parameters, from a low to high phase contrast, while allowing for arbitrary microstructure geometry at the same time. ",
    "url": "https://arxiv.org/abs/2302.12545",
    "authors": [
      "Julian Li\u00dfner",
      "Felix Fritzen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12553",
    "title": "Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice  Polytopes",
    "abstract": "We prove that the set of functions representable by ReLU neural networks with integer weights strictly increases with the network depth while allowing arbitrary width. More precisely, we show that $\\lceil\\log_2(n)\\rceil$ hidden layers are indeed necessary to compute the maximum of $n$ numbers, matching known upper bounds. Our results are based on the known duality between neural networks and Newton polytopes via tropical geometry. The integrality assumption implies that these Newton polytopes are lattice polytopes. Then, our depth lower bounds follow from a parity argument on the normalized volume of faces of such polytopes. ",
    "url": "https://arxiv.org/abs/2302.12553",
    "authors": [
      "Christian Haase",
      "Christoph Hertrich",
      "Georg Loho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12580",
    "title": "Membership Inference Attacks against Synthetic Data through Overfitting  Detection",
    "abstract": "Data is the foundation of most science. Unfortunately, sharing data can be obstructed by the risk of violating data privacy, impeding research in fields like healthcare. Synthetic data is a potential solution. It aims to generate data that has the same distribution as the original data, but that does not disclose information about individuals. Membership Inference Attacks (MIAs) are a common privacy attack, in which the attacker attempts to determine whether a particular real sample was used for training of the model. Previous works that propose MIAs against generative models either display low performance -- giving the false impression that data is highly private -- or need to assume access to internal generative model parameters -- a relatively low-risk scenario, as the data publisher often only releases synthetic data, not the model. In this work we argue for a realistic MIA setting that assumes the attacker has some knowledge of the underlying data distribution. We propose DOMIAS, a density-based MIA model that aims to infer membership by targeting local overfitting of the generative model. Experimentally we show that DOMIAS is significantly more successful at MIA than previous work, especially at attacking uncommon samples. The latter is disconcerting since these samples may correspond to underrepresented groups. We also demonstrate how DOMIAS' MIA performance score provides an interpretable metric for privacy, giving data publishers a new tool for achieving the desired privacy-utility trade-off in their synthetic data. ",
    "url": "https://arxiv.org/abs/2302.12580",
    "authors": [
      "Boris van Breugel",
      "Hao Sun",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.12584",
    "title": "VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio  Features for Argument Mining",
    "abstract": "In this paper, we describe VivesDebate-Speech, a corpus of spoken argumentation created to leverage audio features for argument mining tasks. The creation of this corpus represents an important contribution to the intersection of speech processing and argument mining communities, and one of the most complete publicly available resources in this topic. Moreover, we have performed a set of first-of-their-kind experiments which show an improvement when integrating audio features into the argument mining pipeline. The provided results can be used as a baseline for future research. ",
    "url": "https://arxiv.org/abs/2302.12584",
    "authors": [
      "Ramon Ruiz-Dolz",
      "Javier Iranzo-S\u00e1nchez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.12589",
    "title": "Revisiting Modality Imbalance In Multimodal Pedestrian Detection",
    "abstract": "Multimodal learning, particularly for pedestrian detection, has recently received emphasis due to its capability to function equally well in several critical autonomous driving scenarios such as low-light, night-time, and adverse weather conditions. However, in most cases, the training distribution largely emphasizes the contribution of one specific input that makes the network biased towards one modality. Hence, the generalization of such models becomes a significant problem where the non-dominant input modality during training could be contributing more to the course of inference. Here, we introduce a novel training setup with regularizer in the multimodal architecture to resolve the problem of this disparity between the modalities. Specifically, our regularizer term helps to make the feature fusion method more robust by considering both the feature extractors equivalently important during the training to extract the multimodal distribution which is referred to as removing the imbalance problem. Furthermore, our decoupling concept of output stream helps the detection task by sharing the spatial sensitive information mutually. Extensive experiments of the proposed method on KAIST and UTokyo datasets shows improvement of the respective state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2302.12589",
    "authors": [
      "Arindam Das",
      "Sudip Das",
      "Ganesh Sistu",
      "Jonathan Horgan",
      "Ujjwal Bhattacharya",
      "Edward Jones",
      "Martin Glavin",
      "Ciar\u00e1n Eising"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12592",
    "title": "Securing IoT Communication using Physical Sensor Data -- Graph Layer  Security with Federated Multi-Agent Deep Reinforcement Learning",
    "abstract": "Internet-of-Things (IoT) devices are often used to transmit physical sensor data over digital wireless channels. Traditional Physical Layer Security (PLS)-based cryptography approaches rely on accurate channel estimation and information exchange for key generation, which irrevocably ties key quality with digital channel estimation quality. Recently, we proposed a new concept called Graph Layer Security (GLS), where digital keys are derived from physical sensor readings. The sensor readings between legitimate users are correlated through a common background infrastructure environment (e.g., a common water distribution network or electric grid). The challenge for GLS has been how to achieve distributed key generation. This paper presents a Federated multi-agent Deep reinforcement learning-assisted Distributed Key generation scheme (FD2K), which fully exploits the common features of physical dynamics to establish secret key between legitimate users. We present for the first time initial experimental results of GLS with federated learning, achieving considerable security performance in terms of key agreement rate (KAR), and key randomness. ",
    "url": "https://arxiv.org/abs/2302.12592",
    "authors": [
      "Liang Wang",
      "Zhuangkun Wei",
      "Weisi Guo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12597",
    "title": "Active Velocity Estimation using Light Curtains via Self-Supervised  Multi-Armed Bandits",
    "abstract": "To navigate in an environment safely and autonomously, robots must accurately estimate where obstacles are and how they move. Instead of using expensive traditional 3D sensors, we explore the use of a much cheaper, faster, and higher resolution alternative: programmable light curtains. Light curtains are a controllable depth sensor that sense only along a surface that the user selects. We adapt a probabilistic method based on particle filters and occupancy grids to explicitly estimate the position and velocity of 3D points in the scene using partial measurements made by light curtains. The central challenge is to decide where to place the light curtain to accurately perform this task. We propose multiple curtain placement strategies guided by maximizing information gain and verifying predicted object locations. Then, we combine these strategies using an online learning framework. We propose a novel self-supervised reward function that evaluates the accuracy of current velocity estimates using future light curtain placements. We use a multi-armed bandit framework to intelligently switch between placement policies in real time, outperforming fixed policies. We develop a full-stack navigation system that uses position and velocity estimates from light curtains for downstream tasks such as localization, mapping, path-planning, and obstacle avoidance. This work paves the way for controllable light curtains to accurately, efficiently, and purposefully perceive and navigate complex and dynamic environments. Project website: https://siddancha.github.io/ ",
    "url": "https://arxiv.org/abs/2302.12597",
    "authors": [
      "Siddharth Ancha",
      "Gaurav Pathak",
      "Ji Zhang",
      "Srinivasa Narasimhan",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12598",
    "title": "Dynamic Graph Convolution Network with Spatio-Temporal Attention Fusion  for Traffic Flow Prediction",
    "abstract": "Accurate and real-time traffic state prediction is of great practical importance for urban traffic control and web mapping services (e.g. Google Maps). With the support of massive data, deep learning methods have shown their powerful capability in capturing the complex spatio-temporal patterns of road networks. However, existing approaches use independent components to model temporal and spatial dependencies and thus ignore the heterogeneous characteristics of traffic flow that vary with time and space. In this paper, we propose a novel dynamic graph convolution network with spatio-temporal attention fusion. The method not only captures local spatio-temporal information that changes over time, but also comprehensively models long-distance and multi-scale spatio-temporal patterns based on the fusion mechanism of temporal and spatial attention. This design idea can greatly improve the spatio-temporal perception of the model. We conduct extensive experiments in 4 real-world datasets to demonstrate that our model achieves state-of-the-art performance compared to 22 baseline models. ",
    "url": "https://arxiv.org/abs/2302.12598",
    "authors": [
      "Xunlian Luo",
      "Chunjiang Zhu",
      "Detian Zhang",
      "Qing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12600",
    "title": "EvoTorch: Scalable Evolutionary Computation in Python",
    "abstract": "Evolutionary computation is an important component within various fields such as artificial intelligence research, reinforcement learning, robotics, industrial automation and/or optimization, engineering design, etc. Considering the increasing computational demands and the dimensionalities of modern optimization problems, the requirement for scalable, re-usable, and practical evolutionary algorithm implementations has been growing. To address this requirement, we present EvoTorch: an evolutionary computation library designed to work with high-dimensional optimization problems, with GPU support and with high parallelization capabilities. EvoTorch is based on and seamlessly works with the PyTorch library, and therefore, allows the users to define their optimization problems using a well-known API. ",
    "url": "https://arxiv.org/abs/2302.12600",
    "authors": [
      "Nihat Engin Toklu",
      "Timothy Atkinson",
      "Vojt\u011bch Micka",
      "Pawe\u0142 Liskowski",
      "Rupesh Kumar Srivastava"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12604",
    "title": "Neural Laplace Control for Continuous-time Delayed Systems",
    "abstract": "Many real-world offline reinforcement learning (RL) problems involve continuous-time environments with delays. Such environments are characterized by two distinctive features: firstly, the state x(t) is observed at irregular time intervals, and secondly, the current action a(t) only affects the future state x(t + g) with an unknown delay g > 0. A prime example of such an environment is satellite control where the communication link between earth and a satellite causes irregular observations and delays. Existing offline RL algorithms have achieved success in environments with irregularly observed states in time or known delays. However, environments involving both irregular observations in time and unknown delays remains an open and challenging problem. To this end, we propose Neural Laplace Control, a continuous-time model-based offline RL method that combines a Neural Laplace dynamics model with a model predictive control (MPC) planner--and is able to learn from an offline dataset sampled with irregular time intervals from an environment that has a inherent unknown constant delay. We show experimentally on continuous-time delayed environments it is able to achieve near expert policy performance. ",
    "url": "https://arxiv.org/abs/2302.12604",
    "authors": [
      "Samuel Holt",
      "Alihan H\u00fcy\u00fck",
      "Zhaozhi Qian",
      "Hao Sun",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12636",
    "title": "Streamlining Multimodal Data Fusion in Wireless Communication and Sensor  Networks",
    "abstract": "This paper presents a novel approach for multimodal data fusion based on the Vector-Quantized Variational Autoencoder (VQVAE) architecture. The proposed method is simple yet effective in achieving excellent reconstruction performance on paired MNIST-SVHN data and WiFi spectrogram data. Additionally, the multimodal VQVAE model is extended to the 5G communication scenario, where an end-to-end Channel State Information (CSI) feedback system is implemented to compress data transmitted between the base-station (eNodeB) and User Equipment (UE), without significant loss of performance. The proposed model learns a discriminative compressed feature space for various types of input data (CSI, spectrograms, natural images, etc), making it a suitable solution for applications with limited computational resources. ",
    "url": "https://arxiv.org/abs/2302.12636",
    "authors": [
      "Mohammud J. Bocus",
      "Xiaoyang Wang",
      "Robert. J. Piechocki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.12664",
    "title": "Globally Optimal Resource Allocation Design for IRS-Assisted Multiuser  Networks with Discrete Phase Shifts",
    "abstract": "Intelligent reflecting surfaces (IRSs) are envisioned as a low-cost solution to achieve high spectral and energy efficiency in future communication systems due to their ability to customize wireless propagation environments. Although resource allocation design for IRS-assisted multiuser wireless communication systems has been exhaustively investigated in the literature, the optimal design and performance of such systems are still not well understood. To fill this gap, in this paper, we study optimal resource allocation for IRS-assisted multiuser multiple-input single-output (MISO) systems. In particular, we jointly optimize the beamforming at the base station (BS) and the discrete IRS phase shifts to minimize the total transmit power. For attaining the globally optimal solution of the formulated non-convex combinatorial optimization problem, we develop a resource allocation algorithm with guaranteed convergence based on Schur's complement and the generalized Bender's decomposition. Our numerical results reveal that the proposed algorithm can significantly reduce the BS transmit power compared to the state-of-the-art suboptimal alternating optimization-based approach, especially for moderate-to-large numbers of IRS elements. ",
    "url": "https://arxiv.org/abs/2302.12664",
    "authors": [
      "Yifei Wu",
      "Dongfang Xu",
      "Derrick Wing Kwan Ng",
      "Robert Schober",
      "Wolfgang Gerstacker"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2302.12681",
    "title": "A New Scheduler for URLLC in 5G NR IIoT Networks with Spatio-Temporal  Traffic Correlations",
    "abstract": "This paper explores the issue of enabling Ultra-Reliable Low-Latency Communications (URLLC) in view of the spatio-temporal correlations that characterize real 5th generation (5G) Industrial Internet of Things (IIoT) networks. In this context, we consider a common Standalone Non-Public Network (SNPN) architecture as promoted by the 5G Alliance for Connected Industries and Automation (5G-ACIA), and propose a new variant of the 5G NR semi-persistent scheduler (SPS) to deal with uplink traffic correlations. A benchmark solution with a \"smart\" scheduler (SSPS) is compared with a more realistic adaptive approach (ASPS) that requires the scheduler to estimate some unknown network parameters. We demonstrate via simulations that the 1-ms latency requirement for URLLC is fulfilled in both solutions, at the expense of some complexity introduced in the management of the traffic. Finally, we provide numerical guidelines to dimension IIoT networks as a function of the use case, the number of machines in the factory, and considering both periodic and aperiodic traffic. ",
    "url": "https://arxiv.org/abs/2302.12681",
    "authors": [
      "Sara Cavallero",
      "Nicole Sarcone Grande",
      "Francesco Pase",
      "Marco Giordani",
      "Joseph Eichinger",
      "Roberto Verdone",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2302.12685",
    "title": "Active Membership Inference Attack under Local Differential Privacy in  Federated Learning",
    "abstract": "Federated learning (FL) was originally regarded as a framework for collaborative learning among clients with data privacy protection through a coordinating server. In this paper, we propose a new active membership inference (AMI) attack carried out by a dishonest server in FL. In AMI attacks, the server crafts and embeds malicious parameters into global models to effectively infer whether a target data sample is included in a client's private training data or not. By exploiting the correlation among data features through a non-linear decision boundary, AMI attacks with a certified guarantee of success can achieve severely high success rates under rigorous local differential privacy (LDP) protection; thereby exposing clients' training data to significant privacy risk. Theoretical and experimental results on several benchmark datasets show that adding sufficient privacy-preserving noise to prevent our attack would significantly damage FL's model utility. ",
    "url": "https://arxiv.org/abs/2302.12685",
    "authors": [
      "Truc Nguyen",
      "Phung Lai",
      "Khang Tran",
      "NhatHai Phan",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.12692",
    "title": "Boosting Transformers and Language Models for Clinical Prediction in  Immunotherapy",
    "abstract": "Clinical prediction is an essential task in the healthcare industry. However, the recent success of transformers, on which large language models are built, has not been extended to this domain. In this research, we explore the use of transformers and language models in prognostic prediction for immunotherapy using real-world patients' clinical data and molecular profiles. This paper investigates the potential of transformers to improve clinical prediction compared to conventional machine learning approaches and addresses the challenge of few-shot learning in predicting rare disease areas. The study benchmarks the efficacy of baselines and language models on prognostic prediction across multiple cancer types and investigates the impact of different pretrained language models under few-shot regimes. The results demonstrate significant improvements in accuracy and highlight the potential of NLP in clinical research to improve early detection and intervention for different diseases. Anonymous codes are available at \\url{https://anonymous.4open.science/r/table2text-88ED}. ",
    "url": "https://arxiv.org/abs/2302.12692",
    "authors": [
      "Zekai Chen",
      "Mariann Micsinai Balan",
      "Kevin Brown"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.12716",
    "title": "Supervised Hierarchical Clustering using Graph Neural Networks for  Speaker Diarization",
    "abstract": "Conventional methods for speaker diarization involve windowing an audio file into short segments to extract speaker embeddings, followed by an unsupervised clustering of the embeddings. This multi-step approach generates speaker assignments for each segment. In this paper, we propose a novel Supervised HierArchical gRaph Clustering algorithm (SHARC) for speaker diarization where we introduce a hierarchical structure using Graph Neural Network (GNN) to perform supervised clustering. The supervision allows the model to update the representations and directly improve the clustering performance, thus enabling a single-step approach for diarization. In the proposed work, the input segment embeddings are treated as nodes of a graph with the edge weights corresponding to the similarity scores between the nodes. We also propose an approach to jointly update the embedding extractor and the GNN model to perform end-to-end speaker diarization (E2E-SHARC). During inference, the hierarchical clustering is performed using node densities and edge existence probabilities to merge the segments until convergence. In the diarization experiments, we illustrate that the proposed E2E-SHARC approach achieves 53% and 44% relative improvements over the baseline systems on benchmark datasets like AMI and Voxconverse, respectively. ",
    "url": "https://arxiv.org/abs/2302.12716",
    "authors": [
      "Prachi Singh",
      "Amrit Kaul",
      "Sriram Ganapathy"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.12744",
    "title": "Detection of anomalously emitting ships through deviations from  predicted TROPOMI NO2 retrievals",
    "abstract": "Starting from 2021, more demanding $\\text{NO}_\\text{x}$ emission restrictions were introduced for ships operating in the North and Baltic Sea waters. Since all methods currently used for ship compliance monitoring are financially and time demanding, it is important to prioritize the inspection of ships that have high chances of being non-compliant. The current state-of-the-art approach for a large-scale ship $\\text{NO}_\\text{2}$ estimation is a supervised machine learning-based segmentation of ship plumes on TROPOMI images. However, challenging data annotation and insufficiently complex ship emission proxy used for the validation limit the applicability of the model for ship compliance monitoring. In this study, we present a method for the automated selection of potentially non-compliant ships using a combination of machine learning models on TROPOMI/S5P satellite data. It is based on a proposed regression model predicting the amount of $\\text{NO}_\\text{2}$ that is expected to be produced by a ship with certain properties operating in the given atmospheric conditions. The model does not require manual labeling and is validated with TROPOMI data directly. The differences between the predicted and actual amount of produced $\\text{NO}_\\text{2}$ are integrated over different observations of the same ship in time and are used as a measure of the inspection worthiness of a ship. To assure the robustness of the results, we compare the obtained results with the results of the previously developed segmentation-based method. Ships that are also highly deviating in accordance with the segmentation method require further attention. If no other explanations can be found by checking the TROPOMI data, the respective ships are advised to be the candidates for inspection. ",
    "url": "https://arxiv.org/abs/2302.12744",
    "authors": [
      "Solomiia Kurchaba",
      "Jasper van Vliet",
      "Fons J. Verbeek",
      "Cor J. Veenman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2302.12758",
    "title": "Defending Against Backdoor Attacks by Layer-wise Feature Analysis",
    "abstract": "Training deep neural networks (DNNs) usually requires massive training data and computational resources. Users who cannot afford this may prefer to outsource training to a third party or resort to publicly available pre-trained models. Unfortunately, doing so facilitates a new training-time attack (i.e., backdoor attack) against DNNs. This attack aims to induce misclassification of input samples containing adversary-specified trigger patterns. In this paper, we first conduct a layer-wise feature analysis of poisoned and benign samples from the target class. We find out that the feature difference between benign and poisoned samples tends to be maximum at a critical layer, which is not always the one typically used in existing defenses, namely the layer before fully-connected layers. We also demonstrate how to locate this critical layer based on the behaviors of benign samples. We then propose a simple yet effective method to filter poisoned samples by analyzing the feature differences between suspicious and benign samples at the critical layer. We conduct extensive experiments on two benchmark datasets, which confirm the effectiveness of our defense. ",
    "url": "https://arxiv.org/abs/2302.12758",
    "authors": [
      "Najeeb Moharram Jebreel",
      "Josep Domingo-Ferrer",
      "Yiming Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12759",
    "title": "Modularity-based approach for tracking communities in dynamic social  networks",
    "abstract": "Community detection is a fundamental task in social network analysis. Online social networks have dramatically increased the volume and speed of interactions among users, enabling advanced analysis of these dynamics. Despite a growing interest in tracking the evolution of groups of users in real-world social networks, most community detection efforts focus on communities within static networks. Here, we describe a framework for tracking communities over time in a dynamic network, where a series of significant events is identified for each community. To this end, a modularity-based strategy is proposed to effectively detect and track dynamic communities. The potential of our framework is shown by conducting extensive experiments on synthetic networks containing embedded events. Results indicate that our framework outperforms other state-of-the-art methods. In addition, we briefly explore how the proposed approach can identify dynamic communities in a Twitter network composed of more than 60,000 users, which posted over 5 million tweets throughout 2020. The proposed framework can be applied to different social network and provides a valuable tool to understand the evolution of communities in dynamic social networks. ",
    "url": "https://arxiv.org/abs/2302.12759",
    "authors": [
      "Michele Mazza",
      "Guglielmo Cola",
      "Maurizio Tesconi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2302.12766",
    "title": "Language-Driven Representation Learning for Robotics",
    "abstract": "Recent work in visual representation learning for robotics demonstrates the viability of learning from large video datasets of humans performing everyday tasks. Leveraging methods such as masked autoencoding and contrastive learning, these representations exhibit strong transfer to policy learning for visuomotor control. But, robot learning encompasses a diverse set of problems beyond control including grasp affordance prediction, language-conditioned imitation learning, and intent scoring for human-robot collaboration, amongst others. First, we demonstrate that existing representations yield inconsistent results across these tasks: masked autoencoding approaches pick up on low-level spatial features at the cost of high-level semantics, while contrastive learning approaches capture the opposite. We then introduce Voltron, a framework for language-driven representation learning from human videos and associated captions. Voltron trades off language-conditioned visual reconstruction to learn low-level visual patterns, and visually-grounded language generation to encode high-level semantics. We also construct a new evaluation suite spanning five distinct robot learning problems $\\unicode{x2013}$ a unified platform for holistically evaluating visual representations for robotics. Through comprehensive, controlled experiments across all five problems, we find that Voltron's language-driven representations outperform the prior state-of-the-art, especially on targeted problems requiring higher-level features. ",
    "url": "https://arxiv.org/abs/2302.12766",
    "authors": [
      "Siddharth Karamcheti",
      "Suraj Nair",
      "Annie S. Chen",
      "Thomas Kollar",
      "Chelsea Finn",
      "Dorsa Sadigh",
      "Percy Liang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12780",
    "title": "Provably Efficient Neural Offline Reinforcement Learning via Perturbed  Rewards",
    "abstract": "We propose a novel offline reinforcement learning (RL) algorithm, namely Value Iteration with Perturbed Rewards (VIPeR) which amalgamates the randomized value function idea with the pessimism principle. Most current offline RL algorithms explicitly construct statistical confidence regions to obtain pessimism via lower confidence bounds (LCB), which cannot easily scale to complex problems where a neural network is used to estimate the value functions. Instead, VIPeR implicitly obtains pessimism by simply perturbing the offline data multiple times with carefully-designed i.i.d Gaussian noises to learn an ensemble of estimated state-action values and acting greedily to the minimum of the ensemble. The estimated state-action values are obtained by fitting a parametric model (e.g. neural networks) to the perturbed datasets using gradient descent. As a result, VIPeR only needs $\\mathcal{O}(1)$ time complexity for action selection while LCB-based algorithms require at least $\\Omega(K^2)$, where $K$ is the total number of trajectories in the offline data. We also propose a novel data splitting technique that helps remove the potentially large log covering number in the learning bound. We prove that VIPeR yields a provable uncertainty quantifier with overparameterized neural networks and achieves an $\\tilde{\\mathcal{O}}\\left( \\frac{ \\kappa H^{5/2} \\tilde{d} }{\\sqrt{K}} \\right)$ sub-optimality where $\\tilde{d}$ is the effective dimension, $H$ is the horizon length and $\\kappa$ measures the distributional shift. We corroborate the statistical and computational efficiency of VIPeR with an empirical evaluation in a wide set of synthetic and real-world datasets. To the best of our knowledge, VIPeR is the first offline RL algorithm that is both provably and computationally efficient in general Markov decision processes (MDPs) with neural network function approximation. ",
    "url": "https://arxiv.org/abs/2302.12780",
    "authors": [
      "Thanh Nguyen-Tang",
      "Raman Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12784",
    "title": "STA: Self-controlled Text Augmentation for Improving Text  Classifications",
    "abstract": "Despite recent advancements in Machine Learning, many tasks still involve working in low-data regimes which can make solving natural language problems difficult. Recently, a number of text augmentation techniques have emerged in the field of Natural Language Processing (NLP) which can enrich the training data with new examples, though they are not without their caveats. For instance, simple rule-based heuristic methods are effective, but lack variation in semantic content and syntactic structure with respect to the original text. On the other hand, more complex deep learning approaches can cause extreme shifts in the intrinsic meaning of the text and introduce unwanted noise into the training data. To more reliably control the quality of the augmented examples, we introduce a state-of-the-art approach for Self-Controlled Text Augmentation (STA). Our approach tightly controls the generation process by introducing a self-checking procedure to ensure that generated examples retain the semantic content of the original text. Experimental results on multiple benchmarking datasets demonstrate that STA substantially outperforms existing state-of-the-art techniques, whilst qualitative analysis reveals that the generated examples are both lexically diverse and semantically reliable. ",
    "url": "https://arxiv.org/abs/2302.12784",
    "authors": [
      "Congcong Wang",
      "Gonzalo Fiz Pontiveros",
      "Steven Derby",
      "Tri Kurniawan Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12794",
    "title": "HULAT at SemEval-2023 Task 9: Data augmentation for pre-trained  transformers applied to Multilingual Tweet Intimacy Analysis",
    "abstract": "This paper describes our participation in SemEval-2023 Task 9, Intimacy Analysis of Multilingual Tweets. We fine-tune some of the most popular transformer models with the training dataset and synthetic data generated by different data augmentation techniques. During the development phase, our best results were obtained by using XLM-T. Data augmentation techniques provide a very slight improvement in the results. Our system ranked in the 27th position out of the 45 participating systems. Despite its modest results, our system shows promising results in languages such as Portuguese, English, and Dutch. All our code is available in the repository \\url{https://github.com/isegura/hulat_intimacy}. ",
    "url": "https://arxiv.org/abs/2302.12794",
    "authors": [
      "Isabel Segura-Bedmar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.12796",
    "title": "Revisiting Graph Persistence for Updates and Efficiency",
    "abstract": "It is well known that ordinary persistence on graphs can be computed more efficiently than the general persistence. Recently, it has also been shown that zigzag persistence on graphs also exhibits similar behavior. Motivated by these results, we revisit graph persistence and propose efficient algorithms especially for local updates on filtrations, similar to what is done in ordinary persistence for computing the vineyard. We show that, for a filtration of length $m$ (i) switches (transpositions) in ordinary graph persistence can be done in $O(\\log^4 m)$ amortized time; (ii) zigzag persistence on graphs can be computed in $O(m\\log m)$ time, which improves a recent $O(m\\log^4n)$ time algorithm assuming $n$, the size of the union of all graphs in the filtration, satisfies $n\\in\\Omega({m^\\varepsilon})$ for any fixed $0<\\varepsilon<1$; (iii) open-closed, closed-open, and closed-closed bars in dimension $0$ for graph zigzag persistence can be updated in $O(\\log^4m)$ amortized time, whereas the open-open bars in dimension $0$ and closed-closed bars in dimension $1$ can be done in $O(m)$ time. ",
    "url": "https://arxiv.org/abs/2302.12796",
    "authors": [
      "Tamal K. Dey",
      "Tao Hou"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2302.12806",
    "title": "Morality in the mundane: Categorizing moral reasoning in real-life  social situations",
    "abstract": "Moral reasoning reflects how people acquire and apply moral rules in particular situations. With increasingly social interactions happening online, social media data provides an unprecedented opportunity to assess in-the-wild moral reasoning. We investigate the commonsense aspects of morality in ordinary matters empirically. To this end, we examine data from a Reddit subcommunity (i.e., a subreddit) where an author may describe their behavior in a situation to seek comments about whether that behavior was appropriate. Other users comment to provide judgments and reasoning. We focus on the novel problem of understanding the moral reasoning implicit in user comments about the propriety of an author's behavior. Especially, we explore associations between the common elements of the indicated reasoning and the extractable social factors. Our results suggest the reasoning depends on the author's gender and the topic of a post, such as when expressing anger emotion and using sensible words (e.g., f-ck, hell, and damn) in work-related situations. Moreover, we find that the commonly expressed semantics also depends on commenters' interests. ",
    "url": "https://arxiv.org/abs/2302.12806",
    "authors": [
      "Ruijie Xi",
      "Munindar P. Singh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.12814",
    "title": "GraphSR: A Data Augmentation Algorithm for Imbalanced Node  Classification",
    "abstract": "Graph neural networks (GNNs) have achieved great success in node classification tasks. However, existing GNNs naturally bias towards the majority classes with more labelled data and ignore those minority classes with relatively few labelled ones. The traditional techniques often resort over-sampling methods, but they may cause overfitting problem. More recently, some works propose to synthesize additional nodes for minority classes from the labelled nodes, however, there is no any guarantee if those generated nodes really stand for the corresponding minority classes. In fact, improperly synthesized nodes may result in insufficient generalization of the algorithm. To resolve the problem, in this paper we seek to automatically augment the minority classes from the massive unlabelled nodes of the graph. Specifically, we propose \\textit{GraphSR}, a novel self-training strategy to augment the minority classes with significant diversity of unlabelled nodes, which is based on a Similarity-based selection module and a Reinforcement Learning(RL) selection module. The first module finds a subset of unlabelled nodes which are most similar to those labelled minority nodes, and the second one further determines the representative and reliable nodes from the subset via RL technique. Furthermore, the RL-based module can adaptively determine the sampling scale according to current training data. This strategy is general and can be easily combined with different GNNs models. Our experiments demonstrate the proposed approach outperforms the state-of-the-art baselines on various class-imbalanced datasets. ",
    "url": "https://arxiv.org/abs/2302.12814",
    "authors": [
      "Mengting Zhou",
      "Zhiguo Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12822",
    "title": "Automatic Prompt Augmentation and Selection with Chain-of-Thought from  Labeled Data",
    "abstract": "Chain-of-thought prompting (CoT) advances the reasoning abilities of large language models (LLMs) and achieves superior performance in arithmetic, commonsense, and symbolic reasoning tasks. However, most CoT studies rely on carefully designed human-annotated rational chains to prompt the language model, which poses challenges for real-world applications where labeled training data is available without human-annotated rational chains. This creates barriers to applications of CoT prompting to these general tasks. This paper proposes a new strategy, Automate-CoT (Automatic Prompt Augmentation and Selection with Chain-of-Thought), that can bypass human engineering of CoTs by automatically augmenting rational chains from a small labeled dataset, and then pruning low-quality chains to construct a candidate pool of machine-generated rationale chains based on the labels. Finally, it selects the optimal combination of several rationale chains from the pool for CoT prompting by employing a variance-reduced policy gradient strategy to estimate the significance of each example in a black-box language model. Automate-CoT enables a quick adaptation of the CoT technique to different tasks. Experimental results demonstrate the effectiveness of our method, where state-of-the-art results are achieved on arithmetic reasoning (+2.7\\%), commonsense reasoning (+3.4\\%), symbolic reasoning (+3.2\\%), and non-reasoning tasks (+2.5\\%). Our code will be available at https://github.com/shizhediao/automate-cot. ",
    "url": "https://arxiv.org/abs/2302.12822",
    "authors": [
      "KaShun Shum",
      "Shizhe Diao",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.12828",
    "title": "SplineCam: Exact Visualization and Characterization of Deep Network  Geometry and Decision Boundaries",
    "abstract": "Current Deep Network (DN) visualization and interpretability methods rely heavily on data space visualizations such as scoring which dimensions of the data are responsible for their associated prediction or generating new data features or samples that best match a given DN unit or representation. In this paper, we go one step further by developing the first provably exact method for computing the geometry of a DN's mapping - including its decision boundary - over a specified region of the data space. By leveraging the theory of Continuous Piece-Wise Linear (CPWL) spline DNs, SplineCam exactly computes a DNs geometry without resorting to approximations such as sampling or architecture simplification. SplineCam applies to any DN architecture based on CPWL nonlinearities, including (leaky-)ReLU, absolute value, maxout, and max-pooling and can also be applied to regression DNs such as implicit neural representations. Beyond decision boundary visualization and characterization, SplineCam enables one to compare architectures, measure generalizability and sample from the decision boundary on or off the manifold. Project Website: bit.ly/splinecam. ",
    "url": "https://arxiv.org/abs/2302.12828",
    "authors": [
      "Ahmed Imtiaz Humayun",
      "Randall Balestriero",
      "Guha Balakrishnan",
      "Richard Baraniuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12261",
    "title": "Testing Stationarity Concepts for ReLU Networks: Hardness, Regularity,  and Robust Algorithms",
    "abstract": "We study the computational problem of the stationarity test for the empirical loss of neural networks with ReLU activation functions. Our contributions are: Hardness: We show that checking a certain first-order approximate stationarity concept for a piecewise linear function is co-NP-hard. This implies that testing a certain stationarity concept for a modern nonsmooth neural network is in general computationally intractable. As a corollary, we prove that testing so-called first-order minimality for functions in abs-normal form is co-NP-complete, which was conjectured by Griewank and Walther (2019, SIAM J. Optim., vol. 29, p284). Regularity: We establish a necessary and sufficient condition for the validity of an equality-type subdifferential chain rule in terms of Clarke, Fr\\'echet, and limiting subdifferentials of the empirical loss of two-layer ReLU networks. This new condition is simple and efficiently checkable. Robust algorithms: We introduce an algorithmic scheme to test near-approximate stationarity in terms of both Clarke and Fr\\'echet subdifferentials. Our scheme makes no false positive or false negative error when the tested point is sufficiently close to a stationary one and a certain qualification is satisfied. This is the first practical and robust stationarity test approach for two-layer ReLU networks. ",
    "url": "https://arxiv.org/abs/2302.12261",
    "authors": [
      "Lai Tian",
      "Anthony Man-Cho So"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12341",
    "title": "Rank-Based Causal Discovery for Post-Nonlinear Models",
    "abstract": "Learning causal relationships from empirical observations is a central task in scientific research. A common method is to employ structural causal models that postulate noisy functional relations among a set of interacting variables. To ensure unique identifiability of causal directions, researchers consider restricted subclasses of structural causal models. Post-nonlinear (PNL) causal models constitute one of the most flexible options for such restricted subclasses, containing in particular the popular additive noise models as a further subclass. However, learning PNL models is not well studied beyond the bivariate case. The existing methods learn non-linear functional relations by minimizing residual dependencies and subsequently test independence from residuals to determine causal orientations. However, these methods can be prone to overfitting and, thus, difficult to tune appropriately in practice. As an alternative, we propose a new approach for PNL causal discovery that uses rank-based methods to estimate the functional parameters. This new approach exploits natural invariances of PNL models and disentangles the estimation of the non-linear functions from the independence tests used to find causal orientations. We prove consistency of our method and validate our results in numerical experiments. ",
    "url": "https://arxiv.org/abs/2302.12341",
    "authors": [
      "Grigor Keropyan",
      "David Strieder",
      "Mathias Drton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.12405",
    "title": "Privacy Against Hypothesis-Testing Adversaries for Quantum Computing",
    "abstract": "A novel definition for data privacy in quantum computing based on quantum hypothesis testing is presented in this paper. The parameters in this privacy notion possess an operational interpretation based on the success/failure of an omnipotent adversary being able to distinguish the private categories to which the data belongs using arbitrary measurements on quantum states. Important properties of post processing and composition are then proved for the new notion of privacy. The relationship between privacy against hypothesis-testing adversaries, defined in this paper, and quantum differential privacy are then examined. It is shown that these definitions are intertwined in some parameter regimes. This enables us to provide an interpretation for the privacy budget in quantum differential privacy based on its relationship with privacy against hypothesis testing adversaries. ",
    "url": "https://arxiv.org/abs/2302.12405",
    "authors": [
      "Farhad Farokhi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.12467",
    "title": "The number of descendants in a random directed acyclic graph",
    "abstract": "We consider a well known model of random directed acyclic graphs of order $n$, obtained by recursively adding vertices, where each new vertex has a fixed outdegree $d\\ge2$ and the endpoints of the $d$ edges from it are chosen uniformly at random among previously existing vertices. Our main results concern the number $X$ of vertices that are descendants of $n$. We show that $X/\\sqrt n$ converges in distribution; the limit distribution is, up to a constant factor, given by the $d$th root of a Gamma distributed variable. $\\Gamma(d/(d-1))$. When $d=2$, the limit distribution can also be described as a chi distribution $\\chi(4)$. We also show convergence of moments, and find thus the asymptotics of the mean and higher moments. ",
    "url": "https://arxiv.org/abs/2302.12467",
    "authors": [
      "Svante Janson"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2302.12482",
    "title": "Disease Severity Regression with Continuous Data Augmentation",
    "abstract": "Disease severity regression by a convolutional neural network (CNN) for medical images requires a sufficient number of image samples labeled with severity levels. Conditional generative adversarial network (cGAN)-based data augmentation (DA) is a possible solution, but it encounters two issues. The first issue is that existing cGANs cannot deal with real-valued severity levels as their conditions, and the second is that the severity of the generated images is not fully reliable. We propose continuous DA as a solution to the two issues. Our method uses continuous severity GAN to generate images at real-valued severity levels and dataset-disjoint multi-objective optimization to deal with the second issue. Our method was evaluated for estimating ulcerative colitis (UC) severity of endoscopic images and achieved higher classification performance than conventional DA methods. ",
    "url": "https://arxiv.org/abs/2302.12482",
    "authors": [
      "Shumpei Takezaki",
      "Kiyohito Tanaka",
      "Seiichi Uchida",
      "Takeaki Kadota"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.12504",
    "title": "Recovering Sparse and Interpretable Subgroups with Heterogeneous  Treatment Effects with Censored Time-to-Event Outcomes",
    "abstract": "Studies involving both randomized experiments as well as observational data typically involve time-to-event outcomes such as time-to-failure, death or onset of an adverse condition. Such outcomes are typically subject to censoring due to loss of follow-up and established statistical practice involves comparing treatment efficacy in terms of hazard ratios between the treated and control groups. In this paper we propose a statistical approach to recovering sparse phenogroups (or subtypes) that demonstrate differential treatment effects as compared to the study population. Our approach involves modelling the data as a mixture while enforcing parameter shrinkage through structured sparsity regularization. We propose a novel inference procedure for the proposed model and demonstrate its efficacy in recovering sparse phenotypes across large landmark real world clinical studies in cardiovascular health. ",
    "url": "https://arxiv.org/abs/2302.12504",
    "authors": [
      "Chirag Nagpal",
      "Vedant Sanil",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12563",
    "title": "Retrieved Sequence Augmentation for Protein Representation Learning",
    "abstract": "Protein language models have excelled in a variety of tasks, ranging from structure prediction to protein engineering. However, proteins are highly diverse in functions and structures, and current state-of-the-art models including the latest version of AlphaFold rely on Multiple Sequence Alignments (MSA) to feed in the evolutionary knowledge. Despite their success, heavy computational overheads, as well as the de novo and orphan proteins remain great challenges in protein representation learning. In this work, we show that MSAaugmented models inherently belong to retrievalaugmented methods. Motivated by this finding, we introduce Retrieved Sequence Augmentation(RSA) for protein representation learning without additional alignment or pre-processing. RSA links query protein sequences to a set of sequences with similar structures or properties in the database and combines these sequences for downstream prediction. We show that protein language models benefit from the retrieval enhancement on both structure prediction and property prediction tasks, with a 5% improvement on MSA Transformer on average while being 373 times faster. In addition, we show that our model can transfer to new protein domains better and outperforms MSA Transformer on de novo protein prediction. Our study fills a much-encountered gap in protein prediction and brings us a step closer to demystifying the domain knowledge needed to understand protein sequences. Code is available on https://github.com/HKUNLP/RSA. ",
    "url": "https://arxiv.org/abs/2302.12563",
    "authors": [
      "Chang Ma",
      "Haiteng Zhao",
      "Lin Zheng",
      "Jiayi Xin",
      "Qintong Li",
      "Lijun Wu",
      "Zhihong Deng",
      "Yang Lu",
      "Qi Liu",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12633",
    "title": "Neighborhood complexity of planar graphs",
    "abstract": "Reidl, S\\'anchez Villaamil, and Stravopoulos (2019) characterized graph classes of bounded expansion as follows: A class $\\mathcal{C}$ closed under subgraphs has bounded expansion if and only if there exists a function $f:\\mathbb{N} \\to \\mathbb{N}$ such that for every graph $G \\in \\mathcal{C}$, every nonempty subset $A$ of vertices in $G$ and every nonnegative integer $r$, the number of distinct intersections between $A$ and a ball of radius $r$ in $G$ is at most $f(r) |A|$. When $\\mathcal{C}$ has bounded expansion, the function $f(r)$ coming from existing proofs is typically exponential. In the special case of planar graphs, it was conjectured by Soko{\\l}owski (2021) that $f(r)$ could be taken to be a polynomial. In this paper, we prove this conjecture: For every nonempty subset $A$ of vertices in a planar graph $G$ and every nonnegative integer $r$, the number of distinct intersections between $A$ and a ball of radius $r$ in $G$ is $O(r^4 |A|)$. We also show that a polynomial bound holds more generally for every proper minor-closed class of graphs. ",
    "url": "https://arxiv.org/abs/2302.12633",
    "authors": [
      "Gwena\u00ebl Joret",
      "Cl\u00e9ment Rambaud"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2302.12645",
    "title": "Learning stiff chemical kinetics using extended deep neural operators",
    "abstract": "We utilize neural operators to learn the solution propagator for the challenging chemical kinetics equation. Specifically, we apply the deep operator network (DeepONet) along with its extensions, such as the autoencoder-based DeepONet and the newly proposed Partition-of-Unity (PoU-) DeepONet to study a range of examples, including the ROBERS problem with three species, the POLLU problem with 25 species, pure kinetics of the syngas skeletal model for $CO/H_2$ burning, which contains 11 species and 21 reactions and finally, a temporally developing planar $CO/H_2$ jet flame (turbulent flame) using the same syngas mechanism. We have demonstrated the advantages of the proposed approach through these numerical examples. Specifically, to train the DeepONet for the syngas model, we solve the skeletal kinetic model for different initial conditions. In the first case, we parametrize the initial conditions based on equivalence ratios and initial temperature values. In the second case, we perform a direct numerical simulation of a two-dimensional temporally developing $CO/H_2$ jet flame. Then, we initialize the kinetic model by the thermochemical states visited by a subset of grid points at different time snapshots. Stiff problems are computationally expensive to solve with traditional stiff solvers. Thus, this work aims to develop a neural operator-based surrogate model to solve stiff chemical kinetics. The operator, once trained offline, can accurately integrate the thermochemical state for arbitrarily large time advancements, leading to significant computational gains compared to stiff integration schemes. ",
    "url": "https://arxiv.org/abs/2302.12645",
    "authors": [
      "Somdatta Goswami",
      "Ameya D. Jagtap",
      "Hessam Babaee",
      "Bryan T. Susi",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12711",
    "title": "FG-SSA: Features Gradient-based Signals Selection Algorithm of Linear  Complexity for Convolutional Neural Networks",
    "abstract": "Recently, many convolutional neural networks (CNNs) for classification by time domain data of multisignals have been developed. Although some signals are important for correct classification, others are not. When data that do not include important signals for classification are taken as the CNN input layer, the calculation, memory, and data collection costs increase. Therefore, identifying and eliminating nonimportant signals from the input layer are important. In this study, we proposed features gradient-based signals selection algorithm (FG-SSA), which can be used for finding and removing nonimportant signals for classification by utilizing features gradient obtained by the calculation process of grad-CAM. When we define N as the number of signals, the computational complexity of the proposed algorithm is linear time O(N), that is, it has a low calculation cost. We verified the effectiveness of the algorithm using the OPPORTUNITY Activity Recognition dataset, which is an open dataset comprising acceleration signals of human activities. In addition, we checked the average 6.55 signals from a total of 15 acceleration signals (five triaxial sensors) that were removed by FG-SSA while maintaining high generalization scores of classification. Therefore, the proposed algorithm FG-SSA has an effect on finding and removing signals that are not important for CNN-based classification. ",
    "url": "https://arxiv.org/abs/2302.12711",
    "authors": [
      "Yuto Omae",
      "Yusuke Sakai",
      "Hirotaka Takahashi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12718",
    "title": "Understanding the Impact of Competing Events on Heterogeneous Treatment  Effect Estimation from Time-to-Event Data",
    "abstract": "We study the problem of inferring heterogeneous treatment effects (HTEs) from time-to-event data in the presence of competing events. Albeit its great practical relevance, this problem has received little attention compared to its counterparts studying HTE estimation without time-to-event data or competing events. We take an outcome modeling approach to estimating HTEs, and consider how and when existing prediction models for time-to-event data can be used as plug-in estimators for potential outcomes. We then investigate whether competing events present new challenges for HTE estimation -- in addition to the standard confounding problem --, and find that, because there are multiple definitions of causal effects in this setting -- namely total, direct and separable effects --, competing events can act as an additional source of covariate shift depending on the desired treatment effect interpretation and associated estimand. We theoretically analyze and empirically illustrate when and how these challenges play a role when using generic machine learning prediction models for the estimation of HTEs. ",
    "url": "https://arxiv.org/abs/2302.12718",
    "authors": [
      "Alicia Curth",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12757",
    "title": "Ensemble knowledge distillation of self-supervised speech models",
    "abstract": "Distilled self-supervised models have shown competitive performance and efficiency in recent years. However, there is a lack of experience in jointly distilling multiple self-supervised speech models. In our work, we performed Ensemble Knowledge Distillation (EKD) on various self-supervised speech models such as HuBERT, RobustHuBERT, and WavLM. We tried two different aggregation techniques, layerwise-average and layerwise-concatenation, to the representations of different teacher models and found that the former was more effective. On top of that, we proposed a multiple prediction head method for student models to predict different layer outputs of multiple teacher models simultaneously. The experimental results show that our method improves the performance of the distilled models on four downstream speech processing tasks, Phoneme Recognition, Speaker Identification, Emotion Recognition, and Automatic Speech Recognition in the hidden-set track of the SUPERB benchmark. ",
    "url": "https://arxiv.org/abs/2302.12757",
    "authors": [
      "Kuan-Po Huang",
      "Tzu-hsun Feng",
      "Yu-Kuan Fu",
      "Tsu-Yuan Hsu",
      "Po-Chieh Yen",
      "Wei-Cheng Tseng",
      "Kai-Wei Chang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2101.11885",
    "title": "Causality and independence in perfectly adapted dynamical systems",
    "abstract": " Comments: 35 pages, to appear in Journal of Causal Inference ",
    "url": "https://arxiv.org/abs/2101.11885",
    "authors": [
      "Tineke Blom",
      "Joris M. Mooij"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.10476",
    "title": "Self-Supervised Learning to Prove Equivalence Between Straight-Line  Programs via Rewrite Rules",
    "abstract": " Comments: 30 pages including appendix ",
    "url": "https://arxiv.org/abs/2109.10476",
    "authors": [
      "Steve Kommrusch",
      "Martin Monperrus",
      "Louis-No\u00ebl Pouchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2202.07101",
    "title": "A Survey on Dynamic Neural Networks for Natural Language Processing",
    "abstract": " Comments: EACL 2023 Findings ",
    "url": "https://arxiv.org/abs/2202.07101",
    "authors": [
      "Canwen Xu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09340",
    "title": "Learning Physics-Informed Neural Networks without Stacked  Back-propagation",
    "abstract": " Comments: AISTATS 2023 ",
    "url": "https://arxiv.org/abs/2202.09340",
    "authors": [
      "Di He",
      "Shanda Li",
      "Wenlei Shi",
      "Xiaotian Gao",
      "Jia Zhang",
      "Jiang Bian",
      "Liwei Wang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16668",
    "title": "Flexible and Efficient Contextual Bandits with Heterogeneous Treatment  Effect Oracles",
    "abstract": " Title: Flexible and Efficient Contextual Bandits with Heterogeneous Treatment  Effect Oracles ",
    "url": "https://arxiv.org/abs/2203.16668",
    "authors": [
      "Aldo Gael Carranza",
      "Sanath Kumar Krishnamurthy",
      "Susan Athey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.08152",
    "title": "Dual-mode robust MPC for the tracking control of non-holonomoic mobile  robots",
    "abstract": " Comments: This paper exists a lot of mistakes. Therefore, I want to withdraw it ",
    "url": "https://arxiv.org/abs/2205.08152",
    "authors": [
      "Huan Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.09699",
    "title": "Snake net and balloon force with a neural network for detecting multiple  phases",
    "abstract": " Comments: 13 pages, 15 figures, submitted to PRE ",
    "url": "https://arxiv.org/abs/2205.09699",
    "authors": [
      "Xiaodong Sun",
      "Huijiong Yang",
      "Nan Wu",
      "T.C. Scott",
      "Jie Zhang",
      "Wanzhou Zhang"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11486",
    "title": "Robust and Agnostic Learning of Conditional Distributional Treatment  Effects",
    "abstract": " Comments: 24 pages, 6 figures, AISTATS 2023 ",
    "url": "https://arxiv.org/abs/2205.11486",
    "authors": [
      "Nathan Kallus",
      "Miruna Oprescu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.08562",
    "title": "DHGE: Dual-view Hyper-Relational Knowledge Graph Embedding for Link  Prediction and Entity Typing",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2207.08562",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Ling Tan",
      "Gengxian Zhou",
      "Tianyu Yao",
      "Kaiyang Wan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12594",
    "title": "Confirmation Bias in Social Networks",
    "abstract": " Comments: Status: Accepted (Mathematical Social Sciences, Elsevier) ",
    "url": "https://arxiv.org/abs/2207.12594",
    "authors": [
      "Marcos R. Fernandes"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2208.06322",
    "title": "EEGNN: Edge Enhanced Graph Neural Network with a Bayesian Nonparametric  Graph Model",
    "abstract": " Title: EEGNN: Edge Enhanced Graph Neural Network with a Bayesian Nonparametric  Graph Model ",
    "url": "https://arxiv.org/abs/2208.06322",
    "authors": [
      "Yirui Liu",
      "Xinghao Qiao",
      "Liying Wang",
      "Jessica Lam"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10010",
    "title": "NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs",
    "abstract": " Comments: NeurIPS 2022 GLFrontiers ",
    "url": "https://arxiv.org/abs/2208.10010",
    "authors": [
      "Yijun Tian",
      "Chuxu Zhang",
      "Zhichun Guo",
      "Xiangliang Zhang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.13058",
    "title": "Adversarial Robustness for Tabular Data through Cost and Utility  Awareness",
    "abstract": " Comments: The first two authors contributed equally. To appear in the proceedings of NDSS 2023 ",
    "url": "https://arxiv.org/abs/2208.13058",
    "authors": [
      "Klim Kireev",
      "Bogdan Kulynych",
      "Carmela Troncoso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.13305",
    "title": "Neural Network Approximation of Continuous Functions in High Dimensions  with Applications to Inverse Problems",
    "abstract": " Comments: 22 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2208.13305",
    "authors": [
      "Santhosh Karnik",
      "Rongrong Wang",
      "Mark Iwen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2209.01599",
    "title": "DMiner: Dashboard Design Mining and Recommendation",
    "abstract": " Title: DMiner: Dashboard Design Mining and Recommendation ",
    "url": "https://arxiv.org/abs/2209.01599",
    "authors": [
      "Yanna Lin",
      "Haotian Li",
      "Aoyu Wu",
      "Yong Wang",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2209.04766",
    "title": "Towards Sparsification of Graph Neural Networks",
    "abstract": " Comments: ICCD 2022 Paper ",
    "url": "https://arxiv.org/abs/2209.04766",
    "authors": [
      "Hongwu Peng",
      "Deniz Gurevin",
      "Shaoyi Huang",
      "Tong Geng",
      "Weiwen Jiang",
      "Omer Khan",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.08412",
    "title": "Characterizing Internal Evasion Attacks in Federated Learning",
    "abstract": " Comments: 16 pages, 8 figures (14 images if counting sub-figures separately), Camera ready version for AISTATS 2023, longer version of paper submitted to CrossFL 2022 poster workshop, code available at (this https URL) ",
    "url": "https://arxiv.org/abs/2209.08412",
    "authors": [
      "Taejin Kim",
      "Shubhranshu Singh",
      "Nikhil Madaan",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.09025",
    "title": "RAMP-Net: A Robust Adaptive MPC for Quadrotors via Physics-informed  Neural Network",
    "abstract": " Comments: This work has been accepted for presentation at the 2023 IEEE International Conference on Robotics and Automation (ICRA), May 29 - June 2, 2023, London, UK. arXiv version will be merged with the conference proceeding once available ",
    "url": "https://arxiv.org/abs/2209.09025",
    "authors": [
      "Sourav Sanyal",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.15639",
    "title": "F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language  Models",
    "abstract": " Comments: Accepted to ICLR 2023 (this https URL). 20 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2209.15639",
    "authors": [
      "Weicheng Kuo",
      "Yin Cui",
      "Xiuye Gu",
      "AJ Piergiovanni",
      "Anelia Angelova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01716",
    "title": "Discussion of Features for Acoustic Anomaly Detection under Industrial  Disturbing Noise in an End-of-Line Test of Geared Motors",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2211.01716",
    "authors": [
      "Peter Wissbrock",
      "David Pelkmann",
      "Yvonne Richter"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.02927",
    "title": "Unsupervised Machine Learning for Explainable Health Care Fraud  Detection",
    "abstract": " Comments: NBER Working paper #30946 ",
    "url": "https://arxiv.org/abs/2211.02927",
    "authors": [
      "Shubhranshu Shekhar",
      "Jetson Leder-Luis",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.06750",
    "title": "Multi-Speaker and Wide-Band Simulated Conversations as Training Data for  End-to-End Neural Diarization",
    "abstract": " Comments: Accepted by ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.06750",
    "authors": [
      "Federico Landini",
      "Mireia Diez",
      "Alicia Lozano-Diez",
      "Luk\u00e1\u0161 Burget"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.13469",
    "title": "NQE: N-ary Query Embedding for Complex Query Answering over  Hyper-relational Knowledge Graphs",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.13469",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Yuhao Yang",
      "Gengxian Zhou",
      "Yikai Guo",
      "Tianyu Yao",
      "Zichen Tang",
      "Xueyuan Lin",
      "Kaiyang Wan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13715",
    "title": "Trust Your $\\nabla$: Gradient-based Intervention Targeting for Causal  Discovery",
    "abstract": " Title: Trust Your $\\nabla$: Gradient-based Intervention Targeting for Causal  Discovery ",
    "url": "https://arxiv.org/abs/2211.13715",
    "authors": [
      "Mateusz Olko",
      "Micha\u0142 Zaj\u0105c",
      "Aleksandra Nowak",
      "Nino Scherrer",
      "Yashas Annadani",
      "Stefan Bauer",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.14114",
    "title": "Interval-censored Transformer Hawkes: Detecting Information Operations  using the Reaction of Social Systems",
    "abstract": " Title: Interval-censored Transformer Hawkes: Detecting Information Operations  using the Reaction of Social Systems ",
    "url": "https://arxiv.org/abs/2211.14114",
    "authors": [
      "Quyu Kong",
      "Pio Calderon",
      "Rohit Ram",
      "Olga Boichak",
      "Marian-Andrei Rizoiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.15226",
    "title": "RAMP: A Flat Nanosecond Optical Network and MPI Operations for  Distributed Deep Learning Systems",
    "abstract": " Title: RAMP: A Flat Nanosecond Optical Network and MPI Operations for  Distributed Deep Learning Systems ",
    "url": "https://arxiv.org/abs/2211.15226",
    "authors": [
      "Alessandro Ottino",
      "Joshua Benjamin",
      "Georgios Zervas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.07048",
    "title": "PD-Quant: Post-Training Quantization based on Prediction Difference  Metric",
    "abstract": " Title: PD-Quant: Post-Training Quantization based on Prediction Difference  Metric ",
    "url": "https://arxiv.org/abs/2212.07048",
    "authors": [
      "Jiawei Liu",
      "Lin Niu",
      "Zhihang Yuan",
      "Dawei Yang",
      "Xinggang Wang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.08490",
    "title": "LOCT: A Lightweight Network Using OC-Transformer for Extracting  Buildings and Roads from UAV Aerial Remote Sensing Images",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2212.08490",
    "authors": [
      "Xiaoxiang Han",
      "Yiman Liu",
      "Gang Liu",
      "Yuanjie Lin",
      "Qiaohong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00970",
    "title": "Benchmarking the Robustness of LiDAR Semantic Segmentation Models",
    "abstract": " Comments: The benchmark will be made available at this https URL ",
    "url": "https://arxiv.org/abs/2301.00970",
    "authors": [
      "Xu Yan",
      "Chaoda Zheng",
      "Zhen Li",
      "Shuguang Cui",
      "Dengxin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.04218",
    "title": "Leveraging Diffusion For Strong and High Quality Face Morphing Attacks",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2301.04218",
    "authors": [
      "Zander Blasingame",
      "Chen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12092",
    "title": "The Benefits of Vulnerability Discovery and Bug Bounty Programs: Case  Studies of Chromium and Firefox",
    "abstract": " Title: The Benefits of Vulnerability Discovery and Bug Bounty Programs: Case  Studies of Chromium and Firefox ",
    "url": "https://arxiv.org/abs/2301.12092",
    "authors": [
      "Soodeh Atefi",
      "Amutheezan Sivagnanam",
      "Afiya Ayman",
      "Jens Grossklags",
      "Aron Laszka"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.00869",
    "title": "Disentanglement of Latent Representations via Sparse Causal  Interventions",
    "abstract": " Comments: 16 pages, 10 pages for the main paper and 6 pages for the supplement, 14 figures, submitted to IJCAI 2023. V2: added link to repository ",
    "url": "https://arxiv.org/abs/2302.00869",
    "authors": [
      "Ga\u00ebl Gendron",
      "Michael Witbrock",
      "Gillian Dobbie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Discrete Mathematics (cs.DM)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.01020",
    "title": "Meta Learning in Decentralized Neural Networks: Towards More General AI",
    "abstract": " Comments: Accepted for AAAI 2023 Doctoral Consortium ",
    "url": "https://arxiv.org/abs/2302.01020",
    "authors": [
      "Yuwei Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.03014",
    "title": "Detection and Localization of Melanoma Skin Cancer in Histopathological  Whole Slide Images",
    "abstract": " Comments: Submitted to EUSIPCO 23 ",
    "url": "https://arxiv.org/abs/2302.03014",
    "authors": [
      "Neel Kanwal",
      "Roger Amundsen",
      "Helga Hardardottir",
      "Luca Tomasetti",
      "Erling Sandoy Undersrud",
      "Emiel A.M. Janssen",
      "Kjersti Engan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05443",
    "title": "Believability and Harmfulness Shape the Virality of Misleading Social  Media Posts",
    "abstract": " Comments: Accepted at WWW 23 ",
    "url": "https://arxiv.org/abs/2302.05443",
    "authors": [
      "Chiara Drolsbach",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.06299",
    "title": "Homophily-oriented Heterogeneous Graph Rewiring",
    "abstract": " Comments: Accepted by WWW 2023 ",
    "url": "https://arxiv.org/abs/2302.06299",
    "authors": [
      "Jiayan Guo",
      "Lun Du",
      "Wendong Bi",
      "Qiang Fu",
      "Xiaojun Ma",
      "Xu Chen",
      "Shi Han",
      "Dongmei Zhang",
      "Yan Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06359",
    "title": "Fixing Overconfidence in Dynamic Neural Networks",
    "abstract": " Title: Fixing Overconfidence in Dynamic Neural Networks ",
    "url": "https://arxiv.org/abs/2302.06359",
    "authors": [
      "Lassi Meronen",
      "Martin Trapp",
      "Andrea Pilzer",
      "Le Yang",
      "Arno Solin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.07469",
    "title": "Robust Safety under Stochastic Uncertainty with Discrete-Time Control  Barrier Functions",
    "abstract": " Comments: 11 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2302.07469",
    "authors": [
      "Ryan K. Cosner",
      "Preston Culbertson",
      "Andrew J. Taylor",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.08646",
    "title": "AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust  Autonomous Driving",
    "abstract": " Title: AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust  Autonomous Driving ",
    "url": "https://arxiv.org/abs/2302.08646",
    "authors": [
      "Tianyue Zheng",
      "Ang Li",
      "Zhe Chen",
      "Hongbo Wang",
      "Jun Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.09360",
    "title": "Backdoor Attacks to Pre-trained Unified Foundation Models",
    "abstract": " Comments: This paper is accepted as a poster for NDSS 2023 ",
    "url": "https://arxiv.org/abs/2302.09360",
    "authors": [
      "Zenghui Yuan",
      "Yixin Liu",
      "Kai Zhang",
      "Pan Zhou",
      "Lichao Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.10890",
    "title": "Learning Interpretable Low-dimensional Representation via Physical  Symmetry",
    "abstract": " Title: Learning Interpretable Low-dimensional Representation via Physical  Symmetry ",
    "url": "https://arxiv.org/abs/2302.10890",
    "authors": [
      "Xuanjie Liu",
      "Daniel Chin",
      "Yichen Huang",
      "Gus Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11135",
    "title": "Semi-Supervised Approach for Early Stuck Sign Detection in Drilling  Operations",
    "abstract": " Comments: There is a conflict interest between authors ",
    "url": "https://arxiv.org/abs/2302.11135",
    "authors": [
      "Andres Hernandez-Matamoros",
      "Kohei Sugawara",
      "Tatsuya Kaneko",
      "Ryota Wada",
      "Masahiko Ozaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11880",
    "title": "Catch Me If You Can: Semi-supervised Graph Learning for Spotting Money  Laundering",
    "abstract": " Title: Catch Me If You Can: Semi-supervised Graph Learning for Spotting Money  Laundering ",
    "url": "https://arxiv.org/abs/2302.11880",
    "authors": [
      "Md. Rezaul Karim",
      "Felix Hermsen",
      "Sisay Adugna Chala",
      "Paola de Perthuis",
      "Avikarsha Mandal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11883",
    "title": "PIFON-EPT: MR-Based Electrical Property Tomography Using  Physics-Informed Fourier Networks",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2302.11883",
    "authors": [
      "Xinling Yu",
      "Jos\u00e9 E. C. Serrall\u00e9s",
      "Ilias I. Giannakopoulos",
      "Ziyue Liu",
      "Luca Daniel",
      "Riccardo Lattanzi",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11970",
    "title": "ArtiFact: A Large-Scale Dataset with Artificial and Factual Images for  Generalizable and Robust Synthetic Image Detection",
    "abstract": " Comments: Figures High-Res ",
    "url": "https://arxiv.org/abs/2302.11970",
    "authors": [
      "Md Awsafur Rahman",
      "Bishmoy Paul",
      "Najibul Haque Sarker",
      "Zaber Ibn Abdul Hakim",
      "Shaikh Anowarul Fattah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12003",
    "title": "Robust Representation Learning by Clustering with Bisimulation Metrics  for Visual Reinforcement Learning with Distractions",
    "abstract": " Comments: Accepted to AAAI 2023 ",
    "url": "https://arxiv.org/abs/2302.12003",
    "authors": [
      "Qiyuan Liu",
      "Qi Zhou",
      "Rui Yang",
      "Jie Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12057",
    "title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
    "abstract": " Comments: 4 pages + references, 1 figure ",
    "url": "https://arxiv.org/abs/2302.12057",
    "authors": [
      "Maureen de Seyssel",
      "Marvin Lavechin",
      "Hadrien Titeux",
      "Arthur Thomas",
      "Gwendal Virlet",
      "Andrea Santos Revilla",
      "Guillaume Wisniewski",
      "Bogdan Ludusan",
      "Emmanuel Dupoux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.12237",
    "title": "Learning Neural Volumetric Representations of Dynamic Humans in Minutes",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2302.12237",
    "authors": [
      "Chen Geng",
      "Sida Peng",
      "Zhen Xu",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  }
]