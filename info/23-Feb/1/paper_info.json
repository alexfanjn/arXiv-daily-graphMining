[
  {
    "id": "arXiv:2301.13254",
    "title": "Deep Monocular Hazard Detection for Safe Small Body Landing",
    "abstract": "Hazard detection and avoidance is a key technology for future robotic small body sample return and lander missions. Current state-of-the-practice methods rely on high-fidelity, a priori terrain maps, which require extensive human-in-the-loop verification and expensive reconnaissance campaigns to resolve mapping uncertainties. We propose a novel safety mapping paradigm that leverages deep semantic segmentation techniques to predict landing safety directly from a single monocular image, thus reducing reliance on high-fidelity, a priori data products. We demonstrate precise and accurate safety mapping performance on real in-situ imagery of prospective sample sites from the OSIRIS-REx mission. ",
    "url": "https://arxiv.org/abs/2301.13254",
    "authors": [
      "Travis Driver",
      "Kento Tomita",
      "Koki Ho",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.13271",
    "title": "Probabilistic Neural Data Fusion for Learning from an Arbitrary Number  of Multi-fidelity Data Sets",
    "abstract": "In many applications in engineering and sciences analysts have simultaneous access to multiple data sources. In such cases, the overall cost of acquiring information can be reduced via data fusion or multi-fidelity (MF) modeling where one leverages inexpensive low-fidelity (LF) sources to reduce the reliance on expensive high-fidelity (HF) data. In this paper, we employ neural networks (NNs) for data fusion in scenarios where data is very scarce and obtained from an arbitrary number of sources with varying levels of fidelity and cost. We introduce a unique NN architecture that converts MF modeling into a nonlinear manifold learning problem. Our NN architecture inversely learns non-trivial (e.g., non-additive and non-hierarchical) biases of the LF sources in an interpretable and visualizable manifold where each data source is encoded via a low-dimensional distribution. This probabilistic manifold quantifies model form uncertainties such that LF sources with small bias are encoded close to the HF source. Additionally, we endow the output of our NN with a parametric distribution not only to quantify aleatoric uncertainties, but also to reformulate the network's loss function based on strictly proper scoring rules which improve robustness and accuracy on unseen HF data. Through a set of analytic and engineering examples, we demonstrate that our approach provides a high predictive power while quantifying various sources uncertainties. ",
    "url": "https://arxiv.org/abs/2301.13271",
    "authors": [
      "Carlos Mora",
      "Jonathan Tammer Eweis-Labolle",
      "Tyler Johnson",
      "Likith Gadde",
      "Ramin Bostanabad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13273",
    "title": "Near Optimal Private and Robust Linear Regression",
    "abstract": "We study the canonical statistical estimation problem of linear regression from $n$ i.i.d.~examples under $(\\varepsilon,\\delta)$-differential privacy when some response variables are adversarially corrupted. We propose a variant of the popular differentially private stochastic gradient descent (DP-SGD) algorithm with two innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness. When there is no adversarial corruption, this algorithm improves upon the existing state-of-the-art approach and achieves a near optimal sample complexity. Under label-corruption, this is the first efficient linear regression algorithm to guarantee both $(\\varepsilon,\\delta)$-DP and robustness. Synthetic experiments confirm the superiority of our approach. ",
    "url": "https://arxiv.org/abs/2301.13273",
    "authors": [
      "Xiyang Liu",
      "Prateek Jain",
      "Weihao Kong",
      "Sewoong Oh",
      "Arun Sai Suggala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13279",
    "title": "Learning Coordination Policies over Heterogeneous Graphs for Human-Robot  Teams via Recurrent Neural Schedule Propagation",
    "abstract": "As human-robot collaboration increases in the workforce, it becomes essential for human-robot teams to coordinate efficiently and intuitively. Traditional approaches for human-robot scheduling either utilize exact methods that are intractable for large-scale problems and struggle to account for stochastic, time varying human task performance, or application-specific heuristics that require expert domain knowledge to develop. We propose a deep learning-based framework, called HybridNet, combining a heterogeneous graph-based encoder with a recurrent schedule propagator for scheduling stochastic human-robot teams under upper- and lower-bound temporal constraints. The HybridNet's encoder leverages Heterogeneous Graph Attention Networks to model the initial environment and team dynamics while accounting for the constraints. By formulating task scheduling as a sequential decision-making process, the HybridNet's recurrent neural schedule propagator leverages Long Short-Term Memory (LSTM) models to propagate forward consequences of actions to carry out fast schedule generation, removing the need to interact with the environment between every task-agent pair selection. The resulting scheduling policy network provides a computationally lightweight yet highly expressive model that is end-to-end trainable via Reinforcement Learning algorithms. We develop a virtual task scheduling environment for mixed human-robot teams in a multi-round setting, capable of modeling the stochastic learning behaviors of human workers. Experimental results showed that HybridNet outperformed other human-robot scheduling solutions across problem sizes for both deterministic and stochastic human performance, with faster runtime compared to pure-GNN-based schedulers. ",
    "url": "https://arxiv.org/abs/2301.13279",
    "authors": [
      "Batuhan Altundas",
      "Zheyuan Wang",
      "Joshua Bishop",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.13293",
    "title": "Sifer: Overcoming simplicity bias in deep networks using a feature sieve",
    "abstract": "Simplicity bias is the concerning tendency of deep networks to over-depend on simple, weakly predictive features, to the exclusion of stronger, more complex features. This causes biased, incorrect model predictions in many real-world applications, exacerbated by incomplete training data containing spurious feature-label correlations. We propose a direct, interventional method for addressing simplicity bias in DNNs, which we call the feature sieve. We aim to automatically identify and suppress easily-computable spurious features in lower layers of the network, thereby allowing the higher network levels to extract and utilize richer, more meaningful representations. We provide concrete evidence of this differential suppression & enhancement of relevant features on both controlled datasets and real-world images, and report substantial gains on many real-world debiasing benchmarks (11.4% relative gain on Imagenet-A; 3.2% on BAR, etc). Crucially, we outperform many baselines that incorporate knowledge about known spurious or biased attributes, despite our method not using any such information. We believe that our feature sieve work opens up exciting new research directions in automated adversarial feature extraction & representation learning for deep networks. ",
    "url": "https://arxiv.org/abs/2301.13293",
    "authors": [
      "Rishabh Tiwari",
      "Pradeep Shenoy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13330",
    "title": "Efficient and Effective Methods for Mixed Precision Neural Network  Quantization for Faster, Energy-efficient Inference",
    "abstract": "For effective and efficient deep neural network inference, it is desirable to achieve state-of-the-art accuracy with the simplest networks requiring the least computation, memory, and power. Quantizing networks to lower precision is a powerful technique for simplifying networks. It is generally desirable to quantize as aggressively as possible without incurring significant accuracy degradation. As each layer of a network may have different sensitivity to quantization, mixed precision quantization methods selectively tune the precision of individual layers of a network to achieve a minimum drop in task performance (e.g., accuracy). To estimate the impact of layer precision choice on task performance two methods are introduced: i) Entropy Approximation Guided Layer selection (EAGL) is fast and uses the entropy of the weight distribution, and ii) Accuracy-aware Layer Precision Selection (ALPS) is straightforward and relies on single epoch fine-tuning after layer precision reduction. Using EAGL and ALPS for layer precision selection, full-precision accuracy is recovered with a mix of 4-bit and 2-bit layers for ResNet-50 and ResNet-101 classification networks, demonstrating improved performance across the entire accuracy-throughput frontier, and equivalent performance for the PSPNet segmentation network in our own commensurate comparison over leading mixed precision layer selection techniques, while requiring orders of magnitude less compute time to reach a solution. ",
    "url": "https://arxiv.org/abs/2301.13330",
    "authors": [
      "Deepika Bablani",
      "Jeffrey L. Mckinstry",
      "Steven K. Esser",
      "Rathinakumar Appuswamy",
      "Dharmendra S. Modha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13331",
    "title": "Fast Resolution Agnostic Neural Techniques to Solve Partial Differential  Equations",
    "abstract": "Numerical approximations of partial differential equations (PDEs) are routinely employed to formulate the solution of physics, engineering and mathematical problems involving functions of several variables, such as the propagation of heat or sound, fluid flow, elasticity, electrostatics, electrodynamics, and more. While this has led to solving many complex phenomena, there are still significant limitations. Conventional approaches such as Finite Element Methods (FEMs) and Finite Differential Methods (FDMs) require considerable time and are computationally expensive. In contrast, machine learning-based methods such as neural networks are faster once trained, but tend to be restricted to a specific discretization. This article aims to provide a comprehensive summary of conventional methods and recent machine learning-based methods to approximate PDEs numerically. Furthermore, we highlight several key architectures centered around the neural operator, a novel and fast approach (1000x) to learning the solution operator of a PDE. We will note how these new computational approaches can bring immense advantages in tackling many problems in fundamental and applied physics. ",
    "url": "https://arxiv.org/abs/2301.13331",
    "authors": [
      "Hrishikesh Viswanath",
      "Md Ashiqur Rahman",
      "Abhijeet Vyas",
      "Andrey Shor",
      "Beatriz Medeiros",
      "Stephanie Hernandez",
      "Suhas Eswarappa Prameela",
      "Aniket Bera"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2301.13336",
    "title": "The Fair Value of Data Under Heterogeneous Privacy Constraints",
    "abstract": "Modern data aggregation often takes the form of a platform collecting data from a network of users. More than ever, these users are now requesting that the data they provide is protected with a guarantee of privacy. This has led to the study of optimal data acquisition frameworks, where the optimality criterion is typically the maximization of utility for the agent trying to acquire the data. This involves determining how to allocate payments to users for the purchase of their data at various privacy levels. The main goal of this paper is to characterize a fair amount to pay users for their data at a given privacy level. We propose an axiomatic definition of fairness, analogous to the celebrated Shapley value. Two concepts for fairness are introduced. The first treats the platform and users as members of a common coalition and provides a complete description of how to divide the utility among the platform and users. In the second concept, fairness is defined only among users, leading to a potential fairness-constrained mechanism design problem for the platform. We consider explicit examples involving private heterogeneous data and show how these notions of fairness can be applied. To the best of our knowledge, these are the first fairness concepts for data that explicitly consider privacy constraints. ",
    "url": "https://arxiv.org/abs/2301.13336",
    "authors": [
      "Justin Kang",
      "Ramtin Pedarsani",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2301.13340",
    "title": "Affinity Uncertainty-based Hard Negative Mining in Graph Contrastive  Learning",
    "abstract": "Hard negative mining has shown effective in enhancing self-supervised contrastive learning (CL) on diverse data types, including graph contrastive learning (GCL). Existing hardness-aware CL methods typically treat negative instances that are most similar to the anchor instance as hard negatives, which helps improve the CL performance, especially on image data. However, this approach often fails to identify the hard negatives but leads to many false negatives on graph data. This is mainly due to that the learned graph representations are not sufficiently discriminative due to over-smooth representations and/or non-i.i.d. issues in graph data. To tackle this problem, this paper proposes a novel approach that builds a discriminative model on collective affinity information (i.e, two sets of pairwise affinities between the negative instances and the anchor instance) to mine hard negatives in GCL. In particular, the proposed approach evaluates how confident/uncertain the discriminative model is about the affinity of each negative instance to an anchor instance to determine its hardness weight relative to the anchor instance. This uncertainty information is then incorporated into existing GCL loss functions via a weighting term to enhance their performance. The enhanced GCL is theoretically grounded that the resulting GCL loss is equivalent to a triplet loss with an adaptive margin being exponentially proportional to the learned uncertainty of each negative instance. Extensive experiments on 10 graph datasets show that our approach i) consistently enhances different state-of-the-art GCL methods in both graph and node classification tasks, and ii) significantly improves their robustness against adversarial attacks. ",
    "url": "https://arxiv.org/abs/2301.13340",
    "authors": [
      "Chaoxi Niu",
      "Guansong Pang",
      "Ling Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.13356",
    "title": "Inference Time Evidences of Adversarial Attacks for Forensic on  Transformers",
    "abstract": "Vision Transformers (ViTs) are becoming a very popular paradigm for vision tasks as they achieve state-of-the-art performance on image classification. However, although early works implied that this network structure had increased robustness against adversarial attacks, some works argue ViTs are still vulnerable. This paper presents our first attempt toward detecting adversarial attacks during inference time using the network's input and outputs as well as latent features. We design four quantifications (or derivatives) of input, output, and latent vectors of ViT-based models that provide a signature of the inference, which could be beneficial for the attack detection, and empirically study their behavior over clean samples and adversarial samples. The results demonstrate that the quantifications from input (images) and output (posterior probabilities) are promising for distinguishing clean and adversarial samples, while latent vectors offer less discriminative power, though they give some insights on how adversarial perturbations work. ",
    "url": "https://arxiv.org/abs/2301.13356",
    "authors": [
      "Hugo Lemarchant",
      "Liangzi Li",
      "Yiming Qian",
      "Yuta Nakashima",
      "Hajime Nagahara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13358",
    "title": "Hierarchical Disentangled Representation for Invertible Image Denoising  and Beyond",
    "abstract": "Image denoising is a typical ill-posed problem due to complex degradation. Leading methods based on normalizing flows have tried to solve this problem with an invertible transformation instead of a deterministic mapping. However, the implicit bijective mapping is not explored well. Inspired by a latent observation that noise tends to appear in the high-frequency part of the image, we propose a fully invertible denoising method that injects the idea of disentangled learning into a general invertible neural network to split noise from the high-frequency part. More specifically, we decompose the noisy image into clean low-frequency and hybrid high-frequency parts with an invertible transformation and then disentangle case-specific noise and high-frequency components in the latent space. In this way, denoising is made tractable by inversely merging noiseless low and high-frequency parts. Furthermore, we construct a flexible hierarchical disentangling framework, which aims to decompose most of the low-frequency image information while disentangling noise from the high-frequency part in a coarse-to-fine manner. Extensive experiments on real image denoising, JPEG compressed artifact removal, and medical low-dose CT image restoration have demonstrated that the proposed method achieves competing performance on both quantitative metrics and visual quality, with significantly less computational cost. ",
    "url": "https://arxiv.org/abs/2301.13358",
    "authors": [
      "Wenchao Du",
      "Hu Chen",
      "Yi Zhang",
      "H. Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.13359",
    "title": "IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing",
    "abstract": "Image anomaly detection (IAD) is an emerging and vital computer vision task in industrial manufacturing (IM). Recently many advanced algorithms have been published, but their performance deviates greatly. We realize that the lack of actual IM settings most probably hinders the development and usage of these methods in real-world applications. As far as we know, IAD methods are not evaluated systematically. As a result, this makes it difficult for researchers to analyze them because they are designed for different or special cases. To solve this problem, we first propose a uniform IM setting to assess how well these algorithms perform, which includes several aspects, i.e., various levels of supervision (unsupervised vs. semi-supervised), few-shot learning, continual learning, noisy labels, memory usage, and inference speed. Moreover, we skillfully build a comprehensive image anomaly detection benchmark (IM-IAD) that includes 16 algorithms on 7 mainstream datasets with uniform settings. Our extensive experiments (17,017 in total) provide in-depth insights for IAD algorithm redesign or selection under the IM setting. Next, the proposed benchmark IM-IAD gives challenges as well as directions for the future. To foster reproducibility and accessibility, the source code of IM-IAD is uploaded on the website, https://github.com/M-3LAB/IM-IAD. ",
    "url": "https://arxiv.org/abs/2301.13359",
    "authors": [
      "Guoyang Xie",
      "Jinbao Wang",
      "Jiaqi Liu",
      "Jiayi Lyu",
      "Yong Liu",
      "Chengjie Wang",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13360",
    "title": "Skeleton-based Human Action Recognition via Convolutional Neural  Networks (CNN)",
    "abstract": "Recently, there has been a remarkable increase in the interest towards skeleton-based action recognition within the research community, owing to its various advantageous features, including computational efficiency, representative features, and illumination invariance. Despite this, researchers continue to explore and investigate the most optimal way to represent human actions through skeleton representation and the extracted features. As a result, the growth and availability of human action recognition datasets have risen substantially. In addition, deep learning-based algorithms have gained widespread popularity due to the remarkable advancements in various computer vision tasks. Most state-of-the-art contributions in skeleton-based action recognition incorporate a Graph Neural Network (GCN) architecture for representing the human body and extracting features. Our research demonstrates that Convolutional Neural Networks (CNNs) can attain comparable results to GCN, provided that the proper training techniques, augmentations, and optimizers are applied. Our approach has been rigorously validated, and we have achieved a score of 95% on the NTU-60 dataset ",
    "url": "https://arxiv.org/abs/2301.13360",
    "authors": [
      "Ayman Ali",
      "Ekkasit Pinyoanuntapong",
      "Pu Wang",
      "Mohsen Dorodchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13370",
    "title": "On the Correctness of Automatic Differentiation for Neural Networks with  Machine-Representable Parameters",
    "abstract": "Recent work has shown that automatic differentiation over the reals is almost always correct in a mathematically precise sense. However, actual programs work with machine-representable numbers (e.g., floating-point numbers), not reals. In this paper, we study the correctness of automatic differentiation when the parameter space of a neural network consists solely of machine-representable numbers. For a neural network with bias parameters, we prove that automatic differentiation is correct at all parameters where the network is differentiable. In contrast, it is incorrect at all parameters where the network is non-differentiable, since it never informs non-differentiability. To better understand this non-differentiable set of parameters, we prove a tight bound on its size, which is linear in the number of non-differentiabilities in activation functions, and provide a simple necessary and sufficient condition for a parameter to be in this set. We further prove that automatic differentiation always computes a Clarke subderivative, even on the non-differentiable set. We also extend these results to neural networks possibly without bias parameters. ",
    "url": "https://arxiv.org/abs/2301.13370",
    "authors": [
      "Wonyeol Lee",
      "Sejun Park",
      "Alex Aiken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13372",
    "title": "Improving Open-Domain Dialogue Evaluation with a Causal Inference Model",
    "abstract": "Effective evaluation methods remain a significant challenge for research on open-domain conversational dialogue systems. Explicit satisfaction ratings can be elicited from users, but users often do not provide ratings when asked, and those they give can be highly subjective. Post-hoc ratings by experts are an alternative, but these can be both expensive and complex to collect. Here, we explore the creation of automated methods for predicting both expert and user ratings of open-domain dialogues. We compare four different approaches. First, we train a baseline model using an end-to-end transformer to predict ratings directly from the raw dialogue text. The other three methods are variants of a two-stage approach in which we first extract interpretable features at the turn level that capture, among other aspects, user dialogue behaviors indicating contradiction, repetition, disinterest, compliments, or criticism. We project these features to the dialogue level and train a dialogue-level MLP regression model, a dialogue-level LSTM, and a novel causal inference model called counterfactual-LSTM (CF-LSTM) to predict ratings. The proposed CF-LSTM is a sequential model over turn-level features which predicts ratings using multiple regressors depending on hypotheses derived from the turn-level features. As a causal inference model, CF-LSTM aims to learn the underlying causes of a specific event, such as a low rating. We also bin the user ratings and perform classification experiments with all four models. In evaluation experiments on conversational data from the Alexa Prize SocialBot, we show that the CF-LSTM achieves the best performance for predicting dialogue ratings and classification. ",
    "url": "https://arxiv.org/abs/2301.13372",
    "authors": [
      "Cat P. Le",
      "Luke Dai",
      "Michael Johnston",
      "Yang Liu",
      "Marilyn Walker",
      "Reza Ghanadan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13374",
    "title": "Enabling surrogate-assisted evolutionary reinforcement learning via  policy embedding",
    "abstract": "Evolutionary Reinforcement Learning (ERL) that applying Evolutionary Algorithms (EAs) to optimize the weight parameters of Deep Neural Network (DNN) based policies has been widely regarded as an alternative to traditional reinforcement learning methods. However, the evaluation of the iteratively generated population usually requires a large amount of computational time and can be prohibitively expensive, which may potentially restrict the applicability of ERL. Surrogate is often used to reduce the computational burden of evaluation in EAs. Unfortunately, in ERL, each individual of policy usually represents millions of weights parameters of DNN. This high-dimensional representation of policy has introduced a great challenge to the application of surrogates into ERL to speed up training. This paper proposes a PE-SAERL Framework to at the first time enable surrogate-assisted evolutionary reinforcement learning via policy embedding (PE). Empirical results on 5 Atari games show that the proposed method can perform more efficiently than the four state-of-the-art algorithms. The training process is accelerated up to 7x on tested games, comparing to its counterpart without the surrogate and PE. ",
    "url": "https://arxiv.org/abs/2301.13374",
    "authors": [
      "Lan Tang",
      "Xiaxi Li",
      "Jinyuan Zhang",
      "Guiying Li",
      "Peng Yang",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.13375",
    "title": "Optimal Transport Perturbations for Safe Reinforcement Learning with  Robustness Guarantees",
    "abstract": "Robustness and safety are critical for the trustworthy deployment of deep reinforcement learning in real-world decision making applications. In particular, we require algorithms that can guarantee robust, safe performance in the presence of general environment disturbances, while making limited assumptions on the data collection process during training. In this work, we propose a safe reinforcement learning framework with robustness guarantees through the use of an optimal transport cost uncertainty set. We provide an efficient, theoretically supported implementation based on Optimal Transport Perturbations, which can be applied in a completely offline fashion using only data collected in a nominal training environment. We demonstrate the robust, safe performance of our approach on a variety of continuous control tasks with safety constraints in the Real-World Reinforcement Learning Suite. ",
    "url": "https://arxiv.org/abs/2301.13375",
    "authors": [
      "James Queeney",
      "Erhan Can Ozcan",
      "Ioannis Ch. Paschalidis",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13376",
    "title": "Quantized Neural Networks for Low-Precision Accumulation with Guaranteed  Overflow Avoidance",
    "abstract": "We introduce a quantization-aware training algorithm that guarantees avoiding numerical overflow when reducing the precision of accumulators during inference. We leverage weight normalization as a means of constraining parameters during training using accumulator bit width bounds that we derive. We evaluate our algorithm across multiple quantized models that we train for different tasks, showing that our approach can reduce the precision of accumulators while maintaining model accuracy with respect to a floating-point baseline. We then show that this reduction translates to increased design efficiency for custom FPGA-based accelerators. Finally, we show that our algorithm not only constrains weights to fit into an accumulator of user-defined bit width, but also increases the sparsity and compressibility of the resulting weights. Across all of our benchmark models trained with 8-bit weights and activations, we observe that constraining the hidden layers of quantized neural networks to fit into 16-bit accumulators yields an average 98.2% sparsity with an estimated compression rate of 46.5x all while maintaining 99.2% of the floating-point performance. ",
    "url": "https://arxiv.org/abs/2301.13376",
    "authors": [
      "Ian Colbert",
      "Alessandro Pappalardo",
      "Jakoba Petri-Koenig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13380",
    "title": "Automated Time-frequency Domain Audio Crossfades using Graph Cuts",
    "abstract": "The problem of transitioning smoothly from one audio clip to another arises in many music consumption scenarios, especially as music consumption has moved from professionally curated and live-streamed radios to personal playback devices and services. we present the first steps toward a new method of automatically transitioning from one audio clip to another by discretizing the frequency spectrum into bins and then finding transition times for each bin. We phrase the problem as one of graph flow optimization; specifically min-cut/max-flow. ",
    "url": "https://arxiv.org/abs/2301.13380",
    "authors": [
      "Kyle Robinson",
      "Dan Brown"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2301.13392",
    "title": "Combinatorial Causal Bandits without Graph Skeleton",
    "abstract": "In combinatorial causal bandits (CCB), the learning agent chooses a subset of variables in each round to intervene and collects feedback from the observed variables to minimize expected regret or sample complexity. Previous works study this problem in both general causal models and binary generalized linear models (BGLMs). However, all of them require prior knowledge of causal graph structure. This paper studies the CCB problem without the graph structure on binary general causal models and BGLMs. We first provide an exponential lower bound of cumulative regrets for the CCB problem on general causal models. To overcome the exponentially large space of parameters, we then consider the CCB problem on BGLMs. We design a regret minimization algorithm for BGLMs even without the graph skeleton and show that it still achieves $O(\\sqrt{T}\\ln T)$ expected regret. This asymptotic regret is the same as the state-of-art algorithms relying on the graph structure. Moreover, we sacrifice the regret to $O(T^{\\frac{2}{3}}\\ln T)$ to remove the weight gap covered by the asymptotic notation. At last, we give some discussions and algorithms for pure exploration of the CCB problem without the graph structure. ",
    "url": "https://arxiv.org/abs/2301.13392",
    "authors": [
      "Shi Feng",
      "Nuoya Xiong",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13401",
    "title": "Classified as unknown: A novel Bayesian neural network",
    "abstract": "We establish estimations for the parameters of the output distribution for the softmax activation function using the probit function. As an application, we develop a new efficient Bayesian learning algorithm for fully connected neural networks, where training and predictions are performed within the Bayesian inference framework in closed-form. This approach allows sequential learning and requires no computationally expensive gradient calculation and Monte Carlo sampling. Our work generalizes the Bayesian algorithm for a single perceptron for binary classification in \\cite{H} to multi-layer perceptrons for multi-class classification. ",
    "url": "https://arxiv.org/abs/2301.13401",
    "authors": [
      "Tianbo Yang",
      "Tianshuo Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2301.13403",
    "title": "A Modular Multi-stage Lightweight Graph Transformer Network for Human  Pose and Shape Estimation from 2D Human Pose",
    "abstract": "In this research, we address the challenge faced by existing deep learning-based human mesh reconstruction methods in balancing accuracy and computational efficiency. These methods typically prioritize accuracy, resulting in large network sizes and excessive computational complexity, which may hinder their practical application in real-world scenarios, such as virtual reality systems. To address this issue, we introduce a modular multi-stage lightweight graph-based transformer network for human pose and shape estimation from 2D human pose, a pose-based human mesh reconstruction approach that prioritizes computational efficiency without sacrificing reconstruction accuracy. Our method consists of a 2D-to-3D lifter module that utilizes graph transformers to analyze structured and implicit joint correlations in 2D human poses, and a mesh regression module that combines the extracted pose features with a mesh template to produce the final human mesh parameters. ",
    "url": "https://arxiv.org/abs/2301.13403",
    "authors": [
      "Ayman Ali",
      "Ekkasit Pinyoanuntapong",
      "Pu Wang",
      "Mohsen Dorodchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13411",
    "title": "Few-Shot Object Detection via Variational Feature Aggregation",
    "abstract": "As few-shot object detectors are often trained with abundant base samples and fine-tuned on few-shot novel examples,the learned models are usually biased to base classes and sensitive to the variance of novel examples. To address this issue, we propose a meta-learning framework with two novel feature aggregation schemes. More precisely, we first present a Class-Agnostic Aggregation (CAA) method, where the query and support features can be aggregated regardless of their categories. The interactions between different classes encourage class-agnostic representations and reduce confusion between base and novel classes. Based on the CAA, we then propose a Variational Feature Aggregation (VFA) method, which encodes support examples into class-level support features for robust feature aggregation. We use a variational autoencoder to estimate class distributions and sample variational features from distributions that are more robust to the variance of support examples. Besides, we decouple classification and regression tasks so that VFA is performed on the classification branch without affecting object localization. Extensive experiments on PASCAL VOC and COCO demonstrate that our method significantly outperforms a strong baseline (up to 16\\%) and previous state-of-the-art methods (4\\% in average). Code will be available at: \\url{https://github.com/csuhan/VFA} ",
    "url": "https://arxiv.org/abs/2301.13411",
    "authors": [
      "Jiaming Han",
      "Yuqiang Ren",
      "Jian Ding",
      "Ke Yan",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13416",
    "title": "Structure Flow-Guided Network for Real Depth Super-Resolution",
    "abstract": "Real depth super-resolution (DSR), unlike synthetic settings, is a challenging task due to the structural distortion and the edge noise caused by the natural degradation in real-world low-resolution (LR) depth maps. These defeats result in significant structure inconsistency between the depth map and the RGB guidance, which potentially confuses the RGB-structure guidance and thereby degrades the DSR quality. In this paper, we propose a novel structure flow-guided DSR framework, where a cross-modality flow map is learned to guide the RGB-structure information transferring for precise depth upsampling. Specifically, our framework consists of a cross-modality flow-guided upsampling network (CFUNet) and a flow-enhanced pyramid edge attention network (PEANet). CFUNet contains a trilateral self-attention module combining both the geometric and semantic correlations for reliable cross-modality flow learning. Then, the learned flow maps are combined with the grid-sampling mechanism for coarse high-resolution (HR) depth prediction. PEANet targets at integrating the learned flow map as the edge attention into a pyramid network to hierarchically learn the edge-focused guidance feature for depth edge refinement. Extensive experiments on real and synthetic DSR datasets verify that our approach achieves excellent performance compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2301.13416",
    "authors": [
      "Jiayi Yuan",
      "Haobo Jiang",
      "Xiang Li",
      "Jianjun Qian",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13426",
    "title": "Discrete Search in Heterogeneous Integer Spaces for Automated Choice of  Parameters using Correct-by-Construction Methods",
    "abstract": "Discrete Search of integer spaces for tool parameter values provides a powerful methodology for modeling and finding a heuristically optimal parameter list for a given system. Current tools and implementations that exist focus primarily on homogeneous tool parameters, and the implementations for heterogeneous tool parameters is lacking. In this paper we introduce a correct-by-construction method of heterogeneous parameter reachability and validity search, and further outline the implementation as well as a demonstration using examples of heterogeneous systems that this tool can be used for. ",
    "url": "https://arxiv.org/abs/2301.13426",
    "authors": [
      "Omar Radwan",
      "Yilin Zhang",
      "Luca Geretti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.13428",
    "title": "Contrast and Clustering: Learning Neighborhood Pair Representation for  Source-free Domain Adaptation",
    "abstract": "Domain adaptation has attracted a great deal of attention in the machine learning community, but it requires access to source data, which often raises concerns about data privacy. We are thus motivated to address these issues and propose a simple yet efficient method. This work treats domain adaptation as an unsupervised clustering problem and trains the target model without access to the source data. Specifically, we propose a loss function called contrast and clustering (CaC), where a positive pair term pulls neighbors belonging to the same class together in the feature space to form clusters, while a negative pair term pushes samples of different classes apart. In addition, extended neighbors are taken into account by querying the nearest neighbor indexes in the memory bank to mine for more valuable negative pairs. Extensive experiments on three common benchmarks, VisDA, Office-Home and Office-31, demonstrate that our method achieves state-of-the-art performance. The code will be made publicly available at https://github.com/yukilulu/CaC. ",
    "url": "https://arxiv.org/abs/2301.13428",
    "authors": [
      "Yuqi Chen",
      "Xiangbin Zhu",
      "Yonggang Li",
      "Yingjian Li",
      "Yuanwang Wei",
      "Haojie Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13459",
    "title": "Learning Generalized Hybrid Proximity Representation for Image  Recognition",
    "abstract": "Recently, deep metric learning techniques received attention, as the learned distance representations are useful to capture the similarity relationship among samples and further improve the performance of various of supervised or unsupervised learning tasks. We propose a novel supervised metric learning method that can learn the distance metrics in both geometric and probabilistic space for image recognition. In contrast to the previous metric learning methods which usually focus on learning the distance metrics in Euclidean space, our proposed method is able to learn better distance representation in a hybrid approach. To achieve this, we proposed a Generalized Hybrid Metric Loss (GHM-Loss) to learn the general hybrid proximity features from the image data by controlling the trade-off between geometric proximity and probabilistic proximity. To evaluate the effectiveness of our method, we first provide theoretical derivations and proofs of the proposed loss function, then we perform extensive experiments on two public datasets to show the advantage of our method compared to other state-of-the-art metric learning methods. ",
    "url": "https://arxiv.org/abs/2301.13459",
    "authors": [
      "Zhiyuan Li",
      "Anca Ralescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13473",
    "title": "CRC-RL: A Novel Visual Feature Representation Architecture for  Unsupervised Reinforcement Learning",
    "abstract": "This paper addresses the problem of visual feature representation learning with an aim to improve the performance of end-to-end reinforcement learning (RL) models. Specifically, a novel architecture is proposed that uses a heterogeneous loss function, called CRC loss, to learn improved visual features which can then be used for policy learning in RL. The CRC-loss function is a combination of three individual loss functions, namely, contrastive, reconstruction and consistency loss. The feature representation is learned in parallel to the policy learning while sharing the weight updates through a Siamese Twin encoder model. This encoder model is augmented with a decoder network and a feature projection network to facilitate computation of the above loss components. Through empirical analysis involving latent feature visualization, an attempt is made to provide an insight into the role played by this loss function in learning new action-dependent features and how they are linked to the complexity of the problems being solved. The proposed architecture, called CRC-RL, is shown to outperform the existing state-of-the-art methods on the challenging Deep mind control suite environments by a significant margin thereby creating a new benchmark in this field. ",
    "url": "https://arxiv.org/abs/2301.13473",
    "authors": [
      "Darshita Jain",
      "Anima Majumder",
      "Samrat Dutta",
      "Swagat Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.13487",
    "title": "Adversarial Training of Self-supervised Monocular Depth Estimation  against Physical-World Attacks",
    "abstract": "Monocular Depth Estimation (MDE) is a critical component in applications such as autonomous driving. There are various attacks against MDE networks. These attacks, especially the physical ones, pose a great threat to the security of such systems. Traditional adversarial training method requires ground-truth labels hence cannot be directly applied to self-supervised MDE that does not have ground-truth depth. Some self-supervised model hardening techniques (e.g., contrastive learning) ignore the domain knowledge of MDE and can hardly achieve optimal performance. In this work, we propose a novel adversarial training method for self-supervised MDE models based on view synthesis without using ground-truth depth. We improve adversarial robustness against physical-world attacks using L0-norm-bounded perturbation in training. We compare our method with supervised learning based and contrastive learning based methods that are tailored for MDE. Results on two representative MDE networks show that we achieve better robustness against various adversarial attacks with nearly no benign performance degradation. ",
    "url": "https://arxiv.org/abs/2301.13487",
    "authors": [
      "Zhiyuan Cheng",
      "James Liang",
      "Guanhong Tao",
      "Dongfang Liu",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13492",
    "title": "Company-as-Tribe: Company Financial Risk Assessment on Tribe-Style Graph  with Hierarchical Graph Neural Networks",
    "abstract": "Company financial risk is ubiquitous and early risk assessment for listed companies can avoid considerable losses. Traditional methods mainly focus on the financial statements of companies and lack the complex relationships among them. However, the financial statements are often biased and lagged, making it difficult to identify risks accurately and timely. To address the challenges, we redefine the problem as \\textbf{company financial risk assessment on tribe-style graph} by taking each listed company and its shareholders as a tribe and leveraging financial news to build inter-tribe connections. Such tribe-style graphs present different patterns to distinguish risky companies from normal ones. However, most nodes in the tribe-style graph lack attributes, making it difficult to directly adopt existing graph learning methods (e.g., Graph Neural Networks(GNNs)). In this paper, we propose a novel Hierarchical Graph Neural Network (TH-GNN) for Tribe-style graphs via two levels, with the first level to encode the structure pattern of the tribes with contrastive learning, and the second level to diffuse information based on the inter-tribe relations, achieving effective and efficient risk assessment. Extensive experiments on the real-world company dataset show that our method achieves significant improvements on financial risk assessment over previous competing methods. Also, the extensive ablation studies and visualization comprehensively show the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2301.13492",
    "authors": [
      "Wendong Bi",
      "Bingbing Xu",
      "Xiaoqian Sun",
      "Zidong Wang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13507",
    "title": "An Analysis of Classification Approaches for Hit Song Prediction using  Engineered Metadata Features with Lyrics and Audio Features",
    "abstract": "Hit song prediction, one of the emerging fields in music information retrieval (MIR), remains a considerable challenge. Being able to understand what makes a given song a hit is clearly beneficial to the whole music industry. Previous approaches to hit song prediction have focused on using audio features of a record. This study aims to improve the prediction result of the top 10 hits among Billboard Hot 100 songs using more alternative metadata, including song audio features provided by Spotify, song lyrics, and novel metadata-based features (title topic, popularity continuity and genre class). Five machine learning approaches are applied, including: k-nearest neighbours, Naive Bayes, Random Forest, Logistic Regression and Multilayer Perceptron. Our results show that Random Forest (RF) and Logistic Regression (LR) with all features (including novel features, song audio features and lyrics features) outperforms other models, achieving 89.1% and 87.2% accuracy, and 0.91 and 0.93 AUC, respectively. Our findings also demonstrate the utility of our novel music metadata features, which contributed most to the models' discriminative performance. ",
    "url": "https://arxiv.org/abs/2301.13507",
    "authors": [
      "Mengyisong Zhao",
      "Morgan Harvey",
      "David Cameron",
      "Frank Hopfgartner",
      "Valerie J. Gillet"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2301.13513",
    "title": "Privacy Preserving Ultra-Short-term Wind Power Prediction Based on  Secure Multi Party Computation",
    "abstract": "Mining the spatial and temporal correlation of wind farm output data is beneficial for enhancing the precision of ultra-short-term wind power prediction. However, if the wind farms are owned by separate entities, they may be reluctant to share their data directly due to privacy concerns as well as business management regulation policies. Although cryptographic approaches have been designed to protect privacy in the process of data sharing, it is still a challenging problem to encrypt the original data while extracting the nonlinear relationship among multiple wind farms in the machine learning process. This paper presents pwXGBoost, a technique based on the machine learning tree model and secure multi-party computation (SMPC) that can successfully extract complicated relationships while preserving data privacy. A maximum mean discrepancy (MMD) based scheme is proposed to effectively choose adjacent candidate wind farms to participate in the collaborative model training, therefore improving the accuracy and reducing the burden of data acquisition. The proposed method was evaluated on real world data collected from a cluster of wind farms in Inner Mongolia, China, demonstrating that it is capable of achieving considerable efficiency and performance improvements while preserving privacy ",
    "url": "https://arxiv.org/abs/2301.13513",
    "authors": [
      "Hang Fan",
      "Xiaoyu Fan",
      "Tianyi Hao",
      "Wei Wei",
      "Kun Chen",
      "Guosai Wang",
      "Xiaofeng Jia",
      "Yidong Li",
      "Wei Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.13516",
    "title": "Recurrences reveal shared causal drivers of complex time series",
    "abstract": "Many experimental time series measurements share an unobserved causal driver. Examples include genes targeted by transcription factors, ocean flows influenced by large-scale atmospheric currents, and motor circuits steered by descending neurons. Reliably inferring this unseen driving force is necessary to understand the intermittent nature of top-down control schemes in diverse biological and engineered systems. Here, we introduce a new unsupervised learning algorithm that uses recurrences in time series measurements to gradually reconstruct an unobserved driving signal. Drawing on the mathematical theory of skew-product dynamical systems, we identify recurrence events shared across response time series, which implicitly define a recurrence graph with glass-like structure. As the amount or quality of observed data improves, this recurrence graph undergoes a percolation transition manifesting as weak ergodicity breaking for random walks on the induced landscape -- revealing the shared driver's dynamics, even in the presence of strongly corrupted or noisy measurements. Across several thousand random dynamical systems, we empirically quantify the dependence of reconstruction accuracy on the rate of information transfer from a chaotic driver to the response systems, and we find that effective reconstruction proceeds through gradual approximation of the driver's dominant unstable periodic orbits. Through extensive benchmarks against classical and neural-network-based signal processing techniques, we demonstrate our method's strong ability to extract causal driving signals from diverse real-world datasets spanning neuroscience, genomics, fluid dynamics, and physiology. ",
    "url": "https://arxiv.org/abs/2301.13516",
    "authors": [
      "William Gilpin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2301.13527",
    "title": "Real-Time Outlier Detection with Dynamic Process Limits",
    "abstract": "Anomaly detection methods are part of the systems where rare events may endanger an operation's profitability, safety, and environmental aspects. Although many state-of-the-art anomaly detection methods were developed to date, their deployment is limited to the operation conditions present during the model training. Online anomaly detection brings the capability to adapt to data drifts and change points that may not be represented during model development resulting in prolonged service life. This paper proposes an online anomaly detection algorithm for existing real-time infrastructures where low-latency detection is required and novel patterns in data occur unpredictably. The online inverse cumulative distribution-based approach is introduced to eliminate common problems of offline anomaly detectors, meanwhile providing dynamic process limits to normal operation. The benefit of the proposed method is the ease of use, fast computation, and deployability as shown in two case studies of real microgrid operation data. ",
    "url": "https://arxiv.org/abs/2301.13527",
    "authors": [
      "Marek Wadinger",
      "Michal Kvasnica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13536",
    "title": "Low Complexity Adaptive Machine Learning Approaches for End-to-End  Latency Prediction",
    "abstract": "Software Defined Networks have opened the door to statistical and AI-based techniques to improve efficiency of networking. Especially to ensure a certain Quality of Service (QoS) for specific applications by routing packets with awareness on content nature (VoIP, video, files, etc.) and its needs (latency, bandwidth, etc.) to use efficiently resources of a network. Monitoring and predicting various Key Performance Indicators (KPIs) at any level may handle such problems while preserving network bandwidth. The question addressed in this work is the design of efficient, low-cost adaptive algorithms for KPI estimation, monitoring and prediction. We focus on end-to-end latency prediction, for which we illustrate our approaches and results on data obtained from a public generator provided after the recent international challenge on GNN [12]. In this paper, we improve our previously proposed low-cost estimators [6] by adding the adaptive dimension, and show that the performances are minimally modified while gaining the ability to track varying networks. ",
    "url": "https://arxiv.org/abs/2301.13536",
    "authors": [
      "Pierre Larrenie",
      "Jean-Fran\u00e7ois Bercher",
      "Olivier Venard",
      "Iyad Lahsen-Cherif"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13541",
    "title": "Singular Value Approximation and Reducing Directed to Undirected Graph  Sparsification",
    "abstract": "In this paper, we introduce a new, spectral notion of approximation between directed graphs, which we call Singular Value (SV) approximation. SV-approximation is stronger than previous notions of spectral approximation considered in the literature, including spectral approximation of Laplacians for undirected graphs (Spielman Teng STOC 2004), standard approximation for directed graphs (Cohen et. al. STOC 2007), and unit-circle approximation for directed graphs (Ahmadinejad et. al. FOCS 2020). Moreover, SV approximation enjoys several useful properties not known to be possessed by previous notions of approximation, such as being preserved under products of random-walk matrices and with matrices of bounded norm. Notably, we show that there is a simple black-box reduction from SV-sparsifying Eulerian directed graphs to SV-sparsifying undirected graphs. With this reduction in hand, we provide a nearly linear-time algorithm for SV-sparsifying undirected and hence also Eulerian directed graphs. This also yields the first nearly linear-time algorithm for unit-circle-sparsifying Eulerian directed graphs. In addition, we give a nearly linear-time algorithm for SV-sparsifying (and UC-sparsifying) random-walk polynomials of Eulerian directed graphs with second normalized singular value bounded away from $1$ by $1/\\text{poly}(n)$. Finally, we show that a simple repeated-squaring and sparsification algorithm for solving Laplacian systems, introduced by (Peng Spielman STOC 2014) for undirected graphs, also works for Eulerian digraphs whose random-walk matrix is normal (i.e. unitarily diagonalizable), if we use SV-sparsification at each step. Prior Laplacian solvers for Eulerian digraphs are significantly more complicated. ",
    "url": "https://arxiv.org/abs/2301.13541",
    "authors": [
      "AmirMahdi Ahmadinejad",
      "John Peebles",
      "Edward Pyne",
      "Aaron Sidford",
      "Salil Vadhan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2301.13545",
    "title": "Holistic Graph-based Motion Prediction",
    "abstract": "Motion prediction for automated vehicles in complex environments is a difficult task that is to be mastered when automated vehicles are to be used in arbitrary situations. Many factors influence the future motion of traffic participants starting with traffic rules and reaching from the interaction between each other to personal habits of human drivers. Therefore we present a novel approach for a graph-based prediction based on a heterogeneous holistic graph representation that combines temporal information, properties and relations between traffic participants as well as relations with static elements like the road network. The information are encoded through different types of nodes and edges that both are enriched with arbitrary features. We evaluated the approach on the INTERACTION and the Argoverse dataset and conducted an informative ablation study to demonstrate the benefit of different types of information for the motion prediction quality. ",
    "url": "https://arxiv.org/abs/2301.13545",
    "authors": [
      "Daniel Grimm",
      "Philip Sch\u00f6rner",
      "Moritz Dre\u00dfler",
      "J.-Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13549",
    "title": "Review of methods for automatic cerebral microbleeds detection",
    "abstract": "Cerebral microbleeds detection is an important and challenging task. With the gaining popularity of the MRI, the ability to detect cerebral microbleeds also raises. Unfortunately, for radiologists, it is a time-consuming and laborious procedure. For this reason, various solutions to automate this process have been proposed for several years, but none of them is currently used in medical practice. In this context, the need to systematize the existing knowledge and best practices has been recognized as a factor facilitating the imminent synthesis of a real CMBs detection system practically applicable in medicine. To the best of our knowledge, all available publications regarding automatic cerebral microbleeds detection have been gathered, described, and assessed in this paper in order to distinguish the current research state and provide a starting point for future studies. ",
    "url": "https://arxiv.org/abs/2301.13549",
    "authors": [
      "Maria Ferlin",
      "Zuzanna Klawikowska",
      "Micha\u0142 Grochowski",
      "Ma\u0142gorzata Grzywi\u0144ska",
      "Edyta Szurowska"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.13565",
    "title": "Learning Against Distributional Uncertainty: On the Trade-off Between  Robustness and Specificity",
    "abstract": "Trustworthy machine learning aims at combating distributional uncertainties in training data distributions compared to population distributions. Typical treatment frameworks include the Bayesian approach, (min-max) distributionally robust optimization (DRO), and regularization. However, two issues have to be raised: 1) All these methods are biased estimators of the true optimal cost; 2) the prior distribution in the Bayesian method, the radius of the distributional ball in the DRO method, and the regularizer in the regularization method are difficult to specify. This paper studies a new framework that unifies the three approaches and that addresses the two challenges mentioned above. The asymptotic properties (e.g., consistency and asymptotic normalities), non-asymptotic properties (e.g., unbiasedness and generalization error bound), and a Monte--Carlo-based solution method of the proposed model are studied. The new model reveals the trade-off between the robustness to the unseen data and the specificity to the training data. ",
    "url": "https://arxiv.org/abs/2301.13565",
    "authors": [
      "Shixiong Wang",
      "Haowei Wang",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13576",
    "title": "Sport Task: Fine Grained Action Detection and Classification of Table  Tennis Strokes from Videos for MediaEval 2022",
    "abstract": "Sports video analysis is a widespread research topic. Its applications are very diverse, like events detection during a match, video summary, or fine-grained movement analysis of athletes. As part of the MediaEval 2022 benchmarking initiative, this task aims at detecting and classifying subtle movements from sport videos. We focus on recordings of table tennis matches. Conducted since 2019, this task provides a classification challenge from untrimmed videos recorded under natural conditions with known temporal boundaries for each stroke. Since 2021, the task also provides a stroke detection challenge from unannotated, untrimmed videos. This year, the training, validation, and test sets are enhanced to ensure that all strokes are represented in each dataset. The dataset is now similar to the one used in [1, 2]. This research is intended to build tools for coaches and athletes who want to further evaluate their sport performances. ",
    "url": "https://arxiv.org/abs/2301.13576",
    "authors": [
      "Pierre-Etienne Martin",
      "Jordan Calandre",
      "Boris Mansencal",
      "Jenny Benois-Pineau",
      "Renaud P\u00e9teri",
      "Laurent Mascarilla",
      "Julien Morlier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2301.13577",
    "title": "DRAINCLoG: Detecting Rogue Accounts with Illegally-obtained NFTs using  Classifiers Learned on Graphs",
    "abstract": "As Non-Fungible Tokens (NFTs) continue to grow in popularity, NFT users have become targets of phishing attacks by cybercriminals, called NFT drainers. Over the last year, \\$100 million worth of NFTs were stolen by drainers, and their presence remains as a serious threat to the NFT trading space. Since NFTs are different from cryptocurrencies, existing work on detecting Ethereum phishers is unsuitable to detect NFT drainers. Moreover, no work has yet comprehensively investigated the behaviors of drainers in the NFT ecosystem. In this paper, we present the first study on trading behavior of NFT drainers and present the first dedicated NFT drainer detection system. We extract data of 83M NFT transactions from the Ethereum blockchain and collect 742 drainer accounts from five sources. We find drainers have significantly different transaction context and social context compared to regular users. With the insights gained from our analysis, we design an automatic drainer detection system, DRAINCLoG, that uses graph neural networks to capture the complex relationships in the NFT ecosystem. Our model effectively captures NFT transaction contexts and social contexts using an NFT-User graph and a User graph, respectively. Evaluated on real-world NFT transaction data, we prove the model's effectiveness and robustness. ",
    "url": "https://arxiv.org/abs/2301.13577",
    "authors": [
      "Hanna Kim",
      "Jian Cui",
      "Eugene Jang",
      "Chanhee Lee",
      "Yongjae Lee",
      "Jin-Woo Chung",
      "Seungwon Shin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.13589",
    "title": "Policy Gradient for s-Rectangular Robust Markov Decision Processes",
    "abstract": "We present a novel robust policy gradient method (RPG) for s-rectangular robust Markov Decision Processes (MDPs). We are the first to derive the adversarial kernel in a closed form and demonstrate that it is a one-rank perturbation of the nominal kernel. This allows us to derive an RPG that is similar to the one used in non-robust MDPs, except with a robust Q-value function and an additional correction term. Both robust Q-values and correction terms are efficiently computable, thus the time complexity of our method matches that of non-robust MDPs, which is significantly faster compared to existing black box methods. ",
    "url": "https://arxiv.org/abs/2301.13589",
    "authors": [
      "Navdeep Kumar",
      "Esther Derman",
      "Matthieu Geist",
      "Kfir Levy",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13592",
    "title": "Priors are Powerful: Improving a Transformer for Multi-camera 3D  Detection with 2D Priors",
    "abstract": "Transfomer-based approaches advance the recent development of multi-camera 3D detection both in academia and industry. In a vanilla transformer architecture, queries are randomly initialised and optimised for the whole dataset, without considering the differences among input frames. In this work, we propose to leverage the predictions from an image backbone, which is often highly optimised for 2D tasks, as priors to the transformer part of a 3D detection network. The method works by (1). augmenting image feature maps with 2D priors, (2). sampling query locations via ray-casting along 2D box centroids, as well as (3). initialising query features with object-level image features. Experimental results shows that 2D priors not only help the model converge faster, but also largely improve the baseline approach by up to 12% in terms of average precision. ",
    "url": "https://arxiv.org/abs/2301.13592",
    "authors": [
      "Di Feng",
      "Francesco Ferroni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.13598",
    "title": "Economic Predictive Control with Periodic Horizon for Water Distribution  Networks",
    "abstract": "This paper deals with the control of pumps in large-scale water distribution networks with the aim of minimizing economic costs while satisfying operational constraints. Finding a control algorithm in combination with a model that can be applied in real-time is a challenging problem due to the nonlinearities presented by the pipes and the network sizes. We propose a predictive control algorithm with a periodic horizon. The method provides a way for the economic operation of large water networks with a small linear model. Economic Predictive control with a periodic horizon and a terminal state constraint is constructed to keep the state trajectories close to an optimal periodic trajectory. Barrier terms are also included in the cost function to prevent constraint violations. The proposed method is tested on the EPANET implementation of the water network of a medium size Danish town (Randers) and shown to perform as intended under varying conditions. ",
    "url": "https://arxiv.org/abs/2301.13598",
    "authors": [
      "Mirhan \u00dcrkmez",
      "Carsten Kalles\u00f8e",
      "Jan Dimon Bendtsen",
      "John Leth"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.13613",
    "title": "Geometry-based approximation of waves in complex domains",
    "abstract": "We consider wave propagation problems over 2-dimensional domains with piecewise-linear boundaries, possibly including scatterers. Under the assumption that the initial conditions and forcing terms are radially symmetric and compactly supported (which is common in applications), we propose an approximation of the propagating wave as the sum of some special nonlinear space-time functions: each term in this sum identifies a particular ray, modeling the result of a single reflection or diffraction effect. We describe an algorithm for identifying such rays automatically, based on the domain geometry. To showcase our proposed method, we present several numerical examples, such as waves scattering off wedges and waves propagating through a room in presence of obstacles. ",
    "url": "https://arxiv.org/abs/2301.13613",
    "authors": [
      "Davide Pradovera",
      "Monica Nonino",
      "Ilaria Perugia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.13616",
    "title": "Anti-Exploration by Random Network Distillation",
    "abstract": "Despite the success of Random Network Distillation (RND) in various domains, it was shown as not discriminative enough to be used as an uncertainty estimator for penalizing out-of-distribution actions in offline reinforcement learning. In this paper, we revisit these results and show that, with a naive choice of conditioning for the RND prior, it becomes infeasible for the actor to effectively minimize the anti-exploration bonus and discriminativity is not an issue. We show that this limitation can be avoided with conditioning based on Feature-wise Linear Modulation (FiLM), resulting in a simple and efficient ensemble-free algorithm based on Soft Actor-Critic. We evaluate it on the D4RL benchmark, showing that it is capable of achieving performance comparable to ensemble-based methods and outperforming ensemble-free approaches by a wide margin. ",
    "url": "https://arxiv.org/abs/2301.13616",
    "authors": [
      "Alexander Nikulin",
      "Vladislav Kurenkov",
      "Denis Tarasov",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.13629",
    "title": "DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting with Denoising  Diffusion Models",
    "abstract": "Spatio-temporal graph neural networks (STGNN) have emerged as the dominant model for spatio-temporal graph (STG) forecasting. Despite their success, they fail to model intrinsic uncertainties within STG data, which cripples their practicality in downstream tasks for decision-making. To this end, this paper focuses on probabilistic STG forecasting, which is challenging due to the difficulty in modeling uncertainties and complex ST dependencies. In this study, we present the first attempt to generalize the popular denoising diffusion probabilistic models to STGs, leading to a novel non-autoregressive framework called DiffSTG, along with the first denoising network UGnet for STG in the framework. Our approach combines the spatio-temporal learning capabilities of STGNNs with the uncertainty measurements of diffusion models. Extensive experiments validate that DiffSTG reduces the Continuous Ranked Probability Score (CRPS) by 4%-14%, and Root Mean Squared Error (RMSE) by 2%-7% over existing methods on three real-world datasets. ",
    "url": "https://arxiv.org/abs/2301.13629",
    "authors": [
      "Haomin Wen",
      "Youfang Lin",
      "Yutong Xia",
      "Huaiyu Wan",
      "Roger Zimmermann",
      "Yuxuan Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13630",
    "title": "Enhancing NOMA Networks via Reconfigurable Multi-Functional Surface",
    "abstract": "By flexibly manipulating the radio propagation environment, reconfigurable intelligent surface (RIS) is a promising technique for future wireless communications. However, the single-side coverage and double-fading attenuation faced by conventional RISs largely restrict their applications. To address this issue, we propose a novel concept of multi-functional RIS (MF-RIS), which provides reflection, transmission, and amplification simultaneously for the incident signal. With the aim of enhancing the performance of a non-orthogonal multiple-access (NOMA) downlink multiuser network, we deploy an MF-RIS to maximize the sum rate by jointly optimizing the active beamforming and MF-RIS coefficients. Then, an alternating optimization algorithm is proposed to solve the formulated non-convex problem by exploiting successive convex approximation and penalty-based method. Numerical results show that the proposed MF-RIS outperforms conventional RISs under different settings. ",
    "url": "https://arxiv.org/abs/2301.13630",
    "authors": [
      "Ailing Zheng",
      "Wanli Ni",
      "Wen Wang",
      "Hui Tian"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.13642",
    "title": "An Efficient Solution to s-Rectangular Robust Markov Decision Processes",
    "abstract": "We present an efficient robust value iteration for \\texttt{s}-rectangular robust Markov Decision Processes (MDPs) with a time complexity comparable to standard (non-robust) MDPs which is significantly faster than any existing method. We do so by deriving the optimal robust Bellman operator in concrete forms using our $L_p$ water filling lemma. We unveil the exact form of the optimal policies, which turn out to be novel threshold policies with the probability of playing an action proportional to its advantage. ",
    "url": "https://arxiv.org/abs/2301.13642",
    "authors": [
      "Navdeep Kumar",
      "Kfir Levy",
      "Kaixin Wang",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.13644",
    "title": "Exploring QSAR Models for Activity-Cliff Prediction",
    "abstract": "Pairs of similar compounds that only differ by a small structural modification but exhibit a large difference in their binding affinity for a given target are known as activity cliffs (ACs). It has been hypothesised that quantitative structure-activity relationship (QSAR) models struggle to predict ACs and that ACs thus form a major source of prediction error. However, a study to explore the AC-prediction power of modern QSAR methods and its relationship to general QSAR-prediction performance is lacking. We systematically construct nine distinct QSAR models by combining three molecular representation methods (extended-connectivity fingerprints, physicochemical-descriptor vectors and graph isomorphism networks) with three regression techniques (random forests, k-nearest neighbours and multilayer perceptrons); we then use each resulting model to classify pairs of similar compounds as ACs or non-ACs and to predict the activities of individual molecules in three case studies: dopamine receptor D2, factor Xa, and SARS-CoV-2 main protease. We observe low AC-sensitivity amongst the tested models when the activities of both compounds are unknown, but a substantial increase in AC-sensitivity when the actual activity of one of the compounds is given. Graph isomorphism features are found to be competitive with or superior to classical molecular representations for AC-classification and can thus be employed as baseline AC-prediction models or simple compound-optimisation tools. For general QSAR-prediction, however, extended-connectivity fingerprints still consistently deliver the best performance. Our results provide strong support for the hypothesis that indeed QSAR methods frequently fail to predict ACs. We propose twin-network training for deep learning models as a potential future pathway to increase AC-sensitivity and thus overall QSAR performance. ",
    "url": "https://arxiv.org/abs/2301.13644",
    "authors": [
      "Markus Dablander",
      "Thierry Hanser",
      "Renaud Lambiotte",
      "Garrett M. Morris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13659",
    "title": "Spyker: High-performance Library for Spiking Deep Neural Networks",
    "abstract": "Spiking neural networks (SNNs) have been recently brought to light due to their promising capabilities. SNNs simulate the brain with higher biological plausibility compared to previous generations of neural networks. Learning with fewer samples and consuming less power are among the key features of these networks. However, the theoretical advantages of SNNs have not been seen in practice due to the slowness of simulation tools and the impracticality of the proposed network structures. In this work, we implement a high-performance library named Spyker using C++/CUDA from scratch that outperforms its predecessor. Several SNNs are implemented in this work with different learning rules (spike-timing-dependent plasticity and reinforcement learning) using Spyker that achieve significantly better runtimes, to prove the practicality of the library in the simulation of large-scale networks. To our knowledge, no such tools have been developed to simulate large-scale spiking neural networks with high performance using a modular structure. Furthermore, a comparison of the represented stimuli extracted from Spyker to recorded electrophysiology data is performed to demonstrate the applicability of SNNs in describing the underlying neural mechanisms of the brain functions. The aim of this library is to take a significant step toward uncovering the true potential of the brain computations using SNNs. ",
    "url": "https://arxiv.org/abs/2301.13659",
    "authors": [
      "Shahriar Rezghi Shirsavar",
      "Mohammad-Reza A. Dehaqani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2301.13686",
    "title": "Detecting Unknown Encrypted Malicious Traffic in Real Time via Flow  Interaction Graph Analysis",
    "abstract": "In this paper, we propose HyperVision, a realtime unsupervised machine learning (ML) based malicious traffic detection system. Particularly, HyperVision is able to detect unknown patterns of encrypted malicious traffic by utilizing a compact inmemory graph built upon the traffic patterns. The graph captures flow interaction patterns represented by the graph structural features, instead of the features of specific known attacks. We develop an unsupervised graph learning method to detect abnormal interaction patterns by analyzing the connectivity, sparsity, and statistical features of the graph, which allows HyperVision to detect various encrypted attack traffic without requiring any labeled datasets of known attacks. Moreover, we establish an information theory model to demonstrate that the information preserved by the graph approaches the ideal theoretical bound. We show the performance of HyperVision by real-world experiments with 92 datasets including 48 attacks with encrypted malicious traffic. The experimental results illustrate that HyperVision achieves at least 0.92 AUC and 0.86 F1, which significantly outperform the state-of-the-art methods. In particular, more than 50% attacks in our experiments can evade all these methods. Moreover, HyperVision achieves at least 80.6 Gb/s detection throughput with the average detection latency of 0.83s. ",
    "url": "https://arxiv.org/abs/2301.13686",
    "authors": [
      "Chuanpu Fu",
      "Qi Li",
      "Ke Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.13687",
    "title": "A Proof that Using Crossover Can Guarantee Exponential Speed-Ups in  Evolutionary Multi-Objective Optimisation",
    "abstract": "Evolutionary algorithms are popular algorithms for multiobjective optimisation (also called Pareto optimisation) as they use a population to store trade-offs between different objectives. Despite their popularity, the theoretical foundation of multiobjective evolutionary optimisation (EMO) is still in its early development. Fundamental questions such as the benefits of the crossover operator are still not fully understood. We provide a theoretical analysis of well-known EMO algorithms GSEMO and NSGA-II to showcase the possible advantages of crossover. We propose a class of problems on which these EMO algorithms using crossover find the Pareto set in expected polynomial time. In sharp contrast, they and many other EMO algorithms without crossover require exponential time to even find a single Pareto-optimal point. This is the first example of an exponential performance gap through the use of crossover for the widely used NSGA-II algorithm. ",
    "url": "https://arxiv.org/abs/2301.13687",
    "authors": [
      "Duc-Cuong Dang",
      "Andre Opris",
      "Bahare Salehi",
      "Dirk Sudholt"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.13691",
    "title": "Time Series Forecasting via Semi-Asymmetric Convolutional Architecture  with Global Atrous Sliding Window",
    "abstract": "The proposed method in this paper is designed to address the problem of time series forecasting. Although some exquisitely designed models achieve excellent prediction performances, how to extract more useful information and make accurate predictions is still an open issue. Most of modern models only focus on a short range of information, which are fatal for problems such as time series forecasting which needs to capture long-term information characteristics. As a result, the main concern of this work is to further mine relationship between local and global information contained in time series to produce more precise predictions. In this paper, to satisfactorily realize the purpose, we make three main contributions that are experimentally verified to have performance advantages. Firstly, original time series is transformed into difference sequence which serves as input to the proposed model. And secondly, we introduce the global atrous sliding window into the forecasting model which references the concept of fuzzy time series to associate relevant global information with temporal data within a time period and utilizes central-bidirectional atrous algorithm to capture underlying-related features to ensure validity and consistency of captured data. Thirdly, a variation of widely-used asymmetric convolution which is called semi-asymmetric convolution is devised to more flexibly extract relationships in adjacent elements and corresponding associated global features with adjustable ranges of convolution on vertical and horizontal directions. The proposed model in this paper achieves state-of-the-art on most of time series datasets provided compared with competitive modern models. ",
    "url": "https://arxiv.org/abs/2301.13691",
    "authors": [
      "Yuanpeng He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13694",
    "title": "Are Defenses for Graph Neural Networks Robust?",
    "abstract": "A cursory reading of the literature suggests that we have made a lot of progress in designing effective adversarial defenses for Graph Neural Networks (GNNs). Yet, the standard methodology has a serious flaw - virtually all of the defenses are evaluated against non-adaptive attacks leading to overly optimistic robustness estimates. We perform a thorough robustness analysis of 7 of the most popular defenses spanning the entire spectrum of strategies, i.e., aimed at improving the graph, the architecture, or the training. The results are sobering - most defenses show no or only marginal improvement compared to an undefended baseline. We advocate using custom adaptive attacks as a gold standard and we outline the lessons we learned from successfully designing such attacks. Moreover, our diverse collection of perturbed graphs forms a (black-box) unit test offering a first glance at a model's robustness. ",
    "url": "https://arxiv.org/abs/2301.13694",
    "authors": [
      "Felix Mujkanovic",
      "Simon Geisler",
      "Stephan G\u00fcnnemann",
      "Aleksandar Bojchevski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13714",
    "title": "Recursive Neural Networks with Bottlenecks Diagnose  (Non-)Compositionality",
    "abstract": "A recent line of work in NLP focuses on the (dis)ability of models to generalise compositionally for artificial languages. However, when considering natural language tasks, the data involved is not strictly, or locally, compositional. Quantifying the compositionality of data is a challenging task, which has been investigated primarily for short utterances. We use recursive neural models (Tree-LSTMs) with bottlenecks that limit the transfer of information between nodes. We illustrate that comparing data's representations in models with and without the bottleneck can be used to produce a compositionality metric. The procedure is applied to the evaluation of arithmetic expressions using synthetic data, and sentiment classification using natural language data. We demonstrate that compression through a bottleneck impacts non-compositional examples disproportionately and then use the bottleneck compositionality metric (BCM) to distinguish compositional from non-compositional samples, yielding a compositionality ranking over a dataset. ",
    "url": "https://arxiv.org/abs/2301.13714",
    "authors": [
      "Verna Dankers",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.13729",
    "title": "Low-rank LQR Optimal Control Design over Wireless Communication Networks",
    "abstract": "This paper considers a LQR optimal control design problem for distributed control systems with multi-agents. To control large-scale distributed systems such as smart-grid and multi-agent robotic systems over wireless communication networks, it is desired to design a feedback controller by considering various constraints on communication such as limited power, limited energy, or limited communication bandwidth, etc. In this paper, we focus on the reduction of communication energy in an LQR optimal control design problem on wireless communication networks. By considering the characteristic of wireless communication, i.e., Radio Frequency (RF) signal can spread in all directions in a broadcast way, we formulate a low-rank LQR optimal control model to reduce the communication energy in the distributed feedback control system. To solve the problem, we propose an Alternating Direction Method of Multipliers (ADMM) based algorithm. Through various numerical experiments, we demonstrate that a feedback controller designed using low-rank structure can outperform the previous work on sparse LQR optimal control design, which focuses on reducing the number of communication links in a network, in terms of energy consumption, system stability margin against noise and error in communication. ",
    "url": "https://arxiv.org/abs/2301.13729",
    "authors": [
      "Myung Cho",
      "Abdallah Abdallah",
      "Mohammad Rasouli"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.13733",
    "title": "A Bayesian Generative Adversarial Network (GAN) to Generate Synthetic  Time-Series Data, Application in Combined Sewer Flow Prediction",
    "abstract": "Despite various breakthroughs in machine learning and data analysis techniques for improving smart operation and management of urban water infrastructures, some key limitations obstruct this progress. Among these shortcomings, the absence of freely available data due to data privacy or high costs of data gathering and the nonexistence of adequate rare or extreme events in the available data plays a crucial role. Here, Generative Adversarial Networks (GANs) can help overcome these challenges. In machine learning, generative models are a class of methods capable of learning data distribution to generate artificial data. In this study, we developed a GAN model to generate synthetic time series to balance our limited recorded time series data and improve the accuracy of a data-driven model for combined sewer flow prediction. We considered the sewer system of a small town in Germany as the test case. Precipitation and inflow to the storage tanks are used for the Data-Driven model development. The aim is to predict the flow using precipitation data and examine the impact of data augmentation using synthetic data in model performance. Results show that GAN can successfully generate synthetic time series from real data distribution, which helps more accurate peak flow prediction. However, the model without data augmentation works better for dry weather prediction. Therefore, an ensemble model is suggested to combine the advantages of both models. ",
    "url": "https://arxiv.org/abs/2301.13733",
    "authors": [
      "Amin E. Bakhshipour",
      "Alireza Koochali",
      "Ulrich Dittmer",
      "Ali Haghighi",
      "Sheraz Ahmad",
      "Andreas Dengel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13735",
    "title": "Flipper games for monadically stable graph classes",
    "abstract": "A class of graphs $\\mathscr{C}$ is monadically stable if for any unary expansion $\\widehat{\\mathscr{C}}$ of $\\mathscr{C}$, one cannot interpret, in first-order logic, arbitrarily long linear orders in graphs from $\\widehat{\\mathscr{C}}$. It is known that nowhere dense graph classes are monadically stable; these encompass most of the studied concepts of sparsity in graphs, including graph classes that exclude a fixed topological minor. On the other hand, monadic stability is a property expressed in purely model-theoretic terms and hence it is also suited for capturing structure in dense graphs. For several years, it has been suspected that one can create a structure theory for monadically stable graph classes that mirrors the theory of nowhere dense graph classes in the dense setting. In this work we provide a step in this direction by giving a characterization of monadic stability through the Flipper game: a game on a graph played by Flipper, who in each round can complement the edge relation between any pair of vertex subsets, and Connector, who in each round localizes the game to a ball of bounded radius. This is an analog of the Splitter game, which characterizes nowhere dense classes of graphs (Grohe, Kreutzer, and Siebertz, J.ACM'17). We give two different proofs of our main result. The first proof uses tools from model theory, and it exposes an additional property of monadically stable graph classes that is close in spirit to definability of types. Also, as a byproduct, we give an alternative proof of the recent result of Braunfeld and Laskowski (arXiv 2209.05120) that monadic stability for graph classes coincides with existential monadic stability. The second proof relies on the recently introduced notion of flip-wideness (Dreier, M\\\"ahlmann, Siebertz, and Toru\\'nczyk, arXiv 2206.13765) and provides an efficient algorithm to compute Flipper's moves in a winning strategy. ",
    "url": "https://arxiv.org/abs/2301.13735",
    "authors": [
      "Jakub Gajarsk\u00fd",
      "Nikolas M\u00e4hlmann",
      "Rose McCarty",
      "Pierre Ohlmann",
      "Micha\u0142 Pilipczuk",
      "Wojciech Przybyszewski",
      "Sebastian Siebertz",
      "Marek Soko\u0142owski",
      "Szymon Toru\u0144czyk"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2301.13753",
    "title": "Dynamic Scheduled Sampling with Imitation Loss for Neural Text  Generation",
    "abstract": "State-of-the-art neural text generation models are typically trained to maximize the likelihood of each token in the ground-truth sequence conditioned on the previous target tokens. However, during inference, the model needs to make a prediction conditioned on the tokens generated by itself. This train-test discrepancy is referred to as exposure bias. Scheduled sampling is a curriculum learning strategy that gradually exposes the model to its own predictions during training to mitigate this bias. Most of the proposed approaches design a scheduler based on training steps, which generally requires careful tuning depending on the training setup. In this work, we introduce Dynamic Scheduled Sampling with Imitation Loss (DySI), which maintains the schedule based solely on the training time accuracy, while enhancing the curriculum learning by introducing an imitation loss, which attempts to make the behavior of the decoder indistinguishable from the behavior of a teacher-forced decoder. DySI is universally applicable across training setups with minimal tuning. Extensive experiments and analysis show that DySI not only achieves notable improvements on standard machine translation benchmarks, but also significantly improves the robustness of other text generation models. ",
    "url": "https://arxiv.org/abs/2301.13753",
    "authors": [
      "Xiang Lin",
      "Prathyusha Jwalapuram",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.13755",
    "title": "Retrosynthetic Planning with Dual Value Networks",
    "abstract": "Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes while retaining single-step accuracy. Desirable routes should be both synthesizable and of low cost. We propose an online training algorithm, called Planning with Dual Value Networks (PDVN), in which two value networks predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm improves the search success rate of existing multi-step planners (e.g., increasing the success rate from 85.79% to 98.95% for Retro*, and reducing the number of model calls by half while solving 99.47% molecules for RetroGraph). Furthermore, PDVN finds shorter synthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for Retro*, and from 5.63 to 4.78 for RetroGraph). ",
    "url": "https://arxiv.org/abs/2301.13755",
    "authors": [
      "Guoqing Liu",
      "Di Xue",
      "Shufang Xie",
      "Yingce Xia",
      "Austin Tripp",
      "Krzysztof Maziarz",
      "Marwin Segler",
      "Tao Qin",
      "Zongzhang Zhang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13760",
    "title": "EC-CFI: Control-Flow Integrity via Code Encryption Counteracting Fault  Attacks",
    "abstract": "Fault attacks enable adversaries to manipulate the control-flow of security-critical applications. By inducing targeted faults into the CPU, the software's call graph can be escaped and the control-flow can be redirected to arbitrary functions inside the program. To protect the control-flow from these attacks, dedicated fault control-flow integrity (CFI) countermeasures are commonly deployed. However, these schemes either have high detection latencies or require intrusive hardware changes. In this paper, we present EC-CFI, a software-based cryptographically enforced CFI scheme with no detection latency utilizing hardware features of recent Intel platforms. Our EC-CFI prototype is designed to prevent an adversary from escaping the program's call graph using faults by encrypting each function with a different key before execution. At runtime, the instrumented program dynamically derives the decryption key, ensuring that the code only can be successfully decrypted when the program follows the intended call graph. To enable this level of protection on Intel commodity systems, we introduce extended page table (EPT) aliasing allowing us to achieve function-granular encryption by combing Intel's TME-MK and virtualization technology. We open-source our custom LLVM-based toolchain automatically protecting arbitrary programs with EC-CFI. Furthermore, we evaluate our EPT aliasing approach with the SPEC CPU2017 and Embench-IoT benchmarks and discuss and evaluate potential TME-MK hardware changes minimizing runtime overheads. ",
    "url": "https://arxiv.org/abs/2301.13760",
    "authors": [
      "Pascal Nasahl",
      "Salmin Sultana",
      "Hans Liljestrand",
      "Karanvir Grewal",
      "Michael LeMay",
      "David M. Durham",
      "David Schrammel",
      "Stefan Mangard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.13764",
    "title": "Semi-Supervised Classification with Graph Convolutional Kernel Machines",
    "abstract": "We present a deep Graph Convolutional Kernel Machine (GCKM) for semi-supervised node classification in graphs. First, we introduce an unsupervised kernel machine propagating the node features in a one-hop neighbourhood. Then, we specify a semi-supervised classification kernel machine through the lens of the Fenchel-Young inequality. The deep graph convolutional kernel machine is obtained by stacking multiple shallow kernel machines. After showing that unsupervised and semi-supervised layer corresponds to an eigenvalue problem and a linear system on the aggregated node features, respectively, we derive an efficient end-to-end training algorithm in the dual variables. Numerical experiments demonstrate that our approach is competitive with state-of-the-art graph neural networks for homophilious and heterophilious benchmark datasets. Notably, GCKM achieves superior performance when very few labels are available. ",
    "url": "https://arxiv.org/abs/2301.13764",
    "authors": [
      "Sonny Achten",
      "Francesco Tonin",
      "Panagiotis Patrinos",
      "Johan A. K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13770",
    "title": "Energy-Conserving Neural Network for Turbulence Closure Modeling",
    "abstract": "In turbulence modeling, and more particularly in the Large-Eddy Simulation (LES) framework, we are concerned with finding closure models that represent the effect of the unresolved subgrid-scales on the resolved scales. Recent approaches gravitate towards machine learning techniques to construct such models. However, the stability of machine-learned closure models and their abidance by physical structure (e.g. symmetries, conservation laws) are still open problems. To tackle both issues, we take the `discretize first, filter next' approach, in which we apply a spatial averaging filter to existing energy-conserving (fine-grid) discretizations. The main novelty is that we extend the system of equations describing the filtered solution with a set of equations that describe the evolution of (a compressed version of) the energy of the subgrid-scales. Having an estimate of this energy, we can use the concept of energy conservation and derive stability. The compressed variables are determined via a data-driven technique in such a way that the energy of the subgrid-scales is matched. For the extended system, the closure model should be energy-conserving, and a new skew-symmetric convolutional neural network architecture is proposed that has this property. Stability is thus guaranteed, independent of the actual weights and biases of the network. Importantly, our framework allows energy exchange between resolved scales and compressed subgrid scales and thus enables backscatter. To model dissipative systems (e.g. viscous flows), the framework is extended with a diffusive component. The introduced neural network architecture is constructed such that it also satisfies momentum conservation. We apply the new methodology to both the viscous Burgers' equation and the Korteweg-De Vries equation in 1D and show superior stability properties when compared to a vanilla convolutional neural network. ",
    "url": "https://arxiv.org/abs/2301.13770",
    "authors": [
      "Toby van Gastelen",
      "Wouter Edeling",
      "Benjamin Sanderse"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2301.13799",
    "title": "Partitioning Distributed Compute Jobs with Reinforcement Learning and  Graph Neural Networks",
    "abstract": "From natural language processing to genome sequencing, large-scale machine learning models are bringing advances to a broad range of fields. Many of these models are too large to be trained on a single machine, and instead must be distributed across multiple devices. This has motivated the research of new compute and network systems capable of handling such tasks. In particular, recent work has focused on developing management schemes which decide how to allocate distributed resources such that some overall objective, such as minimising the job completion time (JCT), is optimised. However, such studies omit explicit consideration of how much a job should be distributed, usually assuming that maximum distribution is desirable. In this work, we show that maximum parallelisation is sub-optimal in relation to user-critical metrics such as throughput and blocking rate. To address this, we propose PAC-ML (partitioning for asynchronous computing with machine learning). PAC-ML leverages a graph neural network and reinforcement learning to learn how much to partition computation graphs such that the number of jobs which meet arbitrary user-defined JCT requirements is maximised. In experiments with five real deep learning computation graphs on a recently proposed optical architecture across four user-defined JCT requirement distributions, we demonstrate PAC-ML achieving up to 56.2% lower blocking rates in dynamic job arrival settings than the canonical maximum parallelisation strategy used by most prior works. ",
    "url": "https://arxiv.org/abs/2301.13799",
    "authors": [
      "Christopher W. F. Parsonson",
      "Zacharaya Shabka",
      "Alessandro Ottino",
      "Georgios Zervas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.13801",
    "title": "Cultural Differences in Friendship Network Behaviors: A Snapchat Case  Study",
    "abstract": "Culture shapes people's behavior, both online and offline. Surprisingly, there is sparse research on how cultural context affects network formation and content consumption on social media. We analyzed the friendship networks and dyadic relations between content producers and consumers across 73 countries through a cultural lens in a closed-network setting. Closed networks allow for intimate bonds and self-expression, providing a natural setting to study cultural differences in behavior. We studied three theoretical frameworks of culture - individualism, relational mobility, and tightness. We found that friendship networks formed across different cultures differ in egocentricity, meaning the connectedness between a user's friends. Individualism, mobility, and looseness also significantly negatively impact how tie strength affects content consumption. Our findings show how culture affects social media behavior, and we outline how researchers can incorporate this in their work. Our work has implications for content recommendations and can improve content engagement. ",
    "url": "https://arxiv.org/abs/2301.13801",
    "authors": [
      "Agrima Seth",
      "Jiyin Cao",
      "Xiaolin Shi",
      "Ron Dotsch",
      "Yozen Liu",
      "Maarten W. Bos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2301.13812",
    "title": "Learning Roles with Emergent Social Value Orientations",
    "abstract": "Social dilemmas can be considered situations where individual rationality leads to collective irrationality. The multi-agent reinforcement learning community has leveraged ideas from social science, such as social value orientations (SVO), to solve social dilemmas in complex cooperative tasks. In this paper, by first introducing the typical \"division of labor or roles\" mechanism in human society, we provide a promising solution for intertemporal social dilemmas (ISD) with SVOs. A novel learning framework, called Learning Roles with Emergent SVOs (RESVO), is proposed to transform the learning of roles into the social value orientation emergence, which is symmetrically solved by endowing agents with altruism to share rewards with other agents. An SVO-based role embedding space is then constructed by individual conditioning policies on roles with a novel rank regularizer and mutual information maximizer. Experiments show that RESVO achieves a stable division of labor and cooperation in ISDs with different complexity. ",
    "url": "https://arxiv.org/abs/2301.13812",
    "authors": [
      "Wenhao Li",
      "Xiangfeng Wang",
      "Bo Jin",
      "Jingyi Lu",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2301.13816",
    "title": "Execution-based Code Generation using Deep Reinforcement Learning",
    "abstract": "The utilization of programming language (PL) models, pretrained on large-scale code corpora, as a means of automating software engineering processes has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting specific sequence-level features of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that combines pretrained PL models with Proximal Policy Optimization (PPO) deep reinforcement learning and employs execution feedback as the external source of knowledge into the model optimization. PPOCoder is transferable across different code generation tasks and PLs. Extensive experiments on three code generation tasks demonstrate the effectiveness of our proposed approach compared to SOTA methods, improving the success rate of compilation and functional correctness over different PLs. Our code can be found at https://github.com/reddy-lab-code-research/PPOCoder . ",
    "url": "https://arxiv.org/abs/2301.13816",
    "authors": [
      "Parshin Shojaee",
      "Aneesh Jain",
      "Sindhu Tipirneni",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2301.13817",
    "title": "Patch Gradient Descent: Training Neural Networks on Very Large Images",
    "abstract": "Traditional CNN models are trained and tested on relatively low resolution images (<300 px), and cannot be directly operated on large-scale images due to compute and memory constraints. We propose Patch Gradient Descent (PatchGD), an effective learning strategy that allows to train the existing CNN architectures on large-scale images in an end-to-end manner. PatchGD is based on the hypothesis that instead of performing gradient-based updates on an entire image at once, it should be possible to achieve a good solution by performing model updates on only small parts of the image at a time, ensuring that the majority of it is covered over the course of iterations. PatchGD thus extensively enjoys better memory and compute efficiency when training models on large scale images. PatchGD is thoroughly evaluated on two datasets - PANDA and UltraMNIST with ResNet50 and MobileNetV2 models under different memory constraints. Our evaluation clearly shows that PatchGD is much more stable and efficient than the standard gradient-descent method in handling large images, and especially when the compute memory is limited. ",
    "url": "https://arxiv.org/abs/2301.13817",
    "authors": [
      "Deepak K. Gupta",
      "Gowreesh Mago",
      "Arnav Chavan",
      "Dilip K. Prasad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13820",
    "title": "Explaining Large Language Model-Based Neural Semantic Parsers (Student  Abstract)",
    "abstract": "While large language models (LLMs) have demonstrated strong capability in structured prediction tasks such as semantic parsing, few amounts of research have explored the underlying mechanisms of their success. Our work studies different methods for explaining an LLM-based semantic parser and qualitatively discusses the explained model behaviors, hoping to inspire future research toward better understanding them. ",
    "url": "https://arxiv.org/abs/2301.13820",
    "authors": [
      "Daking Rai",
      "Yilun Zhou",
      "Bailin Wang",
      "Ziyu Yao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13821",
    "title": "Complete Neural Networks for Euclidean Graphs",
    "abstract": "We propose a 2-WL-like geometric graph isomorphism test and prove it is complete when applied to Euclidean Graphs in $\\mathbb{R}^3$. We then use recent results on multiset embeddings to devise an efficient geometric GNN model with equivalent separation power. We verify empirically that our GNN model is able to separate particularly challenging synthetic examples, and demonstrate its usefulness for a chemical property prediction problem. ",
    "url": "https://arxiv.org/abs/2301.13821",
    "authors": [
      "Snir Hordan",
      "Tal Amir",
      "Steven J. Gortler",
      "Nadav Dym"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13830",
    "title": "Age of Information With Non-Poisson Updates in Cache-Updating Networks",
    "abstract": "We study age of information in multi-hop multi-cast cache-enabled networks where the inter-update times on the links are not necessarily exponentially distributed. We focus on the set of non-arithmetic distributions for inter-update times, which includes continuous probability distributions as a subset. We first characterize instantaneous age of information at each node for arbitrary networks. We then explicate the recursive equations for instantaneous age of information in multi-hop networks and derive closed form expressions for expected age of information at an end-user. We show that expected age in multi-hop networks exhibits an additive structure. Further, we show that the expected age at each user is directly proportional to the variance of inter-update times at all links between a user and the source. We expect the analysis in this work to help alleviate the over-dependence on Poisson processes for future work in age of information. ",
    "url": "https://arxiv.org/abs/2301.13830",
    "authors": [
      "Priyanka Kaswan",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.13845",
    "title": "Interpreting Robustness Proofs of Deep Neural Networks",
    "abstract": "In recent years numerous methods have been developed to formally verify the robustness of deep neural networks (DNNs). Though the proposed techniques are effective in providing mathematical guarantees about the DNNs behavior, it is not clear whether the proofs generated by these methods are human-interpretable. In this paper, we bridge this gap by developing new concepts, algorithms, and representations to generate human understandable interpretations of the proofs. Leveraging the proposed method, we show that the robustness proofs of standard DNNs rely on spurious input features, while the proofs of DNNs trained to be provably robust filter out even the semantically meaningful features. The proofs for the DNNs combining adversarial and provably robust training are the most effective at selectively filtering out spurious features as well as relying on human-understandable input features. ",
    "url": "https://arxiv.org/abs/2301.13845",
    "authors": [
      "Debangshu Banerjee",
      "Avaljot Singh",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13853",
    "title": "LAGAN: Deep Semi-Supervised Linguistic-Anthropology Classification with  Conditional Generative Adversarial Neural Network",
    "abstract": "Education is a right of all, however, every individual is different than others. Teachers in post-communism era discover inherent individualism to equally train all towards job market of fourth industrial revolution. We can consider scenario of ethnic minority education in academic practices. Ethnic minority group has grown in their own culture and would prefer to be taught in their native way. We have formulated such linguistic anthropology(how people learn)based engagement as semi-supervised problem. Then, we have developed an conditional deep generative adversarial network algorithm namely LA-GAN to classify linguistic ethnographic features in student engagement. Theoretical justification proves the objective, regularization and loss function of our semi-supervised adversarial model. Survey questions are prepared to reach some form of assumptions about z-generation and ethnic minority group, whose learning style, learning approach and preference are our main area of interest. ",
    "url": "https://arxiv.org/abs/2301.13853",
    "authors": [
      "Rossi Kamal",
      "Zuzana Kubincova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2301.13860",
    "title": "Zero-Memory Graph Exploration with Unknown Inports",
    "abstract": "We study a very restrictive graph exploration problem. In our model, an agent without persistent memory is placed on a vertex of a graph and only sees the adjacent vertices. The goal is to visit every vertex of the graph, return to the start vertex, and terminate. The agent does not know through which edge it entered a vertex. The agent may color the current vertex and can see the colors of the neighboring vertices in an arbitrary order. The agent may not recolor a vertex. We investigate the number of colors necessary and sufficient to explore all graphs. We prove that n-1 colors are necessary and sufficient for exploration in general, 3 colors are necessary and sufficient if only trees are to be explored, and min(2k-3,n-1) colors are necessary and min(2k-1,n-1) colors are sufficient on graphs of size n and circumference $k$, where the circumference is the length of a longest cycle. This only holds if an algorithm has to explore all graphs and not merely certain graph classes. We give an example for a graph class where each graph can be explored with 4 colors, although the graphs have maximal circumference. Moreover, we prove that recoloring vertices is very powerful by designing an algorithm with recoloring that uses only 7 colors and explores all graphs. ",
    "url": "https://arxiv.org/abs/2301.13860",
    "authors": [
      "Hans-Joachim B\u00f6ckenhauer",
      "Fabian Frei",
      "Walter Unger",
      "David Wehner"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.13862",
    "title": "Salient Conditional Diffusion for Defending Against Backdoor Attacks",
    "abstract": "We propose a novel algorithm, Salient Conditional Diffusion (Sancdifi), a state-of-the-art defense against backdoor attacks. Sancdifi uses a denoising diffusion probabilistic model (DDPM) to degrade an image with noise and then recover said image using the learned reverse diffusion. Critically, we compute saliency map-based masks to condition our diffusion, allowing for stronger diffusion on the most salient pixels by the DDPM. As a result, Sancdifi is highly effective at diffusing out triggers in data poisoned by backdoor attacks. At the same time, it reliably recovers salient features when applied to clean data. This performance is achieved without requiring access to the model parameters of the Trojan network, meaning Sancdifi operates as a black-box defense. ",
    "url": "https://arxiv.org/abs/2301.13862",
    "authors": [
      "Brandon B. May",
      "N. Joseph Tatro",
      "Piyush Kumar",
      "Nathan Shnidman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13869",
    "title": "Reverse engineering adversarial attacks with fingerprints from  adversarial examples",
    "abstract": "In spite of intense research efforts, deep neural networks remain vulnerable to adversarial examples: an input that forces the network to confidently produce incorrect outputs. Adversarial examples are typically generated by an attack algorithm that optimizes a perturbation added to a benign input. Many such algorithms have been developed. If it were possible to reverse engineer attack algorithms from adversarial examples, this could deter bad actors because of the possibility of attribution. Here we formulate reverse engineering as a supervised learning problem where the goal is to assign an adversarial example to a class that represents the algorithm and parameters used. To our knowledge it has not been previously shown whether this is even possible. We first test whether we can classify the perturbations added to images by attacks on undefended single-label image classification models. Taking a ``fight fire with fire'' approach, we leverage the sensitivity of deep neural networks to adversarial examples, training them to classify these perturbations. On a 17-class dataset (5 attacks, 4 bounded with 4 epsilon values each), we achieve an accuracy of 99.4\\% with a ResNet50 model trained on the perturbations. We then ask whether we can perform this task without access to the perturbations, obtaining an estimate of them with signal processing algorithms, an approach we call ``fingerprinting''. We find the JPEG algorithm serves as a simple yet effective fingerprinter (85.05\\% accuracy), providing a strong baseline for future work. We discuss how our approach can be extended to attack agnostic, learnable fingerprints, and to open-world scenarios with unknown attacks. ",
    "url": "https://arxiv.org/abs/2301.13869",
    "authors": [
      "David Aaron Nicholson",
      "Vincent Emanuele"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13262",
    "title": "Temporal Consistency Loss for Physics-Informed Neural Networks",
    "abstract": "Physics-informed neural networks (PINNs) have been widely used to solve partial differential equations in a forward and inverse manner using deep neural networks. However, training these networks can be challenging for multiscale problems. While statistical methods can be employed to scale the regression loss on data, it is generally challenging to scale the loss terms for equations. This paper proposes a method for scaling the mean squared loss terms in the objective function used to train PINNs. Instead of using automatic differentiation to calculate the temporal derivative, we use backward Euler discretization. This provides us with a scaling term for the equations. In this work, we consider the two and three-dimensional Navier-Stokes equations and determine the kinematic viscosity using the spatio-temporal data on the velocity and pressure fields. We first consider numerical datasets to test our method. We test the sensitivity of our method to the time step size, the number of timesteps, noise in the data, and spatial resolution. Finally, we use the velocity field obtained using Particle Image Velocimetry (PIV) experiments to generate a reference pressure field. We then test our framework using the velocity and reference pressure field. ",
    "url": "https://arxiv.org/abs/2301.13262",
    "authors": [
      "Sukirt Thakur",
      "Maziar Raissi",
      "Harsa Mitra",
      "Arezoo Ardekani"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13341",
    "title": "Neural Target Speech Extraction: An Overview",
    "abstract": "Humans can listen to a target speaker even in challenging acoustic conditions that have noise, reverberation, and interfering speakers. This phenomenon is known as the cocktail-party effect. For decades, researchers have focused on approaching the listening ability of humans. One critical issue is handling interfering speakers because the target and non-target speech signals share similar characteristics, complicating their discrimination. Target speech/speaker extraction (TSE) isolates the speech signal of a target speaker from a mixture of several speakers with or without noises and reverberations using clues that identify the speaker in the mixture. Such clues might be a spatial clue indicating the direction of the target speaker, a video of the speaker's lips, or a pre-recorded enrollment utterance from which their voice characteristics can be derived. TSE is an emerging field of research that has received increased attention in recent years because it offers a practical approach to the cocktail-party problem and involves such aspects of signal processing as audio, visual, array processing, and deep learning. This paper focuses on recent neural-based approaches and presents an in-depth overview of TSE. We guide readers through the different major approaches, emphasizing the similarities among frameworks and discussing potential future directions. ",
    "url": "https://arxiv.org/abs/2301.13341",
    "authors": [
      "Katerina Zmolikova",
      "Marc Delcroix",
      "Tsubasa Ochiai",
      "Keisuke Kinoshita",
      "Jan \u010cernock\u00fd",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2301.13366",
    "title": "CaraNet: Context Axial Reverse Attention Network for Segmentation of  Small Medical Objects",
    "abstract": "Segmenting medical images accurately and reliably is important for disease diagnosis and treatment. It is a challenging task because of the wide variety of objects' sizes, shapes, and scanning modalities. Recently, many convolutional neural networks (CNN) have been designed for segmentation tasks and achieved great success. Few studies, however, have fully considered the sizes of objects, and thus most demonstrate poor performance for small objects segmentation. This can have a significant impact on the early detection of diseases. This paper proposes a Context Axial Reverse Attention Network (CaraNet) to improve the segmentation performance on small objects compared with several recent state-of-the-art models. CaraNet applies axial reserve attention (ARA) and channel-wise feature pyramid (CFP) module to dig feature information of small medical object. And we evaluate our model by six different measurement metrics. We test our CaraNet on brain tumor (BraTS 2018) and polyp (Kvasir-SEG, CVC-ColonDB, CVC-ClinicDB, CVC-300, and ETIS-LaribPolypDB) segmentation datasets. Our CaraNet achieves the top-rank mean Dice segmentation accuracy, and results show a distinct advantage of CaraNet in the segmentation of small medical objects. ",
    "url": "https://arxiv.org/abs/2301.13366",
    "authors": [
      "Ange Lou",
      "Shuyue Guan",
      "Murray Loew"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13368",
    "title": "Misspecification-robust Sequential Neural Likelihood",
    "abstract": "Simulation-based inference (SBI) techniques are now an essential tool for the parameter estimation of mechanistic and simulatable models with intractable likelihoods. Statistical approaches to SBI such as approximate Bayesian computation and Bayesian synthetic likelihood have been well studied in the well specified and misspecified settings. However, most implementations are inefficient in that many model simulations are wasted. Neural approaches such as sequential neural likelihood (SNL) have been developed that exploit all model simulations to build a surrogate of the likelihood function. However, SNL approaches have been shown to perform poorly under model misspecification. In this paper, we develop a new method for SNL that is robust to model misspecification and can identify areas where the model is deficient. We demonstrate the usefulness of the new approach on several illustrative examples. ",
    "url": "https://arxiv.org/abs/2301.13368",
    "authors": [
      "Ryan P. Kelly",
      "David J. Nott",
      "David T. Frazier",
      "David J. Warne",
      "Chris Drovandi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13486",
    "title": "Robust Linear Regression: Gradient-descent, Early-stopping, and Beyond",
    "abstract": "In this work we study the robustness to adversarial attacks, of early-stopping strategies on gradient-descent (GD) methods for linear regression. More precisely, we show that early-stopped GD is optimally robust (up to an absolute constant) against Euclidean-norm adversarial attacks. However, we show that this strategy can be arbitrarily sub-optimal in the case of general Mahalanobis attacks. This observation is compatible with recent findings in the case of classification~\\cite{Vardi2022GradientMP} that show that GD provably converges to non-robust models. To alleviate this issue, we propose to apply instead a GD scheme on a transformation of the data adapted to the attack. This data transformation amounts to apply feature-depending learning rates and we show that this modified GD is able to handle any Mahalanobis attack, as well as more general attacks under some conditions. Unfortunately, choosing such adapted transformations can be hard for general attacks. To the rescue, we design a simple and tractable estimator whose adversarial risk is optimal up to within a multiplicative constant of 1.1124 in the population regime, and works for any norm. ",
    "url": "https://arxiv.org/abs/2301.13486",
    "authors": [
      "Meyer Scetbon",
      "Elvis Dohmatob"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13532",
    "title": "Population-wise Labeling of Sulcal Graphs using Multi-graph Matching",
    "abstract": "Population-wise matching of the cortical fold is necessary to identify biomarkers of neurological or psychiatric disorders. The difficulty comes from the massive interindividual variations in the morphology and spatial organization of the folds. This task is challenging at both methodological and conceptual levels. In the widely used registration-based techniques, these variations are considered as noise and the matching of folds is only implicit. Alternative approaches are based on the extraction and explicit identification of the cortical folds. In particular, representing cortical folding patterns as graphs of sulcal basins-termed sulcal graphs-enables to formalize the task as a graph-matching problem. In this paper, we propose to address the problem of sulcal graph matching directly at the population level using multi-graph matching techniques. First, we motivate the relevance of multi-graph matching framework in this context. We then introduce a procedure to generate populations of artificial sulcal graphs, which allows us benchmarking several state of the art multi-graph matching methods. Our results on both artificial and real data demonstrate the effectiveness of multi-graph matching techniques to obtain a population-wise consistent labeling of cortical folds at the sulcal basins level. ",
    "url": "https://arxiv.org/abs/2301.13532",
    "authors": [
      "Rohit Yadav",
      "Fran\u00e7ois-Xavier Dup\u00e9",
      "S. Takerkart",
      "Guillaume Auzias"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13557",
    "title": "New bounds and constructions for neighbor-locating colorings of graphs",
    "abstract": "A proper $k$-coloring of a graph $G$ is a \\emph{neighbor-locating $k$-coloring} if for each pair of vertices in the same color class, the sets of colors found in their neighborhoods are different. The neighbor-locating chromatic number $\\chi_{NL}(G)$ is the minimum $k$ for which $G$ admits a neighbor-locating $k$-coloring. A proper $k$-coloring of a graph $G$ is a \\emph{locating $k$-coloring} if for each pair of vertices $x$ and $y$ in the same color-class, there exists a color class $S_i$ such that $d(x,S_i)\\neq d(y,S_i)$. The locating chromatic number $\\chi_{L}(G)$ is the minimum $k$ for which $G$ admits a locating $k$-coloring. It follows that $\\chi(G)\\leq\\chi_L(G)\\leq\\chi_{NL}(G)$ for any graph $G$, where $\\chi(G)$ is the usual chromatic number of $G$. We show that for any three integers $p,q,r$ with $2\\leq p\\leq q\\leq r$ (except when $2=p=q<r$), there exists a connected graph $G_{p,q,r}$ with $\\chi(G_{p,q,r})=p$, $\\chi_L(G_{p,q,r})=q$ and $\\chi_{NL}(G_{p,q,r})=r$. We also show that the locating chromatic number (resp., neighbor-locating chromatic number) of an induced subgraph of a graph $G$ can be arbitrarily larger than that of $G$. Alcon \\textit{et al.} showed that the number $n$ of vertices of $G$ is bounded above by $k(2^{k-1}-1)$, where $\\chi_{NL}(G)=k$ and $G$ is connected (this bound is tight). When $G$ has maximum degree $\\Delta$, they also showed that a smaller upper-bound on $n$ of order $k^{\\Delta+1}$ holds. We generalize the latter by proving that if $G$ has order $n$ and at most $an+b$ edges, then $n$ is upper-bounded by a bound of the order of $k^{2a+1}+2b$. Moreover, we describe constructions of such graphs which are close to reaching the bound. ",
    "url": "https://arxiv.org/abs/2301.13557",
    "authors": [
      "Dipayan Chakraborty",
      "Florent Foucaud",
      "Soumen Nandi",
      "Sagnik Sen",
      "D K Supraja"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.13609",
    "title": "Physarum Inspired Bicycle Lane Network Design in a Congested Mega City",
    "abstract": "Mobility is a key factor in urban life and transport network plays a vital role in mobility. Worse transport network having less mobility is one of the key reasons to decline the living standard in any unplanned mega city. Transport mobility enhancement in an unplanned mega city is always challenging due to various constraints including complex design and high cost involvement. The aim of this thesis is to enhance transport mobility in a megacity introducing a bicycle lane. To design the bicycle lane natural Physarum, brainless single celled multi-nucleated protist, is studied and modified for better optimization. Recently Physarum inspired techniques are drawn significant attention to the construction of effective networks. Exiting Physarum inspired models effectively and efficiently solves different problems including transport network design and modification and implication for bicycle lane is the unique contribution of this study. Central area of Dhaka, the capital city of Bangladesh, is considered to analyze and design the bicycle lane network bypassing primary roads. ",
    "url": "https://arxiv.org/abs/2301.13609",
    "authors": [
      "Md. Ahsan Habib",
      "M. A. H. Akhand"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.13648",
    "title": "CSDN: Combing Shallow and Deep Networks for Accurate Real-time  Segmentation of High-definition Intravascular Ultrasound Images",
    "abstract": "Intravascular ultrasound (IVUS) is the preferred modality for capturing real-time and high resolution cross-sectional images of the coronary arteries, and evaluating the stenosis. Accurate and real-time segmentation of IVUS images involves the delineation of lumen and external elastic membrane borders. In this paper, we propose a two-stream framework for efficient segmentation of 60 MHz high resolution IVUS images. It combines shallow and deep networks, namely, CSDN. The shallow network with thick channels focuses to extract low-level details. The deep network with thin channels takes charge of learning high-level semantics. Treating the above information separately enables learning a model to achieve high accuracy and high efficiency for accurate real-time segmentation. To further improve the segmentation performance, mutual guided fusion module is used to enhance and fuse both different types of feature representation. The experimental results show that our CSDN accomplishes a good trade-off between analysis speed and segmentation accuracy. ",
    "url": "https://arxiv.org/abs/2301.13648",
    "authors": [
      "Shaofeng Yuan",
      "Feng Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13674",
    "title": "Improved distinct bone segmentation in upper-body CT through  multi-resolution networks",
    "abstract": "Purpose: Automated distinct bone segmentation from CT scans is widely used in planning and navigation workflows. U-Net variants are known to provide excellent results in supervised semantic segmentation. However, in distinct bone segmentation from upper body CTs a large field of view and a computationally taxing 3D architecture are required. This leads to low-resolution results lacking detail or localisation errors due to missing spatial context when using high-resolution inputs. Methods: We propose to solve this problem by using end-to-end trainable segmentation networks that combine several 3D U-Nets working at different resolutions. Our approach, which extends and generalizes HookNet and MRN, captures spatial information at a lower resolution and skips the encoded information to the target network, which operates on smaller high-resolution inputs. We evaluated our proposed architecture against single resolution networks and performed an ablation study on information concatenation and the number of context networks. Results: Our proposed best network achieves a median DSC of 0.86 taken over all 125 segmented bone classes and reduces the confusion among similar-looking bones in different locations. These results outperform our previously published 3D U-Net baseline results on the task and distinct-bone segmentation results reported by other groups. Conclusion: The presented multi-resolution 3D U-Nets address current shortcomings in bone segmentation from upper-body CT scans by allowing for capturing a larger field of view while avoiding the cubic growth of the input pixels and intermediate computations that quickly outgrow the computational capacities in 3D. The approach thus improves the accuracy and efficiency of distinct bone segmentation from upper-body CT. ",
    "url": "https://arxiv.org/abs/2301.13674",
    "authors": [
      "Eva Schnider",
      "Julia Wolleb",
      "Antal Huck",
      "Mireille Toranelli",
      "Georg Rauter",
      "Magdalena M\u00fcller-Gerbl",
      "Philippe C. Cattin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13710",
    "title": "On the Initialisation of Wide Low-Rank Feedforward Neural Networks",
    "abstract": "The edge-of-chaos dynamics of wide randomly initialized low-rank feedforward networks are analyzed. Formulae for the optimal weight and bias variances are extended from the full-rank to low-rank setting and are shown to follow from multiplicative scaling. The principle second order effect, the variance of the input-output Jacobian, is derived and shown to increase as the rank to width ratio decreases. These results inform practitioners how to randomly initialize feedforward networks with a reduced number of learnable parameters while in the same ambient dimension, allowing reductions in the computational cost and memory constraints of the associated network. ",
    "url": "https://arxiv.org/abs/2301.13710",
    "authors": [
      "Thiziri Nait Saada",
      "Jared Tanner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13728",
    "title": "Convolutional autoencoder for the spatiotemporal latent representation  of turbulence",
    "abstract": "Turbulence is characterised by chaotic dynamics and a high-dimensional state space, which make the phenomenon challenging to predict. However, turbulent flows are often characterised by coherent spatiotemporal structures, such as vortices or large-scale modes, which can help obtain a latent description of turbulent flows. However, current approaches are often limited by either the need to use some form of thresholding on quantities defining the isosurfaces to which the flow structures are associated or the linearity of traditional modal flow decomposition approaches, such as those based on proper orthogonal decomposition. This problem is exacerbated in flows that exhibit extreme events, which are rare and sudden changes in a turbulent state. The goal of this paper is to obtain an efficient and accurate reduced-order latent representation of a turbulent flow that exhibits extreme events. Specifically, we employ a three-dimensional multiscale convolutional autoencoder (CAE) to obtain such latent representation. We apply it to a three-dimensional turbulent flow. We show that the Multiscale CAE is efficient, requiring less than 10% degrees of freedom than proper orthogonal decomposition for compressing the data and is able to accurately reconstruct flow states related to extreme events. The proposed deep learning architecture opens opportunities for nonlinear reduced-order modeling of turbulent flows from data. ",
    "url": "https://arxiv.org/abs/2301.13728",
    "authors": [
      "Nguyen Anh Khoa Doan",
      "Alberto Racca",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2003.12112",
    "title": "Network Structure and Collective Intelligence in the Diffusion of  Innovation",
    "abstract": " Comments: 43 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2003.12112",
    "authors": [
      "Joshua Becker"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2004.01964",
    "title": "Uplink and Downlink Performance Bounds for Full Duplex Cellular Networks",
    "abstract": " Comments: no longer valid ",
    "url": "https://arxiv.org/abs/2004.01964",
    "authors": [
      "Askar Mandali Kundu",
      "Rudrashish Pal",
      "Mayank Kumar",
      "Sreejith T V"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2106.02600",
    "title": "Causal Graph Discovery from Self and Mutually Exciting Time Series",
    "abstract": " Comments: See v2 for a previous workshop paper on Interpretable ML in Healthcare (IMLH) at ICML 2021, titled \"Causal Graph Recovery for Sepsis-Associated Derangements via Interpretable Hawkes Networks\". Also, see arXiv:2301.11336 for a short conference version with more experiments of our proposed method to learn \"strict\" DAGs ",
    "url": "https://arxiv.org/abs/2106.02600",
    "authors": [
      "Song Wei",
      "Yao Xie",
      "Christopher S. Josef",
      "Rishikesan Kamaleswaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2106.10049",
    "title": "Graphs with at most two moplexes",
    "abstract": " Title: Graphs with at most two moplexes ",
    "url": "https://arxiv.org/abs/2106.10049",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Robert Ganian",
      "Meike Hatzel",
      "Matja\u017e Krnc",
      "Martin Milani\u010d"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2109.05707",
    "title": "Rethinking Lightweight Convolutional Neural Networks for Efficient and  High-quality Pavement Crack Detection",
    "abstract": " Comments: 19 pages, 14 figures, 12 tables ",
    "url": "https://arxiv.org/abs/2109.05707",
    "authors": [
      "Kai Li",
      "Jie Yang",
      "Siwei Ma",
      "Bo Wang",
      "Shanshe Wang",
      "Yingjie Tian",
      "Zhiquan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12390",
    "title": "Model reduction for the material point method via an implicit neural  representation of the deformation map",
    "abstract": " Title: Model reduction for the material point method via an implicit neural  representation of the deformation map ",
    "url": "https://arxiv.org/abs/2109.12390",
    "authors": [
      "Peter Yichen Chen",
      "Maurizio Chiaramonte",
      "Eitan Grinspun",
      "Kevin Carlberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.12685",
    "title": "Robust Coordination of Linear Threshold Dynamics on Directed Weighted  Networks",
    "abstract": " Comments: 16 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2109.12685",
    "authors": [
      "Laura Arditti",
      "Giacomo Como",
      "Fabio Fagnani",
      "Martina Vanelli"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2110.04398",
    "title": "The Role of Masks in Mitigating Viral Spread on Networks",
    "abstract": " Title: The Role of Masks in Mitigating Viral Spread on Networks ",
    "url": "https://arxiv.org/abs/2110.04398",
    "authors": [
      "Yurun Tian",
      "Anirudh Sridhar",
      "Chai Wah Wu",
      "Simon A. Levin",
      "Kathleen M. Carley",
      "H.Vincent Poor",
      "Osman Yagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2110.11091",
    "title": "E-DPNCT: An Enhanced Attack Resilient Differential Privacy Model For  Smart Grids Using Split Noise Cancellation",
    "abstract": " Comments: 13 pages, 7 figues, 1 tables ",
    "url": "https://arxiv.org/abs/2110.11091",
    "authors": [
      "Khadija Hafeez",
      "Donna OShea",
      "Thomas Newe",
      "Mubashir Husain Rehmani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.14303",
    "title": "A proof system for graph (non)-isomorphism verification",
    "abstract": " Title: A proof system for graph (non)-isomorphism verification ",
    "url": "https://arxiv.org/abs/2112.14303",
    "authors": [
      "Milan Bankovi\u0107",
      "Ivan Drecun",
      "Filip Mari\u0107"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2202.06924",
    "title": "Do Gradient Inversion Attacks Make Federated Learning Unsafe?",
    "abstract": " Comments: Revised version; Accepted to IEEE Transactions on Medical Imaging; Improved and reformatted version of this https URL; Added NVFlare reference ",
    "url": "https://arxiv.org/abs/2202.06924",
    "authors": [
      "Ali Hatamizadeh",
      "Hongxu Yin",
      "Pavlo Molchanov",
      "Andriy Myronenko",
      "Wenqi Li",
      "Prerna Dogra",
      "Andrew Feng",
      "Mona G. Flores",
      "Jan Kautz",
      "Daguang Xu",
      "Holger R. Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.07835",
    "title": "SecGNN: Privacy-Preserving Graph Neural Network Training and Inference  as a Cloud Service",
    "abstract": " Comments: Accepted in IEEE Transactions on Services Computing (TSC) ",
    "url": "https://arxiv.org/abs/2202.07835",
    "authors": [
      "Songlei Wang",
      "Yifeng Zheng",
      "Xiaohua Jia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.06704",
    "title": "Hyper-parameter tuning of physics-informed neural networks: Application  to Helmholtz problems",
    "abstract": " Title: Hyper-parameter tuning of physics-informed neural networks: Application  to Helmholtz problems ",
    "url": "https://arxiv.org/abs/2205.06704",
    "authors": [
      "Paul Escapil-Inchausp\u00e9",
      "Gonzalo A. Ruz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11736",
    "title": "Towards a Defense Against Federated Backdoor Attacks Under Continuous  Training",
    "abstract": " Title: Towards a Defense Against Federated Backdoor Attacks Under Continuous  Training ",
    "url": "https://arxiv.org/abs/2205.11736",
    "authors": [
      "Shuaiqi Wang",
      "Jonathan Hayase",
      "Giulia Fanti",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.14116",
    "title": "Don't Explain Noise: Robust Counterfactuals for Randomized Ensembles",
    "abstract": " Title: Don't Explain Noise: Robust Counterfactuals for Randomized Ensembles ",
    "url": "https://arxiv.org/abs/2205.14116",
    "authors": [
      "Alexandre Forel",
      "Axel Parmentier",
      "Thibaut Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.02671",
    "title": "Canonical Cortical Graph Neural Networks and its Application for Speech  Enhancement in Audio-Visual Hearing Aids",
    "abstract": " Title: Canonical Cortical Graph Neural Networks and its Application for Speech  Enhancement in Audio-Visual Hearing Aids ",
    "url": "https://arxiv.org/abs/2206.02671",
    "authors": [
      "Leandro A. Passos",
      "Jo\u00e3o Paulo Papa",
      "Amir Hussain",
      "Ahsan Adeel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.05576",
    "title": "Optimal Solutions for Joint Beamforming and Antenna Selection: From  Branch and Bound to Graph Neural Imitation Learning",
    "abstract": " Title: Optimal Solutions for Joint Beamforming and Antenna Selection: From  Branch and Bound to Graph Neural Imitation Learning ",
    "url": "https://arxiv.org/abs/2206.05576",
    "authors": [
      "Sagar Shrestha",
      "Xiao Fu",
      "Mingyi Hong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07811",
    "title": "Safety Guarantees for Neural Network Dynamic Systems via Stochastic  Barrier Functions",
    "abstract": " Title: Safety Guarantees for Neural Network Dynamic Systems via Stochastic  Barrier Functions ",
    "url": "https://arxiv.org/abs/2206.07811",
    "authors": [
      "Rayan Mazouz",
      "Karan Muvvala",
      "Akash Ratheesh",
      "Luca Laurenti",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.09241",
    "title": "An Empirical Study of Quantum Dynamics as a Ground State Problem with  Neural Quantum States",
    "abstract": " Comments: 20 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2206.09241",
    "authors": [
      "Vladimir Vargas-Calder\u00f3n",
      "Herbert Vinck-Posada",
      "Fabio A. Gonz\u00e1lez"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02016",
    "title": "Robust Reinforcement Learning in Continuous Control Tasks with  Uncertainty Set Regularization",
    "abstract": " Title: Robust Reinforcement Learning in Continuous Control Tasks with  Uncertainty Set Regularization ",
    "url": "https://arxiv.org/abs/2207.02016",
    "authors": [
      "Yuan Zhang",
      "Jianhong Wang",
      "Joschka Boedecker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.04993",
    "title": "Embedding Recycling for Language Models",
    "abstract": " Comments: EACL Findings 2023 ",
    "url": "https://arxiv.org/abs/2207.04993",
    "authors": [
      "Jon Saad-Falcon",
      "Amanpreet Singh",
      "Luca Soldaini",
      "Mike D'Arcy",
      "Arman Cohan",
      "Doug Downey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.08185",
    "title": "Mind the Gap: Polishing Pseudo labels for Accurate Semi-supervised  Object Detection",
    "abstract": " Comments: Accepted by Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023) ",
    "url": "https://arxiv.org/abs/2207.08185",
    "authors": [
      "Lei Zhang",
      "Yuxuan Sun",
      "Wei Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11727",
    "title": "Can we achieve robustness from data alone?",
    "abstract": " Title: Can we achieve robustness from data alone? ",
    "url": "https://arxiv.org/abs/2207.11727",
    "authors": [
      "Nikolaos Tsilivis",
      "Jingtong Su",
      "Julia Kempe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.01003",
    "title": "What can be learnt with wide convolutional neural networks?",
    "abstract": " Title: What can be learnt with wide convolutional neural networks? ",
    "url": "https://arxiv.org/abs/2208.01003",
    "authors": [
      "Francesco Cagnetta",
      "Alessandro Favero",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06987",
    "title": "A Unified Causal View of Domain Invariant Representation Learning",
    "abstract": " Title: A Unified Causal View of Domain Invariant Representation Learning ",
    "url": "https://arxiv.org/abs/2208.06987",
    "authors": [
      "Zihao Wang",
      "Victor Veitch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.08110",
    "title": "PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for  Curriculum Data Augmentation",
    "abstract": " Comments: Accepted to EACL 2023 (main) ",
    "url": "https://arxiv.org/abs/2208.08110",
    "authors": [
      "Hongyuan Lu",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.08609",
    "title": "A Scalable, Interpretable, Verifiable & Differentiable Logic Gate  Convolutional Neural Network Architecture From Truth Tables",
    "abstract": " Title: A Scalable, Interpretable, Verifiable & Differentiable Logic Gate  Convolutional Neural Network Architecture From Truth Tables ",
    "url": "https://arxiv.org/abs/2208.08609",
    "authors": [
      "Adrien Benamira",
      "Tristan Gu\u00e9rand",
      "Thomas Peyrin",
      "Trevor Yap",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2209.05299",
    "title": "Deep Convolutional Pooling Transformer for Deepfake Detection",
    "abstract": " Comments: 13 pages for peer review ",
    "url": "https://arxiv.org/abs/2209.05299",
    "authors": [
      "Tianyi Wang",
      "Harry Cheng",
      "Kam Pui Chow",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.06300",
    "title": "PINCH: An Adversarial Extraction Attack Framework for Deep Learning  Models",
    "abstract": " Comments: 19 pages, 13 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2209.06300",
    "authors": [
      "William Hackett",
      "Stefan Trawicki",
      "Zhengxin Yu",
      "Neeraj Suri",
      "Peter Garraghan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12900",
    "title": "The Efficacy of Self-Supervised Speech Models for Audio Representations",
    "abstract": " Comments: to appear in Proceedings of Machine Learning Research (PMLR): NeurIPS 2021 Competition Track ",
    "url": "https://arxiv.org/abs/2209.12900",
    "authors": [
      "Tung-Yu Wu",
      "Chen-An Li",
      "Tzu-Han Lin",
      "Tsu-Yuan Hsu",
      "Hung-Yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.13565",
    "title": "Neural parameter calibration for large-scale multi-agent models",
    "abstract": " Title: Neural parameter calibration for large-scale multi-agent models ",
    "url": "https://arxiv.org/abs/2209.13565",
    "authors": [
      "Thomas Gaskin",
      "Grigorios A. Pavliotis",
      "Mark Girolami"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00079",
    "title": "Causal Estimation for Text Data with (Apparent) Overlap Violations",
    "abstract": " Title: Causal Estimation for Text Data with (Apparent) Overlap Violations ",
    "url": "https://arxiv.org/abs/2210.00079",
    "authors": [
      "Lin Gui",
      "Victor Veitch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00313",
    "title": "CRISP: Curriculum based Sequential Neural Decoders for Polar Code Family",
    "abstract": " Comments: 22 pages, 23 figures ",
    "url": "https://arxiv.org/abs/2210.00313",
    "authors": [
      "S Ashwin Hebbar",
      "Viraj Nadkarni",
      "Ashok Vardhan Makkuva",
      "Suma Bhat",
      "Sewoong Oh",
      "Pramod Viswanath"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01891",
    "title": "Adaptively Weighted Data Augmentation Consistency Regularization for  Robust Optimization under Concept Shift",
    "abstract": " Title: Adaptively Weighted Data Augmentation Consistency Regularization for  Robust Optimization under Concept Shift ",
    "url": "https://arxiv.org/abs/2210.01891",
    "authors": [
      "Yijun Dong",
      "Yuege Xie",
      "Rachel Ward"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02129",
    "title": "Personalized Decentralized Bilevel Optimization over Random Directed  Networks",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2210.02129",
    "authors": [
      "Naoyuki Terashita",
      "Satoshi Hara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05577",
    "title": "What Can the Neural Tangent Kernel Tell Us About Adversarial Robustness?",
    "abstract": " Comments: NeurIPS 2022; added link to GitHub repository ",
    "url": "https://arxiv.org/abs/2210.05577",
    "authors": [
      "Nikolaos Tsilivis",
      "Julia Kempe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.05974",
    "title": "Clustering the Sketch: A Novel Approach to Embedding Table Compression",
    "abstract": " Title: Clustering the Sketch: A Novel Approach to Embedding Table Compression ",
    "url": "https://arxiv.org/abs/2210.05974",
    "authors": [
      "Henry Ling-Hei Tsang",
      "Thomas Dybdahl Ahle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.13432",
    "title": "Towards Better Few-Shot and Finetuning Performance with Forgetful Causal  Language Models",
    "abstract": " Comments: Added T-FCM and better FCM results ",
    "url": "https://arxiv.org/abs/2210.13432",
    "authors": [
      "Hao Liu",
      "Xinyang Geng",
      "Lisa Lee",
      "Igor Mordatch",
      "Sergey Levine",
      "Sharan Narang",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.01852",
    "title": "Revisiting Hyperparameter Tuning with Differential Privacy",
    "abstract": " Comments: ML Safety Workshop of NeurIPS'22 Accepted Paper ",
    "url": "https://arxiv.org/abs/2211.01852",
    "authors": [
      "Youlong Ding",
      "Xueyang Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.07675",
    "title": "On the Global Convergence of Fitted Q-Iteration with Two-layer Neural  Network Parametrization",
    "abstract": " Title: On the Global Convergence of Fitted Q-Iteration with Two-layer Neural  Network Parametrization ",
    "url": "https://arxiv.org/abs/2211.07675",
    "authors": [
      "Mudit Gaur",
      "Vaneet Aggarwal",
      "Mridul Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11865",
    "title": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "abstract": " Title: Bayesian Learning for Neural Networks: an algorithmic survey ",
    "url": "https://arxiv.org/abs/2211.11865",
    "authors": [
      "Martin Magris",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04325",
    "title": "Lattice-Free Sequence Discriminative Training for Phoneme-Based Neural  Transducers",
    "abstract": " Comments: submitted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2212.04325",
    "authors": [
      "Zijian Yang",
      "Wei Zhou",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2212.09412",
    "title": "Difformer: Empowering Diffusion Models on the Embedding Space for Text  Generation",
    "abstract": " Title: Difformer: Empowering Diffusion Models on the Embedding Space for Text  Generation ",
    "url": "https://arxiv.org/abs/2212.09412",
    "authors": [
      "Zhujin Gao",
      "Junliang Guo",
      "Xu Tan",
      "Yongxin Zhu",
      "Fang Zhang",
      "Jiang Bian",
      "Linli Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01917",
    "title": "Small Moving Object Detection Algorithm in Surveillance Video Based on  Motion Information",
    "abstract": " Title: Small Moving Object Detection Algorithm in Surveillance Video Based on  Motion Information ",
    "url": "https://arxiv.org/abs/2301.01917",
    "authors": [
      "Ziwei Sun",
      "Zexi Hua",
      "Hengcao Li",
      "Haiyan Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02764",
    "title": "Mathematical Models and Reinforcement Learning based Evolutionary  Algorithm Framework for Satellite Scheduling Problem",
    "abstract": " Comments: 12 pages. arXiv admin note: substantial text overlap with arXiv:2206.05694 ",
    "url": "https://arxiv.org/abs/2301.02764",
    "authors": [
      "Yanjie Song"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.06534",
    "title": "Stuck in the Permissions With You: Developer & End-User Perspectives on  App Permissions & Their Privacy Ramifications",
    "abstract": " Comments: To be published in the CHI Conference on Human Factors in Computing Systems (CHI '23), April 23--28, 2023, Hamburg, Germany ",
    "url": "https://arxiv.org/abs/2301.06534",
    "authors": [
      "Mohammad Tahaei",
      "Ruba Abu-Salma",
      "Awais Rashid"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.06695",
    "title": "Quantifying and Managing Impacts of Concept Drifts on IoT Traffic  Inference in Residential ISP Networks",
    "abstract": " Comments: Submitted to IEEE IoT Journal ",
    "url": "https://arxiv.org/abs/2301.06695",
    "authors": [
      "Arman Pashamokhtari",
      "Norihiro Okui",
      "Masataka Nakahara",
      "Ayumu Kubota",
      "Gustavo Batista",
      "Hassan Habibi Gharakheili"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2301.11004",
    "title": "NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental  Health on Social Media",
    "abstract": " Comments: Will revise the work ",
    "url": "https://arxiv.org/abs/2301.11004",
    "authors": [
      "Muskan Garg",
      "Chandni Saxena",
      "Usman Naseem",
      "Bonnie J Dorr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11308",
    "title": "Neural Continuous-Discrete State Space Models for Irregularly-Sampled  Time Series",
    "abstract": " Title: Neural Continuous-Discrete State Space Models for Irregularly-Sampled  Time Series ",
    "url": "https://arxiv.org/abs/2301.11308",
    "authors": [
      "Abdul Fatir Ansari",
      "Alvin Heng",
      "Andre Lim",
      "Harold Soh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11659",
    "title": "Matching Linear Algebra and Tensor Code to Specialized Hardware  Accelerators",
    "abstract": " Comments: This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in Proceedings of the 32nd ACM SIGPLAN International Conference on Compiler Construction (CC '23), February 25-26, 2023, Montr\\'eal, QC, Canada, this https URL ",
    "url": "https://arxiv.org/abs/2301.11659",
    "authors": [
      "Pablo Antonio Mart\u00ednez",
      "Jackson Woodruff",
      "Jordi Armengol-Estap\u00e9",
      "Gregorio Bernab\u00e9",
      "Jos\u00e9 Manuel Garc\u00eda",
      "Michael F. P. O'Boyle"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2301.12097",
    "title": "Enhancing Dyadic Relations with Homogeneous Graphs for Multimodal  Recommendation",
    "abstract": " Comments: modify the format ",
    "url": "https://arxiv.org/abs/2301.12097",
    "authors": [
      "Hongyu Zhou",
      "Xin Zhou",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2301.12914",
    "title": "PromptMix: Text-to-image diffusion models enhance the performance of  lightweight networks",
    "abstract": " Title: PromptMix: Text-to-image diffusion models enhance the performance of  lightweight networks ",
    "url": "https://arxiv.org/abs/2301.12914",
    "authors": [
      "Arian Bakhtiarnia",
      "Qi Zhang",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12929",
    "title": "Can Persistent Homology provide an efficient alternative for Evaluation  of Knowledge Graph Completion Methods?",
    "abstract": " Comments: To appear in proceedings of The Web Conference 2023 (WWW'23) ",
    "url": "https://arxiv.org/abs/2301.12929",
    "authors": [
      "Anson Bastos",
      "Kuldeep Singh",
      "Abhishek Nadgeri",
      "Johannes Hoffart",
      "Toyotaro Suzumura",
      "Manish Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2301.13142",
    "title": "Self-Compressing Neural Networks",
    "abstract": " Comments: Accepted submission to 2023 DL-Hardware Co-Design for AI Acceleration ",
    "url": "https://arxiv.org/abs/2301.13142",
    "authors": [
      "Szabolcs Cs\u00e9falvay",
      "James Imber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]