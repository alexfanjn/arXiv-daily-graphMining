[
  {
    "id": "arXiv:2302.10887",
    "title": "The configurable tree graph (CT-graph): measurable problems in partially  observable and distal reward environments for lifelong reinforcement learning",
    "abstract": "This paper introduces a set of formally defined and transparent problems for reinforcement learning algorithms with the following characteristics: (1) variable degrees of observability (non-Markov observations), (2) distal and sparse rewards, (3) variable and hierarchical reward structure, (4) multiple-task generation, (5) variable problem complexity. The environment provides 1D or 2D categorical observations, and takes actions as input. The core structure of the CT-graph is a multi-branch tree graph with arbitrary branching factor, depth, and observation sets that can be varied to increase the dimensions of the problem in a controllable and measurable way. Two main categories of states, decision states and wait states, are devised to create a hierarchy of importance among observations, typical of real-world problems. A large observation set can produce a vast set of histories that impairs memory-augmented agents. Variable reward functions allow for the easy creation of multiple tasks and the ability of an agent to efficiently adapt in dynamic scenarios where tasks with controllable degrees of similarities are presented. Challenging complexity levels can be easily achieved due to the exponential growth of the graph. The problem formulation and accompanying code provide a fast, transparent, and mathematically defined set of configurable tests to compare the performance of reinforcement learning algorithms, in particular in lifelong learning settings. ",
    "url": "https://arxiv.org/abs/2302.10887",
    "authors": [
      "Andrea Soltoggio",
      "Eseoghene Ben-Iwhiwhu",
      "Christos Peridis",
      "Pawel Ladosz",
      "Jeffery Dick",
      "Praveen K. Pilly",
      "Soheil Kolouri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10889",
    "title": "An Asymmetric Loss with Anomaly Detection LSTM Framework for Power  Consumption Prediction",
    "abstract": "Building an accurate load forecasting model with minimal underpredictions is vital to prevent any undesired power outages due to underproduction of electricity. However, the power consumption patterns of the residential sector contain fluctuations and anomalies making them challenging to predict. In this paper, we propose multiple Long Short-Term Memory (LSTM) frameworks with different asymmetric loss functions to impose a higher penalty on underpredictions. We also apply a density-based spatial clustering of applications with noise (DBSCAN) anomaly detection approach, prior to the load forecasting task, to remove any present oultiers. Considering the effect of weather and social factors, seasonality splitting is performed on the three considered datasets from France, Germany, and Hungary containing hourly power consumption, weather, and calendar features. Root-mean-square error (RMSE) results show that removing the anomalies efficiently reduces the underestimation and overestimation errors in all the seasonal datasets. Additionally, asymmetric loss functions and seasonality splitting effectively minimize underestimations despite increasing the overestimation error to some degree. Reducing underpredictions of electricity consumption is essential to prevent power outages that can be damaging to the community. ",
    "url": "https://arxiv.org/abs/2302.10889",
    "authors": [
      "Jihan Ghanim",
      "Maha Issa",
      "Mariette Awad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10890",
    "title": "Learning Interpretable Low-dimensional Representation via Physical  Symmetry",
    "abstract": "Interpretable representation learning has been playing a key role in creative intelligent systems. In the music domain, current learning algorithms can successfully learn various features such as pitch, timbre, chord, texture, etc. However, most methods rely heavily on music domain knowledge. It remains an open question what general computational principles give rise to interpretable representations, especially low-dim factors that agree with human perception. In this study, we take inspiration from modern physics and use physical symmetry as a self-consistency constraint for the latent space. Specifically, it requires the prior model that characterises the dynamics of the latent states to be equivariant with respect to certain group transformations. We show that physical symmetry leads the model to learn a linear pitch factor from unlabelled monophonic music audio in a self-supervised fashion. In addition, the same methodology can be applied to computer vision, learning a 3D Cartesian space from videos of a simple moving object without labels. Furthermore, physical symmetry naturally leads to representation augmentation, a new technique which improves sample efficiency. ",
    "url": "https://arxiv.org/abs/2302.10890",
    "authors": [
      "Xuanjie Liu",
      "Daniel Chin",
      "Yichen Huang",
      "Gus Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10891",
    "title": "An Implicit GNN Solver for Poisson-like problems",
    "abstract": "This paper presents $\\Psi$-GNN, a novel Graph Neural Network (GNN) approach for solving the ubiquitous Poisson PDE problems with mixed boundary conditions. By leveraging the Implicit Layer Theory, $\\Psi$-GNN models an ''infinitely'' deep network, thus avoiding the empirical tuning of the number of required Message Passing layers to attain the solution. Its original architecture explicitly takes into account the boundary conditions, a critical prerequisite for physical applications, and is able to adapt to any initially provided solution. $\\Psi$-GNN is trained using a ''physics-informed'' loss, and the training process is stable by design, and insensitive to its initialization. Furthermore, the consistency of the approach is theoretically proven, and its flexibility and generalization efficiency are experimentally demonstrated: the same learned model can accurately handle unstructured meshes of various sizes, as well as different boundary conditions. To the best of our knowledge, $\\Psi$-GNN is the first physics-informed GNN-based method that can handle various unstructured domains, boundary conditions and initial solutions while also providing convergence guarantees. ",
    "url": "https://arxiv.org/abs/2302.10891",
    "authors": [
      "Matthieu Nastorg",
      "Michele-Alessandro Bucci",
      "Thibault Faney",
      "Jean-Marc Gratien",
      "Guillaume Charpiat",
      "Marc Schoenauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2302.10894",
    "title": "Benchmarking Interpretability Tools for Deep Neural Networks",
    "abstract": "Interpreting deep neural networks is the topic of much current research in AI. However, few interpretability techniques have shown to be competitive tools in practical applications. Inspired by how benchmarks tend to guide progress in AI, we make three contributions. First, we propose trojan rediscovery as a benchmarking task to evaluate how useful interpretability tools are for generating engineering-relevant insights. Second, we design two such approaches for benchmarking: one for feature attribution methods and one for feature synthesis methods. Third, we apply our benchmarks to evaluate 16 feature attribution/saliency methods and 9 feature synthesis methods. This approach finds large differences in the capabilities of these existing tools and shows significant room for improvement. Finally, we propose several directions for future work. Resources are available at https://github.com/thestephencasper/benchmarking_interpretability ",
    "url": "https://arxiv.org/abs/2302.10894",
    "authors": [
      "Stephen Casper",
      "Yuxiao Li",
      "Jiawei Li",
      "Tong Bu",
      "Kevin Zhang",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10896",
    "title": "IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness",
    "abstract": "In this paper, we propose a novel method, IB-RAR, which uses Information Bottleneck (IB) to strengthen adversarial robustness for both adversarial training and non-adversarial-trained methods. We first use the IB theory to build regularizers as learning objectives in the loss function. Then, we filter out unnecessary features of intermediate representation according to their mutual information (MI) with labels, as the network trained with IB provides easily distinguishable MI for its features. Experimental results show that our method can be naturally combined with adversarial training and provides consistently better accuracy on new adversarial examples. Our method improves the accuracy by an average of 3.07% against five adversarial attacks for the VGG16 network, trained with three adversarial training benchmarks and the CIFAR-10 dataset. In addition, our method also provides good robustness for undefended methods, such as training with cross-entropy loss only. Finally, in the absence of adversarial training, the VGG16 network trained using our method and the CIFAR-10 dataset reaches an accuracy of 35.86% against PGD examples, while using all layers reaches 25.61% accuracy. ",
    "url": "https://arxiv.org/abs/2302.10896",
    "authors": [
      "Xiaoyun Xu",
      "Guilherme Perin",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10899",
    "title": "Feature Affinity Assisted Knowledge Distillation and Quantization of  Deep Neural Networks on Label-Free Data",
    "abstract": "In this paper, we propose a feature affinity (FA) assisted knowledge distillation (KD) method to improve quantization-aware training of deep neural networks (DNN). The FA loss on intermediate feature maps of DNNs plays the role of teaching middle steps of a solution to a student instead of only giving final answers in the conventional KD where the loss acts on the network logits at the output level. Combining logit loss and FA loss, we found that the quantized student network receives stronger supervision than from the labeled ground-truth data. The resulting FAQD is capable of compressing model on label-free data, which brings immediate practical benefits as pre-trained teacher models are readily available and unlabeled data are abundant. In contrast, data labeling is often laborious and expensive. Finally, we propose a fast feature affinity (FFA) loss that accurately approximates FA loss with a lower order of computational complexity, which helps speed up training for high resolution image input. ",
    "url": "https://arxiv.org/abs/2302.10899",
    "authors": [
      "Zhijian Li",
      "Biao Yang",
      "Penghang Yin",
      "Yingyong Qi",
      "Jack Xin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.10900",
    "title": "Semi-decentralized Federated Ego Graph Learning for Recommendation",
    "abstract": "Collaborative filtering (CF) based recommender systems are typically trained based on personal interaction data (e.g., clicks and purchases) that could be naturally represented as ego graphs. However, most existing recommendation methods collect these ego graphs from all users to compose a global graph to obtain high-order collaborative information between users and items, and these centralized CF recommendation methods inevitably lead to a high risk of user privacy leakage. Although recently proposed federated recommendation systems can mitigate the privacy problem, they either restrict the on-device local training to an isolated ego graph or rely on an additional third-party server to access other ego graphs resulting in a cumbersome pipeline, which is hard to work in practice. In addition, existing federated recommendation systems require resource-limited devices to maintain the entire embedding tables resulting in high communication costs. In light of this, we propose a semi-decentralized federated ego graph learning framework for on-device recommendations, named SemiDFEGL, which introduces new device-to-device collaborations to improve scalability and reduce communication costs and innovatively utilizes predicted interacted item nodes to connect isolated ego graphs to augment local subgraphs such that the high-order user-item collaborative information could be used in a privacy-preserving manner. Furthermore, the proposed framework is model-agnostic, meaning that it could be seamlessly integrated with existing graph neural network-based recommendation methods and privacy protection techniques. To validate the effectiveness of the proposed SemiDFEGL, extensive experiments are conducted on three public datasets, and the results demonstrate the superiority of the proposed SemiDFEGL compared to other federated recommendation methods. ",
    "url": "https://arxiv.org/abs/2302.10900",
    "authors": [
      "Liang Qu",
      "Ningzhi Tang",
      "Ruiqi Zheng",
      "Quoc Viet Hung Nguyen",
      "Zi Huang",
      "Yuhui Shi",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.10903",
    "title": "Trajectory-User Linking via Hierarchical Spatio-Temporal Attention  Networks",
    "abstract": "Trajectory-User Linking (TUL) is crucial for human mobility modeling by linking different trajectories to users with the exploration of complex mobility patterns. Existing works mainly rely on the recurrent neural framework to encode the temporal dependencies in trajectories, have fall short in capturing spatial-temporal global context for TUL prediction. To fill this gap, this work presents a new hierarchical spatio-temporal attention neural network, called AttnTUL, to jointly encode the local trajectory transitional patterns and global spatial dependencies for TUL. Specifically, our first model component is built over the graph neural architecture to preserve the local and global context and enhance the representation paradigm of geographical regions and user trajectories. Additionally, a hierarchically structured attention network is designed to simultaneously encode the intra-trajectory and inter-trajectory dependencies, with the integration of the temporal attention mechanism and global elastic attentional encoder. Extensive experiments demonstrate the superiority of our AttnTUL method as compared to state-of-the-art baselines on various trajectory datasets. The source code of our model is available at \\url{https://anonymous.4open.science/r/Attn_TUL}. ",
    "url": "https://arxiv.org/abs/2302.10903",
    "authors": [
      "Wei Chen",
      "Chao Huang",
      "Yanwei Yu",
      "Yongguo Jiang",
      "Junyu Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10905",
    "title": "Scientific Computing with Diffractive Optical Neural Networks",
    "abstract": "Diffractive optical neural networks (DONNs) have been emerging as a high-throughput and energy-efficient hardware platform to perform all-optical machine learning (ML) in machine vision systems. However, the current demonstrated applications of DONNs are largely straightforward image classification tasks, which undermines the prospect of developing and utilizing such hardware for other ML applications. Here, we numerically and experimentally demonstrate the deployment of an all-optical reconfigurable DONNs system for scientific computing, including guiding two-dimensional quantum material synthesis, predicting the properties of nanomaterials and small molecular cancer drugs, predicting the device response of nanopatterned integrated photonic power splitters, and the dynamic stabilization of an inverted pendulum with reinforcement learning. Despite a large variety of input data structures, we develop a universal feature engineering approach to convert categorical input features to the images that can be processed in the DONNs system. Our results open up new opportunities of employing DONNs systems for a broad range of ML applications. ",
    "url": "https://arxiv.org/abs/2302.10905",
    "authors": [
      "Ruiyang Chen",
      "Yingheng Tang",
      "Jianzhu Ma",
      "Weilu Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2302.10906",
    "title": "Deep Neural Networks for Encrypted Inference with TFHE",
    "abstract": "Fully homomorphic encryption (FHE) is an encryption method that allows to perform computation on encrypted data, without decryption. FHE preserves the privacy of the users of online services that handle sensitive data, such as health data, biometrics, credit scores and other personal information. A common way to provide a valuable service on such data is through machine learning and, at this time, Neural Networks are the dominant machine learning model for unstructured data. In this work we show how to construct Deep Neural Networks (DNN) that are compatible with the constraints of TFHE, an FHE scheme that allows arbitrary depth computation circuits. We discuss the constraints and show the architecture of DNNs for two computer vision tasks. We benchmark the architectures using the Concrete stack, an open-source implementation of TFHE. ",
    "url": "https://arxiv.org/abs/2302.10906",
    "authors": [
      "Andrei Stoian",
      "Jordan Frery",
      "Roman Bredehoft",
      "Luis Montero",
      "Celia Kherfallah",
      "Benoit Chevallier-Mames"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.10911",
    "title": "Revisiting Weighted Aggregation in Federated Learning with Neural  Networks",
    "abstract": "In federated learning (FL), weighted aggregation of local models is conducted to generate a global model, and the aggregation weights are normalized (the sum of weights is 1) and proportional to the local data sizes. In this paper, we revisit the weighted aggregation process and gain new insights into the training dynamics of FL. First, we find that the sum of weights can be smaller than 1, causing global weight shrinking effect (analogous to weight decay) and improving generalization. We explore how the optimal shrinking factor is affected by clients' data heterogeneity and local epochs. Second, we dive into the relative aggregation weights among clients to depict the clients' importance. We develop client coherence to study the learning dynamics and find a critical point that exists. Before entering the critical point, more coherent clients play more essential roles in generalization. Based on the above insights, we propose an effective method for Federated Learning with Learnable Aggregation Weights, named as FedLAW. Extensive experiments verify that our method can improve the generalization of the global model by a large margin on different datasets and models. ",
    "url": "https://arxiv.org/abs/2302.10911",
    "authors": [
      "Zexi Li",
      "Tao Lin",
      "Xinyi Shang",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10913",
    "title": "From paintbrush to pixel: A review of deep neural networks in  AI-generated art",
    "abstract": "This paper delves into the fascinating field of AI-generated art and explores the various deep neural network architectures and models that have been utilized to create it. From the classic convolutional networks to the cutting-edge diffusion models, we examine the key players in the field. We explain the general structures and working principles of these neural networks. Then, we showcase examples of milestones, starting with the dreamy landscapes of DeepDream and moving on to the most recent developments, including Stable Diffusion and DALL-E 2, which produce mesmerizing images. A detailed comparison of these models is provided, highlighting their strengths and limitations. Thus, we examine the remarkable progress that deep neural networks have made so far in a short period of time. With a unique blend of technical explanations and insights into the current state of AI-generated art, this paper exemplifies how art and computer science interact. ",
    "url": "https://arxiv.org/abs/2302.10913",
    "authors": [
      "Anne-Sofie Maerten",
      "Derya Soydaner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10952",
    "title": "Machine learning for the prediction of safe and biologically active  organophosphorus molecules",
    "abstract": "Drug discovery is a complex process with a large molecular space to be considered. By constraining the search space, the fragment-based drug design is an approach that can effectively sample the chemical space of interest. Here we propose a framework of Recurrent Neural Networks (RNN) with an attention model to sample the chemical space of organophosphorus molecules using the fragment-based approach. The framework is trained with a ZINC dataset that is screened for high druglikeness scores. The goal is to predict molecules with similar biological action modes as organophosphorus pesticides or chemical warfare agents yet less toxic to humans. The generated molecules contain a starting fragment of PO2F but have a bulky hydrocarbon side chain limiting its binding effectiveness to the targeted protein. ",
    "url": "https://arxiv.org/abs/2302.10952",
    "authors": [
      "Hang Hu",
      "Hsu Kiang Ooi",
      "Mohammad Sajjad Ghaemi",
      "Anguang Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2302.10964",
    "title": "Sedition Hunters: A Quantitative Study of the Crowdsourced Investigation  into the 2021 U.S. Capitol Attack",
    "abstract": "Social media platforms have enabled extremists to organize violent events, such as the 2021 U.S. Capitol Attack. Simultaneously, these platforms enable professional investigators and amateur sleuths to collaboratively collect and identify imagery of suspects with the goal of holding them accountable for their actions. Through a case study of Sedition Hunters, a Twitter community whose goal is to identify individuals who participated in the 2021 U.S. Capitol Attack, we explore what are the main topics or targets of the community, who participates in the community, and how. Using topic modeling, we find that information sharing is the main focus of the community. We also note an increase in awareness of privacy concerns. Furthermore, using social network analysis, we show how some participants played important roles in the community. Finally, we discuss implications for the content and structure of online crowdsourced investigations. ",
    "url": "https://arxiv.org/abs/2302.10964",
    "authors": [
      "Tianjiao Yu",
      "Sukrit Venkatagiri",
      "Ismini Lourentzou",
      "Kurt Luther"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.10972",
    "title": "Complexity of Maker-Breaker Games on Edge Sets of Graphs",
    "abstract": "We initiate the study of the algorithmic complexity of Maker-Breaker games played on edge sets of graphs for general graphs. We mainly consider three of the big four such games: the connectivity game, perfect matching game, and $H$-game. Maker wins if she claims the edges of a spanning tree in the first, a perfect matching in the second, and a copy of a fixed graph $H$ in the third. We prove that deciding who wins the perfect matching game and the $H$-game is PSPACE-complete, even for the latter in graphs of small diameter if $H$ is a tree. Seeking to find the smallest graph $H$ such that the $H$-game is PSPACE-complete, we also prove that there exists such an $H$ of order 51 and size 57. On the positive side, we show that the connectivity game and arboricity-$k$ game are polynomial-time solvable. We then give several positive results for the $H$-game, first giving a structural characterization for Breaker to win the $P_4$-game, which gives a linear-time algorithm for the $P_4$-game. We provide a structural characterization for Maker to win the $K_{1,\\ell}$-game in trees, which implies a linear-time algorithm for the $K_{1,\\ell}$-game in trees. Lastly, we prove that the $K_{1,\\ell}$-game in any graph, and the $H$-game in trees are both FPT parameterized by the length of the game. We leave the complexity of the last of the big four games, the Hamiltonicity game, as an open question. ",
    "url": "https://arxiv.org/abs/2302.10972",
    "authors": [
      "Eric Duch\u00eane",
      "Valentin Gledel",
      "Fionn Mc Inerney",
      "Nicolas Nisse",
      "Nacim Oijid",
      "Aline Parreau",
      "Milo\u0161 Stojakovi\u0107"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2302.10975",
    "title": "Improved uncertainty quantification for neural networks with Bayesian  last layer",
    "abstract": "Uncertainty quantification is an essential task in machine learning - a task in which neural networks (NNs) have traditionally not excelled. Bayesian neural networks (BNNs), in which parameters and predictions are probability distributions, can be a remedy for some applications, but often require expensive sampling for training and inference. NNs with Bayesian last layer (BLL) are simplified BNNs where only the weights in the last layer and the predictions follow a normal distribution. They are conceptually related to Bayesian linear regression (BLR) which has recently gained popularity in learning based-control under uncertainty. Both consider a non-linear feature space which is linearly mapped to the output, and hyperparameters, for example the noise variance, For NNs with BLL, these hyperparameters should include the deterministic weights of all other layers, as these impact the feature space and thus the predictive performance. Unfortunately, the marginal likelihood is expensive to evaluate in this setting and prohibits direct training through back-propagation. In this work, we present a reformulation of the BLL log-marginal likelihood, which considers weights in previous layers as hyperparameters and allows for efficient training through back-propagation. Furthermore, we derive a simple method to improve the extrapolation uncertainty of NNs with BLL. In a multivariate toy example and in the case of a dynamic system identification task, we show that NNs with BLL, trained with our proposed algorithm, outperform standard BLR with NN features. ",
    "url": "https://arxiv.org/abs/2302.10975",
    "authors": [
      "Felix Fiedler",
      "Sergio Lucia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.10980",
    "title": "MultiRobustBench: Benchmarking Robustness Against Multiple Attacks",
    "abstract": "The bulk of existing research in defending against adversarial examples focuses on defending against a single (typically bounded Lp-norm) attack, but for a practical setting, machine learning (ML) models should be robust to a wide variety of attacks. In this paper, we present the first unified framework for considering multiple attacks against ML models. Our framework is able to model different levels of learner's knowledge about the test-time adversary, allowing us to model robustness against unforeseen attacks and robustness against unions of attacks. Using our framework, we present the first leaderboard, MultiRobustBench, for benchmarking multiattack evaluation which captures performance across attack types and attack strengths. We evaluate the performance of 16 defended models for robustness against a set of 9 different attack types, including Lp-based threat models, spatial transformations, and color changes, at 20 different attack strengths (180 attacks total). Additionally, we analyze the state of current defenses against multiple attacks. Our analysis shows that while existing defenses have made progress in terms of average robustness across the set of attacks used, robustness against the worst-case attack is still a big open problem as all existing models perform worse than random guessing. ",
    "url": "https://arxiv.org/abs/2302.10980",
    "authors": [
      "Sihui Dai",
      "Saeed Mahloujifar",
      "Chong Xiang",
      "Vikash Sehwag",
      "Pin-Yu Chen",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.10991",
    "title": "Enabling Versatile Privacy Interfaces Using Machine-Readable  Transparency Information",
    "abstract": "Transparency regarding the processing of personal data in online services is a necessary precondition for informed decisions on whether or not to share personal data. In this paper, we argue that privacy interfaces shall incorporate the context of display, personal preferences, and individual competences of data subjects following the principles of universal design and usable privacy. Doing so requires -- among others -- to consciously decouple the provision of transparency information from their ultimate presentation. To this end, we provide a general model of how transparency information can be provided from a data controller to data subjects, effectively leveraging machine-readable transparency information and facilitating versatile presentation interfaces. We contribute two actual implementations of said model: 1) a GDPR-aligned privacy dashboard and 2) a chatbot and virtual voice assistant enabled by conversational AI. We evaluate our model and implementations with a user study and find that these approaches provide effective and time-efficient transparency. Consequently, we illustrate how transparency can be enhanced using machine-readable transparency information and how data controllers can meet respective regulatory obligations. ",
    "url": "https://arxiv.org/abs/2302.10991",
    "authors": [
      "Elias Gr\u00fcnewald",
      "Johannes M. Halkenh\u00e4u\u00dfer",
      "Nicola Leschke",
      "Johanna Washington",
      "Cristina Paupini",
      "Frank Pallas"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2302.10997",
    "title": "Robust Auto-landing Control of an agile Regional Jet Using Fuzzy  Q-learning",
    "abstract": "A robust auto-landing problem of a Truss-braced Wing (TBW) regional jet aircraft with poor stability characteristics is presented in this study employing a Fuzzy Reinforcement Learning scheme. Reinforcement Learning (RL) has seen a recent surge in practical uses in control systems. In contrast to many studies implementing Deep Learning in RL algorithms to generate continuous actions, the methodology of this study is straightforward and avoids complex neural network architectures by applying Fuzzy rules. An innovative, agile civil aircraft is selected not only to meet future aviation community expectations but also to demonstrate the robustness of the suggested method. In order to create a multi-objective RL environment, a Six-degree-of-freedom (6-DoF) simulation is first developed. By transforming the auto-landing problem of the aircraft into a Markov Decision Process (MDP) formulation, the problem is solved by designing a low-level Fuzzy Q-learning (FQL) controller. More specifically, the well-known Q-learning method, which is a discrete RL algorithm, is supplemented by Fuzzy rules to provide continuous actions with no need to complex learning structures. The performance of the proposed system is then evaluated by extensive flight simulations in different flight conditions considering severe wind gusts, measurement noises, actuator faults, and model uncertainties. Besides, the controller effectiveness would be compared with existing competing techniques such as Dynamic Inversion (DI) and Q-learning. The simulation results indicate the superior performance of the proposed control system as a reliable and robust control method to be employed in real applications. ",
    "url": "https://arxiv.org/abs/2302.10997",
    "authors": [
      "Mohsen Zahmatkesh",
      "Seyyed Ali Emami",
      "Afshin Banazadeh",
      "Paolo Castaldi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.11007",
    "title": "Unification of popular artificial neural network activation functions",
    "abstract": "We present a unified representation of the most popular neural network activation functions. Adopting Mittag-Leffler functions of fractional calculus, we propose a flexible and compact functional form that is able to interpolate between various activation functions and mitigate common problems in training neural networks such as vanishing and exploding gradients. The presented gated representation extends the scope of fixed-shape activation functions to their adaptive counterparts whose shape can be learnt from the training data. The derivatives of the proposed functional form can also be expressed in terms of Mittag-Leffler functions making it a suitable candidate for gradient-based backpropagation algorithms. By training LeNet-5 neural network on MNIST and CIFAR-10 datasets, we demonstrate that adopting a unified gated representation of activation functions offers a promising and affordable alternative to individual built-in implementations of activation functions in conventional machine learning frameworks. ",
    "url": "https://arxiv.org/abs/2302.11007",
    "authors": [
      "Mohammad Mostafanejad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2302.11026",
    "title": "Unsourced Multiple Access with Common Alarm Messages: Network Slicing  for Massive and Critical IoT",
    "abstract": "We investigate the coexistence of massive and critical Internet of Things (IoT) services in the context of the unsourced multiple access (UMA) framework introduced by Polyanskiy (2017), where all users employ a common codebook and the receiver returns an unordered list of decoded codewords. This setup is suitably modified to introduce heterogeneous traffic. Specifically, to model the massive IoT service, a standard message originates independently from each IoT device as in the standard UMA setup. To model the critical IoT service, we assume the generation of alarm messages that are common for all devices. This setup requires a significant redefinition of the error events, i.e., misdetections and false positives. We further assume that the number of active users in each transmission attempt is random and unknown. We derive a random-coding achievability bound on the misdetection and false positive probabilities of both standard and alarm messages on the Gaussian multiple access channel. Using our bound, we demonstrate that orthogonal network slicing enables massive and critical IoT to coexist under the requirement of high energy efficiency. On the contrary, we show that nonorthogonal network slicing is energy inefficient due to the residual interference from the alarm signal when decoding the standard messages. ",
    "url": "https://arxiv.org/abs/2302.11026",
    "authors": [
      "Khac-Hoang Ngo",
      "Giuseppe Durisi",
      "Alexandre Graell i Amat",
      "Petar Popovski",
      "Anders E. Kalor",
      "Beatriz Soret"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2302.11027",
    "title": "Analysis of Real-Time Hostile Activitiy Detection from Spatiotemporal  Features Using Time Distributed Deep CNNs, RNNs and Attention-Based  Mechanisms",
    "abstract": "Real-time video surveillance, through CCTV camera systems has become essential for ensuring public safety which is a priority today. Although CCTV cameras help a lot in increasing security, these systems require constant human interaction and monitoring. To eradicate this issue, intelligent surveillance systems can be built using deep learning video classification techniques that can help us automate surveillance systems to detect violence as it happens. In this research, we explore deep learning video classification techniques to detect violence as they are happening. Traditional image classification techniques fall short when it comes to classifying videos as they attempt to classify each frame separately for which the predictions start to flicker. Therefore, many researchers are coming up with video classification techniques that consider spatiotemporal features while classifying. However, deploying these deep learning models with methods such as skeleton points obtained through pose estimation and optical flow obtained through depth sensors, are not always practical in an IoT environment. Although these techniques ensure a higher accuracy score, they are computationally heavier. Keeping these constraints in mind, we experimented with various video classification and action recognition techniques such as ConvLSTM, LRCN (with both custom CNN layers and VGG-16 as feature extractor) CNNTransformer and C3D. We achieved a test accuracy of 80% on ConvLSTM, 83.33% on CNN-BiLSTM, 70% on VGG16-BiLstm ,76.76% on CNN-Transformer and 80% on C3D. ",
    "url": "https://arxiv.org/abs/2302.11027",
    "authors": [
      "Labib Ahmed Siddique",
      "Rabita Junhai",
      "Tanzim Reza",
      "Salman Sayeed Khan",
      "Tanvir Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11034",
    "title": "Counterfeit Chip Detection using Scattering Parameter Analysis",
    "abstract": "The increase in the number of counterfeit and recycled microelectronic chips in recent years has created significant security and safety concerns in various applications. Hence, detecting such counterfeit chips in electronic systems is critical before deployment in the field. Unfortunately, the conventional verification tools using physical inspection and side-channel methods are costly, unscalable, error-prone, and often incompatible with legacy systems. This paper introduces a generic non-invasive and low-cost counterfeit chip detection based on characterizing the impedance of the system's power delivery network (PDN). Our method relies on the fact that the impedance of the counterfeit and recycled chips differs from the genuine ones. To sense such impedance variations confidently, we deploy scattering parameters, frequently used for impedance characterization of RF/microwave circuits. Our proposed approach can directly be applied to soldered chips on the system's PCB and does not require any modifications on the legacy systems. To validate our claims, we perform extensive measurements on genuine and aged samples from two families of STMicroelectronics chips to assess the effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2302.11034",
    "authors": [
      "Maryam Saadat Safa",
      "Tahoura Mosavirik",
      "Shahin Tajik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.11044",
    "title": "The Target-Charging Technique for Privacy Accounting across Interactive  Computations",
    "abstract": "We propose the \\emph{Target Charging Technique} (TCT), a unified privacy accounting framework for interactive settings where a sensitive dataset is accessed multiple times using differentially private algorithms. Unlike traditional composition, where privacy guarantees deteriorate quickly with the number of accesses, TCT allows computations that don't hit a specified \\emph{target}, often the vast majority, to be essentially free (while incurring instead a small overhead on those that do hit their targets). TCT generalizes tools such as the sparse vector technique and top-$k$ selection from private candidates and extends their remarkable privacy accounting benefits from noisy Lipschitz functions to general private algorithms. ",
    "url": "https://arxiv.org/abs/2302.11044",
    "authors": [
      "Edith Cohen",
      "Xin Lyu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.11048",
    "title": "Adversarial Model for Offline Reinforcement Learning",
    "abstract": "We propose a novel model-based offline Reinforcement Learning (RL) framework, called Adversarial Model for Offline Reinforcement Learning (ARMOR), which can robustly learn policies to improve upon an arbitrary reference policy regardless of data coverage. ARMOR is designed to optimize policies for the worst-case performance relative to the reference policy through adversarially training a Markov decision process model. In theory, we prove that ARMOR, with a well-tuned hyperparameter, can compete with the best policy within data coverage when the reference policy is supported by the data. At the same time, ARMOR is robust to hyperparameter choices: the policy learned by ARMOR, with \"any\" admissible hyperparameter, would never degrade the performance of the reference policy, even when the reference policy is not covered by the dataset. To validate these properties in practice, we design a scalable implementation of ARMOR, which by adversarial training, can optimize policies without using model ensembles in contrast to typical model-based methods. We show that ARMOR achieves competent performance with both state-of-the-art offline model-free and model-based RL algorithms and can robustly improve the reference policy over various hyperparameter choices. ",
    "url": "https://arxiv.org/abs/2302.11048",
    "authors": [
      "Mohak Bhardwaj",
      "Tengyang Xie",
      "Byron Boots",
      "Nan Jiang",
      "Ching-An Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11050",
    "title": "Edgeformers: Graph-Empowered Transformers for Representation Learning on  Textual-Edge Networks",
    "abstract": "Edges in many real-world social/information networks are associated with rich text information (e.g., user-user communications or user-product reviews). However, mainstream network representation learning models focus on propagating and aggregating node attributes, lacking specific designs to utilize text semantics on edges. While there exist edge-aware graph neural networks, they directly initialize edge attributes as a feature vector, which cannot fully capture the contextualized text semantics of edges. In this paper, we propose Edgeformers, a framework built upon graph-enhanced Transformers, to perform edge and node representation learning by modeling texts on edges in a contextualized way. Specifically, in edge representation learning, we inject network information into each Transformer layer when encoding edge texts; in node representation learning, we aggregate edge representations through an attention mechanism within each node's ego-graph. On five public datasets from three different domains, Edgeformers consistently outperform state-of-the-art baselines in edge classification and link prediction, demonstrating the efficacy in learning edge and node representations, respectively. ",
    "url": "https://arxiv.org/abs/2302.11050",
    "authors": [
      "Bowen Jin",
      "Yu Zhang",
      "Yu Meng",
      "Jiawei Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.11055",
    "title": "SGD learning on neural networks: leap complexity and saddle-to-saddle  dynamics",
    "abstract": "We investigate the time complexity of SGD learning on fully-connected neural networks with isotropic data. We put forward a complexity measure -- the leap -- which measures how \"hierarchical\" target functions are. For $d$-dimensional uniform Boolean or isotropic Gaussian data, our main conjecture states that the time complexity to learn a function $f$ with low-dimensional support is $\\tilde\\Theta (d^{\\max(\\mathrm{Leap}(f),2)})$. We prove a version of this conjecture for a class of functions on Gaussian isotropic data and 2-layer neural networks, under additional technical assumptions on how SGD is run. We show that the training sequentially learns the function support with a saddle-to-saddle dynamic. Our result departs from [Abbe et al. 2022] by going beyond leap 1 (merged-staircase functions), and by going beyond the mean-field and gradient flow approximations that prohibit the full complexity control obtained here. Finally, we note that this gives an SGD complexity for the full training trajectory that matches that of Correlational Statistical Query (CSQ) lower-bounds. ",
    "url": "https://arxiv.org/abs/2302.11055",
    "authors": [
      "Emmanuel Abbe",
      "Enric Boix-Adsera",
      "Theodor Misiakiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.11064",
    "title": "Task-Oriented Prediction and Communication Co-Design for Haptic  Communications",
    "abstract": "Prediction has recently been considered as a promising approach to meet low-latency and high-reliability requirements in long-distance haptic communications. However, most of the existing methods did not take features of tasks and the relationship between prediction and communication into account. In this paper, we propose a task-oriented prediction and communication co-design framework, where the reliability of the system depends on prediction errors and packet losses in communications. The goal is to minimize the required radio resources subject to the low-latency and high-reliability requirements of various tasks. Specifically, we consider the just noticeable difference (JND) as a performance metric for the haptic communication system. We collect experiment data from a real-world teleoperation testbed and use time-series generative adversarial networks (TimeGAN) to generate a large amount of synthetic data. This allows us to obtain the relationship between the JND threshold, prediction horizon, and the overall reliability including communication reliability and prediction reliability. We take 5G New Radio as an example to demonstrate the proposed framework and optimize bandwidth allocation and data rates of devices. Our numerical and experimental results show that the proposed framework can reduce wireless resource consumption up to 77.80% compared with a task-agnostic benchmark. ",
    "url": "https://arxiv.org/abs/2302.11064",
    "authors": [
      "Burak Kizilkaya",
      "Changyang She",
      "Guodong Zhao",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.11068",
    "title": "Low Rank Matrix Completion via Robust Alternating Minimization in Nearly  Linear Time",
    "abstract": "Given a matrix $M\\in \\mathbb{R}^{m\\times n}$, the low rank matrix completion problem asks us to find a rank-$k$ approximation of $M$ as $UV^\\top$ for $U\\in \\mathbb{R}^{m\\times k}$ and $V\\in \\mathbb{R}^{n\\times k}$ by only observing a few entries masked by a binary matrix $P_{\\Omega}\\in \\{0, 1 \\}^{m\\times n}$. As a particular instance of the weighted low rank approximation problem, solving low rank matrix completion is known to be computationally hard even to find an approximate solution [RSW16]. However, due to its practical importance, many heuristics have been proposed for this problem. In the seminal work of Jain, Netrapalli, and Sanghavi [JNS13], they show that the alternating minimization framework provides provable guarantees for low rank matrix completion problem whenever $M$ admits an incoherent low rank factorization. Unfortunately, their algorithm requires solving two exact multiple response regressions per iteration and their analysis is non-robust as they exploit the structure of the exact solution. In this paper, we take a major step towards a more efficient and robust alternating minimization framework for low rank matrix completion. Our main result is a robust alternating minimization algorithm that can tolerate moderate errors even though the regressions are solved approximately. Consequently, we also significantly improve the running time of [JNS13] from $\\widetilde{O}(mnk^2 )$ to $\\widetilde{O}(mnk )$ which is nearly linear in the problem size, as verifying the low rank approximation takes $O(mnk)$ time. Our core algorithmic building block is a high accuracy regression solver that solves the regression in nearly linear time per iteration. ",
    "url": "https://arxiv.org/abs/2302.11068",
    "authors": [
      "Yuzhou Gu",
      "Zhao Song",
      "Junze Yin",
      "Lichen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.11082",
    "title": "BB-GCN: A Bi-modal Bridged Graph Convolutional Network for Multi-label  Chest X-Ray Recognition",
    "abstract": "Multi-label chest X-ray (CXR) recognition involves simultaneously diagnosing and identifying multiple labels for different pathologies. Since pathological labels have rich information about their relationship to each other, modeling the co-occurrence dependencies between pathological labels is essential to improve recognition performance. However, previous methods rely on state variable coding and attention mechanisms-oriented to model local label information, and lack learning of global co-occurrence relationships between labels. Furthermore, these methods roughly integrate image features and label embedding, ignoring the alignment and compactness problems in cross-modal vector fusion.To solve these problems, a Bi-modal Bridged Graph Convolutional Network (BB-GCN) model is proposed. This model mainly consists of a backbone module, a pathology Label Co-occurrence relationship Embedding (LCE) module, and a Transformer Bridge Graph (TBG) module. Specifically, the backbone module obtains image visual feature representation. The LCE module utilizes a graph to model the global co-occurrence relationship between multiple labels and employs graph convolutional networks for learning inference. The TBG module bridges the cross-modal vectors more compactly and efficiently through the GroupSum method.We have evaluated the effectiveness of the proposed BB-GCN in two large-scale CXR datasets (ChestX-Ray14 and CheXpert). Our model achieved state-of-the-art performance: the mean AUC scores for the 14 pathologies were 0.835 and 0.813, respectively.The proposed LCE and TBG modules can jointly effectively improve the recognition performance of BB-GCN. Our model also achieves satisfactory results in multi-label chest X-ray recognition and exhibits highly competitive generalization performance. ",
    "url": "https://arxiv.org/abs/2302.11082",
    "authors": [
      "Guoli Wang",
      "Pingping Wang",
      "Jinyu Cong",
      "Kunmeng Liu",
      "Benzheng Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11084",
    "title": "Distribution Normalization: An \"Effortless\" Test-Time Augmentation for  Contrastively Learned Visual-language Models",
    "abstract": "Advances in the field of visual-language contrastive learning have made it possible for many downstream applications to be carried out efficiently and accurately by simply taking the dot product between image and text representations. One of the most representative approaches proposed recently known as CLIP has quickly garnered widespread adoption due to its effectiveness. CLIP is trained with an InfoNCE loss that takes into account both positive and negative samples to help learn a much more robust representation space. This paper however reveals that the common downstream practice of taking a dot product is only a zeroth-order approximation of the optimization goal, resulting in a loss of information during test-time. Intuitively, since the model has been optimized based on the InfoNCE loss, test-time procedures should ideally also be in alignment. The question lies in how one can retrieve any semblance of negative samples information during inference. We propose Distribution Normalization (DN), where we approximate the mean representation of a batch of test samples and use such a mean to represent what would be analogous to negative samples in the InfoNCE loss. DN requires no retraining or fine-tuning and can be effortlessly applied during inference. Extensive experiments on a wide variety of downstream tasks exhibit a clear advantage of DN over the dot product. ",
    "url": "https://arxiv.org/abs/2302.11084",
    "authors": [
      "Yifei Zhou",
      "Juntao Ren",
      "Fengyu Li",
      "Ramin Zabih",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11091",
    "title": "GTRL: An Entity Group-Aware Temporal Knowledge Graph Representation  Learning Method",
    "abstract": "Temporal Knowledge Graph (TKG) representation learning embeds entities and event types into a continuous low-dimensional vector space by integrating the temporal information, which is essential for downstream tasks, e.g., event prediction and question answering. Existing methods stack multiple graph convolution layers to model the influence of distant entities, leading to the over-smoothing problem. To alleviate the problem, recent studies infuse reinforcement learning to obtain paths that contribute to modeling the influence of distant entities. However, due to the limited number of hops, these studies fail to capture the correlation between entities that are far apart and even unreachable. To this end, we propose GTRL, an entity Group-aware Temporal knowledge graph Representation Learning method. GTRL is the first work that incorporates the entity group modeling to capture the correlation between entities by stacking only a finite number of layers. Specifically, the entity group mapper is proposed to generate entity groups from entities in a learning way. Based on entity groups, the implicit correlation encoder is introduced to capture implicit correlations between any pairwise entity groups. In addition, the hierarchical GCNs are exploited to accomplish the message aggregation and representation updating on the entity group graph and the entity graph. Finally, GRUs are employed to capture the temporal dependency in TKGs. Extensive experiments on three real-world datasets demonstrate that GTRL achieves the state-of-the-art performances on the event prediction task, outperforming the best baseline by an average of 13.44%, 9.65%, 12.15%, and 15.12% in MRR, Hits@1, Hits@3, and Hits@10, respectively. ",
    "url": "https://arxiv.org/abs/2302.11091",
    "authors": [
      "Xing Tang",
      "Ling Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.11095",
    "title": "MM-SFENet: Multi-scale Multi-task Localization and Classification of  Bladder Cancer in MRI with Spatial Feature Encoder Network",
    "abstract": "Background and Objective: Bladder cancer is a common malignant urinary carcinoma, with muscle-invasive and non-muscle-invasive as its two major subtypes. This paper aims to achieve automated bladder cancer invasiveness localization and classification based on MRI. Method: Different from previous efforts that segment bladder wall and tumor, we propose a novel end-to-end multi-scale multi-task spatial feature encoder network (MM-SFENet) for locating and classifying bladder cancer, according to the classification criteria of the spatial relationship between the tumor and bladder wall. First, we built a backbone with residual blocks to distinguish bladder wall and tumor; then, a spatial feature encoder is designed to encode the multi-level features of the backbone to learn the criteria. Results: We substitute Smooth-L1 Loss with IoU Loss for multi-task learning, to improve the accuracy of the classification task. By testing a total of 1287 MRIs collected from 98 patients at the hospital, the mAP and IoU are used as the evaluation metrics. The experimental result could reach 93.34\\% and 83.16\\% on test set. Conclusions: The experimental result demonstrates the effectiveness of the proposed MM-SFENet on the localization and classification of bladder cancer. It may provide an effective supplementary diagnosis method for bladder cancer staging. ",
    "url": "https://arxiv.org/abs/2302.11095",
    "authors": [
      "Yu Ren",
      "Guoli Wang",
      "Pingping Wang",
      "Kunmeng Liu",
      "Quanjin Liu",
      "Hongfu Sun",
      "Xiang Li",
      "Benzheng Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11097",
    "title": "A Multi-Modal Neural Geometric Solver with Textual Clauses Parsed from  Diagram",
    "abstract": "Geometry problem solving (GPS) is a high-level mathematical reasoning requiring the capacities of multi-modal fusion and geometric knowledge application. Recently, neural solvers have shown great potential in GPS but still be short in diagram presentation and modal fusion. In this work, we convert diagrams into basic textual clauses to describe diagram features effectively, and propose a new neural solver called PGPSNet to fuse multi-modal information efficiently. Combining structural and semantic pre-training, data augmentation and self-limited decoding, PGPSNet is endowed with rich knowledge of geometry theorems and geometric representation, and therefore promotes geometric understanding and reasoning. In addition, to facilitate the research of GPS, we build a new large-scale and fine-annotated GPS dataset named PGPS9K, labeled with both fine-grained diagram annotation and interpretable solution program. Experiments on PGPS9K and an existing dataset Geometry3K validate the superiority of our method over the state-of-the-art neural solvers. The code and dataset will be public available soon. ",
    "url": "https://arxiv.org/abs/2302.11097",
    "authors": [
      "Ming-Liang Zhang",
      "Fei Yin",
      "Cheng-Lin Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11106",
    "title": "Multi-Head Feature Pyramid Networks for Breast Mass Detection",
    "abstract": "Analysis of X-ray images is one of the main tools to diagnose breast cancer. The ability to quickly and accurately detect the location of masses from the huge amount of image data is the key to reducing the morbidity and mortality of breast cancer. Currently, the main factor limiting the accuracy of breast mass detection is the unequal focus on the mass boxes, leading the network to focus too much on larger masses at the expense of smaller ones. In the paper, we propose the multi-head feature pyramid module (MHFPN) to solve the problem of unbalanced focus of target boxes during feature map fusion and design a multi-head breast mass detection network (MBMDnet). Experimental studies show that, comparing to the SOTA detection baselines, our method improves by 6.58% (in AP@50) and 5.4% (in TPR@50) on the commonly used INbreast dataset, while about 6-8% improvements (in AP@20) are also observed on the public MIAS and BCS-DBT datasets. ",
    "url": "https://arxiv.org/abs/2302.11106",
    "authors": [
      "Hexiang Zhang",
      "Zhenghua Xu",
      "Dan Yao",
      "Shuo Zhang",
      "Junyang Chen",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11121",
    "title": "Counterfactual Prediction Under Outcome Measurement Error",
    "abstract": "Across domains such as medicine, employment, and criminal justice, predictive models often target labels that imperfectly reflect the outcomes of interest to experts and policymakers. For example, clinical risk assessments deployed to inform physician decision-making often predict measures of healthcare utilization (e.g., costs, hospitalization) as a proxy for patient medical need. These proxies can be subject to outcome measurement error when they systematically differ from the target outcome they are intended to measure. However, prior modeling efforts to characterize and mitigate outcome measurement error overlook the fact that the decision being informed by a model often serves as a risk-mitigating intervention that impacts the target outcome of interest and its recorded proxy. Thus, in these settings, addressing measurement error requires counterfactual modeling of treatment effects on outcomes. In this work, we study intersectional threats to model reliability introduced by outcome measurement error, treatment effects, and selection bias from historical decision-making policies. We develop an unbiased risk minimization method which, given knowledge of proxy measurement error properties, corrects for the combined effects of these challenges. We also develop a method for estimating treatment-dependent measurement error parameters when these are unknown in advance. We demonstrate the utility of our approach theoretically and via experiments on real-world data from randomized controlled trials conducted in healthcare and employment domains. As importantly, we demonstrate that models correcting for outcome measurement error or treatment effects alone suffer from considerable reliability limitations. Our work underscores the importance of considering intersectional threats to model validity during the design and evaluation of predictive models for decision support. ",
    "url": "https://arxiv.org/abs/2302.11121",
    "authors": [
      "Luke Guerdan",
      "Amanda Coston",
      "Kenneth Holstein",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.11135",
    "title": "Semi-Supervised Approach for Early Stuck Sign Detection in Drilling  Operations",
    "abstract": "A real-time stuck pipe prediction methodology is proposed in this paper. We assume early signs of stuck pipe to be apparent when the drilling data behavior deviates from that from normal drilling operations. The definition of normalcy changes with drill string configuration or geological conditions. Here, a depth-domain data representation is adopted to capture the localized normal behavior. Several models, based on auto-encoder and variational auto-encoders, are trained on regular drilling data extracted from actual drilling data. When the trained model is applied to data sets before stuck incidents, eight incidents showed large reconstruction errors. These results suggest better performance than the previously reported supervised approach. Inter-comparison of various models reveals the robustness of our approach. The model performance depends on the featured parameter suggesting the need for multiple models in actual operation. ",
    "url": "https://arxiv.org/abs/2302.11135",
    "authors": [
      "Andres Hernandez-Matamoros",
      "Kohei Sugawara",
      "Tatsuya Kaneko",
      "Ryota Wada",
      "Masahiko Ozaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11152",
    "title": "Multi-Message Shuffled Privacy in Federated Learning",
    "abstract": "We study differentially private distributed optimization under communication constraints. A server using SGD for optimization aggregates the client-side local gradients for model updates using distributed mean estimation (DME). We develop a communication-efficient private DME, using the recently developed multi-message shuffled (MMS) privacy framework. We analyze our proposed DME scheme to show that it achieves the order-optimal privacy-communication-performance tradeoff resolving an open question in [1], whether the shuffled models can improve the tradeoff obtained in Secure Aggregation. This also resolves an open question on the optimal trade-off for private vector sum in the MMS model. We achieve it through a novel privacy mechanism that non-uniformly allocates privacy at different resolutions of the local gradient vectors. These results are directly applied to give guarantees on private distributed learning algorithms using this for private gradient aggregation iteratively. We also numerically evaluate the private DME algorithms. ",
    "url": "https://arxiv.org/abs/2302.11152",
    "authors": [
      "Antonious M. Girgis",
      "Suhas Diggavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.11159",
    "title": "BUAA_BIGSCity: Spatial-Temporal Graph Neural Network for Wind Power  Forecasting in Baidu KDD CUP 2022",
    "abstract": "In this technical report, we present our solution for the Baidu KDD Cup 2022 Spatial Dynamic Wind Power Forecasting Challenge. Wind power is a rapidly growing source of clean energy. Accurate wind power forecasting is essential for grid stability and the security of supply. Therefore, organizers provide a wind power dataset containing historical data from 134 wind turbines and launch the Baidu KDD Cup 2022 to examine the limitations of current methods for wind power forecasting. The average of RMSE (Root Mean Square Error) and MAE (Mean Absolute Error) is used as the evaluation score. We adopt two spatial-temporal graph neural network models, i.e., AGCRN and MTGNN, as our basic models. We train AGCRN by 5-fold cross-validation and additionally train MTGNN directly on the training and validation sets. Finally, we ensemble the two models based on the loss values of the validation set as our final submission. Using our method, our team \\team achieves -45.36026 on the test set. We release our codes on Github (https://github.com/BUAABIGSCity/KDDCUP2022) for reproduction. ",
    "url": "https://arxiv.org/abs/2302.11159",
    "authors": [
      "Jiawei Jiang",
      "Chengkai Han",
      "Jingyuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11188",
    "title": "What Are Effective Labels for Augmented Data? Improving Calibration and  Robustness with AutoLabel",
    "abstract": "A wide breadth of research has devised data augmentation approaches that can improve both accuracy and generalization performance for neural networks. However, augmented data can end up being far from the clean training data and what is the appropriate label is less clear. Despite this, most existing work simply uses one-hot labels for augmented data. In this paper, we show re-using one-hot labels for highly distorted data might run the risk of adding noise and degrading accuracy and calibration. To mitigate this, we propose a generic method AutoLabel to automatically learn the confidence in the labels for augmented data, based on the transformation distance between the clean distribution and augmented distribution. AutoLabel is built on label smoothing and is guided by the calibration-performance over a hold-out validation set. We successfully apply AutoLabel to three different data augmentation techniques: the state-of-the-art RandAug, AugMix, and adversarial training. Experiments on CIFAR-10, CIFAR-100 and ImageNet show that AutoLabel significantly improves existing data augmentation techniques over models' calibration and accuracy, especially under distributional shift. ",
    "url": "https://arxiv.org/abs/2302.11188",
    "authors": [
      "Yao Qin",
      "Xuezhi Wang",
      "Balaji Lakshminarayanan",
      "Ed H. Chi",
      "Alex Beutel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11192",
    "title": "Improving Contextual Spelling Correction by External Acoustics Attention  and Semantic Aware Data Augmentation",
    "abstract": "We previously proposed contextual spelling correction (CSC) to correct the output of end-to-end (E2E) automatic speech recognition (ASR) models with contextual information such as name, place, etc. Although CSC has achieved reasonable improvement in the biasing problem, there are still two drawbacks for further accuracy improvement. First, due to information limitation in text only hypothesis or weak performance of ASR model on rare domains, the CSC model may fail to correct phrases with similar pronunciation or anti-context cases where all biasing phrases are not present in the utterance. Second, there is a discrepancy between the training and inference of CSC. The bias list in training is randomly selected but in inference there may be more similarity between ground truth phrase and other phrases. To solve above limitations, in this paper we propose an improved non-autoregressive (NAR) spelling correction model for contextual biasing in E2E neural transducer-based ASR systems to improve the previous CSC model from two perspectives: Firstly, we incorporate acoustics information with an external attention as well as text hypotheses into CSC to better distinguish target phrase from dissimilar or irrelevant phrases. Secondly, we design a semantic aware data augmentation schema in training phrase to reduce the mismatch between training and inference to further boost the biasing accuracy. Experiments show that the improved method outperforms the baseline ASR+Biasing system by as much as 20.3% relative name recall gain and achieves stable improvement compared to the previous CSC method over different bias list name coverage ratio. ",
    "url": "https://arxiv.org/abs/2302.11192",
    "authors": [
      "Xiaoqiang Wang",
      "Yanqing Liu",
      "Jinyu Li",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.11195",
    "title": "Prediction of single well production rate in water-flooding oil fields  driven by the fusion of static, temporal and spatial information",
    "abstract": "It is very difficult to forecast the production rate of oil wells as the output of a single well is sensitive to various uncertain factors, which implicitly or explicitly show the influence of the static, temporal and spatial properties on the oil well production. In this study, a novel machine learning model is constructed to fuse the static geological information, dynamic well production history, and spatial information of the adjacent water injection wells. There are 3 basic modules in this stacking model, which are regarded as the encoders to extract the features from different types of data. One is Multi-Layer Perceptron, which is to analyze the static geological properties of the reservoir that might influence the well production rate. The other two are both LSTMs, which have the input in the form of two matrices rather than vectors, standing for the temporal and the spatial information of the target well. The difference of the two modules is that in the spatial information processing module we take into consideration the time delay of water flooding response, from the injection well to the target well. In addition, we use Symbolic Transfer Entropy to prove the superiorities of the stacking model from the perspective of Causality Discovery. It is proved theoretically and practically that the presented model can make full use of the model structure to integrate the characteristics of the data and the experts' knowledge into the process of machine learning, greatly improving the accuracy and generalization ability of prediction. ",
    "url": "https://arxiv.org/abs/2302.11195",
    "authors": [
      "Chao Min",
      "Yijia Wang",
      "Huohai Yang",
      "Wei Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11196",
    "title": "Invariant Target Detection in Images through the Normalized 2-D  Correlation Technique",
    "abstract": "The normalized 2-D correlation technique is a robust method for detecting targets in images due to its ability to remain invariant under rotation, translation, and scaling. This paper examines the impact of translation, and scaling on target identification in images. The results indicate a high level of accuracy in detecting targets, even when they are exhibit variations in location and size. The results indicate that the similarity between the image and the two used targets improves as the resize ratio increases. All statistical estimators demonstrate a strong similarity between the original and extracted targets. The elapsed time for all scenarios falls within the range (44.75-44.85), (37.48-37.73) seconds for bird and children targets respectively, and the correlation coefficient displays stable relationships with values that fall within the range of (0.90-0.98) and (0.87-0.93) for bird and children targets respectively. ",
    "url": "https://arxiv.org/abs/2302.11196",
    "authors": [
      "Fatin E. M. Al-Obaidi",
      "Anwar H. Al-Saleh",
      "Shaymaa H. Kafi",
      "Ali J.Karam",
      "Ali A. D. Al-Zuky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.11207",
    "title": "Improved Deterministic Leader Election in Diameter-Two Networks",
    "abstract": "In this paper, we investigate the leader election problem in diameter-two networks. Recently, Chatterjee et al. [DC 2020] studied the leader election in diameter-two networks. They presented a $O(\\log n)$-round deterministic {implicit} leader election algorithm which incurs optimal $O(n\\log n)$ messages, but a drawback of their algorithm is that it requires knowledge of $n$. An important question -- whether it is possible to remove the assumption on the knowledge of $n$ was left open in their paper. Another interesting open question raised in their paper is whether {\\em explicit} leader election can be solved in $\\tilde{O}(n)$ messages deterministically. In this paper, we give an affirmative answer to them. Further, we solve the {\\em broadcast problem}, another fundamental problem in distributed computing, deterministically in diameter-two networks with $\\tilde{O}(n)$ messages and $\\tilde{O}(1)$ rounds without the knowledge of $n$. In fact, we address all the open questions raised by Chatterjee et al. for the deterministic leader election problem in diameter-two networks. To the best of our knowledge, this is the first $\\tilde{O}(n)$ deterministic result for the explicit leader election in the diameter-two networks, that too without the knowledge of $n$. ",
    "url": "https://arxiv.org/abs/2302.11207",
    "authors": [
      "Manish Kumar",
      "Anisur Rahaman Molla",
      "Sumathi Sivasubramaniam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.11208",
    "title": "KS-DETR: Knowledge Sharing in Attention Learning for Detection  Transformer",
    "abstract": "Scaled dot-product attention applies a softmax function on the scaled dot-product of queries and keys to calculate weights and then multiplies the weights and values. In this work, we study how to improve the learning of scaled dot-product attention to improve the accuracy of DETR. Our method is based on the following observations: using ground truth foreground-background mask (GT Fg-Bg Mask) as additional cues in the weights/values learning enables learning much better weights/values; with better weights/values, better values/weights can be learned. We propose a triple-attention module in which the first attention is a plain scaled dot-product attention, the second/third attention generates high-quality weights/values (with the assistance of GT Fg-Bg Mask) and shares the values/weights with the first attention to improve the quality of values/weights. The second and third attentions are removed during inference. We call our method knowledge-sharing DETR (KS-DETR), which is an extension of knowledge distillation (KD) in the way that the improved weights and values of the teachers (the second and third attentions) are directly shared, instead of mimicked, by the student (the first attention) to enable more efficient knowledge transfer from the teachers to the student. Experiments on various DETR-like methods show consistent improvements over the baseline methods on the MS COCO benchmark. Code is available at https://github.com/edocanonymous/KS-DETR. ",
    "url": "https://arxiv.org/abs/2302.11208",
    "authors": [
      "Kaikai Zhao",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11211",
    "title": "Distributionally Robust Recourse Action",
    "abstract": "A recourse action aims to explain a particular algorithmic decision by showing one specific way in which the instance could be modified to receive an alternate outcome. Existing recourse generation methods often assume that the machine learning model does not change over time. However, this assumption does not always hold in practice because of data distribution shifts, and in this case, the recourse action may become invalid. To redress this shortcoming, we propose the Distributionally Robust Recourse Action (DiRRAc) framework, which generates a recourse action that has a high probability of being valid under a mixture of model shifts. We formulate the robustified recourse setup as a min-max optimization problem, where the max problem is specified by Gelbrich distance over an ambiguity set around the distribution of model parameters. Then we suggest a projected gradient descent algorithm to find a robust recourse according to the min-max objective. We show that our DiRRAc framework can be extended to hedge against the misspecification of the mixture weights. Numerical experiments with both synthetic and three real-world datasets demonstrate the benefits of our proposed framework over state-of-the-art recourse methods. ",
    "url": "https://arxiv.org/abs/2302.11211",
    "authors": [
      "Duy Nguyen",
      "Ngoc Bui",
      "Viet Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11231",
    "title": "Drugs Resistance Analysis from Scarce Health Records via Multi-task  Graph Representation",
    "abstract": "Clinicians prescribe antibiotics by looking at the patient's health record with an experienced eye. However, the therapy might be rendered futile if the patient has drug resistance. Determining drug resistance requires time-consuming laboratory-level testing while applying clinicians' heuristics in an automated way is difficult due to the categorical or binary medical events that constitute health records. In this paper, we propose a novel framework for rapid clinical intervention by viewing health records as graphs whose nodes are mapped from medical events and edges as correspondence between events in given a time window. A novel graph-based model is then proposed to extract informative features and yield automated drug resistance analysis from those high-dimensional and scarce graphs. The proposed method integrates multi-task learning into a common feature extracting graph encoder for simultaneous analyses of multiple drugs as well as stabilizing learning. On a massive dataset comprising over 110,000 patients with urinary tract infections, we verify the proposed method is capable of attaining superior performance on the drug resistance prediction problem. Furthermore, automated drug recommendations resemblant to laboratory-level testing can also be made based on the model resistance analysis. ",
    "url": "https://arxiv.org/abs/2302.11231",
    "authors": [
      "Honglin Shu",
      "Pei Gao",
      "Lingwei Zhu",
      "Zheng Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11234",
    "title": "Cluster Purging: Efficient Outlier Detection based on Rate-Distortion  Theory",
    "abstract": "Rate-distortion theory-based outlier detection builds upon the rationale that a good data compression will encode outliers with unique symbols. Based on this rationale, we propose Cluster Purging, which is an extension of clustering-based outlier detection. This extension allows one to assess the representivity of clusterings, and to find data that are best represented by individual unique clusters. We propose two efficient algorithms for performing Cluster Purging, one being parameter-free, while the other algorithm has a parameter that controls representivity estimations, allowing it to be tuned in supervised setups. In an experimental evaluation, we show that Cluster Purging improves upon outliers detected from raw clusterings, and that Cluster Purging competes strongly against state-of-the-art alternatives. ",
    "url": "https://arxiv.org/abs/2302.11234",
    "authors": [
      "Maximilian B. Toller",
      "Bernhard C. Geiger",
      "Roman Kern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11239",
    "title": "Robust and Explainable Contextual Anomaly Detection using Quantile  Regression Forests",
    "abstract": "Traditional anomaly detection methods aim to identify objects that deviate from most other objects by treating all features equally. In contrast, contextual anomaly detection methods aim to detect objects that deviate from other objects within a context of similar objects by dividing the features into contextual features and behavioral features. In this paper, we develop connections between dependency-based traditional anomaly detection methods and contextual anomaly detection methods. Based on resulting insights, we propose a novel approach to robust and inherently interpretable contextual anomaly detection that uses Quantile Regression Forests to model dependencies between features. Extensive experiments on various synthetic and real-world datasets demonstrate that our method outperforms state-of-the-art anomaly detection methods in identifying contextual anomalies in terms of accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2302.11239",
    "authors": [
      "Zhong Li",
      "Matthijs van Leeuwen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11268",
    "title": "Towards Decentralized Predictive Quality of Service in Next-Generation  Vehicular Networks",
    "abstract": "To ensure safety in teleoperated driving scenarios, communication between vehicles and remote drivers must satisfy strict latency and reliability requirements. In this context, Predictive Quality of Service (PQoS) was investigated as a tool to predict unanticipated degradation of the Quality of Service (QoS), and allow the network to react accordingly. In this work, we design a reinforcement learning (RL) agent to implement PQoS in vehicular networks. To do so, based on data gathered at the Radio Access Network (RAN) and/or the end vehicles, as well as QoS predictions, our framework is able to identify the optimal level of compression to send automotive data under low latency and reliability constraints. We consider different learning schemes, including centralized, fully-distributed, and federated learning. We demonstrate via ns-3 simulations that, while centralized learning generally outperforms any other solution, decentralized learning, and especially federated learning, offers a good trade-off between convergence time and reliability, with positive implications in terms of privacy and complexity. ",
    "url": "https://arxiv.org/abs/2302.11268",
    "authors": [
      "Filippo Bragato",
      "Tommaso Lotta",
      "Gianmaria Ventura",
      "Matteo Drago",
      "Federico Mason",
      "Marco Giordani",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11296",
    "title": "Refining a $k$-nearest neighbor graph for a computationally efficient  spectral clustering",
    "abstract": "Spectral clustering became a popular choice for data clustering for its ability of uncovering clusters of different shapes. However, it is not always preferable over other clustering methods due to its computational demands. One of the effective ways to bypass these computational demands is to perform spectral clustering on a subset of points (data representatives) then generalize the clustering outcome, this is known as approximate spectral clustering (ASC). ASC uses sampling or quantization to select data representatives. This makes it vulnerable to 1) performance inconsistency (since these methods have a random step either in initialization or training), 2) local statistics loss (because the pairwise similarities are extracted from data representatives instead of data points). We proposed a refined version of $k$-nearest neighbor graph, in which we keep data points and aggressively reduce number of edges for computational efficiency. Local statistics were exploited to keep the edges that do not violate the intra-cluster distances and nullify all other edges in the $k$-nearest neighbor graph. We also introduced an optional step to automatically select the number of clusters $C$. The proposed method was tested on synthetic and real datasets. Compared to ASC methods, the proposed method delivered a consistent performance despite significant reduction of edges. ",
    "url": "https://arxiv.org/abs/2302.11296",
    "authors": [
      "Mashaan Alshammari",
      "John Stavrakakis",
      "Masahiro Takatsuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.11299",
    "title": "Towards End-to-end Semi-supervised Learning for One-stage Object  Detection",
    "abstract": "Semi-supervised object detection (SSOD) is a research hot spot in computer vision, which can greatly reduce the requirement for expensive bounding-box annotations. Despite great success, existing progress mainly focuses on two-stage detection networks like FasterRCNN, while the research on one-stage detectors is often ignored. In this paper, we focus on the semi-supervised learning for the advanced and popular one-stage detection network YOLOv5. Compared with Faster-RCNN, the implementation of YOLOv5 is much more complex, and the various training techniques used in YOLOv5 can also reduce the benefit of SSOD. In addition to this challenge, we also reveal two key issues in one-stage SSOD, which are low-quality pseudo-labeling and multi-task optimization conflict, respectively. To address these issues, we propose a novel teacher-student learning recipe called OneTeacher with two innovative designs, namely Multi-view Pseudo-label Refinement (MPR) and Decoupled Semi-supervised Optimization (DSO). In particular, MPR improves the quality of pseudo-labels via augmented-view refinement and global-view filtering, and DSO handles the joint optimization conflicts via structure tweaks and task-specific pseudo-labeling. In addition, we also carefully revise the implementation of YOLOv5 to maximize the benefits of SSOD, which is also shared with the existing SSOD methods for fair comparison. To validate OneTeacher, we conduct extensive experiments on COCO and Pascal VOC. The extensive experiments show that OneTeacher can not only achieve superior performance than the compared methods, e.g., 15.0% relative AP gains over Unbiased Teacher, but also well handle the key issues in one-stage SSOD. Our source code is available at: https://github.com/luogen1996/OneTeacher. ",
    "url": "https://arxiv.org/abs/2302.11299",
    "authors": [
      "Gen Luo",
      "Yiyi Zhou",
      "Lei Jin",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11327",
    "title": "Boosting the performance of deep learning: A gradient Boosting approach  to training convolutional and deep neural network",
    "abstract": "Deep learning has revolutionized the computer vision and image classification domains. In this context Convolutional Neural Networks (CNNs) based architectures are the most widely applied models. In this article, we introduced two procedures for training Convolutional Neural Networks (CNNs) and Deep Neural Network based on Gradient Boosting (GB), namely GB-CNN and GB-DNN. These models are trained to fit the gradient of the loss function or pseudo-residuals of previous models. At each iteration, the proposed method adds one dense layer to an exact copy of the previous deep NN model. The weights of the dense layers trained on previous iterations are frozen to prevent over-fitting, permitting the model to fit the new dense as well as to fine-tune the convolutional layers (for GB-CNN) while still utilizing the information already learned. Through extensive experimentation on different 2D-image classification and tabular datasets, the presented models show superior performance in terms of classification accuracy with respect to standard CNN and Deep-NN with the same architecture. ",
    "url": "https://arxiv.org/abs/2302.11327",
    "authors": [
      "Seyedsaman Emami",
      "Gonzalo Mart\u00ednez-Mu\u00f1oz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11328",
    "title": "PAD: Towards Principled Adversarial Malware Detection Against Evasion  Attacks",
    "abstract": "Machine Learning (ML) techniques facilitate automating malicious software (malware for short) detection, but suffer from evasion attacks. Many researchers counter such attacks in heuristic manners short of both theoretical guarantees and defense effectiveness. We hence propose a new adversarial training framework, termed Principled Adversarial Malware Detection (PAD), which encourages convergence guarantees for robust optimization methods. PAD lays on a learnable convex measurement that quantifies distribution-wise discrete perturbations and protects the malware detector from adversaries, by which for smooth detectors, adversarial training can be performed heuristically with theoretical treatments. To promote defense effectiveness, we propose a new mixture of attacks to instantiate PAD for enhancing the deep neural network-based measurement and malware detector. Experimental results on two Android malware datasets demonstrate: (i) the proposed method significantly outperforms the state-of-the-art defenses; (ii) it can harden the ML-based malware detection against 27 evasion attacks with detection accuracies greater than 83.45%, while suffering an accuracy decrease smaller than 2.16% in the absence of attacks; (iii) it matches or outperforms many anti-malware scanners in VirusTotal service against realistic adversarial malware. ",
    "url": "https://arxiv.org/abs/2302.11328",
    "authors": [
      "Deqiang Li",
      "Shicheng Cui",
      "Yun Li",
      "Jia Xu",
      "Fu Xiao",
      "Shouhuai Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.11329",
    "title": "HINormer: Representation Learning On Heterogeneous Information Networks  with Graph Transformer",
    "abstract": "Recent studies have highlighted the limitations of message-passing based graph neural networks (GNNs), e.g., limited model expressiveness, over-smoothing, over-squashing, etc. To alleviate these issues, Graph Transformers (GTs) have been proposed which work in the paradigm that allows message passing to a larger coverage even across the whole graph. Hinging on the global range attention mechanism, GTs have shown a superpower for representation learning on homogeneous graphs. However, the investigation of GTs on heterogeneous information networks (HINs) is still under-exploited. In particular, on account of the existence of heterogeneity, HINs show distinct data characteristics and thus require different treatment. To bridge this gap, in this paper we investigate the representation learning on HINs with Graph Transformer, and propose a novel model named HINormer, which capitalizes on a larger-range aggregation mechanism for node representation learning. In particular, assisted by two major modules, i.e., a local structure encoder and a heterogeneous relation encoder, HINormer can capture both the structural and heterogeneous information of nodes on HINs for comprehensive node representations. We conduct extensive experiments on four HIN benchmark datasets, which demonstrate that our proposed model can outperform the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2302.11329",
    "authors": [
      "Qiheng Mao",
      "Zemin Liu",
      "Chenghao Liu",
      "Jianling Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11343",
    "title": "Advancing Stuttering Detection via Data Augmentation, Class-Balanced  Loss and Multi-Contextual Deep Learning",
    "abstract": "Stuttering is a neuro-developmental speech impairment characterized by uncontrolled utterances (interjections) and core behaviors (blocks, repetitions, and prolongations), and is caused by the failure of speech sensorimotors. Due to its complex nature, stuttering detection (SD) is a difficult task. If detected at an early stage, it could facilitate speech therapists to observe and rectify the speech patterns of persons who stutter (PWS). The stuttered speech of PWS is usually available in limited amounts and is highly imbalanced. To this end, we address the class imbalance problem in the SD domain via a multibranching (MB) scheme and by weighting the contribution of classes in the overall loss function, resulting in a huge improvement in stuttering classes on the SEP-28k dataset over the baseline (StutterNet). To tackle data scarcity, we investigate the effectiveness of data augmentation on top of a multi-branched training scheme. The augmented training outperforms the MB StutterNet (clean) by a relative margin of 4.18% in macro F1-score (F1). In addition, we propose a multi-contextual (MC) StutterNet, which exploits different contexts of the stuttered speech, resulting in an overall improvement of 4.48% in F 1 over the single context based MB StutterNet. Finally, we have shown that applying data augmentation in the cross-corpora scenario can improve the overall SD performance by a relative margin of 13.23% in F1 over the clean training. ",
    "url": "https://arxiv.org/abs/2302.11343",
    "authors": [
      "Shakeel A. Sheikh",
      "Md Sahidullah",
      "Fabrice Hirsch",
      "Slim Ouni"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.11344",
    "title": "Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt  Representation Drift in Continual Learning",
    "abstract": "Humans excel at lifelong learning, as the brain has evolved to be robust to distribution shifts and noise in our ever-changing environment. Deep neural networks (DNNs), however, exhibit catastrophic forgetting and the learned representations drift drastically as they encounter a new task. This alludes to a different error-based learning mechanism in the brain. Unlike DNNs, where learning scales linearly with the magnitude of the error, the sensitivity to errors in the brain decreases as a function of their magnitude. To this end, we propose \\textit{ESMER} which employs a principled mechanism to modulate error sensitivity in a dual-memory rehearsal-based system. Concretely, it maintains a memory of past errors and uses it to modify the learning dynamics so that the model learns more from small consistent errors compared to large sudden errors. We also propose \\textit{Error-Sensitive Reservoir Sampling} to maintain episodic memory, which leverages the error history to pre-select low-loss samples as candidates for the buffer, which are better suited for retaining information. Empirical results show that ESMER effectively reduces forgetting and abrupt drift in representations at the task boundary by gradually adapting to the new task while consolidating knowledge. Remarkably, it also enables the model to learn under high levels of label noise, which is ubiquitous in real-world data streams. ",
    "url": "https://arxiv.org/abs/2302.11344",
    "authors": [
      "Fahad Sarfraz",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11346",
    "title": "Task-Aware Information Routing from Common Representation Space in  Lifelong Learning",
    "abstract": "Intelligent systems deployed in the real world suffer from catastrophic forgetting when exposed to a sequence of tasks. Humans, on the other hand, acquire, consolidate, and transfer knowledge between tasks that rarely interfere with the consolidated knowledge. Accompanied by self-regulated neurogenesis, continual learning in the brain is governed by a rich set of neurophysiological processes that harbor different types of knowledge, which are then integrated by conscious processing. Thus, inspired by the Global Workspace Theory of conscious information access in the brain, we propose TAMiL, a continual learning method that entails task-attention modules to capture task-specific information from the common representation space. We employ simple, undercomplete autoencoders to create a communication bottleneck between the common representation space and the global workspace, allowing only the task-relevant information to the global workspace, thus greatly reducing task interference. Experimental results show that our method outperforms state-of-the-art rehearsal-based and dynamic sparse approaches and bridges the gap between fixed capacity and parameter isolation approaches while being scalable. We also show that our method effectively mitigates catastrophic forgetting while being well-calibrated with reduced task-recency bias. ",
    "url": "https://arxiv.org/abs/2302.11346",
    "authors": [
      "Prashant Bhat",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11349",
    "title": "Steerable Equivariant Representation Learning",
    "abstract": "Pre-trained deep image representations are useful for post-training tasks such as classification through transfer learning, image retrieval, and object detection. Data augmentations are a crucial aspect of pre-training robust representations in both supervised and self-supervised settings. Data augmentations explicitly or implicitly promote invariance in the embedding space to the input image transformations. This invariance reduces generalization to those downstream tasks which rely on sensitivity to these particular data augmentations. In this paper, we propose a method of learning representations that are instead equivariant to data augmentations. We achieve this equivariance through the use of steerable representations. Our representations can be manipulated directly in embedding space via learned linear maps. We demonstrate that our resulting steerable and equivariant representations lead to better performance on transfer learning and robustness: e.g. we improve linear probe top-1 accuracy by between 1% to 3% for transfer; and ImageNet-C accuracy by upto 3.4%. We further show that the steerability of our representations provides significant speedup (nearly 50x) for test-time augmentations; by applying a large number of augmentations for out-of-distribution detection, we significantly improve OOD AUC on the ImageNet-C dataset over an invariant representation. ",
    "url": "https://arxiv.org/abs/2302.11349",
    "authors": [
      "Sangnie Bhardwaj",
      "Willie McClinton",
      "Tongzhou Wang",
      "Guillaume Lajoie",
      "Chen Sun",
      "Phillip Isola",
      "Dilip Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11351",
    "title": "Regularised neural networks mimic human insight",
    "abstract": "Humans sometimes show sudden improvements in task performance that have been linked to moments of insight. Such insight-related performance improvements appear special because they are preceded by an extended period of impasse, are unusually abrupt, and occur only in some, but not all, learners. Here, we ask whether insight-like behaviour also occurs in artificial neural networks trained with gradient descent algorithms. We compared learning dynamics in humans and regularised neural networks in a perceptual decision task that provided a hidden opportunity which allowed to solve the task more efficiently. We show that humans tend to discover this regularity through insight, rather than gradually. Notably, neural networks with regularised gate modulation closely mimicked behavioural characteristics of human insights, exhibiting delay of insight, suddenness and selective occurrence. Analyses of network learning dynamics revealed that insight-like behaviour crucially depended on noise added to gradient updates, and was preceded by ``silent knowledge'' that is initially suppressed by regularised (attentional) gating. This suggests that insights can arise naturally from gradual learning, where they reflect the combined influences of noise, attentional gating and regularisation. ",
    "url": "https://arxiv.org/abs/2302.11351",
    "authors": [
      "Anika T. L\u00f6we",
      "L\u00e9o Touzo",
      "Paul S. Muhle-Karbe",
      "Andrew M. Saxe",
      "Christopher Summerfield",
      "Nicolas W. Schuck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2302.11352",
    "title": "X-TRA: Improving Chest X-ray Tasks with Cross-Modal Retrieval  Augmentation",
    "abstract": "An important component of human analysis of medical images and their context is the ability to relate newly seen things to related instances in our memory. In this paper we mimic this ability by using multi-modal retrieval augmentation and apply it to several tasks in chest X-ray analysis. By retrieving similar images and/or radiology reports we expand and regularize the case at hand with additional knowledge, while maintaining factual knowledge consistency. The method consists of two components. First, vision and language modalities are aligned using a pre-trained CLIP model. To enforce that the retrieval focus will be on detailed disease-related content instead of global visual appearance it is fine-tuned using disease class information. Subsequently, we construct a non-parametric retrieval index, which reaches state-of-the-art retrieval levels. We use this index in our downstream tasks to augment image representations through multi-head attention for disease classification and report retrieval. We show that retrieval augmentation gives considerable improvements on these tasks. Our downstream report retrieval even shows to be competitive with dedicated report generation methods, paving the path for this method in medical imaging. ",
    "url": "https://arxiv.org/abs/2302.11352",
    "authors": [
      "Tom van Sonsbeek",
      "Marcel Worring"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11354",
    "title": "Learning Dynamic Graph Embeddings with Neural Controlled Differential  Equations",
    "abstract": "This paper focuses on representation learning for dynamic graphs with temporal interactions. A fundamental issue is that both the graph structure and the nodes own their own dynamics, and their blending induces intractable complexity in the temporal evolution over graphs. Drawing inspiration from the recent process of physical dynamic models in deep neural networks, we propose Graph Neural Controlled Differential Equation (GN-CDE) model, a generic differential model for dynamic graphs that characterise the continuously dynamic evolution of node embedding trajectories with a neural network parameterised vector field and the derivatives of interactions w.r.t. time. Our framework exhibits several desirable characteristics, including the ability to express dynamics on evolving graphs without integration by segments, the capability to calibrate trajectories with subsequent data, and robustness to missing observations. Empirical evaluation on a range of dynamic graph representation learning tasks demonstrates the superiority of our proposed approach compared to the baselines. ",
    "url": "https://arxiv.org/abs/2302.11354",
    "authors": [
      "Tiexin Qin",
      "Benjamin Walker",
      "Terry Lyons",
      "Hong Yan",
      "Haoliang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11361",
    "title": "Saliency detection and quantization index modulation based high payload  HDR image watermarking",
    "abstract": "High-dynamic range (HDR) images are circulated rapidly over the internet with risks of being exploited for unauthenticated usage. To protect these images, some HDR image based watermarking (HDR-IW) methods were put forward. However, they inherited the same problem faced by conventional IW methods for standard dynamic range (SDR) images, where only trade-offs among conflicting requirements are managed instead of simultaneous improvement. In this paper, a novel saliency (eye-catching object) detection based trade-off independent HDR-IW is proposed, to simultaneously improve robustness, imperceptibility and payload capacity. First, the host image goes through our proposed salient object detection model to produce a saliency map, which is, in turn, exploited to segment the foreground and background of the host image. Next, binary watermark is partitioned into the foregrounds and backgrounds using the same mask and scrambled using the random permutation algorithm. Finally, the watermark segments are embedded into the corresponding host segments (i.e., selected bit-plane) using quantized indexed modulation. Experimental results suggest that the proposed work outperforms state-of-the-art methods in terms of improving the conflicting requirements. ",
    "url": "https://arxiv.org/abs/2302.11361",
    "authors": [
      "Ahmed Khan",
      "Minoru Kuribayashi",
      "KokSheik Wong",
      "Vishnu Monn Baskaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.11365",
    "title": "The Impact of Subword Pooling Strategy for Cross-lingual Event Detection",
    "abstract": "Pre-trained multilingual language models (e.g., mBERT, XLM-RoBERTa) have significantly advanced the state-of-the-art for zero-shot cross-lingual information extraction. These language models ubiquitously rely on word segmentation techniques that break a word into smaller constituent subwords. Therefore, all word labeling tasks (e.g. named entity recognition, event detection, etc.), necessitate a pooling strategy that takes the subword representations as input and outputs a representation for the entire word. Taking the task of cross-lingual event detection as a motivating example, we show that the choice of pooling strategy can have a significant impact on the target language performance. For example, the performance varies by up to 16 absolute $f_{1}$ points depending on the pooling strategy when training in English and testing in Arabic on the ACE task. We carry out our analysis with five different pooling strategies across nine languages in diverse multi-lingual datasets. Across configurations, we find that the canonical strategy of taking just the first subword to represent the entire word is usually sub-optimal. On the other hand, we show that attention pooling is robust to language and dataset variations by being either the best or close to the optimal strategy. For reproducibility, we make our code available at https://github.com/isi-boston/ed-pooling. ",
    "url": "https://arxiv.org/abs/2302.11365",
    "authors": [
      "Shantanu Agarwal",
      "Steven Fincke",
      "Chris Jenkins",
      "Scott Miller",
      "Elizabeth Boschee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11370",
    "title": "Recall as a Measure of Ranking Robustness",
    "abstract": "Researchers use recall to evaluate rankings across a variety of retrieval, recommendation, and machine learning tasks. While there is a colloquial interpretation of recall in set-based evaluation, the research community is far from a principled understanding of recall metrics for rankings. The lack of principled understanding of or motivation for recall has resulted in criticism amongst the retrieval community that recall is useful as a measure at all. In this light, we reflect on the measurement of recall in rankings from a formal perspective. Our analysis is composed of three tenets: recall, robustness, and lexicographic evaluation. First, we formally define `recall-orientation' as sensitivity to movement of the bottom-ranked relevant item. Second, we analyze our concept of recall orientation from the perspective of robustness with respect to possible searchers and content providers. Finally, we extend this conceptual and theoretical treatment of recall by developing a practical preference-based evaluation method based on lexicographic comparison. Through extensive empirical analysis across 17 TREC tracks, we establish that our new evaluation method, lexirecall, is correlated with existing recall metrics and exhibits substantially higher discriminative power and stability in the presence of missing labels. Our conceptual, theoretical, and empirical analysis substantially deepens our understanding of recall and motivates its adoption through connections to robustness and fairness. ",
    "url": "https://arxiv.org/abs/2302.11370",
    "authors": [
      "Fernando Diaz",
      "Bhaskar Mitra"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.11396",
    "title": "KGTrust: Evaluating Trustworthiness of SIoT via Knowledge Enhanced Graph  Neural Networks",
    "abstract": "Social Internet of Things (SIoT), a promising and emerging paradigm that injects the notion of social networking into smart objects (i.e., things), paving the way for the next generation of Internet of Things. However, due to the risks and uncertainty, a crucial and urgent problem to be settled is establishing reliable relationships within SIoT, that is, trust evaluation. Graph neural networks for trust evaluation typically adopt a straightforward way such as one-hot or node2vec to comprehend node characteristics, which ignores the valuable semantic knowledge attached to nodes. Moreover, the underlying structure of SIoT is usually complex, including both the heterogeneous graph structure and pairwise trust relationships, which renders hard to preserve the properties of SIoT trust during information propagation. To address these aforementioned problems, we propose a novel knowledge-enhanced graph neural network (KGTrust) for better trust evaluation in SIoT. Specifically, we first extract useful knowledge from users' comment behaviors and external structured triples related to object descriptions, in order to gain a deeper insight into the semantics of users and objects. Furthermore, we introduce a discriminative convolutional layer that utilizes heterogeneous graph structure, node semantics, and augmented trust relationships to learn node embeddings from the perspective of a user as a trustor or a trustee, effectively capturing multi-aspect properties of SIoT trust during information propagation. Finally, a trust prediction layer is developed to estimate the trust relationships between pairwise nodes. Extensive experiments on three public datasets illustrate the superior performance of KGTrust over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2302.11396",
    "authors": [
      "Zhizhi Yu",
      "Di Jin",
      "Cuiying Huo",
      "Zhiqiang Wang",
      "Xiulong Liu",
      "Heng Qi",
      "Jia Wu",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11408",
    "title": "ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep  Learning Paradigms",
    "abstract": "Backdoor data detection is traditionally studied in an end-to-end supervised learning (SL) setting. However, recent years have seen the proliferating adoption of self-supervised learning (SSL) and transfer learning (TL), due to their lesser need for labeled data. Successful backdoor attacks have also been demonstrated in these new settings. However, we lack a thorough understanding of the applicability of existing detection methods across a variety of learning settings. By evaluating 56 attack settings, we show that the performance of most existing detection methods varies significantly across different attacks and poison ratios, and all fail on the state-of-the-art clean-label attack. In addition, they either become inapplicable or suffer large performance losses when applied to SSL and TL. We propose a new detection method called Active Separation via Offset (ASSET), which actively induces different model behaviors between the backdoor and clean samples to promote their separation. We also provide procedures to adaptively select the number of suspicious points to remove. In the end-to-end SL setting, ASSET is superior to existing methods in terms of consistency of defensive performance across different attacks and robustness to changes in poison ratios; in particular, it is the only method that can detect the state-of-the-art clean-label attack. Moreover, ASSET's average detection rates are higher than the best existing methods in SSL and TL, respectively, by 69.3% and 33.2%, thus providing the first practical backdoor defense for these new DL settings. We open-source the project to drive further development and encourage engagement: https://github.com/ruoxi-jia-group/ASSET. ",
    "url": "https://arxiv.org/abs/2302.11408",
    "authors": [
      "Minzhou Pan",
      "Yi Zeng",
      "Lingjuan Lyu",
      "Xue Lin",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11412",
    "title": "Data Augmentation for Neural NLP",
    "abstract": "Data scarcity is a problem that occurs in languages and tasks where we do not have large amounts of labeled data but want to use state-of-the-art models. Such models are often deep learning models that require a significant amount of data to train. Acquiring data for various machine learning problems is accompanied by high labeling costs. Data augmentation is a low-cost approach for tackling data scarcity. This paper gives an overview of current state-of-the-art data augmentation methods used for natural language processing, with an emphasis on methods for neural and transformer-based models. Furthermore, it discusses the practical challenges of data augmentation, possible mitigations, and directions for future research. ",
    "url": "https://arxiv.org/abs/2302.11412",
    "authors": [
      "Domagoj Plu\u0161\u010dec",
      "Jan \u0160najder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11413",
    "title": "Gradient Adjusting Networks for Domain Inversion",
    "abstract": "StyleGAN2 was demonstrated to be a powerful image generation engine that supports semantic editing. However, in order to manipulate a real-world image, one first needs to be able to retrieve its corresponding latent representation in StyleGAN's latent space that is decoded to an image as close as possible to the desired image. For many real-world images, a latent representation does not exist, which necessitates the tuning of the generator network. We present a per-image optimization method that tunes a StyleGAN2 generator such that it achieves a local edit to the generator's weights, resulting in almost perfect inversion, while still allowing image editing, by keeping the rest of the mapping between an input latent representation tensor and an output image relatively intact. The method is based on a one-shot training of a set of shallow update networks (aka. Gradient Modification Modules) that modify the layers of the generator. After training the Gradient Modification Modules, a modified generator is obtained by a single application of these networks to the original parameters, and the previous editing capabilities of the generator are maintained. Our experiments show a sizable gap in performance over the current state of the art in this very active domain. Our code is available at \\url{https://github.com/sheffier/gani}. ",
    "url": "https://arxiv.org/abs/2302.11413",
    "authors": [
      "Erez Sheffi",
      "Michael Rotman",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.11426",
    "title": "Mining compact high utility sequential patterns",
    "abstract": "High utility sequential pattern mining (HUSPM) aims to mine all patterns that yield a high utility (profit) in a sequence dataset. HUSPM is useful for several applications such as market basket analysis, marketing, and website clickstream analysis. In these applications, users may also consider high utility patterns frequently appearing in the dataset to obtain more fruitful information. However, this task is high computation since algorithms may generate a combinatorial explosive number of candidates that may be redundant or of low importance. To reduce complexity and obtain a compact set of frequent high utility sequential patterns (FHUSPs), this paper proposes an algorithm named CHUSP for mining closed frequent high utility sequential patterns (CHUSPs). Such patterns keep a concise representation while preserving the same expressive power of the complete set of FHUSPs. The proposed algorithm relies on a CHUS data structure to maintain information during mining. It uses three pruning strategies to eliminate early low-utility and non-frequent patterns, thereby reducing the search space. An extensive experimental evaluation was performed on six real-life datasets to evaluate the performance of CHUSP in terms of execution time, memory usage, and the number of generated patterns. Experimental results show that CHUSP can efficiently discover the compact set of CHUSPs under different user-defined thresholds. ",
    "url": "https://arxiv.org/abs/2302.11426",
    "authors": [
      "Tai Dinh",
      "Philippe Fournier-Viger",
      "Huynh Van Hong"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.11466",
    "title": "Advancements in Federated Learning: Models, Methods, and Privacy",
    "abstract": "Federated learning (FL) is a promising technique for addressing the rising privacy and security issues. Its main ingredient is to cooperatively learn the model among the distributed clients without uploading any sensitive data. In this paper, we conducted a thorough review of the related works, following the development context and deeply mining the key technologies behind FL from both theoretical and practical perspectives. Specifically, we first classify the existing works in FL architecture based on the network topology of FL systems with detailed analysis and summarization. Next, we abstract the current application problems, summarize the general techniques and frame the application problems into the general paradigm of FL base models. Moreover, we provide our proposed solutions for model training via FL. We have summarized and analyzed the existing FedOpt algorithms, and deeply revealed the algorithmic development principles of many first-order algorithms in depth, proposing a more generalized algorithm design framework. Based on these frameworks, we have instantiated FedOpt algorithms. As privacy and security is the fundamental requirement in FL, we provide the existing attack scenarios and the defense methods. To the best of our knowledge, we are among the first tier to review the theoretical methodology and propose our strategies since there are very few works surveying the theoretical approaches. Our survey targets motivating the development of high-performance, privacy-preserving, and secure methods to integrate FL into real-world applications. ",
    "url": "https://arxiv.org/abs/2302.11466",
    "authors": [
      "Huiming Chen",
      "Huandong Wang",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.11467",
    "title": "Power Constrained Autotuning using Graph Neural Networks",
    "abstract": "Recent advances in multi and many-core processors have led to significant improvements in the performance of scientific computing applications. However, the addition of a large number of complex cores have also increased the overall power consumption, and power has become a first-order design constraint in modern processors. While we can limit power consumption by simply applying software-based power constraints, applying them blindly will lead to non-trivial performance degradation. To address the challenge of improving the performance, power, and energy efficiency of scientific applications on modern multi-core processors, we propose a novel Graph Neural Network based auto-tuning approach that (i) optimizes runtime performance at pre-defined power constraints, and (ii) simultaneously optimizes for runtime performance and energy efficiency by minimizing the energy-delay product. The key idea behind this approach lies in modeling parallel code regions as flow-aware code graphs to capture both semantic and structural code features. We demonstrate the efficacy of our approach by conducting an extensive evaluation on $30$ benchmarks and proxy-/mini-applications with $68$ OpenMP code regions. Our approach identifies OpenMP configurations at different power constraints that yield a geometric mean performance improvement of more than $25\\%$ and $13\\%$ over the default OpenMP configuration on a 32-core Skylake and a $16$-core Haswell processor respectively. In addition, when we optimize for the energy-delay product, the OpenMP configurations selected by our auto-tuner demonstrate both performance improvement of $21\\%$ and $11\\%$ and energy reduction of $29\\%$ and $18\\%$ over the default OpenMP configuration at Thermal Design Power for the same Skylake and Haswell processors, respectively. ",
    "url": "https://arxiv.org/abs/2302.11467",
    "authors": [
      "Akash Dutta",
      "Jee Choi",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2302.11475",
    "title": "Degrees and Network Design: New Problems and Approximations",
    "abstract": "While much of network design focuses mostly on cost (number or weight of edges), node degrees have also played an important role. They have traditionally either appeared as an objective, to minimize the maximum degree (e.g., the Minimum Degree Spanning Tree problem), or as constraints which might be violated to give bicriteria approximations (e.g., the Minimum Cost Degree Bounded Spanning Tree problem). We extend the study of degrees in network design in two ways. First, we introduce and study a new variant of the Survivable Network Design Problem where in addition to the traditional objective of minimizing the cost of the chosen edges, we add a constraint that the $\\ell_p$-norm of the node degree vector is bounded by an input parameter. This interpolates between the classical settings of maximum degree (the $\\ell_{\\infty}$-norm) and the number of edges (the $\\ell_1$-degree), and has natural applications in distributed systems and VLSI design. We give a constant bicriteria approximation in both measures using convex programming. Second, we provide a polylogrithmic bicriteria approximation for the Degree Bounded Group Steiner problem on bounded treewidth graphs, solving an open problem from [Kortsarz and Nutov, Discret. Appl. Math. 2022] and [Guo et al., Algorithmica 2022]. ",
    "url": "https://arxiv.org/abs/2302.11475",
    "authors": [
      "Michael Dinitz",
      "Guy Kortsarz",
      "Shi Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.11479",
    "title": "Drop Edges and Adapt: a Fairness Enforcing Fine-tuning for Graph Neural  Networks",
    "abstract": "The rise of graph representation learning as the primary solution for many different network science tasks led to a surge of interest in the fairness of this family of methods. Link prediction, in particular, has a substantial social impact. However, link prediction algorithms tend to increase the segregation in social networks by disfavoring the links between individuals in specific demographic groups. This paper proposes a novel way to enforce fairness on graph neural networks with a fine-tuning strategy. We Drop the unfair Edges and, simultaneously, we Adapt the model's parameters to those modifications, DEA in short. We introduce two covariance-based constraints designed explicitly for the link prediction task. We use these constraints to guide the optimization process responsible for learning the new \"fair\" adjacency matrix. One novelty of DEA is that we can use a discrete yet learnable adjacency matrix in our fine-tuning. We demonstrate the effectiveness of our approach on five real-world datasets and show that we can improve both the accuracy and the fairness of the link prediction tasks. In addition, we present an in-depth ablation study demonstrating that our training algorithm for the adjacency matrix can be used to improve link prediction performances during training. Finally, we compute the relevance of each component of our framework to show that the combination of both the constraints and the training of the adjacency matrix leads to optimal performances. ",
    "url": "https://arxiv.org/abs/2302.11479",
    "authors": [
      "Indro Spinelli",
      "Riccardo Bianchini",
      "Simone Scardapane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.11539",
    "title": "Position-Based Machine Learning Propagation Loss Model Enabling Fast  Digital Twins of Wireless Networks in ns-3",
    "abstract": "Digital twins have been emerging as a hybrid approach that combines the benefits of simulators with the realism of experimental testbeds. The accurate and repeatable set-ups replicating the dynamic conditions of physical environments, enable digital twins of wireless networks to be used to evaluate the performance of next-generation networks. In this paper, we propose the Position-based Machine Learning Propagation Loss Model (P-MLPL), enabling the creation of fast and more precise digital twins of wireless networks in ns-3. Based on network traces collected in an experimental testbed, the P-MLPL model estimates the propagation loss suffered by packets exchanged between a transmitter and a receiver, considering the absolute node's positions and the traffic direction. The P-MLPL model is validated with a test suite. The results show that the P-MLPL model can predict the propagation loss with a median error of 2.5 dB, which corresponds to 0.5x the error of existing models in ns-3. Moreover, ns-3 simulations with the P-MLPL model estimated the throughput with an error up to 2.5 Mbit/s, when compared to the real values measured in the testbed. ",
    "url": "https://arxiv.org/abs/2302.11539",
    "authors": [
      "Eduardo Nuno Almeida",
      "Helder Fontes",
      "Rui Campos",
      "Manuel Ricardo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.11556",
    "title": "Equivariant Polynomials for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNN) are inherently limited in their expressive power. Recent seminal works (Xu et al., 2019; Morris et al., 2019b) introduced the Weisfeiler-Lehman (WL) hierarchy as a measure of expressive power. Although this hierarchy has propelled significant advances in GNN analysis and architecture developments, it suffers from several significant limitations. These include a complex definition that lacks direct guidance for model improvement and a WL hierarchy that is too coarse to study current GNNs. This paper introduces an alternative expressive power hierarchy based on the ability of GNNs to calculate equivariant polynomials of a certain degree. As a first step, we provide a full characterization of all equivariant graph polynomials by introducing a concrete basis, significantly generalizing previous results. Each basis element corresponds to a specific multi-graph, and its computation over some graph data input corresponds to a tensor contraction problem. Second, we propose algorithmic tools for evaluating the expressiveness of GNNs using tensor contraction sequences, and calculate the expressive power of popular GNNs. Finally, we enhance the expressivity of common GNN architectures by adding polynomial features or additional operations / aggregations inspired by our theory. These enhanced GNNs demonstrate state-of-the-art results in experiments across multiple graph learning benchmarks. ",
    "url": "https://arxiv.org/abs/2302.11556",
    "authors": [
      "Omri Puny",
      "Derek Lim",
      "Bobak T. Kiani",
      "Haggai Maron",
      "Yaron Lipman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11563",
    "title": "Exploration by self-supervised exploitation",
    "abstract": "Reinforcement learning can solve decision-making problems and train an agent to behave in an environment according to a predesigned reward function. However, such an approach becomes very problematic if the reward is too sparse and the agent does not come across the reward during the environmental exploration. The solution to such a problem may be in equipping the agent with an intrinsic motivation, which will provide informed exploration, during which the agent is likely to also encounter external reward. Novelty detection is one of the promising branches of intrinsic motivation research. We present Self-supervised Network Distillation (SND), a class of internal motivation algorithms based on the distillation error as a novelty indicator, where the target model is trained using self-supervised learning. We adapted three existing self-supervised methods for this purpose and experimentally tested them on a set of ten environments that are considered difficult to explore. The results show that our approach achieves faster growth and higher external reward for the same training time compared to the baseline models, which implies improved exploration in a very sparse reward environment. ",
    "url": "https://arxiv.org/abs/2302.11563",
    "authors": [
      "Matej Pech\u00e1\u010d",
      "Michal Chovanec",
      "Igor Farka\u0161"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11566",
    "title": "Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via  Self-supervised Scene Decomposition",
    "abstract": "We present Vid2Avatar, a method to learn human avatars from monocular in-the-wild videos. Reconstructing humans that move naturally from monocular in-the-wild videos is difficult. Solving it requires accurately separating humans from arbitrary backgrounds. Moreover, it requires reconstructing detailed 3D surface from short video sequences, making it even more challenging. Despite these challenges, our method does not require any groundtruth supervision or priors extracted from large datasets of clothed human scans, nor do we rely on any external segmentation modules. Instead, it solves the tasks of scene decomposition and surface reconstruction directly in 3D by modeling both the human and the background in the scene jointly, parameterized via two separate neural fields. Specifically, we define a temporally consistent human representation in canonical space and formulate a global optimization over the background model, the canonical human shape and texture, and per-frame human pose parameters. A coarse-to-fine sampling strategy for volume rendering and novel objectives are introduced for a clean separation of dynamic human and static background, yielding detailed and robust 3D human geometry reconstructions. We evaluate our methods on publicly available datasets and show improvements over prior art. ",
    "url": "https://arxiv.org/abs/2302.11566",
    "authors": [
      "Chen Guo",
      "Tianjian Jiang",
      "Xu Chen",
      "Jie Song",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11205",
    "title": "Contrastive Representation Learning for Acoustic Parameter Estimation",
    "abstract": "A study is presented in which a contrastive learning approach is used to extract low-dimensional representations of the acoustic environment from single-channel, reverberant speech signals. Convolution of room impulse responses (RIRs) with anechoic source signals is leveraged as a data augmentation technique that offers considerable flexibility in the design of the upstream task. We evaluate the embeddings across three different downstream tasks, which include the regression of acoustic parameters reverberation time RT60 and clarity index C50, and the classification into small and large rooms. We demonstrate that the learned representations generalize well to unseen data and achieve similar performance compared to a fully supervised baseline. ",
    "url": "https://arxiv.org/abs/2302.11205",
    "authors": [
      "Philipp G\u00f6tz",
      "Cagdas Tuna",
      "Andreas Walther",
      "Emanu\u00ebl A. P. Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2302.11313",
    "title": "Time-varying Signals Recovery via Graph Neural Networks",
    "abstract": "The recovery of time-varying graph signals is a fundamental problem with numerous applications in sensor networks and forecasting in time series. Effectively capturing the spatio-temporal information in these signals is essential for the downstream tasks. Previous studies have used the smoothness of the temporal differences of such graph signals as an initial assumption. Nevertheless, this smoothness assumption could result in a degradation of performance in the corresponding application when the prior does not hold. In this work, we relax the requirement of this hypothesis by including a learning module. We propose a Time Graph Neural Network (TimeGNN) for the recovery of time-varying graph signals. Our algorithm uses an encoder-decoder architecture with a specialized loss composed of a mean squared error function and a Sobolev smoothness operator.TimeGNN shows competitive performance against previous methods in real datasets. ",
    "url": "https://arxiv.org/abs/2302.11313",
    "authors": [
      "Jhon A. Castro-Correa",
      "Jhony H. Giraldo",
      "Anindya Mondal",
      "Mohsen Badiey",
      "Thierry Bouwmans",
      "Fragkiskos D. Malliaros"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.11488",
    "title": "Magnification Invariant Medical Image Analysis: A Comparison of  Convolutional Networks, Vision Transformers, and Token Mixers",
    "abstract": "Convolution Neural Networks (CNNs) are widely used in medical image analysis, but their performance degrade when the magnification of testing images differ from the training images. The inability of CNNs to generalize across magnification scales can result in sub-optimal performance on external datasets. This study aims to evaluate the robustness of various deep learning architectures in the analysis of breast cancer histopathological images with varying magnification scales at training and testing stages. Here we explore and compare the performance of multiple deep learning architectures, including CNN-based ResNet and MobileNet, self-attention-based Vision Transformers and Swin Transformers, and token-mixing models, such as FNet, ConvMixer, MLP-Mixer, and WaveMix. The experiments are conducted using the BreakHis dataset, which contains breast cancer histopathological images at varying magnification levels. We show that performance of WaveMix is invariant to the magnification of training and testing data and can provide stable and good classification accuracy. These evaluations are critical in identifying deep learning architectures that can robustly handle changes in magnification scale, ensuring that scale changes across anatomical structures do not disturb the inference results. ",
    "url": "https://arxiv.org/abs/2302.11488",
    "authors": [
      "Pranav Jeevan",
      "Nikhil Cherian Kurian",
      "Amit Sethi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.11517",
    "title": "A Global and Patch-wise Contrastive Loss for Accurate Automated Exudate  Detection",
    "abstract": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide. Early diagnosis is essential in the treatment of diabetes and can assist in preventing vision impairment. Since manual annotation of medical images is time-consuming, costly, and prone to subjectivity that leads to inconsistent diagnoses, several deep learning segmentation approaches have been proposed to address these challenges. However, these networks often rely on simple loss functions, such as binary cross entropy (BCE), which may not be sophisticated enough to effectively segment lesions such as those present in DR. In this paper, we propose a loss function that incorporates a global segmentation loss, a patch-wise density loss, and a patch-wise edge-aware loss to improve the performance of these networks on the detection and segmentation of hard exudates. Comparing our proposed loss function against the BCE loss on several state-of-the-art networks, our experimental results reveal substantial improvement in network performance achieved by incorporating the patch-wise contrastive loss. ",
    "url": "https://arxiv.org/abs/2302.11517",
    "authors": [
      "Wei Tang",
      "Yinxiao Wang",
      "Kangning Cui",
      "Raymond H. Chan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2007.15190",
    "title": "Quantitative Understanding of VAE as a Non-linearly Scaled Isometric  Embedding",
    "abstract": " Comments: Accepted to the International Conference on Machine Learning (ICML) 2021. 40 pages, 29 figures ",
    "url": "https://arxiv.org/abs/2007.15190",
    "authors": [
      "Akira Nakagawa",
      "Keizo Kato",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.02909",
    "title": "What Makes a \"Good\" Data Augmentation in Knowledge Distillation -- A  Statistical Perspective",
    "abstract": " Comments: Camera Ready of NeurIPS'22. Code: this https URL ",
    "url": "https://arxiv.org/abs/2012.02909",
    "authors": [
      "Huan Wang",
      "Suhas Lohit",
      "Mike Jones",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2102.02100",
    "title": "Object and Relation Centric Representations for Push Effect Prediction",
    "abstract": " Comments: Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2102.02100",
    "authors": [
      "Ahmet E. Tekden",
      "Aykut Erdem",
      "Erkut Erdem",
      "Tamim Asfour",
      "Emre Ugur"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.04785",
    "title": "Physically-Consistent Generative Adversarial Networks for Coastal Flood  Visualization",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2010.08103 ",
    "url": "https://arxiv.org/abs/2104.04785",
    "authors": [
      "Bj\u00f6rn L\u00fctjens",
      "Brandon Leshchinskiy",
      "Christian Requena-Mesa",
      "Farrukh Chishtie",
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Oc\u00e9ane Boulais",
      "Aruna Sankaranarayanan",
      "Margaux Masson-Forsythe",
      "Aaron Pi\u00f1a",
      "Yarin Gal",
      "Chedy Ra\u00efssi",
      "Alexander Lavin",
      "Dava Newman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2107.07087",
    "title": "Entropic Inequality Constraints from $e$-separation Relations in  Directed Acyclic Graphs with Hidden Variables",
    "abstract": " Comments: 18 pages. New in v3: Minor changes to the main text, substantial revisions to the proofs in Appendix C. We thank Robin Evans for motivating the most significant changes since v2 ",
    "url": "https://arxiv.org/abs/2107.07087",
    "authors": [
      "Noam Finkelstein",
      "Beata Zjawin",
      "Elie Wolfe",
      "Ilya Shpitser",
      "Robert W. Spekkens"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.07858",
    "title": "Understanding and Improving Robustness of Vision Transformers through  Patch-based Negative Augmentation",
    "abstract": " Comments: Accepted to NeurIPS-2022 ",
    "url": "https://arxiv.org/abs/2110.07858",
    "authors": [
      "Yao Qin",
      "Chiyuan Zhang",
      "Ting Chen",
      "Balaji Lakshminarayanan",
      "Alex Beutel",
      "Xuezhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.06640",
    "title": "Towards Adversarial Evaluations for Inexact Machine Unlearning",
    "abstract": " Comments: Tech Report ",
    "url": "https://arxiv.org/abs/2201.06640",
    "authors": [
      "Shashwat Goel",
      "Ameya Prabhu",
      "Amartya Sanyal",
      "Ser-Nam Lim",
      "Philip Torr",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01315",
    "title": "Approximating Full Conformal Prediction at Scale via Influence Functions",
    "abstract": " Comments: 18 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2202.01315",
    "authors": [
      "Javier Abad",
      "Umang Bhatt",
      "Adrian Weller",
      "Giovanni Cherubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2202.10806",
    "title": "Stochastic Causal Programming for Bounding Treatment Effects",
    "abstract": " Title: Stochastic Causal Programming for Bounding Treatment Effects ",
    "url": "https://arxiv.org/abs/2202.10806",
    "authors": [
      "Kirtan Padh",
      "Jakob Zeitler",
      "David Watson",
      "Matt Kusner",
      "Ricardo Silva",
      "Niki Kilbertus"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.13800",
    "title": "Differential equation and probability inspired graph neural networks for  latent variable learning",
    "abstract": " Comments: Notes and proposals about graph neural networks ",
    "url": "https://arxiv.org/abs/2202.13800",
    "authors": [
      "Zhuangwei Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.12855",
    "title": "Disturbance Observer-based Robust Control Barrier Functions",
    "abstract": " Comments: Accepted to American Control Conference (ACC) 2023 ",
    "url": "https://arxiv.org/abs/2203.12855",
    "authors": [
      "Yujie Wang",
      "Xiangru Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.15177",
    "title": "Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network  for Surgical Tools Segmentation",
    "abstract": " Title: Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network  for Surgical Tools Segmentation ",
    "url": "https://arxiv.org/abs/2203.15177",
    "authors": [
      "Ange Lou",
      "Kareem Tawfik",
      "Xing Yao",
      "Ziteng Liu",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.02623",
    "title": "Attention-based CNN-LSTM and XGBoost hybrid model for stock prediction",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2202.13800 ",
    "url": "https://arxiv.org/abs/2204.02623",
    "authors": [
      "Zhuangwei Shi",
      "Yang Hu",
      "Guangliang Mo",
      "Jian Wu"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.09486",
    "title": "Graph neural networks and attention-based CNN-LSTM for protein  classification",
    "abstract": " Comments: Briefings of project outcomes about deep learning on protein classification ",
    "url": "https://arxiv.org/abs/2204.09486",
    "authors": [
      "Zhuangwei Shi",
      "Bo Li"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09109",
    "title": "Fast and Provable Tensor Robust Principal Component Analysis via Scaled  Gradient Descent",
    "abstract": " Title: Fast and Provable Tensor Robust Principal Component Analysis via Scaled  Gradient Descent ",
    "url": "https://arxiv.org/abs/2206.09109",
    "authors": [
      "Harry Dong",
      "Tian Tong",
      "Cong Ma",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.10745",
    "title": "Derivative-Informed Neural Operator: An Efficient Framework for  High-Dimensional Parametric Derivative Learning",
    "abstract": " Title: Derivative-Informed Neural Operator: An Efficient Framework for  High-Dimensional Parametric Derivative Learning ",
    "url": "https://arxiv.org/abs/2206.10745",
    "authors": [
      "Thomas O'Leary-Roseberry",
      "Peng Chen",
      "Umberto Villa",
      "Omar Ghattas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.12987",
    "title": "FlowX: Towards Explainable Graph Neural Networks via Message Flows",
    "abstract": " Title: FlowX: Towards Explainable Graph Neural Networks via Message Flows ",
    "url": "https://arxiv.org/abs/2206.12987",
    "authors": [
      "Shurui Gui",
      "Hao Yuan",
      "Jie Wang",
      "Qicheng Lao",
      "Kang Li",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01105",
    "title": "Scalable Polar Code Construction for Successive Cancellation List  Decoding: A Graph Neural Network-Based Approach",
    "abstract": " Comments: 32 pages, 11 figures, submitted to IEEE Transactions on Communications ",
    "url": "https://arxiv.org/abs/2207.01105",
    "authors": [
      "Yun Liao",
      "Seyyed Ali Hashemi",
      "Hengjie Yang",
      "John M. Cioffi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07870",
    "title": "Scene Graph for Embodied Exploration in Cluttered Scenario",
    "abstract": " Title: Scene Graph for Embodied Exploration in Cluttered Scenario ",
    "url": "https://arxiv.org/abs/2207.07870",
    "authors": [
      "Yuhong Deng",
      "Qie Sima",
      "Di Guo",
      "Huaping Liu",
      "Yi Wang",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.12850",
    "title": "SIViDet: Salient Image for Efficient Weaponized Violence Detection",
    "abstract": " Comments: We observed that we may have used the same data from our train set on the test set since we did the split after preprocessing. Currently we are re running experiments to confirm, and also based on reviews, we are considering adding some other new methodology. Thank you ",
    "url": "https://arxiv.org/abs/2207.12850",
    "authors": [
      "Toluwani Aremu",
      "Li Zhiyuan",
      "Reem Alameeri",
      "Abdulmotaleb El Saddik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.13921",
    "title": "HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein  Language Model as an Alternative",
    "abstract": " Title: HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein  Language Model as an Alternative ",
    "url": "https://arxiv.org/abs/2207.13921",
    "authors": [
      "Xiaomin Fang",
      "Fan Wang",
      "Lihang Liu",
      "Jingzhou He",
      "Dayong Lin",
      "Yingfei Xiang",
      "Xiaonan Zhang",
      "Hua Wu",
      "Hui Li",
      "Le Song"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2208.05924",
    "title": "Regularizing Deep Neural Networks with Stochastic Estimators of Hessian  Trace",
    "abstract": " Title: Regularizing Deep Neural Networks with Stochastic Estimators of Hessian  Trace ",
    "url": "https://arxiv.org/abs/2208.05924",
    "authors": [
      "Yucong Liu",
      "Shixing Yu",
      "Tong Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.06522",
    "title": "ScaTE: A Scalable Framework for Self-Supervised Traversability  Estimation in Unstructured Environments",
    "abstract": " Comments: Accepted to IEEE Robotics and Automation Letters (and IROS 2023). Our video can be found at this https URL ",
    "url": "https://arxiv.org/abs/2209.06522",
    "authors": [
      "Junwon Seo",
      "Taekyung Kim",
      "Kiho Kwak",
      "Jihong Min",
      "Inwook Shim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.08174",
    "title": "Confidence-Guided Data Augmentation for Improved Semi-Supervised  Training",
    "abstract": " Comments: 5 pages ",
    "url": "https://arxiv.org/abs/2209.08174",
    "authors": [
      "Fadoua Khmaissia",
      "Hichem Frigui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.09723",
    "title": "GANet: Goal Area Network for Motion Forecasting",
    "abstract": " Title: GANet: Goal Area Network for Motion Forecasting ",
    "url": "https://arxiv.org/abs/2209.09723",
    "authors": [
      "Mingkun Wang",
      "Xinge Zhu",
      "Changqian Yu",
      "Wei Li",
      "Yuexin Ma",
      "Ruochun Jin",
      "Xiaoguang Ren",
      "Dongchun Ren",
      "Mingxu Wang",
      "Wenjing Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.13519",
    "title": "Hierarchical Interdisciplinary Topic Detection Model for Research  Proposal Classification",
    "abstract": " Comments: 14 pages, Accepted by IEEE Transactions on Knowledge and Data Engineering. arXiv admin note: substantial text overlap with arXiv:2203.10922 ",
    "url": "https://arxiv.org/abs/2209.13519",
    "authors": [
      "Meng Xiao",
      "Ziyue Qiao",
      "Yanjie Fu",
      "Hao Dong",
      "Yi Du",
      "Pengyang Wang",
      "Hui Xiong",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08529",
    "title": "Towards Effective Image Manipulation Detection with Proposal Contrastive  Learning",
    "abstract": " Title: Towards Effective Image Manipulation Detection with Proposal Contrastive  Learning ",
    "url": "https://arxiv.org/abs/2210.08529",
    "authors": [
      "Yuyuan Zeng",
      "Bowen Zhao",
      "Shanzhao Qiu",
      "Tao Dai",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10570",
    "title": "Spoofed training data for speech spoofing countermeasure can be  efficiently created using neural vocoders",
    "abstract": " Comments: ICASSP 2023 accepted. Code: this https URL ",
    "url": "https://arxiv.org/abs/2210.10570",
    "authors": [
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.12402",
    "title": "DIGMN: Dynamic Intent Guided Meta Network for Differentiated User  Engagement Forecasting in Online Professional Social Platforms",
    "abstract": " Comments: 10 pages, Accepted by WSDM'23 ",
    "url": "https://arxiv.org/abs/2210.12402",
    "authors": [
      "Feifan Li",
      "Lun Du",
      "Qiang Fu",
      "Shi Han",
      "Yushu Du",
      "Guangming Lu",
      "Zi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15631",
    "title": "Exploring Effective Distillation of Self-Supervised Speech Models for  Automatic Speech Recognition",
    "abstract": " Title: Exploring Effective Distillation of Self-Supervised Speech Models for  Automatic Speech Recognition ",
    "url": "https://arxiv.org/abs/2210.15631",
    "authors": [
      "Yujin Wang",
      "Changli Tang",
      "Ziyang Ma",
      "Zhisheng Zheng",
      "Xie Chen",
      "Wei-Qiang Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.01297",
    "title": "Self-Attentive Sequential Recommendation with Cheap Causal Convolutions",
    "abstract": " Title: Self-Attentive Sequential Recommendation with Cheap Causal Convolutions ",
    "url": "https://arxiv.org/abs/2211.01297",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Liye Shi",
      "Yu Ji",
      "Wenxin Hu",
      "Xi Chen",
      "Wei Zheng",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.08010",
    "title": "Bayesian Federated Neural Matching that Completes Full Information",
    "abstract": " Title: Bayesian Federated Neural Matching that Completes Full Information ",
    "url": "https://arxiv.org/abs/2211.08010",
    "authors": [
      "Peng Xiao",
      "Samuel Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.07724",
    "title": "Attention-based Multiple Instance Learning for Survival Prediction on  Lung Cancer Tissue Microarrays",
    "abstract": " Comments: Final version for the BVM 2023 Workshop ",
    "url": "https://arxiv.org/abs/2212.07724",
    "authors": [
      "Jonas Ammeling",
      "Lars-Henning Schmidt",
      "Jonathan Ganz",
      "Tanja Niedermair",
      "Christoph Brochhausen-Delius",
      "Christian Schulz",
      "Katharina Breininger",
      "Marc Aubreville"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.11484",
    "title": "SALVE: Self-supervised Adaptive Low-light Video Enhancement",
    "abstract": " Comments: 12 pages, 7 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2212.11484",
    "authors": [
      "Zohreh Azizi",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.03294",
    "title": "Construction of Optimal Binary Z-Complementary Code Sets with New  Lengths",
    "abstract": " Title: Construction of Optimal Binary Z-Complementary Code Sets with New  Lengths ",
    "url": "https://arxiv.org/abs/2301.03294",
    "authors": [
      "Gobinda Ghosh",
      "Sudhan Majhi",
      "Shubabrata Paul"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.05219",
    "title": "Why is the State of Neural Network Pruning so Confusing? On the  Fairness, Comparison Setup, and Trainability in Network Pruning",
    "abstract": " Comments: 17 pages, v2, corrected wrong references ",
    "url": "https://arxiv.org/abs/2301.05219",
    "authors": [
      "Huan Wang",
      "Can Qin",
      "Yue Bai",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00839",
    "title": "Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control",
    "abstract": " Title: Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control ",
    "url": "https://arxiv.org/abs/2302.00839",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Cao Xiao",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.02291",
    "title": "A Semantic Approach to Negation Detection and Word Disambiguation with  Natural Language Processing",
    "abstract": " Title: A Semantic Approach to Negation Detection and Word Disambiguation with  Natural Language Processing ",
    "url": "https://arxiv.org/abs/2302.02291",
    "authors": [
      "Izunna Okpala",
      "Guillermo Romera Rodriguez",
      "Andrea Tapia",
      "Shane Halse",
      "Jess Kropczynski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.03461",
    "title": "Degree-3 Planar Graphs as Topological Minors of Wall Graphs in  Polynomial Time",
    "abstract": " Comments: V2: Updated to fix an error in the proof pointed out by Mika\\\"el Monet. V3: Updated to point out alternative and simpler proof route following this https URL ",
    "url": "https://arxiv.org/abs/2302.03461",
    "authors": [
      "Antoine Amarilli"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2302.03640",
    "title": "S4R: Self-Supervised Semantic Scene Reconstruction from RGB-D Scans",
    "abstract": " Title: S4R: Self-Supervised Semantic Scene Reconstruction from RGB-D Scans ",
    "url": "https://arxiv.org/abs/2302.03640",
    "authors": [
      "Junwen Huang",
      "Alexey Artemov",
      "Yujin Chen",
      "Shuaifeng Zhi",
      "Kai Xu",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05990",
    "title": "Exploiting Graph Structured Cross-Domain Representation for Multi-Domain  Recommendation",
    "abstract": " Comments: Accepted at the 45th European Conference on Information Retrieval (ECIR'23), full paper track ",
    "url": "https://arxiv.org/abs/2302.05990",
    "authors": [
      "Alejandro Ariza-Casabona",
      "Bartlomiej Twardowski",
      "Tri Kurniawan Wijaya"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.06503",
    "title": "Ground(less) Truth: A Causal Framework for Proxy Labels in  Human-Algorithm Decision-Making",
    "abstract": " Title: Ground(less) Truth: A Causal Framework for Proxy Labels in  Human-Algorithm Decision-Making ",
    "url": "https://arxiv.org/abs/2302.06503",
    "authors": [
      "Luke Guerdan",
      "Amanda Coston",
      "Zhiwei Steven Wu",
      "Kenneth Holstein"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.07363",
    "title": "Attacking Fake News Detectors via Manipulating News Social Engagement",
    "abstract": " Comments: In Proceedings of the ACM Web Conference 2023 (WWW'23) ",
    "url": "https://arxiv.org/abs/2302.07363",
    "authors": [
      "Haoran Wang",
      "Yingtong Dou",
      "Canyu Chen",
      "Lichao Sun",
      "Philip S. Yu",
      "Kai Shu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.09018",
    "title": "Self-supervised Action Representation Learning from Partial  Spatio-Temporal Skeleton Sequences",
    "abstract": " Comments: Accepted by AAAI 2023(Oral) ",
    "url": "https://arxiv.org/abs/2302.09018",
    "authors": [
      "Yujie Zhou",
      "Haodong Duan",
      "Anyi Rao",
      "Bing Su",
      "Jiaqi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.09040",
    "title": "Automated Graph Genetic Algorithm based Puzzle Validation for Faster  Game Design",
    "abstract": " Title: Automated Graph Genetic Algorithm based Puzzle Validation for Faster  Game Design ",
    "url": "https://arxiv.org/abs/2302.09040",
    "authors": [
      "Karine Levonyan",
      "Jesse Harder",
      "Fernando De Mesentier Silva"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.09463",
    "title": "The Emerging Artificial Intelligence Protocol for Hierarchical  Information Network",
    "abstract": " Comments: 6 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2302.09463",
    "authors": [
      "Caesar Wu",
      "Pascal Bouvry"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10506",
    "title": "Diffusion Probabilistic Models for Graph-Structured Prediction",
    "abstract": " Title: Diffusion Probabilistic Models for Graph-Structured Prediction ",
    "url": "https://arxiv.org/abs/2302.10506",
    "authors": [
      "Sungsoo Ahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]