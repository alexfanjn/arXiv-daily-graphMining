[
  {
    "id": "arXiv:2302.01932",
    "title": "Sequential pattern mining in educational data: The application context,  potential, strengths, and limitations",
    "abstract": "Increasingly, researchers have suggested the benefits of temporal analysis to improve our understanding of the learning process. Sequential pattern mining (SPM), as a pattern recognition technique, has the potential to reveal the temporal aspects of learning and can be a valuable tool in educational data science. However, its potential is not well understood and exploited. This chapter addresses this gap by reviewing work that utilizes sequential pattern mining in educational contexts. We identify that SPM is suitable for mining learning behaviors, analyzing and enriching educational theories, evaluating the efficacy of instructional interventions, generating features for prediction models, and building educational recommender systems. SPM can contribute to these purposes by discovering similarities and differences in learners' activities and revealing the temporal change in learning behaviors. As a sequential analysis method, SPM can reveal unique insights about learning processes and be powerful for self-regulated learning research. It is more flexible in capturing the relative arrangement of learning events than the other sequential analysis methods. Future research may improve its utility in educational data science by developing tools for counting pattern occurrences as well as identifying and removing unreliable patterns. Future work needs to establish a systematic guideline for data preprocessing, parameter setting, and interpreting sequential patterns. ",
    "url": "https://arxiv.org/abs/2302.01932",
    "authors": [
      "Yingbin Zhang",
      "Luc Paquette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01955",
    "title": "Fixed-kinetic Neural Hamiltonian Flows for enhanced interpretability and  reduced complexity",
    "abstract": "Normalizing Flows (NF) are Generative models which are particularly robust and allow for exact sampling of the learned distribution. They however require the design of an invertible mapping, whose Jacobian determinant has to be computable. Recently introduced, Neural Hamiltonian Flows (NHF) are based on Hamiltonian dynamics-based Flows, which are continuous, volume-preserving and invertible and thus make for natural candidates for robust NF architectures. In particular, their similarity to classical Mechanics could lead to easier interpretability of the learned mapping. However, despite being Physics-inspired architectures, the originally introduced NHF architecture still poses a challenge to interpretability. For this reason, in this work, we introduce a fixed kinetic energy version of the NHF model. Inspired by physics, our approach improves interpretability and requires less parameters than previously proposed architectures. We then study the robustness of the NHF architectures to the choice of hyperparameters. We analyze the impact of the number of leapfrog steps, the integration time and the number of neurons per hidden layer, as well as the choice of prior distribution, on sampling a multimodal 2D mixture. The NHF architecture is robust to these choices, especially the fixed-kinetic energy model. Finally, we adapt NHF to the context of Bayesian inference and illustrate our method on sampling the posterior distribution of two cosmological parameters knowing type Ia supernovae observations. ",
    "url": "https://arxiv.org/abs/2302.01955",
    "authors": [
      "Vincent Souveton",
      "Arnaud Guillin",
      "Jens Jasche",
      "Guilhem Lavaux",
      "Manon Michel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01961",
    "title": "Asymmetric Certified Robustness via Feature-Convex Neural Networks",
    "abstract": "Recent works have introduced input-convex neural networks (ICNNs) as learning models with advantageous training, inference, and generalization properties linked to their convex structure. In this paper, we propose a novel feature-convex neural network architecture as the composition of an ICNN with a Lipschitz feature map in order to achieve adversarial robustness. We consider the asymmetric binary classification setting with one \"sensitive\" class, and for this class we prove deterministic, closed-form, and easily-computable certified robust radii for arbitrary $\\ell_p$-norms. We theoretically justify the use of these models by characterizing their decision region geometry, extending the universal approximation theorem for ICNN regression to the classification setting, and proving a lower bound on the probability that such models perfectly fit even unstructured uniformly distributed data in sufficiently high dimensions. Experiments on Malimg malware classification and subsets of MNIST, Fashion-MNIST, and CIFAR-10 datasets show that feature-convex classifiers attain state-of-the-art certified $\\ell_1$-radii as well as substantial $\\ell_2$- and $\\ell_{\\infty}$-radii while being far more computationally efficient than any competitive baseline. ",
    "url": "https://arxiv.org/abs/2302.01961",
    "authors": [
      "Samuel Pfrommer",
      "Brendon G. Anderson",
      "Julien Piet",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01972",
    "title": "DCA: Delayed Charging Attack on the Electric Shared Mobility System",
    "abstract": "An efficient operation of the electric shared mobility system (ESMS) relies heavily on seamless interconnections between shared electric vehicles (SEV), electric vehicle supply equipment (EVSE), and the grid. Nevertheless, this interconnectivity also makes the ESMS vulnerable to cyberattacks that may cause short-term breakdowns or long-term degradation of the ESMS. This study focuses on one such attack with long-lasting effects, the Delayed Charge Attack (DCA), that stealthily delays the charging service by exploiting the physical and communication vulnerabilities. To begin, we present the ESMS threat model by highlighting the assets, information flow, and access points. We next identify a linked sequence of vulnerabilities as a viable attack vector for launching DCA. Then, we detail the implementation of DCA, which can effectively bypass the detection in the SEV's battery management system and the cross-verification in the cloud environment. We test the DCA model against various Anomaly Detection (AD) algorithms by simulating the DCA dynamics in a Susceptible-Infectious-Removed-Susceptible (SIRS) process, where the EVSE can be compromised by the DCA or detected for repair. Using real-world taxi trip data and EVSE locations in New York City, the DCA model allows us to explore the long-term impacts and validate the system consequences. The results show that a 10-min delay will result in 12-min longer queuing times and 8% more unfulfilled requests, leading to a 10.7% (\\$311.7) weekly revenue loss per driver. With the AD algorithms, the weekly revenue loss remains at 3.8% (\\$111.8), suggesting the robustness of the DCA. ",
    "url": "https://arxiv.org/abs/2302.01972",
    "authors": [
      "Shuocheng Guo",
      "Hanlin Chen",
      "Mizanur Rahman",
      "Xinwu Qian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.01977",
    "title": "Construction of Hierarchically Semi-Separable matrix Representation  using Adaptive Johnson-Lindenstrauss Sketching",
    "abstract": "We extend an adaptive partially matrix-free Hierarchically Semi-Separable (HSS) matrix construction algorithm by Gorman et al. [SIAM J. Sci. Comput. 41(5), 2019] which uses Gaussian sketching operators to a broader class of Johnson--Lindenstrauss (JL) sketching operators. We present theoretical work which justifies this extension. In particular, we extend the earlier concentration bounds to all JL sketching operators and examine this bound for specific classes of such operators including the original Gaussian sketching operators, subsampled randomized Hadamard transform (SRHT) and the sparse Johnson--Lindenstrauss transform (SJLT). We discuss the implementation details of applying SJLT efficiently and demonstrate experimentally that using SJLT instead of Gaussian sketching operators leads to 1.5--2.5x speedups of the HSS construction implementation in the STRUMPACK C++ library. The generalized algorithm allows users to select their own JL sketching operators with theoretical lower bounds on the size of the operators which may lead to faster run time with similar HSS construction accuracy. ",
    "url": "https://arxiv.org/abs/2302.01977",
    "authors": [
      "Yotam Yaniv",
      "Osman Asif Malik",
      "Pieter Ghysels",
      "Xiaoye S. Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.01985",
    "title": "VR-LENS: Super Learning-based Cybersickness Detection and Explainable  AI-Guided Deployment in Virtual Reality",
    "abstract": "A plethora of recent research has proposed several automated methods based on machine learning (ML) and deep learning (DL) to detect cybersickness in Virtual reality (VR). However, these detection methods are perceived as computationally intensive and black-box methods. Thus, those techniques are neither trustworthy nor practical for deploying on standalone VR head-mounted displays (HMDs). This work presents an explainable artificial intelligence (XAI)-based framework VR-LENS for developing cybersickness detection ML models, explaining them, reducing their size, and deploying them in a Qualcomm Snapdragon 750G processor-based Samsung A52 device. Specifically, we first develop a novel super learning-based ensemble ML model for cybersickness detection. Next, we employ a post-hoc explanation method, such as SHapley Additive exPlanations (SHAP), Morris Sensitivity Analysis (MSA), Local Interpretable Model-Agnostic Explanations (LIME), and Partial Dependence Plot (PDP) to explain the expected results and identify the most dominant features. The super learner cybersickness model is then retrained using the identified dominant features. Our proposed method identified eye tracking, player position, and galvanic skin/heart rate response as the most dominant features for the integrated sensor, gameplay, and bio-physiological datasets. We also show that the proposed XAI-guided feature reduction significantly reduces the model training and inference time by 1.91X and 2.15X while maintaining baseline accuracy. For instance, using the integrated sensor dataset, our reduced super learner model outperforms the state-of-the-art works by classifying cybersickness into 4 classes (none, low, medium, and high) with an accuracy of 96% and regressing (FMS 1-10) with a Root Mean Square Error (RMSE) of 0.03. ",
    "url": "https://arxiv.org/abs/2302.01985",
    "authors": [
      "Ripan Kumar Kundu",
      "Osama Yahia Elsaid",
      "Prasad Calyam",
      "Khaza Anuarul Hoque"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.01987",
    "title": "Hierarchical Graph Neural Networks for Causal Discovery and Root Cause  Localization",
    "abstract": "In this paper, we propose REASON, a novel framework that enables the automatic discovery of both intra-level (i.e., within-network) and inter-level (i.e., across-network) causal relationships for root cause localization. REASON consists of Topological Causal Discovery and Individual Causal Discovery. The Topological Causal Discovery component aims to model the fault propagation in order to trace back to the root causes. To achieve this, we propose novel hierarchical graph neural networks to construct interdependent causal networks by modeling both intra-level and inter-level non-linear causal relations. Based on the learned interdependent causal networks, we then leverage random walks with restarts to model the network propagation of a system fault. The Individual Causal Discovery component focuses on capturing abrupt change patterns of a single system entity. This component examines the temporal patterns of each entity's metric data (i.e., time series), and estimates its likelihood of being a root cause based on the Extreme Value theory. Combining the topological and individual causal scores, the top K system entities are identified as root causes. Extensive experiments on three real-world datasets with case studies demonstrate the effectiveness and superiority of the proposed framework. ",
    "url": "https://arxiv.org/abs/2302.01987",
    "authors": [
      "Dongjie Wang",
      "Zhengzhang Chen",
      "Jingchao Ni",
      "Liang Tong",
      "Zheng Wang",
      "Yanjie Fu",
      "Haifeng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.01989",
    "title": "Robust and Verifiable Proportionality Axioms for Multiwinner Voting",
    "abstract": "When selecting a subset of candidates (a so-called committee) based on the preferences of voters, proportional representation is often a major desideratum. When going beyond simplistic models such as party-list or district-based elections, it is surprisingly challenging to capture proportionality formally. As a consequence, the literature has produced numerous competing criteria of when a selected committee qualifies as proportional. Two of the most prominent notions are Dummett's proportionality for solid coalitions (PSC) and Aziz et al.'s extended justified representation (EJR). Both guarantee proportional representation to groups of voters who have very similar preferences; such groups are referred to as solid coalitions by Dummett and as cohesive groups by Aziz et al. However, these notions lose their bite when groups are only almost solid or almost cohesive. In this paper, we propose proportionality axioms that are more robust: they guarantee representation also to groups that do not qualify as solid or cohesive. Further, our novel axioms can be easily verified: Given a committee, we can check in polynomial time whether it satisfies the axiom or not. This is in contrast to many established notions like EJR, for which the corresponding verification problem is known to be intractable. In the setting with approval preferences, we propose a robust and verifiable variant of EJR and a simply greedy procedure to compute committees satisfying it. In the setting with ranked preferences, we propose a robust variant PSC, which can be efficiently verified even for general weak preferences. In the special case of strict preferences, our notion is the first known satisfiable proportionality axiom that is violated by the Single Transferable Vote (STV). We also discuss implications of our results for participatory budgeting, querying procedures, and to the notion of proportionality degree. ",
    "url": "https://arxiv.org/abs/2302.01989",
    "authors": [
      "Markus Brill",
      "Jannik Peters"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.02001",
    "title": "Spatial Network Calculus and Performance Guarantees in Wireless Networks",
    "abstract": "This work develops a novel approach towards performance guarantees for all links in arbitrarily large wireless networks. It introduces spatial regulation properties for stationary spatial point processes, which model transmitter and receiver locations, and develops the first steps of a calculus for this regulation. This spatial network calculus can be seen as an extension to space of the initial network calculus which is available with respect to time. Specifically, two classes of regulations are defined: one includes ball regulation and shot-noise regulation, which upper constraint the total power of interference generated by other links; the other one includes void regulation, which lower constraints the signal power. Notable examples satisfying the first class of regulation are hardcore processes, and a notable counter-example is the Poisson point process. These regulations are defined both in the strong and weak sense: the former requires the regulations to hold everywhere in space, whereas the latter, which relies on Palm calculus, only requires the regulations to hold at the atoms of a jointly stationary observer point process. Using this approach, we show how to derive performance guarantees for various types of device-to-device and cellular networks. We show that, under appropriate spatial regulation, universal bounds hold on the SINR for all links. The bounds are deterministic in the absence of fading and stochastic in the case with fading, respectively. This leads to service guarantees for all links based on information theoretic achievability when treating interference as noise. This can in turn be combined with classical network calculus to provide end-to-end latency guarantees for all packets in queuing processes taking place in all links of a large wireless network. Such guarantees do not exist in networks that are not spatially regulated, e.g., Poisson networks. ",
    "url": "https://arxiv.org/abs/2302.02001",
    "authors": [
      "Ke Feng",
      "Fran\u00e7ois Baccelli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.02006",
    "title": "Robust Budget Pacing with a Single Sample",
    "abstract": "Major Internet advertising platforms offer budget pacing tools as a standard service for advertisers to manage their ad campaigns. Given the inherent non-stationarity in an advertiser's value and also competing advertisers' values over time, a commonly used approach is to learn a target expenditure plan that specifies a target spend as a function of time, and then run a controller that tracks this plan. This raises the question: how many historical samples are required to learn a good expenditure plan? We study this question by considering an advertiser repeatedly participating in $T$ second-price auctions, where the tuple of her value and the highest competing bid is drawn from an unknown time-varying distribution. The advertiser seeks to maximize her total utility subject to her budget constraint. Prior work has shown the sufficiency of $T\\log T$ samples per distribution to achieve the optimal $O(\\sqrt{T})$-regret. We dramatically improve this state-of-the-art and show that just one sample per distribution is enough to achieve the near-optimal $\\tilde O(\\sqrt{T})$-regret, while still being robust to noise in the sampling distributions. ",
    "url": "https://arxiv.org/abs/2302.02006",
    "authors": [
      "Santiago Balseiro",
      "Rachitesh Kumar",
      "Vahab Mirrokni",
      "Balasubramanian Sivan",
      "Di Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.02012",
    "title": "DeTorrent: An Adversarial Padding-only Traffic Analysis Defense",
    "abstract": "While anonymity networks like Tor aim to protect the privacy of their users, they are vulnerable to traffic analysis attacks such as Website Fingerprinting (WF) and Flow Correlation (FC). Recent implementations of WF and FC attacks, such as Tik-Tok and DeepCoFFEA, have shown that the attacks can be effectively carried out, threatening user privacy. Consequently, there is a need for effective traffic analysis defense. There are a variety of existing defenses, but most are either ineffective, incur high latency and bandwidth overhead, or require additional infrastructure. As a result, we aim to design a traffic analysis defense that is efficient and highly resistant to both WF and FC attacks. We propose DeTorrent, which uses competing neural networks to generate and evaluate traffic analysis defenses that insert 'dummy' traffic into real traffic flows. DeTorrent operates with moderate overhead and without delaying traffic. In a closed-world WF setting, it reduces an attacker's accuracy by 60.5%, a reduction 9.5% better than the next-best padding-only defense. Against the state-of-the-art FC attacker, DeTorrent reduces the true positive rate for a $10^{-4}$ false positive rate to about .30, which is less than half that of the next-best defense. We also demonstrate DeTorrent's practicality by deploying it alongside the Tor network and find that it maintains its performance when applied to live traffic. ",
    "url": "https://arxiv.org/abs/2302.02012",
    "authors": [
      "James K Holland",
      "Jason Carpenter",
      "Se Eun Oh",
      "Nicholas Hopper"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.02013",
    "title": "IoT Botnet Detection Using an Economic Deep Learning Model",
    "abstract": "The rapid progress in technology innovation usage and distribution has increased in the last decade. The rapid growth of the Internet of Things (IoT) systems worldwide has increased network security challenges created by malicious third parties. Thus, reliable intrusion detection and network forensics systems that consider security concerns and IoT systems limitations are essential to protect such systems. IoT botnet attacks are one of the significant threats to enterprises and individuals. Thus, this paper proposed an economic deep learning-based model for detecting IoT botnet attacks along with different types of attacks. The proposed model achieved higher accuracy than the state-of-the-art detection models using a smaller implementation budget and accelerating the training and detecting processes. ",
    "url": "https://arxiv.org/abs/2302.02013",
    "authors": [
      "Nelly Elsayed",
      "Zag ElSayed",
      "Magdy Bayoumi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02016",
    "title": "Improving Interpretability via Explicit Word Interaction Graph Layer",
    "abstract": "Recent NLP literature has seen growing interest in improving model interpretability. Along this direction, we propose a trainable neural network layer that learns a global interaction graph between words and then selects more informative words using the learned word interactions. Our layer, we call WIGRAPH, can plug into any neural network-based NLP text classifiers right after its word embedding layer. Across multiple SOTA NLP models and various NLP datasets, we demonstrate that adding the WIGRAPH layer substantially improves NLP models' interpretability and enhances models' prediction performance at the same time. ",
    "url": "https://arxiv.org/abs/2302.02016",
    "authors": [
      "Arshdeep Sekhon",
      "Hanjie Chen",
      "Aman Shrivastava",
      "Zhe Wang",
      "Yangfeng Ji",
      "Yanjun Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02023",
    "title": "TextShield: Beyond Successfully Detecting Adversarial Sentences in Text  Classification",
    "abstract": "Adversarial attack serves as a major challenge for neural network models in NLP, which precludes the model's deployment in safety-critical applications. A recent line of work, detection-based defense, aims to distinguish adversarial sentences from benign ones. However, {the core limitation of previous detection methods is being incapable of giving correct predictions on adversarial sentences unlike defense methods from other paradigms.} To solve this issue, this paper proposes TextShield: (1) we discover a link between text attack and saliency information, and then we propose a saliency-based detector, which can effectively detect whether an input sentence is adversarial or not. (2) We design a saliency-based corrector, which converts the detected adversary sentences to benign ones. By combining the saliency-based detector and corrector, TextShield extends the detection-only paradigm to a detection-correction paradigm, thus filling the gap in the existing detection-based defense. Comprehensive experiments show that (a) TextShield consistently achieves higher or comparable performance than state-of-the-art defense methods across various attacks on different benchmarks. (b) our saliency-based detector outperforms existing detectors for detecting adversarial sentences. ",
    "url": "https://arxiv.org/abs/2302.02023",
    "authors": [
      "Lingfeng Shen",
      "Ze Zhang",
      "Haiyun Jiang",
      "Ying Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02025",
    "title": "Self-Supervised Transformer Architecture for Change Detection in Radio  Access Networks",
    "abstract": "Radio Access Networks (RANs) for telecommunications represent large agglomerations of interconnected hardware consisting of hundreds of thousands of transmitting devices (cells). Such networks undergo frequent and often heterogeneous changes caused by network operators, who are seeking to tune their system parameters for optimal performance. The effects of such changes are challenging to predict and will become even more so with the adoption of 5G/6G networks. Therefore, RAN monitoring is vital for network operators. We propose a self-supervised learning framework that leverages self-attention and self-distillation for this task. It works by detecting changes in Performance Measurement data, a collection of time-varying metrics which reflect a set of diverse measurements of the network performance at the cell level. Experimental results show that our approach outperforms the state of the art by 4% on a real-world based dataset consisting of about hundred thousands timeseries. It also has the merits of being scalable and generalizable. This allows it to provide deep insight into the specifics of mode of operation changes while relying minimally on expert knowledge. ",
    "url": "https://arxiv.org/abs/2302.02025",
    "authors": [
      "Igor Kozlov",
      "Dmitriy Rivkin",
      "Wei-Di Chang",
      "Di Wu",
      "Xue Liu",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02031",
    "title": "Augmenting Rule-based DNS Censorship Detection at Scale with Machine  Learning",
    "abstract": "The proliferation of global censorship has led to the development of a plethora of measurement platforms to monitor and expose it. Censorship of the domain name system (DNS) is a key mechanism used across different countries. It is currently detected by applying heuristics to samples of DNS queries and responses (probes) for specific destinations. These heuristics, however, are both platform-specific and have been found to be brittle when censors change their blocking behavior, necessitating a more reliable automated process for detecting censorship. In this paper, we explore how machine learning (ML) models can (1) help streamline the detection process, (2) improve the usability of large-scale datasets for censorship detection, and (3) discover new censorship instances and blocking signatures missed by existing heuristic methods. Our study shows that supervised models, trained using expert-derived labels on instances of known anomalies and possible censorship, can learn the detection heuristics employed by different measurement platforms. More crucially, we find that unsupervised models, trained solely on uncensored instances, can identify new instances and variations of censorship missed by existing heuristics. Moreover, both methods demonstrate the capability to uncover a substantial number of new DNS blocking signatures, i.e., injected fake IP addresses overlooked by existing heuristics. These results are underpinned by an important methodological finding: comparing the outputs of models trained using the same probes but with labels arising from independent processes allows us to more reliably detect cases of censorship in the absence of ground-truth labels of censorship. ",
    "url": "https://arxiv.org/abs/2302.02031",
    "authors": [
      "Jacob Alexander Markson Brown",
      "Xi Jiang",
      "Van Tran",
      "Arjun Nitin Bhagoji",
      "Nguyen Phong Hoang",
      "Nick Feamster",
      "Prateek Mittal",
      "Vinod Yegneswaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.02038",
    "title": "Rating Sentiment Analysis Systems for Bias through a Causal Lens",
    "abstract": "Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that, given a piece of text, assign one or more numbers conveying the polarity and emotional intensity expressed in the input. Like other automatic machine learning systems, they have also been known to exhibit model uncertainty where a (small) change in the input leads to drastic swings in the output. This can be especially problematic when inputs are related to protected features like gender or race since such behavior can be perceived as a lack of fairness, i.e., bias. We introduce a novel method to assess and rate SASs where inputs are perturbed in a controlled causal setting to test if the output sentiment is sensitive to protected variables even when other components of the textual input, e.g., chosen emotion words, are fixed. We then use the result to assign labels (ratings) at fine-grained and overall levels to convey the robustness of the SAS to input changes. The ratings serve as a principled basis to compare SASs and choose among them based on behavior. It benefits all users, especially developers who reuse off-the-shelf SASs to build larger AI systems but do not have access to their code or training data to compare. ",
    "url": "https://arxiv.org/abs/2302.02038",
    "authors": [
      "Kausik Lakkaraju",
      "Biplav Srivastava",
      "Marco Valtorta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02042",
    "title": "BarrierBypass: Out-of-Sight Clean Voice Command Injection Attacks  through Physical Barriers",
    "abstract": "The growing adoption of voice-enabled devices (e.g., smart speakers), particularly in smart home environments, has introduced many security vulnerabilities that pose significant threats to users' privacy and safety. When multiple devices are connected to a voice assistant, an attacker can cause serious damage if they can gain control of these devices. We ask where and how can an attacker issue clean voice commands stealthily across a physical barrier, and perform the first academic measurement study of this nature on the command injection attack. We present the BarrierBypass attack that can be launched against three different barrier-based scenarios termed across-door, across-window, and across-wall. We conduct a broad set of experiments to observe the command injection attack success rates for multiple speaker samples (TTS and live human recorded) at different command audio volumes (65, 75, 85 dB), and smart speaker locations (0.1-4.0m from barrier). Against Amazon Echo Dot 2, BarrierBypass is able to achieve 100% wake word and command injection success for the across-wall and across-window attacks, and for the across-door attack (up to 2 meters). At 4 meters for the across-door attack, BarrierBypass can achieve 90% and 80% injection accuracy for the wake word and command, respectively. Against Google Home mini BarrierBypass is able to achieve 100% wake word injection accuracy for all attack scenarios. For command injection BarrierBypass can achieve 100% accuracy for all the three barrier settings (up to 2 meters). For the across-door attack at 4 meters, BarrierBypass can achieve 80% command injection accuracy. Further, our demonstration using drones yielded high command injection success, up to 100%. Overall, our results demonstrate the potentially devastating nature of this vulnerability to control a user's device from outside of the device's physical space. ",
    "url": "https://arxiv.org/abs/2302.02042",
    "authors": [
      "Payton Walker",
      "Tianfang Zhang",
      "Cong Shi",
      "Nitesh Saxena",
      "Yingying Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.02050",
    "title": "Location-based AR for Social Justice: Case Studies, Lessons, and Open  Challenges",
    "abstract": "Dear Visitor and Charleston Reconstructed were location-based augmented reality (AR) experiences created between 2018 and 2020 dealing with two controversial monument sites in the US. The projects were motivated by the ability of AR to 1) link layers of context to physical sites in ways that are otherwise difficult or impossible and 2) to visualize changes to physical spaces, potentially inspiring changes to the spaces themselves. We discuss the projects' motivations, designs, and deployments. We reflect on how physical changes to the projects' respective sites radically altered their outcomes, and we describe lessons for future work in location-based AR, particularly for projects in contested spaces. ",
    "url": "https://arxiv.org/abs/2302.02050",
    "authors": [
      "Hope Schroeder",
      "Rob Tokanel",
      "Kyle Qian",
      "Khoi Le"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.02051",
    "title": "Multivariate Time Series Anomaly Detection via Dynamic Graph Forecasting",
    "abstract": "Anomalies in univariate time series often refer to abnormal values and deviations from the temporal patterns from majority of historical observations. In multivariate time series, anomalies also refer to abnormal changes in the inter-series relationship, such as correlation, over time. Existing studies have been able to model such inter-series relationships through graph neural networks. However, most works settle on learning a static graph globally or within a context window to assist a time series forecasting task or a reconstruction task, whose objective is not tailored to explicitly detect the abnormal relationship. Some other works detect anomalies based on reconstructing or forecasting a list of inter-series graphs, which inadvertently weakens their power to capture temporal patterns within the data due to the discrete nature of graphs. In this study, we propose DyGraphAD, a multivariate time series anomaly detection framework based upon a list of dynamic inter-series graphs. The core idea is to detect anomalies based on the deviation of inter-series relationships and intra-series temporal patterns from normal to anomalous states, by leveraging the evolving nature of the graphs in order to assist a graph forecasting task and a time series forecasting task simultaneously. Our numerical experiments on real-world datasets demonstrate that DyGraphAD has superior performance than baseline anomaly detection approaches. ",
    "url": "https://arxiv.org/abs/2302.02051",
    "authors": [
      "Katrina Chen",
      "Mingbin Feng",
      "Tony S. Wirjanto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02057",
    "title": "Semantic Diffusion Network for Semantic Segmentation",
    "abstract": "Precise and accurate predictions over boundary areas are essential for semantic segmentation. However, the commonly-used convolutional operators tend to smooth and blur local detail cues, making it difficult for deep models to generate accurate boundary predictions. In this paper, we introduce an operator-level approach to enhance semantic boundary awareness, so as to improve the prediction of the deep semantic segmentation model. Specifically, we first formulate the boundary feature enhancement as an anisotropic diffusion process. We then propose a novel learnable approach called semantic diffusion network (SDN) to approximate the diffusion process, which contains a parameterized semantic difference convolution operator followed by a feature fusion module. Our SDN aims to construct a differentiable mapping from the original feature to the inter-class boundary-enhanced feature. The proposed SDN is an efficient and flexible module that can be easily plugged into existing encoder-decoder segmentation models. Extensive experiments show that our approach can achieve consistent improvements over several typical and state-of-the-art segmentation baseline models on challenging public benchmarks. The code will be released soon. ",
    "url": "https://arxiv.org/abs/2302.02057",
    "authors": [
      "Haoru Tan",
      "Sitong Wu",
      "Jimin Pi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02060",
    "title": "Representation Deficiency in Masked Language Modeling",
    "abstract": "Masked Language Modeling (MLM) has been one of the most prominent approaches for pretraining bidirectional text encoders due to its simplicity and effectiveness. One notable concern about MLM is that the special $\\texttt{[MASK]}$ symbol causes a discrepancy between pretraining data and downstream data as it is present only in pretraining but not in fine-tuning. In this work, we offer a new perspective on the consequence of such a discrepancy: We demonstrate empirically and theoretically that MLM pretraining allocates some model dimensions exclusively for representing $\\texttt{[MASK]}$ tokens, resulting in a representation deficiency for real tokens and limiting the pretrained model's expressiveness when it is adapted to downstream data without $\\texttt{[MASK]}$ tokens. Motivated by the identified issue, we propose MAE-LM, which pretrains the Masked Autoencoder architecture with MLM where $\\texttt{[MASK]}$ tokens are excluded from the encoder. Empirically, we show that MAE-LM improves the utilization of model dimensions for real token representations, and MAE-LM consistently outperforms MLM-pretrained models across different pretraining settings and model sizes when fine-tuned on the GLUE and SQuAD benchmarks. ",
    "url": "https://arxiv.org/abs/2302.02060",
    "authors": [
      "Yu Meng",
      "Jitin Krishnan",
      "Sinong Wang",
      "Qifan Wang",
      "Yuning Mao",
      "Han Fang",
      "Marjan Ghazvininejad",
      "Jiawei Han",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02064",
    "title": "Lived Experience Matters: Automatic Detection of Stigma toward People  Who Use Substances on Social Media",
    "abstract": "Stigma toward people who use substances (PWUS) is a leading barrier to seeking treatment. Further, those in treatment are more likely to drop out if they experience higher levels of stigmatization. While related concepts of hate speech and toxicity, including those targeted toward vulnerable populations, have been the focus of automatic content moderation research, stigma and, in particular, people who use substances have not. This paper explores stigma toward PWUS using a data set of roughly 5,000 public Reddit posts. We performed a crowd-sourced annotation task where workers are asked to annotate each post for the presence of stigma toward PWUS and answer a series of questions related to their experiences with substance use. Results show that workers who use substances or know someone with a substance use disorder are more likely to rate a post as stigmatizing. Building on this, we use a supervised machine learning framework that centers workers with lived substance use experience to label each Reddit post as stigmatizing. Modeling person-level demographics in addition to comment-level language results in a classification accuracy (as measured by AUC) of 0.69 -- a 17% increase over modeling language alone. Finally, we explore the linguist cues which distinguish stigmatizing content: PWUS substances and those who don't agree that language around othering (\"people\", \"they\") and terms like \"addict\" are stigmatizing, while PWUS (as opposed to those who do not) find discussions around specific substances more stigmatizing. Our findings offer insights into the nature of perceived stigma in substance use. Additionally, these results further establish the subjective nature of such machine learning tasks, highlighting the need for understanding their social contexts. ",
    "url": "https://arxiv.org/abs/2302.02064",
    "authors": [
      "Salvatore Giorgi",
      "Douglas Bellew",
      "Daniel Roy Sadek Habib",
      "Joao Sedoc",
      "Chase Smitterberg",
      "Amanda Devoto",
      "McKenzie Himelein-Wachowiak",
      "Brenda Curtis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.02069",
    "title": "Heterogeneous Federated Knowledge Graph Embedding Learning and  Unlearning",
    "abstract": "Federated Learning (FL) recently emerges as a paradigm to train a global machine learning model across distributed clients without sharing raw data. Knowledge Graph (KG) embedding represents KGs in a continuous vector space, serving as the backbone of many knowledge-driven applications. As a promising combination, federated KG embedding can fully take advantage of knowledge learned from different clients while preserving the privacy of local data. However, realistic problems such as data heterogeneity and knowledge forgetting still remain to be concerned. In this paper, we propose FedLU, a novel FL framework for heterogeneous KG embedding learning and unlearning. To cope with the drift between local optimization and global convergence caused by data heterogeneity, we propose mutual knowledge distillation to transfer local knowledge to global, and absorb global knowledge back. Moreover, we present an unlearning method based on cognitive neuroscience, which combines retroactive interference and passive decay to erase specific knowledge from local clients and propagate to the global model by reusing knowledge distillation. We construct new datasets for assessing realistic performance of the state-of-the-arts. Extensive experiments show that FedLU achieves superior results in both link prediction and knowledge forgetting. ",
    "url": "https://arxiv.org/abs/2302.02069",
    "authors": [
      "Xiangrong Zhu",
      "Guangyao Li",
      "Wei Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.02070",
    "title": "Semantic-Guided Image Augmentation with Pre-trained Models",
    "abstract": "Image augmentation is a common mechanism to alleviate data scarcity in computer vision. Existing image augmentation methods often apply pre-defined transformations or mixup to augment the original image, but only locally vary the image. This makes them struggle to find a balance between maintaining semantic information and improving the diversity of augmented images. In this paper, we propose a Semantic-guided Image augmentation method with Pre-trained models (SIP). Specifically, SIP constructs prompts with image labels and captions to better guide the image-to-image generation process of the pre-trained Stable Diffusion model. The semantic information contained in the original images can be well preserved, and the augmented images still maintain diversity. Experimental results show that SIP can improve two commonly used backbones, i.e., ResNet-50 and ViT, by 12.60% and 2.07% on average over seven datasets, respectively. Moreover, SIP not only outperforms the best image augmentation baseline RandAugment by 4.46% and 1.23% on two backbones, but also further improves the performance by integrating naturally with the baseline. A detailed analysis of SIP is presented, including the diversity of augmented images, an ablation study on textual prompts, and a case study on the generated images. ",
    "url": "https://arxiv.org/abs/2302.02070",
    "authors": [
      "Bohan Li",
      "Xinghao Wang",
      "Xiao Xu",
      "Yutai Hou",
      "Yunlong Feng",
      "Feng Wang",
      "Wanxiang Che"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02079",
    "title": "Sparse Resource Allocation for Spreading Processes on Temporal-Switching  Networks",
    "abstract": "Spreading processes, e.g. epidemics, wildfires and rumors, are often modeled on static networks. However, their underlying network structures, e.g. changing contacts in social networks, different weather forecasts for wildfires, are due to ever-changing circumstances inherently time-varying in nature. In this paper, we therefore, propose an optimization framework for sparse resource allocation for control of spreading processes over temporal networks with known connectivity patterns. We use convex optimization, in particular exponential cone programming, and dynamic programming techniques to bound and minimize the risk of an undetected outbreak by allocating budgeted resources each time step. We demonstrate with misinformation, epidemic and wildfire examples how the method can provide targeted allocation of resources. ",
    "url": "https://arxiv.org/abs/2302.02079",
    "authors": [
      "Vera L. J. Somers",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.02080",
    "title": "Improving Prediction Backward-Compatiblility in NLP Model Upgrade with  Gated Fusion",
    "abstract": "When upgrading neural models to a newer version, new errors that were not encountered in the legacy version can be introduced, known as regression errors. This inconsistent behavior during model upgrade often outweighs the benefits of accuracy gain and hinders the adoption of new models. To mitigate regression errors from model upgrade, distillation and ensemble have proven to be viable solutions without significant compromise in performance. Despite the progress, these approaches attained an incremental reduction in regression which is still far from achieving backward-compatible model upgrade. In this work, we propose a novel method, Gated Fusion, that promotes backward compatibility via learning to mix predictions between old and new models. Empirical results on two distinct model upgrade scenarios show that our method reduces the number of regression errors by 62% on average, outperforming the strongest baseline by an average of 25%. ",
    "url": "https://arxiv.org/abs/2302.02080",
    "authors": [
      "Yi-An Lai",
      "Elman Mansimov",
      "Yuqing Xie",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.02088",
    "title": "AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene  Synthesis",
    "abstract": "Human perception of the complex world relies on a comprehensive analysis of multi-modal signals, and the co-occurrences of audio and video signals provide humans with rich cues. This paper focuses on novel audio-visual scene synthesis in the real world. Given a video recording of an audio-visual scene, the task is to synthesize new videos with spatial audios along arbitrary novel camera trajectories in that audio-visual scene. Directly using a NeRF-based model for audio synthesis is insufficient due to its lack of prior knowledge and acoustic supervision. To tackle the challenges, we first propose an acoustic-aware audio generation module that integrates our prior knowledge of audio propagation into NeRF, in which we associate audio generation with the 3D geometry of the visual environment. In addition, we propose a coordinate transformation module that expresses a viewing direction relative to the sound source. Such a direction transformation helps the model learn sound source-centric acoustic fields. Moreover, we utilize a head-related impulse response function to synthesize pseudo binaural audio for data augmentation that strengthens training. We qualitatively and quantitatively demonstrate the advantage of our model on real-world audio-visual scenes. We refer interested readers to view our video results for convincing comparisons. ",
    "url": "https://arxiv.org/abs/2302.02088",
    "authors": [
      "Susan Liang",
      "Chao Huang",
      "Yapeng Tian",
      "Anurag Kumar",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.02089",
    "title": "MOMA:Distill from Self-Supervised Teachers",
    "abstract": "Contrastive Learning and Masked Image Modelling have demonstrated exceptional performance on self-supervised representation learning, where Momentum Contrast (i.e., MoCo) and Masked AutoEncoder (i.e., MAE) are the state-of-the-art, respectively. In this work, we propose MOMA to distill from pre-trained MoCo and MAE in a self-supervised manner to collaborate the knowledge from both paradigms. We introduce three different mechanisms of knowledge transfer in the propsoed MOMA framework. : (1) Distill pre-trained MoCo to MAE. (2) Distill pre-trained MAE to MoCo (3) Distill pre-trained MoCo and MAE to a random initialized student. During the distillation, the teacher and the student are fed with original inputs and masked inputs, respectively. The learning is enabled by aligning the normalized representations from the teacher and the projected representations from the student. This simple design leads to efficient computation with extremely high mask ratio and dramatically reduced training epochs, and does not require extra considerations on the distillation target. The experiments show MOMA delivers compact student models with comparable performance to existing state-of-the-art methods, combining the power of both self-supervised learning paradigms. It presents competitive results against different benchmarks in computer vision. We hope our method provides an insight on transferring and adapting the knowledge from large-scale pre-trained models in a computationally efficient way. ",
    "url": "https://arxiv.org/abs/2302.02089",
    "authors": [
      "Yuchong Yao",
      "Nandakishor Desai",
      "Marimuthu Palaniswami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02092",
    "title": "Interpolation for Robust Learning: Data Augmentation on Geodesics",
    "abstract": "We propose to study and promote the robustness of a model as per its performance through the interpolation of training data distributions. Specifically, (1) we augment the data by finding the worst-case Wasserstein barycenter on the geodesic connecting subpopulation distributions of different categories. (2) We regularize the model for smoother performance on the continuous geodesic path connecting subpopulation distributions. (3) Additionally, we provide a theoretical guarantee of robustness improvement and investigate how the geodesic location and the sample size contribute, respectively. Experimental validations of the proposed strategy on four datasets, including CIFAR-100 and ImageNet, establish the efficacy of our method, e.g., our method improves the baselines' certifiable robustness on CIFAR10 up to $7.7\\%$, with $16.8\\%$ on empirical robustness on CIFAR-100. Our work provides a new perspective of model robustness through the lens of Wasserstein geodesic-based interpolation with a practical off-the-shelf strategy that can be combined with existing robust training methods. ",
    "url": "https://arxiv.org/abs/2302.02092",
    "authors": [
      "Jiacheng Zhu",
      "Jielin Qiu",
      "Aritra Guha",
      "Zhuolin Yang",
      "Xuanlong Nguyen",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.02093",
    "title": "Knowledge-enhanced Neural Machine Reasoning: A Review",
    "abstract": "Knowledge-enhanced neural machine reasoning has garnered significant attention as a cutting-edge yet challenging research area with numerous practical applications. Over the past few years, plenty of studies have leveraged various forms of external knowledge to augment the reasoning capabilities of deep models, tackling challenges such as effective knowledge integration, implicit knowledge mining, and problems of tractability and optimization. However, there is a dearth of a comprehensive technical review of the existing knowledge-enhanced reasoning techniques across the diverse range of application domains. This survey provides an in-depth examination of recent advancements in the field, introducing a novel taxonomy that categorizes existing knowledge-enhanced methods into two primary categories and four subcategories. We systematically discuss these methods and highlight their correlations, strengths, and limitations. Finally, we elucidate the current application domains and provide insight into promising prospects for future research. ",
    "url": "https://arxiv.org/abs/2302.02093",
    "authors": [
      "Tanmoy Chowdhury",
      "Chen Ling",
      "Xuchao Zhang",
      "Xujiang Zhao",
      "Guangji Bai",
      "Jian Pei",
      "Haifeng Chen",
      "Liang Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.02097",
    "title": "Unsupervised Ensemble Methods for Anomaly Detection in PLC-based Process  Control",
    "abstract": "Programmable logic controller (PLC) based industrial control systems (ICS) are used to monitor and control critical infrastructure. Integration of communication networks and an Internet of Things approach in ICS has increased ICS vulnerability to cyber-attacks. This work proposes novel unsupervised machine learning ensemble methods for anomaly detection in PLC-based ICS. The work presents two broad approaches to anomaly detection: a weighted voting ensemble approach with a learning algorithm based on coefficient of determination and a stacking-based ensemble approach using isolation forest meta-detector. The two ensemble methods were analyzed via an open-source PLC-based ICS subjected to multiple attack scenarios as a case study. The work considers four different learning models for the weighted voting ensemble method. Comparative performance analyses of five ensemble methods driven diverse base detectors are presented. Results show that stacking-based ensemble method using isolation forest meta-detector achieves superior performance to previous work on all performance metrics. Results also suggest that effective unsupervised ensemble methods, such as stacking-based ensemble having isolation forest meta-detector, can robustly detect anomalies in arbitrary ICS datasets. Finally, the presented results were validated by using statistical hypothesis tests. ",
    "url": "https://arxiv.org/abs/2302.02097",
    "authors": [
      "Emmanuel Aboah Boateng",
      "Bruce J. W"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02101",
    "title": "GRANDE: a neural model over directed multigraphs with application to  anti-money laundering",
    "abstract": "The application of graph representation learning techniques to the area of financial risk management (FRM) has attracted significant attention recently. However, directly modeling transaction networks using graph neural models remains challenging: Firstly, transaction networks are directed multigraphs by nature, which could not be properly handled with most of the current off-the-shelf graph neural networks (GNN). Secondly, a crucial problem in FRM scenarios like anti-money laundering (AML) is to identify risky transactions and is most naturally cast into an edge classification problem with rich edge-level features, which are not fully exploited by the prevailing GNN design that follows node-centric message passing protocols. In this paper, we present a systematic investigation of design aspects of neural models over directed multigraphs and develop a novel GNN protocol that overcomes the above challenges via efficiently incorporating directional information, as well as proposing an enhancement that targets edge-related tasks using a novel message passing scheme over an extension of edge-to-node dual graph. A concrete GNN architecture called GRANDE is derived using the proposed protocol, with several further improvements and generalizations to temporal dynamic graphs. We apply the GRANDE model to both a real-world anti-money laundering task and public datasets. Experimental evaluations show the superiority of the proposed GRANDE architecture over recent state-of-the-art models on dynamic graph modeling and directed graph modeling. ",
    "url": "https://arxiv.org/abs/2302.02101",
    "authors": [
      "Ruofan Wu",
      "Boqun Ma",
      "Hong Jin",
      "Wenlong Zhao",
      "Weiqiang Wang",
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02112",
    "title": "Detecting Security Patches via Behavioral Data in Code Repositories",
    "abstract": "The absolute majority of software today is developed collaboratively using collaborative version control tools such as Git. It is a common practice that once a vulnerability is detected and fixed, the developers behind the software issue a Common Vulnerabilities and Exposures or CVE record to alert the user community of the security hazard and urge them to integrate the security patch. However, some companies might not disclose their vulnerabilities and just update their repository. As a result, users are unaware of the vulnerability and may remain exposed. In this paper, we present a system to automatically identify security patches using only the developer behavior in the Git repository without analyzing the code itself or the remarks that accompanied the fix (commit message). We showed we can reveal concealed security patches with an accuracy of 88.3% and F1 Score of 89.8%. This is the first time that a language-oblivious solution for this problem is presented. ",
    "url": "https://arxiv.org/abs/2302.02112",
    "authors": [
      "Nitzan Farhi",
      "Noam Koenigstein",
      "Yuval Shavitt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.02113",
    "title": "Personalized Graph Signal Processing for Collaborative Filtering",
    "abstract": "The collaborative filtering (CF) problem with only user-item interaction information can be solved by graph signal processing (GSP), which uses low-pass filters to smooth the observed interaction signals on the similarity graph to obtain the prediction signals. However, the interaction signal may not be sufficient to accurately characterize user interests and the low-pass filters may ignore the useful information contained in the high-frequency component of the observed signals, resulting in suboptimal accuracy. To this end, we propose a personalized graph signal processing (PGSP) method for collaborative filtering. Firstly, we design the personalized graph signal containing richer user information and construct an augmented similarity graph containing more graph topology information, to more effectively characterize user interests. Secondly, we devise a mixed-frequency graph filter to introduce useful information in the high-frequency components of the observed signals by combining an ideal low-pass filter that smooths signals globally and a linear low-pass filter that smooths signals locally. Finally, we combine the personalized graph signal, the augmented similarity graph and the mixed-frequency graph filter by proposing a pipeline consisting of three key steps: pre-processing, graph convolution and post-processing. Extensive experiments show that PGSP can achieve superior accuracy compared with state-of-the-art CF methods and, as a nonparametric method, PGSP has very high training efficiency. ",
    "url": "https://arxiv.org/abs/2302.02113",
    "authors": [
      "Jiahao Liu",
      "Dongsheng Li",
      "Hansu Gu",
      "Tun Lu",
      "Peng Zhang",
      "Li Shang",
      "Ning Gu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.02116",
    "title": "Knowledge Graph Completion Method Combined With Adaptive Enhanced  Semantic Information",
    "abstract": "Translation models tend to ignore the rich semantic information in triads in the process of knowledge graph complementation. To remedy this shortcoming, this paper constructs a knowledge graph complementation method that incorporates adaptively enhanced semantic information. The hidden semantic information inherent in the triad is obtained by fine-tuning the BERT model, and the attention feature embedding method is used to calculate the semantic attention scores between relations and entities in positive and negative triads and incorporate them into the structural information to form a soft constraint rule for semantic information. The rule is added to the original translation model to realize the adaptive enhancement of semantic information. In addition, the method takes into account the effect of high-dimensional vectors on the effect, and uses the BERT-whitening method to reduce the dimensionality and generate a more efficient semantic vector representation. After experimental comparison, the proposed method performs better on both FB15K and WIN18 datasets, with a numerical improvement of about 2.6% compared with the original translation model, which verifies the reasonableness and effectiveness of the method. ",
    "url": "https://arxiv.org/abs/2302.02116",
    "authors": [
      "Weidong Ji",
      "Zengxiang Yin",
      "Guohui Zhou",
      "Yuqi Yue",
      "Xinru Zhang",
      "Chenghong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.02122",
    "title": "A New cross-domain strategy based XAI models for fake news detection",
    "abstract": "In this study, we presented a four-level cross-domain strategy for fake news detection on pre-trained models. Cross-domain text classification is a task of a model adopting a target domain by using the knowledge of the source domain. Explainability is crucial in understanding the behaviour of these complex models. A fine-tune BERT model is used to. perform cross-domain classification with several experiments using datasets from different domains. Explanatory models like Anchor, ELI5, LIME and SHAP are used to design a novel explainable approach to cross-domain levels. The experimental analysis has given an ideal pair of XAI models on different levels of cross-domain. ",
    "url": "https://arxiv.org/abs/2302.02122",
    "authors": [
      "Deepak Kanneganti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02128",
    "title": "Interaction Order Prediction for Temporal Graphs",
    "abstract": "Link prediction in graphs is a task that has been widely investigated. It has been applied in various domains such as knowledge graph completion, content/item recommendation, social network recommendations and so on. The initial focus of most research was on link prediction in static graphs. However, there has recently been abundant work on modeling temporal graphs, and consequently one of the tasks that has been researched is link prediction in temporal graphs. However, most of the existing work does not focus on the order of link formation, and only predicts the existence of links. In this study, we aim to predict the order of node interactions. ",
    "url": "https://arxiv.org/abs/2302.02128",
    "authors": [
      "Nayana Bannur",
      "Mashrin Srivastava",
      "Harsha Vardhan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02130",
    "title": "Inferencing the earth moving equipment-environment interaction in open  pit mining",
    "abstract": "In mining, grade control generally focuses on blast hole sampling and the estimation of ore control block models with little or no attention given to how the materials are being excavated from the ground. In the process of loading trucks, the underlying variability of the individual bucket load will determine the variability of truck payload. Hence, accurate material movement demands a good knowledge of the excavation process and the buckets interaction with the environment. However, equipment frequently goes into off nominal states due to unexpected delays, disturbances or faults. The large amount of such disturbances causes information loss that reduces the statistical power and biases estimates, leading to increased uncertainty in the production. A reliable method that inferences the missing knowledge about the interaction between the machine and the environment from the available data sources, is vital to accurately model the material movement. In this study, a twostep method was implemented that performed unsupervised clustering and then predicted the missing information. The first method is DBSCAN based spatial clustering which divides the diggers and buckets positional data into connected loading segments. Clear patterns of segmented bucket dig positions were observed. The second model utilized Gaussian process regression which was trained with the clustered data and the model was then used to infer the mean locations of the test clusters. Bucket dig locations were then simulated at the inferred mean locations for different durations and compared against the known bucket dig locations. This method was tested at an open pit mine in the Pilbara of Western Australia. The results demonstrate the advantage of the proposed method in inferencing the missing information of bucket environment interactions and therefore enables miners to continuously track the material movement. ",
    "url": "https://arxiv.org/abs/2302.02130",
    "authors": [
      "M. Balamurali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02139",
    "title": "Structural Explanations for Graph Neural Networks using HSIC",
    "abstract": "Graph neural networks (GNNs) are a type of neural model that tackle graphical tasks in an end-to-end manner. Recently, GNNs have been receiving increased attention in machine learning and data mining communities because of the higher performance they achieve in various tasks, including graph classification, link prediction, and recommendation. However, the complicated dynamics of GNNs make it difficult to understand which parts of the graph features contribute more strongly to the predictions. To handle the interpretability issues, recently, various GNN explanation methods have been proposed. In this study, a flexible model agnostic explanation method is proposed to detect significant structures in graphs using the Hilbert-Schmidt independence criterion (HSIC), which captures the nonlinear dependency between two variables through kernels. More specifically, we extend the GraphLIME method for node explanation with a group lasso and a fused lasso-based node explanation method. The group and fused regularization with GraphLIME enables the interpretation of GNNs in substructure units. Then, we show that the proposed approach can be used for the explanation of sequential graph classification tasks. Through experiments, it is demonstrated that our method can identify crucial structures in a target graph in various settings. ",
    "url": "https://arxiv.org/abs/2302.02139",
    "authors": [
      "Ayato Toyokuni",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.02149",
    "title": "Invariants for neural automata",
    "abstract": "Computational modeling of neurodynamical systems often deploys neural networks and symbolic dynamics. A particular way for combining these approaches within a framework called vector symbolic architectures leads to neural automata. An interesting research direction we have pursued under this framework has been to consider mapping symbolic dynamics onto neurodynamics, represented as neural automata. This representation theory, enables us to ask questions, such as, how does the brain implement Turing computations. Specifically, in this representation theory, neural automata result from the assignment of symbols and symbol strings to numbers, known as G\\\"odel encoding. Under this assignment symbolic computation becomes represented by trajectories of state vectors in a real phase space, that allows for statistical correlation analyses with real-world measurements and experimental data. However, these assignments are usually completely arbitrary. Hence, it makes sense to address the problem question of, which aspects of the dynamics observed under such a representation is intrinsic to the dynamics and which are not. In this study, we develop a formally rigorous mathematical framework for the investigation of symmetries and invariants of neural automata under different encodings. As a central concept we define patterns of equality for such systems. We consider different macroscopic observables, such as the mean activation level of the neural network, and ask for their invariance properties. Our main result shows that only step functions that are defined over those patterns of equality are invariant under recodings, while the mean activation is not. Our work could be of substantial importance for related regression studies of real-world measurements with neurosymbolic processors for avoiding confounding results that are dependant on a particular encoding and not intrinsic to the dynamics. ",
    "url": "https://arxiv.org/abs/2302.02149",
    "authors": [
      "Jone Uria-Albizuri",
      "Giovanni Sirio Carmantini",
      "Peter beim Graben",
      "Serafim Rodrigues"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2302.02160",
    "title": "Directed Acyclic Graphs With Tears",
    "abstract": "Bayesian network is a frequently-used method for fault detection and diagnosis in industrial processes. The basis of Bayesian network is structure learning which learns a directed acyclic graph (DAG) from data. However, the search space will scale super-exponentially with the increase of process variables, which makes the data-driven structure learning a challenging problem. To this end, the DAGs with NOTEARs methods are being well studied not only for their conversion of the discrete optimization into continuous optimization problem but also their compatibility with deep learning framework. Nevertheless, there still remain challenges for NOTEAR-based methods: 1) the infeasible solution results from the gradient descent-based optimization paradigm; 2) the truncation operation to promise the learned graph acyclic. In this work, the reason for challenge 1) is analyzed theoretically, and a novel method named DAGs with Tears method is proposed based on mix-integer programming to alleviate challenge 2). In addition, prior knowledge is able to incorporate into the new proposed method, making structure learning more practical and useful in industrial processes. Finally, a numerical example and an industrial example are adopted as case studies to demonstrate the superiority of the developed method. ",
    "url": "https://arxiv.org/abs/2302.02160",
    "authors": [
      "Zhichao Chen",
      "Zhiqiang Ge"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02162",
    "title": "AUTOLYCUS: Exploiting Explainable AI (XAI) for Model Extraction Attacks  against Decision Tree Models",
    "abstract": "Model extraction attack is one of the most prominent adversarial techniques to target machine learning models along with membership inference attack and model inversion attack. On the other hand, Explainable Artificial Intelligence (XAI) is a set of techniques and procedures to explain the decision making process behind AI. XAI is a great tool to understand the reasoning behind AI models but the data provided for such revelation creates security and privacy vulnerabilities. In this poster, we propose AUTOLYCUS, a model extraction attack that exploits the explanations provided by LIME to infer the decision boundaries of decision tree models and create extracted surrogate models that behave similar to a target model. ",
    "url": "https://arxiv.org/abs/2302.02162",
    "authors": [
      "Abdullah Caglar Oksuz",
      "Anisa Halimi",
      "Erman Ayday"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.02173",
    "title": "Neural Time Series Analysis with Fourier Transform: A Survey",
    "abstract": "Recently, Fourier transform has been widely introduced into deep neural networks to further advance the state-of-the-art regarding both accuracy and efficiency of time series analysis. The advantages of the Fourier transform for time series analysis, such as efficiency and global view, have been rapidly explored and exploited, exhibiting a promising deep learning paradigm for time series analysis. However, although increasing attention has been attracted and research is flourishing in this emerging area, there lacks a systematic review of the variety of existing studies in the area. To this end, in this paper, we provide a comprehensive review of studies on neural time series analysis with Fourier transform. We aim to systematically investigate and summarize the latest research progress. Accordingly, we propose a novel taxonomy to categorize existing neural time series analysis methods from four perspectives, including characteristics, usage paradigms, network design, and applications. We also share some new research directions in this vibrant area. ",
    "url": "https://arxiv.org/abs/2302.02173",
    "authors": [
      "Kun Yi",
      "Qi Zhang",
      "Shoujin Wang",
      "Hui He",
      "Guodong Long",
      "Zhendong Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02178",
    "title": "Construction Grammar Provides Unique Insight into Neural Language Models",
    "abstract": "Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces. ",
    "url": "https://arxiv.org/abs/2302.02178",
    "authors": [
      "Leonie Weissweiler",
      "Taiqi He",
      "Naoki Otani",
      "David R. Mortensen",
      "Lori Levin",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.02181",
    "title": "Model Stitching and Visualization How GAN Generators can Invert Networks  in Real-Time",
    "abstract": "Critical applications, such as in the medical field, require the rapid provision of additional information to interpret decisions made by deep learning methods. In this work, we propose a fast and accurate method to visualize activations of classification and semantic segmentation networks by stitching them with a GAN generator utilizing convolutions. We test our approach on images of animals from the AFHQ wild dataset and real-world digital pathology scans of stained tissue samples. Our method provides comparable results to established gradient descent methods on these datasets while running about two orders of magnitude faster. ",
    "url": "https://arxiv.org/abs/2302.02181",
    "authors": [
      "Rudolf Herdt",
      "Maximilian Schmidt",
      "Daniel Otero Baguer",
      "Jean Le'Clerc Arrastia",
      "Peter Maass"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.02186",
    "title": "Perimeter Defense using a Turret with Finite Range and Service Times",
    "abstract": "We consider a perimeter defense problem in a planar conical environment comprising a single turret that has a finite range and non-zero service time. The turret seeks to defend a concentric perimeter against $N\\geq 2$ intruders. Upon release, each intruder moves radially towards the perimeter with a fixed speed. To capture an intruder, the turret's angle must be aligned with that of the intruder's angle and must spend a specified service time at that orientation. We address offline and online versions of this optimization problem. Specifically, in the offline version, we establish that in general parameter regimes, this problem is equivalent to solving a Travelling Repairperson Problem with Time Windows (TRP-TW). We then identify specific parameter regimes in which there is a polynomial time algorithm that maximizes the number of intruders captured. In the online version, we present a competitive analysis technique in which we establish a fundamental guarantee on the existence of at best $(N-1)$-competitive algorithms. We also design two online algorithms that are provably $1$ and $2$-competitive in specific parameter regimes. ",
    "url": "https://arxiv.org/abs/2302.02186",
    "authors": [
      "Shivam Bajaj",
      "Shaunak D. Bopardikar",
      "Alexander Von Moll",
      "Eric Torng",
      "David W. Casbeer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.02208",
    "title": "Certified Robust Control under Adversarial Perturbations",
    "abstract": "Autonomous systems increasingly rely on machine learning techniques to transform high-dimensional raw inputs into predictions that are then used for decision-making and control. However, it is often easy to maliciously manipulate such inputs and, as a result, predictions. While effective techniques have been proposed to certify the robustness of predictions to adversarial input perturbations, such techniques have been disembodied from control systems that make downstream use of the predictions. We propose the first approach for composing robustness certification of predictions with respect to raw input perturbations with robust control to obtain certified robustness of control to adversarial input perturbations. We use a case study of adaptive vehicle control to illustrate our approach and show the value of the resulting end-to-end certificates through extensive experiments. ",
    "url": "https://arxiv.org/abs/2302.02208",
    "authors": [
      "Jinghan Yang",
      "Hunmin Kim",
      "Wenbin Wan",
      "Naira Hovakimyan",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02209",
    "title": "A Theory of Link Prediction via Relational Weisfeiler-Leman",
    "abstract": "Graph neural networks are prominent models for representation learning over graph-structured data. While the capabilities and limitations of these models are well-understood for simple graphs, our understanding remains highly incomplete in the context of knowledge graphs. The goal of this work is to provide a systematic understanding of the landscape of graph neural networks for knowledge graphs pertaining the prominent task of link prediction. Our analysis entails a unifying perspective on seemingly unrelated models, and unlocks a series of other models. The expressive power of various models is characterized via a corresponding relational Weisfeiler-Leman algorithm with different initialization regimes. This analysis is extended to provide a precise logical characterization of the class of functions captured by a class of graph neural networks. Our theoretical findings explain the benefits of some widely employed practical design choices, which are validated empirically. ",
    "url": "https://arxiv.org/abs/2302.02209",
    "authors": [
      "Xingyue Huang",
      "Miguel Romero Orth",
      "\u0130smail \u0130lkan Ceylan",
      "Pablo Barcel\u00f3"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02213",
    "title": "CosPGD: a unified white-box adversarial attack for pixel-wise prediction  tasks",
    "abstract": "While neural networks allow highly accurate predictions in many tasks, their lack in robustness towards even slight input perturbations hampers their deployment in many real-world applications. Recent research towards evaluating the robustness of neural networks such as the seminal \\emph{projected gradient descent} (PGD) attack and subsequent works and benchmarks have therefore drawn significant attention. Yet, such methods focus predominantly on classification tasks, while only a few approaches specifically address the analysis of pixel-wise prediction tasks such as semantic segmentation, optical flow, or disparity estimation. One notable exception is the recently proposed SegPGD attack, which could showcase the importance of pixel-wise attacks for evaluating semantic segmentation. While SegPGD is limited to pixel-wise classification (i.e. segmentation), in this work, we propose CosPGD, a novel white-box adversarial attack that allows to optimize dedicated attacks for any pixel-wise prediction task in a unified setting. It leverages the cosine similarity between the predictions and ground truth to extend directly from classification tasks to regression settings. Further, we empirically show the superior performance of CosPGD for semantic segmentation as well as for optical flow and disparity estimation. ",
    "url": "https://arxiv.org/abs/2302.02213",
    "authors": [
      "Shashank Agnihotri",
      "Margret Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02215",
    "title": "Linear-time 2-strong connectivity orientations of mixed graphs and  related problems",
    "abstract": "A mixed graph $G$ is a graph that consists of both undirected and directed edges. An orientation of $G$ is formed by orienting all the undirected edges of $G$, i.e., converting each undirected edge $\\{u,v\\}$ into a directed edge that is either $(u,v)$ or $(v,u)$. The problem of finding an orientation of a mixed graph that makes it strongly connected is well understood and can be solved in linear time. Here we introduce the following orientation problem in mixed graphs. Given a mixed graph $G$, we wish to compute its maximal sets of vertices $C_1,C_2,\\ldots,C_k$ with the property that by removing any edge $e$ from $G$ (directed or undirected), there is an orientation $R_i$ of $G\\setminus{e}$ such that all vertices in $C_i$ are strongly connected in $R_i$. We discuss properties of those sets, and we show how to solve this problem in linear time by reducing it to the computation of the $2$-edge twinless strongly connected components of a directed graph. A directed graph $G=(V,E)$ is twinless strongly connected if it contains a strongly connected spanning subgraph without any pair of antiparallel (or twin) edges. The twinless strongly connected components (TSCCs) of a directed graph $G$ are its maximal twinless strongly connected subgraphs. A $2$-edge twinless strongly connected component (2eTSCC) of $G$ is a maximal subset of vertices $C$ such that any two vertices $u, v \\in C$ are in the same twinless strongly connected component of $G \\setminus e$, for any edge $e$. These concepts have several diverse applications, such as the design of road and telecommunication networks, and the structural stability of buildings. ",
    "url": "https://arxiv.org/abs/2302.02215",
    "authors": [
      "Loukas Georgiadis",
      "Dionysios Kefallinos",
      "Evangelos Kosinas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2302.02216",
    "title": "A Minimax Approach Against Multi-Armed Adversarial Attacks Detection",
    "abstract": "Multi-armed adversarial attacks, in which multiple algorithms and objective loss functions are simultaneously used at evaluation time, have been shown to be highly successful in fooling state-of-the-art adversarial examples detectors while requiring no specific side information about the detection mechanism. By formalizing the problem at hand, we can propose a solution that aggregates the soft-probability outputs of multiple pre-trained detectors according to a minimax approach. The proposed framework is mathematically sound, easy to implement, and modular, allowing for integrating existing or future detectors. Through extensive evaluation on popular datasets (e.g., CIFAR10 and SVHN), we show that our aggregation consistently outperforms individual state-of-the-art detectors against multi-armed adversarial attacks, making it an effective solution to improve the resilience of available methods. ",
    "url": "https://arxiv.org/abs/2302.02216",
    "authors": [
      "Federica Granese",
      "Marco Romanelli",
      "Siddharth Garg",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02223",
    "title": "Nooks: Social Spaces to Lower Hesitations in Interacting with New People  at Work",
    "abstract": "Initiating conversations with new people at work is often intimidating because of uncertainty about their interests. People worry others may reject their attempts to initiate conversation or that others may not enjoy the conversation. We introduce a new system, Nooks, built on Slack, that reduces fear of social evaluation by enabling individuals to initiate any conversation as a nook -- a conversation room that identifies its topic, but not its creator. Automatically convening others interested in the nook, Nooks further reduces fears of social evaluation by guaranteeing individuals in advance that others they are about to interact with are interested in the conversation. In a multi-month deployment with participants in a summer research program, Nooks provided participants with non-threatening and inclusive interaction opportunities, and ambient awareness, leading to new interactions online and offline. Our results demonstrate how intentionally designed social spaces can reduce fears of social evaluation and catalyze new workplace connections. ",
    "url": "https://arxiv.org/abs/2302.02223",
    "authors": [
      "Shreya Bali",
      "Pranav Khadpe",
      "Geoff Kaufman",
      "Chinmay Kulkarni"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.02231",
    "title": "PubGraph: A Large Scale Scientific Temporal Knowledge Graph",
    "abstract": "Research publications are the primary vehicle for sharing scientific progress in the form of new discoveries, methods, techniques, and insights. Publications have been studied from the perspectives of both content analysis and bibliometric structure, but a barrier to more comprehensive studies of scientific research is a lack of publicly accessible large-scale data and resources. In this paper, we present PubGraph, a new resource for studying scientific progress that takes the form of a large-scale temporal knowledge graph (KG). It contains more than 432M nodes and 15.49B edges mapped to the popular Wikidata ontology. We extract three KGs with varying sizes from PubGraph to allow experimentation at different scales. Using these KGs, we introduce a new link prediction benchmark for transductive and inductive settings with temporally-aligned training, validation, and testing partitions. Moreover, we develop two new inductive learning methods better suited to PubGraph, operating on unseen nodes without explicit features, scaling to large KGs, and outperforming existing models. Our results demonstrate that structural features of past citations are sufficient to produce high-quality predictions about new publications. We also identify new challenges for KG models, including an adversarial community-based link prediction setting, zero-shot inductive learning, and large-scale learning. ",
    "url": "https://arxiv.org/abs/2302.02231",
    "authors": [
      "Kian Ahrabian",
      "Xinwei Du",
      "Richard Delwin Myloth",
      "Arun Baalaaji Sankar Ananthan",
      "Jay Pujara"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02237",
    "title": "Conformalized semi-supervised random forest for classification and  abnormality detection",
    "abstract": "Traditional classifiers infer labels under the premise that the training and test samples are generated from the same distribution. This assumption can be problematic for safety-critical applications such as medical diagnosis and network attack detection. In this paper, we consider the multi-class classification problem when the training data and the test data may have different distributions. We propose conformalized semi-supervised random forest (CSForest), which constructs set-valued predictions $C(x)$ to include the correct class label with desired probability while detecting outliers efficiently. We compare the proposed method to other state-of-art methods in both a synthetic example and a real data application to demonstrate the strength of our proposal. ",
    "url": "https://arxiv.org/abs/2302.02237",
    "authors": [
      "Yujin Han",
      "Mingwenchan Xu",
      "Leying Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02241",
    "title": "Feature Representation Learning for Click-through Rate Prediction: A  Review and New Perspectives",
    "abstract": "Representation learning has been a critical topic in machine learning. In Click-through Rate Prediction, most features are represented as embedding vectors and learned simultaneously with other parameters in the model. With the development of CTR models, feature representation learning has become a trending topic and has been extensively studied by both industrial and academic researchers in recent years. This survey aims at summarizing the feature representation learning in a broader picture and pave the way for future research. To achieve such a goal, we first present a taxonomy of current research methods on feature representation learning following two main issues: (i) which feature to represent and (ii) how to represent these features. Then we give a detailed description of each method regarding these two issues. Finally, the review concludes with a discussion on the future directions of this field. ",
    "url": "https://arxiv.org/abs/2302.02241",
    "authors": [
      "Fuyuan Lyu",
      "Xing Tang",
      "Dugang Liu",
      "Haolun Wu",
      "Chen Ma",
      "Xiuqiang He",
      "Xue Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.02249",
    "title": "Self-supervised Multi-view Disentanglement for Expansion of Visual  Collections",
    "abstract": "Image search engines enable the retrieval of images relevant to a query image. In this work, we consider the setting where a query for similar images is derived from a collection of images. For visual search, the similarity measurements may be made along multiple axes, or views, such as style and color. We assume access to a set of feature extractors, each of which computes representations for a specific view. Our objective is to design a retrieval algorithm that effectively combines similarities computed over representations from multiple views. To this end, we propose a self-supervised learning method for extracting disentangled view-specific representations for images such that the inter-view overlap is minimized. We show how this allows us to compute the intent of a collection as a distribution over views. We show how effective retrieval can be performed by prioritizing candidate expansion images that match the intent of a query collection. Finally, we present a new querying mechanism for image search enabled by composing multiple collections and perform retrieval under this setting using the techniques presented in this paper. ",
    "url": "https://arxiv.org/abs/2302.02249",
    "authors": [
      "Nihal Jain",
      "Praneetha Vaddamanu",
      "Paridhi Maheshwari",
      "Vishwa Vinay",
      "Kuldeep Kulkarni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02259",
    "title": "CLiNet: Joint Detection of Road Network Centerlines in 2D and 3D",
    "abstract": "This work introduces a new approach for joint detection of centerlines based on image data by localizing the features jointly in 2D and 3D. In contrast to existing work that focuses on detection of visual cues, we explore feature extraction methods that are directly amenable to the urban driving task. To develop and evaluate our approach, a large urban driving dataset dubbed AV Breadcrumbs is automatically labeled by leveraging vector map representations and projective geometry to annotate over 900,000 images. Our results demonstrate potential for dynamic scene modeling across various urban driving scenarios. Our model achieves an F1 score of 0.684 and an average normalized depth error of 2.083. The code and data annotations are publicly available. ",
    "url": "https://arxiv.org/abs/2302.02259",
    "authors": [
      "David Paz",
      "Srinidhi Kalgundi Srinivas",
      "Yunchao Yao",
      "Henrik I. Christensen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02276",
    "title": "JPEG Steganalysis Based on Steganographic Feature Enhancement and Graph  Attention Learning",
    "abstract": "The purpose of image steganalysis is to determine whether the carrier image contains hidden information or not. Since JEPG is the most commonly used image format over social networks, steganalysis in JPEG images is also the most urgently needed to be explored. However, in order to detect whether secret information is hidden within JEPG images, the majority of existing algorithms are designed in conjunction with the popular computer vision related networks, without considering the key characteristics appeared in image steganalysis. It is crucial that the steganographic signal, as an extremely weak signal, can be enhanced during its representation learning process. Motivated by this insight, in this paper, we introduce a novel representation learning algorithm for JPEG steganalysis that is mainly consisting of a graph attention learning module and a feature enhancement module. The graph attention learning module is designed to avoid global feature loss caused by the local feature learning of convolutional neural network and reliance on depth stacking to extend the perceptual domain. The feature enhancement module is applied to prevent the stacking of convolutional layers from weakening the steganographic information. In addition, pretraining as a way to initialize the network weights with a large-scale dataset is utilized to enhance the ability of the network to extract discriminative features. We advocate pretraining with ALASKA2 for the model trained with BOSSBase+BOWS2. The experimental results indicate that the proposed algorithm outperforms previous arts in terms of detection accuracy, which has verified the superiority and applicability of the proposed work. ",
    "url": "https://arxiv.org/abs/2302.02276",
    "authors": [
      "Qiyun Liu",
      "Zhiguang Yang",
      "Hanzhou Wu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02283",
    "title": "Recurrence With Correlation Network for Medical Image Registration",
    "abstract": "We present Recurrence with Correlation Network (RWCNet), a medical image registration network with multi-scale features and a cost volume layer. We demonstrate that these architectural features improve medical image registration accuracy in two image registration datasets prepared for the MICCAI 2022 Learn2Reg Workshop Challenge. On the large-displacement National Lung Screening Test (NLST) dataset, RWCNet is able to achieve a total registration error (TRE) of 2.11mm between corresponding keypoints without instance fine-tuning. On the OASIS brain MRI dataset, RWCNet is able to achieve an average dice overlap of 81.7% for 35 different anatomical labels. It outperforms another multi-scale network, the Laplacian Image Registration Network (LapIRN), on both datasets. Ablation experiments are performed to highlight the contribution of the various architectural features. While multi-scale features improved validation accuracy for both datasets, the cost volume layer and number of recurrent steps only improved performance on the large-displacement NLST dataset. This result suggests that cost volume layer and iterative refinement using RNN provide good support for optimization and generalization in large-displacement medical image registration. The code for RWCNet is available at https://github.com/vigsivan/optimization-based-registration. ",
    "url": "https://arxiv.org/abs/2302.02283",
    "authors": [
      "Vignesh Sivan",
      "Teodora Vujovic",
      "Raj Ranabhat",
      "Alexander Wong",
      "Stewart Mclachlin",
      "Michael Hardisty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02290",
    "title": "Maximal $k$-Edge-Connected Subgraphs in Weighted Graphs via Local Random  Contraction",
    "abstract": "The \\emph{maximal $k$-edge-connected subgraphs} problem is a classical graph clustering problem studied since the 70's. Surprisingly, no non-trivial technique for this problem in weighted graphs is known: a very straightforward recursive-mincut algorithm with $\\Omega(mn)$ time has remained the fastest algorithm until now. All previous progress gives a speed-up only when the graph is unweighted, and $k$ is small enough (e.g.~Henzinger~et~al.~(ICALP'15), Chechik~et~al.~(SODA'17), and Forster~et~al.~(SODA'20)). We give the first algorithm that breaks through the long-standing $\\tilde{O}(mn)$-time barrier in \\emph{weighted undirected} graphs. More specifically, we show a maximal $k$-edge-connected subgraphs algorithm that takes only $\\tilde{O}(m\\cdot\\min\\{m^{3/4},n^{4/5}\\})$ time. As an immediate application, we can $(1+\\epsilon)$-approximate the \\emph{strength} of all edges in undirected graphs in the same running time. Our key technique is the first local cut algorithm with \\emph{exact} cut-value guarantees whose running time depends only on the output size. All previous local cut algorithms either have running time depending on the cut value of the output, which can be arbitrarily slow in weighted graphs or have approximate cut guarantees. ",
    "url": "https://arxiv.org/abs/2302.02290",
    "authors": [
      "Chaitanya Nalam",
      "Thatchaphol Saranurak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.02291",
    "title": "A Semantic Approach to Negation Detection and Word Disambiguation with  Natural Language Processing",
    "abstract": "This study aims to demonstrate the methods for detecting negations in a sentence by uniquely evaluating the lexical structure of the text via word sense disambiguation. Additionally, the proposed method examined all the unique features of the related expressions within a text to resolve the contextual usage of the sentence and the effect of negation on sentiment analysis. The application of popular expression detectors skips this important step, thereby neglecting the root words caught in the web of negation, and making text classification difficult for machine learning and sentiment analysis. This study adopts the Natural Language Processing (NLP) approach to discover and antonimize words that were negated for better accuracy in text classification. This method acts as a lens that reads through a given word sequence using a knowledge base provided by an NLP library called WordHoard in order to detect negation signals. Early results show that our initial analysis improved traditional sentiment analysis that sometimes neglects word negations or assigns an inverse polarity score. The SentiWordNet analyzer was improved by 35%, the Vader analyzer by 20% and the TextBlob analyzer by 6%. ",
    "url": "https://arxiv.org/abs/2302.02291",
    "authors": [
      "Izunna Okpala",
      "Guillermo Romera Rodriguez",
      "Andrea Tapia",
      "Shane Halse",
      "Jess Kropczynski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.02292",
    "title": "RRNet: Towards ReLU-Reduced Neural Network for Two-party Computation  Based Private Inference",
    "abstract": "The proliferation of deep learning (DL) has led to the emergence of privacy and security concerns. To address these issues, secure Two-party computation (2PC) has been proposed as a means of enabling privacy-preserving DL computation. However, in practice, 2PC methods often incur high computation and communication overhead, which can impede their use in large-scale systems. To address this challenge, we introduce RRNet, a systematic framework that aims to jointly reduce the overhead of MPC comparison protocols and accelerate computation through hardware acceleration. Our approach integrates the hardware latency of cryptographic building blocks into the DNN loss function, resulting in improved energy efficiency, accuracy, and security guarantees. Furthermore, we propose a cryptographic hardware scheduler and corresponding performance model for Field Programmable Gate Arrays (FPGAs) to further enhance the efficiency of our framework. Experiments show RRNet achieved a much higher ReLU reduction performance than all SOTA works on CIFAR-10 dataset. ",
    "url": "https://arxiv.org/abs/2302.02292",
    "authors": [
      "Hongwu Peng",
      "Shanglin Zhou",
      "Yukui Luo",
      "Nuo Xu",
      "Shijin Duan",
      "Ran Ran",
      "Jiahui Zhao",
      "Shaoyi Huang",
      "Xi Xie",
      "Chenghong Wang",
      "Tong Geng",
      "Wujie Wen",
      "Xiaolin Xu",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02300",
    "title": "Run-Off Election: Improved Provable Defense against Data Poisoning  Attacks",
    "abstract": "In data poisoning attacks, an adversary tries to change a model's prediction by adding, modifying, or removing samples in the training data. Recently, ensemble-based approaches for obtaining provable defenses against data poisoning have been proposed where predictions are done by taking a majority vote across multiple base models. In this work, we show that merely considering the majority vote in ensemble defenses is wasteful as it does not effectively utilize available information in the logits layers of the base models. Instead, we propose Run-Off Election (ROE), a novel aggregation method based on a two-round election across the base models: In the first round, models vote for their preferred class and then a second, Run-Off election is held between the top two classes in the first round. Based on this approach, we propose DPA+ROE and FA+ROE defense methods based on Deep Partition Aggregation (DPA) and Finite Aggregation (FA) approaches from prior work. We show how to obtain robustness for these methods using ideas inspired by dynamic programming and duality. We evaluate our methods on MNIST, CIFAR-10, and GTSRB and obtain improvements in certified accuracy by up to 4.73%, 3.63%, and 3.54%, respectively, establishing a new state-of-the-art in (pointwise) certified robustness against data poisoning. In many cases, our approach outperforms the state-of-the-art, even when using 32 times less computational power. ",
    "url": "https://arxiv.org/abs/2302.02300",
    "authors": [
      "Keivan Rezaei",
      "Kiarash Banihashem",
      "Atoosa Chegini",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02317",
    "title": "Adversarial Learning Data Augmentation for Graph Contrastive Learning in  Recommendation",
    "abstract": "Recently, Graph Neural Networks (GNNs) achieve remarkable success in Recommendation. To reduce the influence of data sparsity, Graph Contrastive Learning (GCL) is adopted in GNN-based CF methods for enhancing performance. Most GCL methods consist of data augmentation and contrastive loss (e.g., InfoNCE). GCL methods construct the contrastive pairs by hand-crafted graph augmentations and maximize the agreement between different views of the same node compared to that of other nodes, which is known as the InfoMax principle. However, improper data augmentation will hinder the performance of GCL. InfoMin principle, that the good set of views shares minimal information and gives guidelines to design better data augmentation. In this paper, we first propose a new data augmentation (i.e., edge-operating including edge-adding and edge-dropping). Then, guided by InfoMin principle, we propose a novel theoretical guiding contrastive learning framework, named Learnable Data Augmentation for Graph Contrastive Learning (LDA-GCL). Our methods include data augmentation learning and graph contrastive learning, which follow the InfoMin and InfoMax principles, respectively. In implementation, our methods optimize the adversarial loss function to learn data augmentation and effective representations of users and items. Extensive experiments on four public benchmark datasets demonstrate the effectiveness of LDA-GCL. ",
    "url": "https://arxiv.org/abs/2302.02317",
    "authors": [
      "Junjie Huang",
      "Qi Cao",
      "Ruobing Xie",
      "Shaoliang Zhang",
      "Feng Xia",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.02318",
    "title": "Contrast with Reconstruct: Contrastive 3D Representation Learning Guided  by Generative Pretraining",
    "abstract": "Mainstream 3D representation learning approaches are built upon contrastive or generative modeling pretext tasks, where great improvements in performance on various downstream tasks have been achieved. However, by investigating the methods of these two paradigms, we find that (i) contrastive models are data-hungry that suffer from a representation over-fitting issue; (ii) generative models have a data filling issue that shows inferior data scaling capacity compared to contrastive models. This motivates us to learn 3D representations by sharing the merits of both paradigms, which is non-trivial due to the pattern difference between the two paradigms. In this paper, we propose contrast with reconstruct (ReCon) that unifies these two paradigms. ReCon is trained to learn from both generative modeling teachers and cross-modal contrastive teachers through ensemble distillation, where the generative student guides the contrastive student. An encoder-decoder style ReCon-block is proposed that transfers knowledge through cross attention with stop-gradient, which avoids pretraining over-fitting and pattern difference issues. ReCon achieves a new state-of-the-art in 3D representation learning, e.g., 91.26% accuracy on ScanObjectNN. Codes will be released at https://github.com/qizekun/ReCon. ",
    "url": "https://arxiv.org/abs/2302.02318",
    "authors": [
      "Zekun Qi",
      "Runpei Dong",
      "Guofan Fan",
      "Zheng Ge",
      "Xiangyu Zhang",
      "Kaisheng Ma",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02324",
    "title": "Towards Scalable EM-based Anomaly Detection For Embedded Devices Through  Synthetic Fingerprinting",
    "abstract": "Embedded devices are omnipresent in modern networks including the ones operating inside critical environments. However, due to their constrained nature, novel mechanisms are required to provide external, and non-intrusive anomaly detection. Among such approaches, one that has gained traction is based on the analysis of the electromagnetic (EM) signals that get emanated during a device's operation. However, one of the most neglected challenges of this approach is the requirement for manually gathering and fingerprinting the signals that correspond to each execution path of the software/firmware. Indeed, even simple programs are comprised of hundreds if not thousands of branches thus, making the fingerprinting stage an extremely time-consuming process that involves the manual labor of a human specialist. To address this issue, we propose a framework for generating synthetic EM signals directly from the machine code. The synthetic signals can be used to train a Machine Learning based (ML) system for anomaly detection. The main advantage of the proposed approach is that it completely removes the need for an elaborate and error-prone fingerprinting stage, thus, dramatically increasing the scalability of the corresponding protection mechanisms. The experimental evaluations indicate that our method provides high detection accuracy (above 90% AUC score) when employed for the detection of injection attacks. Moreover, the proposed methodology inflicts only a small penalty (-1.3%) in accuracy for the detection of the injection of as little as four malicious instructions when compared to the same methods if real signals were to be used. ",
    "url": "https://arxiv.org/abs/2302.02324",
    "authors": [
      "Kurt A. Vedros",
      "Georgios Michail Makrakis",
      "Constantinos Kolias",
      "Robert C. Ivans",
      "Craig Rieger"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.02345",
    "title": "VuLASTE: Long Sequence Model with Abstract Syntax Tree Embedding for  vulnerability Detection",
    "abstract": "In this paper, we build a model named VuLASTE, which regards vulnerability detection as a special text classification task. To solve the vocabulary explosion problem, VuLASTE uses a byte level BPE algorithm from natural language processing. In VuLASTE, a new AST path embedding is added to represent source code nesting information. We also use a combination of global and dilated window attention from Longformer to extract long sequence semantic from source code. To solve the data imbalance problem, which is a common problem in vulnerability detection datasets, focal loss is used as loss function to make model focus on poorly classified cases during training. To test our model performance on real-world source code, we build a cross-language and multi-repository vulnerability dataset from Github Security Advisory Database. On this dataset, VuLASTE achieved top 50, top 100, top 200, top 500 hits of 29, 51, 86, 228, which are higher than state-of-art researches. ",
    "url": "https://arxiv.org/abs/2302.02345",
    "authors": [
      "Botong Zhu",
      "Huobin Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02352",
    "title": "TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in  CTR Prediction at Kuaishou",
    "abstract": "Life-long user behavior modeling, i.e., extracting a user's hidden interests from rich historical behaviors in months or even years, plays a central role in modern CTR prediction systems. Conventional algorithms mostly follow two cascading stages: a simple General Search Unit (GSU) for fast and coarse search over tens of thousands of long-term behaviors and an Exact Search Unit (ESU) for effective Target Attention (TA) over the small number of finalists from GSU. Although efficient, existing algorithms mostly suffer from a crucial limitation: the \\textit{inconsistent} target-behavior relevance metrics between GSU and ESU. As a result, their GSU usually misses highly relevant behaviors but retrieves ones considered irrelevant by ESU. In such case, the TA in ESU, no matter how attention is allocated, mostly deviates from the real user interests and thus degrades the overall CTR prediction accuracy. To address such inconsistency, we propose \\textbf{TWo-stage Interest Network (TWIN)}, where our Consistency-Preserved GSU (CP-GSU) adopts the identical target-behavior relevance metric as the TA in ESU, making the two stages twins. Specifically, to break TA's computational bottleneck and extend it from ESU to GSU, or namely from behavior length $10^2$ to length $10^4-10^5$, we build a novel attention mechanism by behavior feature splitting. For the video inherent features of a behavior, we calculate their linear projection by efficient pre-computing \\& caching strategies. And for the user-item cross features, we compress each into a one-dimentional bias term in the attention score calculation to save the computational cost. The consistency between two stages, together with the effective TA-based relevance metric in CP-GSU, contributes to significant performance gain in CTR prediction. ",
    "url": "https://arxiv.org/abs/2302.02352",
    "authors": [
      "Jianxin Chang",
      "Chenbin Zhang",
      "Zhiyi Fu",
      "Xiaoxue Zang",
      "Lin Guan",
      "Jing Lu",
      "Yiqun Hui",
      "Dewei Leng",
      "Yanan Niu",
      "Yang Song",
      "Kun Gai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.02369",
    "title": "Deep Graph-Level Clustering Using Pseudo-Label-Guided Mutual Information  Maximization Network",
    "abstract": "In this work, we study the problem of partitioning a set of graphs into different groups such that the graphs in the same group are similar while the graphs in different groups are dissimilar. This problem was rarely studied previously, although there have been a lot of work on node clustering and graph classification. The problem is challenging because it is difficult to measure the similarity or distance between graphs. One feasible approach is using graph kernels to compute a similarity matrix for the graphs and then performing spectral clustering, but the effectiveness of existing graph kernels in measuring the similarity between graphs is very limited. To solve the problem, we propose a novel method called Deep Graph-Level Clustering (DGLC). DGLC utilizes a graph isomorphism network to learn graph-level representations by maximizing the mutual information between the representations of entire graphs and substructures, under the regularization of a clustering module that ensures discriminative representations via pseudo labels. DGLC achieves graph-level representation learning and graph-level clustering in an end-to-end manner. The experimental results on six benchmark datasets of graphs show that our DGLC has state-of-the-art performance in comparison to many baselines. ",
    "url": "https://arxiv.org/abs/2302.02369",
    "authors": [
      "Jinyu Cai",
      "Yi Han",
      "Wenzhong Guo",
      "Jicong Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02403",
    "title": "Neural networks meet hyperelasticity: A guide to enforcing physics",
    "abstract": "In the present work, a hyperelastic constitutive model based on neural networks is proposed which fulfills all common constitutive conditions by construction, and in particular, is applicable to compressible material behavior. Using different sets of invariants as inputs, a hyperelastic potential is formulated as a convex neural network, thus fulfilling symmetry of the stress tensor, objectivity, material symmetry, polyconvexity, and thermodynamic consistency. In addition, a physically sensible stress behavior of the model is ensured by using analytical growth terms, as well as normalization terms which ensure the undeformed state to be stress free and with zero energy. The normalization terms are formulated for both isotropic and transversely isotropic material behavior and do not violate polyconvexity. By fulfilling all of these conditions in an exact way, the proposed physics-augmented model combines a sound mechanical basis with the extraordinary flexibility that neural networks offer. Thus, it harmonizes the theory of hyperelasticity developed in the last decades with the up-to-date techniques of machine learning. Furthermore, the non-negativity of the hyperelastic potential is numerically verified by sampling the space of admissible deformations states, which, to the best of the authors' knowledge, is the only possibility for the considered nonlinear compressible models. The applicability of the model is demonstrated by calibrating it on data generated with analytical potentials, which is followed by an application of the model to finite element simulations. In addition, an adaption of the model to noisy data is shown and its extrapolation capability is compared to models with reduced physical background. Within all numerical examples, excellent and physically meaningful predictions have been achieved with the proposed physics-augmented neural network. ",
    "url": "https://arxiv.org/abs/2302.02403",
    "authors": [
      "Lennart Linden",
      "Dominik K. Klein",
      "Karl A. Kalina",
      "J\u00f6rg Brummund",
      "Oliver Weeger",
      "Markus K\u00e4stner"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2302.02407",
    "title": "HyPHEN: A Hybrid Packing Method and Optimizations for Homomorphic  Encryption-Based Neural Networks",
    "abstract": "Convolutional neural network (CNN) inference using fully homomorphic encryption (FHE) is a promising private inference (PI) solution due to the capability of FHE that enables offloading the whole computation process to the server while protecting the privacy of sensitive user data. However, prior FHEbased CNN (HCNN) implementations are far from being practical due to the high computational and memory overheads of FHE. To overcome this limitation, we present HyPHEN, a deep HCNN construction that features an efficient FHE convolution algorithm, data packing methods (hybrid packing and image slicing), and FHE-specific optimizations. Such enhancements enable HyPHEN to substantially reduce the memory footprint and the number of expensive homomorphic operations, such as ciphertext rotation and bootstrapping. As a result, HyPHEN brings the latency of HCNN CIFAR-10 inference down to a practical level at 1.40s (ResNet20) and demonstrates HCNN ImageNet inference for the first time at 16.87s (ResNet18). ",
    "url": "https://arxiv.org/abs/2302.02407",
    "authors": [
      "Donghwan Kim",
      "Jaiyoung Park",
      "Jongmin Kim",
      "Sangpyo Kim",
      "Jung Ho Ahn"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02419",
    "title": "deep learning of segment-level feature representation for speech emotion  recognition in conversations",
    "abstract": "Accurately detecting emotions in conversation is a necessary yet challenging task due to the complexity of emotions and dynamics in dialogues. The emotional state of a speaker can be influenced by many different factors, such as interlocutor stimulus, dialogue scene, and topic. In this work, we propose a conversational speech emotion recognition method to deal with capturing attentive contextual dependency and speaker-sensitive interactions. First, we use a pretrained VGGish model to extract segment-based audio representation in individual utterances. Second, an attentive bi-directional gated recurrent unit (GRU) models contextual-sensitive information and explores intra- and inter-speaker dependencies jointly in a dynamic manner. The experiments conducted on the standard conversational dataset MELD demonstrate the effectiveness of the proposed method when compared against state-of the-art methods. ",
    "url": "https://arxiv.org/abs/2302.02419",
    "authors": [
      "Jiachen Luo",
      "Huy Phan",
      "Joshua Reiss"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.02426",
    "title": "Online Nonstochastic Control with Adversarial and Static Constraints",
    "abstract": "This paper studies online nonstochastic control problems with adversarial and static constraints. We propose online nonstochastic control algorithms that achieve both sublinear regret and sublinear adversarial constraint violation while keeping static constraint violation minimal against the optimal constrained linear control policy in hindsight. To establish the results, we introduce an online convex optimization with memory framework under adversarial and static constraints, which serves as a subroutine for the constrained online nonstochastic control algorithms. This subroutine also achieves the state-of-the-art regret and constraint violation bounds for constrained online convex optimization problems, which is of independent interest. Our experiments demonstrate the proposed control algorithms are adaptive to adversarial constraints and achieve smaller cumulative costs and violations. Moreover, our algorithms are less conservative and achieve significantly smaller cumulative costs than the state-of-the-art algorithm. ",
    "url": "https://arxiv.org/abs/2302.02426",
    "authors": [
      "Xin Liu",
      "Zixian Yang",
      "Lei Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.02442",
    "title": "Nonlinear elasticity complex and a finite element diagram chase",
    "abstract": "In this paper, we present a nonlinear version of the linear elasticity (Calabi, Kr\\\"oner, Riemannian deformation) complex which encodes isometric embedding, metric, curvature and the Bianchi identity. We reformulate the rigidity theorem and a fundamental theorem of Riemannian geometry as the exactness of this complex. Then we generalize an algebraic approach for constructing finite elements for the Bernstein-Gelfand-Gelfand (BGG) complexes. In particular, we discuss the reduction of degrees of freedom with injective connecting maps in the BGG diagrams. We derive a strain complex in two space dimensions with a diagram chase. ",
    "url": "https://arxiv.org/abs/2302.02442",
    "authors": [
      "Kaibo Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.02452",
    "title": "Performance Analysis of Machine Learning Centered Workload Prediction  Models for Cloud",
    "abstract": "The precise estimation of resource usage is a complex and challenging issue due to the high variability and dimensionality of heterogeneous service types and dynamic workloads. Over the last few years, the prediction of resource usage and traffic has received ample attention from the research community. Many machine learning-based workload forecasting models have been developed by exploiting their computational power and learning capabilities. This paper presents the first systematic survey cum performance analysis-based comparative study of diversified machine learning-driven cloud workload prediction models. The discussion initiates with the significance of predictive resource management followed by a schematic description, operational design, motivation, and challenges concerning these workload prediction models. Classification and taxonomy of different prediction approaches into five distinct categories are presented focusing on the theoretical concepts and mathematical functioning of the existing state-of-the-art workload prediction methods. The most prominent prediction approaches belonging to a distinct class of machine learning models are thoroughly surveyed and compared. All five classified machine learning-based workload prediction models are implemented on a common platform for systematic investigation and comparison using three distinct benchmark cloud workload traces via experimental analysis. The essential key performance indicators of state-of-the-art approaches are evaluated for comparison and the paper is concluded by discussing the trade-offs and notable remarks. ",
    "url": "https://arxiv.org/abs/2302.02452",
    "authors": [
      "Deepika Saxena",
      "Jitendra Kumar",
      "Ashutosh Kumar Singh",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.02483",
    "title": "Multi-Task Self-Supervised Learning for Image Segmentation Task",
    "abstract": "Thanks to breakthroughs in AI and Deep learning methodology, Computer vision techniques are rapidly improving. Most computer vision applications require sophisticated image segmentation to comprehend what is image and to make an analysis of each section easier. Training deep learning networks for semantic segmentation required a large amount of annotated data, which presents a major challenge in practice as it is expensive and labor-intensive to produce such data. The paper presents 1. Self-supervised techniques to boost semantic segmentation performance using multi-task learning with Depth prediction and Surface Normalization . 2. Performance evaluation of the different types of weighing techniques (UW, Nash-MTL) used for Multi-task learning. NY2D dataset was used for performance evaluation. According to our evaluation, the Nash-MTL method outperforms single task learning(Semantic Segmentation). ",
    "url": "https://arxiv.org/abs/2302.02483",
    "authors": [
      "Lichun Gao",
      "Chinmaya Khamesra",
      "Uday Kumbhar",
      "Ashay Aglawe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02502",
    "title": "On the Role of Contrastive Representation Learning in Adversarial  Robustness: An Empirical Study",
    "abstract": "Self-supervised contrastive learning has solved one of the significant obstacles in deep learning by alleviating the annotation cost. This advantage comes with the price of false negative-pair selection without any label information. Supervised contrastive learning has emerged as an extension of contrastive learning to eliminate this issue. However, aside from accuracy, there is a lack of understanding about the impacts of adversarial training on the representations learned by these learning schemes. In this work, we utilize supervised learning as a baseline to comprehensively study the robustness of contrastive and supervised contrastive learning under different adversarial training scenarios. Then, we begin by looking at how adversarial training affects the learned representations in hidden layers, discovering more redundant representations between layers of the model. Our results on CIFAR-10 and CIFAR-100 image classification benchmarks demonstrate that this redundancy is highly reduced by adversarial fine-tuning applied to the contrastive learning scheme, leading to more robust representations. However, adversarial fine-tuning is not very effective for supervised contrastive learning and supervised learning schemes. Our code is released at https://github.com/softsys4ai/CL-Robustness. ",
    "url": "https://arxiv.org/abs/2302.02502",
    "authors": [
      "Fatemeh Ghofrani",
      "Mehdi Yaghouti",
      "Pooyan Jamshidi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02503",
    "title": "Leaving Reality to Imagination: Robust Classification via Generated  Datasets",
    "abstract": "Recent research on robustness has revealed significant performance gaps between neural image classifiers trained on datasets that are similar to the test set, and those that are from a naturally shifted distribution, such as sketches, paintings, and animations of the object categories observed during training. Prior work focuses on reducing this gap by designing engineered augmentations of training data or through unsupervised pretraining of a single large model on massive in-the-wild training datasets scraped from the Internet. However, the notion of a dataset is also undergoing a paradigm shift in recent years. With drastic improvements in the quality, ease-of-use, and access to modern generative models, generated data is pervading the web. In this light, we study the question: How do these generated datasets influence the natural robustness of image classifiers? We find that Imagenet classifiers trained on real data augmented with generated data achieve higher accuracy and effective robustness than standard training and popular augmentation strategies in the presence of natural distribution shifts. We analyze various factors influencing these results, including the choice of conditioning strategies and the amount of generated data. Lastly, we introduce and analyze an evolving generated dataset, ImageNet-G-v1, to better benchmark the design, utility, and critique of standalone generated datasets for robust and trustworthy machine learning. The code and datasets are available at https://github.com/Hritikbansal/generative-robustness. ",
    "url": "https://arxiv.org/abs/2302.02503",
    "authors": [
      "Hritik Bansal",
      "Aditya Grover"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.02506",
    "title": "Generating Dispatching Rules for the Interrupting Swap-Allowed Blocking  Job Shop Problem Using Graph Neural Network and Reinforcement Learning",
    "abstract": "The interrupting swap-allowed blocking job shop problem (ISBJSSP) is a complex scheduling problem that is able to model many manufacturing planning and logistics applications realistically by addressing both the lack of storage capacity and unforeseen production interruptions. Subjected to random disruptions due to machine malfunction or maintenance, industry production settings often choose to adopt dispatching rules to enable adaptive, real-time re-scheduling, rather than traditional methods that require costly re-computation on the new configuration every time the problem condition changes dynamically. To generate dispatching rules for the ISBJSSP problem, a method that uses graph neural networks and reinforcement learning is proposed. ISBJSSP is formulated as a Markov decision process. Using proximal policy optimization, an optimal scheduling policy is learnt from randomly generated instances. Employing a set of reported benchmark instances, we conduct a detailed experimental study on ISBJSSP instances with a range of machine shutdown probabilities to show that the scheduling policies generated can outperform or are at least as competitive as existing dispatching rules with predetermined priority. This study shows that the ISBJSSP, which requires real-time adaptive solutions, can be scheduled efficiently with the proposed machine learning method when production interruptions occur with random machine shutdowns. ",
    "url": "https://arxiv.org/abs/2302.02506",
    "authors": [
      "Vivian W.H. Wong",
      "Sang Hun Kim",
      "Junyoung Park",
      "Jinkyoo Park",
      "Kincho H. Law"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02508",
    "title": "Jointly Optimal Routing and Caching with Bounded Link Capacities",
    "abstract": "We study a cache network in which intermediate nodes equipped with caches can serve requests. We model the problem of jointly optimizing caching and routing decisions with link capacity constraints over an arbitrary network topology. This problem can be formulated as a continuous diminishing-returns (DR) submodular maximization problem under multiple continuous DR-supermodular constraints, and is NP-hard. We propose a poly-time alternating primal-dual heuristic algorithm, in which primal steps produce solutions within $1-\\frac{1}{e}$ approximation factor from the optimal. Through extensive experiments, we demonstrate that our proposed algorithm significantly outperforms competitors. ",
    "url": "https://arxiv.org/abs/2302.02508",
    "authors": [
      "Yuanyuan Li",
      "Yuchao Zhang",
      "Stratis Ioannidis",
      "Jon Crowcroft"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.02513",
    "title": "Connectivity Enhanced Safe Neural Network Planner for Lane Changing in  Mixed Traffic",
    "abstract": "Connectivity technology has shown great potentials in improving the safety and efficiency of transportation systems by providing information beyond the perception and prediction capabilities of individual vehicles. However, it is expected that human-driven and autonomous vehicles, and connected and non-connected vehicles need to share the transportation network during the transition period to fully connected and automated transportation systems. Such mixed traffic scenarios significantly increase the complexity in analyzing system behavior and quantifying uncertainty for highly interactive scenarios, e.g., lane changing. It is even harder to ensure system safety when neural network based planners are leveraged to further improve efficiency. In this work, we propose a connectivity-enhanced neural network based lane changing planner. By cooperating with surrounding connected vehicles in dynamic environment, our proposed planner will adapt its planned trajectory according to the analysis of a safe evasion trajectory. We demonstrate the strength of our planner design in improving efficiency and ensuring safety in various mixed traffic scenarios with extensive simulations. We also analyze the system robustness when the communication or coordination is not perfect. ",
    "url": "https://arxiv.org/abs/2302.02513",
    "authors": [
      "Xiangguo Liu",
      "Ruochen Jiao",
      "Bowen Zheng",
      "Dave Liang",
      "Qi Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.02520",
    "title": "PGCN: Pyramidal Graph Convolutional Network for EEG Emotion Recognition",
    "abstract": "Emotion recognition is essential in the diagnosis and rehabilitation of various mental diseases. In the last decade, electroencephalogram (EEG)-based emotion recognition has been intensively investigated due to its prominative accuracy and reliability, and graph convolutional network (GCN) has become a mainstream model to decode emotions from EEG signals. However, the electrode relationship, especially long-range electrode dependencies across the scalp, may be underutilized by GCNs, although such relationships have been proven to be important in emotion recognition. The small receptive field makes shallow GCNs only aggregate local nodes. On the other hand, stacking too many layers leads to over-smoothing. To solve these problems, we propose the pyramidal graph convolutional network (PGCN), which aggregates features at three levels: local, mesoscopic, and global. First, we construct a vanilla GCN based on the 3D topological relationships of electrodes, which is used to integrate two-order local features; Second, we construct several mesoscopic brain regions based on priori knowledge and employ mesoscopic attention to sequentially calculate the virtual mesoscopic centers to focus on the functional connections of mesoscopic brain regions; Finally, we fuse the node features and their 3D positions to construct a numerical relationship adjacency matrix to integrate structural and functional connections from the global perspective. Experimental results on three public datasets indicate that PGCN enhances the relationship modelling across the scalp and achieves state-of-the-art performance in both subject-dependent and subject-independent scenarios. Meanwhile, PGCN makes an effective trade-off between enhancing network depth and receptive fields while suppressing the ensuing over-smoothing. Our codes are publicly accessible at https://github.com/Jinminbox/PGCN. ",
    "url": "https://arxiv.org/abs/2302.02520",
    "authors": [
      "Ming Jin",
      "Enwei Zhu",
      "Changde Du",
      "Huiguang He",
      "Jinpeng Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2302.02525",
    "title": "Privacy concerns from variances in spatial navigability in VR",
    "abstract": "Current Virtual Reality (VR) input devices make it possible to navigate a virtual environment and record immersive, personalized data regarding the user's movement and specific behavioral habits, which brings the question of the user's privacy concern to the forefront. In this article, the authors propose to investigate Machine Learning driven learning algorithms that try to learn with human users co-operatively and can be used to countermand existing privacy concerns in VR but could also be extended to Augmented Reality (AR) platforms. ",
    "url": "https://arxiv.org/abs/2302.02525",
    "authors": [
      "Aryabrata Basu",
      "Mohammad Jahed Murad Sunny",
      "Jayasri Sai Nikitha Guthula"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2302.02526",
    "title": "On Private and Robust Bandits",
    "abstract": "We study private and robust multi-armed bandits (MABs), where the agent receives Huber's contaminated heavy-tailed rewards and meanwhile needs to ensure differential privacy. We first present its minimax lower bound, characterizing the information-theoretic limit of regret with respect to privacy budget, contamination level and heavy-tailedness. Then, we propose a meta-algorithm that builds on a private and robust mean estimation sub-routine \\texttt{PRM} that essentially relies on reward truncation and the Laplace mechanism only. For two different heavy-tailed settings, we give specific schemes of \\texttt{PRM}, which enable us to achieve nearly-optimal regret. As by-products of our main results, we also give the first minimax lower bound for private heavy-tailed MABs (i.e., without contamination). Moreover, our two proposed truncation-based \\texttt{PRM} achieve the optimal trade-off between estimation accuracy, privacy and robustness. Finally, we support our theoretical results with experimental studies. ",
    "url": "https://arxiv.org/abs/2302.02526",
    "authors": [
      "Yulian Wu",
      "Xingyu Zhou",
      "Youming Tao",
      "Di Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.02535",
    "title": "PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement  and Pose Restoration",
    "abstract": "Recent interest in point cloud analysis has led rapid progress in designing deep learning methods for 3D models. However, state-of-the-art models are not robust to rotations, which remains an unknown prior to real applications and harms the model performance. In this work, we introduce a novel Patch-wise Rotation-invariant network (PaRot), which achieves rotation invariance via feature disentanglement and produces consistent predictions for samples with arbitrary rotations. Specifically, we design a siamese training module which disentangles rotation invariance and equivariance from patches defined over different scales, e.g., the local geometry and global shape, via a pair of rotations. However, our disentangled invariant feature loses the intrinsic pose information of each patch. To solve this problem, we propose a rotation-invariant geometric relation to restore the relative pose with equivariant information for patches defined over different scales. Utilising the pose information, we propose a hierarchical module which implements intra-scale and inter-scale feature aggregation for 3D shape learning. Moreover, we introduce a pose-aware feature propagation process with the rotation-invariant relative pose information embedded. Experiments show that our disentanglement module extracts high-quality rotation-robust features and the proposed lightweight model achieves competitive results in rotated 3D object classification and part segmentation tasks. Our project page is released at: https://patchrot.github.io/. ",
    "url": "https://arxiv.org/abs/2302.02535",
    "authors": [
      "Dingxin Zhang",
      "Jianhui Yu",
      "Chaoyi Zhang",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02547",
    "title": "A Quantum Neural Network Regression for Modeling Lithium-ion Battery  Capacity Degradation",
    "abstract": "Given the high power density low discharge rate and decreasing cost rechargeable lithium-ion batteries LiBs have found a wide range of applications such as power grid level storage systems electric vehicles and mobile devices. Developing a framework to accurately model the nonlinear degradation process of LiBs which is indeed a supervised learning problem becomes an important research topic. This paper presents a classical-quantum hybrid machine learning approach to capture the LiB degradation model that assesses battery cell life loss from operating profiles. Our work is motivated by recent advances in quantum computers as well as the similarity between neural networks and quantum circuits. Similar to adjusting weight parameters in conventional neural networks the parameters of the quantum circuit namely the qubits degree of freedom can be tuned to learn a nonlinear function in a supervised learning fashion. As a proof of concept paper our obtained numerical results with the battery dataset provided by NASA demonstrate the ability of the quantum neural networks in modeling the nonlinear relationship between the degraded capacity and the operating cycles. We also discuss the potential advantage of the quantum approach compared to conventional neural networks in classical computers in dealing with massive data especially in the context of future penetration of EVs and energy storage. ",
    "url": "https://arxiv.org/abs/2302.02547",
    "authors": [
      "Anh Phuong Ngo",
      "Nhat Le",
      "Hieu T. Nguyen",
      "Abdullah Eroglu",
      "Duong T. Nguyen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02553",
    "title": "A Correction-Based Dynamic Enhancement Framework towards Underwater  Detection",
    "abstract": "To assist underwater object detection for better performance, image enhancement technology is often used as a pre-processing step. However, most of the existing enhancement methods tend to pursue the visual quality of an image, instead of providing effective help for detection tasks. In fact, image enhancement algorithms should be optimized with the goal of utility improvement. In this paper, to adapt to the underwater detection tasks, we proposed a lightweight dynamic enhancement algorithm using a contribution dictionary to guide low-level corrections. Dynamic solutions are designed to capture differences in detection preferences. In addition, it can also balance the inconsistency between the contribution of correction operations and their time complexity. Experimental results in real underwater object detection tasks show the superiority of our proposed method in both generalization and real-time performance. ",
    "url": "https://arxiv.org/abs/2302.02553",
    "authors": [
      "Yanling Qiu",
      "Qianxue Feng",
      "Boqin Cai",
      "Hongan Wei",
      "Weiling Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02560",
    "title": "Causal Shift-Response Functions with Neural Networks: The Health  Benefits of Lowering Air Quality Standards in the US",
    "abstract": "Policymakers are required to evaluate the health benefits of reducing the National Ambient Air Quality Standards (NAAQS; i.e., the safety standards) for fine particulate matter PM 2.5 before implementing new policies. We formulate this objective as a shift-response function (SRF) and develop methods to analyze the problem using methods for causal inference, specifically under the stochastic interventions framework. SRFs model the average change in an outcome of interest resulting from a hypothetical shift in the observed exposure distribution. We propose a new broadly applicable doubly-robust method to learn SRFs using targeted regularization with neural networks. We evaluate our proposed method under various benchmarks specific for marginal estimates as a function of continuous exposure. Finally, we implement our estimator in the motivating application that considers the potential reduction in deaths from lowering the NAAQS from the current level of 12 $\\mu g/m^3$ to levels that are recently proposed by the Environmental Protection Agency in the US (10, 9, and 8 $\\mu g/m^3$). ",
    "url": "https://arxiv.org/abs/2302.02560",
    "authors": [
      "Mauricio Tec",
      "Oladimeji Mudele",
      "Kevin Josey",
      "Francesca Dominici"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.02565",
    "title": "Bi-level Multi-objective Evolutionary Learning: A Case Study on  Multi-task Graph Neural Topology Search",
    "abstract": "The construction of machine learning models involves many bi-level multi-objective optimization problems (BL-MOPs), where upper level (UL) candidate solutions must be evaluated via training weights of a model in the lower level (LL). Due to the Pareto optimality of sub-problems and the complex dependency across UL solutions and LL weights, an UL solution is feasible if and only if the LL weight is Pareto optimal. It is computationally expensive to determine which LL Pareto weight in the LL Pareto weight set is the most appropriate for each UL solution. This paper proposes a bi-level multi-objective learning framework (BLMOL), coupling the above decision-making process with the optimization process of the UL-MOP by introducing LL preference $r$. Specifically, the UL variable and $r$ are simultaneously searched to minimize multiple UL objectives by evolutionary multi-objective algorithms. The LL weight with respect to $r$ is trained to minimize multiple LL objectives via gradient-based preference multi-objective algorithms. In addition, the preference surrogate model is constructed to replace the expensive evaluation process of the UL-MOP. We consider a novel case study on multi-task graph neural topology search. It aims to find a set of Pareto topologies and their Pareto weights, representing different trade-offs across tasks at UL and LL, respectively. The found graph neural network is employed to solve multiple tasks simultaneously, including graph classification, node classification, and link prediction. Experimental results demonstrate that BLMOL can outperform some state-of-the-art algorithms and generate well-representative UL solutions and LL weights. ",
    "url": "https://arxiv.org/abs/2302.02565",
    "authors": [
      "Chao Wang",
      "Licheng Jiao",
      "Jiaxuan Zhao",
      "Lingling Li",
      "Xu Liu",
      "Fang Liu",
      "Shuyuan Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.02568",
    "title": "Less is More: Understanding Word-level Textual Adversarial Attack via  n-gram Frequency Descend",
    "abstract": "Word-level textual adversarial attacks have achieved striking performance in fooling natural language processing models. However, the fundamental questions of why these attacks are effective, and the intrinsic properties of the adversarial examples (AEs), are still not well understood. This work attempts to interpret textual attacks through the lens of $n$-gram frequency. Specifically, it is revealed that existing word-level attacks exhibit a strong tendency toward generation of examples with $n$-gram frequency descend ($n$-FD). Intuitively, this finding suggests a natural way to improve model robustness by training the model on the $n$-FD examples. To verify this idea, we devise a model-agnostic and gradient-free AE generation approach that relies solely on the $n$-gram frequency information, and further integrate it into the recently proposed convex hull framework for adversarial training. Surprisingly, the resultant method performs quite similarly to the original gradient-based method in terms of model robustness. These findings provide a human-understandable perspective for interpreting word-level textual adversarial attacks, and a new direction to improve model robustness. ",
    "url": "https://arxiv.org/abs/2302.02568",
    "authors": [
      "Ning Lu",
      "Zhirui Zhang",
      "Qi Wang",
      "Haifeng Liu",
      "Ke Tang",
      "Shengcai Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02595",
    "title": "Clarifying Trust of Materials Property Predictions using Neural Networks  with Distribution-Specific Uncertainty Quantification",
    "abstract": "It is critical that machine learning (ML) model predictions be trustworthy for high-throughput catalyst discovery approaches. Uncertainty quantification (UQ) methods allow estimation of the trustworthiness of an ML model, but these methods have not been well explored in the field of heterogeneous catalysis. Herein, we investigate different UQ methods applied to a crystal graph convolutional neural network (CGCNN) to predict adsorption energies of molecules on alloys from the Open Catalyst 2020 (OC20) dataset, the largest existing heterogeneous catalyst dataset. We apply three UQ methods to the adsorption energy predictions, namely k-fold ensembling, Monte Carlo dropout, and evidential regression. The effectiveness of each UQ method is assessed based on accuracy, sharpness, dispersion, calibration, and tightness. Evidential regression is demonstrated to be a powerful approach for rapidly obtaining tunable, competitively trustworthy UQ estimates for heterogeneous catalysis applications when using neural networks. Recalibration of model uncertainties is shown to be essential in practical screening applications of catalysts using uncertainties. ",
    "url": "https://arxiv.org/abs/2302.02595",
    "authors": [
      "Cameron Gruich",
      "Varun Madhavan",
      "Yixin Wang",
      "Bryan Goldsmith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02596",
    "title": "Ten Lessons We Have Learned in the New \"Sparseland\": A Short Handbook  for Sparse Neural Network Researchers",
    "abstract": "This article does not propose any novel algorithm or new hardware for sparsity. Instead, it aims to serve the \"common good\" for the increasingly prosperous Sparse Neural Network (SNN) research community. We attempt to summarize some most common confusions in SNNs, that one may come across in various scenarios such as paper review/rebuttal and talks - many drawn from the authors' own bittersweet experiences! We feel that doing so is meaningful and timely, since the focus of SNN research is notably shifting from traditional pruning to more diverse and profound forms of sparsity before, during, and after training. The intricate relationships between their scopes, assumptions, and approaches lead to misunderstandings, for non-experts or even experts in SNNs. In response, we summarize ten Q\\&As of SNNs from many key aspects, including dense vs. sparse, unstructured sparse vs. structured sparse, pruning vs. sparse training, dense-to-sparse training vs. sparse-to-sparse training, static sparsity vs. dynamic sparsity, before-training/during-training vs. post-training sparsity, and many more. We strive to provide proper and generically applicable answers to clarify those confusions to the best extent possible. We hope our summary provides useful general knowledge for people who want to enter and engage with this exciting community; and also provides some \"mind of ease\" convenience for SNN researchers to explain their work in the right contexts. At the very least (and perhaps as this article's most insignificant target functionality), if you are writing/planning to write a paper or rebuttal in the field of SNNs, we hope some of our answers could help you! ",
    "url": "https://arxiv.org/abs/2302.02596",
    "authors": [
      "Shiwei Liu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02598",
    "title": "Cluster-aware Contrastive Learning for Unsupervised Out-of-distribution  Detection",
    "abstract": "Unsupervised out-of-distribution (OOD) Detection aims to separate the samples falling outside the distribution of training data without label information. Among numerous branches, contrastive learning has shown its excellent capability of learning discriminative representation in OOD detection. However, for its limited vision, merely focusing on instance-level relationship between augmented samples, it lacks attention to the relationship between samples with same semantics. Based on the classic contrastive learning, we propose Cluster-aware Contrastive Learning (CCL) framework for unsupervised OOD detection, which considers both instance-level and semantic-level information. Specifically, we study a cooperation strategy of clustering and contrastive learning to effectively extract the latent semantics and design a cluster-aware contrastive loss function to enhance OOD discriminative ability. The loss function can simultaneously pay attention to the global and local relationships by treating both the cluster centers and the samples belonging to the same cluster as positive samples. We conducted sufficient experiments to verify the effectiveness of our framework and the model achieves significant improvement on various image benchmarks. ",
    "url": "https://arxiv.org/abs/2302.02598",
    "authors": [
      "Menglong Chen",
      "Xingtai Gui",
      "Shicai Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02601",
    "title": "Learning Representations of Bi-Level Knowledge Graphs for Reasoning  beyond Link Prediction",
    "abstract": "Knowledge graphs represent known facts using triplets. While existing knowledge graph embedding methods only consider the connections between entities, we propose considering the relationships between triplets. For example, let us consider two triplets $T_1$ and $T_2$ where $T_1$ is (Academy_Awards, Nominates, Avatar) and $T_2$ is (Avatar, Wins, Academy_Awards). Given these two base-level triplets, we see that $T_1$ is a prerequisite for $T_2$. In this paper, we define a higher-level triplet to represent a relationship between triplets, e.g., $\\langle T_1$, PrerequisiteFor, $T_2\\rangle$ where PrerequisiteFor is a higher-level relation. We define a bi-level knowledge graph that consists of the base-level and the higher-level triplets. We also propose a data augmentation strategy based on the random walks on the bi-level knowledge graph to augment plausible triplets. Our model called BiVE learns embeddings by taking into account the structures of the base-level and the higher-level triplets, with additional consideration of the augmented triplets. We propose two new tasks: triplet prediction and conditional link prediction. Given a triplet $T_1$ and a higher-level relation, the triplet prediction predicts a triplet that is likely to be connected to $T_1$ by the higher-level relation, e.g., $\\langle T_1$, PrerequisiteFor, ?$\\rangle$. The conditional link prediction predicts a missing entity in a triplet conditioned on another triplet, e.g., $\\langle T_1$, PrerequisiteFor, (Avatar, Wins, ?)$\\rangle$. Experimental results show that BiVE significantly outperforms all other methods in the two new tasks and the typical base-level link prediction in real-world bi-level knowledge graphs. ",
    "url": "https://arxiv.org/abs/2302.02601",
    "authors": [
      "Chanyoung Chung",
      "Joyce Jiyoung Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02614",
    "title": "A Pre-training Framework for Knowledge Graph Completion",
    "abstract": "Knowledge graph completion (KGC) is one of the effective methods to identify new facts in knowledge graph. Except for a few methods based on graph network, most of KGC methods trend to be trained based on independent triples, while are difficult to take a full account of the information of global network connection contained in knowledge network. To address these issues, in this study, we propose a simple and effective Network-based Pre-training framework for knowledge graph completion (termed NetPeace), which takes into account the information of global network connection and local triple relationships in knowledge graph. Experiments show that in NetPeace framework, multiple KGC models yields consistent and significant improvements on benchmarks (e.g., 36.45% Hits@1 and 27.40% MRR improvements for TuckER on FB15k-237), especially dense knowledge graph. On the challenging low-resource task, NetPeace that benefits from the global features of KG achieves higher performance (104.03% MRR and 143.89% Hit@1 improvements at most) than original models. ",
    "url": "https://arxiv.org/abs/2302.02614",
    "authors": [
      "Kuan Xu",
      "Kuo Yang",
      "Hanyang Dong",
      "Xinyan Wang",
      "Xuezhong Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02622",
    "title": "Uncertainty Calibration and its Application to Object Detection",
    "abstract": "Image-based environment perception is an important component especially for driver assistance systems or autonomous driving. In this scope, modern neuronal networks are used to identify multiple objects as well as the according position and size information within a single frame. The performance of such an object detection model is important for the overall performance of the whole system. However, a detection model might also predict these objects under a certain degree of uncertainty. [...] In this work, we examine the semantic uncertainty (which object type?) as well as the spatial uncertainty (where is the object and how large is it?). We evaluate if the predicted uncertainties of an object detection model match with the observed error that is achieved on real-world data. In the first part of this work, we introduce the definition for confidence calibration of the semantic uncertainty in the context of object detection, instance segmentation, and semantic segmentation. We integrate additional position information in our examinations to evaluate the effect of the object's position on the semantic calibration properties. Besides measuring calibration, it is also possible to perform a post-hoc recalibration of semantic uncertainty that might have turned out to be miscalibrated. [...] The second part of this work deals with the spatial uncertainty obtained by a probabilistic detection model. [...] We review and extend common calibration methods so that it is possible to obtain parametric uncertainty distributions for the position information in a more flexible way. In the last part, we demonstrate a possible use-case for our derived calibration methods in the context of object tracking. [...] We integrate our previously proposed calibration techniques and demonstrate the usefulness of semantic and spatial uncertainty calibration in a subsequent process. [...] ",
    "url": "https://arxiv.org/abs/2302.02622",
    "authors": [
      "Fabian K\u00fcppers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.02628",
    "title": "Trust, but Verify: Using Self-Supervised Probing to Improve  Trustworthiness",
    "abstract": "Trustworthy machine learning is of primary importance to the practical deployment of deep learning models. While state-of-the-art models achieve astonishingly good performance in terms of accuracy, recent literature reveals that their predictive confidence scores unfortunately cannot be trusted: e.g., they are often overconfident when wrong predictions are made, or so even for obvious outliers. In this paper, we introduce a new approach of self-supervised probing, which enables us to check and mitigate the overconfidence issue for a trained model, thereby improving its trustworthiness. We provide a simple yet effective framework, which can be flexibly applied to existing trustworthiness-related methods in a plug-and-play manner. Extensive experiments on three trustworthiness-related tasks (misclassification detection, calibration and out-of-distribution detection) across various benchmarks verify the effectiveness of our proposed probing framework. ",
    "url": "https://arxiv.org/abs/2302.02628",
    "authors": [
      "Ailin Deng",
      "Shen Li",
      "Miao Xiong",
      "Zhirui Chen",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02687",
    "title": "On Manipulating Weight Predictions in Signed Weighted Networks",
    "abstract": "Adversarial social network analysis studies how graphs can be rewired or otherwise manipulated to evade social network analysis tools. While there is ample literature on manipulating simple networks, more sophisticated network types are much less understood in this respect. In this paper, we focus on the problem of evading FGA -- an edge weight prediction method for signed weighted networks by Kumar et al.. Among others, this method can be used for trust prediction in reputation systems. We study the theoretical underpinnings of FGA and its computational properties in terms of manipulability. Our positive finding is that, unlike many other tools, this measure is not only difficult to manipulate optimally, but also it can be difficult to manipulate in practice. ",
    "url": "https://arxiv.org/abs/2302.02687",
    "authors": [
      "Tomasz Lizurej",
      "Tomasz Michalak",
      "Stefan Dziembowski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.02713",
    "title": "Flat Seeking Bayesian Neural Networks",
    "abstract": "Bayesian Neural Networks (BNNs) offer a probabilistic interpretation for deep learning models by imposing a prior distribution over model parameters and inferencing a posterior distribution based on observed data. The model sampled from the posterior distribution can be used for providing ensemble predictions and quantifying prediction uncertainty. It is well-known that deep learning models with a lower sharpness have a better generalization ability. Nonetheless, existing posterior inferences are not aware of sharpness/flatness, hence possibly leading to high sharpness for the models sampled from it. In this paper, we develop theories, the Bayesian setting, and the variational inference approach for the sharpness-aware posterior. Specifically, the models sampled from our sharpness-aware posterior and the optimal approximate posterior estimating this sharpness-aware posterior have a better flatness, hence possibly possessing a higher generalization ability. We conduct experiments by leveraging the sharpness-aware posterior with the state-of-the-art Bayesian Neural Networks, showing that the flat-seeking counterparts outperform their baselines in all metrics of interest. ",
    "url": "https://arxiv.org/abs/2302.02713",
    "authors": [
      "Van-Anh Nguyen",
      "Tung-Long Vuong",
      "Hoang Phan",
      "Thanh-Toan Do",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2302.02738",
    "title": "INCREASE: Inductive Graph Representation Learning for Spatio-Temporal  Kriging",
    "abstract": "Spatio-temporal kriging is an important problem in web and social applications, such as Web or Internet of Things, where things (e.g., sensors) connected into a web often come with spatial and temporal properties. It aims to infer knowledge for (the things at) unobserved locations using the data from (the things at) observed locations during a given time period of interest. This problem essentially requires \\emph{inductive learning}. Once trained, the model should be able to perform kriging for different locations including newly given ones, without retraining. However, it is challenging to perform accurate kriging results because of the heterogeneous spatial relations and diverse temporal patterns. In this paper, we propose a novel inductive graph representation learning model for spatio-temporal kriging. We first encode heterogeneous spatial relations between the unobserved and observed locations by their spatial proximity, functional similarity, and transition probability. Based on each relation, we accurately aggregate the information of most correlated observed locations to produce inductive representations for the unobserved locations, by jointly modeling their similarities and differences. Then, we design relation-aware gated recurrent unit (GRU) networks to adaptively capture the temporal correlations in the generated sequence representations for each relation. Finally, we propose a multi-relation attention mechanism to dynamically fuse the complex spatio-temporal information at different time steps from multiple relations to compute the kriging output. Experimental results on three real-world datasets show that our proposed model outperforms state-of-the-art methods consistently, and the advantage is more significant when there are fewer observed locations. Our code is available at https://github.com/zhengchuanpan/INCREASE. ",
    "url": "https://arxiv.org/abs/2302.02738",
    "authors": [
      "Chuanpan Zheng",
      "Xiaoliang Fan",
      "Cheng Wang",
      "Jianzhong Qi",
      "Chaochao Chen",
      "Longbiao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02755",
    "title": "Fine-Grained Action Detection with RGB and Pose Information using Two  Stream Convolutional Networks",
    "abstract": "As participants of the MediaEval 2022 Sport Task, we propose a two-stream network approach for the classification and detection of table tennis strokes. Each stream is a succession of 3D Convolutional Neural Network (CNN) blocks using attention mechanisms. Each stream processes different 4D inputs. Our method utilizes raw RGB data and pose information computed from MMPose toolbox. The pose information is treated as an image by applying the pose either on a black background or on the original RGB frame it has been computed from. Best performance is obtained by feeding raw RGB data to one stream, Pose + RGB (PRGB) information to the other stream and applying late fusion on the features. The approaches were evaluated on the provided TTStroke-21 data sets. We can report an improvement in stroke classification, reaching 87.3% of accuracy, while the detection does not outperform the baseline but still reaches an IoU of 0.349 and mAP of 0.110. ",
    "url": "https://arxiv.org/abs/2302.02755",
    "authors": [
      "Leonard Hacker",
      "Finn Bartels",
      "Pierre-Etienne Martin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.02756",
    "title": "Diagnosis of Constant Faults in Switching Networks",
    "abstract": "In this paper, we study decision trees for diagnosis of constant faults in switching networks. Each constant fault consists in assigning Boolean constants to some edges of the network instead of literals. The problem of diagnosis is to recognize the function implemented by the switching network with a constant fault from a given set of faults. For this problem solving, we use decision trees. Each query (attribute) of a decision tree consists of observing the value of function implemented by the faulty switching network on a given tuple of variable values. We study the depth of decision trees for diagnosis of arbitrary and specially constructed switching networks and the complexity of diagnostic decision tree construction. ",
    "url": "https://arxiv.org/abs/2302.02756",
    "authors": [
      "Mikhail Moshkov"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2302.02759",
    "title": "Detecting Reddit Users with Depression Using a Hybrid Neural Network",
    "abstract": "Depression is a widespread mental health issue, affecting an estimated 3.8% of the global population. It is also one of the main contributors to disability worldwide. Recently it is becoming popular for individuals to use social media platforms (e.g., Reddit) to express their difficulties and health issues (e.g., depression) and seek support from other users in online communities. It opens great opportunities to automatically identify social media users with depression by parsing millions of posts for potential interventions. Deep learning methods have begun to dominate in the field of machine learning and natural language processing (NLP) because of their ease of use, efficient processing, and state-of-the-art results on many NLP tasks. In this work, we propose a hybrid deep learning model which combines a pretrained sentence BERT (SBERT) and convolutional neural network (CNN) to detect individuals with depression with their Reddit posts. The sentence BERT is used to learn the meaningful representation of semantic information in each post. CNN enables the further transformation of those embeddings and the temporal identification of behavioral patterns of users. We trained and evaluated the model performance to identify Reddit users with depression by utilizing the Self-reported Mental Health Diagnoses (SMHD) data. The hybrid deep learning model achieved an accuracy of 0.86 and an F1 score of 0.86 and outperformed the state-of-the-art documented result (F1 score of 0.79) by other machine learning models in the literature. The results show the feasibility of the hybrid model to identify individuals with depression. Although the hybrid model is validated to detect depression with Reddit posts, it can be easily tuned and applied to other text classification tasks and different clinical applications. ",
    "url": "https://arxiv.org/abs/2302.02759",
    "authors": [
      "Ziyi Chen",
      "Ren Yang",
      "Sunyang Fu",
      "Nansu Zong",
      "Hongfang Liu",
      "Ming Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02780",
    "title": "Coherence and Diversity through Noise: Self-Supervised Paraphrase  Generation via Structure-Aware Denoising",
    "abstract": "In this paper, we propose SCANING, an unsupervised framework for paraphrasing via controlled noise injection. We focus on the novel task of paraphrasing algebraic word problems having practical applications in online pedagogy as a means to reduce plagiarism as well as ensure understanding on the part of the student instead of rote memorization. This task is more complex than paraphrasing general-domain corpora due to the difficulty in preserving critical information for solution consistency of the paraphrased word problem, managing the increased length of the text and ensuring diversity in the generated paraphrase. Existing approaches fail to demonstrate adequate performance on at least one, if not all, of these facets, necessitating the need for a more comprehensive solution. To this end, we model the noising search space as a composition of contextual and syntactic aspects and sample noising functions consisting of either one or both aspects. This allows for learning a denoising function that operates over both aspects and produces semantically equivalent and syntactically diverse outputs through grounded noise injection. The denoising function serves as a foundation for learning a paraphrasing function which operates solely in the input-paraphrase space without carrying any direct dependency on noise. We demonstrate SCANING considerably improves performance in terms of both semantic preservation and producing diverse paraphrases through extensive automated and manual evaluation across 4 datasets. ",
    "url": "https://arxiv.org/abs/2302.02780",
    "authors": [
      "Rishabh Gupta",
      "Venktesh V.",
      "Mukesh Mohania",
      "Vikram Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02787",
    "title": "Generative models for two-ground-truth partitions in networks",
    "abstract": "A myriad of approaches have been proposed to characterise the mesoscale structure of networks - most often as a partition based on patterns variously called communities, blocks, or clusters. Clearly, distinct methods designed to detect different types of patterns may provide a variety of answers to the network's mesoscale structure. Yet, even multiple runs of a given method can sometimes yield diverse and conflicting results, yielding entire landscapes of partitions which potentially include multiple (locally optimal) mesoscale explanations of the network. Such ambiguity motivates a closer look at the ability of these methods to find multiple qualitatively different 'ground truth' partitions in a network. Here, we propose a generative model which allows for two distinct partitions to be built into the mesoscale structure of a single benchmark network. We demonstrate a use case of the benchmark model by exploring the power of stochastic block models (SBMs) to detect coexisting bi-community and core-periphery structures of different strengths. We find that the ability to detect the two partitions individually varies considerably by SBM variant and that coexistence of both partitions is recovered only in a very limited number of cases. Our findings suggest that in most instances only one - in some way dominating - structure can be detected, even in the presence of other partitions in the generated network. They underline the need for considering entire landscapes of partitions when different competing explanations exist and motivate future research to advance partition coexistence detection methods. Our model also contributes to the field of benchmark networks more generally by enabling further exploration of the ability of new and existing methods to detect ambiguity in mesoscale structure of networks. ",
    "url": "https://arxiv.org/abs/2302.02787",
    "authors": [
      "Lena Mangold",
      "Camille Roth"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2302.02790",
    "title": "Perception Datasets for Anomaly Detection in Autonomous Driving: A  Survey",
    "abstract": "Deep neural networks (DNN) which are employed in perception systems for autonomous driving require a huge amount of data to train on, as they must reliably achieve high performance in all kinds of situations. However, these DNN are usually restricted to a closed set of semantic classes available in their training data, and are therefore unreliable when confronted with previously unseen instances. Thus, multiple perception datasets have been created for the evaluation of anomaly detection methods, which can be categorized into three groups: real anomalies in real-world, synthetic anomalies augmented into real-world and completely synthetic scenes. This survey provides a structured and, to the best of our knowledge, complete overview and comparison of perception datasets for anomaly detection in autonomous driving. Each chapter provides information about tasks and ground truth, context information, and licenses. Additionally, we discuss current weaknesses and gaps in existing datasets to underline the importance of developing further data. ",
    "url": "https://arxiv.org/abs/2302.02790",
    "authors": [
      "Daniel Bogdoll",
      "Svenja Uhlemeyer",
      "Kamil Kowol",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02829",
    "title": "Collective Robustness Certificates: Exploiting Interdependence in Graph  Neural Networks",
    "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$. ",
    "url": "https://arxiv.org/abs/2302.02829",
    "authors": [
      "Jan Schuchardt",
      "Aleksandar Bojchevski",
      "Johannes Gasteiger",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.02845",
    "title": "Audio Representation Learning by Distilling Video as Privileged  Information",
    "abstract": "Deep audio representation learning using multi-modal audio-visual data often leads to a better performance compared to uni-modal approaches. However, in real-world scenarios both modalities are not always available at the time of inference, leading to performance degradation by models trained for multi-modal inference. In this work, we propose a novel approach for deep audio representation learning using audio-visual data when the video modality is absent at inference. For this purpose, we adopt teacher-student knowledge distillation under the framework of learning using privileged information (LUPI). While the previous methods proposed for LUPI use soft-labels generated by the teacher, in our proposed method we use embeddings learned by the teacher to train the student network. We integrate our method in two different settings: sequential data where the features are divided into multiple segments throughout time, and non-sequential data where the entire features are treated as one whole segment. In the non-sequential setting both the teacher and student networks are comprised of an encoder component and a task header. We use the embeddings produced by the encoder component of the teacher to train the encoder of the student, while the task header of the student is trained using ground-truth labels. In the sequential setting, the networks have an additional aggregation component that is placed between the encoder and task header. We use two sets of embeddings produced by the encoder and aggregation component of the teacher to train the student. Similar to the non-sequential setting, the task header of the student network is trained using ground-truth labels. We test our framework on two different audio-visual tasks, namely speaker recognition and speech emotion recognition and show considerable improvements over sole audio-based recognition as well as prior works that use LUPI. ",
    "url": "https://arxiv.org/abs/2302.02845",
    "authors": [
      "Amirhossein Hajavi",
      "Ali Etemad"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.02858",
    "title": "TR3D: Towards Real-Time Indoor 3D Object Detection",
    "abstract": "Recently, sparse 3D convolutions have changed 3D object detection. Performing on par with the voting-based approaches, 3D CNNs are memory-efficient and scale to large scenes better. However, there is still room for improvement. With a conscious, practice-oriented approach to problem-solving, we analyze the performance of such methods and localize the weaknesses. Applying modifications that resolve the found issues one by one, we end up with TR3D: a fast fully-convolutional 3D object detection model trained end-to-end, that achieves state-of-the-art results on the standard benchmarks, ScanNet v2, SUN RGB-D, and S3DIS. Moreover, to take advantage of both point cloud and RGB inputs, we introduce an early fusion of 2D and 3D features. We employ our fusion module to make conventional 3D object detection methods multimodal and demonstrate an impressive boost in performance. Our model with early feature fusion, which we refer to as TR3D+FF, outperforms existing 3D object detection approaches on the SUN RGB-D dataset. Overall, besides being accurate, both TR3D and TR3D+FF models are lightweight, memory-efficient, and fast, thereby marking another milestone on the way toward real-time 3D object detection. Code is available at https://github.com/SamsungLabs/tr3d . ",
    "url": "https://arxiv.org/abs/2302.02858",
    "authors": [
      "Danila Rukhovich",
      "Anna Vorontsova",
      "Anton Konushin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02860",
    "title": "Solving Maxwell's Equation in 2D with Neural Networks with Local  Converging Inputs",
    "abstract": "In this paper we apply neural networks with local converging inputs (NNLCI), originally introduced in [arXiv:2109.09316], to solve the two dimensional Maxwell's equation around perfect electric conductors (PECs). The input to the networks consist of local patches of low cost numerical solutions to the equation computed on two coarse grids, and the output is a more accurate solution at the center of the local patch. We apply the recently developed second order finite difference method [arXiv:2209.00740] to generate the input and training data which captures the scattering of electromagnetic waves off of a PEC at a given terminal time. The advantage of NNLCI is that once trained it offers an efficient alternative to costly high-resolution conventional numerical methods; our numerical experiments indicate the computational complexity saving by a factor of $8^3$ in terms of the number of spatial-temporal grid points. In contrast with existing research work on applying neural networks to directly solve PDEs, our method takes advantage of the local domain of dependence of the Maxwell's equation in the input solution patches, and is therefore simpler, yet still robust. We demonstrate that we can train our neural network on some PECs to predict accurate solutions to different PECs with quite different geometries from any of the training examples. ",
    "url": "https://arxiv.org/abs/2302.02860",
    "authors": [
      "Harris Cobb",
      "Hwi Lee",
      "Yingjie Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2302.02878",
    "title": "Graph Neural Networks for Joint Communication and Sensing Optimization  in Vehicular Networks",
    "abstract": "In this paper, the problem of joint communication and sensing is studied in the context of terahertz (THz) vehicular networks. In the studied model, a set of service provider vehicles (SPVs) provide either communication service or sensing service to target vehicles, where it is essential to determine 1) the service mode (i.e., providing either communication or sensing service) for each SPV and 2) the subset of target vehicles that each SPV will serve. The problem is formulated as an optimization problem aiming to maximize the sum of the data rates of the communication target vehicles, while satisfying the sensing service requirements of the sensing target vehicles, by determining the service mode and the target vehicle association for each SPV. To solve this problem, a graph neural network (GNN) based algorithm with a heterogeneous graph representation is proposed. The proposed algorithm enables the central controller to extract each vehicle's graph information related to its location, connection, and communication interference. Using this extracted graph information, a joint service mode selection and target vehicle association strategy is then determined to adapt to the dynamic vehicle topology with various vehicle types (e.g., target vehicles and service provider vehicles). Simulation results show that the proposed GNN-based scheme can achieve 93.66% of the sum rate achieved by the optimal solution, and yield up to 3.16% and 31.86% improvements in sum rate, respectively, over a homogeneous GNN-based algorithm and a conventional optimization algorithm without using GNNs. ",
    "url": "https://arxiv.org/abs/2302.02878",
    "authors": [
      "Xuefei Li",
      "Mingzhe Chen",
      "Yuchen Liu",
      "Zhilong Zhang",
      "Danpu Liu",
      "Shiwen Mao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.02887",
    "title": "Neural Document Unwarping using Coupled Grids",
    "abstract": "Restoring the original, flat appearance of a printed document from casual photographs of bent and wrinkled pages is a common everyday problem. In this paper we propose a novel method for grid-based single-image document unwarping. Our method performs geometric distortion correction via a deep fully convolutional neural network that learns to predict the 3D grid mesh of the document and the corresponding 2D unwarping grid in a multi-task fashion, implicitly encoding the coupling between the shape of a 3D object and its 2D image. We additionally create and publish our own dataset, called UVDoc, which combines pseudo-photorealistic document images with ground truth grid-based physical 3D and unwarping information, allowing unwarping models to train on data that is more realistic in appearance than the commonly used synthetic Doc3D dataset, whilst also being more physically accurate. Our dataset is labeled with all the information necessary to train our unwarping network, without having to engineer separate loss functions that can deal with the lack of ground-truth typically found in document in the wild datasets. We include a thorough evaluation that demonstrates that our dual-task unwarping network trained on a mix of synthetic and pseudo-photorealistic images achieves state-of-the-art performance on the DocUNet benchmark dataset. Our code, results and UVDoc dataset will be made publicly available upon publication. ",
    "url": "https://arxiv.org/abs/2302.02887",
    "authors": [
      "Floor Verhoeven",
      "Tanguy Magne",
      "Olga Sorkine-Hornung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2302.02896",
    "title": "Label Assisted Autoencoder for Anomaly Detection in Power Generation  Plants",
    "abstract": "One of the critical factors that drive the economic development of a country and guarantee the sustainability of its industries is the constant availability of electricity. This is usually provided by the national electric grid. However, in developing countries where companies are emerging on a constant basis including telecommunication industries, those are still experiencing a non-stable electricity supply. Therefore, they have to rely on generators to guarantee their full functionality. Those generators depend on fuel to function and the rate of consumption gets usually high, if not monitored properly. Monitoring operation is usually carried out by a (non-expert) human. In some cases, this could be a tedious process, as some companies have reported an exaggerated high consumption rate. This work proposes a label assisted autoencoder for anomaly detection in the fuel consumed by power generating plants. In addition to the autoencoder model, we added a labelling assistance module that checks if an observation is labelled, the label is used to check the veracity of the corresponding anomaly classification given a threshold. A consensus is then reached on whether training should stop or whether the threshold should be updated or the training should continue with the search for hyper-parameters. Results show that the proposed model is highly efficient for reading anomalies with a detection accuracy of $97.20\\%$ which outperforms the existing model of $96.1\\%$ accuracy trained on the same dataset. In addition, the proposed model is able to classify the anomalies according to their degree of severity. ",
    "url": "https://arxiv.org/abs/2302.02896",
    "authors": [
      "Marcellin Atemkeng",
      "Victor Osanyindoro",
      "Rockefeller Rockefeller",
      "Sisipho Hamlomo",
      "Jecinta Mulongo",
      "Theophilus Ansah-Narh",
      "Franklin Tchakounte",
      "Arnaud Nguembang Fadja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02907",
    "title": "GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks",
    "abstract": "While leveraging additional training data is well established to improve adversarial robustness, it incurs the unavoidable cost of data collection and the heavy computation to train models. To mitigate the costs, we propose \\textit{Guided Adversarial Training } (GAT), a novel adversarial training technique that exploits auxiliary tasks under a limited set of training data. Our approach extends single-task models into multi-task models during the min-max optimization of adversarial training, and drives the loss optimization with a regularization of the gradient curvature across multiple tasks. GAT leverages two types of auxiliary tasks: self-supervised tasks, where the labels are generated automatically, and domain-knowledge tasks, where human experts provide additional labels. Experimentally, under limited data, GAT increases the robust accuracy on CIFAR-10 up to four times (from 11% to 42% robust accuracy) and the robust AUC of CheXpert medical imaging dataset from 50\\% to 83\\%. On the full CIFAR-10 dataset, GAT outperforms eight state-of-the-art adversarial training strategies. Our large study across five datasets and six tasks demonstrates that task augmentation is an efficient alternative to data augmentation, and can be key to achieving both clean and robust performances. ",
    "url": "https://arxiv.org/abs/2302.02907",
    "authors": [
      "Salah Ghamizi",
      "Jingfeng Zhang",
      "Maxime Cordy",
      "Mike Papadakis",
      "Masashi Sugiyama",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02909",
    "title": "Spectral Augmentations for Graph Contrastive Learning",
    "abstract": "Contrastive learning has emerged as a premier method for learning representations with or without supervision. Recent studies have shown its utility in graph representation learning for pre-training. Despite successes, the understanding of how to design effective graph augmentations that can capture structural properties common to many different types of downstream graphs remains incomplete. We propose a set of well-motivated graph transformation operations derived via graph spectral analysis to provide a bank of candidates when constructing augmentations for a graph contrastive objective, enabling contrastive learning to capture useful structural representation from pre-training graph datasets. We first present a spectral graph cropping augmentation that involves filtering nodes by applying thresholds to the eigenvalues of the leading Laplacian eigenvectors. Our second novel augmentation reorders the graph frequency components in a structural Laplacian-derived position graph embedding. Further, we introduce a method that leads to improved views of local subgraphs by performing alignment via global random walk embeddings. Our experimental results indicate consistent improvements in out-of-domain graph data transfer compared to state-of-the-art graph contrastive learning methods, shedding light on how to design a graph learner that is able to learn structural properties common to diverse graph types. ",
    "url": "https://arxiv.org/abs/2302.02909",
    "authors": [
      "Amur Ghose",
      "Yingxue Zhang",
      "Jianye Hao",
      "Mark Coates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02910",
    "title": "An Empirical Analysis of Fairness Notions under Differential Privacy",
    "abstract": "Recent works have shown that selecting an optimal model architecture suited to the differential privacy setting is necessary to achieve the best possible utility for a given privacy budget using differentially private stochastic gradient descent (DP-SGD)(Tramer and Boneh 2020; Cheng et al. 2022). In light of these findings, we empirically analyse how different fairness notions, belonging to distinct classes of statistical fairness criteria (independence, separation and sufficiency), are impacted when one selects a model architecture suitable for DP-SGD, optimized for utility. Using standard datasets from ML fairness literature, we show using a rigorous experimental protocol, that by selecting the optimal model architecture for DP-SGD, the differences across groups concerning the relevant fairness metrics (demographic parity, equalized odds and predictive parity) more often decrease or are negligibly impacted, compared to the non-private baseline, for which optimal model architecture has also been selected to maximize utility. These findings challenge the understanding that differential privacy will necessarily exacerbate unfairness in deep learning models trained on biased datasets. ",
    "url": "https://arxiv.org/abs/2302.02910",
    "authors": [
      "Anderson Santana de Oliveira",
      "Caelin Kaplan",
      "Khawla Mallat",
      "Tanmay Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02914",
    "title": "Energy-based Out-of-Distribution Detection for Graph Neural Networks",
    "abstract": "Learning on graphs, where instance nodes are inter-connected, has become one of the central problems for deep learning, as relational structures are pervasive and induce data inter-dependence which hinders trivial adaptation of existing approaches that assume inputs to be i.i.d.~sampled. However, current models mostly focus on improving testing performance of in-distribution data and largely ignore the potential risk w.r.t. out-of-distribution (OOD) testing samples that may cause negative outcome if the prediction is overconfident on them. In this paper, we investigate the under-explored problem, OOD detection on graph-structured data, and identify a provably effective OOD discriminator based on an energy function directly extracted from graph neural networks trained with standard classification loss. This paves a way for a simple, powerful and efficient OOD detection model for GNN-based learning on graphs, which we call GNNSafe. It also has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for in-distribution and OOD samples, which, more critically, can be further strengthened by a learning-free energy belief propagation scheme. For comprehensive evaluation, we introduce new benchmark settings that evaluate the model for detecting OOD data from both synthetic and real distribution shifts (cross-domain graph shifts and temporal graph shifts). The results show that GNNSafe achieves up to $17.0\\%$ AUROC improvement over state-of-the-arts and it could serve as simple yet strong baselines in such an under-developed area. ",
    "url": "https://arxiv.org/abs/2302.02914",
    "authors": [
      "Qitian Wu",
      "Yiting Chen",
      "Chenxiao Yang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.02922",
    "title": "Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural  Networks",
    "abstract": "Due to the significant computational challenge of training large-scale graph neural networks (GNNs), various sparse learning techniques have been exploited to reduce memory and storage costs. Examples include \\textit{graph sparsification} that samples a subgraph to reduce the amount of data aggregation and \\textit{model sparsification} that prunes the neural network to reduce the number of trainable weights. Despite the empirical successes in reducing the training cost while maintaining the test accuracy, the theoretical generalization analysis of sparse learning for GNNs remains elusive. To the best of our knowledge, this paper provides the first theoretical characterization of joint edge-model sparse learning from the perspective of sample complexity and convergence rate in achieving zero generalization error. It proves analytically that both sampling important nodes and pruning neurons with the lowest-magnitude can reduce the sample complexity and improve convergence without compromising the test accuracy. Although the analysis is centered on two-layer GNNs with structural constraints on data, the insights are applicable to more general setups and justified by both synthetic and practical citation datasets. ",
    "url": "https://arxiv.org/abs/2302.02922",
    "authors": [
      "Shuai Zhang",
      "Meng Wang",
      "Pin-Yu Chen",
      "Sijia Liu",
      "Songtao Lu",
      "Miao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.02924",
    "title": "Dropout Injection at Test Time for Post Hoc Uncertainty Quantification  in Neural Networks",
    "abstract": "Among Bayesian methods, Monte-Carlo dropout provides principled tools for evaluating the epistemic uncertainty of neural networks. Its popularity recently led to seminal works that proposed activating the dropout layers only during inference for evaluating uncertainty. This approach, which we call dropout injection, provides clear benefits over its traditional counterpart (which we call embedded dropout) since it allows one to obtain a post hoc uncertainty measure for any existing network previously trained without dropout, avoiding an additional, time-consuming training process. Unfortunately, no previous work compared injected and embedded dropout; therefore, we provide the first thorough investigation, focusing on regression problems. The main contribution of our work is to provide guidelines on the effective use of injected dropout so that it can be a practical alternative to the current use of embedded dropout. In particular, we show that its effectiveness strongly relies on a suitable scaling of the corresponding uncertainty measure, and we discuss the trade-off between negative log-likelihood and calibration error as a function of the scale factor. Experimental results on UCI data sets and crowd counting benchmarks support our claim that dropout injection can effectively behave as a competitive post hoc uncertainty quantification technique. ",
    "url": "https://arxiv.org/abs/2302.02924",
    "authors": [
      "Emanuele Ledda",
      "Giorgio Fumera",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02926",
    "title": "Curriculum Graph Machine Learning: A Survey",
    "abstract": "Graph machine learning has been extensively studied in both academia and industry. However, in the literature, most existing graph machine learning models are designed to conduct training with data samples in a random order, which may suffer from suboptimal performance due to ignoring the importance of different graph data samples and their training orders for the model optimization status. To tackle this critical problem, curriculum graph machine learning (Graph CL), which integrates the strength of graph machine learning and curriculum learning, arises and attracts an increasing amount of attention from the research community. Therefore, in this paper, we comprehensively overview approaches on Graph CL and present a detailed survey of recent advances in this direction. Specifically, we first discuss the key challenges of Graph CL and provide its formal problem definition. Then, we categorize and summarize existing methods into three classes based on three kinds of graph machine learning tasks, i.e., node-level, link-level, and graph-level tasks. Finally, we share our thoughts on future research directions. To the best of our knowledge, this paper is the first survey for curriculum graph machine learning. ",
    "url": "https://arxiv.org/abs/2302.02926",
    "authors": [
      "Haoyang Li",
      "Xin Wang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02931",
    "title": "Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group  Shifts",
    "abstract": "Training machine learning models robust to distribution shifts is critical for real-world applications. Some robust training algorithms (e.g., Group DRO) specialize to group shifts and require group information on all training points. Other methods (e.g., CVaR DRO) that do not need group annotations can be overly conservative, since they naively upweight high loss points which may form a contrived set that does not correspond to any meaningful group in the real world (e.g., when the high loss points are randomly mislabeled training points). In this work, we address limitations in prior approaches by assuming a more nuanced form of group shift: conditioned on the label, we assume that the true group function (indicator over group) is simple. For example, we may expect that group shifts occur along low bitrate features (e.g., image background, lighting). Thus, we aim to learn a model that maintains high accuracy on simple group functions realized by these low bitrate features, that need not spend valuable model capacity achieving high accuracy on contrived groups of examples. Based on this, we consider the two-player game formulation of DRO where the adversary's capacity is bitrate-constrained. Our resulting practical algorithm, Bitrate-Constrained DRO (BR-DRO), does not require group information on training samples yet matches the performance of Group DRO on datasets that have training group annotations and that of CVaR DRO on long-tailed distributions. Our theoretical analysis reveals that in some settings BR-DRO objective can provably yield statistically efficient and less conservative solutions than unconstrained CVaR DRO. ",
    "url": "https://arxiv.org/abs/2302.02931",
    "authors": [
      "Amrith Setlur",
      "Don Dennis",
      "Benjamin Eysenbach",
      "Aditi Raghunathan",
      "Chelsea Finn",
      "Virginia Smith",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02941",
    "title": "On Over-Squashing in Message Passing Neural Networks: The Impact of  Width, Depth, and Topology",
    "abstract": "Message Passing Neural Networks (MPNNs) are instances of Graph Neural Networks that leverage the graph to send messages over the edges. This inductive bias leads to a phenomenon known as over-squashing, where a node feature is insensitive to information contained at distant nodes. Despite recent methods introduced to mitigate this issue, an understanding of the causes for over-squashing and of possible solutions are lacking. In this theoretical work, we prove that: (i) Neural network width can mitigate over-squashing, but at the cost of making the whole network more sensitive; (ii) Conversely, depth cannot help mitigate over-squashing: increasing the number of layers leads to over-squashing being dominated by vanishing gradients; (iii) The graph topology plays the greatest role, since over-squashing occurs between nodes at high commute (access) time. Our analysis provides a unified framework to study different recent methods introduced to cope with over-squashing and serves as a justification for a class of methods that fall under `graph rewiring'. ",
    "url": "https://arxiv.org/abs/2302.02941",
    "authors": [
      "Francesco Di Giovanni",
      "Lorenzo Giusti",
      "Federico Barbero",
      "Giulia Luise",
      "Pietro Lio'",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.02947",
    "title": "GPS++: Reviving the Art of Message Passing for Molecular Property  Prediction",
    "abstract": "We present GPS++, a hybrid Message Passing Neural Network / Graph Transformer model for molecular property prediction. Our model integrates a well-tuned local message passing component and biased global attention with other key ideas from prior literature to achieve state-of-the-art results on large-scale molecular dataset PCQM4Mv2. Through a thorough ablation study we highlight the impact of individual components and, contrary to expectations set by recent trends, find that nearly all of the model's performance can be maintained without any use of global self-attention. We also show that our approach is significantly more accurate than prior art when 3D positional information is not available. ",
    "url": "https://arxiv.org/abs/2302.02947",
    "authors": [
      "Dominic Masters",
      "Josef Dean",
      "Kerstin Klaser",
      "Zhiyi Li",
      "Sam Maddrell-Mander",
      "Adam Sanders",
      "Hatem Helal",
      "Deniz Beker",
      "Andrew Fitzgibbon",
      "Shenyang Huang",
      "Ladislav Ramp\u00e1\u0161ek",
      "Dominique Beaini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02984",
    "title": "Robust Subtask Learning for Compositional Generalization",
    "abstract": "Compositional reinforcement learning is a promising approach for training policies to perform complex long-horizon tasks. Typically, a high-level task is decomposed into a sequence of subtasks and a separate policy is trained to perform each subtask. In this paper, we focus on the problem of training subtask policies in a way that they can be used to perform any task; here, a task is given by a sequence of subtasks. We aim to maximize the worst-case performance over all tasks as opposed to the average-case performance. We formulate the problem as a two agent zero-sum game in which the adversary picks the sequence of subtasks. We propose two RL algorithms to solve this game: one is an adaptation of existing multi-agent RL algorithms to our setting and the other is an asynchronous version which enables parallel training of subtask policies. We evaluate our approach on two multi-task environments with continuous states and actions and demonstrate that our algorithms outperform state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2302.02984",
    "authors": [
      "Kishor Jothimurugan",
      "Steve Hsu",
      "Osbert Bastani",
      "Rajeev Alur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02986",
    "title": "Fitness Dependent Optimizer with Neural Networks for COVID-19 patients",
    "abstract": "The Coronavirus, known as COVID-19, which appeared in 2019 in China, has significantly affected global health and become a huge burden on health institutions all over the world. These effects are continuing today. One strategy for limiting the virus's transmission is to have an early diagnosis of suspected cases and take appropriate measures before the disease spreads further. This work aims to diagnose and show the probability of getting infected by the disease according to textual clinical data. In this work, we used five machine learning techniques (GWO_MLP, GWO_CMLP, MGWO_MLP, FDO_MLP, FDO_CMLP) all of which aim to classify Covid-19 patients into two categories (Positive and Negative). Experiments showed promising results for all used models. The applied methods showed very similar performance, typically in terms of accuracy. However, in each tested dataset, FDO_MLP and FDO_CMLP produced the best results with 100% accuracy. The other models' results varied from one experiment to the other. It is concluded that the models on which the FDO algorithm was used as a learning algorithm had the possibility of obtaining higher accuracy. However, it is found that FDO has the longest runtime compared to the other algorithms. The link to the covid 19 models is found here: https://github.com/Tarik4Rashid4/covid19models ",
    "url": "https://arxiv.org/abs/2302.02986",
    "authors": [
      "Maryam T. Abdulkhaleq",
      "Tarik A. Rashid",
      "Bryar A. Hassan",
      "Abeer Alsadoon",
      "Nebojsa Bacanin",
      "Amit Chhabra",
      "S. Vimal"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02997",
    "title": "Erasure of Unaligned Attributes from Neural Representations",
    "abstract": "We present the Assignment-Maximization Spectral Attribute removaL (AMSAL) algorithm, which aims at removing information from neural representations when the information to be erased is implicit rather than directly being aligned to each input example. Our algorithm works by alternating between two steps. In one, it finds an assignment of the input representations to the information to be erased, and in the other, it creates projections of both the input representations and the information to be erased into a joint latent space. We test our algorithm on an extensive array of datasets, including a Twitter dataset with multiple guarded attributes, the BiasBios dataset and the BiasBench benchmark. The latter benchmark includes four datasets with various types of protected attributes. Our results demonstrate that bias can often be removed in our setup. We also discuss the limitations of our approach when there is a strong entanglement between the main task and the information to be erased. ",
    "url": "https://arxiv.org/abs/2302.02997",
    "authors": [
      "Shun Shao",
      "Yftah Ziser",
      "Shay Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.03004",
    "title": "Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class  Incremental Learning",
    "abstract": "Few-shot class-incremental learning (FSCIL) has been a challenging problem as only a few training samples are accessible for each novel class in the new sessions. Finetuning the backbone or adjusting the classifier prototypes trained in the prior sessions would inevitably cause a misalignment between the feature and classifier of old classes, which explains the well-known catastrophic forgetting problem. In this paper, we deal with this misalignment dilemma in FSCIL inspired by the recently discovered phenomenon named neural collapse, which reveals that the last-layer features of the same class will collapse into a vertex, and the vertices of all classes are aligned with the classifier prototypes, which are formed as a simplex equiangular tight frame (ETF). It corresponds to an optimal geometric structure for classification due to the maximized Fisher Discriminant Ratio. We propose a neural collapse inspired framework for FSCIL. A group of classifier prototypes are pre-assigned as a simplex ETF for the whole label space, including the base session and all the incremental sessions. During training, the classifier prototypes are not learnable, and we adopt a novel loss function that drives the features into their corresponding prototypes. Theoretical analysis shows that our method holds the neural collapse optimality and does not break the feature-classifier alignment in an incremental fashion. Experiments on the miniImageNet, CUB-200, and CIFAR-100 datasets demonstrate that our proposed framework outperforms the state-of-the-art performances. Code address: https://github.com/NeuralCollapseApplications/FSCIL ",
    "url": "https://arxiv.org/abs/2302.03004",
    "authors": [
      "Yibo Yang",
      "Haobo Yuan",
      "Xiangtai Li",
      "Zhouchen Lin",
      "Philip Torr",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03015",
    "title": "Exploring and Exploiting Decision Boundary Dynamics for Adversarial  Robustness",
    "abstract": "The robustness of a deep classifier can be characterized by its margins: the decision boundary's distances to natural data points. However, it is unclear whether existing robust training methods effectively increase the margin for each vulnerable point during training. To understand this, we propose a continuous-time framework for quantifying the relative speed of the decision boundary with respect to each individual point. Through visualizing the moving speed of the decision boundary under Adversarial Training, one of the most effective robust training algorithms, a surprising moving-behavior is revealed: the decision boundary moves away from some vulnerable points but simultaneously moves closer to others, decreasing their margins. To alleviate these conflicting dynamics of the decision boundary, we propose Dynamics-aware Robust Training (DyART), which encourages the decision boundary to engage in movement that prioritizes increasing smaller margins. In contrast to prior works, DyART directly operates on the margins rather than their indirect approximations, allowing for more targeted and effective robustness improvement. Experiments on the CIFAR-10 and Tiny-ImageNet datasets verify that DyART alleviates the conflicting dynamics of the decision boundary and obtains improved robustness under various perturbation sizes compared to the state-of-the-art defenses. Our code is available at https://github.com/Yuancheng-Xu/Dynamics-Aware-Robust-Training. ",
    "url": "https://arxiv.org/abs/2302.03015",
    "authors": [
      "Yuancheng Xu",
      "Yanchao Sun",
      "Micah Goldblum",
      "Tom Goldstein",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03023",
    "title": "V1T: large-scale mouse V1 response prediction using a Vision Transformer",
    "abstract": "Accurate predictive models of the visual cortex neural response to natural visual stimuli remain a challenge in computational neuroscience. In this work, we introduce V1T, a novel Vision Transformer based architecture that learns a shared visual and behavioral representation across animals. We evaluate our model on two large datasets recorded from mouse primary visual cortex and outperform previous convolution-based models by more than 12.7% in prediction performance. Moreover, we show that the attention weights learned by the Transformer correlate with the population receptive fields. Our model thus sets a new benchmark for neural response prediction and captures characteristic features of the visual cortex. ",
    "url": "https://arxiv.org/abs/2302.03023",
    "authors": [
      "Bryan M. Li",
      "Isabel M. Cornacchia",
      "Nathalie L. Rochefort",
      "Arno Onken"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2302.03025",
    "title": "A Toy Model of Universality: Reverse Engineering How Networks Learn  Group Operations",
    "abstract": "Universality is a key hypothesis in mechanistic interpretability -- that different models learn similar features and circuits when trained on similar tasks. In this work, we study the universality hypothesis by examining how small neural networks learn to implement group composition. We present a novel algorithm by which neural networks may implement composition for any finite group via mathematical representation theory. We then show that networks consistently learn this algorithm by reverse engineering model logits and weights, and confirm our understanding using ablations. By studying networks of differing architectures trained on various groups, we find mixed evidence for universality: using our algorithm, we can completely characterize the family of circuits and features that networks learn on this task, but for a given network the precise circuits learned -- as well as the order they develop -- are arbitrary. ",
    "url": "https://arxiv.org/abs/2302.03025",
    "authors": [
      "Bilal Chughtai",
      "Lawrence Chan",
      "Neel Nanda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Representation Theory (math.RT)"
    ]
  },
  {
    "id": "arXiv:2302.01934",
    "title": "A neural operator-based surrogate solver for free-form electromagnetic  inverse design",
    "abstract": "Neural operators have emerged as a powerful tool for solving partial differential equations in the context of scientific machine learning. Here, we implement and train a modified Fourier neural operator as a surrogate solver for electromagnetic scattering problems and compare its data efficiency to existing methods. We further demonstrate its application to the gradient-based nanophotonic inverse design of free-form, fully three-dimensional electromagnetic scatterers, an area that has so far eluded the application of deep learning techniques. ",
    "url": "https://arxiv.org/abs/2302.01934",
    "authors": [
      "Yannick Augenstein",
      "Taavi Rep\u00e4n",
      "Carsten Rockstuhl"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2302.01947",
    "title": "Extracting the gamma-ray source-count distribution below the Fermi-LAT  detection limit with deep learning",
    "abstract": "We reconstruct the extra-galactic gamma-ray source-count distribution, or $dN/dS$, of resolved and unresolved sources by adopting machine learning techniques. Specifically, we train a convolutional neural network on synthetic 2-dimensional sky-maps, which are built by varying parameters of underlying source-counts models and incorporate the Fermi-LAT instrumental response functions. The trained neural network is then applied to the Fermi-LAT data, from which we estimate the source count distribution down to flux levels a factor of 50 below the Fermi-LAT threshold. We perform our analysis using 14 years of data collected in the $(1,10)$ GeV energy range. The results we obtain show a source count distribution which, in the resolved regime, is in excellent agreement with the one derived from catalogued sources, and then extends as $dN/dS \\sim S^{-2}$ in the unresolved regime, down to fluxes of $5 \\cdot 10^{-12}$ cm$^{-2}$ s$^{-1}$. The neural network architecture and the devised methodology have the flexibility to enable future analyses to study the energy dependence of the source-count distribution. ",
    "url": "https://arxiv.org/abs/2302.01947",
    "authors": [
      "Aurelio Amerio",
      "Alessandro Cuoco",
      "Nicolao Fornengo"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02005",
    "title": "DeepAstroUDA: Semi-Supervised Universal Domain Adaptation for  Cross-Survey Galaxy Morphology Classification and Anomaly Detection",
    "abstract": "Artificial intelligence methods show great promise in increasing the quality and speed of work with large astronomical datasets, but the high complexity of these methods leads to the extraction of dataset-specific, non-robust features. Therefore, such methods do not generalize well across multiple datasets. We present a universal domain adaptation method, \\textit{DeepAstroUDA}, as an approach to overcome this challenge. This algorithm performs semi-supervised domain adaptation and can be applied to datasets with different data distributions and class overlaps. Non-overlapping classes can be present in any of the two datasets (the labeled source domain, or the unlabeled target domain), and the method can even be used in the presence of unknown classes. We apply our method to three examples of galaxy morphology classification tasks of different complexities ($3$-class and $10$-class problems), with anomaly detection: 1) datasets created after different numbers of observing years from a single survey (LSST mock data of $1$ and $10$ years of observations); 2) data from different surveys (SDSS and DECaLS); and 3) data from observing fields with different depths within one survey (wide field and Stripe 82 deep field of SDSS). For the first time, we demonstrate the successful use of domain adaptation between very discrepant observational datasets. \\textit{DeepAstroUDA} is capable of bridging the gap between two astronomical surveys, increasing classification accuracy in both domains (up to $40\\%$ on the unlabeled data), and making model performance consistent across datasets. Furthermore, our method also performs well as an anomaly detection algorithm and successfully clusters unknown class samples even in the unlabeled target dataset. ",
    "url": "https://arxiv.org/abs/2302.02005",
    "authors": [
      "A. \u0106iprijanovi\u0107",
      "A. Lewis",
      "K. Pedro",
      "S. Madireddy",
      "B. Nord",
      "G. N. Perdue",
      "S. M. Wild"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02228",
    "title": "Counterfactual Identifiability of Bijective Causal Models",
    "abstract": "We study counterfactual identifiability in causal models with bijective generation mechanisms (BGM), a class that generalizes several widely-used causal models in the literature. We establish their counterfactual identifiability for three common causal structures with unobserved confounding, and propose a practical learning method that casts learning a BGM as structured generative modeling. Learned BGMs enable efficient counterfactual estimation and can be obtained using a variety of deep conditional generative models. We evaluate our techniques in a visual task and demonstrate its application in a real-world video streaming simulation task. ",
    "url": "https://arxiv.org/abs/2302.02228",
    "authors": [
      "Arash Nasr-Esfahany",
      "Mohammad Alizadeh",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02302",
    "title": "Achieving Robust Generalization for Wireless Channel Estimation Neural  Networks by Designed Training Data",
    "abstract": "In this paper, we propose a method to design the training data that can support robust generalization of trained neural networks to unseen channels. The proposed design that improves the generalization is described and analysed. It avoids the requirement of online training for previously unseen channels, as this is a memory and processing intensive solution, especially for battery powered mobile terminals. To prove the validity of the proposed method, we use the channels modelled by different standards and fading modelling for simulation. We also use an attention-based structure and a convolutional neural network to evaluate the generalization results achieved. Simulation results show that the trained neural networks maintain almost identical performance on the unseen channels. ",
    "url": "https://arxiv.org/abs/2302.02302",
    "authors": [
      "Dianxin Luan",
      "John Thompson"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02456",
    "title": "Deep Learning Approach for Early Stage Lung Cancer Detection",
    "abstract": "Lung cancer is the leading cause of death among different types of cancers. Every year, the lives lost due to lung cancer exceed those lost to pancreatic, breast, and prostate cancer combined. The survival rate for lung cancer patients is very low compared to other cancer patients due to late diagnostics. Thus, early lung cancer diagnostics is crucial for patients to receive early treatments, increasing the survival rate or even becoming cancer-free. This paper proposed a deep-learning model for early lung cancer prediction and diagnosis from Computed Tomography (CT) scans. The proposed mode achieves high accuracy. In addition, it can be a beneficial tool to support radiologists' decisions in predicting and detecting lung cancer and its stage. ",
    "url": "https://arxiv.org/abs/2302.02456",
    "authors": [
      "Saleh Abunajm",
      "Nelly Elsayed",
      "Zag ElSayed",
      "Murat Ozer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.02544",
    "title": "Sequential change detection via backward confidence sequences",
    "abstract": "We present a simple reduction from sequential estimation to sequential changepoint detection (SCD). In short, suppose we are interested in detecting changepoints in some parameter or functional $\\theta$ of the underlying distribution. We demonstrate that if we can construct a confidence sequence (CS) for $\\theta$, then we can also successfully perform SCD for $\\theta$. This is accomplished by checking if two CSs -- one forwards and the other backwards -- ever fail to intersect. Since the literature on CSs has been rapidly evolving recently, the reduction provided in this paper immediately solves several old and new change detection problems. Further, our \"backward CS\", constructed by reversing time, is new and potentially of independent interest. We provide strong nonasymptotic guarantees on the frequency of false alarms and detection delay, and demonstrate numerical effectiveness on several problems. ",
    "url": "https://arxiv.org/abs/2302.02544",
    "authors": [
      "Shubhanshu Shekhar",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.02563",
    "title": "Stochastic Gradient Descent-induced drift of representation in a  two-layer neural network",
    "abstract": "Representational drift refers to over-time changes in neural activation accompanied by a stable task performance. Despite being observed in the brain and in artificial networks, the mechanisms of drift and its implications are not fully understood. Motivated by recent experimental findings of stimulus-dependent drift in the piriform cortex, we use theory and simulations to study this phenomenon in a two-layer linear feedforward network. Specifically, in a continual learning scenario, we study the drift induced by the noise inherent in the Stochastic Gradient Descent (SGD). By decomposing the learning dynamics into the normal and tangent spaces of the minimum-loss manifold, we show the former correspond to a finite variance fluctuation, while the latter could be considered as an effective diffusion process on the manifold. We analytically compute the fluctuation and the diffusion coefficients for the stimuli representations in the hidden layer as a function of network parameters and input distribution. Further, consistent with experiments, we show that the drift rate is slower for a more frequently presented stimulus. Overall, our analysis yields a theoretical framework for better understanding of the drift phenomenon in biological and artificial neural networks. ",
    "url": "https://arxiv.org/abs/2302.02563",
    "authors": [
      "Farhad Pashakhanloo",
      "Alexei Koulakov"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02575",
    "title": "Optimizing Energy-Harvesting Hybrid VLC/RF Networks with Random Receiver  Orientation",
    "abstract": "In this paper, we consider an indoor hybrid visible light communication (VLC) and radio frequency (RF) communication scenario with two-hop downlink transmission. The LED carries both data and energy in the first phase, VLC, to an energy harvester relay node, which then uses the harvested energy to re-transmit the decoded information to the RF user in the second phase, RF communication. The direct current (DC) bias and the assigned time duration for VLC transmission are taken into account as design parameters. The optimization problem is formulated to maximize the data rate with the assumption of decode-and-forward relaying for fixed receiver orientation. The non-convex optimization is split into two sub-problems and solved cyclically. It optimizes the data rate by solving two sub-problems: fixing time duration for VLC link to solve DC bias and fixing DC bias to solve time duration. The effect of random receiver orientation on the data rate is also studied, and closed-form expressions for both VLC and RF data rates are derived. The optimization is solved through an exhaustive search, and the results show that a higher data rate can be achieved by solving the joint problem of DC bias and time duration compared to solely optimizing the DC bias. ",
    "url": "https://arxiv.org/abs/2302.02575",
    "authors": [
      "Amir Hossein Fahim Raouf",
      "Chethan Kumar Anjinappa",
      "Ismail Guvenc"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2302.02590",
    "title": "Consensus dynamics and coherence in hierarchical small-world networks",
    "abstract": "The hierarchical small-world network is a real-world network. It models well the benefit transmission web of the pyramid selling in China and many other countries. In this paper, by applying the spectral graph theory, we study three important aspects of the consensus problem in the hierarchical small-world network: convergence speed, communication time-delay robustness, and network coherence. Firstly, we explicitly determine the Laplacian eigenvalues of the hierarchical small-world network by making use of its treelike structure. Secondly, we find that the consensus algorithm on the hierarchical small-world network converges faster than that on some well-studied sparse networks, but is less robust to time delay. The closed-form of the first-order and the second-order network coherence are also derived. Our result shows that the hierarchical small-world network has an optimal structure of noisy consensus dynamics. Therefore, we provide a positive answer to two open questions of Yi \\emph{et al}. Finally, we argue that some network structure characteristics, such as large maximum degree, small average path length, and large vertex and edge connectivity, are responsible for the strong robustness with respect to external perturbations. ",
    "url": "https://arxiv.org/abs/2302.02590",
    "authors": [
      "Yunhua Liao",
      "Mohamed Maama",
      "M.A. Aziz-Alaoui"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2302.02694",
    "title": "Robust Maximum Correntropy Kalman Filter",
    "abstract": "The Kalman filter provides an optimal estimation for a linear system with Gaussian noise. However when the noises are non-Gaussian in nature, its performance deteriorates rapidly. For non-Gaussian noises, maximum correntropy Kalman filter (MCKF) is developed which provides an improved result. But when the system model differs from nominal consideration, the performance of the MCKF degrades. For such cases, we have proposed a new robust filtering technique which maximize a cost function defined by exponential of weighted past and present errors along with the Gaussian kernel function. By solving this cost criteria we have developed prior and posterior mean and covariance matrix propagation equations. By maximizing the correntropy function of error matrix, we have selected the kernel bandwidth value at each time step. Further the conditions for convergence of the proposed algorithm is also derived. Two numerical examples are presented to show the usefulness of the new filtering technique. ",
    "url": "https://arxiv.org/abs/2302.02694",
    "authors": [
      "Joydeb Saha",
      "Shovan Bhaumik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.02714",
    "title": "Differentiable Programming of Chemical Reaction Networks",
    "abstract": "We present a differentiable formulation of abstract chemical reaction networks (CRNs) that can be trained to solve a variety of computational tasks. Chemical reaction networks are one of the most fundamental computational substrates used by nature. We study well-mixed single-chamber systems, as well as systems with multiple chambers separated by membranes, under mass-action kinetics. We demonstrate that differentiable optimisation, combined with proper regularisation, can discover non-trivial sparse reaction networks that can implement various sorts of oscillators and other chemical computing devices. ",
    "url": "https://arxiv.org/abs/2302.02714",
    "authors": [
      "Alexander Mordvintsev",
      "Ettore Randazzo",
      "Eyvind Niklasson"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02731",
    "title": "Root Laplacian Eigenmaps with their application in spectral embedding",
    "abstract": "The root laplacian operator or the square root of Laplacian which can be obtained in complete Riemannian manifolds in the Gromov sense has an analog in graph theory as a square root of graph-Laplacian. Some potential applications have been shown in geometric deep learning (spectral clustering) and graph signal processing. ",
    "url": "https://arxiv.org/abs/2302.02731",
    "authors": [
      "Shouvik Datta Choudhury"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02742",
    "title": "Residual Information in Deep Speaker Embedding Architectures",
    "abstract": "Speaker embeddings represent a means to extract representative vectorial representations from a speech signal such that the representation pertains to the speaker identity alone. The embeddings are commonly used to classify and discriminate between different speakers. However, there is no objective measure to evaluate the ability of a speaker embedding to disentangle the speaker identity from the other speech characteristics. This means that the embeddings are far from ideal, highly dependent on the training corpus and still include a degree of residual information pertaining to factors such as linguistic content, recording conditions or speaking style of the utterance. This paper introduces an analysis over six sets of speaker embeddings extracted with some of the most recent and high-performing DNN architectures, and in particular, the degree to which they are able to truly disentangle the speaker identity from the speech signal. To correctly evaluate the architectures, a large multi-speaker parallel speech dataset is used. The dataset includes 46 speakers uttering the same set of prompts, recorded in either a professional studio or their home environments. The analysis looks into the intra- and inter-speaker similarity measures computed over the different embedding sets, as well as if simple classification and regression methods are able to extract several residual information factors from the speaker embeddings. The results show that the discriminative power of the analyzed embeddings is very high, yet across all the analyzed architectures, residual information is still present in the representations in the form of a high correlation to the recording conditions, linguistic contents and utterance duration. ",
    "url": "https://arxiv.org/abs/2302.02742",
    "authors": [
      "Adriana Stan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2302.02854",
    "title": "NA-SODINN: a deep learning algorithm for exoplanet image detection based  on residual noise regimes",
    "abstract": "Supervised machine learning was recently introduced in high-contrast imaging (HCI) through the SODINN algorithm, a convolutional neural network designed for exoplanet detection in angular differential imaging (ADI) data sets. The benchmarking of HCI algorithms within the Exoplanet Imaging Data Challenge (EIDC) showed that (i) SODINN can produce a high number of false positives in the final detection maps, and (ii) algorithms processing images in a more local manner perform better. This work aims to improve the SODINN detection performance by introducing new local processing approaches and adapting its learning process accordingly. We propose NA-SODINN, a new deep learning architecture that better captures image noise correlations by training an independent SODINN model per noise regime over the processed frame. The identification of these noise regimes is based on a novel technique, named PCA-pmaps, which allows to estimate the distance from the star in the image from which background noise starts to dominate over residual speckle noise. NA-SODINN is also fed with local discriminators, such as S/N curves, which complement spatio-temporal feature maps when training the model.Our new approach is tested against its predecessor, as well as two SODINN-based hybrid models and a more standard annular-PCA approach, through local ROC analysis of ADI sequences from VLT/SPHERE and Keck/NIRC-2 instruments. Results show that NA-SODINN enhances SODINN in both the sensitivity and specificity, especially in the speckle-dominated noise regime. NA-SODINN is also benchmarked against the complete set of submitted detection algorithms in EIDC, in which we show that its final detection score matches or outperforms the most powerful detection algorithms, reaching a performance similar to that of the Regime Switching Model algorithm. ",
    "url": "https://arxiv.org/abs/2302.02854",
    "authors": [
      "Carles Cantero",
      "Olivier Absil",
      "Carl-Henrik Dahlqvist",
      "Marc Van Droogenbroeck"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.02884",
    "title": "Intra-operative Brain Tumor Detection with Deep Learning-Optimized  Hyperspectral Imaging",
    "abstract": "Surgery for gliomas (intrinsic brain tumors), especially when low-grade, is challenging due to the infiltrative nature of the lesion. Currently, no real-time, intra-operative, label-free and wide-field tool is available to assist and guide the surgeon to find the relevant demarcations for these tumors. While marker-based methods exist for the high-grade glioma case, there is no convenient solution available for the low-grade case; thus, marker-free optical techniques represent an attractive option. Although RGB imaging is a standard tool in surgical microscopes, it does not contain sufficient information for tissue differentiation. We leverage the richer information from hyperspectral imaging (HSI), acquired with a snapscan camera in the 468-787 nm range, coupled to a surgical microscope, to build a deep-learning-based diagnostic tool for cancer resection with potential for intra-operative guidance. However, the main limitation of the HSI snapscan camera is the image acquisition time, limiting its widespread deployment in the operation theater. Here, we investigate the effect of HSI channel reduction and pre-selection to scope the design space for the development of cheaper and faster sensors. Neural networks are used to identify the most important spectral channels for tumor tissue differentiation, optimizing the trade-off between the number of channels and precision to enable real-time intra-surgical application. We evaluate the performance of our method on a clinical dataset that was acquired during surgery on five patients. By demonstrating the possibility to efficiently detect low-grade glioma, these results can lead to better cancer resection demarcations, potentially improving treatment effectiveness and patient outcome. ",
    "url": "https://arxiv.org/abs/2302.02884",
    "authors": [
      "Tommaso Giannantonio",
      "Anna Alperovich",
      "Piercosimo Semeraro",
      "Manfredo Atzori",
      "Xiaohan Zhang",
      "Christoph Hauger",
      "Alexander Freytag",
      "Siri Luthman",
      "Roeland Vandebriel",
      "Murali Jayapala",
      "Lien Solie",
      "Steven de Vleeschouwer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02923",
    "title": "In Search of Insights, Not Magic Bullets: Towards Demystification of the  Model Selection Dilemma in Heterogeneous Treatment Effect Estimation",
    "abstract": "Personalized treatment effect estimates are often of interest in high-stakes applications -- thus, before deploying a model estimating such effects in practice, one needs to be sure that the best candidate from the ever-growing machine learning toolbox for this task was chosen. Unfortunately, due to the absence of counterfactual information in practice, it is usually not possible to rely on standard validation metrics for doing so, leading to a well-known model selection dilemma in the treatment effect estimation literature. While some solutions have recently been investigated, systematic understanding of the strengths and weaknesses of different model selection criteria is still lacking. In this paper, instead of attempting to declare a global `winner', we therefore empirically investigate success- and failure modes of different selection criteria. We highlight that there is a complex interplay between selection strategies, candidate estimators and the DGP used for testing, and provide interesting insights into the relative (dis)advantages of different criteria alongside desiderata for the design of further illuminating empirical studies in this context. ",
    "url": "https://arxiv.org/abs/2302.02923",
    "authors": [
      "Alicia Curth",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2302.03014",
    "title": "Detection and Localization of Melanoma Skin Cancer in Histopathological  Whole Slide Images",
    "abstract": "Melanoma diagnosed and treated in its early stages can increase the survival rate. A projected increase in skin cancer incidents and a dearth of dermatopathologists have emphasized the need for computational pathology (CPATH) systems. CPATH systems with deep learning (DL) models have the potential to identify the presence of melanoma by exploiting underlying morphological and cellular features. This paper proposes a DL method to detect melanoma and distinguish between normal skin and benign/malignant melanocytic lesions in Whole Slide Images (WSI). Our method detects lesions with high accuracy and localizes them on a WSI to identify potential regions of interest for pathologists. Interestingly, our DL method relies on using a single CNN network to create localization maps first and use them to perform slide-level predictions to determine patients who have melanoma. Our best model provides favorable patch-wise classification results with a 0.992 F1 score and 0.99 sensitivity on unseen data. ",
    "url": "https://arxiv.org/abs/2302.03014",
    "authors": [
      "Neel Kanwal",
      "Roger Amundsen",
      "Helga Hardardottir",
      "Emiel A.M. Janssen",
      "Kjersti Engan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03018",
    "title": "DDM$^2$: Self-Supervised Diffusion MRI Denoising with Generative  Diffusion Models",
    "abstract": "Magnetic resonance imaging (MRI) is a common and life-saving medical imaging technique. However, acquiring high signal-to-noise ratio MRI scans requires long scan times, resulting in increased costs and patient discomfort, and decreased throughput. Thus, there is great interest in denoising MRI scans, especially for the subtype of diffusion MRI scans that are severely SNR-limited. While most prior MRI denoising methods are supervised in nature, acquiring supervised training datasets for the multitude of anatomies, MRI scanners, and scan parameters proves impractical. Here, we propose Denoising Diffusion Models for Denoising Diffusion MRI (DDM$^2$), a self-supervised denoising method for MRI denoising using diffusion denoising generative models. Our three-stage framework integrates statistic-based denoising theory into diffusion models and performs denoising through conditional generation. During inference, we represent input noisy measurements as a sample from an intermediate posterior distribution within the diffusion Markov chain. We conduct experiments on 4 real-world in-vivo diffusion MRI datasets and show that our DDM$^2$ demonstrates superior denoising performances ascertained with clinically-relevant visual qualitative and quantitative metrics. ",
    "url": "https://arxiv.org/abs/2302.03018",
    "authors": [
      "Tiange Xiang",
      "Mahmut Yurt",
      "Ali B Syed",
      "Kawin Setsompop",
      "Akshay Chaudhari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.03436",
    "title": "Euclidean-Norm-Induced Schatten-p Quasi-Norm Regularization for Low-Rank  Tensor Completion and Tensor Robust Principal Component Analysis",
    "abstract": " Comments: 43 pages; published by Transactions on Machine Learning Research, January 2023; this https URL ",
    "url": "https://arxiv.org/abs/2012.03436",
    "authors": [
      "Jicong Fan",
      "Lijun Ding",
      "Chengrun Yang",
      "Zhao Zhang",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2101.01298",
    "title": "A Taxonomy for Mining and Classifying Privacy Requirements in Issue  Reports",
    "abstract": " Comments: Accepted at Journal of Information and Software Technology ",
    "url": "https://arxiv.org/abs/2101.01298",
    "authors": [
      "Pattaraporn Sangaroonsilp",
      "Hoa Khanh Dam",
      "Morakot Choetkiertikul",
      "Chaiyong Ragkhitwetsagul",
      "Aditya Ghose"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2102.12305",
    "title": "Phragm\u00e9n's Voting Methods and Justified Representation",
    "abstract": " Comments: To be published in Mathematical Programming ",
    "url": "https://arxiv.org/abs/2102.12305",
    "authors": [
      "Markus Brill",
      "Rupert Freeman",
      "Svante Janson",
      "Martin Lackner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2103.11135",
    "title": "High Resolution Face Editing with Masked GAN Latent Code Optimization",
    "abstract": " Comments: Final ArXiv version. The paper has been accepted for publication in IEEE Transactions on Image Processing journal and will be published in 2023 ",
    "url": "https://arxiv.org/abs/2103.11135",
    "authors": [
      "Martin Pernu\u0161",
      "Vitomir \u0160truc",
      "Simon Dobri\u0161ek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.08748",
    "title": "Input Invex Neural Network",
    "abstract": " Comments: 42 pages, 23 figures ",
    "url": "https://arxiv.org/abs/2106.08748",
    "authors": [
      "Suman Sapkota",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2107.07737",
    "title": "EGC2: Enhanced Graph Classification with Easy Graph Compression",
    "abstract": " Comments: 33 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2107.07737",
    "authors": [
      "Jinyin Chen",
      "Haiyang Xiong",
      "Haibin Zhenga",
      "Dunjie Zhang",
      "Jian Zhang",
      "Mingwei Jia",
      "Yi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2108.07774",
    "title": "Are Code Review Processes Influenced by the Genders of the Participants?",
    "abstract": " Title: Are Code Review Processes Influenced by the Genders of the Participants? ",
    "url": "https://arxiv.org/abs/2108.07774",
    "authors": [
      "Sayma Sultana",
      "Amiangshu Bosu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2109.09367",
    "title": "Extending Bootstrap AMG for Clustering of Attributed Graphs",
    "abstract": " Comments: 32 pages, 12 figures, preprint ",
    "url": "https://arxiv.org/abs/2109.09367",
    "authors": [
      "Pasqua D'Ambra",
      "Panayot S. Vassilevski",
      "Luisa Cutillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2109.09941",
    "title": "The Theoretical Limit of Radar Target Detection",
    "abstract": " Comments: 26 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2109.09941",
    "authors": [
      "Dazhuan Xu",
      "Nan Wang",
      "Han Zhang",
      "Xiaolong Kong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2110.03260",
    "title": "An Uncertainty-aware Loss Function for Training Neural Networks with  Calibrated Predictions",
    "abstract": " Comments: 11 pages, 6 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2110.03260",
    "authors": [
      "Afshar Shamsi",
      "Hamzeh Asgharnezhad",
      "AmirReza Tajally",
      "Saeid Nahavandi",
      "Henry Leung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.05057",
    "title": "Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy  for Deep Learning?",
    "abstract": " Title: Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy  for Deep Learning? ",
    "url": "https://arxiv.org/abs/2110.05057",
    "authors": [
      "Guy Heller",
      "Ethan Fetaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2111.04964",
    "title": "On Representation Knowledge Distillation for Graph Neural Networks",
    "abstract": " Comments: IEEE Transactions on Neural Networks and Learning Representation (TNNLS), Special Issue on Deep Neural Networks for Graphs: Theory, Models, Algorithms and Applications ",
    "url": "https://arxiv.org/abs/2111.04964",
    "authors": [
      "Chaitanya K. Joshi",
      "Fayao Liu",
      "Xu Xun",
      "Jie Lin",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.08864",
    "title": "Adversarial Tradeoffs in Robust State Estimation",
    "abstract": " Comments: ACC 2023. V2: consolidated results for filtering, updated figures ",
    "url": "https://arxiv.org/abs/2111.08864",
    "authors": [
      "Thomas T.C.K. Zhang",
      "Bruce D. Lee",
      "Hamed Hassani",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2111.09666",
    "title": "CCSL: A Causal Structure Learning Method from Multiple Unknown  Environments",
    "abstract": " Title: CCSL: A Causal Structure Learning Method from Multiple Unknown  Environments ",
    "url": "https://arxiv.org/abs/2111.09666",
    "authors": [
      "Wei Chen",
      "Yunjin Wu",
      "Ruichu Cai",
      "Yueguo Chen",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.13675",
    "title": "Weakly-guided Self-supervised Pretraining for Temporal Activity  Detection",
    "abstract": " Comments: Published as a conference paper at AAAI 2023 ",
    "url": "https://arxiv.org/abs/2111.13675",
    "authors": [
      "Kumara Kahatapitiya",
      "Zhou Ren",
      "Haoxiang Li",
      "Zhenyu Wu",
      "Michael S. Ryoo",
      "Gang Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.02340",
    "title": "Scanpath Prediction on Information Visualisations",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2112.02340",
    "authors": [
      "Yao Wang",
      "Mihai B\u00e2ce",
      "Andreas Bulling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2112.09036",
    "title": "The Dual PC Algorithm and the Role of Gaussianity for Structure Learning  of Bayesian Networks",
    "abstract": " Title: The Dual PC Algorithm and the Role of Gaussianity for Structure Learning  of Bayesian Networks ",
    "url": "https://arxiv.org/abs/2112.09036",
    "authors": [
      "Enrico Giudice",
      "Jack Kuipers",
      "Giusi Moffa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2201.01134",
    "title": "Network Collaborator: Knowledge Transfer Between Network Reconstruction  and Community Detection",
    "abstract": " Comments: This work has been submitted to the IEEE TAI for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2201.01134",
    "authors": [
      "Kai Wu",
      "Chao Wang",
      "Junyuan Chen",
      "Jing Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.05575",
    "title": "Reasoning Through Memorization: Nearest Neighbor Knowledge Graph  Embeddings",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2201.05575",
    "authors": [
      "Ningyu Zhang",
      "Xin Xie",
      "Xiang Chen",
      "Yongheng Wang",
      "Xu Cheng",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11783",
    "title": "Boosting Exploration in Multi-Task Reinforcement Learning using  Adversarial Networks",
    "abstract": " Title: Boosting Exploration in Multi-Task Reinforcement Learning using  Adversarial Networks ",
    "url": "https://arxiv.org/abs/2201.11783",
    "authors": [
      "Ramnath Kumar",
      "Tristan Deleu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11808",
    "title": "LAP: An Attention-Based Module for Faithful Interpretation and Knowledge  Injection in Convolutional Neural Networks",
    "abstract": " Title: LAP: An Attention-Based Module for Faithful Interpretation and Knowledge  Injection in Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2201.11808",
    "authors": [
      "Rassa Ghavami Modegh",
      "Ahmad Salimi",
      "Alireza Dizaji",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12064",
    "title": "Multiscale Graph Comparison via the Embedded Laplacian Discrepancy",
    "abstract": " Title: Multiscale Graph Comparison via the Embedded Laplacian Discrepancy ",
    "url": "https://arxiv.org/abs/2201.12064",
    "authors": [
      "Edric Tam",
      "David Dunson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12220",
    "title": "Neural Optimal Transport",
    "abstract": " Title: Neural Optimal Transport ",
    "url": "https://arxiv.org/abs/2201.12220",
    "authors": [
      "Alexander Korotin",
      "Daniil Selikhanovych",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12670",
    "title": "SMGRL: Scalable Multi-resolution Graph Representation Learning",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2201.12670",
    "authors": [
      "Reza Namazi",
      "Elahe Ghalebi",
      "Sinead Williamson",
      "Hamidreza Mahyar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.00117",
    "title": "Continuous Forecasting via Neural Eigen Decomposition",
    "abstract": " Title: Continuous Forecasting via Neural Eigen Decomposition ",
    "url": "https://arxiv.org/abs/2202.00117",
    "authors": [
      "Stav Belogolovsky",
      "Ido Greenberg",
      "Danny Eitan",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.06553",
    "title": "Contrastive Learning for Automotive mmWave Radar Detection Points Based  Instance Segmentation",
    "abstract": " Comments: Accepted by IEEE ITSC 2022 ",
    "url": "https://arxiv.org/abs/2203.06553",
    "authors": [
      "Weiyi Xiong",
      "Jianan Liu",
      "Yuxuan Xia",
      "Tao Huang",
      "Bing Zhu",
      "Wei Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16365",
    "title": "IGRF-RFE: A Hybrid Feature Selection Method for MLP-based Network  Intrusion Detection on UNSW-NB15 Dataset",
    "abstract": " Comments: 26 pages ",
    "url": "https://arxiv.org/abs/2203.16365",
    "authors": [
      "Yuhua Yin",
      "Julian Jang-Jaccard",
      "Wen Xu",
      "Amardeep Singh",
      "Jinting Zhu",
      "Fariza Sabrina",
      "Jin Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.10018",
    "title": "NMA: Neural Multi-slot Auctions with Externalities for Online  Advertising",
    "abstract": " Comments: 10 pages, 3figures ",
    "url": "https://arxiv.org/abs/2205.10018",
    "authors": [
      "Guogang Liao",
      "Xuejian Li",
      "Ze Wang",
      "Fan Yang",
      "Muzhi Guan",
      "Bingqi Zhu",
      "Yongkang Wang",
      "Xingxing Wang",
      "Dong Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13496",
    "title": "Censored Quantile Regression Neural Networks for Distribution-Free  Survival Analysis",
    "abstract": " Comments: Published in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.13496",
    "authors": [
      "Tim Pearce",
      "Jong-Hyeon Jeong",
      "Yichen Jia",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15403",
    "title": "Neural Optimal Transport with General Cost Functionals",
    "abstract": " Title: Neural Optimal Transport with General Cost Functionals ",
    "url": "https://arxiv.org/abs/2205.15403",
    "authors": [
      "Arip Asadulaev",
      "Alexander Korotin",
      "Vage Egiazarian",
      "Petr Mokrov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02385",
    "title": "On Hamiltonian-Connected and Mycielski graphs",
    "abstract": " Title: On Hamiltonian-Connected and Mycielski graphs ",
    "url": "https://arxiv.org/abs/2206.02385",
    "authors": [
      "Ashok Kumar Das",
      "Indrajit Paul"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.02617",
    "title": "Individual Privacy Accounting for Differentially Private Stochastic  Gradient Descent",
    "abstract": " Title: Individual Privacy Accounting for Differentially Private Stochastic  Gradient Descent ",
    "url": "https://arxiv.org/abs/2206.02617",
    "authors": [
      "Da Yu",
      "Gautam Kamath",
      "Janardhan Kulkarni",
      "Tie-Yan Liu",
      "Jian Yin",
      "Huishuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02659",
    "title": "Robust Fine-Tuning of Deep Neural Networks with Hessian-based  Generalization Guarantees",
    "abstract": " Comments: 36 pages, 5 figures, 8 tables (Fixed typos). ICML 2022 ",
    "url": "https://arxiv.org/abs/2206.02659",
    "authors": [
      "Haotian Ju",
      "Dongyue Li",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.04798",
    "title": "A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs",
    "abstract": " Title: A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2206.04798",
    "authors": [
      "Zhaocheng Zhu",
      "Xinyu Yuan",
      "Mikhail Galkin",
      "Sophie Xhonneux",
      "Ming Zhang",
      "Maxime Gazeau",
      "Jian Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05480",
    "title": "CodeS: Towards Code Model Generalization Under Distribution Shift",
    "abstract": " Comments: accepted by ICSE'23-NIER ",
    "url": "https://arxiv.org/abs/2206.05480",
    "authors": [
      "Qiang Hu",
      "Yuejun Guo",
      "Xiaofei Xie",
      "Maxime Cordy",
      "Lei Ma",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.03408",
    "title": "Representation Learning in Continuous-Time Dynamic Signed Networks",
    "abstract": " Title: Representation Learning in Continuous-Time Dynamic Signed Networks ",
    "url": "https://arxiv.org/abs/2207.03408",
    "authors": [
      "Kartik Sharma",
      "Mohit Raghavendra",
      "Yeon Chang Lee",
      "Anand Kumar M",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07253",
    "title": "Single Shot Self-Reliant Scene Text Spotter by Decoupled yet  Collaborative Detection and Recognition",
    "abstract": " Title: Single Shot Self-Reliant Scene Text Spotter by Decoupled yet  Collaborative Detection and Recognition ",
    "url": "https://arxiv.org/abs/2207.07253",
    "authors": [
      "Jingjing Wu",
      "Pengyuan Lyu",
      "Guangming Lu",
      "Chengquan Zhang",
      "Kun Yao",
      "Wenjie Pei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.03705",
    "title": "Rate Splitting Multiple Access for Next Generation Cognitive Radio  Enabled LEO Satellite Networks",
    "abstract": " Comments: 32,9. arXiv admin note: substantial text overlap with arXiv:2208.02924 ",
    "url": "https://arxiv.org/abs/2208.03705",
    "authors": [
      "ali Ullah Khan",
      "Zain Ali",
      "Eva Lagunas",
      "Asad Mahmood",
      "Muhammad Asif",
      "Asim Ihsan",
      "Symeon Chatzinotas",
      "Bj\u00f6rn Ottersten",
      "Octavia A. Dobre"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.08025",
    "title": "AutoCAT: Reinforcement Learning for Automated Exploration of  Cache-Timing Attacks",
    "abstract": " Title: AutoCAT: Reinforcement Learning for Automated Exploration of  Cache-Timing Attacks ",
    "url": "https://arxiv.org/abs/2208.08025",
    "authors": [
      "Mulong Luo",
      "Wenjie Xiong",
      "Geunbae Lee",
      "Yueying Li",
      "Xiaomeng Yang",
      "Amy Zhang",
      "Yuandong Tian",
      "Hsien-Hsin S. Lee",
      "G. Edward Suh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2208.09224",
    "title": "SoMoFormer: Social-Aware Motion Transformer for Multi-Person Motion  Prediction",
    "abstract": " Title: SoMoFormer: Social-Aware Motion Transformer for Multi-Person Motion  Prediction ",
    "url": "https://arxiv.org/abs/2208.09224",
    "authors": [
      "Xiaogang Peng",
      "Yaodi Shen",
      "Haoran Wang",
      "Binling Nie",
      "Yigang Wang",
      "Zizhao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.00179",
    "title": "Universal Vision-Language Dense Retrieval: Learning A Unified  Representation Space for Multi-Modal Retrieval",
    "abstract": " Comments: Accepted by ICLR 2023 ",
    "url": "https://arxiv.org/abs/2209.00179",
    "authors": [
      "Zhenghao Liu",
      "Chenyan Xiong",
      "Yuanhuiyi Lv",
      "Zhiyuan Liu",
      "Ge Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2209.06994",
    "title": "PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on  Transformer",
    "abstract": " Comments: Accepted by ICRA 2023 ",
    "url": "https://arxiv.org/abs/2209.06994",
    "authors": [
      "Qibo Qiu",
      "Haiming Gao",
      "Wei Hua",
      "Gang Huang",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11395",
    "title": "Achieve the Minimum Width of Neural Networks for Universal Approximation",
    "abstract": " Comments: ICLR2023 camera ready ",
    "url": "https://arxiv.org/abs/2209.11395",
    "authors": [
      "Yongqiang Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14734",
    "title": "DiGress: Discrete Denoising diffusion for graph generation",
    "abstract": " Comments: 22 pages. Published as a conference paper at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2209.14734",
    "authors": [
      "Clement Vignac",
      "Igor Krawczuk",
      "Antoine Siraudin",
      "Bohan Wang",
      "Volkan Cevher",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00226",
    "title": "Towards Understanding and Mitigating Dimensional Collapse in  Heterogeneous Federated Learning",
    "abstract": " Comments: camera ready version of ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.00226",
    "authors": [
      "Yujun Shi",
      "Jian Liang",
      "Wenqing Zhang",
      "Vincent Y. F. Tan",
      "Song Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00635",
    "title": "Robust Empirical Risk Minimization with Tolerance",
    "abstract": " Comments: 22 pages, 1 figure, To appear at ALT'23 ",
    "url": "https://arxiv.org/abs/2210.00635",
    "authors": [
      "Robi Bhattacharjee",
      "Max Hopkins",
      "Akash Kumar",
      "Hantao Yu",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01213",
    "title": "Robust Active Distillation",
    "abstract": " Title: Robust Active Distillation ",
    "url": "https://arxiv.org/abs/2210.01213",
    "authors": [
      "Cenk Baykal",
      "Khoa Trinh",
      "Fotis Iliopoulos",
      "Gaurav Menghani",
      "Erik Vee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06331",
    "title": "RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims  on Social Media",
    "abstract": " Comments: To appear in the 17th Conference of the European Chapter of the Association for Computational Linguistics (EACL), 2023 ",
    "url": "https://arxiv.org/abs/2210.06331",
    "authors": [
      "Somin Wadhwa",
      "Vivek Khetan",
      "Silvio Amir",
      "Byron Wallace"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06742",
    "title": "H2RBox: Horizontal Box Annotation is All You Need for Oriented Object  Detection",
    "abstract": " Comments: 15 pages, 6 figures, 7 tables, accepted by ICLR 2023, the source code is available at this https URL and this https URL ",
    "url": "https://arxiv.org/abs/2210.06742",
    "authors": [
      "Xue Yang",
      "Gefan Zhang",
      "Wentong Li",
      "Xuehui Wang",
      "Yue Zhou",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07316",
    "title": "MTEB: Massive Text Embedding Benchmark",
    "abstract": " Comments: 24 pages, 14 tables, 6 figures ",
    "url": "https://arxiv.org/abs/2210.07316",
    "authors": [
      "Niklas Muennighoff",
      "Nouamane Tazi",
      "Lo\u00efc Magne",
      "Nils Reimers"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12809",
    "title": "Data Augmentation for Automated Essay Scoring using Transformer Models",
    "abstract": " Comments: Accepted at ICCMST 2022 ",
    "url": "https://arxiv.org/abs/2210.12809",
    "authors": [
      "Kshitij Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.01201",
    "title": "Human alignment of neural network representations",
    "abstract": " Comments: Accepted for publication at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2211.01201",
    "authors": [
      "Lukas Muttenthaler",
      "Jonas Dippel",
      "Lorenz Linhardt",
      "Robert A. Vandermeulen",
      "Simon Kornblith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.06870",
    "title": "Detecting Disengagement in Virtual Learning as an Anomaly using Temporal  Convolutional Network Autoencoder",
    "abstract": " Title: Detecting Disengagement in Virtual Learning as an Anomaly using Temporal  Convolutional Network Autoencoder ",
    "url": "https://arxiv.org/abs/2211.06870",
    "authors": [
      "Ali Abedi",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.06987",
    "title": "BiFSMNv2: Pushing Binary Neural Networks for Keyword Spotting to  Real-Network Performance",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2202.06483 ",
    "url": "https://arxiv.org/abs/2211.06987",
    "authors": [
      "Haotong Qin",
      "Xudong Ma",
      "Yifu Ding",
      "Xiaoyang Li",
      "Yang Zhang",
      "Zejun Ma",
      "Jiakai Wang",
      "Jie Luo",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.07377",
    "title": "Physics-Guided, Physics-Informed, and Physics-Encoded Neural Networks in  Scientific Computing",
    "abstract": " Title: Physics-Guided, Physics-Informed, and Physics-Encoded Neural Networks in  Scientific Computing ",
    "url": "https://arxiv.org/abs/2211.07377",
    "authors": [
      "Salah A Faroughi",
      "Nikhil Pawar",
      "Celio Fernandes",
      "Maziar Raissi",
      "Subasish Das",
      "Nima K. Kalantari",
      "Seyed Kourosh Mahjour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.07915",
    "title": "Backdoor Attacks on Time Series: A Generative Approach",
    "abstract": " Title: Backdoor Attacks on Time Series: A Generative Approach ",
    "url": "https://arxiv.org/abs/2211.07915",
    "authors": [
      "Yujing Jiang",
      "Xingjun Ma",
      "Sarah Monazam Erfani",
      "James Bailey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.07985",
    "title": "Blind Performance Prediction for Deep Learning Based Ultra-Massive MIMO  Channel Estimation",
    "abstract": " Comments: 6 pages, 3 figures, 1 table, accepted by IEEE ICC 2023 ",
    "url": "https://arxiv.org/abs/2211.07985",
    "authors": [
      "Wentao Yu",
      "Hengtao He",
      "Xianghao Yu",
      "Shenghui Song",
      "Jun Zhang",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.09925",
    "title": "FairMILE: A Multi-Level Framework for Fair and Scalable Graph  Representation Learning",
    "abstract": " Title: FairMILE: A Multi-Level Framework for Fair and Scalable Graph  Representation Learning ",
    "url": "https://arxiv.org/abs/2211.09925",
    "authors": [
      "Yuntian He",
      "Saket Gurukar",
      "Srinivasan Parthasarathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.11191",
    "title": "Correlative Preference Transfer with Hierarchical Hypergraph Network for  Multi-Domain Recommendation",
    "abstract": " Comments: Accepted by WWW 2023 research track. The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2211.11191",
    "authors": [
      "Zixuan Xu",
      "Penghui Wei",
      "Shaoguo Liu",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.11665",
    "title": "Representational dissimilarity metric spaces for stochastic neural  networks",
    "abstract": " Comments: Published as a conference paper at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2211.11665",
    "authors": [
      "Lyndon R. Duong",
      "Jingyang Zhou",
      "Josue Nassar",
      "Jules Berman",
      "Jeroen Olieslagers",
      "Alex H. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.12047",
    "title": "Convolutional Neural Generative Coding: Scaling Predictive Coding to  Natural Images",
    "abstract": " Comments: Revisions/updates, expanded appendix ",
    "url": "https://arxiv.org/abs/2211.12047",
    "authors": [
      "Alexander Ororbia",
      "Ankur Mali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12714",
    "title": "Developmental Plasticity-inspired Adaptive Pruning for Deep Spiking and  Artificial Neural Networks",
    "abstract": " Title: Developmental Plasticity-inspired Adaptive Pruning for Deep Spiking and  Artificial Neural Networks ",
    "url": "https://arxiv.org/abs/2211.12714",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Yi Zeng",
      "Guobin Shen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14296",
    "title": "A System for Morphology-Task Generalization via Unified Representation  and Behavior Distillation",
    "abstract": " Comments: Accepted at ICLR2023 (notable-top-25%), Website: this https URL ",
    "url": "https://arxiv.org/abs/2211.14296",
    "authors": [
      "Hiroki Furuta",
      "Yusuke Iwasawa",
      "Yutaka Matsuo",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.15081",
    "title": "Flip Initial Features: Generalization of Neural Networks Under Sparse  Features for Semi-supervised Node Classification",
    "abstract": " Title: Flip Initial Features: Generalization of Neural Networks Under Sparse  Features for Semi-supervised Node Classification ",
    "url": "https://arxiv.org/abs/2211.15081",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chong-Kwon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01944",
    "title": "Learning Automata-Based Task Knowledge Representation from Large-Scale  Generative Language Models",
    "abstract": " Title: Learning Automata-Based Task Knowledge Representation from Large-Scale  Generative Language Models ",
    "url": "https://arxiv.org/abs/2212.01944",
    "authors": [
      "Yunhao Yang",
      "Jean-Rapha\u00ebl Gaglione",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.03853",
    "title": "Clustering with Neural Network and Index",
    "abstract": " Title: Clustering with Neural Network and Index ",
    "url": "https://arxiv.org/abs/2212.03853",
    "authors": [
      "Gangli Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09060",
    "title": "Parsing as a lifting problem and the Chomsky-Sch\u00fctzenberger  representation theorem",
    "abstract": " Comments: reformatted for publication in ENTICS, proceedings of MFPS 2022 ",
    "url": "https://arxiv.org/abs/2212.09060",
    "authors": [
      "Paul-Andr\u00e9 Melli\u00e8s",
      "Noam Zeilberger"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2212.12130",
    "title": "Learning to Detect and Segment for Open Vocabulary Object Detection",
    "abstract": " Comments: code will be available later ",
    "url": "https://arxiv.org/abs/2212.12130",
    "authors": [
      "Tao Wang",
      "Nan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.13425",
    "title": "GEDI: GEnerative and DIscriminative Training for Self-Supervised  Learning",
    "abstract": " Comments: Fixed typos/cleaned the experimental section ",
    "url": "https://arxiv.org/abs/2212.13425",
    "authors": [
      "Emanuele Sansone",
      "Robin Manhaeve"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00106",
    "title": "Physics-informed Neural Networks approach to solve the Blasius function",
    "abstract": " Title: Physics-informed Neural Networks approach to solve the Blasius function ",
    "url": "https://arxiv.org/abs/2301.00106",
    "authors": [
      "Greeshma Krishna",
      "Malavika S Nair",
      "Pramod P Nair",
      "Anil Lal S"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2301.00503",
    "title": "A Concept Knowledge Graph for User Next Intent Prediction at Alipay",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2301.00503",
    "authors": [
      "Yacheng He",
      "Qianghuai Jia",
      "Lin Yuan",
      "Ruopeng Li",
      "Yixin Ou",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00982",
    "title": "Analogical Inference Enhanced Knowledge Graph Embedding",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2301.00982",
    "authors": [
      "Zhen Yao",
      "Wen Zhang",
      "Mingyang Chen",
      "Yufeng Huang",
      "Yi Yang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.03944",
    "title": "CHRONOS: Time-Aware Zero-Shot Identification of Libraries from  Vulnerability Reports",
    "abstract": " Comments: 13 pages, 5 figures, published to ICSE ",
    "url": "https://arxiv.org/abs/2301.03944",
    "authors": [
      "Yunbo Lyu",
      "Thanh Le-Cong",
      "Hong Jin Kang",
      "Ratnadira Widyasari",
      "Zhipeng Zhao",
      "Xuan-Bach D. Le",
      "Ming Li",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.04746",
    "title": "Switchable Lightweight Anti-symmetric Processing (SLAP) with CNN  Outspeeds Data Augmentation by Smaller Sample -- Application in Gomoku  Reinforcement Learning",
    "abstract": " Comments: Add co-author and enrich discussion; 6 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2301.04746",
    "authors": [
      "Chi-Hang Suen",
      "Eduardo Alonso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.06732",
    "title": "Coronal Hole Analysis and Prediction using Computer Vision and LSTM  Neural Network",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2301.06732",
    "authors": [
      "Juyoung Yun"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Space Physics (physics.space-ph)"
    ]
  },
  {
    "id": "arXiv:2301.08209",
    "title": "GIPA: A General Information Propagation Algorithm for Graph Learning",
    "abstract": " Comments: Accepted by DASFAA2023. arXiv admin note: substantial text overlap with arXiv:2105.06035 ",
    "url": "https://arxiv.org/abs/2301.08209",
    "authors": [
      "Houyi Li",
      "Zhihong Chen",
      "Zhao Li",
      "Qinkai Zheng",
      "Peng Zhang",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.08693",
    "title": "Self-supervised learning for a nonlinear inverse problem with forward  operator involving an unknown function arising in photoacoustic tomography",
    "abstract": " Title: Self-supervised learning for a nonlinear inverse problem with forward  operator involving an unknown function arising in photoacoustic tomography ",
    "url": "https://arxiv.org/abs/2301.08693",
    "authors": [
      "Gyeongha Hwang",
      "Gihyeon Jeon",
      "Sunghwan Moon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.09479",
    "title": "Modality-Agnostic Variational Compression of Implicit Neural  Representations",
    "abstract": " Title: Modality-Agnostic Variational Compression of Implicit Neural  Representations ",
    "url": "https://arxiv.org/abs/2301.09479",
    "authors": [
      "Jonathan Richard Schwarz",
      "Jihoon Tack",
      "Yee Whye Teh",
      "Jaeho Lee",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.09489",
    "title": "Contracting Skeletal Kinematic Embeddings for Anomaly Detection",
    "abstract": " Comments: Submitted to Patter Recognition Journal ",
    "url": "https://arxiv.org/abs/2301.09489",
    "authors": [
      "Alessandro Flaborea",
      "Guido D'Amely",
      "Stefano D'Arrigo",
      "Marco Aurelio Sterpa",
      "Alessio Sampieri",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.10405",
    "title": "Editing Language Model-based Knowledge Graph Embeddings",
    "abstract": " Comments: Work in progress and the project website is this https URL ",
    "url": "https://arxiv.org/abs/2301.10405",
    "authors": [
      "Siyuan Cheng",
      "Ningyu Zhang",
      "Bozhong Tian",
      "Zelin Dai",
      "Feiyu Xiong",
      "Wei Guo",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.10481",
    "title": "FewShotTextGCN: K-hop neighborhood regularization for few-shot learning  on graphs",
    "abstract": " Comments: 8 pages, 4 figures, EACL 2023 ",
    "url": "https://arxiv.org/abs/2301.10481",
    "authors": [
      "Niels van der Heijden",
      "Ekaterina Shutova",
      "Helen Yannakoudakis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.10908",
    "title": "Distilling Cognitive Backdoor Patterns within an Image",
    "abstract": " Comments: ICLR2023 ",
    "url": "https://arxiv.org/abs/2301.10908",
    "authors": [
      "Hanxun Huang",
      "Xingjun Ma",
      "Sarah Erfani",
      "James Bailey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11223",
    "title": "CitationSum: Citation-aware Graph Contrastive Learning for Scientific  Paper Summarization",
    "abstract": " Comments: accepted to WWW2023 ",
    "url": "https://arxiv.org/abs/2301.11223",
    "authors": [
      "Zheheng Luo",
      "Qianqian Xie",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2301.11490",
    "title": "Neural Episodic Control with State Abstraction",
    "abstract": " Title: Neural Episodic Control with State Abstraction ",
    "url": "https://arxiv.org/abs/2301.11490",
    "authors": [
      "Zhuo Li",
      "Derui Zhu",
      "Yujing Hu",
      "Xiaofei Xie",
      "Lei Ma",
      "Yan Zheng",
      "Yan Song",
      "Yingfeng Chen",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.11857",
    "title": "Policy-Value Alignment and Robustness in Search-based Multi-Agent  Learning",
    "abstract": " Comments: 9 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2301.11857",
    "authors": [
      "Niko A. Grupen",
      "Michael Hanlon",
      "Alexis Hao",
      "Daniel D. Lee",
      "Bart Selman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2301.11956",
    "title": "On the Connection Between MPNN and Graph Transformer",
    "abstract": " Title: On the Connection Between MPNN and Graph Transformer ",
    "url": "https://arxiv.org/abs/2301.11956",
    "authors": [
      "Chen Cai",
      "Truong Son Hy",
      "Rose Yu",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12348",
    "title": "Demystifying Privacy Policy of Third-Party Libraries in Mobile Apps",
    "abstract": " Title: Demystifying Privacy Policy of Third-Party Libraries in Mobile Apps ",
    "url": "https://arxiv.org/abs/2301.12348",
    "authors": [
      "Kaifa Zhao",
      "Xian Zhan",
      "Le Yu",
      "Shiyao Zhou",
      "Hao Zhou",
      "Xiapu Luo",
      "Haoyu Wang",
      "Yepang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12458",
    "title": "Self-supervised Semi-implicit Graph Variational Auto-encoders with  Masking",
    "abstract": " Comments: Accepted by WebConf 2023 ",
    "url": "https://arxiv.org/abs/2301.12458",
    "authors": [
      "Xiang Li",
      "Tiandi Ye",
      "Caihua Shan",
      "Dongsheng Li",
      "Ming Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12487",
    "title": "Mitigating Adversarial Effects of False Data Injection Attacks in Power  Grid",
    "abstract": " Title: Mitigating Adversarial Effects of False Data Injection Attacks in Power  Grid ",
    "url": "https://arxiv.org/abs/2301.12487",
    "authors": [
      "Farhin Farhad Riya",
      "Shahinul Hoque",
      "Jinyuan Stella Sun",
      "Jiangnan Li",
      "Hairong Qi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12576",
    "title": "Uncovering Adversarial Risks of Test-Time Adaptation",
    "abstract": " Title: Uncovering Adversarial Risks of Test-Time Adaptation ",
    "url": "https://arxiv.org/abs/2301.12576",
    "authors": [
      "Tong Wu",
      "Feiran Jia",
      "Xiangyu Qi",
      "Jiachen T. Wang",
      "Vikash Sehwag",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12868",
    "title": "On Robustness of Prompt-based Semantic Parsing with Large Pre-trained  Language Model: An Empirical Study on Codex",
    "abstract": " Comments: Accepted at EACL2023 (main) ",
    "url": "https://arxiv.org/abs/2301.12868",
    "authors": [
      "Terry Yue Zhuo",
      "Zhuang Li",
      "Yujin Huang",
      "Fatemeh Shiri",
      "Weiqing Wang",
      "Gholamreza Haffari",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.00394",
    "title": "Toward a consistent performance evaluation for defect prediction models",
    "abstract": " Comments: 47 pages, 15 pages ",
    "url": "https://arxiv.org/abs/2302.00394",
    "authors": [
      "Xutong Liu",
      "Shiran Liu",
      "Zhaoqiang Guo",
      "Peng Zhag",
      "Yibiao Yang",
      "Huihui Liu",
      "Hongmin Lu",
      "Yanhui Li",
      "Lin Chen",
      "Yuming Zhou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.00633",
    "title": "Deep Dependency Networks for Multi-Label Classification",
    "abstract": " Title: Deep Dependency Networks for Multi-Label Classification ",
    "url": "https://arxiv.org/abs/2302.00633",
    "authors": [
      "Shivvrat Arya",
      "Yu Xiang",
      "Vibhav Gogate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.00773",
    "title": "Neural Networks for Symbolic Regression",
    "abstract": " Title: Neural Networks for Symbolic Regression ",
    "url": "https://arxiv.org/abs/2302.00773",
    "authors": [
      "Ji\u0159\u00ed Kubal\u00edk",
      "Erik Derner",
      "Robert Babu\u0161ka"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.00942",
    "title": "Efficient Graph Field Integrators Meet Point Clouds",
    "abstract": " Title: Efficient Graph Field Integrators Meet Point Clouds ",
    "url": "https://arxiv.org/abs/2302.00942",
    "authors": [
      "Krzysztof Choromanski",
      "Arijit Sehanobish",
      "Han Lin",
      "Yunfan Zhao",
      "Eli Berger",
      "Tetiana Parshakova",
      "Alvin Pan",
      "David Watkins",
      "Tianyi Zhang",
      "Valerii Likhosherstov",
      "Somnath Basu Roy Chowdhury",
      "Avinava Dubey",
      "Deepali Jain",
      "Tamas Sarlos",
      "Snigdha Chaturvedi",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00956",
    "title": "Resilient Binary Neural Network",
    "abstract": " Comments: AAAI 2023 Oral ",
    "url": "https://arxiv.org/abs/2302.00956",
    "authors": [
      "Sheng Xu",
      "Yanjing Li",
      "Teli Ma",
      "Mingbao Lin",
      "Hao Dong",
      "Baochang Zhang",
      "Peng Gao",
      "Jinhu Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.00981",
    "title": "Predicting Molecule-Target Interaction by Learning Biomedical Network  and Molecule Representations",
    "abstract": " Comments: 9 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2102.01649 ",
    "url": "https://arxiv.org/abs/2302.00981",
    "authors": [
      "Jinjiang Guo",
      "Jie Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01115",
    "title": "PEPNet: Parameter and Embedding Personalized Network for Infusing with  Personalized Prior Information",
    "abstract": " Title: PEPNet: Parameter and Embedding Personalized Network for Infusing with  Personalized Prior Information ",
    "url": "https://arxiv.org/abs/2302.01115",
    "authors": [
      "Jianxin Chang",
      "Chenbin Zhang",
      "Yiqun Hui",
      "Dewei Leng",
      "Yanan Niu",
      "Yang Song",
      "Kun Gai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.01375",
    "title": "On the Robustness of Randomized Ensembles to Adversarial Perturbations",
    "abstract": " Title: On the Robustness of Randomized Ensembles to Adversarial Perturbations ",
    "url": "https://arxiv.org/abs/2302.01375",
    "authors": [
      "Hassan Dbouk",
      "Naresh R. Shanbhag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.01676",
    "title": "Show me your NFT and I tell you how it will perform: Multimodal  representation learning for NFT selling price prediction",
    "abstract": " Comments: Accepted paper at The ACM Web Conference 2023, April 30--May 04, 2023, Austin, Texas, USA ",
    "url": "https://arxiv.org/abs/2302.01676",
    "authors": [
      "Davide Costa",
      "Lucio La Cava",
      "Andrea Tagarelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.01736",
    "title": "Relating EEG to continuous speech using deep neural networks: a review",
    "abstract": " Title: Relating EEG to continuous speech using deep neural networks: a review ",
    "url": "https://arxiv.org/abs/2302.01736",
    "authors": [
      "Corentin Puffay",
      "Bernd Accou",
      "Lies Bollens",
      "Mohammad Jalilpour Monesi",
      "Jonas Vanthornhout",
      "Hugo Van hamme",
      "Tom Francart"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  }
]