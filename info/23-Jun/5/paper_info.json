[
  {
    "id": "arXiv:2306.01008",
    "title": "Credit Card Fraud Detection Using Asexual Reproduction Optimization",
    "abstract": "As the number of credit card users has increased, detecting fraud in this domain has become a vital issue. Previous literature has applied various supervised and unsupervised machine learning methods to find an effective fraud detection system. However, some of these methods require an enormous amount of time to achieve reasonable accuracy. In this paper, an Asexual Reproduction Optimization (ARO) approach was employed, which is a supervised method to detect credit card fraud. ARO refers to a kind of production in which one parent produces some offspring. By applying this method and sampling just from the majority class, the effectiveness of the classification is increased. A comparison to Artificial Immune Systems (AIS), which is one of the best methods implemented on current datasets, has shown that the proposed method is able to remarkably reduce the required training time and at the same time increase the recall that is important in fraud detection problems. The obtained results show that ARO achieves the best cost in a short time, and consequently, it can be considered a real-time fraud detection system. ",
    "url": "https://arxiv.org/abs/2306.01008",
    "authors": [
      "Anahita Farhang Ghahfarokhi",
      "Taha Mansouri",
      "Mohammad Reza Sadeghi Moghadam",
      "Nila Bahrambeik",
      "Ramin Yavari",
      "Mohammadreza Fani Sani"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01012",
    "title": "Graph-Level Embedding for Time-Evolving Graphs",
    "abstract": "Graph representation learning (also known as network embedding) has been extensively researched with varying levels of granularity, ranging from nodes to graphs. While most prior work in this area focuses on node-level representation, limited research has been conducted on graph-level embedding, particularly for dynamic or temporal networks. However, learning low-dimensional graph-level representations for dynamic networks is critical for various downstream graph retrieval tasks such as temporal graph similarity ranking, temporal graph isomorphism, and anomaly detection. In this paper, we present a novel method for temporal graph-level embedding that addresses this gap. Our approach involves constructing a multilayer graph and using a modified random walk with temporal backtracking to generate temporal contexts for the graph's nodes. We then train a \"document-level\" language model on these contexts to generate graph-level embeddings. We evaluate our proposed model on five publicly available datasets for the task of temporal graph similarity ranking, and our model outperforms baseline methods. Our experimental results demonstrate the effectiveness of our method in generating graph-level embeddings for dynamic networks. ",
    "url": "https://arxiv.org/abs/2306.01012",
    "authors": [
      "Lili Wang",
      "Chenghan Huang",
      "Weicheng Ma",
      "Xinyuan Cao",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.01028",
    "title": "ITR: A grammar-based graph compressor supporting fast neighborhood  queries",
    "abstract": "Neighborhood queries are the most common queries on graphs; thus, it is desirable to answer them efficiently on compressed data structures. We present a compression scheme called Incidence-Type-RePair (ITR) for graphs with labeled nodes and labeled edges based on RePair and apply the scheme to RDF graphs. We show that ITR speeds up neighborhood queries to only a few milliseconds and thereby outperforms existing solutions while providing a compression size comparable to existing RDF graph compressors. ",
    "url": "https://arxiv.org/abs/2306.01028",
    "authors": [
      "Enno Adler",
      "Stefan B\u00f6ttcher",
      "Rita Hartel"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2306.01058",
    "title": "Are Layout-Infused Language Models Robust to Layout Distribution Shifts?  A Case Study with Scientific Documents",
    "abstract": "Recent work has shown that infusing layout features into language models (LMs) improves processing of visually-rich documents such as scientific papers. Layout-infused LMs are often evaluated on documents with familiar layout features (e.g., papers from the same publisher), but in practice models encounter documents with unfamiliar distributions of layout features, such as new combinations of text sizes and styles, or new spatial configurations of textual elements. In this work we test whether layout-infused LMs are robust to layout distribution shifts. As a case study we use the task of scientific document structure recovery, segmenting a scientific paper into its structural categories (e.g., \"title\", \"caption\", \"reference\"). To emulate distribution shifts that occur in practice we re-partition the GROTOAP2 dataset. We find that under layout distribution shifts model performance degrades by up to 20 F1. Simple training strategies, such as increasing training diversity, can reduce this degradation by over 35% relative F1; however, models fail to reach in-distribution performance in any tested out-of-distribution conditions. This work highlights the need to consider layout distribution shifts during model evaluation, and presents a methodology for conducting such evaluations. ",
    "url": "https://arxiv.org/abs/2306.01058",
    "authors": [
      "Catherine Chen",
      "Zejiang Shen",
      "Dan Klein",
      "Gabriel Stanovsky",
      "Doug Downey",
      "Kyle Lo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01064",
    "title": "Characterizing the Cloud's Outbound Network Latency: An Experimental and  Modeling Study",
    "abstract": "Cloud latency has critical influences on the success of cloud applications. Therefore, characterizing cloud network performance is crucial for analyzing and satisfying different latency requirements. By focusing on the cloud's outbound network latency, this case study on Google App Engine confirms the necessity of optimizing application deployment. More importantly, our modeling effort has established a divide-and-conquer framework to address the complexity in understanding and investigating the cloud latency. ",
    "url": "https://arxiv.org/abs/2306.01064",
    "authors": [
      "Zheng Li",
      "Francisco Millar-Bilbao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2306.01072",
    "title": "MonArch: Network Slice Monitoring Architecture for Cloud Native 5G  Deployments",
    "abstract": "Automated decision making algorithms are expected to play a key role in management and orchestration of network slices in 5G and beyond networks. State-of-the-art algorithms for automated orchestration and management tend to rely on data-driven methods which require a timely and accurate view of the network. Accurately monitoring an end-to-end (E2E) network slice requires a scalable monitoring architecture that facilitates collection and correlation of data from various network segments comprising the slice. The state-of-the-art on 5G monitoring mostly focuses on scalability, falling short in providing explicit support for network slicing and computing network slice key performance indicators (KPIs). To fill this gap, in this paper, we present MonArch, a scalable monitoring architecture for 5G, which focuses on network slice monitoring, slice KPI computation, and an application programming interface (API) for specifying slice monitoring requests. We validate the proposed architecture by implementing MonArch on a 5G testbed, and demonstrate its capability to compute a network slice KPI (e.g., slice throughput). Our evaluations show that MonArch does not significantly increase data ingestion time when scaling the number of slices and that a 5-second monitoring interval offers a good balance between monitoring overhead and accuracy. ",
    "url": "https://arxiv.org/abs/2306.01072",
    "authors": [
      "Niloy Saha",
      "Nashid Shahriar",
      "Raouf Boutaba",
      "Aladdin Saleh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.01075",
    "title": "Pedestrian Crossing Action Recognition and Trajectory Prediction with 3D  Human Keypoints",
    "abstract": "Accurate understanding and prediction of human behaviors are critical prerequisites for autonomous vehicles, especially in highly dynamic and interactive scenarios such as intersections in dense urban areas. In this work, we aim at identifying crossing pedestrians and predicting their future trajectories. To achieve these goals, we not only need the context information of road geometry and other traffic participants but also need fine-grained information of the human pose, motion and activity, which can be inferred from human keypoints. In this paper, we propose a novel multi-task learning framework for pedestrian crossing action recognition and trajectory prediction, which utilizes 3D human keypoints extracted from raw sensor data to capture rich information on human pose and activity. Moreover, we propose to apply two auxiliary tasks and contrastive learning to enable auxiliary supervisions to improve the learned keypoints representation, which further enhances the performance of major tasks. We validate our approach on a large-scale in-house dataset, as well as a public benchmark dataset, and show that our approach achieves state-of-the-art performance on a wide range of evaluation metrics. The effectiveness of each model component is validated in a detailed ablation study. ",
    "url": "https://arxiv.org/abs/2306.01075",
    "authors": [
      "Jiachen Li",
      "Xinwei Shi",
      "Feiyu Chen",
      "Jonathan Stroud",
      "Zhishuai Zhang",
      "Tian Lan",
      "Junhua Mao",
      "Jeonhyung Kang",
      "Khaled S. Refaat",
      "Weilong Yang",
      "Eugene Ie",
      "Congcong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.01081",
    "title": "4DSR-GCN: 4D Video Point Cloud Upsampling using Graph Convolutional  Networks",
    "abstract": "Time varying sequences of 3D point clouds, or 4D point clouds, are now being acquired at an increasing pace in several applications (e.g., LiDAR in autonomous or assisted driving). In many cases, such volume of data is transmitted, thus requiring that proper compression tools are applied to either reduce the resolution or the bandwidth. In this paper, we propose a new solution for upscaling and restoration of time-varying 3D video point clouds after they have been heavily compressed. In consideration of recent growing relevance of 3D applications, %We focused on a model allowing user-side upscaling and artifact removal for 3D video point clouds, a real-time stream of which would require . Our model consists of a specifically designed Graph Convolutional Network (GCN) that combines Dynamic Edge Convolution and Graph Attention Networks for feature aggregation in a Generative Adversarial setting. By taking inspiration PointNet++, We present a different way to sample dense point clouds with the intent to make these modules work in synergy to provide each node enough features about its neighbourhood in order to later on generate new vertices. Compared to other solutions in the literature that address the same task, our proposed model is capable of obtaining comparable results in terms of quality of the reconstruction, while using a substantially lower number of parameters (about 300KB), making our solution deployable in edge computing devices such as LiDAR. ",
    "url": "https://arxiv.org/abs/2306.01081",
    "authors": [
      "Lorenzo Berlincioni",
      "Stefano Berretti",
      "Marco Bertini",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2306.01089",
    "title": "Semi-supervised Community Detection via Structural Similarity Metrics",
    "abstract": "Motivated by social network analysis and network-based recommendation systems, we study a semi-supervised community detection problem in which the objective is to estimate the community label of a new node using the network topology and partially observed community labels of existing nodes. The network is modeled using a degree-corrected stochastic block model, which allows for severe degree heterogeneity and potentially non-assortative communities. We propose an algorithm that computes a `structural similarity metric' between the new node and each of the $K$ communities by aggregating labeled and unlabeled data. The estimated label of the new node corresponds to the value of $k$ that maximizes this similarity metric. Our method is fast and numerically outperforms existing semi-supervised algorithms. Theoretically, we derive explicit bounds for the misclassification error and show the efficiency of our method by comparing it with an ideal classifier. Our findings highlight, to the best of our knowledge, the first semi-supervised community detection algorithm that offers theoretical guarantees. ",
    "url": "https://arxiv.org/abs/2306.01089",
    "authors": [
      "Yicong Jiang",
      "Tracy Ke"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01090",
    "title": "Improving the Robustness of Summarization Systems with Dual Augmentation",
    "abstract": "A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input. In this work, we first explore the summarization models' robustness against perturbations including word-level synonym substitution and noise. To create semantic-consistent substitutes, we propose a SummAttacker, which is an efficient approach to generating adversarial samples based on language models. Experimental results show that state-of-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first brittleness factor we found is the poor understanding of infrequent words in the input. Correspondingly, we feed the encoder with more diverse cases created by SummAttacker in the input space. The other factor is in the latent space, where the attacked inputs bring more variations to the hidden states. Hence, we construct adversarial decoder input and devise manifold softmixing operation in hidden space to introduce more diversity. Experimental results on Gigaword and CNN/DM datasets demonstrate that our approach achieves significant improvements over strong baselines and exhibits higher robustness on noisy, attacked, and clean datasets. ",
    "url": "https://arxiv.org/abs/2306.01090",
    "authors": [
      "Xiuying Chen",
      "Guodong Long",
      "Chongyang Tao",
      "Mingzhe Li",
      "Xin Gao",
      "Chengqi Zhang",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01095",
    "title": "Large-Batch, Neural Multi-Objective Bayesian Optimization",
    "abstract": "Bayesian optimization provides a powerful framework for global optimization of black-box, expensive-to-evaluate functions. However, it has a limited capacity in handling data-intensive problems, especially in multi-objective settings, due to the poor scalability of default Gaussian Process surrogates. We present a novel Bayesian optimization framework specifically tailored to address these limitations. Our method leverages a Bayesian neural networks approach for surrogate modeling. This enables efficient handling of large batches of data, modeling complex problems, and generating the uncertainty of the predictions. In addition, our method incorporates a scalable, uncertainty-aware acquisition strategy based on the well-known, easy-to-deploy NSGA-II. This fully parallelizable strategy promotes efficient exploration of uncharted regions. Our framework allows for effective optimization in data-intensive environments with a minimum number of iterations. We demonstrate the superiority of our method by comparing it with state-of-the-art multi-objective optimizations. We perform our evaluation on two real-world problems - airfoil design and color printing - showcasing the applicability and efficiency of our approach. Code is available at: https://github.com/an-on-ym-ous/lbn\\_mobo ",
    "url": "https://arxiv.org/abs/2306.01095",
    "authors": [
      "Navid Ansari",
      "Hans-Peter Seidel",
      "Vahid Babaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2306.01102",
    "title": "LLMatic: Neural Architecture Search via Large Language Models and  Quality-Diversity Optimization",
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools capable of accomplishing a broad spectrum of tasks. Their abilities span numerous areas, and one area where they have made a significant impact is in the domain of code generation. In this context, we view LLMs as mutation and crossover tools. Meanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and robust solutions. By merging the code-generating abilities of LLMs with the diversity and robustness of QD solutions, we introduce LLMatic, a Neural Architecture Search (NAS) algorithm. While LLMs struggle to conduct NAS directly through prompts, LLMatic uses a procedural approach, leveraging QD for prompts and network architecture to create diverse and highly performant networks. We test LLMatic on the CIFAR-10 image classification benchmark, demonstrating that it can produce competitive networks with just $2,000$ searches, even without prior knowledge of the benchmark domain or exposure to any previous top-performing models for the benchmark. ",
    "url": "https://arxiv.org/abs/2306.01102",
    "authors": [
      "Muhammad U. Nasir",
      "Sam Earle",
      "Julian Togelius",
      "Steven James",
      "Christopher Cleghorn"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01103",
    "title": "Joint Learning of Label and Environment Causal Independence for Graph  Out-of-Distribution Generalization",
    "abstract": "We tackle the problem of graph out-of-distribution (OOD) generalization. Existing graph OOD algorithms either rely on restricted assumptions or fail to exploit environment information in training data. In this work, we propose to simultaneously incorporate label and environment causal independence (LECI) to fully make use of label and environment information, thereby addressing the challenges faced by prior methods on identifying causal and invariant subgraphs. We further develop an adversarial training strategy to jointly optimize these two properties for casual subgraph discovery with theoretical guarantees. Extensive experiments and analysis show that LECI significantly outperforms prior methods on both synthetic and real-world datasets, establishing LECI as a practical and effective solution for graph OOD generalization. ",
    "url": "https://arxiv.org/abs/2306.01103",
    "authors": [
      "Shurui Gui",
      "Meng Liu",
      "Xiner Li",
      "Youzhi Luo",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01110",
    "title": "Comparative Study on the Effects of Noise in ML-Based Anxiety Detection",
    "abstract": "Wearable health devices are ushering in a new age of continuous and noninvasive remote monitoring. One application of this technology is in anxiety detection. Many advancements in anxiety detection have happened in controlled lab settings, but noise prevents these advancements from generalizing to real-world conditions. We seek to progress the field by studying how noise impacts model performance and developing models that are robust to noisy, real-world conditions and, hence, attuned to the commotion of everyday life. In this study we look to investigate why and how previous methods have failed. Using the wearable stress and affect detection (WESAD) dataset, we compare the effect of various intensities of noise on machine learning models classifying levels of physiological arousal in the three-class classification problem: baseline vs. stress vs. amusement. Before introducing noise, our baseline model performance reaches 98.7%, compared to Schmidt 2018's 80.3%. We discuss potential sources of this discrepancy in results through a careful evaluation of feature extraction and model architecture choices. Finally, after the introduction of noise, we provide a thorough analysis of the effect of noise on each model architecture. ",
    "url": "https://arxiv.org/abs/2306.01110",
    "authors": [
      "Samuel Schapiro",
      "Abdul Alkurdi",
      "Elizabeth Hsiao-Wecksler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.01117",
    "title": "Examining the Causal Effect of First Names on Language Models: The Case  of Social Commonsense Reasoning",
    "abstract": "As language models continue to be integrated into applications of personal and societal relevance, ensuring these models' trustworthiness is crucial, particularly with respect to producing consistent outputs regardless of sensitive attributes. Given that first names may serve as proxies for (intersectional) socio-demographic representations, it is imperative to examine the impact of first names on commonsense reasoning capabilities. In this paper, we study whether a model's reasoning given a specific input differs based on the first names provided. Our underlying assumption is that the reasoning about Alice should not differ from the reasoning about James. We propose and implement a controlled experimental framework to measure the causal effect of first names on commonsense reasoning, enabling us to distinguish between model predictions due to chance and caused by actual factors of interest. Our results indicate that the frequency of first names has a direct effect on model prediction, with less frequent names yielding divergent predictions compared to more frequent names. To gain insights into the internal mechanisms of models that are contributing to these behaviors, we also conduct an in-depth explainable analysis. Overall, our findings suggest that to ensure model robustness, it is essential to augment datasets with more diverse first names during the configuration stage. ",
    "url": "https://arxiv.org/abs/2306.01117",
    "authors": [
      "Sullam Jeoung",
      "Jana Diesner",
      "Halil Kilicoglu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01123",
    "title": "A Neural RDE-based model for solving path-dependent PDEs",
    "abstract": "The concept of the path-dependent partial differential equation (PPDE) was first introduced in the context of path-dependent derivatives in financial markets. Its semilinear form was later identified as a non-Markovian backward stochastic differential equation (BSDE). Compared to the classical PDE, the solution of a PPDE involves an infinite-dimensional spatial variable, making it challenging to approximate, if not impossible. In this paper, we propose a neural rough differential equation (NRDE)-based model to learn PPDEs, which effectively encodes the path information through the log-signature feature while capturing the fundamental dynamics. The proposed continuous-time model for the PPDE solution offers the benefits of efficient memory usage and the ability to scale with dimensionality. Several numerical experiments, provided to validate the performance of the proposed model in comparison to the strong baseline in the literature, are used to demonstrate its effectiveness. ",
    "url": "https://arxiv.org/abs/2306.01123",
    "authors": [
      "Bowen Fang",
      "Hao Ni",
      "Yue Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2306.01143",
    "title": "Federated Graph Learning for Low Probability of Detection in Wireless  Ad-Hoc Networks",
    "abstract": "Low probability of detection (LPD) has recently emerged as a means to enhance the privacy and security of wireless networks. Unlike existing wireless security techniques, LPD measures aim to conceal the entire existence of wireless communication instead of safeguarding the information transmitted from users. Motivated by LPD communication, in this paper, we study a privacy-preserving and distributed framework based on graph neural networks to minimise the detectability of a wireless ad-hoc network as a whole and predict an optimal communication region for each node in the wireless network, allowing them to communicate while remaining undetected from external actors. We also demonstrate the effectiveness of the proposed method in terms of two performance measures, i.e., mean absolute error and median absolute error. ",
    "url": "https://arxiv.org/abs/2306.01143",
    "authors": [
      "Sivaram Krishnan",
      "Jihong Park",
      "Subhash Sagar",
      "Gregory Sherman",
      "Benjamin Campbell",
      "Jinho Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.01147",
    "title": "Smooth Monotonic Networks",
    "abstract": "Monotonicity constraints are powerful regularizers in statistical modelling. They can support fairness in computer supported decision making and increase plausibility in data-driven scientific models. The seminal min-max (MM) neural network architecture ensures monotonicity, but often gets stuck in undesired local optima during training because of vanishing gradients. We propose a simple modification of the MM network using strictly-increasing smooth non-linearities that alleviates this problem. The resulting smooth min-max (SMM) network module inherits the asymptotic approximation properties from the MM architecture. It can be used within larger deep learning systems trained end-to-end. The SMM module is considerably simpler and less computationally demanding than state-of-the-art neural networks for monotonic modelling. Still, in our experiments, it compared favorably to alternative neural and non-neural approaches in terms of generalization performance. ",
    "url": "https://arxiv.org/abs/2306.01147",
    "authors": [
      "Christian Igel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01148",
    "title": "Addressing Discrepancies in Semantic and Visual Alignment in Neural  Networks",
    "abstract": "For the task of image classification, neural networks primarily rely on visual patterns. In robust networks, we would expect for visually similar classes to be represented similarly. We consider the problem of when semantically similar classes are visually dissimilar, and when visual similarity is present among non-similar classes. We propose a data augmentation technique with the goal of better aligning semantically similar classes with arbitrary (non-visual) semantic relationships. We leverage recent work in diffusion-based semantic mixing to generate semantic hybrids of two classes, and these hybrids are added to the training set as augmented data. We evaluate whether the method increases semantic alignment by evaluating model performance on adversarially perturbed data, with the idea that it should be easier for an adversary to switch one class to a similarly represented class. Results demonstrate that there is an increase in alignment of semantically similar classes when using our proposed data augmentation method. ",
    "url": "https://arxiv.org/abs/2306.01148",
    "authors": [
      "Natalie Abreu",
      "Nathan Vaska",
      "Victoria Helus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01154",
    "title": "The Law of Parsimony in Gradient Descent for Learning Deep Linear  Networks",
    "abstract": "Over the past few years, an extensively studied phenomenon in training deep networks is the implicit bias of gradient descent towards parsimonious solutions. In this work, we investigate this phenomenon by narrowing our focus to deep linear networks. Through our analysis, we reveal a surprising \"law of parsimony\" in the learning dynamics when the data possesses low-dimensional structures. Specifically, we show that the evolution of gradient descent starting from orthogonal initialization only affects a minimal portion of singular vector spaces across all weight matrices. In other words, the learning process happens only within a small invariant subspace of each weight matrix, despite the fact that all weight parameters are updated throughout training. This simplicity in learning dynamics could have significant implications for both efficient training and a better understanding of deep networks. First, the analysis enables us to considerably improve training efficiency by taking advantage of the low-dimensional structure in learning dynamics. We can construct smaller, equivalent deep linear networks without sacrificing the benefits associated with the wider counterparts. Second, it allows us to better understand deep representation learning by elucidating the linear progressive separation and concentration of representations from shallow to deep layers. We also conduct numerical experiments to support our theoretical results. The code for our experiments can be found at https://github.com/cjyaras/lawofparsimony. ",
    "url": "https://arxiv.org/abs/2306.01154",
    "authors": [
      "Can Yaras",
      "Peng Wang",
      "Wei Hu",
      "Zhihui Zhu",
      "Laura Balzano",
      "Qing Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01158",
    "title": "Augmented Modular Reinforcement Learning based on Heterogeneous  Knowledge",
    "abstract": "In order to mitigate some of the inefficiencies of Reinforcement Learning (RL), modular approaches composing different decision-making policies to derive agents capable of performing a variety of tasks have been proposed. The modules at the basis of these architectures are generally reusable, also allowing for \"plug-and-play\" integration. However, such solutions still lack the ability to process and integrate multiple types of information (knowledge), such as rules, sub-goals, and skills. We propose Augmented Modular Reinforcement Learning (AMRL) to address these limitations. This new framework uses an arbitrator to select heterogeneous modules and seamlessly incorporate different types of knowledge. Additionally, we introduce a variation of the selection mechanism, namely the Memory-Augmented Arbitrator, which adds the capability of exploiting temporal information. We evaluate the proposed mechanisms on established as well as new environments and benchmark them against prominent deep RL algorithms. Our results demonstrate the performance improvements that can be achieved by augmenting traditional modular RL with other forms of heterogeneous knowledge. ",
    "url": "https://arxiv.org/abs/2306.01158",
    "authors": [
      "Lorenz Wolf",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01160",
    "title": "Faster Causal Attention Over Large Sequences Through Sparse Flash  Attention",
    "abstract": "Transformer-based language models have found many diverse applications requiring them to process sequences of increasing length. For these applications, the causal self-attention -- which is the only component scaling quadratically w.r.t. the sequence length -- becomes a central concern. While many works have proposed schemes to sparsify the attention patterns and reduce the computational overhead of self-attention, those are often limited by implementations concerns and end up imposing a simple and static structure over the attention matrix. Conversely, implementing more dynamic sparse attentions often results in runtimes significantly slower than computing the full attention using the Flash implementation from Dao et al. (2022). We extend FlashAttention to accommodate a large class of attention sparsity patterns that, in particular, encompass key/query dropping and hashing-based attention. This leads to implementations with no computational complexity overhead and a multi-fold runtime speedup on top of FlashAttention. Even with relatively low degrees of sparsity, our method improves visibly upon FlashAttention as the sequence length increases. Without sacrificing perplexity, we increase the training speed of a transformer language model by $2.0\\times$ and $3.3\\times$ for sequences of respectively $8k$ and $16k$ tokens. ",
    "url": "https://arxiv.org/abs/2306.01160",
    "authors": [
      "Matteo Pagliardini",
      "Daniele Paliotta",
      "Martin Jaggi",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01163",
    "title": "A Multi-Modal Latent-Features based Service Recommendation System for  the Social Internet of Things",
    "abstract": "The Social Internet of Things (SIoT), is revolutionizing how we interact with our everyday lives. By adding the social dimension to connecting devices, the SIoT has the potential to drastically change the way we interact with smart devices. This connected infrastructure allows for unprecedented levels of convenience, automation, and access to information, allowing us to do more with less effort. However, this revolutionary new technology also brings an eager need for service recommendation systems. As the SIoT grows in scope and complexity, it becomes increasingly important for businesses and individuals, and SIoT objects alike to have reliable sources for products, services, and information that are tailored to their specific needs. Few works have been proposed to provide service recommendations for SIoT environments. However, these efforts have been confined to only focusing on modeling user-item interactions using contextual information, devices' SIoT relationships, and correlation social groups but these schemes do not account for latent semantic item-item structures underlying the sparse multi-modal contents in SIoT environment. In this paper, we propose a latent-based SIoT recommendation system that learns item-item structures and aggregates multiple modalities to obtain latent item graphs which are then used in graph convolutions to inject high-order affinities into item representations. Experiments showed that the proposed recommendation system outperformed state-of-the-art SIoT recommendation methods and validated its efficacy at mining latent relationships from multi-modal features. ",
    "url": "https://arxiv.org/abs/2306.01163",
    "authors": [
      "Amar Khelloufi",
      "Huansheng Ning",
      "Abdenacer Naouri",
      "Abdelkarim Ben Sada",
      "Attia Qammar",
      "Abdelkader Khalil",
      "Sahraoui Dhelim",
      "Lingfeng Mao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.01174",
    "title": "Neural Ideal Large Eddy Simulation: Modeling Turbulence with Neural  Stochastic Differential Equations",
    "abstract": "We introduce a data-driven learning framework that assimilates two powerful ideas: ideal large eddy simulation (LES) from turbulence closure modeling and neural stochastic differential equations (SDE) for stochastic modeling. The ideal LES models the LES flow by treating each full-order trajectory as a random realization of the underlying dynamics, as such, the effect of small-scales is marginalized to obtain the deterministic evolution of the LES state. However, ideal LES is analytically intractable. In our work, we use a latent neural SDE to model the evolution of the stochastic process and an encoder-decoder pair for transforming between the latent space and the desired ideal flow field. This stands in sharp contrast to other types of neural parameterization of closure models where each trajectory is treated as a deterministic realization of the dynamics. We show the effectiveness of our approach (niLES - neural ideal LES) on a challenging chaotic dynamical system: Kolmogorov flow at a Reynolds number of 20,000. Compared to competing methods, our method can handle non-uniform geometries using unstructured meshes seamlessly. In particular, niLES leads to trajectories with more accurate statistics and enhances stability, particularly for long-horizon rollouts. ",
    "url": "https://arxiv.org/abs/2306.01174",
    "authors": [
      "Anudhyan Boral",
      "Zhong Yi Wan",
      "Leonardo Zepeda-N\u00fa\u00f1ez",
      "James Lottes",
      "Qing Wang",
      "Yi-fan Chen",
      "John Roberts Anderson",
      "Fei Sha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.01177",
    "title": "The Effects of Varying Penetration Rates of L4-L5 Autonomous Vehicles on  Fuel Efficiency and Mobility of Traffic Networks",
    "abstract": "Microscopic traffic simulators that simulate realistic traffic flow are crucial in studying, understanding and evaluating the fuel usage and mobility effects of having a higher number of autonomous vehicles (AVs) in traffic under realistic mixed traffic conditions including both autonomous and non-autonomous vehicles. In this paper, L4-L5 AVs with varying penetration rates in total traffic flow were simulated using the microscopic traffic simulator Vissim on urban, mixed and freeway roadways. The roadways used in these simulations were replicas of real roadways in and around Columbus, Ohio, including an AV shuttle routes in operation. The road-specific information regarding each roadway, such as the number of traffic lights and positions, number of STOP signs and positions, and speed limits, were gathered using OpenStreetMap with SUMO. In simulating L4-L5 AVs, the All-Knowing CoEXist AV and a vehicle with Wiedemann 74 driver were taken to represent AV and non-AV driving, respectively. Then, the driving behaviors, such as headway time and car following, desired acceleration and deceleration profiles of AV, and non-AV car following and lane change models were modified. The effect of having varying penetration rates of L4-L5 AVs were then evaluated using criteria such as average fuel consumption, existence of queues and their average/maximum length, total number of vehicles in the simulation, average delay experience by all vehicles, total number of stops experienced by all vehicles, and total emission of CO, NOx and volatile organic compounds (VOC) from the vehicles in the simulation. The results show that while increasing penetration rates of L4-L5 AVs generally improve overall fuel efficiency and mobility of the traffic network, there were also cases when the opposite trend was observed. ",
    "url": "https://arxiv.org/abs/2306.01177",
    "authors": [
      "Ozgenur Kavas-Torris",
      "M. Ridvan Cantas",
      "Karina Meneses Cime",
      "Bilin Aksun-Guvenc",
      "Levent Guvenc"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.01186",
    "title": "Labeled Interleaving Distance for Reeb Graphs",
    "abstract": "Merge trees, contour trees, and Reeb graphs are graph-based topological descriptors that capture topological changes of (sub)level sets of scalar fields. Comparing scalar fields using their topological descriptors has many applications in topological data analysis and visualization of scientific data. Recently, Munch and Stefanou introduced a labeled interleaving distance for comparing two labeled merge trees, which enjoys a number of theoretical and algorithmic properties. In particular, the labeled interleaving distance between merge trees can be computed in polynomial time. In this work, we define the labeled interleaving distance for labeled Reeb graphs. We then prove that the (ordinary) interleaving distance between Reeb graphs equals the minimum of the labeled interleaving distance over all labelings. We also provide an efficient algorithm for computing the labeled interleaving distance between two labeled contour trees (which are special types of Reeb graphs that arise from simply-connected domains). In the case of merge trees, the notion of the labeled interleaving distance was used by Gasparovic et al. to prove that the (ordinary) interleaving distance on the set of (unlabeled) merge trees is intrinsic. As our final contribution, we present counterexamples showing that, on the contrary, the (ordinary) interleaving distance on (unlabeled) Reeb graphs (and contour trees) is not intrinsic. It turns out that, under mild conditions on the labelings, the labeled interleaving distance is a metric on isomorphism classes of Reeb graphs, analogous to the ordinary interleaving distance. This provides new metrics on large classes of Reeb graphs. ",
    "url": "https://arxiv.org/abs/2306.01186",
    "authors": [
      "Fangfei Lan",
      "Salman Parsa",
      "Bei Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2306.01187",
    "title": "Training neural operators to preserve invariant measures of chaotic  attractors",
    "abstract": "Chaotic systems make long-horizon forecasts difficult because small perturbations in initial conditions cause trajectories to diverge at an exponential rate. In this setting, neural operators trained to minimize squared error losses, while capable of accurate short-term forecasts, often fail to reproduce statistical or structural properties of the dynamics over longer time horizons and can yield degenerate results. In this paper, we propose an alternative framework designed to preserve invariant measures of chaotic attractors that characterize the time-invariant statistical properties of the dynamics. Specifically, in the multi-environment setting (where each sample trajectory is governed by slightly different dynamics), we consider two novel approaches to training with noisy data. First, we propose a loss based on the optimal transport distance between the observed dynamics and the neural operator outputs. This approach requires expert knowledge of the underlying physics to determine what statistical features should be included in the optimal transport loss. Second, we show that a contrastive learning framework, which does not require any specialized prior knowledge, can preserve statistical properties of the dynamics nearly as well as the optimal transport approach. On a variety of chaotic systems, our method is shown empirically to preserve invariant measures of chaotic attractors. ",
    "url": "https://arxiv.org/abs/2306.01187",
    "authors": [
      "Ruoxi Jiang",
      "Peter Y. Lu",
      "Elena Orlova",
      "Rebecca Willett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2306.01189",
    "title": "A General Framework for Uncertainty Quantification via Neural SDE-RNN",
    "abstract": "Uncertainty quantification is a critical yet unsolved challenge for deep learning, especially for the time series imputation with irregularly sampled measurements. To tackle this problem, we propose a novel framework based on the principles of recurrent neural networks and neural stochastic differential equations for reconciling irregularly sampled measurements. We impute measurements at any arbitrary timescale and quantify the uncertainty in the imputations in a principled manner. Specifically, we derive analytical expressions for quantifying and propagating the epistemic and aleatoric uncertainty across time instants. Our experiments on the IEEE 37 bus test distribution system reveal that our framework can outperform state-of-the-art uncertainty quantification approaches for time-series data imputations. ",
    "url": "https://arxiv.org/abs/2306.01189",
    "authors": [
      "Shweta Dahale",
      "Sai Munikoti",
      "Balasubramaniam Natarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01191",
    "title": "Conformal Prediction with Partially Labeled Data",
    "abstract": "While the predictions produced by conformal prediction are set-valued, the data used for training and calibration is supposed to be precise. In the setting of superset learning or learning from partial labels, a variant of weakly supervised learning, it is exactly the other way around: training data is possibly imprecise (set-valued), but the model induced from this data yields precise predictions. In this paper, we combine the two settings by making conformal prediction amenable to set-valued training data. We propose a generalization of the conformal prediction procedure that can be applied to set-valued training and calibration data. We prove the validity of the proposed method and present experimental studies in which it compares favorably to natural baselines. ",
    "url": "https://arxiv.org/abs/2306.01191",
    "authors": [
      "Alireza Javanmardi",
      "Yusuf Sale",
      "Paul Hofman",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01203",
    "title": "Optimal Path Planning in Distinct Topo-Geometric Classes using  Neighborhood-augmented Graph and its Application to Path Planning for a  Tethered Robot in 3D",
    "abstract": "Many robotics applications benefit from being able to compute multiple locally optimal paths in a given configuration space. Examples include path planning for of tethered robots with cable-length constraints, systems involving cables, multi-robot topological exploration & coverage, and, congestion reduction for mobile robots navigation without inter-robot coordination. Existing paradigm is to use topological path planning methods that can provide optimal paths from distinct topological classes available in the underlying configuration space. However, these methods usually require non-trivial and non-universal geometrical constructions, which are prohibitively complex or expensive in 3 or higher dimensional configuration spaces with complex topology. Furthermore, topological methods are unable to distinguish between locally optimal paths that belong to the same topological class but are distinct because of genus-zero obstacles in 3D or due to high-cost or high-curvature regions. In this paper we propose an universal and generalized approach to multi-class path planning using the concept of a novel neighborhood-augmented graph, search-based planning in which can compute paths in distinct topo-geometric classes. This approach can find desired number of locally optimal paths in a wider variety of configuration spaces without requiring any complex pre-processing or geometric constructions. Unlike the existing topological methods, resulting optimal paths are not restricted to distinct topological classes, thus making the algorithm applicable to many other problems where locally optimal and geometrically distinct paths are of interest. For the demonstration of an application of the proposed approach, we implement our algorithm to planning for shortest traversible paths for a tethered robot with cable-length constraint navigating in 3D and validate it in simulations & experiments. ",
    "url": "https://arxiv.org/abs/2306.01203",
    "authors": [
      "Alp Sahin",
      "Subhrajit Bhattacharya"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.01204",
    "title": "Physics-informed UNets for Discovering Hidden Elasticity in  Heterogeneous Materials",
    "abstract": "Soft biological tissues often have complex mechanical properties due to variation in structural components. In this paper, we develop a novel UNet-based neural network model for inversion in elasticity (El-UNet) to infer the spatial distributions of mechanical parameters from strain maps as input images, normal stress boundary conditions, and domain physics information. We show superior performance, both in terms of accuracy and computational cost, by El-UNet compared to fully-connected physics-informed neural networks in estimating unknown parameters and stress distributions for isotropic linear elasticity. We characterize different variations of El-UNet and propose a self-adaptive spatial loss weighting approach. To validate our inversion models, we performed various finite-element simulations of isotropic domains with heterogenous distributions of material parameters to generate synthetic data. El-UNet is faster and more accurate than the fully-connected physics-informed implementation in resolving the distribution of unknown fields. Among the tested models, the self-adaptive spatially weighted models had the most accurate reconstructions in equal computation times. The learned spatial weighting distribution visibly corresponded to regions that the unweighted models were resolving inaccurately. Our work demonstrates a computationally efficient inversion algorithm for elasticity imaging using convolutional neural networks and presents a potential fast framework for three-dimensional inverse elasticity problems that have proven unachievable through previously proposed methods. ",
    "url": "https://arxiv.org/abs/2306.01204",
    "authors": [
      "Ali Kamali",
      "Kaveh Laksari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Soft Condensed Matter (cond-mat.soft)"
    ]
  },
  {
    "id": "arXiv:2306.01213",
    "title": "Learning Causally Disentangled Representations via the Principle of  Independent Causal Mechanisms",
    "abstract": "Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior that utilizes the known causal structure to encourage learning a causally factorized distribution in the latent space. Under relatively mild conditions, we provide theoretical results showing the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demonstrate that our framework induces highly disentangled causal factors, improves interventional robustness, and is compatible with counterfactual generation. ",
    "url": "https://arxiv.org/abs/2306.01213",
    "authors": [
      "Aneesh Komanduri",
      "Yongkai Wu",
      "Feng Chen",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01218",
    "title": "Predicting affinity ties in a surname network",
    "abstract": "From administrative registers of last names in Santiago, Chile, we create a surname affinity network that encodes socioeconomic data. This network is a multi-relational graph with nodes representing surnames and edges representing the prevalence of interactions between surnames by socioeconomic decile. We model the prediction of links as a knowledge base completion problem, and find that sharing neighbors is highly predictive of the formation of new links. Importantly, We distinguish between grounded neighbors and neighbors in the embedding space, and find that the latter is more predictive of tie formation. The paper discusses the implications of this finding in explaining the high levels of elite endogamy in Santiago. ",
    "url": "https://arxiv.org/abs/2306.01218",
    "authors": [
      "Marcelo Mendoza",
      "Naim Bro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01220",
    "title": "Is Model Attention Aligned with Human Attention? An Empirical Study on  Large Language Models for Code Generation",
    "abstract": "Large Language Models (LLMs) have been demonstrated effective for code generation. Due to the complexity and opacity of LLMs, little is known about how these models generate code. To deepen our understanding, we investigate whether LLMs attend to the same parts of a natural language description as human programmers during code generation. An analysis of five LLMs on a popular benchmark, HumanEval, revealed a consistent misalignment between LLMs' and programmers' attention. Furthermore, we found that there is no correlation between the code generation accuracy of LLMs and their alignment with human programmers. Through a quantitative experiment and a user study, we confirmed that, among twelve different attention computation methods, attention computed by the perturbation-based method is most aligned with human attention and is constantly favored by human programmers. Our findings highlight the need for human-aligned LLMs for better interpretability and programmer trust. ",
    "url": "https://arxiv.org/abs/2306.01220",
    "authors": [
      "Bonan Kou",
      "Shengmai Chen",
      "Zhijie Wang",
      "Lei Ma",
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01240",
    "title": "Federated Learning of Models Pre-Trained on Different Features with  Consensus Graphs",
    "abstract": "Learning an effective global model on private and decentralized datasets has become an increasingly important challenge of machine learning when applied in practice. Existing distributed learning paradigms, such as Federated Learning, enable this via model aggregation which enforces a strong form of modeling homogeneity and synchronicity across clients. This is however not suitable to many practical scenarios. For example, in distributed sensing, heterogeneous sensors reading data from different views of the same phenomenon would need to use different models for different data modalities. Local learning therefore happens in isolation but inference requires merging the local models to achieve consensus. To enable consensus among local models, we propose a feature fusion approach that extracts local representations from local models and incorporates them into a global representation that improves the prediction performance. Achieving this requires addressing two non-trivial problems. First, we need to learn an alignment between similar feature components which are arbitrarily arranged across clients to enable representation aggregation. Second, we need to learn a consensus graph that captures the high-order interactions between local feature spaces and how to combine them to achieve a better prediction. This paper presents solutions to these problems and demonstrates them in real-world applications on time series data such as power grids and traffic networks. ",
    "url": "https://arxiv.org/abs/2306.01240",
    "authors": [
      "Tengfei Ma",
      "Trong Nghia Hoang",
      "Jie Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01249",
    "title": "Transforming ECG Diagnosis:An In-depth Review of Transformer-based  DeepLearning Models in Cardiovascular Disease Detection",
    "abstract": "The emergence of deep learning has significantly enhanced the analysis of electrocardiograms (ECGs), a non-invasive method that is essential for assessing heart health. Despite the complexity of ECG interpretation, advanced deep learning models outperform traditional methods. However, the increasing complexity of ECG data and the need for real-time and accurate diagnosis necessitate exploring more robust architectures, such as transformers. Here, we present an in-depth review of transformer architectures that are applied to ECG classification. Originally developed for natural language processing, these models capture complex temporal relationships in ECG signals that other models might overlook. We conducted an extensive search of the latest transformer-based models and summarize them to discuss the advances and challenges in their application and suggest potential future improvements. This review serves as a valuable resource for researchers and practitioners and aims to shed light on this innovative application in ECG interpretation. ",
    "url": "https://arxiv.org/abs/2306.01249",
    "authors": [
      "Zibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.01250",
    "title": "Active Code Learning: Benchmarking Sample-Efficient Training of Code  Models",
    "abstract": "The costly human effort required to prepare the training data of machine learning (ML) models hinders their practical development and usage in software engineering (ML4Code), especially for those with limited budgets. Therefore, efficiently training models of code with less human effort has become an emergent problem. Active learning is such a technique to address this issue that allows developers to train a model with reduced data while producing models with desired performance, which has been well studied in computer vision and natural language processing domains. Unfortunately, there is no such work that explores the effectiveness of active learning for code models. In this paper, we bridge this gap by building the first benchmark to study this critical problem - active code learning. Specifically, we collect 11 acquisition functions~(which are used for data selection in active learning) from existing works and adapt them for code-related tasks. Then, we conduct an empirical study to check whether these acquisition functions maintain performance for code data. The results demonstrate that feature selection highly affects active learning and using output vectors to select data is the best choice. For the code summarization task, active code learning is ineffective which produces models with over a 29.64\\% gap compared to the expected performance. Furthermore, we explore future directions of active code learning with an exploratory study. We propose to replace distance calculation methods with evaluation metrics and find a correlation between these evaluation-based distance methods and the performance of code models. ",
    "url": "https://arxiv.org/abs/2306.01250",
    "authors": [
      "Qiang Hu",
      "Yuejun Guo",
      "Xiaofei Xie",
      "Maxime Cordy",
      "Lei Ma",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.01251",
    "title": "Average AoI Minimization for Energy Harvesting Relay-aided Status Update  Network Using Deep Reinforcement Learning",
    "abstract": "A dual-hop status update system aided by energy harvesting (EH) relays with finite data and energy buffers is studied in this work. To achieve timely status updates, the best relays should be selected to minimize the average age of information (AoI), which is a recently proposed metric to evaluate information freshness. The average AoI minimization can be formulated as a Markov decision process (MDP), but the state space for capturing channel and buffer evolution grows exponentially with the number of relays, leading to high solution complexity. We propose a relay selection (RS) scheme based on deep reinforcement learning (DRL) according to the instantaneous channel packet freshness and buffer information of each relay. Simulation results show a significant improvement of the proposed DRL-based RS scheme over state-of-art approaches. ",
    "url": "https://arxiv.org/abs/2306.01251",
    "authors": [
      "Sin-Yu Huang",
      "Kuang-Hao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.01261",
    "title": "Automatic Translation of Hate Speech to Non-hate Speech in Social Media  Texts",
    "abstract": "In this paper, we investigate the issue of hate speech by presenting a novel task of translating hate speech into non-hate speech text while preserving its meaning. As a case study, we use Spanish texts. We provide a dataset and several baselines as a starting point for further research in the task. We evaluated our baseline results using multiple metrics, including BLEU scores. The aim of this study is to contribute to the development of more effective methods for reducing the spread of hate speech in online communities. ",
    "url": "https://arxiv.org/abs/2306.01261",
    "authors": [
      "Yevhen Kostiuk",
      "Atnafu Lambebo Tonja",
      "Grigori Sidorov",
      "Olga Kolesnikova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01271",
    "title": "Why Clean Generalization and Robust Overfitting Both Happen in  Adversarial Training",
    "abstract": "Adversarial training is a standard method to train deep neural networks to be robust to adversarial perturbation. Similar to surprising $\\textit{clean generalization}$ ability in the standard deep learning setting, neural networks trained by adversarial training also generalize well for $\\textit{unseen clean data}$. However, in constrast with clean generalization, while adversarial training method is able to achieve low $\\textit{robust training error}$, there still exists a significant $\\textit{robust generalization gap}$, which promotes us exploring what mechanism leads to both $\\textit{clean generalization and robust overfitting (CGRO)}$ during learning process. In this paper, we provide a theoretical understanding of this CGRO phenomenon in adversarial training. First, we propose a theoretical framework of adversarial training, where we analyze $\\textit{feature learning process}$ to explain how adversarial training leads network learner to CGRO regime. Specifically, we prove that, under our patch-structured dataset, the CNN model provably partially learns the true feature but exactly memorizes the spurious features from training-adversarial examples, which thus results in clean generalization and robust overfitting. For more general data assumption, we then show the efficiency of CGRO classifier from the perspective of $\\textit{representation complexity}$. On the empirical side, to verify our theoretical analysis in real-world vision dataset, we investigate the $\\textit{dynamics of loss landscape}$ during training. Moreover, inspired by our experiments, we prove a robust generalization bound based on $\\textit{global flatness}$ of loss landscape, which may be an independent interest. ",
    "url": "https://arxiv.org/abs/2306.01271",
    "authors": [
      "Binghui Li",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01272",
    "title": "DeepfakeArt Challenge: A Benchmark Dataset for Generative AI Art Forgery  and Data Poisoning Detection",
    "abstract": "The tremendous recent advances in generative artificial intelligence techniques have led to significant successes and promise in a wide range of different applications ranging from conversational agents and textual content generation to voice and visual synthesis. Amid the rise in generative AI and its increasing widespread adoption, there has been significant growing concern over the use of generative AI for malicious purposes. In the realm of visual content synthesis using generative AI, key areas of significant concern has been image forgery (e.g., generation of images containing or derived from copyright content), and data poisoning (i.e., generation of adversarially contaminated images). Motivated to address these key concerns to encourage responsible generative AI, we introduce the DeepfakeArt Challenge, a large-scale challenge benchmark dataset designed specifically to aid in the building of machine learning algorithms for generative AI art forgery and data poisoning detection. Comprising of over 32,000 records across a variety of generative forgery and data poisoning techniques, each entry consists of a pair of images that are either forgeries / adversarially contaminated or not. Each of the generated images in the DeepfakeArt Challenge benchmark dataset has been quality checked in a comprehensive manner. The DeepfakeArt Challenge is a core part of GenAI4Good, a global open source initiative for accelerating machine learning for promoting responsible creation and deployment of generative AI for good. ",
    "url": "https://arxiv.org/abs/2306.01272",
    "authors": [
      "Hossein Aboutalebi",
      "Daniel Mao",
      "Carol Xu",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01273",
    "title": "VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard  Labels of Transformations",
    "abstract": "Adversarial attacks reveal serious flaws in deep learning models. More dangerously, these attacks preserve the original meaning and escape human recognition. Existing methods for detecting these attacks need to be trained using original/adversarial data. In this paper, we propose detection without training by voting on hard labels from predictions of transformations, namely, VoteTRANS. Specifically, VoteTRANS detects adversarial text by comparing the hard labels of input text and its transformation. The evaluation demonstrates that VoteTRANS effectively detects adversarial text across various state-of-the-art attacks, models, and datasets. ",
    "url": "https://arxiv.org/abs/2306.01273",
    "authors": [
      "Hoang-Quoc Nguyen-Son",
      "Seira Hidano",
      "Kazuhide Fukushima",
      "Shinsaku Kiyomoto",
      "Isao Echizen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01293",
    "title": "LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning",
    "abstract": "We present a novel vision-language prompt learning approach for few-shot out-of-distribution (OOD) detection. Few-shot OOD detection aims to detect OOD images from classes that are unseen during training using only a few labeled in-distribution (ID) images. While prompt learning methods such as CoOp have shown effectiveness and efficiency in few-shot ID classification, they still face limitations in OOD detection due to the potential presence of ID-irrelevant information in text embeddings. To address this issue, we introduce a new approach called \\textbf{Lo}cal regularized \\textbf{Co}ntext \\textbf{Op}timization (LoCoOp), which performs OOD regularization that utilizes the portions of CLIP local features as OOD features during training. CLIP's local features have a lot of ID-irrelevant nuisances (e.g., backgrounds), and by learning to push them away from the ID class text embeddings, we can remove the nuisances in the ID class text embeddings and enhance the separation between ID and OOD. Experiments on the large-scale ImageNet OOD detection benchmarks demonstrate the superiority of our LoCoOp over zero-shot, fully supervised detection methods and prompt learning methods. Notably, even in a one-shot setting -- just one label per class, LoCoOp outperforms existing zero-shot and fully supervised detection methods. The code will be available via \\url{https://github.com/AtsuMiyai/LoCoOp}. ",
    "url": "https://arxiv.org/abs/2306.01293",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01303",
    "title": "DistilXLSR: A Light Weight Cross-Lingual Speech Representation Model",
    "abstract": "Multilingual self-supervised speech representation models have greatly enhanced the speech recognition performance for low-resource languages, and the compression of these huge models has also become a crucial prerequisite for their industrial application. In this paper, we propose DistilXLSR, a distilled cross-lingual speech representation model. By randomly shuffling the phonemes of existing speech, we reduce the linguistic information and distill cross-lingual models using only English data. We also design a layer-jumping initialization method to fully leverage the teacher's pre-trained weights. Experiments on 2 kinds of teacher models and 15 low-resource languages show that our method can reduce the parameters by 50% while maintaining cross-lingual representation ability. Our method is proven to be generalizable to various languages/teacher models and has the potential to improve the cross-lingual performance of the English pre-trained models. ",
    "url": "https://arxiv.org/abs/2306.01303",
    "authors": [
      "Haoyu Wang",
      "Siyuan Wang",
      "Wei-Qiang Zhang",
      "Jinfeng Bai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.01306",
    "title": "Federated Learning Games for Reconfigurable Intelligent Surfaces via  Causal Representations",
    "abstract": "In this paper, we investigate the problem of robust Reconfigurable Intelligent Surface (RIS) phase-shifts configuration over heterogeneous communication environments. The problem is formulated as a distributed learning problem over different environments in a Federated Learning (FL) setting. Equivalently, this corresponds to a game played between multiple RISs, as learning agents, in heterogeneous environments. Using Invariant Risk Minimization (IRM) and its FL equivalent, dubbed FL Games, we solve the RIS configuration problem by learning invariant causal representations across multiple environments and then predicting the phases. The solution corresponds to playing according to Best Response Dynamics (BRD) which yields the Nash Equilibrium of the FL game. The representation learner and the phase predictor are modeled by two neural networks, and their performance is validated via simulations against other benchmarks from the literature. Our results show that causality-based learning yields a predictor that is 15% more accurate in unseen Out-of-Distribution (OoD) environments. ",
    "url": "https://arxiv.org/abs/2306.01306",
    "authors": [
      "Charbel Bou Chaaya",
      "Sumudu Samarakoon",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.01310",
    "title": "EPIC: Graph Augmentation with Edit Path Interpolation via Learnable Cost",
    "abstract": "Graph-based models have become increasingly important in various domains, but the limited size and diversity of existing graph datasets often limit their performance. To address this issue, we propose EPIC (Edit Path Interpolation via learnable Cost), a novel interpolation-based method for augmenting graph datasets. Our approach leverages graph edit distance to generate new graphs that are similar to the original ones but exhibit some variation in their structures. To achieve this, we learn the graph edit distance through a comparison of labeled graphs and utilize this knowledge to create graph edit paths between pairs of original graphs. With randomly sampled graphs from a graph edit path, we enrich the training set to enhance the generalization capability of classification models. We demonstrate the effectiveness of our approach on several benchmark datasets and show that it outperforms existing augmentation methods in graph classification tasks. ",
    "url": "https://arxiv.org/abs/2306.01310",
    "authors": [
      "Jaeseung Heo",
      "Seungbeom Lee",
      "Sungsoo Ahn",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01316",
    "title": "Independent Modular Networks",
    "abstract": "Monolithic neural networks that make use of a single set of weights to learn useful representations for downstream tasks explicitly dismiss the compositional nature of data generation processes. This characteristic exists in data where every instance can be regarded as the combination of an identity concept, such as the shape of an object, combined with modifying concepts, such as orientation, color, and size. The dismissal of compositionality is especially detrimental in robotics, where state estimation relies heavily on the compositional nature of physical mechanisms (e.g., rotations and transformations) to model interactions. To accommodate this data characteristic, modular networks have been proposed. However, a lack of structure in each module's role, and modular network-specific issues such as module collapse have restricted their usability. We propose a modular network architecture that accommodates the mentioned decompositional concept by proposing a unique structure that splits the modules into predetermined roles. Additionally, we provide regularizations that improve the resiliency of the modular network to the problem of module collapse while improving the decomposition accuracy of the model. ",
    "url": "https://arxiv.org/abs/2306.01316",
    "authors": [
      "Hamed Damirchi",
      "Forest Agostinelli",
      "Pooyan Jamshidi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01317",
    "title": "Compatibility and Timing Attacks for JPEG Steganalysis",
    "abstract": "This paper introduces a novel compatibility attack to detect a steganographic message embedded in the DCT domain of a JPEG image at high-quality factors (close to 100). Because the JPEG compression is not a surjective function, i.e. not every DCT blocks can be mapped from a pixel block, embedding a message in the DCT domain can create incompatible blocks. We propose a method to find such a block, which directly proves that a block has been modified during the embedding. This theoretical method provides many advantages such as being completely independent to Cover Source Mismatch, having good detection power, and perfect reliability since false alarms are impossible as soon as incompatible blocks are found. We show that finding an incompatible block is equivalent to proving the infeasibility of an Integer Linear Programming problem. However, solving such a problem requires considerable computational power and has not been reached for 8x8 blocks. Instead, a timing attack approach is presented to perform steganalysis without potentially any false alarms for large computing power. ",
    "url": "https://arxiv.org/abs/2306.01317",
    "authors": [
      "Etienne Levecque",
      "Patrick Bas",
      "Jan Butora"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.01322",
    "title": "Privacy Distillation: Reducing Re-identification Risk of Multimodal  Diffusion Models",
    "abstract": "Knowledge distillation in neural networks refers to compressing a large model or dataset into a smaller version of itself. We introduce Privacy Distillation, a framework that allows a text-to-image generative model to teach another model without exposing it to identifiable data. Here, we are interested in the privacy issue faced by a data provider who wishes to share their data via a multimodal generative model. A question that immediately arises is ``How can a data provider ensure that the generative model is not leaking identifiable information about a patient?''. Our solution consists of (1) training a first diffusion model on real data (2) generating a synthetic dataset using this model and filtering it to exclude images with a re-identifiability risk (3) training a second diffusion model on the filtered synthetic data only. We showcase that datasets sampled from models trained with privacy distillation can effectively reduce re-identification risk whilst maintaining downstream performance. ",
    "url": "https://arxiv.org/abs/2306.01322",
    "authors": [
      "Virginia Fernandez",
      "Pedro Sanchez",
      "Walter Hugo Lopez Pinaya",
      "Grzegorz Jacenk\u00f3w",
      "Sotirios A. Tsaftaris",
      "Jorge Cardoso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01323",
    "title": "Demystifying Structural Disparity in Graph Neural Networks: Can One Size  Fit All?",
    "abstract": "Recent studies on Graph Neural Networks(GNNs) provide both empirical and theoretical evidence supporting their effectiveness in capturing structural patterns on both homophilic and certain heterophilic graphs. Notably, most real-world homophilic and heterophilic graphs are comprised of a mixture of nodes in both homophilic and heterophilic structural patterns, exhibiting a structural disparity. However, the analysis of GNN performance with respect to nodes exhibiting different structural patterns, e.g., homophilic nodes in heterophilic graphs, remains rather limited. In the present study, we provide evidence that Graph Neural Networks(GNNs) on node classification typically perform admirably on homophilic nodes within homophilic graphs and heterophilic nodes within heterophilic graphs while struggling on the opposite node set, exhibiting a performance disparity. We theoretically and empirically identify effects of GNNs on testing nodes exhibiting distinct structural patterns. We then propose a rigorous, non-i.i.d PAC-Bayesian generalization bound for GNNs, revealing reasons for the performance disparity, namely the aggregated feature distance and homophily ratio difference between training and testing nodes. Furthermore, we demonstrate the practical implications of our new findings via (1) elucidating the effectiveness of deeper GNNs; and (2) revealing an over-looked distribution shift factor on graph out-of-distribution problem and proposing a new scenario accordingly. ",
    "url": "https://arxiv.org/abs/2306.01323",
    "authors": [
      "Haitao Mao",
      "Zhikai Chen",
      "Wei Jin",
      "Haoyu Han",
      "Yao Ma",
      "Tong Zhao",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01325",
    "title": "LyricSIM: A novel Dataset and Benchmark for Similarity Detection in  Spanish Song LyricS",
    "abstract": "In this paper, we present a new dataset and benchmark tailored to the task of semantic similarity in song lyrics. Our dataset, originally consisting of 2775 pairs of Spanish songs, was annotated in a collective annotation experiment by 63 native annotators. After collecting and refining the data to ensure a high degree of consensus and data integrity, we obtained 676 high-quality annotated pairs that were used to evaluate the performance of various state-of-the-art monolingual and multilingual language models. Consequently, we established baseline results that we hope will be useful to the community in all future academic and industrial applications conducted in this context. ",
    "url": "https://arxiv.org/abs/2306.01325",
    "authors": [
      "Alejandro Benito-Santos",
      "Adri\u00e1n Ghajari",
      "Pedro Hern\u00e1ndez",
      "V\u00edctor Fresno",
      "Salvador Ros",
      "Elena Gonz\u00e1lez-Blanco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.01335",
    "title": "Invertible residual networks in the context of regularization theory for  linear inverse problems",
    "abstract": "Learned inverse problem solvers exhibit remarkable performance in applications like image reconstruction tasks. These data-driven reconstruction methods often follow a two-step scheme. First, one trains the often neural network-based reconstruction scheme via a dataset. Second, one applies the scheme to new measurements to obtain reconstructions. We follow these steps but parameterize the reconstruction scheme with invertible residual networks (iResNets). We demonstrate that the invertibility enables investigating the influence of the training and architecture choices on the resulting reconstruction scheme. For example, assuming local approximation properties of the network, we show that these schemes become convergent regularizations. In addition, the investigations reveal a formal link to the linear regularization theory of linear inverse problems and provide a nonlinear spectral regularization for particular architecture classes. On the numerical side, we investigate the local approximation property of selected trained architectures and present a series of experiments on the MNIST dataset that underpin and extend our theoretical findings. ",
    "url": "https://arxiv.org/abs/2306.01335",
    "authors": [
      "Clemens Arndt",
      "Alexander Denker",
      "S\u00f6ren Dittmer",
      "Nick Heilenk\u00f6tter",
      "Meira Iske",
      "Tobias Kluth",
      "Peter Maass",
      "Judith Nickel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.01342",
    "title": "Covert Communication Based on the Poisoning Attack in Federated Learning",
    "abstract": "Covert communication has become an important area of research in computer security. It involves hiding specific information on a carrier for message transmission and is often used to transmit private data, military secrets, and even malware. In deep learning, many methods have been developed for hiding information in models to achieve covert communication. However, these methods are not applicable to federated learning, where model aggregation invalidates the exact information embedded in the model by the client. To address this problem, we propose a novel method for covert communication in federated learning based on the poisoning attack. Our approach achieves 100% accuracy in covert message transmission between two clients and is shown to be both stealthy and robust through extensive experiments. However, existing defense methods are limited in their effectiveness against our attack scheme, highlighting the urgent need for new protection methods to be developed. Our study emphasizes the necessity of research in covert communication and serves as a foundation for future research in federated learning attacks and defenses. ",
    "url": "https://arxiv.org/abs/2306.01342",
    "authors": [
      "Junchuan Liang",
      "Rong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.01354",
    "title": "Deep recurrent spiking neural networks capture both static and dynamic  representations of the visual cortex under movie stimuli",
    "abstract": "In the real world, visual stimuli received by the biological visual system are predominantly dynamic rather than static. A better understanding of how the visual cortex represents movie stimuli could provide deeper insight into the information processing mechanisms of the visual system. Although some progress has been made in modeling neural responses to natural movies with deep neural networks, the visual representations of static and dynamic information under such time-series visual stimuli remain to be further explored. In this work, considering abundant recurrent connections in the mouse visual system, we design a recurrent module based on the hierarchy of the mouse cortex and add it into Deep Spiking Neural Networks, which have been demonstrated to be a more compelling computational model for the visual cortex. Using Time-Series Representational Similarity Analysis, we measure the representational similarity between networks and mouse cortical regions under natural movie stimuli. Subsequently, we conduct a comparison of the representational similarity across recurrent/feedforward networks and image/video training tasks. Trained on the video action recognition task, recurrent SNN achieves the highest representational similarity and significantly outperforms feedforward SNN trained on the same task by 15% and the recurrent SNN trained on the image classification task by 8%. We investigate how static and dynamic representations of SNNs influence the similarity, as a way to explain the importance of these two forms of representations in biological neural coding. Taken together, our work is the first to apply deep recurrent SNNs to model the mouse visual cortex under movie stimuli and we establish that these networks are competent to capture both static and dynamic representations and make contributions to understanding the movie information processing mechanisms of the visual cortex. ",
    "url": "https://arxiv.org/abs/2306.01354",
    "authors": [
      "Liwei Huang",
      "ZhengYu Ma",
      "Huihui Zhou",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.01359",
    "title": "DWT-CompCNN: Deep Image Classification Network for High Throughput JPEG  2000 Compressed Documents",
    "abstract": "For any digital application with document images such as retrieval, the classification of document images becomes an essential stage. Conventionally for the purpose, the full versions of the documents, that is the uncompressed document images make the input dataset, which poses a threat due to the big volume required to accommodate the full versions of the documents. Therefore, it would be novel, if the same classification task could be accomplished directly (with some partial decompression) with the compressed representation of documents in order to make the whole process computationally more efficient. In this research work, a novel deep learning model, DWT CompCNN is proposed for classification of documents that are compressed using High Throughput JPEG 2000 (HTJ2K) algorithm. The proposed DWT-CompCNN comprises of five convolutional layers with filter sizes of 16, 32, 64, 128, and 256 consecutively for each increasing layer to improve learning from the wavelet coefficients extracted from the compressed images. Experiments are performed on two benchmark datasets- Tobacco-3482 and RVL-CDIP, which demonstrate that the proposed model is time and space efficient, and also achieves a better classification accuracy in compressed domain. ",
    "url": "https://arxiv.org/abs/2306.01359",
    "authors": [
      "Tejasvee Bisen",
      "Mohammed Javed",
      "Shashank Kirtania",
      "P. Nagabhushan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.01363",
    "title": "Quantifying Sample Anonymity in Score-Based Generative Models with  Adversarial Fingerprinting",
    "abstract": "Recent advances in score-based generative models have led to a huge spike in the development of downstream applications using generative models ranging from data augmentation over image and video generation to anomaly detection. Despite publicly available trained models, their potential to be used for privacy preserving data sharing has not been fully explored yet. Training diffusion models on private data and disseminating the models and weights rather than the raw dataset paves the way for innovative large-scale data-sharing strategies, particularly in healthcare, where safeguarding patients' personal health information is paramount. However, publishing such models without individual consent of, e.g., the patients from whom the data was acquired, necessitates guarantees that identifiable training samples will never be reproduced, thus protecting personal health data and satisfying the requirements of policymakers and regulatory bodies. This paper introduces a method for estimating the upper bound of the probability of reproducing identifiable training images during the sampling process. This is achieved by designing an adversarial approach that searches for anatomic fingerprints, such as medical devices or dermal art, which could potentially be employed to re-identify training images. Our method harnesses the learned score-based model to estimate the probability of the entire subspace of the score function that may be utilized for one-to-one reproduction of training samples. To validate our estimates, we generate anomalies containing a fingerprint and investigate whether generated samples from trained generative models can be uniquely mapped to the original training samples. Overall our results show that privacy-breaching images are reproduced at sampling time if the models were trained without care. ",
    "url": "https://arxiv.org/abs/2306.01363",
    "authors": [
      "Mischa Dombrowski",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01364",
    "title": "Towards Robust GAN-generated Image Detection: a Multi-view Completion  Representation",
    "abstract": "GAN-generated image detection now becomes the first line of defense against the malicious uses of machine-synthesized image manipulations such as deepfakes. Although some existing detectors work well in detecting clean, known GAN samples, their success is largely attributable to overfitting unstable features such as frequency artifacts, which will cause failures when facing unknown GANs or perturbation attacks. To overcome the issue, we propose a robust detection framework based on a novel multi-view image completion representation. The framework first learns various view-to-image tasks to model the diverse distributions of genuine images. Frequency-irrelevant features can be represented from the distributional discrepancies characterized by the completion models, which are stable, generalized, and robust for detecting unknown fake patterns. Then, a multi-view classification is devised with elaborated intra- and inter-view learning strategies to enhance view-specific feature representation and cross-view feature aggregation, respectively. We evaluated the generalization ability of our framework across six popular GANs at different resolutions and its robustness against a broad range of perturbation attacks. The results confirm our method's improved effectiveness, generalization, and robustness over various baselines. ",
    "url": "https://arxiv.org/abs/2306.01364",
    "authors": [
      "Chi Liu",
      "Tianqing Zhu",
      "Sheng Shen",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01376",
    "title": "DSHGT: Dual-Supervisors Heterogeneous Graph Transformer -- A pioneer  study of using heterogeneous graph learning for detecting software  vulnerabilities",
    "abstract": "Vulnerability detection is a critical problem in software security and attracts growing attention both from academia and industry. Traditionally, software security is safeguarded by designated rule-based detectors that heavily rely on empirical expertise, requiring tremendous effort from software experts to generate rule repositories for large code corpus. Recent advances in deep learning, especially Graph Neural Networks (GNN), have uncovered the feasibility of automatic detection of a wide range of software vulnerabilities. However, prior learning-based works only break programs down into a sequence of word tokens for extracting contextual features of codes, or apply GNN largely on homogeneous graph representation (e.g., AST) without discerning complex types of underlying program entities (e.g., methods, variables). In this work, we are one of the first to explore heterogeneous graph representation in the form of Code Property Graph and adapt a well-known heterogeneous graph network with a dual-supervisor structure for the corresponding graph learning task. Using the prototype built, we have conducted extensive experiments on both synthetic datasets and real-world projects. Compared with the state-of-the-art baselines, the results demonstrate promising effectiveness in this research direction in terms of vulnerability detection performance (average F1 improvements over 10\\% in real-world projects) and transferability from C/C++ to other programming languages (average F1 improvements over 11%). ",
    "url": "https://arxiv.org/abs/2306.01376",
    "authors": [
      "Tiehua Zhang",
      "Rui Xu",
      "Jianping Zhang",
      "Yuzhe Tian",
      "Xin Chen",
      "Xiaowei Huang",
      "Jun Yin",
      "Xi Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01377",
    "title": "A systematic literature review on the code smells datasets and  validation mechanisms",
    "abstract": "The accuracy reported for code smell-detecting tools varies depending on the dataset used to evaluate the tools. Our survey of 45 existing datasets reveals that the adequacy of a dataset for detecting smells highly depends on relevant properties such as the size, severity level, project types, number of each type of smell, number of smells, and the ratio of smelly to non-smelly samples in the dataset. Most existing datasets support God Class, Long Method, and Feature Envy while six smells in Fowler and Beck's catalog are not supported by any datasets. We conclude that existing datasets suffer from imbalanced samples, lack of supporting severity level, and restriction to Java language. ",
    "url": "https://arxiv.org/abs/2306.01377",
    "authors": [
      "Morteza Zakeri-Nasrabadi",
      "Saeed Parsa",
      "Ehsan Esmaili",
      "Fabio Palomba"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2306.01381",
    "title": "Adaptive Message Quantization and Parallelization for Distributed  Full-graph GNN Training",
    "abstract": "Distributed full-graph training of Graph Neural Networks (GNNs) over large graphs is bandwidth-demanding and time-consuming. Frequent exchanges of node features, embeddings and embedding gradients (all referred to as messages) across devices bring significant communication overhead for nodes with remote neighbors on other devices (marginal nodes) and unnecessary waiting time for nodes without remote neighbors (central nodes) in the training graph. This paper proposes an efficient GNN training system, AdaQP, to expedite distributed full-graph GNN training. We stochastically quantize messages transferred across devices to lower-precision integers for communication traffic reduction and advocate communication-computation parallelization between marginal nodes and central nodes. We provide theoretical analysis to prove fast training convergence (at the rate of O(T^{-1}) with T being the total number of training epochs) and design an adaptive quantization bit-width assignment scheme for each message based on the analysis, targeting a good trade-off between training convergence and efficiency. Extensive experiments on mainstream graph datasets show that AdaQP substantially improves distributed full-graph training's throughput (up to 3.01 X) with negligible accuracy drop (at most 0.30%) or even accuracy improvement (up to 0.19%) in most cases, showing significant advantages over the state-of-the-art works. ",
    "url": "https://arxiv.org/abs/2306.01381",
    "authors": [
      "Borui Wan",
      "Juntao Zhao",
      "Chuan Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2306.01383",
    "title": "Analysis and FPGA based Implementation of Permutation Binary Neural  Networks",
    "abstract": "This paper studies a permutation binary neural network characterized by local binary connections, global permutation connections, and the signum activation function. Depending on the permutation connections, the network can generate various periodic orbits of binary vectors. Especially, we focus on globally stable periodic orbits such that almost all initial points fall into the orbits. In order to explore the periodic orbits, we present a simple evolutionary algorithm. Applying the algorithm to typical examples of PBNNs, existence of a variety of periodic orbits is clarified. Presenting an FPGA based hardware prototype, typical periodic orbits are confirmed experimentally. The hardware will be developed into various engineering applications such that stable control signals of switching circuits and stable approximation signals of time-series. ",
    "url": "https://arxiv.org/abs/2306.01383",
    "authors": [
      "Mikito Onuki",
      "Kento Saka",
      "Toshimichi Saito"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2306.01391",
    "title": "Chemical Property-Guided Neural Networks for Naphtha Composition  Prediction",
    "abstract": "The naphtha cracking process heavily relies on the composition of naphtha, which is a complex blend of different hydrocarbons. Predicting the naphtha composition accurately is crucial for efficiently controlling the cracking process and achieving maximum performance. Traditional methods, such as gas chromatography and true boiling curve, are not feasible due to the need for pilot-plant-scale experiments or cost constraints. In this paper, we propose a neural network framework that utilizes chemical property information to improve the performance of naphtha composition prediction. Our proposed framework comprises two parts: a Watson K factor estimation network and a naphtha composition prediction network. Both networks share a feature extraction network based on Convolutional Neural Network (CNN) architecture, while the output layers use Multi-Layer Perceptron (MLP) based networks to generate two different outputs - Watson K factor and naphtha composition. The naphtha composition is expressed in percentages, and its sum should be 100%. To enhance the naphtha composition prediction, we utilize a distillation simulator to obtain the distillation curve from the naphtha composition, which is dependent on its chemical properties. By designing a loss function between the estimated and simulated Watson K factors, we improve the performance of both Watson K estimation and naphtha composition prediction. The experimental results show that our proposed framework can predict the naphtha composition accurately while reflecting real naphtha chemical properties. ",
    "url": "https://arxiv.org/abs/2306.01391",
    "authors": [
      "Chonghyo Joo",
      "Jeongdong Kim",
      "Hyungtae Cho",
      "Jaewon Lee",
      "Sungho Suh",
      "Junghwan Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2306.01398",
    "title": "Evaluating The Robustness of Self-Supervised Representations to  Background/Foreground Removal",
    "abstract": "Despite impressive empirical advances of SSL in solving various tasks, the problem of understanding and characterizing SSL representations learned from input data remains relatively under-explored. We provide a comparative analysis of how the representations produced by SSL models differ when masking parts of the input. Specifically, we considered state-of-the-art SSL pretrained models, such as DINOv2, MAE, and SwaV, and analyzed changes at the representation levels across 4 Image Classification datasets. First, we generate variations of the datasets by applying foreground and background segmentation. Then, we conduct statistical analysis using Canonical Correlation Analysis (CCA) and Centered Kernel Alignment (CKA) to evaluate the robustness of the representations learned in SSL models. Empirically, we show that not all models lead to representations that separate foreground, background, and complete images. Furthermore, we test different masking strategies by occluding the center regions of the images to address cases where foreground and background are difficult. For example, the DTD dataset that focuses on texture rather specific objects. ",
    "url": "https://arxiv.org/abs/2306.01398",
    "authors": [
      "Xavier F. Cadet",
      "Ranya Aloufi",
      "Alain Miranville",
      "Sara Ahmadi-Abhari",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01399",
    "title": "Knowledge Graph Reasoning over Entities and Numerical Values",
    "abstract": "A complex logic query in a knowledge graph refers to a query expressed in logic form that conveys a complex meaning, such as where did the Canadian Turing award winner graduate from? Knowledge graph reasoning-based applications, such as dialogue systems and interactive search engines, rely on the ability to answer complex logic queries as a fundamental task. In most knowledge graphs, edges are typically used to either describe the relationships between entities or their associated attribute values. An attribute value can be in categorical or numerical format, such as dates, years, sizes, etc. However, existing complex query answering (CQA) methods simply treat numerical values in the same way as they treat entities. This can lead to difficulties in answering certain queries, such as which Australian Pulitzer award winner is born before 1927, and which drug is a pain reliever and has fewer side effects than Paracetamol. In this work, inspired by the recent advances in numerical encoding and knowledge graph reasoning, we propose numerical complex query answering. In this task, we introduce new numerical variables and operations to describe queries involving numerical attribute values. To address the difference between entities and numerical values, we also propose the framework of Number Reasoning Network (NRN) for alternatively encoding entities and numerical values into separate encoding structures. During the numerical encoding process, NRN employs a parameterized density function to encode the distribution of numerical values. During the entity encoding process, NRN uses established query encoding methods for the original CQA problem. Experimental results show that NRN consistently improves various query encoding methods on three different knowledge graphs and achieves state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2306.01399",
    "authors": [
      "Jiaxin Bai",
      "Chen Luo",
      "Zheng Li",
      "Qingyu Yin",
      "Bing Yin",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2306.01400",
    "title": "Adaptive Attractors: A Defense Strategy against ML Adversarial Collusion  Attacks",
    "abstract": "In the seller-buyer setting on machine learning models, the seller generates different copies based on the original model and distributes them to different buyers, such that adversarial samples generated on one buyer's copy would likely not work on other copies. A known approach achieves this using attractor-based rewriter which injects different attractors to different copies. This induces different adversarial regions in different copies, making adversarial samples generated on one copy not replicable on others. In this paper, we focus on a scenario where multiple malicious buyers collude to attack. We first give two formulations and conduct empirical studies to analyze effectiveness of collusion attack under different assumptions on the attacker's capabilities and properties of the attractors. We observe that existing attractor-based methods do not effectively mislead the colluders in the sense that adversarial samples found are influenced more by the original model instead of the attractors as number of colluders increases. Based on this observation, we propose using adaptive attractors whose weight is guided by a U-shape curve to cover the shortfalls. Experimentation results show that when using our approach, the attack success rate of a collusion attack converges to around 15% even when lots of copies are applied for collusion. In contrast, when using the existing attractor-based rewriter with fixed weight, the attack success rate increases linearly with the number of copies used for collusion. ",
    "url": "https://arxiv.org/abs/2306.01400",
    "authors": [
      "Jiyi Zhang",
      "Han Fang",
      "Ee-Chien Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.01401",
    "title": "Network Agnostic MPC with Statistical Security",
    "abstract": "We initiate the study of the network agnostic MPC protocols with statistical security. Network agnostic protocols give the best possible security guarantees irrespective of the underlying network type. We consider the general-adversary model, where the adversary is characterized by an adversary structure which enumerates all possible candidate subsets of corrupt parties. The $\\mathcal{Q}^{(k)}$ condition enforces that the union of no $k$ subsets from the adversary structure covers the party set. Given an unconditionally-secure PKI setup, known statistically-secure synchronous MPC protocols are secure against adversary structures satisfying the $\\mathcal{Q}^{(2)}$ condition. Known statistically-secure asynchronous MPC protocols can tolerate $\\mathcal{Q}^{(3)}$ adversary structures. Fix a set of $n$ parties $\\mathcal{P} = \\{P_1, ... ,P_n\\}$ and adversary structures $\\mathcal{Z}_s$ and $\\mathcal{Z}_a$, satisfying the $\\mathcal{Q}^{(2)}$ and $\\mathcal{Q}^{(3)}$ conditions respectively, where $\\mathcal{Z}_a \\subset \\mathcal{Z}_s$. Then, given an unconditionally-secure PKI, we ask whether it is possible to design a statistically-secure MPC protocol resilient against $\\mathcal{Z}_s$ and $\\mathcal{Z}_a$ in a synchronous and an asynchronous network respectively if the parties in $\\mathcal{P}$ are unaware of the network type. We show that it is possible iff $\\mathcal{Z}_s$ and $\\mathcal{Z}_a$ satisfy the $\\mathcal{Q}^{(2,1)}$ condition, meaning that the union of any two subsets from $\\mathcal{Z}_s$ and any one subset from $\\mathcal{Z}_a$ is a proper subset of $\\mathcal{P}$. We design several important network agnostic building blocks with the $\\mathcal{Q}^{(2,1)}$ condition, such as Byzantine broadcast, Byzantine agreement, information checking protocol, verifiable secret-sharing and secure multiplication protocol, whose complexity is polynomial in $n$ and $|\\mathcal{Z}_s|$. ",
    "url": "https://arxiv.org/abs/2306.01401",
    "authors": [
      "Ananya Appan",
      "Ashish Choudhury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.01428",
    "title": "Improved DeepFake Detection Using Whisper Features",
    "abstract": "With a recent influx of voice generation methods, the threat introduced by audio DeepFake (DF) is ever-increasing. Several different detection methods have been presented as a countermeasure. Many methods are based on so-called front-ends, which, by transforming the raw audio, emphasize features crucial for assessing the genuineness of the audio sample. Our contribution contains investigating the influence of the state-of-the-art Whisper automatic speech recognition model as a DF detection front-end. We compare various combinations of Whisper and well-established front-ends by training 3 detection models (LCNN, SpecRNet, and MesoNet) on a widely used ASVspoof 2021 DF dataset and later evaluating them on the DF In-The-Wild dataset. We show that using Whisper-based features improves the detection for each model and outperforms recent results on the In-The-Wild dataset by reducing Equal Error Rate by 21%. ",
    "url": "https://arxiv.org/abs/2306.01428",
    "authors": [
      "Piotr Kawa",
      "Marcin Plata",
      "Micha\u0142 Czuba",
      "Piotr Szyma\u0144ski",
      "Piotr Syga"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.01429",
    "title": "A Closer Look at the Adversarial Robustness of Deep Equilibrium Models",
    "abstract": "Deep equilibrium models (DEQs) refrain from the traditional layer-stacking paradigm and turn to find the fixed point of a single layer. DEQs have achieved promising performance on different applications with featured memory efficiency. At the same time, the adversarial vulnerability of DEQs raises concerns. Several works propose to certify robustness for monotone DEQs. However, limited efforts are devoted to studying empirical robustness for general DEQs. To this end, we observe that an adversarially trained DEQ requires more forward steps to arrive at the equilibrium state, or even violates its fixed-point structure. Besides, the forward and backward tracks of DEQs are misaligned due to the black-box solvers. These facts cause gradient obfuscation when applying the ready-made attacks to evaluate or adversarially train DEQs. Given this, we develop approaches to estimate the intermediate gradients of DEQs and integrate them into the attacking pipelines. Our approaches facilitate fully white-box evaluations and lead to effective adversarial defense for DEQs. Extensive experiments on CIFAR-10 validate the adversarial robustness of DEQs competitive with deep networks of similar sizes. ",
    "url": "https://arxiv.org/abs/2306.01429",
    "authors": [
      "Zonghan Yang",
      "Tianyu Pang",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01435",
    "title": "Improving Adversarial Robustness of DEQs with Explicit Regulations Along  the Neural Dynamics",
    "abstract": "Deep equilibrium (DEQ) models replace the multiple-layer stacking of conventional deep networks with a fixed-point iteration of a single-layer transformation. Having been demonstrated to be competitive in a variety of real-world scenarios, the adversarial robustness of general DEQs becomes increasingly crucial for their reliable deployment. Existing works improve the robustness of general DEQ models with the widely-used adversarial training (AT) framework, but they fail to exploit the structural uniquenesses of DEQ models. To this end, we interpret DEQs through the lens of neural dynamics and find that AT under-regulates intermediate states. Besides, the intermediate states typically provide predictions with a high prediction entropy. Informed by the correlation between the entropy of dynamical systems and their stability properties, we propose reducing prediction entropy by progressively updating inputs along the neural dynamics. During AT, we also utilize random intermediate states to compute the loss function. Our methods regulate the neural dynamics of DEQ models in this manner. Extensive experiments demonstrate that our methods substantially increase the robustness of DEQ models and even outperform the strong deep network baselines. ",
    "url": "https://arxiv.org/abs/2306.01435",
    "authors": [
      "Zonghan Yang",
      "Peng Li",
      "Tianyu Pang",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01438",
    "title": "Bi-LRFusion: Bi-Directional LiDAR-Radar Fusion for 3D Dynamic Object  Detection",
    "abstract": "LiDAR and Radar are two complementary sensing approaches in that LiDAR specializes in capturing an object's 3D shape while Radar provides longer detection ranges as well as velocity hints. Though seemingly natural, how to efficiently combine them for improved feature representation is still unclear. The main challenge arises from that Radar data are extremely sparse and lack height information. Therefore, directly integrating Radar features into LiDAR-centric detection networks is not optimal. In this work, we introduce a bi-directional LiDAR-Radar fusion framework, termed Bi-LRFusion, to tackle the challenges and improve 3D detection for dynamic objects. Technically, Bi-LRFusion involves two steps: first, it enriches Radar's local features by learning important details from the LiDAR branch to alleviate the problems caused by the absence of height information and extreme sparsity; second, it combines LiDAR features with the enhanced Radar features in a unified bird's-eye-view representation. We conduct extensive experiments on nuScenes and ORR datasets, and show that our Bi-LRFusion achieves state-of-the-art performance for detecting dynamic objects. Notably, Radar data in these two datasets have different formats, which demonstrates the generalizability of our method. Codes are available at https://github.com/JessieW0806/BiLRFusion. ",
    "url": "https://arxiv.org/abs/2306.01438",
    "authors": [
      "Yingjie Wang",
      "Jiajun Deng",
      "Yao Li",
      "Jinshui Hu",
      "Cong Liu",
      "Yu Zhang",
      "Jianmin Ji",
      "Wanli Ouyang",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01442",
    "title": "Towards Robust FastSpeech 2 by Modelling Residual Multimodality",
    "abstract": "State-of-the-art non-autoregressive text-to-speech (TTS) models based on FastSpeech 2 can efficiently synthesise high-fidelity and natural speech. For expressive speech datasets however, we observe characteristic audio distortions. We demonstrate that such artefacts are introduced to the vocoder reconstruction by over-smooth mel-spectrogram predictions, which are induced by the choice of mean-squared-error (MSE) loss for training the mel-spectrogram decoder. With MSE loss FastSpeech 2 is limited to learn conditional averages of the training distribution, which might not lie close to a natural sample if the distribution still appears multimodal after all conditioning signals. To alleviate this problem, we introduce TVC-GMM, a mixture model of Trivariate-Chain Gaussian distributions, to model the residual multimodality. TVC-GMM reduces spectrogram smoothness and improves perceptual audio quality in particular for expressive datasets as shown by both objective and subjective evaluation. ",
    "url": "https://arxiv.org/abs/2306.01442",
    "authors": [
      "Fabian K\u00f6gel",
      "Bac Nguyen",
      "Fabien Cardinaux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.01485",
    "title": "Robust low-rank training via approximate orthonormal constraints",
    "abstract": "With the growth of model and data sizes, a broad effort has been made to design pruning techniques that reduce the resource demand of deep learning pipelines, while retaining model performance. In order to reduce both inference and training costs, a prominent line of work uses low-rank matrix factorizations to represent the network weights. Although able to retain accuracy, we observe that low-rank methods tend to compromise model robustness against adversarial perturbations. By modeling robustness in terms of the condition number of the neural network, we argue that this loss of robustness is due to the exploding singular values of the low-rank weight matrices. Thus, we introduce a robust low-rank training algorithm that maintains the network's weights on the low-rank matrix manifold while simultaneously enforcing approximate orthonormal constraints. The resulting model reduces both training and inference costs while ensuring well-conditioning and thus better adversarial robustness, without compromising model accuracy. This is shown by extensive numerical evidence and by our main approximation theorem that shows the computed robust low-rank network well-approximates the ideal full model, provided a highly performing low-rank sub-network exists. ",
    "url": "https://arxiv.org/abs/2306.01485",
    "authors": [
      "Dayana Savostianova",
      "Emanuele Zangrando",
      "Gianluca Ceruti",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01505",
    "title": "Supervised Adversarial Contrastive Learning for Emotion Recognition in  Conversations",
    "abstract": "Extracting generalized and robust representations is a major challenge in emotion recognition in conversations (ERC). To address this, we propose a supervised adversarial contrastive learning (SACL) framework for learning class-spread structured representations. The framework applies contrast-aware adversarial training to generate worst-case samples and uses a joint class-spread contrastive learning objective on both original and adversarial samples. It can effectively utilize label-level feature consistency and retain fine-grained intra-class features. To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training strategy to learn more diverse features from context and enhance the model's context robustness. We develop a sequence-based method SACL-LSTM under this framework, to learn label-consistent and context-robust emotional features for ERC. Experiments on three datasets demonstrate that SACL-LSTM achieves state-of-the-art performance on ERC. Extended experiments prove the effectiveness of the SACL framework. ",
    "url": "https://arxiv.org/abs/2306.01505",
    "authors": [
      "Dou Hu",
      "Yinan Bao",
      "Lingwei Wei",
      "Wei Zhou",
      "Songlin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01506",
    "title": "BabySLM: language-acquisition-friendly benchmark of self-supervised  spoken language models",
    "abstract": "Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech. ",
    "url": "https://arxiv.org/abs/2306.01506",
    "authors": [
      "Marvin Lavechin",
      "Yaya Sy",
      "Hadrien Titeux",
      "Mar\u00eda Andrea Cruz Bland\u00f3n",
      "Okko R\u00e4s\u00e4nen",
      "Herv\u00e9 Bredin",
      "Emmanuel Dupoux",
      "Alejandrina Cristia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01507",
    "title": "One for All: Unified Workload Prediction for Dynamic Multi-tenant Edge  Cloud Platforms",
    "abstract": "Workload prediction in multi-tenant edge cloud platforms (MT-ECP) is vital for efficient application deployment and resource provisioning. However, the heterogeneous application patterns, variable infrastructure performance, and frequent deployments in MT-ECP pose significant challenges for accurate and efficient workload prediction. Clustering-based methods for dynamic MT-ECP modeling often incur excessive costs due to the need to maintain numerous data clusters and models, which leads to excessive costs. Existing end-to-end time series prediction methods are challenging to provide consistent prediction performance in dynamic MT-ECP. In this paper, we propose an end-to-end framework with global pooling and static content awareness, DynEformer, to provide a unified workload prediction scheme for dynamic MT-ECP. Meticulously designed global pooling and information merging mechanisms can effectively identify and utilize global application patterns to drive local workload predictions. The integration of static content-aware mechanisms enhances model robustness in real-world scenarios. Through experiments on five real-world datasets, DynEformer achieved state-of-the-art in the dynamic scene of MT-ECP and provided a unified end-to-end prediction scheme for MT-ECP. ",
    "url": "https://arxiv.org/abs/2306.01507",
    "authors": [
      "Shaoyuan Huang",
      "Zheng Wang",
      "Heng Zhang",
      "Xiaofei Wang",
      "Cheng Zhang",
      "Wenyu Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01513",
    "title": "Network Degeneracy as an Indicator of Training Performance: Comparing  Finite and Infinite Width Angle Predictions",
    "abstract": "Neural networks are powerful functions with widespread use, but the theoretical behaviour of these functions is not fully understood. Creating deep neural networks by stacking many layers has achieved exceptional performance in many applications and contributed to the recent explosion of these methods. Previous works have shown that depth can exponentially increase the expressibility of the network. However, as networks get deeper and deeper, they are more susceptible to becoming degenerate. We observe this degeneracy in the sense that on initialization, inputs tend to become more and more correlated as they travel through the layers of the network. If a network has too many layers, it tends to approximate a (random) constant function, making it effectively incapable of distinguishing between inputs. This seems to affect the training of the network and cause it to perform poorly, as we empirically investigate in this paper. We use a simple algorithm that can accurately predict the level of degeneracy for any given fully connected ReLU network architecture, and demonstrate how the predicted degeneracy relates to training dynamics of the network. We also compare this prediction to predictions derived using infinite width networks. ",
    "url": "https://arxiv.org/abs/2306.01513",
    "authors": [
      "Cameron Jakub",
      "Mihai Nica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01517",
    "title": "Parameterized Broadcast Networks with Registers: from NP to the  Frontiers of Decidability",
    "abstract": "We consider the parameterized verification of arbitrarily large networks of agents which communicate by broadcasting and receiving messages. In our model, the broadcast topology is reconfigurable so that a sent message can be received by any set of agents. In addition, agents have local registers which are initially distinct and may therefore be thought of as identifiers. When an agent broadcasts a message, it appends to the message the value stored in one of its registers. Upon reception, an agent can store the received value or test this value for equality with one of its own registers. We consider the coverability problem, where one asks whether a given state of the system may be reached by at least one agent. We establish that this problem is decidable; however, it is as hard as coverability in lossy channel systems, which is non-primitive recursive. This model lies at the frontier of decidability as other classical problems on this model are undecidable; this is in particular true for the target problem where all processes must synchronize on a given state. By contrast, we show that the coverability problem is NP-complete when each agent has only one register. ",
    "url": "https://arxiv.org/abs/2306.01517",
    "authors": [
      "Lucie Guillou",
      "Corto Mascle",
      "Nicolas Waldburger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2306.01526",
    "title": "Group channel pruning and spatial attention distilling for object  detection",
    "abstract": "Due to the over-parameterization of neural networks, many model compression methods based on pruning and quantization have emerged. They are remarkable in reducing the size, parameter number, and computational complexity of the model. However, most of the models compressed by such methods need the support of special hardware and software, which increases the deployment cost. Moreover, these methods are mainly used in classification tasks, and rarely directly used in detection tasks. To address these issues, for the object detection network we introduce a three-stage model compression method: dynamic sparse training, group channel pruning, and spatial attention distilling. Firstly, to select out the unimportant channels in the network and maintain a good balance between sparsity and accuracy, we put forward a dynamic sparse training method, which introduces a variable sparse rate, and the sparse rate will change with the training process of the network. Secondly, to reduce the effect of pruning on network accuracy, we propose a novel pruning method called group channel pruning. In particular, we divide the network into multiple groups according to the scales of the feature layer and the similarity of module structure in the network, and then we use different pruning thresholds to prune the channels in each group. Finally, to recover the accuracy of the pruned network, we use an improved knowledge distillation method for the pruned network. Especially, we extract spatial attention information from the feature maps of specific scales in each group as knowledge for distillation. In the experiments, we use YOLOv4 as the object detection network and PASCAL VOC as the training dataset. Our method reduces the parameters of the model by 64.7 % and the calculation by 34.9%. ",
    "url": "https://arxiv.org/abs/2306.01526",
    "authors": [
      "Yun Chu",
      "Pu Li",
      "Yong Bai",
      "Zhuhua Hu",
      "Yongqing Chen",
      "Jiafeng Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01533",
    "title": "Enhance Temporal Relations in Audio Captioning with Sound Event  Detection",
    "abstract": "Automated audio captioning aims at generating natural language descriptions for given audio clips, not only detecting and classifying sounds, but also summarizing the relationships between audio events. Recent research advances in audio captioning have introduced additional guidance to improve the accuracy of audio events in generated sentences. However, temporal relations between audio events have received little attention while revealing complex relations is a key component in summarizing audio content. Therefore, this paper aims to better capture temporal relationships in caption generation with sound event detection (SED), a task that locates events' timestamps. We investigate the best approach to integrate temporal information in a captioning model and propose a temporal tag system to transform the timestamps into comprehensible relations. Results evaluated by the proposed temporal metrics suggest that great improvement is achieved in terms of temporal relation generation. ",
    "url": "https://arxiv.org/abs/2306.01533",
    "authors": [
      "Zeyu Xie",
      "Xuenan Xu",
      "Mengyue Wu",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.01536",
    "title": "Parameterized Complexity of Broadcasting in Graphs",
    "abstract": "The task of the broadcast problem is, given a graph G and a source vertex s, to compute the minimum number of rounds required to disseminate a piece of information from s to all vertices in the graph. It is assumed that, at each round, an informed vertex can transmit the information to at most one of its neighbors. The broadcast problem is known to NP-hard. We show that the problem is FPT when parametrized by the size k of a feedback edge-set, or by the size k of a vertex-cover, or by k=n-t where t is the input deadline for the broadcast protocol to complete. ",
    "url": "https://arxiv.org/abs/2306.01536",
    "authors": [
      "Fedor V. Fomin",
      "Pierre Fraigniaud",
      "Petr A. Golovach"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.01540",
    "title": "CLIPGraphs: Multimodal Graph Networks to Infer Object-Room Affinities",
    "abstract": "This paper introduces a novel method for determining the best room to place an object in, for embodied scene rearrangement. While state-of-the-art approaches rely on large language models (LLMs) or reinforcement learned (RL) policies for this task, our approach, CLIPGraphs, efficiently combines commonsense domain knowledge, data-driven methods, and recent advances in multimodal learning. Specifically, it (a)encodes a knowledge graph of prior human preferences about the room location of different objects in home environments, (b) incorporates vision-language features to support multimodal queries based on images or text, and (c) uses a graph network to learn object-room affinities based on embeddings of the prior knowledge and the vision-language features. We demonstrate that our approach provides better estimates of the most appropriate location of objects from a benchmark set of object categories in comparison with state-of-the-art baselines ",
    "url": "https://arxiv.org/abs/2306.01540",
    "authors": [
      "Ayush Agrawal",
      "Raghav Arora",
      "Ahana Datta",
      "Snehasis Banerjee",
      "Brojeshwar Bhowmick",
      "Krishna Murthy Jatavallabhula",
      "Mohan Sridharan",
      "Madhava Krishna"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.01623",
    "title": "HomE: Homography-Equivariant Video Representation Learning",
    "abstract": "Recent advances in self-supervised representation learning have enabled more efficient and robust model performance without relying on extensive labeled data. However, most works are still focused on images, with few working on videos and even fewer on multi-view videos, where more powerful inductive biases can be leveraged for self-supervision. In this work, we propose a novel method for representation learning of multi-view videos, where we explicitly model the representation space to maintain Homography Equivariance (HomE). Our method learns an implicit mapping between different views, culminating in a representation space that maintains the homography relationship between neighboring views. We evaluate our HomE representation via action recognition and pedestrian intent prediction as downstream tasks. On action classification, our method obtains 96.4% 3-fold accuracy on the UCF101 dataset, better than most state-of-the-art self-supervised learning methods. Similarly, on the STIP dataset, we outperform the state-of-the-art by 6% for pedestrian intent prediction one second into the future while also obtaining an accuracy of 91.2% for pedestrian action (cross vs. not-cross) classification. Code is available at https://github.com/anirudhs123/HomE. ",
    "url": "https://arxiv.org/abs/2306.01623",
    "authors": [
      "Anirudh Sriram",
      "Adrien Gaidon",
      "Jiajun Wu",
      "Juan Carlos Niebles",
      "Li Fei-Fei",
      "Ehsan Adeli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01631",
    "title": "Gode -- Integrating Biochemical Knowledge Graph into Pre-training  Molecule Graph Neural Network",
    "abstract": "The precise prediction of molecular properties holds paramount importance in facilitating the development of innovative treatments and comprehending the intricate interplay between chemicals and biological systems. In this study, we propose a novel approach that integrates graph representations of individual molecular structures with multi-domain information from biomedical knowledge graphs (KGs). Integrating information from both levels, we can pre-train a more extensive and robust representation for both molecule-level and KG-level prediction tasks with our novel self-supervision strategy. For performance evaluation, we fine-tune our pre-trained model on 11 challenging chemical property prediction tasks. Results from our framework demonstrate our fine-tuned models outperform existing state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2306.01631",
    "authors": [
      "Pengcheng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.01635",
    "title": "Q&A: Query-Based Representation Learning for Multi-Track Symbolic Music  re-Arrangement",
    "abstract": "Music rearrangement is a common music practice of reconstructing and reconceptualizing a piece using new composition or instrumentation styles, which is also an important task of automatic music generation. Existing studies typically model the mapping from a source piece to a target piece via supervised learning. In this paper, we tackle rearrangement problems via self-supervised learning, in which the mapping styles can be regarded as conditions and controlled in a flexible way. Specifically, we are inspired by the representation disentanglement idea and propose Q&A, a query-based algorithm for multi-track music rearrangement under an encoder-decoder framework. Q&A learns both a content representation from the mixture and function (style) representations from each individual track, while the latter queries the former in order to rearrange a new piece. Our current model focuses on popular music and provides a controllable pathway to four scenarios: 1) re-instrumentation, 2) piano cover generation, 3) orchestration, and 4) voice separation. Experiments show that our query system achieves high-quality rearrangement results with delicate multi-track structures, significantly outperforming the baselines. ",
    "url": "https://arxiv.org/abs/2306.01635",
    "authors": [
      "Jingwei Zhao",
      "Gus Xia",
      "Ye Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.01645",
    "title": "Quantifying synergy and redundancy in multiplex networks",
    "abstract": "Understanding how different networks relate to each other is key for obtaining a greater insight into complex systems. Here, we introduce an intuitive yet powerful framework to characterise the relationship between two networks, comprising the same nodes. We showcase our framework by decomposing the shortest paths between nodes as being contributed uniquely by one or the other source network, or redundantly by either, or synergistically by the two together. Our approach takes into account the networks' full topology, but it also provides insights at multiple levels of resolution: from global statistics, to individual paths of different length. We show that this approach is widely applicable, from brains to the London transport system. In humans and across $123$ other species, we demonstrate that reliance on unique contributions by long-range white matter fibers is a conserved feature of mammalian structural connectomes. Across species, we also find that efficient communication relies on significantly greater synergy between long-range and short-range fibers than expected by chance, and significantly less redundancy. Our framework may find applications to help decide how to trade-off different desiderata when designing network systems, or to evaluate their relative presence in existing systems, whether biological or artificial. ",
    "url": "https://arxiv.org/abs/2306.01645",
    "authors": [
      "Andrea I. Luppi",
      "Eckehard Olbrich",
      "Conor Finn",
      "Laura E. Su\u00e1rez",
      "Fernando E. Rosas",
      "Pedro A.M. Mediano",
      "J\u00fcrgen Jost"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.01650",
    "title": "Fair multilingual vandalism detection system for Wikipedia",
    "abstract": "This paper presents a novel design of the system aimed at supporting the Wikipedia community in addressing vandalism on the platform. To achieve this, we collected a massive dataset of 47 languages, and applied advanced filtering and feature engineering techniques, including multilingual masked language modeling to build the training dataset from human-generated data. The performance of the system was evaluated through comparison with the one used in production in Wikipedia, known as ORES. Our research results in a significant increase in the number of languages covered, making Wikipedia patrolling more efficient to a wider range of communities. Furthermore, our model outperforms ORES, ensuring that the results provided are not only more accurate but also less biased against certain groups of contributors. ",
    "url": "https://arxiv.org/abs/2306.01650",
    "authors": [
      "Mykola Trokhymovych",
      "Muniza Aslam",
      "Ai-Jou Chou",
      "Ricardo Baeza-Yates",
      "Diego Saez-Trumper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01652",
    "title": "On the Coverage of Cognitive mmWave Networks with Directional Sensing  and Communication",
    "abstract": "Millimeter-waves' propagation characteristics create prospects for spatial and temporal spectrum sharing in a variety of contexts, including cognitive spectrum sharing (CSS). However, CSS along with omnidirectional sensing, is not efficient at mmWave frequencies due to their directional nature of transmission, as this limits secondary networks' ability to access the spectrum. This inspired us to create an analytical approach using stochastic geometry to examine the implications of directional cognitive sensing in mmWave networks. We explore a scenario where multiple secondary transmitter-receiver pairs coexist with a primary transmitter-receiver pair, forming a cognitive network. The positions of the secondary transmitters are modelled using a homogeneous Poisson point process (PPP) with corresponding secondary receivers located around them. A threshold on directional transmission is imposed on each secondary transmitter in order to limit its interference at the primary receiver. We derive the medium-access-probability of a secondary user along with the fraction of the secondary transmitters active at a time-instant. To understand cognition's feasibility, we derive the coverage probabilities of primary and secondary links. We provide various design insights via numerical results. For example, we investigate the interference-threshold's optimal value while ensuring coverage for both links and its dependence on various parameters. We find that directionality improves both links' performance as a key factor. Further, allowing location-aware secondary directionality can help achieve similar coverage for all secondary links. ",
    "url": "https://arxiv.org/abs/2306.01652",
    "authors": [
      "Shuchi Tripathi",
      "Abhishek K. Gupta",
      "SaiDhiraj Amuru"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.01655",
    "title": "Poisoning Network Flow Classifiers",
    "abstract": "As machine learning (ML) classifiers increasingly oversee the automated monitoring of network traffic, studying their resilience against adversarial attacks becomes critical. This paper focuses on poisoning attacks, specifically backdoor attacks, against network traffic flow classifiers. We investigate the challenging scenario of clean-label poisoning where the adversary's capabilities are constrained to tampering only with the training data - without the ability to arbitrarily modify the training labels or any other component of the training process. We describe a trigger crafting strategy that leverages model interpretability techniques to generate trigger patterns that are effective even at very low poisoning rates. Finally, we design novel strategies to generate stealthy triggers, including an approach based on generative Bayesian network models, with the goal of minimizing the conspicuousness of the trigger, and thus making detection of an ongoing poisoning campaign more challenging. Our findings provide significant insights into the feasibility of poisoning attacks on network traffic classifiers used in multiple scenarios, including detecting malicious communication and application classification. ",
    "url": "https://arxiv.org/abs/2306.01655",
    "authors": [
      "Giorgio Severi",
      "Simona Boboila",
      "Alina Oprea",
      "John Holodnak",
      "Kendra Kratkiewicz",
      "Jason Matterer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01656",
    "title": "Backchannel Detection and Agreement Estimation from Video with  Transformer Networks",
    "abstract": "Listeners use short interjections, so-called backchannels, to signify attention or express agreement. The automatic analysis of this behavior is of key importance for human conversation analysis and interactive conversational agents. Current state-of-the-art approaches for backchannel analysis from visual behavior make use of two types of features: features based on body pose and features based on facial behavior. At the same time, transformer neural networks have been established as an effective means to fuse input from different data sources, but they have not yet been applied to backchannel analysis. In this work, we conduct a comprehensive evaluation of multi-modal transformer architectures for automatic backchannel analysis based on pose and facial information. We address both the detection of backchannels as well as the task of estimating the agreement expressed in a backchannel. In evaluations on the MultiMediate'22 backchannel detection challenge, we reach 66.4% accuracy with a one-layer transformer architecture, outperforming the previous state of the art. With a two-layer transformer architecture, we furthermore set a new state of the art (0.0604 MSE) on the task of estimating the amount of agreement expressed in a backchannel. ",
    "url": "https://arxiv.org/abs/2306.01656",
    "authors": [
      "Ahmed Amer",
      "Chirag Bhuvaneshwara",
      "Gowtham K. Addluri",
      "Mohammed M. Shaik",
      "Vedant Bonde",
      "Philipp M\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2306.01665",
    "title": "SourceP: Smart Ponzi Schemes Detection on Ethereum Using Pre-training  Model with Data Flow",
    "abstract": "As blockchain technology becomes more and more popular, a typical financial scam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum. This Ponzi scheme deployed through smart contracts, also known as the smart Ponzi scheme, has caused a lot of economic losses and negative impacts. Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely on bytecode features, opcode features, account features, and transaction behavior features of smart contracts, and such methods lack interpretability and sustainability. In this paper, we propose SourceP, a method to detect smart Ponzi schemes on the Ethereum platform using pre-training models and data flow, which only requires using the source code of smart contracts as features to explore the possibility of detecting smart Ponzi schemes from another direction. SourceP reduces the difficulty of data acquisition and feature extraction of existing detection methods while increasing the interpretability of the model. Specifically, we first convert the source code of a smart contract into a data flow graph and then introduce a pre-training model based on learning code representations to build a classification model to identify Ponzi schemes in smart contracts. The experimental results show that SourceP achieves 87.2\\% recall and 90.7\\% F-score for detecting smart Ponzi schemes within Ethereum's smart contract dataset, outperforming state-of-the-art methods in terms of performance and sustainability. We also demonstrate through additional experiments that pre-training models and data flow play an important contribution to SourceP, as well as proving that SourceP has a good generalization ability. ",
    "url": "https://arxiv.org/abs/2306.01665",
    "authors": [
      "Pengcheng Lu",
      "Liang Cai",
      "Keting Yin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01692",
    "title": "Uniform Convergence of Deep Neural Networks with Lipschitz Continuous  Activation Functions and Variable Widths",
    "abstract": "We consider deep neural networks with a Lipschitz continuous activation function and with weight matrices of variable widths. We establish a uniform convergence analysis framework in which sufficient conditions on weight matrices and bias vectors together with the Lipschitz constant are provided to ensure uniform convergence of the deep neural networks to a meaningful function as the number of their layers tends to infinity. In the framework, special results on uniform convergence of deep neural networks with a fixed width, bounded widths and unbounded widths are presented. In particular, as convolutional neural networks are special deep neural networks with weight matrices of increasing widths, we put forward conditions on the mask sequence which lead to uniform convergence of resulting convolutional neural networks. The Lipschitz continuity assumption on the activation functions allows us to include in our theory most of commonly used activation functions in applications. ",
    "url": "https://arxiv.org/abs/2306.01692",
    "authors": [
      "Yuesheng Xu",
      "Haizhang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01725",
    "title": "Graph Sparsification for GCN Towards Optimal Crop Yield Predictions",
    "abstract": "In agronomics, predicting crop yield at a per field/county granularity is important for farmers to minimize uncertainty and plan seeding for the next crop cycle. While state-of-the-art prediction techniques employ graph convolutional nets (GCN) to predict future crop yields given relevant features and crop yields of previous years, a dense underlying graph kernel requires long training and execution time. In this paper, we propose a graph sparsification method based on the Fiedler number to remove edges from a complete graph kernel, in order to lower the complexity of GCN training/execution. Specifically, we first show that greedily removing an edge at a time that induces the minimal change in the second eigenvalue leads to a sparse graph with good GCN performance. We then propose a fast method to choose an edge for removal per iteration based on an eigenvalue perturbation theorem. Experiments show that our Fiedler-based method produces a sparse graph with good GCN performance compared to other graph sparsification schemes in crop yield prediction. ",
    "url": "https://arxiv.org/abs/2306.01725",
    "authors": [
      "Saghar Bagheri",
      "Gene Cheung",
      "Tim Eadie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01731",
    "title": "PAGAR: Imitation Learning with Protagonist Antagonist Guided Adversarial  Reward",
    "abstract": "Imitation learning (IL) algorithms often rely on inverse reinforcement learning (IRL) to first learn a reward function from expert demonstrations. However, IRL can suffer from identifiability issues and there is no performance or efficiency guarantee when training with the learned reward function. In this paper, we propose Protagonist Antagonist Guided Adversarial Reward (PAGAR), a semi-supervised learning paradigm for designing rewards for policy training. PAGAR employs an iterative adversarially search for reward functions to maximize the performance gap between a protagonist policy and an antagonist policy. This allows the protagonist policy to perform well across a set of possible reward functions despite the identifiability issue. When integrated with IRL-based IL, PAGAR guarantees that the trained policy succeeds in the underlying task. Furthermore, we introduce a practical on-and-off policy approach to IL with PAGAR. This approach maximally utilizes samples from both the protagonist and antagonist policies for the optimization of policy and reward functions. Experimental results demonstrate that our algorithm achieves higher training efficiency compared to state-of-the-art IL/IRL baselines in standard settings, as well as zero-shot learning from demonstrations in transfer environments. ",
    "url": "https://arxiv.org/abs/2306.01731",
    "authors": [
      "Weichao Zhou",
      "Wenchao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01738",
    "title": "OCBEV: Object-Centric BEV Transformer for Multi-View 3D Object Detection",
    "abstract": "Multi-view 3D object detection is becoming popular in autonomous driving due to its high effectiveness and low cost. Most of the current state-of-the-art detectors follow the query-based bird's-eye-view (BEV) paradigm, which benefits from both BEV's strong perception power and end-to-end pipeline. Despite achieving substantial progress, existing works model objects via globally leveraging temporal and spatial information of BEV features, resulting in problems when handling the challenging complex and dynamic autonomous driving scenarios. In this paper, we proposed an Object-Centric query-BEV detector OCBEV, which can carve the temporal and spatial cues of moving targets more effectively. OCBEV comprises three designs: Object Aligned Temporal Fusion aligns the BEV feature based on ego-motion and estimated current locations of moving objects, leading to a precise instance-level feature fusion. Object Focused Multi-View Sampling samples more 3D features from an adaptive local height ranges of objects for each scene to enrich foreground information. Object Informed Query Enhancement replaces part of pre-defined decoder queries in common DETR-style decoders with positional features of objects on high-confidence locations, introducing more direct object positional priors. Extensive experimental evaluations are conducted on the challenging nuScenes dataset. Our approach achieves a state-of-the-art result, surpassing the traditional BEVFormer by 1.5 NDS points. Moreover, we have a faster convergence speed and only need half of the training iterations to get comparable performance, which further demonstrates its effectiveness. ",
    "url": "https://arxiv.org/abs/2306.01738",
    "authors": [
      "Zhangyang Qi",
      "Jiaqi Wang",
      "Xiaoyang Wu",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01212",
    "title": "Linked Deep Gaussian Process Emulation for Model Networks",
    "abstract": "Modern scientific problems are often multi-disciplinary and require integration of computer models from different disciplines, each with distinct functional complexities, programming environments, and computation times. Linked Gaussian process (LGP) emulation tackles this challenge through a divide-and-conquer strategy that integrates Gaussian process emulators of the individual computer models in a network. However, the required stationarity of the component Gaussian process emulators within the LGP framework limits its applicability in many real-world applications. In this work, we conceptualize a network of computer models as a deep Gaussian process with partial exposure of its hidden layers. We develop a method for inference for these partially exposed deep networks that retains a key strength of the LGP framework, whereby each model can be emulated separately using a DGP and then linked together. We show in both synthetic and empirical examples that our linked deep Gaussian process emulators exhibit significantly better predictive performance than standard LGP emulators in terms of accuracy and uncertainty quantification. They also outperform single DGPs fitted to the network as a whole because they are able to integrate information from the partially exposed hidden layers. Our methods are implemented in an R package $\\texttt{dgpsi}$ that is freely available on CRAN. ",
    "url": "https://arxiv.org/abs/2306.01212",
    "authors": [
      "Deyu Ming",
      "Daniel Williamson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.01341",
    "title": "New bounds for odd colourings of graphs",
    "abstract": "Given a graph $G$, a vertex-colouring $\\sigma$ of $G$, and a subset $X\\subseteq V(G)$, a colour $x \\in \\sigma(X)$ is said to be \\emph{odd} for $X$ in $\\sigma$ if it has an odd number of occurrences in $X$. We say that $\\sigma$ is an \\emph{odd colouring} of $G$ if it is proper and every (open) neighbourhood has an odd colour in $\\sigma$. The odd chromatic number of a graph $G$, denoted by $\\chi_o(G)$, is the minimum $k\\in\\mathbb{N}$ such that an odd colouring $\\sigma \\colon V(G)\\to [k]$ exists. In a recent paper, Caro, Petru\\v sevski and \\v Skrekovski conjectured that every connected graph of maximum degree $\\Delta\\ge 3$ has odd-chromatic number at most $\\Delta+1$. We prove that this conjecture holds asymptotically: for every connected graph $G$ with maximum degree $\\Delta$, $\\chi_o(G)\\le\\Delta+O(\\ln\\Delta)$ as $\\Delta \\to \\infty$. We also prove that $\\chi_o(G)\\le\\lfloor3\\Delta/2\\rfloor+2$ for every $\\Delta$. If moreover the minimum degree $\\delta$ of $G$ is sufficiently large, we have $\\chi_o(G) \\le \\chi(G) + O(\\Delta \\ln \\Delta/\\delta)$ and $\\chi_o(G) = O(\\chi(G)\\ln \\Delta)$. Finally, given an integer $h\\ge 1$, we study the generalisation of these results to $h$-odd colourings, where every vertex $v$ must have at least $\\min \\{\\deg(v),h\\}$ odd colours in its neighbourhood. Many of our results are tight up to some multiplicative constant. ",
    "url": "https://arxiv.org/abs/2306.01341",
    "authors": [
      "Tianjiao Dai",
      "Qiancheng Ouyang",
      "Fran\u00e7ois Pirot"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.01375",
    "title": "Robust and Generalisable Segmentation of Subtle Epilepsy-causing  Lesions: a Graph Convolutional Approach",
    "abstract": "Focal cortical dysplasia (FCD) is a leading cause of drug-resistant focal epilepsy, which can be cured by surgery. These lesions are extremely subtle and often missed even by expert neuroradiologists. \"Ground truth\" manual lesion masks are therefore expensive, limited and have large inter-rater variability. Existing FCD detection methods are limited by high numbers of false positive predictions, primarily due to vertex- or patch-based approaches that lack whole-brain context. Here, we propose to approach the problem as semantic segmentation using graph convolutional networks (GCN), which allows our model to learn spatial relationships between brain regions. To address the specific challenges of FCD identification, our proposed model includes an auxiliary loss to predict distance from the lesion to reduce false positives and a weak supervision classification loss to facilitate learning from uncertain lesion masks. On a multi-centre dataset of 1015 participants with surface-based features and manual lesion masks from structural MRI data, the proposed GCN achieved an AUC of 0.74, a significant improvement against a previously used vertex-wise multi-layer perceptron (MLP) classifier (AUC 0.64). With sensitivity thresholded at 67%, the GCN had a specificity of 71% in comparison to 49% when using the MLP. This improvement in specificity is vital for clinical integration of lesion-detection tools into the radiological workflow, through increasing clinical confidence in the use of AI radiological adjuncts and reducing the number of areas requiring expert review. ",
    "url": "https://arxiv.org/abs/2306.01375",
    "authors": [
      "Hannah Spitzer",
      "Mathilde Ripart",
      "Abdulah Fawaz",
      "Logan Z. J. Williams",
      "MELD project",
      "Emma Robinson",
      "Juan Eugenio Iglesias",
      "Sophie Adler",
      "Konrad Wagstyl"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01385",
    "title": "Task-Agnostic Structured Pruning of Speech Representation Models",
    "abstract": "Self-supervised pre-trained models such as Wav2vec2, Hubert, and WavLM have been shown to significantly improve many speech tasks. However, their large memory and strong computational requirements hinder their industrial applicability. Structured pruning is a hardware-friendly model compression technique but usually results in a larger loss of accuracy. In this paper, we propose a fine-grained attention head pruning method to compensate for the performance degradation. In addition, we also introduce the straight through estimator into the L0 regularization to further accelerate the pruned model. Experiments on the SUPERB benchmark show that our model can achieve comparable performance to the dense model in multiple tasks and outperforms the Wav2vec 2.0 base model on average, with 72% fewer parameters and 2 times faster inference speed. ",
    "url": "https://arxiv.org/abs/2306.01385",
    "authors": [
      "Haoyu Wang",
      "Siyuan Wang",
      "Wei-Qiang Zhang",
      "Hongbin Suo",
      "Yulong Wan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2306.01411",
    "title": "HD-DEMUCS: General Speech Restoration with Heterogeneous Decoders",
    "abstract": "This paper introduces an end-to-end neural speech restoration model, HD-DEMUCS, demonstrating efficacy across multiple distortion environments. Unlike conventional approaches that employ cascading frameworks to remove undesirable noise first and then restore missing signal components, our model performs these tasks in parallel using two heterogeneous decoder networks. Based on the U-Net style encoder-decoder framework, we attach an additional decoder so that each decoder network performs noise suppression or restoration separately. We carefully design each decoder architecture to operate appropriately depending on its objectives. Additionally, we improve performance by leveraging a learnable weighting factor, aggregating the two decoder output waveforms. Experimental results with objective metrics across various environments clearly demonstrate the effectiveness of our approach over a single decoder or multi-stage systems for general speech restoration task. ",
    "url": "https://arxiv.org/abs/2306.01411",
    "authors": [
      "Doyeon Kim",
      "Soo-Whan Chung",
      "Hyewon Han",
      "Youna Ji",
      "Hong-Goo Kang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2306.01522",
    "title": "Auditory Representation Effective for Estimating Vocal Tract Information",
    "abstract": "We can estimate the size of the speaker solely based on their speech sounds. We had proposed an auditory computational theory of the stabilised wavelet-Mellin transform (SWMT), which segregates information about the size and shape of vocal tract and glottal vibration, to explain this observation. It was demonstrated that the auditory representation or excitation pattern (EP) associated with a weighting function based on SWMT, referred to as \"SSI weigh\", made it possible to explain the psychometric functions of size perception. In this study, we investigated whether EP with SSI weight can precisely estimate vocal tract lengths (VTLs) which were measured using male and female MRI data. It was found that the use of SSI weight significantly improved the VTL estimation. Moreover, the estimation errors were significantly smaller in the EP with the SSI weight than those in the commonly used spectra derived from the Fourier transform, Mel filterbank, and WORLD vocoder. It was also shown that the SSI weight can be easily introduced into these spectra to improve the performance. ",
    "url": "https://arxiv.org/abs/2306.01522",
    "authors": [
      "Toshio Irino",
      "Shintaro Doan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2306.01638",
    "title": "Do we become wiser with time? On causal equivalence with tiered  background knowledge",
    "abstract": "Equivalence classes of DAGs (represented by CPDAGs) may be too large to provide useful causal information. Here, we address incorporating tiered background knowledge yielding restricted equivalence classes represented by 'tiered MPDAGs'. Tiered knowledge leads to considerable gains in informativeness and computational efficiency: We show that construction of tiered MPDAGs only requires application of Meek's 1st rule, and that tiered MPDAGs (unlike general MPDAGs) are chain graphs with chordal components. This entails simplifications e.g. of determining valid adjustment sets for causal effect estimation. Further, we characterise when one tiered ordering is more informative than another, providing insights into useful aspects of background knowledge. ",
    "url": "https://arxiv.org/abs/2306.01638",
    "authors": [
      "Christine W. Bang",
      "Vanessa Didelez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2306.01639",
    "title": "Reduction of finite sampling noise in quantum neural networks",
    "abstract": "Quantum neural networks (QNNs) use parameterized quantum circuits with data-dependent inputs and generate outputs through the evaluation of expectation values. Calculating these expectation values necessitates repeated circuit evaluations, thus introducing fundamental finite-sampling noise even on error-free quantum computers. We reduce this noise by introducing the variance regularization, a technique for reducing the variance of the expectation value during the quantum model training. This technique requires no additional circuit evaluations if the QNN is properly constructed. Our empirical findings demonstrate the reduced variance speeds up the training and lowers the output noise as well as decreases the number of measurements in the gradient circuit evaluation. This regularization method is benchmarked on the regression of multiple functions. We show that in our examples, it lowers the variance by an order of magnitude on average and leads to a significantly reduced noise level of the QNN. We finally demonstrate QNN training on a real quantum device and evaluate the impact of error mitigation. Here, the optimization is practical only due to the reduced number shots in the gradient evaluation resulting from the reduced variance. ",
    "url": "https://arxiv.org/abs/2306.01639",
    "authors": [
      "David Kreplin",
      "Marco Roth"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01674",
    "title": "Neural Differential Recurrent Neural Network with Adaptive Time Steps",
    "abstract": "The neural Ordinary Differential Equation (ODE) model has shown success in learning complex continuous-time processes from observations on discrete time stamps. In this work, we consider the modeling and forecasting of time series data that are non-stationary and may have sharp changes like spikes. We propose an RNN-based model, called RNN-ODE-Adap, that uses a neural ODE to represent the time development of the hidden states, and we adaptively select time steps based on the steepness of changes of the data over time so as to train the model more efficiently for the \"spike-like\" time series. Theoretically, RNN-ODE-Adap yields provably a consistent estimation of the intensity function for the Hawkes-type time series data. We also provide an approximation analysis of the RNN-ODE model showing the benefit of adaptive steps. The proposed model is demonstrated to achieve higher prediction accuracy with reduced computational cost on simulated dynamic system data and point process data and on a real electrocardiography dataset. ",
    "url": "https://arxiv.org/abs/2306.01674",
    "authors": [
      "Yixuan Tan",
      "Liyan Xie",
      "Xiuyuan Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.01689",
    "title": "Unique Brain Network Identification Number for Parkinson's Individuals  Using Structural MRI",
    "abstract": "We propose a novel algorithm called Unique Brain Network Identification Number (UBNIN) for encoding brain networks of individual subject. To realize this objective, we employed T1-weighted structural MRI of 180 Parkinson's disease (PD) patients from National Institute of Mental Health and Neurosciences, India. We parcellated each subject's brain volume and constructed individual adjacency matrix using correlation between grey matter (GM) volume of every pair of regions. The unique code is derived from values representing connections of every node (i), weighted by a factor of 2^-(i-1). The numerical representation UBNIN was observed to be distinct for each individual brain network, which may also be applied to other neuroimaging modalities. This model may be implemented as neural signature of a person's unique brain connectivity, thereby useful for brainprinting applications. Additionally, we segregated the above dataset into five age-cohorts: A:22-32years, B:33-42years, C:43-52years, D:53-62years and E:63-72years to study the variation in network topology over age. Sparsity was adopted as the threshold estimate to binarize each age-based correlation matrix. Connectivity metrics were obtained using Brain Connectivity toolbox-based MATLAB functions. For each age-cohort, a decreasing trend was observed in mean clustering coefficient with increasing sparsity. Significantly different clustering coefficient was noted between age-cohort B and C (sparsity: 0.63,0.66), C and E (sparsity: 0.66,0.69). Our findings suggest network connectivity patterns change with age, indicating network disruption due to the underlying neuropathology. Varying clustering coefficient for different cohorts indicate that information transfer between neighboring nodes change with age. This provides evidence on age-related brain shrinkage and network degeneration. ",
    "url": "https://arxiv.org/abs/2306.01689",
    "authors": [
      "Tanmayee Samantaray",
      "Utsav Gupta",
      "Jitender Saini",
      "Cota Navin Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.01710",
    "title": "A Data-Driven Measure of Relative Uncertainty for Misclassification  Detection",
    "abstract": "Misclassification detection is an important problem in machine learning, as it allows for the identification of instances where the model's predictions are unreliable. However, conventional uncertainty measures such as Shannon entropy do not provide an effective way to infer the real uncertainty associated with the model's predictions. In this paper, we introduce a novel data-driven measure of relative uncertainty to an observer for misclassification detection. By learning patterns in the distribution of soft-predictions, our uncertainty measure can identify misclassified samples based on the predicted class probabilities. Interestingly, according to the proposed measure, soft-predictions that correspond to misclassified instances can carry a large amount of uncertainty, even though they may have low Shannon entropy. We demonstrate empirical improvements over multiple image classification tasks, outperforming state-of-the-art misclassification detection methods. ",
    "url": "https://arxiv.org/abs/2306.01710",
    "authors": [
      "Eduardo Dadalto",
      "Marco Romanelli",
      "Georg Pichler",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1803.05001",
    "title": "Graph Ranking and the Cost of Sybil Defense",
    "abstract": " Comments: 39 pages ",
    "url": "https://arxiv.org/abs/1803.05001",
    "authors": [
      "Gwendolyn Farach-Colton",
      "Martin Farach-Colton",
      "Leslie Ann Goldberg",
      "Hanna Komlos",
      "John Lapinskas",
      "Reut Levi",
      "Moti Medina",
      "Miguel A. Mosteiro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2106.14186",
    "title": "An XAI Approach to Deep Learning Models in the Detection of DCIS",
    "abstract": " Comments: 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2106.14186",
    "authors": [
      "Michele La Ferla"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.04100",
    "title": "Taming Self-Supervised Learning for Presentation Attack Detection:  De-Folding and De-Mixing",
    "abstract": " Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS) ",
    "url": "https://arxiv.org/abs/2109.04100",
    "authors": [
      "Zhe Kong",
      "Wentian Zhang",
      "Feng Liu",
      "Wenhan Luo",
      "Haozhe Liu",
      "Linlin Shen",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.05395",
    "title": "De Rham compatible Deep Neural Network FEM",
    "abstract": " Title: De Rham compatible Deep Neural Network FEM ",
    "url": "https://arxiv.org/abs/2201.05395",
    "authors": [
      "Marcello Longo",
      "Joost A. A. Opschoor",
      "Nico Disch",
      "Christoph Schwab",
      "Jakob Zech"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.06382",
    "title": "Differentiated Relevances Embedding for Group-based Referring Expression  Comprehension",
    "abstract": " Title: Differentiated Relevances Embedding for Group-based Referring Expression  Comprehension ",
    "url": "https://arxiv.org/abs/2203.06382",
    "authors": [
      "Fuhai Chen",
      "Xuri Ge",
      "Xiaoshuai Sun",
      "Yue Gao",
      "Jianzhuang Liu",
      "Fufeng Chen",
      "Wenjie Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15876",
    "title": "Self-Supervised Learning for Recommender Systems: A Survey",
    "abstract": " Comments: 20 pages. Accepted by TKDE ",
    "url": "https://arxiv.org/abs/2203.15876",
    "authors": [
      "Junliang Yu",
      "Hongzhi Yin",
      "Xin Xia",
      "Tong Chen",
      "Jundong Li",
      "Zi Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.14814",
    "title": "Your Contrastive Learning Is Secretly Doing Stochastic Neighbor  Embedding",
    "abstract": " Comments: Accepted by ICLR 2023 ",
    "url": "https://arxiv.org/abs/2205.14814",
    "authors": [
      "Tianyang Hu",
      "Zhili Liu",
      "Fengwei Zhou",
      "Wenjia Wang",
      "Weiran Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03317",
    "title": "Subject Membership Inference Attacks in Federated Learning",
    "abstract": " Title: Subject Membership Inference Attacks in Federated Learning ",
    "url": "https://arxiv.org/abs/2206.03317",
    "authors": [
      "Anshuman Suri",
      "Pallika Kanani",
      "Virendra J. Marathe",
      "Daniel W. Peterson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03861",
    "title": "Decentralized Online Regularized Learning Over Random Time-Varying  Graphs",
    "abstract": " Title: Decentralized Online Regularized Learning Over Random Time-Varying  Graphs ",
    "url": "https://arxiv.org/abs/2206.03861",
    "authors": [
      "Xiwei Zhang",
      "Tao Li",
      "Xiaozheng Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.04149",
    "title": "A Survey of Graph-based Deep Learning for Anomaly Detection in  Distributed Systems",
    "abstract": " Comments: The first two authors (A. Danesh Pazho and G. Alinezhad Noghre) have equal contribution. The article is accepted by IEEE Transactions on Knowledge and Data Engineering ",
    "url": "https://arxiv.org/abs/2206.04149",
    "authors": [
      "Armin Danesh Pazho",
      "Ghazal Alinezhad Noghre",
      "Arnab A Purkayastha",
      "Jagannadh Vempati",
      "Otto Martin",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14268",
    "title": "BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from  Pretrained Language Models",
    "abstract": " Comments: ACL 2023 (Findings); Code available at this https URL ",
    "url": "https://arxiv.org/abs/2206.14268",
    "authors": [
      "Shibo Hao",
      "Bowen Tan",
      "Kaiwen Tang",
      "Bin Ni",
      "Xiyan Shao",
      "Hengzhe Zhang",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.01580",
    "title": "Dynamic Spatial Sparsification for Efficient Vision Transformers and  Convolutional Neural Networks",
    "abstract": " Comments: Accepted to T-PAMI. Journal version of our NeurIPS 2021 work: arXiv:2106.02034. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2207.01580",
    "authors": [
      "Yongming Rao",
      "Zuyan Liu",
      "Wenliang Zhao",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08786",
    "title": "Characterizing and Detecting State-Sponsored Troll Activity on Social  Media",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2210.08786",
    "authors": [
      "Fatima Ezzeddine",
      "Luca Luceri",
      "Omran Ayoub",
      "Ihab Sbeity",
      "Gianluca Nogara",
      "Emilio Ferrara",
      "Silvia Giordano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16205",
    "title": "Local Model Reconstruction Attacks in Federated Learning and their Uses",
    "abstract": " Title: Local Model Reconstruction Attacks in Federated Learning and their Uses ",
    "url": "https://arxiv.org/abs/2210.16205",
    "authors": [
      "Ilias Driouich",
      "Chuan Xu",
      "Giovanni Neglia",
      "Frederic Giroire",
      "Eoin Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.16751",
    "title": "Formalizing Statistical Causality via Modal Logic",
    "abstract": " Title: Formalizing Statistical Causality via Modal Logic ",
    "url": "https://arxiv.org/abs/2210.16751",
    "authors": [
      "Yusuke Kawamoto",
      "Tetsuya Sato",
      "Kohei Suenaga"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2211.11300",
    "title": "Multi-Level Knowledge Distillation for Out-of-Distribution Detection in  Text",
    "abstract": " Comments: ACL 2023. Our code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2211.11300",
    "authors": [
      "Qianhui Wu",
      "Huiqiang Jiang",
      "Haonan Yin",
      "B\u00f6rje F. Karlsson",
      "Chin-Yew Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.17068",
    "title": "Self-Supervised Continual Graph Learning in Adaptive Riemannian Spaces",
    "abstract": " Comments: Accepted by AAAI 2023 (Main Track), 9 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2211.17068",
    "authors": [
      "Li Sun",
      "Junda Ye",
      "Hao Peng",
      "Feiyang Wang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01705",
    "title": "Breaking Down the Lockdown: The Causal Effects of Stay-At-Home Mandates  on Uncertainty and Sentiments During the COVID-19 Pandemic",
    "abstract": " Title: Breaking Down the Lockdown: The Causal Effects of Stay-At-Home Mandates  on Uncertainty and Sentiments During the COVID-19 Pandemic ",
    "url": "https://arxiv.org/abs/2212.01705",
    "authors": [
      "C. Biliotti",
      "F.J. Bargagli-Stoffi",
      "N. Fraccaroli",
      "M. Puliga",
      "M. Riccaboni"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2212.07401",
    "title": "BKinD-3D: Self-Supervised 3D Keypoint Discovery from Multi-View Videos",
    "abstract": " Comments: CVPR 2023. Project page: this https URL Code: this https URL ",
    "url": "https://arxiv.org/abs/2212.07401",
    "authors": [
      "Jennifer J. Sun",
      "Lili Karashchuk",
      "Amil Dravid",
      "Serim Ryou",
      "Sonia Fereidooni",
      "John Tuthill",
      "Aggelos Katsaggelos",
      "Bingni W. Brunton",
      "Georgia Gkioxari",
      "Ann Kennedy",
      "Yisong Yue",
      "Pietro Perona"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09993",
    "title": "Are Deep Neural Networks SMARTer than Second Graders?",
    "abstract": " Comments: Accepted at CVPR 2023. For the SMART-101 dataset, see this https URL ",
    "url": "https://arxiv.org/abs/2212.09993",
    "authors": [
      "Anoop Cherian",
      "Kuan-Chuan Peng",
      "Suhas Lohit",
      "Kevin A. Smith",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.13179",
    "title": "Mining Architectural Information: A Systematic Mapping Study",
    "abstract": " Comments: 85 pages, 5 images, 15 tables, Manuscript submitted to a Journal (2023) ",
    "url": "https://arxiv.org/abs/2212.13179",
    "authors": [
      "Musengamana Jean de Dieu",
      "Peng Liang",
      "Mojtaba Shahin",
      "Chen Yang",
      "Zengyang Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.01404",
    "title": "Neighbor Contrastive Learning on Learnable Graph Augmentation",
    "abstract": " Title: Neighbor Contrastive Learning on Learnable Graph Augmentation ",
    "url": "https://arxiv.org/abs/2301.01404",
    "authors": [
      "Xiao Shen",
      "Dewang Sun",
      "Shirui Pan",
      "Xi Zhou",
      "Laurence T. Yang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.11624",
    "title": "Neural Wasserstein Gradient Flows for Maximum Mean Discrepancies with  Riesz Kernels",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2211.01804 ",
    "url": "https://arxiv.org/abs/2301.11624",
    "authors": [
      "Fabian Altekr\u00fcger",
      "Johannes Hertrich",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2301.12549",
    "title": "Scaling in Depth: Unlocking Robustness Certification on ImageNet",
    "abstract": " Title: Scaling in Depth: Unlocking Robustness Certification on ImageNet ",
    "url": "https://arxiv.org/abs/2301.12549",
    "authors": [
      "Kai Hu",
      "Andy Zou",
      "Zifan Wang",
      "Klas Leino",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12942",
    "title": "Refined Regret for Adversarial MDPs with Linear Function Approximation",
    "abstract": " Comments: Accepted to ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.12942",
    "authors": [
      "Yan Dai",
      "Haipeng Luo",
      "Chen-Yu Wei",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.01056",
    "title": "Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial  Defense",
    "abstract": " Title: Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial  Defense ",
    "url": "https://arxiv.org/abs/2302.01056",
    "authors": [
      "Zunzhi You",
      "Daochang Liu",
      "Bohyung Han",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10607",
    "title": "Differentiable Multi-Target Causal Bayesian Experimental Design",
    "abstract": " Comments: Camera-ready version ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.10607",
    "authors": [
      "Yashas Annadani",
      "Panagiotis Tigas",
      "Desi R. Ivanova",
      "Andrew Jesson",
      "Yarin Gal",
      "Adam Foster",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.00456",
    "title": "N-best T5: Robust ASR Error Correction using Multiple Input Hypotheses  and Constrained Decoding Space",
    "abstract": " Comments: submitted to INTERSPEECH ",
    "url": "https://arxiv.org/abs/2303.00456",
    "authors": [
      "Rao Ma",
      "Mark J. F. Gales",
      "Kate M. Knill",
      "Mengjie Qian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.02262",
    "title": "Locally Regularized Neural Differential Equations: Some Black Boxes Were  Meant to Remain Closed!",
    "abstract": " Comments: Proceedings of the 40th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023 ",
    "url": "https://arxiv.org/abs/2303.02262",
    "authors": [
      "Avik Pal",
      "Alan Edelman",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.03565",
    "title": "CLIP-Layout: Style-Consistent Indoor Scene Synthesis with Semantic  Furniture Embedding",
    "abstract": " Comments: Changed paper template and cleaned up tables ",
    "url": "https://arxiv.org/abs/2303.03565",
    "authors": [
      "Jingyu Liu",
      "Wenhan Xiong",
      "Ian Jones",
      "Yixin Nie",
      "Anchit Gupta",
      "Barlas O\u011fuz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06730",
    "title": "Iterative Decoupling Method for High-Precision Imaging of Complex  Surfaces",
    "abstract": " Title: Iterative Decoupling Method for High-Precision Imaging of Complex  Surfaces ",
    "url": "https://arxiv.org/abs/2303.06730",
    "authors": [
      "Eyal Baruch",
      "Izhak Bucher"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.08893",
    "title": "A Multifidelity deep operator network approach to closure for multiscale  systems",
    "abstract": " Comments: 24 pages, 21 figures ",
    "url": "https://arxiv.org/abs/2303.08893",
    "authors": [
      "Shady E. Ahmed",
      "Panos Stinis"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2303.15266",
    "title": "Multi-Granularity Archaeological Dating of Chinese Bronze Dings Based on  a Knowledge-Guided Relation Graph",
    "abstract": " Comments: CVPR2023 accepted ",
    "url": "https://arxiv.org/abs/2303.15266",
    "authors": [
      "Rixin Zhou",
      "Jiafu Wei",
      "Qian Zhang",
      "Ruihua Qi",
      "Xi Yang",
      "Chuntao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.00257",
    "title": "RADIFUSION: A multi-radiomics deep learning based breast cancer risk  prediction model using sequential mammographic images with image attention  and bilateral asymmetry refinement",
    "abstract": " Comments: v2 ",
    "url": "https://arxiv.org/abs/2304.00257",
    "authors": [
      "Hong Hui Yeoh",
      "Andrea Liew",
      "Rapha\u00ebl Phan",
      "Fredrik Strand",
      "Kartini Rahmat",
      "Tuong Linh Nguyen",
      "John L. Hopper",
      "Maxine Tan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03048",
    "title": "Generalization with Reverse-Calibration of Well and Seismic Data Using  Machine Learning Methods for Complex Reservoirs Predicting During Early-Stage  Geological Exploration Oil Field",
    "abstract": " Comments: 12 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2304.03048",
    "authors": [
      "Dmitry Ivlev"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04736",
    "title": "On the Possibilities of AI-Generated Text Detection",
    "abstract": " Title: On the Possibilities of AI-Generated Text Detection ",
    "url": "https://arxiv.org/abs/2304.04736",
    "authors": [
      "Souradip Chakraborty",
      "Amrit Singh Bedi",
      "Sicheng Zhu",
      "Bang An",
      "Dinesh Manocha",
      "Furong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.13229",
    "title": "Generating Adversarial Examples with Task Oriented Multi-Objective  Optimization",
    "abstract": " Title: Generating Adversarial Examples with Task Oriented Multi-Objective  Optimization ",
    "url": "https://arxiv.org/abs/2304.13229",
    "authors": [
      "Anh Bui",
      "Trung Le",
      "He Zhao",
      "Quan Tran",
      "Paul Montague",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.14446",
    "title": "HyperMODEST: Self-Supervised 3D Object Detection with Confidence Score  Filtering",
    "abstract": " Comments: Accepted in CRV (Conference on Robots and Vision) 2023 ",
    "url": "https://arxiv.org/abs/2304.14446",
    "authors": [
      "Jenny Xu",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.05829",
    "title": "Constant Approximation for Network Revenue Management with  Markovian-Correlated Customer Arrivals",
    "abstract": " Title: Constant Approximation for Network Revenue Management with  Markovian-Correlated Customer Arrivals ",
    "url": "https://arxiv.org/abs/2305.05829",
    "authors": [
      "Jiashuo Jiang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.07270",
    "title": "SSD-MonoDETR: Supervised Scale-aware Deformable Transformer for  Monocular 3D Object Detection",
    "abstract": " Comments: Code will be made publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2305.07270",
    "authors": [
      "Xuan He",
      "Fan Yang",
      "Kailun Yang",
      "Jiacheng Lin",
      "Haolong Fu",
      "Meng Wang",
      "Jin Yuan",
      "Zhiyong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.10036",
    "title": "Are You Copying My Model? Protecting the Copyright of Large Language  Models for EaaS via Backdoor Watermark",
    "abstract": " Comments: Accepted by ACL 2023 ",
    "url": "https://arxiv.org/abs/2305.10036",
    "authors": [
      "Wenjun Peng",
      "Jingwei Yi",
      "Fangzhao Wu",
      "Shangxi Wu",
      "Bin Zhu",
      "Lingjuan Lyu",
      "Binxing Jiao",
      "Tong Xu",
      "Guangzhong Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.10930",
    "title": "On the Off-Target Problem of Zero-Shot Multilingual Neural Machine  Translation",
    "abstract": " Comments: Findings of ACL 2023 ",
    "url": "https://arxiv.org/abs/2305.10930",
    "authors": [
      "Liang Chen",
      "Shuming Ma",
      "Dongdong Zhang",
      "Furu Wei",
      "Baobao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12134",
    "title": "Privacy in Multimodal Federated Human Activity Recognition",
    "abstract": " Comments: In 3rd On-Device Intelligence Workshop at MLSys 2023, 8 pages ",
    "url": "https://arxiv.org/abs/2305.12134",
    "authors": [
      "Alex Iacob",
      "Pedro P. B. Gusm\u00e3o",
      "Nicholas D. Lane",
      "Armand K. Koupai",
      "Mohammud J. Bocus",
      "Ra\u00fal Santos-Rodr\u00edguez",
      "Robert J. Piechocki",
      "Ryan McConville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16259",
    "title": "Neural Natural Language Processing for Long Texts: A Survey of the  State-of-the-Art",
    "abstract": " Comments: 53 pages, 2 figures, 171 citations ",
    "url": "https://arxiv.org/abs/2305.16259",
    "authors": [
      "Dimitrios Tsirmpas",
      "Ioannis Gkionis",
      "Ioannis Mademlis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17813",
    "title": "Meerkat: A framework for Dynamic Graph Algorithms on GPUs",
    "abstract": " Title: Meerkat: A framework for Dynamic Graph Algorithms on GPUs ",
    "url": "https://arxiv.org/abs/2305.17813",
    "authors": [
      "Kevin Jude Concessao",
      "Unnikrishnan Cheramangalath",
      "MJ Ricky Dev",
      "Rupesh Nasre"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.18149",
    "title": "Multiscale Positive-Unlabeled Detection of AI-Generated Texts",
    "abstract": " Title: Multiscale Positive-Unlabeled Detection of AI-Generated Texts ",
    "url": "https://arxiv.org/abs/2305.18149",
    "authors": [
      "Yuchuan Tian",
      "Hanting Chen",
      "Xutao Wang",
      "Zheyuan Bai",
      "Qinghua Zhang",
      "Ruifeng Li",
      "Chao Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18651",
    "title": "UMD: Unsupervised Model Detection for X2X Backdoor Attacks",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2305.18651",
    "authors": [
      "Zhen Xiang",
      "Zidi Xiong",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18797",
    "title": "Learning Weakly Supervised Audio-Visual Violence Detection in Hyperbolic  Space",
    "abstract": " Comments: 8 pages, 5 figures, typos are fixed ",
    "url": "https://arxiv.org/abs/2305.18797",
    "authors": [
      "Xiaogang Peng",
      "Hao Wen",
      "Yikai Luo",
      "Xiao Zhou",
      "Keyang Yu",
      "Yigang Wang",
      "Zizhao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18888",
    "title": "Contrastive Shapelet Learning for Unsupervised Multivariate Time Series  Representation Learning",
    "abstract": " Title: Contrastive Shapelet Learning for Unsupervised Multivariate Time Series  Representation Learning ",
    "url": "https://arxiv.org/abs/2305.18888",
    "authors": [
      "Zhiyu Liang",
      "Jianfeng Zhang",
      "Chen Liang",
      "Hongzhi Wang",
      "Zheng Liang",
      "Lujia Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19241",
    "title": "Accountable authentication with privacy protection: The Larch system for  universal login",
    "abstract": " Comments: This is an extended version of a paper appearing at OSDI 2023 ",
    "url": "https://arxiv.org/abs/2305.19241",
    "authors": [
      "Emma Dauterman",
      "Danny Lin",
      "Henry Corrigan-Gibbs",
      "David Mazi\u00e8res"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.19666",
    "title": "Efficient Algorithms for Exact Graph Matching on Correlated Stochastic  Block Models with Constant Correlation",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2305.19666",
    "authors": [
      "Joonhyuk Yang",
      "Dongpil Shin",
      "Hye Won Chung"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19678",
    "title": "Smooth-Trajectron++: Augmenting the Trajectron++ behaviour prediction  model with smooth attention",
    "abstract": " Title: Smooth-Trajectron++: Augmenting the Trajectron++ behaviour prediction  model with smooth attention ",
    "url": "https://arxiv.org/abs/2305.19678",
    "authors": [
      "Frederik S.B. Westerhout",
      "Julian F. Schumann",
      "Arkady Zgonnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.00006",
    "title": "Truncated Affinity Maximization: One-class Homophily Modeling for Graph  Anomaly Detection",
    "abstract": " Comments: 19 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2306.00006",
    "authors": [
      "Hezhe Qiao",
      "Guansong Pang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.00037",
    "title": "BotArtist: Twitter bot detection Machine Learning model based on Twitter  suspension",
    "abstract": " Title: BotArtist: Twitter bot detection Machine Learning model based on Twitter  suspension ",
    "url": "https://arxiv.org/abs/2306.00037",
    "authors": [
      "Alexander Shevtsov",
      "Despoina Antonakaki",
      "Ioannis Lamprou",
      "Polyvios Pratikakis",
      "Sotiris Ioannidis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]