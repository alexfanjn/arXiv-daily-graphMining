[
  {
    "id": "arXiv:2306.06107",
    "title": "Adversarial Attacks on Leakage Detectors in Water Distribution Networks",
    "abstract": "Many Machine Learning models are vulnerable to adversarial attacks: There exist methodologies that add a small (imperceptible) perturbation to an input such that the model comes up with a wrong prediction. Better understanding of such attacks is crucial in particular for models used in security-critical domains, such as monitoring of water distribution networks, in order to devise counter-measures enhancing model robustness and trustworthiness. We propose a taxonomy for adversarial attacks against machine learning based leakage detectors in water distribution networks. Following up on this, we focus on a particular type of attack: an adversary searching the least sensitive point, that is, the location in the water network where the largest possible undetected leak could occur. Based on a mathematical formalization of the least sensitive point problem, we use three different algorithmic approaches to find a solution. Results are evaluated on two benchmark water distribution networks. ",
    "url": "https://arxiv.org/abs/2306.06107",
    "authors": [
      "Paul Stahlhofen",
      "Andr\u00e9 Artelt",
      "Luca Hermes",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06108",
    "title": "Demystifying Fraudulent Transactions and Illicit Nodes in the Bitcoin  Network for Financial Forensics",
    "abstract": "Blockchain provides the unique and accountable channel for financial forensics by mining its open and immutable transaction data. A recent surge has been witnessed by training machine learning models with cryptocurrency transaction data for anomaly detection, such as money laundering and other fraudulent activities. This paper presents a holistic applied data science approach to fraud detection in the Bitcoin network with two original contributions. First, we contribute the Elliptic++ dataset, which extends the Elliptic transaction dataset to include over 822k Bitcoin wallet addresses (nodes), each with 56 features, and 1.27M temporal interactions. This enables both the detection of fraudulent transactions and the detection of illicit addresses (actors) in the Bitcoin network by leveraging four types of graph data: (i) the transaction-to-transaction graph, representing the money flow in the Bitcoin network, (ii) the address-to-address interaction graph, capturing the types of transaction flows between Bitcoin addresses, (iii) the address-transaction graph, representing the bi-directional money flow between addresses and transactions (BTC flow from input address to one or more transactions and BTC flow from a transaction to one or more output addresses), and (iv) the user entity graph, capturing clusters of Bitcoin addresses representing unique Bitcoin users. Second, we perform fraud detection tasks on all four graphs by using diverse machine learning algorithms. We show that adding enhanced features from the address-to-address and the address-transaction graphs not only assists in effectively detecting both illicit transactions and illicit addresses, but also assists in gaining in-depth understanding of the root cause of money laundering vulnerabilities in cryptocurrency transactions and the strategies for fraud detection and prevention. Released at github.com/git-disl/EllipticPlusPlus. ",
    "url": "https://arxiv.org/abs/2306.06108",
    "authors": [
      "Youssef Elmougy",
      "Ling Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06109",
    "title": "Learning to Quantize Vulnerability Patterns and Match to Locate  Statement-Level Vulnerabilities",
    "abstract": "Deep learning (DL) models have become increasingly popular in identifying software vulnerabilities. Prior studies found that vulnerabilities across different vulnerable programs may exhibit similar vulnerable scopes, implicitly forming discernible vulnerability patterns that can be learned by DL models through supervised training. However, vulnerable scopes still manifest in various spatial locations and formats within a program, posing challenges for models to accurately identify vulnerable statements. Despite this challenge, state-of-the-art vulnerability detection approaches fail to exploit the vulnerability patterns that arise in vulnerable programs. To take full advantage of vulnerability patterns and unleash the ability of DL models, we propose a novel vulnerability-matching approach in this paper, drawing inspiration from program analysis tools that locate vulnerabilities based on pre-defined patterns. Specifically, a vulnerability codebook is learned, which consists of quantized vectors representing various vulnerability patterns. During inference, the codebook is iterated to match all learned patterns and predict the presence of potential vulnerabilities within a given program. Our approach was extensively evaluated on a real-world dataset comprising more than 188,000 C/C++ functions. The evaluation results show that our approach achieves an F1-score of 94% (6% higher than the previous best) and 82% (19% higher than the previous best) for function and statement-level vulnerability identification, respectively. These substantial enhancements highlight the effectiveness of our approach to identifying vulnerabilities. The training code and pre-trained models are available at https://github.com/optimatch/optimatch. ",
    "url": "https://arxiv.org/abs/2306.06109",
    "authors": [
      "Michael Fu",
      "Trung Le",
      "Van Nguyen",
      "Chakkrit Tantithamthavorn",
      "Dinh Phung"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06111",
    "title": "Dual-Propagation-Feature Fusion Enhanced Neural CSI Compression for  Massive MIMO",
    "abstract": "Due to the ability of feature extraction, deep learning (DL)-based methods have been recently applied to channel state information (CSI) compression feedback in massive multiple-input multiple-output (MIMO) systems. Existing DL-based CSI compression methods are usually effective in extracting a certain type of features in the CSI. However, the CSI usually contains two types of propagation features, i.g., non-line-of-sight (NLOS) propagation-path feature and dominant propagation-path feature, especially in channel environments with rich scatterers. To fully extract the both propagation features and learn a dual-feature representation for CSI, this paper proposes a dual-feature-fusion neural network (NN), referred to as DuffinNet. The proposed DuffinNet adopts a parallel structure with a convolutional neural network (CNN) and an attention-empowered neural network (ANN) to respectively extract different features in the CSI, and then explores their interplay by a fusion NN. Built upon this proposed DuffinNet, a new encoder-decoder framework is developed, referred to as Duffin-CsiNet, for improving the end-to-end performance of CSI compression and reconstruction. To facilitate the application of Duffin-CsiNet in practice, this paper also presents a two-stage approach for codeword quantization of the CSI feedback. Besides, a transfer learning-based strategy is introduced to improve the generalization of Duffin-CsiNet, which enables the network to be applied to new propagation environments. Simulation results illustrate that the proposed Duffin-CsiNet noticeably outperforms the existing DL-based methods in terms of reconstruction performance, encoder complexity, and network convergence, validating the effectiveness of the proposed dual-feature fusion design. ",
    "url": "https://arxiv.org/abs/2306.06111",
    "authors": [
      "Shaoqing Zhang",
      "Wei Xu",
      "Shi Jin",
      "Xiaohu You",
      "Derrick Wing Kwan Ng",
      "Li-Chun Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2306.06123",
    "title": "Adversarial Attacks and Defenses in Explainable Artificial Intelligence:  A Survey",
    "abstract": "Explainable artificial intelligence (XAI) methods are portrayed as a remedy for debugging and trusting statistical and deep learning models, as well as interpreting their predictions. However, recent advances in adversarial machine learning highlight the limitations and vulnerabilities of state-of-the-art explanations, putting their security and trustworthiness into question. The possibility of manipulating, fooling or fairwashing evidence of the model's reasoning has detrimental consequences when applied in high-stakes decision-making and knowledge discovery. This concise survey of over 50 papers summarizes research concerning adversarial attacks on explanations of machine learning models, as well as fairness metrics. We discuss how to defend against attacks and design robust interpretation methods. We contribute a list of existing insecurities in XAI and outline the emerging research directions in adversarial XAI (AdvXAI). ",
    "url": "https://arxiv.org/abs/2306.06123",
    "authors": [
      "Hubert Baniecki",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06136",
    "title": "Robustness Testing for Multi-Agent Reinforcement Learning: State  Perturbations on Critical Agents",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) has been widely applied in many fields such as smart traffic and unmanned aerial vehicles. However, most MARL algorithms are vulnerable to adversarial perturbations on agent states. Robustness testing for a trained model is an essential step for confirming the trustworthiness of the model against unexpected perturbations. This work proposes a novel Robustness Testing framework for MARL that attacks states of Critical Agents (RTCA). The RTCA has two innovations: 1) a Differential Evolution (DE) based method to select critical agents as victims and to advise the worst-case joint actions on them; and 2) a team cooperation policy evaluation method employed as the objective function for the optimization of DE. Then, adversarial state perturbations of the critical agents are generated based on the worst-case joint actions. This is the first robustness testing framework with varying victim agents. RTCA demonstrates outstanding performance in terms of the number of victim agents and destroying cooperation policies. ",
    "url": "https://arxiv.org/abs/2306.06136",
    "authors": [
      "Ziyuan Zhou",
      "Guanjun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2306.06139",
    "title": "WePaMaDM-Outlier Detection: Weighted Outlier Detection using Pattern  Approaches for Mass Data Mining",
    "abstract": "Weighted Outlier Detection is a method for identifying unusual or anomalous data points in a dataset, which can be caused by various factors like human error, fraud, or equipment malfunctions. Detecting outliers can reveal vital information about system faults, fraudulent activities, and patterns in the data, assisting experts in addressing the root causes of these anomalies. However,creating a model of normal data patterns to identify outliers can be challenging due to the nature of input data, labeled data availability, and specific requirements of the problem. This article proposed the WePaMaDM-Outlier Detection with distinct mass data mining domain, demonstrating that such techniques are domain-dependent and usually developed for specific problem formulations. Nevertheless, similar domains can adapt solutions with modifications. This work also investigates the significance of data modeling in outlier detection techniques in surveillance, fault detection, and trend analysis, also referred to as novelty detection, a semisupervised task where the algorithm learns to recognize abnormality while being taught the normal class. ",
    "url": "https://arxiv.org/abs/2306.06139",
    "authors": [
      "Ravindrakumar Purohit",
      "Jai Prakash Verma",
      "Rachna Jain",
      "Madhuri Bhavsar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06143",
    "title": "Integrating Usage Control into Distributed Ledger Technology for  Internet of Things Privacy",
    "abstract": "The Internet of Things brings new ways to collect privacy-sensitive data from billions of devices. Well-tailored distributed ledger technologies (DLTs) can provide high transaction processing capacities to IoT devices in a decentralized fashion. However, privacy aspects are often neglected or unsatisfying, with a focus mainly on performance and security. In this paper, we introduce decentralized usage control mechanisms to empower IoT devices to control the data they generate. Usage control defines obligations, i.e., actions to be fulfilled to be granted access, and conditions on the system in addition to data dissemination control. The originality of this paper is to consider the usage control system as a component of distributed ledger networks, instead of an external tool. With this integration, both technologies work in synergy, benefiting their privacy, security and performance. We evaluated the performance improvements of integration using the IOTA technology, particularly suitable due to the participation of small devices in the consensus. The results of the tests on a private network show an approximate 90% decrease of the time needed for the UCS to push a transaction and make its access decision in the integrated setting, regardless of the number of nodes in the network. ",
    "url": "https://arxiv.org/abs/2306.06143",
    "authors": [
      "Nathana\u00ebl Denis",
      "Maryline Laurent",
      "Sophie Chabridon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.06152",
    "title": "EfficientBioAI: Making Bioimaging AI Models Efficient in Energy, Latency  and Representation",
    "abstract": "Artificial intelligence (AI) has been widely used in bioimage image analysis nowadays, but the efficiency of AI models, like the energy consumption and latency is not ignorable due to the growing model size and complexity, as well as the fast-growing analysis needs in modern biomedical studies. Like we can compress large images for efficient storage and sharing, we can also compress the AI models for efficient applications and deployment. In this work, we present EfficientBioAI, a plug-and-play toolbox that can compress given bioimaging AI models for them to run with significantly reduced energy cost and inference time on both CPU and GPU, without compromise on accuracy. In some cases, the prediction accuracy could even increase after compression, since the compression procedure could remove redundant information in the model representation and therefore reduce over-fitting. From four different bioimage analysis applications, we observed around 2-5 times speed-up during inference and 30-80$\\%$ saving in energy. Cutting the runtime of large scale bioimage analysis from days to hours or getting a two-minutes bioimaging AI model inference done in near real-time will open new doors for method development and biomedical discoveries. We hope our toolbox will facilitate resource-constrained bioimaging AI and accelerate large-scale AI-based quantitative biological studies in an eco-friendly way, as well as stimulate further research on the efficiency of bioimaging AI. ",
    "url": "https://arxiv.org/abs/2306.06152",
    "authors": [
      "Yu Zhou",
      "Justin Sonneck",
      "Sweta Banerjee",
      "Stefanie D\u00f6rr",
      "Anika Gr\u00fcneboom",
      "Kristina Lorenz",
      "Jianxu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06155",
    "title": "Intensity Profile Projection: A Framework for Continuous-Time  Representation Learning for Dynamic Networks",
    "abstract": "We present a new algorithmic framework, Intensity Profile Projection, for learning continuous-time representations of the nodes of a dynamic network, characterised by a node set and a collection of instantaneous interaction events which occur in continuous time. Our framework consists of three stages: estimating the intensity functions underlying the interactions between pairs of nodes, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and inductively constructing evolving node representations via the learned projection. We show that our representations preserve the underlying structure of the network, and are temporally coherent, meaning that node representations can be meaningfully compared at different points in time. We develop estimation theory which elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce smoothing as the signal-to-noise ratio increases on account of the algorithm `borrowing strength' across the network. ",
    "url": "https://arxiv.org/abs/2306.06155",
    "authors": [
      "Alexander Modell",
      "Ian Gallagher",
      "Emma Ceccherini",
      "Nick Whiteley",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06176",
    "title": "Quantitative Analysis of Cultural Dynamics Seen from an Event-based  Social Network",
    "abstract": "Culture is a collection of connected and potentially interactive patterns that characterize a social group or a passed-on idea that people acquire as members of society. While offline activities can provide a better picture of the geographical association of cultural traits than online activities, gathering such data on a large scale has been challenging. Here, we use multi-decade longitudinal records of cultural events from Meetup.com, the largest event-based social networking service, to examine the landscape of offline cultural events. We analyze the temporal and categorical event dynamics driven by cultural diversity using over 2 million event logs collected over 17 years in 90 countries. Our results show that the national economic status explains 44.6 percent of the variance in total event count, while cultural characteristics such as individualism and long-term orientation explain 32.8 percent of the variance in topic categories. Furthermore, our analysis using hierarchical clustering reveals cultural proximity between the topics of socio-cultural activities (e.g., politics, leisure, health, technology). We expect that this work provides a landscape of social and cultural activities across the world, which allows us to better understand their dynamical patterns as well as their associations with cultural characteristics. ",
    "url": "https://arxiv.org/abs/2306.06176",
    "authors": [
      "Bayu Adhi Tama",
      "Jaehong Kim",
      "Jaehyuk Park",
      "Lev Manovich",
      "Meeyoung Cha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2306.06179",
    "title": "Hidden symmetries of ReLU networks",
    "abstract": "The parameter space for any fixed architecture of feedforward ReLU neural networks serves as a proxy during training for the associated class of functions - but how faithful is this representation? It is known that many different parameter settings can determine the same function. Moreover, the degree of this redundancy is inhomogeneous: for some networks, the only symmetries are permutation of neurons in a layer and positive scaling of parameters at a neuron, while other networks admit additional hidden symmetries. In this work, we prove that, for any network architecture where no layer is narrower than the input, there exist parameter settings with no hidden symmetries. We also describe a number of mechanisms through which hidden symmetries can arise, and empirically approximate the functional dimension of different network architectures at initialization. These experiments indicate that the probability that a network has no hidden symmetries decreases towards 0 as depth increases, while increasing towards 1 as width and input dimension increase. ",
    "url": "https://arxiv.org/abs/2306.06179",
    "authors": [
      "J. Elisenda Grigsby",
      "Kathryn Lindsey",
      "David Rolnick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2306.06194",
    "title": "Public Transit Demand Prediction During Highly Dynamic Conditions: A  Meta-Analysis of State-of-the-Art Models and Open-Source Benchmarking  Infrastructure",
    "abstract": "Real-time demand prediction is a critical input for dynamic bus routing. While many researchers have developed numerous complex methods to predict short-term transit demand, the applications have been limited to short, stable time frames and a few stations. How these methods perform in highly dynamic environments has not been studied, nor has their performance been systematically compared. We built an open-source infrastructure with five common methodologies, including econometric and deep learning approaches, and assessed their performance under stable and highly dynamic conditions. We used a time series from smartcard data to predict demand for the following day for the BRT system in Bogota, Colombia. The dynamic conditions in the time series include a month-long protest and the COVID-19 pandemic. Both conditions triggered drastic shifts in demand. The results reveal that most tested models perform similarly in stable conditions, with MAAPE varying from 0.08 to 0.12. The benchmark demonstrated that all models performed significantly worse in both dynamic conditions compared to the stable conditions. In the month-long protest, the increased MAAPE ranged from 0.14 to 0.24. Similarly, during the COVID-19 pandemic, the increased MAAPE ranged from 0.12 to 0.82. Notably, in the COVID-19 pandemic condition, an LSTM model with adaptive training and a multi-output design outperformed other models, adapting faster to disruptions. The prediction error stabilized within approximately 1.5 months, whereas other models continued to exhibit higher error rates even a year after the start of the pandemic. The aim of this open-source codebase infrastructure is to lower the barrier for other researchers to replicate and reproduce models, facilitate a collective effort within the research community to improve the benchmarking process and accelerate the advancement of short-term ridership prediction models. ",
    "url": "https://arxiv.org/abs/2306.06194",
    "authors": [
      "Juan D. Caicedo",
      "Marta C. Gonz\u00e1lez",
      "Joan L. Walker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06196",
    "title": "ElectroCardioGuard: Preventing Patient Misidentification in  Electrocardiogram Databases through Neural Networks",
    "abstract": "Electrocardiograms (ECGs) are commonly used by cardiologists to detect heart-related pathological conditions. Reliable collections of ECGs are crucial for precise diagnosis. However, in clinical practice, the assignment of captured ECG recordings to incorrect patients can occur inadvertently. In collaboration with a clinical and research facility which recognized this challenge and reached out to us, we present a study that addresses this issue. In this work, we propose a small and efficient neural-network based model for determining whether two ECGs originate from the same patient. Our model demonstrates great generalization capabilities and achieves state-of-the-art performance in gallery-probe patient identification on PTB-XL while utilizing 760x fewer parameters. Furthermore, we present a technique leveraging our model for detection of recording-assignment mistakes, showcasing its applicability in a realistic scenario. Finally, we evaluate our model on a newly collected ECG dataset specifically curated for this study, and make it public for the research community. ",
    "url": "https://arxiv.org/abs/2306.06196",
    "authors": [
      "Michal Sej\u00e1k",
      "Jakub Sido",
      "David \u017dahour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06198",
    "title": "Spoofing Against Spoofing: Towards Caller ID Verification In  Heterogeneous Telecommunication Systems",
    "abstract": "Caller ID spoofing is a global industry problem and often acts as a critical enabler for telephone fraud. To address this problem, the Federal Communications Commission (FCC) has mandated telecom providers in the US to implement STIR/SHAKEN, an industry-driven solution based on digital signatures. STIR/SHAKEN relies on a public key infrastructure (PKI) to manage digital certificates, but scaling up this PKI for the global telecom industry is extremely difficult, if not impossible. Furthermore, it only works with the SIP (VoIP) system, leaving the traditional SS7 (landline and cellular) systems unprotected. So far the alternatives to the STIR/SHAKEN have not been sufficiently studied. In this paper, we propose a PKI-free solution, Caller ID Verification (CIV), to combat caller ID spoofing. CIV authenticates the caller ID based on a challenge-response process instead of digital signatures. It supports both SIP and SS7 systems. Perhaps counter-intuitively, we show that number spoofing can be leveraged, in conjunction with Dual-Tone Multi-Frequency (DTMF), to efficiently implement the challenge-response process, i.e., using spoofing to fight against spoofing. We implement CIV for VoIP, cellular, and landline phones across heterogeneous networks (SS7/SIP) by only updating the software on the user's phone. This is the first caller ID authentication solution with working prototypes for all three types of telephone systems in the current telecom architecture. Finally, we show how the implementation of CIV can be optimized by integrating it into telecom clouds as a service, which users may subscribe to. ",
    "url": "https://arxiv.org/abs/2306.06198",
    "authors": [
      "Shen Wang",
      "Mahshid Delavar",
      "Muhammad Ajmal Azad",
      "Farshad Nabizadeh",
      "Steve Smith",
      "Feng Hao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.06202",
    "title": "NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics",
    "abstract": "Machine learning provides a valuable tool for analyzing high-dimensional functional neuroimaging data, and is proving effective in predicting various neurological conditions, psychiatric disorders, and cognitive patterns. In functional Magnetic Resonance Imaging (MRI) research, interactions between brain regions are commonly modeled using graph-based representations. The potency of graph machine learning methods has been established across myriad domains, marking a transformative step in data interpretation and predictive modeling. Yet, despite their promise, the transposition of these techniques to the neuroimaging domain remains surprisingly under-explored due to the expansive preprocessing pipeline and large parameter search space for graph-based datasets construction. In this paper, we introduce NeuroGraph, a collection of graph-based neuroimaging datasets that span multiple categories of behavioral and cognitive traits. We delve deeply into the dataset generation search space by crafting 35 datasets within both static and dynamic contexts, running in excess of 15 baseline methods for benchmarking. Additionally, we provide generic frameworks for learning on dynamic as well as static graphs. Our extensive experiments lead to several key observations. Notably, using correlation vectors as node features, incorporating larger number of regions of interest, and employing sparser graphs lead to improved performance. To foster further advancements in graph-based data driven Neuroimaging, we offer a comprehensive open source Python package that includes the datasets, baseline implementations, model training, and standard evaluation. The package is publicly accessible at https://anwar-said.github.io/anwarsaid/neurograph.html . ",
    "url": "https://arxiv.org/abs/2306.06202",
    "authors": [
      "Anwar Said",
      "Roza G. Bayrak",
      "Tyler Derr",
      "Mudassir Shabbir",
      "Daniel Moyer",
      "Catie Chang",
      "Xenofon Koutsoukos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.06203",
    "title": "FLSL: Feature-level Self-supervised Learning",
    "abstract": "Current self-supervised learning (SSL) methods (e.g., SimCLR, DINO, VICReg, MOCOv3) target primarily on representations at instance level and do not generalize well to dense prediction tasks, such as object detection and segmentation. Towards aligning SSL with dense predictions, this paper demonstrates for the first time the underlying mean-shift clustering process of Vision Transformers (ViT), which aligns well with natural image semantics (e.g., a world of objects and stuffs). By employing transformer for joint embedding and clustering, we propose a two-level feature clustering SSL method, coined Feature-Level Self-supervised Learning (FLSL). We present the formal definition of the FLSL problem and construct the objectives from the mean-shift and k-means perspectives. We show that FLSL promotes remarkable semantic cluster representations and learns an embedding scheme amenable to intra-view and inter-view feature clustering. Experiments show that FLSL yields significant improvements in dense prediction tasks, achieving 44.9 (+2.8)% AP and 46.5% AP in object detection, as well as 40.8 (+2.3)% AP and 42.1% AP in instance segmentation on MS-COCO, using Mask R-CNN with ViT-S/16 and ViT-S/8 as backbone, respectively. FLSL consistently outperforms existing SSL methods across additional benchmarks, including UAV object detection on UAVDT, and video instance segmentation on DAVIS 2017. We conclude by presenting visualization and various ablation studies to better 20 understand the success of FLSL. ",
    "url": "https://arxiv.org/abs/2306.06203",
    "authors": [
      "Qing Su",
      "Anton Netchaev",
      "Hai Li",
      "Shihao Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06204",
    "title": "Spectrahedral Geometry of Graph Sparsifiers",
    "abstract": "We propose an approach to graph sparsification based on the idea of preserving the smallest $k$ eigenvalues and eigenvectors of the Graph Laplacian. This is motivated by the fact that small eigenvalues and their associated eigenvectors tend to be more informative of the global structure and geometry of the graph than larger eigenvalues and their eigenvectors. The set of all weighted subgraphs of a graph $G$ that have the same first $k$ eigenvalues (and eigenvectors) as $G$ is the intersection of a polyhedron with a cone of positive semidefinite matrices. We discuss the geometry of these sets and deduce the natural scale of $k$. Various families of graphs illustrate our construction. ",
    "url": "https://arxiv.org/abs/2306.06204",
    "authors": [
      "Catherine Babecki",
      "Stefan Steinerberger",
      "Rekha R. Thomas"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2306.06206",
    "title": "PotatoPestNet: A CTInceptionV3-RS-Based Neural Network for Accurate  Identification of Potato Pests",
    "abstract": "Potatoes are the third-largest food crop globally, but their production frequently encounters difficulties because of aggressive pest infestations. The aim of this study is to investigate the various types and characteristics of these pests and propose an efficient PotatoPestNet AI-based automatic potato pest identification system. To accomplish this, we curated a reliable dataset consisting of eight types of potato pests. We leveraged the power of transfer learning by employing five customized, pre-trained transfer learning models: CMobileNetV2, CNASLargeNet, CXception, CDenseNet201, and CInceptionV3, in proposing a robust PotatoPestNet model to accurately classify potato pests. To improve the models' performance, we applied various augmentation techniques, incorporated a global average pooling layer, and implemented proper regularization methods. To further enhance the performance of the models, we utilized random search (RS) optimization for hyperparameter tuning. This optimization technique played a significant role in fine-tuning the models and achieving improved performance. We evaluated the models both visually and quantitatively, utilizing different evaluation metrics. The robustness of the models in handling imbalanced datasets was assessed using the Receiver Operating Characteristic (ROC) curve. Among the models, the Customized Tuned Inception V3 (CTInceptionV3) model, optimized through random search, demonstrated outstanding performance. It achieved the highest accuracy (91%), precision (91%), recall (91%), and F1-score (91%), showcasing its superior ability to accurately identify and classify potato pests. ",
    "url": "https://arxiv.org/abs/2306.06206",
    "authors": [
      "Md. Simul Hasan Talukder",
      "Rejwan Bin Sulaiman",
      "Mohammad Raziuddin Chowdhury",
      "Musarrat Saberin Nipun",
      "Ben Hadj Hassine"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06208",
    "title": "A Differential Testing Framework to Evaluate Image Recognition Model  Robustness",
    "abstract": "Image recognition tasks typically use deep learning and require enormous processing power, thus relying on hardware accelerators like GPUs and TPUs for fast, timely processing. Failure in real-time image recognition tasks can occur due to sub-optimal mapping on hardware accelerators during model deployment, which may lead to timing uncertainty and erroneous behavior. Mapping on hardware accelerators is done through multiple software components like deep learning frameworks, compilers, device libraries, that we refer to as the computational environment. Owing to the increased use of image recognition tasks in safety-critical applications like autonomous driving and medical imaging, it is imperative to assess their robustness to changes in the computational environment, as the impact of parameters like deep learning frameworks, compiler optimizations, and hardware devices on model performance and correctness is not well understood. In this paper we present a differential testing framework, which allows deep learning model variant generation, execution, differential analysis and testing for a number of computational environment parameters. Using our framework, we conduct an empirical study of robustness analysis of three popular image recognition models using the ImageNet dataset, assessing the impact of changing deep learning frameworks, compiler optimizations, and hardware devices. We report the impact in terms of misclassifications and inference time differences across different settings. In total, we observed up to 72% output label differences across deep learning frameworks, and up to 82% unexpected performance degradation in terms of inference time, when applying compiler optimizations. Using the analysis tools in our framework, we also perform fault analysis to understand the reasons for the observed differences. ",
    "url": "https://arxiv.org/abs/2306.06208",
    "authors": [
      "Nikolaos Louloudakis",
      "Perry Gibson",
      "Jos\u00e9 Cano",
      "Ajitha Rajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06209",
    "title": "Backdoor Attack with Sparse and Invisible Trigger",
    "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attacks, where the adversary manipulates a small portion of training data such that the victim model predicts normally on the benign samples but classifies the triggered samples as the target class. The backdoor attack is an emerging yet threatening training-phase threat, leading to serious risks in DNN-based applications. In this paper, we revisit the trigger patterns of existing backdoor attacks. We reveal that they are either visible or not sparse and therefore are not stealthy enough. More importantly, it is not feasible to simply combine existing methods to design an effective sparse and invisible backdoor attack. To address this problem, we formulate the trigger generation as a bi-level optimization problem with sparsity and invisibility constraints and propose an effective method to solve it. The proposed method is dubbed sparse and invisible backdoor attack (SIBA). We conduct extensive experiments on benchmark datasets under different settings, which verify the effectiveness of our attack and its resistance to existing backdoor defenses. The codes for reproducing main experiments are available at \\url{https://github.com/YinghuaGao/SIBA}. ",
    "url": "https://arxiv.org/abs/2306.06209",
    "authors": [
      "Yinghua Gao",
      "Yiming Li",
      "Xueluan Gong",
      "Shu-Tao Xia",
      "Qian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06213",
    "title": "Robust Twin Parametric Margin Support Vector Machine for Multiclass  Classification",
    "abstract": "In this paper we present a Twin Parametric-Margin Support Vector Machine (TPMSVM) model to tackle the problem of multiclass classification. In the spirit of one-versus-all paradigm, for each class we construct a classifier by solving a TPMSVM-type model. Once all classifiers have been determined, they are combined into an aggregate decision function. We consider the cases of both linear and nonlinear kernel-induced classifiers. In addition, we robustify the proposed approach through robust optimization techniques. Indeed, in real-world applications observations are subject to measurement errors and noise, affecting the quality of the solutions. Consequently, data uncertainties need to be included within the model in order to prevent low accuracies in the classification process. Preliminary computational experiments on real-world datasets show the good performance of the proposed approach. ",
    "url": "https://arxiv.org/abs/2306.06213",
    "authors": [
      "Renato De Leone",
      "Francesca Maggioni",
      "Andrea Spinelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2306.06230",
    "title": "Design Frameworks for Hyper-Connected Social XRI Immersive Metaverse  Environments",
    "abstract": "The metaverse refers to the merger of technologies for providing a digital twin of the real world and the underlying connectivity and interactions for the many kinds of agents within. As this set of technology paradigms - involving artificial intelligence, mixed reality, the internet-of-things and others - gains in scale, maturity, and utility there are rapidly emerging design challenges and new research opportunities. In particular is the metaverse disconnect problem, the gap in task switching that inevitably occurs when a user engages with multiple virtual and physical environments simultaneously. Addressing this gap remains an open issue that affects the user experience and must be overcome to increase overall utility of the metaverse. This article presents design frameworks that consider how to address the metaverse as a hyper-connected meta-environment that connects and expands multiple user environments, modalities, contexts, and the many objects and relationships within them. This article contributes to i) a framing of the metaverse as a social XR-IoT (XRI) concept, ii) design Considerations for XRI metaverse experiences, iii) a design architecture for social multi-user XRI metaverse environments, and iv) descriptive exploration of social interaction scenarios within XRI multi-user metaverses. These contribute a new design framework for metaverse researchers and creators to consider the coming wave of interconnected and immersive smart environments. ",
    "url": "https://arxiv.org/abs/2306.06230",
    "authors": [
      "Jie Guan",
      "Alexis Morris"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2306.06232",
    "title": "Probing self-supervised speech models for phonetic and phonemic  information: a case study in aspiration",
    "abstract": "Textless self-supervised speech models have grown in capabilities in recent years, but the nature of the linguistic information they encode has not yet been thoroughly examined. We evaluate the extent to which these models' learned representations align with basic representational distinctions made by humans, focusing on a set of phonetic (low-level) and phonemic (more abstract) contrasts instantiated in word-initial stops. We find that robust representations of both phonetic and phonemic distinctions emerge in early layers of these models' architectures, and are preserved in the principal components of deeper layer representations. Our analyses suggest two sources for this success: some can only be explained by the optimization of the models on speech data, while some can be attributed to these models' high-dimensional architectures. Our findings show that speech-trained HuBERT derives a low-noise and low-dimensional subspace corresponding to abstract phonological distinctions. ",
    "url": "https://arxiv.org/abs/2306.06232",
    "authors": [
      "Kinan Martin",
      "Jon Gauthier",
      "Canaan Breiss",
      "Roger Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.06235",
    "title": "Resolving the Steiner Point Removal Problem in Planar Graphs via  Shortcut Partitions",
    "abstract": "Recently the authors [CCLMST23] introduced the notion of shortcut partition of planar graphs and obtained several results from the partition, including a tree cover with $O(1)$ trees for planar metrics and an additive embedding into small treewidth graphs. In this note, we apply the same partition to resolve the Steiner point removal (SPR) problem in planar graphs: Given any set $K$ of terminals in an arbitrary edge-weighted planar graph $G$, we construct a minor $M$ of $G$ whose vertex set is $K$, which preserves the shortest-path distances between all pairs of terminals in $G$ up to a constant factor. This resolves in the affirmative an open problem that has been asked repeatedly in literature. ",
    "url": "https://arxiv.org/abs/2306.06235",
    "authors": [
      "Hsien-Chih Chang",
      "Jonathan Conroy",
      "Hung Le",
      "Lazar Milenkovic",
      "Shay Solomon",
      "Cuong Than"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2306.06236",
    "title": "iPLAN: Intent-Aware Planning in Heterogeneous Traffic via Distributed  Multi-Agent Reinforcement Learning",
    "abstract": "Navigating safely and efficiently in dense and heterogeneous traffic scenarios is challenging for autonomous vehicles (AVs) due to their inability to infer the behaviors or intentions of nearby drivers. In this work, we propose a distributed multi-agent reinforcement learning (MARL) algorithm with trajectory and intent prediction in dense and heterogeneous traffic scenarios. Our approach for intent-aware planning, iPLAN, allows agents to infer nearby drivers' intents solely from their local observations. We model two distinct incentives for agents' strategies: Behavioral incentives for agents' long-term planning based on their driving behavior or personality; Instant incentives for agents' short-term planning for collision avoidance based on the current traffic state. We design a two-stream inference module that allows agents to infer their opponents' incentives and incorporate their inferred information into decision-making. We perform experiments on two simulation environments, Non-Cooperative Navigation and Heterogeneous Highway. In Heterogeneous Highway, results show that, compared with centralized MARL baselines such as QMIX and MAPPO, our method yields a 4.0% and 35.7% higher episodic reward in mild and chaotic traffic, with 48.1% higher success rate and 80.6% longer survival time in chaotic traffic. We also compare with a decentralized baseline IPPO and demonstrate a higher episodic reward of 9.2% and 10.3% in mild traffic and chaotic traffic, 25.3% higher success rate, and 13.7% longer survival time. ",
    "url": "https://arxiv.org/abs/2306.06236",
    "authors": [
      "Xiyang Wu",
      "Rohan Chandra",
      "Tianrui Guan",
      "Amrit Singh Bedi",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.06237",
    "title": "Beyond Weights: Deep learning in Spiking Neural Networks with pure  synaptic-delay training",
    "abstract": "Biological evidence suggests that adaptation of synaptic delays on short to medium timescales plays an important role in learning in the brain. Inspired by biology, we explore the feasibility and power of using synaptic delays to solve challenging tasks even when the synaptic weights are not trained but kept at randomly chosen fixed values. We show that training ONLY the delays in feed-forward spiking networks using backpropagation can achieve performance comparable to the more conventional weight training. Moreover, further constraining the weights to ternary values does not significantly affect the networks' ability to solve the tasks using only the synaptic delays. We demonstrate the task performance of delay-only training on MNIST and Fashion-MNIST datasets in preliminary experiments. This demonstrates a new paradigm for training spiking neural networks and sets the stage for models that can be more efficient than the ones that use weights for computation. ",
    "url": "https://arxiv.org/abs/2306.06237",
    "authors": [
      "Edoardo W. Grappolini",
      "Anand Subramoney"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.06238",
    "title": "Understanding the Effect of the Long Tail on Neural Network Compression",
    "abstract": "Network compression is now a mature sub-field of neural network research: over the last decade, significant progress has been made towards reducing the size of models and speeding up inference, while maintaining the classification accuracy. However, many works have observed that focusing on just the overall accuracy can be misguided. E.g., it has been shown that mismatches between the full and compressed models can be biased towards under-represented classes. This raises the important research question, \\emph{can we achieve network compression while maintaining ``semantic equivalence'' with the original network?} In this work, we study this question in the context of the ``long tail'' phenomenon in computer vision datasets observed by Feldman, et al. They argue that \\emph{memorization} of certain inputs (appropriately defined) is essential to achieving good generalization. As compression limits the capacity of a network (and hence also its ability to memorize), we study the question: are mismatches between the full and compressed models correlated with the memorized training data? We present positive evidence in this direction for image classification tasks, by considering different base architectures and compression schemes. ",
    "url": "https://arxiv.org/abs/2306.06238",
    "authors": [
      "Harvey Dam",
      "Vinu Joseph",
      "Aditya Bhaskara",
      "Ganesh Gopalakrishna",
      "Saurav Muralidharan",
      "Michael Garland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06252",
    "title": "Feature Programming for Multivariate Time Series Prediction",
    "abstract": "We introduce the concept of programmable feature engineering for time series modeling and propose a feature programming framework. This framework generates large amounts of predictive features for noisy multivariate time series while allowing users to incorporate their inductive bias with minimal effort. The key motivation of our framework is to view any multivariate time series as a cumulative sum of fine-grained trajectory increments, with each increment governed by a novel spin-gas dynamical Ising model. This fine-grained perspective motivates the development of a parsimonious set of operators that summarize multivariate time series in an abstract fashion, serving as the foundation for large-scale automated feature engineering. Numerically, we validate the efficacy of our method on several synthetic and real-world noisy time series datasets. ",
    "url": "https://arxiv.org/abs/2306.06252",
    "authors": [
      "Alex Reneau",
      "Jerry Yao-Chieh Hu",
      "Chenwei Xu",
      "Weijian Li",
      "Ammar Gilani",
      "Han Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06255",
    "title": "Early Malware Detection and Next-Action Prediction",
    "abstract": "In this paper, we propose a framework for early-stage malware detection and mitigation by leveraging natural language processing (NLP) techniques and machine learning algorithms. Our primary contribution is presenting an approach for predicting the upcoming actions of malware by treating application programming interface (API) call sequences as natural language inputs and employing text classification methods, specifically a Bi-LSTM neural network, to predict the next API call. This enables proactive threat identification and mitigation, demonstrating the effectiveness of applying NLP principles to API call sequences. The Bi-LSTM model is evaluated using two datasets. %The model achieved an accuracy of 93.6\\% and 88.8\\% for the %first and second dataset respectively. Additionally, by modeling consecutive API calls as 2-gram and 3-gram strings, we extract new features to be further processed using a Bagging-XGBoost algorithm, effectively predicting malware presence at its early stages. The accuracy of the proposed framework is evaluated by simulations. ",
    "url": "https://arxiv.org/abs/2306.06255",
    "authors": [
      "Zahra Jamadi",
      "Amir G. Aghdam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06263",
    "title": "A Cross-Moment Approach for Causal Effect Estimation",
    "abstract": "We consider the problem of estimating the causal effect of a treatment on an outcome in linear structural causal models (SCM) with latent confounders when we have access to a single proxy variable. Several methods (such as difference-in-difference (DiD) estimator or negative outcome control) have been proposed in this setting in the literature. However, these approaches require either restrictive assumptions on the data generating model or having access to at least two proxy variables. We propose a method to estimate the causal effect using cross moments between the treatment, the outcome, and the proxy variable. In particular, we show that the causal effect can be identified with simple arithmetic operations on the cross moments if the latent confounder in linear SCM is non-Gaussian. In this setting, DiD estimator provides an unbiased estimate only in the special case where the latent confounder has exactly the same direct causal effects on the outcomes in the pre-treatment and post-treatment phases. This translates to the common trend assumption in DiD, which we effectively relax. Additionally, we provide an impossibility result that shows the causal effect cannot be identified if the observational distribution over the treatment, the outcome, and the proxy is jointly Gaussian. Our experiments on both synthetic and real-world datasets showcase the effectiveness of the proposed approach in estimating the causal effect. ",
    "url": "https://arxiv.org/abs/2306.06263",
    "authors": [
      "Yaroslav Kivva",
      "Saber Salehkaleybar",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2306.06268",
    "title": "Attention-stacked Generative Adversarial Network (AS-GAN)-empowered  Sensor Data Augmentation for Online Monitoring of Manufacturing System",
    "abstract": "Machine learning (ML) has been extensively adopted for the online sensing-based monitoring in advanced manufacturing systems. However, the sensor data collected under abnormal states are usually insufficient, leading to significant data imbalanced issue for supervised machine learning. A common solution for this issue is to incorporate data augmentation technique, i.e., augmenting the available abnormal states data (i.e., minority samples) via synthetic generation. To generate the high-quality minority samples effectively, it is vital to learn the underlying distribution of the abnormal states data. In recent years, the generative adversarial network (GAN)-based approaches become popular to learn data distribution as well as perform data augmentation. However, in practice, the quality of generated samples from GAN-based data augmentation may vary drastically. In addition, the sensor signals are collected sequentially by time from the manufacturing systems, which means the consideration of sequential information is also very important in data augmentation. To address these limitations, inspired by the multi-head attention mechanism, this paper proposed an attention-stacked GAN (AS-GAN) architecture for the sensor data augmentation of online monitoring in advanced manufacturing. In this proposed AS-GAN, a new attention-stacked framework is incorporated to strengthen the generator in GAN with the learning capability of considering sequential information. Furthermore, the developed attention-stacked framework also greatly helps to improve the quality of generated sensor signals. The case studies conducted in additive manufacturing also successfully validate the effectiveness of AS-GAN to augment high-quality artificial multi-channel sensor signals for online monitoring of manufacturing systems. ",
    "url": "https://arxiv.org/abs/2306.06268",
    "authors": [
      "Yuxuan Li",
      "Chenang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06294",
    "title": "Explaining SAT Solving Using Causal Reasoning",
    "abstract": "The past three decades have witnessed notable success in designing efficient SAT solvers, with modern solvers capable of solving industrial benchmarks containing millions of variables in just a few seconds. The success of modern SAT solvers owes to the widely-used CDCL algorithm, which lacks comprehensive theoretical investigation. Furthermore, it has been observed that CDCL solvers still struggle to deal with specific classes of benchmarks comprising only hundreds of variables, which contrasts with their widespread use in real-world applications. Consequently, there is an urgent need to uncover the inner workings of these seemingly weak yet powerful black boxes. In this paper, we present a first step towards this goal by introducing an approach called CausalSAT, which employs causal reasoning to gain insights into the functioning of modern SAT solvers. CausalSAT initially generates observational data from the execution of SAT solvers and learns a structured graph representing the causal relationships between the components of a SAT solver. Subsequently, given a query such as whether a clause with low literals blocks distance (LBD) has a higher clause utility, CausalSAT calculates the causal effect of LBD on clause utility and provides an answer to the question. We use CausalSAT to quantitatively verify hypotheses previously regarded as \"rules of thumb\" or empirical findings such as the query above. Moreover, CausalSAT can address previously unexplored questions, like which branching heuristic leads to greater clause utility in order to study the relationship between branching and clause management. Experimental evaluations using practical benchmarks demonstrate that CausalSAT effectively fits the data, verifies four \"rules of thumb\", and provides answers to three questions closely related to implementing modern solvers. ",
    "url": "https://arxiv.org/abs/2306.06294",
    "authors": [
      "Jiong Yang",
      "Arijit Shaw",
      "Teodora Baluta",
      "Mate Soos",
      "Kuldeep S. Meel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06299",
    "title": "Front-running Attack in Distributed Sharded Ledgers and Fair Cross-shard  Consensus",
    "abstract": "Sharding is a prominent technique for scaling blockchains. By dividing the network into smaller components known as shards, a sharded blockchain can process transactions in parallel without introducing inconsistencies through the coordination of intra-shard and cross-shard consensus protocols. However, we observe a critical security issue with sharded systems: transaction ordering manipulations can occur when coordinating intra-shard and cross-shard consensus protocols, leaving the system vulnerable to attack. Specifically, we identify a novel security issue known as finalization fairness, which can be exploited through a front-running attack. This attack allows an attacker to manipulate the execution order of transactions, even if the victim's transaction has already been processed and added to the blockchain by a fair intra-shard consensus. To address the issue, we offer Haechi, a novel cross-shard protocol that is immune to front-running attacks. Haechi introduces an ordering phase between transaction processing and execution, ensuring that the execution order of transactions is the same as the processing order and achieving finalization fairness. To accommodate different consensus speeds among shards, Haechi incorporates a finalization fairness algorithm to achieve a globally fair order with minimal performance loss. By providing a global order, Haechi ensures strong consistency among shards, enabling better parallelism in handling conflicting transactions across shards. These features make Haechi a promising solution for supporting popular smart contracts in the real world. To evaluate Haechi's performance, we implemented the protocol using Tendermint and conducted extensive experiments on a geo-distributed AWS environment. Our results demonstrate that Haechi achieves finalization fairness with little performance sacrifice compared to existing cross-shard consensus protocols. ",
    "url": "https://arxiv.org/abs/2306.06299",
    "authors": [
      "Jianting Zhang",
      "Wuhui Chen",
      "Sifu Luo",
      "Tiantian Gong",
      "Zicong Hong",
      "Aniket Kate"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.06304",
    "title": "Finite element interpolated neural networks for solving forward and  inverse problems",
    "abstract": "We propose a general framework for solving forward and inverse problems constrained by partial differential equations, where we interpolate neural networks onto finite element spaces to represent the (partial) unknowns. The framework overcomes the challenges related to the imposition of boundary conditions, the choice of collocation points in physics-informed neural networks, and the integration of variational physics-informed neural networks. A numerical experiment set confirms the framework's capability of handling various forward and inverse problems. In particular, the trained neural network generalises well for smooth problems, beating finite element solutions by some orders of magnitude. We finally propose an effective one-loop solver with an initial data fitting step (to obtain a cheap initialisation) to solve inverse problems. ",
    "url": "https://arxiv.org/abs/2306.06304",
    "authors": [
      "Santiago Badia",
      "Wei Li",
      "Alberto F. Mart\u00edn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.06327",
    "title": "Any-dimensional equivariant neural networks",
    "abstract": "Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments. ",
    "url": "https://arxiv.org/abs/2306.06327",
    "authors": [
      "Eitan Levin",
      "Mateo D\u00edaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06333",
    "title": "A convergent hybrid neural network and finite difference scheme for  Stokes interface problems",
    "abstract": "In this paper, we present a novel hybrid method for solving a Stokes interface problem in a regular domain with jump discontinuities on an interface. Our approach combines the expressive power of neural networks with the convergence of finite difference schemes to achieve efficient implementations and accurate results. The key concept of our method is to decompose the solution into two parts: the singular part and the regular part. We employ neural networks to approximate the singular part, which captures the jump discontinuities across the interface. We then utilize a finite difference scheme to approximate the regular part, which handles the smooth variations of the solution in that regular domain. To validate the effectiveness of our approach, we present two- and three-dimensional examples to demonstrate the accuracy and convergence of the proposed method, and show that our proposed hybrid method provides an innovative and reliable approach to tackle Stokes interface problems. ",
    "url": "https://arxiv.org/abs/2306.06333",
    "authors": [
      "Che-Chia Chang",
      "Chen-Yang Dai",
      "Wei-Fan Hu",
      "Te-Sheng Lin",
      "Ming-Chih Lai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2306.06335",
    "title": "How to Learn and Generalize From Three Minutes of Data:  Physics-Constrained and Uncertainty-Aware Neural Stochastic Differential  Equations",
    "abstract": "We present a framework and algorithms to learn controlled dynamics models using neural stochastic differential equations (SDEs) -- SDEs whose drift and diffusion terms are both parametrized by neural networks. We construct the drift term to leverage a priori physics knowledge as inductive bias, and we design the diffusion term to represent a distance-aware estimate of the uncertainty in the learned model's predictions -- it matches the system's underlying stochasticity when evaluated on states near those from the training dataset, and it predicts highly stochastic dynamics when evaluated on states beyond the training regime. The proposed neural SDEs can be evaluated quickly enough for use in model predictive control algorithms, or they can be used as simulators for model-based reinforcement learning. Furthermore, they make accurate predictions over long time horizons, even when trained on small datasets that cover limited regions of the state space. We demonstrate these capabilities through experiments on simulated robotic systems, as well as by using them to model and control a hexacopter's flight dynamics: A neural SDE trained using only three minutes of manually collected flight data results in a model-based control policy that accurately tracks aggressive trajectories that push the hexacopter's velocity and Euler angles to nearly double the maximum values observed in the training dataset. ",
    "url": "https://arxiv.org/abs/2306.06335",
    "authors": [
      "Franck Djeumou",
      "Cyrus Neary",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06345",
    "title": "Improving Non-autoregressive Translation Quality with Pretrained  Language Model, Embedding Distillation and Upsampling Strategy for CTC",
    "abstract": "Non-autoregressive approaches aim to improve the inference speed of translation models, particularly those that generate output in a one-pass forward manner. However, these approaches often suffer from a significant drop in translation quality compared to autoregressive models. This paper introduces a series of innovative techniques to enhance the translation quality of Non-Autoregressive Translation (NAT) models while maintaining a substantial acceleration in inference speed. We propose fine-tuning Pretrained Multilingual Language Models (PMLMs) with the CTC loss to train NAT models effectively. Furthermore, we adopt the MASK insertion scheme for up-sampling instead of token duplication, and we present an embedding distillation method to further enhance performance. In our experiments, our model outperforms the baseline autoregressive model (Transformer \\textit{base}) on multiple datasets, including WMT'14 DE$\\leftrightarrow$EN, WMT'16 RO$\\leftrightarrow$EN, and IWSLT'14 DE$\\leftrightarrow$EN. Notably, our model achieves better performance than the baseline autoregressive model on the IWSLT'14 En$\\leftrightarrow$De and WMT'16 En$\\leftrightarrow$Ro datasets, even without using distillation data during training. It is worth highlighting that on the IWSLT'14 DE$\\rightarrow$EN dataset, our model achieves an impressive BLEU score of 39.59, setting a new state-of-the-art performance. Additionally, our model exhibits a remarkable speed improvement of 16.35 times compared to the autoregressive model. ",
    "url": "https://arxiv.org/abs/2306.06345",
    "authors": [
      "Shen-sian Syu",
      "Juncheng Xie",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06347",
    "title": "Bootstrapping Code-Text Pretrained Language Model to Detect  Inconsistency Between Code and Comment",
    "abstract": "Comments on source code serve as critical documentation for enabling developers to understand the code's functionality and use it properly. However, it is challenging to ensure that comments accurately reflect the corresponding code, particularly as the software evolves over time. Although increasing interest has been taken in developing automated methods for identifying and fixing inconsistencies between code and comments, the existing methods have primarily relied on heuristic rules. In this paper, we propose DocChecker, a deep-learning-based tool to detect the inconsistency between code and comments. DocChecker is trained to detect noisy code-comment pairs and generate synthetic comments, enabling it to determine comments that do not match their associated code snippets and correct them. Its effectiveness is demonstrated on the Just-In-Time dataset compared with other state-of-the-art methods. This tool is available at https://github.com/FSoft-AI4Code/DocChecker and this http URL; the demonstration video can be found on https://youtu.be/KFbyaSf2I3c. ",
    "url": "https://arxiv.org/abs/2306.06347",
    "authors": [
      "Anh T. V. Dau",
      "Nghi D. Q. Bui",
      "Jin L. C. Guo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.06359",
    "title": "NeRFool: Uncovering the Vulnerability of Generalizable Neural Radiance  Fields against Adversarial Perturbations",
    "abstract": "Generalizable Neural Radiance Fields (GNeRF) are one of the most promising real-world solutions for novel view synthesis, thanks to their cross-scene generalization capability and thus the possibility of instant rendering on new scenes. While adversarial robustness is essential for real-world applications, little study has been devoted to understanding its implication on GNeRF. We hypothesize that because GNeRF is implemented by conditioning on the source views from new scenes, which are often acquired from the Internet or third-party providers, there are potential new security concerns regarding its real-world applications. Meanwhile, existing understanding and solutions for neural networks' adversarial robustness may not be applicable to GNeRF, due to its 3D nature and uniquely diverse operations. To this end, we present NeRFool, which to the best of our knowledge is the first work that sets out to understand the adversarial robustness of GNeRF. Specifically, NeRFool unveils the vulnerability patterns and important insights regarding GNeRF's adversarial robustness. Built upon the above insights gained from NeRFool, we further develop NeRFool+, which integrates two techniques capable of effectively attacking GNeRF across a wide range of target views, and provide guidelines for defending against our proposed attacks. We believe that our NeRFool/NeRFool+ lays the initial foundation for future innovations in developing robust real-world GNeRF solutions. Our codes are available at: https://github.com/GATECH-EIC/NeRFool. ",
    "url": "https://arxiv.org/abs/2306.06359",
    "authors": [
      "Yonggan Fu",
      "Ye Yuan",
      "Souvik Kundu",
      "Shang Wu",
      "Shunyao Zhang",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06366",
    "title": "Zero-Day Threats Detection for Critical Infrastructures",
    "abstract": "Technological advancements in various industries, such as network intelligence, vehicle networks, e-commerce, the Internet of Things (IoT), ubiquitous computing, and cloud-based applications, have led to an exponential increase in the volume of information flowing through critical systems. As a result, protecting critical infrastructures from intrusions and security threats have become a paramount concern in the field of intrusion detection systems (IDS). To address this concern, this research paper focuses on the importance of defending critical infrastructures against intrusions and security threats. It proposes a computational framework that incorporates feature selection through fuzzification. The effectiveness and performance of the proposed framework is evaluated using the NSL-KDD and UGRansome datasets in combination with selected machine learning (ML) models. The findings of the study highlight the effectiveness of fuzzy logic and the use of ensemble learning to enhance the performance of ML models. The research identifies Random Forest (RF) and Extreme Gradient Boosting (XGB) as the top performing algorithms to detect zero-day attacks. The results obtained from the implemented computational framework outperform previous methods documented in the IDS literature, reaffirming the significance of safeguarding critical infrastructures from intrusions and security threats. ",
    "url": "https://arxiv.org/abs/2306.06366",
    "authors": [
      "Mike Nkongolo",
      "Mahmut Tokmak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.06368",
    "title": "On Improving the Cohesiveness of Graphs by Merging Nodes: Formulation,  Analysis, and Algorithms",
    "abstract": "Graphs are a powerful mathematical model, and they are used to represent real-world structures in various fields. In many applications, real-world structures with high connectivity and robustness are preferable. For enhancing the connectivity and robustness of graphs, two operations, adding edges and anchoring nodes, have been extensively studied. However, merging nodes, which is a realistic operation in many scenarios (e.g., bus station reorganization, multiple team formation), has been overlooked. In this work, we study the problem of improving graph cohesiveness by merging nodes. First, we formulate the problem mathematically using the size of the $k$-truss, for a given $k$, as the objective. Then, we prove the NP-hardness and non-modularity of the problem. After that, we develop BATMAN, a fast and effective algorithm for choosing sets of nodes to be merged, based on our theoretical findings and empirical observations. Lastly, we demonstrate the superiority of BATMAN over several baselines, in terms of speed and effectiveness, through extensive experiments on fourteen real-world graphs. ",
    "url": "https://arxiv.org/abs/2306.06368",
    "authors": [
      "Fanchen Bu",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.06371",
    "title": "A Comprehensive Review of State-of-The-Art Methods for Java Code  Generation from Natural Language Text",
    "abstract": "Java Code Generation consists in generating automatically Java code from a Natural Language Text. This NLP task helps in increasing programmers' productivity by providing them with immediate solutions to the simplest and most repetitive tasks. Code generation is a challenging task because of the hard syntactic rules and the necessity of a deep understanding of the semantic aspect of the programming language. Many works tried to tackle this task using either RNN-based, or Transformer-based models. The latter achieved remarkable advancement in the domain and they can be divided into three groups: (1) encoder-only models, (2) decoder-only models, and (3) encoder-decoder models. In this paper, we provide a comprehensive review of the evolution and progress of deep learning models in Java code generation task. We focus on the most important methods and present their merits and limitations, as well as the objective functions used by the community. In addition, we provide a detailed description of datasets and evaluation metrics used in the literature. Finally, we discuss results of different models on CONCODE dataset, then propose some future directions. ",
    "url": "https://arxiv.org/abs/2306.06371",
    "authors": [
      "Jessica L\u00f3pez Espejel",
      "Mahaman Sanoussi Yahaya Alassan",
      "El Mehdi Chouham",
      "Walid Dahhane",
      "El Hassane Ettifouri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06384",
    "title": "Adversarial Training For Low-Resource Disfluency Correction",
    "abstract": "Disfluencies commonly occur in conversational speech. Speech with disfluencies can result in noisy Automatic Speech Recognition (ASR) transcripts, which affects downstream tasks like machine translation. In this paper, we propose an adversarially-trained sequence-tagging model for Disfluency Correction (DC) that utilizes a small amount of labeled real disfluent data in conjunction with a large amount of unlabeled data. We show the benefit of our proposed technique, which crucially depends on synthetically generated disfluent data, by evaluating it for DC in three Indian languages- Bengali, Hindi, and Marathi (all from the Indo-Aryan family). Our technique also performs well in removing stuttering disfluencies in ASR transcripts introduced by speech impairments. We achieve an average 6.15 points improvement in F1-score over competitive baselines across all three languages mentioned. To the best of our knowledge, we are the first to utilize adversarial training for DC and use it to correct stuttering disfluencies in English, establishing a new benchmark for this task. ",
    "url": "https://arxiv.org/abs/2306.06384",
    "authors": [
      "Vineet Bhat",
      "Preethi Jyothi",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06385",
    "title": "Continually learning out-of-distribution spatiotemporal data for robust  energy forecasting",
    "abstract": "Forecasting building energy usage is essential for promoting sustainability and reducing waste, as it enables building managers to optimize energy consumption and reduce costs. This importance is magnified during anomalous periods, such as the COVID-19 pandemic, which have disrupted occupancy patterns and made accurate forecasting more challenging. Forecasting energy usage during anomalous periods is difficult due to changes in occupancy patterns and energy usage behavior. One of the primary reasons for this is the shift in distribution of occupancy patterns, with many people working or learning from home. This has created a need for new forecasting methods that can adapt to changing occupancy patterns. Online learning has emerged as a promising solution to this challenge, as it enables building managers to adapt to changes in occupancy patterns and adjust energy usage accordingly. With online learning, models can be updated incrementally with each new data point, allowing them to learn and adapt in real-time. Another solution is to use human mobility data as a proxy for occupancy, leveraging the prevalence of mobile devices to track movement patterns and infer occupancy levels. Human mobility data can be useful in this context as it provides a way to monitor occupancy patterns without relying on traditional sensors or manual data collection methods. We have conducted extensive experiments using data from six buildings to test the efficacy of these approaches. However, deploying these methods in the real world presents several challenges. ",
    "url": "https://arxiv.org/abs/2306.06385",
    "authors": [
      "Arian Prabowo",
      "Kaixuan Chen",
      "Hao Xue",
      "Subbu Sethuvenkatraman",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06399",
    "title": "Personalized Graph Federated Learning with Differential Privacy",
    "abstract": "This paper presents a personalized graph federated learning (PGFL) framework in which distributedly connected servers and their respective edge devices collaboratively learn device or cluster-specific models while maintaining the privacy of every individual device. The proposed approach exploits similarities among different models to provide a more relevant experience for each device, even in situations with diverse data distributions and disproportionate datasets. Furthermore, to ensure a secure and efficient approach to collaborative personalized learning, we study a variant of the PGFL implementation that utilizes differential privacy, specifically zero-concentrated differential privacy, where a noise sequence perturbs model exchanges. Our mathematical analysis shows that the proposed privacy-preserving PGFL algorithm converges to the optimal cluster-specific solution for each cluster in linear time. It also shows that exploiting similarities among clusters leads to an alternative output whose distance to the original solution is bounded, and that this bound can be adjusted by modifying the algorithm's hyperparameters. Further, our analysis shows that the algorithm ensures local differential privacy for all clients in terms of zero-concentrated differential privacy. Finally, the performance of the proposed PGFL algorithm is examined by performing numerical experiments in the context of regression and classification using synthetic data and the MNIST dataset. ",
    "url": "https://arxiv.org/abs/2306.06399",
    "authors": [
      "Francois Gauthier",
      "Vinay Chakravarthi Gogineni",
      "Stefan Werner",
      "Yih-Fang Huang",
      "Anthony Kuh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06403",
    "title": "Bayesian Inverse Contextual Reasoning for Heterogeneous Semantics-Native  Communication",
    "abstract": "This work deals with the heterogeneous semantic-native communication (SNC) problem. When agents do not share the same communication context, the effectiveness of contextual reasoning (CR) is compromised calling for agents to infer other agents' context. This article proposes a novel framework for solving the inverse problem of CR in SNC using two Bayesian inference methods, namely: Bayesian inverse CR (iCR) and Bayesian inverse linearized CR (iLCR). The first proposed Bayesian iCR method utilizes Markov Chain Monte Carlo (MCMC) sampling to infer the agent's context while being computationally expensive. To address this issue, a Bayesian iLCR method is leveraged which obtains a linearized CR (LCR) model by training a linear neural network. Experimental results show that the Bayesian iLCR method requires less computation and achieves higher inference accuracy compared to Bayesian iCR. Additionally, heterogeneous SNC based on the context obtained through the Bayesian iLCR method shows better communication effectiveness than that of Bayesian iCR. Overall, this work provides valuable insights and methods to improve the effectiveness of SNC in situations where agents have different contexts. ",
    "url": "https://arxiv.org/abs/2306.06403",
    "authors": [
      "Hyowoon Seo",
      "Yoonseong Kang",
      "Mehdi Bennis",
      "Wan Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06414",
    "title": "Revealing Model Biases: Assessing Deep Neural Networks via Recovered  Sample Analysis",
    "abstract": "This paper proposes a straightforward and cost-effective approach to assess whether a deep neural network (DNN) relies on the primary concepts of training samples or simply learns discriminative, yet simple and irrelevant features that can differentiate between classes. The paper highlights that DNNs, as discriminative classifiers, often find the simplest features to discriminate between classes, leading to a potential bias towards irrelevant features and sometimes missing generalization. While a generalization test is one way to evaluate a trained model's performance, it can be costly and may not cover all scenarios to ensure that the model has learned the primary concepts. Furthermore, even after conducting a generalization test, identifying bias in the model may not be possible. Here, the paper proposes a method that involves recovering samples from the parameters of the trained model and analyzing the reconstruction quality. We believe that if the model's weights are optimized to discriminate based on some features, these features will be reflected in the reconstructed samples. If the recovered samples contain the primary concepts of the training data, it can be concluded that the model has learned the essential and determining features. On the other hand, if the recovered samples contain irrelevant features, it can be concluded that the model is biased towards these features. The proposed method does not require any test or generalization samples, only the parameters of the trained model and the training data that lie on the margin. Our experiments demonstrate that the proposed method can determine whether the model has learned the desired features of the training data. The paper highlights that our understanding of how these models work is limited, and the proposed approach addresses this issue. ",
    "url": "https://arxiv.org/abs/2306.06414",
    "authors": [
      "Mohammad Mahdi Mehmanchi",
      "Mahbod Nouri",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06423",
    "title": "Bayesian and Neural Inference on LSTM-based Object Recognition from  Tactile and Kinesthetic Information",
    "abstract": "Recent advances in the field of intelligent robotic manipulation pursue providing robotic hands with touch sensitivity. Haptic perception encompasses the sensing modalities encountered in the sense of touch (e.g., tactile and kinesthetic sensations). This letter focuses on multimodal object recognition and proposes analytical and data-driven methodologies to fuse tactile- and kinesthetic-based classification results. The procedure is as follows: a three-finger actuated gripper with an integrated high-resolution tactile sensor performs squeeze-and-release Exploratory Procedures (EPs). The tactile images and kinesthetic information acquired using angular sensors on the finger joints constitute the time-series datasets of interest. Each temporal dataset is fed to a Long Short-term Memory (LSTM) Neural Network, which is trained to classify in-hand objects. The LSTMs provide an estimation of the posterior probability of each object given the corresponding measurements, which after fusion allows to estimate the object through Bayesian and Neural inference approaches. An experiment with 36-classes is carried out to evaluate and compare the performance of the fused, tactile, and kinesthetic perception systems.The results show that the Bayesian-based classifiers improves capabilities for object recognition and outperforms the Neural-based approach. ",
    "url": "https://arxiv.org/abs/2306.06423",
    "authors": [
      "Francisco Pastor",
      "Jorge Garc\u00eda-Gonz\u00e1lez",
      "Juan M. Gandarias",
      "Daniel Medina",
      "Pau Closas",
      "Alfonso J. Garc\u00eda-Cerezo",
      "Jes\u00fas M. G\u00f3mez-de-Gabriel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06434",
    "title": "Sliding Window Neural Generated Tracking Based on Measurement Model",
    "abstract": "In the pursuit of further advancement in the field of target tracking, this paper explores the efficacy of a feedforward neural network in predicting drones tracks, aiming to eventually, compare the tracks created by the well-known Kalman filter and the ones created by our proposed neural network. The unique feature of our proposed neural network tracker is that it is using only a measurement model to estimate the next states of the track. Object model selection and linearization is one of the challenges that always face in the tracking process. The neural network uses a sliding window to incorporate the history of measurements when applying estimations of the track values. The testing results are comparable to the ones generated by the Kalman filter, especially for the cases where there is low measurement covariance. The complexity of linearization is avoided when using this proposed model. ",
    "url": "https://arxiv.org/abs/2306.06434",
    "authors": [
      "Haya Ejjawi",
      "Amal El Fallah Seghrouchni",
      "Frederic Barbaresco",
      "Raed Abu Zitar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06440",
    "title": "Epidemic spreading in wireless sensor networks with node sleep  scheduling",
    "abstract": "Wireless Sensor Networks (WSNs) have become widely used in various fields like environmental monitoring, smart agriculture, and health care. However, their extensive usage also introduces significant vulnerabilities to cyber viruses. Addressing this security issue in WSNs is very challenging due to their inherent limitations in energy and bandwidth to implement real-time security measures. To tackle the virus issue, it is crucial to first understand how it spreads in WSNs. In this brief, we propose a novel epidemic spreading model for WSNs, integrating the susceptible-infected-susceptible (SIS) epidemic spreading model and node probabilistic sleep scheduling--a critical mechanism for optimizing energy efficiency. Using the microscopic Markov chain (MMC) method, we derive the spreading equations and epidemic threshold of our model. We conduct numerical simulations to validate the theoretical results and investigate the impact of key factors on epidemic spreading in WSNs. Notably, we discover that the epidemic threshold is directly proportional to the ratio of node sleeping and node activation probabilities. ",
    "url": "https://arxiv.org/abs/2306.06440",
    "authors": [
      "Yanqing Wu",
      "Cunlai Pu",
      "Gongxuan Zhang",
      "Lunbo Li",
      "Yongxiang Xia",
      "Chengyi Xia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06449",
    "title": "List homomorphisms to separable signed graphs",
    "abstract": "The complexity of the list homomorphism problem for signed graphs appears difficult to classify. Existing results focus on special classes of signed graphs, such as trees \\cite{mfcs} and reflexive signed graphs \\cite{ks}. Irreflexive signed graphs are in a certain sense the heart of the problem, as noted by a recent paper of Kim and Siggers. We focus on a special class of irreflexive signed graphs, namely those in which the unicoloured edges form a spanning path or cycle, which we call separable signed graphs. We classify the complexity of list homomorphisms to these separable signed graphs; we believe that these signed graphs will play an important role for the general resolution of the irreflexive case. We also relate our results to a conjecture of Kim and Siggers concerning the special case of weakly balanced irreflexive signed graphs; we have proved the conjecture in another paper, and the present results add structural information to that topic. ",
    "url": "https://arxiv.org/abs/2306.06449",
    "authors": [
      "Jan Bok",
      "Richard Brewster",
      "Tom\u00e1s Feder",
      "Pavol Hell",
      "Nikola Jedli\u010dkov\u00e1"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.06452",
    "title": "BlockTheFall: Wearable Device-based Fall Detection Framework Powered by  Machine Learning and Blockchain for Elderly Care",
    "abstract": "Falls among the elderly are a major health concern, frequently resulting in serious injuries and a reduced quality of life. In this paper, we propose \"BlockTheFall,\" a wearable device-based fall detection framework which detects falls in real time by using sensor data from wearable devices. To accurately identify patterns and detect falls, the collected sensor data is analyzed using machine learning algorithms. To ensure data integrity and security, the framework stores and verifies fall event data using blockchain technology. The proposed framework aims to provide an efficient and dependable solution for fall detection with improved emergency response, and elderly individuals' overall well-being. Further experiments and evaluations are being carried out to validate the effectiveness and feasibility of the proposed framework, which has shown promising results in distinguishing genuine falls from simulated falls. By providing timely and accurate fall detection and response, this framework has the potential to substantially boost the quality of elderly care. ",
    "url": "https://arxiv.org/abs/2306.06452",
    "authors": [
      "Bilash Saha",
      "Md Saiful Islam",
      "Abm Kamrul Riad",
      "Sharaban Tahora",
      "Hossain Shahriar",
      "Sweta Sneha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06462",
    "title": "Boosting Adversarial Robustness using Feature Level Stochastic Smoothing",
    "abstract": "Advances in adversarial defenses have led to a significant improvement in the robustness of Deep Neural Networks. However, the robust accuracy of present state-ofthe-art defenses is far from the requirements in critical applications such as robotics and autonomous navigation systems. Further, in practical use cases, network prediction alone might not suffice, and assignment of a confidence value for the prediction can prove crucial. In this work, we propose a generic method for introducing stochasticity in the network predictions, and utilize this for smoothing decision boundaries and rejecting low confidence predictions, thereby boosting the robustness on accepted samples. The proposed Feature Level Stochastic Smoothing based classification also results in a boost in robustness without rejection over existing adversarial training methods. Finally, we combine the proposed method with adversarial detection methods, to achieve the benefits of both approaches. ",
    "url": "https://arxiv.org/abs/2306.06462",
    "authors": [
      "Sravanti Addepalli",
      "Samyak Jain",
      "Gaurang Sriramanan",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06470",
    "title": "TALENT: Targeted Mining of Non-overlapping Sequential Patterns",
    "abstract": "With the widespread application of efficient pattern mining algorithms, sequential patterns that allow gap constraints have become a valuable tool to discover knowledge from biological data such as DNA and protein sequences. Among all kinds of gap-constrained mining, non-overlapping sequence mining can mine interesting patterns and satisfy the anti-monotonic property (the Apriori property). However, existing algorithms do not search for targeted sequential patterns, resulting in unnecessary and redundant pattern generation. Targeted pattern mining can not only mine patterns that are more interesting to users but also reduce the unnecessary redundant sequence generated, which can greatly avoid irrelevant computation. In this paper, we define and formalize the problem of targeted non-overlapping sequential pattern mining and propose an algorithm named TALENT (TArgeted mining of sequentiaL pattErN with consTraints). Two search methods including breadth-first and depth-first searching are designed to troubleshoot the generation of patterns. Furthermore, several pruning strategies to reduce the reading of sequences and items in the data and terminate redundant pattern extensions are presented. Finally, we select a series of datasets with different characteristics and conduct extensive experiments to compare the TALENT algorithm with the existing algorithms for mining non-overlapping sequential patterns. The experimental results demonstrate that the proposed targeted mining algorithm, TALENT, has excellent mining efficiency and can deal efficiently with many different query settings. ",
    "url": "https://arxiv.org/abs/2306.06470",
    "authors": [
      "Zefeng Chen",
      "Wensheng Gan",
      "Gengsen Huang",
      "Zhenlian Qi",
      "Yan Li",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2306.06472",
    "title": "Modeling Structural Similarities between Documents for Coherence  Assessment with Graph Convolutional Networks",
    "abstract": "Coherence is an important aspect of text quality, and various approaches have been applied to coherence modeling. However, existing methods solely focus on a single document's coherence patterns, ignoring the underlying correlation between documents. We investigate a GCN-based coherence model that is capable of capturing structural similarities between documents. Our model first creates a graph structure for each document, from where we mine different subgraph patterns. We then construct a heterogeneous graph for the training corpus, connecting documents based on their shared subgraphs. Finally, a GCN is applied to the heterogeneous graph to model the connectivity relationships. We evaluate our method on two tasks, assessing discourse coherence and automated essay scoring. Results show that our GCN-based model outperforms all baselines, achieving a new state-of-the-art on both tasks. ",
    "url": "https://arxiv.org/abs/2306.06472",
    "authors": [
      "Wei Liu",
      "Xiyan Fu",
      "Michael Strube"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06485",
    "title": "The Defense of Networked Targets in General Lotto games",
    "abstract": "Ensuring the security of networked systems is a significant problem, considering the susceptibility of modern infrastructures and technologies to adversarial interference. A central component of this problem is how defensive resources should be allocated to mitigate the severity of potential attacks on the system. In this paper, we consider this in the context of a General Lotto game, where a defender and attacker deploys resources on the nodes of a network, and the objective is to secure as many links as possible. The defender secures a link only if it out-competes the attacker on both of its associated nodes. For bipartite networks, we completely characterize equilibrium payoffs and strategies for both the defender and attacker. Surprisingly, the resulting payoffs are the same for any bipartite graph. On arbitrary network structures, we provide lower and upper bounds on the defender's max-min value. Notably, the equilibrium payoff from bipartite networks serves as the lower bound. These results suggest that more connected networks are easier to defend against attacks. We confirm these findings with simulations that compute deterministic allocation strategies on large random networks. This also highlights the importance of randomization in the equilibrium strategies. ",
    "url": "https://arxiv.org/abs/2306.06485",
    "authors": [
      "Adel Aghajan",
      "Keith Paarporn",
      "Jason R. Marden"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2306.06490",
    "title": "Automated Code Editing with Search-Generate-Modify",
    "abstract": "Code editing is essential in evolving software development. Many automated code editing tools have been proposed that leverage both Information Retrieval-based techniques and Machine Learning-based code generation and code editing models. Each technique comes with its own promises and perils, and they are often used together to complement their strengths and compensate for their weaknesses. This paper proposes a hybrid approach to better synthesize code edits by leveraging the power of code search, generation, and modification. Our key observation is that a patch obtained by search and retrieval, even if imperfect, can provide helpful guidance to a code generation model. However, a retrieval-guided patch produced by a code generation model can still be a few tokens off from the intended patch. Such generated patches can be slightly modified to create the intended patches. SARGAM is a novel tool designed to mimic a real developer's code editing behavior. Given an original code version, the developer may search for related patches, generate or write the code, and then modify the generated code to adapt it to the right context. Our evaluation of SARGAM on edit generation shows superior performance with respect to current state-of-the-art techniques. SARGAM also shows great effectiveness on automated program repair tasks. ",
    "url": "https://arxiv.org/abs/2306.06490",
    "authors": [
      "Changshu Liu",
      "Pelin Cetin",
      "Yogesh Patodia",
      "Saikat Chakraborty",
      "Yangruibo Ding",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2306.06503",
    "title": "Preserving privacy in domain transfer of medical AI models comes at no  performance costs: The integral role of differential privacy",
    "abstract": "Developing robust and effective artificial intelligence (AI) models in medicine requires access to large amounts of patient data. The use of AI models solely trained on large multi-institutional datasets can help with this, yet the imperative to ensure data privacy remains, particularly as membership inference risks breaching patient confidentiality. As a proposed remedy, we advocate for the integration of differential privacy (DP). We specifically investigate the performance of models trained with DP as compared to models trained without DP on data from institutions that the model had not seen during its training (i.e., external validation) - the situation that is reflective of the clinical use of AI models. By leveraging more than 590,000 chest radiographs from five institutions, we evaluated the efficacy of DP-enhanced domain transfer (DP-DT) in diagnosing cardiomegaly, pleural effusion, pneumonia, atelectasis, and in identifying healthy subjects. We juxtaposed DP-DT with non-DP-DT and examined diagnostic accuracy and demographic fairness using the area under the receiver operating characteristic curve (AUC) as the main metric, as well as accuracy, sensitivity, and specificity. Our results show that DP-DT, even with exceptionally high privacy levels (epsilon around 1), performs comparably to non-DP-DT (P>0.119 across all domains). Furthermore, DP-DT led to marginal AUC differences - less than 1% - for nearly all subgroups, relative to non-DP-DT. Despite consistent evidence suggesting that DP models induce significant performance degradation for on-domain applications, we show that off-domain performance is almost not affected. Therefore, we ardently advocate for the adoption of DP in training diagnostic medical AI models, given its minimal impact on performance. ",
    "url": "https://arxiv.org/abs/2306.06503",
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Mahshad Lotfinia",
      "Teresa Nolte",
      "Marwin Saehn",
      "Peter Isfort",
      "Christiane Kuhl",
      "Sven Nebelung",
      "Georgios Kaissis",
      "Daniel Truhn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.06511",
    "title": "Analysis of Cascading Failures Due to Dynamic Load-Altering Attacks",
    "abstract": "Large-scale load-altering attacks (LAAs) are known to severely disrupt power grid operations by manipulating several internet-of-things (IoT)-enabled load devices. In this work, we analyze power grid cascading failures induced by such attacks. The inherent security features in power grids such as the $N-1$ design philosophy dictate LAAs that can trigger cascading failures are \\emph{rare} events. We overcome the challenge of efficiently sampling critical LAAs scenarios for a wide range of attack parameters by using the so-called ``skipping sampler'' algorithm. We conduct extensive simulations using a three-area IEEE-39 bus system and provide several novel insights into the composition of cascades due to LAAs. Our results highlight the particular risks to modern power systems posed by strategically designed coordinated LAAs that exploit their structural and real-time operating characteristics. ",
    "url": "https://arxiv.org/abs/2306.06511",
    "authors": [
      "Maldon Patrice Goodridge",
      "Alessandro Zocca",
      "Subhash Lakshminarayana"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06514",
    "title": "Vocoder-Free Non-Parallel Conversion of Whispered Speech With Masked  Cycle-Consistent Generative Adversarial Networks",
    "abstract": "Cycle-consistent generative adversarial networks have been widely used in non-parallel voice conversion (VC). Their ability to learn mappings between source and target features without relying on parallel training data eliminates the need for temporal alignments. However, most methods decouple the conversion of acoustic features from synthesizing the audio signal by using separate models for conversion and waveform synthesis. This work unifies conversion and synthesis into a single model, thereby eliminating the need for a separate vocoder. By leveraging cycle-consistent training and a self-supervised auxiliary training task, our model is able to efficiently generate converted high-quality raw audio waveforms. Subjective listening tests show that our method outperforms the baseline in whispered speech conversion (up to 6.7% relative improvement), and mean opinion score predictions yield competitive results in conventional VC (between 0.5% and 2.4% relative improvement). ",
    "url": "https://arxiv.org/abs/2306.06514",
    "authors": [
      "Dominik Wagner",
      "Ilja Baumann",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.06522",
    "title": "TS-MoCo: Time-Series Momentum Contrast for Self-Supervised Physiological  Representation Learning",
    "abstract": "Limited availability of labeled physiological data often prohibits the use of powerful supervised deep learning models in the biomedical machine intelligence domain. We approach this problem and propose a novel encoding framework that relies on self-supervised learning with momentum contrast to learn representations from multivariate time-series of various physiological domains without needing labels. Our model uses a transformer architecture that can be easily adapted to classification problems by optimizing a linear output classification layer. We experimentally evaluate our framework using two publicly available physiological datasets from different domains, i.e., human activity recognition from embedded inertial sensory and emotion recognition from electroencephalography. We show that our self-supervised learning approach can indeed learn discriminative features which can be exploited in downstream classification tasks. Our work enables the development of domain-agnostic intelligent systems that can effectively analyze multivariate time-series data from physiological domains. ",
    "url": "https://arxiv.org/abs/2306.06522",
    "authors": [
      "Philipp Hallgarten",
      "David Bethge",
      "Ozan \u00d6zdenizci",
      "Tobias Grosse-Puppendahl",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06523",
    "title": "Finding Hamiltonian cycles with graph neural networks",
    "abstract": "We train a small message-passing graph neural network to predict Hamiltonian cycles on Erd\\H{o}s-R\\'enyi random graphs in a critical regime. It outperforms existing hand-crafted heuristics after about 2.5 hours of training on a single GPU. Our findings encourage an alternative approach to solving computationally demanding (NP-hard) problems arising in practice. Instead of devising a heuristic by hand, one can train it end-to-end using a neural network. This has several advantages. Firstly, it is relatively quick and requires little problem-specific knowledge. Secondly, the network can adjust to the distribution of training samples, improving the performance on the most relevant problem instances. The model is trained using supervised learning on artificially created problem instances; this training procedure does not use an existing solver to produce the supervised signal. Finally, the model generalizes well to larger graph sizes and retains reasonable performance even on graphs eight times the original size. ",
    "url": "https://arxiv.org/abs/2306.06523",
    "authors": [
      "Filip Bosni\u0107",
      "Mile \u0160iki\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.06529",
    "title": "Neural Injective Functions for Multisets, Measures and Graphs via a  Finite Witness Theorem",
    "abstract": "Injective multiset functions have a key role in the theoretical study of machine learning on multisets and graphs. Yet, there remains a gap between the provably injective multiset functions considered in theory, which typically rely on polynomial moments, and the multiset functions used in practice which typically rely on $\\textit{neural moments}$, whose injectivity on multisets has not been studied to date. In this paper we bridge this gap by showing that moments of neural network do define an injective multiset function, provided that an analytic non-polynomial activation is used. The number of moments required by our theory is optimal up to a multiplicative factor of two. To prove this result, we state and prove a $\\textit{finite witness theorem}$, which is of independent interest. As a corollary to our main theorem, we derive new approximation results for functions on multisets and measures, and new separation results for graph neural networks. We also provide two negative results: We show that (1) moments of piecewise-linear neural networks do not lead to injective multiset functions, and (2) even when moment-based multiset functions are injective, they will never be bi-Lipschitz. ",
    "url": "https://arxiv.org/abs/2306.06529",
    "authors": [
      "Tal Amir",
      "Steven J. Gortler",
      "Ilai Avni",
      "Ravina Ravina",
      "Nadav Dym"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06530",
    "title": "Use of Robust DOB/CDOB Compensation to Improve Autonomous Vehicle Path  Following Performance in the Presence of Model Uncertainty, CAN Bus Delays  and External Disturbances",
    "abstract": "A path tracking control system is chosen as the proof-of-concept demonstration application in this paper. A disturbance observer (DOB) is embedded within the steering to path error automated driving loop to handle uncertain parameters such as vehicle mass, vehicle velocities and road friction coefficient and to reject yaw moment disturbances. The compensation of vehicle model with the embedded disturbance observer forces it to behave like its nominal model within the bandwidth of the disturbance observer. A parameter space approach based steering controller is then used to optimize performance. The proposed method demonstrates good disturbance rejection and achieves stability robustness. The variable time delay from the steer-by-wire system in an actual vehicle can also lead to stability issues since it adds large negative phase angle to the plant frequency response and tends to destabilize it. A communication disturbance observer (CDOB) based time delay compensation approach that does not require exact knowledge of this time delay is embedded into the steering actuation loop to handle this problem. Stability analysis of both DOB and CDOB compensation system are presented in this paper. Extensive model-in-the-loop simulations were performed to test the designed disturbance observer and CDOB systems and show reduced path following errors in the presence of uncertainty, disturbances and time delay. A validated model of our 2017 Ford Fusion Hybrid research autonomous vehicle is used in the simulation analyses. Simulation results verify the performance enhancement of the vehicle path following control with proposed DOB and CDOB structure. A HiL simulator that uses a validated CarSim model with sensors and traffic will be used later to verify the real time capability of our approach. ",
    "url": "https://arxiv.org/abs/2306.06530",
    "authors": [
      "Haoan Wang",
      "Levent Guvenc"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06543",
    "title": "MANER: Multi-Agent Neural Rearrangement Planning of Objects in Cluttered  Environments",
    "abstract": "Object rearrangement is a fundamental problem in robotics with various practical applications ranging from managing warehouses to cleaning and organizing home kitchens. While existing research has primarily focused on single-agent solutions, real-world scenarios often require multiple robots to work together on rearrangement tasks. This paper proposes a comprehensive learning-based framework for multi-agent object rearrangement planning, addressing the challenges of task sequencing and path planning in complex environments. The proposed method iteratively selects objects, determines their relocation regions, and pairs them with available robots under kinematic feasibility and task reachability for execution to achieve the target arrangement. Our experiments on a diverse range of environments demonstrate the effectiveness and robustness of the proposed framework. Furthermore, results indicate improved performance in terms of traversal time and success rate compared to baseline approaches. ",
    "url": "https://arxiv.org/abs/2306.06543",
    "authors": [
      "Vivek Gupta",
      "Praphpreet Dhir",
      "Jeegn Dani",
      "Ahmed H. Qureshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06547",
    "title": "Local-to-global Perspectives on Graph Neural Networks",
    "abstract": "We present a local-to-global perspective on graph neural networks (GNN), which are categorized as local Message Passing Neural Networks (MPNN) and global Graph Transformer. We present three pieces of work: 1) study the convergence property of a type of global GNN, Invariant Graph Networks, 2) connect the local MPNN and global Graph Transformer, and 3) use local MPNN for graph coarsening, a common subroutine used in global modeling. ",
    "url": "https://arxiv.org/abs/2306.06547",
    "authors": [
      "Chen Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06551",
    "title": "An Efficient and Accurate Memristive Memory for Array-based Spiking  Neural Networks",
    "abstract": "Memristors provide a tempting solution for weighted synapse connections in neuromorphic computing due to their size and non-volatile nature. However, memristors are unreliable in the commonly used voltage-pulse-based programming approaches and require precisely shaped pulses to avoid programming failure. In this paper, we demonstrate a current-limiting-based solution that provides a more predictable analog memory behavior when reading and writing memristive synapses. With our proposed design READ current can be optimized by about 19x compared to the 1T1R design. Moreover, our proposed design saves about 9x energy compared to the 1T1R design. Our 3T1R design also shows promising write operation which is less affected by the process variation in MOSFETs and the inherent stochastic behavior of memristors. Memristors used for testing are hafnium oxide based and were fabricated in a 65nm hybrid CMOS-memristor process. The proposed design also shows linear characteristics between the voltage applied and the resulting resistance for the writing operation. The simulation and measured data show similar patterns with respect to voltage pulse-based programming and current compliance-based programming. We further observed the impact of this behavior on neuromorphic-specific applications such as a spiking neural network ",
    "url": "https://arxiv.org/abs/2306.06551",
    "authors": [
      "Hritom Das",
      "Rocco D. Febbo",
      "SNB Tushar",
      "Nishith N. Chakraborty",
      "Maximilian Liehr",
      "Nathaniel Cady",
      "Garrett S. Rose"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2306.06563",
    "title": "Provably Efficient Adversarial Imitation Learning with Unknown  Transitions",
    "abstract": "Imitation learning (IL) has proven to be an effective method for learning good policies from expert demonstrations. Adversarial imitation learning (AIL), a subset of IL methods, is particularly promising, but its theoretical foundation in the presence of unknown transitions has yet to be fully developed. This paper explores the theoretical underpinnings of AIL in this context, where the stochastic and uncertain nature of environment transitions presents a challenge. We examine the expert sample complexity and interaction complexity required to recover good policies. To this end, we establish a framework connecting reward-free exploration and AIL, and propose an algorithm, MB-TAIL, that achieves the minimax optimal expert sample complexity of $\\widetilde{O} (H^{3/2} |S|/\\varepsilon)$ and interaction complexity of $\\widetilde{O} (H^{3} |S|^2 |A|/\\varepsilon^2)$. Here, $H$ represents the planning horizon, $|S|$ is the state space size, $|A|$ is the action space size, and $\\varepsilon$ is the desired imitation gap. MB-TAIL is the first algorithm to achieve this level of expert sample complexity in the unknown transition setting and improves upon the interaction complexity of the best-known algorithm, OAL, by $O(H)$. Additionally, we demonstrate the generalization ability of MB-TAIL by extending it to the function approximation setting and proving that it can achieve expert sample and interaction complexity independent of $|S|$ ",
    "url": "https://arxiv.org/abs/2306.06563",
    "authors": [
      "Tian Xu",
      "Ziniu Li",
      "Yang Yu",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06574",
    "title": "Learnable Digital Twin for Efficient Wireless Network Evaluation",
    "abstract": "Network digital twins (NDTs) facilitate the estimation of key performance indicators (KPIs) before physically implementing a network, thereby enabling efficient optimization of the network configuration. In this paper, we propose a learning-based NDT for network simulators. The proposed method offers a holistic representation of information flow in a wireless network by integrating node, edge, and path embeddings. Through this approach, the model is trained to map the network configuration to KPIs in a single forward pass. Hence, it offers a more efficient alternative to traditional simulation-based methods, thus allowing for rapid experimentation and optimization. Our proposed method has been extensively tested through comprehensive experimentation in various scenarios, including wired and wireless networks. Results show that it outperforms baseline learning models in terms of accuracy and robustness. Moreover, our approach achieves comparable performance to simulators but with significantly higher computational efficiency. ",
    "url": "https://arxiv.org/abs/2306.06574",
    "authors": [
      "Boning Li",
      "Timofey Efimov",
      "Abhishek Kumar",
      "Jose Cortes",
      "Gunjan Verma",
      "Ananthram Swami",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06579",
    "title": "Learning Robust and Consistent Time Series Representations: A Dilated  Inception-Based Approach",
    "abstract": "Representation learning for time series has been an important research area for decades. Since the emergence of the foundation models, this topic has attracted a lot of attention in contrastive self-supervised learning, to solve a wide range of downstream tasks. However, there have been several challenges for contrastive time series processing. First, there is no work considering noise, which is one of the critical factors affecting the efficacy of time series tasks. Second, there is a lack of efficient yet lightweight encoder architectures that can learn informative representations robust to various downstream tasks. To fill in these gaps, we initiate a novel sampling strategy that promotes consistent representation learning with the presence of noise in natural time series. In addition, we propose an encoder architecture that utilizes dilated convolution within the Inception block to create a scalable and robust network architecture with a wide receptive field. Experiments demonstrate that our method consistently outperforms state-of-the-art methods in forecasting, classification, and abnormality detection tasks, e.g. ranks first over two-thirds of the classification UCR datasets, with only $40\\%$ of the parameters compared to the second-best approach. Our source code for CoInception framework is accessible at https://github.com/anhduy0911/CoInception. ",
    "url": "https://arxiv.org/abs/2306.06579",
    "authors": [
      "Anh Duy Nguyen",
      "Trang H. Tran",
      "Hieu H. Pham",
      "Phi Le Nguyen",
      "Lam M. Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06584",
    "title": "Compositional Prototypical Networks for Few-Shot Classification",
    "abstract": "It is assumed that pre-training provides the feature extractor with strong class transferability and that high novel class generalization can be achieved by simply reusing the transferable feature extractor. In this work, our motivation is to explicitly learn some fine-grained and transferable meta-knowledge so that feature reusability can be further improved. Concretely, inspired by the fact that humans can use learned concepts or components to help them recognize novel classes, we propose Compositional Prototypical Networks (CPN) to learn a transferable prototype for each human-annotated attribute, which we call a component prototype. We empirically demonstrate that the learned component prototypes have good class transferability and can be reused to construct compositional prototypes for novel classes. Then a learnable weight generator is utilized to adaptively fuse the compositional and visual prototypes. Extensive experiments demonstrate that our method can achieve state-of-the-art results on different datasets and settings. The performance gains are especially remarkable in the 5-way 1-shot setting. The code is available at https://github.com/fikry102/CPN. ",
    "url": "https://arxiv.org/abs/2306.06584",
    "authors": [
      "Qiang Lyu",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06595",
    "title": "Neural Projection Mapping Using Reflectance Fields",
    "abstract": "We introduce a high resolution spatially adaptive light source, or a projector, into a neural reflectance field that allows to both calibrate the projector and photo realistic light editing. The projected texture is fully differentiable with respect to all scene parameters, and can be optimized to yield a desired appearance suitable for applications in augmented reality and projection mapping. Our neural field consists of three neural networks, estimating geometry, material, and transmittance. Using an analytical BRDF model and carefully selected projection patterns, our acquisition process is simple and intuitive, featuring a fixed uncalibrated projected and a handheld camera with a co-located light source. As we demonstrate, the virtual projector incorporated into the pipeline improves scene understanding and enables various projection mapping applications, alleviating the need for time consuming calibration steps performed in a traditional setting per view or projector location. In addition to enabling novel viewpoint synthesis, we demonstrate state-of-the-art performance projector compensation for novel viewpoints, improvement over the baselines in material and scene reconstruction, and three simply implemented scenarios where projection image optimization is performed, including the use of a 2D generative model to consistently dictate scene appearance from multiple viewpoints. We believe that neural projection mapping opens up the door to novel and exciting downstream tasks, through the joint optimization of the scene and projection images. ",
    "url": "https://arxiv.org/abs/2306.06595",
    "authors": [
      "Yotam Erel",
      "Daisuke Iwai",
      "Amit H. Bermano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06632",
    "title": "The role of all-optical neural networks",
    "abstract": "In light of recent achievements in optical computing and machine learning, we consider the conditions under which all-optical computing may surpass electronic and optoelectronic computing in terms of energy efficiency and scalability. When considering the performance of a system as a whole, the cost of memory access and data acquisition is likely to be one of the main efficiency bottlenecks not only for electronic, but also for optoelectronic and all-optical devices. However, we predict that all-optical devices will be at an advantage in the case of inference in large neural network models, and the advantage will be particularly large in the case of generative models. We also consider the limitations of all-optical neural networks including footprint, strength of nonlinearity, optical signal degradation, limited precision of computations, and quantum noise. ",
    "url": "https://arxiv.org/abs/2306.06632",
    "authors": [
      "Matuszewski Micha\u0142",
      "Prystupiuk Adam",
      "Opala Andrzej"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Optics (physics.optics)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2306.06643",
    "title": "Detection and Recovery of Hidden Submatrices",
    "abstract": "In this paper, we study the problems of detection and recovery of hidden submatrices with elevated means inside a large Gaussian random matrix. We consider two different structures for the planted submatrices. In the first model, the planted matrices are disjoint, and their row and column indices can be arbitrary. Inspired by scientific applications, the second model restricts the row and column indices to be consecutive. In the detection problem, under the null hypothesis, the observed matrix is a realization of independent and identically distributed standard normal entries. Under the alternative, there exists a set of hidden submatrices with elevated means inside the same standard normal matrix. Recovery refers to the task of locating the hidden submatrices. For both problems, and for both models, we characterize the statistical and computational barriers by deriving information-theoretic lower bounds, designing and analyzing algorithms matching those bounds, and proving computational lower bounds based on the low-degree polynomials conjecture. In particular, we show that the space of the model parameters (i.e., number of planted submatrices, their dimensions, and elevated mean) can be partitioned into three regions: the impossible regime, where all algorithms fail; the hard regime, where while detection or recovery are statistically possible, we give some evidence that polynomial-time algorithm do not exist; and finally the easy regime, where polynomial-time algorithms exist. ",
    "url": "https://arxiv.org/abs/2306.06643",
    "authors": [
      "Marom Dadon",
      "Wasim Huleihel",
      "Tamir Bendory"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2306.06672",
    "title": "Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with  Academic Compute",
    "abstract": "Self-supervised learning (SSL) has led to great strides in speech processing. However, the resources needed to train these models has become prohibitively large as they continue to scale. Currently, only a few groups with substantial resources are capable of creating SSL models, which harms reproducibility. In this work, we optimize HuBERT SSL to fit in academic constraints. We reproduce HuBERT independently from the original implementation, with no performance loss. Our code and training optimizations make SSL feasible with only 8 GPUs, instead of the 32 used in the original work. We also explore a semi-supervised route, using an ASR model to skip the first pre-training iteration. Within one iteration of pre-training, our models improve over HuBERT on several tasks. Furthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar performance to the original trained on 128. As our contribution to the community, all models, configurations, and code are made open-source in ESPnet. ",
    "url": "https://arxiv.org/abs/2306.06672",
    "authors": [
      "William Chen",
      "Xuankai Chang",
      "Yifan Peng",
      "Zhaoheng Ni",
      "Soumi Maiti",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.06675",
    "title": "Contact Reduction with Bounded Stiffness for Robust Sim-to-Real Transfer  of Robot Assembly",
    "abstract": "In sim-to-real Reinforcement Learning (RL), a policy is trained in a simulated environment and then deployed on the physical system. The main challenge of sim-to-real RL is to overcome the reality gap - the discrepancies between the real world and its simulated counterpart. Using general geometric representations, such as convex decomposition, triangular mesh, signed distance field can improve simulation fidelity, and thus potentially narrow the reality gap. Common to these approaches is that many contact points are generated for geometrically-complex objects, which slows down simulation and may cause numerical instability. Contact reduction methods address these issues by limiting the number of contact points, but the validity of these methods for sim-to-real RL has not been confirmed. In this paper, we present a contact reduction method with bounded stiffness to improve the simulation accuracy. Our experiments show that the proposed method critically enables training RL policy for a tight-clearance double pin insertion task and successfully deploying the policy on a rigid, position-controlled physical robot. ",
    "url": "https://arxiv.org/abs/2306.06675",
    "authors": [
      "Nghia Vuong",
      "Quang-Cuong Pham"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.06686",
    "title": "UAV Trajectory and Multi-User Beamforming Optimization for Clustered  Users Against Passive Eavesdropping Attacks With Unknown CSI",
    "abstract": "This paper tackles the fundamental passive eavesdropping problem in modern wireless communications in which the location and the channel state information (CSI) of the attackers are unknown. In this regard, we propose deploying an unmanned aerial vehicle (UAV) that serves as a mobile aerial relay (AR) to help ground base station (GBS) support a subset of vulnerable users. More precisely, our solution (1) clusters the single-antenna users in two groups to be either served by the GBS directly or via the AR, (2) employs optimal multi-user beamforming to the directly served users, and (3) optimizes the AR's 3D position, its multi-user beamforming matrix and transmit powers by combining closed-form solutions with machine learning techniques. Specifically, we design a plain beamforming and power optimization combined with a deep reinforcement learning (DRL) algorithm for an AR to optimize its trajectory for the security maximization of the served users. Numerical results show that the multi-user multiple input, single output (MU-MISO) system split between a GBS and an AR with optimized transmission parameters without knowledge of the eavesdropping channels achieves high secrecy capacities that scale well with increasing the number of users. ",
    "url": "https://arxiv.org/abs/2306.06686",
    "authors": [
      "Aly Sabri Abdalla",
      "Ali Behfarnia",
      "Vuk Marojevic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06712",
    "title": "Neural Architecture Design and Robustness: A Dataset",
    "abstract": "Deep learning models have proven to be successful in a wide range of machine learning tasks. Yet, they are often highly sensitive to perturbations on the input data which can lead to incorrect decisions with high confidence, hampering their deployment for practical use-cases. Thus, finding architectures that are (more) robust against perturbations has received much attention in recent years. Just like the search for well-performing architectures in terms of clean accuracy, this usually involves a tedious trial-and-error process with one additional challenge: the evaluation of a network's robustness is significantly more expensive than its evaluation for clean accuracy. Thus, the aim of this paper is to facilitate better streamlined research on architectural design choices with respect to their impact on robustness as well as, for example, the evaluation of surrogate measures for robustness. We therefore borrow one of the most commonly considered search spaces for neural architecture search for image classification, NAS-Bench-201, which contains a manageable size of 6466 non-isomorphic network designs. We evaluate all these networks on a range of common adversarial attacks and corruption types and introduce a database on neural architecture design and robustness evaluations. We further present three exemplary use cases of this dataset, in which we (i) benchmark robustness measurements based on Jacobian and Hessian matrices for their robustness predictability, (ii) perform neural architecture search on robust accuracies, and (iii) provide an initial analysis of how architectural design choices affect robustness. We find that carefully crafting the topology of a network can have substantial impact on its robustness, where networks with the same parameter count range in mean adversarial robust accuracy from 20%-41%. Code and data is available at this http URL ",
    "url": "https://arxiv.org/abs/2306.06712",
    "authors": [
      "Steffen Jung",
      "Jovita Lukasik",
      "Margret Keuper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06719",
    "title": "Proteinoid microspheres as proto-neural networks",
    "abstract": "Proteinoids, also known as thermal proteins, possess a fascinating ability to generate microspheres that exhibit electrical spikes resembling the action potentials of neurons. These spiking microspheres, referred to as protoneurons, hold the potential to assemble into proto-nano-brains. In our study, we investigate the feasibility of utilizing a promising electrochemical technique called differential pulse voltammetry (DPV) to interface with proteinoid nano-brains. We evaluate DPV's suitability by examining critical parameters such as selectivity, sensitivity, and linearity of the electrochemical responses. The research systematically explores the influence of various operational factors, including pulse width, pulse amplitude, scan rate, and scan time. Encouragingly, our findings indicate that DPV exhibits significant potential as an efficient electrochemical interface for proteinoid nano-brains. This technology opens up new avenues for developing artificial neural networks with broad applications across diverse fields of research. ",
    "url": "https://arxiv.org/abs/2306.06719",
    "authors": [
      "Panagiotis Mougkogiannis",
      "Andrew Adamatzky"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Biological Physics (physics.bio-ph)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.06723",
    "title": "Counting Distinct Elements in the Turnstile Model with Differential  Privacy under Continual Observation",
    "abstract": "Privacy is a central challenge for systems that learn from sensitive data sets, especially when a system's outputs must be continuously updated to reflect changing data. We consider the achievable error for the differentially private continual release of a basic statistic -- the number of distinct items -- in a stream where items may be both inserted and deleted (the turnstile model). With only insertions, existing algorithms have additive error just polylogarithmic in the length of the stream $T$. We uncover a much richer landscape in the turnstile model, even without considering memory restrictions. We show that any differentially private mechanism that handles insertions and deletions has worst-case additive error at least $T^{1/4}$ even under a relatively weak, event-level privacy definition. Then, we identify a property of the input stream, its maximum flippancy, that is low for natural data streams and for which one can give tight parameterized error guarantees. Specifically, the maximum flippancy is the largest number of times the count of a single item changes from a positive number to zero over the course of the stream. We present an item-level differentially private mechanism that, for all turnstile streams with maximum flippancy $w$, continually outputs the number of distinct elements with an $O(\\sqrt{w} \\cdot \\mathsf{poly}\\log T)$ additive error, without requiring prior knowledge of $w$. This is the best achievable error bound that depends only on $w$, for a large range of values of $w$. When $w$ is small, our mechanism provides similar error guarantees to the polylogarithmic in $T$ guarantees in the insertion-only setting, bypassing the hardness in the turnstile model. ",
    "url": "https://arxiv.org/abs/2306.06723",
    "authors": [
      "Palak Jain",
      "Iden Kalemaj",
      "Sofya Raskhodnikova",
      "Satchit Sivakumar",
      "Adam Smith"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.06734",
    "title": "MLE-based Device Activity Detection under Rician Fading for Massive  Grant-free Access with Perfect and Imperfect Synchronization",
    "abstract": "Most existing studies on massive grant-free access, proposed to support massive machine-type communications (mMTC) for the Internet of things (IoT), assume Rayleigh fading and perfect synchronization for simplicity. However, in practice, line-of-sight (LoS) components generally exist, and time and frequency synchronization are usually imperfect. This paper systematically investigates maximum likelihood estimation (MLE)-based device activity detection under Rician fading for massive grant-free access with perfect and imperfect synchronization. Specifically, we formulate device activity detection in the synchronous case and joint device activity and offset detection in three asynchronous cases (i.e., time, frequency, and time and frequency asynchronous cases) as MLE problems. In the synchronous case, we propose an iterative algorithm to obtain a stationary point of the MLE problem. In each asynchronous case, we propose two iterative algorithms with identical detection performance but different computational complexities. In particular, one is computationally efficient for small ranges of offsets, whereas the other one, relying on fast Fourier transform (FFT) and inverse FFT, is computationally efficient for large ranges of offsets. The proposed algorithms generalize the existing MLE-based methods for Rayleigh fading and perfect synchronization. Numerical results show the notable gains of the proposed algorithms over existing methods in detection accuracy and computation time. ",
    "url": "https://arxiv.org/abs/2306.06734",
    "authors": [
      "Wang Liu",
      "Ying Cui",
      "Feng Yang",
      "Lianghui Ding",
      "Jun Sun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06747",
    "title": "Precise and Generalized Robustness Certification for Neural Networks",
    "abstract": "The objective of neural network (NN) robustness certification is to determine if a NN changes its predictions when mutations are made to its inputs. While most certification research studies pixel-level or a few geometrical-level and blurring operations over images, this paper proposes a novel framework, GCERT, which certifies NN robustness under a precise and unified form of diverse semantic-level image mutations. We formulate a comprehensive set of semantic-level image mutations uniformly as certain directions in the latent space of generative models. We identify two key properties, independence and continuity, that convert the latent space into a precise and analysis-friendly input space representation for certification. GCERT can be smoothly integrated with de facto complete, incomplete, or quantitative certification frameworks. With its precise input space representation, GCERT enables for the first time complete NN robustness certification with moderate cost under diverse semantic-level input mutations, such as weather-filter, style transfer, and perceptual changes (e.g., opening/closing eyes). We show that GCERT enables certifying NN robustness under various common and security-sensitive scenarios like autonomous driving. ",
    "url": "https://arxiv.org/abs/2306.06747",
    "authors": [
      "Yuanyuan Yuan",
      "Shuai Wang",
      "Zhendong Su"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06769",
    "title": "Adversarial Reconnaissance Mitigation and Modeling",
    "abstract": "Adversarial reconnaissance is a crucial step in sophisticated cyber-attacks as it enables threat actors to find the weakest points of otherwise well-defended systems. To thwart reconnaissance, defenders can employ cyber deception techniques, such as deploying honeypots. In recent years, researchers have made great strides in developing game-theoretic models to find optimal deception strategies. However, most of these game-theoretic models build on relatively simple models of adversarial reconnaissance -- even though reconnaissance should be a focus point as the very purpose of deception is to thwart reconnaissance. In this paper, we first discuss effective cyber reconnaissance mitigation techniques including deception strategies and beyond. Then we provide a review of the literature on deception games from the perspective of modeling adversarial reconnaissance, highlighting key aspects of reconnaissance that have not been adequately captured in prior work. We then describe a probability-theory based model of the adversaries' belief formation and illustrate using numerical examples that this model can capture key aspects of adversarial reconnaissance. We believe that our review and belief model can serve as a stepping stone for developing more realistic and practical deception games. ",
    "url": "https://arxiv.org/abs/2306.06769",
    "authors": [
      "Shanto Roy",
      "Nazia Sharmin",
      "Mohammad Sujan Miah",
      "Jaime C Acosta",
      "Christopher Kiekintveld",
      "Aron Laszka"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.06772",
    "title": "Between-Sample Relationship in Learning Tabular Data Using Graph and  Attention Networks",
    "abstract": "Traditional machine learning assumes samples in tabular data to be independent and identically distributed (i.i.d). This assumption may miss useful information within and between sample relationships in representation learning. This paper relaxes the i.i.d assumption to learn tabular data representations by incorporating between-sample relationships for the first time using graph neural networks (GNN). We investigate our hypothesis using several GNNs and state-of-the-art (SOTA) deep attention models to learn the between-sample relationship on ten tabular data sets by comparing them to traditional machine learning methods. GNN methods show the best performance on tabular data with large feature-to-sample ratios. Our results reveal that attention-based GNN methods outperform traditional machine learning on five data sets and SOTA deep tabular learning methods on three data sets. Between-sample learning via GNN and deep attention methods yield the best classification accuracy on seven of the ten data sets. This suggests that the i.i.d assumption may not always hold for most tabular data sets. ",
    "url": "https://arxiv.org/abs/2306.06772",
    "authors": [
      "Shourav B. Rabbani",
      "Manar D. Samad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06788",
    "title": "Graph Mixup with Soft Alignments",
    "abstract": "We study graph data augmentation by mixup, which has been used successfully on images. A key operation of mixup is to compute a convex combination of a pair of inputs. This operation is straightforward for grid-like data, such as images, but challenging for graph data. The key difficulty lies in the fact that different graphs typically have different numbers of nodes, and thus there lacks a node-level correspondence between graphs. In this work, we propose S-Mixup, a simple yet effective mixup method for graph classification by soft alignments. Specifically, given a pair of graphs, we explicitly obtain node-level correspondence via computing a soft assignment matrix to match the nodes between two graphs. Based on the soft assignments, we transform the adjacency and node feature matrices of one graph, so that the transformed graph is aligned with the other graph. In this way, any pair of graphs can be mixed directly to generate an augmented graph. We conduct systematic experiments to show that S-Mixup can improve the performance and generalization of graph neural networks (GNNs) on various graph classification tasks. In addition, we show that S-Mixup can increase the robustness of GNNs against noisy labels. ",
    "url": "https://arxiv.org/abs/2306.06788",
    "authors": [
      "Hongyi Ling",
      "Zhimeng Jiang",
      "Meng Liu",
      "Shuiwang Ji",
      "Na Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06792",
    "title": "A Neural Network Implementation for Free Energy Principle",
    "abstract": "The free energy principle (FEP), as an encompassing framework and a unified brain theory, has been widely applied to account for various problems in fields such as cognitive science, neuroscience, social interaction, and hermeneutics. As a computational model deeply rooted in math and statistics, FEP posits an optimization problem based on variational Bayes, which is solved either by dynamic programming or expectation maximization in practice. However, there seems to be a bottleneck in extending the FEP to machine learning and implementing such models with neural networks. This paper gives a preliminary attempt at bridging FEP and machine learning, via a classical neural network model, the Helmholtz machine. As a variational machine learning model, the Helmholtz machine is optimized by minimizing its free energy, the same objective as FEP. Although the Helmholtz machine is not temporal, it gives an ideal parallel to the vanilla FEP and the hierarchical model of the brain, under which the active inference and predictive coding could be formulated coherently. Besides a detailed theoretical discussion, the paper also presents a preliminary experiment to validate the hypothesis. By fine-tuning the trained neural network through active inference, the model performance is promoted to accuracy above 99\\%. In the meantime, the data distribution is continuously deformed to a salience that conforms to the model representation, as a result of active sampling. ",
    "url": "https://arxiv.org/abs/2306.06792",
    "authors": [
      "Jingwei Liu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.06797",
    "title": "VBSF-TLD: Validation-Based Approach for Soft Computing-Inspired Transfer  Learning in Drone Detection",
    "abstract": "With the increasing utilization of Internet of Things (IoT) enabled drones in diverse applications like photography, delivery, and surveillance, concerns regarding privacy and security have become more prominent. Drones have the ability to capture sensitive information, compromise privacy, and pose security risks. As a result, the demand for advanced technology to automate drone detection has become crucial. This paper presents a project on a transfer-based drone detection scheme, which forms an integral part of a computer vision-based module and leverages transfer learning to enhance performance. By harnessing the knowledge of pre-trained models from a related domain, transfer learning enables improved results even with limited training data. To evaluate the scheme's performance, we conducted tests on benchmark datasets, including the Drone-vs-Bird Dataset and the UAVDT dataset. Notably, the scheme's effectiveness is highlighted by its IOU-based validation results, demonstrating the potential of deep learning-based technology in automating drone detection in critical areas such as airports, military bases, and other high-security zones. ",
    "url": "https://arxiv.org/abs/2306.06797",
    "authors": [
      "Jaskaran Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06798",
    "title": "Kepler: Robust Learning for Faster Parametric Query Optimization",
    "abstract": "Most existing parametric query optimization (PQO) techniques rely on traditional query optimizer cost models, which are often inaccurate and result in suboptimal query performance. We propose Kepler, an end-to-end learning-based approach to PQO that demonstrates significant speedups in query latency over a traditional query optimizer. Central to our method is Row Count Evolution (RCE), a novel plan generation algorithm based on perturbations in the sub-plan cardinality space. While previous approaches require accurate cost models, we bypass this requirement by evaluating candidate plans via actual execution data and training an ML model to predict the fastest plan given parameter binding values. Our models leverage recent advances in neural network uncertainty in order to robustly predict faster plans while avoiding regressions in query performance. Experimentally, we show that Kepler achieves significant improvements in query runtime on multiple datasets on PostgreSQL. ",
    "url": "https://arxiv.org/abs/2306.06798",
    "authors": [
      "Lyric Doshi",
      "Vincent Zhuang",
      "Gaurav Jain",
      "Ryan Marcus",
      "Haoyu Huang",
      "Deniz Altinb\u00fcken",
      "Eugene Brevdo",
      "Campbell Fraser"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06804",
    "title": "Neural Machine Translation for the Indigenous Languages of the Americas:  An Introduction",
    "abstract": "Neural models have drastically advanced state of the art for machine translation (MT) between high-resource languages. Traditionally, these models rely on large amounts of training data, but many language pairs lack these resources. However, an important part of the languages in the world do not have this amount of data. Most languages from the Americas are among them, having a limited amount of parallel and monolingual data, if any. Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages. ",
    "url": "https://arxiv.org/abs/2306.06804",
    "authors": [
      "Manuel Mager",
      "Rajat Bhatnagar",
      "Graham Neubig",
      "Ngoc Thang Vu",
      "Katharina Kann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06805",
    "title": "Unlocking Feature Visualization for Deeper Networks with MAgnitude  Constrained Optimization",
    "abstract": "Feature visualization has gained substantial popularity, particularly after the influential work by Olah et al. in 2017, which established it as a crucial tool for explainability. However, its widespread adoption has been limited due to a reliance on tricks to generate interpretable images, and corresponding challenges in scaling it to deeper neural networks. Here, we describe MACO, a simple approach to address these shortcomings. The main idea is to generate images by optimizing the phase spectrum while keeping the magnitude constant to ensure that generated explanations lie in the space of natural images. Our approach yields significantly better results (both qualitatively and quantitatively) and unlocks efficient and interpretable feature visualizations for large state-of-the-art neural networks. We also show that our approach exhibits an attribution mechanism allowing us to augment feature visualizations with spatial importance. We validate our method on a novel benchmark for comparing feature visualization methods, and release its visualizations for all classes of the ImageNet dataset on https://serre-lab.github.io/Lens/. Overall, our approach unlocks, for the first time, feature visualizations for large, state-of-the-art deep neural networks without resorting to any parametric prior image model. ",
    "url": "https://arxiv.org/abs/2306.06805",
    "authors": [
      "Thomas Fel",
      "Thibaut Boissin",
      "Victor Boutin",
      "Agustin Picard",
      "Paul Novello",
      "Julien Colin",
      "Drew Linsley",
      "Tom Rousseau",
      "R\u00e9mi Cad\u00e8ne",
      "Laurent Gardes",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06815",
    "title": "TrojPrompt: A Black-box Trojan Attack on Pre-trained Language Models",
    "abstract": "Prompt learning has been proven to be highly effective in improving pre-trained language model (PLM) adaptability, surpassing conventional fine-tuning paradigms, and showing exceptional promise in an ever-growing landscape of applications and APIs tailored for few-shot learning scenarios. Despite the growing prominence of prompt learning-based APIs, their security concerns remain underexplored. In this paper, we undertake a pioneering study on the Trojan susceptibility of prompt-learning PLM APIs. We identified several key challenges, including discrete-prompt, few-shot, and black-box settings, which limit the applicability of existing backdoor attacks. To address these challenges, we propose TrojPrompt, an automatic and black-box framework to effectively generate universal and stealthy triggers and insert Trojans into hard prompts. Specifically, we propose a universal API-driven trigger discovery algorithm for generating universal triggers for various inputs by querying victim PLM APIs using few-shot data samples. Furthermore, we introduce a novel progressive trojan poisoning algorithm designed to generate poisoned prompts that retain efficacy and transferability across a diverse range of models. Our experiments and results demonstrate TrojPrompt's capacity to effectively insert Trojans into text prompts in real-world black-box PLM APIs, while maintaining exceptional performance on clean test sets and significantly outperforming baseline models. Our work sheds light on the potential security risks in current models and offers a potential defensive approach. ",
    "url": "https://arxiv.org/abs/2306.06815",
    "authors": [
      "Jiaqi Xue",
      "Yepeng Liu",
      "Mengxin Zheng",
      "Ting Hua",
      "Yilin Shen",
      "Ladislau Boloni",
      "Qian Lou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06819",
    "title": "Multimodal Audio-textual Architecture for Robust Spoken Language  Understanding",
    "abstract": "Recent voice assistants are usually based on the cascade spoken language understanding (SLU) solution, which consists of an automatic speech recognition (ASR) engine and a natural language understanding (NLU) system. Because such approach relies on the ASR output, it often suffers from the so-called ASR error propagation. In this work, we investigate impacts of this ASR error propagation on state-of-the-art NLU systems based on pre-trained language models (PLM), such as BERT and RoBERTa. Moreover, a multimodal language understanding (MLU) module is proposed to mitigate SLU performance degradation caused by errors present in the ASR transcript. The MLU benefits from self-supervised features learned from both audio and text modalities, specifically Wav2Vec for speech and Bert/RoBERTa for language. Our MLU combines an encoder network to embed the audio signal and a text encoder to process text transcripts followed by a late fusion layer to fuse audio and text logits. We found that the proposed MLU showed to be robust towards poor quality ASR transcripts, while the performance of BERT and RoBERTa are severely compromised. Our model is evaluated on five tasks from three SLU datasets and robustness is tested using ASR transcripts from three ASR engines. Results show that the proposed approach effectively mitigates the ASR error propagation problem, surpassing the PLM models' performance across all datasets for the academic ASR engine. ",
    "url": "https://arxiv.org/abs/2306.06819",
    "authors": [
      "Anderson R. Avila",
      "Mehdi Rezagholizadeh",
      "Chao Xing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.06839",
    "title": "Single-Integrator Consensus Dynamics over Minimally Reactive Networks",
    "abstract": "The problem of achieving consensus in a network of connected systems arises in many science and engineering applications. In contrast to previous works, we focus on the system reactivity, i.e., the initial amplification of the norm of the system states. We identify a class of networks that we call minimally reactive, which are such that the indegree and the outdegree of each node of the network are the same. We propose several optimization procedures in which minimum perturbations (links or link weights) are imposed on a given network topology to make it minimally reactive. A new concept of structural reactivity is introduced which measures how much a given network is far from becoming minimally reactive by link perturbations. The structural reactivity of directed random graphs is studied. ",
    "url": "https://arxiv.org/abs/2306.06839",
    "authors": [
      "Amirhossein Nazerian",
      "David Phillips",
      "Hernan A. Makse",
      "Francesco Sorrentino"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06843",
    "title": "Recurrent Attention Networks for Long-text Modeling",
    "abstract": "Self-attention-based models have achieved remarkable progress in short-text mining. However, the quadratic computational complexities restrict their application in long text processing. Prior works have adopted the chunking strategy to divide long documents into chunks and stack a self-attention backbone with the recurrent structure to extract semantic representation. Such an approach disables parallelization of the attention mechanism, significantly increasing the training cost and raising hardware requirements. Revisiting the self-attention mechanism and the recurrent structure, this paper proposes a novel long-document encoding model, Recurrent Attention Network (RAN), to enable the recurrent operation of self-attention. Combining the advantages from both sides, the well-designed RAN is capable of extracting global semantics in both token-level and document-level representations, making it inherently compatible with both sequential and classification tasks, respectively. Furthermore, RAN is computationally scalable as it supports parallelization on long document processing. Extensive experiments demonstrate the long-text encoding ability of the proposed RAN model on both classification and sequential tasks, showing its potential for a wide range of applications. ",
    "url": "https://arxiv.org/abs/2306.06843",
    "authors": [
      "Xianming Li",
      "Zongxi Li",
      "Xiaotian Luo",
      "Haoran Xie",
      "Xing Lee",
      "Yingbin Zhao",
      "Fu Lee Wang",
      "Qing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06851",
    "title": "UniPoll: A Unified Social Media Poll Generation Framework via  Multi-Objective Optimization",
    "abstract": "Social media platforms are essential outlets for expressing opinions, providing a valuable resource for capturing public viewpoints via text analytics. However, for many users, passive browsing is their preferred mode of interaction, leading to their perspectives being overlooked by text analytics methods. Meanwhile, social media polls have emerged as a practical feature for gathering public opinions, allowing post authors to pose questions with pre-defined answer options for readers to vote on. To broaden the benefits of polls for posts without them, this article explores the automatic generation of a poll from a social media post by leveraging cutting-edge natural language generation (NLG) techniques. However, existing NLG techniques, primarily developed for general-domain texts, may be ineffective when applied to noisy social media data, which often feature implicit context-question-answer relations. To tackle these challenges, we enrich a post context with its comments and propose a novel unified poll generation framework called UniPoll. It employs prompt tuning with multi-objective optimization to bolster the connection exploration between contexts (posts and comments) and polls (questions and answers). Experimental comparisons on a large-scale Chinese Weibo dataset show that UniPoll significantly outperforms T5, the state-of-the-art NLG model, which generates question and answer separately. Comprehensive qualitative and quantitative analyses further underscore the superiority of UniPoll through various evaluation lenses. ",
    "url": "https://arxiv.org/abs/2306.06851",
    "authors": [
      "Yixia Li",
      "Rong Xiang",
      "Yanlin Song",
      "Jing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06865",
    "title": "Deep denoising autoencoder-based non-invasive blood flow detection for  arteriovenous fistula",
    "abstract": "Clinical guidelines underscore the importance of regularly monitoring and surveilling arteriovenous fistula (AVF) access in hemodialysis patients to promptly detect any dysfunction. Although phono-angiography/sound analysis overcomes the limitations of standardized AVF stenosis diagnosis tool, prior studies have depended on conventional feature extraction methods, restricting their applicability in diverse contexts. In contrast, representation learning captures fundamental underlying factors that can be readily transferred across different contexts. We propose an approach based on deep denoising autoencoders (DAEs) that perform dimensionality reduction and reconstruction tasks using the waveform obtained through one-level discrete wavelet transform, utilizing representation learning. Our results demonstrate that the latent representation generated by the DAE surpasses expectations with an accuracy of 0.93. The incorporation of noise-mixing and the utilization of a noise-to-clean scheme effectively enhance the discriminative capabilities of the latent representation. Moreover, when employed to identify patient-specific characteristics, the latent representation exhibited performance by surpassing an accuracy of 0.92. Appropriate light-weighted methods can restore the detection performance of the excessively reduced dimensionality version and enable operation on less computational devices. Our findings suggest that representation learning is a more feasible approach for extracting auscultation features in AVF, leading to improved generalization and applicability across multiple tasks. The manipulation of latent representations holds immense potential for future advancements. Further investigations in this area are promising and warrant continued exploration. ",
    "url": "https://arxiv.org/abs/2306.06865",
    "authors": [
      "Li-Chin Chen",
      "Yi-Heng Lin",
      "Li-Ning Peng",
      "Feng-Ming Wang",
      "Yu-Hsin Chen",
      "Po-Hsun Huang",
      "Shang-Feng Yang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06872",
    "title": "History Semantic Graph Enhanced Conversational KBQA with Temporal  Information Modeling",
    "abstract": "Context information modeling is an important task in conversational KBQA. However, existing methods usually assume the independence of utterances and model them in isolation. In this paper, we propose a History Semantic Graph Enhanced KBQA model (HSGE) that is able to effectively model long-range semantic dependencies in conversation history while maintaining low computational cost. The framework incorporates a context-aware encoder, which employs a dynamic memory decay mechanism and models context at different levels of granularity. We evaluate HSGE on a widely used benchmark dataset for complex sequential question answering. Experimental results demonstrate that it outperforms existing baselines averaged on all question types. ",
    "url": "https://arxiv.org/abs/2306.06872",
    "authors": [
      "Hao Sun",
      "Yang Li",
      "Liwei Deng",
      "Bowen Li",
      "Binyuan Hui",
      "Binhua Li",
      "Yunshi Lan",
      "Yan Zhang",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06874",
    "title": "VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion  Models",
    "abstract": "Diffusion Models (DMs) are state-of-the-art generative models that learn a reversible corruption process from iterative noise addition and denoising. They are the backbone of many generative AI applications, such as text-to-image conditional generation. However, recent studies have shown that basic unconditional DMs (e.g., DDPM and DDIM) are vulnerable to backdoor injection, a type of output manipulation attack triggered by a maliciously embedded pattern at model input. This paper presents a unified backdoor attack framework (VillanDiffusion) to expand the current scope of backdoor analysis for DMs. Our framework covers mainstream unconditional and conditional DMs (denoising-based and score-based) and various training-free samplers for holistic evaluations. Experiments show that our unified framework facilitates the backdoor analysis of different DM configurations and provides new insights into caption-based backdoor attacks on DMs. ",
    "url": "https://arxiv.org/abs/2306.06874",
    "authors": [
      "Sheng-Yen Chou",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06878",
    "title": "Fitch Graph Completion",
    "abstract": "Horizontal gene transfer is an important contributor to evolution. According to Walter M.\\ Fitch, two genes are xenologs if they are separated by at least one HGT. More formally, the directed Fitch graph has a set of genes is its vertices, and directed edges $(x,y)$ for all pairs of genes $x$ and $y$ for which $y$ has been horizontally transferred at least once since it diverged from the last common ancestor of $x$ and $y$. Subgraphs of Fitch graphs can be inferred by comparative sequence analysis. In many cases, however, only partial knowledge about the ``full'' Fitch graph can be obtained. Here, we characterize Fitch-satisfiable graphs that can be extended to a biologically feasible ``full'' Fitch graph and derive a simple polynomial-time recognition algorithm. We then proceed to showing that finding the Fitch graphs with total maximum (confidence) edge-weights is an NP-hard problem. ",
    "url": "https://arxiv.org/abs/2306.06878",
    "authors": [
      "Marc Hellmuth",
      "Peter F. Stadler",
      "Sandhya Thekkumpadan Puthiyaveedu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.06881",
    "title": "Unmasking Deepfakes: Masked Autoencoding Spatiotemporal Transformers for  Enhanced Video Forgery Detection",
    "abstract": "We present a novel approach for the detection of deepfake videos using a pair of vision transformers pre-trained by a self-supervised masked autoencoding setup. Our method consists of two distinct components, one of which focuses on learning spatial information from individual RGB frames of the video, while the other learns temporal consistency information from optical flow fields generated from consecutive frames. Unlike most approaches where pre-training is performed on a generic large corpus of images, we show that by pre-training on smaller face-related datasets, namely Celeb-A (for the spatial learning component) and YouTube Faces (for the temporal learning component), strong results can be obtained. We perform various experiments to evaluate the performance of our method on commonly used datasets namely FaceForensics++ (Low Quality and High Quality, along with a new highly compressed version named Very Low Quality) and Celeb-DFv2 datasets. Our experiments show that our method sets a new state-of-the-art on FaceForensics++ (LQ, HQ, and VLQ), and obtains competitive results on Celeb-DFv2. Moreover, our method outperforms other methods in the area in a cross-dataset setup where we fine-tune our model on FaceForensics++ and test on CelebDFv2, pointing to its strong cross-dataset generalization ability. ",
    "url": "https://arxiv.org/abs/2306.06881",
    "authors": [
      "Sayantan Das",
      "Mojtaba Kolahdouzi",
      "Levent \u00d6zparlak",
      "Will Hickie",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06885",
    "title": "NPVForensics: Jointing Non-critical Phonemes and Visemes for Deepfake  Detection",
    "abstract": "Deepfake technologies empowered by deep learning are rapidly evolving, creating new security concerns for society. Existing multimodal detection methods usually capture audio-visual inconsistencies to expose Deepfake videos. More seriously, the advanced Deepfake technology realizes the audio-visual calibration of the critical phoneme-viseme regions, achieving a more realistic tampering effect, which brings new challenges. To address this problem, we propose a novel Deepfake detection method to mine the correlation between Non-critical Phonemes and Visemes, termed NPVForensics. Firstly, we propose the Local Feature Aggregation block with Swin Transformer (LFA-ST) to construct non-critical phoneme-viseme and corresponding facial feature streams effectively. Secondly, we design a loss function for the fine-grained motion of the talking face to measure the evolutionary consistency of non-critical phoneme-viseme. Next, we design a phoneme-viseme awareness module for cross-modal feature fusion and representation alignment, so that the modality gap can be reduced and the intrinsic complementarity of the two modalities can be better explored. Finally, a self-supervised pre-training strategy is leveraged to thoroughly learn the audio-visual correspondences in natural videos. In this manner, our model can be easily adapted to the downstream Deepfake datasets with fine-tuning. Extensive experiments on existing benchmarks demonstrate that the proposed approach outperforms state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2306.06885",
    "authors": [
      "Yu Chen",
      "Yang Yu",
      "Rongrong Ni",
      "Yao Zhao",
      "Haoliang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06893",
    "title": "In-context Cross-Density Adaptation on Noisy Mammogram Abnormalities  Detection",
    "abstract": "This paper investigates the impact of breast density distribution on the generalization performance of deep-learning models on mammography images using the VinDr-Mammo dataset. We explore the use of domain adaptation techniques, specifically Domain Adaptive Object Detection (DAOD) with the Noise Latent Transferability Exploration (NLTE) framework, to improve model performance across breast densities under noisy labeling circumstances. We propose a robust augmentation framework to bridge the domain gap between the source and target inside a dataset. Our results show that DAOD-based methods, along with the proposed augmentation framework, can improve the generalization performance of deep-learning models (+5% overall mAP improvement approximately in our experimental results compared to commonly used detection models). This paper highlights the importance of domain adaptation techniques in medical imaging, particularly in the context of breast density distribution, which is critical in mammography. ",
    "url": "https://arxiv.org/abs/2306.06893",
    "authors": [
      "Huy T. Nguyen",
      "Thinh B. Lam",
      "Quan D.D. Tran",
      "Minh T. Nguyen",
      "Dat T. Chung",
      "Vinh Q. Dinh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06895",
    "title": "MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time  Series Forecasting",
    "abstract": "Long-term time series forecasting plays an important role in various real-world scenarios. Recent deep learning methods for long-term series forecasting tend to capture the intricate patterns of time series by decomposition-based or sampling-based methods. However, most of the extracted patterns may include unpredictable noise and lack good interpretability. Moreover, the multivariate series forecasting methods usually ignore the individual characteristics of each variate, which may affecting the prediction accuracy. To capture the intrinsic patterns of time series, we propose a novel deep learning network architecture, named Multi-resolution Periodic Pattern Network (MPPN), for long-term series forecasting. We first construct context-aware multi-resolution semantic units of time series and employ multi-periodic pattern mining to capture the key patterns of time series. Then, we propose a channel adaptive module to capture the perceptions of multivariate towards different patterns. In addition, we present an entropy-based method for evaluating the predictability of time series and providing an upper bound on the prediction accuracy before forecasting. Our experimental evaluation on nine real-world benchmarks demonstrated that MPPN significantly outperforms the state-of-the-art Transformer-based, decomposition-based and sampling-based methods for long-term series forecasting. ",
    "url": "https://arxiv.org/abs/2306.06895",
    "authors": [
      "Xing Wang",
      "Zhendong Wang",
      "Kexin Yang",
      "Junlan Feng",
      "Zhiyan Song",
      "Chao Deng",
      "Lin zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06899",
    "title": "Augmenting Zero-Shot Detection Training with Image Labels",
    "abstract": "Zero-shot detection (ZSD), i.e., detection on classes not seen during training, is essential for real world detection use-cases, but remains a difficult task. Recent research attempts ZSD with detection models that output embeddings instead of direct class labels. To this aim, the output of the detection model must be aligned to a learned embedding space such as CLIP. However, this alignment is hindered by detection data sets which are expensive to produce compared to image classification annotations, and the resulting lack of category diversity in the training data. We address this challenge by leveraging the CLIP embedding space in combination with image labels from ImageNet. Our results show that image labels are able to better align the detector output to the embedding space and thus have a high potential for ZSD. Compared to only training on detection data, we see a significant gain by adding image label data of 3.3 mAP for the 65/15 split on COCO on the unseen classes, i.e., we more than double the gain of related work. ",
    "url": "https://arxiv.org/abs/2306.06899",
    "authors": [
      "Katharina Kornmeier",
      "Ulla Scheler",
      "Pascal Herrmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06900",
    "title": "FocalGatedNet: A Novel Deep Learning Model for Accurate Knee Joint Angle  Prediction",
    "abstract": "Predicting knee joint angles accurately is critical for biomechanical analysis and rehabilitation. This paper introduces a new deep learning model called FocalGatedNet that incorporates Dynamic Contextual Focus (DCF) Attention and Gated Linear Units (GLU) to enhance feature dependencies and interactions. Our proposed model is evaluated on a large-scale dataset and compared to existing models such as Transformer, Autoformer, Informer, NLinear, DLinear, and LSTM in multi-step gait trajectory prediction. Our results demonstrate that FocalGatedNet outperforms other state-of-the-art models for long-term prediction lengths (60 ms, 80 ms, and 100 ms), achieving an average improvement of 13.66% in MAE and 8.13% in RMSE compared to the second-best performing model (Transformer). Furthermore, our model has a lower computational load than most equivalent deep learning models. These results highlight the effectiveness of our proposed model for knee joint angle prediction and the importance of our modifications for this specific application. ",
    "url": "https://arxiv.org/abs/2306.06900",
    "authors": [
      "Humaid Ibrahim",
      "Lyes Saad Saoud",
      "Ahmad Aljarah",
      "Irfan Hussain"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.06904",
    "title": "Differentiable Multi-Fidelity Fusion: Efficient Learning of Physics  Simulations with Neural Architecture Search and Transfer Learning",
    "abstract": "With rapid progress in deep learning, neural networks have been widely used in scientific research and engineering applications as surrogate models. Despite the great success of neural networks in fitting complex systems, two major challenges still remain: i) the lack of generalization on different problems/datasets, and ii) the demand for large amounts of simulation data that are computationally expensive. To resolve these challenges, we propose the differentiable \\mf (DMF) model, which leverages neural architecture search (NAS) to automatically search the suitable model architecture for different problems, and transfer learning to transfer the learned knowledge from low-fidelity (fast but inaccurate) data to high-fidelity (slow but accurate) model. Novel and latest machine learning techniques such as hyperparameters search and alternate learning are used to improve the efficiency and robustness of DMF. As a result, DMF can efficiently learn the physics simulations with only a few high-fidelity training samples, and outperform the state-of-the-art methods with a significant margin (with up to 58$\\%$ improvement in RMSE) based on a variety of synthetic and practical benchmark problems. ",
    "url": "https://arxiv.org/abs/2306.06904",
    "authors": [
      "Yuwen Deng",
      "Wang Kang",
      "Wei W. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06908",
    "title": "Active Learning Guided Fine-Tuning for enhancing Self-Supervised Based  Multi-Label Classification of Remote Sensing Images",
    "abstract": "In recent years, deep neural networks (DNNs) have been found very successful for multi-label classification (MLC) of remote sensing (RS) images. Self-supervised pre-training combined with fine-tuning on a randomly selected small training set has become a popular approach to minimize annotation efforts of data-demanding DNNs. However, fine-tuning on a small and biased training set may limit model performance. To address this issue, we investigate the effectiveness of the joint use of self-supervised pre-training with active learning (AL). The considered AL strategy aims at guiding the MLC fine-tuning of a self-supervised model by selecting informative training samples to annotate in an iterative manner. Experimental results show the effectiveness of applying AL-guided fine-tuning (particularly for the case where strong class-imbalance is present in MLC problems) compared to the application of fine-tuning using a randomly constructed small training set. ",
    "url": "https://arxiv.org/abs/2306.06908",
    "authors": [
      "Lars M\u00f6llenbrok",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06909",
    "title": "Graph Agent Network: Empowering Nodes with Decentralized Communications  Capabilities for Adversarial Resilience",
    "abstract": "End-to-end training with global optimization have popularized graph neural networks (GNNs) for node classification, yet inadvertently introduced vulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit the inherent opened interfaces of GNNs' input and output, perturbing critical edges and thus manipulating the classification results. Current defenses, due to their persistent utilization of global-optimization-based end-to-end training schemes, inherently encapsulate the vulnerabilities of GNNs. This is specifically evidenced in their inability to defend against targeted secondary attacks. In this paper, we propose the Graph Agent Network (GAgN) to address the aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent network in which each node is designed as an 1-hop-view agent. Through the decentralized interactions between agents, they can learn to infer global perceptions to perform tasks including inferring embeddings, degrees and neighbor relationships for given nodes. This empowers nodes to filtering adversarial edges while carrying out classification tasks. Furthermore, agents' limited view prevents malicious messages from propagating globally in GAgN, thereby resisting global-optimization-based secondary attacks. We prove that single-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient to achieve these functionalities. Experimental results show that GAgN effectively implements all its intended capabilities and, compared to state-of-the-art defenses, achieves optimal classification accuracy on the perturbed datasets. ",
    "url": "https://arxiv.org/abs/2306.06909",
    "authors": [
      "Ao Liu",
      "Wenshan Li",
      "Tao Li",
      "Beibei Li",
      "Hanyuan Huang",
      "Guangquan Xu",
      "Pan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.06913",
    "title": "Network Robustness Learning via Graph Transformer",
    "abstract": "Learning and analysis of network robustness, including controllability robustness and connectivity robustness, is critical for various networked systems against attacks. Traditionally, network robustness is determined by attack simulations, which is very time-consuming and even incapable for large-scale networks. Network Robustness Learning, which is dedicated to learning network robustness with high precision and high speed, provides a powerful tool to analyze network robustness by replacing simulations. In this paper, a novel versatile and unified robustness learning approach via graph transformer (NRL-GT) is proposed, which accomplishes the task of controllability robustness learning and connectivity robustness learning from multiple aspects including robustness curve learning, overall robustness learning, and synthetic network classification. Numerous experiments show that: 1) NRL-GT is a unified learning framework for controllability robustness and connectivity robustness, demonstrating a strong generalization ability to ensure high precision when training and test sets are distributed differently; 2) Compared to the cutting-edge methods, NRL-GT can simultaneously perform network robustness learning from multiple aspects and obtains superior results in less time. NRL-GT is also able to deal with complex networks of different size with low learning error and high efficiency; 3) It is worth mentioning that the backbone of NRL-GT can serve as a transferable feature learning module for complex networks of different size and different downstream tasks. ",
    "url": "https://arxiv.org/abs/2306.06913",
    "authors": [
      "Yu Zhang",
      "Jia Li",
      "Jie Ding",
      "Xiang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.06928",
    "title": "Sparse-Inductive Generative Adversarial Hashing for Nearest Neighbor  Search",
    "abstract": "Unsupervised hashing has received extensive research focus on the past decade, which typically aims at preserving a predefined metric (i.e. Euclidean metric) in the Hamming space. To this end, the encoding functions of the existing hashing are typically quasi-isometric, which devote to reducing the quantization loss from the target metric space to the discrete Hamming space. However, it is indeed problematic to directly minimize such error, since such mentioned two metric spaces are heterogeneous, and the quasi-isometric mapping is non-linear. The former leads to inconsistent feature distributions, while the latter leads to problematic optimization issues. In this paper, we propose a novel unsupervised hashing method, termed Sparsity-Induced Generative Adversarial Hashing (SiGAH), to encode large-scale high-dimensional features into binary codes, which well solves the two problems through a generative adversarial training framework. Instead of minimizing the quantization loss, our key innovation lies in enforcing the learned Hamming space to have similar data distribution to the target metric space via a generative model. In particular, we formulate a ReLU-based neural network as a generator to output binary codes and an MSE-loss based auto-encoder network as a discriminator, upon which a generative adversarial learning is carried out to train hash functions. Furthermore, to generate the synthetic features from the hash codes, a compressed sensing procedure is introduced into the generative model, which enforces the reconstruction boundary of binary codes to be consistent with that of original features. Finally, such generative adversarial framework can be trained via the Adam optimizer. Experimental results on four benchmarks, i.e., Tiny100K, GIST1M, Deep1M, and MNIST, have shown that the proposed SiGAH has superior performance over the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2306.06928",
    "authors": [
      "Hong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06930",
    "title": "Localised Adaptive Spatial-Temporal Graph Neural Network",
    "abstract": "Spatial-temporal graph models are prevailing for abstracting and modelling spatial and temporal dependencies. In this work, we ask the following question: \\textit{whether and to what extent can we localise spatial-temporal graph models?} We limit our scope to adaptive spatial-temporal graph neural networks (ASTGNNs), the state-of-the-art model architecture. Our approach to localisation involves sparsifying the spatial graph adjacency matrices. To this end, we propose Adaptive Graph Sparsification (AGS), a graph sparsification algorithm which successfully enables the localisation of ASTGNNs to an extreme extent (fully localisation). We apply AGS to two distinct ASTGNN architectures and nine spatial-temporal datasets. Intriguingly, we observe that spatial graphs in ASTGNNs can be sparsified by over 99.5\\% without any decline in test accuracy. Furthermore, even when ASTGNNs are fully localised, becoming graph-less and purely temporal, we record no drop in accuracy for the majority of tested datasets, with only minor accuracy deterioration observed in the remaining datasets. However, when the partially or fully localised ASTGNNs are reinitialised and retrained on the same data, there is a considerable and consistent drop in accuracy. Based on these observations, we reckon that \\textit{(i)} in the tested data, the information provided by the spatial dependencies is primarily included in the information provided by the temporal dependencies and, thus, can be essentially ignored for inference; and \\textit{(ii)} although the spatial dependencies provide redundant information, it is vital for the effective training of ASTGNNs and thus cannot be ignored during training. Furthermore, the localisation of ASTGNNs holds the potential to reduce the heavy computation overhead required on large-scale spatial-temporal data and further enable the distributed deployment of ASTGNNs. ",
    "url": "https://arxiv.org/abs/2306.06930",
    "authors": [
      "Wenying Duan",
      "Xiaoxi He",
      "Zimu Zhou",
      "Lothar Thiele",
      "Hong Rao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06934",
    "title": "Scale-Rotation-Equivariant Lie Group Convolution Neural Networks (Lie  Group-CNNs)",
    "abstract": "The weight-sharing mechanism of convolutional kernels ensures translation-equivariance of convolution neural networks (CNNs). Recently, rotation-equivariance has been investigated. However, research on scale-equivariance or simultaneous scale-rotation-equivariance is insufficient. This study proposes a Lie group-CNN, which can keep scale-rotation-equivariance for image classification tasks. The Lie group-CNN includes a lifting module, a series of group convolution modules, a global pooling layer, and a classification layer. The lifting module transfers the input image from Euclidean space to Lie group space, and the group convolution is parameterized through a fully connected network using Lie-algebra of Lie-group elements as inputs to achieve scale-rotation-equivariance. The Lie group SIM(2) is utilized to establish the Lie group-CNN with scale-rotation-equivariance. Scale-rotation-equivariance of Lie group-CNN is verified and achieves the best recognition accuracy on the blood cell dataset (97.50%) and the HAM10000 dataset (77.90%) superior to Lie algebra convolution network, dilation convolution, spatial transformer network, and scale-equivariant steerable network. In addition, the generalization ability of the Lie group-CNN on SIM(2) on rotation-equivariance is verified on rotated-MNIST and rotated-CIFAR10, and the robustness of the network is verified on SO(2) and SE(2). Therefore, the Lie group-CNN can successfully extract geometric features and performs equivariant recognition on images with rotation and scale transformations. ",
    "url": "https://arxiv.org/abs/2306.06934",
    "authors": [
      "Wei-Dong Qiao",
      "Yang Xu",
      "Hui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06935",
    "title": "LIVABLE: Exploring Long-Tailed Classification of Software Vulnerability  Types",
    "abstract": "Prior studies generally focus on software vulnerability detection and have demonstrated the effectiveness of Graph Neural Network (GNN)-based approaches for the task. Considering the various types of software vulnerabilities and the associated different degrees of severity, it is also beneficial to determine the type of each vulnerable code for developers. In this paper, we observe that the distribution of vulnerability type is long-tailed in practice, where a small portion of classes have massive samples (i.e., head classes) but the others contain only a few samples (i.e., tail classes). Directly adopting previous vulnerability detection approaches tends to result in poor detection performance, mainly due to two reasons. First, it is difficult to effectively learn the vulnerability representation due to the over-smoothing issue of GNNs. Second, vulnerability types in tails are hard to be predicted due to the extremely few associated samples.To alleviate these issues, we propose a Long-taIled software VulnerABiLity typE classification approach, called LIVABLE. LIVABLE mainly consists of two modules, including (1) vulnerability representation learning module, which improves the propagation steps in GNN to distinguish node representations by a differentiated propagation method. A sequence-to-sequence model is also involved to enhance the vulnerability representations. (2) adaptive re-weighting module, which adjusts the learning weights for different types according to the training epochs and numbers of associated samples by a novel training loss. ",
    "url": "https://arxiv.org/abs/2306.06935",
    "authors": [
      "Xin-Cheng Wen",
      "Cuiyun Gao",
      "Feng Luo",
      "Haoyu Wang",
      "Ge Li",
      "Qing Liao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06936",
    "title": "CARL-G: Clustering-Accelerated Representation Learning on Graphs",
    "abstract": "Self-supervised learning on graphs has made large strides in achieving great performance in various downstream tasks. However, many state-of-the-art methods suffer from a number of impediments, which prevent them from realizing their full potential. For instance, contrastive methods typically require negative sampling, which is often computationally costly. While non-contrastive methods avoid this expensive step, most existing methods either rely on overly complex architectures or dataset-specific augmentations. In this paper, we ask: Can we borrow from classical unsupervised machine learning literature in order to overcome those obstacles? Guided by our key insight that the goal of distance-based clustering closely resembles that of contrastive learning: both attempt to pull representations of similar items together and dissimilar items apart. As a result, we propose CARL-G - a novel clustering-based framework for graph representation learning that uses a loss inspired by Cluster Validation Indices (CVIs), i.e., internal measures of cluster quality (no ground truth required). CARL-G is adaptable to different clustering methods and CVIs, and we show that with the right choice of clustering method and CVI, CARL-G outperforms node classification baselines on 4/5 datasets with up to a 79x training speedup compared to the best-performing baseline. CARL-G also performs at par or better than baselines in node clustering and similarity search tasks, training up to 1,500x faster than the best-performing baseline. Finally, we also provide theoretical foundations for the use of CVI-inspired losses in graph representation learning. ",
    "url": "https://arxiv.org/abs/2306.06936",
    "authors": [
      "William Shiao",
      "Uday Singh Saini",
      "Yozen Liu",
      "Tong Zhao",
      "Neil Shah",
      "Evangelos E. Papalexakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06945",
    "title": "Underwater Acoustic Target Recognition based on Smoothness-inducing  Regularization and Spectrogram-based Data Augmentation",
    "abstract": "Underwater acoustic target recognition is a challenging task owing to the intricate underwater environments and limited data availability. Insufficient data can hinder the ability of recognition systems to support complex modeling, thus impeding their advancement. To improve the generalization capacity of recognition models, techniques such as data augmentation have been employed to simulate underwater signals and diversify data distribution. However, the complexity of underwater environments can cause the simulated signals to deviate from real scenarios, resulting in biased models that are misguided by non-true data. In this study, we propose two strategies to enhance the generalization ability of models in the case of limited data while avoiding the risk of performance degradation. First, as an alternative to traditional data augmentation, we utilize smoothness-inducing regularization, which only incorporates simulated signals in the regularization term. Additionally, we propose a specialized spectrogram-based data augmentation strategy, namely local masking and replicating (LMR), to capture inter-class relationships. Our experiments and visualization analysis demonstrate the superiority of our proposed strategies. ",
    "url": "https://arxiv.org/abs/2306.06945",
    "authors": [
      "Ji Xu",
      "Yuan Xie",
      "Wenchao Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06948",
    "title": "Rethinking Translation Memory Augmented Neural Machine Translation",
    "abstract": "This paper rethinks translation memory augmented neural machine translation (TM-augmented NMT) from two perspectives, i.e., a probabilistic view of retrieval and the variance-bias decomposition principle. The finding demonstrates that TM-augmented NMT is good at the ability of fitting data (i.e., lower bias) but is more sensitive to the fluctuations in the training data (i.e., higher variance), which provides an explanation to a recently reported contradictory phenomenon on the same translation task: TM-augmented NMT substantially advances vanilla NMT under the high-resource scenario whereas it fails under the low-resource scenario. Then we propose a simple yet effective TM-augmented NMT model to promote the variance and address the contradictory phenomenon. Extensive experiments show that the proposed TM-augmented NMT achieves consistent gains over both conventional NMT and existing TM-augmented NMT under two variance-preferable (low-resource and plug-and-play) scenarios as well as the high-resource scenario. ",
    "url": "https://arxiv.org/abs/2306.06948",
    "authors": [
      "Hongkun Hao",
      "Guoping Huang",
      "Lemao Liu",
      "Zhirui Zhang",
      "Shuming Shi",
      "Rui Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06956",
    "title": "Assessing the Impact of File Ordering Strategies on Code Review Process",
    "abstract": "Popular modern code review tools (e.g. Gerrit and GitHub) sort files in a code review in alphabetical order. A prior study (on open-source projects) shows that the changed files' positions in the code review affect the review process. Their results show that files placed lower in the order have less chance of receiving reviewing efforts than the other files. Hence, there is a higher chance of missing defects in these files. This paper explores the impact of file order in the code review of the well-known industrial project IntelliJ IDEA. First, we verify the results of the prior study on a big proprietary software project. Then, we explore an alternative to the default Alphabetical order: ordering changed files according to their code diff. Our results confirm the observations of the previous study. We discover that reviewers leave more comments on the files shown higher in the code review. Moreover, these results show that, even with the data skewed toward Alphabetical order, ordering changed files according to their code diff performs better than standard Alphabetical order regarding placing problematic files, which needs more reviewing effort, in the code review. These results confirm that exploring various ordering strategies for code review needs more exploration. ",
    "url": "https://arxiv.org/abs/2306.06956",
    "authors": [
      "Farid Bagirov",
      "Pouria Derakhshanfar",
      "Alexey Kalina",
      "Elena Kartysheva",
      "Vladimir Kovalenko"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.06960",
    "title": "Semantic Parsing of Colonoscopy Videos with Multi-Label Temporal  Networks",
    "abstract": "Following the successful debut of polyp detection and characterization, more advanced automation tools are being developed for colonoscopy. The new automation tasks, such as quality metrics or report generation, require understanding of the procedure flow that includes activities, events, anatomical landmarks, etc. In this work we present a method for automatic semantic parsing of colonoscopy videos. The method uses a novel DL multi-label temporal segmentation model trained in supervised and unsupervised regimes. We evaluate the accuracy of the method on a test set of over 300 annotated colonoscopy videos, and use ablation to explore the relative importance of various method's components. ",
    "url": "https://arxiv.org/abs/2306.06960",
    "authors": [
      "Ori Kelner",
      "Or Weinstein",
      "Ehud Rivlin",
      "Roman Goldenberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06979",
    "title": "A Weakly Supervised Approach to Emotion-change Prediction and Improved  Mood Inference",
    "abstract": "Whilst a majority of affective computing research focuses on inferring emotions, examining mood or understanding the \\textit{mood-emotion interplay} has received significantly less attention. Building on prior work, we (a) deduce and incorporate emotion-change ($\\Delta$) information for inferring mood, without resorting to annotated labels, and (b) attempt mood prediction for long duration video clips, in alignment with the characterisation of mood. We generate the emotion-change ($\\Delta$) labels via metric learning from a pre-trained Siamese Network, and use these in addition to mood labels for mood classification. Experiments evaluating \\textit{unimodal} (training only using mood labels) vs \\textit{multimodal} (training using mood plus $\\Delta$ labels) models show that mood prediction benefits from the incorporation of emotion-change information, emphasising the importance of modelling the mood-emotion interplay for effective mood inference. ",
    "url": "https://arxiv.org/abs/2306.06979",
    "authors": [
      "Soujanya Narayana",
      "Ibrahim Radwan",
      "Ravikiran Parameshwara",
      "Iman Abbasnejad",
      "Akshay Asthana",
      "Ramanathan Subramanian",
      "Roland Goecke"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2306.06994",
    "title": "Correlated Time Series Self-Supervised Representation Learning via  Spatiotemporal Bootstrapping",
    "abstract": "Correlated time series analysis plays an important role in many real-world industries. Learning an efficient representation of this large-scale data for further downstream tasks is necessary but challenging. In this paper, we propose a time-step-level representation learning framework for individual instances via bootstrapped spatiotemporal representation prediction. We evaluated the effectiveness and flexibility of our representation learning framework on correlated time series forecasting and cold-start transferring the forecasting model to new instances with limited data. A linear regression model trained on top of the learned representations demonstrates our model performs best in most cases. Especially compared to representation learning models, we reduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset, respectively. Furthermore, in real-world metro passenger flow data, our framework demonstrates the ability to transfer to infer future information of new cold-start instances, with gains of 15%, 19%, and 18%. The source code will be released under the GitHub https://github.com/bonaldli/Spatiotemporal-TS-Representation-Learning ",
    "url": "https://arxiv.org/abs/2306.06994",
    "authors": [
      "Luxuan Wang",
      "Lei Bai",
      "Ziyue Li",
      "Rui Zhao",
      "Fugee Tsung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06995",
    "title": "How robust accuracy suffers from certified training with convex  relaxations",
    "abstract": "Adversarial attacks pose significant threats to deploying state-of-the-art classifiers in safety-critical applications. Two classes of methods have emerged to address this issue: empirical defences and certified defences. Although certified defences come with robustness guarantees, empirical defences such as adversarial training enjoy much higher popularity among practitioners. In this paper, we systematically compare the standard and robust error of these two robust training paradigms across multiple computer vision tasks. We show that in most tasks and for both $\\mathscr{l}_\\infty$-ball and $\\mathscr{l}_2$-ball threat models, certified training with convex relaxations suffers from worse standard and robust error than adversarial training. We further explore how the error gap between certified and adversarial training depends on the threat model and the data distribution. In particular, besides the perturbation budget, we identify as important factors the shape of the perturbation set and the implicit margin of the data distribution. We support our arguments with extensive ablations on both synthetic and image datasets. ",
    "url": "https://arxiv.org/abs/2306.06995",
    "authors": [
      "Piersilvio De Bartolomeis",
      "Jacob Clarysse",
      "Amartya Sanyal",
      "Fanny Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06999",
    "title": "Temporal Reachability Dominating Sets: contagion in temporal graphs",
    "abstract": "SARS-CoV-2 was independently introduced to the UK at least 1300 times by June 2020. Given a population with dynamic pairwise connections, we ask if the entire population could be (indirectly) infected by a small group of $k$ initially infected individuals. We formalise this problem as the Temporal Reachability Dominating Set (TaRDiS) problem on temporal graphs. We provide positive and negative parameterized complexity results in four different parameters: the number $k$ of initially infected, the lifetime $\\tau$ of the graph, the number of locally earliest edges in the graph, and the treewidth of the footprint graph $\\mathcal{G}_\\downarrow$. We additionally introduce and study the MaxMinTaRDiS problem, which can be naturally expressed as scheduling connections between individuals so that a population needs to be infected by at least $k$ individuals to become fully infected. Interestingly, we find a restriction of this problem to correspond exactly to the well-studied Distance-3 Independent Set problem on static graphs. ",
    "url": "https://arxiv.org/abs/2306.06999",
    "authors": [
      "David C. Kutner",
      "Laura Larios-Jones"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.07005",
    "title": "AI-Generated Image Detection using a Cross-Attention Enhanced  Dual-Stream Network",
    "abstract": "With the rapid evolution of AI Generated Content (AIGC), forged images produced through this technology are inherently more deceptive and require less human intervention compared to traditional Computer-generated Graphics (CG). However, owing to the disparities between CG and AIGC, conventional CG detection methods tend to be inadequate in identifying AIGC-produced images. To address this issue, our research concentrates on the text-to-image generation process in AIGC. Initially, we first assemble two text-to-image databases utilizing two distinct AI systems, DALLE2 and DreamStudio. Aiming to holistically capture the inherent anomalies produced by AIGC, we develope a robust dual-stream network comprised of a residual stream and a content stream. The former employs the Spatial Rich Model (SRM) to meticulously extract various texture information from images, while the latter seeks to capture additional forged traces in low frequency, thereby extracting complementary information that the residual stream may overlook. To enhance the information exchange between these two streams, we incorporate a cross multi-head attention mechanism. Numerous comparative experiments are performed on both databases, and the results show that our detection method consistently outperforms traditional CG detection techniques across a range of image resolutions. Moreover, our method exhibits superior performance through a series of robustness tests and cross-database experiments. When applied to widely recognized traditional CG benchmarks such as SPL2018 and DsTok, our approach significantly exceeds the capabilities of other existing methods in the field of CG detection. ",
    "url": "https://arxiv.org/abs/2306.07005",
    "authors": [
      "Ziyi Xi",
      "Wenmin Huang",
      "Kangkang Wei",
      "Weiqi Luo",
      "Peijia Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.07019",
    "title": "Dynamic Causal Graph Convolutional Network for Traffic Prediction",
    "abstract": "Modeling complex spatiotemporal dependencies in correlated traffic series is essential for traffic prediction. While recent works have shown improved prediction performance by using neural networks to extract spatiotemporal correlations, their effectiveness depends on the quality of the graph structures used to represent the spatial topology of the traffic network. In this work, we propose a novel approach for traffic prediction that embeds time-varying dynamic Bayesian network to capture the fine spatiotemporal topology of traffic data. We then use graph convolutional networks to generate traffic forecasts. To enable our method to efficiently model nonlinear traffic propagation patterns, we develop a deep learning-based module as a hyper-network to generate stepwise dynamic causal graphs. Our experimental results on a real traffic dataset demonstrate the superior prediction performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2306.07019",
    "authors": [
      "Junpeng Lin",
      "Ziyue Li",
      "Zhishuai Li",
      "Lei Bai",
      "Rui Zhao",
      "Chen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.07024",
    "title": "DRCFS: Doubly Robust Causal Feature Selection",
    "abstract": "Knowing the features of a complex system that are highly relevant to a particular target variable is of fundamental interest in many areas of science. Existing approaches are often limited to linear settings, sometimes lack guarantees, and in most cases, do not scale to the problem at hand, in particular to images. We propose DRCFS, a doubly robust feature selection method for identifying the causal features even in nonlinear and high dimensional settings. We provide theoretical guarantees, illustrate necessary conditions for our assumptions, and perform extensive experiments across a wide range of simulated and semi-synthetic datasets. DRCFS significantly outperforms existing state-of-the-art methods, selecting robust features even in challenging highly non-linear and high-dimensional problems. ",
    "url": "https://arxiv.org/abs/2306.07024",
    "authors": [
      "Francesco Quinzan",
      "Ashkan Soleymani",
      "Patrik Jaillet",
      "Cristian R. Rojas",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.07027",
    "title": "Rotational augmentation techniques: a new perspective on ensemble  learning for image classification",
    "abstract": "The popularity of data augmentation techniques in machine learning has increased in recent years, as they enable the creation of new samples from existing datasets. Rotational augmentation, in particular, has shown great promise by revolving images and utilising them as additional data points for training. This research study introduces a new approach to enhance the performance of classification methods where the testing sets were generated employing transformations on every image from the original dataset. Subsequently, ensemble-based systems were implemented to determine the most reliable outcome in each subset acquired from the augmentation phase to get a final prediction for every original image. The findings of this study suggest that rotational augmentation techniques can significantly improve the accuracy of standard classification models; and the selection of a voting scheme can considerably impact the model's performance. Overall, the study found that using an ensemble-based voting system produced more accurate results than simple voting. ",
    "url": "https://arxiv.org/abs/2306.07027",
    "authors": [
      "Unai Mu\u00f1oz-Aseguinolaza",
      "Basilio Sierra",
      "Naiara Aginako"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07030",
    "title": "Resource Efficient Neural Networks Using Hessian Based Pruning",
    "abstract": "Neural network pruning is a practical way for reducing the size of trained models and the number of floating-point operations. One way of pruning is to use the relative Hessian trace to calculate sensitivity of each channel, as compared to the more common magnitude pruning approach. However, the stochastic approach used to estimate the Hessian trace needs to iterate over many times before it can converge. This can be time-consuming when used for larger models with many millions of parameters. To address this problem, we modify the existing approach by estimating the Hessian trace using FP16 precision instead of FP32. We test the modified approach (EHAP) on ResNet-32/ResNet-56/WideResNet-28-8 trained on CIFAR10/CIFAR100 image classification tasks and achieve faster computation of the Hessian trace. Specifically, our modified approach can achieve speed ups ranging from 17% to as much as 44% during our experiments on different combinations of model architectures and GPU devices. Our modified approach also takes up around 40% less GPU memory when pruning ResNet-32 and ResNet-56 models, which allows for a larger Hessian batch size to be used for estimating the Hessian trace. Meanwhile, we also present the results of pruning using both FP16 and FP32 Hessian trace calculation and show that there are no noticeable accuracy differences between the two. Overall, it is a simple and effective way to compute the relative Hessian trace faster without sacrificing on pruned model performance. We also present a full pipeline using EHAP and quantization aware training (QAT), using INT8 QAT to compress the network further after pruning. In particular, we use symmetric quantization for the weights and asymmetric quantization for the activations. ",
    "url": "https://arxiv.org/abs/2306.07030",
    "authors": [
      "Jack Chong",
      "Manas Gupta",
      "Lihui Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.07032",
    "title": "Mitigating Prior Errors in Causal Structure Learning: Towards LLM driven  Prior Knowledge",
    "abstract": "Causal structure learning, a prominent technique for encoding cause and effect relationships among variables, through Bayesian Networks (BNs). Merely recovering causal structures from real-world observed data lacks precision, while the development of Large Language Models (LLM) is opening a new frontier of causality. LLM presents strong capability in discovering causal relationships between variables with the \"text\" inputs defining the investigated variables, leading to a potential new hierarchy and new ladder of causality. We aim an critical issue in the emerging topic of LLM based causal structure learning, to tackle erroneous prior causal statements from LLM, which is seldom considered in the current context of expert dominating prior resources. As a pioneer attempt, we propose a BN learning strategy resilient to prior errors without need of human intervention. Focusing on the edge-level prior, we classify the possible prior errors into three types: order-consistent, order-reversed, and irrelevant, and provide their theoretical impact on the Structural Hamming Distance (SHD) under the presumption of sufficient data. Intriguingly, we discover and prove that only the order-reversed error contributes to an increase in a unique acyclic closed structure, defined as a \"quasi-circle\". Leveraging this insight, a post-hoc strategy is employed to identify the order-reversed prior error by its impact on the increment of \"quasi-circles\". Through empirical evaluation on both real and synthetic datasets, we demonstrate our strategy's robustness against prior errors. Specifically, we highlight its substantial ability to resist order-reversed errors while maintaining the majority of correct prior knowledge. ",
    "url": "https://arxiv.org/abs/2306.07032",
    "authors": [
      "Lyuzhou Chen",
      "Taiyu Ban",
      "Xiangyu Wang",
      "Derui Lyu",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.07033",
    "title": "When Vision Fails: Text Attacks Against ViT and OCR",
    "abstract": "While text-based machine learning models that operate on visual inputs of rendered text have become robust against a wide range of existing attacks, we show that they are still vulnerable to visual adversarial examples encoded as text. We use the Unicode functionality of combining diacritical marks to manipulate encoded text so that small visual perturbations appear when the text is rendered. We show how a genetic algorithm can be used to generate visual adversarial examples in a black-box setting, and conduct a user study to establish that the model-fooling adversarial examples do not affect human comprehension. We demonstrate the effectiveness of these attacks in the real world by creating adversarial examples against production models published by Facebook, Microsoft, IBM, and Google. ",
    "url": "https://arxiv.org/abs/2306.07033",
    "authors": [
      "Nicholas Boucher",
      "Jenny Blessing",
      "Ilia Shumailov",
      "Ross Anderson",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07048",
    "title": "Consistent, Central and Comprehensive Participation on Social Media",
    "abstract": "Participation research in online community has concentrated on popularity and social interactions. In this paper the attention is shifted to the conversational trees as the focus of analysis in order to achieve a measure of deliberative participation. Three methods to measure consistent, central and comprehensive participation (CCCP) in online conversations are proposed. ",
    "url": "https://arxiv.org/abs/2306.07048",
    "authors": [
      "Julian Dehne",
      "Valentin Gold"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.07050",
    "title": "Revisiting Token Pruning for Object Detection and Instance Segmentation",
    "abstract": "Vision Transformers (ViTs) have shown impressive performance in computer vision, but their high computational cost, quadratic in the number of tokens, limits their adoption in computation-constrained applications. However, this large number of tokens may not be necessary, as not all tokens are equally important. In this paper, we investigate token pruning to accelerate inference for object detection and instance segmentation, extending prior works from image classification. Through extensive experiments, we offer four insights for dense tasks: (i) tokens should not be completely pruned and discarded, but rather preserved in the feature maps for later use. (ii) reactivating previously pruned tokens can further enhance model performance. (iii) a dynamic pruning rate based on images is better than a fixed pruning rate. (iv) a lightweight, 2-layer MLP can effectively prune tokens, achieving accuracy comparable with complex gating networks with a simpler design. We evaluate the impact of these design choices on COCO dataset and present a method integrating these insights that outperforms prior art token pruning models, significantly reducing performance drop from ~1.5 mAP to ~0.3 mAP for both boxes and masks. Compared to the dense counterpart that uses all tokens, our method achieves up to 34% faster inference speed for the whole network and 46% for the backbone. ",
    "url": "https://arxiv.org/abs/2306.07050",
    "authors": [
      "Yifei Liu",
      "Mathias Gehrig",
      "Nico Messikommer",
      "Marco Cannici",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.07060",
    "title": "Prediction Algorithms Achieving Bayesian Decision Theoretical Optimality  Based on Decision Trees as Data Observation Processes",
    "abstract": "In the field of decision trees, most previous studies have difficulty ensuring the statistical optimality of a prediction of new data and suffer from overfitting because trees are usually used only to represent prediction functions to be constructed from given data. In contrast, some studies, including this paper, used the trees to represent stochastic data observation processes behind given data. Moreover, they derived the statistically optimal prediction, which is robust against overfitting, based on the Bayesian decision theory by assuming a prior distribution for the trees. However, these studies still have a problem in computing this Bayes optimal prediction because it involves an infeasible summation for all division patterns of a feature space, which is represented by the trees and some parameters. In particular, an open problem is a summation with respect to combinations of division axes, i.e., the assignment of features to inner nodes of the tree. We solve this by a Markov chain Monte Carlo method, whose step size is adaptively tuned according to a posterior distribution for the trees. ",
    "url": "https://arxiv.org/abs/2306.07060",
    "authors": [
      "Yuta Nakahara",
      "Shota Saito",
      "Naoki Ichijo",
      "Koki Kazama",
      "Toshiyasu Matsushima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.07082",
    "title": "Residual-Based Detection of Attacks in Cyber-Physical Inverter-Based  Microgrids",
    "abstract": "This paper discusses the challenges faced by cyber-physical microgrids (MGs) due to the inclusion of information and communication technologies in their already complex, multi-layered systems. The work identifies a research gap in modeling and analyzing stealthy intermittent integrity attacks in MGs, which are designed to maximize damage and cancel secondary control objectives. To address this, the paper proposes a nonlinear residual-based observer approach to detect and mitigate such attacks. In order to ensure a stable operation of the MG, the formulation then incorporates stability constraints along with the detection observer. The proposed design is validated through case studies on a MG benchmark with four distributed generators, demonstrating its effectiveness in detecting attacks while satisfying network and stability constraints. ",
    "url": "https://arxiv.org/abs/2306.07082",
    "authors": [
      "Andres Intriago",
      "Francesco Liberati",
      "Nikos D. Hatziargyriou",
      "Charalambos Konstantinou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.07084",
    "title": "Performance of Graph Database Management Systems as route planning  solutions for different data and usage characteristics",
    "abstract": "Graph databases have grown in popularity in recent years as they are able to efficiently store and query complex relationships between data. Incidentally, navigation data and road networks can be processed, sampled or modified efficiently when stored as a graph. As a result, graph databases are a solution for solving route planning tasks that comes more and more to the attention of developers of autonomous vehicles. To achieve a computational performance that enables the realization of route planning on large road networks or for a great number of agents concurrently, several aspects need to be considered in the design of the solution. Based on a concrete use case for centralized route planning, we discuss the characteristics and properties of a use case that can significantly influence the computational effort or efficiency of the database management system. Subsequently we evaluate the performance of both Neo4j and ArangoDB depending on these properties. With these results, it is not only possible to choose the most suitable database system but also to improve the resulting performance by addressing relevant aspects in the design of the application. ",
    "url": "https://arxiv.org/abs/2306.07084",
    "authors": [
      "Karin Festl",
      "Patrick Promitzer",
      "Daniel Watzenig",
      "Huilin Yin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.07098",
    "title": "Efficiently Learning the Graph for Semi-supervised Learning",
    "abstract": "Computational efficiency is a major bottleneck in using classic graph-based approaches for semi-supervised learning on datasets with a large number of unlabeled examples. Known techniques to improve efficiency typically involve an approximation of the graph regularization objective, but suffer two major drawbacks - first the graph is assumed to be known or constructed with heuristic hyperparameter values, second they do not provide a principled approximation guarantee for learning over the full unlabeled dataset. Building on recent work on learning graphs for semi-supervised learning from multiple datasets for problems from the same domain, and leveraging techniques for fast approximations for solving linear systems in the graph Laplacian matrix, we propose algorithms that overcome both the above limitations. We show a formal separation in the learning-theoretic complexity of sparse and dense graph families. We further show how to approximately learn the best graphs from the sparse families efficiently using the conjugate gradient method. Our approach can also be used to learn the graph efficiently online with sub-linear regret, under mild smoothness assumptions. Our online learning results are stated generally, and may be useful for approximate and efficient parameter tuning in other problems. We implement our approach and demonstrate significant ($\\sim$10-100x) speedups over prior work on semi-supervised learning with learned graphs on benchmark datasets. ",
    "url": "https://arxiv.org/abs/2306.07098",
    "authors": [
      "Dravyansh Sharma",
      "Maxwell Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.07106",
    "title": "Adversarial Constrained Bidding via Minimax Regret Optimization with  Causality-Aware Reinforcement Learning",
    "abstract": "The proliferation of the Internet has led to the emergence of online advertising, driven by the mechanics of online auctions. In these repeated auctions, software agents participate on behalf of aggregated advertisers to optimize for their long-term utility. To fulfill the diverse demands, bidding strategies are employed to optimize advertising objectives subject to different spending constraints. Existing approaches on constrained bidding typically rely on i.i.d. train and test conditions, which contradicts the adversarial nature of online ad markets where different parties possess potentially conflicting objectives. In this regard, we explore the problem of constrained bidding in adversarial bidding environments, which assumes no knowledge about the adversarial factors. Instead of relying on the i.i.d. assumption, our insight is to align the train distribution of environments with the potential test distribution meanwhile minimizing policy regret. Based on this insight, we propose a practical Minimax Regret Optimization (MiRO) approach that interleaves between a teacher finding adversarial environments for tutoring and a learner meta-learning its policy over the given distribution of environments. In addition, we pioneer to incorporate expert demonstrations for learning bidding strategies. Through a causality-aware policy design, we improve upon MiRO by distilling knowledge from the experts. Extensive experiments on both industrial data and synthetic data show that our method, MiRO with Causality-aware reinforcement Learning (MiROCL), outperforms prior methods by over 30%. ",
    "url": "https://arxiv.org/abs/2306.07106",
    "authors": [
      "Haozhe Wang",
      "Chao Du",
      "Panyan Fang",
      "Li He",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.07114",
    "title": "Coupled Attention Networks for Multivariate Time Series Anomaly  Detection",
    "abstract": "Multivariate time series anomaly detection (MTAD) plays a vital role in a wide variety of real-world application domains. Over the past few years, MTAD has attracted rapidly increasing attention from both academia and industry. Many deep learning and graph learning models have been developed for effective anomaly detection in multivariate time series data, which enable advanced applications such as smart surveillance and risk management with unprecedented capabilities. Nevertheless, MTAD is facing critical challenges deriving from the dependencies among sensors and variables, which often change over time. To address this issue, we propose a coupled attention-based neural network framework (CAN) for anomaly detection in multivariate time series data featuring dynamic variable relationships. We combine adaptive graph learning methods with graph attention to generate a global-local graph that can represent both global correlations and dynamic local correlations among sensors. To capture inter-sensor relationships and temporal dependencies, a convolutional neural network based on the global-local graph is integrated with a temporal self-attention module to construct a coupled attention module. In addition, we develop a multilevel encoder-decoder architecture that accommodates reconstruction and prediction tasks to better characterize multivariate time series data. Extensive experiments on real-world datasets have been conducted to evaluate the performance of the proposed CAN approach, and the results show that CAN significantly outperforms state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2306.07114",
    "authors": [
      "Feng Xia",
      "Xin Chen",
      "Shuo Yu",
      "Mingliang Hou",
      "Mujie Liu",
      "Linlin You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07125",
    "title": "On the Dynamics of Learning Time-Aware Behavior with Recurrent Neural  Networks",
    "abstract": "Recurrent Neural Networks (RNNs) have shown great success in modeling time-dependent patterns, but there is limited research on their learned representations of latent temporal features and the emergence of these representations during training. To address this gap, we use timed automata (TA) to introduce a family of supervised learning tasks modeling behavior dependent on hidden temporal variables whose complexity is directly controllable. Building upon past studies from the perspective of dynamical systems, we train RNNs to emulate temporal flipflops, a new collection of TA that emphasizes the need for time-awareness over long-term memory. We find that these RNNs learn in phases: they quickly perfect any time-independent behavior, but they initially struggle to discover the hidden time-dependent features. In the case of periodic \"time-of-day\" aware automata, we show that the RNNs learn to switch between periodic orbits that encode time modulo the period of the transition rules. We subsequently apply fixed point stability analysis to monitor changes in the RNN dynamics during training, and we observe that the learning phases are separated by a bifurcation from which the periodic behavior emerges. In this way, we demonstrate how dynamical systems theory can provide insights into not only the learned representations of these models, but also the dynamics of the learning process itself. We argue that this style of analysis may provide insights into the training pathologies of recurrent architectures in contexts outside of time-awareness. ",
    "url": "https://arxiv.org/abs/2306.07125",
    "authors": [
      "Peter DelMastro",
      "Rushiv Arora",
      "Edward Rietman",
      "Hava T. Siegelmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.07170",
    "title": "Prompt-based Extraction of Social Determinants of Health Using Few-shot  Learning",
    "abstract": "Social determinants of health (SDOH) documented in the electronic health record through unstructured text are increasingly being studied to understand how SDOH impacts patient health outcomes. In this work, we utilize the Social History Annotation Corpus (SHAC), a multi-institutional corpus of de-identified social history sections annotated for SDOH, including substance use, employment, and living status information. We explore the automatic extraction of SDOH information with SHAC in both standoff and inline annotation formats using GPT-4 in a one-shot prompting setting. We compare GPT-4 extraction performance with a high-performing supervised approach and perform thorough error analyses. Our prompt-based GPT-4 method achieved an overall 0.652 F1 on the SHAC test set, similar to the 7th best-performing system among all teams in the n2c2 challenge with SHAC. ",
    "url": "https://arxiv.org/abs/2306.07170",
    "authors": [
      "Giridhar Kaushik Ramachandran",
      "Yujuan Fu",
      "Bin Han",
      "Kevin Lybarger",
      "Nicholas J Dobbins",
      "\u00d6zlem Uzuner",
      "Meliha Yetisgen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.07178",
    "title": "Frequency-Based Vulnerability Analysis of Deep Learning Models against  Image Corruptions",
    "abstract": "Deep learning models often face challenges when handling real-world image corruptions. In response, researchers have developed image corruption datasets to evaluate the performance of deep neural networks in handling such corruptions. However, these datasets have a significant limitation: they do not account for all corruptions encountered in real-life scenarios. To address this gap, we present MUFIA (Multiplicative Filter Attack), an algorithm designed to identify the specific types of corruptions that can cause models to fail. Our algorithm identifies the combination of image frequency components that render a model susceptible to misclassification while preserving the semantic similarity to the original image. We find that even state-of-the-art models trained to be robust against known common corruptions struggle against the low visibility-based corruptions crafted by MUFIA. This highlights the need for more comprehensive approaches to enhance model robustness against a wider range of real-world image corruptions. ",
    "url": "https://arxiv.org/abs/2306.07178",
    "authors": [
      "Harshitha Machiraju",
      "Michael H. Herzog",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07179",
    "title": "Benchmarking Neural Network Training Algorithms",
    "abstract": "Training algorithms, broadly construed, are an essential part of every deep learning pipeline. Training algorithm improvements that speed up training across a wide variety of workloads (e.g., better update rules, tuning protocols, learning rate schedules, or data selection schemes) could save time, save computational resources, and lead to better, more accurate, models. Unfortunately, as a community, we are currently unable to reliably identify training algorithm improvements, or even determine the state-of-the-art training algorithm. In this work, using concrete experiments, we argue that real progress in speeding up training requires new benchmarks that resolve three basic challenges faced by empirical comparisons of training algorithms: (1) how to decide when training is complete and precisely measure training time, (2) how to handle the sensitivity of measurements to exact workload details, and (3) how to fairly compare algorithms that require hyperparameter tuning. In order to address these challenges, we introduce a new, competitive, time-to-result benchmark using multiple workloads running on fixed hardware, the AlgoPerf: Training Algorithms benchmark. Our benchmark includes a set of workload variants that make it possible to detect benchmark submissions that are more robust to workload changes than current widely-used methods. Finally, we evaluate baseline submissions constructed using various optimizers that represent current practice, as well as other optimizers that have recently received attention in the literature. These baseline results collectively demonstrate the feasibility of our benchmark, show that non-trivial gaps between methods exist, and set a provisional state-of-the-art for future benchmark submissions to try and surpass. ",
    "url": "https://arxiv.org/abs/2306.07179",
    "authors": [
      "George E. Dahl",
      "Frank Schneider",
      "Zachary Nado",
      "Naman Agarwal",
      "Chandramouli Shama Sastry",
      "Philipp Hennig",
      "Sourabh Medapati",
      "Runa Eschenhagen",
      "Priya Kasimbeg",
      "Daniel Suo",
      "Juhan Bae",
      "Justin Gilmer",
      "Abel L. Peirson",
      "Bilal Khan",
      "Rohan Anil",
      "Mike Rabbat",
      "Shankar Krishnan",
      "Daniel Snider",
      "Ehsan Amid",
      "Kongtao Chen",
      "Chris J. Maddison",
      "Rakshith Vasudev",
      "Michal Badura",
      "Ankush Garg",
      "Peter Mattson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.07186",
    "title": "CD-CTFM: A Lightweight CNN-Transformer Network for Remote Sensing Cloud  Detection Fusing Multiscale Features",
    "abstract": "Clouds in remote sensing images inevitably affect information extraction, which hinder the following analysis of satellite images. Hence, cloud detection is a necessary preprocessing procedure. However, the existing methods have numerous calculations and parameters. In this letter, a lightweight CNN-Transformer network, CD-CTFM, is proposed to solve the problem. CD-CTFM is based on encoder-decoder architecture and incorporates the attention mechanism. In the decoder part, we utilize a lightweight network combing CNN and Transformer as backbone, which is conducive to extract local and global features simultaneously. Moreover, a lightweight feature pyramid module is designed to fuse multiscale features with contextual information. In the decoder part, we integrate a lightweight channel-spatial attention module into each skip connection between encoder and decoder, extracting low-level features while suppressing irrelevant information without introducing many parameters. Finally, the proposed model is evaluated on two cloud datasets, 38-Cloud and MODIS. The results demonstrate that CD-CTFM achieves comparable accuracy as the state-of-art methods. At the same time, CD-CTFM outperforms state-of-art methods in terms of efficiency. ",
    "url": "https://arxiv.org/abs/2306.07186",
    "authors": [
      "Wenxuan Ge",
      "Xubing Yang",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.07191",
    "title": "Neural Intersection Function",
    "abstract": "The ray casting operation in the Monte Carlo ray tracing algorithm usually adopts a bounding volume hierarchy (BVH) to accelerate the process of finding intersections to evaluate visibility. However, its characteristics are irregular, with divergence in memory access and branch execution, so it cannot achieve maximum efficiency on GPUs. This paper proposes a novel Neural Intersection Function based on a multilayer perceptron whose core operation contains only dense matrix multiplication with predictable memory access. Our method is the first solution integrating the neural network-based approach and BVH-based ray tracing pipeline into one unified rendering framework. We can evaluate the visibility and occlusion of secondary rays without traversing the most irregular and time-consuming part of the BVH and thus accelerate ray casting. The experiments show the proposed method can reduce the secondary ray casting time for direct illumination by up to 35% compared to a BVH-based implementation and still preserve the image quality. ",
    "url": "https://arxiv.org/abs/2306.07191",
    "authors": [
      "Shin Fujieda",
      "Chih-Chen Kao",
      "Takahiro Harada"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2306.07197",
    "title": "AROID: Improving Adversarial Robustness through Online Instance-wise  Data Augmentation",
    "abstract": "Deep neural networks are vulnerable to adversarial examples. Adversarial training (AT) is an effective defense against adversarial examples. However, AT is prone to overfitting which degrades robustness substantially. Recently, data augmentation (DA) was shown to be effective in mitigating robust overfitting if appropriately designed and optimized for AT. This work proposes a new method to automatically learn online, instance-wise, DA policies to improve robust generalization for AT. A novel policy learning objective, consisting of Vulnerability, Affinity and Diversity, is proposed and shown to be sufficiently effective and efficient to be practical for automatic DA generation during AT. This allows our method to efficiently explore a large search space for a more effective DA policy and evolve the policy as training progresses. Empirically, our method is shown to outperform or match all competitive DA methods across various model architectures (CNNs and ViTs) and datasets (CIFAR10, SVHN and Imagenette). Our DA policy reinforced vanilla AT to surpass several state-of-the-art AT methods (with baseline DA) in terms of both accuracy and robustness. It can also be combined with those advanced AT methods to produce a further boost in robustness. ",
    "url": "https://arxiv.org/abs/2306.07197",
    "authors": [
      "Lin Li",
      "Jianing Qiu",
      "Michael Spratling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07201",
    "title": "LTCR: Long-Text Chinese Rumor Detection Dataset",
    "abstract": "The Long-Text Chinese Rumor detection dataset we developed is focusing on the identification of misleading information in the context of rumor verification. Especially in the current era of the COVID-19 pandemic, false information spread rapidly on social media platforms and can negatively impact people's health behaviors and responses to health emergencies. By providing a resource for accurate misinformation detection, the LTCR dataset offers a resource for improving the identification of fake news, particularly longer and more complex texts. The dataset consists of 1,729 and 500 pieces of real and fake news, respectively. The average lengths of real and fake news are approximately 230 and 152 characters. We also propose \\method, Salience-aware Fake News Detection Model, which achieves the highest accuracy (95.85%), fake news recall (90.91%) and F-score (90.60%) on the dataset.(https://github.com/Enderfga/DoubleCheck) ",
    "url": "https://arxiv.org/abs/2306.07201",
    "authors": [
      "Ziyang Ma",
      "Mengsha Liu",
      "Guian Fang",
      "Ying Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.07212",
    "title": "Polyhedral Complex Extraction from ReLU Networks using Edge Subdivision",
    "abstract": "A neural network consisting of piecewise affine building blocks, such as fully-connected layers and ReLU activations, is itself a piecewise affine function supported on a polyhedral complex. This complex has been previously studied to characterize theoretical properties of neural networks, but, in practice, extracting it remains a challenge due to its high combinatorial complexity. A natural idea described in previous works is to subdivide the regions via intersections with hyperplanes induced by each neuron. However, we argue that this view leads to computational redundancy. Instead of regions, we propose to subdivide edges, leading to a novel method for polyhedral complex extraction. A key to this are sign-vectors, which encode the combinatorial structure of the complex. Our approach allows to use standard tensor operations on a GPU, taking seconds for millions of cells on a consumer grade machine. Motivated by the growing interest in neural shape representation, we use the speed and differentiability of our method to optimize geometric properties of the complex. The code is available at https://github.com/arturs-berzins/relu_edge_subdivision . ",
    "url": "https://arxiv.org/abs/2306.07212",
    "authors": [
      "Arturs Berzins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07220",
    "title": "Strokes2Surface: Recovering Curve Networks From 4D Architectural Design  Sketches",
    "abstract": "We present Strokes2Surface, an offline geometry-reconstruction pipeline built upon a 4D Sketching Interface, MR.Sketch, targeted at architectural design. The pipeline recovers a curve network from designer-drawn strokes, thus bridging between concept design and digital modeling stages in architectural design. The input to our pipeline consists of 3D strokes' polyline vertices and their corresponding timestamps (as of the fourth dimension), along with additional geometric and stylus-related recorded properties. Inspired by sketch consolidation and sketch-based modeling methods, our pipeline leverages such data and combines three Machine Learning (ML) models; a classifier and two clustering models. In particular, based on observations of practices designers typically employ in architectural design sketches, we solve a binary classification problem to recognize whether a stroke depicts a boundary and edge or is used to fill in the enclosing areas and faces of the intended architectural object. Followed by the two clustering models, strokes of each type are further parsed into groups, each representing either a single edge or a single face. Next, groups representing edges are approximated with B-spline curves, followed by a topology-recovering process identifying and fixing desired connectivities between the curves forming a well-connected curve network. Next, groups representing the faces are employed to detect the cycles bounding patches in the curve network, resulting in the final surface mesh geometry of the architectural object. We confirm the usability of Strokes2Surface via a user study and further validate and compare our results against a range of reconstructions computed using alternative methods. We also introduce our manually labeled dataset of 4D architectural design sketches for further use in the community. ",
    "url": "https://arxiv.org/abs/2306.07220",
    "authors": [
      "S. Rasoulzadeh",
      "M. Wimmer",
      "I. Kovacic"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07249",
    "title": "Generic Attacks against Cryptographic Hardware through Long-Range Deep  Learning",
    "abstract": "Hardware-based cryptographic implementations utilize countermeasures to resist side-channel attacks. In this paper, we propose a novel deep-learning architecture for side-channel analysis called SCANET that generalizes across multiple implementations and algorithms without manual tuning or trace pre-processing. We achieve this by combining a novel input processing technique with several advanced deep learning techniques including transformer blocks and multi-task learning. We demonstrate the generality of our approach by successfully attacking four hardware-accelerated countermeasures for elliptic curve digital signatures in an end-to-end manner without human tuning. Additionally, we showcase SCANET's ability to generalize across multiple algorithms by successfully replicating state-of-the-art attacks against protected AES without the need for trace preprocessing, hand-tuning, or model architectural changes. These results offer promising prospects for generic and automated side-channel leakage evaluation without manual effort. ",
    "url": "https://arxiv.org/abs/2306.07249",
    "authors": [
      "Elie Bursztein",
      "Luca Invernizzi",
      "Karel Kr\u00e1l",
      "Daniel Moghimi",
      "Jean-Michel Picod",
      "Marina Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.07263",
    "title": "Backpressure control with predicted imminent saturation flow rate for  urban networks",
    "abstract": "The network's admissible demand region (ADR), which is a key index to characterize a network's ability to handle incoming demands, is shaped by each movement's saturation flow rate (SFR). Existing backpressure (BP) traffic control policies commonly assumed a fixed and/or completely known SFR when calculating the pressure for decision-making. On one hand, since real-time traffic conditions can significantly influence the traffic supply, the fixed mean SFR (M-SFR) assumption could result in a mismatch between dynamic demand and supply. On the other hand, accurately predicting the imminent SFR (I-SFR) is challenging because of the complicated interactions between traffic participants. Hence, the completely known SFR assumption is impractical in real-world settings. Our paper demonstrates that, compared with only using the constant M-SFR information, using more knowledge of I-SFR can enlarge the upper bound of ADR. In addition, we theoretically prove that the BP with predicted I-SFR can guarantee network stability as long as the demand is interior to the ADR. The proposed theory is validated by a calibrated simulation model in the experiments. Three I-SFR prediction methods with different accuracies are adopted: the M-SFR method, the heuristic estimation method, and the deep neural network method. They are tested in three BP-based control policies to investigate whether our findings are robust. The simulation results show that: a higher prediction accuracy of I-SFR can effectively help all three BP-based policies enlarge the network ADR, and more accurate I-SFR can productively reduce the average vehicle delay. ",
    "url": "https://arxiv.org/abs/2306.07263",
    "authors": [
      "Dianchao Lin",
      "Li Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.07265",
    "title": "detrex: Benchmarking Detection Transformers",
    "abstract": "The DEtection TRansformer (DETR) algorithm has received considerable attention in the research community and is gradually emerging as a mainstream approach for object detection and other perception tasks. However, the current field lacks a unified and comprehensive benchmark specifically tailored for DETR-based models. To address this issue, we develop a unified, highly modular, and lightweight codebase called detrex, which supports a majority of the mainstream DETR-based instance recognition algorithms, covering various fundamental tasks, including object detection, segmentation, and pose estimation. We conduct extensive experiments under detrex and perform a comprehensive benchmark for DETR-based models. Moreover, we enhance the performance of detection transformers through the refinement of training hyper-parameters, providing strong baselines for supported algorithms.We hope that detrex could offer research communities a standardized and unified platform to evaluate and compare different DETR-based models while fostering a deeper understanding and driving advancements in DETR-based instance recognition. Our code is available at https://github.com/IDEA-Research/detrex. The project is currently being actively developed. We encourage the community to use detrex codebase for further development and contributions. ",
    "url": "https://arxiv.org/abs/2306.07265",
    "authors": [
      "Tianhe Ren",
      "Shilong Liu",
      "Feng Li",
      "Hao Zhang",
      "Ailing Zeng",
      "Jie Yang",
      "Xingyu Liao",
      "Ding Jia",
      "Hongyang Li",
      "He Cao",
      "Jianan Wang",
      "Zhaoyang Zeng",
      "Xianbiao Qi",
      "Yuhui Yuan",
      "Jianwei Yang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.07266",
    "title": "Operator Learning with Neural Fields: Tackling PDEs on General  Geometries",
    "abstract": "Machine learning approaches for solving partial differential equations require learning mappings between function spaces. While convolutional or graph neural networks are constrained to discretized functions, neural operators present a promising milestone toward mapping functions directly. Despite impressive results they still face challenges with respect to the domain geometry and typically rely on some form of discretization. In order to alleviate such limitations, we present CORAL, a new method that leverages coordinate-based networks for solving PDEs on general geometries. CORAL is designed to remove constraints on the input mesh, making it applicable to any spatial sampling and geometry. Its ability extends to diverse problem domains, including PDE solving, spatio-temporal forecasting, and inverse problems like geometric design. CORAL demonstrates robust performance across multiple resolutions and performs well in both convex and non-convex domains, surpassing or performing on par with state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2306.07266",
    "authors": [
      "Louis Serrano",
      "Lise Le Boudec",
      "Armand Kassa\u00ef Koupa\u00ef",
      "Thomas X Wang",
      "Yuan Yin",
      "Jean-No\u00ebl Vittaut",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.07273",
    "title": "Gaussian Membership Inference Privacy",
    "abstract": "We propose a new privacy notion called $f$-Membership Inference Privacy ($f$-MIP), which explicitly considers the capabilities of realistic adversaries under the membership inference attack threat model. By doing so $f$-MIP offers interpretable privacy guarantees and improved utility (e.g., better classification accuracy). Our novel theoretical analysis of likelihood ratio-based membership inference attacks on noisy stochastic gradient descent (SGD) results in a parametric family of $f$-MIP guarantees that we refer to as $\\mu$-Gaussian Membership Inference Privacy ($\\mu$-GMIP). Our analysis additionally yields an analytical membership inference attack that offers distinct advantages over previous approaches. First, unlike existing methods, our attack does not require training hundreds of shadow models to approximate the likelihood ratio. Second, our analytical attack enables straightforward auditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes the importance of various factors, such as hyperparameters (e.g., batch size, number of model parameters) and data specific characteristics in controlling an attacker's success in reliably inferring a given point's membership to the training set. We demonstrate the effectiveness of our method on models trained across vision and tabular datasets. ",
    "url": "https://arxiv.org/abs/2306.07273",
    "authors": [
      "Tobias Leemann",
      "Martin Pawelczyk",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.07274",
    "title": "Reconstructing Heterogeneous Cryo-EM Molecular Structures by Decomposing  Them into Polymer Chains",
    "abstract": "Cryogenic electron microscopy (cryo-EM) has transformed structural biology by allowing to reconstruct 3D biomolecular structures up to near-atomic resolution. However, the 3D reconstruction process remains challenging, as the 3D structures may exhibit substantial shape variations, while the 2D image acquisition suffers from a low signal-to-noise ratio, requiring to acquire very large datasets that are time-consuming to process. Current reconstruction methods are precise but computationally expensive, or faster but lack a physically-plausible model of large molecular shape variations. To fill this gap, we propose CryoChains that encodes large deformations of biomolecules via rigid body transformation of their polymer instances (chains), while representing their finer shape variations with the normal mode analysis framework of biophysics. Our synthetic data experiments on the human $\\text{GABA}_{\\text{B}}$ and heat shock protein show that CryoChains gives a biophysically-grounded quantification of the heterogeneous conformations of biomolecules, while reconstructing their 3D molecular structures at an improved resolution compared to the current fastest, interpretable deep learning method. ",
    "url": "https://arxiv.org/abs/2306.07274",
    "authors": [
      "Bongjin Koo",
      "Julien Martel",
      "Ariana Peck",
      "Axel Levy",
      "Fr\u00e9d\u00e9ric Poitevin",
      "Nina Miolane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2306.07284",
    "title": "No Free Lunch: The Hazards of Over-Expressive Representations in Anomaly  Detection",
    "abstract": "Anomaly detection methods, powered by deep learning, have recently been making significant progress, mostly due to improved representations. It is tempting to hypothesize that anomaly detection can improve indefinitely by increasing the scale of our networks, making their representations more expressive. In this paper, we provide theoretical and empirical evidence to the contrary. In fact, we empirically show cases where very expressive representations fail to detect even simple anomalies when evaluated beyond the well-studied object-centric datasets. To investigate this phenomenon, we begin by introducing a novel theoretical toy model for anomaly detection performance. The model uncovers a fundamental trade-off between representation sufficiency and over-expressivity. It provides evidence for a no-free-lunch theorem in anomaly detection stating that increasing representation expressivity will eventually result in performance degradation. Instead, guidance must be provided to focus the representation on the attributes relevant to the anomalies of interest. We conduct an extensive empirical investigation demonstrating that state-of-the-art representations often suffer from over-expressivity, failing to detect many types of anomalies. Our investigation demonstrates how this over-expressivity impairs image anomaly detection in practical settings. We conclude with future directions for mitigating this issue. ",
    "url": "https://arxiv.org/abs/2306.07284",
    "authors": [
      "Tal Reiss",
      "Niv Cohen",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.01406",
    "title": "An efficient plasma-surface interaction surrogate model for sputtering  processes based on autoencoder neural networks",
    "abstract": "Simulations of thin film sputter deposition require the separation of the plasma and material transport in the gas-phase from the growth/sputtering processes at the bounding surfaces. Interface models based on analytic expressions or look-up tables inherently restrict this complex interaction to a bare minimum. A machine learning model has recently been shown to overcome this remedy for Ar ions bombarding a Ti-Al composite target. However, the chosen network structure (i.e., a multilayer perceptron) provides approximately 4 million degrees of freedom, which bears the risk of overfitting the relevant dynamics and complicating the model to an unreliable extend. This work proposes a conceptually more sophisticated but parameterwise simplified regression artificial neural network for an extended scenario, considering a variable instead of a single fixed Ti-Al stoichiometry. A convolutional $\\beta$-variational autoencoder is trained to reduce the high-dimensional energy-angular distribution of sputtered particles to a latent space representation of only two components. In addition to a primary decoder which is trained to reconstruct the input energy-angular distribution, a secondary decoder is employed to reconstruct the mean energy of incident Ar ions as well as the present Ti-Al composition. The mutual latent space is hence conditioned on these quantities. The trained primary decoder of the variational autoencoder network is subsequently transferred to a regression network, for which only the mapping to the particular latent space has to be learned. While obtaining a competitive performance, the number of degrees of freedom is drastically reduced to 15,111 and 486 parameters for the primary decoder and the remaining regression network, respectively. The underlying methodology is general and can easily be extended to more complex physical descriptions with a minimal amount of data required. ",
    "url": "https://arxiv.org/abs/2109.01406",
    "authors": [
      "Tobias Gergs",
      "Borislav Borislavov",
      "Jan Trieschmann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2211.04796",
    "title": "Physics-separating artificial neural networks for predicting initial  stages of Al sputtering and thin film deposition in Ar plasma discharges",
    "abstract": "Simulations of Al thin film sputter depositions rely on accurate plasma and surface interaction models. Establishing the latter commonly requires a higher level of abstraction and means to dismiss the fundamental atomic fidelity. Previous works on sputtering processes addressed this issue by establishing machine learning surrogate models, which include a basic surface state (i.e., stoichiometry) as static input. In this work, an evolving surface state and defect structure are introduced to jointly describe sputtering and growth with physics-separating artificial neural networks. The data describing the plasma-surface interactions stem from hybrid reactive molecular dynamics/time-stamped force bias Monte Carlo simulations of Al neutrals and Ar$^+$ ions impinging onto Al(001) surfaces. It is demonstrated that the fundamental processes are comprehensively described by taking the surface state as well as defect structure into account. Hence, a machine learning plasma-surface interaction surrogate model is established that resolves the inherent kinetics with high physical fidelity. The resulting model is not restricted to input from modeling and simulation, but may similarly be applied to experimental input data. ",
    "url": "https://arxiv.org/abs/2211.04796",
    "authors": [
      "Tobias Gergs",
      "Thomas Mussenbrock",
      "Jan Trieschmann"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2301.03524",
    "title": "Physics-separating artificial neural networks for predicting sputtering  and thin film deposition of AlN in Ar/N$_2$ discharges on experimental  timescales",
    "abstract": "Understanding and modeling plasma-surface interactions frame a multi-scale as well as multi-physics problem. Scale-bridging machine learning surface surrogate models have been demonstrated to perceive the fundamental atomic fidelity for the physical vapor deposition of pure metals. However, the immense computational cost of the data-generating simulations render a practical application with predictions on relevant timescales impracticable. This issue is resolved in this work for the sputter deposition of AlN in Ar/N$_2$ discharges by developing a scheme that populates the parameter spaces effectively. Hybrid reactive molecular dynamics / time-stamped force-bias Monte Carlo simulations of randomized plasma-surface interactions / diffusion processes are used to setup a physics-separating artificial neural network. The application of this generic machine learning model to a specific experimental reference case study enables the systematic analysis of the particle flux emission as well as underlying system state (e.g., composition, mass density, stress, point defect structure) evolution within process times of up to 45 minutes. ",
    "url": "https://arxiv.org/abs/2301.03524",
    "authors": [
      "Tobias Gergs",
      "Thomas Mussenbrock",
      "Jan Trieschmann"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2306.06119",
    "title": "Doubly Stochastic Graph-based Non-autoregressive Reaction Prediction",
    "abstract": "Organic reaction prediction is a critical task in drug discovery. Recently, researchers have achieved non-autoregressive reaction prediction by modeling the redistribution of electrons, resulting in state-of-the-art top-1 accuracy, and enabling parallel sampling. However, the current non-autoregressive decoder does not satisfy two essential rules of electron redistribution modeling simultaneously: the electron-counting rule and the symmetry rule. This violation of the physical constraints of chemical reactions impairs model performance. In this work, we propose a new framework called that combines two doubly stochastic self-attention mappings to obtain electron redistribution predictions that follow both constraints. We further extend our solution to a general multi-head attention mechanism with augmented constraints. To achieve this, we apply Sinkhorn's algorithm to iteratively update self-attention mappings, which imposes doubly conservative constraints as additional informative priors on electron redistribution modeling. We theoretically demonstrate that our can simultaneously satisfy both rules, which the current decoder mechanism cannot do. Empirical results show that our approach consistently improves the predictive performance of non-autoregressive models and does not bring an unbearable additional computational cost. ",
    "url": "https://arxiv.org/abs/2306.06119",
    "authors": [
      "Ziqiao Meng",
      "Peilin Zhao",
      "Yang Yu",
      "Irwin King"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06124",
    "title": "Unsupervised clustering of disturbances in power systems via deep  convolutional autoencoders",
    "abstract": "Power quality (PQ) events are recorded by PQ meters whenever anomalous events are detected on the power grid. Using neural networks with machine learning can aid in accurately classifying the recorded waveforms and help power system engineers diagnose and rectify the root causes of problems. However, many of the waveforms captured during a disturbance in the power system need to be labeled for supervised learning, leaving a large number of data recordings for engineers to process manually or go unseen. This paper presents an autoencoder and K-means clustering-based unsupervised technique that can be used to cluster PQ events into categories like sag, interruption, transients, normal, and harmonic distortion to enable filtering of anomalous waveforms from recurring or normal waveforms. The method is demonstrated using three-phase, field-obtained voltage waveforms recorded in a distribution grid. First, a convolutional autoencoder compresses the input signals into a set of lower feature dimensions which, after further processing, is passed to the K-means algorithm to identify data clusters. Using a small, labeled dataset, numerical labels are then assigned to events based on a cosine similarity analysis. Finally, the study analyzes the clusters using the t-distributed stochastic neighbor embedding (t-SNE) visualization tool, demonstrating that the technique can help investigate a large number of captured events in a quick manner. ",
    "url": "https://arxiv.org/abs/2306.06124",
    "authors": [
      "Md Maidul Islam",
      "Md Omar Faruque",
      "Joshua Butterfield",
      "Gaurav Singh",
      "Thomas A. Cooke"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.06195",
    "title": "Risk stratification of malignant melanoma using neural networks",
    "abstract": "In order to improve the detection and classification of malignant melanoma, this paper describes an image-based method that can achieve AUROC values of up to 0.78 without additional clinical information. Furthermore, the importance of the domain gap between two different image sources is considered, as it is important to create usability independent of hardware components such as the high-resolution scanner used. Since for the application of machine learning methods, alterations of scanner-specific properties such as brightness, contrast or sharpness can have strong (negative) effects on the quality of the prediction methods, two ways to overcome this domain gap are discussed in this paper. ",
    "url": "https://arxiv.org/abs/2306.06195",
    "authors": [
      "Julian Burghoff",
      "Leonhard Ackermann",
      "Younes Salahdine",
      "Veronika Bram",
      "Katharina Wunderlich",
      "Julius Balkenhol",
      "Thomas Dirschka",
      "Hanno Gottschalk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06281",
    "title": "Energy-Dissipative Evolutionary Deep Operator Neural Networks",
    "abstract": "Energy-Dissipative Evolutionary Deep Operator Neural Network is an operator learning neural network. It is designed to seed numerical solutions for a class of partial differential equations instead of a single partial differential equation, such as partial differential equations with different parameters or different initial conditions. The network consists of two sub-networks, the Branch net and the Trunk net. For an objective operator G, the Branch net encodes different input functions u at the same number of sensors, and the Trunk net evaluates the output function at any location. By minimizing the error between the evaluated output q and the expected output G(u)(y), DeepONet generates a good approximation of the operator G. In order to preserve essential physical properties of PDEs, such as the Energy Dissipation Law, we adopt a scalar auxiliary variable approach to generate the minimization problem. It introduces a modified energy and enables unconditional energy dissipation law at the discrete level. By taking the parameter as a function of time t, this network can predict the accurate solution at any further time with feeding data only at the initial state. The data needed can be generated by the initial conditions, which are readily available. In order to validate the accuracy and efficiency of our neural networks, we provide numerical simulations of several partial differential equations, including heat equations, parametric heat equations and Allen-Cahn equations. ",
    "url": "https://arxiv.org/abs/2306.06281",
    "authors": [
      "Jiahao Zhang",
      "Shiheng Zhang",
      "Jie Shen",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06291",
    "title": "Optimal Heterogeneous Collaborative Linear Regression and Contextual  Bandits",
    "abstract": "Large and complex datasets are often collected from several, possibly heterogeneous sources. Collaborative learning methods improve efficiency by leveraging commonalities across datasets while accounting for possible differences among them. Here we study collaborative linear regression and contextual bandits, where each instance's associated parameters are equal to a global parameter plus a sparse instance-specific term. We propose a novel two-stage estimator called MOLAR that leverages this structure by first constructing an entry-wise median of the instances' linear regression estimates, and then shrinking the instance-specific estimates towards the median. MOLAR improves the dependence of the estimation error on the data dimension, compared to independent least squares estimates. We then apply MOLAR to develop methods for sparsely heterogeneous collaborative contextual bandits, which lead to improved regret guarantees compared to independent bandit methods. We further show that our methods are minimax optimal by providing a number of lower bounds. Finally, we support the efficiency of our methods by performing experiments on both synthetic data and the PISA dataset on student educational outcomes from heterogeneous countries. ",
    "url": "https://arxiv.org/abs/2306.06291",
    "authors": [
      "Xinmeng Huang",
      "Kan Xu",
      "Donghwan Lee",
      "Hamed Hassani",
      "Hamsa Bastani",
      "Edgar Dobriban"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.06296",
    "title": "Response Time Improves Choice Prediction and Function Estimation for  Gaussian Process Models of Perception and Preferences",
    "abstract": "Models for human choice prediction in preference learning and psychophysics often consider only binary response data, requiring many samples to accurately learn preferences or perceptual detection thresholds. The response time (RT) to make each choice captures additional information about the decision process, however existing models incorporating RTs for choice prediction do so in fully parametric settings or over discrete stimulus sets. This is in part because the de-facto standard model for choice RTs, the diffusion decision model (DDM), does not admit tractable, differentiable inference. The DDM thus cannot be easily integrated with flexible models for continuous, multivariate function approximation, particularly Gaussian process (GP) models. We propose a novel differentiable approximation to the DDM likelihood using a family of known, skewed three-parameter distributions. We then use this new likelihood to incorporate RTs into GP models for binary choices. Our RT-choice GPs enable both better latent value estimation and held-out choice prediction relative to baselines, which we demonstrate on three real-world multivariate datasets covering both human psychophysics and preference learning applications. ",
    "url": "https://arxiv.org/abs/2306.06296",
    "authors": [
      "Michael Shvartsman",
      "Benjamin Letham",
      "Stephen Keeley"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06340",
    "title": "ECGBERT: Understanding Hidden Language of ECGs with Self-Supervised  Representation Learning",
    "abstract": "In the medical field, current ECG signal analysis approaches rely on supervised deep neural networks trained for specific tasks that require substantial amounts of labeled data. However, our paper introduces ECGBERT, a self-supervised representation learning approach that unlocks the underlying language of ECGs. By unsupervised pre-training of the model, we mitigate challenges posed by the lack of well-labeled and curated medical data. ECGBERT, inspired by advances in the area of natural language processing and large language models, can be fine-tuned with minimal additional layers for various ECG-based problems. Through four tasks, including Atrial Fibrillation arrhythmia detection, heartbeat classification, sleep apnea detection, and user authentication, we demonstrate ECGBERT's potential to achieve state-of-the-art results on a wide variety of tasks. ",
    "url": "https://arxiv.org/abs/2306.06340",
    "authors": [
      "Seokmin Choi",
      "Sajad Mousavi",
      "Phillip Si",
      "Haben G. Yhdego",
      "Fatemeh Khadem",
      "Fatemeh Afghah"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.06373",
    "title": "Quantum feedback control of a two-atom network closed by a semi-infinite  waveguide",
    "abstract": "The purpose of this paper is to study the dynamics of a coherent feedback network where two two-level atoms are coupled with a semi-infinite waveguide. In this set-up, the two-level atoms can work as the photon source, and the photons can be emitted into the waveguide via the nonchiral or chiral couplings between the atom and the waveguide, according to whether the coupling strengths between the atoms and different directional propagating modes in the waveguide are identical or not. For the photon emitted by one of the two atoms, it can be reflected by the terminal mirror, or interact with the other atom, and then the photon can re-interact with the former atom. When the two atoms are both initially excited, finally there can be two-photon, one-photon or zero-photon states in the waveguide via the spontaneous emission and feedback interactions, and this is influenced by the locations of the atoms and the chirality of the coupling between the atom and the waveguide. Similarly, if only one of the two atoms is initially excited, there can be zero or one photon in the waveguide. Thus we can control the number of the photons in the waveguide and the atomic states by tuning the feedback loop length and the chiral couplings between the atom and waveguide. The photonic state in the waveguide is analyzed in the frequency domain and the spatial domain, and the transient process of photon emissions can be better understood based on the comprehensive analysis in these two domains. ",
    "url": "https://arxiv.org/abs/2306.06373",
    "authors": [
      "Haijin Ding",
      "Guofeng Zhang",
      "Mu-Tian Cheng",
      "Guoqing Cai"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)",
      "Atomic Physics (physics.atom-ph)"
    ]
  },
  {
    "id": "arXiv:2306.06408",
    "title": "Fast light-field 3D microscopy with out-of-distribution detection and  adaptation through Conditional Normalizing Flows",
    "abstract": "Real-time 3D fluorescence microscopy is crucial for the spatiotemporal analysis of live organisms, such as neural activity monitoring. The eXtended field-of-view light field microscope (XLFM), also known as Fourier light field microscope, is a straightforward, single snapshot solution to achieve this. The XLFM acquires spatial-angular information in a single camera exposure. In a subsequent step, a 3D volume can be algorithmically reconstructed, making it exceptionally well-suited for real-time 3D acquisition and potential analysis. Unfortunately, traditional reconstruction methods (like deconvolution) require lengthy processing times (0.0220 Hz), hampering the speed advantages of the XLFM. Neural network architectures can overcome the speed constraints at the expense of lacking certainty metrics, which renders them untrustworthy for the biomedical realm. This work proposes a novel architecture to perform fast 3D reconstructions of live immobilized zebrafish neural activity based on a conditional normalizing flow. It reconstructs volumes at 8 Hz spanning 512x512x96 voxels, and it can be trained in under two hours due to the small dataset requirements (10 image-volume pairs). Furthermore, normalizing flows allow for exact Likelihood computation, enabling distribution monitoring, followed by out-of-distribution detection and retraining of the system when a novel sample is detected. We evaluate the proposed method on a cross-validation approach involving multiple in-distribution samples (genetically identical zebrafish) and various out-of-distribution ones. ",
    "url": "https://arxiv.org/abs/2306.06408",
    "authors": [
      "Josu\u00e9 Page Vizca\u00edno",
      "Panagiotis Symvoulidis",
      "Zeguan Wang",
      "Jonas Jelten",
      "Paolo Favaro",
      "Edward S. Boyden",
      "Tobias Lasser"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.06409",
    "title": "Functional Causal Bayesian Optimization",
    "abstract": "We propose functional causal Bayesian optimization (fCBO), a method for finding interventions that optimize a target variable in a known causal graph. fCBO extends the CBO family of methods to enable functional interventions, which set a variable to be a deterministic function of other variables in the graph. fCBO models the unknown objectives with Gaussian processes whose inputs are defined in a reproducing kernel Hilbert space, thus allowing to compute distances among vector-valued functions. In turn, this enables to sequentially select functions to explore by maximizing an expected improvement acquisition functional while keeping the typical computational tractability of standard BO settings. We introduce graphical criteria that establish when considering functional interventions allows attaining better target effects, and conditions under which selected interventions are also optimal for conditional target effects. We demonstrate the benefits of the method in a synthetic and in a real-world causal graph. ",
    "url": "https://arxiv.org/abs/2306.06409",
    "authors": [
      "Limor Gultchin",
      "Virginia Aglietti",
      "Alexis Bellot",
      "Silvia Chiappa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06461",
    "title": "Semi-supervsied Learning-based Sound Event Detection using Freuqency  Dynamic Convolution with Large Kernel Attention for DCASE Challenge 2023 Task  4",
    "abstract": "This report proposes a frequency dynamic convolution (FDY) with a large kernel attention (LKA)-convolutional recurrent neural network (CRNN) with a pre-trained bidirectional encoder representation from audio transformers (BEATs) embedding-based sound event detection (SED) model that employs a mean-teacher and pseudo-label approach to address the challenge of limited labeled data for DCASE 2023 Task 4. The proposed FDY with LKA integrates the FDY and LKA module to effectively capture time-frequency patterns, long-term dependencies, and high-level semantic information in audio signals. The proposed FDY with LKA-CRNN with a BEATs embedding network is initially trained on the entire DCASE 2023 Task 4 dataset using the mean-teacher approach, generating pseudo-labels for weakly labeled, unlabeled, and the AudioSet. Subsequently, the proposed SED model is retrained using the same pseudo-label approach. A subset of these models is selected for submission, demonstrating superior F1-scores and polyphonic SED score performance on the DCASE 2023 Challenge Task 4 validation dataset. ",
    "url": "https://arxiv.org/abs/2306.06461",
    "authors": [
      "Ji Won Kim",
      "Sang Won Son",
      "Yoonah Song",
      "Hong Kook Kim",
      "Il Hoon Song",
      "Jeong Eun Lim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2306.06474",
    "title": "Augmentations of Forman's Ricci Curvature and their Applications in  Community Detection",
    "abstract": "The notion of curvature on graphs has recently gained traction in the networks community, with the Ollivier-Ricci curvature (ORC) in particular being used for several tasks in network analysis, such as community detection. In this work, we choose a different approach and study augmentations of the discretization of the Ricci curvature proposed by Forman (AFRC). We empirically and theoretically investigate its relation to the ORC and the un-augmented Forman-Ricci curvature. In particular, we provide evidence that the AFRC frequently gives sufficient insight into the structure of a network to be used for community detection, and therefore provides a computationally cheaper alternative to previous ORC-based methods. Our novel AFRC-based community detection algorithm is competitive with an ORC-based approach. The codebase for fast and efficient computations of AFRC and the experiments in this article will be made publicly available upon publication. ",
    "url": "https://arxiv.org/abs/2306.06474",
    "authors": [
      "Lukas Fesser",
      "Sergio Serrano de Haro Iv\u00e1\u00f1ez",
      "Karel Devriendt",
      "Melanie Weber",
      "Renaud Lambiotte"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Metric Geometry (math.MG)"
    ]
  },
  {
    "id": "arXiv:2306.06582",
    "title": "Fast, Distribution-free Predictive Inference for Neural Networks with  Coverage Guarantees",
    "abstract": "This paper introduces a novel, computationally-efficient algorithm for predictive inference (PI) that requires no distributional assumptions on the data and can be computed faster than existing bootstrap-type methods for neural networks. Specifically, if there are $n$ training samples, bootstrap methods require training a model on each of the $n$ subsamples of size $n-1$; for large models like neural networks, this process can be computationally prohibitive. In contrast, our proposed method trains one neural network on the full dataset with $(\\epsilon, \\delta)$-differential privacy (DP) and then approximates each leave-one-out model efficiently using a linear approximation around the differentially-private neural network estimate. With exchangeable data, we prove that our approach has a rigorous coverage guarantee that depends on the preset privacy parameters and the stability of the neural network, regardless of the data distribution. Simulations and experiments on real data demonstrate that our method satisfies the coverage guarantees with substantially reduced computation compared to bootstrap methods. ",
    "url": "https://arxiv.org/abs/2306.06582",
    "authors": [
      "Yue Gao",
      "Garvesh Raskutti",
      "Rebecca Willet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06674",
    "title": "Self-supervised Equality Embedded Deep Lagrange Dual for Approximate  Constrained Optimization",
    "abstract": "Conventional solvers are often computationally expensive for constrained optimization, particularly in large-scale and time-critical problems. While this leads to a growing interest in using neural networks (NNs) as fast optimal solution approximators, incorporating the constraints with NNs is challenging. In this regard, we propose deep Lagrange dual with equality embedding (DeepLDE), a framework that learns to find an optimal solution without using labels. To ensure feasible solutions, we embed equality constraints into the NNs and train the NNs using the primal-dual method to impose inequality constraints. Furthermore, we prove the convergence of DeepLDE and show that the primal-dual learning method alone cannot ensure equality constraints without the help of equality embedding. Simulation results on convex, non-convex, and AC optimal power flow (AC-OPF) problems show that the proposed DeepLDE achieves the smallest optimality gap among all the NN-based approaches while always ensuring feasible solutions. Furthermore, the computation time of the proposed method is about 5 to 250 times faster than DC3 and the conventional solvers in solving constrained convex, non-convex optimization, and/or AC-OPF. ",
    "url": "https://arxiv.org/abs/2306.06674",
    "authors": [
      "Minsoo kim",
      "Hongseok Kim"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06814",
    "title": "HiddenSinger: High-Quality Singing Voice Synthesis via Neural Audio  Codec and Latent Diffusion Models",
    "abstract": "Recently, denoising diffusion models have demonstrated remarkable performance among generative models in various domains. However, in the speech domain, the application of diffusion models for synthesizing time-varying audio faces limitations in terms of complexity and controllability, as speech synthesis requires very high-dimensional samples with long-term acoustic features. To alleviate the challenges posed by model complexity in singing voice synthesis, we propose HiddenSinger, a high-quality singing voice synthesis system using a neural audio codec and latent diffusion models. To ensure high-fidelity audio, we introduce an audio autoencoder that can encode audio into an audio codec as a compressed representation and reconstruct the high-fidelity audio from the low-dimensional compressed latent vector. Subsequently, we use the latent diffusion models to sample a latent representation from a musical score. In addition, our proposed model is extended to an unsupervised singing voice learning framework, HiddenSinger-U, to train the model using an unlabeled singing voice dataset. Experimental results demonstrate that our model outperforms previous models in terms of audio quality. Furthermore, the HiddenSinger-U can synthesize high-quality singing voices of speakers trained solely on unlabeled data. ",
    "url": "https://arxiv.org/abs/2306.06814",
    "authors": [
      "Ji-Sang Hwang",
      "Sang-Hoon Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06982",
    "title": "Weakly Supervised Lesion Detection and Diagnosis for Breast Cancers with  Partially Annotated Ultrasound Images",
    "abstract": "Deep learning (DL) has proven highly effective for ultrasound-based computer-aided diagnosis (CAD) of breast cancers. In an automaticCAD system, lesion detection is critical for the following diagnosis. However, existing DL-based methods generally require voluminous manually-annotated region of interest (ROI) labels and class labels to train both the lesion detection and diagnosis models. In clinical practice, the ROI labels, i.e. ground truths, may not always be optimal for the classification task due to individual experience of sonologists, resulting in the issue of coarse annotation that limits the diagnosis performance of a CAD model. To address this issue, a novel Two-Stage Detection and Diagnosis Network (TSDDNet) is proposed based on weakly supervised learning to enhance diagnostic accuracy of the ultrasound-based CAD for breast cancers. In particular, all the ROI-level labels are considered as coarse labels in the first training stage, and then a candidate selection mechanism is designed to identify optimallesion areas for both the fully and partially annotated samples. It refines the current ROI-level labels in the fully annotated images and the detected ROIs in the partially annotated samples with a weakly supervised manner under the guidance of class labels. In the second training stage, a self-distillation strategy further is further proposed to integrate the detection network and classification network into a unified framework as the final CAD model for joint optimization, which then further improves the diagnosis performance. The proposed TSDDNet is evaluated on a B-mode ultrasound dataset, and the experimental results show that it achieves the best performance on both lesion detection and diagnosis tasks, suggesting promising application potential. ",
    "url": "https://arxiv.org/abs/2306.06982",
    "authors": [
      "Jian Wang",
      "Liang Qiao",
      "Shichong Zhou",
      "Jin Zhou",
      "Jun Wang",
      "Juncheng Li",
      "Shihui Ying",
      "Cai Chang",
      "Jun Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07056",
    "title": "Kernel Random Projection Depth for Outlier Detection",
    "abstract": "This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC). ",
    "url": "https://arxiv.org/abs/2306.07056",
    "authors": [
      "Akira Tamamori"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.07074",
    "title": "Using a neural network approach to accelerate disequilibrium chemistry  calculations in exoplanet atmospheres",
    "abstract": "In this era of exoplanet characterisation with JWST, the need for a fast implementation of classical forward models to understand the chemical and physical processes in exoplanet atmospheres is more important than ever. Notably, the time-dependent ordinary differential equations to be solved by chemical kinetics codes are very time-consuming to compute. In this study, we focus on the implementation of neural networks to replace mathematical frameworks in one-dimensional chemical kinetics codes. Using the gravity profile, temperature-pressure profiles, initial mixing ratios, and stellar flux of a sample of hot-Jupiters atmospheres as free parameters, the neural network is built to predict the mixing ratio outputs in steady state. The architecture of the network is composed of individual autoencoders for each input variable to reduce the input dimensionality, which is then used as the input training data for an LSTM-like neural network. Results show that the autoencoders for the mixing ratios, stellar spectra, and pressure profiles are exceedingly successful in encoding and decoding the data. Our results show that in 90% of the cases, the fully trained model is able to predict the evolved mixing ratios of the species in the hot-Jupiter atmosphere simulations. The fully trained model is ~1000 times faster than the simulations done with the forward, chemical kinetics model while making accurate predictions. ",
    "url": "https://arxiv.org/abs/2306.07074",
    "authors": [
      "Julius L. A. M. Hendrix",
      "Amy J. Louca",
      "Yamila Miguel"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07158",
    "title": "Riemannian Laplace approximations for Bayesian neural networks",
    "abstract": "Bayesian neural networks often approximate the weight-posterior with a Gaussian distribution. However, practical posteriors are often, even locally, highly non-Gaussian, and empirical performance deteriorates. We propose a simple parametric approximate posterior that adapts to the shape of the true posterior through a Riemannian metric that is determined by the log-posterior gradient. We develop a Riemannian Laplace approximation where samples naturally fall into weight-regions with low negative log-posterior. We show that these samples can be drawn by solving a system of ordinary differential equations, which can be done efficiently by leveraging the structure of the Riemannian metric and automatic differentiation. Empirically, we demonstrate that our approach consistently improves over the conventional Laplace approximation across tasks. We further show that, unlike the conventional Laplace approximation, our method is not overly sensitive to the choice of prior, which alleviates a practical pitfall of current approaches. ",
    "url": "https://arxiv.org/abs/2306.07158",
    "authors": [
      "Federico Bergamin",
      "Pablo Moreno-Mu\u00f1oz",
      "S\u00f8ren Hauberg",
      "Georgios Arvanitidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.07246",
    "title": "Reliable machine learning potentials based on artificial neural network  for graphene",
    "abstract": "Graphene is one of the most researched two dimensional (2D) material due to its unique combination of mechanical, thermal and electrical properties. Special 2D structure of graphene enables it to exhibit a wide range of peculiar material properties like high Young's modulus, high specific strength etc. which are critical for myriad of applications including light weight structural materials, multi-functional coating and flexible electronics. It is quite challenging and costly to experimentally investigate graphene/graphene based nanocomposites, computational simulations such as molecular dynamics (MD) simulations are widely adopted for understanding the microscopic origins of their unique properties. However, disparate results were reported from computational studies, especially MD simulations using various empirical inter-atomic potentials. In this work, an artificial neural network based interatomic potential has been developed for graphene to represent the potential energy surface based on first principle calculations. The developed machine learning potential (MLP) facilitates high fidelity MD simulations to approach the accuracy of ab initio methods but with a fraction of computational cost, which allows larger simulation size/length, and thereby enables accelerated discovery/design of graphene-based novel materials. Lattice parameter, coefficient of thermal expansion (CTE), Young's modulus and yield strength are estimated using machine learning accelerated MD simulations (MLMD), which are compared to experimental/first principle calculations from previous literatures. It is demonstrated that MLMD can capture the dominating mechanism governing CTE of graphene, including effects from lattice parameter and out of plane rippling. ",
    "url": "https://arxiv.org/abs/2306.07246",
    "authors": [
      "Akash Singh",
      "Yumeng Li"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07254",
    "title": "On the Expected Size of Conformal Prediction Sets",
    "abstract": "While conformal predictors reap the benefits of rigorous statistical guarantees for their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction set under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high probability intervals that can be easily computed, providing a practical method for characterizing the expected prediction set size across different possible realizations of the test and calibration data. Additionally, we corroborate the efficacy of our results with experiments on real-world datasets, for both regression and classification problems. ",
    "url": "https://arxiv.org/abs/2306.07254",
    "authors": [
      "Guneet S. Dhillon",
      "George Deligiannidis",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1908.10705",
    "title": "Improving a State-of-the-Art Heuristic for the Minimum Latency Problem  with Data Mining",
    "abstract": " Title: Improving a State-of-the-Art Heuristic for the Minimum Latency Problem  with Data Mining ",
    "url": "https://arxiv.org/abs/1908.10705",
    "authors": [
      "\u00cdtalo Santana",
      "Alexandre Plastino",
      "Isabel Rosseti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1908.11831",
    "title": "Efficient limited-time reachability estimation in temporal networks",
    "abstract": " Comments: Software implementation available at this https URL ",
    "url": "https://arxiv.org/abs/1908.11831",
    "authors": [
      "Arash Badie-Modiri",
      "M\u00e1rton Karsai",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:1911.09910",
    "title": "Learning Robustness with Bounded Failure: An Iterative MPC Approach",
    "abstract": " Comments: Added a set of important references that were missing ",
    "url": "https://arxiv.org/abs/1911.09910",
    "authors": [
      "Monimoy Bujarbaruah",
      "Akhil Shetty",
      "Kameshwar Poolla",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2003.09895",
    "title": "The Local Information Cost of Distributed Graph Problems",
    "abstract": " Comments: A preliminary version of this paper appeared in the proceedings of SODA 2021 ",
    "url": "https://arxiv.org/abs/2003.09895",
    "authors": [
      "Peter Robinson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2007.00112",
    "title": "Robustness to Transformations Across Categories: Is Robustness To  Transformations Driven by Invariant Neural Representations?",
    "abstract": " Title: Robustness to Transformations Across Categories: Is Robustness To  Transformations Driven by Invariant Neural Representations? ",
    "url": "https://arxiv.org/abs/2007.00112",
    "authors": [
      "Hojin Jang",
      "Syed Suleman Abbas Zaidi",
      "Xavier Boix",
      "Neeraj Prasad",
      "Sharon Gilad-Gutnick",
      "Shlomit Ben-Ami",
      "Pawan Sinha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.05523",
    "title": "Robust Sensing of Low-Rank Matrices with Non-Orthogonal Sparse  Decomposition",
    "abstract": " Title: Robust Sensing of Low-Rank Matrices with Non-Orthogonal Sparse  Decomposition ",
    "url": "https://arxiv.org/abs/2103.05523",
    "authors": [
      "Johannes Maly"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2108.07401",
    "title": "Mobile App Crowdsourced Test Report Consistency Detection via Deep  Image-and-Text Fusion Understanding",
    "abstract": " Title: Mobile App Crowdsourced Test Report Consistency Detection via Deep  Image-and-Text Fusion Understanding ",
    "url": "https://arxiv.org/abs/2108.07401",
    "authors": [
      "Shengcheng Yu",
      "Chunrong Fang",
      "Quanjun Zhang",
      "Zhihao Cao",
      "Yexiao Yun",
      "Zhenfei Cao",
      "Kai Mei",
      "Zhenyu Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2110.03301",
    "title": "EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box  Android Malware Detection",
    "abstract": " Title: EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box  Android Malware Detection ",
    "url": "https://arxiv.org/abs/2110.03301",
    "authors": [
      "Hamid Bostani",
      "Veelasha Moonsamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.07698",
    "title": "Directed Percolation in Random Temporal Network Models with  Heterogeneities",
    "abstract": " Comments: Implementation available at this https URL ",
    "url": "https://arxiv.org/abs/2110.07698",
    "authors": [
      "Arash Badie-Modiri",
      "Abbas K. Rizi",
      "M\u00e1rton Karsai",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2111.03892",
    "title": "Efficient Multi-objective Neural Architecture Search Framework via  Policy Gradient Algorithm",
    "abstract": " Title: Efficient Multi-objective Neural Architecture Search Framework via  Policy Gradient Algorithm ",
    "url": "https://arxiv.org/abs/2111.03892",
    "authors": [
      "Bo Lyu",
      "Shiping Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00648",
    "title": "Measuring the Impact of Individual Domain Factors in Self-Supervised  Pre-Training",
    "abstract": " Comments: Accepted to IEEE ICASSP SASB 2023 ",
    "url": "https://arxiv.org/abs/2203.00648",
    "authors": [
      "Ramon Sanabria",
      "Wei-Ning Hsu",
      "Alexei Baevski",
      "Michael Auli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.01391",
    "title": "DDL-MVS: Depth Discontinuity Learning for MVS Networks",
    "abstract": " Title: DDL-MVS: Depth Discontinuity Learning for MVS Networks ",
    "url": "https://arxiv.org/abs/2203.01391",
    "authors": [
      "Nail Ibrahimli",
      "Hugo Ledoux",
      "Julian Kooij",
      "Liangliang Nan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03047",
    "title": "Recent Advances in Neural Text Generation: A Task-Agnostic Survey",
    "abstract": " Comments: This has been updated with some recent advances in 2023 ",
    "url": "https://arxiv.org/abs/2203.03047",
    "authors": [
      "Chen Tang",
      "Frank Guerin",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.04769",
    "title": "Autoregressive based Drift Detection Method",
    "abstract": " Title: Autoregressive based Drift Detection Method ",
    "url": "https://arxiv.org/abs/2203.04769",
    "authors": [
      "Mansour Zoubeirou A Mayaki",
      "Michel Riveill"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05067",
    "title": "Universal Regression with Adversarial Responses",
    "abstract": " Title: Universal Regression with Adversarial Responses ",
    "url": "https://arxiv.org/abs/2203.05067",
    "authors": [
      "Mo\u00efse Blanchard",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.01922",
    "title": "SHAIL: Safety-Aware Hierarchical Adversarial Imitation Learning for  Autonomous Driving in Urban Environments",
    "abstract": " Comments: Presented at the 2023 IEEE International Conference on Robotics and Automation (ICRA) ",
    "url": "https://arxiv.org/abs/2204.01922",
    "authors": [
      "Arec Jamgochian",
      "Etienne Buehrle",
      "Johannes Fischer",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.13366",
    "title": "Semantic Information Recovery in Wireless Networks",
    "abstract": " Comments: Submitted for peer review ",
    "url": "https://arxiv.org/abs/2204.13366",
    "authors": [
      "Edgar Beck",
      "Carsten Bockelmann",
      "Armin Dekorsy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15128",
    "title": "Level Up with RealAEs: Leveraging Domain Constraints in Feature Space to  Strengthen Robustness of Android Malware Detection",
    "abstract": " Title: Level Up with RealAEs: Leveraging Domain Constraints in Feature Space to  Strengthen Robustness of Android Malware Detection ",
    "url": "https://arxiv.org/abs/2205.15128",
    "authors": [
      "Hamid Bostani",
      "Zhengyu Zhao",
      "Zhuoran Liu",
      "Veelasha Moonsamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09215",
    "title": "Mind the Gap: Norm-Aware Adaptive Robust Loss for Multivariate  Least-Squares Problems",
    "abstract": " Comments: 8 pages, 4 figures. This paper has been accepted for publication in IEEE Robotics and Automation Letters. V2: Update weighting in (13), (28) and re-run results. Hypothesis, methodology, and general findings remain unchanged. Update Sec. II-A to reference IRLS, and update citation [11] accordingly. Include acknowledgement to Mitchell Cohen. V3: Update Section II-A to least-squares ",
    "url": "https://arxiv.org/abs/2206.09215",
    "authors": [
      "Thomas Hitchcox",
      "James Richard Forbes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.13037",
    "title": "Universality of Approximate Message Passing algorithms and tensor  networks",
    "abstract": " Comments: 54 pages. v2: We extend the results in the previous version to matrix ensembles with sign-and-permutation invariance in law and a limit distribution over the diagonal ",
    "url": "https://arxiv.org/abs/2206.13037",
    "authors": [
      "Tianhao Wang",
      "Xinyi Zhong",
      "Zhou Fan"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2207.02621",
    "title": "VMRF: View Matching Neural Radiance Fields",
    "abstract": " Comments: This paper has been accepted to ACM MM 2022 ",
    "url": "https://arxiv.org/abs/2207.02621",
    "authors": [
      "Jiahui Zhang",
      "Fangneng Zhan",
      "Rongliang Wu",
      "Yingchen Yu",
      "Wenqing Zhang",
      "Bai Song",
      "Xiaoqin Zhang",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04932",
    "title": "Stochastic Gradient Descent and Anomaly of Variance-flatness Relation in  Artificial Neural Networks",
    "abstract": " Title: Stochastic Gradient Descent and Anomaly of Variance-flatness Relation in  Artificial Neural Networks ",
    "url": "https://arxiv.org/abs/2207.04932",
    "authors": [
      "Xia Xiong",
      "Yong-Cong Chen",
      "Chunxiao Shi",
      "Ping Ao"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10771",
    "title": "Reticula: A temporal network and hypergraph analysis software package",
    "abstract": " Comments: Accepted for publication at SoftwareX. Live documentation available at this https URL ",
    "url": "https://arxiv.org/abs/2207.10771",
    "authors": [
      "Arash Badie-Modiri",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.10579",
    "title": "First-order Policy Optimization for Robust Markov Decision Process",
    "abstract": " Title: First-order Policy Optimization for Robust Markov Decision Process ",
    "url": "https://arxiv.org/abs/2209.10579",
    "authors": [
      "Yan Li",
      "Guanghui Lan",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.02694",
    "title": "Probabilistic partition of unity networks for high-dimensional  regression problems",
    "abstract": " Title: Probabilistic partition of unity networks for high-dimensional  regression problems ",
    "url": "https://arxiv.org/abs/2210.02694",
    "authors": [
      "Tiffany Fan",
      "Nathaniel Trask",
      "Marta D'Elia",
      "Eric Darve"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.03123",
    "title": "On the Effectiveness of Hybrid Pooling in Mixup-Based Graph Learning for  Language Processing",
    "abstract": " Comments: 16 pages, ongoing work ",
    "url": "https://arxiv.org/abs/2210.03123",
    "authors": [
      "Zeming Dong",
      "Qiang Hu",
      "Zhenya Zhang",
      "Yuejun Guo",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08376",
    "title": "Variant Parallelism: Lightweight Deep Convolutional Models for  Distributed Inference on IoT Devices",
    "abstract": " Comments: 8 pages, 6 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2210.08376",
    "authors": [
      "Navidreza Asadi",
      "Maziar Goudarzi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10880",
    "title": "Learning to Invert: Simple Adaptive Attacks for Gradient Inversion in  Federated Learning",
    "abstract": " Title: Learning to Invert: Simple Adaptive Attacks for Gradient Inversion in  Federated Learning ",
    "url": "https://arxiv.org/abs/2210.10880",
    "authors": [
      "Ruihan Wu",
      "Xiangyu Chen",
      "Chuan Guo",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.12331",
    "title": "Deep Multi-Branch CNN Architecture for Early Alzheimer's Detection from  Brain MRIs",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2210.12331",
    "authors": [
      "Paul K. Mandal",
      "Rakesh Mahto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00435",
    "title": "Spreading dynamics in networks under context-dependent behavior",
    "abstract": " Comments: 23 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2211.00435",
    "authors": [
      "Giulio Burgio",
      "Sergio G\u00f3mez",
      "Alex Arenas"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.01156",
    "title": "Entropic Neural Optimal Transport via Diffusion Processes",
    "abstract": " Title: Entropic Neural Optimal Transport via Diffusion Processes ",
    "url": "https://arxiv.org/abs/2211.01156",
    "authors": [
      "Nikita Gushchin",
      "Alexander Kolesov",
      "Alexander Korotin",
      "Dmitry Vetrov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.07432",
    "title": "The $\u03b1$-$\u03b7$-$\u03ba$-$\u03bc$ Fading Model: An Exact Statistical  Representation",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication ",
    "url": "https://arxiv.org/abs/2211.07432",
    "authors": [
      "Pranay Bhardwaj",
      "Eesha Santosh Karnawat",
      "S. M. Zafaruddin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.11074",
    "title": "Frozen Overparameterization: A Double Descent Perspective on Transfer  Learning of Deep Neural Networks",
    "abstract": " Title: Frozen Overparameterization: A Double Descent Perspective on Transfer  Learning of Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2211.11074",
    "authors": [
      "Yehuda Dar",
      "Lorenzo Luzi",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15755",
    "title": "Confidence-Aware Graph Neural Networks for Learning Reliability  Assessment Commitments",
    "abstract": " Comments: Submitted to IEEE Transactions on Power Systems ",
    "url": "https://arxiv.org/abs/2211.15755",
    "authors": [
      "Seonho Park",
      "Wenbo Chen",
      "Dahye Han",
      "Mathieu Tanneau",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.16467",
    "title": "Linear Causal Disentanglement via Interventions",
    "abstract": " Title: Linear Causal Disentanglement via Interventions ",
    "url": "https://arxiv.org/abs/2211.16467",
    "authors": [
      "Chandler Squires",
      "Anna Seigal",
      "Salil Bhate",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.02269",
    "title": "Federated Neural Topic Models",
    "abstract": " Comments: 14 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2212.02269",
    "authors": [
      "Lorena Calvo-Bartolom\u00e9",
      "Jer\u00f3nimo Arenas-Garc\u00eda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.03063",
    "title": "Causal Inference via Style Transfer for Out-of-distribution  Generalisation",
    "abstract": " Comments: In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 23), August 6-10, 2023, Long Beach, CA, USA. ACM, New York, NY, USA, 19 pages ",
    "url": "https://arxiv.org/abs/2212.03063",
    "authors": [
      "Toan Nguyen",
      "Kien Do",
      "Duc Thanh Nguyen",
      "Bao Duong",
      "Thin Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.04055",
    "title": "Mitigating Memorization of Noisy Labels by Clipping the Model Prediction",
    "abstract": " Comments: Accepted by ICML 2024 ",
    "url": "https://arxiv.org/abs/2212.04055",
    "authors": [
      "Hongxin Wei",
      "Huiping Zhuang",
      "Renchunzi Xie",
      "Lei Feng",
      "Gang Niu",
      "Bo An",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05332",
    "title": "An approach to robust ICP initialization",
    "abstract": " Comments: 9 pages, 18 figures; GitHub repository at (this https URL) ",
    "url": "https://arxiv.org/abs/2212.05332",
    "authors": [
      "Alexander Kolpakov",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.09097",
    "title": "Continual Knowledge Distillation for Neural Machine Translation",
    "abstract": " Comments: Accepted to ACL 2023. The source code is available at this https URL ",
    "url": "https://arxiv.org/abs/2212.09097",
    "authors": [
      "Yuanchi Zhang",
      "Peng Li",
      "Maosong Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.14597",
    "title": "Defense Against Adversarial Attacks on Audio DeepFake Detection",
    "abstract": " Comments: Accepted to INTERSPEECH 2023 ",
    "url": "https://arxiv.org/abs/2212.14597",
    "authors": [
      "Piotr Kawa",
      "Marcin Plata",
      "Piotr Syga"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.14665",
    "title": "Sizing Grid-Connected Wind Power Generation and Energy Storage with Wake  Effect and Endogenous Uncertainty: A Distributionally Robust Method",
    "abstract": " Comments: 14 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2212.14665",
    "authors": [
      "Rui Xie",
      "Wei Wei",
      "Yue Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.05119",
    "title": "ITA-ELECTION-2022: A multi-platform dataset of social media  conversations around the 2022 Italian general election",
    "abstract": " Comments: 4 pages, 3 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2301.05119",
    "authors": [
      "Francesco Pierri",
      "Geng Liu",
      "Stefano Ceri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.06499",
    "title": "PROPAGATE: a seed propagation framework to compute Distance-based  metrics on Very Large Graphs",
    "abstract": " Title: PROPAGATE: a seed propagation framework to compute Distance-based  metrics on Very Large Graphs ",
    "url": "https://arxiv.org/abs/2301.06499",
    "authors": [
      "Giambattista Amati",
      "Antonio Cruciani",
      "Daniele Pasquini",
      "Paola Vocca",
      "Simone Angelini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.08918",
    "title": "Improving Signed Propagation for Graph Neural Networks",
    "abstract": " Title: Improving Signed Propagation for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2301.08918",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chong-Kwon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.10053",
    "title": "A Linear Reconstruction Approach for Attribute Inference Attacks against  Synthetic Data",
    "abstract": " Title: A Linear Reconstruction Approach for Attribute Inference Attacks against  Synthetic Data ",
    "url": "https://arxiv.org/abs/2301.10053",
    "authors": [
      "Meenatchi Sundaram Muthu Selva Annamalai",
      "Andrea Gadotti",
      "Luc Rocher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.10119",
    "title": "Minimal Value-Equivalent Partial Models for Scalable and Robust Planning  in Lifelong Reinforcement Learning",
    "abstract": " Comments: Published as a conference paper at CoLLAs 2023 ",
    "url": "https://arxiv.org/abs/2301.10119",
    "authors": [
      "Safa Alver",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.10900",
    "title": "Graph Contrastive Learning for Skeleton-based Action Recognition",
    "abstract": " Comments: Accepted by ICLR2023 ",
    "url": "https://arxiv.org/abs/2301.10900",
    "authors": [
      "Xiaohu Huang",
      "Hao Zhou",
      "Jian Wang",
      "Haocheng Feng",
      "Junyu Han",
      "Errui Ding",
      "Jingdong Wang",
      "Xinggang Wang",
      "Wenyu Liu",
      "Bin Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12258",
    "title": "Cross-domain Neural Pitch and Periodicity Estimation",
    "abstract": " Title: Cross-domain Neural Pitch and Periodicity Estimation ",
    "url": "https://arxiv.org/abs/2301.12258",
    "authors": [
      "Max Morrison",
      "Caedon Hsieh",
      "Nathan Pruyne",
      "Bryan Pardo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2302.00942",
    "title": "Efficient Graph Field Integrators Meet Point Clouds",
    "abstract": " Title: Efficient Graph Field Integrators Meet Point Clouds ",
    "url": "https://arxiv.org/abs/2302.00942",
    "authors": [
      "Krzysztof Choromanski",
      "Arijit Sehanobish",
      "Han Lin",
      "Yunfan Zhao",
      "Eli Berger",
      "Tetiana Parshakova",
      "Alvin Pan",
      "David Watkins",
      "Tianyi Zhang",
      "Valerii Likhosherstov",
      "Somnath Basu Roy Chowdhury",
      "Avinava Dubey",
      "Deepali Jain",
      "Tamas Sarlos",
      "Snigdha Chaturvedi",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03322",
    "title": "Attacking Cooperative Multi-Agent Reinforcement Learning by Adversarial  Minority Influence",
    "abstract": " Title: Attacking Cooperative Multi-Agent Reinforcement Learning by Adversarial  Minority Influence ",
    "url": "https://arxiv.org/abs/2302.03322",
    "authors": [
      "Simin Li",
      "Jun Guo",
      "Jingqiao Xiu",
      "Pu Feng",
      "Xin Yu",
      "Aishan Liu",
      "Wenjun Wu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04379",
    "title": "The Certification Paradox: Certifications Admit Better Attacks",
    "abstract": " Comments: 16 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2302.04379",
    "authors": [
      "Andrew C. Cullen",
      "Shijie Liu",
      "Paul Montague",
      "Sarah M. Erfani",
      "Benjamin I.P. Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.07186",
    "title": "Adversarial Rewards in Universal Learning for Contextual Bandits",
    "abstract": " Title: Adversarial Rewards in Universal Learning for Contextual Bandits ",
    "url": "https://arxiv.org/abs/2302.07186",
    "authors": [
      "Moise Blanchard",
      "Steve Hanneke",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2302.08237",
    "title": "A Cloud-based Deep Learning Framework for Early Detection of Pushing at  Crowded Event Entrances",
    "abstract": " Title: A Cloud-based Deep Learning Framework for Early Detection of Pushing at  Crowded Event Entrances ",
    "url": "https://arxiv.org/abs/2302.08237",
    "authors": [
      "Ahmed Alia",
      "Mohammed Maree",
      "Mohcine Chraibi",
      "Anas Toma",
      "Armin Seyfried"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.09119",
    "title": "A Review on Generative Adversarial Networks for Data Augmentation in  Person Re-Identification Systems",
    "abstract": " Title: A Review on Generative Adversarial Networks for Data Augmentation in  Person Re-Identification Systems ",
    "url": "https://arxiv.org/abs/2302.09119",
    "authors": [
      "Victor Uc-Cetina",
      "Laura Alvarez-Gonzalez",
      "Anabel Martin-Gonzalez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10911",
    "title": "Revisiting Weighted Aggregation in Federated Learning with Neural  Networks",
    "abstract": " Comments: Accepted by ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.10911",
    "authors": [
      "Zexi Li",
      "Tao Lin",
      "Xinyi Shang",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12338",
    "title": "Tight Runtime Bounds for Static Unary Unbiased Evolutionary Algorithms  on Linear Functions",
    "abstract": " Comments: Full version of a paper that is to appear in the Proc. of GECCO 2023 ",
    "url": "https://arxiv.org/abs/2302.12338",
    "authors": [
      "Carola Doerr",
      "Duri Andrea Janett",
      "Johannes Lengler"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.14370",
    "title": "CrossSpeech: Speaker-independent Acoustic Representation for  Cross-lingual Speech Synthesis",
    "abstract": " Comments: Accepted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2302.14370",
    "authors": [
      "Ji-Hoon Kim",
      "Hong-Sun Yang",
      "Yoon-Cheol Ju",
      "Il-Hwan Kim",
      "Byeong-Yeol Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.14685",
    "title": "DART: Diversify-Aggregate-Repeat Training Improves Generalization of  Neural Networks",
    "abstract": " Comments: CVPR 2023. First two authors contributed equally ",
    "url": "https://arxiv.org/abs/2302.14685",
    "authors": [
      "Samyak Jain",
      "Sravanti Addepalli",
      "Pawan Sahu",
      "Priyam Dey",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05203",
    "title": "RMMDet: Road-Side Multitype and Multigroup Sensor Detection System for  Autonomous Driving",
    "abstract": " Title: RMMDet: Road-Side Multitype and Multigroup Sensor Detection System for  Autonomous Driving ",
    "url": "https://arxiv.org/abs/2303.05203",
    "authors": [
      "Xiuyu Yang",
      "Zhuangyan Zhang",
      "Haikuo Du",
      "Sui Yang",
      "Fengping Sun",
      "Yanbo Liu",
      "Ling Pei",
      "Wenchao Xu",
      "Weiqi Sun",
      "Zhengyu Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.07203",
    "title": "On the Robustness of Text Vectorizers",
    "abstract": " Comments: Accepted to ICML 2023. 33 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2303.07203",
    "authors": [
      "R\u00e9mi Catellier",
      "Samuel Vaiter",
      "Damien Garreau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.08256",
    "title": "Gamora: Graph Learning based Symbolic Reasoning for Large-Scale Boolean  Networks",
    "abstract": " Comments: This work will appear at 60th Design Automation Conference (DAC'23) ",
    "url": "https://arxiv.org/abs/2303.08256",
    "authors": [
      "Nan Wu",
      "Yingjie Li",
      "Cong Hao",
      "Steve Dai",
      "Cunxi Yu",
      "Yuan Xie"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2303.18186",
    "title": "Adaptive Model Prediction Control-Based Multi-Terrain Trajectory  Tracking Framework for Mobile Spherical Robots",
    "abstract": " Comments: 10 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2303.18186",
    "authors": [
      "Yifan Liu",
      "Tao Hu",
      "Xiaoqing Guan",
      "Yixu Wang",
      "Bixuan Zhang",
      "You Wang",
      "Guang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.00613",
    "title": "Improving Few-Shot Inductive Learning on Temporal Knowledge Graphs using  Confidence-Augmented Reinforcement Learning",
    "abstract": " Comments: Accepted to ECML/PKDD 2023 ",
    "url": "https://arxiv.org/abs/2304.00613",
    "authors": [
      "Zifeng Ding",
      "Jingpei Wu",
      "Zongyue Li",
      "Yunpu Ma",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.01874",
    "title": "Incremental Verification of Neural Networks",
    "abstract": " Comments: PLDI 2023 ",
    "url": "https://arxiv.org/abs/2304.01874",
    "authors": [
      "Shubham Ugare",
      "Debangshu Banerjee",
      "Sasa Misailovic",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2304.06094",
    "title": "Energy-guided Entropic Neural Optimal Transport",
    "abstract": " Title: Energy-guided Entropic Neural Optimal Transport ",
    "url": "https://arxiv.org/abs/2304.06094",
    "authors": [
      "Petr Mokrov",
      "Alexander Korotin",
      "Alexander Kolesov",
      "Nikita Gushchin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.09439",
    "title": "Local object crop collision network for efficient simulation of  non-convex objects in GPU-based simulators",
    "abstract": " Comments: RSS 2023 this https URL ",
    "url": "https://arxiv.org/abs/2304.09439",
    "authors": [
      "Dongwon Son",
      "Beomjoon Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.12244",
    "title": "WizardLM: Empowering Large Language Models to Follow Complex  Instructions",
    "abstract": " Comments: large language model, instruction fine-tune ",
    "url": "https://arxiv.org/abs/2304.12244",
    "authors": [
      "Can Xu",
      "Qingfeng Sun",
      "Kai Zheng",
      "Xiubo Geng",
      "Pu Zhao",
      "Jiazhan Feng",
      "Chongyang Tao",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.13995",
    "title": "Rotation and Translation Invariant Representation Learning with Implicit  Neural Representations",
    "abstract": " Title: Rotation and Translation Invariant Representation Learning with Implicit  Neural Representations ",
    "url": "https://arxiv.org/abs/2304.13995",
    "authors": [
      "Sehyun Kwon",
      "Joo Young Choi",
      "Ernest K. Ryu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.14845",
    "title": "SFD2: Semantic-guided Feature Detection and Description",
    "abstract": " Comments: CVPR 2023. code is available at this https URL ",
    "url": "https://arxiv.org/abs/2304.14845",
    "authors": [
      "Fei Xue",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.01210",
    "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of  Large Language Models for Code Generation",
    "abstract": " Title: Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of  Large Language Models for Code Generation ",
    "url": "https://arxiv.org/abs/2305.01210",
    "authors": [
      "Jiawei Liu",
      "Chunqiu Steven Xia",
      "Yuyao Wang",
      "Lingming Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.02133",
    "title": "Frank number and nowhere-zero flows on graphs",
    "abstract": " Comments: 22 pages ",
    "url": "https://arxiv.org/abs/2305.02133",
    "authors": [
      "Jan Goedgebeur",
      "Edita M\u00e1\u010dajov\u00e1",
      "Jarne Renders"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.05832",
    "title": "Causal Information Splitting: Engineering Proxy Features for Robustness  to Distribution Shifts",
    "abstract": " Comments: To appear in UAI 2023 ",
    "url": "https://arxiv.org/abs/2305.05832",
    "authors": [
      "Bijan Mazaheri",
      "Atalanti Mastakouri",
      "Dominik Janzing",
      "Michaela Hardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.08265",
    "title": "Vehicle Detection and Classification without Residual Calculation:  Accelerating HEVC Image Decoding with Random Perturbation Injection",
    "abstract": " Comments: 10 pages 4 figures ",
    "url": "https://arxiv.org/abs/2305.08265",
    "authors": [
      "Muhammet Sebul Berato\u011flu",
      "Beh\u00e7et U\u011fur T\u00f6reyin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08317",
    "title": "By-Software Branch Prediction in Loops",
    "abstract": " Title: By-Software Branch Prediction in Loops ",
    "url": "https://arxiv.org/abs/2305.08317",
    "authors": [
      "Maziar Goudarzi",
      "Reza Azimi",
      "Julian Humecki",
      "Faizaan Rehman",
      "Richard Zhang",
      "Chirag Sethi",
      "Tanishq Bomman",
      "Yuqi Yang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.08528",
    "title": "NICOL: A Neuro-inspired Collaborative Semi-humanoid Robot that Bridges  Social Interaction and Reliable Manipulation",
    "abstract": " Title: NICOL: A Neuro-inspired Collaborative Semi-humanoid Robot that Bridges  Social Interaction and Reliable Manipulation ",
    "url": "https://arxiv.org/abs/2305.08528",
    "authors": [
      "Matthias Kerzel",
      "Philipp Allgeuer",
      "Erik Strahl",
      "Nicolas Frick",
      "Jan-Gerrit Habekost",
      "Manfred Eppe",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.09779",
    "title": "A Scalable Walsh-Hadamard Regularizer to Overcome the Low-degree  Spectral Bias of Neural Networks",
    "abstract": " Comments: Accepted for the 39th Conference on Uncertainty in Artificial Intelligence (UAI 2023) ",
    "url": "https://arxiv.org/abs/2305.09779",
    "authors": [
      "Ali Gorji",
      "Andisheh Amrollahi",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12831",
    "title": "Target Active Speaker Detection with Audio-visual Cues",
    "abstract": " Comments: Accepted to INTERSPEECH2023 ",
    "url": "https://arxiv.org/abs/2305.12831",
    "authors": [
      "Yidi Jiang",
      "Ruijie Tao",
      "Zexu Pan",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12900",
    "title": "Evaluating Prompt-based Question Answering for Object Prediction in the  Open Research Knowledge Graph",
    "abstract": " Comments: 14 pages, 1 figure, accepted for publication as a short paper at DEXA 2023 (this https URL) ",
    "url": "https://arxiv.org/abs/2305.12900",
    "authors": [
      "Jennifer D'Souza",
      "Moussab Hrou",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.15189",
    "title": "Black-Box vs. Gray-Box: A Case Study on Learning Table Tennis Ball  Trajectory Prediction with Spin and Impacts",
    "abstract": " Comments: Accepted for publication at the 5th Annual Conference on Learning for Dynamics and Control (L4DC) 2023 (camera-ready). With supplementary material ",
    "url": "https://arxiv.org/abs/2305.15189",
    "authors": [
      "Jan Achterhold",
      "Philip Tobuschat",
      "Hao Ma",
      "Dieter Buechler",
      "Michael Muehlebach",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.16588",
    "title": "Legion: Automatically Pushing the Envelope of Multi-GPU System for  Billion-Scale GNN Training",
    "abstract": " Title: Legion: Automatically Pushing the Envelope of Multi-GPU System for  Billion-Scale GNN Training ",
    "url": "https://arxiv.org/abs/2305.16588",
    "authors": [
      "Jie Sun",
      "Li Su",
      "Zuocheng Shi",
      "Wenting Shen",
      "Zeke Wang",
      "Lei Wang",
      "Jie Zhang",
      "Yong Li",
      "Wenyuan Yu",
      "Jingren Zhou",
      "Fei Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.16649",
    "title": "FSD: Fully-Specialized Detector via Neural Architecture Search",
    "abstract": " Title: FSD: Fully-Specialized Detector via Neural Architecture Search ",
    "url": "https://arxiv.org/abs/2305.16649",
    "authors": [
      "Zhe Huang",
      "Yudian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16967",
    "title": "Evaluating Open-Domain Dialogues in Latent Space with Next Sentence  Prediction and Mutual Information",
    "abstract": " Comments: Accepted at ACL2023 ",
    "url": "https://arxiv.org/abs/2305.16967",
    "authors": [
      "Kun Zhao",
      "Bohao Yang",
      "Chenghua Lin",
      "Wenge Rong",
      "Aline Villavicencio",
      "Xiaohui Cui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17506",
    "title": "Backdooring Neural Code Search",
    "abstract": " Comments: Accepted to the 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023) ",
    "url": "https://arxiv.org/abs/2305.17506",
    "authors": [
      "Weisong Sun",
      "Yuchen Chen",
      "Guanhong Tao",
      "Chunrong Fang",
      "Xiangyu Zhang",
      "Quanjun Zhang",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17537",
    "title": "Modeling Dynamic Environments with Scene Graph Memory",
    "abstract": " Title: Modeling Dynamic Environments with Scene Graph Memory ",
    "url": "https://arxiv.org/abs/2305.17537",
    "authors": [
      "Andrey Kurenkov",
      "Michael Lingelbach",
      "Tanmay Agarwal",
      "Emily Jin",
      "Chengshu Li",
      "Ruohan Zhang",
      "Li Fei-Fei",
      "Jiajun Wu",
      "Silvio Savarese",
      "Roberto Mart\u00edn-Mart\u00edn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19567",
    "title": "DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code  Collaborated with Mixer",
    "abstract": " Comments: need revision ",
    "url": "https://arxiv.org/abs/2305.19567",
    "authors": [
      "Yerin Choi",
      "Myoung-Wan Koo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.19915",
    "title": "Data Augmentation Approaches for Source Code Models: A Survey",
    "abstract": " Comments: Technical Report ",
    "url": "https://arxiv.org/abs/2305.19915",
    "authors": [
      "Terry Yue Zhuo",
      "Zhou Yang",
      "Zhensu Sun",
      "Yufei Wang",
      "Li Li",
      "Xiaoning Du",
      "Zhenchang Xing",
      "David Lo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.20055",
    "title": "Cross-Domain Car Detection Model with Integrated Convolutional Block  Attention Mechanism",
    "abstract": " Title: Cross-Domain Car Detection Model with Integrated Convolutional Block  Attention Mechanism ",
    "url": "https://arxiv.org/abs/2305.20055",
    "authors": [
      "Haoxuan Xu",
      "Songning Lai",
      "Xianyang Li",
      "Yang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.00585",
    "title": "Causal Imitability Under Context-Specific Independence Relations",
    "abstract": " Comments: 19 pages, 4 figures, under review ",
    "url": "https://arxiv.org/abs/2306.00585",
    "authors": [
      "Fateme Jamshidi",
      "Sina Akbari",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01095",
    "title": "Large-Batch, Neural Multi-Objective Bayesian Optimization",
    "abstract": " Title: Large-Batch, Neural Multi-Objective Bayesian Optimization ",
    "url": "https://arxiv.org/abs/2306.01095",
    "authors": [
      "Navid Ansari",
      "Hans-Peter Seidel",
      "Vahid Babaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2306.01272",
    "title": "DeepfakeArt Challenge: A Benchmark Dataset for Generative AI Art Forgery  and Data Poisoning Detection",
    "abstract": " Title: DeepfakeArt Challenge: A Benchmark Dataset for Generative AI Art Forgery  and Data Poisoning Detection ",
    "url": "https://arxiv.org/abs/2306.01272",
    "authors": [
      "Hossein Aboutalebi",
      "Dayou Mao",
      "Carol Xu",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01293",
    "title": "LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning",
    "abstract": " Comments: v2: minor modification (i.e., I removed tex commands from the arXiv abstract) ",
    "url": "https://arxiv.org/abs/2306.01293",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02080",
    "title": "Benchmarking Robustness of Adaptation Methods on Pre-trained  Vision-Language Models",
    "abstract": " Comments: 9 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2306.02080",
    "authors": [
      "Shuo Chen",
      "Jindong Gu",
      "Zhen Han",
      "Yunpu Ma",
      "Philip Torr",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02911",
    "title": "Catch Me If You Can: Deep Meta-RL for Search-and-Rescue using LoRa UAV  Networks",
    "abstract": " Title: Catch Me If You Can: Deep Meta-RL for Search-and-Rescue using LoRa UAV  Networks ",
    "url": "https://arxiv.org/abs/2306.02911",
    "authors": [
      "Mehdi Naderi Soorki",
      "Hossein Aghajari",
      "Sajad Ahmadinabi",
      "Hamed Bakhtiari Babadegani",
      "Christina Chaccour",
      "Walid Saad"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.03374",
    "title": "PGformer: Proxy-Bridged Game Transformer for Multi-Person Extremely  Interactive Motion Prediction",
    "abstract": " Title: PGformer: Proxy-Bridged Game Transformer for Multi-Person Extremely  Interactive Motion Prediction ",
    "url": "https://arxiv.org/abs/2306.03374",
    "authors": [
      "Yanwen Fang",
      "Chao Li",
      "Jintai Chen",
      "Peng-Tao Jiang",
      "Yifeng Geng",
      "Xuansong Xie",
      "Eddy K. F. Lam",
      "Guodong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.03722",
    "title": "Evaluating the Effectiveness of Natural Language Inference for Hate  Speech Detection in Languages with Limited Labeled Data",
    "abstract": " Comments: 15 pages, 7 figures, Accepted at the 7th Workshop on Online Abuse and Harms (WOAH), ACL 2023 ",
    "url": "https://arxiv.org/abs/2306.03722",
    "authors": [
      "Janis Goldzycher",
      "Moritz Preisig",
      "Chantal Amrhein",
      "Gerold Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2306.03995",
    "title": "Elephant Flows Detection Using Deep Neural Network, Convolutional Neural  Network, Long Short Term Memory and Autoencoder",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2306.03995",
    "authors": [
      "Getahun Wassie Geremew",
      "Jianguo Ding"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.04166",
    "title": "BAA-NGP: Bundle-Adjusting Accelerated Neural Graphics Primitives",
    "abstract": " Title: BAA-NGP: Bundle-Adjusting Accelerated Neural Graphics Primitives ",
    "url": "https://arxiv.org/abs/2306.04166",
    "authors": [
      "Sainan Liu",
      "Shan Lin",
      "Jingpei Lu",
      "Shreya Saha",
      "Alexey Supikov",
      "Michael Yip"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.04581",
    "title": "Divide and Repair: Using Options to Improve Performance of Imitation  Learning Against Adversarial Demonstrations",
    "abstract": " Comments: 33 pages, 4 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2306.04581",
    "authors": [
      "Prithviraj Dasgupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.04828",
    "title": "Fast and Effective GNN Training with Linearized Random Spanning Trees",
    "abstract": " Title: Fast and Effective GNN Training with Linearized Random Spanning Trees ",
    "url": "https://arxiv.org/abs/2306.04828",
    "authors": [
      "Francesco Bonchi",
      "Claudio Gentile",
      "Andr\u00e9 Panisson",
      "Fabio Vitale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.04979",
    "title": "CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive  Graph Classification",
    "abstract": " Title: CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive  Graph Classification ",
    "url": "https://arxiv.org/abs/2306.04979",
    "authors": [
      "Nan Yin",
      "Li Shen",
      "Mengzhu Wang",
      "Long Lan",
      "Zeyu Ma",
      "Chong Chen",
      "Xian-Sheng Hua",
      "Xiao Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.05554",
    "title": "Simulation and Prediction of Countercurrent Spontaneous Imbibition at  Early and Late Times Using Physics-Informed Neural Networks",
    "abstract": " Title: Simulation and Prediction of Countercurrent Spontaneous Imbibition at  Early and Late Times Using Physics-Informed Neural Networks ",
    "url": "https://arxiv.org/abs/2306.05554",
    "authors": [
      "Jassem Abbasi",
      "P\u00e5l \u00d8steb\u00f8 Andersen"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05872",
    "title": "Neural Haircut: Prior-Guided Strand-Based Hair Reconstruction",
    "abstract": " Title: Neural Haircut: Prior-Guided Strand-Based Hair Reconstruction ",
    "url": "https://arxiv.org/abs/2306.05872",
    "authors": [
      "Vanessa Sklyarova",
      "Jenya Chelishev",
      "Andreea Dogaru",
      "Igor Medvedev",
      "Victor Lempitsky",
      "Egor Zakharov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2306.05880",
    "title": "Time Series Continuous Modeling for Imputation and Forecasting with  Implicit Neural Representations",
    "abstract": " Title: Time Series Continuous Modeling for Imputation and Forecasting with  Implicit Neural Representations ",
    "url": "https://arxiv.org/abs/2306.05880",
    "authors": [
      "Etienne Le Naour",
      "Louis Serrano",
      "L\u00e9on Migus",
      "Yuan Yin",
      "Ghislain Agoua",
      "Nicolas Baskiotis",
      "Patrick Gallinari",
      "Vincent Guigue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.05923",
    "title": "GAN-CAN: A Novel Attack to Behavior-Based Driver Authentication Systems",
    "abstract": " Comments: 16 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2306.05923",
    "authors": [
      "Emad Efatinasab",
      "Francesco Marchiori",
      "Denis Donadel",
      "Alessandro Brighente",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.05949",
    "title": "Evaluating the Social Impact of Generative AI Systems in Systems and  Society",
    "abstract": " Title: Evaluating the Social Impact of Generative AI Systems in Systems and  Society ",
    "url": "https://arxiv.org/abs/2306.05949",
    "authors": [
      "Irene Solaiman",
      "Zeerak Talat",
      "William Agnew",
      "Lama Ahmad",
      "Dylan Baker",
      "Su Lin Blodgett",
      "Hal Daum\u00e9 III",
      "Jesse Dodge",
      "Ellie Evans",
      "Sara Hooker",
      "Yacine Jernite",
      "Alexandra Sasha Luccioni",
      "Alberto Lusoli",
      "Margaret Mitchell",
      "Jessica Newman",
      "Marie-Therese Png",
      "Andrew Strait",
      "Apostol Vassilev"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06033",
    "title": "SoK: Analysis of User-Centered Studies Focusing on Healthcare Privacy &  Security",
    "abstract": " Title: SoK: Analysis of User-Centered Studies Focusing on Healthcare Privacy &  Security ",
    "url": "https://arxiv.org/abs/2306.06033",
    "authors": [
      "Faiza Tazi",
      "Archana Nandakumar",
      "Josiah Dykstra",
      "Prashanth Rajivan",
      "Sanchari Das"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2306.06062",
    "title": "Neural FIM for learning Fisher Information Metrics from point cloud data",
    "abstract": " Comments: 13 pages, 11 figures, 1 table ",
    "url": "https://arxiv.org/abs/2306.06062",
    "authors": [
      "Oluwadamilola Fasina",
      "Guillaume Huguet",
      "Alexander Tong",
      "Yanlei Zhang",
      "Guy Wolf",
      "Maximilian Nickel",
      "Ian Adelstein",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]