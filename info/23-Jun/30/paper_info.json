[
  {
    "id": "arXiv:2306.16495",
    "title": "Event Detection from Social Media Stream: Methods, Datasets and  Opportunities",
    "abstract": "Social media streams contain large and diverse amount of information, ranging from daily-life stories to the latest global and local events and news. Twitter, especially, allows a fast spread of events happening real time, and enables individuals and organizations to stay informed of the events happening now. Event detection from social media data poses different challenges from traditional text and is a research area that has attracted much attention in recent years. In this paper, we survey a wide range of event detection methods for Twitter data stream, helping readers understand the recent development in this area. We present the datasets available to the public. Furthermore, a few research opportunities ",
    "url": "https://arxiv.org/abs/2306.16495",
    "authors": [
      "Quanzhi Li",
      "Yang Chao",
      "Dong Li",
      "Yao Lu",
      "Chi Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.16506",
    "title": "Equivariant Neural Networks for Indirect Measurements",
    "abstract": "In the recent years, deep learning techniques have shown great success in various tasks related to inverse problems, where a target quantity of interest can only be observed through indirect measurements by a forward operator. Common approaches apply deep neural networks in a post-processing step to the reconstructions obtained by classical reconstruction methods. However, the latter methods can be computationally expensive and introduce artifacts that are not present in the measured data and, in turn, can deteriorate the performance on the given task. To overcome these limitations, we propose a class of equivariant neural networks that can be directly applied to the measurements to solve the desired task. To this end, we build appropriate network structures by developing layers that are equivariant with respect to data transformations induced by well-known symmetries in the domain of the forward operator. We rigorously analyze the relation between the measurement operator and the resulting group representations and prove a representer theorem that characterizes the class of linear operators that translate between a given pair of group actions. Based on this theory, we extend the existing concepts of Lie group equivariant deep learning to inverse problems and introduce new representations that result from the involved measurement operations. This allows us to efficiently solve classification, regression or even reconstruction tasks based on indirect measurements also for very sparse data problems, where a classical reconstruction-based approach may be hard or even impossible. We illustrate the effectiveness of our approach in numerical experiments and compare with existing methods. ",
    "url": "https://arxiv.org/abs/2306.16506",
    "authors": [
      "Matthias Beckmann",
      "Nick Heilenk\u00f6tter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2306.16524",
    "title": "HNO: Hyena Neural Operator for solving PDEs",
    "abstract": "Numerically solving partial differential equations (PDEs) typically requires fine discretization to resolve necessary spatiotemporal scales, which can be computationally expensive. Recent advances in deep learning have provided a new approach to solving PDEs that involves the use of neural operators. Neural operators are neural network architectures that learn mappings between function spaces and have the capability to solve partial differential equations based on data. This study utilizes a novel neural operator called Hyena, which employs a long convolutional filter that is parameterized by a multilayer perceptron. The Hyena operator is an operation that enjoys sub-quadratic complexity and state space model to parameterize long convolution that enjoys global receptive field. This mechanism enhances the model's comprehension of the input's context and enables data-dependent weight for different PDE instances. To measure how effective the layers are in solving PDEs, we conduct experiments on Burger's equation and Navier Stokes equation. Our findings indicate Hyena Neural operator can serve as an efficient and accurate model for learning PDEs' solution operator. The data and code used can be found at: https://github.com/Saupatil07/Hyena-Neural-Operator ",
    "url": "https://arxiv.org/abs/2306.16524",
    "authors": [
      "Saurabh Patil",
      "Zijie Li",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.16531",
    "title": "Prediction of Rapid Early Progression and Survival Risk with  Pre-Radiation MRI in WHO Grade 4 Glioma Patients",
    "abstract": "Recent clinical research describes a subset of glioblastoma patients that exhibit REP prior to start of radiation therapy. Current literature has thus far described this population using clinicopathologic features. To our knowledge, this study is the first to investigate the potential of conventional ra-diomics, sophisticated multi-resolution fractal texture features, and different molecular features (MGMT, IDH mutations) as a diagnostic and prognostic tool for prediction of REP from non-REP cases using computational and statistical modeling methods. Radiation-planning T1 post-contrast (T1C) MRI sequences of 70 patients are analyzed. Ensemble method with 5-fold cross validation over 1000 iterations offers AUC of 0.793 with standard deviation of 0.082 for REP and non-REP classification. In addition, copula-based modeling under dependent censoring (where a subset of the patients may not be followed up until death) identifies significant features (p-value <0.05) for survival probability and prognostic grouping of patient cases. The prediction of survival for the patients cohort produces precision of 0.881 with standard deviation of 0.056. The prognostic index (PI) calculated using the fused features suggests that 84.62% of REP cases fall under the bad prognostic group, suggesting potentiality of fused features to predict a higher percentage of REP cases. The experimental result further shows that mul-ti-resolution fractal texture features perform better than conventional radiomics features for REP and survival outcomes. ",
    "url": "https://arxiv.org/abs/2306.16531",
    "authors": [
      "Walia Farzana",
      "Mustafa M Basree",
      "Norou Diawara",
      "Zeina A. Shboul",
      "Sagel Dubey",
      "Marie M Lockhart",
      "Mohamed Hamza",
      "Joshua D. Palmer",
      "Khan M. Iftekharuddin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16539",
    "title": "A systematic study of the foreground-background imbalance problem in  deep learning for object detection",
    "abstract": "The class imbalance problem in deep learning has been explored in several studies, but there has yet to be a systematic analysis of this phenomenon in object detection. Here, we present comprehensive analyses and experiments of the foreground-background (F-B) imbalance problem in object detection, which is very common and caused by small, infrequent objects of interest. We experimentally study the effects of different aspects of F-B imbalance (object size, number of objects, dataset size, object type) on detection performance. In addition, we also compare 9 leading methods for addressing this problem, including Faster-RCNN, SSD, OHEM, Libra-RCNN, Focal-Loss, GHM, PISA, YOLO-v3, and GFL with a range of datasets from different imaging domains. We conclude that (1) the F-B imbalance can indeed cause a significant drop in detection performance, (2) The detection performance is more affected by F-B imbalance when fewer training data are available, (3) in most cases, decreasing object size leads to larger performance drop than decreasing number of objects, given the same change in the ratio of object pixels to non-object pixels, (6) among all selected methods, Libra-RCNN and PISA demonstrate the best performance in addressing the issue of F-B imbalance. (7) When the training dataset size is large, the choice of method is not impactful (8) Soft-sampling methods, including focal-loss, GHM, and GFL, perform fairly well on average but are relatively unstable. ",
    "url": "https://arxiv.org/abs/2306.16539",
    "authors": [
      "Hanxue Gu",
      "Haoyu Dong",
      "Nicholas Konz",
      "Maciej A. Mazurowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16557",
    "title": "Non-Convex Optimizations for Machine Learning with Theoretical  Guarantee: Robust Matrix Completion and Neural Network Learning",
    "abstract": "Despite the recent development in machine learning, most learning systems are still under the concept of \"black box\", where the performance cannot be understood and derived. With the rise of safety and privacy concerns in public, designing an explainable learning system has become a new trend in machine learning. In general, many machine learning problems are formulated as minimizing (or maximizing) some loss function. Since real data are most likely generated from non-linear models, the loss function is non-convex in general. Unlike the convex optimization problem, gradient descent algorithms will be trapped in spurious local minima in solving non-convex optimization. Therefore, it is challenging to provide explainable algorithms when studying non-convex optimization problems. In this thesis, two popular non-convex problems are studied: (1) low-rank matrix completion and (2) neural network learning. ",
    "url": "https://arxiv.org/abs/2306.16557",
    "authors": [
      "Shuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.16568",
    "title": "Early warning signals for predicting cryptomarket vendor success using  dark net forum networks",
    "abstract": "In this work we focus on identifying key players in dark net cryptomarkets. Law enforcement aims to disrupt criminal activity conducted through these markets by targeting key players vital to the market's existence and success. We particularly focus on detecting successful vendors responsible for the majority of illegal trade. Our methodology aims to uncover whether the task of key player identification should center around plainly measuring user and forum activity, or that it requires leveraging specific patterns of user communication. We focus on a large-scale dataset from the Evolution cryptomarket, which we model as an evolving communication network. While user and forum activity measures are useful for identifying the most successful vendors, we find that betweenness centrality additionally identifies those with lesser activity. But more importantly, analyzing the forum data over time, we find evidence that attaining a high betweenness score comes before vendor success. This suggests that the proposed network-driven approach of modelling user communication might prove useful as an early warning signal for key player identification. ",
    "url": "https://arxiv.org/abs/2306.16568",
    "authors": [
      "Hanjo D. Boekhout",
      "Arjan A.J. Blokland",
      "Frank W. Takes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.16576",
    "title": "Blockchain in Oil and Gas Supply Chain: A Literature Review from User  Security and Privacy Perspective",
    "abstract": "Blockchain's influence extends beyond finance, impacting diverse sectors such as real estate, oil and gas, and education. This extensive reach stems from blockchain's intrinsic ability to reliably manage digital transactions and supply chains. Within the oil and gas sector, the merger of blockchain with supply chain management and data handling is a notable trend. The supply chain encompasses several operations: extraction, transportation, trading, and distribution of resources. Unfortunately, the current supply chain structure misses critical features such as transparency, traceability, flexible trading, and secure data storage - all of which blockchain can provide. Nevertheless, it is essential to investigate blockchain's security and privacy in the oil and gas industry. Such scrutiny enables the smooth, secure, and usable execution of transactions. For this purpose, we reviewed 124 peer-reviewed academic publications, conducting an in-depth analysis of 21 among them. We classified the articles by their relevance to various phases of the supply chain flow: upstream, midstream, downstream, and data management. Despite blockchain's potential to address existing security and privacy voids in the supply chain, there is a significant lack of practical implementation of blockchain integration in oil and gas operations. This deficiency substantially challenges the transition from conventional methods to a blockchain-centric approach. ",
    "url": "https://arxiv.org/abs/2306.16576",
    "authors": [
      "Urvashi Kishnani",
      "Srinidhi Madabhushi",
      "Sanchari Das"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2306.16577",
    "title": "Evaluating the Task Generalization of Temporal Convolutional Networks  for Surgical Gesture and Motion Recognition using Kinematic Data",
    "abstract": "Fine-grained activity recognition enables explainable analysis of procedures for skill assessment, autonomy, and error detection in robot-assisted surgery. However, existing recognition models suffer from the limited availability of annotated datasets with both kinematic and video data and an inability to generalize to unseen subjects and tasks. Kinematic data from the surgical robot is particularly critical for safety monitoring and autonomy, as it is unaffected by common camera issues such as occlusions and lens contamination. We leverage an aggregated dataset of six dry-lab surgical tasks from a total of 28 subjects to train activity recognition models at the gesture and motion primitive (MP) levels and for separate robotic arms using only kinematic data. The models are evaluated using the LOUO (Leave-One-User-Out) and our proposed LOTO (Leave-One-Task-Out) cross validation methods to assess their ability to generalize to unseen users and tasks respectively. Gesture recognition models achieve higher accuracies and edit scores than MP recognition models. But, using MPs enables the training of models that can generalize better to unseen tasks. Also, higher MP recognition accuracy can be achieved by training separate models for the left and right robot arms. For task-generalization, MP recognition models perform best if trained on similar tasks and/or tasks from the same dataset. ",
    "url": "https://arxiv.org/abs/2306.16577",
    "authors": [
      "Kay Hutchinson",
      "Ian Reyes",
      "Zongyu Li",
      "Homa Alemzadeh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.16581",
    "title": "Does Saliency-Based Training bring Robustness for Deep Neural Networks  in Image Classification?",
    "abstract": "Deep Neural Networks are powerful tools to understand complex patterns and making decisions. However, their black-box nature impedes a complete understanding of their inner workings. While online saliency-guided training methods try to highlight the prominent features in the model's output to alleviate this problem, it is still ambiguous if the visually explainable features align with robustness of the model against adversarial examples. In this paper, we investigate the saliency trained model's vulnerability to adversarial examples methods. Models are trained using an online saliency-guided training method and evaluated against popular algorithms of adversarial examples. We quantify the robustness and conclude that despite the well-explained visualizations in the model's output, the salient models suffer from the lower performance against adversarial examples attacks. ",
    "url": "https://arxiv.org/abs/2306.16581",
    "authors": [
      "Ali Karkehabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16585",
    "title": "SeMLaPS: Real-time Semantic Mapping with Latent Prior Networks and  Quasi-Planar Segmentation",
    "abstract": "The availability of real-time semantics greatly improves the core geometric functionality of SLAM systems, enabling numerous robotic and AR/VR applications. We present a new methodology for real-time semantic mapping from RGB-D sequences that combines a 2D neural network and a 3D network based on a SLAM system with 3D occupancy mapping. When segmenting a new frame we perform latent feature re-projection from previous frames based on differentiable rendering. Fusing re-projected feature maps from previous frames with current-frame features greatly improves image segmentation quality, compared to a baseline that processes images independently. For 3D map processing, we propose a novel geometric quasi-planar over-segmentation method that groups 3D map elements likely to belong to the same semantic classes, relying on surface normals. We also describe a novel neural network design for lightweight semantic map post-processing. Our system achieves state-of-the-art semantic mapping quality within 2D-3D networks-based systems and matches the performance of 3D convolutional networks on three real indoor datasets, while working in real-time. Moreover, it shows better cross-sensor generalization abilities compared to 3D CNNs, enabling training and inference with different depth sensors. Code and data will be released on project page: this http URL ",
    "url": "https://arxiv.org/abs/2306.16585",
    "authors": [
      "Jingwen Wang",
      "Juan Tarrio",
      "Lourdes Agapito",
      "Pablo F. Alcantarilla",
      "Alexander Vakhitov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.16614",
    "title": "Group-based Robustness: A General Framework for Customized Robustness in  the Real World",
    "abstract": "Machine-learning models are known to be vulnerable to evasion attacks that perturb model inputs to induce misclassifications. In this work, we identify real-world scenarios where the true threat cannot be assessed accurately by existing attacks. Specifically, we find that conventional metrics measuring targeted and untargeted robustness do not appropriately reflect a model's ability to withstand attacks from one set of source classes to another set of target classes. To address the shortcomings of existing methods, we formally define a new metric, termed group-based robustness, that complements existing metrics and is better-suited for evaluating model performance in certain attack scenarios. We show empirically that group-based robustness allows us to distinguish between models' vulnerability against specific threat models in situations where traditional robustness metrics do not apply. Moreover, to measure group-based robustness efficiently and accurately, we 1) propose two loss functions and 2) identify three new attack strategies. We show empirically that with comparable success rates, finding evasive samples using our new loss functions saves computation by a factor as large as the number of targeted classes, and finding evasive samples using our new attack strategies saves time by up to 99\\% compared to brute-force search methods. Finally, we propose a defense method that increases group-based robustness by up to 3.52$\\times$. ",
    "url": "https://arxiv.org/abs/2306.16614",
    "authors": [
      "Weiran Lin",
      "Keane Lucas",
      "Neo Eyal",
      "Lujo Bauer",
      "Michael K. Reiter",
      "Mahmood Sharif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16615",
    "title": "Representation learning of vertex heatmaps for 3D human mesh  reconstruction from multi-view images",
    "abstract": "This study addresses the problem of 3D human mesh reconstruction from multi-view images. Recently, approaches that directly estimate the skinned multi-person linear model (SMPL)-based human mesh vertices based on volumetric heatmap representation from input images have shown good performance. We show that representation learning of vertex heatmaps using an autoencoder helps improve the performance of such approaches. Vertex heatmap autoencoder (VHA) learns the manifold of plausible human meshes in the form of latent codes using AMASS, which is a large-scale motion capture dataset. Body code predictor (BCP) utilizes the learned body prior from VHA for human mesh reconstruction from multi-view images through latent code-based supervision and transfer of pretrained weights. According to experiments on Human3.6M and LightStage datasets, the proposed method outperforms previous methods and achieves state-of-the-art human mesh reconstruction performance. ",
    "url": "https://arxiv.org/abs/2306.16615",
    "authors": [
      "Sungho Chun",
      "Sungbum Park",
      "Ju Yong Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16624",
    "title": "Streaming phishing scam detection method on Ethereum",
    "abstract": "Phishing is a widespread scam activity on Ethereum, causing huge financial losses to victims. Most existing phishing scam detection methods abstract accounts on Ethereum as nodes and transactions as edges, then use manual statistics of static node features to obtain node embedding and finally identify phishing scams through classification models. However, these methods can not dynamically learn new Ethereum transactions. Since the phishing scams finished in a short time, a method that can detect phishing scams in real-time is needed. In this paper, we propose a streaming phishing scam detection method. To achieve streaming detection and capture the dynamic changes of Ethereum transactions, we first abstract transactions into edge features instead of node features, and then design a broadcast mechanism and a storage module, which integrate historical transaction information and neighbor transaction information to strengthen the node embedding. Finally, the node embedding can be learned from the storage module and the previous node embedding. Experimental results show that our method achieves decent performance on the Ethereum phishing scam detection task. ",
    "url": "https://arxiv.org/abs/2306.16624",
    "authors": [
      "Wenjia Yu",
      "Yijun Xia",
      "Jieli Liu",
      "Jiajing Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.16635",
    "title": "Improving Fairness in Deepfake Detection",
    "abstract": "Despite the development of effective deepfake detection models in recent years, several recent studies have demonstrated that biases in the training data utilized to develop deepfake detection models can lead to unfair performance for demographic groups of different races and/or genders. Such can result in these groups being unfairly targeted or excluded from detection, allowing misclassified deepfakes to manipulate public opinion and erode trust in the model. While these studies have focused on identifying and evaluating the unfairness in deepfake detection, no methods have been developed to address the fairness issue of deepfake detection at the algorithm level. In this work, we make the first attempt to improve deepfake detection fairness by proposing novel loss functions to train fair deepfake detection models in ways that are agnostic or aware of demographic factors. Extensive experiments on four deepfake datasets and five deepfake detectors demonstrate the effectiveness and flexibility of our approach in improving the deepfake detection fairness. ",
    "url": "https://arxiv.org/abs/2306.16635",
    "authors": [
      "Yan Ju",
      "Shu Hu",
      "Shan Jia",
      "George H. Chen",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16638",
    "title": "A negation detection assessment of GPTs: analysis with the xNot360  dataset",
    "abstract": "Negation is a fundamental aspect of natural language, playing a critical role in communication and comprehension. Our study assesses the negation detection performance of Generative Pre-trained Transformer (GPT) models, specifically GPT-2, GPT-3, GPT-3.5, and GPT-4. We focus on the identification of negation in natural language using a zero-shot prediction approach applied to our custom xNot360 dataset. Our approach examines sentence pairs labeled to indicate whether the second sentence negates the first. Our findings expose a considerable performance disparity among the GPT models, with GPT-4 surpassing its counterparts and GPT-3.5 displaying a marked performance reduction. The overall proficiency of the GPT models in negation detection remains relatively modest, indicating that this task pushes the boundaries of their natural language understanding capabilities. We not only highlight the constraints of GPT models in handling negation but also emphasize the importance of logical reliability in high-stakes domains such as healthcare, science, and law. ",
    "url": "https://arxiv.org/abs/2306.16638",
    "authors": [
      "Ha Thanh Nguyen",
      "Randy Goebel",
      "Francesca Toni",
      "Kostas Stathis",
      "Ken Satoh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.16644",
    "title": "Probabilistic Linguistic Knowledge and Token-level Text Augmentation",
    "abstract": "This paper investigates the effectiveness of token-level text augmentation and the role of probabilistic linguistic knowledge within a linguistically-motivated evaluation context. Two text augmentation programs, REDA and REDA$_{NG}$, were developed, both implementing five token-level text editing operations: Synonym Replacement (SR), Random Swap (RS), Random Insertion (RI), Random Deletion (RD), and Random Mix (RM). REDA$_{NG}$ leverages pretrained $n$-gram language models to select the most likely augmented texts from REDA's output. Comprehensive and fine-grained experiments were conducted on a binary question matching classification task in both Chinese and English. The results strongly refute the general effectiveness of the five token-level text augmentation techniques under investigation, whether applied together or separately, and irrespective of various common classification model types used, including transformers. Furthermore, the role of probabilistic linguistic knowledge is found to be minimal. ",
    "url": "https://arxiv.org/abs/2306.16644",
    "authors": [
      "Zhengxiang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.16648",
    "title": "Private Covariance Approximation and Eigenvalue-Gap Bounds for Complex  Gaussian Perturbations",
    "abstract": "We consider the problem of approximating a $d \\times d$ covariance matrix $M$ with a rank-$k$ matrix under $(\\varepsilon,\\delta)$-differential privacy. We present and analyze a complex variant of the Gaussian mechanism and show that the Frobenius norm of the difference between the matrix output by this mechanism and the best rank-$k$ approximation to $M$ is bounded by roughly $\\tilde{O}(\\sqrt{kd})$, whenever there is an appropriately large gap between the $k$'th and the $k+1$'th eigenvalues of $M$. This improves on previous work that requires that the gap between every pair of top-$k$ eigenvalues of $M$ is at least $\\sqrt{d}$ for a similar bound. Our analysis leverages the fact that the eigenvalues of complex matrix Brownian motion repel more than in the real case, and uses Dyson's stochastic differential equations governing the evolution of its eigenvalues to show that the eigenvalues of the matrix $M$ perturbed by complex Gaussian noise have large gaps with high probability. Our results contribute to the analysis of low-rank approximations under average-case perturbations and to an understanding of eigenvalue gaps for random matrices, which may be of independent interest. ",
    "url": "https://arxiv.org/abs/2306.16648",
    "authors": [
      "Oren Mangoubi",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2306.16660",
    "title": "Real-Time Fully Unsupervised Domain Adaptation for Lane Detection in  Autonomous Driving",
    "abstract": "While deep neural networks are being utilized heavily for autonomous driving, they need to be adapted to new unseen environmental conditions for which they were not trained. We focus on a safety critical application of lane detection, and propose a lightweight, fully unsupervised, real-time adaptation approach that only adapts the batch-normalization parameters of the model. We demonstrate that our technique can perform inference, followed by on-device adaptation, under a tight constraint of 30 FPS on Nvidia Jetson Orin. It shows similar accuracy (avg. of 92.19%) as a state-of-the-art semi-supervised adaptation algorithm but which does not support real-time adaptation. ",
    "url": "https://arxiv.org/abs/2306.16660",
    "authors": [
      "Kshitij Bhardwaj",
      "Zishen Wan",
      "Arijit Raychowdhury",
      "Ryan Goldhahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.16665",
    "title": "OpenPARF: An Open-Source Placement and Routing Framework for Large-Scale  Heterogeneous FPGAs with Deep Learning Toolkit",
    "abstract": "This paper proposes OpenPARF, an open-source placement and routing framework for large-scale FPGA designs. OpenPARF is implemented with the deep learning toolkit PyTorch and supports massive parallelization on GPU. The framework proposes a novel asymmetric multi-electrostatic field system to solve FPGA placement. It considers fine-grained routing resources inside configurable logic blocks (CLBs) for FPGA routing and supports large-scale irregular routing resource graphs. Experimental results on ISPD 2016 and ISPD 2017 FPGA contest benchmarks and industrial benchmarks demonstrate that OpenPARF can achieve 0.4-12.7% improvement in routed wirelength and more than $2\\times$ speedup in placement. We believe that OpenPARF can pave the road for developing FPGA physical design engines and stimulate further research on related topics. ",
    "url": "https://arxiv.org/abs/2306.16665",
    "authors": [
      "Jing Mai",
      "Jiarui Wang",
      "Zhixiong Di",
      "Guojie Luo",
      "Yun Liang",
      "Yibo Lin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2306.16666",
    "title": "Game Level Blending using a Learned Level Representation",
    "abstract": "Game level blending via machine learning, the process of combining features of game levels to create unique and novel game levels using Procedural Content Generation via Machine Learning (PCGML) techniques, has gained increasing popularity in recent years. However, many existing techniques rely on human-annotated level representations, which limits game level blending to a limited number of annotated games. Even with annotated games, researchers often need to author an additional shared representation to make blending possible. In this paper, we present a novel approach to game level blending that employs Clustering-based Tile Embeddings (CTE), a learned level representation technique that can serve as a level representation for unannotated games and a unified level representation across games without the need for human annotation. CTE represents game level tiles as a continuous vector representation, unifying their visual, contextual, and behavioral information. We apply this approach to two classic Nintendo games, Lode Runner and The Legend of Zelda. We run an evaluation comparing the CTE representation to a common, human-annotated representation in the blending task and find that CTE has comparable or better performance without the need for human annotation. ",
    "url": "https://arxiv.org/abs/2306.16666",
    "authors": [
      "Venkata Sai Revanth Atmakuri",
      "Seth Cooper",
      "Matthew Guzdial"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16671",
    "title": "Entanglement Routing over Quantum Networks Using  Greenberger-Horne-Zeilinger Measurements",
    "abstract": "Generating a long-distance quantum entanglement is one of the most essential functions of a quantum network to support quantum communication and computing applications. The successful entanglement rate during a probabilistic entanglement process decreases dramatically with distance, and swapping is a widely-applied quantum technique to address this issue. Most existing entanglement routing protocols use a classic entanglement-swapping method based on Bell State measurements that can only fuse two successful entanglement links. This paper appeals to a more general and efficient swapping method, namely n-fusion based on Greenberger-Horne-Zeilinger measurements that can fuse n successful entanglement links, to maximize the entanglement rate for multiple quantum-user pairs over a quantum network. We propose efficient entanglement routing algorithms that utilize the properties of n-fusion for quantum networks with general topologies. Evaluation results highlight that our proposed algorithm under n-fusion can greatly improve the network performance compared with existing ones. ",
    "url": "https://arxiv.org/abs/2306.16671",
    "authors": [
      "Yiming Zeng",
      "Jiarui Zhang",
      "Ji Liu",
      "Zhenhua Liu",
      "Yuanyuan Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.16672",
    "title": "Towards understanding the performance of IEEE 802.11 MAC in  heterogeneous traffic conditions",
    "abstract": "Motivated by the need to study the performance of vehicular communication protocols as applicable to heterogeneous traffic conditions, we study the performance of IEEE 802.11p medium access protocol under such a traffic setup. We consider a setup comprising connected vehicles and human-driven Motorised Two Wheelers (MTWs), where the connected vehicles are required to move as platoon with a desired constant headway despite interruptions from the two wheelers. We invoke specific mobility models for the movement of the vehicles--car following models for connected vehicle platoons and gap-acceptance model to capture the movement of the MTWs--and use them to configure (i) the traffic setup and (ii) the rate at which data packets related to safety-critical messages need to be transmitted. A control-theoretic analysis of the car-following models yields a bound on the admissible communication delay to ensure non-oscillatory convergence of the platoon headway. We then use suitable Markov chain models to derive the distribution of the MAC access delay experienced by packets pertaining to safety-critical events as well as routine safety messages. The distribution along with the bound on the admissible delay enables us to derive the reliability of the 802.11p MAC protocol in terms of traffic and EDCA parameters. Our study highlights the need for redesign of MAC protocols for vehicular communications for safety-critical applications in heterogeneous conditions. ",
    "url": "https://arxiv.org/abs/2306.16672",
    "authors": [
      "MS Gayathree",
      "Sreelakshmi Manjunath"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.16674",
    "title": "Online learning for robust voltage control under uncertain grid topology",
    "abstract": "Voltage control generally requires accurate information about the grid's topology in order to guarantee network stability. However, accurate topology identification is challenging for existing methods, especially as the grid is subject to increasingly frequent reconfiguration due to the adoption of renewable energy. Further, running existing control mechanisms with incorrect network information may lead to unstable control. In this work, we combine a nested convex body chasing algorithm with a robust predictive controller to achieve provably finite-time convergence to safe voltage limits in the online setting where the network topology is initially unknown. Specifically, the online controller does not know the true network topology and line parameters, but instead learns them over time by narrowing down the set of network topologies and line parameters that are consistent with its observations and adjusting reactive power generation accordingly to keep voltages within desired safety limits. We demonstrate the effectiveness of our approach in a case study on a Southern California Edison 56-bus distribution system. Our experiments show that in practical settings, the controller is indeed able to narrow the set of consistent topologies quickly enough to make control decisions that ensure stability in both linearized and realistic non-linear models of the distribution grid. ",
    "url": "https://arxiv.org/abs/2306.16674",
    "authors": [
      "Christopher Yeh",
      "Jing Yu",
      "Yuanyuan Shi",
      "Adam Wierman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2306.16675",
    "title": "A Survey on Enterprise Network Security: Asset Behavioral Monitoring and  Distributed Attack Detection",
    "abstract": "Enterprise networks that host valuable assets and services are popular and frequent targets of distributed network attacks. In order to cope with the ever-increasing threats, industrial and research communities develop systems and methods to monitor the behaviors of their assets and protect them from critical attacks. In this paper, we systematically survey related research articles and industrial systems to highlight the current status of this arms race in enterprise network security. First, we discuss the taxonomy of distributed network attacks on enterprise assets, including distributed denial-of-service (DDoS) and reconnaissance attacks. Second, we review existing methods in monitoring and classifying network behavior of enterprise hosts to verify their benign activities and isolate potential anomalies. Third, state-of-the-art detection methods for distributed network attacks sourced from external attackers are elaborated, highlighting their merits and bottlenecks. Fourth, as programmable networks and machine learning (ML) techniques are increasingly becoming adopted by the community, their current applications in network security are discussed. Finally, we highlight several research gaps on enterprise network security to inspire future research. ",
    "url": "https://arxiv.org/abs/2306.16675",
    "authors": [
      "Minzhao Lyu",
      "Hassan Habibi Gharakheili",
      "Vijay Sivaraman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.16678",
    "title": "BinaryViT: Pushing Binary Vision Transformers Towards Convolutional  Models",
    "abstract": "With the increasing popularity and the increasing size of vision transformers (ViTs), there has been an increasing interest in making them more efficient and less computationally costly for deployment on edge devices with limited computing resources. Binarization can be used to help reduce the size of ViT models and their computational cost significantly, using popcount operations when the weights and the activations are in binary. However, ViTs suffer a larger performance drop when directly applying convolutional neural network (CNN) binarization methods or existing binarization methods to binarize ViTs compared to CNNs on datasets with a large number of classes such as ImageNet-1k. With extensive analysis, we find that binary vanilla ViTs such as DeiT miss out on a lot of key architectural properties that CNNs have that allow binary CNNs to have much higher representational capability than binary vanilla ViT. Therefore, we propose BinaryViT, in which inspired by the CNN architecture, we include operations from the CNN architecture into a pure ViT architecture to enrich the representational capability of a binary ViT without introducing convolutions. These include an average pooling layer instead of a token pooling layer, a block that contains multiple average pooling branches, an affine transformation right before the addition of each main residual connection, and a pyramid structure. Experimental results on the ImageNet-1k dataset show the effectiveness of these operations that allow a binary pure ViT model to be competitive with previous state-of-the-art (SOTA) binary CNN models. ",
    "url": "https://arxiv.org/abs/2306.16678",
    "authors": [
      "Phuoc-Hoan Charles Le",
      "Xinlin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16680",
    "title": "Exploring the Representation Power of SPLADE Models",
    "abstract": "The SPLADE (SParse Lexical AnD Expansion) model is a highly effective approach to learned sparse retrieval, where documents are represented by term impact scores derived from large language models. During training, SPLADE applies regularization to ensure postings lists are kept sparse -- with the aim of mimicking the properties of natural term distributions -- allowing efficient and effective lexical matching and ranking. However, we hypothesize that SPLADE may encode additional signals into common postings lists to further improve effectiveness. To explore this idea, we perform a number of empirical analyses where we re-train SPLADE with different, controlled vocabularies and measure how effective it is at ranking passages. Our findings suggest that SPLADE can effectively encode useful ranking signals in documents even when the vocabulary is constrained to terms that are not traditionally useful for ranking, such as stopwords or even random words. ",
    "url": "https://arxiv.org/abs/2306.16680",
    "authors": [
      "Joel Mackenzie",
      "Shengyao Zhuang",
      "Guido Zuccon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.16684",
    "title": "Decomposing spiking neural networks with Graphical Neural Activity  Threads",
    "abstract": "A satisfactory understanding of information processing in spiking neural networks requires appropriate computational abstractions of neural activity. Traditionally, the neural population state vector has been the most common abstraction applied to spiking neural networks, but this requires artificially partitioning time into bins that are not obviously relevant to the network itself. We introduce a distinct set of techniques for analyzing spiking neural networks that decomposes neural activity into multiple, disjoint, parallel threads of activity. We construct these threads by estimating the degree of causal relatedness between pairs of spikes, then use these estimates to construct a directed acyclic graph that traces how the network activity evolves through individual spikes. We find that this graph of spiking activity naturally decomposes into disjoint connected components that overlap in space and time, which we call Graphical Neural Activity Threads (GNATs). We provide an efficient algorithm for finding analogous threads that reoccur in large spiking datasets, revealing that seemingly distinct spike trains are composed of similar underlying threads of activity, a hallmark of compositionality. The picture of spiking neural networks provided by our GNAT analysis points to new abstractions for spiking neural computation that are naturally adapted to the spatiotemporally distributed dynamics of spiking neural networks. ",
    "url": "https://arxiv.org/abs/2306.16684",
    "authors": [
      "Bradley H. Theilman",
      "Felix Wang",
      "Fred Rothganger",
      "James B. Aimone"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.16694",
    "title": "Gaussian Data Privacy Under Linear Function Recoverability",
    "abstract": "A user's data is represented by a Gaussian random variable. Given a linear function of the data, a querier is required to recover, with at least a prescribed accuracy level, the function value based on a query response provided by the user. The user devises the query response, subject to the recoverability requirement, so as to maximize privacy of the data from the querier. Recoverability and privacy are both measured by $\\ell_2$-distance criteria. An exact characterization is provided of maximum user data privacy under the recoverability condition. An explicit optimal achievability scheme for the user is given whose privacy is shown to match a converse upper bound. ",
    "url": "https://arxiv.org/abs/2306.16694",
    "authors": [
      "Ajaykrishnan Nageswaran"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2306.16697",
    "title": "Neural Polarizer: A Lightweight and Effective Backdoor Defense via  Purifying Poisoned Features",
    "abstract": "Recent studies have demonstrated the susceptibility of deep neural networks to backdoor attacks. Given a backdoored model, its prediction of a poisoned sample with trigger will be dominated by the trigger information, though trigger information and benign information coexist. Inspired by the mechanism of the optical polarizer that a polarizer could pass light waves with particular polarizations while filtering light waves with other polarizations, we propose a novel backdoor defense method by inserting a learnable neural polarizer into the backdoored model as an intermediate layer, in order to purify the poisoned sample via filtering trigger information while maintaining benign information. The neural polarizer is instantiated as one lightweight linear transformation layer, which is learned through solving a well designed bi-level optimization problem, based on a limited clean dataset. Compared to other fine-tuning-based defense methods which often adjust all parameters of the backdoored model, the proposed method only needs to learn one additional layer, such that it is more efficient and requires less clean data. Extensive experiments demonstrate the effectiveness and efficiency of our method in removing backdoors across various neural network architectures and datasets, especially in the case of very limited clean data. ",
    "url": "https://arxiv.org/abs/2306.16697",
    "authors": [
      "Mingli Zhu",
      "Shaokui Wei",
      "Hongyuan Zha",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.16699",
    "title": "Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural  Representation",
    "abstract": "Implicit Neural Representation (INR) is an innovative approach for representing complex shapes or objects without explicitly defining their geometry or surface structure. Instead, INR represents objects as continuous functions. Previous research has demonstrated the effectiveness of using neural networks as INR for image compression, showcasing comparable performance to traditional methods such as JPEG. However, INR holds potential for various applications beyond image compression. This paper introduces Rapid-INR, a novel approach that utilizes INR for encoding and compressing images, thereby accelerating neural network training in computer vision tasks. Our methodology involves storing the whole dataset directly in INR format on a GPU, mitigating the significant data communication overhead between the CPU and GPU during training. Additionally, the decoding process from INR to RGB format is highly parallelized and executed on-the-fly. To further enhance compression, we propose iterative and dynamic pruning, as well as layer-wise quantization, building upon previous work. We evaluate our framework on the image classification task, utilizing the ResNet-18 backbone network and three commonly used datasets with varying image sizes. Rapid-INR reduces memory consumption to only 5% of the original dataset size and achieves a maximum 6$\\times$ speedup over the PyTorch training pipeline, as well as a maximum 1.2x speedup over the DALI training pipeline, with only a marginal decrease in accuracy. Importantly, Rapid-INR can be readily applied to other computer vision tasks and backbone networks with reasonable engineering efforts. Our implementation code is publicly available at https://anonymous.4open.science/r/INR-4BF7. ",
    "url": "https://arxiv.org/abs/2306.16699",
    "authors": [
      "Hanqiu Chen",
      "Hang Yang",
      "Stephen BR Fitzmeyer",
      "Cong Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16713",
    "title": "Answer Mining from a Pool of Images: Towards Retrieval-Based Visual  Question Answering",
    "abstract": "We study visual question answering in a setting where the answer has to be mined from a pool of relevant and irrelevant images given as a context. For such a setting, a model must first retrieve relevant images from the pool and answer the question from these retrieved images. We refer to this problem as retrieval-based visual question answering (or RETVQA in short). The RETVQA is distinctively different and more challenging than the traditionally-studied Visual Question Answering (VQA), where a given question has to be answered with a single relevant image in context. Towards solving the RETVQA task, we propose a unified Multi Image BART (MI-BART) that takes a question and retrieved images using our relevance encoder for free-form fluent answer generation. Further, we introduce the largest dataset in this space, namely RETVQA, which has the following salient features: multi-image and retrieval requirement for VQA, metadata-independent questions over a pool of heterogeneous images, expecting a mix of classification-oriented and open-ended generative answers. Our proposed framework achieves an accuracy of 76.5% and a fluency of 79.3% on the proposed dataset, namely RETVQA and also outperforms state-of-the-art methods by 4.9% and 11.8% on the image segment of the publicly available WebQA dataset on the accuracy and fluency metrics, respectively. ",
    "url": "https://arxiv.org/abs/2306.16713",
    "authors": [
      "Abhirama Subramanyam Penamakuri",
      "Manish Gupta",
      "Mithun Das Gupta",
      "Anand Mishra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16718",
    "title": "Metric-aligned Sample Selection and Critical Feature Sampling for  Oriented Object Detection",
    "abstract": "Arbitrary-oriented object detection is a relatively emerging but challenging task. Although remarkable progress has been made, there still remain many unsolved issues due to the large diversity of patterns in orientation, scale, aspect ratio, and visual appearance of objects in aerial images. Most of the existing methods adopt a coarse-grained fixed label assignment strategy and suffer from the inconsistency between the classification score and localization accuracy. First, to align the metric inconsistency between sample selection and regression loss calculation caused by fixed IoU strategy, we introduce affine transformation to evaluate the quality of samples and propose a distance-based label assignment strategy. The proposed metric-aligned selection (MAS) strategy can dynamically select samples according to the shape and rotation characteristic of objects. Second, to further address the inconsistency between classification and localization, we propose a critical feature sampling (CFS) module, which performs localization refinement on the sampling location for classification task to extract critical features accurately. Third, we present a scale-controlled smooth $L_1$ loss (SC-Loss) to adaptively select high quality samples by changing the form of regression loss function based on the statistics of proposals during training. Extensive experiments are conducted on four challenging rotated object detection datasets DOTA, FAIR1M-1.0, HRSC2016, and UCAS-AOD. The results show the state-of-the-art accuracy of the proposed detector. ",
    "url": "https://arxiv.org/abs/2306.16718",
    "authors": [
      "Peng Sun",
      "Yongbin Zheng",
      "Wenqi Wu",
      "Wanying Xu",
      "Shengjian Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16722",
    "title": "Evaluating Paraphrastic Robustness in Textual Entailment Models",
    "abstract": "We present PaRTE, a collection of 1,126 pairs of Recognizing Textual Entailment (RTE) examples to evaluate whether models are robust to paraphrasing. We posit that if RTE models understand language, their predictions should be consistent across inputs that share the same meaning. We use the evaluation set to determine if RTE models' predictions change when examples are paraphrased. In our experiments, contemporary models change their predictions on 8-16\\% of paraphrased examples, indicating that there is still room for improvement. ",
    "url": "https://arxiv.org/abs/2306.16722",
    "authors": [
      "Dhruv Verma",
      "Yash Kumar Lal",
      "Shreyashee Sinha",
      "Benjamin Van Durme",
      "Adam Poliak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16738",
    "title": "Towards Optimal Randomized Strategies in Adversarial Example Game",
    "abstract": "The vulnerability of deep neural network models to adversarial example attacks is a practical challenge in many artificial intelligence applications. A recent line of work shows that the use of randomization in adversarial training is the key to find optimal strategies against adversarial example attacks. However, in a fully randomized setting where both the defender and the attacker can use randomized strategies, there are no efficient algorithm for finding such an optimal strategy. To fill the gap, we propose the first algorithm of its kind, called FRAT, which models the problem with a new infinite-dimensional continuous-time flow on probability distribution spaces. FRAT maintains a lightweight mixture of models for the defender, with flexibility to efficiently update mixing weights and model parameters at each iteration. Furthermore, FRAT utilizes lightweight sampling subroutines to construct a random strategy for the attacker. We prove that the continuous-time limit of FRAT converges to a mixed Nash equilibria in a zero-sum game formed by a defender and an attacker. Experimental results also demonstrate the efficiency of FRAT on CIFAR-10 and CIFAR-100 datasets. ",
    "url": "https://arxiv.org/abs/2306.16738",
    "authors": [
      "Jiahao Xie",
      "Chao Zhang",
      "Weijie Liu",
      "Wensong Bai",
      "Hui Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2306.16740",
    "title": "Principles and Guidelines for Evaluating Social Robot Navigation  Algorithms",
    "abstract": "A major challenge to deploying robots widely is navigation in human-populated environments, commonly referred to as social robot navigation. While the field of social navigation has advanced tremendously in recent years, the fair evaluation of algorithms that tackle social navigation remains hard because it involves not just robotic agents moving in static environments but also dynamic human agents and their perceptions of the appropriateness of robot behavior. In contrast, clear, repeatable, and accessible benchmarks have accelerated progress in fields like computer vision, natural language processing and traditional robot navigation by enabling researchers to fairly compare algorithms, revealing limitations of existing solutions and illuminating promising new directions. We believe the same approach can benefit social navigation. In this paper, we pave the road towards common, widely accessible, and repeatable benchmarking criteria to evaluate social robot navigation. Our contributions include (a) a definition of a socially navigating robot as one that respects the principles of safety, comfort, legibility, politeness, social competency, agent understanding, proactivity, and responsiveness to context, (b) guidelines for the use of metrics, development of scenarios, benchmarks, datasets, and simulators to evaluate social navigation, and (c) a design of a social navigation metrics framework to make it easier to compare results from different simulators, robots and datasets. ",
    "url": "https://arxiv.org/abs/2306.16740",
    "authors": [
      "Anthony Francis",
      "Claudia Perez-D'Arpino",
      "Chengshu Li",
      "Fei Xia",
      "Alexandre Alahi",
      "Rachid Alami",
      "Aniket Bera",
      "Abhijat Biswas",
      "Joydeep Biswas",
      "Rohan Chandra",
      "Hao-Tien Lewis Chiang",
      "Michael Everett",
      "Sehoon Ha",
      "Justin Hart",
      "Jonathan P. How",
      "Haresh Karnan",
      "Tsang-Wei Edward Lee",
      "Luis J. Manso",
      "Reuth Mirksy",
      "Soeren Pirk",
      "Phani Teja Singamaneni",
      "Peter Stone",
      "Ada V. Taylor",
      "Peter Trautman",
      "Nathan Tsoi",
      "Marynel Vazquez",
      "Xuesu Xiao",
      "Peng Xu",
      "Naoki Yokoyama",
      "Alexander Toshev",
      "Roberto Martin-Martin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16741",
    "title": "Foundation Model for Endoscopy Video Analysis via Large-scale  Self-supervised Pre-train",
    "abstract": "Foundation models have exhibited remarkable success in various applications, such as disease diagnosis and text report generation. To date, a foundation model for endoscopic video analysis is still lacking. In this paper, we propose Endo-FM, a foundation model specifically developed using massive endoscopic video data. First, we build a video transformer, which captures both local and global long-range dependencies across spatial and temporal dimensions. Second, we pre-train our transformer model using global and local views via a self-supervised manner, aiming to make it robust to spatial-temporal variations and discriminative across different scenes. To develop the foundation model, we construct a large-scale endoscopy video dataset by combining 9 publicly available datasets and a privately collected dataset from Baoshan Branch of Renji Hospital in Shanghai, China. Our dataset overall consists of over 33K video clips with up to 5 million frames, encompassing various protocols, target organs, and disease types. Our pre-trained Endo-FM can be easily adopted for a given downtream task via fine-tuning by serving as the backbone. With experiments on 3 different types of downstream tasks, including classification, segmentation, and detection, our Endo-FM surpasses the current state-of-the-art self-supervised pre-training and adapter-based transfer learning methods by a significant margin, such as VCL (3.1% F1 for classification, 4.8% Dice for segmentation, and 5.5% F1 for detection) and ST-Adapter (5.9% F1 for classification, 9.6% Dice for segmentation, and 9.9% F1 for detection). Code, datasets, and models are released at https://github.com/med-air/Endo-FM. ",
    "url": "https://arxiv.org/abs/2306.16741",
    "authors": [
      "Zhao Wang",
      "Chang Liu",
      "Shaoting Zhang",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16762",
    "title": "Unified Language Representation for Question Answering over Text,  Tables, and Images",
    "abstract": "When trying to answer complex questions, people often rely on multiple sources of information, such as visual, textual, and tabular data. Previous approaches to this problem have focused on designing input features or model structure in the multi-modal space, which is inflexible for cross-modal reasoning or data-efficient training. In this paper, we call for an alternative paradigm, which transforms the images and tables into unified language representations, so that we can simplify the task into a simpler textual QA problem that can be solved using three steps: retrieval, ranking, and generation, all within a language space. This idea takes advantage of the power of pre-trained language models and is implemented in a framework called Solar. Our experimental results show that Solar outperforms all existing methods by 10.6-32.3 pts on two datasets, MultimodalQA and MMCoQA, across ten different metrics. Additionally, Solar achieves the best performance on the WebQA leaderboard ",
    "url": "https://arxiv.org/abs/2306.16762",
    "authors": [
      "Bowen Yu",
      "Cheng Fu",
      "Haiyang Yu",
      "Fei Huang",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.16770",
    "title": "DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data  Augmentation in Multi-Turn Conversations",
    "abstract": "In open-domain dialogue generation tasks, contexts and responses in most datasets are one-to-one mapped, violating an important many-to-many characteristic: a context leads to various responses, and a response answers multiple contexts. Without such patterns, models poorly generalize and prefer responding safely. Many attempts have been made in either multi-turn settings from a one-to-many perspective or in a many-to-many perspective but limited to single-turn settings. The major challenge to many-to-many augment multi-turn dialogues is that discretely replacing each turn with semantic similarity breaks fragile context coherence. In this paper, we propose DialoGue Path Sampling (DialoGPS) method in continuous semantic space, the first many-to-many augmentation method for multi-turn dialogues. Specifically, we map a dialogue to our extended Brownian Bridge, a special Gaussian process. We sample latent variables to form coherent dialogue paths in the continuous space. A dialogue path corresponds to a new multi-turn dialogue and is used as augmented training data. We show the effect of DialoGPS with both automatic and human evaluation. ",
    "url": "https://arxiv.org/abs/2306.16770",
    "authors": [
      "Ang Lv",
      "Jinpeng Li",
      "Yuhan Chen",
      "Xing Gao",
      "Ji Zhang",
      "Rui Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16775",
    "title": "Algorithms for Computing Maximum Cliques in Hyperbolic Random Graphs",
    "abstract": "In this paper, we study the maximum clique problem on hyperbolic random graphs. A hyperbolic random graph is a mathematical model for analyzing scale-free networks since it effectively explains the power-law degree distribution of scale-free networks. We propose a simple algorithm for finding a maximum clique in hyperbolic random graph. We first analyze the running time of our algorithm theoretically. We can compute a maximum clique on a hyperbolic random graph $G$ in $O(m + n^{4.5(1-\\alpha)})$ expected time if a geometric representation is given or in $O(m + n^{6(1-\\alpha)})$ expected time if a geometric representation is not given, where $n$ and $m$ denote the numbers of vertices and edges of $G$, respectively, and $\\alpha$ denotes a parameter controlling the power-law exponent of the degree distribution of $G$. Also, we implemented and evaluated our algorithm empirically. Our algorithm outperforms the previous algorithm [BFK18] practically and theoretically. Beyond the hyperbolic random graphs, we have experiment on real-world networks. For most of instances, we get large cliques close to the optimum solutions efficiently. ",
    "url": "https://arxiv.org/abs/2306.16775",
    "authors": [
      "Eunjin Oh",
      "Seunghyeok Oh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.16780",
    "title": "Graph Sampling-based Meta-Learning for Molecular Property Prediction",
    "abstract": "Molecular property is usually observed with a limited number of samples, and researchers have considered property prediction as a few-shot problem. One important fact that has been ignored by prior works is that each molecule can be recorded with several different properties simultaneously. To effectively utilize many-to-many correlations of molecules and properties, we propose a Graph Sampling-based Meta-learning (GS-Meta) framework for few-shot molecular property prediction. First, we construct a Molecule-Property relation Graph (MPG): molecule and properties are nodes, while property labels decide edges. Then, to utilize the topological information of MPG, we reformulate an episode in meta-learning as a subgraph of the MPG, containing a target property node, molecule nodes, and auxiliary property nodes. Third, as episodes in the form of subgraphs are no longer independent of each other, we propose to schedule the subgraph sampling process with a contrastive loss function, which considers the consistency and discrimination of subgraphs. Extensive experiments on 5 commonly-used benchmarks show GS-Meta consistently outperforms state-of-the-art methods by 5.71%-6.93% in ROC-AUC and verify the effectiveness of each proposed module. Our code is available at https://github.com/HICAI-ZJU/GS-Meta. ",
    "url": "https://arxiv.org/abs/2306.16780",
    "authors": [
      "Xiang Zhuang",
      "Qiang Zhang",
      "Bin Wu",
      "Keyan Ding",
      "Yin Fang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2306.16791",
    "title": "Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph  of Empirical Research in Requirements Engineering",
    "abstract": "[Background.] Empirical research in requirements engineering (RE) is a constantly evolving topic, with a growing number of publications. Several papers address this topic using literature reviews to provide a snapshot of its \"current\" state and evolution. However, these papers have never built on or updated earlier ones, resulting in overlap and redundancy. The underlying problem is the unavailability of data from earlier works. Researchers need technical infrastructures to conduct sustainable literature reviews. [Aims.] We examine the use of the Open Research Knowledge Graph (ORKG) as such an infrastructure to build and publish an initial Knowledge Graph of Empirical research in RE (KG-EmpiRE) whose data is openly available. Our long-term goal is to continuously maintain KG-EmpiRE with the research community to synthesize a comprehensive, up-to-date, and long-term available overview of the state and evolution of empirical research in RE. [Method.] We conduct a literature review using the ORKG to build and publish KG-EmpiRE which we evaluate against competency questions derived from a published vision of empirical research in software (requirements) engineering for 2020 - 2025. [Results.] From 570 papers of the IEEE International Requirements Engineering Conference (2000 - 2022), we extract and analyze data on the reported empirical research and answer 16 out of 77 competency questions. These answers show a positive development towards the vision, but also the need for future improvements. [Conclusions.] The ORKG is a ready-to-use and advanced infrastructure to organize data from literature reviews as knowledge graphs. The resulting knowledge graphs make the data openly available and maintainable by research communities, enabling sustainable literature reviews. ",
    "url": "https://arxiv.org/abs/2306.16791",
    "authors": [
      "Oliver Karras",
      "Felix Wernlein",
      "Jil Kl\u00fcnder",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2306.16798",
    "title": "Evaluation of Environmental Conditions on Object Detection using  Oriented Bounding Boxes for AR Applications",
    "abstract": "The objective of augmented reality (AR) is to add digital content to natural images and videos to create an interactive experience between the user and the environment. Scene analysis and object recognition play a crucial role in AR, as they must be performed quickly and accurately. In this study, a new approach is proposed that involves using oriented bounding boxes with a detection and recognition deep network to improve performance and processing time. The approach is evaluated using two datasets: a real image dataset (DOTA dataset) commonly used for computer vision tasks, and a synthetic dataset that simulates different environmental, lighting, and acquisition conditions. The focus of the evaluation is on small objects, which are difficult to detect and recognise. The results indicate that the proposed approach tends to produce better Average Precision and greater accuracy for small objects in most of the tested conditions. ",
    "url": "https://arxiv.org/abs/2306.16798",
    "authors": [
      "Vladislav Li",
      "Barbara Villarini",
      "Jean-Christophe Nebel",
      "Thomas Lagkas",
      "Panagiotis Sarigiannidis",
      "Vasileios Argyriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16823",
    "title": "Length of Stay prediction for Hospital Management using Domain  Adaptation",
    "abstract": "Inpatient length of stay (LoS) is an important managerial metric which if known in advance can be used to efficiently plan admissions, allocate resources and improve care. Using historical patient data and machine learning techniques, LoS prediction models can be developed. Ethically, these models can not be used for patient discharge in lieu of unit heads but are of utmost necessity for hospital management systems in charge of effective hospital planning. Therefore, the design of the prediction system should be adapted to work in a true hospital setting. In this study, we predict early hospital LoS at the granular level of admission units by applying domain adaptation to leverage information learned from a potential source domain. Time-varying data from 110,079 and 60,492 patient stays to 8 and 9 intensive care units were respectively extracted from eICU-CRD and MIMIC-IV. These were fed into a Long-Short Term Memory and a Fully connected network to train a source domain model, the weights of which were transferred either partially or fully to initiate training in target domains. Shapley Additive exPlanations (SHAP) algorithms were used to study the effect of weight transfer on model explanability. Compared to the benchmark, the proposed weight transfer model showed statistically significant gains in prediction accuracy (between 1% and 5%) as well as computation time (up to 2hrs) for some target domains. The proposed method thus provides an adapted clinical decision support system for hospital management that can ease processes of data access via ethical committee, computation infrastructures and time. ",
    "url": "https://arxiv.org/abs/2306.16823",
    "authors": [
      "Lyse Naomi Wamba Momo",
      "Nyalleng Moorosi",
      "Elaine O. Nsoesie",
      "Frank Rademakers",
      "Bart De Moor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16827",
    "title": "SaGess: Sampling Graph Denoising Diffusion Model for Scalable Graph  Generation",
    "abstract": "Over recent years, denoising diffusion generative models have come to be considered as state-of-the-art methods for synthetic data generation, especially in the case of generating images. These approaches have also proved successful in other applications such as tabular and graph data generation. However, due to computational complexity, to this date, the application of these techniques to graph data has been restricted to small graphs, such as those used in molecular modeling. In this paper, we propose SaGess, a discrete denoising diffusion approach, which is able to generate large real-world networks by augmenting a diffusion model (DiGress) with a generalized divide-and-conquer framework. The algorithm is capable of generating larger graphs by sampling a covering of subgraphs of the initial graph in order to train DiGress. SaGess then constructs a synthetic graph using the subgraphs that have been generated by DiGress. We evaluate the quality of the synthetic data sets against several competitor methods by comparing graph statistics between the original and synthetic samples, as well as evaluating the utility of the synthetic data set produced by using it to train a task-driven model, namely link prediction. In our experiments, SaGess, outperforms most of the one-shot state-of-the-art graph generating methods by a significant factor, both on the graph metrics and on the link prediction task. ",
    "url": "https://arxiv.org/abs/2306.16827",
    "authors": [
      "Stratis Limnios",
      "Praveen Selvaraj",
      "Mihai Cucuringu",
      "Carsten Maple",
      "Gesine Reinert",
      "Andrew Elliott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16830",
    "title": "Sampling weights of deep neural networks",
    "abstract": "We introduce a probability distribution, combined with an efficient sampling algorithm, for weights and biases of fully-connected neural networks. In a supervised learning context, no iterative optimization or gradient computations of internal network parameters are needed to obtain a trained network. The sampling is based on the idea of random feature models. However, instead of a data-agnostic distribution, e.g., a normal distribution, we use both the input and the output training data of the supervised learning problem to sample both shallow and deep networks. We prove that the sampled networks we construct are universal approximators. We also show that our sampling scheme is invariant to rigid body transformations and scaling of the input data. This implies many popular pre-processing techniques are no longer required. For Barron functions, we show that the $L^2$-approximation error of sampled shallow networks decreases with the square root of the number of neurons. In numerical experiments, we demonstrate that sampled networks achieve comparable accuracy as iteratively trained ones, but can be constructed orders of magnitude faster. Our test cases involve a classification benchmark from OpenML, sampling of neural operators to represent maps in function spaces, and transfer learning using well-known architectures. ",
    "url": "https://arxiv.org/abs/2306.16830",
    "authors": [
      "Erik Lien Bolager",
      "Iryna Burak",
      "Chinmay Datar",
      "Qing Sun",
      "Felix Dietrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.16847",
    "title": "Opinion Optimization in Directed Social Networks",
    "abstract": "Shifting social opinions has far-reaching implications in various aspects, such as public health campaigns, product marketing, and political candidates. In this paper, we study a problem of opinion optimization based on the popular Friedkin-Johnsen (FJ) model for opinion dynamics in an unweighted directed social network with $n$ nodes and $m$ edges. In the FJ model, the internal opinion of every node lies in the closed interval $[0, 1]$, with 0 and 1 being polar opposites of opinions about a certain issue. Concretely, we focus on the problem of selecting a small number of $ k\\ll n $ nodes and changing their internal opinions to 0, in order to minimize the average opinion at equilibrium. We then design an algorithm that returns the optimal solution to the problem in $O(n^3)$ time. To speed up the computation, we further develop a fast algorithm by sampling spanning forests, the time complexity of which is $ O(ln) $, with $l$ being the number of samplings. Finally, we execute extensive experiments on various real directed networks, which show that the effectiveness of our two algorithms is similar to each other, both of which outperform several baseline strategies of node selection. Moreover, our fast algorithm is more efficient than the first one, which is scalable to massive graphs with more than twenty million nodes. ",
    "url": "https://arxiv.org/abs/2306.16847",
    "authors": [
      "Haoxin Sun",
      "Zhongzhi Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.16862",
    "title": "Sustainable Palm Tree Farming: Leveraging IoT and Multi-Modal Data for  Early Detection and Mapping of Red Palm Weevil",
    "abstract": "The Red Palm Weevil (RPW) is a highly destructive insect causing economic losses and impacting palm tree farming worldwide. This paper proposes an innovative approach for sustainable palm tree farming by utilizing advanced technologies for the early detection and management of RPW. Our approach combines computer vision, deep learning (DL), the Internet of Things (IoT), and geospatial data to detect and classify RPW-infested palm trees effectively. The main phases include; (1) DL classification using sound data from IoT devices, (2) palm tree detection using YOLOv8 on UAV images, and (3) RPW mapping using geospatial data. Our custom DL model achieves 100% precision and recall in detecting and localizing infested palm trees. Integrating geospatial data enables the creation of a comprehensive RPW distribution map for efficient monitoring and targeted management strategies. This technology-driven approach benefits agricultural authorities, farmers, and researchers in managing RPW infestations and safeguarding palm tree plantations' productivity. ",
    "url": "https://arxiv.org/abs/2306.16862",
    "authors": [
      "Yosra Hajjaji",
      "Ayyub Alzahem",
      "Wadii Boulila",
      "Imed Riadh Farah",
      "Anis Koubaa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16869",
    "title": "NeuralFuse: Learning to Improve the Accuracy of Access-Limited Neural  Network Inference in Low-Voltage Regimes",
    "abstract": "Deep neural networks (DNNs) have become ubiquitous in machine learning, but their energy consumption remains a notable issue. Lowering the supply voltage is an effective strategy for reducing energy consumption. However, aggressively scaling down the supply voltage can lead to accuracy degradation due to random bit flips in static random access memory (SRAM) where model parameters are stored. To address this challenge, we introduce NeuralFuse, a novel add-on module that addresses the accuracy-energy tradeoff in low-voltage regimes by learning input transformations to generate error-resistant data representations. NeuralFuse protects DNN accuracy in both nominal and low-voltage scenarios. Moreover, NeuralFuse is easy to implement and can be readily applied to DNNs with limited access, such as non-configurable hardware or remote access to cloud-based APIs. Experimental results demonstrate that, at a 1% bit error rate, NeuralFuse can reduce SRAM memory access energy by up to 24% while improving accuracy by up to 57%. To the best of our knowledge, this is the first model-agnostic approach (i.e., no model retraining) to address low-voltage-induced bit errors. The source code is available at https://github.com/IBM/NeuralFuse. ",
    "url": "https://arxiv.org/abs/2306.16869",
    "authors": [
      "Hao-Lun Sun",
      "Lei Hsiung",
      "Nandhini Chandramoorthy",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16891",
    "title": "Harnessing the Power of Hugging Face Transformers for Predicting Mental  Health Disorders in Social Networks",
    "abstract": "Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results. Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms. Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature. The results show that new models outperform the previous approach with an accuracy rate of up to 97%. Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders. We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task. ",
    "url": "https://arxiv.org/abs/2306.16891",
    "authors": [
      "Alireza Pourkeyvan",
      "Ramin Safa",
      "Ali Sorourkhah"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2306.16902",
    "title": "From Query Tools to Causal Architects: Harnessing Large Language Models  for Advanced Causal Discovery from Data",
    "abstract": "Large Language Models (LLMs) exhibit exceptional abilities for causal analysis between concepts in numerous societally impactful domains, including medicine, science, and law. Recent research on LLM performance in various causal discovery and inference tasks has given rise to a new ladder in the classical three-stage framework of causality. In this paper, we advance the current research of LLM-driven causal discovery by proposing a novel framework that combines knowledge-based LLM causal analysis with data-driven causal structure learning. To make LLM more than a query tool and to leverage its power in discovering natural and new laws of causality, we integrate the valuable LLM expertise on existing causal mechanisms into statistical analysis of objective data to build a novel and practical baseline for causal structure learning. We introduce a universal set of prompts designed to extract causal graphs from given variables and assess the influence of LLM prior causality on recovering causal structures from data. We demonstrate the significant enhancement of LLM expertise on the quality of recovered causal structures from data, while also identifying critical challenges and issues, along with potential approaches to address them. As a pioneering study, this paper aims to emphasize the new frontier that LLMs are opening for classical causal discovery and inference, and to encourage the widespread adoption of LLM capabilities in data-driven causal analysis. ",
    "url": "https://arxiv.org/abs/2306.16902",
    "authors": [
      "Taiyu Ban",
      "Lyvzhou Chen",
      "Xiangyu Wang",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16938",
    "title": "Restore Translation Using Equivariant Neural Networks",
    "abstract": "Invariance to spatial transformations such as translations and rotations is a desirable property and a basic design principle for classification neural networks. However, the commonly used convolutional neural networks (CNNs) are actually very sensitive to even small translations. There exist vast works to achieve exact or approximate transformation invariance by designing transformation-invariant models or assessing the transformations. These works usually make changes to the standard CNNs and harm the performance on standard datasets. In this paper, rather than modifying the classifier, we propose a pre-classifier restorer to recover translated (or even rotated) inputs to the original ones which will be fed into any classifier for the same dataset. The restorer is based on a theoretical result which gives a sufficient and necessary condition for an affine operator to be translational equivariant on a tensor space. ",
    "url": "https://arxiv.org/abs/2306.16938",
    "authors": [
      "Yihan Wang",
      "Lijia Yu",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16955",
    "title": "Predicting Music Hierarchies with a Graph-Based Neural Decoder",
    "abstract": "This paper describes a data-driven framework to parse musical sequences into dependency trees, which are hierarchical structures used in music cognition research and music analysis. The parsing involves two steps. First, the input sequence is passed through a transformer encoder to enrich it with contextual information. Then, a classifier filters the graph of all possible dependency arcs to produce the dependency tree. One major benefit of this system is that it can be easily integrated into modern deep-learning pipelines. Moreover, since it does not rely on any particular symbolic grammar, it can consider multiple musical features simultaneously, make use of sequential context information, and produce partial results for noisy inputs. We test our approach on two datasets of musical trees -- time-span trees of monophonic note sequences and harmonic trees of jazz chord sequences -- and show that our approach outperforms previous methods. ",
    "url": "https://arxiv.org/abs/2306.16955",
    "authors": [
      "Francesco Foscarin",
      "Daniel Harasim",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.16957",
    "title": "Cross-Inferential Networks for Source-free Unsupervised Domain  Adaptation",
    "abstract": "One central challenge in source-free unsupervised domain adaptation (UDA) is the lack of an effective approach to evaluate the prediction results of the adapted network model in the target domain. To address this challenge, we propose to explore a new method called cross-inferential networks (CIN). Our main idea is that, when we adapt the network model to predict the sample labels from encoded features, we use these prediction results to construct new training samples with derived labels to learn a new examiner network that performs a different but compatible task in the target domain. Specifically, in this work, the base network model is performing image classification while the examiner network is tasked to perform relative ordering of triplets of samples whose training labels are carefully constructed from the prediction results of the base network model. Two similarity measures, cross-network correlation matrix similarity and attention consistency, are then developed to provide important guidance for the UDA process. Our experimental results on benchmark datasets demonstrate that our proposed CIN approach can significantly improve the performance of source-free UDA. ",
    "url": "https://arxiv.org/abs/2306.16957",
    "authors": [
      "Yushun Tang",
      "Qinghai Guo",
      "Zhihai He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16958",
    "title": "Identifiability of direct effects from summary causal graphs",
    "abstract": "Dynamic structural causal models (SCMs) are a powerful framework for reasoning in dynamic systems about direct effects which measure how a change in one variable affects another variable while holding all other variables constant. The causal relations in a dynamic structural causal model can be qualitatively represented with a full-time causal graph. Assuming linearity and causal sufficiency and given the full-time causal graph, the direct causal effect is always identifiable and can be estimated from data by adjusting on any set of variables given by the so-called single-door criterion. However, in many application such a graph is not available for various reasons but nevertheless experts have access to an abstraction of the full-time causal graph which represents causal relations between time series while omitting temporal information. This paper presents a complete identifiability result which characterizes all cases for which the direct effect is graphically identifiable from summary causal graphs and gives two sound finite adjustment sets that can be used to estimate the direct effect whenever it is identifiable. ",
    "url": "https://arxiv.org/abs/2306.16958",
    "authors": [
      "Simon Ferreira",
      "Charles K. Assaad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16962",
    "title": "Speech-based Age and Gender Prediction with Transformers",
    "abstract": "We report on the curation of several publicly available datasets for age and gender prediction. Furthermore, we present experiments to predict age and gender with models based on a pre-trained wav2vec 2.0. Depending on the dataset, we achieve an MAE between 7.1 years and 10.8 years for age, and at least 91.1% ACC for gender (female, male, child). Compared to a modelling approach built on handcrafted features, our proposed system shows an improvement of 9% UAR for age and 4% UAR for gender. To make our findings reproducible, we release the best performing model to the community as well as the sample lists of the data splits. ",
    "url": "https://arxiv.org/abs/2306.16962",
    "authors": [
      "Felix Burkhardt",
      "Johannes Wagner",
      "Hagen Wierstorf",
      "Florian Eyben",
      "Bj\u00f6rn Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.16973",
    "title": "Experience Transfer for Robust Direct Data-Driven Control",
    "abstract": "Learning-based control uses data to design efficient controllers for specific systems. When multiple systems are involved, experience transfer usually focuses on data availability and controller performance yet neglects robustness to variations between systems. In contrast, this letter explores experience transfer from a robustness perspective. We leverage the transfer to design controllers that are robust not only to the uncertainty regarding an individual agent's model but also to the choice of agent in a fleet. Experience transfer enables the design of safe and robust controllers that work out of the box for all systems in a heterogeneous fleet. Our approach combines scenario optimization and recent formulations for direct data-driven control without the need to estimate a model of the system or determine uncertainty bounds for its parameters. We demonstrate the benefits of our data-driven robustification method through a numerical case study and obtain learned controllers that generalize well from a small number of open-loop trajectories in a quadcopter simulation. ",
    "url": "https://arxiv.org/abs/2306.16973",
    "authors": [
      "Alexander von Rohr",
      "Dmitrii Likhachev",
      "Sebastian Trimpe"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.17020",
    "title": "Classifying Crime Types using Judgment Documents from Social Media",
    "abstract": "The task of determining crime types based on criminal behavior facts has become a very important and meaningful task in social science. But the problem facing the field now is that the data samples themselves are unevenly distributed, due to the nature of the crime itself. At the same time, data sets in the judicial field are less publicly available, and it is not practical to produce large data sets for direct training. This article proposes a new training model to solve this problem through NLP processing methods. We first propose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the defects of uneven data set distribution by generating new samples. Then we use a large open source dataset (CAIL-big) as our pretraining dataset and a small dataset collected by ourselves for Fine-tuning, giving it good generalization ability to unfamiliar small datasets. At the same time, we use the improved Bert model with dynamic masking to improve the model. Experiments show that the proposed method achieves state-of-the-art results on the present dataset. At the same time, the effectiveness of module CFDPM is proved by experiments. This article provides a valuable methodology contribution for classifying social science texts such as criminal behaviors. Extensive experiments on public benchmarks show that the proposed method achieves new state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2306.17020",
    "authors": [
      "Haoxuan Xu",
      "Zeyu He",
      "Mengfan Shen",
      "Songning Lai",
      "Ziqiang Han",
      "Yifan Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.17034",
    "title": "Exploring & Exploiting High-Order Graph Structure for Sparse Knowledge  Graph Completion",
    "abstract": "Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge Graph Completion (KGC) methods, that is, the completion performance decreases rapidly with the increase of graph sparsity. This problem is also exacerbated because of the widespread existence of sparse KGs in practical applications. To alleviate this challenge, we present a novel framework, LR-GCN, that is able to automatically capture valuable long-range dependency among entities to supplement insufficient structure features and distill logical reasoning knowledge for sparse KGC. The proposed approach comprises two main components: a GNN-based predictor and a reasoning path distiller. The reasoning path distiller explores high-order graph structures such as reasoning paths and encodes them as rich-semantic edges, explicitly compositing long-range dependencies into the predictor. This step also plays an essential role in densifying KGs, effectively alleviating the sparse issue. Furthermore, the path distiller further distills logical reasoning knowledge from these mined reasoning paths into the predictor. These two components are jointly optimized using a well-designed variational EM algorithm. Extensive experiments and analyses on four sparse benchmarks demonstrate the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2306.17034",
    "authors": [
      "Tao He",
      "Ming Liu",
      "Yixin Cao",
      "Zekun Wang",
      "Zihao Zheng",
      "Zheng Chu",
      "Bing Qin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.17038",
    "title": "Comparison of Single- and Multi- Objective Optimization Quality for  Evolutionary Equation Discovery",
    "abstract": "Evolutionary differential equation discovery proved to be a tool to obtain equations with less a priori assumptions than conventional approaches, such as sparse symbolic regression over the complete possible terms library. The equation discovery field contains two independent directions. The first one is purely mathematical and concerns differentiation, the object of optimization and its relation to the functional spaces and others. The second one is dedicated purely to the optimizational problem statement. Both topics are worth investigating to improve the algorithm's ability to handle experimental data a more artificial intelligence way, without significant pre-processing and a priori knowledge of their nature. In the paper, we consider the prevalence of either single-objective optimization, which considers only the discrepancy between selected terms in the equation, or multi-objective optimization, which additionally takes into account the complexity of the obtained equation. The proposed comparison approach is shown on classical model examples -- Burgers equation, wave equation, and Korteweg - de Vries equation. ",
    "url": "https://arxiv.org/abs/2306.17038",
    "authors": [
      "Mikhail Maslyaev",
      "Alexander Hvatov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.17063",
    "title": "Honesty is the Best Policy: On the Accuracy of Apple Privacy Labels  Compared to Apps' Privacy Policies",
    "abstract": "Apple introduced \\textit{privacy labels} in Dec. 2020 as a way for developers to report the privacy behaviors of their apps. While Apple does not validate labels, they do also require developers to provide a privacy policy, which offers an important comparison point. In this paper, we applied the NLP framework of Polisis to extract features of the privacy policy for 515,920 apps on the iOS App Store comparing the output to the privacy labels. We identify discrepancies between the policies and the labels, particularly as it relates to data collected that is linked to users. We find that 287$\\pm196$K apps' privacy policies may indicate data collection that is linked to users than what is reported in the privacy labels. More alarming, a large number of (97$\\pm30$\\%) of the apps that have {\\em Data Not Collected} privacy label have a privacy policy that indicates otherwise. We provide insights into potential sources for discrepancies, including the use of templates and confusion around Apple's definitions and requirements. These results suggest that there is still significant work to be done to help developers more accurately labeling their apps. Incorporating a Polisis-like system as a first-order check can help improve the current state and better inform developers when there are possible misapplication of privacy labels. ",
    "url": "https://arxiv.org/abs/2306.17063",
    "authors": [
      "Mir Masood Ali",
      "David G. Balash",
      "Chris Kanich",
      "Adam J. Aviv"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.17066",
    "title": "On the Predictive Accuracy of Neural Temporal Point Process Models for  Continuous-time Event Data",
    "abstract": "Temporal Point Processes (TPPs) serve as the standard mathematical framework for modeling asynchronous event sequences in continuous time. However, classical TPP models are often constrained by strong assumptions, limiting their ability to capture complex real-world event dynamics. To overcome this limitation, researchers have proposed Neural TPPs, which leverage neural network parametrizations to offer more flexible and efficient modeling. While recent studies demonstrate the effectiveness of Neural TPPs, they often lack a unified setup, relying on different baselines, datasets, and experimental configurations. This makes it challenging to identify the key factors driving improvements in predictive accuracy, hindering research progress. To bridge this gap, we present a comprehensive large-scale experimental study that systematically evaluates the predictive accuracy of state-of-the-art neural TPP models. Our study encompasses multiple real-world and synthetic event sequence datasets, following a carefully designed unified setup. We thoroughly investigate the influence of major architectural components such as event encoding, history encoder, and decoder parametrization on both time and mark prediction tasks. Additionally, we delve into the less explored area of probabilistic calibration for neural TPP models. By analyzing our results, we draw insightful conclusions regarding the significance of history size and the impact of architectural components on predictive accuracy. Furthermore, we shed light on the miscalibration of mark distributions in neural TPP models. Our study aims to provide valuable insights into the performance and characteristics of neural TPP models, contributing to a better understanding of their strengths and limitations. ",
    "url": "https://arxiv.org/abs/2306.17066",
    "authors": [
      "Tanguy Bosser",
      "Souhaib Ben Taieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.17068",
    "title": "Presenting an approach based on weighted CapsuleNet networks for Arabic  and Persian multi-domain sentiment analysis",
    "abstract": "Sentiment classification is a fundamental task in natural language processing, assigning one of the three classes, positive, negative, or neutral, to free texts. However, sentiment classification models are highly domain dependent; the classifier may perform classification with reasonable accuracy in one domain but not in another due to the Semantic multiplicity of words getting poor accuracy. This article presents a new Persian/Arabic multi-domain sentiment analysis method using the cumulative weighted capsule networks approach. Weighted capsule ensemble consists of training separate capsule networks for each domain and a weighting measure called domain belonging degree (DBD). This criterion consists of TF and IDF, which calculates the dependency of each document for each domain separately; this value is multiplied by the possible output that each capsule creates. In the end, the sum of these multiplications is the title of the final output, and is used to determine the polarity. And the most dependent domain is considered the final output for each domain. The proposed method was evaluated using the Digikala dataset and obtained acceptable accuracy compared to the existing approaches. It achieved an accuracy of 0.89 on detecting the domain of belonging and 0.99 on detecting the polarity. Also, for the problem of dealing with unbalanced classes, a cost-sensitive function was used. This function was able to achieve 0.0162 improvements in accuracy for sentiment classification. This approach on Amazon Arabic data can achieve 0.9695 accuracies in domain classification. ",
    "url": "https://arxiv.org/abs/2306.17068",
    "authors": [
      "Mahboobeh Sadat Kobari",
      "Nima Karimi",
      "Benyamin Pourhosseini",
      "Ramin Mousa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.17073",
    "title": "Axis-Parallel Right Angle Crossing Graphs",
    "abstract": "A RAC graph is one admitting a RAC drawing, that is, a polyline drawing in which each crossing occurs at a right angle. Originally motivated by psychological studies on readability of graph layouts, RAC graphs form one of the most prominent graph classes in beyond planarity. In this work, we study a subclass of RAC graphs, called axis-parallel RAC (or apRAC, for short), that restricts the crossings to pairs of axis-parallel edge-segments. apRAC drawings combine the readability of planar drawings with the clarity of (non-planar) orthogonal drawings. We consider these graphs both with and without bends. Our contribution is as follows: (i) We study inclusion relationships between apRAC and traditional RAC graphs. (ii) We establish bounds on the edge density of apRAC graphs. (iii) We show that every graph with maximum degree 8 is 2-bend apRAC and give a linear time drawing algorithm. Some of our results on apRAC graphs also improve the state of the art for general RAC graphs. We conclude our work with a list of open questions and a discussion of a natural generalization of the apRAC model. ",
    "url": "https://arxiv.org/abs/2306.17073",
    "authors": [
      "Patrizio Angelini",
      "Michael A. Bekos",
      "Julia Katheder",
      "Michael Kaufmann",
      "Maximilian Pfister",
      "Torsten Ueckerdt"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.17075",
    "title": "Detect Any Deepfakes: Segment Anything Meets Face Forgery Detection and  Localization",
    "abstract": "The rapid advancements in computer vision have stimulated remarkable progress in face forgery techniques, capturing the dedicated attention of researchers committed to detecting forgeries and precisely localizing manipulated areas. Nonetheless, with limited fine-grained pixel-wise supervision labels, deepfake detection models perform unsatisfactorily on precise forgery detection and localization. To address this challenge, we introduce the well-trained vision segmentation foundation model, i.e., Segment Anything Model (SAM) in face forgery detection and localization. Based on SAM, we propose the Detect Any Deepfakes (DADF) framework with the Multiscale Adapter, which can capture short- and long-range forgery contexts for efficient fine-tuning. Moreover, to better identify forged traces and augment the model's sensitivity towards forgery regions, Reconstruction Guided Attention (RGA) module is proposed. The proposed framework seamlessly integrates end-to-end forgery localization and detection optimization. Extensive experiments on three benchmark datasets demonstrate the superiority of our approach for both forgery detection and localization. The codes will be released soon at https://github.com/laiyingxin2/DADF. ",
    "url": "https://arxiv.org/abs/2306.17075",
    "authors": [
      "Yingxin Lai",
      "Zhiming Luo",
      "Zitong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.17077",
    "title": "RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot",
    "abstract": "Performance bugs are non-functional bugs that can even manifest in well-tested commercial products. Fixing these performance bugs is an important yet challenging problem. In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction. It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix. We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing. Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers. ",
    "url": "https://arxiv.org/abs/2306.17077",
    "authors": [
      "Spandan Garg",
      "Roshanak Zilouchian Moghaddam",
      "Neel Sundaresan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.17091",
    "title": "The Importance of Robust Features in Mitigating Catastrophic Forgetting",
    "abstract": "Continual learning (CL) is an approach to address catastrophic forgetting, which refers to forgetting previously learned knowledge by neural networks when trained on new tasks or data distributions. The adversarial robustness has decomposed features into robust and non-robust types and demonstrated that models trained on robust features significantly enhance adversarial robustness. However, no study has been conducted on the efficacy of robust features from the lens of the CL model in mitigating catastrophic forgetting in CL. In this paper, we introduce the CL robust dataset and train four baseline models on both the standard and CL robust datasets. Our results demonstrate that the CL models trained on the CL robust dataset experienced less catastrophic forgetting of the previously learned tasks than when trained on the standard dataset. Our observations highlight the significance of the features provided to the underlying CL models, showing that CL robust features can alleviate catastrophic forgetting. ",
    "url": "https://arxiv.org/abs/2306.17091",
    "authors": [
      "Hikmat Khan",
      "Nidhal C. Bouaynaya",
      "Ghulam Rasoom"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.17103",
    "title": "LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by  Whispering to ChatGPT",
    "abstract": "We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model. In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction. Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation. We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task. ",
    "url": "https://arxiv.org/abs/2306.17103",
    "authors": [
      "Le Zhuo",
      "Ruibin Yuan",
      "Jiahao Pan",
      "Yinghao Ma",
      "Yizhi LI",
      "Ge Zhang",
      "Si Liu",
      "Roger Dannenberg",
      "Jie Fu",
      "Chenghua Lin",
      "Emmanouil Benetos",
      "Wenhu Chen",
      "Wei Xue",
      "Yike Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.17104",
    "title": "Deep Ensemble for Rotorcraft Attitude Prediction",
    "abstract": "Historically, the rotorcraft community has experienced a higher fatal accident rate than other aviation segments, including commercial and general aviation. Recent advancements in artificial intelligence (AI) and the application of these technologies in different areas of our lives are both intriguing and encouraging. When developed appropriately for the aviation domain, AI techniques provide an opportunity to help design systems that can address rotorcraft safety challenges. Our recent work demonstrated that AI algorithms could use video data from onboard cameras and correctly identify different flight parameters from cockpit gauges, e.g., indicated airspeed. These AI-based techniques provide a potentially cost-effective solution, especially for small helicopter operators, to record the flight state information and perform post-flight analyses. We also showed that carefully designed and trained AI systems could accurately predict rotorcraft attitude (i.e., pitch and yaw) from outside scenes (images or video data). Ordinary off-the-shelf video cameras were installed inside the rotorcraft cockpit to record the outside scene, including the horizon. The AI algorithm could correctly identify rotorcraft attitude at an accuracy in the range of 80\\%. In this work, we combined five different onboard camera viewpoints to improve attitude prediction accuracy to 94\\%. In this paper, five onboard camera views included the pilot windshield, co-pilot windshield, pilot Electronic Flight Instrument System (EFIS) display, co-pilot EFIS display, and the attitude indicator gauge. Using video data from each camera view, we trained various convolutional neural networks (CNNs), which achieved prediction accuracy in the range of 79\\% % to 90\\% %. We subsequently ensembled the learned knowledge from all CNNs and achieved an ensembled accuracy of 93.3\\%. ",
    "url": "https://arxiv.org/abs/2306.17104",
    "authors": [
      "Hikmat Khan",
      "Nidhal Carla Bouaynaya",
      "Ghulam Rasool",
      "Tyler Travis",
      "Lacey Thompson",
      "Charles C. Johnson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.17105",
    "title": "Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural  Representations",
    "abstract": "Recent work has observed an intriguing ''Neural Collapse'' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels achieve $93\\%$ accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture. We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting. Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts. ",
    "url": "https://arxiv.org/abs/2306.17105",
    "authors": [
      "Yongyi Yang",
      "Jacob Steinhardt",
      "Wei Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.17109",
    "title": "Synthetic Demographic Data Generation for Card Fraud Detection Using  GANs",
    "abstract": "Using machine learning models to generate synthetic data has become common in many fields. Technology to generate synthetic transactions that can be used to detect fraud is also growing fast. Generally, this synthetic data contains only information about the transaction, such as the time, place, and amount of money. It does not usually contain the individual user's characteristics (age and gender are occasionally included). Using relatively complex synthetic demographic data may improve the complexity of transaction data features, thus improving the fraud detection performance. Benefiting from developments of machine learning, some deep learning models have potential to perform better than other well-established synthetic data generation methods, such as microsimulation. In this study, we built a deep-learning Generative Adversarial Network (GAN), called DGGAN, which will be used for demographic data generation. Our model generates samples during model training, which we found important to overcame class imbalance issues. This study can help improve the cognition of synthetic data and further explore the application of synthetic data generation in card fraud detection. ",
    "url": "https://arxiv.org/abs/2306.17109",
    "authors": [
      "Shuo Wang",
      "Terrence Tricco",
      "Xianta Jiang",
      "Charles Robertson",
      "John Hawkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.17115",
    "title": "Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text  Aligned Latent Representation",
    "abstract": "We present a novel alignment-before-generation approach to tackle the challenging task of generating general 3D shapes based on 2D images or texts. Directly learning a conditional generative model from images or texts to 3D shapes is prone to producing inconsistent results with the conditions because 3D shapes have an additional dimension whose distribution significantly differs from that of 2D images and texts. To bridge the domain gap among the three modalities and facilitate multi-modal-conditioned 3D shape generation, we explore representing 3D shapes in a shape-image-text-aligned space. Our framework comprises two models: a Shape-Image-Text-Aligned Variational Auto-Encoder (SITA-VAE) and a conditional Aligned Shape Latent Diffusion Model (ASLDM). The former model encodes the 3D shapes into the shape latent space aligned to the image and text and reconstructs the fine-grained 3D neural fields corresponding to given shape embeddings via the transformer-based decoder. The latter model learns a probabilistic mapping function from the image or text space to the latent shape space. Our extensive experiments demonstrate that our proposed approach can generate higher-quality and more diverse 3D shapes that better semantically conform to the visual or textural conditional inputs, validating the effectiveness of the shape-image-text-aligned space for cross-modality 3D shape generation. ",
    "url": "https://arxiv.org/abs/2306.17115",
    "authors": [
      "Zibo Zhao",
      "Wen Liu",
      "Xin Chen",
      "Xianfang Zeng",
      "Rui Wang",
      "Pei Cheng",
      "Bin Fu",
      "Tao Chen",
      "Gang Yu",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.17137",
    "title": "Nonlinear Data-Driven Control Part I: Trajectory Representation under  quasi-Linear Parameter Varying Embeddings",
    "abstract": "Recent literature has shown how linear time-invariant (LTI) systems can be represented by trajectories features, that is relying on a single input-output (IO) data dictionary to span all possible system trajectories, as long as the input is persistently exciting. The so-called behavioural framework is a promising alternative for controller synthesis without the necessity of system identification. In this paper, we benefit from differential inclusion in order to adapt previous results to the case quasi-Linear Parameter Varying (qLPV) embeddings, which are use to represent nonlinear dynamical systems along suitable IO coordinates. Accordingly, we propose a set of data-driven analysis tools for a wide class of nonlinear systems, which enable nonlinear data-driven simulation and predictions. Furthermore, a parameter-dependent dissipativity analysis verification setup is also presented, which serves to assess stability of the system within a bounded operation region. The major requirement is that there should exist a scheduling function which maps the nonlinear outputs into a finite number of scheduling variables, and this function should be analytically known. The effectiveness of the proposed tools is tested in practice and shown to provide accurate descriptions of the nonlinear dynamics by the means of a linear representation structure. For such, we consider a high-fidelity nonlinear simulator of a rotational pendulum benchmark simulator and an electro-mechanical positioning experimental validation test-bench. We also show that, even if the scheduling function is erroneously selected, the proposed framework is still able to offer a trustworthy representation of the output dynamics. ",
    "url": "https://arxiv.org/abs/2306.17137",
    "authors": [
      "Marcelo Menezes Morato",
      "Julio Elias Normey-Rico",
      "Olivier Sename"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2306.17165",
    "title": "An Efficient General-Purpose Modular Vision Model via Multi-Task  Heterogeneous Training",
    "abstract": "We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently. Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels. Such multi-label data sets are rare, small, and expensive. We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets. Few have explored training on such heterogeneous datasets. General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes. The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies. To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision transformers, so that they can simultaneously learn classification, detection, and segmentation on diverse mainstream vision datasets including ImageNet, COCO, and ADE20K. Our approach achieves comparable results to single-task state-of-the-art models and demonstrates strong generalization on downstream tasks. Due to its emergent modularity, this general-purpose model decomposes into high-performing components, efficiently adapting to downstream tasks. We can fine-tune it with fewer training parameters, fewer model parameters, and less computation. Additionally, its modularity allows for easy expansion in continual-learning-without-forgetting scenarios. Finally, these functions can be controlled and combined to meet various demands of downstream tasks. ",
    "url": "https://arxiv.org/abs/2306.17165",
    "authors": [
      "Zitian Chen",
      "Mingyu Ding",
      "Yikang Shen",
      "Wei Zhan",
      "Masayoshi Tomizuka",
      "Erik Learned-Miller",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16422",
    "title": "Neural networks can detect model-free static arbitrage strategies",
    "abstract": "In this paper we demonstrate both theoretically as well as numerically that neural networks can detect model-free static arbitrage opportunities whenever the market admits some. Due to the use of neural networks, our method can be applied to financial markets with a high number of traded securities and ensures almost immediate execution of the corresponding trading strategies. To demonstrate its tractability, effectiveness, and robustness we provide examples using real financial data. From a technical point of view, we prove that a single neural network can approximately solve a class of convex semi-infinite programs, which is the key result in order to derive our theoretical results that neural networks can detect model-free static arbitrage strategies whenever the financial market admits such opportunities. ",
    "url": "https://arxiv.org/abs/2306.16422",
    "authors": [
      "Ariel Neufeld",
      "Julian Sester"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.16556",
    "title": "Inter-Rater Uncertainty Quantification in Medical Image Segmentation via  Rater-Specific Bayesian Neural Networks",
    "abstract": "Automated medical image segmentation inherently involves a certain degree of uncertainty. One key factor contributing to this uncertainty is the ambiguity that can arise in determining the boundaries of a target region of interest, primarily due to variations in image appearance. On top of this, even among experts in the field, different opinions can emerge regarding the precise definition of specific anatomical structures. This work specifically addresses the modeling of segmentation uncertainty, known as inter-rater uncertainty. Its primary objective is to explore and analyze the variability in segmentation outcomes that can occur when multiple experts in medical imaging interpret and annotate the same images. We introduce a novel Bayesian neural network-based architecture to estimate inter-rater uncertainty in medical image segmentation. Our approach has three key advancements. Firstly, we introduce a one-encoder-multi-decoder architecture specifically tailored for uncertainty estimation, enabling us to capture the rater-specific representation of each expert involved. Secondly, we propose Bayesian modeling for the new architecture, allowing efficient capture of the inter-rater distribution, particularly in scenarios with limited annotations. Lastly, we enhance the rater-specific representation by integrating an attention module into each decoder. This module facilitates focused and refined segmentation results for each rater. We conduct extensive evaluations using synthetic and real-world datasets to validate our technical innovations rigorously. Our method surpasses existing baseline methods in five out of seven diverse tasks on the publicly available \\emph{QUBIQ} dataset, considering two evaluation metrics encompassing different uncertainty aspects. Our codes, models, and the new dataset are available through our GitHub repository: https://github.com/HaoWang420/bOEMD-net . ",
    "url": "https://arxiv.org/abs/2306.16556",
    "authors": [
      "Qingqiao Hu",
      "Hao Wang",
      "Jing Luo",
      "Yunhao Luo",
      "Zhiheng Zhangg",
      "Jan S. Kirschke",
      "Benedikt Wiestler",
      "Bjoern Menze",
      "Jianguo Zhang",
      "Hongwei Bran Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16621",
    "title": "Assessing the Performance of 1D-Convolution Neural Networks to Predict  Concentration of Mixture Components from Raman Spectra",
    "abstract": "An emerging application of Raman spectroscopy is monitoring the state of chemical reactors during biologic drug production. Raman shift intensities scale linearly with the concentrations of chemical species and thus can be used to analytically determine real-time concentrations using non-destructive light irradiation in a label-free manner. Chemometric algorithms are used to interpret Raman spectra produced from complex mixtures of bioreactor contents as a reaction evolves. Finding the optimal algorithm for a specific bioreactor environment is challenging due to the lack of freely available Raman mixture datasets. The RaMix Python package addresses this challenge by enabling the generation of synthetic Raman mixture datasets with controllable noise levels to assess the utility of different chemometric algorithm types for real-time monitoring applications. To demonstrate the capabilities of this package and compare the performance of different chemometric algorithms, 48 datasets of simulated spectra were generated using the RaMix Python package. The four tested algorithms include partial least squares regression (PLS), a simple neural network, a simple convolutional neural network (simple CNN), and a 1D convolutional neural network with a ResNet architecture (ResNet). The performance of the PLS and simple CNN model was found to be comparable, with the PLS algorithm slightly outperforming the other models on 83\\% of the data sets. The simple CNN model outperforms the other models on large, high noise datasets, demonstrating the superior capability of convolutional neural networks compared to PLS in analyzing noisy spectra. These results demonstrate the promise of CNNs to automatically extract concentration information from unprocessed, noisy spectra, allowing for better process control of industrial drug production. Code for this project is available at github.com/DexterAntonio/RaMix. ",
    "url": "https://arxiv.org/abs/2306.16621",
    "authors": [
      "Dexter Antonio",
      "Hannah O'Toole",
      "Randy Carney",
      "Ambarish Kulkarni",
      "Ahmet Palazoglu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2306.16654",
    "title": "Self-Supervised MRI Reconstruction with Unrolled Diffusion Models",
    "abstract": "Magnetic Resonance Imaging (MRI) produces excellent soft tissue contrast, albeit it is an inherently slow imaging modality. Promising deep learning methods have recently been proposed to reconstruct accelerated MRI scans. However, existing methods still suffer from various limitations regarding image fidelity, contextual sensitivity, and reliance on fully-sampled acquisitions for model training. To comprehensively address these limitations, we propose a novel self-supervised deep reconstruction model, named Self-Supervised Diffusion Reconstruction (SSDiffRecon). SSDiffRecon expresses a conditional diffusion process as an unrolled architecture that interleaves cross-attention transformers for reverse diffusion steps with data-consistency blocks for physics-driven processing. Unlike recent diffusion methods for MRI reconstruction, a self-supervision strategy is adopted to train SSDiffRecon using only undersampled k-space data. Comprehensive experiments on public brain MR datasets demonstrates the superiority of SSDiffRecon against state-of-the-art supervised, and self-supervised baselines in terms of reconstruction speed and quality. Implementation will be available at https://github.com/yilmazkorkmaz1/SSDiffRecon. ",
    "url": "https://arxiv.org/abs/2306.16654",
    "authors": [
      "Yilmaz Korkmaz",
      "Tolga Cukur",
      "Vishal Patel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16705",
    "title": "NNQS-Transformer: an Efficient and Scalable Neural Network Quantum  States Approach for Ab initio Quantum Chemistry",
    "abstract": "Neural network quantum state (NNQS) has emerged as a promising candidate for quantum many-body problems, but its practical applications are often hindered by the high cost of sampling and local energy calculation. We develop a high-performance NNQS method for \\textit{ab initio} electronic structure calculations. The major innovations include: (1) A transformer based architecture as the quantum wave function ansatz; (2) A data-centric parallelization scheme for the variational Monte Carlo (VMC) algorithm which preserves data locality and well adapts for different computing architectures; (3) A parallel batch sampling strategy which reduces the sampling cost and achieves good load balance; (4) A parallel local energy evaluation scheme which is both memory and computationally efficient; (5) Study of real chemical systems demonstrates both the superior accuracy of our method compared to state-of-the-art and the strong and weak scalability for large molecular systems with up to $120$ spin orbitals. ",
    "url": "https://arxiv.org/abs/2306.16705",
    "authors": [
      "Yangjun Wu",
      "Chu Guo",
      "Yi Fan",
      "Pengyu Zhou",
      "Honghui Shang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16819",
    "title": "Graph Denoising Diffusion for Inverse Protein Folding",
    "abstract": "Inverse protein folding is challenging due to its inherent one-to-many mapping characteristic, where numerous possible amino acid sequences can fold into a single, identical protein backbone. This task involves not only identifying viable sequences but also representing the sheer diversity of potential solutions. However, existing discriminative models, such as transformer-based auto-regressive models, struggle to encapsulate the diverse range of plausible solutions. In contrast, diffusion probabilistic models, as an emerging genre of generative approaches, offer the potential to generate a diverse set of sequence candidates for determined protein backbones. We propose a novel graph denoising diffusion model for inverse protein folding, where a given protein backbone guides the diffusion process on the corresponding amino acid residue types. The model infers the joint distribution of amino acids conditioned on the nodes' physiochemical properties and local environment. Moreover, we utilize amino acid replacement matrices for the diffusion forward process, encoding the biologically-meaningful prior knowledge of amino acids from their spatial and sequential neighbors as well as themselves, which reduces the sampling space of the generative process. Our model achieves state-of-the-art performance over a set of popular baseline methods in sequence recovery and exhibits great potential in generating diverse protein sequences for a determined protein backbone structure. ",
    "url": "https://arxiv.org/abs/2306.16819",
    "authors": [
      "Kai Yi",
      "Bingxin Zhou",
      "Yiqing Shen",
      "Pietro Li\u00f2",
      "Yu Guang Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16989",
    "title": "The State of Applying Artificial Intelligence to Tissue Imaging for  Cancer Research and Early Detection",
    "abstract": "Artificial intelligence represents a new frontier in human medicine that could save more lives and reduce the costs, thereby increasing accessibility. As a consequence, the rate of advancement of AI in cancer medical imaging and more particularly tissue pathology has exploded, opening it to ethical and technical questions that could impede its adoption into existing systems. In order to chart the path of AI in its application to cancer tissue imaging, we review current work and identify how it can improve cancer pathology diagnostics and research. In this review, we identify 5 core tasks that models are developed for, including regression, classification, segmentation, generation, and compression tasks. We address the benefits and challenges that such methods face, and how they can be adapted for use in cancer prevention and treatment. The studies looked at in this paper represent the beginning of this field and future experiments will build on the foundations that we highlight. ",
    "url": "https://arxiv.org/abs/2306.16989",
    "authors": [
      "Michael Robben",
      "Amir Hajighasemi",
      "Mohammad Sadegh Nasr",
      "Jai Prakesh Veerla",
      "Anne M. Alsup",
      "Biraaj Rout",
      "Helen H. Shang",
      "Kelli Fowlds",
      "Parisa Boodaghi Malidarreh",
      "Paul Koomey",
      "MD Jillur Rahman Saurav",
      "Jacob M. Luber"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.17005",
    "title": "High-Quality Automatic Voice Over with Accurate Alignment: Supervision  through Self-Supervised Discrete Speech Units",
    "abstract": "The goal of Automatic Voice Over (AVO) is to generate speech in sync with a silent video given its text script. Recent AVO frameworks built upon text-to-speech synthesis (TTS) have shown impressive results. However, the current AVO learning objective of acoustic feature reconstruction brings in indirect supervision for inter-modal alignment learning, thus limiting the synchronization performance and synthetic speech quality. To this end, we propose a novel AVO method leveraging the learning objective of self-supervised discrete speech unit prediction, which not only provides more direct supervision for the alignment learning, but also alleviates the mismatch between the text-video context and acoustic features. Experimental results show that our proposed method achieves remarkable lip-speech synchronization and high speech quality by outperforming baselines in both objective and subjective evaluations. Code and speech samples are publicly available. ",
    "url": "https://arxiv.org/abs/2306.17005",
    "authors": [
      "Junchen Lu",
      "Berrak Sisman",
      "Mingyang Zhang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:1911.06253",
    "title": "Understanding Graph Neural Networks with Generalized Geometric  Scattering Transforms",
    "abstract": " Title: Understanding Graph Neural Networks with Generalized Geometric  Scattering Transforms ",
    "url": "https://arxiv.org/abs/1911.06253",
    "authors": [
      "Michael Perlmutter",
      "Alexander Tong",
      "Feng Gao",
      "Guy Wolf",
      "Matthew Hirn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.05954",
    "title": "MVPipe: Enabling Lightweight Updates and Fast Convergence in  Hierarchical Heavy Hitter Detection",
    "abstract": " Comments: 14 pages. Accepted by IEEE/ACM Transactions on Networking ",
    "url": "https://arxiv.org/abs/2107.05954",
    "authors": [
      "Lu Tang",
      "Qun Huang",
      "Patrick P. C. Lee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2108.01032",
    "title": "The tripartite-circle crossing number of graphs with two small partition  classes",
    "abstract": " Comments: 22 pages, 11 figures. Added new results and revised throughout. Originally appeared in arXiv:1910.06963v1, now removed from arXiv:1910.06963v2 ",
    "url": "https://arxiv.org/abs/2108.01032",
    "authors": [
      "Charles Camacho",
      "Silvia Fern\u00e1ndez-Merchant",
      "Marija Jeli\u0107 Milutinovi\u0107",
      "Rachel Kirsch",
      "Linda Kleist",
      "Elizabeth Bailey Matson",
      "Jennifer White"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2201.01505",
    "title": "Transmission-Constrained Consensus of Multiagent Networks",
    "abstract": " Title: Transmission-Constrained Consensus of Multiagent Networks ",
    "url": "https://arxiv.org/abs/2201.01505",
    "authors": [
      "Xiaotian Wang",
      "Housheng Su"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.04636",
    "title": "\"That Is a Suspicious Reaction!\": Interpreting Logits Variation to  Detect NLP Adversarial Attacks",
    "abstract": " Comments: ACL 2022 ",
    "url": "https://arxiv.org/abs/2204.04636",
    "authors": [
      "Edoardo Mosca",
      "Shreyash Agarwal",
      "Javier Rando",
      "Georg Groh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08247",
    "title": "Joint Multi-view Unsupervised Feature Selection and Graph Learning",
    "abstract": " Comments: To appear in IEEE Transactions on Emerging Topics in Computational Intelligence ",
    "url": "https://arxiv.org/abs/2204.08247",
    "authors": [
      "Si-Guo Fang",
      "Dong Huang",
      "Chang-Dong Wang",
      "Yong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.08790",
    "title": "On-device modeling of user's social context and familiar places from  smartphone-embedded sensor data",
    "abstract": " Comments: I request the withdrawal of the paper because it has been already submitted (and published) on arXiv with identifier 2306.15437 ",
    "url": "https://arxiv.org/abs/2205.08790",
    "authors": [
      "Mattia Giovanni Campana",
      "Franca Delmastro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.00865",
    "title": "ORA3D: Overlap Region Aware Multi-view 3D Object Detection",
    "abstract": " Comments: BMVC2022 ",
    "url": "https://arxiv.org/abs/2207.00865",
    "authors": [
      "Wonseok Roh",
      "Gyusam Chang",
      "Seokha Moon",
      "Giljoo Nam",
      "Chanyoung Kim",
      "Younghyun Kim",
      "Jinkyu Kim",
      "Sangpil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04589",
    "title": "Learned Video Compression via Heterogeneous Deformable Compensation  Network",
    "abstract": " Title: Learned Video Compression via Heterogeneous Deformable Compensation  Network ",
    "url": "https://arxiv.org/abs/2207.04589",
    "authors": [
      "Huairui Wang",
      "Zhenzhong Chen",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.07292",
    "title": "PASS: A Parameter Audit-based Secure and Fair Federated Learning Scheme  against Free-Rider Attack",
    "abstract": " Comments: 11 pages, 13 figures, 5 tables. Accepted by IoTJ. For associated file, see early access this https URL ",
    "url": "https://arxiv.org/abs/2207.07292",
    "authors": [
      "Jianhua Wang",
      "Xiaolin Chang",
      "Jelena Mi\u0161i\u0107",
      "Vojislav B. Mi\u0161i\u0107",
      "Yixiang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.04477",
    "title": "Robust Policy Optimization in Continuous-time Mixed  $\\mathcal{H}_2/\\mathcal{H}_\\infty$ Stochastic Control",
    "abstract": " Title: Robust Policy Optimization in Continuous-time Mixed  $\\mathcal{H}_2/\\mathcal{H}_\\infty$ Stochastic Control ",
    "url": "https://arxiv.org/abs/2209.04477",
    "authors": [
      "Leilei Cui",
      "Lekan Molu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.11559",
    "title": "Query-based Hard-Image Retrieval for Object Detection at Test Time",
    "abstract": " Title: Query-based Hard-Image Retrieval for Object Detection at Test Time ",
    "url": "https://arxiv.org/abs/2209.11559",
    "authors": [
      "Edward Ayers",
      "Jonathan Sadeghi",
      "John Redford",
      "Romain Mueller",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08765",
    "title": "Temporal Link Prediction: A Unified Framework, Taxonomy, and Review",
    "abstract": " Title: Temporal Link Prediction: A Unified Framework, Taxonomy, and Review ",
    "url": "https://arxiv.org/abs/2210.08765",
    "authors": [
      "Meng Qin",
      "Dit-Yan Yeung"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.13148",
    "title": "Transformers over Directed Acyclic Graphs",
    "abstract": " Title: Transformers over Directed Acyclic Graphs ",
    "url": "https://arxiv.org/abs/2210.13148",
    "authors": [
      "Yuankai Luo",
      "Veronika Thost",
      "Lei Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14290",
    "title": "Parallel Order-Based Core Maintenance in Dynamic Graphs",
    "abstract": " Comments: Published on 52nd International Conference on Parallel Processing (ICPP 2023), 17 pages, 7 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2210.14290",
    "authors": [
      "Bin Guo",
      "Emil Sekerinski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.16561",
    "title": "iSmallNet: Densely Nested Network with Label Decoupling for Infrared  Small Target Detection",
    "abstract": " Title: iSmallNet: Densely Nested Network with Label Decoupling for Infrared  Small Target Detection ",
    "url": "https://arxiv.org/abs/2210.16561",
    "authors": [
      "Zhiheng Hu",
      "Yongzhen Wang",
      "Peng Li",
      "Jie Qin",
      "Haoran Xie",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.01579",
    "title": "Data-free Defense of Black Box Models Against Adversarial Attacks",
    "abstract": " Comments: Neural Networks Journal (Under Review) ",
    "url": "https://arxiv.org/abs/2211.01579",
    "authors": [
      "Gaurav Kumar Nayak",
      "Inder Khatri",
      "Ruchit Rawal",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00423",
    "title": "Motion Informed Object Detection of Small Insects in Time-lapse Camera  Recordings",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2212.00423",
    "authors": [
      "Kim Bjerge",
      "Carsten Eie Frigaard",
      "Henrik Karstoft"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00049",
    "title": "Transformers Meet Directed Graphs",
    "abstract": " Comments: 29 pages ",
    "url": "https://arxiv.org/abs/2302.00049",
    "authors": [
      "Simon Geisler",
      "Yujia Li",
      "Daniel Mankowitz",
      "Ali Taylan Cemgil",
      "Stephan G\u00fcnnemann",
      "Cosmin Paduraru"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03684",
    "title": "Temporal Robustness against Data Poisoning",
    "abstract": " Comments: 13 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2302.03684",
    "authors": [
      "Wenxiao Wang",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.11715",
    "title": "Variable Importance Matching for Causal Inference",
    "abstract": " Title: Variable Importance Matching for Causal Inference ",
    "url": "https://arxiv.org/abs/2302.11715",
    "authors": [
      "Quinn Lanners",
      "Harsh Parikh",
      "Alexander Volfovsky",
      "Cynthia Rudin",
      "David Page"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2303.02245",
    "title": "Exploring Self-Supervised Representation Learning For Low-Resource  Medical Image Analysis",
    "abstract": " Comments: Accepted at IEEE ICIP 2023 ",
    "url": "https://arxiv.org/abs/2303.02245",
    "authors": [
      "Soumitri Chattopadhyay",
      "Soham Ganguly",
      "Sreejit Chaudhury",
      "Sayan Nag",
      "Samiran Chattopadhyay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.02577",
    "title": "Effectiveness of Data Augmentation for Parameter Efficient Tuning with  Limited Data",
    "abstract": " Comments: Published at the 8th Workshop on Representation Learning for NLP (RepL4NLP 2023) at ACL 2023 ",
    "url": "https://arxiv.org/abs/2303.02577",
    "authors": [
      "Stephen Obadinma",
      "Hongyu Guo",
      "Xiaodan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.07064",
    "title": "A Generalized Multi-Modal Fusion Detection Framework",
    "abstract": " Title: A Generalized Multi-Modal Fusion Detection Framework ",
    "url": "https://arxiv.org/abs/2303.07064",
    "authors": [
      "Leichao Cui",
      "Xiuxian Li",
      "Min Meng",
      "Xiaoyu Mo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12077",
    "title": "VAD: Vectorized Scene Representation for Efficient Autonomous Driving",
    "abstract": " Comments: Code&Demos: this https URL ",
    "url": "https://arxiv.org/abs/2303.12077",
    "authors": [
      "Bo Jiang",
      "Shaoyu Chen",
      "Qing Xu",
      "Bencheng Liao",
      "Jiajie Chen",
      "Helong Zhou",
      "Qian Zhang",
      "Wenyu Liu",
      "Chang Huang",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15057",
    "title": "Meta-Calibration Regularized Neural Networks",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2303.15057",
    "authors": [
      "Cheng Wang",
      "Jacek Golebiowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15301",
    "title": "PeakNet: An Autonomous Bragg Peak Finder with Deep Neural Networks",
    "abstract": " Title: PeakNet: An Autonomous Bragg Peak Finder with Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2303.15301",
    "authors": [
      "Cong Wang",
      "Po-Nan Li",
      "Jana Thayer",
      "Chun Hong Yoon"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.06408",
    "title": "Intriguing properties of synthetic images: from generative adversarial  networks to diffusion models",
    "abstract": " Title: Intriguing properties of synthetic images: from generative adversarial  networks to diffusion models ",
    "url": "https://arxiv.org/abs/2304.06408",
    "authors": [
      "Riccardo Corvi",
      "Davide Cozzolino",
      "Giovanni Poggi",
      "Koki Nagano",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12217",
    "title": "Impact-Oriented Contextual Scholar Profiling using Self-Citation Graphs",
    "abstract": " Comments: KDD 2023 ",
    "url": "https://arxiv.org/abs/2304.12217",
    "authors": [
      "Yuankai Luo",
      "Lei Shi",
      "Mufan Xu",
      "Yuwen Ji",
      "Fengli Xiao",
      "Chunming Hu",
      "Zhiguang Shan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.13390",
    "title": "Group Equivariant BEV for 3D Object Detection",
    "abstract": " Comments: 8 pages,3 figures ",
    "url": "https://arxiv.org/abs/2304.13390",
    "authors": [
      "Hongwei Liu",
      "Jian Yang",
      "Jianfeng Zhang",
      "Dongheng Shao",
      "Jielong Guo",
      "Shaobo Li",
      "Xuan Tang",
      "Xian Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.09671",
    "title": "Pick your Poison: Undetectability versus Robustness in Data Poisoning  Attacks",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2305.09671",
    "authors": [
      "Nils Lukas",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10631",
    "title": "An image segmentation algorithm based on multi-scale feature pyramid  network",
    "abstract": " Title: An image segmentation algorithm based on multi-scale feature pyramid  network ",
    "url": "https://arxiv.org/abs/2305.10631",
    "authors": [
      "Yu Xiao",
      "Xin Yang",
      "Sijuan Huang",
      "Lihua Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14912",
    "title": "SVDinsTN: An Integrated Method for Tensor Network Representation with  Efficient Structure Search",
    "abstract": " Title: SVDinsTN: An Integrated Method for Tensor Network Representation with  Efficient Structure Search ",
    "url": "https://arxiv.org/abs/2305.14912",
    "authors": [
      "Yu-Bang Zheng",
      "Xi-Le Zhao",
      "Junhua Zeng",
      "Chao Li",
      "Qibin Zhao",
      "Heng-Chao Li",
      "Ting-Zhu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16129",
    "title": "Energy-based Detection of Adverse Weather Effects in LiDAR Data",
    "abstract": " Comments: Accepted for publication in IEEE Robotics and Automation Letters (RA-L) ",
    "url": "https://arxiv.org/abs/2305.16129",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Johannes Kopp",
      "Marc Walessa",
      "Daniel Meissner",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18221",
    "title": "GazeGNN: A Gaze-Guided Graph Neural Network for Chest X-ray  Classification",
    "abstract": " Title: GazeGNN: A Gaze-Guided Graph Neural Network for Chest X-ray  Classification ",
    "url": "https://arxiv.org/abs/2305.18221",
    "authors": [
      "Bin Wang",
      "Hongyi Pan",
      "Armstrong Aboah",
      "Zheyuan Zhang",
      "Elif Keles",
      "Drew Torigian",
      "Baris Turkbey",
      "Elizabeth Krupinski",
      "Jayaram Udupa",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19067",
    "title": "Multi-source adversarial transfer learning based on similar source  domains with local features",
    "abstract": " Comments: Submitted to Information Fusion ",
    "url": "https://arxiv.org/abs/2305.19067",
    "authors": [
      "Yifu Zhang",
      "Hongru Li",
      "Shimeng Shi",
      "Youqi Li",
      "Jiansong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19915",
    "title": "Data Augmentation Approaches for Source Code Models: A Survey",
    "abstract": " Comments: Technical Report ",
    "url": "https://arxiv.org/abs/2305.19915",
    "authors": [
      "Terry Yue Zhuo",
      "Zhou Yang",
      "Zhensu Sun",
      "Yufei Wang",
      "Li Li",
      "Xiaoning Du",
      "Zhenchang Xing",
      "David Lo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.05979",
    "title": "Optimal distance query reconstruction for graphs without long induced  cycles",
    "abstract": " Comments: 35 pages ",
    "url": "https://arxiv.org/abs/2306.05979",
    "authors": [
      "Paul Bastide",
      "Carla Groenland"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.11876",
    "title": "BMAD: Benchmarks for Medical Anomaly Detection",
    "abstract": " Title: BMAD: Benchmarks for Medical Anomaly Detection ",
    "url": "https://arxiv.org/abs/2306.11876",
    "authors": [
      "Jinan Bao",
      "Hanshi Sun",
      "Hanqiu Deng",
      "Yinsheng He",
      "Zhaoxiang Zhang",
      "Xingyu Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13455",
    "title": "DreamEditor: Text-Driven 3D Scene Editing with Neural Fields",
    "abstract": " Title: DreamEditor: Text-Driven 3D Scene Editing with Neural Fields ",
    "url": "https://arxiv.org/abs/2306.13455",
    "authors": [
      "Jingyu Zhuang",
      "Chen Wang",
      "Lingjie Liu",
      "Liang Lin",
      "Guanbin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13651",
    "title": "Bring Your Own Data! Self-Supervised Evaluation for Large Language  Models",
    "abstract": " Comments: Code is available at this https URL First two authors contributed equally. 21 pages, 22 figures ",
    "url": "https://arxiv.org/abs/2306.13651",
    "authors": [
      "Neel Jain",
      "Khalid Saifullah",
      "Yuxin Wen",
      "John Kirchenbauer",
      "Manli Shu",
      "Aniruddha Saha",
      "Micah Goldblum",
      "Jonas Geiping",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.14011",
    "title": "Machine Learning based Autotuning of a GPU-accelerated Computational  Fluid Dynamics Code",
    "abstract": " Title: Machine Learning based Autotuning of a GPU-accelerated Computational  Fluid Dynamics Code ",
    "url": "https://arxiv.org/abs/2306.14011",
    "authors": [
      "Weicheng Xue",
      "Christohper John Roy"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2306.14275",
    "title": "Enhancing Adversarial Training via Reweighting Optimization Trajectory",
    "abstract": " Comments: Accepted by ECML 2023 ",
    "url": "https://arxiv.org/abs/2306.14275",
    "authors": [
      "Tianjin Huang",
      "Shiwei Liu",
      "Tianlong Chen",
      "Meng Fang",
      "Li Shen",
      "Vlaod Menkovski",
      "Lu Yin",
      "Yulong Pei",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.14406",
    "title": "TCEIP: Text Condition Embedded Regression Network for Dental Implant  Position Prediction",
    "abstract": " Comments: MICCAI 2023 ",
    "url": "https://arxiv.org/abs/2306.14406",
    "authors": [
      "Xinquan Yang",
      "Jinheng Xie",
      "Xuguang Li",
      "Xuechen Li",
      "Xin Li",
      "Linlin Shen",
      "Yongqiang Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.15138",
    "title": "A Restarted Large-Scale Spectral Clustering with Self-Guiding and Block  Diagonal Representation",
    "abstract": " Comments: 36 pages ",
    "url": "https://arxiv.org/abs/2306.15138",
    "authors": [
      "Yongyan Guo",
      "Gang Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.15955",
    "title": "Bridging the Gap: Neural Collapse Inspired Prompt Tuning for  Generalization under Class Imbalance",
    "abstract": " Title: Bridging the Gap: Neural Collapse Inspired Prompt Tuning for  Generalization under Class Imbalance ",
    "url": "https://arxiv.org/abs/2306.15955",
    "authors": [
      "Didi Zhu",
      "Yinchuan Li",
      "Min Zhang",
      "Junkun Yuan",
      "Jiashuo Liu",
      "Zexi Li",
      "Kun Kuang",
      "Chao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16125",
    "title": "A Framework for Identifying Depression on Social Media:  MentalRiskES@IberLEF 2023",
    "abstract": " Comments: Submitted to the Proceedings of IberLEF 2023, September 2023, Ja\\'en, Spain ",
    "url": "https://arxiv.org/abs/2306.16125",
    "authors": [
      "Simon Sanchez Viloria",
      "Daniel Peix del R\u00edo",
      "Rub\u00e9n Berm\u00fadez Cabo",
      "Guillermo Arturo Arrojo Fuentes",
      "Isabel Segura-Bedmar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]