[
  {
    "id": "arXiv:2306.13103",
    "title": "Evaluating the Robustness of Text-to-image Diffusion Models against  Real-world Attacks",
    "abstract": "Text-to-image (T2I) diffusion models (DMs) have shown promise in generating high-quality images from textual descriptions. The real-world applications of these models require particular attention to their safety and fidelity, but this has not been sufficiently explored. One fundamental question is whether existing T2I DMs are robust against variations over input texts. To answer it, this work provides the first robustness evaluation of T2I DMs against real-world attacks. Unlike prior studies that focus on malicious attacks involving apocryphal alterations to the input texts, we consider an attack space spanned by realistic errors (e.g., typo, glyph, phonetic) that humans can make, to ensure semantic consistency. Given the inherent randomness of the generation process, we develop novel distribution-based attack objectives to mislead T2I DMs. We perform attacks in a black-box manner without any knowledge of the model. Extensive experiments demonstrate the effectiveness of our method for attacking popular T2I DMs and simultaneously reveal their non-trivial robustness issues. Moreover, we provide an in-depth analysis of our method to show that it is not designed to attack the text encoder in T2I DMs solely. ",
    "url": "https://arxiv.org/abs/2306.13103",
    "authors": [
      "Hongcheng Gao",
      "Hao Zhang",
      "Yinpeng Dong",
      "Zhijie Deng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13119",
    "title": "Adversarial Resilience in Sequential Prediction via Abstention",
    "abstract": "We study the problem of sequential prediction in the stochastic setting with an adversary that is allowed to inject clean-label adversarial (or out-of-distribution) examples. Algorithms designed to handle purely stochastic data tend to fail in the presence of such adversarial examples, often leading to erroneous predictions. This is undesirable in many high-stakes applications such as medical recommendations, where abstaining from predictions on adversarial examples is preferable to misclassification. On the other hand, assuming fully adversarial data leads to very pessimistic bounds that are often vacuous in practice. To capture this motivation, we propose a new model of sequential prediction that sits between the purely stochastic and fully adversarial settings by allowing the learner to abstain from making a prediction at no cost on adversarial examples. Assuming access to the marginal distribution on the non-adversarial examples, we design a learner whose error scales with the VC dimension (mirroring the stochastic setting) of the hypothesis class, as opposed to the Littlestone dimension which characterizes the fully adversarial setting. Furthermore, we design a learner for VC dimension~1 classes, which works even in the absence of access to the marginal distribution. Our key technical contribution is a novel measure for quantifying uncertainty for learning VC classes, which may be of independent interest. ",
    "url": "https://arxiv.org/abs/2306.13119",
    "authors": [
      "Surbhi Goel",
      "Steve Hanneke",
      "Shay Moran",
      "Abhishek Shetty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.13166",
    "title": "A Sparse Graph Formulation for Efficient Spectral Image Segmentation",
    "abstract": "Spectral Clustering is one of the most traditional methods to solve segmentation problems. Based on Normalized Cuts, it aims at partitioning an image using an objective function defined by a graph. Despite their mathematical attractiveness, spectral approaches are traditionally neglected by the scientific community due to their practical issues and underperformance. In this paper, we adopt a sparse graph formulation based on the inclusion of extra nodes to a simple grid graph. While the grid encodes the pixel spatial disposition, the extra nodes account for the pixel color data. Applying the original Normalized Cuts algorithm to this graph leads to a simple and scalable method for spectral image segmentation, with an interpretable solution. Our experiments also demonstrate that our proposed methodology over performs traditional spectral algorithms for segmentation. ",
    "url": "https://arxiv.org/abs/2306.13166",
    "authors": [
      "Rahul Palnitkar",
      "Jeova Farias Sales Rocha Neto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13176",
    "title": "Key Frame Extraction with Attention Based Deep Neural Networks",
    "abstract": "Automatic keyframe detection from videos is an exercise in selecting scenes that can best summarize the content for long videos. Providing a summary of the video is an important task to facilitate quick browsing and content summarization. The resulting photos are used for automated works (e.g. summarizing security footage, detecting different scenes used in music clips) in different industries. In addition, processing high-volume videos in advanced machine learning methods also creates resource costs. Keyframes obtained; It can be used as an input feature to the methods and models to be used. In this study; We propose a deep learning-based approach for keyframe detection using a deep auto-encoder model with an attention layer. The proposed method first extracts the features from the video frames using the encoder part of the autoencoder and applies segmentation using the k-means clustering algorithm to group these features and similar frames together. Then, keyframes are selected from each cluster by selecting the frames closest to the center of the clusters. The method was evaluated on the TVSUM video dataset and achieved a classification accuracy of 0.77, indicating a higher success rate than many existing methods. The proposed method offers a promising solution for key frame extraction in video analysis and can be applied to various applications such as video summarization and video retrieval. ",
    "url": "https://arxiv.org/abs/2306.13176",
    "authors": [
      "Samed Arslan",
      "Senem Tanberk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.13181",
    "title": "Prediction of Annual Snow Accumulation Using a Recurrent Graph  Convolutional Approach",
    "abstract": "The precise tracking and prediction of polar ice layers can unveil historic trends in snow accumulation. In recent years, airborne radar sensors, such as the Snow Radar, have been shown to be able to measure these internal ice layers over large areas with a fine vertical resolution. In our previous work, we found that temporal graph convolutional networks perform reasonably well in predicting future snow accumulation when given temporal graphs containing deep ice layer thickness. In this work, we experiment with a graph attention network-based model and used it to predict more annual snow accumulation data points with fewer input data points on a larger dataset. We found that these large changes only very slightly negatively impacted performance. ",
    "url": "https://arxiv.org/abs/2306.13181",
    "authors": [
      "Benjamin Zalatan",
      "Maryam Rahnemoonfar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.13186",
    "title": "A Decade of Scholarly Research on Open Knowledge Graphs",
    "abstract": "The proliferation of open knowledge graphs has led to a surge in scholarly research on the topic over the past decade. This paper presents a bibliometric analysis of the scholarly literature on open knowledge graphs published between 2013 and 2023. The study aims to identify the trends, patterns, and impact of research in this field, as well as the key topics and research questions that have emerged. The work uses bibliometric techniques to analyze a sample of 4445 scholarly articles retrieved from Scopus. The findings reveal an ever-increasing number of publications on open knowledge graphs published every year, particularly in developed countries (+50 per year). These outputs are published in highly-referred scholarly journals and conferences. The study identifies three main research themes: (1) knowledge graph construction and enrichment, (2) evaluation and reuse, and (3) fusion of knowledge graphs into NLP systems. Within these themes, the study identifies specific tasks that have received considerable attention, including entity linking, knowledge graph embedding, and graph neural networks. ",
    "url": "https://arxiv.org/abs/2306.13186",
    "authors": [
      "Houcemeddine Turki",
      "Abraham Toluwase Owodunni",
      "Mohamed Ali Hadj Taieb",
      "Ren\u00e9 Fabrice Bile",
      "Mohamed Ben Aouicha",
      "Vil\u00e9m Zouhar"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.13203",
    "title": "Neural Network Pruning for Real-time Polyp Segmentation",
    "abstract": "Computer-assisted treatment has emerged as a viable application of medical imaging, owing to the efficacy of deep learning models. Real-time inference speed remains a key requirement for such applications to help medical personnel. Even though there generally exists a trade-off between performance and model size, impressive efforts have been made to retain near-original performance by compromising model size. Neural network pruning has emerged as an exciting area that aims to eliminate redundant parameters to make the inference faster. In this study, we show an application of neural network pruning in polyp segmentation. We compute the importance score of convolutional filters and remove the filters having the least scores, which to some value of pruning does not degrade the performance. For computing the importance score, we use the Taylor First Order (TaylorFO) approximation of the change in network output for the removal of certain filters. Specifically, we employ a gradient-normalized backpropagation for the computation of the importance score. Through experiments in the polyp datasets, we validate that our approach can significantly reduce the parameter count and FLOPs retaining similar performance. ",
    "url": "https://arxiv.org/abs/2306.13203",
    "authors": [
      "Suman Sapkota",
      "Pranav Poudel",
      "Sudarshan Regmi",
      "Bibek Panthi",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13210",
    "title": "Directional diffusion models for graph representation learning",
    "abstract": "In recent years, diffusion models have achieved remarkable success in various domains of artificial intelligence, such as image synthesis, super-resolution, and 3D molecule generation. However, the application of diffusion models in graph learning has received relatively little attention. In this paper, we address this gap by investigating the use of diffusion models for unsupervised graph representation learning. We begin by identifying the anisotropic structures of graphs and a crucial limitation of the vanilla forward diffusion process in learning anisotropic structures. This process relies on continuously adding an isotropic Gaussian noise to the data, which may convert the anisotropic signals to noise too quickly. This rapid conversion hampers the training of denoising neural networks and impedes the acquisition of semantically meaningful representations in the reverse process. To address this challenge, we propose a new class of models called {\\it directional diffusion models}. These models incorporate data-dependent, anisotropic, and directional noises in the forward diffusion process. To assess the efficacy of our proposed models, we conduct extensive experiments on 12 publicly available datasets, focusing on two distinct graph representation learning tasks. The experimental results demonstrate the superiority of our models over state-of-the-art baselines, indicating their effectiveness in capturing meaningful graph representations. Our studies not only provide valuable insights into the forward process of diffusion models but also highlight the wide-ranging potential of these models for various graph-related tasks. ",
    "url": "https://arxiv.org/abs/2306.13210",
    "authors": [
      "Run Yang",
      "Yuling Yang",
      "Fan Zhou",
      "Qiang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13213",
    "title": "Visual Adversarial Examples Jailbreak Large Language Models",
    "abstract": "Recently, there has been a surge of interest in introducing vision into Large Language Models (LLMs). The proliferation of large Visual Language Models (VLMs), such as Flamingo, BLIP-2, and GPT-4, signifies an exciting convergence of advancements in both visual and language foundation models. Yet, the risks associated with this integrative approach are largely unexamined. In this paper, we shed light on the security and safety implications of this trend. First, we underscore that the continuous and high-dimensional nature of the additional visual input space intrinsically makes it a fertile ground for adversarial attacks. This unavoidably expands the attack surfaces of LLMs. Second, we highlight that the broad functionality of LLMs also presents visual attackers with a wider array of achievable adversarial objectives, extending the implications of security failures beyond mere misclassification. To elucidate these risks, we study adversarial examples in the visual input space of a VLM. Specifically, against MiniGPT-4, which incorporates safety mechanisms that can refuse harmful instructions, we present visual adversarial examples that can circumvent the safety mechanisms and provoke harmful behaviors of the model. Remarkably, we discover that adversarial examples, even if optimized on a narrow, manually curated derogatory corpus against specific social groups, can universally jailbreak the model's safety mechanisms. A single such adversarial example can generally undermine MiniGPT-4's safety, enabling it to heed a wide range of harmful instructions and produce harmful content far beyond simply imitating the derogatory corpus used in optimization. Unveiling these risks, we accentuate the urgent need for comprehensive risk assessments, robust defense strategies, and the implementation of responsible practices for the secure and safe utilization of VLMs. ",
    "url": "https://arxiv.org/abs/2306.13213",
    "authors": [
      "Xiangyu Qi",
      "Kaixuan Huang",
      "Ashwinee Panda",
      "Mengdi Wang",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13214",
    "title": "Prior-itizing Privacy: A Bayesian Approach to Setting the Privacy Budget  in Differential Privacy",
    "abstract": "When releasing outputs from confidential data, agencies need to balance the analytical usefulness of the released data with the obligation to protect data subjects' confidentiality. For releases satisfying differential privacy, this balance is reflected by the parameter epsilon, known as the privacy budget. In practice, it can be difficult for agencies to select and interpret epsilon. We use Bayesian posterior probabilities of disclosure to provide a framework for setting epsilon. The agency decides how much posterior risk it is willing to accept in a data release at various levels of prior risk. Using a mathematical relationship among these probabilities and epsilon, the agency selects the maximum epsilon that ensures the posterior-to-prior ratios are acceptable for all values of prior disclosure risk. The framework applies to any differentially private mechanism. ",
    "url": "https://arxiv.org/abs/2306.13214",
    "authors": [
      "Zeki Kazan",
      "Jerome P. Reiter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.13215",
    "title": "ovla: Neural Network Ownership Verification using Latent Watermarks",
    "abstract": "Ownership verification for neural networks is important for protecting these models from illegal copying, free-riding, re-distribution and other intellectual property misuse. We present a novel methodology for neural network ownership verification based on the notion of latent watermarks. Existing ownership verification methods either modify or introduce constraints to the neural network parameters, which are accessible to an attacker in a white-box attack and can be harmful to the network's normal operation, or train the network to respond to specific watermarks in the inputs similar to data poisoning-based backdoor attacks, which are susceptible to backdoor removal techniques. In this paper, we address these problems by decoupling a network's normal operation from its responses to watermarked inputs during ownership verification. The key idea is to train the network such that the watermarks remain dormant unless the owner's secret key is applied to activate it. The secret key is realized as a specific perturbation only known to the owner to the network's parameters. We show that our approach offers strong defense against backdoor detection, backdoor removal and surrogate model attacks.In addition, our method provides protection against ambiguity attacks where the attacker either tries to guess the secret weight key or uses fine-tuning to embed their own watermarks with a different key into a pre-trained neural network. Experimental results demonstrate the advantages and effectiveness of our proposed approach. ",
    "url": "https://arxiv.org/abs/2306.13215",
    "authors": [
      "Feisi Fu",
      "Wenchao Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13216",
    "title": "Diverse Community Data for Benchmarking Data Privacy Algorithms",
    "abstract": "The Diverse Communities Data Excerpts are the core of a National Institute of Standards and Technology (NIST) program to strengthen understanding of tabular data deidentification technologies such as synthetic data. Synthetic data is an ambitious attempt to democratize the benefits of big data; it uses generative models to recreate sensitive personal data with new records for public release. However, it is vulnerable to the same bias and privacy issues that impact other machine learning applications, and can even amplify those issues. When deidentified data distributions introduce bias or artifacts, or leak sensitive information, they propagate these problems to downstream applications. Furthermore, real-world survey conditions such as diverse subpopulations, heterogeneous non-ordinal data spaces, and complex dependencies between features pose specific challenges for synthetic data algorithms. These observations motivate the need for real, diverse, and complex benchmark data to support a robust understanding of algorithm behavior. This paper introduces four contributions: new theoretical work on the relationship between diverse populations and challenges for equitable deidentification; public benchmark data focused on diverse populations and challenging features curated from the American Community Survey; an open source suite of evaluation metrology for deidentified datasets; and an archive of evaluation results on a broad collection of deidentification techniques. The initial set of evaluation results demonstrate the suitability of these tools for investigations in this field. ",
    "url": "https://arxiv.org/abs/2306.13216",
    "authors": [
      "Aniruddha Sen",
      "Christine Task",
      "Dhruv Kapur",
      "Gary Howarth",
      "Karan Bhagat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13250",
    "title": "Emergent Influence Networks in Good-Faith Online Discussions",
    "abstract": "Town hall-type debates are increasingly moving online, irrevocably transforming public discourse. Yet, we know relatively little about crucial social dynamics that determine which arguments are more likely to be successful. This study investigates the impact of one's position in the discussion network created via responses to others' arguments on one's persuasiveness in unfacilitated online debates. We propose a novel framework for measuring the impact of network position on persuasiveness, using a combination of social network analysis and machine learning. Complementing existing studies investigating the effect of linguistic aspects on persuasiveness, we show that the user's position in a discussion network influences their persuasiveness online. Moreover, the recognition of successful persuasion further increases this dominant network position. Our findings offer important insights into the complex social dynamics of online discourse and provide practical insights for organizations and individuals seeking to understand the interplay between influential positions in a discussion network and persuasive strategies in digital spaces. ",
    "url": "https://arxiv.org/abs/2306.13250",
    "authors": [
      "Henry K. Dambanemuya",
      "Daniel Romero",
      "Em\u0151ke-\u00c1gnes Horv\u00e1t"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2306.13271",
    "title": "Variational Counterfactual Prediction under Runtime Domain Corruption",
    "abstract": "To date, various neural methods have been proposed for causal effect estimation based on observational data, where a default assumption is the same distribution and availability of variables at both training and inference (i.e., runtime) stages. However, distribution shift (i.e., domain shift) could happen during runtime, and bigger challenges arise from the impaired accessibility of variables. This is commonly caused by increasing privacy and ethical concerns, which can make arbitrary variables unavailable in the entire runtime data and imputation impractical. We term the co-occurrence of domain shift and inaccessible variables runtime domain corruption, which seriously impairs the generalizability of a trained counterfactual predictor. To counter runtime domain corruption, we subsume counterfactual prediction under the notion of domain adaptation. Specifically, we upper-bound the error w.r.t. the target domain (i.e., runtime covariates) by the sum of source domain error and inter-domain distribution distance. In addition, we build an adversarially unified variational causal effect model, named VEGAN, with a novel two-stage adversarial domain adaptation scheme to reduce the latent distribution disparity between treated and control groups first, and between training and runtime variables afterwards. We demonstrate that VEGAN outperforms other state-of-the-art baselines on individual-level treatment effect estimation in the presence of runtime domain corruption on benchmark datasets. ",
    "url": "https://arxiv.org/abs/2306.13271",
    "authors": [
      "Hechuan Wen",
      "Tong Chen",
      "Li Kheng Chai",
      "Shazia Sadiq",
      "Junbin Gao",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.13273",
    "title": "A First Order Meta Stackelberg Method for Robust Federated Learning  (Technical Report)",
    "abstract": "Recent research efforts indicate that federated learning (FL) systems are vulnerable to a variety of security breaches. While numerous defense strategies have been suggested, they are mainly designed to counter specific attack patterns and lack adaptability, rendering them less effective when facing uncertain or adaptive threats. This work models adversarial FL as a Bayesian Stackelberg Markov game (BSMG) between the defender and the attacker to address the lack of adaptability to uncertain adaptive attacks. We further devise an effective meta-learning technique to solve for the Stackelberg equilibrium, leading to a resilient and adaptable defense. The experiment results suggest that our meta-Stackelberg learning approach excels in combating intense model poisoning and backdoor attacks of indeterminate types. ",
    "url": "https://arxiv.org/abs/2306.13273",
    "authors": [
      "Henger Li",
      "Tianyi Xu",
      "Tao Li",
      "Yunian Pan",
      "Quanyan Zhu",
      "Zizhan Zheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2306.13287",
    "title": "Optimal Power Flow for Integrated Primary-Secondary Distribution  Networks with Service Transformers",
    "abstract": "Secondary distribution networks (SDNets) play an increasingly important role in smart grids due to a high proliferation of distributed energy resources (DERs) in SDNets. However, most existing optimal power flow (OPF) problems do not take into account SDNets with service transformers. Handling the nonlinear and nonconvex SDNet power flow constraints is still an outstanding problem. To meet this gap, we first utilize the second-order cone programming relaxation and linearization to make service transformer constraints convex, respectively. Then, the linearized triplex service line power flow model, including its compact matrix-vector form, is further developed to compose the SDNet OPF model with our proposed service transformer model. This proposed SDNet OPF model can be easily embedded into existing primary distribution network (PDNet) OPF models, resulting in a holistic power system decision-making solution for integrated primary-secondary distribution networks. A case study is presented for an integrated primary-secondary distribution network that demonstrates the practical effectiveness of this model. ",
    "url": "https://arxiv.org/abs/2306.13287",
    "authors": [
      "Rui Cheng",
      "Naihao Shi",
      "Zhaoyu Wang",
      "Zixiao Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.13290",
    "title": "Robustness of Segment Anything Model (SAM) for Autonomous Driving in  Adverse Weather Conditions",
    "abstract": "Segment Anything Model (SAM) has gained considerable interest in recent times for its remarkable performance and has emerged as a foundational model in computer vision. It has been integrated in diverse downstream tasks, showcasing its strong zero-shot transfer capabilities. Given its impressive performance, there is a strong desire to apply SAM in autonomous driving to improve the performance of vision tasks, particularly in challenging scenarios such as driving under adverse weather conditions. However, its robustness under adverse weather conditions remains uncertain. In this work, we investigate the application of SAM in autonomous driving and specifically explore its robustness under adverse weather conditions. Overall, this work aims to enhance understanding of SAM's robustness in challenging scenarios before integrating it into autonomous driving vision tasks, providing valuable insights for future applications. ",
    "url": "https://arxiv.org/abs/2306.13290",
    "authors": [
      "Xinru Shan",
      "Chaoning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13292",
    "title": "Variance-Covariance Regularization Improves Representation Learning",
    "abstract": "Transfer learning has emerged as a key approach in the machine learning domain, enabling the application of knowledge derived from one domain to improve performance on subsequent tasks. Given the often limited information about these subsequent tasks, a strong transfer learning approach calls for the model to capture a diverse range of features during the initial pretraining stage. However, recent research suggests that, without sufficient regularization, the network tends to concentrate on features that primarily reduce the pretraining loss function. This tendency can result in inadequate feature learning and impaired generalization capability for target tasks. To address this issue, we propose Variance-Covariance Regularization (VCR), a regularization technique aimed at fostering diversity in the learned network features. Drawing inspiration from recent advancements in the self-supervised learning approach, our approach promotes learned representations that exhibit high variance and minimal covariance, thus preventing the network from focusing solely on loss-reducing features. We empirically validate the efficacy of our method through comprehensive experiments coupled with in-depth analytical studies on the learned representations. In addition, we develop an efficient implementation strategy that assures minimal computational overhead associated with our method. Our results indicate that VCR is a powerful and efficient method for enhancing transfer learning performance for both supervised learning and self-supervised learning, opening new possibilities for future research in this domain. ",
    "url": "https://arxiv.org/abs/2306.13292",
    "authors": [
      "Jiachen Zhu",
      "Ravid Shwartz-Ziv",
      "Yubei Chen",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13301",
    "title": "Deep Omni-supervised Learning for Rib Fracture Detection from Chest  Radiology Images",
    "abstract": "Deep learning (DL)-based rib fracture detection has shown promise of playing an important role in preventing mortality and improving patient outcome. Normally, developing DL-based object detection models requires huge amount of bounding box annotation. However, annotating medical data is time-consuming and expertise-demanding, making obtaining a large amount of fine-grained annotations extremely infeasible. This poses pressing need of developing label-efficient detection models to alleviate radiologists' labeling burden. To tackle this challenge, the literature of object detection has witnessed an increase of weakly-supervised and semi-supervised approaches, yet still lacks a unified framework that leverages various forms of fully-labeled, weakly-labeled, and unlabeled data. In this paper, we present a novel omni-supervised object detection network, ORF-Netv2, to leverage as much available supervision as possible. Specifically, a multi-branch omni-supervised detection head is introduced with each branch trained with a specific type of supervision. A co-training-based dynamic label assignment strategy is then proposed to enable flexibly and robustly learning from the weakly-labeled and unlabeled data. Extensively evaluation was conducted for the proposed framework with three rib fracture datasets on both chest CT and X-ray. By leveraging all forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the three datasets, respectively, surpassing the baseline detector which uses only box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively. Furthermore, ORF-Netv2 consistently outperforms other competitive label-efficient methods over various scenarios, showing a promising framework for label-efficient fracture detection. ",
    "url": "https://arxiv.org/abs/2306.13301",
    "authors": [
      "Zhizhong Chai",
      "Luyang Luo",
      "Huangjing Lin",
      "Pheng-Ann Heng",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13306",
    "title": "On minimum $t$-claw deletion in split graphs",
    "abstract": "For $t\\geq 3$, $K_{1, t}$ is called $t$-claw. In minimum $t$-claw deletion problem (\\texttt{Min-$t$-Claw-Del}), given a graph $G=(V, E)$, it is required to find a vertex set $S$ of minimum size such that $G[V\\setminus S]$ is $t$-claw free. In a split graph, the vertex set is partitioned into two sets such that one forms a clique and the other forms an independent set. Every $t$-claw in a split graph has a center vertex in the clique partition. This observation motivates us to consider the minimum one-sided bipartite $t$-claw deletion problem (\\texttt{Min-$t$-OSBCD}). Given a bipartite graph $G=(A \\cup B, E)$, in \\texttt{Min-$t$-OSBCD} it is asked to find a vertex set $S$ of minimum size such that $G[V \\setminus S]$ has no $t$-claw with the center vertex in $A$. A primal-dual algorithm approximates \\texttt{Min-$t$-OSBCD} within a factor of $t$. We prove that it is $\\UGC$-hard to approximate with a factor better than $t$. We also prove it is approximable within a factor of 2 for dense bipartite graphs. By using these results on \\texttt{Min-$t$-OSBCD}, we prove that \\texttt{Min-$t$-Claw-Del} is $\\UGC$-hard to approximate within a factor better than $t$, for split graphs. We also consider their complementary maximization problems and prove that they are $\\APX$-complete. ",
    "url": "https://arxiv.org/abs/2306.13306",
    "authors": [
      "Sounaka Mishra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.13334",
    "title": "Availability Analysis of Redundant and Replicated Cloud Services with  Bayesian Networks",
    "abstract": "Due to the growing complexity of modern data centers, failures are not uncommon any more. Therefore, fault tolerance mechanisms play a vital role in fulfilling the availability requirements. Multiple availability models have been proposed to assess compute systems, among which Bayesian network models have gained popularity in industry and research due to its powerful modeling formalism. In particular, this work focuses on assessing the availability of redundant and replicated cloud computing services with Bayesian networks. So far, research on availability has only focused on modeling either infrastructure or communication failures in Bayesian networks, but have not considered both simultaneously. This work addresses practical modeling challenges of assessing the availability of large-scale redundant and replicated services with Bayesian networks, including cascading and common-cause failures from the surrounding infrastructure and communication network. In order to ease the modeling task, this paper introduces a high-level modeling formalism to build such a Bayesian network automatically. Performance evaluations demonstrate the feasibility of the presented Bayesian network approach to assess the availability of large-scale redundant and replicated services. This model is not only applicable in the domain of cloud computing it can also be applied for general cases of local and geo-distributed systems. ",
    "url": "https://arxiv.org/abs/2306.13334",
    "authors": [
      "Otto Bibartiu",
      "Frank D\u00fcrr",
      "Kurt Rothermel",
      "Beate Ottenw\u00e4lder",
      "Andreas Grau"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.13337",
    "title": "Patch-Level Contrasting without Patch Correspondence for Accurate and  Dense Contrastive Representation Learning",
    "abstract": "We propose ADCLR: A ccurate and D ense Contrastive Representation Learning, a novel self-supervised learning framework for learning accurate and dense vision representation. To extract spatial-sensitive information, ADCLR introduces query patches for contrasting in addition with global contrasting. Compared with previous dense contrasting methods, ADCLR mainly enjoys three merits: i) achieving both global-discriminative and spatial-sensitive representation, ii) model-efficient (no extra parameters in addition to the global contrasting baseline), and iii) correspondence-free and thus simpler to implement. Our approach achieves new state-of-the-art performance for contrastive methods. On classification tasks, for ViT-S, ADCLR achieves 77.5% top-1 accuracy on ImageNet with linear probing, outperforming our baseline (DINO) without our devised techniques as plug-in, by 0.5%. For ViT-B, ADCLR achieves 79.8%, 84.0% accuracy on ImageNet by linear probing and finetune, outperforming iBOT by 0.3%, 0.2% accuracy. For dense tasks, on MS-COCO, ADCLR achieves significant improvements of 44.3% AP on object detection, 39.7% AP on instance segmentation, outperforming previous SOTA method SelfPatch by 2.2% and 1.2%, respectively. On ADE20K, ADCLR outperforms SelfPatch by 1.0% mIoU, 1.2% mAcc on the segme ",
    "url": "https://arxiv.org/abs/2306.13337",
    "authors": [
      "Shaofeng Zhang",
      "Feng Zhu",
      "Rui Zhao",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13339",
    "title": "TrustGuard: GNN-based Robust and Explainable Trust Evaluation with  Dynamicity Support",
    "abstract": "Trust evaluation assesses trust relationships between entities and facilitates decision-making. Machine Learning (ML) shows great potential for trust evaluation owing to its learning capabilities. In recent years, Graph Neural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in dealing with graph data. This has motivated researchers to explore their use in trust evaluation, as trust relationships among entities can be modeled as a graph. However, current trust evaluation methods that employ GNNs fail to fully satisfy the dynamicity nature of trust, overlook the adverse effects of attacks on trust evaluation, and cannot provide convincing explanations on evaluation results. To address these problems, in this paper, we propose TrustGuard, a GNN-based accurate trust evaluation model that supports trust dynamicity, is robust against typical attacks, and provides explanations through visualization. Specifically, TrustGuard is designed with a layered architecture that contains a snapshot input layer, a spatial aggregation layer, a temporal aggregation layer, and a prediction layer. Among them, the spatial aggregation layer can be plugged into a defense mechanism for a robust aggregation of local trust relationships, and the temporal aggregation layer applies an attention mechanism for effective learning of temporal patterns. Extensive experiments on two real-world datasets show that TrustGuard outperforms state-of-the-art GNN-based trust evaluation models with respect to trust prediction across single-timeslot and multi-timeslot, even in the presence of attacks. In particular, TrustGuard can explain its evaluation results by visualizing both spatial and temporal views. ",
    "url": "https://arxiv.org/abs/2306.13339",
    "authors": [
      "Jie Wang",
      "Zheng Yan",
      "Jiahe Lan",
      "Elisa Bertino",
      "Witold Pedrycz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13347",
    "title": "High-Speed Area-Efficient Hardware Architecture for the Efficient  Detection of Faults in a Bit-Parallel Multiplier Utilizing the Polynomial  Basis of GF(2m)",
    "abstract": "The utilization of finite field multipliers is pervasive in contemporary digital systems, with hardware implementation for bit parallel operation often necessitating millions of logic gates. However, various digital design issues, whether natural or stemming from soft errors, can result in gate malfunction, ultimately leading to erroneous multiplier outputs. Thus, to prevent susceptibility to error, it is imperative to employ an effective finite field multiplier implementation that boasts a robust fault detection capability. This study proposes a novel fault detection scheme for a recent bit-parallel polynomial basis multiplier over GF(2m), intended to achieve optimal fault detection performance for finite field multipliers while simultaneously maintaining a low-complexity implementation, a favored attribute in resource-constrained applications like smart cards. The primary concept behind the proposed approach is centered on the implementation of a BCH decoder that utilizes re-encoding technique and FIBM algorithm in its first and second sub-modules, respectively. This approach serves to address hardware complexity concerns while also making use of Berlekamp-Rumsey-Solomon (BRS) algorithm and Chien search method in the third sub-module of the decoder to effectively locate errors with minimal delay. The results of our synthesis indicate that our proposed error detection and correction architecture for a 45-bit multiplier with 5-bit errors achieves a 37% and 49% reduction in critical path delay compared to existing designs. Furthermore, the hardware complexity associated with a 45-bit multiplicand that contains 5 errors is confined to a mere 80%, which is significantly lower than the most exceptional BCH-based fault recognition methodologies, including TMR, Hamming's single error correction, and LDPC-based procedures within the realm of finite field multiplication. ",
    "url": "https://arxiv.org/abs/2306.13347",
    "authors": [
      "Saeideh Nabipour",
      "Javad Javidan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2306.13349",
    "title": "Multi-objective optimization based network control principles for  identifying personalized drug targets with cancer",
    "abstract": "It is a big challenge to develop efficient models for identifying personalized drug targets (PDTs) from high-dimensional personalized genomic profile of individual patients. Recent structural network control principles have introduced a new approach to discover PDTs by selecting an optimal set of driver genes in personalized gene interaction network (PGIN). However, most of current methods only focus on controlling the system through a minimum driver-node set and ignore the existence of multiple candidate driver-node sets for therapeutic drug target identification in PGIN. Therefore, this paper proposed multi-objective optimization-based structural network control principles (MONCP) by considering minimum driver nodes and maximum prior-known drug-target information. To solve MONCP, a discrete multi-objective optimization problem is formulated with many constrained variables, and a novel evolutionary optimization model called LSCV-MCEA was developed by adapting a multi-tasking framework and a rankings-based fitness function method. With genomics data of patients with breast or lung cancer from The Cancer Genome Atlas database, the effectiveness of LSCV-MCEA was validated. The experimental results indicated that compared with other advanced methods, LSCV-MCEA can more effectively identify PDTs with the highest Area Under the Curve score for predicting clinically annotated combinatorial drugs. Meanwhile, LSCV-MCEA can more effectively solve MONCP than other evolutionary optimization methods in terms of algorithm convergence and diversity. Particularly, LSCV-MCEA can efficiently detect disease signals for individual patients with BRCA cancer. The study results show that multi-objective optimization can solve structural network control principles effectively and offer a new perspective for understanding tumor heterogeneity in cancer precision medicine. ",
    "url": "https://arxiv.org/abs/2306.13349",
    "authors": [
      "Jing Liang",
      "Zhuo Hu",
      "Zong-Wei Li",
      "Kang-Jia Qiao",
      "Wei-Feng Guo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.13366",
    "title": "Lesion Detection on Leaves using Class Activation Maps",
    "abstract": "Lesion detection on plant leaves is a critical task in plant pathology and agricultural research. Identifying lesions enables assessing the severity of plant diseases and making informed decisions regarding disease control measures and treatment strategies. To detect lesions, there are studies that propose well-known object detectors. However, training object detectors to detect small objects such as lesions can be problematic. In this study, we propose a method for lesion detection on plant leaves utilizing class activation maps generated by a ResNet-18 classifier. In the test set, we achieved a 0.45 success rate in predicting the locations of lesions in leaves. Our study presents a novel approach for lesion detection on plant leaves by utilizing CAMs generated by a ResNet classifier while eliminating the need for a lesion annotation process. ",
    "url": "https://arxiv.org/abs/2306.13366",
    "authors": [
      "Enes Sadi Uysal",
      "Deniz Sen",
      "Ahmet Haydar Ornek",
      "Ahmet Emin Yetkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.13382",
    "title": "OptMSM: Optimizing Multi-Scenario Modeling for Click-Through Rate  Prediction",
    "abstract": "A large-scale industrial recommendation platform typically consists of multiple associated scenarios, requiring a unified click-through rate (CTR) prediction model to serve them simultaneously. Existing approaches for multi-scenario CTR prediction generally consist of two main modules: i) a scenario-aware learning module that learns a set of multi-functional representations with scenario-shared and scenario-specific information from input features, and ii) a scenario-specific prediction module that serves each scenario based on these representations. However, most of these approaches primarily focus on improving the former module and neglect the latter module. This can result in challenges such as increased model parameter size, training difficulty, and performance bottlenecks for each scenario. To address these issues, we propose a novel framework called OptMSM (\\textbf{Opt}imizing \\textbf{M}ulti-\\textbf{S}cenario \\textbf{M}odeling). First, we introduce a simplified yet effective scenario-enhanced learning module to alleviate the aforementioned challenges. Specifically, we partition the input features into scenario-specific and scenario-shared features, which are mapped to specific information embedding encodings and a set of shared information embeddings, respectively. By imposing an orthogonality constraint on the shared information embeddings to facilitate the disentanglement of shared information corresponding to each scenario, we combine them with the specific information embeddings to obtain multi-functional representations. Second, we introduce a scenario-specific hypernetwork in the scenario-specific prediction module to capture interactions within each scenario more effectively, thereby alleviating the performance bottlenecks. Finally, we conduct extensive offline experiments and an online A/B test to demonstrate the effectiveness of OptMSM. ",
    "url": "https://arxiv.org/abs/2306.13382",
    "authors": [
      "Xing Tang",
      "Yang Qiao",
      "Yuwen Fu",
      "Fuyuan Lyu",
      "Dugang Liu",
      "Xiuqiang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.13385",
    "title": "Solving a class of multi-scale elliptic PDEs by means of Fourier-based  mixed physics informed neural networks",
    "abstract": "Deep neural networks have received significant attention due to their simplicity and flexibility in the fields of engineering and scientific calculation. In this work, we probe into solving a class of elliptic PDEs with multiple scales by means of Fourier-based mixed physics-informed neural networks (called FMPINN), and its solver is configured as a multi-scale DNN model. Unlike the classical PINN method, a dual (flux) variable about the rough coefficient of PDEs is introduced to avoid the ill-condition of neural tangent kernel matrix that resulted from the oscillating coefficient of multi-scale PDEs. Therefore, apart from the physical conservation laws, the discrepancy between the auxiliary variables and the gradients of multi-scale coefficients is incorporated into the cost function, then leveraging the optimization method to yield the satisfactory solution of PDEs by minimizing the defined loss. Additionally, a novel trigonometric activation function is introduced for FMPINN, which is suited for representing the derivatives of complex target functions. Handling the input data by Fourier feature mapping will effectively improve the capacity of deep neural networks to solve high-frequency problems. Finally, by introducing several numerical examples of multi-scale problems in various dimensional Euclidean spaces, we validate the efficiency and robustness of the proposed FMPINN algorithm in both low-frequency and high-frequency oscillation cases. ",
    "url": "https://arxiv.org/abs/2306.13385",
    "authors": [
      "Xi'an Li",
      "Jinran Wu",
      "Zhi-Qin John Xu",
      "You-Gan Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.13387",
    "title": "Improved Competitive Ratios for Online Bipartite Matching on Degree  Bounded Graphs",
    "abstract": "We consider the online bipartite matching problem on $(k,d)$-bounded graphs, where each online vertex has at most $d$ neighbors, each offline vertex has at least $k$ neighbors, and $k\\geq d\\geq 2$. The model of $(k,d)$-bounded graphs is proposed by Naor and Wajc (EC 2015 and TEAC 2018) to model the online advertising applications in which offline advertisers are interested in a large number of ad slots, while each online ad slot is interesting to a small number of advertisers. They proposed deterministic and randomized algorithms with a competitive ratio of $1 - (1-1/d)^k$ for the problem, and show that the competitive ratio is optimal for deterministic algorithms. They also raised the open questions of whether strictly better competitive ratios can be achieved using randomized algorithms, for both the adversarial and stochastic arrival models. In this paper we answer both of their open problems affirmatively. For the adversarial arrival model, we propose a randomized algorithm with competitive ratio $1 - (1-1/d)^k + \\Omega(d^{-4}\\cdot e^{-\\frac{k}{d}})$ for all $k\\geq d\\geq 2$. We also consider the stochastic model and show that even better competitive ratios can be achieved. We show that for all $k\\geq d\\geq 2$, the competitive ratio is always at least $0.8237$. We further consider the $b$-matching problem when each offline vertex can be matched at most $b$ times, and provide several competitive ratio lower bounds for the adversarial and stochastic model. ",
    "url": "https://arxiv.org/abs/2306.13387",
    "authors": [
      "Yilong Feng",
      "Xiaowei Wu",
      "Shengwei Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.13388",
    "title": "Preventing EFail Attacks with Client-Side WebAssembly: The Case of Swiss  Post's IncaMail",
    "abstract": "Traditional email encryption schemes are vulnerable to EFail attacks, which exploit the lack of message authentication by manipulating ciphertexts and exfiltrating plaintext via HTML backchannels. Swiss Post's IncaMail, a secure email service for transmitting legally binding, encrypted, and verifiable emails, counters EFail attacks using an authenticated-encryption with associated data (AEAD) encryption scheme to ensure message privacy and authentication between servers. IncaMail relies on a trusted infrastructure backend and encrypts messages per user policy. This paper presents a revised IncaMail architecture that offloads the majority of cryptographic operations to clients, offering benefits such as reduced computational load and energy footprint, relaxed trust assumptions, and per-message encryption key policies. Our proof-of-concept prototype and benchmarks demonstrate the robustness of the proposed scheme, with client-side WebAssembly-based cryptographic operations yielding significant performance improvements (up to ~14x) over conventional JavaScript implementations. ",
    "url": "https://arxiv.org/abs/2306.13388",
    "authors": [
      "Pascal Gerig",
      "J\u00e4mes M\u00e9n\u00e9trey",
      "Baptiste Lanoix",
      "Florian Stoller",
      "Pascal Felber",
      "Marcelo Pasin",
      "Valerio Schiavoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.13411",
    "title": "Neural Algorithmic Reasoning Without Intermediate Supervision",
    "abstract": "Neural Algorithmic Reasoning is an emerging area of machine learning focusing on building models which can imitate the execution of classic algorithms, such as sorting, shortest paths, etc. One of the main challenges is to learn algorithms that are able to generalize to out-of-distribution data, in particular with significantly larger input sizes. Recent work on this problem has demonstrated the advantages of learning algorithms step-by-step, giving models access to all intermediate steps of the original algorithm. In this work, we instead focus on learning neural algorithmic reasoning only from the input-output pairs without appealing to the intermediate supervision. We propose simple but effective architectural improvements and also build a self-supervised objective that can regularise intermediate computations of the model without access to the algorithm trajectory. We demonstrate that our approach is competitive to its trajectory-supervised counterpart on tasks from the CLRS Algorithmic Reasoning Benchmark and achieves new state-of-the-art results for several problems, including sorting, where we obtain significant improvements. Thus, learning without intermediate supervision is a promising direction for further research on neural reasoners. ",
    "url": "https://arxiv.org/abs/2306.13411",
    "authors": [
      "Gleb Rodionov",
      "Liudmila Prokhorenkova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13414",
    "title": "A Low-Complexity Design for Rate-Splitting Multiple Access in Overloaded  MIMO Networks",
    "abstract": "Rate-Splitting Multiple Access (RSMA) is a robust multiple access scheme for multi-antenna wireless networks. In this work, we study the performance of RSMA in downlink overloaded networks, where the number of transmit antennas is smaller than the number of users. We provide analysis and closed-form solutions for optimal power and rate allocations that maximize max-min fairness when low-complexity precoding schemes are employed. The derived closed-form solutions are used to propose a low-complexity RSMA system design for precoder selection and resource allocation for arbitrary number of users and antennas under perfect Channel State Information at the Transmitter (CSIT). We compare the performance of the proposed design with benchmark designs based on Space Division Multiple Access (SDMA) to show that the proposed low-complexity RSMA design achieves a significantly higher performance gain in overloaded networks. ",
    "url": "https://arxiv.org/abs/2306.13414",
    "authors": [
      "Onur Dizdar",
      "Ata Sattarzadeh",
      "Yi Xien Yap",
      "Stephen Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2306.13420",
    "title": "Towards Unseen Triples: Effective Text-Image-joint Learning for Scene  Graph Generation",
    "abstract": "Scene Graph Generation (SGG) aims to structurally and comprehensively represent objects and their connections in images, it can significantly benefit scene understanding and other related downstream tasks. Existing SGG models often struggle to solve the long-tailed problem caused by biased datasets. However, even if these models can fit specific datasets better, it may be hard for them to resolve the unseen triples which are not included in the training set. Most methods tend to feed a whole triple and learn the overall features based on statistical machine learning. Such models have difficulty predicting unseen triples because the objects and predicates in the training set are combined differently as novel triples in the test set. In this work, we propose a Text-Image-joint Scene Graph Generation (TISGG) model to resolve the unseen triples and improve the generalisation capability of the SGG models. We propose a Joint Fearture Learning (JFL) module and a Factual Knowledge based Refinement (FKR) module to learn object and predicate categories separately at the feature level and align them with corresponding visual features so that the model is no longer limited to triples matching. Besides, since we observe the long-tailed problem also affects the generalization ability, we design a novel balanced learning strategy, including a Charater Guided Sampling (CGS) and an Informative Re-weighting (IR) module, to provide tailor-made learning methods for each predicate according to their characters. Extensive experiments show that our model achieves state-of-the-art performance. In more detail, TISGG boosts the performances by 11.7% of zR@20(zero-shot recall) on the PredCls sub-task on the Visual Genome dataset. ",
    "url": "https://arxiv.org/abs/2306.13420",
    "authors": [
      "Qianji Di",
      "Wenxi Ma",
      "Zhongang Qi",
      "Tianxiang Hou",
      "Ying Shan",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13427",
    "title": "A Robustness Analysis to Structured Channel Tampering Over  Secure-by-Design Consensus Networks",
    "abstract": "This work addresses multi-agent consensus networks where adverse attackers affect the convergence performances of the protocol by manipulating the edge weights. We generalize (Fabris and Zelazo, 2022) and provide guarantees on the agents' agreement in the presence of attacks on multiple links in the network. A stability analysis is conducted to show the robustness to channel tampering in the scenario where part of the codeword, corresponding to the value of the edge weights, is corrupted. Exploiting the built-in objective coding, we show how to compensate the conservatism that may emerge because of multiple threats in exchange for higher encryption capabilities. Numerical examples related to semi-autonomous networks are provided. ",
    "url": "https://arxiv.org/abs/2306.13427",
    "authors": [
      "Marco Fabris",
      "Daniel Zelazo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.13450",
    "title": "MUSER: A MUlti-Step Evidence Retrieval Enhancement Framework for Fake  News Detection",
    "abstract": "The ease of spreading false information online enables individuals with malicious intent to manipulate public opinion and destabilize social stability. Recently, fake news detection based on evidence retrieval has gained popularity in an effort to identify fake news reliably and reduce its impact. Evidence retrieval-based methods can improve the reliability of fake news detection by computing the textual consistency between the evidence and the claim in the news. In this paper, we propose a framework for fake news detection based on MUlti-Step Evidence Retrieval enhancement (MUSER), which simulates the steps of human beings in the process of reading news, summarizing, consulting materials, and inferring whether the news is true or fake. Our model can explicitly model dependencies among multiple pieces of evidence, and perform multi-step associations for the evidence required for news verification through multi-step retrieval. In addition, our model is able to automatically collect existing evidence through paragraph retrieval and key evidence selection, which can save the tedious process of manual evidence collection. We conducted extensive experiments on real-world datasets in different languages, and the results demonstrate that our proposed model outperforms state-of-the-art baseline methods for detecting fake news by at least 3% in F1-Macro and 4% in F1-Micro. Furthermore, it provides interpretable evidence for end users. ",
    "url": "https://arxiv.org/abs/2306.13450",
    "authors": [
      "Hao Liao",
      "Jiaohao Peng",
      "Zhanyi Huang",
      "Wei Zhang",
      "Guanghua Li",
      "Kai Shu",
      "Xing Xie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.13452",
    "title": "A Graph Neural Network Approach for Temporal Mesh Blending and  Correspondence",
    "abstract": "We have proposed a self-supervised deep learning framework for solving the mesh blending problem in scenarios where the meshes are not in correspondence. To solve this problem, we have developed Red-Blue MPNN, a novel graph neural network that processes an augmented graph to estimate the correspondence. We have designed a novel conditional refinement scheme to find the exact correspondence when certain conditions are satisfied. We further develop a graph neural network that takes the aligned meshes and the time value as input and fuses this information to process further and generate the desired result. Using motion capture datasets and human mesh designing software, we create a large-scale synthetic dataset consisting of temporal sequences of human meshes in motion. Our results demonstrate that our approach generates realistic deformation of body parts given complex inputs. ",
    "url": "https://arxiv.org/abs/2306.13452",
    "authors": [
      "Aalok Gangopadhyay",
      "Abhinav Narayan Harish",
      "Prajwal Singh",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2306.13455",
    "title": "DreamEditor: Text-Driven 3D Scene Editing with Neural Fields",
    "abstract": "Neural fields have achieved impressive advancements in view synthesis and scene reconstruction. However, editing these neural fields remains challenging due to the implicit encoding of geometry and texture information. In this paper, we propose DreamEditor, a novel framework that enables users to perform controlled editing of neural fields using text prompts. By representing scenes as mesh-based neural fields, DreamEditor allows localized editing within specific regions. DreamEditor utilizes the text encoder of a pretrained text-to-Image diffusion model to automatically identify the regions to be edited based on the semantics of the text prompts. Subsequently, DreamEditor optimizes the editing region and aligns its geometry and texture with the text prompts through score distillation sampling [29]. Extensive experiments have demonstrated that DreamEditor can accurately edit neural fields of real-world scenes according to the given text prompts while ensuring consistency in irrelevant areas. DreamEditor generates highly realistic textures and geometry, significantly surpassing previous works in both quantitative and qualitative evaluations. ",
    "url": "https://arxiv.org/abs/2306.13455",
    "authors": [
      "Jingyu Zhuang",
      "Chen Wang",
      "Lingjie Liu",
      "Liang Lin",
      "Guanbin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13456",
    "title": "Enhanced Dengue Outbreak Prediction in Tamilnadu using Meteorological  and Entomological data",
    "abstract": "This paper focuses on studying the impact of climate data and vector larval indices on dengue outbreak. After a comparative study of the various LSTM models, Bidirectional Stacked LSTM network is selected to analyze the time series climate data and health data collected for the state of Tamil Nadu (India), for the period 2014 to 2020. Prediction accuracy of the model is significantly improved by including the mosquito larval index, an indication of VBD control measure. ",
    "url": "https://arxiv.org/abs/2306.13456",
    "authors": [
      "Varalakshmi M",
      "Daphne Lopez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13467",
    "title": "Incorporating Graph Information in Transformer-based AMR Parsing",
    "abstract": "Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that aims at providing a semantic graph abstraction representing a given text. Current approaches are based on autoregressive language models such as BART or T5, fine-tuned through Teacher Forcing to obtain a linearized version of the AMR graph from a sentence. In this paper, we present LeakDistill, a model and method that explores a modification to the Transformer architecture, using structural adapters to explicitly incorporate graph information into the learned representations and improve AMR parsing performance. Our experiments show how, by employing word-to-node alignment to embed graph structural information into the encoder at training time, we can obtain state-of-the-art AMR parsing through self-knowledge distillation, even without the use of additional data. We release the code at \\url{this http URL}. ",
    "url": "https://arxiv.org/abs/2306.13467",
    "authors": [
      "Pavlo Vasylenko",
      "Pere-Llu\u00eds Huguet Cabot",
      "Abelardo Carlos Mart\u00ednez Lorenzo",
      "Roberto Navigli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.13474",
    "title": "Efficient Online Processing with Deep Neural Networks",
    "abstract": "The capabilities and adoption of deep neural networks (DNNs) grow at an exhilarating pace: Vision models accurately classify human actions in videos and identify cancerous tissue in medical scans as precisely than human experts; large language models answer wide-ranging questions, generate code, and write prose, becoming the topic of everyday dinner-table conversations. Even though their uses are exhilarating, the continually increasing model sizes and computational complexities have a dark side. The economic cost and negative environmental externalities of training and serving models is in evident disharmony with financial viability and climate action goals. Instead of pursuing yet another increase in predictive performance, this dissertation is dedicated to the improvement of neural network efficiency. Specifically, a core contribution addresses the efficiency aspects during online inference. Here, the concept of Continual Inference Networks (CINs) is proposed and explored across four publications. CINs extend prior state-of-the-art methods developed for offline processing of spatio-temporal data and reuse their pre-trained weights, improving their online processing efficiency by an order of magnitude. These advances are attained through a bottom-up computational reorganization and judicious architectural modifications. The benefit to online inference is demonstrated by reformulating several widely used network architectures into CINs, including 3D CNNs, ST-GCNs, and Transformer Encoders. An orthogonal contribution tackles the concurrent adaptation and computational acceleration of a large source model into multiple lightweight derived models. Drawing on fusible adapter networks and structured pruning, Structured Pruning Adapters achieve superior predictive accuracy under aggressive pruning using significantly fewer learned weights compared to fine-tuning with pruning. ",
    "url": "https://arxiv.org/abs/2306.13474",
    "authors": [
      "Lukas Hedegaard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13493",
    "title": "Smoothed Circulant Embedding with Applications to Multilevel Monte Carlo  Methods for PDEs with Random Coefficients",
    "abstract": "We consider the computational efficiency of Monte Carlo (MC) and Multilevel Monte Carlo (MLMC) methods applied to partial differential equations with random coefficients. These arise, for example, in groundwater flow modelling, where a commonly used model for the unknown parameter is a random field. We make use of the circulant embedding procedure for sampling from the aforementioned coefficient. To improve the computational complexity of the MLMC estimator in the case of highly oscillatory random fields, we devise and implement a smoothing technique integrated into the circulant embedding method. This allows to choose the coarsest mesh on the first level of MLMC independently of the correlation length of the covariance function of the random field, leading to considerable savings in computational cost. We illustrate this with numerical experiments, where we see a saving of factor 5-10 in computational cost for accuracies of practical interest. ",
    "url": "https://arxiv.org/abs/2306.13493",
    "authors": [
      "Anastasia Istratuca",
      "Aretha Teckentrup"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.13500",
    "title": "Cascade Subspace Clustering for Outlier Detection",
    "abstract": "Many methods based on sparse and low-rank representation been developed along with guarantees of correct outlier detection. Self-representation states that a point in a subspace can always be expressed as a linear combination of other points in the subspace. A suitable Markov Chain can be defined on the self-representation and it allows us to recognize the difference between inliers and outliers. However, the reconstruction error of self-representation that is still informative to detect outlier detection, is neglected.Inspired by the gradient boosting, in this paper, we propose a new outlier detection framework that combines a series of weak \"outlier detectors\" into a single strong one in an iterative fashion by constructing multi-pass self-representation. At each stage, we construct a self-representation based on elastic-net and define a suitable Markov Chain on it to detect outliers. The residual of the self-representation is used for the next stage to learn the next weaker outlier detector. Such a stage will repeat many times. And the final decision of outliers is generated by the previous all results. Experimental results on image and speaker datasets demonstrate its superiority with respect to state-of-the-art sparse and low-rank outlier detection methods. ",
    "url": "https://arxiv.org/abs/2306.13500",
    "authors": [
      "Qi Yang",
      "Hao Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13515",
    "title": "Binary domain generalization for sparsifying binary neural networks",
    "abstract": "Binary neural networks (BNNs) are an attractive solution for developing and deploying deep neural network (DNN)-based applications in resource constrained devices. Despite their success, BNNs still suffer from a fixed and limited compression factor that may be explained by the fact that existing pruning methods for full-precision DNNs cannot be directly applied to BNNs. In fact, weight pruning of BNNs leads to performance degradation, which suggests that the standard binarization domain of BNNs is not well adapted for the task. This work proposes a novel more general binary domain that extends the standard binary one that is more robust to pruning techniques, thus guaranteeing improved compression and avoiding severe performance losses. We demonstrate a closed-form solution for quantizing the weights of a full-precision network into the proposed binary domain. Finally, we show the flexibility of our method, which can be combined with other pruning strategies. Experiments over CIFAR-10 and CIFAR-100 demonstrate that the novel approach is able to generate efficient sparse networks with reduced memory usage and run-time latency, while maintaining performance. ",
    "url": "https://arxiv.org/abs/2306.13515",
    "authors": [
      "Riccardo Schiavone",
      "Francesco Galati",
      "Maria A. Zuluaga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13526",
    "title": "Bridging the Performance Gap between DETR and R-CNN for Graphical Object  Detection in Document Images",
    "abstract": "This paper takes an important step in bridging the performance gap between DETR and R-CNN for graphical object detection. Existing graphical object detection approaches have enjoyed recent enhancements in CNN-based object detection methods, achieving remarkable progress. Recently, Transformer-based detectors have considerably boosted the generic object detection performance, eliminating the need for hand-crafted features or post-processing steps such as Non-Maximum Suppression (NMS) using object queries. However, the effectiveness of such enhanced transformer-based detection algorithms has yet to be verified for the problem of graphical object detection. Essentially, inspired by the latest advancements in the DETR, we employ the existing detection transformer with few modifications for graphical object detection. We modify object queries in different ways, using points, anchor boxes and adding positive and negative noise to the anchors to boost performance. These modifications allow for better handling of objects with varying sizes and aspect ratios, more robustness to small variations in object positions and sizes, and improved image discrimination between objects and non-objects. We evaluate our approach on the four graphical datasets: PubTables, TableBank, NTable and PubLaynet. Upon integrating query modifications in the DETR, we outperform prior works and achieve new state-of-the-art results with the mAP of 96.9\\%, 95.7\\% and 99.3\\% on TableBank, PubLaynet, PubTables, respectively. The results from extensive ablations show that transformer-based methods are more effective for document analysis analogous to other applications. We hope this study draws more attention to the research of using detection transformers in document image analysis. ",
    "url": "https://arxiv.org/abs/2306.13526",
    "authors": [
      "Tahira Shehzadi",
      "Khurram Azeem Hashmi",
      "Didier Stricker",
      "Marcus Liwicki",
      "Muhammad Zeshan Afzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13532",
    "title": "PathMLP: Smooth Path Towards High-order Homophily",
    "abstract": "Real-world graphs exhibit increasing heterophily, where nodes no longer tend to be connected to nodes with the same label, challenging the homophily assumption of classical graph neural networks (GNNs) and impeding their performance. Intriguingly, we observe that certain high-order information on heterophilous data exhibits high homophily, which motivates us to involve high-order information in node representation learning. However, common practices in GNNs to acquire high-order information mainly through increasing model depth and altering message-passing mechanisms, which, albeit effective to a certain extent, suffer from three shortcomings: 1) over-smoothing due to excessive model depth and propagation times; 2) high-order information is not fully utilized; 3) low computational efficiency. In this regard, we design a similarity-based path sampling strategy to capture smooth paths containing high-order homophily. Then we propose a lightweight model based on multi-layer perceptrons (MLP), named PathMLP, which can encode messages carried by paths via simple transformation and concatenation operations, and effectively learn node representations in heterophilous graphs through adaptive path aggregation. Extensive experiments demonstrate that our method outperforms baselines on 16 out of 20 datasets, underlining its effectiveness and superiority in alleviating the heterophily problem. In addition, our method is immune to over-smoothing and has high computational efficiency. ",
    "url": "https://arxiv.org/abs/2306.13532",
    "authors": [
      "Chenxuan Xie",
      "Jiajun Zhou",
      "Shengbo Gong",
      "Jiacheng Wan",
      "Jiaxu Qian",
      "Shanqing Yu",
      "Qi Xuan",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.13541",
    "title": "Torsion Graph Neural Networks",
    "abstract": "Geometric deep learning (GDL) models have demonstrated a great potential for the analysis of non-Euclidian data. They are developed to incorporate the geometric and topological information of non-Euclidian data into the end-to-end deep learning architectures. Motivated by the recent success of discrete Ricci curvature in graph neural network (GNNs), we propose TorGNN, an analytic Torsion enhanced Graph Neural Network model. The essential idea is to characterize graph local structures with an analytic torsion based weight formula. Mathematically, analytic torsion is a topological invariant that can distinguish spaces which are homotopy equivalent but not homeomorphic. In our TorGNN, for each edge, a corresponding local simplicial complex is identified, then the analytic torsion (for this local simplicial complex) is calculated, and further used as a weight (for this edge) in message-passing process. Our TorGNN model is validated on link prediction tasks from sixteen different types of networks and node classification tasks from three types of networks. It has been found that our TorGNN can achieve superior performance on both tasks, and outperform various state-of-the-art models. This demonstrates that analytic torsion is a highly efficient topological invariant in the characterization of graph structures and can significantly boost the performance of GNNs. ",
    "url": "https://arxiv.org/abs/2306.13541",
    "authors": [
      "Cong Shen",
      "Xiang Liu",
      "Jiawei Luo",
      "Kelin Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.13557",
    "title": "FPGA Implementation of Convolutional Neural Network for Real-Time  Handwriting Recognition",
    "abstract": "Machine Learning (ML) has recently been a skyrocketing field in Computer Science. As computer hardware engineers, we are enthusiastic about hardware implementations of popular software ML architectures to optimize their performance, reliability, and resource usage. In this project, we designed a highly-configurable, real-time device for recognizing handwritten letters and digits using an Altera DE1 FPGA Kit. We followed various engineering standards, including IEEE-754 32-bit Floating-Point Standard, Video Graphics Array (VGA) display protocol, Universal Asynchronous Receiver-Transmitter (UART) protocol, and Inter-Integrated Circuit (I2C) protocols to achieve the project goals. These significantly improved our design in compatibility, reusability, and simplicity in verifications. Following these standards, we designed a 32-bit floating-point (FP) instruction set architecture (ISA). We developed a 5-stage RISC processor in System Verilog to manage image processing, matrix multiplications, ML classifications, and user interfaces. Three different ML architectures were implemented and evaluated on our design: Linear Classification (LC), a 784-64-10 fully connected neural network (NN), and a LeNet-like Convolutional Neural Network (CNN) with ReLU activation layers and 36 classes (10 for the digits and 26 for the case-insensitive letters). The training processes were done in Python scripts, and the resulting kernels and weights were stored in hex files and loaded into the FPGA's SRAM units. Convolution, pooling, data management, and various other ML features were guided by firmware in our custom assembly language. This paper documents the high-level design block diagrams, interfaces between each System Verilog module, implementation details of our software and firmware components, and further discussions on potential impacts. ",
    "url": "https://arxiv.org/abs/2306.13557",
    "authors": [
      "Shichen",
      "Qiao",
      "Haining Qiu",
      "Lingkai",
      "Zhao",
      "Qikun Liu",
      "Eric J. Hoffman"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.13566",
    "title": "The MI-Motion Dataset and Benchmark for 3D Multi-Person Motion  Prediction",
    "abstract": "3D multi-person motion prediction is a challenging task that involves modeling individual behaviors and interactions between people. Despite the emergence of approaches for this task, comparing them is difficult due to the lack of standardized training settings and benchmark datasets. In this paper, we introduce the Multi-Person Interaction Motion (MI-Motion) Dataset, which includes skeleton sequences of multiple individuals collected by motion capture systems and refined and synthesized using a game engine. The dataset contains 167k frames of interacting people's skeleton poses and is categorized into 5 different activity scenes. To facilitate research in multi-person motion prediction, we also provide benchmarks to evaluate the performance of prediction methods in three settings: short-term, long-term, and ultra-long-term prediction. Additionally, we introduce a novel baseline approach that leverages graph and temporal convolutional networks, which has demonstrated competitive results in multi-person motion prediction. We believe that the proposed MI-Motion benchmark dataset and baseline will facilitate future research in this area, ultimately leading to better understanding and modeling of multi-person interactions. ",
    "url": "https://arxiv.org/abs/2306.13566",
    "authors": [
      "Xiaogang Peng",
      "Xiao Zhou",
      "Yikai Luo",
      "Hao Wen",
      "Yu Ding",
      "Zizhao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13576",
    "title": "Penalty Gradient Normalization for Generative Adversarial Networks",
    "abstract": "In this paper, we propose a novel normalization method called penalty gradient normalization (PGN) to tackle the training instability of Generative Adversarial Networks (GANs) caused by the sharp gradient space. Unlike existing work such as gradient penalty and spectral normalization, the proposed PGN only imposes a penalty gradient norm constraint on the discriminator function, which increases the capacity of the discriminator. Moreover, the proposed penalty gradient normalization can be applied to different GAN architectures with little modification. Extensive experiments on three datasets show that GANs trained with penalty gradient normalization outperform existing methods in terms of both Frechet Inception and Distance and Inception Score. ",
    "url": "https://arxiv.org/abs/2306.13576",
    "authors": [
      "Tian Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13584",
    "title": "Revisiting the Optimal PMU Placement Problem in Multi-Machine Power  Networks",
    "abstract": "To provide real-time visibility of physics-based states, phasor measurement units (PMUs) are deployed throughout power networks. PMU data enable real-time grid monitoring and control -- and is essential in transitioning to smarter grids. Various considerations are taken into account when determining the geographic, optimal PMU placements (OPP). This paper focuses on the control-theoretic, observability aspect of OPP. A myriad of studies have investigated observability-based formulations to determine the OPP within a transmission network. However, they have mostly adopted a simplified representation of system dynamics, ignored basic algebraic equations that model power flows, disregarded including renewables such as solar and wind, and did not model their uncertainty. Consequently, this paper revisits the observability-based OPP problem by addressing the literature's limitations. A nonlinear differential algebraic representation (NDAE) of the power system is considered and implicitly discretized -- using various different discretization approaches -- while explicitly accounting for uncertainty. A moving horizon estimation approach is explored to reconstruct the joint differential and algebraic initial states of the system, as a gateway to the OPP problem which is then formulated as a computationally tractable integer program (IP). Comprehensive numerical simulations on standard power networks are conducted to validate various aspects of this approach and test its robustness to various dynamical conditions. ",
    "url": "https://arxiv.org/abs/2306.13584",
    "authors": [
      "Mohamad H. Kazma",
      "Ahmad F. Taha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2306.13587",
    "title": "Creating Valid Adversarial Examples of Malware",
    "abstract": "Machine learning is becoming increasingly popular as a go-to approach for many tasks due to its world-class results. As a result, antivirus developers are incorporating machine learning models into their products. While these models improve malware detection capabilities, they also carry the disadvantage of being susceptible to adversarial attacks. Although this vulnerability has been demonstrated for many models in white-box settings, a black-box attack is more applicable in practice for the domain of malware detection. We present a generator of adversarial malware examples using reinforcement learning algorithms. The reinforcement learning agents utilize a set of functionality-preserving modifications, thus creating valid adversarial examples. Using the proximal policy optimization (PPO) algorithm, we achieved an evasion rate of 53.84% against the gradient-boosted decision tree (GBDT) model. The PPO agent previously trained against the GBDT classifier scored an evasion rate of 11.41% against the neural network-based classifier MalConv and an average evasion rate of 2.31% against top antivirus programs. Furthermore, we discovered that random application of our functionality-preserving portable executable modifications successfully evades leading antivirus engines, with an average evasion rate of 11.65%. These findings indicate that machine learning-based models used in malware detection systems are vulnerable to adversarial attacks and that better safeguards need to be taken to protect these systems. ",
    "url": "https://arxiv.org/abs/2306.13587",
    "authors": [
      "Matou\u0161 Koz\u00e1k",
      "Martin Jure\u010dek",
      "Mark Stamp",
      "Fabio Di Troia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.13614",
    "title": "Adversarial Robustness Certification for Bayesian Neural Networks",
    "abstract": "We study the problem of certifying the robustness of Bayesian neural networks (BNNs) to adversarial input perturbations. Given a compact set of input points $T \\subseteq \\mathbb{R}^m$ and a set of output points $S \\subseteq \\mathbb{R}^n$, we define two notions of robustness for BNNs in an adversarial setting: probabilistic robustness and decision robustness. Probabilistic robustness is the probability that for all points in $T$ the output of a BNN sampled from the posterior is in $S$. On the other hand, decision robustness considers the optimal decision of a BNN and checks if for all points in $T$ the optimal decision of the BNN for a given loss function lies within the output set $S$. Although exact computation of these robustness properties is challenging due to the probabilistic and non-convex nature of BNNs, we present a unified computational framework for efficiently and formally bounding them. Our approach is based on weight interval sampling, integration, and bound propagation techniques, and can be applied to BNNs with a large number of parameters, and independently of the (approximate) inference method employed to train the BNN. We evaluate the effectiveness of our methods on various regression and classification tasks, including an industrial regression benchmark, MNIST, traffic sign recognition, and airborne collision avoidance, and demonstrate that our approach enables certification of robustness and uncertainty of BNN predictions. ",
    "url": "https://arxiv.org/abs/2306.13614",
    "authors": [
      "Matthew Wicker",
      "Andrea Patane",
      "Luca Laurenti",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.13630",
    "title": "Offline Skill Graph (OSG): A Framework for Learning and Planning using  Offline Reinforcement Learning Skills",
    "abstract": "Reinforcement Learning has received wide interest due to its success in competitive games. Yet, its adoption in everyday applications is limited (e.g. industrial, home, healthcare, etc.). In this paper, we address this limitation by presenting a framework for planning over offline skills and solving complex tasks in real-world environments. Our framework is comprised of three modules that together enable the agent to learn from previously collected data and generalize over it to solve long-horizon tasks. We demonstrate our approach by testing it on a robotic arm that is required to solve complex tasks. ",
    "url": "https://arxiv.org/abs/2306.13630",
    "authors": [
      "Ben-ya Halevy",
      "Yehudit Aperstein",
      "Dotan Di Castro"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13651",
    "title": "Bring Your Own Data! Self-Supervised Evaluation for Large Language  Models",
    "abstract": "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set which can lead to misleading evaluations. To bypass these drawbacks, we propose a framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, and long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-supervised and human-supervised evaluations. The self-supervised paradigm complements current evaluation strategies that rely on labeled data. ",
    "url": "https://arxiv.org/abs/2306.13651",
    "authors": [
      "Neel Jain",
      "Khalid Saifullah",
      "Yuxin Wen",
      "John Kirchenbauer",
      "Manli Shu",
      "Aniruddha Saha",
      "Micah Goldblum",
      "Jonas Geiping",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13093",
    "title": "Robust Divergence Angle for Inter-satellite Laser Communications under  Target Deviation Uncertainty",
    "abstract": "Performance degradation due to target deviation by, for example, drift or jitter, presents a significant issue to inter-satellite laser communications. In particular, with periodic acquisition for positioning the satellite receiver, deviation may arise in the time period between two consecutive acquisition operations. One solution to mitigate the issue is to use a divergence angle at the transmitter being wider than that if the receiver position is perfectly known. However, as how the deviation would vary over time is generally very hard to predict or model, there is no clear clue for setting the divergence angle. We propose a robust optimization approach to the problem, with the advantage that no distribution of the deviation need to be modelled. Instead, a so-called uncertainty set (often defined in form of a convex set such as a polytope) is used, where each element represents a possible scenario, i.e., a sequence of deviation values over time. Robust optimization seeks the solution that maximizes the performance (e.g., sum rate) that can be guaranteed, no matter which scenario in the uncertainty set materializes. To solve the robust optimization problem, we deploy a process of alternately solving a decision maker's problem and an adversarial problem. The former optimizes the divergence angle for a subset of the uncertainty set, whereas the latter is used to explore if the subset needs to be augmented. Simulation results show the approach leads to significantly more robust performance than using the divergence angle as if there is no deviation, or other ad-hoc schemes. ",
    "url": "https://arxiv.org/abs/2306.13093",
    "authors": [
      "Zhanwei Yu",
      "Yi Zhao",
      "Di Yuan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2306.13101",
    "title": "BrainNet: Epileptic Wave Detection from SEEG with Hierarchical Graph  Diffusion Learning",
    "abstract": "Epilepsy is one of the most serious neurological diseases, affecting 1-2% of the world's population. The diagnosis of epilepsy depends heavily on the recognition of epileptic waves, i.e., disordered electrical brainwave activity in the patient's brain. Existing works have begun to employ machine learning models to detect epileptic waves via cortical electroencephalogram (EEG). However, the recently developed stereoelectrocorticography (SEEG) method provides information in stereo that is more precise than conventional EEG, and has been broadly applied in clinical practice. Therefore, we propose the first data-driven study to detect epileptic waves in a real-world SEEG dataset. While offering new opportunities, SEEG also poses several challenges. In clinical practice, epileptic wave activities are considered to propagate between different regions in the brain. These propagation paths, also known as the epileptogenic network, are deemed to be a key factor in the context of epilepsy surgery. However, the question of how to extract an exact epileptogenic network for each patient remains an open problem in the field of neuroscience. To address these challenges, we propose a novel model (BrainNet) that jointly learns the dynamic diffusion graphs and models the brain wave diffusion patterns. In addition, our model effectively aids in resisting label imbalance and severe noise by employing several self-supervised learning tasks and a hierarchical framework. By experimenting with the extensive real SEEG dataset obtained from multiple patients, we find that BrainNet outperforms several latest state-of-the-art baselines derived from time-series analysis. ",
    "url": "https://arxiv.org/abs/2306.13101",
    "authors": [
      "Junru Chen",
      "Yang Yang",
      "Tao Yu",
      "Yingying Fan",
      "Xiaolong Mo",
      "Carl Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13102",
    "title": "MBrain: A Multi-channel Self-Supervised Learning Framework for Brain  Signals",
    "abstract": "Brain signals are important quantitative data for understanding physiological activities and diseases of human brain. Most existing studies pay attention to supervised learning methods, which, however, require high-cost clinical labels. In addition, the huge difference in the clinical patterns of brain signals measured by invasive (e.g., SEEG) and non-invasive (e.g., EEG) methods leads to the lack of a unified method. To handle the above issues, we propose to study the self-supervised learning (SSL) framework for brain signals that can be applied to pre-train either SEEG or EEG data. Intuitively, brain signals, generated by the firing of neurons, are transmitted among different connecting structures in human brain. Inspired by this, we propose MBrain to learn implicit spatial and temporal correlations between different channels (i.e., contacts of the electrode, corresponding to different brain areas) as the cornerstone for uniformly modeling different types of brain signals. Specifically, we represent the spatial correlation by a graph structure, which is built with proposed multi-channel CPC. We theoretically prove that optimizing the goal of multi-channel CPC can lead to a better predictive representation and apply the instantaneou-time-shift prediction task based on it. Then we capture the temporal correlation by designing the delayed-time-shift prediction task. Finally, replace-discriminative-learning task is proposed to preserve the characteristics of each channel. Extensive experiments of seizure detection on both EEG and SEEG large-scale real-world datasets demonstrate that our model outperforms several state-of-the-art time series SSL and unsupervised models, and has the ability to be deployed to clinical practice. ",
    "url": "https://arxiv.org/abs/2306.13102",
    "authors": [
      "Donghong Cai",
      "Junru Chen",
      "Yang Yang",
      "Teng Liu",
      "Yafeng Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13109",
    "title": "EEG Decoding for Datasets with Heterogenous Electrode Configurations  using Transfer Learning Graph Neural Networks",
    "abstract": "Brain-Machine Interfacing (BMI) has greatly benefited from adopting machine learning methods for feature learning that require extensive data for training, which are often unavailable from a single dataset. Yet, it is difficult to combine data across labs or even data within the same lab collected over the years due to the variation in recording equipment and electrode layouts resulting in shifts in data distribution, changes in data dimensionality, and altered identity of data dimensions. Our objective is to overcome this limitation and learn from many different and diverse datasets across labs with different experimental protocols. To tackle the domain adaptation problem, we developed a novel machine learning framework combining graph neural networks (GNNs) and transfer learning methodologies for non-invasive Motor Imagery (MI) EEG decoding, as an example of BMI. Empirically, we focus on the challenges of learning from EEG data with different electrode layouts and varying numbers of electrodes. We utilise three MI EEG databases collected using very different numbers of EEG sensors (from 22 channels to 64) and layouts (from custom layouts to 10-20). Our model achieved the highest accuracy with lower standard deviations on the testing datasets. This indicates that the GNN-based transfer learning framework can effectively aggregate knowledge from multiple datasets with different electrode layouts, leading to improved generalization in subject-independent MI EEG classification. The findings of this study have important implications for Brain-Computer-Interface (BCI) research, as they highlight a promising method for overcoming the limitations posed by non-unified experimental setups. By enabling the integration of diverse datasets with varying electrode layouts, our proposed approach can help advance the development and application of BMI technologies. ",
    "url": "https://arxiv.org/abs/2306.13109",
    "authors": [
      "Jinpei Han",
      "Xiaoxi Wei",
      "A. Aldo Faisal"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13201",
    "title": "Decomposition of Geometric Graphs into Star Forests",
    "abstract": "We solve a problem of Dujmovi\\'c and Wood (2007) by showing that a complete convex geometric graph on $n$ vertices cannot be decomposed into fewer than $n-1$ star-forests, each consisting of noncrossing edges. This bound is clearly tight. We also discuss similar questions for abstract graphs. ",
    "url": "https://arxiv.org/abs/2306.13201",
    "authors": [
      "J\u00e1nos Pach",
      "Morteza Saghafian",
      "Patrick Schnider"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2306.13242",
    "title": "Approximate Causal Effect Identification under Weak Confounding",
    "abstract": "Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable causal queries. For non-identifiable causal queries, researchers developed polynomial programs to estimate tight bounds on causal effect. However, these are computationally difficult to optimize for variables with large support sizes. In this paper, we analyze the effect of \"weak confounding\" on causal estimands. More specifically, under the assumption that the unobserved confounders that render a query non-identifiable have small entropy, we propose an efficient linear program to derive the upper and lower bounds of the causal effect. We show that our bounds are consistent in the sense that as the entropy of unobserved confounders goes to zero, the gap between the upper and lower bound vanishes. Finally, we conduct synthetic and real data simulations to compare our bounds with the bounds obtained by the existing work that cannot incorporate such entropy constraints and show that our bounds are tighter for the setting with weak confounders. ",
    "url": "https://arxiv.org/abs/2306.13242",
    "authors": [
      "Ziwei Jiang",
      "Lai Wei",
      "Murat Kocaoglu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13276",
    "title": "On Sensitivity and Robustness of Normalization Schemes to Input  Distribution Shifts in Automatic MR Image Diagnosis",
    "abstract": "Magnetic Resonance Imaging (MRI) is considered the gold standard of medical imaging because of the excellent soft-tissue contrast exhibited in the images reconstructed by the MRI pipeline, which in-turn enables the human radiologist to discern many pathologies easily. More recently, Deep Learning (DL) models have also achieved state-of-the-art performance in diagnosing multiple diseases using these reconstructed images as input. However, the image reconstruction process within the MRI pipeline, which requires the use of complex hardware and adjustment of a large number of scanner parameters, is highly susceptible to noise of various forms, resulting in arbitrary artifacts within the images. Furthermore, the noise distribution is not stationary and varies within a machine, across machines, and patients, leading to varying artifacts within the images. Unfortunately, DL models are quite sensitive to these varying artifacts as it leads to changes in the input data distribution between the training and testing phases. The lack of robustness of these models against varying artifacts impedes their use in medical applications where safety is critical. In this work, we focus on improving the generalization performance of these models in the presence of multiple varying artifacts that manifest due to the complexity of the MR data acquisition. In our experiments, we observe that Batch Normalization, a widely used technique during the training of DL models for medical image analysis, is a significant cause of performance degradation in these changing environments. As a solution, we propose to use other normalization techniques, such as Group Normalization and Layer Normalization (LN), to inject robustness into model performance against varying image artifacts. Through a systematic set of experiments, we show that GN and LN provide better accuracy for various MR artifacts and distribution shifts. ",
    "url": "https://arxiv.org/abs/2306.13276",
    "authors": [
      "Divyam Madaan",
      "Daniel Sodickson",
      "Kyunghyun Cho",
      "Sumit Chopra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13307",
    "title": "Towards Effective and Compact Contextual Representation for Conformer  Transducer Speech Recognition Systems",
    "abstract": "Current ASR systems are mainly trained and evaluated at the utterance level. Long range cross utterance context can be incorporated. A key task is to derive a suitable compact representation of the most relevant history contexts. In contrast to previous researches based on either LSTM-RNN encoded histories that attenuate the information from longer range contexts, or frame level concatenation of transformer context embeddings, in this paper compact low-dimensional cross utterance contextual features are learned in the Conformer-Transducer Encoder using specially designed attention pooling layers that are applied over efficiently cached preceding utterances history vectors. Experiments on the 1000-hr Gigaspeech corpus demonstrate that the proposed contextualized streaming Conformer-Transducers outperform the baseline using utterance internal context only with statistically significant WER reductions of 0.7% to 0.5% absolute (4.3% to 3.1% relative) on the dev and test data. ",
    "url": "https://arxiv.org/abs/2306.13307",
    "authors": [
      "Mingyu Cui",
      "Jiawen Kang",
      "Jiajun Deng",
      "Xi Yin",
      "Yutao Xie",
      "Xie Chen",
      "Xunying Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.13319",
    "title": "A SAT Solver and Computer Algebra Attack on the Minimum Kochen-Specker  Problem",
    "abstract": "One of the foundational results in quantum mechanics is the Kochen-Specker (KS) theorem, which states that any theory whose predictions agree with quantum mechanics must be contextual, i.e., a quantum observation cannot be understood as revealing a pre-existing value. The theorem hinges on the existence of a mathematical object called a KS vector system. While many KS vector systems are known to exist, the problem of finding the minimum KS vector system has remained stubbornly open for over 55 years, despite significant attempts by leading scientists and mathematicians. In this paper, we present a new method based on a combination of a SAT solver and a computer algebra system (CAS) to address this problem. Our approach improves the lower bound on the minimum number of vectors in a KS system from 22 to 24, and is about 35,000 times more efficient compared to the previous best computational methods. The increase in efficiency derives from the fact we are able to exploit the powerful combinatorial search-with-learning capabilities of a SAT solver together with the isomorph-free exhaustive generation methods of a CAS. The quest for the minimum KS vector system is motivated by myriad applications such as simplifying experimental tests of contextuality, zero-error classical communication, dimension witnessing, and the security of certain quantum cryptographic protocols. To the best of our knowledge, this is the first application of a novel SAT+CAS system to a problem in the realm of quantum foundations. ",
    "url": "https://arxiv.org/abs/2306.13319",
    "authors": [
      "Zhengyu Li",
      "Curtis Bright",
      "Vijay Ganesh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.13361",
    "title": "Neural 360$^\\circ$ Structured Light with Learned Metasurfaces",
    "abstract": "Structured light has proven instrumental in 3D imaging, LiDAR, and holographic light projection. Metasurfaces, comprised of sub-wavelength-sized nanostructures, facilitate 180$^\\circ$ field-of-view (FoV) structured light, circumventing the restricted FoV inherent in traditional optics like diffractive optical elements. However, extant metasurface-facilitated structured light exhibits sub-optimal performance in downstream tasks, due to heuristic pattern designs such as periodic dots that do not consider the objectives of the end application. In this paper, we present neural 360$^\\circ$ structured light, driven by learned metasurfaces. We propose a differentiable framework, that encompasses a computationally-efficient 180$^\\circ$ wave propagation model and a task-specific reconstructor, and exploits both transmission and reflection channels of the metasurface. Leveraging a first-order optimizer within our differentiable framework, we optimize the metasurface design, thereby realizing neural 360$^\\circ$ structured light. We have utilized neural 360$^\\circ$ structured light for holographic light projection and 3D imaging. Specifically, we demonstrate the first 360$^\\circ$ light projection of complex patterns, enabled by our propagation model that can be computationally evaluated 50,000$\\times$ faster than the Rayleigh-Sommerfeld propagation. For 3D imaging, we improve depth-estimation accuracy by 5.09$\\times$ in RMSE compared to the heuristically-designed structured light. Neural 360$^\\circ$ structured light promises robust 360$^\\circ$ imaging and display for robotics, extended-reality systems, and human-computer interactions. ",
    "url": "https://arxiv.org/abs/2306.13361",
    "authors": [
      "Eunsue Choi",
      "Gyeongtae Kim",
      "Jooyeong Yun",
      "Yujin Jeon",
      "Junseok Rho",
      "Seung-Hwan Baek"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.13395",
    "title": "Physics-informed neural networks modeling for systems with moving  immersed boundaries: application to an unsteady flow past a plunging foil",
    "abstract": "Recently, physics informed neural networks (PINNs) have been explored extensively for solving various forward and inverse problems and facilitating querying applications in fluid mechanics applications. However, work on PINNs for unsteady flows past moving bodies, such as flapping wings is scarce. Earlier studies mostly relied on transferring to a body attached frame of reference which is restrictive towards handling multiple moving bodies or deforming structures. Hence, in the present work, an immersed boundary aware framework has been explored for developing surrogate models for unsteady flows past moving bodies. Specifically, simultaneous pressure recovery and velocity reconstruction from Immersed boundary method (IBM) simulation data has been investigated. While, efficacy of velocity reconstruction has been tested against the fine resolution IBM data, as a step further, the pressure recovered was compared with that of an arbitrary Lagrange Eulerian (ALE) based solver. Under this framework, two PINN variants, (i) a moving-boundary-enabled standard Navier-Stokes based PINN (MB-PINN), and, (ii) a moving-boundary-enabled IBM based PINN (MB-IBM-PINN) have been formulated. A fluid-solid partitioning of the physics losses in MB-IBM-PINN has been allowed, in order to investigate the effects of solid body points while training. This enables MB-IBM-PINN to match with the performance of MB-PINN under certain loss weighting conditions. MB-PINN is found to be superior to MB-IBM-PINN when {\\it a priori} knowledge of the solid body position and velocity are available. To improve the data efficiency of MB-PINN, a physics based data sampling technique has also been investigated. It is observed that a suitable combination of physics constraint relaxation and physics based sampling can achieve a model performance comparable to the case of using all the data points, under a fixed training budget. ",
    "url": "https://arxiv.org/abs/2306.13395",
    "authors": [
      "Rahul Sundar",
      "Dipanjan Majumdar",
      "Didier Lucor",
      "Sunetra Sarkar"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13400",
    "title": "Network community detection via neural embeddings",
    "abstract": "Recent advances in machine learning research have produced powerful neural graph embedding methods, which learn useful, low-dimensional vector representations of network data. These neural methods for graph embedding excel in graph machine learning tasks and are now widely adopted. However, how and why these methods work -- particularly how network structure gets encoded in the embedding -- remain largely unexplained. Here, we show that shallow neural graph embedding methods encode community structure as well as, or even better than, spectral embedding methods for both dense and sparse networks, with and without degree and community size heterogeneity. Our results provide the foundations for the design of novel effective community detection methods as well as theoretical studies that bridge network science and machine learning. ",
    "url": "https://arxiv.org/abs/2306.13400",
    "authors": [
      "Sadamori Kojaku",
      "Filippo Radicchi",
      "Yong-Yeol Ahn",
      "Santo Fortunato"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.13429",
    "title": "Spectral Dynamic Causal Modelling: A Didactic Introduction and its  Relationship with Functional Connectivity",
    "abstract": "We present a didactic introduction to spectral Dynamic Causal Modelling (DCM), a Bayesian state-space modelling approach used to infer effective connectivity from non-invasive neuroimaging data. Spectral DCM is currently the most widely applied DCM variant for resting-state functional MRI analysis. Our aim is to explain its technical foundations to an audience with limited expertise in state-space modelling and spectral data analysis. Particular attention will be paid to cross-spectral density, which is the most distinctive feature of spectral DCM and is closely related to functional connectivity, as measured by (zero-lag) Pearson correlations. In fact, the model parameters estimated by spectral DCM are those that best reproduce the cross-correlations between all variables--at all time lags--including the zero-lag correlations that are usually interpreted as functional connectivity. We derive the functional connectivity matrix from the model equations and show how changing a single effective connectivity parameter can affect all pairwise correlations. To complicate matters, the pairs of brain regions showing the largest changes in functional connectivity do not necessarily coincide with those presenting the largest changes in effective connectivity. We discuss the implications and conclude with a comprehensive summary of the assumptions and limitations of spectral DCM. ",
    "url": "https://arxiv.org/abs/2306.13429",
    "authors": [
      "Leonardo Novelli",
      "Karl Friston",
      "Adeel Razi"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2306.13442",
    "title": "Minibatch training of neural network ensembles via trajectory sampling",
    "abstract": "Most iterative neural network training methods use estimates of the loss function over small random subsets (or minibatches) of the data to update the parameters, which aid in decoupling the training time from the (often very large) size of the training datasets. Here, we show that a minibatch approach can also be used to train neural network ensembles (NNEs) via trajectory methods in a highly efficent manner. We illustrate this approach by training NNEs to classify images in the MNIST datasets. This method gives an improvement to the training times, allowing it to scale as the ratio of the size of the dataset to that of the average minibatch size which, in the case of MNIST, gives a computational improvement typically of two orders of magnitude. We highlight the advantage of using longer trajectories to represent NNEs, both for improved accuracy in inference and reduced update cost in terms of the samples needed in minibatch updates. ",
    "url": "https://arxiv.org/abs/2306.13442",
    "authors": [
      "Jamie F. Mair",
      "Luke Causer",
      "Juan P. Garrahan"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13472",
    "title": "Prediction under Latent Subgroup Shifts with High-Dimensional  Observations",
    "abstract": "We introduce a new approach to prediction in graphical models with latent-shift adaptation, i.e., where source and target environments differ in the distribution of an unobserved confounding latent variable. Previous work has shown that as long as \"concept\" and \"proxy\" variables with appropriate dependence are observed in the source environment, the latent-associated distributional changes can be identified, and target predictions adapted accurately. However, practical estimation methods do not scale well when the observations are complex and high-dimensional, even if the confounding latent is categorical. Here we build upon a recently proposed probabilistic unsupervised learning framework, the recognition-parametrised model (RPM), to recover low-dimensional, discrete latents from image observations. Applied to the problem of latent shifts, our novel form of RPM identifies causal latent structure in the source environment, and adapts properly to predict in the target. We demonstrate results in settings where predictor and proxy are high-dimensional images, a context to which previous methods fail to scale. ",
    "url": "https://arxiv.org/abs/2306.13472",
    "authors": [
      "William I. Walker",
      "Arthur Gretton",
      "Maneesh Sahani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13492",
    "title": "Identification of the most important external features of highly cited  scholarly papers through 3 (i.e., Ridge, Lasso, and Boruta) feature selection  data mining methods",
    "abstract": "Highly cited papers are influenced by external factors that are not directly related to the document's intrinsic quality. In this study, 50 characteristics for measuring the performance of 68 highly cited papers, from the Journal of the American Medical Informatics Association indexed in Web of Sciences (WoS), from 2009 to 2019 were investigated. In the first step, a Pearson correlation analysis is performed to eliminate variables with zero or weak correlation with the target (dependent) variable ([number of citations in WOS]). Consequently, 32 variables are selected for the next step. By applying the Ridge technique, 13 features show a positive effect on the number of citations. Using three different algorithms, i.e., Ridge, Lasso, and Boruta, 6 factors appear to be the most relevant ones. The [Number of citations by international researchers], [Journal self-citations in citing documents], and [Authors' self-citations in citing documents], are recognized as the most important features by all three methods here used. The [First author's scientific age], [Open-access paper], and [Number of first author's citations in WOS] are identified as the important features of highly cited papers by only two methods, Ridge and Lasso. Notice that we use specific machine learning algorithms as feature selection methods (Ridge, Lasso, and Boruta) to identify the most important features of highly cited papers, tools that had not previously been used for this purpose. In conclusion, we re-emphasize the performance resulting from such algorithms. Moreover, we do not advise authors to seek to increase the citations of their articles by manipulating the identified performance features. Indeed, ethical rules regarding these characteristics must be strictly obeyed. ",
    "url": "https://arxiv.org/abs/2306.13492",
    "authors": [
      "Sepideh Fahimifar",
      "Khadijeh Mousavi",
      "Fatemeh Mozaffari",
      "Marcel Ausloos"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.13561",
    "title": "Efficient Model Selection for Predictive Pattern Mining Model by Safe  Pattern Pruning",
    "abstract": "Predictive pattern mining is an approach used to construct prediction models when the input is represented by structured data, such as sets, graphs, and sequences. The main idea behind predictive pattern mining is to build a prediction model by considering substructures, such as subsets, subgraphs, and subsequences (referred to as patterns), present in the structured data as features of the model. The primary challenge in predictive pattern mining lies in the exponential growth of the number of patterns with the complexity of the structured data. In this study, we propose the Safe Pattern Pruning (SPP) method to address the explosion of pattern numbers in predictive pattern mining. We also discuss how it can be effectively employed throughout the entire model building process in practical data analysis. To demonstrate the effectiveness of the proposed method, we conduct numerical experiments on regression and classification problems involving sets, graphs, and sequences. ",
    "url": "https://arxiv.org/abs/2306.13561",
    "authors": [
      "Takumi Yoshida",
      "Hiroyuki Hanada",
      "Kazuya Nakagawa",
      "Kouichi Taji",
      "Koji Tsuda",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13595",
    "title": "Autoencoders for Real-Time SUEP Detection",
    "abstract": "Confining dark sectors with pseudo-conformal dynamics can produce Soft Unclustered Energy Patterns, or SUEPs, at the Large Hadron Collider: the production of dark quarks in proton-proton collisions leading to a dark shower and the high-multiplicity production of dark hadrons. The final experimental signature is spherically-symmetric energy deposits by an anomalously large number of soft Standard Model particles with a transverse energy of a few hundred MeV. The dominant background for the SUEP search, if it gets produced via gluon-gluon fusion, is multi-jet QCD events. We have developed a deep learning-based Anomaly Detection technique to reject QCD jets and identify any anomalous signature, including SUEP, in real-time in the High-Level Trigger system of the Compact Muon Solenoid experiment at the Large Hadron Collider. A deep convolutional neural autoencoder network has been trained using QCD events by taking transverse energy deposits in the inner tracker, electromagnetic calorimeter, and hadron calorimeter sub-detectors as 3-channel image data. To tackle the biggest challenge of the task, due to the sparse nature of the data: only ~0.5% of the total ~300 k image pixels have non-zero values, a non-standard loss function, the inverse of the so-called Dice Loss, has been exploited. The trained autoencoder with learned spatial features of QCD jets can detect 40% of the SUEP events, with a QCD event mistagging rate as low as 2%. The model inference time has been measured using the Intel CoreTM i5-9600KF processor and found to be ~20 ms, which perfectly satisfies the High-Level Trigger system's latency of O(100) ms. Given the virtue of the unsupervised learning of the autoencoders, the trained model can be applied to any new physics model that predicts an experimental signature anomalous to QCD jets. ",
    "url": "https://arxiv.org/abs/2306.13595",
    "authors": [
      "Simranjit Singh Chhibra",
      "Nadezda Chernyavskaya",
      "Benedikt Maier",
      "Maurzio Pierini",
      "Syed Hasan"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13641",
    "title": "A New Paradigm for Generative Adversarial Networks based on Randomized  Decision Rules",
    "abstract": "The Generative Adversarial Network (GAN) was recently introduced in the literature as a novel machine learning method for training generative models. It has many applications in statistics such as nonparametric clustering and nonparametric conditional independence tests. However, training the GAN is notoriously difficult due to the issue of mode collapse, which refers to the lack of diversity among generated data. In this paper, we identify the reasons why the GAN suffers from this issue, and to address it, we propose a new formulation for the GAN based on randomized decision rules. In the new formulation, the discriminator converges to a fixed point while the generator converges to a distribution at the Nash equilibrium. We propose to train the GAN by an empirical Bayes-like method by treating the discriminator as a hyper-parameter of the posterior distribution of the generator. Specifically, we simulate generators from its posterior distribution conditioned on the discriminator using a stochastic gradient Markov chain Monte Carlo (MCMC) algorithm, and update the discriminator using stochastic gradient descent along with simulations of the generators. We establish convergence of the proposed method to the Nash equilibrium. Apart from image generation, we apply the proposed method to nonparametric clustering and nonparametric conditional independence tests. A portion of the numerical results is presented in the supplementary material. ",
    "url": "https://arxiv.org/abs/2306.13641",
    "authors": [
      "Sehwan Kim",
      "Qifan Song",
      "Faming Liang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.10324",
    "title": "Necessary and sufficient graphical conditions for optimal adjustment  sets in causal graphical models with hidden variables",
    "abstract": " Comments: 41 pages, published as spotlight paper in 35th Conference on Neural Information Processing Systems (NeurIPS 2021); this version has an updated Supplementary Material with corrected proofs (also updated in NeurIPS proceedings) ",
    "url": "https://arxiv.org/abs/2102.10324",
    "authors": [
      "Jakob Runge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2111.10302",
    "title": "Instance-Adaptive Video Compression: Improving Neural Codecs by Training  on the Test Set",
    "abstract": " Comments: Matches version published in TMLR ",
    "url": "https://arxiv.org/abs/2111.10302",
    "authors": [
      "Ties van Rozendaal",
      "Johann Brehmer",
      "Yunfan Zhang",
      "Reza Pourreza",
      "Auke Wiggers",
      "Taco S. Cohen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07369",
    "title": "Convergence proof for stochastic gradient descent in the training of  deep neural networks with ReLU activation for constant target functions",
    "abstract": " Comments: 71 pages, 5 figures, 2 tables, 4 Python source codes. To appear in Electronic Research Archive ",
    "url": "https://arxiv.org/abs/2112.07369",
    "authors": [
      "Martin Hutzenthaler",
      "Arnulf Jentzen",
      "Katharina Pohl",
      "Adrian Riekert",
      "Luca Scarpa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.01868",
    "title": "Hazard Exposure Heterophily: A Latent Characteristic in Socio-Spatial  Networks Influencing Community Resilience",
    "abstract": " Comments: 14 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2205.01868",
    "authors": [
      "Chia-Fu Liu",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.10920",
    "title": "Test-Time Robust Personalization for Federated Learning",
    "abstract": " Comments: Accepted to ICLR 2023 (LJ and TL contribute equally) ",
    "url": "https://arxiv.org/abs/2205.10920",
    "authors": [
      "Liangze Jiang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.14148",
    "title": "Large-step neural network for learning the symplectic evolution from  partitioned data",
    "abstract": " Comments: 13 pages, 7 figures, accepted for publication in MNRAS ",
    "url": "https://arxiv.org/abs/2208.14148",
    "authors": [
      "Xin Li",
      "Jian Li",
      "Zhihong Jeff Xia",
      "Nikolaos Georgakarakos"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2209.12127",
    "title": "SpeedLimit: Neural Architecture Search for Quantized Transformer Models",
    "abstract": " Title: SpeedLimit: Neural Architecture Search for Quantized Transformer Models ",
    "url": "https://arxiv.org/abs/2209.12127",
    "authors": [
      "Yuji Chai",
      "Luke Bailey",
      "Yunho Jin",
      "Matthew Karle",
      "Glenn G. Ko",
      "David Brooks",
      "Gu-Yeon Wei",
      "H. T. Kung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.13827",
    "title": "Compressing network populations with modal networks reveals structural  diversity",
    "abstract": " Title: Compressing network populations with modal networks reveals structural  diversity ",
    "url": "https://arxiv.org/abs/2209.13827",
    "authors": [
      "Alec Kirkley",
      "Alexis Rojas",
      "Martin Rosvall",
      "Jean-Gabriel Young"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.03826",
    "title": "Network Diffusion Model Reveals Recovery Multipliers and Heterogeneous  Spatial Effects in Post-Disaster Community Recovery",
    "abstract": " Comments: 20 pages, 9 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2211.03826",
    "authors": [
      "Chia-Fu Liu",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.04924",
    "title": "Bayesian Networks for the robust and unbiased prediction of depression  and its symptoms utilizing speech and multimodal data",
    "abstract": " Comments: Accepted for publication at Interspeech 2023 ",
    "url": "https://arxiv.org/abs/2211.04924",
    "authors": [
      "Salvatore Fara",
      "Orlaith Hickey",
      "Alexandra Georgescu",
      "Stefano Goria",
      "Emilia Molimpakis",
      "Nicholas Cummins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08516",
    "title": "Phenotype Search Trajectory Networks for Linear Genetic Programming",
    "abstract": " Title: Phenotype Search Trajectory Networks for Linear Genetic Programming ",
    "url": "https://arxiv.org/abs/2211.08516",
    "authors": [
      "Ting Hu",
      "Gabriela Ochoa",
      "Wolfgang Banzhaf"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.06506",
    "title": "Solving Sample-Level Out-of-Distribution Detection on 3D Medical Images",
    "abstract": " Comments: We had made a mistake in the proposed algorithm's code (IHF), which led to a biased evaluation -- the reported AUROC scores (Tab. 1) are higher than they should be. It led to a false conclusion and the primary paper's message ",
    "url": "https://arxiv.org/abs/2212.06506",
    "authors": [
      "Daria Frolova",
      "Anton Vasiliuk",
      "Mikhail Belyaev",
      "Boris Shirokikh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.07648",
    "title": "Relightable Neural Human Assets from Multi-view Gradient Illuminations",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2212.07648",
    "authors": [
      "Taotao Zhou",
      "Kai He",
      "Di Wu",
      "Teng Xu",
      "Qixuan Zhang",
      "Kuixiang Shao",
      "Wenzheng Chen",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.03150",
    "title": "Self-Supervised Time-to-Event Modeling with Structured Medical Records",
    "abstract": " Title: Self-Supervised Time-to-Event Modeling with Structured Medical Records ",
    "url": "https://arxiv.org/abs/2301.03150",
    "authors": [
      "Ethan Steinberg",
      "Yizhe Xu",
      "Jason Fries",
      "Nigam Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.03262",
    "title": "Network Slicing via Transfer Learning aided Distributed Deep  Reinforcement Learning",
    "abstract": " Comments: 6 pages, 8 figures, IEEE Global Communications Conference 2022 ",
    "url": "https://arxiv.org/abs/2301.03262",
    "authors": [
      "Tianlun Hu",
      "Qi Liao",
      "Qiang Liu",
      "Georg Carle"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2301.04470",
    "title": "InstaGraM: Instance-level Graph Modeling for Vectorized HD Map Learning",
    "abstract": " Comments: Workshop on Vision-Centric Autonomous Driving (VCAD) at Conference on Computer Vision and Pattern Recognition (CVPR) 2023 ",
    "url": "https://arxiv.org/abs/2301.04470",
    "authors": [
      "Juyeb Shin",
      "Francois Rameau",
      "Hyeonjun Jeong",
      "Dongsuk Kum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.06601",
    "title": "A Dataset of Coordinated Cryptocurrency-Related Social Media Campaigns",
    "abstract": " Comments: Camera-ready version for the ICWSM 2023 Conference. This paper describes the dataset available at this https URL ",
    "url": "https://arxiv.org/abs/2301.06601",
    "authors": [
      "Karolis Zilius",
      "Tasos Spiliotopoulos",
      "Aad van Moorsel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.08918",
    "title": "Improving Signed Propagation for Graph Neural Networks",
    "abstract": " Title: Improving Signed Propagation for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2301.08918",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chong-Kwon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12906",
    "title": "Curvature Filtrations for Graph Generative Model Evaluation",
    "abstract": " Title: Curvature Filtrations for Graph Generative Model Evaluation ",
    "url": "https://arxiv.org/abs/2301.12906",
    "authors": [
      "Joshua Southern",
      "Jeremy Wayland",
      "Michael Bronstein",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.00817",
    "title": "Recurrent Graph Convolutional Networks for Spatiotemporal Prediction of  Snow Accumulation Using Airborne Radar",
    "abstract": " Comments: Accepted to IEEE Radar Conference 2023. 6 pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2302.00817",
    "authors": [
      "Benjamin Zalatan",
      "Maryam Rahnemoonfar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.01463",
    "title": "Gradient Descent with Linearly Correlated Noise: Theory and Applications  to Differential Privacy",
    "abstract": " Title: Gradient Descent with Linearly Correlated Noise: Theory and Applications  to Differential Privacy ",
    "url": "https://arxiv.org/abs/2302.01463",
    "authors": [
      "Anastasia Koloskova",
      "Ryan McKenna",
      "Zachary Charles",
      "Keith Rush",
      "Brendan McMahan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.09444",
    "title": "mBEST: Realtime Deformable Linear Object Detection Through Minimal  Bending Energy Skeleton Pixel Traversals",
    "abstract": " Comments: YouTube video: this https URL ",
    "url": "https://arxiv.org/abs/2302.09444",
    "authors": [
      "Andrew Choi",
      "Dezhong Tong",
      "Brian Park",
      "Demetri Terzopoulos",
      "Jungseock Joo",
      "Mohammad Khalid Jawed"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.01879",
    "title": "Low-Complexity Audio Embedding Extractors",
    "abstract": " Comments: In Proceedings of the 31st European Signal Processing Conference, EUSIPCO 2023. Source Code available at: this https URL ",
    "url": "https://arxiv.org/abs/2303.01879",
    "authors": [
      "Florian Schmid",
      "Khaled Koutini",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.11052",
    "title": "ContraNeRF: Generalizable Neural Radiance Fields for Synthetic-to-real  Novel View Synthesis via Contrastive Learning",
    "abstract": " Title: ContraNeRF: Generalizable Neural Radiance Fields for Synthetic-to-real  Novel View Synthesis via Contrastive Learning ",
    "url": "https://arxiv.org/abs/2303.11052",
    "authors": [
      "Hao Yang",
      "Lanqing Hong",
      "Aoxue Li",
      "Tianyang Hu",
      "Zhenguo Li",
      "Gim Hee Lee",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.13460",
    "title": "End-to-end Neural Network Based Quadcopter control",
    "abstract": " Comments: 11 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2304.13460",
    "authors": [
      "Robin Ferede",
      "Guido C.H.E. de Croon",
      "Christophe De Wagter",
      "Dario Izzo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.13887",
    "title": "A Vision and An Evolutionary Framework for 6G: Scenarios, Capabilities  and Enablers",
    "abstract": " Comments: Submitted to an IEEE Magazine ",
    "url": "https://arxiv.org/abs/2305.13887",
    "authors": [
      "Ruiqi Liu",
      "Ruyue Yu-Ngok Li",
      "Marco Di Renzo",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.19185",
    "title": "Compression with Bayesian Implicit Neural Representations",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2305.19185",
    "authors": [
      "Zongyu Guo",
      "Gergely Flamich",
      "Jiajun He",
      "Zhibo Chen",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01110",
    "title": "Comparative Study on the Effects of Noise in ML-Based Anxiety Detection",
    "abstract": " Comments: Did not undergo sufficient review by all authors ",
    "url": "https://arxiv.org/abs/2306.01110",
    "authors": [
      "Samuel Schapiro",
      "Abdul Alkurdi",
      "Elizabeth Hsiao-Wecksler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06237",
    "title": "Beyond Weights: Deep learning in Spiking Neural Networks with pure  synaptic-delay training",
    "abstract": " Comments: Accepted at International Conference on Neuromorphic Systems (ICONS) 2023 ",
    "url": "https://arxiv.org/abs/2306.06237",
    "authors": [
      "Edoardo W. Grappolini",
      "Anand Subramoney"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.09621",
    "title": "Regression-based Physics Informed Neural Networks (Reg-PINNs) for  Magnetopause Tracking",
    "abstract": " Comments: This article will be rewritten to focus on the development of algorithms, with the magnetopause in space physics as auxiliary supporting content ",
    "url": "https://arxiv.org/abs/2306.09621",
    "authors": [
      "Po-Han Hou",
      "Jih-Hong Shue"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2306.10045",
    "title": "Efficient Approximations of Complete Interatomic Potentials for Crystal  Property Prediction",
    "abstract": " Title: Efficient Approximations of Complete Interatomic Potentials for Crystal  Property Prediction ",
    "url": "https://arxiv.org/abs/2306.10045",
    "authors": [
      "Yuchao Lin",
      "Keqiang Yan",
      "Youzhi Luo",
      "Yi Liu",
      "Xiaoning Qian",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10798",
    "title": "ExpPoint-MAE: Better interpretability and performance for  self-supervised point cloud transformers",
    "abstract": " Title: ExpPoint-MAE: Better interpretability and performance for  self-supervised point cloud transformers ",
    "url": "https://arxiv.org/abs/2306.10798",
    "authors": [
      "Ioannis Romanelis",
      "Vlassis Fotis",
      "Konstantinos Moustakas",
      "Adrian Munteanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.12235",
    "title": "CompMix: A Benchmark for Heterogeneous Question Answering",
    "abstract": " Title: CompMix: A Benchmark for Heterogeneous Question Answering ",
    "url": "https://arxiv.org/abs/2306.12235",
    "authors": [
      "Philipp Christmann",
      "Rishiraj Saha Roy",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.12446",
    "title": "Comparing Deep Learning Models for the Task of Volatility Prediction  Using Multivariate Data",
    "abstract": " Title: Comparing Deep Learning Models for the Task of Volatility Prediction  Using Multivariate Data ",
    "url": "https://arxiv.org/abs/2306.12446",
    "authors": [
      "Wenbo Ge",
      "Pooia Lalbakhsh",
      "Leigh Isai",
      "Artem Lensky",
      "Hanna Suominen"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2306.12703",
    "title": "OptIForest: Optimal Isolation Forest for Anomaly Detection",
    "abstract": " Comments: This paper has been accepted by International Joint Conference on Artificial Intelligence (IJCAI-23) ",
    "url": "https://arxiv.org/abs/2306.12703",
    "authors": [
      "Haolong Xiang",
      "Xuyun Zhang",
      "Hongsheng Hu",
      "Lianyong Qi",
      "Wanchun Dou",
      "Mark Dras",
      "Amin Beheshti",
      "Xiaolong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.12802",
    "title": "Otter-Knowledge: benchmarks of multimodal knowledge graph representation  learning from different sources for drug discovery",
    "abstract": " Title: Otter-Knowledge: benchmarks of multimodal knowledge graph representation  learning from different sources for drug discovery ",
    "url": "https://arxiv.org/abs/2306.12802",
    "authors": [
      "Hoang Thanh Lam",
      "Marco Luca Sbodio",
      "Marcos Mart\u00ednez Galindo",
      "Mykhaylo Zayats",
      "Ra\u00fal Fern\u00e1ndez-D\u00edaz",
      "V\u00edctor Valls",
      "Gabriele Picco",
      "Cesar Berrospi Ramis",
      "Vanessa L\u00f3pez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2306.13002",
    "title": "ACC Saturator: Automatic Kernel Optimization for Directive-Based GPU  Code",
    "abstract": " Title: ACC Saturator: Automatic Kernel Optimization for Directive-Based GPU  Code ",
    "url": "https://arxiv.org/abs/2306.13002",
    "authors": [
      "Kazuaki Matsumura",
      "Simon Garcia De Gonzalo",
      "Antonio J. Pe\u00f1a"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  }
]