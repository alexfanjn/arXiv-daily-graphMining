[
  {
    "id": "arXiv:2305.19292",
    "title": "Revisiting Random Forests in a Comparative Evaluation of Graph  Convolutional Neural Network Variants for Traffic Prediction",
    "abstract": "Traffic prediction is a spatiotemporal predictive task that plays an essential role in intelligent transportation systems. Today, graph convolutional neural networks (GCNNs) have become the prevailing models in the traffic prediction literature since they excel at extracting spatial correlations. In this work, we classify the components of successful GCNN prediction models and analyze the effects of matrix factorization, attention mechanism, and weight sharing on their performance. Furthermore, we compare these variations against random forests, a traditional regression method that predates GCNNs by over 15 years. We evaluated these methods using simulated data of two regions in Toronto as well as real-world sensor data from selected California highways. We found that incorporating matrix factorization, attention, and location-specific model weights either individually or collectively into GCNNs can result in a better overall performance. Moreover, although random forest regression is a less compact model, it matches or exceeds the performance of all variations of GCNNs in our experiments. This suggests that the current graph convolutional methods may not be the best approach to traffic prediction and there is still room for improvement. Finally, our findings also suggest that for future research on GCNN for traffic prediction to be credible, researchers must include performance comparison to random forests. ",
    "url": "https://arxiv.org/abs/2305.19292",
    "authors": [
      "Ta Jiun Ting",
      "Xiaocan Li",
      "Scott Sanner",
      "Baher Abdulhai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19295",
    "title": "Low Precision Quantization-aware Training in Spiking Neural Networks  with Differentiable Quantization Function",
    "abstract": "Deep neural networks have been proven to be highly effective tools in various domains, yet their computational and memory costs restrict them from being widely deployed on portable devices. The recent rapid increase of edge computing devices has led to an active search for techniques to address the above-mentioned limitations of machine learning frameworks. The quantization of artificial neural networks (ANNs), which converts the full-precision synaptic weights into low-bit versions, emerged as one of the solutions. At the same time, spiking neural networks (SNNs) have become an attractive alternative to conventional ANNs due to their temporal information processing capability, energy efficiency, and high biological plausibility. Despite being driven by the same motivation, the simultaneous utilization of both concepts has yet to be thoroughly studied. Therefore, this work aims to bridge the gap between recent progress in quantized neural networks and SNNs. It presents an extensive study on the performance of the quantization function, represented as a linear combination of sigmoid functions, exploited in low-bit weight quantization in SNNs. The presented quantization function demonstrates the state-of-the-art performance on four popular benchmarks, CIFAR10-DVS, DVS128 Gesture, N-Caltech101, and N-MNIST, for binary networks (64.05\\%, 95.45\\%, 68.71\\%, and 99.43\\% respectively) with small accuracy drops and up to 31$\\times$ memory savings, which outperforms existing methods. ",
    "url": "https://arxiv.org/abs/2305.19295",
    "authors": [
      "Ayan Shymyrbay",
      "Mohammed E. Fouda",
      "Ahmed Eltawil"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.19299",
    "title": "The Role Of Social Media On Selected Businesses In Nigeria In The Era Of  Covid-19 Pandemic",
    "abstract": "As several countries were experiencing unprecedented economic slowdowns due to the outbreak of COVID-19 pandemic in early 2020, small business enterprises started adapting to digital technologies for business transactions. However, in Africa, particularly Nigeria, COVID-19 pandemic resulted to some financial crisis that impacted negatively on the sustainability of small and medium-sized (SMEs) businesses. Thus, this study examined the role of social media on selected SMEs in Nigeria in the heat of the COVID-19 pandemic that led to several lock downs in a bid to curtail the spread of the virus. Cross-sectional survey research design was used alongside convenience population sampling techniques. The population was categorised based on selected SMEs businesses, while a quantitative research approach was adopted, and primary data were collected using a questionnaire. The questionnaires were administered to owners and operators of SMEs in Ikotun and Ikeja areas of Lagos State, Nigeria. A total of 190 questionnaires were distributed, where 183 usable responses were analysed. The findings of the study show that SMEs were aware of the usefulness of social media to their businesses as they largely leveraged it in conducting their businesses during the national lockdowns. The study recommended that labour/trade unions should sensitise and encourage business owners on the benefits of continuous use of social media in carrying out their business transactions. ",
    "url": "https://arxiv.org/abs/2305.19299",
    "authors": [
      "Cajetan Ihemebiri",
      "Elochukwu Ukwandu",
      "Lizzy Ofusori",
      "Comfort Olebara"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.19306",
    "title": "A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets  Spiking Neural Networks",
    "abstract": "While contrastive self-supervised learning has become the de-facto learning paradigm for graph neural networks, the pursuit of high task accuracy requires a large hidden dimensionality to learn informative and discriminative full-precision representations, raising concerns about computation, memory footprint, and energy consumption burden (largely overlooked) for real-world applications. This paper explores a promising direction for graph contrastive learning (GCL) with spiking neural networks (SNNs), which leverage sparse and binary characteristics to learn more biologically plausible and compact representations. We propose SpikeGCL, a novel GCL framework to learn binarized 1-bit representations for graphs, making balanced trade-offs between efficiency and performance. We provide theoretical guarantees to demonstrate that SpikeGCL has comparable expressiveness with its full-precision counterparts. Experimental results demonstrate that, with nearly 32x representation storage compression, SpikeGCL is either comparable to or outperforms many fancy state-of-the-art supervised and self-supervised methods across several graph benchmarks. ",
    "url": "https://arxiv.org/abs/2305.19306",
    "authors": [
      "Jintang Li",
      "Huizhe Zhang",
      "Ruofan Wu",
      "Zulun Zhu",
      "Liang Chen",
      "Zibin Zheng",
      "Baokun Wang",
      "Changhua Meng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19330",
    "title": "Breeding Machine Translations: Evolutionary approach to survive and  thrive in the world of automated evaluation",
    "abstract": "We propose a genetic algorithm (GA) based method for modifying n-best lists produced by a machine translation (MT) system. Our method offers an innovative approach to improving MT quality and identifying weaknesses in evaluation metrics. Using common GA operations (mutation and crossover) on a list of hypotheses in combination with a fitness function (an arbitrary MT metric), we obtain novel and diverse outputs with high metric scores. With a combination of multiple MT metrics as the fitness function, the proposed method leads to an increase in translation quality as measured by other held-out automatic metrics. With a single metric (including popular ones such as COMET) as the fitness function, we find blind spots and flaws in the metric. This allows for an automated search for adversarial examples in an arbitrary metric, without prior assumptions on the form of such example. As a demonstration of the method, we create datasets of adversarial examples and use them to show that reference-free COMET is substantially less robust than the reference-based version. ",
    "url": "https://arxiv.org/abs/2305.19330",
    "authors": [
      "Josef Jon",
      "Ond\u0159ej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19337",
    "title": "HiGen: Hierarchical Graph Generative Networks",
    "abstract": "Most real-world graphs exhibit a hierarchical structure, which is often overlooked by existing graph generation methods. To address this limitation, we propose a novel graph generative network that captures the hierarchical nature of graphs and successively generates the graph sub-structures in a coarse-to-fine fashion. At each level of hierarchy, this model generates communities in parallel, followed by the prediction of cross-edges between communities using a separate model. This modular approach results in a highly scalable graph generative network. Moreover, we model the output distribution of edges in the hierarchical graph with a multinomial distribution and derive a recursive factorization for this distribution, enabling us to generate sub-graphs with integer-valued edge weights in an autoregressive approach. Empirical studies demonstrate that the proposed generative model can effectively capture both local and global properties of graphs and achieves state-of-the-art performance in terms of graph quality on various benchmarks. ",
    "url": "https://arxiv.org/abs/2305.19337",
    "authors": [
      "Mahdi Karami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.19343",
    "title": "Budget-Aware Graph Convolutional Network Design using Probabilistic  Magnitude Pruning",
    "abstract": "Graph convolutional networks (GCNs) are nowadays becoming mainstream in solving many image processing tasks including skeleton-based recognition. Their general recipe consists in learning convolutional and attention layers that maximize classification performances. With multi-head attention, GCNs are highly accurate but oversized, and their deployment on edge devices requires their pruning. Among existing methods, magnitude pruning (MP) is relatively effective but its design is clearly suboptimal as network topology selection and weight retraining are achieved independently. In this paper, we devise a novel lightweight GCN design dubbed as Probabilistic Magnitude Pruning (PMP) that jointly trains network topology and weights. Our method is variational and proceeds by aligning the weight distribution of the learned networks with an a priori distribution. This allows implementing any fixed pruning rate, and also enhancing the generalization performances of the designed lightweight GCNs. Extensive experiments conducted on the challenging task of skeleton-based recognition show a substantial gain of our lightweight GCNs particularly at very high pruning regimes. ",
    "url": "https://arxiv.org/abs/2305.19343",
    "authors": [
      "Hichem Sahbi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19366",
    "title": "Joint Bayesian Inference of Graphical Structure and Parameters with a  Single Generative Flow Network",
    "abstract": "Generative Flow Networks (GFlowNets), a class of generative models over discrete and structured sample spaces, have been previously applied to the problem of inferring the marginal posterior distribution over the directed acyclic graph (DAG) of a Bayesian Network, given a dataset of observations. Based on recent advances extending this framework to non-discrete sample spaces, we propose in this paper to approximate the joint posterior over not only the structure of a Bayesian Network, but also the parameters of its conditional probability distributions. We use a single GFlowNet whose sampling policy follows a two-phase process: the DAG is first generated sequentially one edge at a time, and then the corresponding parameters are picked once the full structure is known. Since the parameters are included in the posterior distribution, this leaves more flexibility for the local probability models of the Bayesian Network, making our approach applicable even to non-linear models parametrized by neural networks. We show that our method, called JSP-GFN, offers an accurate approximation of the joint posterior, while comparing favorably against existing methods on both simulated and real data. ",
    "url": "https://arxiv.org/abs/2305.19366",
    "authors": [
      "Tristan Deleu",
      "Mizu Nishikawa-Toomey",
      "Jithendaraa Subramanian",
      "Nikolay Malkin",
      "Laurent Charlin",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19373",
    "title": "Mining Themes in Clinical Notes to Identify Phenotypes and to Predict  Length of Stay in Patients admitted with Heart Failure",
    "abstract": "Heart failure is a syndrome which occurs when the heart is not able to pump blood and oxygen to support other organs in the body. Identifying the underlying themes in the diagnostic codes and procedure reports of patients admitted for heart failure could reveal the clinical phenotypes associated with heart failure and to group patients based on their similar characteristics which could also help in predicting patient outcomes like length of stay. These clinical phenotypes usually have a probabilistic latent structure and hence, as there has been no previous work on identifying phenotypes in clinical notes of heart failure patients using a probabilistic framework and to predict length of stay of these patients using data-driven artificial intelligence-based methods, we apply natural language processing technique, topic modeling, to identify the themes present in diagnostic codes and in procedure reports of 1,200 patients admitted for heart failure at the University of Illinois Hospital and Health Sciences System (UI Health). Topic modeling identified twelve themes each in diagnostic codes and procedure reports which revealed information about different phenotypes related to various perspectives about heart failure, to study patients' profiles and to discover new relationships among medical concepts. Each theme had a set of keywords and each clinical note was labeled with two themes - one corresponding to its diagnostic code and the other corresponding to its procedure reports along with their percentage contribution. We used these themes and their percentage contribution to predict length of stay. We found that the themes discovered in diagnostic codes and procedure reports using topic modeling together were able to predict length of stay of the patients with an accuracy of 61.1% and an Area under the Receiver Operating Characteristic Curve (ROC AUC) value of 0.828. ",
    "url": "https://arxiv.org/abs/2305.19373",
    "authors": [
      "Ankita Agarwal",
      "Tanvi Banerjee",
      "William L. Romine",
      "Krishnaprasad Thirunarayan",
      "Lingwei Chen",
      "Mia Cajita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19375",
    "title": "Sensitivity Analysis of RF+clust for Leave-one-problem-out Performance  Prediction",
    "abstract": "Leave-one-problem-out (LOPO) performance prediction requires machine learning (ML) models to extrapolate algorithms' performance from a set of training problems to a previously unseen problem. LOPO is a very challenging task even for state-of-the-art approaches. Models that work well in the easier leave-one-instance-out scenario often fail to generalize well to the LOPO setting. To address the LOPO problem, recent work suggested enriching standard random forest (RF) performance regression models with a weighted average of algorithms' performance on training problems that are considered similar to a test problem. More precisely, in this RF+clust approach, the weights are chosen proportionally to the distances of the problems in some feature space. Here in this work, we extend the RF+clust approach by adjusting the distance-based weights with the importance of the features for performance regression. That is, instead of considering cosine distance in the feature space, we consider a weighted distance measure, with weights depending on the relevance of the feature for the regression model. Our empirical evaluation of the modified RF+clust approach on the CEC 2014 benchmark suite confirms its advantages over the naive distance measure. However, we also observe room for improvement, in particular with respect to more expressive feature portfolios. ",
    "url": "https://arxiv.org/abs/2305.19375",
    "authors": [
      "Ana Nikolikj",
      "Michal Pluh\u00e1\u010dek",
      "Carola Doerr",
      "Peter Koro\u0161ec",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19377",
    "title": "Benign Overfitting in Deep Neural Networks under Lazy Training",
    "abstract": "This paper focuses on over-parameterized deep neural networks (DNNs) with ReLU activation functions and proves that when the data distribution is well-separated, DNNs can achieve Bayes-optimal test error for classification while obtaining (nearly) zero-training error under the lazy training regime. For this purpose, we unify three interrelated concepts of overparameterization, benign overfitting, and the Lipschitz constant of DNNs. Our results indicate that interpolating with smoother functions leads to better generalization. Furthermore, we investigate the special case where interpolating smooth ground-truth functions is performed by DNNs under the Neural Tangent Kernel (NTK) regime for generalization. Our result demonstrates that the generalization error converges to a constant order that only depends on label noise and initialization noise, which theoretically verifies benign overfitting. Our analysis provides a tight lower bound on the normalized margin under non-smooth activation functions, as well as the minimum eigenvalue of NTK under high-dimensional settings, which has its own interest in learning theory. ",
    "url": "https://arxiv.org/abs/2305.19377",
    "authors": [
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Francesco Locatello",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19398",
    "title": "Generating Finite Element Codes combining Adaptive Octrees with Complex  Geometries",
    "abstract": "We present a high-level domain-specific language (DSL) interface to drive an adaptive incomplete $k$-d tree-based framework for finite element (FEM) solutions to PDEs. This DSL provides three key advances: (a) it abstracts out the complexity of implementing non-trivial FEM formulations, (b) it simplifies deploying these formulations on arbitrarily complicated and adaptively refined meshes, and (c) it exhibits good parallel performance. Taken together, the DSL interface allows end-users to rapidly and efficiently prototype new mathematical approaches, and deploy them on large clusters for solving practical problems. We illustrate this DSL by implementing a workflow for solving PDEs using the recently developed shifted boundary method (SBM). The SBM requires approximating relatively complicated integrals over boundary surfaces. Using a high-level DSL greatly simplifies this process and allows rapid exploration of variations. We demonstrate these tools on a variety of 2-D and 3-D configurations. With fewer than 20 lines of input, we can produce a parallel code that scales well to thousands of processes. This generated code is made accessible and readable to be easily modified and hand-tuned, making this tool useful even to experts with the target software. ",
    "url": "https://arxiv.org/abs/2305.19398",
    "authors": [
      "Eric Heisler",
      "Cheng-Hau Yang",
      "Aadesh Deshmukh",
      "Baskar Ganapathysubramanian",
      "Hari Sundar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2305.19400",
    "title": "Automating GPU Scalability for Complex Scientific Models: Phonon  Boltzman Transport Equation",
    "abstract": "Heterogeneous computing environments combining CPU and GPU resources provide a great boost to large-scale scientific computing applications. Code generation utilities that partition the work into CPU and GPU tasks while considering data movement costs allow researchers to more quickly and easily develop high-performance solutions, and make these resources accessible to a larger user base. We present developments for a domain-specific language (DSL) and code generation framework for solving partial differential equations (PDEs). These enhancements facilitate GPU-accelerated solution of the Boltzmann transport equation (BTE) for phonons, which is the governing equation for simulating thermal transport in semiconductor materials at sub-micron scales. The solution of the BTE involves thousands of coupled PDEs as well as complicated boundary conditions and nonlinear processing at each time step. These developments enable the DSL to generate configurable hybrid GPU/CPU code that couples accelerated kernels with user-defined code. We observed performance improvements of around 18X compared to a CPU-only version produced by this same DSL with minimal additional programming effort. ",
    "url": "https://arxiv.org/abs/2305.19400",
    "authors": [
      "Eric Heisler",
      "Siddharth Saurav",
      "Aadesh Deshmukh",
      "Sandip Mazumder",
      "Ponnuswamy Sadayappan",
      "Hari Sundar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2305.19402",
    "title": "Contextual Vision Transformers for Robust Representation Learning",
    "abstract": "We present Contextual Vision Transformers (ContextViT), a method for producing robust feature representations for images exhibiting grouped structure such as covariates. ContextViT introduces an extra context token to encode group-specific information, allowing the model to explain away group-specific covariate structures while keeping core visual features shared across groups. Specifically, given an input image, Context-ViT maps images that share the same covariate into this context token appended to the input image tokens to capture the effects of conditioning the model on group membership. We furthermore introduce a context inference network to predict such tokens on the fly given a few samples from a group distribution, enabling ContextViT to generalize to new testing distributions at inference time. We illustrate the performance of ContextViT through a diverse range of applications. In supervised fine-tuning, we demonstrate that augmenting pre-trained ViTs with additional context conditioning leads to significant improvements in out-of-distribution generalization on iWildCam and FMoW. We also explored self-supervised representation learning with ContextViT. Our experiments on the Camelyon17 pathology imaging benchmark and the cpg-0000 microscopy imaging benchmark demonstrate that ContextViT excels in learning stable image featurizations amidst covariate shift, consistently outperforming its ViT counterpart. ",
    "url": "https://arxiv.org/abs/2305.19402",
    "authors": [
      "Yujia Bao",
      "Theofanis Karaletsos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19404",
    "title": "Incremental Learning for Heterogeneous Structure Segmentation in Brain  Tumor MRI",
    "abstract": "Deep learning (DL) models for segmenting various anatomical structures have achieved great success via a static DL model that is trained in a single source domain. Yet, the static DL model is likely to perform poorly in a continually evolving environment, requiring appropriate model updates. In an incremental learning setting, we would expect that well-trained static models are updated, following continually evolving target domain data -- e.g., additional lesions or structures of interest -- collected from different sites, without catastrophic forgetting. This, however, poses challenges, due to distribution shifts, additional structures not seen during the initial model training, and the absence of training data in a source domain. To address these challenges, in this work, we seek to progressively evolve an ``off-the-shelf\" trained segmentation model to diverse datasets with additional anatomical categories in a unified manner. Specifically, we first propose a divergence-aware dual-flow module with balanced rigidity and plasticity branches to decouple old and new tasks, which is guided by continuous batch renormalization. Then, a complementary pseudo-label training scheme with self-entropy regularized momentum MixUp decay is developed for adaptive network optimization. We evaluated our framework on a brain tumor segmentation task with continually changing target domains -- i.e., new MRI scanners/modalities with incremental structures. Our framework was able to well retain the discriminability of previously learned structures, hence enabling the realistic life-long segmentation model extension along with the widespread accumulation of big medical data. ",
    "url": "https://arxiv.org/abs/2305.19404",
    "authors": [
      "Xiaofeng Liu",
      "Helen A. Shih",
      "Fangxu Xing",
      "Emiliano Santarnecchi",
      "Georges El Fakhri",
      "Jonghye Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2305.19424",
    "title": "Quantifying Overfitting: Evaluating Neural Network Performance through  Analysis of Null Space",
    "abstract": "Machine learning models that are overfitted/overtrained are more vulnerable to knowledge leakage, which poses a risk to privacy. Suppose we download or receive a model from a third-party collaborator without knowing its training accuracy. How can we determine if it has been overfitted or overtrained on its training data? It's possible that the model was intentionally over-trained to make it vulnerable during testing. While an overfitted or overtrained model may perform well on testing data and even some generalization tests, we can't be sure it's not over-fitted. Conducting a comprehensive generalization test is also expensive. The goal of this paper is to address these issues and ensure the privacy and generalization of our method using only testing data. To achieve this, we analyze the null space in the last layer of neural networks, which enables us to quantify overfitting without access to training data or knowledge of the accuracy of those data. We evaluated our approach on various architectures and datasets and observed a distinct pattern in the angle of null space when models are overfitted. Furthermore, we show that models with poor generalization exhibit specific characteristics in this space. Our work represents the first attempt to quantify overfitting without access to training data or knowing any knowledge about the training samples. ",
    "url": "https://arxiv.org/abs/2305.19424",
    "authors": [
      "Hossein Rezaei",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19445",
    "title": "A Computational Account Of Self-Supervised Visual Learning From  Egocentric Object Play",
    "abstract": "Research in child development has shown that embodied experience handling physical objects contributes to many cognitive abilities, including visual learning. One characteristic of such experience is that the learner sees the same object from several different viewpoints. In this paper, we study how learning signals that equate different viewpoints -- e.g., assigning similar representations to different views of a single object -- can support robust visual learning. We use the Toybox dataset, which contains egocentric videos of humans manipulating different objects, and conduct experiments using a computer vision framework for self-supervised contrastive learning. We find that representations learned by equating different physical viewpoints of an object benefit downstream image classification accuracy. Further experiments show that this performance improvement is robust to variations in the gaps between viewpoints, and that the benefits transfer to several different image classification tasks. ",
    "url": "https://arxiv.org/abs/2305.19445",
    "authors": [
      "Deepayan Sanyal",
      "Joel Michelson",
      "Yuan Yang",
      "James Ainooson",
      "Maithilee Kunda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19462",
    "title": "Optimized Constellation Design for Two User Binary Sensor Networks Using  NOMA",
    "abstract": "Data Fusion of wireless sensors is a common technique employed in many communication systems. This work focuses on incorporating the principles of non-orthogonal-multiple-access (NOMA) to optimize error performance directly in the choice of constellation design. More specifically, the problem of two sensor data fusion of a binary uniform source sent over a Gaussian multiple access channel via symmetric binary constellations is investigated. A so-called planar upper bound on the error probability is analytically derived. A constellation design is then obtained by establishing in closed form its rotation parameter that minimizes the upper bound. Simulation results show that the resulting constellations achieve a near identical performance as experimentally determined optimal constellations. ",
    "url": "https://arxiv.org/abs/2305.19462",
    "authors": [
      "Luca Sardellitti",
      "Glen Takahara",
      "Fady Alajaji"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.19468",
    "title": "Efficient Implementation of a Multi-Layer Gradient-Free Online-Trainable  Spiking Neural Network on FPGA",
    "abstract": "This paper presents an efficient hardware implementation of the recently proposed Optimized Deep Event-driven Spiking Neural Network Architecture (ODESA). ODESA is the first network to have end-to-end multi-layer online local supervised training without using gradients and has the combined adaptation of weights and thresholds in an efficient hierarchical structure. This research shows that the network architecture and the online training of weights and thresholds can be implemented efficiently on a large scale in hardware. The implementation consists of a multi-layer Spiking Neural Network (SNN) and individual training modules for each layer that enable online self-learning without using back-propagation. By using simple local adaptive selection thresholds, a Winner-Takes-All (WTA) constraint on each layer, and a modified weight update rule that is more amenable to hardware, the trainer module allocates neuronal resources optimally at each layer without having to pass high-precision error measurements across layers. All elements in the system, including the training module, interact using event-based binary spikes. The hardware-optimized implementation is shown to preserve the performance of the original algorithm across multiple spatial-temporal classification problems with significantly reduced hardware requirements. ",
    "url": "https://arxiv.org/abs/2305.19468",
    "authors": [
      "Ali Mehrabi",
      "Yeshwanth Bethi",
      "Andr\u00e9 van Schaik",
      "Andrew Wabnitz",
      "Saeed Afshar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.19470",
    "title": "Label Embedding by Johnson-Lindenstrauss Matrices",
    "abstract": "We present a simple and scalable framework for extreme multiclass classification based on Johnson-Lindenstrauss matrices (JLMs). Using the columns of a JLM to embed the labels, a $C$-class classification problem is transformed into a regression problem with $\\cO(\\log C)$ output dimension. We derive an excess risk bound, revealing a tradeoff between computational efficiency and prediction accuracy, and further show that under the Massart noise condition, the penalty for dimension reduction vanishes. Our approach is easily parallelizable, and experimental results demonstrate its effectiveness and scalability in large-scale applications. ",
    "url": "https://arxiv.org/abs/2305.19470",
    "authors": [
      "Jianxin Zhang",
      "Clayton Scott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19487",
    "title": "SPGNN-API: A Transferable Graph Neural Network for Attack Paths  Identification and Autonomous Mitigation",
    "abstract": "Attack paths are the potential chain of malicious activities an attacker performs to compromise network assets and acquire privileges through exploiting network vulnerabilities. Attack path analysis helps organizations to identify new/unknown chains of attack vectors that reach critical assets within the network, as opposed to individual attack vectors in signature-based attack analysis. Timely identification of attack paths enables proactive mitigation of threats. Nevertheless, manual analysis of complex network configurations, vulnerabilities, and security events to identify attack paths is rarely feasible. This work proposes a novel transferable graph neural network-based model for shortest path identification. The proposed shortest path detection approach, integrated with a novel holistic and comprehensive model for identifying potential network vulnerabilities interactions, is then utilized to detect network attack paths. Our framework automates the risk assessment of attack paths indicating the propensity of the paths to enable the compromise of highly-critical assets (e.g., databases) given the network configuration, assets' criticality, and the severity of the vulnerabilities in-path to the asset. The proposed framework, named SPGNN-API, incorporates automated threat mitigation through a proactive timely tuning of the network firewall rules and zero-trust policies to break critical attack paths and bolster cyber defenses. Our evaluation process is twofold; evaluating the performance of the shortest path identification and assessing the attack path detection accuracy. Our results show that SPGNN-API largely outperforms the baseline model for shortest path identification with an average accuracy >= 95% and successfully detects 100% of the potentially compromised assets, outperforming the attack graph baseline by 47%. ",
    "url": "https://arxiv.org/abs/2305.19487",
    "authors": [
      "Houssem Jmal",
      "Firas Ben Hmida",
      "Nardine Basta",
      "Muhammad Ikram",
      "Mohamed Ali Kaafar",
      "Andy Walker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.19497",
    "title": "Towards Flow Graph Prediction of Open-Domain Procedural Texts",
    "abstract": "Machine comprehension of procedural texts is essential for reasoning about the steps and automating the procedures. However, this requires identifying entities within a text and resolving the relationships between the entities. Previous work focused on the cooking domain and proposed a framework to convert a recipe text into a flow graph (FG) representation. In this work, we propose a framework based on the recipe FG for flow graph prediction of open-domain procedural texts. To investigate flow graph prediction performance in non-cooking domains, we introduce the wikiHow-FG corpus from articles on wikiHow, a website of how-to instruction articles. In experiments, we consider using the existing recipe corpus and performing domain adaptation from the cooking to the target domain. Experimental results show that the domain adaptation models achieve higher performance than those trained only on the cooking or target domain data. ",
    "url": "https://arxiv.org/abs/2305.19497",
    "authors": [
      "Keisuke Shirai",
      "Hirotaka Kameko",
      "Shinsuke Mori"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19502",
    "title": "Graph Entropy Minimization for Semi-supervised Node Classification",
    "abstract": "Node classifiers are required to comprehensively reduce prediction errors, training resources, and inference latency in the industry. However, most graph neural networks (GNN) concentrate only on one or two of them. The compromised aspects thus are the shortest boards on the bucket, hindering their practical deployments for industrial-level tasks. This work proposes a novel semi-supervised learning method termed Graph Entropy Minimization (GEM) to resolve the three issues simultaneously. GEM benefits its one-hop aggregation from massive uncategorized nodes, making its prediction accuracy comparable to GNNs with two or more hops message passing. It can be decomposed to support stochastic training with mini-batches of independent edge samples, achieving extremely fast sampling and space-saving training. While its one-hop aggregation is faster in inference than deep GNNs, GEM can be further accelerated to an extreme by deriving a non-hop classifier via online knowledge distillation. Thus, GEM can be a handy choice for latency-restricted and error-sensitive services running on resource-constraint hardware. Code is available at https://github.com/cf020031308/GEM. ",
    "url": "https://arxiv.org/abs/2305.19502",
    "authors": [
      "Yi Luo",
      "Guangchun Luo",
      "Ke Qin",
      "Aiguo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19510",
    "title": "Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape",
    "abstract": "We study the loss landscape of two-layer mildly overparameterized ReLU neural networks on a generic finite input dataset for the squared error loss. Our approach involves bounding the dimension of the sets of local and global minima using the rank of the Jacobian of the parameterization map. Using results on random binary matrices, we show most activation patterns correspond to parameter regions with no bad differentiable local minima. Furthermore, for one-dimensional input data, we show most activation regions realizable by the network contain a high dimensional set of global minima and no bad local minima. We experimentally confirm these results by finding a phase transition from most regions having full rank to many regions having deficient rank depending on the amount of overparameterization. ",
    "url": "https://arxiv.org/abs/2305.19510",
    "authors": [
      "Kedar Karhadkar",
      "Michael Murray",
      "Hanna Tseran",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19513",
    "title": "Towards Accurate and Reliable Change Detection of Remote Sensing Images  via Knowledge Review and Online Uncertainty Estimation",
    "abstract": "Change detection (CD) is an essential task for various real-world applications, such as urban management and disaster assessment. However, previous methods primarily focus on improving the accuracy of CD, while neglecting the reliability of detection results. In this paper, we propose a novel change detection network, called AR-CDNet, which is able to provide accurate change maps and generate pixel-wise uncertainty. Specifically, an online uncertainty estimation branch is constructed to model the pixel-wise uncertainty, which is supervised by the difference between predicted change maps and corresponding ground truth during the training process. Furthermore, we introduce a knowledge review strategy to distill temporal change knowledge from low-level features to high-level ones, thereby enhancing the discriminability of temporal difference features. Finally, we aggregate the uncertainty-aware features extracted from the online uncertainty estimation branch with multi-level temporal difference features to improve the accuracy of CD. Once trained, our AR-CDNet can provide accurate change maps and evaluate pixel-wise uncertainty without ground truth. Experimental results on two benchmark datasets demonstrate the superior performance of AR-CDNet in the CD task. The demo code for our work will be publicly available at \\url{https://github.com/guanyuezhen/AR-CDNet}. ",
    "url": "https://arxiv.org/abs/2305.19513",
    "authors": [
      "Zhenglai Li",
      "Chang Tang",
      "Xianju Li",
      "Weiying Xie",
      "Kun Sun",
      "Xinzhong Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19523",
    "title": "Explanations as Features: LLM-Based Features for Text-Attributed Graphs",
    "abstract": "Representation learning on text-attributed graphs (TAGs) has become a critical research problem in recent years. A typical example of a TAG is a paper citation graph, where the text of each paper serves as node attributes. Most graph neural network (GNN) pipelines handle these text attributes by transforming them into shallow or hand-crafted features, such as skip-gram or bag-of-words features. Recent efforts have focused on enhancing these pipelines with language models. With the advent of powerful large language models (LLMs) such as GPT, which demonstrate an ability to reason and to utilize general knowledge, there is a growing need for techniques which combine the textual modelling abilities of LLMs with the structural learning capabilities of GNNs. Hence, in this work, we focus on leveraging LLMs to capture textual information as features, which can be used to boost GNN performance on downstream tasks. A key innovation is our use of \\emph{explanations as features}: we prompt an LLM to perform zero-shot classification and to provide textual explanations for its decisions, and find that the resulting explanations can be transformed into useful and informative features to augment downstream GNNs. Through experiments we show that our enriched features improve the performance of a variety of GNN models across different datasets. Notably, we achieve top-1 performance on \\texttt{ogbn-arxiv} by a significant margin over the closest baseline even with $2.88\\times$ lower computation time, as well as top-1 performance on TAG versions of the widely used \\texttt{PubMed} and \\texttt{Cora} benchmarks~\\footnote{Our codes and datasets are available at: \\url{https://github.com/XiaoxinHe/TAPE}}. ",
    "url": "https://arxiv.org/abs/2305.19523",
    "authors": [
      "Xiaoxin He",
      "Xavier Bresson",
      "Thomas Laurent",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19531",
    "title": "Multi-Epoch Learning for Deep Click-Through Rate Prediction Models",
    "abstract": "The one-epoch overfitting phenomenon has been widely observed in industrial Click-Through Rate (CTR) applications, where the model performance experiences a significant degradation at the beginning of the second epoch. Recent advances try to understand the underlying factors behind this phenomenon through extensive experiments. However, it is still unknown whether a multi-epoch training paradigm could achieve better results, as the best performance is usually achieved by one-epoch training. In this paper, we hypothesize that the emergence of this phenomenon may be attributed to the susceptibility of the embedding layer to overfitting, which can stem from the high-dimensional sparsity of data. To maintain feature sparsity while simultaneously avoiding overfitting of embeddings, we propose a novel Multi-Epoch learning with Data Augmentation (MEDA), which can be directly applied to most deep CTR models. MEDA achieves data augmentation by reinitializing the embedding layer in each epoch, thereby avoiding embedding overfitting and simultaneously improving convergence. To our best knowledge, MEDA is the first multi-epoch training paradigm designed for deep CTR prediction models. We conduct extensive experiments on several public datasets, and the effectiveness of our proposed MEDA is fully verified. Notably, the results show that MEDA can significantly outperform the conventional one-epoch training. Besides, MEDA has exhibited significant benefits in a real-world scene on Kuaishou. ",
    "url": "https://arxiv.org/abs/2305.19531",
    "authors": [
      "Zhaocheng Liu",
      "Zhongxiang Fan",
      "Jian Liang",
      "Dongying Kong",
      "Han Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19550",
    "title": "Spotlight Attention: Robust Object-Centric Learning With a Spatial  Locality Prior",
    "abstract": "The aim of object-centric vision is to construct an explicit representation of the objects in a scene. This representation is obtained via a set of interchangeable modules called \\emph{slots} or \\emph{object files} that compete for local patches of an image. The competition has a weak inductive bias to preserve spatial continuity; consequently, one slot may claim patches scattered diffusely throughout the image. In contrast, the inductive bias of human vision is strong, to the degree that attention has classically been described with a spotlight metaphor. We incorporate a spatial-locality prior into state-of-the-art object-centric vision models and obtain significant improvements in segmenting objects in both synthetic and real-world datasets. Similar to human visual attention, the combination of image content and spatial constraints yield robust unsupervised object-centric learning, including less sensitivity to model hyperparameters. ",
    "url": "https://arxiv.org/abs/2305.19550",
    "authors": [
      "Ayush Chakravarthy",
      "Trang Nguyen",
      "Anirudh Goyal",
      "Yoshua Bengio",
      "Michael C. Mozer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19567",
    "title": "DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code  Collaborated with Mixer",
    "abstract": "Despite the huge successes made in neutral TTS, content-leakage remains a challenge. In this paper, we propose a new input representation and simple architecture to achieve improved prosody modeling. Inspired by the recent success in the use of discrete code in TTS, we introduce discrete code to the input of the reference encoder. Specifically, we leverage the vector quantizer from the audio compression model to exploit the diverse acoustic information it has already been trained on. In addition, we apply the modified MLP-Mixer to the reference encoder, making the architecture lighter. As a result, we train the prosody transfer TTS in an end-to-end manner. We prove the effectiveness of our method through both subjective and objective evaluations. We demonstrate that the reference encoder learns better speaker-independent prosody when discrete code is utilized as input in the experiments. In addition, we obtain comparable results even when fewer parameters are inputted. ",
    "url": "https://arxiv.org/abs/2305.19567",
    "authors": [
      "Yerin Choi",
      "Myoung-Wan Koo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.19571",
    "title": "Fractional weak adversarial networks for the stationary fractional  advection dispersion equations",
    "abstract": "In this article, we propose the fractional weak adversarial networks (f-WANs) for the stationary fractional advection dispersion equations (FADE) based on their weak formulas. This enables us to handle less regular solutions for the fractional equations. To handle the non-local property of the fractional derivatives, convolutional layers and special loss functions are introduced in this neural network. Numerical experiments for both smooth and less regular solutions show the validity of f-WANs. ",
    "url": "https://arxiv.org/abs/2305.19571",
    "authors": [
      "Dian Feng",
      "Zhiwei Yang",
      "Sen Zou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.19581",
    "title": "SVVAD: Personal Voice Activity Detection for Speaker Verification",
    "abstract": "Voice activity detection (VAD) improves the performance of speaker verification (SV) by preserving speech segments and attenuating the effects of non-speech. However, this scheme is not ideal: (1) it fails in noisy environments or multi-speaker conversations; (2) it is trained based on inaccurate non-SV sensitive labels. To address this, we propose a speaker verification-based voice activity detection (SVVAD) framework that can adapt the speech features according to which are most informative for SV. To achieve this, we introduce a label-free training method with triplet-like losses that completely avoids the performance degradation of SV due to incorrect labeling. Extensive experiments show that SVVAD significantly outperforms the baseline in terms of equal error rate (EER) under conditions where other speakers are mixed at different ratios. Moreover, the decision boundaries reveal the importance of the different parts of speech, which are largely consistent with human judgments. ",
    "url": "https://arxiv.org/abs/2305.19581",
    "authors": [
      "Zuheng Kang",
      "Jianzong Wang",
      "Junqing Peng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.19582",
    "title": "Causal Discovery with Latent Confounders Based on Higher-Order Cumulants",
    "abstract": "Causal discovery with latent confounders is an important but challenging task in many scientific areas. Despite the success of some overcomplete independent component analysis (OICA) based methods in certain domains, they are computationally expensive and can easily get stuck into local optima. We notice that interestingly, by making use of higher-order cumulants, there exists a closed-form solution to OICA in specific cases, e.g., when the mixing procedure follows the One-Latent-Component structure. In light of the power of the closed-form solution to OICA corresponding to the One-Latent-Component structure, we formulate a way to estimate the mixing matrix using the higher-order cumulants, and further propose the testable One-Latent-Component condition to identify the latent variables and determine causal orders. By iteratively removing the share identified latent components, we successfully extend the results on the One-Latent-Component structure to the Multi-Latent-Component structure and finally provide a practical and asymptotically correct algorithm to learn the causal structure with latent variables. Experimental results illustrate the asymptotic correctness and effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2305.19582",
    "authors": [
      "Ruichu Cai",
      "Zhiyi Huang",
      "Wei Chen",
      "Zhifeng Hao",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.19586",
    "title": "CryptOpt: Automatic Optimization of Straightline Code",
    "abstract": "Manual engineering of high-performance implementations typically consumes many resources and requires in-depth knowledge of the hardware. Compilers try to address these problems; however, they are limited by design in what they can do. To address this, we present CryptOpt, an automatic optimizer for long stretches of straightline code. Experimental results across eight hardware platforms show that CryptOpt achieves a speed-up factor of up to 2.56 over current off-the-shelf compilers. ",
    "url": "https://arxiv.org/abs/2305.19586",
    "authors": [
      "Joel Kuepper",
      "Andres Erbsen",
      "Jason Gross",
      "Owen Conoly",
      "Chuyue Sun",
      "Samuel Tian",
      "David Wu",
      "Adam Chlipala",
      "Chitchanok Chuengsatiansup",
      "Daniel Genkin",
      "Markus Wagner",
      "Yuval Yarom"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.19587",
    "title": "Towards Omni-generalizable Neural Methods for Vehicle Routing Problems",
    "abstract": "Learning heuristics for vehicle routing problems (VRPs) has gained much attention due to the less reliance on hand-crafted rules. However, existing methods are typically trained and tested on the same task with a fixed size and distribution (of nodes), and hence suffer from limited generalization performance. This paper studies a challenging yet realistic setting, which considers generalization across both size and distribution in VRPs. We propose a generic meta-learning framework, which enables effective training of an initialized model with the capability of fast adaptation to new tasks during inference. We further develop a simple yet efficient approximation method to reduce the training overhead. Extensive experiments on both synthetic and benchmark instances of the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP) demonstrate the effectiveness of our method. The code is available at: https://github.com/RoyalSkye/Omni-VRP. ",
    "url": "https://arxiv.org/abs/2305.19587",
    "authors": [
      "Jianan Zhou",
      "Yaoxin Wu",
      "Wen Song",
      "Zhiguang Cao",
      "Jie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19588",
    "title": "Active causal structure learning with advice",
    "abstract": "We introduce the problem of active causal structure learning with advice. In the typical well-studied setting, the learning algorithm is given the essential graph for the observational distribution and is asked to recover the underlying causal directed acyclic graph (DAG) $G^*$ while minimizing the number of interventions made. In our setting, we are additionally given side information about $G^*$ as advice, e.g. a DAG $G$ purported to be $G^*$. We ask whether the learning algorithm can benefit from the advice when it is close to being correct, while still having worst-case guarantees even when the advice is arbitrarily bad. Our work is in the same space as the growing body of research on algorithms with predictions. When the advice is a DAG $G$, we design an adaptive search algorithm to recover $G^*$ whose intervention cost is at most $O(\\max\\{1, \\log \\psi\\})$ times the cost for verifying $G^*$; here, $\\psi$ is a distance measure between $G$ and $G^*$ that is upper bounded by the number of variables $n$, and is exactly 0 when $G=G^*$. Our approximation factor matches the state-of-the-art for the advice-less setting. ",
    "url": "https://arxiv.org/abs/2305.19588",
    "authors": [
      "Davin Choo",
      "Themis Gouleakis",
      "Arnab Bhattacharyya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19590",
    "title": "Neural Kernel Surface Reconstruction",
    "abstract": "We present a novel method for reconstructing a 3D implicit surface from a large-scale, sparse, and noisy point cloud. Our approach builds upon the recently introduced Neural Kernel Fields (NKF) representation. It enjoys similar generalization capabilities to NKF, while simultaneously addressing its main limitations: (a) We can scale to large scenes through compactly supported kernel functions, which enable the use of memory-efficient sparse linear solvers. (b) We are robust to noise, through a gradient fitting solve. (c) We minimize training requirements, enabling us to learn from any dataset of dense oriented points, and even mix training data consisting of objects and scenes at different scales. Our method is capable of reconstructing millions of points in a few seconds, and handling very large scenes in an out-of-core fashion. We achieve state-of-the-art results on reconstruction benchmarks consisting of single objects, indoor scenes, and outdoor scenes. ",
    "url": "https://arxiv.org/abs/2305.19590",
    "authors": [
      "Jiahui Huang",
      "Zan Gojcic",
      "Matan Atzmon",
      "Or Litany",
      "Sanja Fidler",
      "Francis Williams"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19591",
    "title": "Traffic Prediction using Artificial Intelligence: Review of Recent  Advances and Emerging Opportunities",
    "abstract": "Traffic prediction plays a crucial role in alleviating traffic congestion which represents a critical problem globally, resulting in negative consequences such as lost hours of additional travel time and increased fuel consumption. Integrating emerging technologies into transportation systems provides opportunities for improving traffic prediction significantly and brings about new research problems. In order to lay the foundation for understanding the open research challenges in traffic prediction, this survey aims to provide a comprehensive overview of traffic prediction methodologies. Specifically, we focus on the recent advances and emerging research opportunities in Artificial Intelligence (AI)-based traffic prediction methods, due to their recent success and potential in traffic prediction, with an emphasis on multivariate traffic time series modeling. We first provide a list and explanation of the various data types and resources used in the literature. Next, the essential data preprocessing methods within the traffic prediction context are categorized, and the prediction methods and applications are subsequently summarized. Lastly, we present primary research challenges in traffic prediction and discuss some directions for future research. ",
    "url": "https://arxiv.org/abs/2305.19591",
    "authors": [
      "Maryam Shaygan",
      "Collin Meese",
      "Wanxin Li",
      "Xiaolong Zhao",
      "Mark Nejad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19593",
    "title": "Exploring the Vulnerabilities of Machine Learning and Quantum Machine  Learning to Adversarial Attacks using a Malware Dataset: A Comparative  Analysis",
    "abstract": "The burgeoning fields of machine learning (ML) and quantum machine learning (QML) have shown remarkable potential in tackling complex problems across various domains. However, their susceptibility to adversarial attacks raises concerns when deploying these systems in security sensitive applications. In this study, we present a comparative analysis of the vulnerability of ML and QML models, specifically conventional neural networks (NN) and quantum neural networks (QNN), to adversarial attacks using a malware dataset. We utilize a software supply chain attack dataset known as ClaMP and develop two distinct models for QNN and NN, employing Pennylane for quantum implementations and TensorFlow and Keras for traditional implementations. Our methodology involves crafting adversarial samples by introducing random noise to a small portion of the dataset and evaluating the impact on the models performance using accuracy, precision, recall, and F1 score metrics. Based on our observations, both ML and QML models exhibit vulnerability to adversarial attacks. While the QNNs accuracy decreases more significantly compared to the NN after the attack, it demonstrates better performance in terms of precision and recall, indicating higher resilience in detecting true positives under adversarial conditions. We also find that adversarial samples crafted for one model type can impair the performance of the other, highlighting the need for robust defense mechanisms. Our study serves as a foundation for future research focused on enhancing the security and resilience of ML and QML models, particularly QNN, given its recent advancements. A more extensive range of experiments will be conducted to better understand the performance and robustness of both models in the face of adversarial attacks. ",
    "url": "https://arxiv.org/abs/2305.19593",
    "authors": [
      "Mst Shapna Akter",
      "Hossain Shahriar",
      "Iysa Iqbal",
      "MD Hossain",
      "M.A. Karim",
      "Victor Clincy",
      "Razvan Voicu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2305.19598",
    "title": "Towards Semi-supervised Universal Graph Classification",
    "abstract": "Graph neural networks have pushed state-of-the-arts in graph classifications recently. Typically, these methods are studied within the context of supervised end-to-end training, which necessities copious task-specific labels. However, in real-world circumstances, labeled data could be limited, and there could be a massive corpus of unlabeled data, even from unknown classes as a complementary. Towards this end, we study the problem of semi-supervised universal graph classification, which not only identifies graph samples which do not belong to known classes, but also classifies the remaining samples into their respective classes. This problem is challenging due to a severe lack of labels and potential class shifts. In this paper, we propose a novel graph neural network framework named UGNN, which makes the best of unlabeled data from the subgraph perspective. To tackle class shifts, we estimate the certainty of unlabeled graphs using multiple subgraphs, which facilities the discovery of unlabeled data from unknown categories. Moreover, we construct semantic prototypes in the embedding space for both known and unknown categories and utilize posterior prototype assignments inferred from the Sinkhorn-Knopp algorithm to learn from abundant unlabeled graphs across different subgraph views. Extensive experiments on six datasets verify the effectiveness of UGNN in different settings. ",
    "url": "https://arxiv.org/abs/2305.19598",
    "authors": [
      "Xiao Luo",
      "Yusheng Zhao",
      "Yifang Qin",
      "Wei Ju",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.19600",
    "title": "Federated Learning on Heterogeneous Data via Adaptive Self-Distillation",
    "abstract": "Federated Learning (FL) is a machine learning paradigm that enables clients to jointly train a global model by aggregating the locally trained models without sharing any local training data. In practice, there can often be substantial heterogeneity (e.g., class imbalance) across the local data distributions observed by each of these clients. Under such non-iid data distributions across clients, FL suffers from the 'client-drift' problem where every client converges to its own local optimum. This results in slower convergence and poor performance of the aggregated model. To address this limitation, we propose a novel regularization technique based on adaptive self-distillation (ASD) for training models on the client side. Our regularization scheme adaptively adjusts to the client's training data based on: (1) the closeness of the local model's predictions with that of the global model and (2) the client's label distribution. The proposed regularization can be easily integrated atop existing, state-of-the-art FL algorithms leading to a further boost in the performance of these off-the-shelf methods. We demonstrate the efficacy of our proposed FL approach through extensive experiments on multiple real-world benchmarks (including datasets with common corruptions and perturbations) and show substantial gains in performance over the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.19600",
    "authors": [
      "M.Yashwanth",
      "Gaurav. K. Nayak",
      "Arya Singh",
      "Yogesh Singh",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19602",
    "title": "Learning Music Sequence Representation from Text Supervision",
    "abstract": "Music representation learning is notoriously difficult for its complex human-related concepts contained in the sequence of numerical signals. To excavate better MUsic SEquence Representation from labeled audio, we propose a novel text-supervision pre-training method, namely MUSER. MUSER adopts an audio-spectrum-text tri-modal contrastive learning framework, where the text input could be any form of meta-data with the help of text templates while the spectrum is derived from an audio sequence. Our experiments reveal that MUSER could be more flexibly adapted to downstream tasks compared with the current data-hungry pre-training method, and it only requires 0.056% of pre-training data to achieve the state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2305.19602",
    "authors": [
      "Tianyu Chen",
      "Yuan Xie",
      "Shuai Zhang",
      "Shaohan Huang",
      "Haoyi Zhou",
      "Jianxin Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.19607",
    "title": "Adversarial Clean Label Backdoor Attacks and Defenses on Text  Classification Systems",
    "abstract": "Clean-label (CL) attack is a form of data poisoning attack where an adversary modifies only the textual input of the training data, without requiring access to the labeling function. CL attacks are relatively unexplored in NLP, as compared to label flipping (LF) attacks, where the latter additionally requires access to the labeling function as well. While CL attacks are more resilient to data sanitization and manual relabeling methods than LF attacks, they often demand as high as ten times the poisoning budget than LF attacks. In this work, we first introduce an Adversarial Clean Label attack which can adversarially perturb in-class training examples for poisoning the training set. We then show that an adversary can significantly bring down the data requirements for a CL attack, using the aforementioned approach, to as low as 20% of the data otherwise required. We then systematically benchmark and analyze a number of defense methods, for both LF and CL attacks, some previously employed solely for LF attacks in the textual domain and others adapted from computer vision. We find that text-specific defenses greatly vary in their effectiveness depending on their properties. ",
    "url": "https://arxiv.org/abs/2305.19607",
    "authors": [
      "Ashim Gupta",
      "Amrith Krishna"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.19617",
    "title": "MSMix:An Interpolation-Based Text Data Augmentation Method Manifold Swap  Mixup",
    "abstract": "To solve the problem of poor performance of deep neural network models due to insufficient data, a simple yet effective interpolation-based data augmentation method is proposed: MSMix (Manifold Swap Mixup). This method feeds two different samples to the same deep neural network model, and then randomly select a specific layer and partially replace hidden features at that layer of one of the samples by the counterpart of the other. The mixed hidden features are fed to the model and go through the rest of the network. Two different selection strategies are also proposed to obtain richer hidden representation. Experiments are conducted on three Chinese intention recognition datasets, and the results show that the MSMix method achieves better results than other methods in both full-sample and small-sample configurations. ",
    "url": "https://arxiv.org/abs/2305.19617",
    "authors": [
      "Mao Ye",
      "Haitao Wang",
      "Zheqian Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19623",
    "title": "Point-GCC: Universal Self-supervised 3D Scene Pre-training via  Geometry-Color Contrast",
    "abstract": "Geometry and color information provided by the point clouds are both crucial for 3D scene understanding. Two pieces of information characterize the different aspects of point clouds, but existing methods lack an elaborate design for the discrimination and relevance. Hence we explore a 3D self-supervised paradigm that can better utilize the relations of point cloud information. Specifically, we propose a universal 3D scene pre-training framework via Geometry-Color Contrast (Point-GCC), which aligns geometry and color information using a Siamese network. To take care of actual application tasks, we design (i) hierarchical supervision with point-level contrast and reconstruct and object-level contrast based on the novel deep clustering module to close the gap between pre-training and downstream tasks; (ii) architecture-agnostic backbone to adapt for various downstream models. Benefiting from the object-level representation associated with downstream tasks, Point-GCC can directly evaluate model performance and the result demonstrates the effectiveness of our methods. Transfer learning results on a wide range of tasks also show consistent improvements across all datasets. e.g., new state-of-the-art object detection results on SUN RGB-D and S3DIS datasets. Codes will be released at https://github.com/Asterisci/Point-GCC. ",
    "url": "https://arxiv.org/abs/2305.19623",
    "authors": [
      "Guofan Fan",
      "Zekun Qi",
      "Wenkai Shi",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19624",
    "title": "A Multi-Modal Transformer Network for Action Detection",
    "abstract": "This paper proposes a novel multi-modal transformer network for detecting actions in untrimmed videos. To enrich the action features, our transformer network utilizes a new multi-modal attention mechanism that computes the correlations between different spatial and motion modalities combinations. Exploring such correlations for actions has not been attempted previously. To use the motion and spatial modality more effectively, we suggest an algorithm that corrects the motion distortion caused by camera movement. Such motion distortion, common in untrimmed videos, severely reduces the expressive power of motion features such as optical flow fields. Our proposed algorithm outperforms the state-of-the-art methods on two public benchmarks, THUMOS14 and ActivityNet. We also conducted comparative experiments on our new instructional activity dataset, including a large set of challenging classroom videos captured from elementary schools. ",
    "url": "https://arxiv.org/abs/2305.19624",
    "authors": [
      "Matthew Korban",
      "Scott T. Acton",
      "Peter Youngs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19636",
    "title": "Explainable AI for Malnutrition Risk Prediction from m-Health and  Clinical Data",
    "abstract": "Malnutrition is a serious and prevalent health problem in the older population, and especially in hospitalised or institutionalised subjects. Accurate and early risk detection is essential for malnutrition management and prevention. M-health services empowered with Artificial Intelligence (AI) may lead to important improvements in terms of a more automatic, objective, and continuous monitoring and assessment. Moreover, the latest Explainable AI (XAI) methodologies may make AI decisions interpretable and trustworthy for end users. This paper presents a novel AI framework for early and explainable malnutrition risk detection based on heterogeneous m-health data. We performed an extensive model evaluation including both subject-independent and personalised predictions, and the obtained results indicate Random Forest (RF) and Gradient Boosting as the best performing classifiers, especially when incorporating body composition assessment data. We also investigated several benchmark XAI methods to extract global model explanations. Model-specific explanation consistency assessment indicates that each selected model privileges similar subsets of the most relevant predictors, with the highest agreement shown between SHapley Additive ExPlanations (SHAP) and feature permutation method. Furthermore, we performed a preliminary clinical validation to verify that the learned feature-output trends are compliant with the current evidence-based assessment. ",
    "url": "https://arxiv.org/abs/2305.19636",
    "authors": [
      "Flavio Di Martino",
      "Franca Delmastro",
      "Cristina Dolciotti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19643",
    "title": "Mask, Stitch, and Re-Sample: Enhancing Robustness and Generalizability  in Anomaly Detection through Automatic Diffusion Models",
    "abstract": "The introduction of diffusion models in anomaly detection has paved the way for more effective and accurate image reconstruction in pathologies. However, the current limitations in controlling noise granularity hinder diffusion models' ability to generalize across diverse anomaly types and compromise the restoration of healthy tissues. To overcome these challenges, we propose AutoDDPM, a novel approach that enhances the robustness of diffusion models. AutoDDPM utilizes diffusion models to generate initial likelihood maps of potential anomalies and seamlessly integrates them with the original image. Through joint noised distribution re-sampling, AutoDDPM achieves harmonization and in-painting effects. Our study demonstrates the efficacy of AutoDDPM in replacing anomalous regions while preserving healthy tissues, considerably surpassing diffusion models' limitations. It also contributes valuable insights and analysis on the limitations of current diffusion models, promoting robust and interpretable anomaly detection in medical imaging - an essential aspect of building autonomous clinical decision systems with higher interpretability. ",
    "url": "https://arxiv.org/abs/2305.19643",
    "authors": [
      "Cosmin I. Bercea",
      "Michael Neumayr",
      "Daniel Rueckert",
      "Julia A. Schnabel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.19659",
    "title": "Improving Expressivity of Graph Neural Networks using Localization",
    "abstract": "In this paper, we propose localized versions of Weisfeiler-Leman (WL) algorithms in an effort to both increase the expressivity, as well as decrease the computational overhead. We focus on the specific problem of subgraph counting and give localized versions of $k-$WL for any $k$. We analyze the power of Local $k-$WL and prove that it is more expressive than $k-$WL and at most as expressive as $(k+1)-$WL. We give a characterization of patterns whose count as a subgraph and induced subgraph are invariant if two graphs are Local $k-$WL equivalent. We also introduce two variants of $k-$WL: Layer $k-$WL and recursive $k-$WL. These methods are more time and space efficient than applying $k-$WL on the whole graph. We also propose a fragmentation technique that guarantees the exact count of all induced subgraphs of size at most 4 using just $1-$WL. The same idea can be extended further for larger patterns using $k>1$. We also compare the expressive power of Local $k-$WL with other GNN hierarchies and show that given a bound on the time-complexity, our methods are more expressive than the ones mentioned in Papp and Wattenhofer[2022a]. ",
    "url": "https://arxiv.org/abs/2305.19659",
    "authors": [
      "Anant Kumar",
      "Shrutimoy Das",
      "Shubhajit Roy",
      "Binita Maity",
      "Anirban Dasgupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.19663",
    "title": "Vandermonde Neural Operators",
    "abstract": "Fourier Neural Operators (FNOs) have emerged as very popular machine learning architectures for learning operators, particularly those arising in PDEs. However, as FNOs rely on the fast Fourier transform for computational efficiency, the architecture can be limited to input data on equispaced Cartesian grids. Here, we generalize FNOs to handle input data on non-equispaced point distributions. Our proposed model, termed as Vandermonde Neural Operator (VNO), utilizes Vandermonde-structured matrices to efficiently compute forward and inverse Fourier transforms, even on arbitrarily distributed points. We present numerical experiments to demonstrate that VNOs can be significantly faster than FNOs, while retaining comparable accuracy, and improve upon accuracy of comparable non-equispaced methods such as the Geo-FNO. ",
    "url": "https://arxiv.org/abs/2305.19663",
    "authors": [
      "Levi Lingsch",
      "Mike Michelis",
      "Sirani M. Perera",
      "Robert K. Katzschmann",
      "Siddartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.19664",
    "title": "Unveiling Cross Modality Bias in Visual Question Answering: A Causal  View with Possible Worlds VQA",
    "abstract": "To increase the generalization capability of VQA systems, many recent studies have tried to de-bias spurious language or vision associations that shortcut the question or image to the answer. Despite these efforts, the literature fails to address the confounding effect of vision and language simultaneously. As a result, when they reduce bias learned from one modality, they usually increase bias from the other. In this paper, we first model a confounding effect that causes language and vision bias simultaneously, then propose a counterfactual inference to remove the influence of this effect. The model trained in this strategy can concurrently and efficiently reduce vision and language bias. To the best of our knowledge, this is the first work to reduce biases resulting from confounding effects of vision and language in VQA, leveraging causal explain-away relations. We accompany our method with an explain-away strategy, pushing the accuracy of the questions with numerical answers results compared to existing methods that have been an open problem. The proposed method outperforms the state-of-the-art methods in VQA-CP v2 datasets. ",
    "url": "https://arxiv.org/abs/2305.19664",
    "authors": [
      "Ali Vosoughi",
      "Shijian Deng",
      "Songyang Zhang",
      "Yapeng Tian",
      "Chenliang Xu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.19666",
    "title": "Efficient Algorithms for Exact Graph Matching on Correlated Stochastic  Block Models with Constant Correlation",
    "abstract": "We consider the problem of graph matching, or learning vertex correspondence, between two correlated stochastic block models (SBMs). The graph matching problem arises in various fields, including computer vision, natural language processing and bioinformatics, and in particular, matching graphs with inherent community structure has significance related to de-anonymization of correlated social networks. Compared to the correlated Erdos-Renyi (ER) model, where various efficient algorithms have been developed, among which a few algorithms have been proven to achieve the exact matching with constant edge correlation, no low-order polynomial algorithm has been known to achieve exact matching for the correlated SBMs with constant correlation. In this work, we propose an efficient algorithm for matching graphs with community structure, based on the comparison between partition trees rooted from each vertex, by extending the idea of Mao et al. (2021) to graphs with communities. The partition tree divides the large neighborhoods of each vertex into disjoint subsets using their edge statistics to different communities. Our algorithm is the first low-order polynomial-time algorithm achieving exact matching between two correlated SBMs with high probability in dense graphs. ",
    "url": "https://arxiv.org/abs/2305.19666",
    "authors": [
      "Joonhyuk Yang",
      "Dongpil Shin",
      "Hye Won Chung"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19673",
    "title": "Quantum Speedups for Bayesian Network Structure Learning",
    "abstract": "The Bayesian network structure learning (BNSL) problem asks for a directed acyclic graph that maximizes a given score function. For networks with $n$ nodes, the fastest known algorithms run in time $O(2^n n^2)$ in the worst case, with no improvement in the asymptotic bound for two decades. Inspired by recent advances in quantum computing, we ask whether BNSL admits a polynomial quantum speedup, that is, whether the problem can be solved by a quantum algorithm in time $O(c^n)$ for some constant $c$ less than $2$. We answer the question in the affirmative by giving two algorithms achieving $c \\leq 1.817$ and $c \\leq 1.982$ assuming the number of potential parent sets is, respectively, subexponential and $O(1.453^n)$. Both algorithms assume the availability of a quantum random access memory. ",
    "url": "https://arxiv.org/abs/2305.19673",
    "authors": [
      "Juha Harviainen",
      "Kseniya Rychkova",
      "Mikko Koivisto"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2305.19678",
    "title": "Smooth-Trajectron++: Augmenting the Trajectron++ behaviour prediction  model with smooth attention",
    "abstract": "Understanding traffic participants' behaviour is crucial for predicting their future trajectories, aiding in developing safe and reliable planning systems for autonomous vehicles. Integrating cognitive processes and machine learning models has shown promise in other domains but is lacking in the trajectory forecasting of multiple traffic agents in large-scale autonomous driving datasets. This work investigates the state-of-the-art trajectory forecasting model Trajectron++ which we enhance by incorporating a smoothing term in its attention module. This attention mechanism mimics human attention inspired by cognitive science research indicating limits to attention switching. We evaluate the performance of the resulting Smooth-Trajectron++ model and compare it to the original model on various benchmarks, revealing the potential of incorporating insights from human cognition into trajectory prediction models. ",
    "url": "https://arxiv.org/abs/2305.19678",
    "authors": [
      "Frederik S.B. Westerhout",
      "Julian F. Schumann",
      "Arkady Zgonnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19696",
    "title": "An Efficient Machine Learning-based Channel Prediction Technique for  OFDM Sub-Bands",
    "abstract": "The acquisition of accurate channel state information (CSI) is of utmost importance since it provides performance improvement of wireless communication systems. However, acquiring accurate CSI, which can be done through channel estimation or channel prediction, is an intricate task due to the complexity of the time-varying and frequency selectivity of the wireless environment. To this end, we propose an efficient machine learning (ML)-based technique for channel prediction in orthogonal frequency-division multiplexing (OFDM) sub-bands. The novelty of the proposed approach lies in the training of channel fading samples used to estimate future channel behaviour in selective fading. ",
    "url": "https://arxiv.org/abs/2305.19696",
    "authors": [
      "Pedro E. G. Silva",
      "Jules M. Moualeu",
      "Pedro H. Nardelli",
      "Rausley A. A. de Souza"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.19717",
    "title": "Is Rewiring Actually Helpful in Graph Neural Networks?",
    "abstract": "Graph neural networks compute node representations by performing multiple message-passing steps that consist in local aggregations of node features. Having deep models that can leverage longer-range interactions between nodes is hindered by the issues of over-smoothing and over-squashing. In particular, the latter is attributed to the graph topology which guides the message-passing, causing a node representation to become insensitive to information contained at distant nodes. Many graph rewiring methods have been proposed to remedy or mitigate this problem. However, properly evaluating the benefits of these methods is made difficult by the coupling of over-squashing with other issues strictly related to model training, such as vanishing gradients. Therefore, we propose an evaluation setting based on message-passing models that do not require training to compute node and graph representations. We perform a systematic experimental comparison on real-world node and graph classification tasks, showing that rewiring the underlying graph rarely does confer a practical benefit for message-passing. ",
    "url": "https://arxiv.org/abs/2305.19717",
    "authors": [
      "Domenico Tortorella",
      "Alessio Micheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19719",
    "title": "Low-Complexity Dynamic Directional Modulation: Vulnerability and  Information Leakage",
    "abstract": "In this paper, the privacy of wireless transmissions is improved through the use of an efficient technique termed dynamic directional modulation (DDM), and is subsequently assessed in terms of the measure of information leakage. Recently, a variation of DDM termed low-power dynamic directional modulation (LPDDM) has attracted significant attention as a prominent secure transmission method due to its ability to further improve the privacy of wireless communications. Roughly speaking, this modulation operates by randomly selecting the transmitting antenna from an antenna array whose radiation pattern is well known. Thereafter, the modulator adjusts the constellation phase so as to ensure that only the legitimate receiver recovers the information. To begin with, we highlight some privacy boundaries inherent to the underlying system. In addition, we propose features that the antenna array must meet in order to increase the privacy of a wireless communication system. Last, we adopt a uniform circular monopole antenna array with equiprobable transmitting antennas in order to assess the impact of DDM on the information leakage. It is shown that the bit error rate, while being a useful metric in the evaluation of wireless communication systems, does not provide the full information about the vulnerability of the underlying system. ",
    "url": "https://arxiv.org/abs/2305.19719",
    "authors": [
      "Pedro E. G\u00f3ria Silva",
      "Adam Narbudowicz",
      "Nicola Marchetti",
      "Pedro H. J. Nardelli",
      "Rausley A. A. de Souza",
      "Jules M. Moualeu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.19725",
    "title": "Direct Learning-Based Deep Spiking Neural Networks: A Review",
    "abstract": "The spiking neural network (SNN), as a promising brain-inspired computational model with binary spike information transmission mechanism, rich spatially-temporal dynamics, and event-driven characteristics, has received extensive attention. However, its intricately discontinuous spike mechanism brings difficulty to the optimization of the deep SNN. Since the surrogate gradient method can greatly mitigate the optimization difficulty and shows great potential in directly training deep SNNs, a variety of direct learning-based deep SNN works have been proposed and achieved satisfying progress in recent years. In this paper, we present a comprehensive survey of these direct learning-based deep SNN works, mainly categorized into accuracy improvement methods, efficiency improvement methods, and temporal dynamics utilization methods. In addition, we also divide these categorizations into finer granularities further to better organize and introduce them. Finally, the challenges and trends that may be faced in future research are prospected. ",
    "url": "https://arxiv.org/abs/2305.19725",
    "authors": [
      "Yufei Guo",
      "Xuhui Huang",
      "Zhe Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19729",
    "title": "OVNS: Opportunistic Variable Neighborhood Search for Heaviest Subgraph  Problem in Social Networks",
    "abstract": "We propose a hybrid heuristic algorithm for solving the Heaviest k-Subgraph Problem in online social networks -- a combinatorial graph optimization problem central to many important applications in weighted social networks, including detection of coordinated behavior, maximizing diversity of a group of users, and detecting social groups. Our approach builds upon an existing metaheuristic framework known as Variable Neighborhood Search and takes advantage of empirical insights about social network structures to derive an improved optimization heuristic. We conduct benchmarks in both real life social networks as well as synthetic networks and demonstrate that the proposed modifications match and in the majority of cases supersede those of the current state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2305.19729",
    "authors": [
      "Ville P. Saarinen",
      "Ted Hsuan Yun Chen",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.19744",
    "title": "Neural Markov Jump Processes",
    "abstract": "Markov jump processes are continuous-time stochastic processes with a wide range of applications in both natural and social sciences. Despite their widespread use, inference in these models is highly non-trivial and typically proceeds via either Monte Carlo or expectation-maximization methods. In this work we introduce an alternative, variational inference algorithm for Markov jump processes which relies on neural ordinary differential equations, and is trainable via back-propagation. Our methodology learns neural, continuous-time representations of the observed data, that are used to approximate the initial distribution and time-dependent transition probability rates of the posterior Markov jump process. The time-independent rates of the prior process are in contrast trained akin to generative adversarial networks. We test our approach on synthetic data sampled from ground-truth Markov jump processes, experimental switching ion channel data and molecular dynamics simulations. Source code to reproduce our experiments is available online. ",
    "url": "https://arxiv.org/abs/2305.19744",
    "authors": [
      "Patrick Seifner",
      "Ramses J. Sanchez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19753",
    "title": "The Tunnel Effect: Building Data Representations in Deep Neural Networks",
    "abstract": "Deep neural networks are widely known for their remarkable effectiveness across various tasks, with the consensus that deeper networks implicitly learn more complex data representations. This paper shows that sufficiently deep networks trained for supervised image classification split into two distinct parts that contribute to the resulting data representations differently. The initial layers create linearly-separable representations, while the subsequent layers, which we refer to as \\textit{the tunnel}, compress these representations and have a minimal impact on the overall performance. We explore the tunnel's behavior through comprehensive empirical studies, highlighting that it emerges early in the training process. Its depth depends on the relation between the network's capacity and task complexity. Furthermore, we show that the tunnel degrades out-of-distribution generalization and discuss its implications for continual learning. ",
    "url": "https://arxiv.org/abs/2305.19753",
    "authors": [
      "Wojciech Masarczyk",
      "Mateusz Ostaszewski",
      "Ehsan Imani",
      "Razvan Pascanu",
      "Piotr Mi\u0142o\u015b",
      "Tomasz Trzci\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19757",
    "title": "Automatic Discrimination of Human and Neural Machine Translation in  Multilingual Scenarios",
    "abstract": "We tackle the task of automatically discriminating between human and machine translations. As opposed to most previous work, we perform experiments in a multilingual setting, considering multiple languages and multilingual pretrained language models. We show that a classifier trained on parallel data with a single source language (in our case German-English) can still perform well on English translations that come from different source languages, even when the machine translations were produced by other systems than the one it was trained on. Additionally, we demonstrate that incorporating the source text in the input of a multilingual classifier improves (i) its accuracy and (ii) its robustness on cross-system evaluation, compared to a monolingual classifier. Furthermore, we find that using training data from multiple source languages (German, Russian, and Chinese) tends to improve the accuracy of both monolingual and multilingual classifiers. Finally, we show that bilingual classifiers and classifiers trained on multiple source languages benefit from being trained on longer text sequences, rather than on sentences. ",
    "url": "https://arxiv.org/abs/2305.19757",
    "authors": [
      "Malina Chichirau",
      "Rik van Noord",
      "Antonio Toral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19770",
    "title": "Quality In / Quality Out: Assessing Data quality in an Anomaly Detection  Benchmark",
    "abstract": "Autonomous or self-driving networks are expected to provide a solution to the myriad of extremely demanding new applications in the Future Internet. The key to handle complexity is to perform tasks like network optimization and failure recovery with minimal human supervision. For this purpose, the community relies on the development of new Machine Learning (ML) models and techniques. However, ML can only be as good as the data it is fitted with. Datasets provided to the community as benchmarks for research purposes, which have a relevant impact in research findings and directions, are often assumed to be of good quality by default. In this paper, we show that relatively minor modifications on the same benchmark dataset (UGR'16, a flow-based real-traffic dataset for anomaly detection) cause significantly more impact on model performance than the specific ML technique considered. To understand this finding, we contribute a methodology to investigate the root causes for those differences, and to assess the quality of the data labelling. Our findings illustrate the need to devote more attention into (automatic) data quality assessment and optimization techniques in the context of autonomous networks. ",
    "url": "https://arxiv.org/abs/2305.19770",
    "authors": [
      "Jos\u00e9 Camacho",
      "Katarzyna Wasielewska",
      "Marta Fuentes-Garc\u00eda",
      "Rafael Rodr\u00edguez-G\u00f3mez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19775",
    "title": "Evolutionary Solution Adaption for Multi-Objective Metal Cutting Process  Optimization",
    "abstract": "Optimizing manufacturing process parameters is typically a multi-objective problem with often contradictory objectives such as production quality and production time. If production requirements change, process parameters have to be optimized again. Since optimization usually requires costly simulations based on, for example, the Finite Element method, it is of great interest to have means to reduce the number of evaluations needed for optimization. To this end, we consider optimizing for different production requirements from the viewpoint of a framework for system flexibility that allows us to study the ability of an algorithm to transfer solutions from previous optimization tasks, which also relates to dynamic evolutionary optimization. Based on the extended Oxley model for orthogonal metal cutting, we introduce a multi-objective optimization benchmark where different materials define related optimization tasks, and use it to study the flexibility of NSGA-II, which we extend by two variants: 1) varying goals, that optimizes solutions for two tasks simultaneously to obtain in-between source solutions expected to be more adaptable, and 2) active-inactive genotype, that accommodates different possibilities that can be activated or deactivated. Results show that adaption with standard NSGA-II greatly reduces the number of evaluations required for optimization to a target goal, while the proposed variants further improve the adaption costs, although further work is needed towards making the methods advantageous for real applications. ",
    "url": "https://arxiv.org/abs/2305.19775",
    "authors": [
      "Leo Francoso Dal Piccol Sotto",
      "Sebastian Mayer",
      "Hemanth Janarthanam",
      "Alexander Butz",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.19778",
    "title": "Impact Assessment of Data Integrity Attacks in MVDC Shipboard Power  Systems",
    "abstract": "The development of power electronics-based medium voltage direct current (MVDC) networks has revolutionized the marine industry by enabling all-electric ships (AES). This technology facilitates the integration of heterogeneous resources and improves efficiency. The independent shipboard power system (SPS) is controlled by exchanging measurements and control signals over a communication network. However, the reliance on communication channels raises concerns about the potential exploitation of vulnerabilities leading to cyber-attacks that could disrupt the system. In this paper, a notional 12 kV MVDC SPS model with zonal electrical distribution system (ZEDS) architecture is considered as an exemplary model. As the system stability is closely linked to the transient performance, we investigate how to determine the operational status of the system under potential data integrity attacks on the governor and exciter of the power generation modules (PGMs). Further, the impact of these attacks on the stability of rotor speed and the DC link voltage is derived and discussed. The simulation of the system is carried out in MATLAB/Simulink environment. ",
    "url": "https://arxiv.org/abs/2305.19778",
    "authors": [
      "Kirti Gupta",
      "Subham Sahoo",
      "Bijaya Ketan Panigrahi",
      "Charalambos Konstantinou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.19798",
    "title": "Primal-Attention: Self-attention through Asymmetric Kernel SVD in Primal  Representation",
    "abstract": "Recently, a new line of works has emerged to understand and improve self-attention in Transformers by treating it as a kernel machine. However, existing works apply the methods for symmetric kernels to the asymmetric self-attention, resulting in a nontrivial gap between the analytical understanding and numerical implementation. In this paper, we provide a new perspective to represent and optimize self-attention through asymmetric Kernel Singular Value Decomposition (KSVD), which is also motivated by the low-rank property of self-attention normally observed in deep layers. Through asymmetric KSVD, $i$) a primal-dual representation of self-attention is formulated, where the optimization objective is cast to maximize the projection variances in the attention outputs; $ii$) a novel attention mechanism, i.e., Primal-Attention, is proposed via the primal representation of KSVD, avoiding explicit computation of the kernel matrix in the dual; $iii$) with KKT conditions, we prove that the stationary solution to the KSVD optimization in Primal-Attention yields a zero-value objective. In this manner, KSVD optimization can be implemented by simply minimizing a regularization loss, so that low-rank property is promoted without extra decomposition. Numerical experiments show state-of-the-art performance of our Primal-Attention with improved efficiency. Moreover, we demonstrate that the deployed KSVD optimization regularizes Primal-Attention with a sharper singular value decay than that of the canonical self-attention, further verifying the great potential of our method. To the best of our knowledge, this is the first work that provides a primal-dual representation for the asymmetric kernel in self-attention and successfully applies it to modeling and optimization. ",
    "url": "https://arxiv.org/abs/2305.19798",
    "authors": [
      "Yingyi Chen",
      "Qinghua Tao",
      "Francesco Tonin",
      "Johan A.K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19818",
    "title": "Bridging Spectral Embedding and Matrix Completion in Self-Supervised  Learning",
    "abstract": "Self-supervised methods received tremendous attention thanks to their seemingly heuristic approach to learning representations that respect the semantics of the data without any apparent supervision in the form of labels. A growing body of literature is already being published in an attempt to build a coherent and theoretically grounded understanding of the workings of a zoo of losses used in modern self-supervised representation learning methods. In this paper, we attempt to provide an understanding from the perspective of a Laplace operator and connect the inductive bias stemming from the augmentation process to a low-rank matrix completion problem. To this end, we leverage the results from low-rank matrix completion to provide theoretical analysis on the convergence of modern SSL methods and a key property that affects their downstream performance. ",
    "url": "https://arxiv.org/abs/2305.19818",
    "authors": [
      "Marina Munkhoeva",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19845",
    "title": "Guiding Computational Stance Detection with Expanded Stance Triangle  Framework",
    "abstract": "Stance detection determines whether the author of a piece of text is in favor of, against, or neutral towards a specified target, and can be used to gain valuable insights into social media. The ubiquitous indirect referral of targets makes this task challenging, as it requires computational solutions to model semantic features and infer the corresponding implications from a literal statement. Moreover, the limited amount of available training data leads to subpar performance in out-of-domain and cross-target scenarios, as data-driven approaches are prone to rely on superficial and domain-specific features. In this work, we decompose the stance detection task from a linguistic perspective, and investigate key components and inference paths in this task. The stance triangle is a generic linguistic framework previously proposed to describe the fundamental ways people express their stance. We further expand it by characterizing the relationship between explicit and implicit objects. We then use the framework to extend one single training corpus with additional annotation. Experimental results show that strategically-enriched data can significantly improve the performance on out-of-domain and cross-target evaluation. ",
    "url": "https://arxiv.org/abs/2305.19845",
    "authors": [
      "Zhengyuan Liu",
      "Yong Keong Yap",
      "Hai Leong Chieu",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19858",
    "title": "Enhancing image quality prediction with self-supervised visual masking",
    "abstract": "Full-reference image quality metrics (FR-IQMs) aim to measure the visual differences between a pair of reference and distorted images, with the goal of accurately predicting human judgments. However, existing FR-IQMs, including traditional ones like PSNR and SSIM and even perceptual ones such as HDR-VDP, LPIPS, and DISTS, still fall short in capturing the complexities and nuances of human perception. In this work, rather than devising a novel IQM model, we seek to improve upon the perceptual quality of existing FR-IQM methods. We achieve this by considering visual masking, an important characteristic of the human visual system that changes its sensitivity to distortions as a function of local image content. Specifically, for a given FR-IQM metric, we propose to predict a visual masking model that modulates reference and distorted images in a way that penalizes the visual errors based on their visibility. Since the ground truth visual masks are difficult to obtain, we demonstrate how they can be derived in a self-supervised manner solely based on mean opinion scores (MOS) collected from an FR-IQM dataset. Our approach results in enhanced FR-IQM metrics that are more in line with human prediction both visually and quantitatively. ",
    "url": "https://arxiv.org/abs/2305.19858",
    "authors": [
      "U\u011fur \u00c7o\u011falan",
      "Mojtaba Bemana",
      "Hans-Peter Seidel",
      "Karol Myszkowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.19862",
    "title": "Self-supervised Learning to Bring Dual Reversed Rolling Shutter Images  Alive",
    "abstract": "Modern consumer cameras usually employ the rolling shutter (RS) mechanism, where images are captured by scanning scenes row-by-row, yielding RS distortions for dynamic scenes. To correct RS distortions, existing methods adopt a fully supervised learning manner, where high framerate global shutter (GS) images should be collected as ground-truth supervision. In this paper, we propose a Self-supervised learning framework for Dual reversed RS distortions Correction (SelfDRSC), where a DRSC network can be learned to generate a high framerate GS video only based on dual RS images with reversed distortions. In particular, a bidirectional distortion warping module is proposed for reconstructing dual reversed RS images, and then a self-supervised loss can be deployed to train DRSC network by enhancing the cycle consistency between input and reconstructed dual reversed RS images. Besides start and end RS scanning time, GS images at arbitrary intermediate scanning time can also be supervised in SelfDRSC, thus enabling the learned DRSC network to generate a high framerate GS video. Moreover, a simple yet effective self-distillation strategy is introduced in self-supervised loss for mitigating boundary artifacts in generated GS images. On synthetic dataset, SelfDRSC achieves better or comparable quantitative metrics in comparison to state-of-the-art methods trained in the full supervision manner. On real-world RS cases, our SelfDRSC can produce high framerate GS videos with finer correction textures and better temporary consistency. The source code and trained models are made publicly available at https://github.com/shangwei5/SelfDRSC. ",
    "url": "https://arxiv.org/abs/2305.19862",
    "authors": [
      "Wei Shang",
      "Dongwei Ren",
      "Chaoyu Feng",
      "Xiaotao Wang",
      "Lei Lei",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19868",
    "title": "Fast-SNN: Fast Spiking Neural Network by Converting Quantized ANN",
    "abstract": "Spiking neural networks (SNNs) have shown advantages in computation and energy efficiency over traditional artificial neural networks (ANNs) thanks to their event-driven representations. SNNs also replace weight multiplications in ANNs with additions, which are more energy-efficient and less computationally intensive. However, it remains a challenge to train deep SNNs due to the discrete spike function. A popular approach to circumvent this challenge is ANN-to-SNN conversion. However, due to the quantization error and accumulating error, it often requires lots of time steps (high inference latency) to achieve high performance, which negates SNN's advantages. To this end, this paper proposes Fast-SNN that achieves high performance with low latency. We demonstrate the equivalent mapping between temporal quantization in SNNs and spatial quantization in ANNs, based on which the minimization of the quantization error is transferred to quantized ANN training. With the minimization of the quantization error, we show that the sequential error is the primary cause of the accumulating error, which is addressed by introducing a signed IF neuron model and a layer-wise fine-tuning mechanism. Our method achieves state-of-the-art performance and low latency on various computer vision tasks, including image classification, object detection, and semantic segmentation. Codes are available at: https://github.com/yangfan-hu/Fast-SNN. ",
    "url": "https://arxiv.org/abs/2305.19868",
    "authors": [
      "Yangfan Hu",
      "Qian Zheng",
      "Xudong Jiang",
      "Gang Pan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.19871",
    "title": "There is more to graphs than meets the eye: Learning universal features  with self-supervision",
    "abstract": "We study the problem of learning universal features across multiple graphs through self-supervision. Graph self supervised learning has been shown to facilitate representation learning, and produce competitive models compared to supervised baselines. However, existing methods of self-supervision learn features from one graph, and thus, produce models that are specialized to a particular graph. We hypothesize that leveraging multiple graphs of the same type/class can improve the quality of learnt representations in the model by extracting features that are universal to the class of graphs. We adopt a transformer backbone that acts as a universal representation learning module for multiple graphs. We leverage neighborhood aggregation coupled with graph-specific embedding generator to transform disparate node embeddings from multiple graphs to a common space for the universal backbone. We learn both universal and graph-specific parameters in an end-to-end manner. Our experiments reveal that leveraging multiple graphs of the same type -- citation networks -- improves the quality of representations and results in better performance on downstream node classification task compared to self-supervision with one graph. The results of our study improve the state-of-the-art in graph self-supervised learning, and bridge the gap between self-supervised and supervised performance. ",
    "url": "https://arxiv.org/abs/2305.19871",
    "authors": [
      "Laya Das",
      "Sai Munikoti",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19872",
    "title": "Spectral Heterogeneous Graph Convolutions via Positive Noncommutative  Polynomials",
    "abstract": "Heterogeneous Graph Neural Networks (HGNNs) have gained significant popularity in various heterogeneous graph learning tasks. However, most HGNNs rely on spatial domain-based message passing and attention modules for information propagation and aggregation. These spatial-based HGNNs neglect the utilization of spectral graph convolutions, which are the foundation of Graph Convolutional Networks (GCN) on homogeneous graphs. Inspired by the effectiveness and scalability of spectral-based GNNs on homogeneous graphs, this paper explores the extension of spectral-based GNNs to heterogeneous graphs. We propose PSHGCN, a novel heterogeneous convolutional network based on positive noncommutative polynomials. PSHGCN provides a simple yet effective approach for learning spectral graph convolutions on heterogeneous graphs. Moreover, we demonstrate the rationale of PSHGCN in graph optimization. We conducted an extensive experimental study to show that PSHGCN can learn diverse spectral heterogeneous graph convolutions and achieve superior performance in node classification tasks. Our code is available at https://github.com/ivam-he/PSHGCN. ",
    "url": "https://arxiv.org/abs/2305.19872",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Shikun Feng",
      "Zhengjie Huang",
      "Weibin Li",
      "Yu Sun",
      "Dianhai Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19906",
    "title": "Neural LerPlane Representations for Fast 4D Reconstruction of Deformable  Tissues",
    "abstract": "Reconstructing deformable tissues from endoscopic stereo videos in robotic surgery is crucial for various clinical applications. However, existing methods relying only on implicit representations are computationally expensive and require dozens of hours, which limits further practical applications. To address this challenge, we introduce LerPlane, a novel method for fast and accurate reconstruction of surgical scenes under a single-viewpoint setting. LerPlane treats surgical procedures as 4D volumes and factorizes them into explicit 2D planes of static and dynamic fields, leading to a compact memory footprint and significantly accelerated optimization. The efficient factorization is accomplished by fusing features obtained through linear interpolation of each plane and enables using lightweight neural networks to model surgical scenes. Besides, LerPlane shares static fields, significantly reducing the workload of dynamic tissue modeling. We also propose a novel sample scheme to boost optimization and improve performance in regions with tool occlusion and large motions. Experiments on DaVinci robotic surgery videos demonstrate that LerPlane accelerates optimization by over 100$\\times$ while maintaining high quality across various non-rigid deformations, showing significant promise for future intraoperative surgery applications. ",
    "url": "https://arxiv.org/abs/2305.19906",
    "authors": [
      "Chen Yang",
      "Kailing Wang",
      "Yuehao Wang",
      "Xiaokang Yang",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19913",
    "title": "Are Neural Operators Really Neural Operators? Frame Theory Meets  Operator Learning",
    "abstract": "Recently, there has been significant interest in operator learning, i.e. learning mappings between infinite-dimensional function spaces. This has been particularly relevant in the context of learning partial differential equations from data. However, it has been observed that proposed models may not behave as operators when implemented on a computer, questioning the very essence of what operator learning should be. We contend that in addition to defining the operator at the continuous level, some form of continuous-discrete equivalence is necessary for an architecture to genuinely learn the underlying operator, rather than just discretizations of it. To this end, we propose to employ frames, a concept in applied harmonic analysis and signal processing that gives rise to exact and stable discrete representations of continuous signals. Extending these concepts to operators, we introduce a unifying mathematical framework of Representation equivalent Neural Operator (ReNO) to ensure operations at the continuous and discrete level are equivalent. Lack of this equivalence is quantified in terms of aliasing errors. We analyze various existing operator learning architectures to determine whether they fall within this framework, and highlight implications when they fail to do so. ",
    "url": "https://arxiv.org/abs/2305.19913",
    "authors": [
      "Francesca Bartolucci",
      "Emmanuel de B\u00e9zenac",
      "Bogdan Raoni\u0107",
      "Roberto Molinaro",
      "Siddhartha Mishra",
      "Rima Alaifari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.19915",
    "title": "Data Augmentation Approaches for Source Code Models: A Survey",
    "abstract": "The increasingly popular adoption of source code in many critical tasks motivates the development of data augmentation (DA) techniques to enhance training data and improve various capabilities (e.g., robustness and generalizability) of these models. Although a series of DA methods have been proposed and tailored for source code models, there lacks a comprehensive survey and examination to understand their effectiveness and implications. This paper fills this gap by conducting a comprehensive and integrative survey of data augmentation for source code, wherein we systematically compile and encapsulate existing literature to provide a comprehensive overview of the field. We start by constructing a taxonomy of DA for source code models model approaches, followed by a discussion on prominent, methodologically illustrative approaches. Next, we highlight the general strategies and techniques to optimize the DA quality. Subsequently, we underscore techniques that find utility in widely-accepted source code scenarios and downstream tasks. Finally, we outline the prevailing challenges and potential opportunities for future research. In essence, this paper endeavors to demystify the corpus of existing literature on DA for source code models, and foster further exploration in this sphere. Complementing this, we present a continually updated GitHub repository that hosts a list of update-to-date papers on DA for source code models, accessible at \\url{https://github.com/terryyz/DataAug4Code}. ",
    "url": "https://arxiv.org/abs/2305.19915",
    "authors": [
      "Terry Yue Zhuo",
      "Zhou Yang",
      "Zhensu Sun",
      "Yufei Wang",
      "Li Li",
      "Xiaoning Du",
      "Zhenchang Xing",
      "David Lo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.19917",
    "title": "ReDSEa: Automated Acceleration of Triangular Solver on Supercloud  Heterogeneous Systems",
    "abstract": "When utilized effectively, Supercloud heterogeneous systems have the potential to significantly enhance performance. Our ReDSEa tool-chain automates the mapping, load balancing, scheduling, parallelism, and overlapping processes for the Triangular System Solver (TS) on a heterogeneous system consisting of a Huawei Kunpeng ARM multi-core CPU and an Ascend 910 AI HW accelerator. We propose an LLVM compiler tool-chain that a) leverages compiler analysis and b) utilizes novel performance models exploring recursive, iterative, and blocked computation models. Our tool-chain facilitates a speedup of up to 16x compared to an optimized 48-core CPU-only implementation. ",
    "url": "https://arxiv.org/abs/2305.19917",
    "authors": [
      "Georgios Zacharopoulos",
      "Ilias Bournias",
      "Verner Vlacic",
      "Lukas Cavigelli"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.19937",
    "title": "Breast Cancer Detection and Diagnosis: A comparative study of  state-of-the-arts deep learning architectures",
    "abstract": "Breast cancer is a prevalent form of cancer among women, with over 1.5 million women being diagnosed each year. Unfortunately, the survival rates for breast cancer patients in certain third-world countries, like South Africa, are alarmingly low, with only 40% of diagnosed patients surviving beyond five years. The inadequate availability of resources, including qualified pathologists, delayed diagnoses, and ineffective therapy planning, contribute to this low survival rate. To address this pressing issue, medical specialists and researchers have turned to domain-specific AI approaches, specifically deep learning models, to develop end-to-end solutions that can be integrated into computer-aided diagnosis (CAD) systems. By improving the workflow of pathologists, these AI models have the potential to enhance the detection and diagnosis of breast cancer. This research focuses on evaluating the performance of various cutting-edge convolutional neural network (CNN) architectures in comparison to a relatively new model called the Vision Trans-former (ViT). The objective is to determine the superiority of these models in terms of their accuracy and effectiveness. The experimental results reveal that the ViT models outperform the other selected state-of-the-art CNN architectures, achieving an impressive accuracy rate of 95.15%. This study signifies a significant advancement in the field, as it explores the utilization of data augmentation and other relevant preprocessing techniques in conjunction with deep learning models for the detection and diagnosis of breast cancer using datasets of Breast Cancer Histopathological Image Classification. ",
    "url": "https://arxiv.org/abs/2305.19937",
    "authors": [
      "Brennon Maistry",
      "Absalom E. Ezugwu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19946",
    "title": "A Survey of Potential MPI Complex Collectives: Large-Scale Mining and  Analysis of HPC Applications",
    "abstract": "Offload of MPI collectives to network devices, e.g., NICs and switches, is being implemented as an effective mechanism to improve application performance by reducing inter- and intra-node communication and bypassing MPI software layers. Given the rich deployment of accelerators and programmable NICs/switches in data centers, we posit that there is an opportunity to further improve performance by extending this idea (of in-network collective processing) to a new class of more complex collectives. The most basic type of complex collective is the fusion of existing collectives. In previous work we have demonstrated the efficacy of this additional hardware and software support and shown that it can substantially improve the performance of certain applications. In this work we extend this approach. We seek to characterize a large number of MPI applications to determine overall applicability, both breadth and type, and so provide insight for hardware designers and MPI developers about future offload possibilities. Besides increasing the scope of prior surveys to include finding (potential) new MPI constructs, we also tap into new methods to extend the survey process. Prior surveys on MPI usage considered lists of applications constructed based on application developers' knowledge. The approach taken in this paper, however, is based on an automated mining of a large collection of code sources. More specifically, the mining is accomplished by GitHub REST APIs. We use a database management system to store the results and to answer queries. Another advantage is that this approach provides support for a more complex analysis of MPI usage, which is accomplished by user queries. ",
    "url": "https://arxiv.org/abs/2305.19946",
    "authors": [
      "Pouya Haghi",
      "Ryan Marshall",
      "Po Hao Chen",
      "Anthony Skjellum",
      "Martin Herbordt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.19971",
    "title": "Federated Learning in the Presence of Adversarial Client Unavailability",
    "abstract": "Federated learning is a decentralized machine learning framework wherein not all clients are able to participate in each round. An emerging line of research is devoted to tackling arbitrary client unavailability. Existing theoretical analysis imposes restrictive structural assumptions on the unavailability patterns, and their proposed algorithms were tailored to those assumptions. In this paper, we relax those assumptions and consider adversarial client unavailability. To quantify the degrees of client unavailability, we use the notion of {\\em $\\epsilon$-adversary dropout fraction}. For both non-convex and strongly-convex global objectives, we show that simple variants of FedAvg or FedProx, albeit completely agnostic to $\\epsilon$, converge to an estimation error on the order of $\\epsilon (G^2 + \\sigma^2)$, where $G$ is a heterogeneity parameter and $\\sigma^2$ is the noise level. We prove that this estimation error is minimax-optimal. We also show that the variants of FedAvg or FedProx have convergence speeds $O(1/\\sqrt{T})$ for non-convex objectives and $O(1/T)$ for strongly-convex objectives, both of which are the best possible for any first-order method that only has access to noisy gradients. Our proofs build upon a tight analysis of the selection bias that persists in the entire learning process. We validate our theoretical prediction through numerical experiments on synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2305.19971",
    "authors": [
      "Lili Su",
      "Jiaming Xu",
      "Pengkun Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.19979",
    "title": "Knowledge Graph Embeddings in the Biomedical Domain: Are They Useful? A  Look at Link Prediction, Rule Learning, and Downstream Polypharmacy Tasks",
    "abstract": "Knowledge graphs are powerful tools for representing and organising complex biomedical data. Several knowledge graph embedding algorithms have been proposed to learn from and complete knowledge graphs. However, a recent study demonstrates the limited efficacy of these embedding algorithms when applied to biomedical knowledge graphs, raising the question of whether knowledge graph embeddings have limitations in biomedical settings. This study aims to apply state-of-the-art knowledge graph embedding models in the context of a recent biomedical knowledge graph, BioKG, and evaluate their performance and potential downstream uses. We achieve a three-fold improvement in terms of performance based on the HITS@10 score over previous work on the same biomedical knowledge graph. Additionally, we provide interpretable predictions through a rule-based method. We demonstrate that knowledge graph embedding models are applicable in practice by evaluating the best-performing model on four tasks that represent real-life polypharmacy situations. Results suggest that knowledge learnt from large biomedical knowledge graphs can be transferred to such downstream use cases. Our code is available at https://github.com/aryopg/biokge. ",
    "url": "https://arxiv.org/abs/2305.19979",
    "authors": [
      "Aryo Pradipta Gema",
      "Dominik Grabarczyk",
      "Wolf De Wulf",
      "Piyush Borole",
      "Javier Antonio Alfaro",
      "Pasquale Minervini",
      "Antonio Vergari",
      "Ajitha Rajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19987",
    "title": "InGram: Inductive Knowledge Graph Embedding via Relation Graphs",
    "abstract": "Inductive knowledge graph completion has been considered as the task of predicting missing triplets between new entities that are not observed during training. While most inductive knowledge graph completion methods assume that all entities can be new, they do not allow new relations to appear at inference time. This restriction prohibits the existing methods from appropriately handling real-world knowledge graphs where new entities accompany new relations. In this paper, we propose an INductive knowledge GRAph eMbedding method, InGram, that can generate embeddings of new relations as well as new entities at inference time. Given a knowledge graph, we define a relation graph as a weighted graph consisting of relations and the affinity weights between them. Based on the relation graph and the original knowledge graph, InGram learns how to aggregate neighboring embeddings to generate relation and entity embeddings using an attention mechanism. Experimental results show that InGram outperforms 14 different state-of-the-art methods on varied inductive learning scenarios. ",
    "url": "https://arxiv.org/abs/2305.19987",
    "authors": [
      "Jaejun Lee",
      "Chanyoung Chung",
      "Joyce Jiyoung Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.20028",
    "title": "A Study of Bayesian Neural Network Surrogates for Bayesian Optimization",
    "abstract": "Bayesian optimization is a highly efficient approach to optimizing objective functions which are expensive to query. These objectives are typically represented by Gaussian process (GP) surrogate models which are easy to optimize and support exact inference. While standard GP surrogates have been well-established in Bayesian optimization, Bayesian neural networks (BNNs) have recently become practical function approximators, with many benefits over standard GPs such as the ability to naturally handle non-stationarity and learn representations for high-dimensional data. In this paper, we study BNNs as alternatives to standard GP surrogates for optimization. We consider a variety of approximate inference procedures for finite-width BNNs, including high-quality Hamiltonian Monte Carlo, low-cost stochastic MCMC, and heuristics such as deep ensembles. We also consider infinite-width BNNs and partially stochastic models such as deep kernel learning. We evaluate this collection of surrogate models on diverse problems with varying dimensionality, number of objectives, non-stationarity, and discrete and continuous inputs. We find: (i) the ranking of methods is highly problem dependent, suggesting the need for tailored inductive biases; (ii) HMC is the most successful approximate inference procedure for fully stochastic BNNs; (iii) full stochasticity may be unnecessary as deep kernel learning is relatively competitive; (iv) infinite-width BNNs are particularly promising, especially in high dimensions. ",
    "url": "https://arxiv.org/abs/2305.20028",
    "authors": [
      "Yucen Lily Li",
      "Tim G. J. Rudner",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.20030",
    "title": "Tree-Ring Watermarks: Fingerprints for Diffusion Images that are  Invisible and Robust",
    "abstract": "Watermarking the outputs of generative models is a crucial technique for tracing copyright and preventing potential harm from AI-generated content. In this paper, we introduce a novel technique called Tree-Ring Watermarking that robustly fingerprints diffusion model outputs. Unlike existing methods that perform post-hoc modifications to images after sampling, Tree-Ring Watermarking subtly influences the entire sampling process, resulting in a model fingerprint that is invisible to humans. The watermark embeds a pattern into the initial noise vector used for sampling. These patterns are structured in Fourier space so that they are invariant to convolutions, crops, dilations, flips, and rotations. After image generation, the watermark signal is detected by inverting the diffusion process to retrieve the noise vector, which is then checked for the embedded signal. We demonstrate that this technique can be easily applied to arbitrary diffusion models, including text-conditioned Stable Diffusion, as a plug-in with negligible loss in FID. Our watermark is semantically hidden in the image space and is far more robust than watermarking alternatives that are currently deployed. Code is available at github.com/YuxinWenRick/tree-ring-watermark. ",
    "url": "https://arxiv.org/abs/2305.20030",
    "authors": [
      "Yuxin Wen",
      "John Kirchenbauer",
      "Jonas Geiping",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.20035",
    "title": "Modelling the Performance of High Capacity Access Networks for the  Benefit of End-Users and Public Policies",
    "abstract": "This paper deals with the challenge of modeling the performance of planned ultrabroadband access networks while maintaining technological neutrality and accuracy in measurable quality. We highlight the importance of such modeling also for addressing public funding policies compared to models mainly based on the maximum nominal speed of the access networks, taking also into account the widespread use of measurement tools like \"speed test\" that have influenced the perceived quality by end-users. We present a performance modelling approach based on the extension of well-known traffic models that accurately characterizes the performance of broadband access networks. We also show how the presented model has been validated with data from two network operators and has been applied to address the recent Italian public interventions for the development of ultrabroadband access networks in market failure areas. ",
    "url": "https://arxiv.org/abs/2305.20035",
    "authors": [
      "Antonio Capone",
      "Maurizio Decina",
      "Aldo Milan",
      "Marco Petracca"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.20041",
    "title": "Simulation and Retargeting of Complex Multi-Character Interactions",
    "abstract": "We present a method for reproducing complex multi-character interactions for physically simulated humanoid characters using deep reinforcement learning. Our method learns control policies for characters that imitate not only individual motions, but also the interactions between characters, while maintaining balance and matching the complexity of reference data. Our approach uses a novel reward formulation based on an interaction graph that measures distances between pairs of interaction landmarks. This reward encourages control policies to efficiently imitate the character's motion while preserving the spatial relationships of the interactions in the reference motion. We evaluate our method on a variety of activities, from simple interactions such as a high-five greeting to more complex interactions such as gymnastic exercises, Salsa dancing, and box carrying and throwing. This approach can be used to ``clean-up'' existing motion capture data to produce physically plausible interactions or to retarget motion to new characters with different sizes, kinematics or morphologies while maintaining the interactions in the original data. ",
    "url": "https://arxiv.org/abs/2305.20041",
    "authors": [
      "Yunbo Zhang",
      "Deepak Gopinath",
      "Yuting Ye",
      "Jessica Hodgins",
      "Greg Turk",
      "Jungdam Won"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.20043",
    "title": "Deception by Omission: Using Adversarial Missingness to Poison Causal  Structure Learning",
    "abstract": "Inference of causal structures from observational data is a key component of causal machine learning; in practice, this data may be incompletely observed. Prior work has demonstrated that adversarial perturbations of completely observed training data may be used to force the learning of inaccurate causal structural models (SCMs). However, when the data can be audited for correctness (e.g., it is crytographically signed by its source), this adversarial mechanism is invalidated. This work introduces a novel attack methodology wherein the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner. Theoretically sound attack mechanisms are derived for the case of arbitrary SCMs, and a sample-efficient learning-based heuristic is given for Gaussian SCMs. Experimental validation of these approaches on real and synthetic data sets demonstrates the effectiveness of adversarial missingness attacks at deceiving popular causal structure learning algorithms. ",
    "url": "https://arxiv.org/abs/2305.20043",
    "authors": [
      "Deniz Koyuncu",
      "Alex Gittens",
      "B\u00fclent Yener",
      "Moti Yung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.20044",
    "title": "Probabilistic Uncertainty Quantification of Prediction Models with  Application to Visual Localization",
    "abstract": "The uncertainty quantification of prediction models (e.g., neural networks) is crucial for their adoption in many robotics applications. This is arguably as important as making accurate predictions, especially for safety-critical applications such as self-driving cars. This paper proposes our approach to uncertainty quantification in the context of visual localization for autonomous driving, where we predict locations from images. Our proposed framework estimates probabilistic uncertainty by creating a sensor error model that maps an internal output of the prediction model to the uncertainty. The sensor error model is created using multiple image databases of visual localization, each with ground-truth location. We demonstrate the accuracy of our uncertainty prediction framework using the Ithaca365 dataset, which includes variations in lighting, weather (sunny, snowy, night), and alignment errors between databases. We analyze both the predicted uncertainty and its incorporation into a Kalman-based localization filter. Our results show that prediction error variations increase with poor weather and lighting condition, leading to greater uncertainty and outliers, which can be predicted by our proposed uncertainty model. Additionally, our probabilistic error model enables the filter to remove ad hoc sensor gating, as the uncertainty automatically adjusts the model to the input data ",
    "url": "https://arxiv.org/abs/2305.20044",
    "authors": [
      "Junan Chen",
      "Josephine Monica",
      "Wei-Lun Chao",
      "Mark Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.20045",
    "title": "ActiveAED: A Human in the Loop Improves Annotation Error Detection",
    "abstract": "Manually annotated datasets are crucial for training and evaluating Natural Language Processing models. However, recent work has discovered that even widely-used benchmark datasets contain a substantial number of erroneous annotations. This problem has been addressed with Annotation Error Detection (AED) models, which can flag such errors for human re-annotation. However, even though many of these AED methods assume a final curation step in which a human annotator decides whether the annotation is erroneous, they have been developed as static models without any human-in-the-loop component. In this work, we propose ActiveAED, an AED method that can detect errors more accurately by repeatedly querying a human for error corrections in its prediction loop. We evaluate ActiveAED on eight datasets spanning five different tasks and find that it leads to improvements over the state of the art on seven of them, with gains of up to six percentage points in average precision. ",
    "url": "https://arxiv.org/abs/2305.20045",
    "authors": [
      "Leon Weber",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.20054",
    "title": "UNSSOR: Unsupervised Neural Speech Separation by Leveraging  Over-determined Training Mixtures",
    "abstract": "In reverberant conditions with multiple concurrent speakers, each microphone acquires a mixture signal of multiple speakers at a different location. In over-determined conditions where the microphones out-number speakers, we can narrow down the solutions to speaker images and realize unsupervised speech separation by leveraging each mixture signal as a constraint (i.e., the estimated speaker images at a microphone should add up to the mixture). Equipped with this insight, we propose UNSSOR, an algorithm for $\\textbf{u}$nsupervised $\\textbf{n}$eural $\\textbf{s}$peech $\\textbf{s}$eparation by leveraging $\\textbf{o}$ver-determined training mixtu$\\textbf{r}$es. At each training step, we feed an input mixture to a deep neural network (DNN) to produce an intermediate estimate for each speaker, linearly filter the estimates, and optimize a loss so that, at each microphone, the filtered estimates of all the speakers can add up to the mixture to satisfy the above constraint. We show that this loss can promote unsupervised separation of speakers. The linear filters are computed in each sub-band based on the mixture and DNN estimates through the forward convolutive prediction (FCP) algorithm. To address the frequency permutation problem incurred by using sub-band FCP, a loss term based on minimizing intra-source magnitude scattering is proposed. Although UNSSOR requires over-determined training mixtures, we can train DNNs to achieve under-determined separation (e.g., unsupervised monaural speech separation). Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR. ",
    "url": "https://arxiv.org/abs/2305.20054",
    "authors": [
      "Zhong-Qiu Wang",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.20055",
    "title": "Cross-Domain Car Detection Model with Integrated Convolutional Block  Attention Mechanism",
    "abstract": "Car detection, particularly through camera vision, has become a major focus in the field of computer vision and has gained widespread adoption. While current car detection systems are capable of good detection, reliable detection can still be challenging due to factors such as proximity between the car, light intensity, and environmental visibility. To address these issues, we propose a cross-domain car detection model that we apply to car recognition for autonomous driving and other areas. Our model includes several novelties: 1)Building a complete cross-domain target detection framework. 2)Developing an unpaired target domain picture generation module with an integrated convolutional attention mechanism. 3)Adopting Generalized Intersection over Union (GIOU) as the loss function of the target detection framework. 4)Designing an object detection model integrated with two-headed Convolutional Block Attention Module(CBAM). 5)Utilizing an effective data enhancement method. To evaluate the model's effectiveness, we performed a reduced will resolution process on the data in the SSLAD dataset and used it as the benchmark dataset for our task. Experimental results show that the performance of the cross-domain car target detection model improves by 40% over the model without our framework, and our improvements have a significant impact on cross-domain car recognition. ",
    "url": "https://arxiv.org/abs/2305.20055",
    "authors": [
      "Haoxuan Xu",
      "Songning Lai",
      "Yang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.20056",
    "title": "Rare Life Event Detection via Mobile Sensing Using Multi-Task Learning",
    "abstract": "Rare life events significantly impact mental health, and their detection in behavioral studies is a crucial step towards health-based interventions. We envision that mobile sensing data can be used to detect these anomalies. However, the human-centered nature of the problem, combined with the infrequency and uniqueness of these events makes it challenging for unsupervised machine learning methods. In this paper, we first investigate granger-causality between life events and human behavior using sensing data. Next, we propose a multi-task framework with an unsupervised autoencoder to capture irregular behavior, and an auxiliary sequence predictor that identifies transitions in workplace performance to contextualize events. We perform experiments using data from a mobile sensing study comprising N=126 information workers from multiple industries, spanning 10106 days with 198 rare events (<2%). Through personalized inference, we detect the exact day of a rare event with an F1 of 0.34, demonstrating that our method outperforms several baselines. Finally, we discuss the implications of our work from the context of real-world deployment. ",
    "url": "https://arxiv.org/abs/2305.20056",
    "authors": [
      "Arvind Pillai",
      "Subigya Nepal",
      "Andrew Campbell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2305.20061",
    "title": "Towards Neural Path Tracing in SRAM",
    "abstract": "We present an experimental neural path tracer designed to exploit the large on-chip memory of Graphcore intelligence-processing-units (IPUs). This open source renderer demonstrates how to map path tracing to the novel software and hardware architecture and is a useful tool for analysing in-cache neural-rendering scenarios. Such scenarios will be increasingly important if rasterisation is replaced by combinations of ray/path tracing, neural-radiance caching, and AI denoising/up-scaling, for which small neural networks are already routinely employed. A detailed description of the implementation also serves as a self-contained resource for more general software design on IPU. ",
    "url": "https://arxiv.org/abs/2305.20061",
    "authors": [
      "Mark Pupilli"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.20068",
    "title": "TOFG: A Unified and Fine-Grained Environment Representation in  Autonomous Driving",
    "abstract": "In autonomous driving, an accurate understanding of environment, e.g., the vehicle-to-vehicle and vehicle-to-lane interactions, plays a critical role in many driving tasks such as trajectory prediction and motion planning. Environment information comes from high-definition (HD) map and historical trajectories of vehicles. Due to the heterogeneity of the map data and trajectory data, many data-driven models for trajectory prediction and motion planning extract vehicle-to-vehicle and vehicle-to-lane interactions in a separate and sequential manner. However, such a manner may capture biased interpretation of interactions, causing lower prediction and planning accuracy. Moreover, separate extraction leads to a complicated model structure and hence the overall efficiency and scalability are sacrificed. To address the above issues, we propose an environment representation, Temporal Occupancy Flow Graph (TOFG). Specifically, the occupancy flow-based representation unifies the map information and vehicle trajectories into a homogeneous data format and enables a consistent prediction. The temporal dependencies among vehicles can help capture the change of occupancy flow timely to further promote model performance. To demonstrate that TOFG is capable of simplifying the model architecture, we incorporate TOFG with a simple graph attention (GAT) based neural network and propose TOFG-GAT, which can be used for both trajectory prediction and motion planning. Experiment results show that TOFG-GAT achieves better or competitive performance than all the SOTA baselines with less training time. ",
    "url": "https://arxiv.org/abs/2305.20068",
    "authors": [
      "Zihao Wen",
      "Yifan Zhang",
      "Xinhong Chen",
      "Jianping Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19396",
    "title": "Resource-Efficient Fine-Tuning Strategies for Automatic MOS Prediction  in Text-to-Speech for Low-Resource Languages",
    "abstract": "We train a MOS prediction model based on wav2vec 2.0 using the open-access data sets BVCC and SOMOS. Our test with neural TTS data in the low-resource language (LRL) West Frisian shows that pre-training on BVCC before fine-tuning on SOMOS leads to the best accuracy for both fine-tuned and zero-shot prediction. Further fine-tuning experiments show that using more than 30 percent of the total data does not lead to significant improvements. In addition, fine-tuning with data from a single listener shows promising system-level accuracy, supporting the viability of one-participant pilot tests. These findings can all assist the resource-conscious development of TTS for LRLs by progressing towards better zero-shot MOS prediction and informing the design of listening tests, especially in early-stage evaluation. ",
    "url": "https://arxiv.org/abs/2305.19396",
    "authors": [
      "Phat Do",
      "Matt Coler",
      "Jelske Dijkstra",
      "Esther Klabbers"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19428",
    "title": "Evaluating geospatial context information for travel mode detection",
    "abstract": "Detecting travel modes from global navigation satellite system (GNSS) trajectories is essential for understanding individual travel behaviour and a prerequisite for achieving sustainable transport systems. While studies have acknowledged the benefits of incorporating geospatial context information into travel mode detection models, few have summarized context modelling approaches and analyzed the significance of these context features, hindering the development of an efficient model. Here, we identify context representations from related work and propose an analytical pipeline to assess the contribution of geospatial context information for travel mode detection based on a random forest model and the SHapley Additive exPlanation (SHAP) method. Through experiments on a large-scale GNSS tracking dataset, we report that features describing relationships with infrastructure networks, such as the distance to the railway or road network, significantly contribute to the model's prediction. Moreover, features related to the geospatial point entities help identify public transport travel, but most land-use and land-cover features barely contribute to the task. We finally reveal that geospatial contexts have distinct contributions in identifying different travel modes, providing insights into selecting appropriate context information and modelling approaches. The results from this study enhance our understanding of the relationship between movement and geospatial context and guide the implementation of effective and efficient transport mode detection models. ",
    "url": "https://arxiv.org/abs/2305.19428",
    "authors": [
      "Ye Hong",
      "Emanuel St\u00fcdeli",
      "Martin Raubal"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.19482",
    "title": "Adaptive False Discovery Rate Control with Privacy Guarantee",
    "abstract": "Differentially private multiple testing procedures can protect the information of individuals used in hypothesis tests while guaranteeing a small fraction of false discoveries. In this paper, we propose a differentially private adaptive FDR control method that can control the classic FDR metric exactly at a user-specified level $\\alpha$ with privacy guarantee, which is a non-trivial improvement compared to the differentially private Benjamini-Hochberg method proposed in Dwork et al. (2021). Our analysis is based on two key insights: 1) a novel p-value transformation that preserves both privacy and the mirror conservative property, and 2) a mirror peeling algorithm that allows the construction of the filtration and application of the optimal stopping technique. Numerical studies demonstrate that the proposed DP-AdaPT performs better compared to the existing differentially private FDR control methods. Compared to the non-private AdaPT, it incurs a small accuracy loss but significantly reduces the computation cost. ",
    "url": "https://arxiv.org/abs/2305.19482",
    "authors": [
      "Xintao Xia",
      "Zhanrui Cai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.19535",
    "title": "Low-rank extended Kalman filtering for online learning of neural  networks from streaming data",
    "abstract": "We propose an efficient online approximate Bayesian inference algorithm for estimating the parameters of a nonlinear function from a potentially non-stationary data stream. The method is based on the extended Kalman filter (EKF), but uses a novel low-rank plus diagonal decomposition of the posterior precision matrix, which gives a cost per step which is linear in the number of model parameters. In contrast to methods based on stochastic variational inference, our method is fully deterministic, and does not require step-size tuning. We show experimentally that this results in much faster (more sample efficient) learning, which results in more rapid adaptation to changing distributions, and faster accumulation of reward when used as part of a contextual bandit algorithm. ",
    "url": "https://arxiv.org/abs/2305.19535",
    "authors": [
      "Peter Chang",
      "Gerardo Dur\u00e0n-Mart\u00edn",
      "Alexander Y Shestopaloff",
      "Matt Jones",
      "Kevin Murphy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19545",
    "title": "Catalysis distillation neural network for the few shot open catalyst  challenge",
    "abstract": "The integration of artificial intelligence and science has resulted in substantial progress in computational chemistry methods for the design and discovery of novel catalysts. Nonetheless, the challenges of electrocatalytic reactions and developing a large-scale language model in catalysis persist, and the recent success of ChatGPT's (Chat Generative Pre-trained Transformer) few-shot methods surpassing BERT (Bidirectional Encoder Representation from Transformers) underscores the importance of addressing limited data, expensive computations, time constraints and structure-activity relationship in research. Hence, the development of few-shot techniques for catalysis is critical and essential, regardless of present and future requirements. This paper introduces the Few-Shot Open Catalyst Challenge 2023, a competition aimed at advancing the application of machine learning technology for predicting catalytic reactions on catalytic surfaces, with a specific focus on dual-atom catalysts in hydrogen peroxide electrocatalysis. To address the challenge of limited data in catalysis, we propose a machine learning approach based on MLP-Like and a framework called Catalysis Distillation Graph Neural Network (CDGNN). Our results demonstrate that CDGNN effectively learns embeddings from catalytic structures, enabling the capture of structure-adsorption relationships. This accomplishment has resulted in the utmost advanced and efficient determination of the reaction pathway for hydrogen peroxide, surpassing the current graph neural network approach by 16.1%.. Consequently, CDGNN presents a promising approach for few-shot learning in catalysis. ",
    "url": "https://arxiv.org/abs/2305.19545",
    "authors": [
      "Bowen Deng"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19621",
    "title": "XTransCT: Ultra-Fast Volumetric CT Reconstruction using Two Orthogonal  X-Ray Projections via a Transformer Network",
    "abstract": "Computed tomography (CT) scans offer a detailed, three-dimensional representation of patients' internal organs. However, conventional CT reconstruction techniques necessitate acquiring hundreds or thousands of x-ray projections through a complete rotational scan of the body, making navigation or positioning during surgery infeasible. In image-guided radiation therapy, a method that reconstructs ultra-sparse X-ray projections into CT images, we can exploit the substantially reduced radiation dose and minimize equipment burden for localization and navigation. In this study, we introduce a novel Transformer architecture, termed XTransCT, devised to facilitate real-time reconstruction of CT images from two-dimensional X-ray images. We assess our approach regarding image quality and structural reliability using a dataset of fifty patients, supplied by a hospital, as well as the larger public dataset LIDC-IDRI, which encompasses thousands of patients. Additionally, we validated our algorithm's generalizability on the LNDb dataset. Our findings indicate that our algorithm surpasses other methods in image quality, structural precision, and generalizability. Moreover, in comparison to previous 3D convolution-based approaches, we note a substantial speed increase of approximately 300 $\\%$, achieving 44 ms per 3D image reconstruction. To guarantee the replicability of our results, we have made our code publicly available. ",
    "url": "https://arxiv.org/abs/2305.19621",
    "authors": [
      "Chulong Zhang",
      "Jingjing Dai",
      "Tangsheng Wang",
      "Xuan Liu",
      "Yinping Chan",
      "Lin Liu",
      "Wenfeng He",
      "Yaoqin Xie",
      "Xiaokun Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2305.19640",
    "title": "Optimal Estimates for Pairwise Learning with Deep ReLU Networks",
    "abstract": "Pairwise learning refers to learning tasks where a loss takes a pair of samples into consideration. In this paper, we study pairwise learning with deep ReLU networks and estimate the excess generalization error. For a general loss satisfying some mild conditions, a sharp bound for the estimation error of order $O((V\\log(n) /n)^{1/(2-\\beta)})$ is established. In particular, with the pairwise least squares loss, we derive a nearly optimal bound of the excess generalization error which achieves the minimax lower bound up to a logrithmic term when the true predictor satisfies some smoothness regularities. ",
    "url": "https://arxiv.org/abs/2305.19640",
    "authors": [
      "Junyu Zhou",
      "Shuo Huang",
      "Han Feng",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19695",
    "title": "Causal discovery for time series with constraint-based model and PMIME  measure",
    "abstract": "Causality defines the relationship between cause and effect. In multivariate time series field, this notion allows to characterize the links between several time series considering temporal lags. These phenomena are particularly important in medicine to analyze the effect of a drug for example, in manufacturing to detect the causes of an anomaly in a complex system or in social sciences... Most of the time, studying these complex systems is made through correlation only. But correlation can lead to spurious relationships. To circumvent this problem, we present in this paper a novel approach for discovering causality in time series data that combines a causal discovery algorithm with an information theoretic-based measure. Hence the proposed method allows inferring both linear and non-linear relationships and building the underlying causal graph. We evaluate the performance of our approach on several simulated data sets, showing promising results. ",
    "url": "https://arxiv.org/abs/2305.19695",
    "authors": [
      "Antonin Arsac",
      "Aurore Lomet",
      "Jean-Philippe Poli"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19698",
    "title": "Investigation of the Robustness of Neural Density Fields",
    "abstract": "Recent advances in modeling density distributions, so-called neural density fields, can accurately describe the density distribution of celestial bodies without, e.g., requiring a shape model - properties of great advantage when designing trajectories close to these bodies. Previous work introduced this approach, but several open questions remained. This work investigates neural density fields and their relative errors in the context of robustness to external factors like noise or constraints during training, like the maximal available gravity signal strength due to a certain distance exemplified for 433 Eros and 67P/Churyumov-Gerasimenko. It is found that both models trained on a polyhedral and mascon ground truth perform similarly, indicating that the ground truth is not the accuracy bottleneck. The impact of solar radiation pressure on a typical probe affects training neglectable, with the relative error being of the same magnitude as without noise. However, limiting the precision of measurement data by applying Gaussian noise hurts the obtainable precision. Further, pretraining is shown as practical in order to speed up network training. Hence, this work demonstrates that training neural networks for the gravity inversion problem is appropriate as long as the gravity signal is distinguishable from noise. Code and results are available at https://github.com/gomezzz/geodesyNets ",
    "url": "https://arxiv.org/abs/2305.19698",
    "authors": [
      "Jonas Schuhmacher",
      "Fabio Gratl",
      "Dario Izzo",
      "Pablo G\u00f3mez"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19738",
    "title": "Bures-Wasserstein Means of Graphs",
    "abstract": "Finding the mean of sampled data is a fundamental task in machine learning and statistics. However, in cases where the data samples are graph objects, defining a mean is an inherently difficult task. We propose a novel framework for defining a graph mean via embeddings in the space of smooth graph signal distributions, where graph similarity can be measured using the Wasserstein metric. By finding a mean in this embedding space, we can recover a mean graph that preserves structural information. We establish the existence and uniqueness of the novel graph mean, and provide an iterative algorithm for computing it. To highlight the potential of our framework as a valuable tool for practical applications in machine learning, it is evaluated on various tasks, including k-means clustering of structured graphs, classification of functional brain networks, and semi-supervised node classification in multi-layer graphs. Our experimental results demonstrate that our approach achieves consistent performance, outperforms existing baseline approaches, and improves state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.19738",
    "authors": [
      "Isabel Haasler",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.19801",
    "title": "Predicting protein stability changes under multiple amino acid  substitutions using equivariant graph neural networks",
    "abstract": "The accurate prediction of changes in protein stability under multiple amino acid substitutions is essential for realising true in-silico protein re-design. To this purpose, we propose improvements to state-of-the-art Deep learning (DL) protein stability prediction models, enabling first-of-a-kind predictions for variable numbers of amino acid substitutions, on structural representations, by decoupling the atomic and residue scales of protein representations. This was achieved using E(3)-equivariant graph neural networks (EGNNs) for both atomic environment (AE) embedding and residue-level scoring tasks. Our AE embedder was used to featurise a residue-level graph, then trained to score mutant stability ($\\Delta\\Delta G$). To achieve effective training of this predictive EGNN we have leveraged the unprecedented scale of a new high-throughput protein stability experimental data-set, Mega-scale. Finally, we demonstrate the immediately promising results of this procedure, discuss the current shortcomings, and highlight potential future strategies. ",
    "url": "https://arxiv.org/abs/2305.19801",
    "authors": [
      "Sebastien Boyer",
      "Sam Money-Kyrle",
      "Oliver Bent"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19867",
    "title": "Unsupervised Anomaly Detection in Medical Images Using Masked Diffusion  Model",
    "abstract": "It can be challenging to identify brain MRI anomalies using supervised deep-learning techniques due to anatomical heterogeneity and the requirement for pixel-level labeling. Unsupervised anomaly detection approaches provide an alternative solution by relying only on sample-level labels of healthy brains to generate a desired representation to identify abnormalities at the pixel level. Although, generative models are crucial for generating such anatomically consistent representations of healthy brains, accurately generating the intricate anatomy of the human brain remains a challenge. In this study, we present a method called masked-DDPM (mDPPM), which introduces masking-based regularization to reframe the generation task of diffusion models. Specifically, we introduce Masked Image Modeling (MIM) and Masked Frequency Modeling (MFM) in our self-supervised approach that enables models to learn visual representations from unlabeled data. To the best of our knowledge, this is the first attempt to apply MFM in DPPM models for medical applications. We evaluate our approach on datasets containing tumors and numerous sclerosis lesions and exhibit the superior performance of our unsupervised method as compared to the existing fully/weakly supervised baselines. Code is available at https://github.com/hasan1292/mDDPM. ",
    "url": "https://arxiv.org/abs/2305.19867",
    "authors": [
      "Hasan Iqbal",
      "Umar Khalid",
      "Jing Hua",
      "Chen Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.20006",
    "title": "Physics-Informed Ensemble Representation for Light-Field Image  Super-Resolution",
    "abstract": "Recent learning-based approaches have achieved significant progress in light field (LF) image super-resolution (SR) by exploring convolution-based or transformer-based network structures. However, LF imaging has many intrinsic physical priors that have not been fully exploited. In this paper, we analyze the coordinate transformation of the LF imaging process to reveal the geometric relationship in the LF images. Based on such geometric priors, we introduce a new LF subspace of virtual-slit images (VSI) that provide sub-pixel information complementary to sub-aperture images. To leverage the abundant correlation across the four-dimensional data with manageable complexity, we propose learning ensemble representation of all $C_4^2$ LF subspaces for more effective feature extraction. To super-resolve image structures from undersampled LF data, we propose a geometry-aware decoder, named EPIXformer, which constrains the transformer's operational searching regions with a LF physical prior. Experimental results on both spatial and angular SR tasks demonstrate that the proposed method outperforms other state-of-the-art schemes, especially in handling various disparities. ",
    "url": "https://arxiv.org/abs/2305.20006",
    "authors": [
      "Manchang Jin",
      "Gaosheng Liu",
      "Kunshu Hu",
      "Xin Luo",
      "Kun Li",
      "Jingyu Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.20011",
    "title": "Constrained Causal Bayesian Optimization",
    "abstract": "We propose constrained causal Bayesian optimization (cCBO), an approach for finding interventions in a known causal graph that optimize a target variable under some constraints. cCBO first reduces the search space by exploiting the graph structure and, if available, an observational dataset; and then solves the restricted optimization problem by modelling target and constraint quantities using Gaussian processes and by sequentially selecting interventions via a constrained expected improvement acquisition function. We propose different surrogate models that enable to integrate observational and interventional data while capturing correlation among effects with increasing levels of sophistication. We evaluate cCBO on artificial and real-world causal graphs showing successful trade off between fast convergence and percentage of feasible interventions. ",
    "url": "https://arxiv.org/abs/2305.20011",
    "authors": [
      "Virginia Aglietti",
      "Alan Malek",
      "Ira Ktena",
      "Silvia Chiappa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.20013",
    "title": "Software Architecture for Operation and Use of Quantum Communications  Networks",
    "abstract": "Quantum Communications Networks using the properties of qubits, namely state superposition, no-cloning and entanglement, can enable the exchange of information in a very secure manner across optical links or free space. New innovations enable the use of optical repeaters as well as multi-cast communication in the networks. Some types of quantum communications mechanisms can be implemented at room-temperature instead of requiring super-cooled systems. This makes it likely that business impact from quantum communications will be realized sooner than that from quantum computers. Quantum networks need to be integrated into the ecosystem of currently deployed classical networks and augment them with new capabilities. Classical computers and networks need to be able to use the new secure communication capabilities offered by quantum networks. To provide this interoperability, appropriate software abstractions on the usage of quantum networks need to be developed. In this paper, we examine what the type of software abstractions quantum networks can provide, and the type of applications that the new abstractions can support. ",
    "url": "https://arxiv.org/abs/2305.20013",
    "authors": [
      "Dinesh Verma",
      "Eden Figueroa",
      "Gabriella Carini",
      "Mark Ritter"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.20053",
    "title": "Efficient PDE-Constrained optimization under high-dimensional  uncertainty using derivative-informed neural operators",
    "abstract": "We propose a novel machine learning framework for solving optimization problems governed by large-scale partial differential equations (PDEs) with high-dimensional random parameters. Such optimization under uncertainty (OUU) problems may be computational prohibitive using classical methods, particularly when a large number of samples is needed to evaluate risk measures at every iteration of an optimization algorithm, where each sample requires the solution of an expensive-to-solve PDE. To address this challenge, we propose a new neural operator approximation of the PDE solution operator that has the combined merits of (1) accurate approximation of not only the map from the joint inputs of random parameters and optimization variables to the PDE state, but also its derivative with respect to the optimization variables, (2) efficient construction of the neural network using reduced basis architectures that are scalable to high-dimensional OUU problems, and (3) requiring only a limited number of training data to achieve high accuracy for both the PDE solution and the OUU solution. We refer to such neural operators as multi-input reduced basis derivative informed neural operators (MR-DINOs). We demonstrate the accuracy and efficiency our approach through several numerical experiments, i.e. the risk-averse control of a semilinear elliptic PDE and the steady state Navier--Stokes equations in two and three spatial dimensions, each involving random field inputs. Across the examples, MR-DINOs offer $10^{3}$--$10^{7} \\times$ reductions in execution time, and are able to produce OUU solutions of comparable accuracies to those from standard PDE based solutions while being over $10 \\times$ more cost-efficient after factoring in the cost of construction. ",
    "url": "https://arxiv.org/abs/2305.20053",
    "authors": [
      "Dingcheng Luo",
      "Thomas O'Leary-Roseberry",
      "Peng Chen",
      "Omar Ghattas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:1911.02661",
    "title": "On the density of critical graphs with no large cliques",
    "abstract": " Comments: 27 pages; to appear in Combinatorica ",
    "url": "https://arxiv.org/abs/1911.02661",
    "authors": [
      "Tom Kelly",
      "Luke Postle"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2008.08427",
    "title": "How Powerful are Shallow Neural Networks with Bandlimited Random  Weights?",
    "abstract": " Comments: Published as a conference paper at ICML 2023 ",
    "url": "https://arxiv.org/abs/2008.08427",
    "authors": [
      "Ming Li",
      "Sho Sonoda",
      "Feilong Cao",
      "Yu Guang Wang",
      "Jiye Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.15319",
    "title": "A framework to measure the robustness of programs in the unpredictable  environment",
    "abstract": " Title: A framework to measure the robustness of programs in the unpredictable  environment ",
    "url": "https://arxiv.org/abs/2111.15319",
    "authors": [
      "Valentina Castiglioni",
      "Michele Loreti",
      "Simone Tini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2112.11602",
    "title": "Causal Inference Despite Limited Global Confounding via Mixture Models",
    "abstract": " Comments: Published in CleaR 2023 ",
    "url": "https://arxiv.org/abs/2112.11602",
    "authors": [
      "Spencer L. Gordon",
      "Bijan Mazaheri",
      "Yuval Rabani",
      "Leonard J. Schulman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12675",
    "title": "Decepticons: Corrupted Transformers Breach Privacy in Federated Learning  for Language Models",
    "abstract": " Comments: First two authors contributed equally. Order chosen by coin flip. Published at ICLR 2023. Implementation available at github.com/JonasGeiping/breaching ",
    "url": "https://arxiv.org/abs/2201.12675",
    "authors": [
      "Liam Fowl",
      "Jonas Geiping",
      "Steven Reich",
      "Yuxin Wen",
      "Wojtek Czaja",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.09551",
    "title": "Implementing Boolean Functions with switching lattice networks",
    "abstract": " Title: Implementing Boolean Functions with switching lattice networks ",
    "url": "https://arxiv.org/abs/2202.09551",
    "authors": [
      "Rajesh Kumar Datta"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2202.11556",
    "title": "Bounds on the Twin-Width of Product Graphs",
    "abstract": " Comments: 24 pages, 1 table, 1 figure ",
    "url": "https://arxiv.org/abs/2202.11556",
    "authors": [
      "William Pettersson",
      "John Sylvester"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.05858",
    "title": "Deep Learning-Based Blind Multiple User Detection for Grant-free SCMA  and MUSA Systems",
    "abstract": " Comments: Accepted for publication in the IEEE Transactions on Machine Learning in Communications and Networking ",
    "url": "https://arxiv.org/abs/2203.05858",
    "authors": [
      "Thushan Sivalingam",
      "Samad Ali",
      "Nurul Huda Mahmood",
      "Nandana Rajatheva",
      "Matti Latva Aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.07065",
    "title": "Optimal Aggregation Strategies for Social Learning over Graphs",
    "abstract": " Title: Optimal Aggregation Strategies for Social Learning over Graphs ",
    "url": "https://arxiv.org/abs/2203.07065",
    "authors": [
      "Ping Hu",
      "Virginia Bordignon",
      "Stefan Vlaski",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2204.02978",
    "title": "A neural network-supported two-stage algorithm for lightweight  dereverberation on hearing devices",
    "abstract": " Comments: Accepted for publication in EURASIP Journal on Audio, Speech and Music Processing ",
    "url": "https://arxiv.org/abs/2204.02978",
    "authors": [
      "Jean-Marie Lemercier",
      "Joachim Thiemann",
      "Raphael Koning",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.01059",
    "title": "Enhanced Physics-Informed Neural Networks with Augmented Lagrangian  Relaxation Method (AL-PINNs)",
    "abstract": " Title: Enhanced Physics-Informed Neural Networks with Augmented Lagrangian  Relaxation Method (AL-PINNs) ",
    "url": "https://arxiv.org/abs/2205.01059",
    "authors": [
      "Hwijae Son",
      "Sung Woong Cho",
      "Hyung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.03612",
    "title": "BrainIB: Interpretable Brain Network-based Psychiatric Diagnosis with  Graph Information Bottleneck",
    "abstract": " Comments: 15 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2205.03612",
    "authors": [
      "Kaizhong Zheng",
      "Shujian Yu",
      "Baojuan Li",
      "Robert Jenssen",
      "Badong Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.03635",
    "title": "Ultrafast Image Categorization in Biology and Neural Models",
    "abstract": " Title: Ultrafast Image Categorization in Biology and Neural Models ",
    "url": "https://arxiv.org/abs/2205.03635",
    "authors": [
      "Jean-Nicolas J\u00e9r\u00e9mie",
      "Laurent U Perrinet"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.07229",
    "title": "RoMFAC: A robust mean-field actor-critic reinforcement learning against  adversarial perturbations on states",
    "abstract": " Title: RoMFAC: A robust mean-field actor-critic reinforcement learning against  adversarial perturbations on states ",
    "url": "https://arxiv.org/abs/2205.07229",
    "authors": [
      "Ziyuan Zhou",
      "Guanjun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08096",
    "title": "Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an  Incompetent Teacher",
    "abstract": " Comments: Accepted in AAAI 2023 ",
    "url": "https://arxiv.org/abs/2205.08096",
    "authors": [
      "Vikram S Chundawat",
      "Ayush K Tarun",
      "Murari Mandal",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13462",
    "title": "FedBR: Improving Federated Learning on Heterogeneous Data via Local  Learning Bias Reduction",
    "abstract": " Comments: Accepted by International Conference on Machine Learning (ICML2023) ",
    "url": "https://arxiv.org/abs/2205.13462",
    "authors": [
      "Yongxin Guo",
      "Xiaoying Tang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03656",
    "title": "Fair Classification via Domain Adaptation: A Dual Adversarial Learning  Approach",
    "abstract": " Title: Fair Classification via Domain Adaptation: A Dual Adversarial Learning  Approach ",
    "url": "https://arxiv.org/abs/2206.03656",
    "authors": [
      "Yueqing Liang",
      "Canyu Chen",
      "Tian Tian",
      "Kai Shu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10991",
    "title": "Understanding convolution on graphs via energies",
    "abstract": " Comments: First two authors equal contribution; 34 pages ",
    "url": "https://arxiv.org/abs/2206.10991",
    "authors": [
      "Francesco Di Giovanni",
      "James Rowbottom",
      "Benjamin P. Chamberlain",
      "Thomas Markovich",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14772",
    "title": "IBP Regularization for Verified Adversarial Robustness via  Branch-and-Bound",
    "abstract": " Comments: ICML 2022 Workshop on Formal Verification of Machine Learning ",
    "url": "https://arxiv.org/abs/2206.14772",
    "authors": [
      "Alessandro De Palma",
      "Rudy Bunel",
      "Krishnamurthy Dvijotham",
      "M. Pawan Kumar",
      "Robert Stanforth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.00449",
    "title": "Dissecting Self-Supervised Learning Methods for Surgical Computer Vision",
    "abstract": " Title: Dissecting Self-Supervised Learning Methods for Surgical Computer Vision ",
    "url": "https://arxiv.org/abs/2207.00449",
    "authors": [
      "Sanat Ramesh",
      "Vinkle Srivastav",
      "Deepak Alapatt",
      "Tong Yu",
      "Aditya Murali",
      "Luca Sestini",
      "Chinedu Innocent Nwoye",
      "Idris Hamoud",
      "Saurav Sharma",
      "Antoine Fleurentin",
      "Georgios Exarchakis",
      "Alexandros Karargyris",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.14709",
    "title": "Robust Quantitative Susceptibility Mapping via Approximate Message  Passing with Parameter Estimation",
    "abstract": " Comments: Keywords: Approximate message passing, Compressive sensing, Outlier modelling, Parameter estimation, Quantitative susceptibility mapping ",
    "url": "https://arxiv.org/abs/2207.14709",
    "authors": [
      "Shuai Huang",
      "James J. Lah",
      "Jason W. Allen",
      "Deqiang Qiu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.01003",
    "title": "What Can Be Learnt With Wide Convolutional Neural Networks?",
    "abstract": " Title: What Can Be Learnt With Wide Convolutional Neural Networks? ",
    "url": "https://arxiv.org/abs/2208.01003",
    "authors": [
      "Francesco Cagnetta",
      "Alessandro Favero",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.01962",
    "title": "Adversarial Detection: Attacking Object Detection in Real Time",
    "abstract": " Comments: Accepted by IEEE Intelligent Vehicle Symposium, 2023 ",
    "url": "https://arxiv.org/abs/2209.01962",
    "authors": [
      "Han Wu",
      "Syed Yunas",
      "Sareh Rowlands",
      "Wenjie Ruan",
      "Johan Wahlstrom"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.11255",
    "title": "3DGTN: 3D Dual-Attention GLocal Transformer Network for Point Cloud  Classification and Segmentation",
    "abstract": " Comments: 10 pages, 6 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2209.11255",
    "authors": [
      "Dening Lu",
      "Kyle Gao",
      "Qian Xie",
      "Linlin Xu",
      "Jonathan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.15315",
    "title": "FusionRetro: Molecule Representation Fusion via In-Context Learning for  Retrosynthetic Planning",
    "abstract": " Comments: Accepted by ICML 2023 ",
    "url": "https://arxiv.org/abs/2209.15315",
    "authors": [
      "Songtao Liu",
      "Zhengkai Tu",
      "Minkai Xu",
      "Zuobai Zhang",
      "Lu Lin",
      "Rex Ying",
      "Jian Tang",
      "Peilin Zhao",
      "Dinghao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.00069",
    "title": "Topological Singularity Detection at Multiple Scales",
    "abstract": " Comments: Accepted at the International Conference on Machine Learning (ICML) 2023; camera-ready version ",
    "url": "https://arxiv.org/abs/2210.00069",
    "authors": [
      "Julius von Rohrscheidt",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00124",
    "title": "Implicit Neural Spatial Representations for Time-dependent PDEs",
    "abstract": " Comments: ICML 2023. Project page: this http URL ",
    "url": "https://arxiv.org/abs/2210.00124",
    "authors": [
      "Honglin Chen",
      "Rundi Wu",
      "Eitan Grinspun",
      "Changxi Zheng",
      "Peter Yichen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.04763",
    "title": "On the Forward Invariance of Neural ODEs",
    "abstract": " Comments: 25 pages, accepted in ICML2023, website: this https URL ",
    "url": "https://arxiv.org/abs/2210.04763",
    "authors": [
      "Wei Xiao",
      "Tsun-Hsuan Wang",
      "Ramin Hasani",
      "Mathias Lechner",
      "Yutong Ban",
      "Chuang Gan",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.02940",
    "title": "Effective Audio Classification Network Based on Paired Inverse Pyramid  Structure and Dense MLP Block",
    "abstract": " Title: Effective Audio Classification Network Based on Paired Inverse Pyramid  Structure and Dense MLP Block ",
    "url": "https://arxiv.org/abs/2211.02940",
    "authors": [
      "Yunhao Chen",
      "Yunjie Zhu",
      "Zihui Yan",
      "Yifan Huang",
      "Zhen Ren",
      "Jianlu Shen",
      "Lifang Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.05528",
    "title": "PAD-Net: An Efficient Framework for Dynamic Networks",
    "abstract": " Comments: Proceedings of ACL 2023 ",
    "url": "https://arxiv.org/abs/2211.05528",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Boan Liu",
      "Fuqiang Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.07321",
    "title": "MT4SSL: Boosting Self-Supervised Speech Representation Learning by  Integrating Multiple Targets",
    "abstract": " Comments: Accepted to Interspeech 2023. Code available at: this https URL ",
    "url": "https://arxiv.org/abs/2211.07321",
    "authors": [
      "Ziyang Ma",
      "Zhisheng Zheng",
      "Changli Tang",
      "Yujin Wang",
      "Xie Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.10629",
    "title": "Unifying Label-inputted Graph Neural Networks with Deep Equilibrium  Models",
    "abstract": " Comments: 15 pages, 4 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2211.10629",
    "authors": [
      "Yi Luo",
      "Guiduo Duan",
      "Guangchun Luo",
      "Aiguo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09864",
    "title": "Synthetic Pre-Training Tasks for Neural Machine Translation",
    "abstract": " Comments: Accepted to ACL2023-Findings. New added Phrase-cat for synthetic pre-training. 17 pages including 5-page appendix ",
    "url": "https://arxiv.org/abs/2212.09864",
    "authors": [
      "Zexue He",
      "Graeme Blackwood",
      "Rameswar Panda",
      "Julian McAuley",
      "Rogerio Feris"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.10409",
    "title": "ClarifyDelphi: Reinforced Clarification Questions with Defeasibility  Rewards for Social and Moral Situations",
    "abstract": " Comments: Accepted to ACL 2023 main conference, 9 pages + bibliography + appendix ",
    "url": "https://arxiv.org/abs/2212.10409",
    "authors": [
      "Valentina Pyatkin",
      "Jena D. Hwang",
      "Vivek Srikumar",
      "Ximing Lu",
      "Liwei Jiang",
      "Yejin Choi",
      "Chandra Bhagavatula"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.13350",
    "title": "A Generalization of ViT/MLP-Mixer to Graphs",
    "abstract": " Comments: In Proceedings of ICML 2023 ",
    "url": "https://arxiv.org/abs/2212.13350",
    "authors": [
      "Xiaoxin He",
      "Bryan Hooi",
      "Thomas Laurent",
      "Adam Perold",
      "Yann LeCun",
      "Xavier Bresson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.13835",
    "title": "Representation Learning in Deep RL via Discrete Information Bottleneck",
    "abstract": " Comments: AISTATS 2023 ",
    "url": "https://arxiv.org/abs/2212.13835",
    "authors": [
      "Riashat Islam",
      "Hongyu Zang",
      "Manan Tomar",
      "Aniket Didolkar",
      "Md Mofijul Islam",
      "Samin Yeasar Arnob",
      "Tariq Iqbal",
      "Xin Li",
      "Anirudh Goyal",
      "Nicolas Heess",
      "Alex Lamb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.02079",
    "title": "PEAK: Explainable Privacy Assistant through Automated Knowledge  Extraction",
    "abstract": " Comments: 43 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2301.02079",
    "authors": [
      "Gonul Ayci",
      "Arzucan \u00d6zg\u00fcr",
      "Murat \u015eensoy",
      "P\u0131nar Yolum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2301.02129",
    "title": "Algorithms and Complexity for Computing Nash Equilibria in Adversarial  Team Games",
    "abstract": " Comments: To appear at the conference on Economics and Computation (EC) 2023 ",
    "url": "https://arxiv.org/abs/2301.02129",
    "authors": [
      "Ioannis Anagnostides",
      "Fivos Kalogiannis",
      "Ioannis Panageas",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
      "Stephen McAleer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.08771",
    "title": "Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt  Learning for Automatic Scoring in Science Education",
    "abstract": " Comments: 10 page + 1 figure ",
    "url": "https://arxiv.org/abs/2301.08771",
    "authors": [
      "Xuansheng Wu",
      "Xinyu He",
      "Tianming Liu",
      "Ninghao Liu",
      "Xiaoming Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.10857",
    "title": "Improving Graph Generation by Restricting Graph Bandwidth",
    "abstract": " Comments: Accepted at ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.10857",
    "authors": [
      "Nathaniel Diamant",
      "Alex M. Tseng",
      "Kangway V. Chuang",
      "Tommaso Biancalani",
      "Gabriele Scalia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.10956",
    "title": "Graph Neural Networks can Recover the Hidden Features Solely from the  Graph Structure",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.10956",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.11520",
    "title": "SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning",
    "abstract": " Comments: ICML 2023. First two authors contributed equally. Order was determined by coin flip ",
    "url": "https://arxiv.org/abs/2301.11520",
    "authors": [
      "Dongseok Shim",
      "Seungjae Lee",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.11562",
    "title": "Is My Prediction Arbitrary? Measuring Self-Consistency in Fair  Classification",
    "abstract": " Title: Is My Prediction Arbitrary? Measuring Self-Consistency in Fair  Classification ",
    "url": "https://arxiv.org/abs/2301.11562",
    "authors": [
      "A. Feder Cooper",
      "Katherine Lee",
      "Solon Barocas",
      "Christopher De Sa",
      "Siddhartha Sen",
      "Baobao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11592",
    "title": "Solving Richly Constrained Reinforcement Learning through State  Augmentation and Reward Penalties",
    "abstract": " Title: Solving Richly Constrained Reinforcement Learning through State  Augmentation and Reward Penalties ",
    "url": "https://arxiv.org/abs/2301.11592",
    "authors": [
      "Hao Jiang",
      "Tien Mai",
      "Pradeep Varakantham",
      "Minh Huy Hoang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12353",
    "title": "On Enhancing Expressive Power via Compositions of Single Fixed-Size ReLU  Network",
    "abstract": " Title: On Enhancing Expressive Power via Compositions of Single Fixed-Size ReLU  Network ",
    "url": "https://arxiv.org/abs/2301.12353",
    "authors": [
      "Shijun Zhang",
      "Jianfeng Lu",
      "Hongkai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12730",
    "title": "General Covariance Data Augmentation for Neural PDE Solvers",
    "abstract": " Comments: accepted to ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.12730",
    "authors": [
      "Vladimir Fanaskov",
      "Tianchi Yu",
      "Alexander Rudikov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.04168",
    "title": "Generalizing Neural Wave Functions",
    "abstract": " Comments: Published at the 40th International Conference on Machine Learning (ICML 2023) ",
    "url": "https://arxiv.org/abs/2302.04168",
    "authors": [
      "Nicholas Gao",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2302.09195",
    "title": "Data-Efficient Contrastive Self-supervised Learning: Most Beneficial  Examples for Supervised Learning Contribute the Least",
    "abstract": " Comments: Accepted to ICML 2023, Code: this https URL ",
    "url": "https://arxiv.org/abs/2302.09195",
    "authors": [
      "Siddharth Joshi",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10512",
    "title": "Robust Failure Diagnosis of Microservice System through Multimodal Data",
    "abstract": " Title: Robust Failure Diagnosis of Microservice System through Multimodal Data ",
    "url": "https://arxiv.org/abs/2302.10512",
    "authors": [
      "Shenglin Zhang",
      "Pengxiang Jin",
      "Zihan Lin",
      "Yongqian Sun",
      "Bicheng Zhang",
      "Sibo Xia",
      "Zhengdan Li",
      "Zhenyu Zhong",
      "Minghua Ma",
      "Wa Jin",
      "Dai Zhang",
      "Zhenyu Zhu",
      "Dan Pei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.10896",
    "title": "IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness",
    "abstract": " Title: IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness ",
    "url": "https://arxiv.org/abs/2302.10896",
    "authors": [
      "Xiaoyun Xu",
      "Guilherme Perin",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.14376",
    "title": "GNOT: A General Neural Operator Transformer for Operator Learning",
    "abstract": " Title: GNOT: A General Neural Operator Transformer for Operator Learning ",
    "url": "https://arxiv.org/abs/2302.14376",
    "authors": [
      "Zhongkai Hao",
      "Zhengyi Wang",
      "Hang Su",
      "Chengyang Ying",
      "Yinpeng Dong",
      "Songming Liu",
      "Ze Cheng",
      "Jian Song",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2303.02165",
    "title": "DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural  Network",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.02165",
    "authors": [
      "Xuan Shen",
      "Yaohua Wang",
      "Ming Lin",
      "Yilun Huang",
      "Hao Tang",
      "Xiuyu Sun",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02536",
    "title": "Finding Alignments Between Interpretable Causal Variables and  Distributed Neural Representations",
    "abstract": " Title: Finding Alignments Between Interpretable Causal Variables and  Distributed Neural Representations ",
    "url": "https://arxiv.org/abs/2303.02536",
    "authors": [
      "Atticus Geiger",
      "Zhengxuan Wu",
      "Christopher Potts",
      "Thomas Icard",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03293",
    "title": "On Hierarchical Multi-Resolution Graph Generative Models",
    "abstract": " Title: On Hierarchical Multi-Resolution Graph Generative Models ",
    "url": "https://arxiv.org/abs/2303.03293",
    "authors": [
      "Mahdi Karami",
      "Jun Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.07275",
    "title": "A Survey of Graph Prompting Methods: Techniques, Applications, and  Challenges",
    "abstract": " Comments: 9 pages + 1 figure ",
    "url": "https://arxiv.org/abs/2303.07275",
    "authors": [
      "Xuansheng Wu",
      "Kaixiong Zhou",
      "Mingchen Sun",
      "Xin Wang",
      "Ninghao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.10417",
    "title": "On the Benefit of Nonlinear Control for Robust Logarithmic Growth: Coin  Flipping Games as a Demonstration Case",
    "abstract": " Title: On the Benefit of Nonlinear Control for Robust Logarithmic Growth: Coin  Flipping Games as a Demonstration Case ",
    "url": "https://arxiv.org/abs/2303.10417",
    "authors": [
      "Anton V. Proskurnikov",
      "B. Ross Barmish"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Mathematical Finance (q-fin.MF)"
    ]
  },
  {
    "id": "arXiv:2303.11341",
    "title": "What does it take to catch a Chinchilla? Verifying Rules on Large-Scale  Neural Network Training via Compute Monitoring",
    "abstract": " Title: What does it take to catch a Chinchilla? Verifying Rules on Large-Scale  Neural Network Training via Compute Monitoring ",
    "url": "https://arxiv.org/abs/2303.11341",
    "authors": [
      "Yonadav Shavit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12695",
    "title": "Adaptive Conformal Prediction by Reweighting Nonconformity Score",
    "abstract": " Title: Adaptive Conformal Prediction by Reweighting Nonconformity Score ",
    "url": "https://arxiv.org/abs/2303.12695",
    "authors": [
      "Salim I. Amoukou",
      "Nicolas J.B Brunel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03778",
    "title": "Conformal Regression in Calorie Prediction for Team Jumbo-Visma",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2304.03778",
    "authors": [
      "Kristian van Kuijk",
      "Mark Dirksen",
      "Christof Seiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2304.13383",
    "title": "N$\\text{A}^\\text{2}$Q: Neural Attention Additive Model for Interpretable  Multi-Agent Q-Learning",
    "abstract": " Title: N$\\text{A}^\\text{2}$Q: Neural Attention Additive Model for Interpretable  Multi-Agent Q-Learning ",
    "url": "https://arxiv.org/abs/2304.13383",
    "authors": [
      "Zichuan Liu",
      "Yuanyang Zhu",
      "Chunlin Chen"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2304.14463",
    "title": "Moccasin: Efficient Tensor Rematerialization for Neural Networks",
    "abstract": " Title: Moccasin: Efficient Tensor Rematerialization for Neural Networks ",
    "url": "https://arxiv.org/abs/2304.14463",
    "authors": [
      "Burak Bartan",
      "Haoming Li",
      "Harris Teague",
      "Christopher Lott",
      "Bistra Dilkina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.02154",
    "title": "Random Schreier graphs of the general linear group over finite fields  and expanders",
    "abstract": " Comments: 31 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2305.02154",
    "authors": [
      "Geoffroy Caillat-Grenier"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.02886",
    "title": "SlipCover: Near Zero-Overhead Code Coverage for Python",
    "abstract": " Comments: Accepted to ISSTA 2023 ",
    "url": "https://arxiv.org/abs/2305.02886",
    "authors": [
      "Juan Altmayer Pizzorno",
      "Emery D Berger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2305.04111",
    "title": "Efficient and Degree-Guided Graph Generation via Discrete Diffusion  Modeling",
    "abstract": " Comments: ICML 2023, camera-ready revision ",
    "url": "https://arxiv.org/abs/2305.04111",
    "authors": [
      "Xiaohui Chen",
      "Jiaxing He",
      "Xu Han",
      "Li-Ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.05665",
    "title": "ImageBind: One Embedding Space To Bind Them All",
    "abstract": " Comments: CVPR 2023 (Highlighted Paper). Website: this https URL Code/Models: this https URL ",
    "url": "https://arxiv.org/abs/2305.05665",
    "authors": [
      "Rohit Girdhar",
      "Alaaeldin El-Nouby",
      "Zhuang Liu",
      "Mannat Singh",
      "Kalyan Vasudev Alwala",
      "Armand Joulin",
      "Ishan Misra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.09948",
    "title": "HICO-DET-SG and V-COCO-SG: New Data Splits for Evaluating the Systematic  Generalization Performance of Human-Object Interaction Detection Models",
    "abstract": " Comments: 19 pages, 3 figures, 4 tables, This is a non-anonymized version of the manuscript submitted to Transactions on Machine Learning Research (TMLR) ",
    "url": "https://arxiv.org/abs/2305.09948",
    "authors": [
      "Kentaro Takemoto",
      "Moyuru Yamada",
      "Tomotake Sasaki",
      "Hisanao Akima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10631",
    "title": "A Subabdominal MRI Image Segmentation Algorithm Based on Multi-Scale  Feature Pyramid Network and Dual Attention Mechanism",
    "abstract": " Comments: 20 pages,9 figures ",
    "url": "https://arxiv.org/abs/2305.10631",
    "authors": [
      "Yu Xiao",
      "Xin Yang",
      "Sijuan Huang",
      "Lihua Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11192",
    "title": "TPMDP: Threshold Personalized Multi-party Differential Privacy via  Optimal Gaussian Mechanism",
    "abstract": " Comments: 12 pages, 4 figures, submitted to MASS 2023, correct typos ",
    "url": "https://arxiv.org/abs/2305.11192",
    "authors": [
      "Jiandong Liu",
      "Lan Zhang",
      "Chaojie Lv",
      "Ting Yu",
      "Nikolaos M. Freris",
      "Xiang-Yang Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.12514",
    "title": "Towards robust paralinguistic assessment for real-world mobile health  (mHealth) monitoring: an initial study of reverberation effects on speech",
    "abstract": " Comments: Accepted for publication at Interspeech 2023 ",
    "url": "https://arxiv.org/abs/2305.12514",
    "authors": [
      "Judith Dineley",
      "Ewan Carr",
      "Faith Matcham",
      "Johnny Downs",
      "Richard Dobson",
      "Thomas F Quatieri",
      "Nicholas Cummins"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.12606",
    "title": "Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech  Pre-Training for Adaptation to Unseen Languages",
    "abstract": " Comments: Accepted at Interspeech 2023 ",
    "url": "https://arxiv.org/abs/2305.12606",
    "authors": [
      "Andrew Rouditchenko",
      "Sameer Khurana",
      "Samuel Thomas",
      "Rogerio Feris",
      "Leonid Karlinsky",
      "Hilde Kuehne",
      "David Harwath",
      "Brian Kingsbury",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.13059",
    "title": "Friendly Neighbors: Contextualized Sequence-to-Sequence Link Prediction",
    "abstract": " Comments: 7 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2305.13059",
    "authors": [
      "Adrian Kochsiek",
      "Apoorv Saxena",
      "Inderjeet Nair",
      "Rainer Gemulla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.14035",
    "title": "Can Self-Supervised Neural Representations Pre-Trained on Human Speech  distinguish Animal Callers?",
    "abstract": " Comments: Accepted at Interspeech 2023 ",
    "url": "https://arxiv.org/abs/2305.14035",
    "authors": [
      "Eklavya Sarkar",
      "Mathew Magimai.-Doss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.15006",
    "title": "A Human-in-the-Loop Approach for Information Extraction from Privacy  Policies under Data Scarcity",
    "abstract": " Comments: Accepted for 2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&P) ",
    "url": "https://arxiv.org/abs/2305.15006",
    "authors": [
      "Michael Gebauer",
      "Faraz Maschhur",
      "Nicola Leschke",
      "Elias Gr\u00fcnewald",
      "Frank Pallas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15614",
    "title": "Reverse Engineering Self-Supervised Learning",
    "abstract": " Title: Reverse Engineering Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2305.15614",
    "authors": [
      "Ido Ben-Shaul",
      "Ravid Shwartz-Ziv",
      "Tomer Galanti",
      "Shai Dekel",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16966",
    "title": "Hybrid Energy Based Model in the Feature Space for Out-of-Distribution  Detection",
    "abstract": " Title: Hybrid Energy Based Model in the Feature Space for Out-of-Distribution  Detection ",
    "url": "https://arxiv.org/abs/2305.16966",
    "authors": [
      "Marc Lafon",
      "Elias Ramzi",
      "Cl\u00e9ment Rambour",
      "Nicolas Thome"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17510",
    "title": "A Hybrid Quantum-Classical Approach based on the Hadamard Transform for  the Convolutional Layer",
    "abstract": " Comments: To be presented at International Conference on Machine Learning (ICML), 2023 ",
    "url": "https://arxiv.org/abs/2305.17510",
    "authors": [
      "Hongyi Pan",
      "Xin Zhu",
      "Salih Atici",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.17537",
    "title": "Modeling Dynamic Environments with Scene Graph Memory",
    "abstract": " Title: Modeling Dynamic Environments with Scene Graph Memory ",
    "url": "https://arxiv.org/abs/2305.17537",
    "authors": [
      "Andrey Kurenkov",
      "Michael Lingelbach",
      "Tanmay Agarwal",
      "Chengshu Li",
      "Emily Jin",
      "Ruohan Zhang",
      "Fei-Fei Li",
      "Jiajun Wu",
      "Silvio Savarese",
      "Roberto Mart\u00edn-Mart\u00edn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17916",
    "title": "Volume Feature Rendering for Fast Neural Radiance Field Reconstruction",
    "abstract": " Title: Volume Feature Rendering for Fast Neural Radiance Field Reconstruction ",
    "url": "https://arxiv.org/abs/2305.17916",
    "authors": [
      "Kang Han",
      "Wei Xiang",
      "Lu Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18405",
    "title": "Dink-Net: Neural Clustering on Large Graphs",
    "abstract": " Comments: 18 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2305.18405",
    "authors": [
      "Yue Liu",
      "Ke Liang",
      "Jun Xia",
      "Sihang Zhou",
      "Xihong Yang",
      "Xinwang Liu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18446",
    "title": "Trompt: Towards a Better Deep Neural Network for Tabular Data",
    "abstract": " Comments: ICML'23 (poster) ",
    "url": "https://arxiv.org/abs/2305.18446",
    "authors": [
      "Kuan-Yu Chen",
      "Ping-Han Chiang",
      "Hsin-Rung Chou",
      "Ting-Wei Chen",
      "Tien-Hao Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18601",
    "title": "BRIGHT: Bi-level Feature Representation of Image Collections using  Groups of Hash Tables",
    "abstract": " Comments: project page: this https URL ",
    "url": "https://arxiv.org/abs/2305.18601",
    "authors": [
      "Dingdong Yang",
      "Yizhi Wang",
      "Ali Mahdavi-Amiri",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18731",
    "title": "Hybrid Representation Learning via Epistemic Graph",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2305.18731",
    "authors": [
      "Jin Yuan",
      "Yang Zhang",
      "Yangzhou Du",
      "Zhongchao Shi",
      "Xin Geng",
      "Jianping Fan",
      "Yong Rui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18743",
    "title": "Decomposed Human Motion Prior for Video Pose Estimation via Adversarial  Training",
    "abstract": " Title: Decomposed Human Motion Prior for Video Pose Estimation via Adversarial  Training ",
    "url": "https://arxiv.org/abs/2305.18743",
    "authors": [
      "Wenshuo Chen",
      "Xiang Zhou",
      "Zhengdi Yu",
      "Zhaoyu Zheng",
      "Weixi Gu",
      "Kai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18758",
    "title": "Task-Equivariant Graph Few-shot Learning",
    "abstract": " Comments: KDD 2023 ",
    "url": "https://arxiv.org/abs/2305.18758",
    "authors": [
      "Sungwon Kim",
      "Junseok Lee",
      "Namkyeong Lee",
      "Wonjoong Kim",
      "Seungyoon Choi",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18831",
    "title": "Convolutional Monge Mapping Normalization for learning on biosignals",
    "abstract": " Title: Convolutional Monge Mapping Normalization for learning on biosignals ",
    "url": "https://arxiv.org/abs/2305.18831",
    "authors": [
      "Th\u00e9o Gnassounou",
      "R\u00e9mi Flamary",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18897",
    "title": "HuMoT: Human Motion Representation using Topology-Agnostic Transformers  for Character Animation Retargeting",
    "abstract": " Comments: 17 pages, 12 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2305.18897",
    "authors": [
      "Lucas Mourot",
      "Ludovic Hoyet",
      "Fran\u00e7ois Le Clerc",
      "Pierre Hellier"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.19130",
    "title": "Adaptation of Tongue Ultrasound-Based Silent Speech Interfaces Using  Spatial Transformer Networks",
    "abstract": " Comments: 5 pages, 3 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2305.19130",
    "authors": [
      "L\u00e1szl\u00f3 T\u00f3th",
      "Amin Honarmandi Shandiz",
      "G\u00e1bor Gosztolya",
      "Csap\u00f3 Tam\u00e1s G\u00e1bor"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.19182",
    "title": "Optimal Hub Placement and Deadlock-Free Routing for Payment Channel  Network Scalability",
    "abstract": " Comments: Accepted by ICDCS 2023 ",
    "url": "https://arxiv.org/abs/2305.19182",
    "authors": [
      "Lingxiao Yang",
      "Xuewen Dong",
      "Sheng Gao",
      "Qiang Qu",
      "Xiaodong Zhang",
      "Wensheng Tian",
      "Yulong Shen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.19230",
    "title": "Controlled Text Generation with Hidden Representation Transformations",
    "abstract": " Comments: Accepted at ACL 2023 as a long paper (Findings) ",
    "url": "https://arxiv.org/abs/2305.19230",
    "authors": [
      "Vaibhav Kumar",
      "Hana Koorehdavoudi",
      "Masud Moshtaghi",
      "Amita Misra",
      "Ankit Chadha",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]