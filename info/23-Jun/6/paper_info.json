[
  {
    "id": "arXiv:2306.01742",
    "title": "Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech  Detection",
    "abstract": "Health experts assert that hope plays a crucial role in enhancing individuals' physical and mental well-being, facilitating their recovery, and promoting restoration. Hope speech refers to comments, posts and other social media messages that offer support, reassurance, suggestions, inspiration, and insight. The detection of hope speech involves the analysis of such textual content, with the aim of identifying messages that invoke positive emotions in people. Our study aims to find computationally efficient yet comparable/superior methods for hope speech detection. We also make our codebase public at https://github.com/aflah02/Hope_Speech_Detection ",
    "url": "https://arxiv.org/abs/2306.01742",
    "authors": [
      "Neemesh Yadav",
      "Mohammad Aflah Khan",
      "Diksha Sethi",
      "Raghav Sahni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01751",
    "title": "Differential Privacy with Random Projections and Sign Random Projections",
    "abstract": "In this paper, we develop a series of differential privacy (DP) algorithms from a family of random projections (RP), for general applications in machine learning, data mining, and information retrieval. Among the presented algorithms, \\textbf{iDP-SignRP} is remarkably effective under the setting of ``individual differential privacy'' (iDP), based on sign random projections (SignRP). Also, \\textbf{DP-SignOPORP} considerably improves existing algorithms in the literature under the standard DP setting, using ``one permutation + one random projection'' (OPORP), where OPORP is a variant of the celebrated count-sketch method with fixed-length binning and normalization. Without taking signs, among the DP-RP family, \\textbf{DP-OPORP} achieves the best performance. The concept of iDP (individual differential privacy) is defined only on a particular dataset of interest. While iDP is not strictly DP, iDP might be useful in certain applications, such as releasing a dataset (including sharing embeddings across companies or countries). In our study, we find that \\textbf{iDP-SignRP} is remarkably effective for search and machine learning applications, in that the utilities are exceptionally good even at a very small privacy parameter $\\epsilon$ (e.g., $\\epsilon<0.5$). ",
    "url": "https://arxiv.org/abs/2306.01751",
    "authors": [
      "Ping Li",
      "Xiaoyun Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01754",
    "title": "Transformer-based Vulnerability Detection in Code at EditTime:  Zero-shot, Few-shot, or Fine-tuning?",
    "abstract": "Software vulnerabilities bear enterprises significant costs. Despite extensive efforts in research and development of software vulnerability detection methods, uncaught vulnerabilities continue to put software owners and users at risk. Many current vulnerability detection methods require that code snippets can compile and build before attempting detection. This, unfortunately, introduces a long latency between the time a vulnerability is injected to the time it is removed, which can substantially increases the cost of fixing a vulnerability. We recognize that the current advances in machine learning can be used to detect vulnerable code patterns on syntactically incomplete code snippets as the developer is writing the code at EditTime. In this paper we present a practical system that leverages deep learning on a large-scale data set of vulnerable code patterns to learn complex manifestations of more than 250 vulnerability types and detect vulnerable code patterns at EditTime. We discuss zero-shot, few-shot, and fine-tuning approaches on state of the art pre-trained Large Language Models (LLMs). We show that in comparison with state of the art vulnerability detection models our approach improves the state of the art by 10%. We also evaluate our approach to detect vulnerability in auto-generated code by code LLMs. Evaluation on a benchmark of high-risk code scenarios shows a reduction of up to 90% vulnerability reduction. ",
    "url": "https://arxiv.org/abs/2306.01754",
    "authors": [
      "Aaron Chan",
      "Anant Kharkar",
      "Roshanak Zilouchian Moghaddam",
      "Yevhen Mohylevskyy",
      "Alec Helyar",
      "Eslam Kamal",
      "Mohamed Elkamhawy",
      "Neel Sundaresan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01756",
    "title": "CSI-Based Efficient Self-Quarantine Monitoring System Using Branchy  Convolution Neural Network",
    "abstract": "Nowadays, Coronavirus disease (COVID-19) has become a global pandemic because of its fast spread in various countries. To build an anti-epidemic barrier, self-isolation is required for people who have been to any at-risk places or have been in close contact with infected people. However, existing camera or wearable device-based monitoring systems may present privacy leakage risks or cause user inconvenience in some cases. In this paper, we propose a Wi-Fi-based device-free self-quarantine monitoring system. Specifically, we exploit channel state information (CSI) derived from Wi-Fi signals as human activity features. We collect CSI data in a simulated self-quarantine scenario and present BranchyGhostNet, a lightweight convolution neural network (CNN) with an early exit prediction branch, for the efficient joint task of room occupancy detection (ROD) and human activity recognition (HAR). The early exiting branch is used for ROD, and the final one is used for HAR. Our experimental results indicate that the proposed model can achieve an average accuracy of 98.19% for classifying five different human activities. They also confirm that after leveraging the early exit prediction mechanism, the inference latency for ROD can be significantly reduced by 54.04% when compared with the final exiting branch while guaranteeing the accuracy of ROD. ",
    "url": "https://arxiv.org/abs/2306.01756",
    "authors": [
      "Jingtao Guo",
      "Ivan Wang-Hei Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01762",
    "title": "Pre-trained transformer for adversarial purification",
    "abstract": "With more and more deep neural networks being deployed as various daily services, their reliability is essential. It's frightening that deep neural networks are vulnerable and sensitive to adversarial attacks, the most common one of which for the services is evasion-based. Recent works usually strengthen the robustness by adversarial training or leveraging the knowledge of an amount of clean data. However, in practical terms, retraining and redeploying the model need a large computational budget, leading to heavy losses to the online service. In addition, when adversarial examples of a certain attack are detected, only limited adversarial examples are available for the service provider, while much clean data may not be accessible. Given the mentioned problems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is to rapidly defend against a certain attack for the frozen original service model with limitations of few clean and adversarial examples. Motivated by the generalization and the universal computation ability of pre-trained transformer models, we come up with a new defender method, CeTaD, which stands for Considering Pre-trained Transformers as Defenders. In particular, we evaluate the effectiveness and the transferability of CeTaD in the case of one-shot adversarial examples and explore the impact of different parts of CeTaD as well as training data conditions. CeTaD is flexible, able to be embedded into an arbitrary differentiable model, and suitable for various types of attacks. ",
    "url": "https://arxiv.org/abs/2306.01762",
    "authors": [
      "Kai Wu",
      "Yujian Betterest Li",
      "Xiaoyu Zhang",
      "Handing Wang",
      "Jing Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01782",
    "title": "Capacity Constrained Influence Maximization in Social Networks",
    "abstract": "Influence maximization (IM) aims to identify a small number of influential individuals to maximize the information spread and finds applications in various fields. It was first introduced in the context of viral marketing, where a company pays a few influencers to promote the product. However, apart from the cost factor, the capacity of individuals to consume content poses challenges for implementing IM in real-world scenarios. For example, players on online gaming platforms can only interact with a limited number of friends. In addition, we observe that in these scenarios, (i) the initial adopters of promotion are likely to be the friends of influencers rather than the influencers themselves, and (ii) existing IM solutions produce sub-par results with high computational demands. Motivated by these observations, we propose a new IM variant called capacity constrained influence maximization (CIM), which aims to select a limited number of influential friends for each initial adopter such that the promotion can reach more users. To solve CIM effectively, we design two greedy algorithms, MG-Greedy and RR-Greedy, ensuring the $1/2$-approximation ratio. To improve the efficiency, we devise the scalable implementation named RR-OPIM+ with $(1/2-\\epsilon)$-approximation and near-linear running time. We extensively evaluate the performance of 9 approaches on 6 real-world networks, and our solutions outperform all competitors in terms of result quality and running time. Additionally, we deploy RR-OPIM+ to online game scenarios, which improves the baseline considerably. ",
    "url": "https://arxiv.org/abs/2306.01782",
    "authors": [
      "Shiqi Zhang",
      "Yiqian Huang",
      "Jiachen Sun",
      "Wenqing Lin",
      "Xiaokui Xiao",
      "Bo Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.01792",
    "title": "Task Relation-aware Continual User Representation Learning",
    "abstract": "User modeling, which learns to represent users into a low-dimensional representation space based on their past behaviors, got a surge of interest from the industry for providing personalized services to users. Previous efforts in user modeling mainly focus on learning a task-specific user representation that is designed for a single task. However, since learning task-specific user representations for every task is infeasible, recent studies introduce the concept of universal user representation, which is a more generalized representation of a user that is relevant to a variety of tasks. Despite their effectiveness, existing approaches for learning universal user representations are impractical in real-world applications due to the data requirement, catastrophic forgetting and the limited learning capability for continually added tasks. In this paper, we propose a novel continual user representation learning method, called TERACON, whose learning capability is not limited as the number of learned tasks increases while capturing the relationship between the tasks. The main idea is to introduce an embedding for each task, i.e., task embedding, which is utilized to generate task-specific soft masks that not only allow the entire model parameters to be updated until the end of training sequence, but also facilitate the relationship between the tasks to be captured. Moreover, we introduce a novel knowledge retention module with pseudo-labeling strategy that successfully alleviates the long-standing problem of continual learning, i.e., catastrophic forgetting. Extensive experiments on public and proprietary real-world datasets demonstrate the superiority and practicality of TERACON. Our code is available at https://github.com/Sein-Kim/TERACON. ",
    "url": "https://arxiv.org/abs/2306.01792",
    "authors": [
      "Sein Kim",
      "Namkyeong Lee",
      "Donghyun Kim",
      "Minchul Yang",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01799",
    "title": "Pairwise Ranking Losses of Click-Through Rates Prediction for Welfare  Maximization in Ad Auctions",
    "abstract": "We study the design of loss functions for click-through rates (CTR) to optimize (social) welfare in advertising auctions. Existing works either only focus on CTR predictions without consideration of business objectives (e.g., welfare) in auctions or assume that the distribution over the participants' expected cost-per-impression (eCPM) is known a priori, then use various additional assumptions on the parametric form of the distribution to derive loss functions for predicting CTRs. In this work, we bring back the welfare objectives of ad auctions into CTR predictions and propose a novel weighted rankloss to train the CTR model. Compared to existing literature, our approach provides a provable guarantee on welfare but without assumptions on the eCPMs' distribution while also avoiding the intractability of naively applying existing learning-to-rank methods. Further, we propose a theoretically justifiable technique for calibrating the losses using labels generated from a teacher network, only assuming that the teacher network has bounded $\\ell_2$ generalization error. Finally, we demonstrate the advantages of the proposed loss on synthetic and real-world data. ",
    "url": "https://arxiv.org/abs/2306.01799",
    "authors": [
      "Boxiang Lyu",
      "Zhe Feng",
      "Zachary Robertson",
      "Sanmi Koyejo"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01805",
    "title": "Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes",
    "abstract": "As people become more aware of their food choices, food computation models have become increasingly popular in assisting people in maintaining healthy eating habits. For example, food recommendation systems analyze recipe instructions to assess nutritional contents and provide recipe recommendations. The recent and remarkable successes of generative AI methods, such as auto-regressive large language models, can lead to robust methods for a more comprehensive understanding of recipes for healthy food recommendations beyond surface-level nutrition content assessments. In this study, we explore the use of generative AI methods to extend current food computation models, primarily involving the analysis of nutrition and ingredients, to also incorporate cooking actions (e.g., add salt, fry the meat, boil the vegetables, etc.). Cooking actions are notoriously hard to model using statistical learning methods due to irregular data patterns - significantly varying natural language descriptions for the same action (e.g., marinate the meat vs. marinate the meat and leave overnight) and infrequently occurring patterns (e.g., add salt occurs far more frequently than marinating the meat). The prototypical approach to handling irregular data patterns is to increase the volume of data that the model ingests by orders of magnitude. Unfortunately, in the cooking domain, these problems are further compounded with larger data volumes presenting a unique challenge that is not easily handled by simply scaling up. In this work, we propose novel aggregation-based generative AI methods, Cook-Gen, that reliably generate cooking actions from recipes, despite difficulties with irregular data patterns, while also outperforming Large Language Models and other strong baselines. ",
    "url": "https://arxiv.org/abs/2306.01805",
    "authors": [
      "Revathy Venkataramanan",
      "Kaushik Roy",
      "Kanak Raj",
      "Renjith Prasad",
      "Yuxin Zi",
      "Vignesh Narayanan",
      "Amit Sheth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.01809",
    "title": "Adversarial Attack Based on Prediction-Correction",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial examples obtained by adding small perturbations to original examples. The added perturbations in existing attacks are mainly determined by the gradient of the loss function with respect to the inputs. In this paper, the close relationship between gradient-based attacks and the numerical methods for solving ordinary differential equation (ODE) is studied for the first time. Inspired by the numerical solution of ODE, a new prediction-correction (PC) based adversarial attack is proposed. In our proposed PC-based attack, some existing attack can be selected to produce a predicted example first, and then the predicted example and the current example are combined together to determine the added perturbations. The proposed method possesses good extensibility and can be applied to all available gradient-based attacks easily. Extensive experiments demonstrate that compared with the state-of-the-art gradient-based adversarial attacks, our proposed PC-based attacks have higher attack success rates, and exhibit better transferability. ",
    "url": "https://arxiv.org/abs/2306.01809",
    "authors": [
      "Chen Wan",
      "Fangjun Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01812",
    "title": "SAPI: Surroundings-Aware Vehicle Trajectory Prediction at Intersections",
    "abstract": "In this work we propose a deep learning model, i.e., SAPI, to predict vehicle trajectories at intersections. SAPI uses an abstract way to represent and encode surrounding environment by utilizing information from real-time map, right-of-way, and surrounding traffic. The proposed model consists of two convolutional network (CNN) and recurrent neural network (RNN)-based encoders and one decoder. A refiner is proposed to conduct a look-back operation inside the model, in order to make full use of raw history trajectory information. We evaluate SAPI on a proprietary dataset collected in real-world intersections through autonomous vehicles. It is demonstrated that SAPI shows promising performance when predicting vehicle trajectories at intersection, and outperforms benchmark methods. The average displacement error(ADE) and final displacement error(FDE) for 6-second prediction are 1.84m and 4.32m respectively. We also show that the proposed model can accurately predict vehicle trajectories in different scenarios. ",
    "url": "https://arxiv.org/abs/2306.01812",
    "authors": [
      "Ethan Zhang",
      "Hao Xiao",
      "Yiqian Gan",
      "Lei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01816",
    "title": "Prediction of Citrus Diseases Using Machine Learning And Deep Learning:  Classifier, Models SLR",
    "abstract": "Citrus diseases have been major issues for citrus growing worldwide for many years they can lead significantly reduce fruit quality. the most harmful citrus diseases are citrus canker, citrus greening, citrus black spot, citrus leaf miner which can have significant economic losses of citrus industry in worldwide prevention and management strategies like chemical treatments. Citrus diseases existing in all over the world where citrus is growing its effects the citrus tree root, citrus tree leaf, citrus tree orange etc. Existing of citrus diseases is highly impact on economic factor that can also produce low quality fruits and increased the rate for diseases management. Sanitation and routine monitoring can be effective in managing certain citrus diseases, but others may require more intensive treatments like chemical or biological control methods. ",
    "url": "https://arxiv.org/abs/2306.01816",
    "authors": [
      "Muhammad Shoaib Farooq",
      "Abdullah Mehboob"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01817",
    "title": "Heart Diseases Prediction Using Block-chain and Machine Learning",
    "abstract": "Most people around the globe are dying due to heart disease. The main reason behind the rapid increase in the death rate due to heart disease is that there is no infrastructure developed for the healthcare department that can provide a secure way of data storage and transmission. Due to redundancy in the patient data, it is difficult for cardiac Professionals to predict the disease early on. This rapid increase in the death rate due to heart disease can be controlled by monitoring and eliminating some of the key attributes in the early stages such as blood pressure, cholesterol level, body weight, and addiction to smoking. Patient data can be monitored by cardiac Professionals (Cp) by using the advanced framework in the healthcare departments. Blockchain is the world's most reliable provider. The use of advanced systems in the healthcare departments providing new ways of dealing with diseases has been developed as well. In this article Machine Learning (ML) algorithm known as a sine-cosine weighted k-nearest neighbor (SCA-WKNN) is used for predicting the Hearth disease with the maximum accuracy among the existing approaches. Blockchain technology has been used in the research to secure the data throughout the session and can give more accurate results using this technology. The performance of the system can be improved by using this algorithm and the dataset proposed has been improved by using different resources as well. ",
    "url": "https://arxiv.org/abs/2306.01817",
    "authors": [
      "Muhammad Shoaib Farooq",
      "Kiran Amjad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01818",
    "title": "Beta Thalassemia Carriers detection empowered federated Learning",
    "abstract": "Thalassemia is a group of inherited blood disorders that happen when hemoglobin, the protein in red blood cells that carries oxygen, is not made enough. It is found all over the body and is needed for survival. If both parents have thalassemia, a child's chance of getting it increases. Genetic counselling and early diagnosis are essential for treating thalassemia and stopping it from being passed on to future generations. It may be hard for healthcare professionals to differentiate between people with thalassemia carriers and those without. The current blood tests for beta thalassemia carriers are too expensive, take too long, and require too much screening equipment. The World Health Organization says there is a high death rate for people with thalassemia. Therefore, it is essential to find thalassemia carriers to act quickly. High-performance liquid chromatography (HPLC), the standard test method, has problems such as cost, time, and equipment needs. So, there must be a quick and cheap way to find people carrying the thalassemia gene. Using federated learning (FL) techniques, this study shows a new way to find people with the beta-thalassemia gene. FL allows data to be collected and processed on-site while following privacy rules, making it an excellent choice for sensitive health data. Researchers used FL to train a model for beta-thalassemia carriers by looking at the complete blood count results and red blood cell indices. The model was 92.38 % accurate at telling the difference between beta-thalassemia carriers and people who did not have the disease. The proposed FL model is better than other published methods in terms of how well it works, how reliable it is, and how private it is. This research shows a promising, quick, accurate, and low-cost way to find thalassemia carriers and opens the door for screening them on a large scale. ",
    "url": "https://arxiv.org/abs/2306.01818",
    "authors": [
      "Muhammad Shoaib Farooq",
      "Hafiz Ali Younas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01820",
    "title": "Concurrent Classifier Error Detection (CCED) in Large Scale Machine  Learning Systems",
    "abstract": "The complexity of Machine Learning (ML) systems increases each year, with current implementations of large language models or text-to-image generators having billions of parameters and requiring billions of arithmetic operations. As these systems are widely utilized, ensuring their reliable operation is becoming a design requirement. Traditional error detection mechanisms introduce circuit or time redundancy that significantly impacts system performance. An alternative is the use of Concurrent Error Detection (CED) schemes that operate in parallel with the system and exploit their properties to detect errors. CED is attractive for large ML systems because it can potentially reduce the cost of error detection. In this paper, we introduce Concurrent Classifier Error Detection (CCED), a scheme to implement CED in ML systems using a concurrent ML classifier to detect errors. CCED identifies a set of check signals in the main ML system and feeds them to the concurrent ML classifier that is trained to detect errors. The proposed CCED scheme has been implemented and evaluated on two widely used large-scale ML models: Contrastive Language Image Pretraining (CLIP) used for image classification and Bidirectional Encoder Representations from Transformers (BERT) used for natural language applications. The results show that more than 95 percent of the errors are detected when using a simple Random Forest classifier that is order of magnitude simpler than CLIP or BERT. These results illustrate the potential of CCED to implement error detection in large-scale ML models. ",
    "url": "https://arxiv.org/abs/2306.01820",
    "authors": [
      "Pedro Reviriego",
      "Ziheng Wang",
      "Alvaro Alonso",
      "Zhen Gao",
      "Farzad Niknia",
      "Shanshan Liu",
      "Fabrizio Lombardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01822",
    "title": "ErfReLU: Adaptive Activation Function for Deep Neural Network",
    "abstract": "Recent research has found that the activation function (AF) selected for adding non-linearity into the output can have a big impact on how effectively deep learning networks perform. Developing activation functions that can adapt simultaneously with learning is a need of time. Researchers recently started developing activation functions that can be trained throughout the learning process, known as trainable, or adaptive activation functions (AAF). Research on AAF that enhance the outcomes is still in its early stages. In this paper, a novel activation function 'ErfReLU' has been developed based on the erf function and ReLU. This function exploits the ReLU and the error function (erf) to its advantage. State of art activation functions like Sigmoid, ReLU, Tanh, and their properties have been briefly explained. Adaptive activation functions like Tanhsoft1, Tanhsoft2, Tanhsoft3, TanhLU, SAAF, ErfAct, Pserf, Smish, and Serf have also been described. Lastly, performance analysis of 9 trainable activation functions along with the proposed one namely Tanhsoft1, Tanhsoft2, Tanhsoft3, TanhLU, SAAF, ErfAct, Pserf, Smish, and Serf has been shown by applying these activation functions in MobileNet, VGG16, and ResNet models on CIFAR-10, MNIST, and FMNIST benchmark datasets. ",
    "url": "https://arxiv.org/abs/2306.01822",
    "authors": [
      "Ashish Rajanand",
      "Pradeep Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01845",
    "title": "Multi-View Multi-Task Representation Learning for Mispronunciation  Detection",
    "abstract": "The disparity in phonology between learner's native (L1) and target (L2) language poses a significant challenge for mispronunciation detection and diagnosis (MDD) systems. This challenge is further intensified by lack of annotated L2 data. This paper proposes a novel MDD architecture that exploits multiple `views' of the same input data assisted by auxiliary tasks to learn more distinctive phonetic representation in a low-resource setting. Using the mono- and multilingual encoders, the model learn multiple views of the input, and capture the sound properties across diverse languages and accents. These encoded representations are further enriched by learning articulatory features in a multi-task setup. Our reported results using the L2-ARCTIC data outperformed the SOTA models, with a phoneme error rate reduction of 11.13% and 8.60% and absolute F1 score increase of 5.89%, and 2.49% compared to the single-view mono- and multilingual systems, with a limited L2 dataset. ",
    "url": "https://arxiv.org/abs/2306.01845",
    "authors": [
      "Yassine El Kheir",
      "Shammur Absar Chowdhury",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.01859",
    "title": "Spatially Resolved Gene Expression Prediction from H&E Histology Images  via Bi-modal Contrastive Learning",
    "abstract": "Histology imaging is an important tool in medical diagnosis and research, enabling the examination of tissue structure and composition at the microscopic level. Understanding the underlying molecular mechanisms of tissue architecture is critical in uncovering disease mechanisms and developing effective treatments. Gene expression profiling provides insight into the molecular processes underlying tissue architecture, but the process can be time-consuming and expensive. In this study, we present BLEEP (Bi-modaL Embedding for Expression Prediction), a bi-modal embedding framework capable of generating spatially resolved gene expression profiles of whole-slide Hematoxylin and eosin (H&E) stained histology images. BLEEP uses a contrastive learning framework to construct a low-dimensional joint embedding space from a reference dataset using paired image and expression profiles at micrometer resolution. With this framework, the gene expression of any query image patch can be imputed using the expression profiles from the reference dataset. We demonstrate BLEEP's effectiveness in gene expression prediction by benchmarking its performance on a human liver tissue dataset captured via the 10x Visium platform, where it achieves significant improvements over existing methods. Our results demonstrate the potential of BLEEP to provide insights into the molecular mechanisms underlying tissue architecture, with important implications in diagnosis and research of various diseases. The proposed framework can significantly reduce the time and cost associated with gene expression profiling, opening up new avenues for high-throughput analysis of histology images for both research and clinical applications. ",
    "url": "https://arxiv.org/abs/2306.01859",
    "authors": [
      "Ronald Xie",
      "Kuan Pang",
      "Gary D. Bader",
      "Bo Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01862",
    "title": "Systemic Risk and Vulnerability Analysis of Multi-cloud Environments",
    "abstract": "With the increasing use of multi-cloud environments, security professionals face challenges in configuration, management, and integration due to uneven security capabilities and features among providers. As a result, a fragmented approach toward security has been observed, leading to new attack vectors and potential vulnerabilities. Other research has focused on single-cloud platforms or specific applications of multi-cloud environments. Therefore, there is a need for a holistic security and vulnerability assessment and defense strategy that applies to multi-cloud platforms. We perform a risk and vulnerability analysis to identify attack vectors from software, hardware, and the network, as well as interoperability security issues in multi-cloud environments. Applying the STRIDE and DREAD threat modeling methods, we present an analysis of the ecosystem across six attack vectors: cloud architecture, APIs, authentication, automation, management differences, and cybersecurity legislation. We quantitatively determine and rank the threats in multi-cloud environments and suggest mitigation strategies. ",
    "url": "https://arxiv.org/abs/2306.01862",
    "authors": [
      "Morgan Reece",
      "Theodore Edward Lander Jr.",
      "Matthew Stoffolano",
      "Andy Sampson",
      "Josiah Dykstra",
      "Sudip Mittal",
      "Nidhi Rastogi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.01863",
    "title": "Embedding Security into Ferroelectric FET Array via In-Situ Memory  Operation",
    "abstract": "Non-volatile memories (NVMs) have the potential to reshape next-generation memory systems because of their promising properties of near-zero leakage power consumption, high density and non-volatility. However, NVMs also face critical security threats that exploit the non-volatile property. Compared to volatile memory, the capability of retaining data even after power down makes NVM more vulnerable. Existing solutions to address the security issues of NVMs are mainly based on Advanced Encryption Standard (AES), which incurs significant performance and power overhead. In this paper, we propose a lightweight memory encryption/decryption scheme by exploiting in-situ memory operations with negligible overhead. To validate the feasibility of the encryption/decryption scheme, device-level and array-level experiments are performed using ferroelectric field effect transistor (FeFET) as an example NVM without loss of generality. Besides, a comprehensive evaluation is performed on a 128x128 FeFET AND-type memory array in terms of area, latency, power and throughput. Compared with the AES-based scheme, our scheme shows around 22.6x/14.1x increase in encryption/decryption throughput with negligible power penalty. Furthermore, we evaluate the performance of our scheme over the AES-based scheme when deploying different neural network workloads. Our scheme yields significant latency reduction by 90% on average for encryption and decryption processes. ",
    "url": "https://arxiv.org/abs/2306.01863",
    "authors": [
      "Yixin Xu",
      "Yi Xiao",
      "Zijian Zhao",
      "Franz M\u00fcller",
      "Alptekin Vardar",
      "Xiao Gong",
      "Sumitha George",
      "Thomas K\u00e4mpfe",
      "Vijaykrishnan Narayanan",
      "Kai Ni"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2306.01867",
    "title": "Revisiting Garg's 2-Approximation Algorithm for the k-MST Problem in  Graphs",
    "abstract": "This paper revisits the 2-approximation algorithm for $k$-MST presented by Garg in light of a recent paper of Paul et al.. In the $k$-MST problem, the goal is to return a tree spanning $k$ vertices of minimum total edge cost. Paul et al. extend Garg's primal-dual subroutine to improve the approximation ratios for the budgeted prize-collecting traveling salesman and minimum spanning tree problems. We follow their algorithm and analysis to provide a cleaner version of Garg's result. Additionally, we introduce the novel concept of a kernel which allows an easier visualization of the stages of the algorithm and a clearer understanding of the pruning phase. Other notable updates include presenting a linear programming formulation of the $k$-MST problem, including pseudocode, replacing the coloring scheme used by Garg with the simpler concept of neutral sets, and providing an explicit potential function. ",
    "url": "https://arxiv.org/abs/2306.01867",
    "authors": [
      "Emmett Breen",
      "Renee Mirka",
      "Zichen Wang",
      "David P. Williamson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.01870",
    "title": "Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks",
    "abstract": "In the quest to enhance the efficiency and bio-plausibility of training deep neural networks, Feedback Alignment (FA), which replaces the backward pass weights with random matrices in the training process, has emerged as an alternative to traditional backpropagation. While the appeal of FA lies in its circumvention of computational challenges and its plausible biological alignment, the theoretical understanding of this learning rule remains partial. This paper uncovers a set of conservation laws underpinning the learning dynamics of FA, revealing intriguing parallels between FA and Gradient Descent (GD). Our analysis reveals that FA harbors implicit biases akin to those exhibited by GD, challenging the prevailing narrative that these learning algorithms are fundamentally different. Moreover, we demonstrate that these conservation laws elucidate sufficient conditions for layer-wise alignment with feedback matrices in ReLU networks. We further show that this implies over-parameterized two-layer linear networks trained with FA converge to minimum-norm solutions. The implications of our findings offer avenues for developing more efficient and biologically plausible alternatives to backpropagation through an understanding of the principles governing learning dynamics in deep networks. ",
    "url": "https://arxiv.org/abs/2306.01870",
    "authors": [
      "Zachary Robertson",
      "Oluwasanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01874",
    "title": "SACSoN: Scalable Autonomous Data Collection for Social Navigation",
    "abstract": "Machine learning provides a powerful tool for building socially compliant robotic systems that go beyond simple predictive models of human behavior. By observing and understanding human interactions from past experiences, learning can enable effective social navigation behaviors directly from data. However, collecting navigation data in human-occupied environments may require teleoperation or continuous monitoring, making the process prohibitively expensive to scale. In this paper, we present a scalable data collection system for vision-based navigation, SACSoN, that can autonomously navigate around pedestrians in challenging real-world environments while encouraging rich interactions. SACSoN uses visual observations to observe and react to humans in its vicinity. It couples this visual understanding with continual learning and an autonomous collision recovery system that limits the involvement of a human operator, allowing for better dataset scaling. We use a this system to collect the SACSoN dataset, the largest-of-its-kind visual navigation dataset of autonomous robots operating in human-occupied spaces, spanning over 75 hours and 4000 rich interactions with humans. Our experiments show that collecting data with a novel objective that encourages interactions, leads to significant improvements in downstream tasks such as inferring pedestrian dynamics and learning socially compliant navigation behaviors. We make videos of our autonomous data collection system and the SACSoN dataset publicly available on our project page. ",
    "url": "https://arxiv.org/abs/2306.01874",
    "authors": [
      "Noriaki Hirose",
      "Dhruv Shah",
      "Ajay Sridhar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01899",
    "title": "Discrete-time Robust PD Controlled System with DOB/CDOB Compensation for  High Speed Autonomous Vehicle Path Following",
    "abstract": "Autonomous vehicle path following performance is one of significant consideration. This paper presents discrete time design of robust PD controlled system with disturbance observer (DOB) and communication disturbance observer (CDOB) compensation to enhance autonomous vehicle path following performance. Although always implemented on digital devices, DOB and CDOB structure are usually designed in continuous time in the literature and also in our previous work. However, it requires high sampling rate for continuous-time design block diagram to automatically convert to corresponding discrete-time controller using rapid controller prototyping systems. In this paper, direct discrete time design is carried out. Digital PD feedback controller is designed based on the nominal plant using the proposed parameter space approach. Zero order hold method is applied to discretize the nominal plant, DOB and CDOB structure in continuous domain. Discrete time DOB is embedded into the steering to path following error loop for model regulation in the presence of uncertainty in vehicle parameters such as vehicle mass, vehicle speed and road-tire friction coefficient and rejecting external disturbance like crosswind force. On the other hand, time delay from CAN bus based sensor and actuator command interfaces results in degradation of system performance since large negative phase angles are added to the plant frequency response. Discrete time CDOB compensated control system can be used for time delay compensation where the accurate knowledge of delay time value is not necessary. A validated model of our lab Ford Fusion hybrid automated driving research vehicle is used for the simulation analysis while the vehicle is driving at high speed. Simulation results successfully demonstrate the improvement of autonomous vehicle path following performance with the proposed discrete time DOB and CDOB structure. ",
    "url": "https://arxiv.org/abs/2306.01899",
    "authors": [
      "Haoan Wang",
      "Levent Guvenc"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.01906",
    "title": "Synaptic motor adaptation: A three-factor learning rule for adaptive  robotic control in spiking neural networks",
    "abstract": "Legged robots operating in real-world environments must possess the ability to rapidly adapt to unexpected conditions, such as changing terrains and varying payloads. This paper introduces the Synaptic Motor Adaptation (SMA) algorithm, a novel approach to achieving real-time online adaptation in quadruped robots through the utilization of neuroscience-derived rules of synaptic plasticity with three-factor learning. To facilitate rapid adaptation, we meta-optimize a three-factor learning rule via gradient descent to adapt to uncertainty by approximating an embedding produced by privileged information using only locally accessible onboard sensing data. Our algorithm performs similarly to state-of-the-art motor adaptation algorithms and presents a clear path toward achieving adaptive robotics with neuromorphic hardware. ",
    "url": "https://arxiv.org/abs/2306.01906",
    "authors": [
      "Samuel Schmidgall",
      "Joe Hays"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.01913",
    "title": "PDT: Pretrained Dual Transformers for Time-aware Bipartite Graphs",
    "abstract": "Pre-training on large models is prevalent and emerging with the ever-growing user-generated content in many machine learning application categories. It has been recognized that learning contextual knowledge from the datasets depicting user-content interaction plays a vital role in downstream tasks. Despite several studies attempting to learn contextual knowledge via pre-training methods, finding an optimal training objective and strategy for this type of task remains a challenging problem. In this work, we contend that there are two distinct aspects of contextual knowledge, namely the user-side and the content-side, for datasets where user-content interaction can be represented as a bipartite graph. To learn contextual knowledge, we propose a pre-training method that learns a bi-directional mapping between the spaces of the user-side and the content-side. We formulate the training goal as a contrastive learning task and propose a dual-Transformer architecture to encode the contextual knowledge. We evaluate the proposed method for the recommendation task. The empirical studies have demonstrated that the proposed method outperformed all the baselines with significant gains. ",
    "url": "https://arxiv.org/abs/2306.01913",
    "authors": [
      "Xin Dai",
      "Yujie Fan",
      "Zhongfang Zhuang",
      "Shubham Jain",
      "Chin-Chia Michael Yeh",
      "Junpeng Wang",
      "Liang Wang",
      "Yan Zheng",
      "Wei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01920",
    "title": "Context-Aware Bayesian Network Actor-Critic Methods for Cooperative  Multi-Agent Reinforcement Learning",
    "abstract": "Executing actions in a correlated manner is a common strategy for human coordination that often leads to better cooperation, which is also potentially beneficial for cooperative multi-agent reinforcement learning (MARL). However, the recent success of MARL relies heavily on the convenient paradigm of purely decentralized execution, where there is no action correlation among agents for scalability considerations. In this work, we introduce a Bayesian network to inaugurate correlations between agents' action selections in their joint policy. Theoretically, we establish a theoretical justification for why action dependencies are beneficial by deriving the multi-agent policy gradient formula under such a Bayesian network joint policy and proving its global convergence to Nash equilibria under tabular softmax policy parameterization in cooperative Markov games. Further, by equipping existing MARL algorithms with a recent method of differentiable directed acyclic graphs (DAGs), we develop practical algorithms to learn the context-aware Bayesian network policies in scenarios with partial observability and various difficulty. We also dynamically decrease the sparsity of the learned DAG throughout the training process, which leads to weakly or even purely independent policies for decentralized execution. Empirical results on a range of MARL benchmarks show the benefits of our approach. ",
    "url": "https://arxiv.org/abs/2306.01920",
    "authors": [
      "Dingyang Chen",
      "Qi Zhang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01925",
    "title": "Improving the generalizability and robustness of large-scale traffic  signal control",
    "abstract": "A number of deep reinforcement-learning (RL) approaches propose to control traffic signals. In this work, we study the robustness of such methods along two axes. First, sensor failures and GPS occlusions create missing-data challenges and we show that recent methods remain brittle in the face of these missing data. Second, we provide a more systematic study of the generalization ability of RL methods to new networks with different traffic regimes. Again, we identify the limitations of recent approaches. We then propose using a combination of distributional and vanilla reinforcement learning through a policy ensemble. Building upon the state-of-the-art previous model which uses a decentralized approach for large-scale traffic signal control with graph convolutional networks (GCNs), we first learn models using a distributional reinforcement learning (DisRL) approach. In particular, we use implicit quantile networks (IQN) to model the state-action return distribution with quantile regression. For traffic signal control problems, an ensemble of standard RL and DisRL yields superior performance across different scenarios, including different levels of missing sensor data and traffic flow patterns. Furthermore, the learning scheme of the resulting model can improve zero-shot transferability to different road network structures, including both synthetic networks and real-world networks (e.g., Luxembourg, Manhattan). We conduct extensive experiments to compare our approach to multi-agent reinforcement learning and traditional transportation approaches. Results show that the proposed method improves robustness and generalizability in the face of missing data, varying road networks, and traffic flows. ",
    "url": "https://arxiv.org/abs/2306.01925",
    "authors": [
      "Tianyu Shi",
      "Francois-Xavier Devailly",
      "Denis Larocque",
      "Laurent Charlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01931",
    "title": "Exploring semantic information in disease: Simple Data Augmentation  Techniques for Chinese Disease Normalization",
    "abstract": "The disease is a core concept in the medical field, and the task of normalizing disease names is the basis of all disease-related tasks. However, due to the multi-axis and multi-grain nature of disease names, incorrect information is often injected and harms the performance when using general text data augmentation techniques. To address the above problem, we propose a set of data augmentation techniques that work together as an augmented training task for disease normalization. Our data augmentation methods are based on both the clinical disease corpus and standard disease corpus derived from ICD-10 coding. Extensive experiments are conducted to show the effectiveness of our proposed methods. The results demonstrate that our methods can have up to 3\\% performance gain compared to non-augmented counterparts, and they can work even better on smaller datasets. ",
    "url": "https://arxiv.org/abs/2306.01931",
    "authors": [
      "Wenqian Cui",
      "Shaohui Liu",
      "Xiangling Fu",
      "Xien Liu",
      "Ji Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01937",
    "title": "LIC-GAN: Language Information Conditioned Graph Generative GAN Model",
    "abstract": "Deep generative models for Natural Language data offer a new angle on the problem of graph synthesis: by optimizing differentiable models that directly generate graphs, it is possible to side-step expensive search procedures in the discrete and vast space of possible graphs. We introduce LIC-GAN, an implicit, likelihood-free generative model for small graphs that circumvents the need for expensive graph matching procedures. Our method takes as input a natural language query and using a combination of language modelling and Generative Adversarial Networks (GANs) and returns a graph that closely matches the description of the query. We combine our approach with a reward network to further enhance the graph generation with desired properties. Our experiments, show that LIC-GAN does well on metrics such as PropMatch and Closeness getting scores of 0.36 and 0.48. We also show that LIC-GAN performs as good as ChatGPT, with ChatGPT getting scores of 0.40 and 0.42. We also conduct a few experiments to demonstrate the robustness of our method, while also highlighting a few interesting caveats of the model. ",
    "url": "https://arxiv.org/abs/2306.01937",
    "authors": [
      "Robert Lo",
      "Arnhav Datar",
      "Abishek Sridhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01938",
    "title": "Self-supervised Interest Point Detection and Description for Fisheye and  Perspective Images",
    "abstract": "Keypoint detection and matching is a fundamental task in many computer vision problems, from shape reconstruction, to structure from motion, to AR/VR applications and robotics. It is a well-studied problem with remarkable successes such as SIFT, and more recent deep learning approaches. While great robustness is exhibited by these techniques with respect to noise, illumination variation, and rigid motion transformations, less attention has been placed on image distortion sensitivity. In this work, we focus on the case when this is caused by the geometry of the cameras used for image acquisition, and consider the keypoint detection and matching problem between the hybrid scenario of a fisheye and a projective image. We build on a state-of-the-art approach and derive a self-supervised procedure that enables training an interest point detector and descriptor network. We also collected two new datasets for additional training and testing in this unexplored scenario, and we demonstrate that current approaches are suboptimal because they are designed to work in traditional projective conditions, while the proposed approach turns out to be the most effective. ",
    "url": "https://arxiv.org/abs/2306.01938",
    "authors": [
      "Marcela Mera-Trujillo",
      "Shivang Patel",
      "Yu Gu",
      "Gianfranco Doretto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.01951",
    "title": "GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction",
    "abstract": "Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes within graphs, finding applications in network security, fraud detection, social media spam detection, and various other domains. A common method for GAD is Graph Auto-Encoders (GAEs), which encode graph data into node representations and identify anomalies by assessing the reconstruction quality of the graphs based on these representations. However, existing GAE models are primarily optimized for direct link reconstruction, resulting in nodes connected in the graph being clustered in the latent space. As a result, they excel at detecting cluster-type structural anomalies but struggle with more complex structural anomalies that do not conform to clusters. To address this limitation, we propose a novel solution called GAD-NR, a new variant of GAE that incorporates neighborhood reconstruction for graph anomaly detection. GAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the local structure, self-attributes, and neighbor attributes, based on the corresponding node representation. By comparing the neighborhood reconstruction loss between anomalous nodes and normal nodes, GAD-NR can effectively detect any anomalies. Extensive experimentation conducted on six real-world datasets validates the effectiveness of GAD-NR, showcasing significant improvements (by up to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR is openly available. Importantly, the comparative analysis reveals that the existing methods perform well only in detecting one or two types of anomalies out of the three types studied. In contrast, GAD-NR excels at detecting all three types of anomalies across the datasets, demonstrating its comprehensive anomaly detection capabilities. ",
    "url": "https://arxiv.org/abs/2306.01951",
    "authors": [
      "Amit Roy",
      "Juan Shu",
      "Jia Li",
      "Carl Yang",
      "Olivier Elshocht",
      "Jeroen Smeets",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01958",
    "title": "A Survey on Explainability of Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) are powerful graph-based deep-learning models that have gained significant attention and demonstrated remarkable performance in various domains, including natural language processing, drug discovery, and recommendation systems. However, combining feature information and combinatorial graph structures has led to complex non-linear GNN models. Consequently, this has increased the challenges of understanding the workings of GNNs and the underlying reasons behind their predictions. To address this, numerous explainability methods have been proposed to shed light on the inner mechanism of the GNNs. Explainable GNNs improve their security and enhance trust in their recommendations. This survey aims to provide a comprehensive overview of the existing explainability techniques for GNNs. We create a novel taxonomy and hierarchy to categorize these methods based on their objective and methodology. We also discuss the strengths, limitations, and application scenarios of each category. Furthermore, we highlight the key evaluation metrics and datasets commonly used to assess the explainability of GNNs. This survey aims to assist researchers and practitioners in understanding the existing landscape of explainability methods, identifying gaps, and fostering further advancements in interpretable graph-based machine learning. ",
    "url": "https://arxiv.org/abs/2306.01958",
    "authors": [
      "Jaykumar Kakkad",
      "Jaspal Jannu",
      "Kartik Sharma",
      "Charu Aggarwal",
      "Sourav Medya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01970",
    "title": "Temporal-spatial Correlation Attention Network for Clinical Data  Analysis in Intensive Care Unit",
    "abstract": "In recent years, medical information technology has made it possible for electronic health record (EHR) to store fairly complete clinical data. This has brought health care into the era of \"big data\". However, medical data are often sparse and strongly correlated, which means that medical problems cannot be solved effectively. With the rapid development of deep learning in recent years, it has provided opportunities for the use of big data in healthcare. In this paper, we propose a temporal-saptial correlation attention network (TSCAN) to handle some clinical characteristic prediction problems, such as predicting death, predicting length of stay, detecting physiologic decline, and classifying phenotypes. Based on the design of the attention mechanism model, our approach can effectively remove irrelevant items in clinical data and irrelevant nodes in time according to different tasks, so as to obtain more accurate prediction results. Our method can also find key clinical indicators of important outcomes that can be used to improve treatment options. Our experiments use information from the Medical Information Mart for Intensive Care (MIMIC-IV) database, which is open to the public. Finally, we have achieved significant performance benefits of 2.0\\% (metric) compared to other SOTA prediction methods. We achieved a staggering 90.7\\% on mortality rate, 45.1\\% on length of stay. The source code can be find: \\url{https://github.com/yuyuheintju/TSCAN}. ",
    "url": "https://arxiv.org/abs/2306.01970",
    "authors": [
      "Weizhi Nie",
      "Yuhe Yu",
      "Chen Zhang",
      "Dan Song",
      "Lina Zhao",
      "Yunpeng Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2306.01983",
    "title": "Mitigating Backdoor Attack Via Prerequisite Transformation",
    "abstract": "In recent years, with the successful application of DNN in fields such as NLP and CV, its security has also received widespread attention. (Author) proposed the method of backdoor attack in Badnet. Switch implanted backdoor into the model by poisoning the training samples. The model with backdoor did not exhibit any abnormalities on the normal validation sample set, but in the input with trigger, they were mistakenly classified as the attacker's designated category or randomly classified as a different category from the ground truth, This attack method seriously threatens the normal application of DNN in real life, such as autonomous driving, object detection, etc.This article proposes a new method to combat backdoor attacks. We refer to the features in the area covered by the trigger as trigger features, and the remaining areas as normal features. By introducing prerequisite calculation conditions during the training process, these conditions have little impact on normal features and trigger features, and can complete the training of a standard backdoor model. The model trained under these prerequisite calculation conditions can, In the verification set D'val with the same premise calculation conditions, the performance is consistent with that of the ordinary backdoor model. However, in the verification set Dval without the premise calculation conditions, the verification accuracy decreases very little (7%~12%), while the attack success rate (ASR) decreases from 90% to about 8%.Author call this method Prerequisite Transformation(PT). ",
    "url": "https://arxiv.org/abs/2306.01983",
    "authors": [
      "Han Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01988",
    "title": "Lightweight Structure-aware Transformer Network for VHR Remote Sensing  Image Change Detection",
    "abstract": "Popular Transformer networks have been successfully applied to remote sensing (RS) image change detection (CD) identifications and achieve better results than most convolutional neural networks (CNNs), but they still suffer from two main problems. First, the computational complexity of the Transformer grows quadratically with the increase of image spatial resolution, which is unfavorable to very high-resolution (VHR) RS images. Second, these popular Transformer networks tend to ignore the importance of fine-grained features, which results in poor edge integrity and internal tightness for largely changed objects and leads to the loss of small changed objects. To address the above issues, this Letter proposes a Lightweight Structure-aware Transformer (LSAT) network for RS image CD. The proposed LSAT has two advantages. First, a Cross-dimension Interactive Self-attention (CISA) module with linear complexity is designed to replace the vanilla self-attention in visual Transformer, which effectively reduces the computational complexity while improving the feature representation ability of the proposed LSAT. Second, a Structure-aware Enhancement Module (SAEM) is designed to enhance difference features and edge detail information, which can achieve double enhancement by difference refinement and detail aggregation so as to obtain fine-grained features of bi-temporal RS images. Experimental results show that the proposed LSAT achieves significant improvement in detection accuracy and offers a better tradeoff between accuracy and computational costs than most state-of-the-art CD methods for VHR RS images. ",
    "url": "https://arxiv.org/abs/2306.01988",
    "authors": [
      "Tao Lei",
      "Yetong Xu",
      "Hailong Ning",
      "Zhiyong Lv",
      "Chongdan Min",
      "Yaochu Jin",
      "Asoke K. Nandi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01991",
    "title": "A Bio-Inspired Chaos Sensor Based on the Perceptron Neural Network:  Concept and Application for Computational Neuro-science",
    "abstract": "The study presents a bio-inspired chaos sensor based on the perceptron neural network. After training, the sensor on perceptron, having 50 neurons in the hidden layer and 1 neuron at the output, approximates the fuzzy entropy of short time series with high accuracy with a determination coefficient R2 ~ 0.9. The Hindmarsh-Rose spike model was used to generate time series of spike intervals, and datasets for training and testing the perceptron. The selection of the hyperparameters of the perceptron model and the estimation of the sensor accuracy were performed using the K-block cross-validation method. Even for a hidden layer with 1 neuron, the model approximates the fuzzy entropy with good results and the metric R2 ~ 0.5-0.8. In a simplified model with 1 neuron and equal weights in the first layer, the principle of approximation is based on the linear transformation of the average value of the time series into the entropy value. The bio-inspired chaos sensor model based on an ensemble of neurons is able to dynamically track the chaotic behavior of a spiked biosystem and transmit this information to other parts of the bio-system for further processing. The study will be useful for specialists in the field of computational neuroscience. ",
    "url": "https://arxiv.org/abs/2306.01991",
    "authors": [
      "Andrei Velichko",
      "Petr Boriskov",
      "Maksim Belyaev",
      "Vadim Putrolaynen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2306.01992",
    "title": "On Size-Independent Sample Complexity of ReLU Networks",
    "abstract": "We study the sample complexity of learning ReLU neural networks from the point of view of generalization. Given norm constraints on the weight matrices, a common approach is to estimate the Rademacher complexity of the associated function class. Previously Golowich-Rakhlin-Shamir (2020) obtained a bound independent of the network size (scaling with a product of Frobenius norms) except for a factor of the square-root depth. We give a refinement which often has no explicit depth-dependence at all. ",
    "url": "https://arxiv.org/abs/2306.01992",
    "authors": [
      "Mark Sellke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01997",
    "title": "UADB: Unsupervised Anomaly Detection Booster",
    "abstract": "Unsupervised Anomaly Detection (UAD) is a key data mining problem owing to its wide real-world applications. Due to the complete absence of supervision signals, UAD methods rely on implicit assumptions about anomalous patterns (e.g., scattered/sparsely/densely clustered) to detect anomalies. However, real-world data are complex and vary significantly across different domains. No single assumption can describe such complexity and be valid in all scenarios. This is also confirmed by recent research that shows no UAD method is omnipotent. Based on above observations, instead of searching for a magic universal winner assumption, we seek to design a general UAD Booster (UADB) that empowers any UAD models with adaptability to different data. This is a challenging task given the heterogeneous model structures and assumptions adopted by existing UAD methods. To achieve this, we dive deep into the UAD problem and find that compared to normal data, anomalies (i) lack clear structure/pattern in feature space, thus (ii) harder to learn by model without a suitable assumption, and finally, leads to (iii) high variance between different learners. In light of these findings, we propose to (i) distill the knowledge of the source UAD model to an imitation learner (booster) that holds no data assumption, then (ii) exploit the variance between them to perform automatic correction, and thus (iii) improve the booster over the original UAD model. We use a neural network as the booster for its strong expressive power as a universal approximator and ability to perform flexible post-hoc tuning. Note that UADB is a model-agnostic framework that can enhance heterogeneous UAD models in a unified way. Extensive experiments on over 80 tabular datasets demonstrate the effectiveness of UADB. ",
    "url": "https://arxiv.org/abs/2306.01997",
    "authors": [
      "Hangting Ye",
      "Zhining Liu",
      "Xinyi Shen",
      "Wei Cao",
      "Shun Zheng",
      "Xiaofan Gui",
      "Huishuai Zhang",
      "Yi Chang",
      "Jiang Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01999",
    "title": "GAT-GAN : A Graph-Attention-based Time-Series Generative Adversarial  Network",
    "abstract": "Generative Adversarial Networks (GANs) have proven to be a powerful tool for generating realistic synthetic data. However, traditional GANs often struggle to capture complex relationships between features which results in generation of unrealistic multivariate time-series data. In this paper, we propose a Graph-Attention-based Generative Adversarial Network (GAT-GAN) that explicitly includes two graph-attention layers, one that learns temporal dependencies while the other captures spatial relationships. Unlike RNN-based GANs that struggle with modeling long sequences of data points, GAT-GAN generates long time-series data of high fidelity using an adversarially trained autoencoder architecture. Our empirical evaluations, using a variety of real-time-series datasets, show that our framework consistently outperforms state-of-the-art benchmarks based on \\emph{Frechet Transformer distance} and \\emph{Predictive score}, that characterizes (\\emph{Fidelity, Diversity}) and \\emph{predictive performance} respectively. Moreover, we introduce a Frechet Inception distance-like (FID) metric for time-series data called Frechet Transformer distance (FTD) score (lower is better), to evaluate the quality and variety of generated data. We also found that low FTD scores correspond to the best-performing downstream predictive experiments. Hence, FTD scores can be used as a standardized metric to evaluate synthetic time-series data. ",
    "url": "https://arxiv.org/abs/2306.01999",
    "authors": [
      "Srikrishna Iyer",
      "Teng Teck Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02002",
    "title": "Can Directed Graph Neural Networks be Adversarially Robust?",
    "abstract": "The existing research on robust Graph Neural Networks (GNNs) fails to acknowledge the significance of directed graphs in providing rich information about networks' inherent structure. This work presents the first investigation into the robustness of GNNs in the context of directed graphs, aiming to harness the profound trust implications offered by directed graphs to bolster the robustness and resilience of GNNs. Our study reveals that existing directed GNNs are not adversarially robust. In pursuit of our goal, we introduce a new and realistic directed graph attack setting and propose an innovative, universal, and efficient message-passing framework as a plug-in layer to significantly enhance the robustness of GNNs. Combined with existing defense strategies, this framework achieves outstanding clean accuracy and state-of-the-art robust performance, offering superior defense against both transfer and adaptive attacks. The findings in this study reveal a novel and promising direction for this crucial research area. The code will be made publicly available upon the acceptance of this work. ",
    "url": "https://arxiv.org/abs/2306.02002",
    "authors": [
      "Zhichao Hou",
      "Xitong Zhang",
      "Wei Wang",
      "Charu C. Aggarwal",
      "Xiaorui Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.02014",
    "title": "Uncovering the Hidden Dynamics of Video Self-supervised Learning under  Distribution Shifts",
    "abstract": "Video self-supervised learning (VSSL) has made significant progress in recent years. However, the exact behavior and dynamics of these models under different forms of distribution shift are not yet known. In this paper, we comprehensively study the behavior of six popular self-supervised methods (v-SimCLR, v-MOCO, v-BYOL, v-SimSiam, v-DINO, v-MAE) in response to various forms of natural distribution shift, i.e., (i) context shift, (ii) viewpoint shift, (iii) actor shift, (iv) source shift, (v) generalizability to unknown classes (zero-shot), and (vi) open-set recognition. To perform this extensive study, we carefully craft a test bed consisting of $17$ in-distribution and out-of-distribution benchmark pairs using available public datasets and a series of evaluation protocols to stress-test the different methods under the intended shifts. Our study uncovers a series of intriguing findings and interesting behaviors of VSSL methods. For instance, we observe that while video models generally struggle with context shifts, v-MAE and supervised learning exhibit more robustness. Moreover, our study shows that v-MAE is a strong temporal learner, whereas contrastive methods, v-SimCLR and v-MOCO, exhibit strong performances against viewpoint shifts. When studying the notion of open-set recognition, we notice a trade-off between closed-set and open-set recognition performance, particularly if the pretrained VSSL encoders are used without finetuning. We hope that our work will contribute to the development of robust video representation learning frameworks for various real-world scenarios. ",
    "url": "https://arxiv.org/abs/2306.02014",
    "authors": [
      "Pritam Sarkar",
      "Ahmad Beirami",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02017",
    "title": "Resilient Distributed Parameter Estimation in Sensor Networks",
    "abstract": "In this paper, we study the problem of parameter estimation in a sensor network, where the measurements and updates of some sensors might be arbitrarily manipulated by adversaries. Despite the presence of such misbehaviors, normally behaving sensors make successive observations of an unknown $d$-dimensional vector parameter and aim to infer its true value by cooperating with their neighbors over a directed communication graph. To this end, by leveraging the so-called dynamic regressor extension and mixing procedure, we transform the problem of estimating the vector parameter to that of estimating $d$ scalar ones. For each of the scalar problem, we propose a resilient combine-then-adapt diffusion algorithm, where each normal sensor performs a resilient combination to discard the suspicious estimates in its neighborhood and to fuse the remaining values, alongside an adaptation step to process its streaming observations. With a low computational cost, this estimator guarantees that each normal sensor exponentially infers the true parameter even if some of them are not sufficiently excited. ",
    "url": "https://arxiv.org/abs/2306.02017",
    "authors": [
      "Jiaqi Yan",
      "Kuo Li",
      "Hideaki Ishii"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.02019",
    "title": "Generative Adversarial Networks for Data Augmentation",
    "abstract": "One way to expand the available dataset for training AI models in the medical field is through the use of Generative Adversarial Networks (GANs) for data augmentation. GANs work by employing a generator network to create new data samples that are then assessed by a discriminator network to determine their similarity to real samples. The discriminator network is taught to differentiate between actual and synthetic samples, while the generator system is trained to generate data that closely resemble real ones. The process is repeated until the generator network can produce synthetic data that is indistinguishable from genuine data. GANs have been utilized in medical image analysis for various tasks, including data augmentation, image creation, and domain adaptation. They can generate synthetic samples that can be used to increase the available dataset, especially in cases where obtaining large amounts of genuine data is difficult or unethical. However, it is essential to note that the use of GANs in medical imaging is still an active area of research to ensure that the produced images are of high quality and suitable for use in clinical settings. ",
    "url": "https://arxiv.org/abs/2306.02019",
    "authors": [
      "Angona Biswas",
      "MD Abdullah Al Nasim",
      "Al Imran",
      "Anika Tabassum Sejuty",
      "Fabliha Fairooz",
      "Sai Puppala",
      "Sajedul Talukder"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02020",
    "title": "Replay Attack Detection Based on Parity Space Method for Cyber-Physical  Systems",
    "abstract": "The replay attack detection problem is studied from a new perspective based on parity space method in this paper. The proposed detection methods have the ability to distinguish system fault and replay attack, handle both input and output data replay, maintain certain control performance, and can be implemented conveniently and efficiently. First, the replay attack effect on the residual is derived and analyzed. The residual change induced by replay attack is characterized explicitly and the detection performance analysis based on two different test statistics are given. Second, based on the replay attack effect characterization, targeted passive and active design for detection performance enhancement are proposed. Regarding the passive design, four optimization schemes regarding different cost functions are proposed with optimal parity matrix solutions, and the unified solution to the passive optimization schemes is obtained; the active design is enabled by a marginally stable filter so as to enlarge the replay attack effect on the residual for detection. Simulations and comparison studies are given to show the effectiveness of the proposed methods. ",
    "url": "https://arxiv.org/abs/2306.02020",
    "authors": [
      "Dong Zhao",
      "Yang Shi",
      "Steven X. Ding",
      "Yueyang Li",
      "Fangzhou Fu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.02021",
    "title": "Towards Black-box Adversarial Example Detection: A Data  Reconstruction-based Method",
    "abstract": "Adversarial example detection is known to be an effective adversarial defense method. Black-box attack, which is a more realistic threat and has led to various black-box adversarial training-based defense methods, however, does not attract considerable attention in adversarial example detection. In this paper, we fill this gap by positioning the problem of black-box adversarial example detection (BAD). Data analysis under the introduced BAD settings demonstrates (1) the incapability of existing detectors in addressing the black-box scenario and (2) the potential of exploring BAD solutions from a data perspective. To tackle the BAD problem, we propose a data reconstruction-based adversarial example detection method. Specifically, we use variational auto-encoder (VAE) to capture both pixel and frequency representations of normal examples. Then we use reconstruction error to detect adversarial examples. Compared with existing detection methods, the proposed method achieves substantially better detection performance in BAD, which helps promote the deployment of adversarial example detection-based defense solutions in real-world models. ",
    "url": "https://arxiv.org/abs/2306.02021",
    "authors": [
      "Yifei Gao",
      "Zhiyu Lin",
      "Yunfan Yang",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02025",
    "title": "Exploring Global and Local Information for Anomaly Detection with Normal  Samples",
    "abstract": "Anomaly detection aims to detect data that do not conform to regular patterns, and such data is also called outliers. The anomalies to be detected are often tiny in proportion, containing crucial information, and are suitable for application scenes like intrusion detection, fraud detection, fault diagnosis, e-commerce platforms, et al. However, in many realistic scenarios, only the samples following normal behavior are observed, while we can hardly obtain any anomaly information. To address such problem, we propose an anomaly detection method GALDetector which is combined of global and local information based on observed normal samples. The proposed method can be divided into a three-stage method. Firstly, the global similar normal scores and the local sparsity scores of unlabeled samples are computed separately. Secondly, potential anomaly samples are separated from the unlabeled samples corresponding to these two scores and corresponding weights are assigned to the selected samples. Finally, a weighted anomaly detector is trained by loads of samples, then the detector is utilized to identify else anomalies. To evaluate the effectiveness of the proposed method, we conducted experiments on three categories of real-world datasets from diverse domains, and experimental results show that our method achieves better performance when compared with other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2306.02025",
    "authors": [
      "Fan Xu",
      "Nan Wang",
      "Xibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02029",
    "title": "Model-aided Federated Reinforcement Learning for Multi-UAV Trajectory  Planning in IoT Networks",
    "abstract": "Deploying teams of cooperative unmanned aerial vehicles (UAVs) to harvest data from distributed Internet of Things (IoT) devices requires efficient trajectory planning and coordination algorithms. Multi-agent reinforcement learning (MARL) has emerged as an effective solution, but often requires extensive and costly real-world training data. In this paper, we propose a novel model-aided federated MARL algorithm to coordinate multiple UAVs on a data harvesting mission with limited knowledge about the environment, significantly reducing the real-world training data demand. The proposed algorithm alternates between learning an environment model from real-world measurements and federated QMIX training in the simulated environment. Specifically, collected measurements from the real-world environment are used to learn the radio channel and estimate unknown IoT device locations to create a simulated environment. Each UAV agent trains a local QMIX model in its simulated environment and continuously consolidates it through federated learning with other agents, accelerating the learning process and further improving training sample efficiency. Simulation results demonstrate that our proposed model-aided FedQMIX algorithm substantially reduces the need for real-world training experiences while attaining similar data collection performance as standard MARL algorithms. ",
    "url": "https://arxiv.org/abs/2306.02029",
    "authors": [
      "Jichao Chen",
      "Omid Esrafilian",
      "Harald Bayerlein",
      "David Gesbert",
      "Marco Caccamo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02031",
    "title": "DOS: Diverse Outlier Sampling for Out-of-Distribution Detection",
    "abstract": "Modern neural networks are known to give overconfident prediction for out-of-distribution inputs when deployed in the open world. It is common practice to leverage a surrogate outlier dataset to regularize the model during training, and recent studies emphasize the role of uncertainty in designing the sampling strategy for outlier dataset. However, the OOD samples selected solely based on predictive uncertainty can be biased towards certain types, which may fail to capture the full outlier distribution. In this work, we empirically show that diversity is critical in sampling outliers for OOD detection performance. Motivated by the observation, we propose a straightforward and novel sampling strategy named DOS (Diverse Outlier Sampling) to select diverse and informative outliers. Specifically, we cluster the normalized features at each iteration, and the most informative outlier from each cluster is selected for model training with absent category loss. With DOS, the sampled outliers efficiently shape a globally compact decision boundary between ID and OOD data. Extensive experiments demonstrate the superiority of DOS, reducing the average FPR95 by up to 25.79% on CIFAR-100 with TI-300K. ",
    "url": "https://arxiv.org/abs/2306.02031",
    "authors": [
      "Wenyu Jiang",
      "Hao Cheng",
      "Mingcai Chen",
      "Chongjun Wang",
      "Hongxin Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02043",
    "title": "Painsight: An Extendable Opinion Mining Framework for Detecting Pain  Points Based on Online Customer Reviews",
    "abstract": "As the e-commerce market continues to expand and online transactions proliferate, customer reviews have emerged as a critical element in shaping the purchasing decisions of prospective buyers. Previous studies have endeavored to identify key aspects of customer reviews through the development of sentiment analysis models and topic models. However, extracting specific dissatisfaction factors remains a challenging task. In this study, we delineate the pain point detection problem and propose Painsight, an unsupervised framework for automatically extracting distinct dissatisfaction factors from customer reviews without relying on ground truth labels. Painsight employs pre-trained language models to construct sentiment analysis and topic models, leveraging attribution scores derived from model gradients to extract dissatisfaction factors. Upon application of the proposed methodology to customer review data spanning five product categories, we successfully identified and categorized dissatisfaction factors within each group, as well as isolated factors for each type. Notably, Painsight outperformed benchmark methods, achieving substantial performance enhancements and exceptional results in human evaluations. ",
    "url": "https://arxiv.org/abs/2306.02043",
    "authors": [
      "Yukyung Lee",
      "Jaehee Kim",
      "Doyoon Kim",
      "Yookyung Kho",
      "Younsun Kim",
      "Pilsung Kang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02049",
    "title": "LambdaBeam: Neural Program Search with Higher-Order Functions and  Lambdas",
    "abstract": "Search is an important technique in program synthesis that allows for adaptive strategies such as focusing on particular search directions based on execution results. Several prior works have demonstrated that neural models are effective at guiding program synthesis searches. However, a common drawback of those approaches is the inability to handle iterative loops, higher-order functions, or lambda functions, thus limiting prior neural searches from synthesizing longer and more general programs. We address this gap by designing a search algorithm called LambdaBeam that can construct arbitrary lambda functions that compose operations within a given DSL. We create semantic vector representations of the execution behavior of the lambda functions and train a neural policy network to choose which lambdas to construct during search, and pass them as arguments to higher-order functions to perform looping computations. Our experiments show that LambdaBeam outperforms neural, symbolic, and LLM-based techniques in an integer list manipulation domain. ",
    "url": "https://arxiv.org/abs/2306.02049",
    "authors": [
      "Kensen Shi",
      "Hanjun Dai",
      "Wen-Ding Li",
      "Kevin Ellis",
      "Charles Sutton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2306.02080",
    "title": "Benchmarking Robustness of Adaptation Methods on Pre-trained  Vision-Language Models",
    "abstract": "Various adaptation methods, such as LoRA, prompts, and adapters, have been proposed to enhance the performance of pre-trained vision-language models in specific domains. The robustness of these adaptation methods against distribution shifts have not been studied. In this study, we assess the robustness of 11 widely-used adaptation methods across 4 vision-language datasets under multimodal corruptions. Concretely, we introduce 7 benchmark datasets, including 96 visual and 87 textual corruptions, to investigate the robustness of different adaptation methods, the impact of available adaptation examples, and the influence of trainable parameter size during adaptation. Our analysis reveals that: 1) Adaptation methods are more sensitive to text corruptions than visual corruptions. 2) Full fine-tuning does not consistently provide the highest robustness; instead, adapters can achieve better robustness with comparable clean performance. 3) Contrary to expectations, our findings indicate that increasing the number of adaptation data and parameters does not guarantee enhanced robustness; instead it results in even lower robustness. We hope this study could benefit future research in the development of robust multimodal adaptation methods. The benchmark, code, and dataset used in this study can be accessed at \\url{https://adarobustness.github.io}. ",
    "url": "https://arxiv.org/abs/2306.02080",
    "authors": [
      "Shuo Chen",
      "Jindong Gu",
      "Zhen Han",
      "Yunpu Ma",
      "Philip Torr",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02081",
    "title": "Message-passing selection: Towards interpretable GNNs for graph  classification",
    "abstract": "In this paper, we strive to develop an interpretable GNNs' inference paradigm, termed MSInterpreter, which can serve as a plug-and-play scheme readily applicable to various GNNs' baselines. Unlike the most existing explanation methods, MSInterpreter provides a Message-passing Selection scheme(MSScheme) to select the critical paths for GNNs' message aggregations, which aims at reaching the self-explaination instead of post-hoc explanations. In detail, the elaborate MSScheme is designed to calculate weight factors of message aggregation paths by considering the vanilla structure and node embedding components, where the structure base aims at weight factors among node-induced substructures; on the other hand, the node embedding base focuses on weight factors via node embeddings obtained by one-layer GNN.Finally, we demonstrate the effectiveness of our approach on graph classification benchmarks. ",
    "url": "https://arxiv.org/abs/2306.02081",
    "authors": [
      "Wenda Li",
      "Kaixuan Chen",
      "Shunyu Liu",
      "Wenjie Huang",
      "Haofei Zhang",
      "Yingjie Tian",
      "Yun Su",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02092",
    "title": "Relieving Triplet Ambiguity: Consensus Network for Language-Guided Image  Retrieval",
    "abstract": "Language-guided image retrieval enables users to search for images and interact with the retrieval system more naturally and expressively by using a reference image and a relative caption as a query. Most existing studies mainly focus on designing image-text composition architecture to extract discriminative visual-linguistic relations. Despite great success, we identify an inherent problem that obstructs the extraction of discriminative features and considerably compromises model training: \\textbf{triplet ambiguity}. This problem stems from the annotation process wherein annotators view only one triplet at a time. As a result, they often describe simple attributes, such as color, while neglecting fine-grained details like location and style. This leads to multiple false-negative candidates matching the same modification text. We propose a novel Consensus Network (Css-Net) that self-adaptively learns from noisy triplets to minimize the negative effects of triplet ambiguity. Inspired by the psychological finding that groups perform better than individuals, Css-Net comprises 1) a consensus module featuring four distinct compositors that generate diverse fused image-text embeddings and 2) a Kullback-Leibler divergence loss, which fosters learning among the compositors, enabling them to reduce biases learned from noisy triplets and reach a consensus. The decisions from four compositors are weighted during evaluation to further achieve consensus. Comprehensive experiments on three datasets demonstrate that Css-Net can alleviate triplet ambiguity, achieving competitive performance on benchmarks, such as $+2.77\\%$ R@10 and $+6.67\\%$ R@50 on FashionIQ. ",
    "url": "https://arxiv.org/abs/2306.02092",
    "authors": [
      "Xu Zhang",
      "Zhedong Zheng",
      "Xiaohan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02098",
    "title": "Towards Complex Real-World Safety Factory Inspection: A High-Quality  Dataset for Safety Clothing and Helmet Detection",
    "abstract": "Safety clothing and helmets play a crucial role in ensuring worker safety at construction sites. Recently, deep learning methods have garnered significant attention in the field of computer vision for their potential to enhance safety and efficiency in various industries. However, limited availability of high-quality datasets has hindered the development of deep learning methods for safety clothing and helmet detection. In this work, we present a large, comprehensive, and realistic high-quality dataset for safety clothing and helmet detection, which was collected from a real-world chemical plant and annotated by professional security inspectors. Our dataset has been compared with several existing open-source datasets, and its effectiveness has been verified applying some classic object detection methods. The results demonstrate that our dataset is more complete and performs better in real-world settings. Furthermore, we have released our deployment code to the public to encourage the adoption of our dataset and improve worker safety. We hope that our efforts will promote the convergence of academic research and industry, ultimately contribute to the betterment of society. ",
    "url": "https://arxiv.org/abs/2306.02098",
    "authors": [
      "Fusheng Yu",
      "Xiaoping Wang",
      "Jiang Li",
      "Shaojin Wu",
      "Junjie Zhang",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02109",
    "title": "Encoding Time-Series Explanations through Self-Supervised Model Behavior  Consistency",
    "abstract": "Interpreting time series models is uniquely challenging because it requires identifying both the location of time series signals that drive model predictions and their matching to an interpretable temporal pattern. While explainers from other modalities can be applied to time series, their inductive biases do not transfer well to the inherently uninterpretable nature of time series. We present TimeX, a time series consistency model for training explainers. TimeX trains an interpretable surrogate to mimic the behavior of a pretrained time series model. It addresses the issue of model faithfulness by introducing model behavior consistency, a novel formulation that preserves relations in the latent space induced by the pretrained model with relations in the latent space induced by TimeX. TimeX provides discrete attribution maps and, unlike existing interpretability methods, it learns a latent space of explanations that can be used in various ways, such as to provide landmarks to visually aggregate similar explanations and easily recognize temporal patterns. We evaluate TimeX on 8 synthetic and real-world datasets and compare its performance against state-of-the-art interpretability methods. We also conduct case studies using physiological time series. Quantitative evaluations demonstrate that TimeX achieves the highest or second-highest performance in every metric compared to baselines across all datasets. Through case studies, we show that the novel components of TimeX show potential for training faithful, interpretable models that capture the behavior of pretrained time series models. ",
    "url": "https://arxiv.org/abs/2306.02109",
    "authors": [
      "Owen Queen",
      "Thomas Hartvigsen",
      "Teddy Koker",
      "Huan He",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02117",
    "title": "Scaling Up, Scaling Deep: Blockwise Graph Contrastive Learning",
    "abstract": "Oversmoothing is a common phenomenon in graph neural networks (GNNs), in which an increase in the network depth leads to a deterioration in their performance. Graph contrastive learning (GCL) is emerging as a promising way of leveraging vast unlabeled graph data. As a marriage between GNNs and contrastive learning, it remains unclear whether GCL inherits the same oversmoothing defect from GNNs. This work undertakes a fundamental analysis of GCL from the perspective of oversmoothing on the first hand. We demonstrate empirically that increasing network depth in GCL also leads to oversmoothing in their deep representations, and surprisingly, the shallow ones. We refer to this phenomenon in GCL as long-range starvation', wherein lower layers in deep networks suffer from degradation due to the lack of sufficient guidance from supervision (e.g., loss computing). Based on our findings, we present BlockGCL, a remarkably simple yet effective blockwise training framework to prevent GCL from notorious oversmoothing. Without bells and whistles, BlockGCL consistently improves robustness and stability for well-established GCL methods with increasing numbers of layers on real-world graph benchmarks. We believe our work will provide insights for future improvements of scalable and deep GCL frameworks. ",
    "url": "https://arxiv.org/abs/2306.02117",
    "authors": [
      "Jintang Li",
      "Wangbin Sun",
      "Ruofan Wu",
      "Yuchang Zhu",
      "Liang Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02133",
    "title": "Graph Mover's Distance: An Efficiently Computable Distance Measure for  Geometric Graphs",
    "abstract": "Many applications in pattern recognition represent patterns as a geometric graph. The geometric graph distance (GGD) has recently been studied as a meaningful measure of similarity between two geometric graphs. Since computing the GGD is known to be $\\mathcal{NP}$-hard, the distance measure proves an impractical choice for applications. As a computationally tractable alternative, we propose in this paper the Graph Mover's Distance (GMD), which has been formulated as an instance of the earth mover's distance. The computation of the GMD between two geometric graphs with at most $n$ vertices takes only $O(n^3)$-time. Alongside studying the metric properties of the GMD, we investigate the stability of the GGD and GMD. The GMD also demonstrates extremely promising empirical evidence at recognizing letter drawings from the {\\tt LETTER} dataset \\cite{da_vitoria_lobo_iam_2008}. ",
    "url": "https://arxiv.org/abs/2306.02133",
    "authors": [
      "Sushovan Majhi"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02137",
    "title": "Inconsistent Matters: A Knowledge-guided Dual-consistency Network for  Multi-modal Rumor Detection",
    "abstract": "Rumor spreaders are increasingly utilizing multimedia content to attract the attention and trust of news consumers. Though quite a few rumor detection models have exploited the multi-modal data, they seldom consider the inconsistent semantics between images and texts, and rarely spot the inconsistency among the post contents and background knowledge. In addition, they commonly assume the completeness of multiple modalities and thus are incapable of handling handle missing modalities in real-life scenarios. Motivated by the intuition that rumors in social media are more likely to have inconsistent semantics, a novel Knowledge-guided Dual-consistency Network is proposed to detect rumors with multimedia contents. It uses two consistency detection subnetworks to capture the inconsistency at the cross-modal level and the content-knowledge level simultaneously. It also enables robust multi-modal representation learning under different missing visual modality conditions, using a special token to discriminate between posts with visual modality and posts without visual modality. Extensive experiments on three public real-world multimedia datasets demonstrate that our framework can outperform the state-of-the-art baselines under both complete and incomplete modality conditions. Our codes are available at https://github.com/MengzSun/KDCN. ",
    "url": "https://arxiv.org/abs/2306.02137",
    "authors": [
      "Mengzhu Sun",
      "Xi Zhang",
      "Jianqiang Ma",
      "Sihong Xie",
      "Yazheng Liu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02143",
    "title": "Hierarchical Multiresolution Feature- and Prior-based Graphs for  Classification",
    "abstract": "To incorporate spatial (neighborhood) and bidirectional hierarchical relationships as well as features and priors of the samples into their classification, we formulated the classification problem on three variants of multiresolution neighborhood graphs and the graph of a hierarchical conditional random field. Each of these graphs was weighted and undirected and could thus incorporate the spatial or hierarchical relationships in all directions. In addition, each variant of the proposed neighborhood graphs was composed of a spatial feature-based subgraph and an aspatial prior-based subgraph. It expanded on a random walker graph by using novel mechanisms to derive the edge weights of its spatial feature-based subgraph. These mechanisms included implicit and explicit edge detection to enhance detection of weak boundaries between different classes in spatial domain. The implicit edge detection relied on the outlier detection capability of the Tukey's function and the classification reliabilities of the samples estimated by a hierarchical random forest classifier. Similar mechanism was used to derive the edge weights and thus the energy function of the hierarchical conditional random field. This way, the classification problem boiled down to a system of linear equations and a minimization of the energy function which could be done via fast and efficient techniques. ",
    "url": "https://arxiv.org/abs/2306.02143",
    "authors": [
      "Faezeh Fallah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02149",
    "title": "Infomorphic networks: Locally learning neural networks derived from  partial information decomposition",
    "abstract": "Understanding the intricate cooperation among individual neurons in performing complex tasks remains a challenge to this date. In this paper, we propose a novel type of model neuron that emulates the functional characteristics of biological neurons by optimizing an abstract local information processing goal. We have previously formulated such a goal function based on principles from partial information decomposition (PID). Here, we present a corresponding parametric local learning rule which serves as the foundation of \"infomorphic networks\" as a novel concrete model of neural networks. We demonstrate the versatility of these networks to perform tasks from supervised, unsupervised and memory learning. By leveraging the explanatory power and interpretable nature of the PID framework, these infomorphic networks represent a valuable tool to advance our understanding of cortical function. ",
    "url": "https://arxiv.org/abs/2306.02149",
    "authors": [
      "Marcel Graetz",
      "Abdullah Makkeh",
      "Andreas C. Schneider",
      "David A. Ehrlich",
      "Viola Priesemann",
      "Michael Wibral"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.02157",
    "title": "Transforming to Yoked Neural Networks to Improve ANN Structure",
    "abstract": "Most existing classical artificial neural networks (ANN) are designed as a tree structure to imitate neural networks. In this paper, we argue that the connectivity of a tree is not sufficient to characterize a neural network. The nodes of the same level of a tree cannot be connected with each other, i.e., these neural unit cannot share information with each other, which is a major drawback of ANN. Although ANN has been significantly improved in recent years to more complex structures, such as the directed acyclic graph (DAG), these methods also have unidirectional and acyclic bias for ANN. In this paper, we propose a method to build a bidirectional complete graph for the nodes in the same level of an ANN, which yokes the nodes of the same level to formulate a neural module. We call our model as YNN in short. YNN promotes the information transfer significantly which obviously helps in improving the performance of the method. Our YNN can imitate neural networks much better compared with the traditional ANN. In this paper, we analyze the existing structural bias of ANN and propose a model YNN to efficiently eliminate such structural bias. In our model, nodes also carry out aggregation and transformation of features, and edges determine the flow of information. We further impose auxiliary sparsity constraint to the distribution of connectedness, which promotes the learned structure to focus on critical connections. Finally, based on the optimized structure, we also design small neural module structure based on the minimum cut technique to reduce the computational burden of the YNN model. This learning process is compatible with the existing networks and different tasks. The obtained quantitative experimental results reflect that the learned connectivity is superior to the traditional NN structure. ",
    "url": "https://arxiv.org/abs/2306.02157",
    "authors": [
      "Xinshun Liu",
      "Yizhi Fang",
      "Yichao Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02165",
    "title": "Learning to Defend by Attacking (and Vice-Versa): Transfer of Learning  in Cybersecurity Games",
    "abstract": "Designing cyber defense systems to account for cognitive biases in human decision making has demonstrated significant success in improving performance against human attackers. However, much of the attention in this area has focused on relatively simple accounts of biases in human attackers, and little is known about adversarial behavior or how defenses could be improved by disrupting attacker's behavior. In this work, we present a novel model of human decision-making inspired by the cognitive faculties of Instance-Based Learning Theory, Theory of Mind, and Transfer of Learning. This model functions by learning from both roles in a security scenario: defender and attacker, and by making predictions of the opponent's beliefs, intentions, and actions. The proposed model can better defend against attacks from a wide range of opponents compared to alternatives that attempt to perform optimally without accounting for human biases. Additionally, the proposed model performs better against a range of human-like behavior by explicitly modeling human transfer of learning, which has not yet been applied to cyber defense scenarios. Results from simulation experiments demonstrate the potential usefulness of cognitively inspired models of agents trained in attack and defense roles and how these insights could potentially be used in real-world cybersecurity. ",
    "url": "https://arxiv.org/abs/2306.02165",
    "authors": [
      "Tyler Malloy",
      "Cleotilde Gonzalez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02177",
    "title": "Towards Coding Social Science Datasets with Language Models",
    "abstract": "Researchers often rely on humans to code (label, annotate, etc.) large sets of texts. This kind of human coding forms an important part of social science research, yet the coding process is both resource intensive and highly variable from application to application. In some cases, efforts to automate this process have achieved human-level accuracies, but to achieve this, these attempts frequently rely on thousands of hand-labeled training examples, which makes them inapplicable to small-scale research studies and costly for large ones. Recent advances in a specific kind of artificial intelligence tool - language models (LMs) - provide a solution to this problem. Work in computer science makes it clear that LMs are able to classify text, without the cost (in financial terms and human effort) of alternative methods. To demonstrate the possibilities of LMs in this area of political science, we use GPT-3, one of the most advanced LMs, as a synthetic coder and compare it to human coders. We find that GPT-3 can match the performance of typical human coders and offers benefits over other machine learning methods of coding text. We find this across a variety of domains using very different coding procedures. This provides exciting evidence that language models can serve as a critical advance in the coding of open-ended texts in a variety of applications. ",
    "url": "https://arxiv.org/abs/2306.02177",
    "authors": [
      "Christopher Michael Rytting",
      "Taylor Sorensen",
      "Lisa Argyle",
      "Ethan Busby",
      "Nancy Fulda",
      "Joshua Gubler",
      "David Wingate"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02199",
    "title": "Shrinking Embeddings for Hyper-Relational Knowledge Graphs",
    "abstract": "Link prediction on knowledge graphs (KGs) has been extensively studied on binary relational KGs, wherein each fact is represented by a triple. A significant amount of important knowledge, however, is represented by hyper-relational facts where each fact is composed of a primal triple and a set of qualifiers comprising a key-value pair that allows for expressing more complicated semantics. Although some recent works have proposed to embed hyper-relational KGs, these methods fail to capture essential inference patterns of hyper-relational facts such as qualifier monotonicity, qualifier implication, and qualifier mutual exclusion, limiting their generalization capability. To unlock this, we present \\emph{ShrinkE}, a geometric hyper-relational KG embedding method aiming to explicitly model these patterns. ShrinkE models the primal triple as a spatial-functional transformation from the head into a relation-specific box. Each qualifier ``shrinks'' the box to narrow down the possible answer set and, thus, realizes qualifier monotonicity. The spatial relationships between the qualifier boxes allow for modeling core inference patterns of qualifiers such as implication and mutual exclusion. Experimental results demonstrate ShrinkE's superiority on three benchmarks of hyper-relational KGs. ",
    "url": "https://arxiv.org/abs/2306.02199",
    "authors": [
      "Bo Xiong",
      "Mojtaba Nayyer",
      "Shirui Pan",
      "Steffen Staab"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02221",
    "title": "ATEM: A Topic Evolution Model for the Detection of Emerging Topics in  Scientific Archives",
    "abstract": "This paper presents ATEM, a novel framework for studying topic evolution in scientific archives. ATEM is based on dynamic topic modeling and dynamic graph embedding techniques that explore the dynamics of content and citations of documents within a scientific corpus. ATEM explores a new notion of contextual emergence for the discovery of emerging interdisciplinary research topics based on the dynamics of citation links in topic clusters. Our experiments show that ATEM can efficiently detect emerging cross-disciplinary topics within the DBLP archive of over five million computer science articles. ",
    "url": "https://arxiv.org/abs/2306.02221",
    "authors": [
      "Hamed Rahimi",
      "Hubert Naacke",
      "Camelia Constantin",
      "Bernd Amann"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02235",
    "title": "Learning Linear Causal Representations from Interventions under General  Nonlinear Mixing",
    "abstract": "We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of causal identifiability from non-paired interventions for deep neural network embeddings. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks. ",
    "url": "https://arxiv.org/abs/2306.02235",
    "authors": [
      "Simon Buchholz",
      "Goutham Rajendran",
      "Elan Rosenfeld",
      "Bryon Aragam",
      "Bernhard Sch\u00f6lkopf",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02239",
    "title": "Generative Flow Network for Listwise Recommendation",
    "abstract": "Personalized recommender systems fulfill the daily demands of customers and boost online businesses. The goal is to learn a policy that can generate a list of items that matches the user's demand or interest. While most existing methods learn a pointwise scoring model that predicts the ranking score of each individual item, recent research shows that the listwise approach can further improve the recommendation quality by modeling the intra-list correlations of items that are exposed together. This has motivated the recent list reranking and generative recommendation approaches that optimize the overall utility of the entire list. However, it is challenging to explore the combinatorial space of list actions and existing methods that use cross-entropy loss may suffer from low diversity issues. In this work, we aim to learn a policy that can generate sufficiently diverse item lists for users while maintaining high recommendation quality. The proposed solution, GFN4Rec, is a generative method that takes the insight of the flow network to ensure the alignment between list generation probability and its reward. The key advantages of our solution are the log scale reward matching loss that intrinsically improves the generation diversity and the autoregressive item selection model that captures the item mutual influences while capturing future reward of the list. As validation of our method's effectiveness and its superior diversity during active exploration, we conduct experiments on simulated online environments as well as an offline evaluation framework for two real-world datasets. ",
    "url": "https://arxiv.org/abs/2306.02239",
    "authors": [
      "Shuchang Liu",
      "Qingpeng Cai",
      "Zhankui He",
      "Bowen Sun",
      "Julian McAuley",
      "Done Zheng",
      "Peng Jiang",
      "Kun Gai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.02242",
    "title": "Extract and Attend: Improving Entity Translation in Neural Machine  Translation",
    "abstract": "While Neural Machine Translation(NMT) has achieved great progress in recent years, it still suffers from inaccurate translation of entities (e.g., person/organization name, location), due to the lack of entity training instances. When we humans encounter an unknown entity during translation, we usually first look up in a dictionary and then organize the entity translation together with the translations of other parts to form a smooth target sentence. Inspired by this translation process, we propose an Extract-and-Attend approach to enhance entity translation in NMT, where the translation candidates of source entities are first extracted from a dictionary and then attended to by the NMT model to generate the target sentence. Specifically, the translation candidates are extracted by first detecting the entities in a source sentence and then translating the entities through looking up in a dictionary. Then, the extracted candidates are added as a prefix of the decoder input to be attended to by the decoder when generating the target sentence through self-attention. Experiments conducted on En-Zh and En-Ru demonstrate that the proposed method is effective on improving both the translation accuracy of entities and the overall translation quality, with up to 35% reduction on entity error rate and 0.85 gain on BLEU and 13.8 gain on COMET. ",
    "url": "https://arxiv.org/abs/2306.02242",
    "authors": [
      "Zixin Zeng",
      "Rui Wang",
      "Yichong Leng",
      "Junliang Guo",
      "Xu Tan",
      "Tao Qin",
      "Tie-yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02245",
    "title": "SAM3D: Zero-Shot 3D Object Detection via Segment Anything Model",
    "abstract": "With the development of large language models, many remarkable linguistic systems like ChatGPT have thrived and achieved astonishing success on many tasks, showing the incredible power of foundation models. In the spirit of unleashing the capability of foundation models on vision tasks, the Segment Anything Model (SAM), a vision foundation model for image segmentation, has been proposed recently and presents strong zero-shot ability on many downstream 2D tasks. However, whether SAM can be adapted to 3D vision tasks has yet to be explored, especially 3D object detection. With this inspiration, we explore adapting the zero-shot ability of SAM to 3D object detection in this paper. We propose a SAM-powered BEV processing pipeline to detect objects and get promising results on the large-scale Waymo open dataset. As an early attempt, our method takes a step toward 3D object detection with vision foundation models and presents the opportunity to unleash their power on 3D vision tasks. The code is released at https://github.com/DYZhang09/SAM3D. ",
    "url": "https://arxiv.org/abs/2306.02245",
    "authors": [
      "Dingyuan Zhang",
      "Dingkang Liang",
      "Hongcheng Yang",
      "Zhikang Zou",
      "Xiaoqing Ye",
      "Zhe Liu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02247",
    "title": "Sen2Pro: A Probabilistic Perspective to Sentence Embedding from  Pre-trained Language Model",
    "abstract": "Sentence embedding is one of the most fundamental tasks in Natural Language Processing and plays an important role in various tasks. The recent breakthrough in sentence embedding is achieved by pre-trained language models (PLMs). Despite its success, an embedded vector (Sen2Vec) representing a point estimate does not naturally express uncertainty in a taskagnostic way. This paper thereby proposes an efficient framework on probabilistic sentence embedding (Sen2Pro) from PLMs, and it represents a sentence as a probability density distribution in an embedding space to reflect both model uncertainty and data uncertainty (i.e., many-to-one nature) in the sentence representation. The proposed framework performs in a plug-and-play way without retraining PLMs anymore, and it is easy to implement and generally applied on top of any PLM. The superiority of Sen2Pro over Sen2Vec has been theoretically verified and practically illustrated on different NLP tasks. ",
    "url": "https://arxiv.org/abs/2306.02247",
    "authors": [
      "Lingfeng Shen",
      "Haiyun Jiang",
      "Lemao Liu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02256",
    "title": "Less is More: Revisiting Gaussian Mechanism for Differential Privacy",
    "abstract": "In this paper, we identify that the classic Gaussian mechanism and its variants for differential privacy all suffer from \\textbf{the curse of full-rank covariance matrices}, and hence the expected accuracy losses of these mechanisms applied to high dimensional query results, e.g., in $\\mathbb{R}^M$, all increase linearly with $M$. To lift this curse, we design a Rank-1 Singular Multivariate Gaussian Mechanism (R1SMG). It achieves $(\\epsilon,\\delta)$-DP on query results in $\\mathbb{R}^M$ by perturbing the results with noise following a singular multivariate Gaussian distribution, whose covariance matrix is a \\textbf{randomly} generated rank-1 positive semi-definite matrix. In contrast, the classic Gaussian mechanism and its variants all consider \\textbf{deterministic} full-rank covariance matrices. Our idea is motivated by a clue from Dwork et al.'s work on Gaussian mechanism that has been ignored in the literature: when projecting multivariate Gaussian noise with a full-rank covariance matrix onto a set of orthonormal basis in $\\mathbb{R}^M$, only the coefficient of a single basis can contribute to the privacy guarantee. This paper makes the following technical contributions. (i) R1SMG achieves $(\\epsilon,\\delta)$-DP guarantee on query results in $\\mathbb{R}^M$, while the magnitude of the additive noise decreases with $M$. Therefore, \\textbf{less is more}, i.e., less amount of noise is able to sanitize higher dimensional query results. When $M\\rightarrow \\infty$, the expected accuracy loss converges to ${2(\\Delta_2f)^2}/{\\epsilon}$, where $\\Delta_2f$ is the $l_2$ sensitivity of the query function $f$. (ii) Compared with other mechanisms, R1SMG is less likely to generate noise with large magnitude that overwhelms the query results, because the kurtosis and skewness of the nondeterministic accuracy loss introduced by R1SMG is larger than that introduced by other mechanisms. ",
    "url": "https://arxiv.org/abs/2306.02256",
    "authors": [
      "Tianxi Ji",
      "Pan Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.02266",
    "title": "Decoupling Numerical Method Based on Deep Neural Network for Nonlinear  Degenerate Interface Problems",
    "abstract": "Interface problems depict many fundamental physical phenomena and widely apply in the engineering. However, it is challenging to develop efficient fully decoupled numerical methods for solving degenerate interface problems in which the coefficient of a PDE is discontinuous and greater than or equal to zero on the interface. The main motivation in this paper is to construct fully decoupled numerical methods for solving nonlinear degenerate interface problems with ``double singularities\". An efficient fully decoupled numerical method is proposed for nonlinear degenerate interface problems. The scheme combines deep neural network on the singular subdomain with finite difference method on the regular subdomain. The key of the new approach is to split nonlinear degenerate partial differential equation with interface into two independent boundary value problems based on deep learning. The outstanding advantages of the proposed schemes are that not only the convergence order of the degenerate interface problems on whole domain is determined by the finite difference scheme on the regular subdomain, but also can calculate $\\mathbf{VERY}$ $\\mathbf{BIG}$ jump ratio(such as $10^{12}:1$ or $1:10^{12}$) for the interface problems including degenerate and non-degenerate cases. The expansion of the solutions does not contains any undetermined parameters in the numerical method. In this way, two independent nonlinear systems are constructed in other subdomains and can be computed in parallel. The flexibility, accuracy and efficiency of the methods are validated from various experiments in both 1D and 2D. Specially, not only our method is suitable for solving degenerate interface case, but also for non-degenerate interface case. Some application examples with complicated multi-connected and sharp edge interface examples including degenerate and nondegenerate cases are also presented. ",
    "url": "https://arxiv.org/abs/2306.02266",
    "authors": [
      "Chen Fan",
      "Zhiyue Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.02268",
    "title": "Revisiting Class Imbalance for End-to-end Semi-Supervised Object  Detection",
    "abstract": "Semi-supervised object detection (SSOD) has made significant progress with the development of pseudo-label-based end-to-end methods. However, many of these methods face challenges due to class imbalance, which hinders the effectiveness of the pseudo-label generator. Furthermore, in the literature, it has been observed that low-quality pseudo-labels severely limit the performance of SSOD. In this paper, we examine the root causes of low-quality pseudo-labels and present novel learning mechanisms to improve the label generation quality. To cope with high false-negative and low precision rates, we introduce an adaptive thresholding mechanism that helps the proposed network to filter out optimal bounding boxes. We further introduce a Jitter-Bagging module to provide accurate information on localization to help refine the bounding boxes. Additionally, two new losses are introduced using the background and foreground scores predicted by the teacher and student networks to improvise the pseudo-label recall rate. Furthermore, our method applies strict supervision to the teacher network by feeding strong & weak augmented data to generate robust pseudo-labels so that it can detect small and complex objects. Finally, the extensive experiments show that the proposed network outperforms state-of-the-art methods on MS-COCO and Pascal VOC datasets and allows the baseline network to achieve 100% supervised performance with much less (i.e., 20%) labeled data. ",
    "url": "https://arxiv.org/abs/2306.02268",
    "authors": [
      "Purbayan Kar",
      "Vishal Chudasama",
      "Naoyuki Onoe",
      "Pankaj Wasnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02270",
    "title": "Crypto-ransomware Detection through Quantitative API-based Behavioral  Profiling",
    "abstract": "With crypto-ransomware's unprecedented scope of impact and evolving level of sophistication, there is an urgent need to pinpoint the security gap and improve the effectiveness of defenses by identifying new detection approaches. Based on our characterization results on dynamic API behaviors of ransomware, we present a new API profiling-based detection mechanism. Our method involves two operations, namely consistency analysis and refinement. We evaluate it against a set of real-world ransomware and also benign samples. We are able to detect all ransomware executions in consistency analysis and reduce the false positive case in refinement. We also conduct in-depth case studies on the most informative API for detection with context. ",
    "url": "https://arxiv.org/abs/2306.02270",
    "authors": [
      "Wenjia Song",
      "Sanjula Karanam",
      "Ya Xiao",
      "Jingyuan Qi",
      "Nathan Dautenhahn",
      "Na Meng",
      "Danfeng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.02277",
    "title": "EfficientSRFace: An Efficient Network with Super-Resolution Enhancement  for Accurate Face Detection",
    "abstract": "In face detection, low-resolution faces, such as numerous small faces of a human group in a crowded scene, are common in dense face prediction tasks. They usually contain limited visual clues and make small faces less distinguishable from the other small objects, which poses great challenge to accurate face detection. Although deep convolutional neural network has significantly promoted the research on face detection recently, current deep face detectors rarely take into account low-resolution faces and are still vulnerable to the real-world scenarios where massive amount of low-resolution faces exist. Consequently, they usually achieve degraded performance for low-resolution face detection. In order to alleviate this problem, we develop an efficient detector termed EfficientSRFace by introducing a feature-level super-resolution reconstruction network for enhancing the feature representation capability of the model. This module plays an auxiliary role in the training process, and can be removed during the inference without increasing the inference time. Extensive experiments on public benchmarking datasets, such as FDDB and WIDER Face, show that the embedded image super-resolution module can significantly improve the detection accuracy at the cost of a small amount of additional parameters and computational overhead, while helping our model achieve competitive performance compared with the state-of-the-arts methods. ",
    "url": "https://arxiv.org/abs/2306.02277",
    "authors": [
      "Guangtao Wang",
      "Jun Li",
      "Jie Xie",
      "Jianhua Xu",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02287",
    "title": "It Takes a Village: A Case for Including Extended Family Members in the  Joint Oversight of Family-based Privacy and Security for Mobile Smartphones",
    "abstract": "We conducted a user study with 19 parent-teen dyads to understand the perceived benefits and drawbacks of using a mobile app that allows them to co-manage mobile privacy, safety, and security within their families. While the primary goal of the study was to understand the use case as it pertained to parents and teens, an emerging finding from our study was that participants found value in extending app use to other family members (siblings, cousins, and grandparents). Participants felt that it would help bring the necessary expertise into their immediate family network and help protect the older adults and children of the family from privacy and security risks. However, participants expressed that co-monitoring by extended family members might cause tensions in their families, creating interpersonal conflicts. To alleviate these concerns, participants suggested more control over the privacy features to facilitate sharing their installed apps with only trusted family members. ",
    "url": "https://arxiv.org/abs/2306.02287",
    "authors": [
      "Mamtaj Akter",
      "Leena Alghamdi",
      "Jess Kropczynski",
      "Heather Lipford",
      "Pamela Wisniewski"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2306.02289",
    "title": "Evaluating the Impact of Community Oversight for Managing Mobile Privacy  and Security",
    "abstract": "Mobile privacy and security can be a collaborative process where individuals seek advice and help from their trusted communities. To support such collective privacy and security management, we developed a mobile app for Community Oversight of Privacy and Security (\"CO-oPS\") that allows community members to review one another's apps installed and permissions granted to provide feedback. We conducted a four-week-long field study with 22 communities (101 participants) of friends, families, or co-workers who installed the CO-oPS app on their phones. Measures of transparency, trust, and awareness of one another's mobile privacy and security behaviors, along with individual and community participation in mobile privacy and security co-management, increased from pre- to post-study. Interview findings confirmed that the app features supported collective considerations of apps and permissions. However, participants expressed a range of concerns regarding having community members with different levels of technical expertise and knowledge regarding mobile privacy and security that can impact motivation to participate and perform oversight. Our study demonstrates the potential and challenges of community oversight mechanisms to support communities to co-manage mobile privacy and security. ",
    "url": "https://arxiv.org/abs/2306.02289",
    "authors": [
      "Mamtaj Akter",
      "Madiha Tabassum",
      "Nazmus Sakib Miazi",
      "Leena Alghamdi",
      "Jess Kropczynski",
      "Pamela Wisniewski",
      "Heather Lipford"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2306.02293",
    "title": "Efficient Approximation Algorithms for Scheduling Coflows with Total  Weighted Completion Time in Identical Parallel Networks",
    "abstract": "This paper addresses the scheduling problem of coflows in identical parallel networks, which is a well-known $NP$-hard problem. Coflow is a relatively new network abstraction used to characterize communication patterns in data centers. We consider both flow-level scheduling and coflow-level scheduling problems. In the flow-level scheduling problem, flows within a coflow can be transmitted through different network cores. However, in the coflow-level scheduling problem, flows within a coflow must be transmitted through the same network core. The key difference between these two problems lies in their scheduling granularity. Previous approaches relied on linear programming to solve the scheduling order. In this paper, we enhance the efficiency of solving by utilizing the primal-dual method. For the flow-level scheduling problem, we propose a $(6-\\frac{2}{m})$-approximation algorithm with arbitrary release times and a $(5-\\frac{2}{m})$-approximation algorithm without release time, where $m$ represents the number of network cores. Additionally, for the coflow-level scheduling problem, we introduce a $(4m+1)$-approximation algorithm with arbitrary release times and a $(4m)$-approximation algorithm without release time. To validate the effectiveness of our proposed algorithms, we conduct simulations using both synthetic and real traffic traces. The results demonstrate the superior performance of our algorithms compared to previous approach, emphasizing their practical utility. ",
    "url": "https://arxiv.org/abs/2306.02293",
    "authors": [
      "Chi-Yeh Chen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.02298",
    "title": "NB-IoT Uplink Synchronization by Change Point Detection of Phase Series  in NTNs",
    "abstract": "Non-Terrestrial Networks (NTNs) are widely recognized as a potential solution to achieve ubiquitous connections of Narrow Bandwidth Internet of Things (NB-IoT). In order to adopt NTNs in NB-IoT, one of the main challenges is the uplink synchronization of Narrowband Physical Random Access procedure which refers to the estimation of time of arrival (ToA) and carrier frequency offset (CFO). Due to the large propagation delay and Doppler shift in NTNs, traditional estimation methods for Terrestrial Networks (TNs) can not be applied in NTNs directly. In this context, we design a two stage ToA and CFO estimation scheme including coarse estimation and fine estimation based on abrupt change point detection (CPD) of phase series with machine learning. Our method achieves high estimation accuracy of ToA and CFO under the low signal-noise ratio (SNR) and large Doppler shift conditions and extends the estimation range without enhancing Random Access preambles. ",
    "url": "https://arxiv.org/abs/2306.02298",
    "authors": [
      "Jiaqi Jiang",
      "Yihang Huang",
      "Yin Xu",
      "Runnan Liu",
      "XiaoWu Ou",
      "Dazhi He"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2306.02301",
    "title": "rPPG-MAE: Self-supervised Pre-training with Masked Autoencoders for  Remote Physiological Measurement",
    "abstract": "Remote photoplethysmography (rPPG) is an important technique for perceiving human vital signs, which has received extensive attention. For a long time, researchers have focused on supervised methods that rely on large amounts of labeled data. These methods are limited by the requirement for large amounts of data and the difficulty of acquiring ground truth physiological signals. To address these issues, several self-supervised methods based on contrastive learning have been proposed. However, they focus on the contrastive learning between samples, which neglect the inherent self-similar prior in physiological signals and seem to have a limited ability to cope with noisy. In this paper, a linear self-supervised reconstruction task was designed for extracting the inherent self-similar prior in physiological signals. Besides, a specific noise-insensitive strategy was explored for reducing the interference of motion and illumination. The proposed framework in this paper, namely rPPG-MAE, demonstrates excellent performance even on the challenging VIPL-HR dataset. We also evaluate the proposed method on two public datasets, namely PURE and UBFC-rPPG. The results show that our method not only outperforms existing self-supervised methods but also exceeds the state-of-the-art (SOTA) supervised methods. One important observation is that the quality of the dataset seems more important than the size in self-supervised pre-training of rPPG. The source code is released at https://github.com/linuxsino/rPPG-MAE. ",
    "url": "https://arxiv.org/abs/2306.02301",
    "authors": [
      "Xin Liu",
      "Yuting Zhang",
      "Zitong Yu",
      "Hao Lu",
      "Huanjing Yue",
      "Jingyu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02306",
    "title": "Cross-CBAM: A Lightweight network for Scene Segmentation",
    "abstract": "Scene parsing is a great challenge for real-time semantic segmentation. Although traditional semantic segmentation networks have made remarkable leap-forwards in semantic accuracy, the performance of inference speed is unsatisfactory. Meanwhile, this progress is achieved with fairly large networks and powerful computational resources. However, it is difficult to run extremely large models on edge computing devices with limited computing power, which poses a huge challenge to the real-time semantic segmentation tasks. In this paper, we present the Cross-CBAM network, a novel lightweight network for real-time semantic segmentation. Specifically, a Squeeze-and-Excitation Atrous Spatial Pyramid Pooling Module(SE-ASPP) is proposed to get variable field-of-view and multiscale information. And we propose a Cross Convolutional Block Attention Module(CCBAM), in which a cross-multiply operation is employed in the CCBAM module to make high-level semantic information guide low-level detail information. Different from previous work, these works use attention to focus on the desired information in the backbone. CCBAM uses cross-attention for feature fusion in the FPN structure. Extensive experiments on the Cityscapes dataset and Camvid dataset demonstrate the effectiveness of the proposed Cross-CBAM model by achieving a promising trade-off between segmentation accuracy and inference speed. On the Cityscapes test set, we achieve 73.4% mIoU with a speed of 240.9FPS and 77.2% mIoU with a speed of 88.6FPS on NVIDIA GTX 1080Ti. ",
    "url": "https://arxiv.org/abs/2306.02306",
    "authors": [
      "Zhengbin Zhang",
      "Zhenhao Xu",
      "Xingsheng Gu",
      "Juan Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.02317",
    "title": "SpellMapper: A non-autoregressive neural spellchecker for ASR  customization with candidate retrieval based on n-gram mappings",
    "abstract": "Contextual spelling correction models are an alternative to shallow fusion to improve automatic speech recognition (ASR) quality given user vocabulary. To deal with large user vocabularies, most of these models include candidate retrieval mechanisms, usually based on minimum edit distance between fragments of ASR hypothesis and user phrases. However, the edit-distance approach is slow, non-trainable, and may have low recall as it relies only on common letters. We propose: 1) a novel algorithm for candidate retrieval, based on misspelled n-gram mappings, which gives up to 90% recall with just the top 10 candidates on Spoken Wikipedia; 2) a non-autoregressive neural model based on BERT architecture, where the initial transcript and ten candidates are combined into one input. The experiments on Spoken Wikipedia show 21.4% word error rate improvement compared to a baseline ASR system. ",
    "url": "https://arxiv.org/abs/2306.02317",
    "authors": [
      "Alexandra Antonova",
      "Evelina Bakhturina",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.02318",
    "title": "Distributionally robust uncertainty quantification via data-driven  stochastic optimal control",
    "abstract": "This paper studies optimal control problems of unknown linear systems subject to stochastic disturbances of uncertain distribution. Uncertainty about the stochastic disturbances is usually described via ambiguity sets of probability measures or distributions. Typically, stochastic optimal control requires knowledge of underlying dynamics and is as such challenging. Relying on a stochastic fundamental lemma from data-driven control and on the framework of polynomial chaos expansions, we propose an approach to reformulate distributionally robust optimal control problems with ambiguity sets as uncertain conic programs in a finite-dimensional vector space. We show how to construct these programs from previously recorded data and how to relax the uncertain conic program to numerically tractable convex programs via appropriate sampling of the underlying distributions. The efficacy of our method is illustrated via a numerical example. ",
    "url": "https://arxiv.org/abs/2306.02318",
    "authors": [
      "Guanru Pan",
      "Timm Faulwasser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.02325",
    "title": "Random Feedback Alignment Algorithms to train Neural Networks: Why do  they Align?",
    "abstract": "Feedback alignment algorithms are an alternative to backpropagation to train neural networks, whereby some of the partial derivatives that are required to compute the gradient are replaced by random terms. This essentially transforms the update rule into a random walk in weight space. Surprisingly, learning still works with those algorithms, including training of deep neural networks. This is generally attributed to an alignment of the update of the random walker with the true gradient - the eponymous gradient alignment -- which drives an approximate gradient descend. The mechanism that leads to this alignment remains unclear, however. In this paper, we use mathematical reasoning and simulations to investigate gradient alignment. We observe that the feedback alignment update rule has fixed points, which correspond to extrema of the loss function. We show that gradient alignment is a stability criterion for those fixed points. It is only a necessary criterion for algorithm performance. Experimentally, we demonstrate that high levels of gradient alignment can lead to poor algorithm performance and that the alignment is not always driving the gradient descend. ",
    "url": "https://arxiv.org/abs/2306.02325",
    "authors": [
      "Dominique Chu",
      "Florian Bacho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02330",
    "title": "Graph Transformer for Recommendation",
    "abstract": "This paper presents a novel approach to representation learning in recommender systems by integrating generative self-supervised learning with graph transformer architecture. We highlight the importance of high-quality data augmentation with relevant self-supervised pretext tasks for improving performance. Towards this end, we propose a new approach that automates the self-supervision augmentation process through a rationale-aware generative SSL that distills informative user-item interaction patterns. The proposed recommender with Graph TransFormer (GFormer) that offers parameterized collaborative rationale discovery for selective augmentation while preserving global-aware user-item relationships. In GFormer, we allow the rationale-aware SSL to inspire graph collaborative filtering with task-adaptive invariant rationalization in graph transformer. The experimental results reveal that our GFormer has the capability to consistently improve the performance over baselines on different datasets. Several in-depth experiments further investigate the invariant rationale-aware augmentation from various aspects. The source code for this work is publicly available at: https://github.com/HKUDS/GFormer. ",
    "url": "https://arxiv.org/abs/2306.02330",
    "authors": [
      "Chaoliu Li",
      "Lianghao Xia",
      "Xubin Ren",
      "Yaowen Ye",
      "Yong Xu",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.02335",
    "title": "Towards Robust Feature Learning with t-vFM Similarity for Continual  Learning",
    "abstract": "Continual learning has been developed using standard supervised contrastive loss from the perspective of feature learning. Due to the data imbalance during the training, there are still challenges in learning better representations. In this work, we suggest using a different similarity metric instead of cosine similarity in supervised contrastive loss in order to learn more robust representations. We validate the our method on one of the image classification datasets Seq-CIFAR-10 and the results outperform recent continual learning baselines. ",
    "url": "https://arxiv.org/abs/2306.02335",
    "authors": [
      "Bilan Gao",
      "YoungBin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02351",
    "title": "RSSOD-Bench: A large-scale benchmark dataset for Salient Object  Detection in Optical Remote Sensing Imagery",
    "abstract": "We present the RSSOD-Bench dataset for salient object detection (SOD) in optical remote sensing imagery. While SOD has achieved success in natural scene images with deep learning, research in SOD for remote sensing imagery (RSSOD) is still in its early stages. Existing RSSOD datasets have limitations in terms of scale, and scene categories, which make them misaligned with real-world applications. To address these shortcomings, we construct the RSSOD-Bench dataset, which contains images from four different cities in the USA. The dataset provides annotations for various salient object categories, such as buildings, lakes, rivers, highways, bridges, aircraft, ships, athletic fields, and more. The salient objects in RSSOD-Bench exhibit large-scale variations, cluttered backgrounds, and different seasons. Unlike existing datasets, RSSOD-Bench offers uniform distribution across scene categories. We benchmark 23 different state-of-the-art approaches from both the computer vision and remote sensing communities. Experimental results demonstrate that more research efforts are required for the RSSOD task. ",
    "url": "https://arxiv.org/abs/2306.02351",
    "authors": [
      "Zhitong Xiong",
      "Yanfeng Liu",
      "Qi Wang",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02376",
    "title": "Towards Deep Attention in Graph Neural Networks: Problems and Remedies",
    "abstract": "Graph neural networks (GNNs) learn the representation of graph-structured data, and their expressiveness can be further enhanced by inferring node relations for propagation. Attention-based GNNs infer neighbor importance to manipulate the weight of its propagation. Despite their popularity, the discussion on deep graph attention and its unique challenges has been limited. In this work, we investigate some problematic phenomena related to deep graph attention, including vulnerability to over-smoothed features and smooth cumulative attention. Through theoretical and empirical analyses, we show that various attention-based GNNs suffer from these problems. Motivated by our findings, we propose AEROGNN, a novel GNN architecture designed for deep graph attention. AERO-GNN provably mitigates the proposed problems of deep graph attention, which is further empirically demonstrated with (a) its adaptive and less smooth attention functions and (b) higher performance at deep layers (up to 64). On 9 out of 12 node classification benchmarks, AERO-GNN outperforms the baseline GNNs, highlighting the advantages of deep graph attention. Our code is available at https://github.com/syleeheal/AERO-GNN. ",
    "url": "https://arxiv.org/abs/2306.02376",
    "authors": [
      "Soo Yong Lee",
      "Fanchen Bu",
      "Jaemin Yoo",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02384",
    "title": "Spear or Shield: Leveraging Generative AI to Tackle Security Threats of  Intelligent Network Services",
    "abstract": "Generative AI (GAI) models have been rapidly advancing, with a wide range of applications including intelligent networks and mobile AI-generated content (AIGC) services. Despite their numerous applications and potential, such models create opportunities for novel security challenges. In this paper, we examine the challenges and opportunities of GAI in the realm of the security of intelligent network AIGC services such as suggesting security policies, acting as both a ``spear'' for potential attacks and a ``shield'' as an integral part of various defense mechanisms. First, we present a comprehensive overview of the GAI landscape, highlighting its applications and the techniques underpinning these advancements, especially large language and diffusion models. Then, we investigate the dynamic interplay between GAI's spear and shield roles, highlighting two primary categories of potential GAI-related attacks and their respective defense strategies within wireless networks. A case study illustrates the impact of GAI defense strategies on energy consumption in an image request scenario under data poisoning attack. Our results show that by employing an AI-optimized diffusion defense mechanism, energy can be reduced by 8.7%, and retransmission count can be decreased from 32 images, without defense, to just 6 images, showcasing the effectiveness of GAI in enhancing network security. ",
    "url": "https://arxiv.org/abs/2306.02384",
    "authors": [
      "Hongyang Du",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Kwok-Yan Lam",
      "Yuguang Fang",
      "Yonghui Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.02405",
    "title": "An Information-Theoretic Analysis of Self-supervised Discrete  Representations of Speech",
    "abstract": "Self-supervised representation learning for speech often involves a quantization step that transforms the acoustic input into discrete units. However, it remains unclear how to characterize the relationship between these discrete units and abstract phonetic categories such as phonemes. In this paper, we develop an information-theoretic framework whereby we represent each phonetic category as a distribution over discrete units. We then apply our framework to two different self-supervised models (namely wav2vec 2.0 and XLSR) and use American English speech as a case study. Our study demonstrates that the entropy of phonetic distributions reflects the variability of the underlying speech sounds, with phonetically similar sounds exhibiting similar distributions. While our study confirms the lack of direct, one-to-one correspondence, we find an intriguing, indirect relationship between phonetic categories and discrete units. ",
    "url": "https://arxiv.org/abs/2306.02405",
    "authors": [
      "Badr M. Abdullah",
      "Mohammed Maqsood Shaik",
      "Bernd M\u00f6bius",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.02407",
    "title": "Heteroskedastic Geospatial Tracking with Distributed Camera Networks",
    "abstract": "Visual object tracking has seen significant progress in recent years. However, the vast majority of this work focuses on tracking objects within the image plane of a single camera and ignores the uncertainty associated with predicted object locations. In this work, we focus on the geospatial object tracking problem using data from a distributed camera network. The goal is to predict an object's track in geospatial coordinates along with uncertainty over the object's location while respecting communication constraints that prohibit centralizing raw image data. We present a novel single-object geospatial tracking data set that includes high-accuracy ground truth object locations and video data from a network of four cameras. We present a modeling framework for addressing this task including a novel backbone model and explore how uncertainty calibration and fine-tuning through a differentiable tracker affect performance. ",
    "url": "https://arxiv.org/abs/2306.02407",
    "authors": [
      "Colin Samplawski",
      "Shiwei Fang",
      "Ziqi Wang",
      "Deepak Ganesan",
      "Mani Srivastava",
      "Benjamin M. Marlin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02415",
    "title": "Top-Down Processing: Top-Down Network Combines Back-Propagation with  Attention",
    "abstract": "Early neural network models relied exclusively on bottom-up processing going from the input signals to higher-level representations. Many recent models also incorporate top-down networks going in the opposite direction. Top-down processing in deep learning models plays two primary roles: learning and directing attention. These two roles are accomplished in current models through distinct mechanisms. While top-down attention is often implemented by extending the model's architecture with additional units that propagate information from high to low levels of the network, learning is typically accomplished by an external learning algorithm such as back-propagation. In the current work, we present an integration of the two functions above, which appear unrelated, using a single unified mechanism. We propose a novel symmetric bottom-up top-down network structure that can integrate standard bottom-up networks with a symmetric top-down counterpart, allowing each network to guide and influence the other. The same top-down network is being used for both learning, via back-propagating feedback signals, and at the same time also for top-down attention, by guiding the bottom-up network to perform a selected task. We show that our method achieves competitive performance on a standard multi-task learning benchmark. Yet, we rely on standard single-task architectures and optimizers, without any task-specific parameters. Additionally, our learning algorithm addresses in a new way some neuroscience issues that arise in biological modeling of learning in the brain. ",
    "url": "https://arxiv.org/abs/2306.02415",
    "authors": [
      "Roy Abel",
      "Shimon Ullman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02436",
    "title": "Joint Activity Detection and Channel Estimation in Massive Machine-Type  Communications with Low-Resolution ADC",
    "abstract": "In massive machine-type communications, data transmission is usually considered sporadic, and thus inherently has a sparse structure. This paper focuses on the joint activity detection (AD) and channel estimation (CE) problems in massive-connected communication systems with low-resolution analog-to-digital converters. To further exploit the sparse structure in transmission, we propose a maximum posterior probability (MAP) estimation problem based on both sporadic activity and sparse channels for joint AD and CE. Moreover, a majorization-minimization-based method is proposed for solving the MAP problem. Finally, various numerical experiments verify that the proposed scheme outperforms state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2306.02436",
    "authors": [
      "Ye Xue",
      "An Liu",
      "Yang Li",
      "Qingjiang Shi",
      "Vincent Lau"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.02447",
    "title": "Active Inference-Based Optimization of Discriminative Neural Network  Classifiers",
    "abstract": "Commonly used objective functions (losses) for a supervised optimization of discriminative neural network classifiers were either distribution-based or metric-based. The distribution-based losses could compromise the generalization or cause classification biases towards the dominant classes of an imbalanced class-sample distribution. The metric-based losses could make the network model independent of any distribution and thus improve its generalization. However, they could still be biased towards the dominant classes and could suffer from discrepancies when a class was absent in both the reference (ground truth) and the predicted labels. In this paper, we proposed a novel optimization process which not only tackled the unbalancedness of the class-sample distribution of the training samples but also provided a mechanism to tackle errors in the reference labels of the training samples. This was achieved by proposing a novel algorithm to find candidate classification labels of the training samples from their prior probabilities and the currently estimated posteriors on the network and a novel objective function for the optimizations. The algorithm was the result of casting the generalized Kelly criterion for optimal betting into a multiclass classification problem. The proposed objective function was the expected free energy of a prospective active inference and could incorporate the candidate labels, the original reference labels, and the priors of the training samples while still being distribution-based. The incorporation of the priors into the optimization not only helped to tackle errors in the reference labels but also allowed to reduce classification biases towards the dominant classes by focusing the attention of the neural network on important but minority foreground classes. ",
    "url": "https://arxiv.org/abs/2306.02447",
    "authors": [
      "Faezeh Fallah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02449",
    "title": "The Power Of Simplicity: Why Simple Linear Models Outperform Complex  Machine Learning Techniques -- Case Of Breast Cancer Diagnosis",
    "abstract": "This research paper investigates the effectiveness of simple linear models versus complex machine learning techniques in breast cancer diagnosis, emphasizing the importance of interpretability and computational efficiency in the medical domain. We focus on Logistic Regression (LR), Decision Trees (DT), and Support Vector Machines (SVM) and optimize their performance using the UCI Machine Learning Repository dataset. Our findings demonstrate that the simpler linear model, LR, outperforms the more complex DT and SVM techniques, with a test score mean of 97.28%, a standard deviation of 1.62%, and a computation time of 35.56 ms. In comparison, DT achieved a test score mean of 93.73%, and SVM had a test score mean of 96.44%. The superior performance of LR can be attributed to its simplicity and interpretability, which provide a clear understanding of the relationship between input features and the outcome. This is particularly valuable in the medical domain, where interpretability is crucial for decision-making. Moreover, the computational efficiency of LR offers advantages in terms of scalability and real-world applicability. The results of this study highlight the power of simplicity in the context of breast cancer diagnosis and suggest that simpler linear models like LR can be more effective, interpretable, and computationally efficient than their complex counterparts, making them a more suitable choice for medical applications. ",
    "url": "https://arxiv.org/abs/2306.02449",
    "authors": [
      "Muhammad Arbab Arshad",
      "Sakib Shahriar",
      "Khizar Anjum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02451",
    "title": "For SALE: State-Action Representation Learning for Deep Reinforcement  Learning",
    "abstract": "In the field of reinforcement learning (RL), representation learning is a proven tool for complex image-based tasks, but is often overlooked for environments with low-level states, such as physical control problems. This paper introduces SALE, a novel approach for learning embeddings that model the nuanced interaction between state and action, enabling effective representation learning from low-level states. We extensively study the design space of these embeddings and highlight important design considerations. We integrate SALE and an adaptation of checkpoints for RL into TD3 to form the TD7 algorithm, which significantly outperforms existing continuous control algorithms. On OpenAI gym benchmark tasks, TD7 has an average performance gain of 276.7% and 50.7% over TD3 at 300k and 5M time steps, respectively, and works in both the online and offline settings. ",
    "url": "https://arxiv.org/abs/2306.02451",
    "authors": [
      "Scott Fujimoto",
      "Wei-Di Chang",
      "Edward J. Smith",
      "Shixiang Shane Gu",
      "Doina Precup",
      "David Meger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02456",
    "title": "Fully coupled mortar-type embedding of one-dimensional fibers into  three-dimensional fluid flow",
    "abstract": "The present article proposes a partitioned Dirichlet-Neumann algorithm, that allows to address unique challenges arising from a novel mixed-dimensional coupling of very slender fibers embedded in fluid flow using a regularized mortar finite element type discretization. Here, the fibers are modeled via one-dimensional (1D) partial differential equations based on geometrically exact nonlinear beam theory, while the flow is described by the three-dimensional (3D) incompressible Navier-Stokes equations. The arising truly mixed-dimensional 1D-3D coupling scheme constitutes a novel numerical strategy, that naturally necessitates specifically tailored algorithmic solution schemes to ensure an accurate and efficient computational treatment. In particular, we present a strongly coupled partitioned solution algorithm based on a Quasi-Newton method for applications involving fibers with high slenderness ratios that usually present a challenge with regard to the well-known added mass effect. The influence of all employed algorithmic and numerical parameters, namely the applied acceleration technique, the employed constraint regularization parameter as well as shape functions, on efficiency and results of the solution procedure is studied through appropriate examples. Finally, the convergence of the two-way coupled mixed-dimensional problem solution under uniform mesh refinement is demonstrated, and the method's capabilities in capturing flow phenomena at large geometric scale separation is illustrated by the example of a submersed vegetation canopy. ",
    "url": "https://arxiv.org/abs/2306.02456",
    "authors": [
      "Nora Hagmeyer",
      "Matthias Mayr",
      "Alexander Popp"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.02459",
    "title": "Multi-Predict: Few Shot Predictors For Efficient Neural Architecture  Search",
    "abstract": "Many hardware-aware neural architecture search (NAS) methods have been developed to optimize the topology of neural networks (NN) with the joint objectives of higher accuracy and lower latency. Recently, both accuracy and latency predictors have been used in NAS with great success, achieving high sample efficiency and accurate modeling of hardware (HW) device latency respectively. However, a new accuracy predictor needs to be trained for every new NAS search space or NN task, and a new latency predictor needs to be additionally trained for every new HW device. In this paper, we explore methods to enable multi-task, multi-search-space, and multi-HW adaptation of accuracy and latency predictors to reduce the cost of NAS. We introduce a novel search-space independent NN encoding based on zero-cost proxies that achieves sample-efficient prediction on multiple tasks and NAS search spaces, improving the end-to-end sample efficiency of latency and accuracy predictors by over an order of magnitude in multiple scenarios. For example, our NN encoding enables multi-search-space transfer of latency predictors from NASBench-201 to FBNet (and vice-versa) in under 85 HW measurements, a 400$\\times$ improvement in sample efficiency compared to a recent meta-learning approach. Our method also improves the total sample efficiency of accuracy predictors by over an order of magnitude. Finally, we demonstrate the effectiveness of our method for multi-search-space and multi-task accuracy prediction on 28 NAS search spaces and tasks. ",
    "url": "https://arxiv.org/abs/2306.02459",
    "authors": [
      "Yash Akhauri",
      "Mohamed S. Abdelfattah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2306.02473",
    "title": "Anomaly Detection Techniques in Smart Grid Systems: A Review",
    "abstract": "Smart grid data can be evaluated for anomaly detection in numerous fields, including cyber-security, fault detection, electricity theft, etc. The strange anomalous behaviors may have been caused by various reasons, including peculiar consumption patterns of the consumers, malfunctioning grid infrastructures, outages, external cyber-attacks, or energy fraud. Recently, anomaly detection of the smart grid has attracted a large amount of interest from researchers, and it is widely applied in a number of high-impact fields. One of the most significant challenges within the smart grid is the implementation of efficient anomaly detection for multiple forms of aberrant behaviors. In this paper, we provide a scoping review of research from the recent advancements in anomaly detection in the context of smart grids. We categorize our study from numerous aspects for deep understanding and inspection of the research challenges so far. Finally, after analyzing the gap in the reviewed paper, the direction for future research on anomaly detection in smart-grid systems has been provided briefly. ",
    "url": "https://arxiv.org/abs/2306.02473",
    "authors": [
      "Shampa Banik",
      "Sohag Kumar Saha",
      "Trapa Banik",
      "S M Mostaq Hossain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02482",
    "title": "Aerial Swarm Defense using Interception and Herding Strategies",
    "abstract": "This paper presents a multi-mode solution to the problem of defending a circular protected area (target) from a wide range of attacks by swarms of risk-taking and/or risk-averse attacking agents (attackers). The proposed multi-mode solution combines two defense strategies, namely: 1) an interception strategy for a team of defenders to intercept multiple risk-taking attackers while ensuring that the defenders do not collide with each other, 2) a herding strategy to herd a swarm of risk-averse attackers to a safe area. In particular, we develop mixed integer programs (MIPs) and geometry-inspired heuristics to distribute and assign and/or reassign the defenders to interception and herding tasks under different spatiotemporal behaviors by the attackers such as splitting into smaller swarms to evade defenders easily or high-speed maneuvers by some risk-taking attackers to maximize damage to the protected area. We provide theoretical as well as numerical comparisons of the computational costs of these MIPs and the heuristics, and demonstrate the overall approach in simulations. ",
    "url": "https://arxiv.org/abs/2306.02482",
    "authors": [
      "Vishnu S. Chipade",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.02488",
    "title": "Adversary for Social Good: Leveraging Adversarial Attacks to Protect  Personal Attribute Privacy",
    "abstract": "Social media has drastically reshaped the world that allows billions of people to engage in such interactive environments to conveniently create and share content with the public. Among them, text data (e.g., tweets, blogs) maintains the basic yet important social activities and generates a rich source of user-oriented information. While those explicit sensitive user data like credentials has been significantly protected by all means, personal private attribute (e.g., age, gender, location) disclosure due to inference attacks is somehow challenging to avoid, especially when powerful natural language processing (NLP) techniques have been effectively deployed to automate attribute inferences from implicit text data. This puts users' attribute privacy at risk. To address this challenge, in this paper, we leverage the inherent vulnerability of machine learning to adversarial attacks, and design a novel text-space Adversarial attack for Social Good, called Adv4SG. In other words, we cast the problem of protecting personal attribute privacy as an adversarial attack formulation problem over the social media text data to defend against NLP-based attribute inference attacks. More specifically, Adv4SG proceeds with a sequence of word perturbations under given constraints such that the probed attribute cannot be identified correctly. Different from the prior works, we advance Adv4SG by considering social media property, and introducing cost-effective mechanisms to expedite attribute obfuscation over text data under the black-box setting. Extensive experiments on real-world social media datasets have demonstrated that our method can effectively degrade the inference accuracy with less computational cost over different attribute settings, which substantially helps mitigate the impacts of inference attacks and thus achieve high performance in user attribute privacy protection. ",
    "url": "https://arxiv.org/abs/2306.02488",
    "authors": [
      "Xiaoting Li",
      "Lingwei Chen",
      "Dinghao Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02508",
    "title": "Graph Fourier MMD for Signals on Graphs",
    "abstract": "While numerous methods have been proposed for computing distances between probability distributions in Euclidean space, relatively little attention has been given to computing such distances for distributions on graphs. However, there has been a marked increase in data that either lies on graph (such as protein interaction networks) or can be modeled as a graph (single cell data), particularly in the biomedical sciences. Thus, it becomes important to find ways to compare signals defined on such graphs. Here, we propose Graph Fourier MMD (GFMMD), a novel distance between distributions and signals on graphs. GFMMD is defined via an optimal witness function that is both smooth on the graph and maximizes difference in expectation between the pair of distributions on the graph. We find an analytical solution to this optimization problem as well as an embedding of distributions that results from this method. We also prove several properties of this method including scale invariance and applicability to disconnected graphs. We showcase it on graph benchmark datasets as well on single cell RNA-sequencing data analysis. In the latter, we use the GFMMD-based gene embeddings to find meaningful gene clusters. We also propose a novel type of score for gene selection called \"gene localization score\" which helps select genes for cellular state space characterization. ",
    "url": "https://arxiv.org/abs/2306.02508",
    "authors": [
      "Samuel Leone",
      "Aarthi Venkat",
      "Guillaume Huguet",
      "Alexander Tong",
      "Guy Wolf",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02524",
    "title": "Kinodynamic FMT* with Dimensionality Reduction Heuristics and Neural  Network Controllers",
    "abstract": "This paper proposes a new sampling-based kinodynamic motion planning algorithm, called FMT*PFF, for nonlinear systems. It exploits the novel idea of dimensionality reduction using partial-final-state-free (PFF) optimal controllers.With the proposed dimensionality reduction heuristic, the search space is restricted within a subspace, thus faster convergence is achieved compared to a regular kinodynamic FMT*. The dimensionality reduction heuristic can be viewed as a sampling strategy and asymptotic optimality is preserved when combined with uniform full-state sampling. Another feature of FMT*PFF is the ability to deal with a steering function with inexact steering, which is vital when using learning-based steering functions. Learning-based methods allow us to solve the steering problem for nonlinear systems efficiently. However, learning-based methods often fail to reach the exact goal state. For nonlinear systems, we train a neural network controller using supervised learning to generate the steering commands. We show that FMT*PFF with a learning-based steering function is efficient and generates dynamically feasible motion plans. We compare our algorithm with previous algorithms and show superior performance in various simulations. ",
    "url": "https://arxiv.org/abs/2306.02524",
    "authors": [
      "Dongliang Zheng",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.02532",
    "title": "R-Mixup: Riemannian Mixup for Biological Networks",
    "abstract": "Biological networks are commonly used in biomedical and healthcare domains to effectively model the structure of complex biological systems with interactions linking biological entities. However, due to their characteristics of high dimensionality and low sample size, directly applying deep learning models on biological networks usually faces severe overfitting. In this work, we propose R-MIXUP, a Mixup-based data augmentation technique that suits the symmetric positive definite (SPD) property of adjacency matrices from biological networks with optimized training efficiency. The interpolation process in R-MIXUP leverages the log-Euclidean distance metrics from the Riemannian manifold, effectively addressing the swelling effect and arbitrarily incorrect label issues of vanilla Mixup. We demonstrate the effectiveness of R-MIXUP with five real-world biological network datasets on both regression and classification tasks. Besides, we derive a commonly ignored necessary condition for identifying the SPD matrices of biological networks and empirically study its influence on the model performance. The code implementation can be found in Appendix E. ",
    "url": "https://arxiv.org/abs/2306.02532",
    "authors": [
      "Xuan Kan",
      "Zimu Li",
      "Hejie Cui",
      "Yue Yu",
      "Ran Xu",
      "Shaojun Yu",
      "Zilong Zhang",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.02533",
    "title": "On Emergence of Clean-Priority Learning in Early Stopped Neural Networks",
    "abstract": "When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time. This behaviour is believed to be a result of neural networks learning the pattern of clean data first and fitting the noise later in the training, a phenomenon that we refer to as clean-priority learning. In this study, we aim to explore the learning dynamics underlying this phenomenon. We theoretically demonstrate that, in the early stage of training, the update direction of gradient descent is determined by the clean subset of training data, leaving the noisy subset has minimal to no impact, resulting in a prioritization of clean learning. Moreover, we show both theoretically and experimentally, as the clean-priority learning goes on, the dominance of the gradients of clean samples over those of noisy samples diminishes, and finally results in a termination of the clean-priority learning and fitting of the noisy samples. ",
    "url": "https://arxiv.org/abs/2306.02533",
    "authors": [
      "Chaoyue Liu",
      "Amirhesam Abedsoltan",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02534",
    "title": "Incorporating L2 Phonemes Using Articulatory Features for Robust Speech  Recognition",
    "abstract": "The limited availability of non-native speech datasets presents a major challenge in automatic speech recognition (ASR) to narrow the performance gap between native and non-native speakers. To address this, the focus of this study is on the efficient incorporation of the L2 phonemes, which in this work refer to Korean phonemes, through articulatory feature analysis. This not only enables accurate modeling of pronunciation variants but also allows for the utilization of both native Korean and English speech datasets. We employ the lattice-free maximum mutual information (LF-MMI) objective in an end-to-end manner, to train the acoustic model to align and predict one of multiple pronunciation candidates. Experimental results show that the proposed method improves ASR accuracy for Korean L2 speech by training solely on L1 speech data. Furthermore, fine-tuning on L2 speech improves recognition accuracy for both L1 and L2 speech without performance trade-offs. ",
    "url": "https://arxiv.org/abs/2306.02534",
    "authors": [
      "Jisung Wang",
      "Haram Lee",
      "Myungwoo Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.02544",
    "title": "Fourier Test-time Adaptation with Multi-level Consistency for Robust  Classification",
    "abstract": "Deep classifiers may encounter significant performance degradation when processing unseen testing data from varying centers, vendors, and protocols. Ensuring the robustness of deep models against these domain shifts is crucial for their widespread clinical application. In this study, we propose a novel approach called Fourier Test-time Adaptation (FTTA), which employs a dual-adaptation design to integrate input and model tuning, thereby jointly improving the model robustness. The main idea of FTTA is to build a reliable multi-level consistency measurement of paired inputs for achieving self-correction of prediction. Our contribution is two-fold. First, we encourage consistency in global features and local attention maps between the two transformed images of the same input. Here, the transformation refers to Fourier-based input adaptation, which can transfer one unseen image into source style to reduce the domain gap. Furthermore, we leverage style-interpolated images to enhance the global and local features with learnable parameters, which can smooth the consistency measurement and accelerate convergence. Second, we introduce a regularization technique that utilizes style interpolation consistency in the frequency space to encourage self-consistency in the logit space of the model output. This regularization provides strong self-supervised signals for robustness enhancement. FTTA was extensively validated on three large classification datasets with different modalities and organs. Experimental results show that FTTA is general and outperforms other strong state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2306.02544",
    "authors": [
      "Yuhao Huang",
      "Xin Yang",
      "Xiaoqiong Huang",
      "Xinrui Zhou",
      "Haozhe Chi",
      "Haoran Dou",
      "Xindi Hu",
      "Jian Wang",
      "Xuedong Deng",
      "Dong Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02555",
    "title": "Barriers for the performance of graph neural networks (GNN) in discrete  random structures. A comment  on~\\cite{schuetz2022combinatorial},\\cite{angelini2023modern},\\cite{schuetz2023reply}",
    "abstract": "Recently graph neural network (GNN) based algorithms were proposed to solve a variety of combinatorial optimization problems, including Maximum Cut problem, Maximum Independent Set problem and similar other problems~\\cite{schuetz2022combinatorial},\\cite{schuetz2022graph}. The publication~\\cite{schuetz2022combinatorial} stirred a debate whether GNN based method was adequately benchmarked against best prior methods. In particular, critical commentaries~\\cite{angelini2023modern} and~\\cite{boettcher2023inability} point out that simple greedy algorithm performs better than GNN in the setting of random graphs, and in fact stronger algorithmic performance can be reached with more sophisticated methods. A response from the authors~\\cite{schuetz2023reply} pointed out that GNN performance can be improved further by tuning up the parameters better. We do not intend to discuss the merits of arguments and counter-arguments in~\\cite{schuetz2022combinatorial},\\cite{angelini2023modern},\\cite{boettcher2023inability},\\cite{schuetz2023reply}. Rather in this note we establish a fundamental limitation for running GNN on random graphs considered in these references, for a broad range of choices of GNN architecture. These limitations arise from the presence of the Overlap Gap Property (OGP) phase transition, which is a barrier for many algorithms, both classical and quantum. As we demonstrate in this paper, it is also a barrier to GNN due to its local structure. We note that at the same time known algorithms ranging from simple greedy algorithms to more sophisticated algorithms based on message passing, provide best results for these problems \\emph{up to} the OGP phase transition. This leaves very little space for GNN to outperform the known algorithms, and based on this we side with the conclusions made in~\\cite{angelini2023modern} and~\\cite{boettcher2023inability}. ",
    "url": "https://arxiv.org/abs/2306.02555",
    "authors": [
      "David Gamarnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.02556",
    "title": "Improved Active Multi-Task Representation Learning via Lasso",
    "abstract": "To leverage the copious amount of data from source tasks and overcome the scarcity of the target task samples, representation learning based on multi-task pretraining has become a standard approach in many applications. However, up until now, most existing works design a source task selection strategy from a purely empirical perspective. Recently, \\citet{chen2022active} gave the first active multi-task representation learning (A-MTRL) algorithm which adaptively samples from source tasks and can provably reduce the total sample complexity using the L2-regularized-target-source-relevance parameter $\\nu^2$. But their work is theoretically suboptimal in terms of total source sample complexity and is less practical in some real-world scenarios where sparse training source task selection is desired. In this paper, we address both issues. Specifically, we show the strict dominance of the L1-regularized-relevance-based ($\\nu^1$-based) strategy by giving a lower bound for the $\\nu^2$-based strategy. When $\\nu^1$ is unknown, we propose a practical algorithm that uses the LASSO program to estimate $\\nu^1$. Our algorithm successfully recovers the optimal result in the known case. In addition to our sample complexity results, we also characterize the potential of our $\\nu^1$-based strategy in sample-cost-sensitive settings. Finally, we provide experiments on real-world computer vision datasets to illustrate the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2306.02556",
    "authors": [
      "Yiping Wang",
      "Yifang Chen",
      "Kevin Jamieson",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02558",
    "title": "Learning from Multi-View Representation for Point-Cloud Pre-Training",
    "abstract": "A critical problem in the pre-training of 3D point clouds is leveraging massive 2D data. A fundamental challenge is to address the 2D-3D domain gap. This paper proposes a novel approach to point-cloud pre-training that enables learning 3D representations by leveraging pre-trained 2D-based networks. In particular, it avoids overfitting to 2D representations and potentially discarding critical 3D features for 3D recognition tasks. The key to our approach is a novel multi-view representation, which learns a shared 3D feature volume consistent with deep features extracted from multiple 2D camera views. The 2D deep features are regularized using pre-trained 2D networks through the 2D knowledge transfer loss. To prevent the resulting 3D feature representations from discarding 3D signals, we introduce the multi-view consistency loss that forces the projected 2D feature representations to capture pixel-wise correspondences across different views. Such correspondences induce 3D geometry and effectively retain 3D features in the projected 2D features. Experimental results demonstrate that our pre-trained model can be successfully transferred to various downstream tasks, including 3D detection and semantic segmentation, and achieve state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2306.02558",
    "authors": [
      "Siming Yan",
      "Chen Song",
      "Youkang Kong",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02560",
    "title": "Tensorized Hypergraph Neural Networks",
    "abstract": "Hypergraph neural networks (HGNN) have recently become attractive and received significant attention due to their excellent performance in various domains. However, most existing HGNNs rely on first-order approximations of hypergraph connectivity patterns, which ignores important high-order information. To address this issue, we propose a novel adjacency-tensor-based Tensorized Hypergraph Neural Network (THNN). THNN is a faithful hypergraph modeling framework through high-order outer product feature message passing and is a natural tensor extension of the adjacency-matrix-based graph neural networks. The proposed THNN is equivalent to an high-order polynomial regression scheme, which enable THNN with the ability to efficiently extract high-order information from uniform hypergraphs. Moreover, in consideration of the exponential complexity of directly processing high-order outer product features, we propose using a partially symmetric CP decomposition approach to reduce model complexity to a linear degree. Additionally, we propose two simple yet effective extensions of our method for non-uniform hypergraphs commonly found in real-world applications. Results from experiments on two widely used hypergraph datasets for 3-D visual object classification show the promising performance of the proposed THNN. ",
    "url": "https://arxiv.org/abs/2306.02560",
    "authors": [
      "Maolin Wang",
      "Yaoming Zhen",
      "Yu Pan",
      "Zenglin Xu",
      "Ruocheng Guo",
      "Xiangyu Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02564",
    "title": "Spatial Implicit Neural Representations for Global-Scale Species Mapping",
    "abstract": "Estimating the geographical range of a species from sparse observations is a challenging and important geospatial prediction problem. Given a set of locations where a species has been observed, the goal is to build a model to predict whether the species is present or absent at any location. This problem has a long history in ecology, but traditional methods struggle to take advantage of emerging large-scale crowdsourced datasets which can include tens of millions of records for hundreds of thousands of species. In this work, we use Spatial Implicit Neural Representations (SINRs) to jointly estimate the geographical range of 47k species simultaneously. We find that our approach scales gracefully, making increasingly better predictions as we increase the number of species and the amount of data per species when training. To make this problem accessible to machine learning researchers, we provide four new benchmarks that measure different aspects of species range estimation and spatial representation learning. Using these benchmarks, we demonstrate that noisy and biased crowdsourced data can be combined with implicit neural representations to approximate expert-developed range maps for many species. ",
    "url": "https://arxiv.org/abs/2306.02564",
    "authors": [
      "Elijah Cole",
      "Grant Van Horn",
      "Christian Lange",
      "Alexander Shepard",
      "Patrick Leary",
      "Pietro Perona",
      "Scott Loarie",
      "Oisin Mac Aodha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02579",
    "title": "Cross-Lingual Transfer Learning for Phrase Break Prediction with  Multilingual Language Model",
    "abstract": "Phrase break prediction is a crucial task for improving the prosody naturalness of a text-to-speech (TTS) system. However, most proposed phrase break prediction models are monolingual, trained exclusively on a large amount of labeled data. In this paper, we address this issue for low-resource languages with limited labeled data using cross-lingual transfer. We investigate the effectiveness of zero-shot and few-shot cross-lingual transfer for phrase break prediction using a pre-trained multilingual language model. We use manually collected datasets in four Indo-European languages: one high-resource language and three with limited resources. Our findings demonstrate that cross-lingual transfer learning can be a particularly effective approach, especially in the few-shot setting, for improving performance in low-resource languages. This suggests that cross-lingual transfer can be inexpensive and effective for developing TTS front-end in resource-poor languages. ",
    "url": "https://arxiv.org/abs/2306.02579",
    "authors": [
      "Hoyeon Lee",
      "Hyun-Wook Yoon",
      "Jong-Hwan Kim",
      "Jae-Min Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.02592",
    "title": "Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help  Multiple Graph Applications",
    "abstract": "Model pre-training on large text corpora has been demonstrated effective for various downstream applications in the NLP domain. In the graph mining domain, a similar analogy can be drawn for pre-training graph models on large graphs in the hope of benefiting downstream graph applications, which has also been explored by several recent studies. However, no existing study has ever investigated the pre-training of text plus graph models on large heterogeneous graphs with abundant textual information (a.k.a. large graph corpora) and then fine-tuning the model on different related downstream applications with different graph schemas. To address this problem, we propose a framework of graph-aware language model pre-training (GALM) on a large graph corpus, which incorporates large language models and graph neural networks, and a variety of fine-tuning methods on downstream applications. We conduct extensive experiments on Amazon's real internal datasets and large public datasets. Comprehensive empirical results and in-depth analysis demonstrate the effectiveness of our proposed methods along with lessons learned. ",
    "url": "https://arxiv.org/abs/2306.02592",
    "authors": [
      "Han Xie",
      "Da Zheng",
      "Jun Ma",
      "Houyu Zhang",
      "Vassilis N. Ioannidis",
      "Xiang Song",
      "Qing Ping",
      "Sheng Wang",
      "Carl Yang",
      "Yi Xu",
      "Belinda Zeng",
      "Trishul Chilimbi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02593",
    "title": "Rhythm-controllable Attention with High Robustness for Long Sentence  Speech Synthesis",
    "abstract": "Regressive Text-to-Speech (TTS) system utilizes attention mechanism to generate alignment between text and acoustic feature sequence. Alignment determines synthesis robustness (e.g, the occurence of skipping, repeating, and collapse) and rhythm via duration control. However, current attention algorithms used in speech synthesis cannot control rhythm using external duration information to generate natural speech while ensuring robustness. In this study, we propose Rhythm-controllable Attention (RC-Attention) based on Tracotron2, which improves robustness and naturalness simultaneously. Proposed attention adopts a trainable scalar learned from four kinds of information to achieve rhythm control, which makes rhythm control more robust and natural, even when synthesized sentences are extremely longer than training corpus. We use word errors counting and AB preference test to measure robustness of proposed method and naturalness of synthesized speech, respectively. Results shows that RC-Attention has the lowest word error rate of nearly 0.6%, compared with 11.8% for baseline system. Moreover, nearly 60% subjects prefer to the speech synthesized with RC-Attention to that with Forward Attention, because the former has more natural rhythm. ",
    "url": "https://arxiv.org/abs/2306.02593",
    "authors": [
      "Dengfeng Ke",
      "Yayue Deng",
      "Yukang Jia",
      "Jinlong Xue",
      "Qi Luo",
      "Ya Li",
      "Jianqing Sun",
      "Jiaen Liang",
      "Binghuai Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02597",
    "title": "Early Rumor Detection Using Neural Hawkes Process with a New Benchmark  Dataset",
    "abstract": "Little attention has been paid on \\underline{EA}rly \\underline{R}umor \\underline{D}etection (EARD), and EARD performance was evaluated inappropriately on a few datasets where the actual early-stage information is largely missing. To reverse such situation, we construct BEARD, a new \\underline{B}enchmark dataset for \\underline{EARD}, based on claims from fact-checking websites by trying to gather as many early relevant posts as possible. We also propose HEARD, a novel model based on neural \\underline{H}awkes process for \\underline{EARD}, which can guide a generic rumor detection model to make timely, accurate and stable predictions. Experiments show that HEARD achieves effective EARD performance on two commonly used general rumor detection datasets and our BEARD dataset. ",
    "url": "https://arxiv.org/abs/2306.02597",
    "authors": [
      "Fengzhu Zeng",
      "Wei Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.02602",
    "title": "ReContrast: Domain-Specific Anomaly Detection via Contrastive  Reconstruction",
    "abstract": "Most advanced unsupervised anomaly detection (UAD) methods rely on modeling feature representations of frozen encoder networks pre-trained on large-scale datasets, e.g. ImageNet. However, the features extracted from the encoders that are borrowed from natural image domains coincide little with the features required in the target UAD domain, such as industrial inspection and medical imaging. In this paper, we propose a novel epistemic UAD method, namely ReContrast, which optimizes the entire network to reduce biases towards the pre-trained image domain and orients the network in the target domain. We start with a feature reconstruction approach that detects anomalies from errors. Essentially, the elements of contrastive learning are elegantly embedded in feature reconstruction to prevent the network from training instability, pattern collapse, and identical shortcut, while simultaneously optimizing both the encoder and decoder on the target domain. To demonstrate our transfer ability on various image domains, we conduct extensive experiments across two popular industrial defect detection benchmarks and three medical image UAD tasks, which shows our superiority over current state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2306.02602",
    "authors": [
      "Jia Guo",
      "Shuai Lu",
      "Lize Jia",
      "Weihang Zhang",
      "Huiqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02606",
    "title": "Physics-Informed Kernel Function Neural Networks for Solving Partial  Differential Equations",
    "abstract": "This paper proposed a novel radial basis function neural network (RBFNN) to solve various partial differential equations (PDEs). In the proposed RBF neural networks, the physics-informed kernel functions (PIKFs), which are derived according to the governing equations of the considered PDEs, are used to be the activation functions instead of the traditional RBFs. Similar to the well-known physics-informed neural networks (PINNs), the proposed physics-informed kernel function neural networks (PIKFNNs) also include the physical information of the considered PDEs in the neural network. The difference is that the PINNs put this physical information in the loss function, and the proposed PIKFNNs put the physical information of the considered governing equations in the activation functions. By using the derived physics-informed kernel functions satisfying the considered governing equations of homogeneous, nonhomogeneous, transient PDEs as the activation functions, only the boundary/initial data are required to train the neural network. Finally, the feasibility and accuracy of the proposed PIKFNNs are validated by several benchmark examples referred to high-wavenumber wave propagation problem, infinite domain problem, nonhomogeneous problem, long-time evolution problem, inverse problem, spatial structural derivative diffusion model, and so on. ",
    "url": "https://arxiv.org/abs/2306.02606",
    "authors": [
      "Zhuojia Fu",
      "Wenzhi Xu",
      "Shuainan Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.02611",
    "title": "Stochastic Population Update Can Provably Be Helpful in Multi-Objective  Evolutionary Algorithms",
    "abstract": "Evolutionary algorithms (EAs) have been widely and successfully applied to solve multi-objective optimization problems, due to their nature of population-based search. Population update is a key component in multi-objective EAs (MOEAs), and it is performed in a greedy, deterministic manner. That is, the next-generation population is formed by selecting the first population-size ranked solutions (based on some selection criteria, e.g., non-dominated sorting, crowdedness and indicators) from the collections of the current population and newly-generated solutions. In this paper, we question this practice. We analytically present that introducing randomness into the population update procedure in MOEAs can be beneficial for the search. More specifically, we prove that the expected running time of a well-established MOEA (SMS-EMOA) for solving a commonly studied bi-objective problem, OneJumpZeroJump, can be exponentially decreased if replacing its deterministic population update mechanism by a stochastic one. Empirical studies also verify the effectiveness of the proposed stochastic population update method. This work is an attempt to challenge a common practice for the population update in MOEAs. Its positive results, which might hold more generally, should encourage the exploration of developing new MOEAs in the area. ",
    "url": "https://arxiv.org/abs/2306.02611",
    "authors": [
      "Chao Bian",
      "Yawen Zhou",
      "Miqing Li",
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02618",
    "title": "Enhance Diffusion to Improve Robust Generalization",
    "abstract": "Deep neural networks are susceptible to human imperceptible adversarial perturbations. One of the strongest defense mechanisms is \\emph{Adversarial Training} (AT). In this paper, we aim to address two predominant problems in AT. First, there is still little consensus on how to set hyperparameters with a performance guarantee for AT research, and customized settings impede a fair comparison between different model designs in AT research. Second, the robustly trained neural networks struggle to generalize well and suffer from tremendous overfitting. This paper focuses on the primary AT framework - Projected Gradient Descent Adversarial Training (PGD-AT). We approximate the dynamic of PGD-AT by a continuous-time Stochastic Differential Equation (SDE), and show that the diffusion term of this SDE determines the robust generalization. An immediate implication of this theoretical finding is that robust generalization is positively correlated with the ratio between learning rate and batch size. We further propose a novel approach, \\emph{Diffusion Enhanced Adversarial Training} (DEAT), to manipulate the diffusion term to improve robust generalization with virtually no extra computational burden. We theoretically show that DEAT obtains a tighter generalization bound than PGD-AT. Our empirical investigation is extensive and firmly attests that DEAT universally outperforms PGD-AT by a significant margin. ",
    "url": "https://arxiv.org/abs/2306.02618",
    "authors": [
      "Jianhui Sun",
      "Sanchit Sinha",
      "Aidong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02622",
    "title": "What Makes Entities Similar? A Similarity Flooding Perspective for  Multi-sourced Knowledge Graph Embeddings",
    "abstract": "Joint representation learning over multi-sourced knowledge graphs (KGs) yields transferable and expressive embeddings that improve downstream tasks. Entity alignment (EA) is a critical step in this process. Despite recent considerable research progress in embedding-based EA, how it works remains to be explored. In this paper, we provide a similarity flooding perspective to explain existing translation-based and aggregation-based EA models. We prove that the embedding learning process of these models actually seeks a fixpoint of pairwise similarities between entities. We also provide experimental evidence to support our theoretical analysis. We propose two simple but effective methods inspired by the fixpoint computation in similarity flooding, and demonstrate their effectiveness on benchmark datasets. Our work bridges the gap between recent embedding-based models and the conventional similarity flooding algorithm. It would improve our understanding of and increase our faith in embedding-based EA. ",
    "url": "https://arxiv.org/abs/2306.02622",
    "authors": [
      "Zequn Sun",
      "Jiacheng Huang",
      "Xiaozhou Xu",
      "Qijin Chen",
      "Weijun Ren",
      "Wei Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.02639",
    "title": "Evaluating robustness of support vector machines with the Lagrangian  dual approach",
    "abstract": "Adversarial examples bring a considerable security threat to support vector machines (SVMs), especially those used in safety-critical applications. Thus, robustness verification is an essential issue for SVMs, which can provide provable robustness against various kinds of adversary attacks. The evaluation results obtained through the robustness verification can provide a safe guarantee for the use of SVMs. The existing verification method does not often perform well in verifying SVMs with nonlinear kernels. To this end, we propose a method to improve the verification performance for SVMs with nonlinear kernels. We first formalize the adversarial robustness evaluation of SVMs as an optimization problem. Then a lower bound of the original problem is obtained by solving the Lagrangian dual problem of the original problem. Finally, the adversarial robustness of SVMs is evaluated concerning the lower bound. We evaluate the adversarial robustness of SVMs with linear and nonlinear kernels on the MNIST and Fashion-MNIST datasets. The experimental results show that the percentage of provable robustness obtained by our method on the test set is better than that of the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2306.02639",
    "authors": [
      "Yuting Liu",
      "Hong Gu",
      "Pan Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02648",
    "title": "Continuous Cartesian Genetic Programming based representation for  Multi-Objective Neural Architecture Search",
    "abstract": "We propose a novel approach for the challenge of designing less complex yet highly effective convolutional neural networks (CNNs) through the use of cartesian genetic programming (CGP) for neural architecture search (NAS). Our approach combines real-based and block-chained CNNs representations based on CGP for optimization in the continuous domain using multi-objective evolutionary algorithms (MOEAs). Two variants are introduced that differ in the granularity of the search space they consider. The proposed CGP-NASV1 and CGP-NASV2 algorithms were evaluated using the non-dominated sorting genetic algorithm II (NSGA-II) on the CIFAR-10 and CIFAR-100 datasets. The empirical analysis was extended to assess the crossover operator from differential evolution (DE), the multi-objective evolutionary algorithm based on decomposition (MOEA/D) and S metric selection evolutionary multi-objective algorithm (SMS-EMOA) using the same representation. Experimental results demonstrate that our approach is competitive with state-of-the-art proposals in terms of classification performance and model complexity. ",
    "url": "https://arxiv.org/abs/2306.02648",
    "authors": [
      "Cosijopii Garcia-Garcia",
      "Alicia Morales-Reyes",
      "Hugo Jair Escalante"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02649",
    "title": "On the Complexity of Lombardi Graph Drawing",
    "abstract": "In a Lombardi drawing of a graph the vertices are drawn as points and the edges are drawn as circular arcs connecting their respective endpoints. Additionally, all vertices have perfect angular resolution, i.e., all angles incident to a vertex $v$ have size $2\\pi/\\mathrm{deg}(v)$. We prove that it is $\\exists\\mathbb{R}$-complete to determine whether a given graph admits a Lombardi drawing respecting a fixed cyclic ordering of the incident edges around each vertex. In particular, this implies NP-hardness. While most previous work studied the (non-)existence of Lombardi drawings for different graph classes, our result is the first on the computational complexity of finding Lombardi drawings of general graphs. ",
    "url": "https://arxiv.org/abs/2306.02649",
    "authors": [
      "Paul Jungeblut"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.02651",
    "title": "Dynamic Interactive Relation Capturing via Scene Graph Learning for  Robotic Surgical Report Generation",
    "abstract": "For robot-assisted surgery, an accurate surgical report reflects clinical operations during surgery and helps document entry tasks, post-operative analysis and follow-up treatment. It is a challenging task due to many complex and diverse interactions between instruments and tissues in the surgical scene. Although existing surgical report generation methods based on deep learning have achieved large success, they often ignore the interactive relation between tissues and instrumental tools, thereby degrading the report generation performance. This paper presents a neural network to boost surgical report generation by explicitly exploring the interactive relation between tissues and surgical instruments. We validate the effectiveness of our method on a widely-used robotic surgery benchmark dataset, and experimental results show that our network can significantly outperform existing state-of-the-art surgical report generation methods (e.g., 7.48% and 5.43% higher for BLEU-1 and ROUGE). ",
    "url": "https://arxiv.org/abs/2306.02651",
    "authors": [
      "Hongqiu Wang",
      "Yueming Jin",
      "Lei Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02664",
    "title": "Structure-free Graph Condensation: From Large-scale Graphs to Condensed  Graph-free Data",
    "abstract": "Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediate benefits for various graph learning tasks. However, existing graph condensation methods rely on the joint optimization of nodes and structures in the condensed graph, and overlook critical issues in effectiveness and generalization ability. In this paper, we advocate a new Structure-Free Graph Condensation paradigm, named SFGC, to distill a large-scale graph into a small-scale graph node set without explicit graph structures, i.e., graph-free data. Our idea is to implicitly encode topology structure information into the node attributes in the synthesized graph-free data, whose topology is reduced to an identity matrix. Specifically, SFGC contains two collaborative components: (1) a training trajectory meta-matching scheme for effectively synthesizing small-scale graph-free data; (2) a graph neural feature score metric for dynamically evaluating the quality of the condensed data. Through training trajectory meta-matching, SFGC aligns the long-term GNN learning behaviors between the large-scale graph and the condensed small-scale graph-free data, ensuring comprehensive and compact transfer of informative knowledge to the graph-free data. Afterward, the underlying condensed graph-free data would be dynamically evaluated with the graph neural feature score, which is a closed-form metric for ensuring the excellent expressiveness of the condensed graph-free data. Extensive experiments verify the superiority of SFGC across different condensation ratios. ",
    "url": "https://arxiv.org/abs/2306.02664",
    "authors": [
      "Xin Zheng",
      "Miao Zhang",
      "Chunyang Chen",
      "Quoc Viet Hung Nguyen",
      "Xingquan Zhu",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.02666",
    "title": "Does a sparse ReLU network training problem always admit an optimum?",
    "abstract": "Given a training set, a loss function, and a neural network architecture, it is often taken for granted that optimal network parameters exist, and a common practice is to apply available optimization algorithms to search for them. In this work, we show that the existence of an optimal solution is not always guaranteed, especially in the context of {\\em sparse} ReLU neural networks. In particular, we first show that optimization problems involving deep networks with certain sparsity patterns do not always have optimal parameters, and that optimization algorithms may then diverge. Via a new topological relation between sparse ReLU neural networks and their linear counterparts, we derive -- using existing tools from real algebraic geometry -- an algorithm to verify that a given sparsity pattern suffers from this issue. Then, the existence of a global optimum is proved for every concrete optimization problem involving a shallow sparse ReLU neural network of output dimension one. Overall, the analysis is based on the investigation of two topological properties of the space of functions implementable as sparse ReLU neural networks: a best approximation property, and a closedness property, both in the uniform norm. This is studied both for (finite) domains corresponding to practical training on finite training sets, and for more general domains such as the unit cube. This allows us to provide conditions for the guaranteed existence of an optimum given a sparsity pattern. The results apply not only to several sparsity patterns proposed in recent works on network pruning/sparsification, but also to classical dense neural networks, including architectures not covered by existing results. ",
    "url": "https://arxiv.org/abs/2306.02666",
    "authors": [
      "Quoc-Tung Le",
      "Elisa Riccietti",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Algebraic Geometry (math.AG)",
      "Functional Analysis (math.FA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2306.02679",
    "title": "Joint Pre-training and Local Re-training: Transferable Representation  Learning on Multi-source Knowledge Graphs",
    "abstract": "In this paper, we present the ``joint pre-training and local re-training'' framework for learning and applying multi-source knowledge graph (KG) embeddings. We are motivated by the fact that different KGs contain complementary information to improve KG embeddings and downstream tasks. We pre-train a large teacher KG embedding model over linked multi-source KGs and distill knowledge to train a student model for a task-specific KG. To enable knowledge transfer across different KGs, we use entity alignment to build a linked subgraph for connecting the pre-trained KGs and the target KG. The linked subgraph is re-trained for three-level knowledge distillation from the teacher to the student, i.e., feature knowledge distillation, network knowledge distillation, and prediction knowledge distillation, to generate more expressive embeddings. The teacher model can be reused for different target KGs and tasks without having to train from scratch. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our framework. ",
    "url": "https://arxiv.org/abs/2306.02679",
    "authors": [
      "Zequn Sun",
      "Jiacheng Huang",
      "Jinghao Lin",
      "Xiaozhou Xu",
      "Qijin Chen",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02694",
    "title": "Social Robots As Companions for Lonely Hearts: The Role of  Anthropomorphism and Robot Appearances",
    "abstract": "Loneliness is a distressing personal experience and a growing social issue. Social robots could alleviate the pain of loneliness, particularly for those who lack in-person interaction. This paper investigated how the effect of loneliness on anthropomorphizing social robots differs by robot appearances, and how it leads to the purchase intention of social robots. Participants viewed a video of one of the three robots(machine-like, animal-like, and human-like) moving and interacting with a human counterpart. The results revealed that when individuals were lonelier, the tendency to anthropomorphize human-like robots increased more than that of animal-like robots. The moderating effect remained significant after covariates were included. The increase in anthropomorphic tendency predicted the heightened purchase intent. The findings imply that human-like robots induce lonely individuals' desire to replenish the sense of connectedness from robots more than animal-like robots, and that anthropomorphic tendency reveals the potential of social robots as real-life companions of lonely individuals. ",
    "url": "https://arxiv.org/abs/2306.02694",
    "authors": [
      "Yoonwon Jung",
      "Sowon Hahn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2306.02697",
    "title": "Efficient GPT Model Pre-training using Tensor Train Matrix  Representation",
    "abstract": "Large-scale transformer models have shown remarkable performance in language modelling tasks. However, such models feature billions of parameters, leading to difficulties in their deployment and prohibitive training costs from scratch. To reduce the number of the parameters in the GPT-2 architecture, we replace the matrices of fully-connected layers with the corresponding Tensor Train Matrix~(TTM) structure. Finally, we customize forward and backward operations through the TTM-based layer for simplicity and the stableness of further training. % The resulting GPT-2-based model stores up to 40% fewer parameters, showing the perplexity comparable to the original model. On the downstream tasks, including language understanding and text summarization, the model performs similarly to the original GPT-2 model. The proposed tensorized layers could be used to efficiently pre-training other Transformer models. ",
    "url": "https://arxiv.org/abs/2306.02697",
    "authors": [
      "Viktoriia Chekalina",
      "Georgii Novikov",
      "Julia Gusak",
      "Ivan Oseledets",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02705",
    "title": "Situational Adaptive Motion Prediction for Firefighting Squads in Indoor  Search and Rescue",
    "abstract": "Firefighting is a complex, yet low automated task. To mitigate ergonomic and safety related risks on the human operators, robots could be deployed in a collaborative approach. To allow human-robot teams in firefighting, important basics are missing. Amongst other aspects, the robot must predict the human motion as occlusion is ever-present. In this work, we propose a novel motion prediction pipeline for firefighters' squads in indoor search and rescue. The squad paths are generated with an optimal graph-based planning approach representing firefighters' tactics. Paths are generated per room which allows to dynamically adapt the path locally without global re-planning. The motion of singular agents is simulated using a modification of the headed social force model. We evaluate the pipeline for feasibility with a novel data set generated from real footage and show the computational efficiency. ",
    "url": "https://arxiv.org/abs/2306.02705",
    "authors": [
      "Nils Mandischer",
      "Frederik Schicks",
      "Burkhard Corves"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.02707",
    "title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
    "abstract": "Recent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small model's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at https://aka.ms/orca-lm), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills. ",
    "url": "https://arxiv.org/abs/2306.02707",
    "authors": [
      "Subhabrata Mukherjee",
      "Arindam Mitra",
      "Ganesh Jawahar",
      "Sahaj Agarwal",
      "Hamid Palangi",
      "Ahmed Awadallah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02709",
    "title": "Comparative Study on Semi-supervised Learning Applied for Anomaly  Detection in Hydraulic Condition Monitoring System",
    "abstract": "Condition-based maintenance is becoming increasingly important in hydraulic systems. However, anomaly detection for these systems remains challenging, especially since that anomalous data is scarce and labeling such data is tedious and even dangerous. Therefore, it is advisable to make use of unsupervised or semi-supervised methods, especially for semi-supervised learning which utilizes unsupervised learning as a feature extraction mechanism to aid the supervised part when only a small number of labels are available. This study systematically compares semi-supervised learning methods applied for anomaly detection in hydraulic condition monitoring systems. Firstly, thorough data analysis and feature learning were carried out to understand the open-sourced hydraulic condition monitoring dataset. Then, various methods were implemented and evaluated including traditional stand-alone semi-supervised learning models (e.g., one-class SVM, Robust Covariance), ensemble models (e.g., Isolation Forest), and deep neural network based models (e.g., autoencoder, Hierarchical Extreme Learning Machine (HELM)). Typically, this study customized and implemented an extreme learning machine based semi-supervised HELM model and verified its superiority over other semi-supervised methods. Extensive experiments show that the customized HELM model obtained state-of-the-art performance with the highest accuracy (99.5%), the lowest false positive rate (0.015), and the best F1-score (0.985) beating other semi-supervised methods. ",
    "url": "https://arxiv.org/abs/2306.02709",
    "authors": [
      "Yongqi Dong",
      "Kejia Chen",
      "Zhiyuan Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02715",
    "title": "Federated Intrusion Detection System based on Deep Belief Networks",
    "abstract": "The vast increase of IoT technologies and the ever-evolving attack vectors and threat actors have increased cyber-security risks dramatically. Novel attacks can compromise IoT devices to gain access to sensitive data or control them to deploy further malicious activities. The detection of novel attacks often relies upon AI solutions. A common approach to implementing AI-based IDS in distributed IoT systems is in a centralised manner. However, this approach may violate data privacy and secrecy. In addition, centralised data collection prohibits the scale-up of IDSs. Therefore, intrusion detection solutions in IoT ecosystems need to move towards a decentralised direction. FL has attracted significant interest in recent years due to its ability to perform collaborative learning while preserving data confidentiality and locality. Nevertheless, most FL-based IDS for IoT systems are designed under unrealistic data distribution conditions. To that end, we design an experiment representative of the real world and evaluate the performance of two FL IDS implementations, one based on DNNs and another on our previous work on DBNs. For our experiments, we rely on TON-IoT, a realistic IoT network traffic dataset, associating each IP address with a single FL client. Additionally, we explore pre-training and investigate various aggregation methods to mitigate the impact of data heterogeneity. Lastly, we benchmark our approach against a centralised solution. The comparison shows that the heterogeneous nature of the data has a considerable negative impact on the model performance when trained in a distributed manner. However, in the case of a pre-trained initial global FL model, we demonstrate a performance improvement of over 20% (F1-score) when compared against a randomly initiated global model. ",
    "url": "https://arxiv.org/abs/2306.02715",
    "authors": [
      "Othmane Belarbi",
      "Theodoros Spyridopoulos",
      "Eirini Anthi",
      "Ioannis Mavromatis",
      "Pietro Carnelli",
      "Aftab Khan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02729",
    "title": "Gibbs Sampling the Posterior of Neural Networks",
    "abstract": "In this paper, we study sampling from a posterior derived from a neural network. We propose a new probabilistic model consisting of adding noise at every pre- and post-activation in the network, arguing that the resulting posterior can be sampled using an efficient Gibbs sampler. The Gibbs sampler attains similar performances as the state-of-the-art Monte Carlo Markov chain methods, such as the Hamiltonian Monte Carlo or the Metropolis adjusted Langevin algorithm, both on real and synthetic data. By framing our analysis in the teacher-student setting, we introduce a thermalization criterion that allows us to detect when an algorithm, when run on data with synthetic labels, fails to sample from the posterior. The criterion is based on the fact that in the teacher-student setting we can initialize an algorithm directly at equilibrium. ",
    "url": "https://arxiv.org/abs/2306.02729",
    "authors": [
      "Giovanni Piccioli",
      "Emanuele Troiani",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02730",
    "title": "Streaming Task Graph Scheduling for Dataflow Architectures",
    "abstract": "Dataflow devices represent an avenue towards saving the control and data movement overhead of Load-Store Architectures. Various dataflow accelerators have been proposed, but how to efficiently schedule applications on such devices remains an open problem. The programmer can explicitly implement both temporal and spatial parallelism, and pipelining across multiple processing elements can be crucial to take advantage of the fast on-chip interconnect, enabling the concurrent execution of different program components. This paper introduces canonical task graphs, a model that enables streaming scheduling of task graphs over dataflow architectures. We show how a task graph can be statically analyzed to understand its steady-state behavior, and we use this information to partition it into temporally multiplexed components of spatially executed tasks. Results on synthetic and realistic workloads show how streaming scheduling can increase speedup and device utilization over a traditional scheduling approach. ",
    "url": "https://arxiv.org/abs/2306.02730",
    "authors": [
      "Tiziano De Matteis",
      "Lukas Gianinazzi",
      "Johannes de Fine Licht",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2306.02731",
    "title": "Enhanced Distribution Modelling via Augmented Architectures For Neural  ODE Flows",
    "abstract": "While the neural ODE formulation of normalizing flows such as in FFJORD enables us to calculate the determinants of free form Jacobians in O(D) time, the flexibility of the transformation underlying neural ODEs has been shown to be suboptimal. In this paper, we present AFFJORD, a neural ODE-based normalizing flow which enhances the representation power of FFJORD by defining the neural ODE through special augmented transformation dynamics which preserve the topology of the space. Furthermore, we derive the Jacobian determinant of the general augmented form by generalizing the chain rule in the continuous sense into the Cable Rule, which expresses the forward sensitivity of ODEs with respect to their initial conditions. The cable rule gives an explicit expression for the Jacobian of a neural ODE transformation, and provides an elegant proof of the instantaneous change of variable. Our experimental results on density estimation in synthetic and high dimensional data, such as MNIST, CIFAR-10 and CelebA 32x32, show that AFFJORD outperforms the baseline FFJORD through the improved flexibility of the underlying vector field. ",
    "url": "https://arxiv.org/abs/2306.02731",
    "authors": [
      "Etrit Haxholli",
      "Marco Lorenzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02738",
    "title": "A Large-Scale Study of Probabilistic Calibration in Neural Network  Regression",
    "abstract": "Accurate probabilistic predictions are essential for optimal decision making. While neural network miscalibration has been studied primarily in classification, we investigate this in the less-explored domain of regression. We conduct the largest empirical study to date to assess the probabilistic calibration of neural networks. We also analyze the performance of recalibration, conformal, and regularization methods to enhance probabilistic calibration. Additionally, we introduce novel differentiable recalibration and regularization methods, uncovering new insights into their effectiveness. Our findings reveal that regularization methods offer a favorable tradeoff between calibration and sharpness. Post-hoc methods exhibit superior probabilistic calibration, which we attribute to the finite-sample coverage guarantee of conformal prediction. Furthermore, we demonstrate that quantile recalibration can be considered as a specific case of conformal prediction. Our study is fully reproducible and implemented in a common code base for fair comparisons. ",
    "url": "https://arxiv.org/abs/2306.02738",
    "authors": [
      "Victor Dheur",
      "Souhaib Ben Taieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02741",
    "title": "ZIGNeRF: Zero-shot 3D Scene Representation with Invertible Generative  Neural Radiance Fields",
    "abstract": "Generative Neural Radiance Fields (NeRFs) have demonstrated remarkable proficiency in synthesizing multi-view images by learning the distribution of a set of unposed images. Despite the aptitude of existing generative NeRFs in generating 3D-consistent high-quality random samples within data distribution, the creation of a 3D representation of a singular input image remains a formidable challenge. In this manuscript, we introduce ZIGNeRF, an innovative model that executes zero-shot Generative Adversarial Network (GAN) inversion for the generation of multi-view images from a single out-of-domain image. The model is underpinned by a novel inverter that maps out-of-domain images into the latent code of the generator manifold. Notably, ZIGNeRF is capable of disentangling the object from the background and executing 3D operations such as 360-degree rotation or depth and horizontal translation. The efficacy of our model is validated using multiple real-image datasets: Cats, AFHQ, CelebA, CelebA-HQ, and CompCars. ",
    "url": "https://arxiv.org/abs/2306.02741",
    "authors": [
      "Kanghyeok Ko",
      "Minhyeok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02744",
    "title": "Towards Better Explanations for Object Detection",
    "abstract": "Recent advances in Artificial Intelligence (AI) technology have promoted their use in almost every field. The growing complexity of deep neural networks (DNNs) makes it increasingly difficult and important to explain the inner workings and decisions of the network. However, most current techniques for explaining DNNs focus mainly on interpreting classification tasks. This paper proposes a method to explain the decision for any object detection model called D-CLOSE. To closely track the model's behavior, we used multiple levels of segmentation on the image and a process to combine them. We performed tests on the MS-COCO dataset with the YOLOX model, which shows that our method outperforms D-RISE and can give a better quality and less noise explanation. ",
    "url": "https://arxiv.org/abs/2306.02744",
    "authors": [
      "Van Binh Truong",
      "Truong Thanh Hung Nguyen",
      "Vo Thanh Khang Nguyen",
      "Quoc Khanh Nguyen",
      "Quoc Hung Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02747",
    "title": "Tackling Non-Stationarity in Reinforcement Learning via Causal-Origin  Representation",
    "abstract": "In real-world scenarios, the application of reinforcement learning is significantly challenged by complex non-stationarity. Most existing methods attempt to model the changes of the environment explicitly, often requiring impractical prior knowledge. In this paper, we propose a new perspective, positing that non-stationarity can propagate and accumulate through complex causal relationships during state transitions, thereby compounding its sophistication and affecting policy learning. We believe that this challenge can be more effectively addressed by tracing the causal origin of non-stationarity. To this end, we introduce the Causal-Origin REPresentation (COREP) algorithm. COREP primarily employs a guided updating mechanism to learn a stable graph representation for states termed as causal-origin representation. By leveraging this representation, the learned policy exhibits impressive resilience to non-stationarity. We supplement our approach with a theoretical analysis grounded in the causal interpretation for non-stationary reinforcement learning, advocating for the validity of the causal-origin representation. Experimental results further demonstrate the superior performance of COREP over existing methods in tackling non-stationarity. ",
    "url": "https://arxiv.org/abs/2306.02747",
    "authors": [
      "Wanpeng Zhang",
      "Yilin Li",
      "Boyu Yang",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02750",
    "title": "The Learning Prescription, A Neural Network Hearing Aid Core",
    "abstract": "The definition of a hearing aid core which is based on a prescription neural network (such as NAL-NL2) is defined here. This hearing aid core replaces a traditional compressor hearing aid core which mimics the said hearing aid prescription. Whilst the replacement of the compressors for a neural network may seem simple, the implications are vast in terms of the \"learning prescription\" where the topology of the neural network may be increased to make available more free parameters and allow great personalisation of the hearing aid prescription. ",
    "url": "https://arxiv.org/abs/2306.02750",
    "authors": [
      "Matt R. Flax"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.02754",
    "title": "PULSAR: Pre-training with Extracted Healthcare Terms for Summarising  Patients' Problems and Data Augmentation with Black-box Large Language Models",
    "abstract": "Medical progress notes play a crucial role in documenting a patient's hospital journey, including his or her condition, treatment plan, and any updates for healthcare providers. Automatic summarisation of a patient's problems in the form of a problem list can aid stakeholders in understanding a patient's condition, reducing workload and cognitive bias. BioNLP 2023 Shared Task 1A focuses on generating a list of diagnoses and problems from the provider's progress notes during hospitalisation. In this paper, we introduce our proposed approach to this task, which integrates two complementary components. One component employs large language models (LLMs) for data augmentation; the other is an abstractive summarisation LLM with a novel pre-training objective for generating the patients' problems summarised as a list. Our approach was ranked second among all submissions to the shared task. The performance of our model on the development and test datasets shows that our approach is more robust on unknown data, with an improvement of up to 3.1 points over the same size of the larger model. ",
    "url": "https://arxiv.org/abs/2306.02754",
    "authors": [
      "Hao Li",
      "Yuping Wu",
      "Viktor Schlegel",
      "Riza Batista-Navarro",
      "Thanh-Tung Nguyen",
      "Abhinav Ramesh Kashyap",
      "Xiaojun Zeng",
      "Daniel Beck",
      "Stefan Winkler",
      "Goran Nenadic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.02760",
    "title": "A2B: Anchor to Barycentric Coordinate for Robust Correspondence",
    "abstract": "There is a long-standing problem of repeated patterns in correspondence problems, where mismatches frequently occur because of inherent ambiguity. The unique position information associated with repeated patterns makes coordinate representations a useful supplement to appearance representations for improving feature correspondences. However, the issue of appropriate coordinate representation has remained unresolved. In this study, we demonstrate that geometric-invariant coordinate representations, such as barycentric coordinates, can significantly reduce mismatches between features. The first step is to establish a theoretical foundation for geometrically invariant coordinates. We present a seed matching and filtering network (SMFNet) that combines feature matching and consistency filtering with a coarse-to-fine matching strategy in order to acquire reliable sparse correspondences. We then introduce DEGREE, a novel anchor-to-barycentric (A2B) coordinate encoding approach, which generates multiple affine-invariant correspondence coordinates from paired images. DEGREE can be used as a plug-in with standard descriptors, feature matchers, and consistency filters to improve the matching quality. Extensive experiments in synthesized indoor and outdoor datasets demonstrate that DEGREE alleviates the problem of repeated patterns and helps achieve state-of-the-art performance. Furthermore, DEGREE also reports competitive performance in the third Image Matching Challenge at CVPR 2021. This approach offers a new perspective to alleviate the problem of repeated patterns and emphasizes the importance of choosing coordinate representations for feature correspondences. ",
    "url": "https://arxiv.org/abs/2306.02760",
    "authors": [
      "Weiyue Zhao",
      "Hao Lu",
      "Zhiguo Cao",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02763",
    "title": "STAR Loss: Reducing Semantic Ambiguity in Facial Landmark Detection",
    "abstract": "Recently, deep learning-based facial landmark detection has achieved significant improvement. However, the semantic ambiguity problem degrades detection performance. Specifically, the semantic ambiguity causes inconsistent annotation and negatively affects the model's convergence, leading to worse accuracy and instability prediction. To solve this problem, we propose a Self-adapTive Ambiguity Reduction (STAR) loss by exploiting the properties of semantic ambiguity. We find that semantic ambiguity results in the anisotropic predicted distribution, which inspires us to use predicted distribution to represent semantic ambiguity. Based on this, we design the STAR loss that measures the anisotropism of the predicted distribution. Compared with the standard regression loss, STAR loss is encouraged to be small when the predicted distribution is anisotropic and thus adaptively mitigates the impact of semantic ambiguity. Moreover, we propose two kinds of eigenvalue restriction methods that could avoid both distribution's abnormal change and the model's premature convergence. Finally, the comprehensive experiments demonstrate that STAR loss outperforms the state-of-the-art methods on three benchmarks, i.e., COFW, 300W, and WFLW, with negligible computation overhead. Code is at https://github.com/ZhenglinZhou/STAR. ",
    "url": "https://arxiv.org/abs/2306.02763",
    "authors": [
      "Zhenglin Zhou",
      "Huaxia Li",
      "Hong Liu",
      "Nanyang Wang",
      "Gang Yu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02776",
    "title": "Cheap-fake Detection with LLM using Prompt Engineering",
    "abstract": "The misuse of real photographs with conflicting image captions in news items is an example of the out-of-context (OOC) misuse of media. In order to detect OOC media, individuals must determine the accuracy of the statement and evaluate whether the triplet (~\\textit{i.e.}, the image and two captions) relates to the same event. This paper presents a novel learnable approach for detecting OOC media in ICME'23 Grand Challenge on Detecting Cheapfakes. The proposed method is based on the COSMOS structure, which assesses the coherence between an image and captions, as well as between two captions. We enhance the baseline algorithm by incorporating a Large Language Model (LLM), GPT3.5, as a feature extractor. Specifically, we propose an innovative approach to feature extraction utilizing prompt engineering to develop a robust and reliable feature extractor with GPT3.5 model. The proposed method captures the correlation between two captions and effectively integrates this module into the COSMOS baseline model, which allows for a deeper understanding of the relationship between captions. By incorporating this module, we demonstrate the potential for significant improvements in cheap-fakes detection performance. The proposed methodology holds promising implications for various applications such as natural language processing, image captioning, and text-to-image synthesis. Docker for submission is available at https://hub.docker.com/repository/docker/mulns/ acmmmcheapfakes. ",
    "url": "https://arxiv.org/abs/2306.02776",
    "authors": [
      "Guangyang Wu",
      "Weijie Wu",
      "Xiaohong Liu",
      "Kele Xu",
      "Tianjiao Wan",
      "Wenyi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02808",
    "title": "Deep Active Learning with Structured Neural Depth Search",
    "abstract": "Previous work optimizes traditional active learning (AL) processes with incremental neural network architecture search (Active-iNAS) based on data complexity change, which improves the accuracy and learning efficiency. However, Active-iNAS trains several models and selects the model with the best generalization performance for querying the subsequent samples after each active learning cycle. The independent training processes lead to an insufferable computational budget, which is significantly inefficient and limits search flexibility and final performance. To address this issue, we propose a novel active strategy with the method called structured variational inference (SVI) or structured neural depth search (SNDS) whereby we could use the gradient descent method in neural network depth search during AL processes. At the same time, we theoretically demonstrate that the current VI-based methods based on the mean-field assumption could lead to poor performance. We apply our strategy using three querying techniques and three datasets and show that our strategy outperforms current methods. ",
    "url": "https://arxiv.org/abs/2306.02808",
    "authors": [
      "Xiaoyun Zhang",
      "Xieyi Ping",
      "Jianwei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02816",
    "title": "MultiAdam: Parameter-wise Scale-invariant Optimizer for Multiscale  Training of Physics-informed Neural Networks",
    "abstract": "Physics-informed Neural Networks (PINNs) have recently achieved remarkable progress in solving Partial Differential Equations (PDEs) in various fields by minimizing a weighted sum of PDE loss and boundary loss. However, there are several critical challenges in the training of PINNs, including the lack of theoretical frameworks and the imbalance between PDE loss and boundary loss. In this paper, we present an analysis of second-order non-homogeneous PDEs, which are classified into three categories and applicable to various common problems. We also characterize the connections between the training loss and actual error, guaranteeing convergence under mild conditions. The theoretical analysis inspires us to further propose MultiAdam, a scale-invariant optimizer that leverages gradient momentum to parameter-wisely balance the loss terms. Extensive experiment results on multiple problems from different physical domains demonstrate that our MultiAdam solver can improve the predictive accuracy by 1-2 orders of magnitude compared with strong baselines. ",
    "url": "https://arxiv.org/abs/2306.02816",
    "authors": [
      "Jiachen Yao",
      "Chang Su",
      "Zhongkai Hao",
      "Songming Liu",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.02819",
    "title": "Enhancing Language Representation with Constructional Information for  Natural Language Understanding",
    "abstract": "Natural language understanding (NLU) is an essential branch of natural language processing, which relies on representations generated by pre-trained language models (PLMs). However, PLMs primarily focus on acquiring lexico-semantic information, while they may be unable to adequately handle the meaning of constructions. To address this issue, we introduce construction grammar (CxG), which highlights the pairings of form and meaning, to enrich language representation. We adopt usage-based construction grammar as the basis of our work, which is highly compatible with statistical models such as PLMs. Then a HyCxG framework is proposed to enhance language representation through a three-stage solution. First, all constructions are extracted from sentences via a slot-constraints approach. As constructions can overlap with each other, bringing redundancy and imbalance, we formulate the conditional max coverage problem for selecting the discriminative constructions. Finally, we propose a relational hypergraph attention network to acquire representation from constructional information by capturing high-order word interactions among constructions. Extensive experiments demonstrate the superiority of the proposed model on a variety of NLU tasks. ",
    "url": "https://arxiv.org/abs/2306.02819",
    "authors": [
      "Lvxiaowei Xu",
      "Jianwang Wu",
      "Jiawei Peng",
      "Zhilin Gong",
      "Ming Cai",
      "Tianxiang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.02822",
    "title": "Discovering Dynamic Causal Space for DAG Structure Learning",
    "abstract": "Discovering causal structure from purely observational data (i.e., causal discovery), aiming to identify causal relationships among variables, is a fundamental task in machine learning. The recent invention of differentiable score-based DAG learners is a crucial enabler, which reframes the combinatorial optimization problem into a differentiable optimization with a DAG constraint over directed graph space. Despite their great success, these cutting-edge DAG learners incorporate DAG-ness independent score functions to evaluate the directed graph candidates, lacking in considering graph structure. As a result, measuring the data fitness alone regardless of DAG-ness inevitably leads to discovering suboptimal DAGs and model vulnerabilities. Towards this end, we propose a dynamic causal space for DAG structure learning, coined CASPER, that integrates the graph structure into the score function as a new measure in the causal space to faithfully reflect the causal distance between estimated and ground truth DAG. CASPER revises the learning process as well as enhances the DAG structure learning via adaptive attention to DAG-ness. Grounded by empirical visualization, CASPER, as a space, satisfies a series of desired properties, such as structure awareness and noise robustness. Extensive experiments on both synthetic and real-world datasets clearly validate the superiority of our CASPER over the state-of-the-art causal discovery methods in terms of accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2306.02822",
    "authors": [
      "Fangfu Liu",
      "Wenchang Ma",
      "An Zhang",
      "Xiang Wang",
      "Yueqi Duan",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02827",
    "title": "UNIDECOR: A Unified Deception Corpus for Cross-Corpus Deception  Detection",
    "abstract": "Verbal deception has been studied in psychology, forensics, and computational linguistics for a variety of reasons, like understanding behaviour patterns, identifying false testimonies, and detecting deception in online communication. Varying motivations across research fields lead to differences in the domain choices to study and in the conceptualization of deception, making it hard to compare models and build robust deception detection systems for a given language. With this paper, we improve this situation by surveying available English deception datasets which include domains like social media reviews, court testimonials, opinion statements on specific topics, and deceptive dialogues from online strategy games. We consolidate these datasets into a single unified corpus. Based on this resource, we conduct a correlation analysis of linguistic cues of deception across datasets to understand the differences and perform cross-corpus modeling experiments which show that a cross-domain generalization is challenging to achieve. The unified deception corpus (UNIDECOR) can be obtained from https://www.ims.uni-stuttgart.de/data/unidecor. ",
    "url": "https://arxiv.org/abs/2306.02827",
    "authors": [
      "Aswathy Velutharambath",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.02834",
    "title": "Computational Complexity of Detecting Proximity to Losslessly  Compressible Neural Network Parameters",
    "abstract": "To better understand complexity in neural networks, we theoretically investigate the idealised phenomenon of lossless network compressibility, whereby an identical function can be implemented with a smaller network. We give an efficient formal algorithm for optimal lossless compression in the setting of single-hidden-layer hyperbolic tangent networks. To measure lossless compressibility, we define the rank of a parameter as the minimum number of hidden units required to implement the same function. Losslessly compressible parameters are atypical, but their existence has implications for nearby parameters. We define the proximate rank of a parameter as the rank of the most compressible parameter within a small $L^\\infty$ neighbourhood. Unfortunately, detecting nearby losslessly compressible parameters is not so easy: we show that bounding the proximate rank is an NP-complete problem, using a reduction from Boolean satisfiability via a geometric problem involving covering points in the plane with small squares. These results underscore the computational complexity of measuring neural network complexity, laying a foundation for future theoretical and empirical work in this direction. ",
    "url": "https://arxiv.org/abs/2306.02834",
    "authors": [
      "Matthew Farrugia-Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2306.02838",
    "title": "Impact of the Covid 19 outbreaks on the italian twitter vaccination  debat: a network based analysis",
    "abstract": "Vaccine hesitancy, or the reluctance to be vaccinated, is a phenomenon that has recently become particularly significant, in conjunction with the vaccination campaign against COVID-19. During the lockdown period, necessary to control the spread of the virus, social networks have played an important role in the Italian debate on vaccination, generally representing the easiest and safest way to exchange opinions and maintain some form of sociability. Among social network platforms, Twitter has assumed a strategic role in driving the public opinion, creating compact groups of users sharing similar views towards the utility, uselessness or even dangerousness of vaccines. In this paper, we present a new, publicly available, dataset of Italian tweets, TwitterVax, collected in the period January 2019--May 2022. Considering monthly data, gathered into forty one retweet networks -- where nodes identify users and edges are present between users who have retweeted each other -- we performed community detection within the networks, analyzing their evolution and polarization with respect to NoVax and ProVax users through time. This allowed us to clearly discover debate trends as well as identify potential key moments and actors in opinion flows, characterizing the main features and tweeting behavior of the two communities. ",
    "url": "https://arxiv.org/abs/2306.02838",
    "authors": [
      "Veronica Lachi",
      "Giovanna Maria Dimitri",
      "Alessandro Di Stefano",
      "Pietro Li\u00f2",
      "Monica Bianchini",
      "Chiara Mocenni"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2306.02841",
    "title": "CTRL: Connect Tabular and Language Model for CTR Prediction",
    "abstract": "Traditional click-through rate (CTR) prediction models convert the tabular data into one-hot vectors and leverage the collaborative relations among features for inferring user's preference over items. This modeling paradigm discards the essential semantic information. Though some recent works like P5 and M6-Rec have explored the potential of using Pre-trained Language Models (PLMs) to extract semantic signals for CTR prediction, they are computationally expensive and suffer from low efficiency. Besides, the beneficial collaborative relations are not considered, hindering the recommendation performance. To solve these problems, in this paper, we propose a novel framework \\textbf{CTRL}, which is industrial friendly and model-agnostic with high training and inference efficiency. Specifically, the original tabular data is first converted into textual data. Both tabular data and converted textual data are regarded as two different modalities and are separately fed into the collaborative CTR model and pre-trained language model. A cross-modal knowledge alignment procedure is performed to fine-grained align and integrate the collaborative and semantic signals, and the lightweight collaborative model can be deployed online for efficient serving after fine-tuned with supervised signals. Experimental results on three public datasets show that CTRL outperforms the SOTA CTR models significantly. Moreover, we further verify its effectiveness on a large-scale industrial recommender system. ",
    "url": "https://arxiv.org/abs/2306.02841",
    "authors": [
      "Xiangyang Li",
      "Bo Chen",
      "Lu Hou",
      "Ruiming Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.02867",
    "title": "Benchmarking Middle-Trained Language Models for Neural Search",
    "abstract": "Middle training methods aim to bridge the gap between the Masked Language Model (MLM) pre-training and the final finetuning for retrieval. Recent models such as CoCondenser, RetroMAE, and LexMAE argue that the MLM task is not sufficient enough to pre-train a transformer network for retrieval and hence propose various tasks to do so. Intrigued by those novel methods, we noticed that all these models used different finetuning protocols, making it hard to assess the benefits of middle training. We propose in this paper a benchmark of CoCondenser, RetroMAE, and LexMAE, under the same finetuning conditions. We compare both dense and sparse approaches under various finetuning protocols and middle training on different collections (MS MARCO, Wikipedia or Tripclick). We use additional middle training baselines, such as a standard MLM finetuning on the retrieval collection, optionally augmented by a CLS predicting the passage term frequency. For the sparse approach, our study reveals that there is almost no statistical difference between those methods: the more effective the finetuning procedure is, the less difference there is between those models. For the dense approach, RetroMAE using MS MARCO as middle-training collection shows excellent results in almost all the settings. Finally, we show that middle training on the retrieval collection, thus adapting the language model to it, is a critical factor. Overall, a better experimental setup should be adopted to evaluate middle training methods. Code available at https://github.com/naver/splade/tree/benchmarch-SIGIR23 ",
    "url": "https://arxiv.org/abs/2306.02867",
    "authors": [
      "Herv\u00e9 D\u00e9jean",
      "St\u00e9phane Clinchant",
      "Carlos Lassance",
      "Simon Lupart",
      "Thibault Formal"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.02879",
    "title": "Neuron Activation Coverage: Rethinking Out-of-distribution Detection and  Generalization",
    "abstract": "The out-of-distribution (OOD) problem generally arises when neural networks encounter data that significantly deviates from the training data distribution, \\ie, in-distribution (InD). In this paper, we study the OOD problem from a neuron activation view. We first formulate neuron activation states by considering both the neuron output and its influence on model decisions. Then, we propose the concept of \\textit{neuron activation coverage} (NAC), which characterizes the neuron behaviors under InD and OOD data. Leveraging our NAC, we show that 1) InD and OOD inputs can be naturally separated based on the neuron behavior, which significantly eases the OOD detection problem and achieves a record-breaking performance of 0.03% FPR95 on ResNet-50, outperforming the previous best method by 20.67%; 2) a positive correlation between NAC and model generalization ability consistently holds across architectures and datasets, which enables a NAC-based criterion for evaluating model robustness. By comparison with the traditional validation criterion, we show that NAC-based criterion not only can select more robust models, but also has a stronger correlation with OOD test performance. ",
    "url": "https://arxiv.org/abs/2306.02879",
    "authors": [
      "Yibing Liu",
      "Chris Xing Tian",
      "Haoliang Li",
      "Lei Ma",
      "Shiqi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02883",
    "title": "Unsupervised network for low-light enhancement",
    "abstract": "Supervised networks address the task of low-light enhancement using paired images. However, collecting a wide variety of low-light/clean paired images is tedious as the scene needs to remain static during imaging. In this paper, we propose an unsupervised low-light enhancement network using contextguided illumination-adaptive norm (CIN). Inspired by coarse to fine methods, we propose to address this task in two stages. In stage-I, a pixel amplifier module (PAM) is used to generate a coarse estimate with an overall improvement in visibility and aesthetic quality. Stage-II further enhances the saturated dark pixels and scene properties of the image using CIN. Different ablation studies show the importance of PAM and CIN in improving the visible quality of the image. Next, we propose a region-adaptive single input multiple output (SIMO) model that can generate multiple enhanced images from a single lowlight image. The objective of SIMO is to let users choose the image of their liking from a pool of enhanced images. Human subjective analysis of SIMO results shows that the distribution of preferred images varies, endorsing the importance of SIMO-type models. Lastly, we propose a low-light road scene (LLRS) dataset having an unpaired collection of low-light and clean scenes. Unlike existing datasets, the clean and low-light scenes in LLRS are real and captured using fixed camera settings. Exhaustive comparisons on publicly available datasets, and the proposed dataset reveal that the results of our model outperform prior art quantitatively and qualitatively. ",
    "url": "https://arxiv.org/abs/2306.02883",
    "authors": [
      "Praveen Kandula",
      "Maitreya Suin",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.02900",
    "title": "Robust Fiber ODF Estimation Using Deep Constrained Spherical  Deconvolution for Diffusion MRI",
    "abstract": "Diffusion-weighted magnetic resonance imaging (DW-MRI) is a critical imaging method for capturing and modeling tissue microarchitecture at a millimeter scale. A common practice to model the measured DW-MRI signal is via fiber orientation distribution function (fODF). This function is the essential first step for the downstream tractography and connectivity analyses. With recent advantages in data sharing, large-scale multi-site DW-MRI datasets are being made available for multi-site studies. However, measurement variabilities (e.g., inter- and intra-site variability, hardware performance, and sequence design) are inevitable during the acquisition of DW-MRI. Most existing model-based methods (e.g., constrained spherical deconvolution (CSD)) and learning based methods (e.g., deep learning (DL)) do not explicitly consider such variabilities in fODF modeling, which consequently leads to inferior performance on multi-site and/or longitudinal diffusion studies. In this paper, we propose a novel data-driven deep constrained spherical deconvolution method to explicitly constrain the scan-rescan variabilities for a more reproducible and robust estimation of brain microstructure from repeated DW-MRI scans. Specifically, the proposed method introduces a new 3D volumetric scanner-invariant regularization scheme during the fODF estimation. We study the Human Connectome Project (HCP) young adults test-retest group as well as the MASiVar dataset (with inter- and intra-site scan/rescan data). The Baltimore Longitudinal Study of Aging (BLSA) dataset is employed for external validation. From the experimental results, the proposed data-driven framework outperforms the existing benchmarks in repeated fODF estimation. The proposed method is assessing the downstream connectivity analysis and shows increased performance in distinguishing subjects with different biomarkers. ",
    "url": "https://arxiv.org/abs/2306.02900",
    "authors": [
      "Tianyuan Yao",
      "Francois Rheault",
      "Leon Y Cai",
      "Vishwesh nath",
      "Zuhayr Asad",
      "Nancy Newlin",
      "Can Cui",
      "Ruining Deng",
      "Karthik Ramadass",
      "Andrea Shafer",
      "Susan Resnick",
      "Kurt Schilling",
      "Bennett A. Landman",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02907",
    "title": "SelfEvolve: A Code Evolution Framework via Large Language Models",
    "abstract": "Large language models (LLMs) have already revolutionized code generation, after being pretrained on publicly available code data. However, while various methods have been proposed to augment LLMs with retrieved knowledge and enhance the quality of code generation, the performance of these retrieval-based methods is limited by the strength of the retrievers used. In addition, while LLMs show great emergent ability, they still struggle to produce the correct code in one turn. To address these challenges, we propose a novel two-step pipeline, called \\autoknow, that leverages LLMs as both knowledge providers and self-reflective programmers. Unlike retrieval-based methods, \\autoknow~obtains the knowledge from input prompts and generates intermediate code based on the generated knowledge. After that, \\autoknow~asks LLM to act as an expert programmer to perform debugging for the generated code. This is achieved by receiving the error message from the interpreter, without requiring special test cases for correctness verification. We evaluate \\autoknow~on three code generation datasets, including DS-1000 for data science code, HumanEval for software engineering code, and TransCoder for C++-to-Python translation. Our empirical experiments show that \\autoknow~outperforms strong baselines by a significant margin on all datasets. We also conduct exhaustive analytical experiments to validate the effectiveness of the two stages of \\autoknow, and find that both are superior to other prompting-based methods. Further scalability analysis demonstrates that \\autoknow~can be adapted to other more advanced models, such as GPT-4, and bring consistent efficacy improvement. ",
    "url": "https://arxiv.org/abs/2306.02907",
    "authors": [
      "Shuyang Jiang",
      "Yuhao Wang",
      "Yu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.02911",
    "title": "Catch Me If You Can: Deep Meta-RL for Search-and-Rescue using LoRa UAV  Networks",
    "abstract": "Long range (LoRa) wireless networks have been widely proposed as a efficient wireless access networks for the battery-constrained Internet of Things (IoT) devices. In many practical search-and-rescue (SAR) operations, one challenging problem is finding the location of devices carried by a lost person. However, using a LoRa-based IoT network for SAR operations will have a limited coverage caused by high signal attenuation due to the terrestrial blockages especially in highly remote areas. To overcome this challenge, the use of unmanned aerial vehicles (UAVs) as a flying LoRa gateway to transfer messages from ground LoRa nodes to the ground rescue station can be a promising solution. In this paper, the problem of the flying LoRa (FL) gateway control in the search-and-rescue system using the UAV-assisted LoRa network is modeled as a partially observable Markov decision process. Then, a deep meta-RL-based policy is proposed to control the FL gateway trajectory during SAR operation. For initialization of proposed deep meta-RL-based policy, first, a deep RL-based policy is designed to determine the adaptive FL gateway trajectory in a fixed search environment including a fixed radio geometry. Then, as a general solution, a deep meta-RL framework is used for SAR in any new and unknown environments to integrate the prior FL gateway experience with information collected from the other search environments and rapidly adapt the SAR policy model for SAR operation in a new environment. The proposed UAV-assisted LoRa network is then experimentally designed and implemented. Practical evaluation results show that if the deep meta-RL based control policy is applied instead of the deep RL-based one, the number of SAR time slots decreases from 141 to 50. ",
    "url": "https://arxiv.org/abs/2306.02911",
    "authors": [
      "Mehdi Naderi Soorki",
      "Hossein Aghajari",
      "Sajad Ahmadinabi",
      "Hamed Bakhtiari Babadegani",
      "Christina Chaccoury",
      "Walid Saad"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.02918",
    "title": "Adversarial Ink: Componentwise Backward Error Attacks on Deep Learning",
    "abstract": "Deep neural networks are capable of state-of-the-art performance in many classification tasks. However, they are known to be vulnerable to adversarial attacks -- small perturbations to the input that lead to a change in classification. We address this issue from the perspective of backward error and condition number, concepts that have proved useful in numerical analysis. To do this, we build on the work of Beuzeville et al. (2021). In particular, we develop a new class of attack algorithms that use componentwise relative perturbations. Such attacks are highly relevant in the case of handwritten documents or printed texts where, for example, the classification of signatures, postcodes, dates or numerical quantities may be altered by changing only the ink consistency and not the background. This makes the perturbed images look natural to the naked eye. Such ``adversarial ink'' attacks therefore reveal a weakness that can have a serious impact on safety and security. We illustrate the new attacks on real data and contrast them with existing algorithms. We also study the use of a componentwise condition number to quantify vulnerability. ",
    "url": "https://arxiv.org/abs/2306.02918",
    "authors": [
      "Lucas Beerens",
      "Desmond J. Higham"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.02920",
    "title": "Second Language Acquisition of Neural Language Models",
    "abstract": "With the success of neural language models (LMs), their language acquisition has gained much attention. This work sheds light on the second language (L2) acquisition of LMs, while previous work has typically explored their first language (L1) acquisition. Specifically, we trained bilingual LMs with a scenario similar to human L2 acquisition and analyzed their cross-lingual transfer from linguistic perspectives. Our exploratory experiments demonstrated that the L1 pretraining accelerated their linguistic generalization in L2, and language transfer configurations (e.g., the L1 choice, and presence of parallel texts) substantially affected their generalizations. These clarify their (non-)human-like L2 acquisition in particular aspects. ",
    "url": "https://arxiv.org/abs/2306.02920",
    "authors": [
      "Miyu Oba",
      "Tatsuki Kuribayashi",
      "Hiroki Ouchi",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.02928",
    "title": "Weakly-Supervised Conditional Embedding for Referred Visual Search",
    "abstract": "This paper presents a new approach to image similarity search in the context of fashion, a domain with inherent ambiguity due to the multiple ways in which images can be considered similar. We introduce the concept of Referred Visual Search (RVS), where users provide additional information to define the desired similarity. We present a new dataset, LAION-RVS-Fashion, consisting of 272K fashion products with 842K images extracted from LAION, designed explicitly for this task. We then propose an innovative method for learning conditional embeddings using weakly-supervised training, achieving a 6% increase in Recall at one (R@1) against a gallery with 2M distractors, compared to classical approaches based on explicit attention and filtering. The proposed method demonstrates robustness, maintaining similar R@1 when dealing with 2.5 times as many distractors as the baseline methods. We believe this is a step forward in the emerging field of Referred Visual Search both in terms of accessible data and approach. Code, data and models are available at https://www.github.com/Simon-Lepage/CondViT-LRVSF . ",
    "url": "https://arxiv.org/abs/2306.02928",
    "authors": [
      "Simon Lepage",
      "J\u00e9r\u00e9mie Mary",
      "David Picard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02934",
    "title": "Modeling Tor Network Growth by Extrapolating Consensus Data",
    "abstract": "Since the Tor network is evolving into an infrastructure for anonymous communication, analyzing the consequences of network growth is becoming more relevant than ever. In particular, adding large amounts of resources may have unintentional consequences for the system performance as well as security. To this end, we contribute a methodology for the analysis of scaled Tor networks that enables researchers to leverage real-world network data. Based on historical network snapshots (consensuses), we derive and implement a model for methodically scaling Tor consensuses. This allows researchers to apply established research methods to scaled networks. We validate our model based on historical data, showing its applicability. Furthermore, we demonstrate the merits of our data-driven approach by conducting a simulation study to identify performance impacts of scaling Tor. ",
    "url": "https://arxiv.org/abs/2306.02934",
    "authors": [
      "Christoph D\u00f6pmann",
      "Florian Tschorsch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.02955",
    "title": "A Simple and Flexible Modeling for Mental Disorder Detection by Learning  from Clinical Questionnaires",
    "abstract": "Social media is one of the most highly sought resources for analyzing characteristics of the language by its users. In particular, many researchers utilized various linguistic features of mental health problems from social media. However, existing approaches to detecting mental disorders face critical challenges, such as the scarcity of high-quality data or the trade-off between addressing the complexity of models and presenting interpretable results grounded in expert domain knowledge. To address these challenges, we design a simple but flexible model that preserves domain-based interpretability. We propose a novel approach that captures the semantic meanings directly from the text and compares them to symptom-related descriptions. Experimental results demonstrate that our model outperforms relevant baselines on various mental disorder detection tasks. Our detailed analysis shows that the proposed model is effective at leveraging domain knowledge, transferable to other mental disorders, and providing interpretable detection results. ",
    "url": "https://arxiv.org/abs/2306.02955",
    "authors": [
      "Hoyun Song",
      "Jisu Shin",
      "Huije Lee",
      "Jong C. Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02956",
    "title": "Explicit Neural Surfaces: Learning Continuous Geometry With Deformation  Fields",
    "abstract": "We introduce Explicit Neural Surfaces (ENS), an efficient surface reconstruction method that learns an explicitly defined continuous surface from multiple views. We use a series of neural deformation fields to progressively transform a continuous input surface to a target shape. By sampling meshes as discrete surface proxies, we train the deformation fields through efficient differentiable rasterization, and attain a mesh-independent and smooth surface representation. By using Laplace-Beltrami eigenfunctions as an intrinsic positional encoding alongside standard extrinsic Fourier features, our approach can capture fine surface details. ENS trains 1 to 2 orders of magnitude faster and can extract meshes of higher quality compared to implicit representations, whilst maintaining competitive surface reconstruction performance and real-time capabilities. Finally, we apply our approach to learn a collection of objects in a single model, and achieve disentangled interpolations between different shapes, their surface details, and textures. ",
    "url": "https://arxiv.org/abs/2306.02956",
    "authors": [
      "Thomas Walker",
      "Octave Mariotti",
      "Amir Vaxman",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02957",
    "title": "Complex Preferences for Different Convergent Priors in Discrete Graph  Diffusion",
    "abstract": "Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos. Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework. To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs. To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance. We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuitions which previous works have suggested. ",
    "url": "https://arxiv.org/abs/2306.02957",
    "authors": [
      "Alex M. Tseng",
      "Nathaniel Diamant",
      "Tommaso Biancalani",
      "Gabriele Scalia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02964",
    "title": "Beyond Harm: an Ethical Framework to Tackle Misinformation on Social  Media",
    "abstract": "This paper aims to build an actionable framework for permissible online content moderation to combat misinformation. Often strong content moderation policies are invoked when misinformation causes harm. By adopting Mill's ethical framework, I show the complexities involved in permissible content moderation. The conclusion will be that, besides invoking the notion of harm, we should also introduce the idea of cognitive autonomy and adopt useful tools, such as cognitive nudging, to promote a healthier epistemic environment online. ",
    "url": "https://arxiv.org/abs/2306.02964",
    "authors": [
      "Marianna Ganapini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.02978",
    "title": "Which Argumentative Aspects of Hate Speech in Social Media can be  reliably identified?",
    "abstract": "With the increasing diversity of use cases of large language models, a more informative treatment of texts seems necessary. An argumentative analysis could foster a more reasoned usage of chatbots, text completion mechanisms or other applications. However, it is unclear which aspects of argumentation can be reliably identified and integrated in language models. In this paper, we present an empirical assessment of the reliability with which different argumentative aspects can be automatically identified in hate speech in social media. We have enriched the Hateval corpus (Basile et al. 2019) with a manual annotation of some argumentative components, adapted from Wagemans (2016)'s Periodic Table of Arguments. We show that some components can be identified with reasonable reliability. For those that present a high error ratio, we analyze the patterns of disagreement between expert annotators and errors in automatic procedures, and we propose adaptations of those categories that can be more reliably reproduced. ",
    "url": "https://arxiv.org/abs/2306.02978",
    "authors": [
      "Dami\u00e1n Furman",
      "Pablo Torres",
      "Jos\u00e9 A. Rodr\u00edguez",
      "Diego Letzen",
      "Vanina Mart\u00ednez",
      "Laura Alonso Alemany"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.03000",
    "title": "BeyondPixels: A Comprehensive Review of the Evolution of Neural Radiance  Fields",
    "abstract": "Neural rendering combines ideas from classical computer graphics and machine learning to synthesize images from real-world observations. NeRF, short for Neural Radiance Fields, is a recent innovation that uses AI algorithms to create 3D objects from 2D images. By leveraging an interpolation approach, NeRF can produce new 3D reconstructed views of complicated scenes. Rather than directly restoring the whole 3D scene geometry, NeRF generates a volumetric representation called a ``radiance field,'' which is capable of creating color and density for every point within the relevant 3D space. The broad appeal and notoriety of NeRF make it imperative to examine the existing research on the topic comprehensively. While previous surveys on 3D rendering have primarily focused on traditional computer vision-based or deep learning-based approaches, only a handful of them discuss the potential of NeRF. However, such surveys have predominantly focused on NeRF's early contributions and have not explored its full potential. NeRF is a relatively new technique continuously being investigated for its capabilities and limitations. This survey reviews recent advances in NeRF and categorizes them according to their architectural designs, especially in the field of novel view synthesis. ",
    "url": "https://arxiv.org/abs/2306.03000",
    "authors": [
      "AKM Shahariar Azad Rabby",
      "Chengcui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.03002",
    "title": "Unveiling the Two-Faced Truth: Disentangling Morphed Identities for Face  Morphing Detection",
    "abstract": "Morphing attacks keep threatening biometric systems, especially face recognition systems. Over time they have become simpler to perform and more realistic, as such, the usage of deep learning systems to detect these attacks has grown. At the same time, there is a constant concern regarding the lack of interpretability of deep learning models. Balancing performance and interpretability has been a difficult task for scientists. However, by leveraging domain information and proving some constraints, we have been able to develop IDistill, an interpretable method with state-of-the-art performance that provides information on both the identity separation on morph samples and their contribution to the final prediction. The domain information is learnt by an autoencoder and distilled to a classifier system in order to teach it to separate identity information. When compared to other methods in the literature it outperforms them in three out of five databases and is competitive in the remaining. ",
    "url": "https://arxiv.org/abs/2306.03002",
    "authors": [
      "Eduarda Caldeira",
      "Pedro C. Neto",
      "Tiago Gon\u00e7alves",
      "Naser Damer",
      "Ana F. Sequeira",
      "Jaime S. Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.03013",
    "title": "Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated  Learning",
    "abstract": "Malicious server (MS) attacks have enabled the scaling of data stealing in federated learning to large batch sizes and secure aggregation, settings previously considered private. However, many concerns regarding client-side detectability of MS attacks were raised, questioning their practicality once they are publicly known. In this work, for the first time, we thoroughly study the problem of client-side detectability.We demonstrate that most prior MS attacks, which fundamentally rely on one of two key principles, are detectable by principled client-side checks. Further, we formulate desiderata for practical MS attacks and propose SEER, a novel attack framework that satisfies all desiderata, while stealing user data from gradients of realistic networks, even for large batch sizes (up to 512 in our experiments) and under secure aggregation. The key insight of SEER is the use of a secret decoder, which is jointly trained with the shared model. Our work represents a promising first step towards more principled treatment of MS attacks, paving the way for realistic data stealing that can compromise user privacy in real-world deployments. ",
    "url": "https://arxiv.org/abs/2306.03013",
    "authors": [
      "Kostadin Garov",
      "Dimitar I. Dimitrov",
      "Nikola Jovanovi\u0107",
      "Martin Vechev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.03041",
    "title": "Embedding Delay-Constrained VNF Forwarding Graphs into Reconfigurable  WDM Optical Networks -- Extended Version",
    "abstract": "Operators of reconfigurable wavelength-division multiplexed (WDM) optical networks adapt the lightpath topology to balance load and reduce transmission delays. Such an adaption generally depends on a known or estimated traffic matrix. Network function virtualization (NFV) allows to implicitly change this traffic matrix. However, these two degrees of freedom have largely been considered separately, using resources suboptimally. Especially for delay-sensitive services, an optimal use of resources can be crucial. We aim to jointly optimize the embedding of virtualized network function (VNF) forwarding graphs with delay constraints and the lightpath topology of WDM optical networks. Unlike previous work, we consider all three types of delays: propagation, processing and forwarding-induced queuing delay. We model the latter two as M/M/1 queues. We formulate and analyze a mixed-integer nonlinear program (MINLP), reformulate it as a mixed-integer quadratic constrained program (MIQCP) and approximate it by a mixed-integer linear program (MILP). We evaluate our approach for small-scale examples of a multicast service. ",
    "url": "https://arxiv.org/abs/2306.03041",
    "authors": [
      "Valentin Kirchner",
      "Holger Karl"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.03045",
    "title": "Designing Equilibria in Concurrent Games with Social Welfare and  Temporal Logic Constraints",
    "abstract": "In game theory, mechanism design is concerned with the design of incentives so that a desired outcome of the game can be achieved. In this paper, we explore the concept of equilibrium design, where incentives are designed to obtain a desirable equilibrium that satisfies a specific temporal logic property. Our study is based on a framework where system specifications are represented as temporal logic formulae, games as quantitative concurrent game structures, and players' goals as mean-payoff objectives. We consider system specifications given by LTL and GR(1) formulae, and show that designing incentives to ensure that a given temporal logic property is satisfied on some/every Nash equilibrium of the game can be achieved in PSPACE for LTL properties and in NP/{\\Sigma}P 2 for GR(1) specifications. We also examine the complexity of related decision and optimisation problems, such as optimality and uniqueness of solutions, as well as considering social welfare, and show that the complexities of these problems lie within the polynomial hierarchy. Equilibrium design can be used as an alternative solution to rational synthesis and verification problems for concurrent games with mean-payoff objectives when no solution exists or as a technique to repair concurrent games with undesirable Nash equilibria in an optimal way. ",
    "url": "https://arxiv.org/abs/2306.03045",
    "authors": [
      "Julian Gutierrez",
      "Muhammad Najib",
      "Giuseppe Perelli",
      "Michael Wooldridge"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2306.03048",
    "title": "From Robustness to Explainability and Back Again",
    "abstract": "In contrast with ad-hoc methods for eXplainable Artificial Intelligence (XAI), formal explainability offers important guarantees of rigor. However, formal explainability is hindered by poor scalability for some families of classifiers, the most significant being neural networks. As a result, there are concerns as to whether formal explainability might serve to complement other approaches in delivering trustworthy AI. This paper addresses the limitation of scalability of formal explainability, and proposes novel algorithms for computing formal explanations. The novel algorithm computes explanations by answering instead a number of robustness queries, and such that the number of such queries is at most linear on the number of features. Consequently, the proposed algorithm establishes a direct relationship between the practical complexity of formal explainability and that of robustness. More importantly, the paper generalizes the definition of formal explanation, thereby allowing the use of robustness tools that are based on different distance norms, and also by reasoning in terms of some target degree of robustness. The experiments validate the practical efficiency of the proposed approach. ",
    "url": "https://arxiv.org/abs/2306.03048",
    "authors": [
      "Xuanxiang Huang",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.03054",
    "title": "Discriminative Adversarial Privacy: Balancing Accuracy and Membership  Privacy in Neural Networks",
    "abstract": "The remarkable proliferation of deep learning across various industries has underscored the importance of data privacy and security in AI pipelines. As the evolution of sophisticated Membership Inference Attacks (MIAs) threatens the secrecy of individual-specific information used for training deep learning models, Differential Privacy (DP) raises as one of the most utilized techniques to protect models against malicious attacks. However, despite its proven theoretical properties, DP can significantly hamper model performance and increase training time, turning its use impractical in real-world scenarios. Tackling this issue, we present Discriminative Adversarial Privacy (DAP), a novel learning technique designed to address the limitations of DP by achieving a balance between model performance, speed, and privacy. DAP relies on adversarial training based on a novel loss function able to minimise the prediction error while maximising the MIA's error. In addition, we introduce a novel metric named Accuracy Over Privacy (AOP) to capture the performance-privacy trade-off. Finally, to validate our claims, we compare DAP with diverse DP scenarios, providing an analysis of the results from performance, time, and privacy preservation perspectives. ",
    "url": "https://arxiv.org/abs/2306.03054",
    "authors": [
      "Eugenio Lomurno",
      "Alberto Archetti",
      "Francesca Ausonio",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.03058",
    "title": "Shoal: Improving DAG-BFT Latency And Robustness",
    "abstract": "The Narwhal system is a state-of-the-art Byzantine fault-tolerant scalable architecture that involves constructing a directed acyclic graph (DAG) of messages among a set of validators in a Blockchain network. Bullshark is a zero-overhead consensus protocol on top of the Narwhal's DAG that can order over 100k transactions per second. Unfortunately, the high throughput of Bullshark comes with a latency price due to the DAG construction, increasing the latency compared to the state-of-the-art leader-based BFT consensus protocols. We introduce Shoal, a protocol-agnostic framework for enhancing Narwhal-based consensus. By incorporating leader reputation and pipelining support for the first time, Shoal significantly reduces latency. Moreover, the combination of properties of the DAG construction and the leader reputation mechanism enables the elimination of timeouts in all but extremely uncommon scenarios in practice, a property we name Prevalent Responsiveness\" (it strictly subsumes the established and often desired Optimistic Responsiveness property for BFT protocols). We integrated Shoal instantiated with Bullshark, the fastest existing Narwhal-based consensus protocol, in an open-source Blockchain project and provide experimental evaluations demonstrating up to 40% latency reduction in the failure-free executions, and up-to 80% reduction in executions with failures against the vanilla Bullshark implementation. ",
    "url": "https://arxiv.org/abs/2306.03058",
    "authors": [
      "Alexander Spiegelman",
      "Balaji Aurn",
      "Rati Gelashvili",
      "Zekun Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2306.03078",
    "title": "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight  Compression",
    "abstract": "Recent advances in large language model (LLM) pretraining have led to high-quality LLMs with impressive abilities. By compressing such LLMs via quantization to 3-4 bits per parameter, they can fit into memory-limited devices such as laptops and mobile phones, enabling personalized use. However, quantization down to 3-4 bits per parameter usually leads to moderate-to-high accuracy losses, especially for smaller models in the 1-10B parameter range, which are well-suited for edge deployments. To address this accuracy issue, we introduce the Sparse-Quantized Representation (SpQR), a new compressed format and quantization technique which enables for the first time near-lossless compression of LLMs across model scales, while reaching similar compression levels to previous methods. SpQR works by identifying and isolating outlier weights, which cause particularly-large quantization errors, and storing them in higher precision, while compressing all other weights to 3-4 bits, and achieves relative accuracy losses of less than 1% in perplexity for highly-accurate LLaMA and Falcon LLMs. This makes it possible to run 33B parameter LLM on a single 24 GB consumer GPU without any performance degradation at 15% speedup thus making powerful LLMs available to consumer without any downsides. SpQR comes with efficient algorithms for both encoding weights into its format, as well as decoding them efficiently at runtime. Specifically, we provide an efficient GPU inference algorithm for SpQR which yields faster inference than 16-bit baselines at similar accuracy, while enabling memory compression gains of more than 4x. ",
    "url": "https://arxiv.org/abs/2306.03078",
    "authors": [
      "Tim Dettmers",
      "Ruslan Svirschevski",
      "Vage Egiazarian",
      "Denis Kuznedelev",
      "Elias Frantar",
      "Saleh Ashkboos",
      "Alexander Borzunov",
      "Torsten Hoefler",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.03083",
    "title": "MotionDiffuser: Controllable Multi-Agent Motion Prediction using  Diffusion",
    "abstract": "We present MotionDiffuser, a diffusion based representation for the joint distribution of future trajectories over multiple agents. Such representation has several key advantages: first, our model learns a highly multimodal distribution that captures diverse future outcomes. Second, the simple predictor design requires only a single L2 loss training objective, and does not depend on trajectory anchors. Third, our model is capable of learning the joint distribution for the motion of multiple agents in a permutation-invariant manner. Furthermore, we utilize a compressed trajectory representation via PCA, which improves model performance and allows for efficient computation of the exact sample log probability. Subsequently, we propose a general constrained sampling framework that enables controlled trajectory sampling based on differentiable cost functions. This strategy enables a host of applications such as enforcing rules and physical priors, or creating tailored simulation scenarios. MotionDiffuser can be combined with existing backbone architectures to achieve top motion forecasting results. We obtain state-of-the-art results for multi-agent motion prediction on the Waymo Open Motion Dataset. ",
    "url": "https://arxiv.org/abs/2306.03083",
    "authors": [
      "Chiyu Max Jiang",
      "Andre Cornman",
      "Cheolho Park",
      "Ben Sapp",
      "Yin Zhou",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.03088",
    "title": "DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear  Functional Brain Network Dynamics",
    "abstract": "Functional brain dynamics is supported by parallel and overlapping functional network modes that are associated with specific neural circuits. Decomposing these network modes from fMRI data and finding their temporal characteristics is challenging due to their time-varying nature and the non-linearity of the functional dynamics. Dynamic Mode Decomposition (DMD) algorithms have been quite popular for solving this decomposition problem in recent years. In this work, we apply GraphDMD -- an extension of the DMD for network data -- to extract the dynamic network modes and their temporal characteristics from the fMRI time series in an interpretable manner. GraphDMD, however, regards the underlying system as a linear dynamical system that is sub-optimal for extracting the network modes from non-linear functional data. In this work, we develop a generalized version of the GraphDMD algorithm -- DeepGraphDMD -- applicable to arbitrary non-linear graph dynamical systems. DeepGraphDMD is an autoencoder-based deep learning model that learns Koopman eigenfunctions for graph data and embeds the non-linear graph dynamics into a latent linear space. We show the effectiveness of our method in both simulated data and the HCP resting-state fMRI data. In the HCP data, DeepGraphDMD provides novel insights into cognitive brain functions by discovering two major network modes related to fluid and crystallized intelligence. ",
    "url": "https://arxiv.org/abs/2306.03088",
    "authors": [
      "Md Asadullah Turja",
      "Martin Styner",
      "Guorong Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.03091",
    "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems",
    "abstract": "Large Language Models (LLMs) have greatly advanced code auto-completion systems, with a potential for substantial productivity enhancements for developers. However, current benchmarks mainly focus on single-file tasks, leaving an assessment gap for more complex, real-world, multi-file programming scenarios. To fill this gap, we introduce RepoBench, a new benchmark specifically designed for evaluating repository-level code auto-completion systems. RepoBench consists of three interconnected evaluation tasks: RepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P (Pipeline). Each task respectively measures the system's ability to retrieve the most relevant code snippets from other files as cross-file context, predict the next line of code with cross-file and in-file context, and handle complex tasks that require a combination of both retrieval and next-line prediction. RepoBench aims to facilitate a more complete comparison of performance and encouraging continuous improvement in auto-completion systems. RepoBench is publicly available at https://github.com/Leolty/repobench. ",
    "url": "https://arxiv.org/abs/2306.03091",
    "authors": [
      "Tianyang Liu",
      "Canwen Xu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.03092",
    "title": "Neuralangelo: High-Fidelity Neural Surface Reconstruction",
    "abstract": "Neural surface reconstruction has been shown to be powerful for recovering dense 3D surfaces via image-based neural rendering. However, current methods struggle to recover detailed structures of real-world scenes. To address the issue, we present Neuralangelo, which combines the representation power of multi-resolution 3D hash grids with neural surface rendering. Two key ingredients enable our approach: (1) numerical gradients for computing higher-order derivatives as a smoothing operation and (2) coarse-to-fine optimization on the hash grids controlling different levels of details. Even without auxiliary inputs such as depth, Neuralangelo can effectively recover dense 3D surface structures from multi-view images with fidelity significantly surpassing previous methods, enabling detailed large-scale scene reconstruction from RGB video captures. ",
    "url": "https://arxiv.org/abs/2306.03092",
    "authors": [
      "Zhaoshuo Li",
      "Thomas M\u00fcller",
      "Alex Evans",
      "Russell H. Taylor",
      "Mathias Unberath",
      "Ming-Yu Liu",
      "Chen-Hsuan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01745",
    "title": "Biomarker Discovery with Quantum Neural Networks: A Case-study in  CTLA4-Activation Pathways",
    "abstract": "Biomarker discovery is a challenging task due to the massive search space. Quantum computing and quantum Artificial Intelligence (quantum AI) can be used to address the computational problem of biomarker discovery tasks. We propose a Quantum Neural Networks (QNNs) architecture to discover biomarkers for input activation pathways. The Maximum Relevance, Minimum Redundancy (mRMR) criteria is used to score biomarker candidate sets. Our proposed model is economical since the neural solution can be delivered on constrained hardware. We demonstrate the proof of concept on four activation pathways associated with CTLA4, including (1) CTLA4-activation stand-alone, (2) CTLA4-CD8A-CD8B co-activation, (3) CTLA4-CD2 co-activation, and (4) CTLA4-CD2-CD48-CD53-CD58-CD84 co-activation. The model indicates new biomarkers associated with the mutational activation of CLTA4-associated pathways, including 20 genes: CLIC4, CPE, ETS2, FAM107A, GPR116, HYOU1, LCN2, MACF1, MT1G, NAPA, NDUFS5, PAK1, PFN1, PGAP3, PPM1G, PSMD8, RNF213, SLC25A3, UBA1, and WLS. We open source the implementation at: https://github.com/namnguyen0510/Biomarker-Discovery-with-Quantum-Neural-Networks. ",
    "url": "https://arxiv.org/abs/2306.01745",
    "authors": [
      "Nam Nguyen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.01752",
    "title": "Handling Label Uncertainty on the Example of Automatic Detection of  Shepherd's Crook RCA in Coronary CT Angiography",
    "abstract": "Coronary artery disease (CAD) is often treated minimally invasively with a catheter being inserted into the diseased coronary vessel. If a patient exhibits a Shepherd's Crook (SC) Right Coronary Artery (RCA) - an anatomical norm variant of the coronary vasculature - the complexity of this procedure is increased. Automated reporting of this variant from coronary CT angiography screening would ease prior risk assessment. We propose a 1D convolutional neural network which leverages a sequence of residual dilated convolutions to automatically determine this norm variant from a prior extracted vessel centerline. As the SC RCA is not clearly defined with respect to concrete measurements, labeling also includes qualitative aspects. Therefore, 4.23% samples in our dataset of 519 RCA centerlines were labeled as unsure SC RCAs, with 5.97% being labeled as sure SC RCAs. We explore measures to handle this label uncertainty, namely global/model-wise random assignment, exclusion, and soft label assignment. Furthermore, we evaluate how this uncertainty can be leveraged for the determination of a rejection class. With our best configuration, we reach an area under the receiver operating characteristic curve (AUC) of 0.938 on confident labels. Moreover, we observe an increase of up to 0.020 AUC when rejecting 10% of the data and leveraging the labeling uncertainty information in the exclusion process. ",
    "url": "https://arxiv.org/abs/2306.01752",
    "authors": [
      "Felix Denzinger",
      "Michael Wels",
      "Oliver Taubmann",
      "Florian Kordon",
      "Fabian Wagner",
      "Stephanie Mehltretter",
      "Mehmet A. G\u00fcls\u00fcn",
      "Max Sch\u00f6binger",
      "Florian Andr\u00e9",
      "Sebastian Buss",
      "Johannes G\u00f6rich",
      "Michael S\u00fchling",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01793",
    "title": "Hypoxia-resistance heterogeneity in tumours: the impact of geometrical  characterization of environmental niches and evolutionary trade-offs. A  mathematical approach",
    "abstract": "In the study of cancer evolution and therapeutic strategies, scientific evidence shows that a key dynamics lies in the tumor-environment interaction. In particular, oxygen concentration plays a central role in the determination of the phenotypic heterogeneity of cancer cell populations, whose qualitative and geometric characteristics are predominant factors in the occurrence of relapses and failure of eradication. We propose a mathematical model able to describe the eco-evolutionary spatial dynamics of tumour cells in their adaptation to hypoxic microenvironments. As a main novelty with respect to the existing literature, we combine a phenotypic indicator reflecting the experimentally-observed metabolic trade-off between the hypoxia-resistance ability and the proliferative potential with a 2d geometric domain, without the constraint of radial symmetry. The model is settled in the mathematical framework of phenotype-structured population dynamics and it is formulated in terms of systems of coupled non-linear integro-differential equations. The computational outcomes demonstrate that hypoxia-induced selection results in a geometric characterization of phenotypic-defined tumour niches that impact on tumour aggressiveness and invasive ability. Furthermore, results show how the knowledge of environmental characteristics provides a predictive advantage on tumour mass development in terms of size, shape, and composition. ",
    "url": "https://arxiv.org/abs/2306.01793",
    "authors": [
      "Giulia Chiari",
      "Giada Fiandaca",
      "Marcello Edoardo Delitala"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2306.01802",
    "title": "Linear Time GPs for Inferring Latent Trajectories from Neural Spike  Trains",
    "abstract": "Latent Gaussian process (GP) models are widely used in neuroscience to uncover hidden state evolutions from sequential observations, mainly in neural activity recordings. While latent GP models provide a principled and powerful solution in theory, the intractable posterior in non-conjugate settings necessitates approximate inference schemes, which may lack scalability. In this work, we propose cvHM, a general inference framework for latent GP models leveraging Hida-Mat\\'ern kernels and conjugate computation variational inference (CVI). With cvHM, we are able to perform variational inference of latent neural trajectories with linear time complexity for arbitrary likelihoods. The reparameterization of stationary kernels using Hida-Mat\\'ern GPs helps us connect the latent variable models that encode prior assumptions through dynamical systems to those that encode trajectory assumptions through GPs. In contrast to previous work, we use bidirectional information filtering, leading to a more concise implementation. Furthermore, we employ the Whittle approximate likelihood to achieve highly efficient hyperparameter learning. ",
    "url": "https://arxiv.org/abs/2306.01802",
    "authors": [
      "Matthew Dowling",
      "Yuan Zhao",
      "Il Memming Park"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01824",
    "title": "Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence  Alignment Generation",
    "abstract": "The field of protein folding research has been greatly advanced by deep learning methods, with AlphaFold2 (AF2) demonstrating exceptional performance and atomic-level precision. As co-evolution is integral to protein structure prediction, AF2's accuracy is significantly influenced by the depth of multiple sequence alignment (MSA), which requires extensive exploration of a large protein database for similar sequences. However, not all protein sequences possess abundant homologous families, and consequently, AF2's performance can degrade on such queries, at times failing to produce meaningful results. To address this, we introduce a novel generative language model, MSA-Augmenter, which leverages protein-specific attention mechanisms and large-scale MSAs to generate useful, novel protein sequences not currently found in databases. These sequences supplement shallow MSAs, enhancing the accuracy of structural property predictions. Our experiments on CASP14 demonstrate that MSA-Augmenter can generate de novo sequences that retain co-evolutionary information from inferior MSAs, thereby improving protein structure prediction quality on top of strong AF2. ",
    "url": "https://arxiv.org/abs/2306.01824",
    "authors": [
      "Le Zhang",
      "Jiayang Chen",
      "Tao Shen",
      "Yu Li",
      "Siqi Sun"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2306.01916",
    "title": "In-the-wild Speech Emotion Conversion Using Disentangled Self-Supervised  Representations and Neural Vocoder-based Resynthesis",
    "abstract": "Speech emotion conversion aims to convert the expressed emotion of a spoken utterance to a target emotion while preserving the lexical information and the speaker's identity. In this work, we specifically focus on in-the-wild emotion conversion where parallel data does not exist, and the problem of disentangling lexical, speaker, and emotion information arises. In this paper, we introduce a methodology that uses self-supervised networks to disentangle the lexical, speaker, and emotional content of the utterance, and subsequently uses a HiFiGAN vocoder to resynthesise the disentangled representations to a speech signal of the targeted emotion. For better representation and to achieve emotion intensity control, we specifically focus on the aro\\-usal dimension of continuous representations, as opposed to performing emotion conversion on categorical representations. We test our methodology on the large in-the-wild MSP-Podcast dataset. Results reveal that the proposed approach is aptly conditioned on the emotional content of input speech and is capable of synthesising natural-sounding speech for a target emotion. Results further reveal that the methodology better synthesises speech for mid-scale arousal (2 to 6) than for extreme arousal (1 and 7). ",
    "url": "https://arxiv.org/abs/2306.01916",
    "authors": [
      "Navin Raj Prabhu",
      "Nale Lehmann-Willenbrock",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01952",
    "title": "Online Control with Adversarial Disturbance for Continuous-time Linear  Systems",
    "abstract": "We study online control for continuous-time linear systems with finite sampling rates, where the objective is to design an online procedure that learns under non-stochastic noise and performs comparably to a fixed optimal linear controller. We present a novel two-level online algorithm, by integrating a higher-level learning strategy and a lower-level feedback control strategy. This method offers a practical and robust solution for online control, which achieves sublinear regret. Our work provides one of the first nonasymptotic results for controlling continuous-time linear systems a with finite number of interactions with the system. ",
    "url": "https://arxiv.org/abs/2306.01952",
    "authors": [
      "Jingwei Li",
      "Jing Dong",
      "Baoxiang Wang",
      "Jingzhao Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.02065",
    "title": "Make a graph singly connected by edge orientations",
    "abstract": "A directed graph $D$ is singly connected if for every ordered pair of vertices $(s,t)$, there is at most one path from $s$ to $t$ in $D$. Graph orientation problems ask, given an undirected graph $G$, to find an orientation of the edges such that the resultant directed graph $D$ has a certain property. In this work, we study the graph orientation problem where the desired property is that $D$ is singly connected. Our main result concerns graphs of a fixed girth $g$ and coloring number $c$. For every $g,c\\geq 3$, the problem restricted to instances of girth $g$ and coloring number $c$, is either NP-complete or in P. As further algorithmic results, we show that the problem is NP-hard on planar graphs and polynomial time solvable distance-hereditary graphs. ",
    "url": "https://arxiv.org/abs/2306.02065",
    "authors": [
      "Tim A. Hartmann",
      "Komal Muluk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.02108",
    "title": "Random matrix theory and the loss surfaces of neural networks",
    "abstract": "Neural network models are one of the most successful approaches to machine learning, enjoying an enormous amount of development and research over recent years and finding concrete real-world applications in almost any conceivable area of science, engineering and modern life in general. The theoretical understanding of neural networks trails significantly behind their practical success and the engineering heuristics that have grown up around them. Random matrix theory provides a rich framework of tools with which aspects of neural network phenomenology can be explored theoretically. In this thesis, we establish significant extensions of prior work using random matrix theory to understand and describe the loss surfaces of large neural networks, particularly generalising to different architectures. Informed by the historical applications of random matrix theory in physics and elsewhere, we establish the presence of local random matrix universality in real neural networks and then utilise this as a modeling assumption to derive powerful and novel results about the Hessians of neural network loss surfaces and their spectra. In addition to these major contributions, we make use of random matrix models for neural network loss surfaces to shed light on modern neural network training approaches and even to derive a novel and effective variant of a popular optimisation algorithm. Overall, this thesis provides important contributions to cement the place of random matrix theory in the theoretical study of modern neural networks, reveals some of the limits of existing approaches and begins the study of an entirely new role for random matrix theory in the theory of deep learning with important experimental discoveries and novel theoretical results based on local random matrix universality. ",
    "url": "https://arxiv.org/abs/2306.02108",
    "authors": [
      "Nicholas P Baskerville"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2306.02169",
    "title": "Probabilistic Solar Proxy Forecasting with Neural Network Ensembles",
    "abstract": "Space weather indices are used commonly to drive forecasts of thermosphere density, which directly affects objects in low-Earth orbit (LEO) through atmospheric drag. One of the most commonly used space weather proxies, $F_{10.7 cm}$, correlates well with solar extreme ultra-violet (EUV) energy deposition into the thermosphere. Currently, the USAF contracts Space Environment Technologies (SET), which uses a linear algorithm to forecast $F_{10.7 cm}$. In this work, we introduce methods using neural network ensembles with multi-layer perceptrons (MLPs) and long-short term memory (LSTMs) to improve on the SET predictions. We make predictions only from historical $F_{10.7 cm}$ values, but also investigate data manipulation to improve forecasting. We investigate data manipulation methods (backwards averaging and lookback) as well as multi step and dynamic forecasting. This work shows an improvement over the baseline when using ensemble methods. The best models found in this work are ensemble approaches using multi step or a combination of multi step and dynamic predictions. Nearly all approaches offer an improvement, with the best models improving between 45 and 55\\% on relative MSE. Other relative error metrics were shown to improve greatly when ensembles methods were used. We were also able to leverage the ensemble approach to provide a distribution of predicted values; allowing an investigation into forecast uncertainty. Our work found models that produced less biased predictions at elevated and high solar activity levels. Uncertainty was also investigated through the use of a calibration error score metric (CES), our best ensemble reached similar CES as other work. ",
    "url": "https://arxiv.org/abs/2306.02169",
    "authors": [
      "Joshua D. Daniell",
      "Piyush M. Mehta"
    ],
    "subjectives": [
      "Space Physics (physics.space-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02195",
    "title": "Subchromatic numbers of powers of graphs with excluded minors",
    "abstract": "A $k$-subcolouring of a graph $G$ is a function $f:V(G) \\to \\{0,\\ldots,k-1\\}$ such that the set of vertices coloured $i$ induce a disjoint union of cliques. The subchromatic number, $\\chi_{\\textrm{sub}}(G)$, is the minimum $k$ such that $G$ admits a $k$-subcolouring. Ne\\v{s}et\\v{r}il, Ossona de Mendez, Pilipczuk, and Zhu (2020), recently raised the problem of finding tight upper bounds for $\\chi_{\\textrm{sub}}(G^2)$ when $G$ is planar. We show that $\\chi_{\\textrm{sub}}(G^2)\\le 43$ when $G$ is planar, improving their bound of 135. We give even better bounds when the planar graph $G$ has larger girth. Moreover, we show that $\\chi_{\\textrm{sub}}(G^{3})\\le 95$, improving the previous bound of 364. For these we adapt some recent techniques of Almulhim and Kierstead (2022), while also extending the decompositions of triangulated planar graphs of Van den Heuvel, Ossona de Mendez, Quiroz, Rabinovich and Siebertz (2017), to planar graphs of arbitrary girth. Note that these decompositions are the precursors of the graph product structure theorem of planar graphs. We give improved bounds for $\\chi_{\\textrm{sub}}(G^p)$ for all $p$, whenever $G$ has bounded treewidth, bounded simple treewidth, bounded genus, or excludes a clique or biclique as a minor. For this we introduce a family of parameters which form a gradation between the strong and the weak colouring numbers. We give upper bounds for these parameters for graphs coming from such classes. Finally, we give a 2-approximation algorithm for the subchromatic number of graphs coming from any fixed class with bounded layered cliquewidth. In particular, this implies a 2-approximation algorithm for the subchromatic number of powers $G^p$ of graphs coming from any fixed class with bounded layered treewidth (such as the class of planar graphs). This algorithm works even if the power $p$ and the graph $G$ is unknown. ",
    "url": "https://arxiv.org/abs/2306.02195",
    "authors": [
      "Pedro P. Cort\u00e9s",
      "Pankaj Kumar",
      "Benjamin Moore",
      "Patrice Ossona de Mendez",
      "Daniel A. Quiroz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.02200",
    "title": "Valid path-based graph vertex numbering",
    "abstract": "A labelling of a graph is an assignment of labels to its vertex or edge sets (or both), subject to certain conditions, a well established concept. A labelling of a graph G of order n is termed a numbering when the set of integers {1,...,n} is used to label the vertices of G distinctly. A 2-path (a path with three vertices) in a vertex-numbered graph is said to be valid if the number of its middle vertex is smaller than the numbers of its endpoints. The problem of finding a vertex numbering of a given graph that optimises the number of induced valid 2-paths is studied, which is conjectured to be in the NP-hard class. The reported results for several graph classes show that apparently there are not one or more numbering patterns applicable to different classes of graphs, which requires the development of a specific numbering for each graph class under study. ",
    "url": "https://arxiv.org/abs/2306.02200",
    "authors": [
      "Les Foulds",
      "Humberto J. Longo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.02300",
    "title": "How neural networks learn to classify chaotic time series",
    "abstract": "Neural networks are increasingly employed to model, analyze and control non-linear dynamical systems ranging from physics to biology. Owing to their universal approximation capabilities, they regularly outperform state-of-the-art model-driven methods in terms of accuracy, computational speed, and/or control capabilities. On the other hand, neural networks are very often they are taken as black boxes whose explainability is challenged, among others, by huge amounts of trainable parameters. In this paper, we tackle the outstanding issue of analyzing the inner workings of neural networks trained to classify regular-versus-chaotic time series. This setting, well-studied in dynamical systems, enables thorough formal analyses. We focus specifically on a family of networks dubbed Large Kernel Convolutional Neural Networks (LKCNN), recently introduced by Boull\\'{e} et al. (2021). These non-recursive networks have been shown to outperform other established architectures (e.g. residual networks, shallow neural networks and fully convolutional networks) at this classification task. Furthermore, they outperform ``manual'' classification approaches based on direct reconstruction of the Lyapunov exponent. We find that LKCNNs use qualitative properties of the input sequence. In particular, we show that the relation between input periodicity and activation periodicity is key for the performance of LKCNN models. Low performing models show, in fact, analogous periodic activations to random untrained models. This could give very general criteria for identifying, a priori, trained models that have poor accuracy. ",
    "url": "https://arxiv.org/abs/2306.02300",
    "authors": [
      "Alessandro Corbetta",
      "Thomas Geert de Jong"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02474",
    "title": "Dispersion on the Complete Graph",
    "abstract": "We consider a synchronous process of particles moving on the vertices of a graph $G$, introduced by Cooper, McDowell, Radzik, Rivera and Shiraga (2018). Initially,~$M$ particles are placed on a vertex of $G$. At the beginning of each time step, for every vertex inhabited by at least two particles, each of these particles moves independently to a neighbour chosen uniformly at random. The process ends at the first step when no vertex is inhabited by more than one particle. Cooper et al. showed that when the underlying graph is the complete graph on~$n$ vertices, then there is a phase transition when the number of particles $M = n/2$. They showed that if $M<(1-\\varepsilon)n/2$ for some fixed $\\varepsilon>0$, then the process finishes in a logarithmic number of steps, while if $M>(1+\\varepsilon)n/2$, an exponential number of steps are required with high probability. In this paper we provide a thorough analysis of the dispersion time around criticality, where $\\varepsilon = o(1)$, and describe the fine details of the transition between logarithmic and exponential time. As a consequence of our results we establish, for example, that the dispersion time is in probability and in expectation $\\Theta(n^{1/2})$ when $|\\varepsilon| = O(n^{-1/2})$, and provide qualitative bounds for its tail behavior. ",
    "url": "https://arxiv.org/abs/2306.02474",
    "authors": [
      "Umberto De Ambroggio",
      "Tam\u00e1s Makai",
      "Konstantinos Panagiotou"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.02732",
    "title": "Conformal Prediction with Missing Values",
    "abstract": "Conformal prediction is a theoretically grounded framework for constructing predictive intervals. We study conformal prediction with missing values in the covariates -- a setting that brings new challenges to uncertainty quantification. We first show that the marginal coverage guarantee of conformal prediction holds on imputed data for any missingness distribution and almost all imputation functions. However, we emphasize that the average coverage varies depending on the pattern of missing values: conformal methods tend to construct prediction intervals that under-cover the response conditionally to some missing patterns. This motivates our novel generalized conformalized quantile regression framework, missing data augmentation, which yields prediction intervals that are valid conditionally to the patterns of missing values, despite their exponential number. We then show that a universally consistent quantile regression algorithm trained on the imputed data is Bayes optimal for the pinball risk, thus achieving valid coverage conditionally to any given data point. Moreover, we examine the case of a linear model, which demonstrates the importance of our proposal in overcoming the heteroskedasticity induced by missing values. Using synthetic and data from critical care, we corroborate our theory and report improved performance of our methods. ",
    "url": "https://arxiv.org/abs/2306.02732",
    "authors": [
      "Margaux Zaffran",
      "Aymeric Dieuleveut",
      "Julie Josse",
      "Yaniv Romano"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02775",
    "title": "Input gradient diversity for neural network ensembles",
    "abstract": "Deep Ensembles (DEs) demonstrate improved accuracy, calibration and robustness to perturbations over single neural networks partly due to their functional diversity. Particle-based variational inference (ParVI) methods enhance diversity by formalizing a repulsion term based on a network similarity kernel. However, weight-space repulsion is inefficient due to over-parameterization, while direct function-space repulsion has been found to produce little improvement over DEs. To sidestep these difficulties, we propose First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based on ParVI, which performs repulsion in the space of first-order input gradients. As input gradients uniquely characterize a function up to translation and are much smaller in dimension than the weights, this method guarantees that ensemble members are functionally different. Intuitively, diversifying the input gradients encourages each network to learn different features, which is expected to improve the robustness of an ensemble. Experiments on image classification datasets show that FoRDE significantly outperforms the gold-standard DEs and other ensemble methods in accuracy and calibration under covariate shift due to input perturbations. ",
    "url": "https://arxiv.org/abs/2306.02775",
    "authors": [
      "Trung Trinh",
      "Markus Heinonen",
      "Luigi Acerbi",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02886",
    "title": "Image Reconstruction for Accelerated MR Scan with Faster Fourier  Convolutional Neural Networks",
    "abstract": "Partial scan is a common approach to accelerate Magnetic Resonance Imaging (MRI) data acquisition in both 2D and 3D settings. However, accurately reconstructing images from partial scan data (i.e., incomplete k-space matrices) remains challenging due to lack of an effectively global receptive field in both spatial and k-space domains. To address this problem, we propose the following: (1) a novel convolutional operator called Faster Fourier Convolution (FasterFC) to replace the two consecutive convolution operations typically used in convolutional neural networks (e.g., U-Net, ResNet). Based on the spectral convolution theorem in Fourier theory, FasterFC employs alternating kernels of size 1 in 3D case) in different domains to extend the dual-domain receptive field to the global and achieves faster calculation speed than traditional Fast Fourier Convolution (FFC). (2) A 2D accelerated MRI method, FasterFC-End-to-End-VarNet, which uses FasterFC to improve the sensitivity maps and reconstruction quality. (3) A multi-stage 3D accelerated MRI method called FasterFC-based Single-to-group Network (FAS-Net) that utilizes a single-to-group algorithm to guide k-space domain reconstruction, followed by FasterFC-based cascaded convolutional neural networks to expand the effective receptive field in the dual-domain. Experimental results on the fastMRI and Stanford MRI Data datasets demonstrate that FasterFC improves the quality of both 2D and 3D reconstruction. Moreover, FAS-Net, as a 3D high-resolution multi-coil (eight) accelerated MRI method, achieves superior reconstruction performance in both qualitative and quantitative results compared with state-of-the-art 2D and 3D methods. ",
    "url": "https://arxiv.org/abs/2306.02886",
    "authors": [
      "Xiaohan Liu",
      "Yanwei Pang",
      "Xuebin Sun",
      "Yiming Liu",
      "Yonghong Hou",
      "Zhenchang Wang",
      "Xuelong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02899",
    "title": "Learning nonparametric latent causal graphs with unknown interventions",
    "abstract": "We establish conditions under which latent causal graphs are nonparametrically identifiable and can be reconstructed from unknown interventions in the latent space. Our primary focus is the identification of the latent structure in a measurement model, i.e. causal graphical models where dependence between observed variables is insignificant compared to dependence between latent representations, without making parametric assumptions such as linearity or Gaussianity. Moreover, we do not assume the number of hidden variables is known, and we show that at most one unknown intervention per hidden variable is needed. This extends a recent line of work on learning causal representations from observations and interventions. The proofs are constructive and introduce two new graphical concepts -- imaginary subsets and isolated edges -- that may be useful in their own right. As a matter of independent interest, the proofs also involve a novel characterization of the limits of edge orientations within the equivalence class of DAGs induced by unknown interventions. Experiments confirm that the latent graph can be recovered from data using our theoretical results. These are the first results to characterize the conditions under which causal representations are identifiable without making any parametric assumptions in a general setting with unknown interventions and without faithfulness. ",
    "url": "https://arxiv.org/abs/2306.02899",
    "authors": [
      "Yibo Jiang",
      "Bryon Aragam"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02931",
    "title": "Causal Discovery using Bayesian Model Selection",
    "abstract": "With only observational data on two variables, and without other assumptions, it is not possible to infer which one causes the other. Much of the causal literature has focused on guaranteeing identifiability of causal direction in statistical models for datasets where strong assumptions hold, such as additive noise or restrictions on parameter count. These methods are then subsequently tested on realistic datasets, most of which violate their assumptions. Building on previous attempts, we show how to use causal assumptions within the Bayesian framework. This allows us to specify models with realistic assumptions, while also encoding independent causal mechanisms, leading to an asymmetry between the causal directions. Identifying causal direction then becomes a Bayesian model selection problem. We analyse why Bayesian model selection works for known identifiable cases and flexible model classes, while also providing correctness guarantees about its behaviour. To demonstrate our approach, we construct a Bayesian non-parametric model that can flexibly model the joint. We then outperform previous methods on a wide range of benchmark datasets with varying data generating assumptions showing the usefulness of our method. ",
    "url": "https://arxiv.org/abs/2306.02931",
    "authors": [
      "Anish Dhir",
      "Mark van der Wilk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02948",
    "title": "Random Distribution Shift in Refugee Placement: Strategies for Building  Robust Models",
    "abstract": "Algorithmic assignment of refugees and asylum seekers to locations within host countries has gained attention in recent years, with implementations in the US and Switzerland. These approaches use data on past arrivals to generate machine learning models that can be used (along with assignment algorithms) to match families to locations, with the goal of maximizing a policy-relevant integration outcome such as employment status after a certain duration. Existing implementations and research train models to predict the policy outcome directly, and use these predictions in the assignment procedure. However, the merits of this approach, particularly in non-stationary settings, has not been previously explored. This study proposes and compares three different modeling strategies: the standard approach described above, an approach that uses newer data and proxy outcomes, and a hybrid approach. We show that the hybrid approach is robust to both distribution shift and weak proxy relationships -- the failure points of the other two methods, respectively. We compare these approaches empirically using data on asylum seekers in the Netherlands. Surprisingly, we find that both the proxy and hybrid approaches out-perform the standard approach in practice. These insights support the development of a real-world recommendation tool currently used by NGOs and government agencies. ",
    "url": "https://arxiv.org/abs/2306.02948",
    "authors": [
      "Kirk Bansak",
      "Elisabeth Paulson",
      "Dominik Rothenh\u00e4usler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.02972",
    "title": "Simultaneous or Sequential Training? How Speech Representations  Cooperate in a Multi-Task Self-Supervised Learning System",
    "abstract": "Speech representation learning with self-supervised algorithms has resulted in notable performance boosts in many downstream tasks. Recent work combined self-supervised learning (SSL) and visually grounded speech (VGS) processing mechanisms for representation learning. The joint training with SSL and VGS mechanisms provides the opportunity to utilize both unlabeled speech and speech-related visual information based on data availability. This has shown to enhance the quality of learned representations, especially at encoding semantic- and lexical-level knowledge. In this work, we further study the joint optimization of wav2vec 2.0-based SSL and transformer-based VGS as a multi-task learning system. We explore a set of training scenarios to understand how speech representations are shared or transferred between the two tasks, and what is the optimal training strategy for cross-modal semantic retrieval and phoneme discrimination performance. As a result, we find that sequential training with wav2vec 2.0 first and VGS next provides higher performance on audio-visual retrieval compared to simultaneous optimization of both learning mechanisms. However, the parallel SSL-VGS training reduces the effects of catastrophic forgetting when switching between optimization criteria. Moreover, the results suggest that phonemic representations learned through the VGS mechanism may generalize better across datasets compared to those learned with SSL. ",
    "url": "https://arxiv.org/abs/2306.02972",
    "authors": [
      "Khazar Khorrami",
      "Mar\u00eda Andrea Cruz Bland\u00f3n",
      "Tuomas Virtanen",
      "Okko R\u00e4s\u00e4nen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.03027",
    "title": "Explicit feedback synthesis driven by quasi-interpolation for nonlinear  robust model predictive control",
    "abstract": "We present QuIFS (Quasi-Interpolation driven Feedback Synthesis) -- an offline feedback synthesis algorithm for explicit nonlinear robust minmax model predictive control (MPC) problems with guaranteed quality of approximation. The underlying technique is driven by a particular type of grid-based quasi-interpolation scheme. The QuIFS algorithm departs drastically from conventional approximation algorithms that are employed in the MPC industry (in particular, it is neither based on multi-parametric programming tools nor does it involve kernel methods), and the essence of their point of departure is encoded in the following challenge-answer approach: Given an error margin $\\varepsilon>0$, compute a feasible feedback policy that is uniformly $\\varepsilon$-close to the optimal MPC feedback policy for a given nonlinear system subjected to hard constraints and bounded uncertainties. Conditions for closed-loop stability and recursive feasibility under the approximate feedback policy are also established. We provide a library of numerical examples to illustrate our results. ",
    "url": "https://arxiv.org/abs/2306.03027",
    "authors": [
      "Siddhartha Ganguly",
      "Debasish Chatterjee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:1907.09282",
    "title": "Learning the Relation between Code Features and Code Transforms with  Structured Prediction",
    "abstract": " Title: Learning the Relation between Code Features and Code Transforms with  Structured Prediction ",
    "url": "https://arxiv.org/abs/1907.09282",
    "authors": [
      "Zhongxing Yu",
      "Matias Martinez",
      "Zimin Chen",
      "Tegawend\u00e9 F. Bissyand\u00e9",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:1910.13601",
    "title": "Deep Weakly-supervised Anomaly Detection",
    "abstract": " Comments: Accepted to KDD 2023 ",
    "url": "https://arxiv.org/abs/1910.13601",
    "authors": [
      "Guansong Pang",
      "Chunhua Shen",
      "Huidong Jin",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.10174",
    "title": "Restorable Shortest Path Tiebreaking for Edge-Faulty Graphs",
    "abstract": " Comments: PODC 2021 ",
    "url": "https://arxiv.org/abs/2102.10174",
    "authors": [
      "Greg Bodwin",
      "Merav Parter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2104.13764",
    "title": "Segmentation-Based Bounding Box Generation for Omnidirectional  Pedestrian Detection",
    "abstract": " Comments: Pre-print version of a paper accepted to The Visual Computer ",
    "url": "https://arxiv.org/abs/2104.13764",
    "authors": [
      "Masato Tamura",
      "Tomoaki Yoshinaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.02747",
    "title": "Quantum Reduction of Finding Short Code Vectors to the Decoding Problem",
    "abstract": " Title: Quantum Reduction of Finding Short Code Vectors to the Decoding Problem ",
    "url": "https://arxiv.org/abs/2106.02747",
    "authors": [
      "Thomas Debris-Alazard",
      "Maxime Remaud",
      "Jean-Pierre Tillich"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2106.07451",
    "title": "Noise-robust Graph Learning by Estimating and Leveraging Pairwise  Interactions",
    "abstract": " Comments: accepted to TMLR ",
    "url": "https://arxiv.org/abs/2106.07451",
    "authors": [
      "Xuefeng Du",
      "Tian Bian",
      "Yu Rong",
      "Bo Han",
      "Tongliang Liu",
      "Tingyang Xu",
      "Wenbing Huang",
      "Yixuan Li",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.11926",
    "title": "Sinkhorn Distributionally Robust Optimization",
    "abstract": " Comments: 57 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2109.11926",
    "authors": [
      "Jie Wang",
      "Rui Gao",
      "Yao Xie"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.03922",
    "title": "The Eigenlearning Framework: A Conservation Law Perspective on Kernel  Regression and Wide Neural Networks",
    "abstract": " Comments: 12 pages (main text) + 25 pages (refs + appendices). A previous version of this manuscript was entitled \"Neural Tangent Kernel Eigenvalues Accurately Predict Generalization.\" ",
    "url": "https://arxiv.org/abs/2110.03922",
    "authors": [
      "James B. Simon",
      "Madeline Dickens",
      "Dhruva Karkada",
      "Michael R. DeWeese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.12968",
    "title": "Does Label Differential Privacy Prevent Label Inference Attacks?",
    "abstract": " Title: Does Label Differential Privacy Prevent Label Inference Attacks? ",
    "url": "https://arxiv.org/abs/2202.12968",
    "authors": [
      "Ruihan Wu",
      "Jin Peng Zhou",
      "Kilian Q. Weinberger",
      "Chuan Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00922",
    "title": "Canonical foliations of neural networks: application to robustness",
    "abstract": " Title: Canonical foliations of neural networks: application to robustness ",
    "url": "https://arxiv.org/abs/2203.00922",
    "authors": [
      "Eliot Tron",
      "Nicolas Couellan",
      "St\u00e9phane Puechmorel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ]
  },
  {
    "id": "arXiv:2203.02034",
    "title": "Data-Efficient and Interpretable Tabular Anomaly Detection",
    "abstract": " Comments: Accepted in 2023 KDD ",
    "url": "https://arxiv.org/abs/2203.02034",
    "authors": [
      "Chun-Hao Chang",
      "Jinsung Yoon",
      "Sercan Arik",
      "Madeleine Udell",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.02928",
    "title": "Evaluation of Interpretability Methods and Perturbation Artifacts in  Deep Neural Networks",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2203.02928",
    "authors": [
      "Lennart Brocki",
      "Neo Christopher Chung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07390",
    "title": "What's the Difference? The potential for Convolutional Neural Networks  for transient detection without template subtraction",
    "abstract": " Title: What's the Difference? The potential for Convolutional Neural Networks  for transient detection without template subtraction ",
    "url": "https://arxiv.org/abs/2203.07390",
    "authors": [
      "Tatiana Acero-Cuellar",
      "Federica Bianco",
      "Gregory Dobler",
      "Masao Sako",
      "Helen Qu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ]
  },
  {
    "id": "arXiv:2203.15578",
    "title": "Disentangling speech from surroundings with neural embeddings",
    "abstract": " Comments: Accepted at ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2203.15578",
    "authors": [
      "Ahmed Omran",
      "Neil Zeghidour",
      "Zal\u00e1n Borsos",
      "F\u00e9lix de Chaumont Quitry",
      "Malcolm Slaney",
      "Marco Tagliasacchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.01057",
    "title": "A Survey on Machine Learning Solutions for Graph Pattern Extraction",
    "abstract": " Comments: v1: 41 pages; v2: 40 pages ; v3: This version focuses on just subgraph problems (discussions on other classic graph problems can be found in the earlier versions) ",
    "url": "https://arxiv.org/abs/2204.01057",
    "authors": [
      "Kai Siong Yow",
      "Ningyi Liao",
      "Siqiang Luo",
      "Reynold Cheng",
      "Chenhao Ma",
      "Xiaolin Han"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.01297",
    "title": "Learning Constrained Dynamic Correlations in Spatiotemporal Graphs for  Motion Prediction",
    "abstract": " Comments: Accepted by TNNLS. Codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2204.01297",
    "authors": [
      "Jiajun Fu",
      "Fuxing Yang",
      "Yonghao Dang",
      "Xiaoli Liu",
      "Jianqin Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02241",
    "title": "A Set Membership Approach to Discovering Feature Relevance and  Explaining Neural Classifier Decisions",
    "abstract": " Comments: Revised description in Section 2 (The Proposed Approach) results unchanged ",
    "url": "https://arxiv.org/abs/2204.02241",
    "authors": [
      "Stavros P. Adam",
      "Aristidis C. Likas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.10965",
    "title": "CLIP-Dissect: Automatic Description of Neuron Representations in Deep  Vision Networks",
    "abstract": " Comments: Published in ICLR 2023 Conference (Spotlight). New v5(5 June 2023) - Added crowdsourced user study in Appendix B, not included in ICLR publication ",
    "url": "https://arxiv.org/abs/2204.10965",
    "authors": [
      "Tuomas Oikarinen",
      "Tsui-Wei Weng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10282",
    "title": "Heterformer: Transformer-based Deep Node Representation Learning on  Heterogeneous Text-Rich Networks",
    "abstract": " Comments: KDD 2023. (Code: this https URL) ",
    "url": "https://arxiv.org/abs/2205.10282",
    "authors": [
      "Bowen Jin",
      "Yu Zhang",
      "Qi Zhu",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14714",
    "title": "Comparison of meta-learners for estimating multi-valued treatment  heterogeneous effects",
    "abstract": " Comments: 42 pages, 9 figures, to appear in ICML 2023 conference ",
    "url": "https://arxiv.org/abs/2205.14714",
    "authors": [
      "Naoufal Acharki",
      "Ramiro Lugo",
      "Antoine Bertoncello",
      "Josselin Garnier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.12062",
    "title": "Adaptive Asynchronous Control Using Meta-learned Neural Ordinary  Differential Equations",
    "abstract": " Comments: 16 double column pages, 14 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2207.12062",
    "authors": [
      "Achkan Salehi",
      "Steffen R\u00fchl",
      "Stephane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.13963",
    "title": "Meta-Learning based Degradation Representation for Blind  Super-Resolution",
    "abstract": " Comments: This paper is accepted by TIP 2023, and code will be released at this https URL ",
    "url": "https://arxiv.org/abs/2207.13963",
    "authors": [
      "Bin Xia",
      "Yapeng Tian",
      "Yulun Zhang",
      "Yucheng Hang",
      "Wenming Yang",
      "Qingmin Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10230",
    "title": "From Static to Dynamic Structures: Improving Binding Affinity Prediction  with a Graph-Based Deep Learning Model",
    "abstract": " Comments: totally reorganize the texts and figures ",
    "url": "https://arxiv.org/abs/2208.10230",
    "authors": [
      "Yaosen Min",
      "Ye Wei",
      "Peizhuo Wang",
      "Xiaoting Wang",
      "Han Li",
      "Nian Wu",
      "Stefan Bauer",
      "Shuxin Zheng",
      "Yu Shi",
      "Yingheng Wang",
      "Ji Wu",
      "Dan Zhao",
      "Jianyang Zeng"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2208.10917",
    "title": "Graph Embeddings via Tensor Products and Approximately Orthonormal Codes",
    "abstract": " Comments: 59 pages, 2 tables. arxiv admin note: substantial text overlap with arXiv:2208.08769 ",
    "url": "https://arxiv.org/abs/2208.10917",
    "authors": [
      "Frank Qiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.00128",
    "title": "Archangel: A Hybrid UAV-based Human Detection Benchmark with Position  and Pose Metadata",
    "abstract": " Comments: Submission to IEEE Access ",
    "url": "https://arxiv.org/abs/2209.00128",
    "authors": [
      "Yi-Ting Shen",
      "Yaesop Lee",
      "Heesung Kwon",
      "Damon M. Conover",
      "Shuvra S. Bhattacharyya",
      "Nikolas Vale",
      "Joshua D. Gray",
      "G. Jeremy Leong",
      "Kenneth Evensen",
      "Frank Skirlo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.10931",
    "title": "Robust Collaborative Learning with Linear Gradient Overhead",
    "abstract": " Comments: Accepted paper at ICML 2023 ",
    "url": "https://arxiv.org/abs/2209.10931",
    "authors": [
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "L\u00ea Nguy\u00ean Hoang",
      "Rafael Pinot",
      "John Stephan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2209.12457",
    "title": "Fault Detection for Grid-Forming Inverters in Islanded Droop-Controlled  AC Microgrids",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2209.12457",
    "authors": [
      "Gabriel Intriago",
      "Andres Intriago",
      "Charalambos Konstantinou",
      "Yu Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.15266",
    "title": "Data Poisoning Attacks Against Multimodal Encoders",
    "abstract": " Comments: To Appear in the 40th International Conference on Machine Learning, July 2023 ",
    "url": "https://arxiv.org/abs/2209.15266",
    "authors": [
      "Ziqing Yang",
      "Xinlei He",
      "Zheng Li",
      "Michael Backes",
      "Mathias Humbert",
      "Pascal Berrang",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02097",
    "title": "Teaching Yourself: Graph Self-Distillation on Neighborhood for Node  Classification",
    "abstract": " Title: Teaching Yourself: Graph Self-Distillation on Neighborhood for Node  Classification ",
    "url": "https://arxiv.org/abs/2210.02097",
    "authors": [
      "Lirong Wu",
      "Jun Xia",
      "Haitao Lin",
      "Zhangyang Gao",
      "Zicheng Liu",
      "Guojiang Zhao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04183",
    "title": "MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language  Representation Learning",
    "abstract": " Comments: SIGIR 2023, 10 pages ",
    "url": "https://arxiv.org/abs/2210.04183",
    "authors": [
      "Zijia Zhao",
      "Longteng Guo",
      "Xingjian He",
      "Shuai Shao",
      "Zehuan Yuan",
      "Jing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.04318",
    "title": "Prediction intervals for neural network models using weighted asymmetric  loss functions",
    "abstract": " Comments: 14 pages, 3 figures, not submitted anywhere yet ",
    "url": "https://arxiv.org/abs/2210.04318",
    "authors": [
      "Milo Grillo",
      "Yunpeng Han",
      "Agnieszka Werpachowska"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05801",
    "title": "Linkless Link Prediction via Relational Distillation",
    "abstract": " Title: Linkless Link Prediction via Relational Distillation ",
    "url": "https://arxiv.org/abs/2210.05801",
    "authors": [
      "Zhichun Guo",
      "William Shiao",
      "Shichang Zhang",
      "Yozen Liu",
      "Nitesh V. Chawla",
      "Neil Shah",
      "Tong Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15034",
    "title": "InfoShape: Task-Based Neural Data Shaping via Mutual Information",
    "abstract": " Comments: 5 pages, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) ",
    "url": "https://arxiv.org/abs/2210.15034",
    "authors": [
      "Homa Esfahanizadeh",
      "William Wu",
      "Manya Ghobadi",
      "Regina Barzilay",
      "Muriel Medard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.15469",
    "title": "Learning Failure-Inducing Models for Testing Software-Defined Networks",
    "abstract": " Title: Learning Failure-Inducing Models for Testing Software-Defined Networks ",
    "url": "https://arxiv.org/abs/2210.15469",
    "authors": [
      "Rapha\u00ebl Ollando",
      "Seung Yeob Shin",
      "Lionel C. Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.00437",
    "title": "Disentangled representation learning for multilingual speaker  recognition",
    "abstract": " Comments: Interspeech 2023 ",
    "url": "https://arxiv.org/abs/2211.00437",
    "authors": [
      "Kihyun Nam",
      "Youkyum Kim",
      "Hee Soo Heo",
      "Jee-weon Jung",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.01669",
    "title": "Channel-Aware Pretraining of Joint Encoder-Decoder Self-Supervised Model  for Telephonic-Speech ASR",
    "abstract": " Comments: 5 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2211.01669",
    "authors": [
      "Vrunda N. Sukhadia",
      "A. Arunkumar",
      "S. Umesh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.01842",
    "title": "Construction of Hierarchical Neural Architecture Search Spaces based on  Context-free Grammars",
    "abstract": " Title: Construction of Hierarchical Neural Architecture Search Spaces based on  Context-free Grammars ",
    "url": "https://arxiv.org/abs/2211.01842",
    "authors": [
      "Simon Schrodi",
      "Danny Stoll",
      "Binxin Ru",
      "Rhea Sukthanker",
      "Thomas Brox",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.02167",
    "title": "Hardware/Software co-design with ADC-Less In-memory Computing Hardware  for Spiking Neural Networks",
    "abstract": " Comments: 13 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2211.02167",
    "authors": [
      "Marco Paul E. Apolinario",
      "Adarsh Kumar Kosta",
      "Utkarsh Saxena",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2211.05551",
    "title": "Causal Counterfactuals for Improving the Robustness of Reinforcement  Learning",
    "abstract": " Comments: Accepted to ARMS-2023 (ARMS-2023: AAMAS 2023 Workshop on Autonomous Robots and Multirobot Systems) ",
    "url": "https://arxiv.org/abs/2211.05551",
    "authors": [
      "Tom He",
      "Jasmina Gajcin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11255",
    "title": "Diffusion Denoising Process for Perceptron Bias in Out-of-distribution  Detection",
    "abstract": " Title: Diffusion Denoising Process for Perceptron Bias in Out-of-distribution  Detection ",
    "url": "https://arxiv.org/abs/2211.11255",
    "authors": [
      "Luping Liu",
      "Yi Ren",
      "Xize Cheng",
      "Rongjie Huang",
      "Chongxuan Li",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14218",
    "title": "Shotgun assembly of random graphs",
    "abstract": " Comments: 36 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2211.14218",
    "authors": [
      "Tom Johnston",
      "Gal Kronenberg",
      "Alexander Roberts",
      "Alex Scott"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2212.05251",
    "title": "A Unified Knowledge Graph Augmentation Service for Boosting  Domain-specific NLP Tasks",
    "abstract": " Comments: Accepted by ACL Findings 2023 ",
    "url": "https://arxiv.org/abs/2212.05251",
    "authors": [
      "Ruiqing Ding",
      "Xiao Han",
      "Leye Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.06079",
    "title": "Robust Perception through Equivariance",
    "abstract": " Comments: Published in ICML 2023 ",
    "url": "https://arxiv.org/abs/2212.06079",
    "authors": [
      "Chengzhi Mao",
      "Lingyu Zhang",
      "Abhishek Joshi",
      "Junfeng Yang",
      "Hao Wang",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08966",
    "title": "Graph Learning and Its Applications: A Holistic Survey",
    "abstract": " Comments: 20 pages, 8 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2212.08966",
    "authors": [
      "Shaopeng Wei",
      "Yu Zhao",
      "Xingyan Chen",
      "Qing Li",
      "Fuzhen Zhuang",
      "Ji Liu",
      "Gang Kou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09034",
    "title": "Graph Neural Networks are Inherently Good Generalizers: Insights by  Bridging GNNs and MLPs",
    "abstract": " Comments: Accepted to ICLR 2023. Codes in this https URL ",
    "url": "https://arxiv.org/abs/2212.09034",
    "authors": [
      "Chenxiao Yang",
      "Qitian Wu",
      "Jiahua Wang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10950",
    "title": "Incremental Neural Implicit Representation with Uncertainty-Filtered  Knowledge Distillation",
    "abstract": " Title: Incremental Neural Implicit Representation with Uncertainty-Filtered  Knowledge Distillation ",
    "url": "https://arxiv.org/abs/2212.10950",
    "authors": [
      "Mengqi Guo",
      "Chen Li",
      "Hanlin Chen",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.14736",
    "title": "PRISM: Privacy Preserving Healthcare Internet of Things Security  Management",
    "abstract": " Title: PRISM: Privacy Preserving Healthcare Internet of Things Security  Management ",
    "url": "https://arxiv.org/abs/2212.14736",
    "authors": [
      "Savvas Hadjixenophontos",
      "Anna Maria Mandalari",
      "Yuchen Zhao",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.02364",
    "title": "Object as Query: Lifting any 2D Object Detector to 3D Detection",
    "abstract": " Comments: technical report ",
    "url": "https://arxiv.org/abs/2301.02364",
    "authors": [
      "Zitian Wang",
      "Zehao Huang",
      "Jiahui Fu",
      "Naiyan Wang",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.03041",
    "title": "Learning the Relation between Similarity Loss and Clustering Loss in  Self-Supervised Learning",
    "abstract": " Comments: This paper is accepted by IEEE Transactions on Image Processing ",
    "url": "https://arxiv.org/abs/2301.03041",
    "authors": [
      "Jidong Ge",
      "Yuxiang Liu",
      "Jie Gui",
      "Lanting Fang",
      "Ming Lin",
      "James Tin-Yau Kwok",
      "LiGuo Huang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.05412",
    "title": "Evolve Path Tracer: Early Detection of Malicious Addresses in  Cryptocurrency",
    "abstract": " Comments: In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD23) ",
    "url": "https://arxiv.org/abs/2301.05412",
    "authors": [
      "Ling Cheng",
      "Feida Zhu",
      "Yong Wang",
      "Ruicheng Liang",
      "Huiwen Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.09308",
    "title": "On the Expressive Power of Geometric Graph Neural Networks",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.09308",
    "authors": [
      "Chaitanya K. Joshi",
      "Cristian Bodnar",
      "Simon V. Mathis",
      "Taco Cohen",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Group Theory (math.GR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.10448",
    "title": "Pre-computed memory or on-the-fly encoding? A hybrid approach to  retrieval augmentation makes the most of your compute",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.10448",
    "authors": [
      "Michiel de Jong",
      "Yury Zemlyanskiy",
      "Nicholas FitzGerald",
      "Joshua Ainslie",
      "Sumit Sanghai",
      "Fei Sha",
      "William Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.10521",
    "title": "ExaRanker: Explanation-Augmented Neural Ranker",
    "abstract": " Title: ExaRanker: Explanation-Augmented Neural Ranker ",
    "url": "https://arxiv.org/abs/2301.10521",
    "authors": [
      "Fernando Ferraretto",
      "Thiago Laitz",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2301.11167",
    "title": "Neural Inverse Operators for Solving PDE Inverse Problems",
    "abstract": " Title: Neural Inverse Operators for Solving PDE Inverse Problems ",
    "url": "https://arxiv.org/abs/2301.11167",
    "authors": [
      "Roberto Molinaro",
      "Yunan Yang",
      "Bj\u00f6rn Engquist",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2301.11342",
    "title": "A Robust Optimisation Perspective on Counterexample-Guided Repair of  Neural Networks",
    "abstract": " Comments: Accepted at ICML 2023. 9 pages + 13 pages appendix, 8 figures ",
    "url": "https://arxiv.org/abs/2301.11342",
    "authors": [
      "David Boetius",
      "Stefan Leue",
      "Tobias Sutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.11955",
    "title": "Adaptive whitening in neural populations with gain-modulating  interneurons",
    "abstract": " Comments: 20 pages, 10 figures (incl. appendix). To appear in the Proceedings of the 40th International Conference on Machine Learning ",
    "url": "https://arxiv.org/abs/2301.11955",
    "authors": [
      "Lyndon R. Duong",
      "David Lipshutz",
      "David J. Heeger",
      "Dmitri B. Chklovskii",
      "Eero P. Simoncelli"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.11990",
    "title": "Alignment with human representations supports robust few-shot learning",
    "abstract": " Title: Alignment with human representations supports robust few-shot learning ",
    "url": "https://arxiv.org/abs/2301.11990",
    "authors": [
      "Ilia Sucholutsky",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12159",
    "title": "ClusterFuG: Clustering Fully connected Graphs by Multicut",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.12159",
    "authors": [
      "Ahmed Abbas",
      "Paul Swoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00236",
    "title": "Generative Adversarial Symmetry Discovery",
    "abstract": " Title: Generative Adversarial Symmetry Discovery ",
    "url": "https://arxiv.org/abs/2302.00236",
    "authors": [
      "Jianke Yang",
      "Robin Walters",
      "Nima Dehmamy",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00732",
    "title": "Protecting Cache States Against Both Speculative Execution Attacks and  Side-channel Attacks",
    "abstract": " Title: Protecting Cache States Against Both Speculative Execution Attacks and  Side-channel Attacks ",
    "url": "https://arxiv.org/abs/2302.00732",
    "authors": [
      "Guangyuan Hu",
      "Ruby B. Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2302.01501",
    "title": "ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics",
    "abstract": " Title: ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics ",
    "url": "https://arxiv.org/abs/2302.01501",
    "authors": [
      "Hamed Rahimi",
      "Hubert Naacke",
      "Camelia Constantin",
      "Bernd Amann"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.01677",
    "title": "Revisiting Personalized Federated Learning: Robustness Against Backdoor  Attacks",
    "abstract": " Comments: KDD 2023 ",
    "url": "https://arxiv.org/abs/2302.01677",
    "authors": [
      "Zeyu Qin",
      "Liuyi Yao",
      "Daoyuan Chen",
      "Yaliang Li",
      "Bolin Ding",
      "Minhao Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.05757",
    "title": "Multispectral Contrastive Learning with Viewmaker Networks",
    "abstract": " Comments: Appearing in CVPR-PBVS 2023 ",
    "url": "https://arxiv.org/abs/2302.05757",
    "authors": [
      "Jasmine Bayrooti",
      "Noah Goodman",
      "Alex Tamkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.06079",
    "title": "Byzantine-Robust Learning on Heterogeneous Data via Gradient Splitting",
    "abstract": " Title: Byzantine-Robust Learning on Heterogeneous Data via Gradient Splitting ",
    "url": "https://arxiv.org/abs/2302.06079",
    "authors": [
      "Yuchen Liu",
      "Chen Chen",
      "Lingjuan Lyu",
      "Fangzhao Wu",
      "Sai Wu",
      "Gang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.06144",
    "title": "SkCoder: A Sketch-based Approach for Automatic Code Generation",
    "abstract": " Comments: Accepted by the 45th IEEE/ACM International Conference on Software Engineering (ICSE 2023) ",
    "url": "https://arxiv.org/abs/2302.06144",
    "authors": [
      "Jia Li",
      "Yongmin Li",
      "Ge Li",
      "Zhi Jin",
      "Yiyang Hao",
      "Xing Hu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.09048",
    "title": "MiDi: Mixed Graph and 3D Denoising Diffusion for Molecule Generation",
    "abstract": " Comments: 22 pages. Under review ",
    "url": "https://arxiv.org/abs/2302.09048",
    "authors": [
      "Clement Vignac",
      "Nagham Osman",
      "Laura Toni",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.09826",
    "title": "On the Expressivity of Persistent Homology in Graph Learning",
    "abstract": " Title: On the Expressivity of Persistent Homology in Graph Learning ",
    "url": "https://arxiv.org/abs/2302.09826",
    "authors": [
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.11556",
    "title": "Equivariant Polynomials for Graph Neural Networks",
    "abstract": " Title: Equivariant Polynomials for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2302.11556",
    "authors": [
      "Omri Puny",
      "Derek Lim",
      "Bobak T. Kiani",
      "Haggai Maron",
      "Yaron Lipman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.13002",
    "title": "Introducing Depth into Transformer-based 3D Object Detection",
    "abstract": " Comments: revision ",
    "url": "https://arxiv.org/abs/2302.13002",
    "authors": [
      "Hao Zhang",
      "Hongyang Li",
      "Ailing Zeng",
      "Feng Li",
      "Shilong Liu",
      "Xingyu Liao",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.13875",
    "title": "Evaluating Robustness and Uncertainty of Graph Models Under Structural  Distributional Shifts",
    "abstract": " Title: Evaluating Robustness and Uncertainty of Graph Models Under Structural  Distributional Shifts ",
    "url": "https://arxiv.org/abs/2302.13875",
    "authors": [
      "Gleb Bazhenov",
      "Denis Kuznedelev",
      "Andrey Malinin",
      "Artem Babenko",
      "Liudmila Prokhorenkova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.01339",
    "title": "Sensitivity of matrix function based network communicability measures:  Computational methods and a priori bounds",
    "abstract": " Title: Sensitivity of matrix function based network communicability measures:  Computational methods and a priori bounds ",
    "url": "https://arxiv.org/abs/2303.01339",
    "authors": [
      "Marcel Schweitzer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.02904",
    "title": "Social Cue Analysis using Transfer Entropy",
    "abstract": " Comments: 8 pages, 9 figures. Preprint ",
    "url": "https://arxiv.org/abs/2303.02904",
    "authors": [
      "Haoyang Jiang",
      "Elizabeth A. Croft",
      "Michael Burke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.03616",
    "title": "Geometry-Aware Coverage Path Planning for Depowdering on Complex 3D  Surfaces",
    "abstract": " Comments: 8 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2303.03616",
    "authors": [
      "Van-Thach Do",
      "Quang-Cuong Pham"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.03848",
    "title": "Parareal with a physics-informed neural network as coarse propagator",
    "abstract": " Comments: 13 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2303.03848",
    "authors": [
      "Abdul Qadir Ibrahim",
      "Sebastian G\u00f6tschel",
      "Daniel Ruprecht"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.04341",
    "title": "Neural Vector Fields: Implicit Representation by Explicit Learning",
    "abstract": " Comments: Accepted by CVPR2023. Video: this https URL ",
    "url": "https://arxiv.org/abs/2303.04341",
    "authors": [
      "Xianghui Yang",
      "Guosheng Lin",
      "Zhenghao Chen",
      "Luping Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.04630",
    "title": "Contribution of clinical course to outcome after traumatic brain injury:  mining patient trajectories from European intensive care unit data",
    "abstract": " Title: Contribution of clinical course to outcome after traumatic brain injury:  mining patient trajectories from European intensive care unit data ",
    "url": "https://arxiv.org/abs/2303.04630",
    "authors": [
      "Shubhayu Bhattacharyay",
      "Pier Francesco Caruso",
      "Cecilia \u00c5kerlund",
      "Lindsay Wilson",
      "Robert D Stevens",
      "David K Menon",
      "Ewout W Steyerberg",
      "David W Nelson",
      "Ari Ercole",
      "CENTER-TBI investigators/participants"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2303.06138",
    "title": "Learning Object-Centric Neural Scattering Functions for Free-viewpoint  Relighting and Scene Composition",
    "abstract": " Comments: Project website: this https URL Journal extension of arXiv:2012.08503. The first two authors contributed equally to this work ",
    "url": "https://arxiv.org/abs/2303.06138",
    "authors": [
      "Hong-Xing Yu",
      "Michelle Guo",
      "Alireza Fathi",
      "Yen-Yu Chang",
      "Eric Ryan Chan",
      "Ruohan Gao",
      "Thomas Funkhouser",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.06500",
    "title": "Diffusion-Based Hierarchical Multi-Label Object Detection to Analyze  Panoramic Dental X-rays",
    "abstract": " Comments: MICCAI 2023 ",
    "url": "https://arxiv.org/abs/2303.06500",
    "authors": [
      "Ibrahim Ethem Hamamci",
      "Sezgin Er",
      "Enis Simsar",
      "Anjany Sekuboyina",
      "Mustafa Gundogar",
      "Bernd Stadlinger",
      "Albert Mehl",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07925",
    "title": "Robust incremental learning pipelines for temporal tabular datasets with  distribution shifts",
    "abstract": " Title: Robust incremental learning pipelines for temporal tabular datasets with  distribution shifts ",
    "url": "https://arxiv.org/abs/2303.07925",
    "authors": [
      "Thomas Wong",
      "Mauricio Barahona"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ]
  },
  {
    "id": "arXiv:2303.10644",
    "title": "Spatio-Temporal AU Relational Graph Representation Learning For Facial  Action Units Detection",
    "abstract": " Title: Spatio-Temporal AU Relational Graph Representation Learning For Facial  Action Units Detection ",
    "url": "https://arxiv.org/abs/2303.10644",
    "authors": [
      "Zihan Wang",
      "Siyang Song",
      "Cheng Luo",
      "Yuzhi Zhou",
      "Shiling Wu",
      "Weicheng Xie",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14633",
    "title": "An Evaluation of Memory Optimization Methods for Training Neural  Networks",
    "abstract": " Title: An Evaluation of Memory Optimization Methods for Training Neural  Networks ",
    "url": "https://arxiv.org/abs/2303.14633",
    "authors": [
      "Xiaoxuan Liu",
      "Siddharth Jha",
      "Alvin Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2303.14730",
    "title": "Joint fMRI Decoding and Encoding with Latent Embedding Alignment",
    "abstract": " Comments: 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2303.14730",
    "authors": [
      "Xuelin Qian",
      "Yikai Wang",
      "Yanwei Fu",
      "Xinwei Sun",
      "Xiangyang Xue",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15754",
    "title": "Transferable Adversarial Attacks on Vision Transformers with Token  Gradient Regularization",
    "abstract": " Comments: CVPR 2023, Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.15754",
    "authors": [
      "Jianping Zhang",
      "Yizhan Huang",
      "Weibin Wu",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15821",
    "title": "Scaling Multi-Objective Security Games Provably via Space Discretization  Based Evolutionary Search",
    "abstract": " Title: Scaling Multi-Objective Security Games Provably via Space Discretization  Based Evolutionary Search ",
    "url": "https://arxiv.org/abs/2303.15821",
    "authors": [
      "Yu-Peng Wu",
      "Hong Qian",
      "Rong-Jun Qin",
      "Yi Chen",
      "Aimin Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.16132",
    "title": "Transformer and Snowball Graph Convolution Learning for Brain functional  network Classification",
    "abstract": " Comments: Prepared for submitting to HBP ",
    "url": "https://arxiv.org/abs/2303.16132",
    "authors": [
      "Jinlong Hu",
      "Yangmin Huang",
      "Shoubin Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.17671",
    "title": "Neural signature kernels as infinite-width-depth-limits of controlled  ResNets",
    "abstract": " Comments: Added commutativity of limits, ICML 2023 final version ",
    "url": "https://arxiv.org/abs/2303.17671",
    "authors": [
      "Nicola Muca Cirone",
      "Maud Lemercier",
      "Cristopher Salvi"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2303.17783",
    "title": "SOSR: Source-Free Image Super-Resolution with Wavelet Augmentation  Transformer",
    "abstract": " Comments: 15 pages, 9 figures, 10 tables ",
    "url": "https://arxiv.org/abs/2303.17783",
    "authors": [
      "Yuang Ai",
      "Xiaoqiang Zhou",
      "Huaibo Huang",
      "Lei Zhang",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.00234",
    "title": "Coordinated Defense Allocation in Reach-Avoid Scenarios with Efficient  Online Optimization",
    "abstract": " Title: Coordinated Defense Allocation in Reach-Avoid Scenarios with Efficient  Online Optimization ",
    "url": "https://arxiv.org/abs/2304.00234",
    "authors": [
      "Junwei Liu",
      "Zikai Ouyang",
      "Jiahui Yang",
      "Hua Chen",
      "Haibo Lu",
      "Wei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.03501",
    "title": "Continuous Input Embedding Size Search For Recommender Systems",
    "abstract": " Comments: To appear in SIGIR'23 ",
    "url": "https://arxiv.org/abs/2304.03501",
    "authors": [
      "Yunke Qu",
      "Tong Chen",
      "Xiangyu Zhao",
      "Lizhen Cui",
      "Kai Zheng",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.04033",
    "title": "Exploring the Connection between Robust and Generative Models",
    "abstract": " Comments: Italian Conference on AI - AI per Cybersecurity, 6 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2304.04033",
    "authors": [
      "Senad Beadini",
      "Iacopo Masi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04959",
    "title": "AdaTT: Adaptive Task-to-Task Fusion Network for Multitask Learning in  Recommendations",
    "abstract": " Title: AdaTT: Adaptive Task-to-Task Fusion Network for Multitask Learning in  Recommendations ",
    "url": "https://arxiv.org/abs/2304.04959",
    "authors": [
      "Danwei Li",
      "Zhengyu Zhang",
      "Siyang Yuan",
      "Mingze Gao",
      "Weilin Zhang",
      "Chaofei Yang",
      "Xi Liu",
      "Jiyan Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.08216",
    "title": "Context-Dependent Embedding Utterance Representations for Emotion  Recognition in Conversations",
    "abstract": " Comments: WASSA'23 ",
    "url": "https://arxiv.org/abs/2304.08216",
    "authors": [
      "Patr\u00edcia Pereira",
      "Helena Moniz",
      "Isabel Dias",
      "Joao Paulo Carvalho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.08457",
    "title": "Deep Learning Criminal Networks",
    "abstract": " Comments: 14 two-column pages, 5 figures ",
    "url": "https://arxiv.org/abs/2304.08457",
    "authors": [
      "Haroldo V. Ribeiro",
      "Diego D. Lopes",
      "Arthur A. B. Pessa",
      "Alvaro F. Martins",
      "Bruno R. da Cunha",
      "Sebastian Goncalves",
      "Ervin K. Lenzi",
      "Quentin S. Hanley",
      "Matjaz Perc"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2304.08996",
    "title": "Joint Age-based Client Selection and Resource Allocation for  Communication-Efficient Federated Learning over NOMA Networks",
    "abstract": " Title: Joint Age-based Client Selection and Resource Allocation for  Communication-Efficient Federated Learning over NOMA Networks ",
    "url": "https://arxiv.org/abs/2304.08996",
    "authors": [
      "Bibo Wu",
      "Fang Fang",
      "Xianbin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.11379",
    "title": "LiDAR2Map: In Defense of LiDAR-Based Semantic Map Construction Using  Online Camera Distillation",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2304.11379",
    "authors": [
      "Song Wang",
      "Wentong Li",
      "Wenyu Liu",
      "Xiaolu Liu",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.14268",
    "title": "Graphlet and Orbit Computation on Heterogeneous Graphs",
    "abstract": " Comments: 13 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2304.14268",
    "authors": [
      "Colin Cleveland",
      "Chin-Yen Lee",
      "Shen-Fu Tsai",
      "Wei-Hsuan Yu",
      "Hsuan-Wei Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2305.00097",
    "title": "NNSplitter: An Active Defense Solution for DNN Model via Automated  Weight Obfuscation",
    "abstract": " Comments: To appear at ICML 2023 ",
    "url": "https://arxiv.org/abs/2305.00097",
    "authors": [
      "Tong Zhou",
      "Yukui Luo",
      "Shaolei Ren",
      "Xiaolin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.00664",
    "title": "Dynamic Transfer Learning across Graphs",
    "abstract": " Title: Dynamic Transfer Learning across Graphs ",
    "url": "https://arxiv.org/abs/2305.00664",
    "authors": [
      "Haohui Wang",
      "Yuzhen Mao",
      "Jianhui Sun",
      "Si Zhang",
      "Yonghui Fan",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.02522",
    "title": "BitGNN: Unleashing the Performance Potential of Binary Graph Neural  Networks on GPUs",
    "abstract": " Comments: To appear in the International Conference on Supercomputing (ICS'23) ",
    "url": "https://arxiv.org/abs/2305.02522",
    "authors": [
      "Jou-An Chen",
      "Hsin-Hsuan Sung",
      "Xipeng Shen",
      "Sutanay Choudhury",
      "Ang Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.03063",
    "title": "Neuro-symbolic model for cantilever beams damage detection",
    "abstract": " Title: Neuro-symbolic model for cantilever beams damage detection ",
    "url": "https://arxiv.org/abs/2305.03063",
    "authors": [
      "Darian Onchis",
      "Gilbert-Rainer Gillich",
      "Eduard Hogea",
      "Cristian Tufisi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.03517",
    "title": "Few-shot Domain-Adaptive Visually-fused Event Detection from Text",
    "abstract": " Title: Few-shot Domain-Adaptive Visually-fused Event Detection from Text ",
    "url": "https://arxiv.org/abs/2305.03517",
    "authors": [
      "Farhad Moghimifar",
      "Fatemeh Shiri",
      "Van Nguyen",
      "Reza Haffari",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.03716",
    "title": "DSPDet3D: Dynamic Spatial Pruning for 3D Small Object Detection",
    "abstract": " Comments: Code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2305.03716",
    "authors": [
      "Xiuwei Xu",
      "Zhihao Sun",
      "Ziwei Wang",
      "Hongmin Liu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.04087",
    "title": "Self-Edit: Fault-Aware Code Editor for Code Generation",
    "abstract": " Comments: Accepted by ACL2023 ",
    "url": "https://arxiv.org/abs/2305.04087",
    "authors": [
      "Kechi Zhang",
      "Zhuo Li",
      "Jia Li",
      "Ge Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.04379",
    "title": "Data Efficient Training with Imbalanced Label Sample Distribution for  Fashion Detection",
    "abstract": " Comments: We have identified a substantial error in the experimental results and a potentially misleading explanation of the algorithm. We kindly request that you consider withdrawing this version to mitigate the risk of disseminating inaccurate information ",
    "url": "https://arxiv.org/abs/2305.04379",
    "authors": [
      "Xin Shen",
      "Praful Agrawal",
      "Zhongwei Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.04505",
    "title": "Target-Side Augmentation for Document-Level Machine Translation",
    "abstract": " Comments: Accepted by ACL2023 main conference ",
    "url": "https://arxiv.org/abs/2305.04505",
    "authors": [
      "Guangsheng Bao",
      "Zhiyang Teng",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.04560",
    "title": "Building Neural Networks on Matrix Manifolds: A Gyrovector Space  Approach",
    "abstract": " Title: Building Neural Networks on Matrix Manifolds: A Gyrovector Space  Approach ",
    "url": "https://arxiv.org/abs/2305.04560",
    "authors": [
      "Xuan Son Nguyen",
      "Shuo Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06167",
    "title": "K-SpecPart: Supervised embedding algorithms and cut overlay for improved  hypergraph partitioning",
    "abstract": " Title: K-SpecPart: Supervised embedding algorithms and cut overlay for improved  hypergraph partitioning ",
    "url": "https://arxiv.org/abs/2305.06167",
    "authors": [
      "Ismail Bustany",
      "Andrew B. Kahng",
      "Ioannis Koutis",
      "Bodhisatta Pramanik",
      "Zhiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06395",
    "title": "ACTC: Active Threshold Calibration for Cold-Start Knowledge Graph  Completion",
    "abstract": " Comments: Accepted to ACL'23 ",
    "url": "https://arxiv.org/abs/2305.06395",
    "authors": [
      "Anastasiia Sedova",
      "Benjamin Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.09938",
    "title": "Characterizing Long-Tail Categories on Graphs",
    "abstract": " Title: Characterizing Long-Tail Categories on Graphs ",
    "url": "https://arxiv.org/abs/2305.09938",
    "authors": [
      "Haohui Wang",
      "Baoyu Jing",
      "Kaize Ding",
      "Yada Zhu",
      "Liqing Zhang",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.10044",
    "title": "Two-Stream Regression Network for Dental Implant Position Prediction",
    "abstract": " Title: Two-Stream Regression Network for Dental Implant Position Prediction ",
    "url": "https://arxiv.org/abs/2305.10044",
    "authors": [
      "Xinquan Yang",
      "Xuguang Li",
      "Xuechen Li",
      "Wenting Chen",
      "Linlin Shen",
      "Xin Li",
      "Yongqiang Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10638",
    "title": "Disentangled Causal Graph Learning for Online Unsupervised Root Cause  Analysis",
    "abstract": " Title: Disentangled Causal Graph Learning for Online Unsupervised Root Cause  Analysis ",
    "url": "https://arxiv.org/abs/2305.10638",
    "authors": [
      "Dongjie Wang",
      "Zhengzhang Chen",
      "Yanjie Fu",
      "Yanchi Liu",
      "Haifeng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10758",
    "title": "Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and  Injecting it into MLPs: An Effective GNN-to-MLP Distillation Framework",
    "abstract": " Title: Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and  Injecting it into MLPs: An Effective GNN-to-MLP Distillation Framework ",
    "url": "https://arxiv.org/abs/2305.10758",
    "authors": [
      "Lirong Wu",
      "Haitao Lin",
      "Yufei Huang",
      "Tianyu Fan",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10838",
    "title": "ProgSG: Cross-Modality Representation Learning for Programs in  Electronic Design Automation",
    "abstract": " Comments: Requires further polishing ",
    "url": "https://arxiv.org/abs/2305.10838",
    "authors": [
      "Yunsheng Bai",
      "Atefeh Sohrabizadeh",
      "Zongyue Qin",
      "Ziniu Hu",
      "Yizhou Sun",
      "Jason Cong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2305.10847",
    "title": "Large Language Models can be Guided to Evade AI-Generated Text Detection",
    "abstract": " Title: Large Language Models can be Guided to Evade AI-Generated Text Detection ",
    "url": "https://arxiv.org/abs/2305.10847",
    "authors": [
      "Ning Lu",
      "Shengcai Liu",
      "Rui He",
      "Qi Wang",
      "Ke Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10964",
    "title": "Learning Activation Functions for Sparse Neural Networks",
    "abstract": " Title: Learning Activation Functions for Sparse Neural Networks ",
    "url": "https://arxiv.org/abs/2305.10964",
    "authors": [
      "Mohammad Loni",
      "Aditya Mohan",
      "Mehdi Asadi",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.14000",
    "title": "Node-wise Diffusion for Scalable Graph Learning",
    "abstract": " Title: Node-wise Diffusion for Scalable Graph Learning ",
    "url": "https://arxiv.org/abs/2305.14000",
    "authors": [
      "Keke Huang",
      "Jing Tang",
      "Juncheng Liu",
      "Renchi Yang",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.14079",
    "title": "Masked Modeling Duo for Speech: Specializing General-Purpose Audio  Representation to Speech using Denoising Distillation",
    "abstract": " Comments: Interspeech 2023; 5 pages, 2 figures, 6 tables, Code: this https URL ",
    "url": "https://arxiv.org/abs/2305.14079",
    "authors": [
      "Daisuke Niizumi",
      "Daiki Takeuchi",
      "Yasunori Ohishi",
      "Noboru Harada",
      "Kunio Kashino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.14449",
    "title": "Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust  Conversational Understanding",
    "abstract": " Title: Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust  Conversational Understanding ",
    "url": "https://arxiv.org/abs/2305.14449",
    "authors": [
      "Zheng Chen",
      "Ziyan Jiang",
      "Fan Yang",
      "Eunah Cho",
      "Xing Fan",
      "Xiaojiang Huang",
      "Yanbin Lu",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14668",
    "title": "Robust 3D-aware Object Classification via Discriminative  Render-and-Compare",
    "abstract": " Title: Robust 3D-aware Object Classification via Discriminative  Render-and-Compare ",
    "url": "https://arxiv.org/abs/2305.14668",
    "authors": [
      "Artur Jesslen",
      "Guofeng Zhang",
      "Angtian Wang",
      "Alan Yuille",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14955",
    "title": "DC-Net: Divide-and-Conquer for Salient Object Detection",
    "abstract": " Title: DC-Net: Divide-and-Conquer for Salient Object Detection ",
    "url": "https://arxiv.org/abs/2305.14955",
    "authors": [
      "Jiayi Zhu",
      "Xuebin Qin",
      "Abdulmotaleb Elsaddik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15148",
    "title": "Theoretically Principled Federated Learning for Balancing Privacy and  Utility",
    "abstract": " Title: Theoretically Principled Federated Learning for Balancing Privacy and  Utility ",
    "url": "https://arxiv.org/abs/2305.15148",
    "authors": [
      "Xiaojin Zhang",
      "Wenjie Li",
      "Kai Chen",
      "Shutao Xia",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.16044",
    "title": "Exploiting Noise as a Resource for Computation and Learning in Spiking  Neural Networks",
    "abstract": " Comments: Updated the code link; fixed the bug in the BBL file generated with bibliography management program ",
    "url": "https://arxiv.org/abs/2305.16044",
    "authors": [
      "Gehua Ma",
      "Rui Yan",
      "Huajin Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16649",
    "title": "FSD: Fully-Specialized Detector via Neural Architecture Search",
    "abstract": " Title: FSD: Fully-Specialized Detector via Neural Architecture Search ",
    "url": "https://arxiv.org/abs/2305.16649",
    "authors": [
      "Zhe Huang",
      "Yudian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17220",
    "title": "VoxDet: Voxel Learning for Novel Instance Detection",
    "abstract": " Comments: 17 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2305.17220",
    "authors": [
      "Bowen Li",
      "Jiashun Wang",
      "Yaoyu Hu",
      "Chen Wang",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17321",
    "title": "Optimal Resource Allocation with Delay Guarantees for Network Slicing in  Disaggregated RAN",
    "abstract": " Comments: 21 pages, 10 figures. For the associated GitHub repository, see this https URL ",
    "url": "https://arxiv.org/abs/2305.17321",
    "authors": [
      "Fl\u00e1vio G. C. Rocha",
      "Gabriel M. F. de Almeida",
      "Kleber V. Cardoso",
      "Cristiano B. Both",
      "Jos\u00e9 F. de Rezende"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.17537",
    "title": "Modeling Dynamic Environments with Scene Graph Memory",
    "abstract": " Title: Modeling Dynamic Environments with Scene Graph Memory ",
    "url": "https://arxiv.org/abs/2305.17537",
    "authors": [
      "Andrey Kurenkov",
      "Michael Lingelbach",
      "Tanmay Agarwal",
      "Chengshu Li",
      "Emily Jin",
      "Ruohan Zhang",
      "Fei-Fei Li",
      "Jiajun Wu",
      "Silvio Savarese",
      "Roberto Mart\u00edn-Mart\u00edn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17556",
    "title": "Scheduling Fork-Join Task Graphs to Heterogeneous Processors",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2305.17556",
    "authors": [
      "Huijun Wang",
      "Oliver Sinnen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.18402",
    "title": "Neural Sculpting: Uncovering hierarchically modular task structure  through pruning and network analysis",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2305.18402",
    "authors": [
      "Shreyas Malakarjun Patil",
      "Loizos Michael",
      "Constantine Dovrolis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18444",
    "title": "Continual Task Allocation in Meta-Policy Network via Sparse Prompting",
    "abstract": " Comments: Accepted by ICML 2023 ",
    "url": "https://arxiv.org/abs/2305.18444",
    "authors": [
      "Yijun Yang",
      "Tianyi Zhou",
      "Jing Jiang",
      "Guodong Long",
      "Yuhui Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18885",
    "title": "Criteria Tell You More than Ratings: Criteria Preference-Aware Light  Graph Convolution for Effective Multi-Criteria Recommendation",
    "abstract": " Comments: 12 pages, 10 figures, 5 tables; 29th ACM SIGKDD Conference on Knowledge Discovery & Data (KDD 2023) (to appear) (Please cite our conference version.) ",
    "url": "https://arxiv.org/abs/2305.18885",
    "authors": [
      "Jin-Duk Park",
      "Siqing Li",
      "Xin Cao",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19591",
    "title": "Traffic Prediction using Artificial Intelligence: Review of Recent  Advances and Emerging Opportunities",
    "abstract": " Comments: Published in Transportation Research Part C: Emerging Technologies (TR_C), Volume 145, 2022 ",
    "url": "https://arxiv.org/abs/2305.19591",
    "authors": [
      "Maryam Shaygan",
      "Collin Meese",
      "Wanxin Li",
      "Xiaolong Zhao",
      "Mark Nejad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19663",
    "title": "Vandermonde Neural Operators",
    "abstract": " Comments: 21 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2305.19663",
    "authors": [
      "Levi Lingsch",
      "Mike Michelis",
      "Sirani M. Perera",
      "Robert K. Katzschmann",
      "Siddartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.19725",
    "title": "Direct Learning-Based Deep Spiking Neural Networks: A Review",
    "abstract": " Comments: Accepted by Frontiers in Neuroscience. If your relevant work is omitted, feel free to email me at yfguo@pku.edu.cn ",
    "url": "https://arxiv.org/abs/2305.19725",
    "authors": [
      "Yufei Guo",
      "Xuhui Huang",
      "Zhe Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.00274",
    "title": "Optimal Rate-Matrix Pruning For Large-Scale Heterogeneous Systems",
    "abstract": " Comments: 38 pages ",
    "url": "https://arxiv.org/abs/2306.00274",
    "authors": [
      "Zhisheng Zhao",
      "Debankur Mukherjee"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2306.00418",
    "title": "Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect  Sentiment Quad Prediction",
    "abstract": " Comments: Accepted by ACL Findings (2023) ",
    "url": "https://arxiv.org/abs/2306.00418",
    "authors": [
      "Mengting Hu",
      "Yinhao Bai",
      "Yike Wu",
      "Zhen Zhang",
      "Liqi Zhang",
      "Hang Gao",
      "Shiwan Zhao",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.00488",
    "title": "Reconstructing Graph Diffusion History from a Single Snapshot",
    "abstract": " Comments: Full version of the KDD 2023 paper (including the appendix) ",
    "url": "https://arxiv.org/abs/2306.00488",
    "authors": [
      "Ruizhong Qiu",
      "Dingsu Wang",
      "Lei Ying",
      "H. Vincent Poor",
      "Yifang Zhang",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.01375",
    "title": "Robust and Generalisable Segmentation of Subtle Epilepsy-causing  Lesions: a Graph Convolutional Approach",
    "abstract": " Comments: accepted at MICCAI 2023 ",
    "url": "https://arxiv.org/abs/2306.01375",
    "authors": [
      "Hannah Spitzer",
      "Mathilde Ripart",
      "Abdulah Fawaz",
      "Logan Z. J. Williams",
      "MELD project",
      "Emma Robinson",
      "Juan Eugenio Iglesias",
      "Sophie Adler",
      "Konrad Wagstyl"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]