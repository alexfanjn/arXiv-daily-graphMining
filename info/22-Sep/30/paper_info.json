[
  {
    "id": "arXiv:2209.14299",
    "title": "Software Defect Prediction Using Support Vector Machine",
    "abstract": "Software defect prediction is an essential task during the software development Lifecycle as it can help managers to identify the most defect-proneness modules. Thus, it can reduce the test cost and assign testing resources efficiently. Many classification methods can be used to determine if the software is defective or not. Support Vector Machine (SVM) has not been used extensively for such problems because of its instability when applied on different datasets and parameter settings. The main parameter that influences the accuracy is the choice of the kernel function. The use of kernel functions has not been studied thoroughly in previous papers. Therefore, this research examines the performance and accuracy of SVM with six different kernel functions. Various public datasets from the PROMISE project empirically validate our hypothesis. The results demonstrate that no kernel function can give stable performance across different experimental settings. In addition, the use of PCA as a feature reduction algorithm shows slight accuracy improvement over some datasets. ",
    "url": "https://arxiv.org/abs/2209.14299",
    "authors": [
      "Haneen Abu Alhija",
      "Mohammad Azzeh",
      "Fadi Almasalha"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2209.14345",
    "title": "Audio Barlow Twins: Self-Supervised Audio Representation Learning",
    "abstract": "The Barlow Twins self-supervised learning objective requires neither negative samples or asymmetric learning updates, achieving results on a par with the current state-of-the-art within Computer Vision. As such, we present Audio Barlow Twins, a novel self-supervised audio representation learning approach, adapting Barlow Twins to the audio domain. We pre-train on the large-scale audio dataset AudioSet, and evaluate the quality of the learnt representations on 18 tasks from the HEAR 2021 Challenge, achieving results which outperform, or otherwise are on a par with, the current state-of-the-art for instance discrimination self-supervised learning approaches to audio representation learning. Code at https://github.com/jonahanton/SSL_audio. ",
    "url": "https://arxiv.org/abs/2209.14345",
    "authors": [
      "Jonah Anton",
      "Harry Coppock",
      "Pancham Shukla",
      "Bjorn W.Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14359",
    "title": "Robust Incremental Smoothing and Mapping (riSAM)",
    "abstract": "This paper presents a method for robust optimization for online incremental Simultaneous Localization and Mapping (SLAM). Due to the NP-Hardness of data association in the presence of perceptual aliasing, tractable (approximate) approaches to data association will produce erroneous measurements. We require SLAM back-ends that can converge to accurate solutions in the presence of outlier measurements while meeting online efficiency constraints. Existing robust SLAM methods either remain sensitive to outliers, become increasingly sensitive to initialization, or fail to provide online efficiency. We present the robust incremental Smoothing and Mapping (riSAM) algorithm, a robust back-end optimizer for incremental SLAM based on Graduated Non-Convexity. We demonstrate on benchmarking datasets that our algorithm achieves online efficiency, outperforms existing online approaches, and matches or improves the performance of existing offline methods. ",
    "url": "https://arxiv.org/abs/2209.14359",
    "authors": [
      "Daniel McGann",
      "John G. Rogers III",
      "Michael Kaess"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14360",
    "title": "Robust Lattice-based Motion Planning",
    "abstract": "This paper proposes a robust lattice-based motion-planning algorithm for nonlinear systems affected by a bounded disturbance. The proposed motion planner utilizes the nominal disturbance-free system model to generate motion primitives, which are associated with fixed-size tubes. These tubes are characterized through designing a feedback controller, that guarantees boundedness of the errors occurring due to mismatch between the disturbed nonlinear system and the nominal system. The motion planner then sequentially implements the tube-based motion primitives while solving an online graph-search problem. The objective of the graph-search problem is to connect the initial state to the final state, through sampled states in a suitably discretized state space, such that the tubes do not pass through any unsafe states (representing obstacles) appearing during runtime. The proposed strategy is implemented on an Euler-Lagrange based ship model which is affected by significant wind disturbance. It is shown that the uncertain system trajectories always stay within a suitably constructed tube around the nominal trajectory and terminate within a region around the final state, whose size is dictated by the size of the tube. ",
    "url": "https://arxiv.org/abs/2209.14360",
    "authors": [
      "Abhishek Dhar",
      "Carl Hyn\u00e9n",
      "Johan L\u00f6fberg",
      "Daniel Axehill"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.14369",
    "title": "Social Search: retrieving information in Online Social Platforms -- A  Survey",
    "abstract": "Social Search research deals with studying methodologies exploiting social information to better satisfy user information needs in Online Social Media while simplifying the search effort and consequently reducing the time spent and the computational resources utilized. Starting from previous studies, in this work, we analyze the current state of the art of the Social Search area, proposing a new taxonomy and highlighting current limitations and open research directions. We divide the Social Search area into three subcategories, where the social aspect plays a pivotal role: Social Question&Answering, Social Content Search, and Social Collaborative Search. For each subcategory, we present the key concepts and selected representative approaches in the literature in greater detail. We found that, up to now, a large body of studies model users' preferences and their relations by simply combining social features made available by social platforms. It paves the way for significant research to exploit more structured information about users' social profiles and behaviors (as they can be inferred from data available on social platforms) to optimize their information needs further. ",
    "url": "https://arxiv.org/abs/2209.14369",
    "authors": [
      "Maddalena Amendola",
      "Andrea Passarella",
      "Raffaele Perego"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.14378",
    "title": "UNesT: Local Spatial Representation Learning with Hierarchical  Transformer for Efficient Medical Segmentation",
    "abstract": "Transformer-based models, capable of learning better global dependencies, have recently demonstrated exceptional representation learning capabilities in computer vision and medical image analysis. Transformer reformats the image into separate patches and realize global communication via the self-attention mechanism. However, positional information between patches is hard to preserve in such 1D sequences, and loss of it can lead to sub-optimal performance when dealing with large amounts of heterogeneous tissues of various sizes in 3D medical image segmentation. Additionally, current methods are not robust and efficient for heavy-duty medical segmentation tasks such as predicting a large number of tissue classes or modeling globally inter-connected tissues structures. Inspired by the nested hierarchical structures in vision transformer, we proposed a novel 3D medical image segmentation method (UNesT), employing a simplified and faster-converging transformer encoder design that achieves local communication among spatially adjacent patch sequences by aggregating them hierarchically. We extensively validate our method on multiple challenging datasets, consisting anatomies of 133 structures in brain, 14 organs in abdomen, 4 hierarchical components in kidney, and inter-connected kidney tumors). We show that UNesT consistently achieves state-of-the-art performance and evaluate its generalizability and data efficiency. Particularly, the model achieves whole brain segmentation task complete ROI with 133 tissue classes in single network, outperforms prior state-of-the-art method SLANT27 ensembled with 27 network tiles, our model performance increases the mean DSC score of the publicly available Colin and CANDI dataset from 0.7264 to 0.7444 and from 0.6968 to 0.7025, respectively. ",
    "url": "https://arxiv.org/abs/2209.14378",
    "authors": [
      "Xin Yu",
      "Qi Yang",
      "Yinchi Zhou",
      "Leon Y. Cai",
      "Riqiang Gao",
      "Ho Hin Lee",
      "Thomas Li",
      "Shunxing Bao",
      "Zhoubing Xu",
      "Thomas A. Lasko",
      "Richard G. Abramson",
      "Zizhao Zhang",
      "Yuankai Huo",
      "Bennett A. Landman",
      "Yucheng Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14385",
    "title": "Feature Decoupling in Self-supervised Representation Learning for Open  Set Recognition",
    "abstract": "Assuming unknown classes could be present during classification, the open set recognition (OSR) task aims to classify an instance into a known class or reject it as unknown. In this paper, we use a two-stage training strategy for the OSR problems. In the first stage, we introduce a self-supervised feature decoupling method that finds the content features of the input samples from the known classes. Specifically, our feature decoupling approach learns a representation that can be split into content features and transformation features. In the second stage, we fine-tune the content features with the class labels. The fine-tuned content features are then used for the OSR problems. Moreover, we consider an unsupervised OSR scenario, where we cluster the content features learned from the first stage. To measure representation quality, we introduce intra-inter ratio (IIR). Our experimental results indicate that our proposed self-supervised approach outperforms others in image and malware OSR problems. Also, our analyses indicate that IIR is correlated with OSR performance. ",
    "url": "https://arxiv.org/abs/2209.14385",
    "authors": [
      "Jingyun Jia",
      "Philip K. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14401",
    "title": "Shortest Beer Path Queries in Interval Graphs",
    "abstract": "Our interest is in paths between pairs of vertices that go through at least one of a subset of the vertices known as beer vertices. Such a path is called a beer path, and the beer distance between two vertices is the length of the shortest beer path. We show that we can represent unweighted interval graphs using $2n \\log n + O(n) + O(|B|\\log n)$ bits where $|B|$ is the number of beer vertices. This data structure answers beer distance queries in $O(\\log^\\varepsilon n)$ time for any constant $\\varepsilon > 0$ and shortest beer path queries in $O(\\log^\\varepsilon n + d)$ time, where $d$ is the beer distance between the two nodes. We also show that proper interval graphs may be represented using $3n + o(n)$ bits to support beer distance queries in $O(f(n)\\log n)$ time for any $f(n) \\in \\omega(1)$ and shortest beer path queries in $O(d)$ time. All of these results also have time-space trade-offs. Lastly we show that the information theoretic lower bound for beer proper interval graphs is very close to the space of our structure, namely $\\log(4+2\\sqrt{3})n - o(n)$ (or about $ 2.9 n$) bits. ",
    "url": "https://arxiv.org/abs/2209.14401",
    "authors": [
      "Rathish Das",
      "Meng He",
      "Eitan Kondratovsky",
      "J. Ian Munro",
      "Anurag Murty Naredla",
      "Kaiyu Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2209.14402",
    "title": "Learning to Explain Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are a popular class of machine learning models. Inspired by the learning to explain (L2X) paradigm, we propose L2XGNN, a framework for explainable GNNs which provides faithful explanations by design. L2XGNN learns a mechanism for selecting explanatory subgraphs (motifs) which are exclusively used in the GNNs message-passing operations. L2XGNN is able to select, for each input graph, a subgraph with specific properties such as being sparse and connected. Imposing such constraints on the motifs often leads to more interpretable and effective explanations. Experiments on several datasets suggest that L2XGNN achieves the same classification accuracy as baseline methods using the entire input graph while ensuring that only the provided explanations are used to make predictions. Moreover, we show that L2XGNN is able to identify motifs responsible for the graph's properties it is intended to predict. ",
    "url": "https://arxiv.org/abs/2209.14402",
    "authors": [
      "Giuseppe Serra",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14406",
    "title": "Biological connectomes as a representation for the architecture of  artificial neural networks",
    "abstract": "Grand efforts in neuroscience are working toward mapping the connectomes of many new species, including the near completion of the Drosophila melanogaster. It is important to ask whether these models could benefit artificial intelligence. In this work we ask two fundamental questions: (1) where and when biological connectomes can provide use in machine learning, (2) which design principles are necessary for extracting a good representation of the connectome. Toward this end, we translate the motor circuit of the C. Elegans nematode into artificial neural networks at varying levels of biophysical realism and evaluate the outcome of training these networks on motor and non-motor behavioral tasks. We demonstrate that biophysical realism need not be upheld to attain the advantages of using biological circuits. We also establish that, even if the exact wiring diagram is not retained, the architectural statistics provide a valuable prior. Finally, we show that while the C. Elegans locomotion circuit provides a powerful inductive bias on locomotion problems, its structure may hinder performance on tasks unrelated to locomotion such as visual classification problems. ",
    "url": "https://arxiv.org/abs/2209.14406",
    "authors": [
      "Samuel Schmidgall",
      "Catherine Schuman",
      "Maryam Parsa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14409",
    "title": "Applying Machine Learning for Duplicate Detection, Throttling and  Prioritization of Equipment Commissioning Audits at Fulfillment Network",
    "abstract": "VQ (Vendor Qualification) and IOQ (Installation and Operation Qualification) audits are implemented in warehouses to ensure all equipment being turned over in the fulfillment network meets the quality standards. Audit checks are likely to be skipped if there are many checks to be performed in a short time. In addition, exploratory data analysis reveals several instances of similar checks being performed on the same assets and thus, duplicating the effort. In this work, Natural Language Processing and Machine Learning are applied to trim a large checklist dataset for a network of warehouses by identifying similarities and duplicates, and predict the non-critical ones with a high passing rate. The study proposes ML classifiers to identify checks which have a high passing probability of IOQ and VQ and assign priorities to checks to be prioritized when the time is not available to perform all checks. This research proposes using NLP-based BlazingText classifier to throttle the checklists with a high passing rate, which can reduce 10%-37% of the checks and achieve significant cost reduction. The applied algorithm over performs Random Forest and Neural Network classifiers and achieves an area under the curve of 90%. Because of imbalanced data, down-sampling and upweighting have shown a positive impact on the models' accuracy using F1 score, which improve from 8% to 75%. In addition, the proposed duplicate detection process identifies 17% possible redundant checks to be trimmed. ",
    "url": "https://arxiv.org/abs/2209.14409",
    "authors": [
      "Farouq Halawa",
      "Majid Abdul",
      "Raashid Mohammed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2209.14429",
    "title": "Efficient parameterized algorithms on graphs with heterogeneous  structure: Combining tree-depth and modular-width",
    "abstract": "Many computational problems admit fast algorithms on special inputs, however, the required properties might be quite restrictive. E.g., many graph problems can be solved much faster on interval or cographs, or on graphs of small modular-width or small tree-width, than on general graphs. One challenge is to attain the greatest generality of such results, i.e., being applicable to less restrictive input classes, without losing much in terms of running time. Building on the use of algebraic expressions we present a clean and robust way of combining such homogeneous structure into more complex heterogeneous structure, and we show-case this for the combination of modular-width, tree-depth, and a natural notion of modular tree-depth. We give a generic framework for designing efficient parameterized algorithms on the created graph classes, aimed at getting competitive running times that match the homogeneous cases. To show the applicability we give efficient parameterized algorithms for Negative Cycle Detection, Vertex-Weighted All-Pairs Shortest Paths, and Triangle Counting. ",
    "url": "https://arxiv.org/abs/2209.14429",
    "authors": [
      "Stefan Kratsch",
      "Florian Nelles"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2209.14431",
    "title": "Increasing the Accuracy of a Neural Network Using Frequency Selective  Mesh-to-Grid Resampling",
    "abstract": "Neural networks are widely used for almost any task of recognizing image content. Even though much effort has been put into investigating efficient network architectures, optimizers, and training strategies, the influence of image interpolation on the performance of neural networks is not well studied. Furthermore, research has shown that neural networks are often sensitive to minor changes in the input image leading to drastic drops of their performance. Therefore, we propose the use of keypoint agnostic frequency selective mesh-to-grid resampling (FSMR) for the processing of input data for neural networks in this paper. This model-based interpolation method already showed that it is capable of outperforming common interpolation methods in terms of PSNR. Using an extensive experimental evaluation we show that depending on the network architecture and classification task the application of FSMR during training aids the learning process. Furthermore, we show that the usage of FSMR in the application phase is beneficial. The classification accuracy can be increased by up to 4.31 percentage points for ResNet50 and the Oxflower17 dataset. ",
    "url": "https://arxiv.org/abs/2209.14431",
    "authors": [
      "Andreas Spruck",
      "Viktoria Heimann",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.14434",
    "title": "Efficient Medical Image Assessment via Self-supervised Learning",
    "abstract": "High-performance deep learning methods typically rely on large annotated training datasets, which are difficult to obtain in many clinical applications due to the high cost of medical image labeling. Existing data assessment methods commonly require knowing the labels in advance, which are not feasible to achieve our goal of 'knowing which data to label.' To this end, we formulate and propose a novel and efficient data assessment strategy, EXponentiAl Marginal sINgular valuE (EXAMINE) score, to rank the quality of unlabeled medical image data based on their useful latent representations extracted via Self-supervised Learning (SSL) networks. Motivated by theoretical implication of SSL embedding space, we leverage a Masked Autoencoder for feature extraction. Furthermore, we evaluate data quality based on the marginal change of the largest singular value after excluding the data point in the dataset. We conduct extensive experiments on a pathology dataset. Our results indicate the effectiveness and efficiency of our proposed methods for selecting the most valuable data to label. ",
    "url": "https://arxiv.org/abs/2209.14434",
    "authors": [
      "Chun-Yin Huang",
      "Qi Lei",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14435",
    "title": "Out-of-Distribution Detection for LiDAR-based 3D Object Detection",
    "abstract": "3D object detection is an essential part of automated driving, and deep neural networks (DNNs) have achieved state-of-the-art performance for this task. However, deep models are notorious for assigning high confidence scores to out-of-distribution (OOD) inputs, that is, inputs that are not drawn from the training distribution. Detecting OOD inputs is challenging and essential for the safe deployment of models. OOD detection has been studied extensively for the classification task, but it has not received enough attention for the object detection task, specifically LiDAR-based 3D object detection. In this paper, we focus on the detection of OOD inputs for LiDAR-based 3D object detection. We formulate what OOD inputs mean for object detection and propose to adapt several OOD detection methods for object detection. We accomplish this by our proposed feature extraction method. To evaluate OOD detection methods, we develop a simple but effective technique of generating OOD objects for a given object detection model. Our evaluation based on the KITTI dataset shows that different OOD detection methods have biases toward detecting specific OOD objects. It emphasizes the importance of combined OOD detection methods and more research in this direction. ",
    "url": "https://arxiv.org/abs/2209.14435",
    "authors": [
      "Chengjie Huang",
      "Van Duong Nguyen",
      "Vahdat Abdelzad",
      "Christopher Gus Mannes",
      "Luke Rowe",
      "Benjamin Therien",
      "Rick Salay",
      "Krzysztof Czarnecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.14440",
    "title": "GeONet: a neural operator for learning the Wasserstein geodesic",
    "abstract": "Optimal transport (OT) offers a versatile framework to compare complex data distributions in a geometrically meaningful way. Traditional methods for computing the Wasserstein distance and geodesic between probability measures require mesh-dependent domain discretization and suffer from the curse-of-dimensionality. We present GeONet, a mesh-invariant deep neural operator network that learns the non-linear mapping from the input pair of initial and terminal distributions to the Wasserstein geodesic connecting the two endpoint distributions. In the offline training stage, GeONet learns the saddle point optimality conditions for the dynamic formulation of the OT problem in the primal and dual spaces that are characterized by a coupled PDE system. The subsequent inference stage is instantaneous and can be deployed for real-time predictions in the online learning setting. We demonstrate that GeONet achieves comparable testing accuracy to the standard OT solvers on a simulation example and the CIFAR-10 dataset with considerably reduced inference-stage computational cost by orders of magnitude. ",
    "url": "https://arxiv.org/abs/2209.14440",
    "authors": [
      "Andrew Gracyk",
      "Xiaohui Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.14447",
    "title": "Visual Detection of Diver Attentiveness for Underwater Human-Robot  Interaction",
    "abstract": "Many underwater tasks, such as cable-and-wreckage inspection, search-and-rescue, benefit from robust human-robot interaction (HRI) capabilities. With the recent advancements in vision-based underwater HRI methods, autonomous underwater vehicles (AUVs) can communicate with their human partners even during a mission. However, these interactions usually require active participation especially from humans (e.g., one must keep looking at the robot during an interaction). Therefore, an AUV must know when to start interacting with a human partner, i.e., if the human is paying attention to the AUV or not. In this paper, we present a diver attention estimation framework for AUVs to autonomously detect the attentiveness of a diver and then navigate and reorient itself, if required, with respect to the diver to initiate an interaction. The core element of the framework is a deep neural network (called DATT-Net) which exploits the geometric relation among 10 facial keypoints of the divers to determine their head orientation. Our on-the-bench experimental evaluations (using unseen data) demonstrate that the proposed DATT-Net architecture can determine the attentiveness of human divers with promising accuracy. Our real-world experiments also confirm the efficacy of DATT-Net which enables real-time inference and allows the AUV to position itself for an AUV-diver interaction. ",
    "url": "https://arxiv.org/abs/2209.14447",
    "authors": [
      "Sadman Sakib Enan",
      "Junaed Sattar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14464",
    "title": "Neural Methods for Logical Reasoning Over Knowledge Graphs",
    "abstract": "Reasoning is a fundamental problem for computers and deeply studied in Artificial Intelligence. In this paper, we specifically focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real-world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which include negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to handle FOL queries with Conjunction ($\\wedge$), Disjunction ($\\vee$) and Negation ($\\neg$) operators. We demonstrate experimentally the performance of our model through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10\\% relative increase over the best performing state of the art and more than 30\\% over the original method based on single-point vector embeddings. ",
    "url": "https://arxiv.org/abs/2209.14464",
    "authors": [
      "Alfonso Amayuelas",
      "Shuai Zhang",
      "Susie Xi Rao",
      "Ce Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14479",
    "title": "Semantics-Guided Object Removal for Facial Images: with Broad  Applicability and Robust Style Preservation",
    "abstract": "Object removal and image inpainting in facial images is a task in which objects that occlude a facial image are specifically targeted, removed, and replaced by a properly reconstructed facial image. Two different approaches utilizing U-net and modulated generator respectively have been widely endorsed for this task for their unique advantages but notwithstanding each method's innate disadvantages. U-net, a conventional approach for conditional GANs, retains fine details of unmasked regions but the style of the reconstructed image is inconsistent with the rest of the original image and only works robustly when the size of the occluding object is small enough. In contrast, the modulated generative approach can deal with a larger occluded area in an image and provides {a} more consistent style, yet it usually misses out on most of the detailed features. This trade-off between these two models necessitates an invention of a model that can be applied to any size of mask while maintaining a consistent style and preserving minute details of facial features. Here, we propose Semantics-Guided Inpainting Network (SGIN) which itself is a modification of the modulated generator, aiming to take advantage of its advanced generative capability and preserve the high-fidelity details of the original image. By using the guidance of a semantic map, our model is capable of manipulating facial features which grants direction to the one-to-many problem for further practicability. ",
    "url": "https://arxiv.org/abs/2209.14479",
    "authors": [
      "Jookyung Song",
      "Yeonjin Chang",
      "Seonguk Park",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14499",
    "title": "NVRadarNet: Real-Time Radar Obstacle and Free Space Detection for  Autonomous Driving",
    "abstract": "Detecting obstacles is crucial for safe and efficient autonomous driving. To this end, we present NVRadarNet, a deep neural network (DNN) that detects dynamic obstacles and drivable free space using automotive RADAR sensors. The network utilizes temporally accumulated data from multiple RADAR sensors to detect dynamic obstacles and compute their orientation in a top-down bird's-eye view (BEV). The network also regresses drivable free space to detect unclassified obstacles. Our DNN is the first of its kind to utilize sparse RADAR signals in order to perform obstacle and free space detection in real time from RADAR data only. The network has been successfully used for perception on our autonomous vehicles in real self-driving scenarios. The network runs faster than real time on an embedded GPU and shows good generalization across geographic regions. ",
    "url": "https://arxiv.org/abs/2209.14499",
    "authors": [
      "Alexander Popov",
      "Patrik Gebhardt",
      "Ke Chen",
      "Ryan Oldja",
      "Heeseok Lee",
      "Shane Murray",
      "Ruchi Bhargava",
      "Nikolai Smolyanskiy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14503",
    "title": "Tourism's trend Ranking on Social Media Data Using Fuzzy-AHP vs. AHP",
    "abstract": "Tourism is an exciting thing to be visited by people in the world. Search for attractive and popular places can be done through social media. Data from social media or websites can be used as a reference to find current travel trends and get information about reviews, stories, likes, forums, blogs, and feedback from a place. However, if the search is done manually one by one, it takes a long time, and it becomes interesting to do research. So, searching based on current trends will be easier and faster. For this reason, this study uses a computer base to search by ranking tourist facilities from social media data or websites using the multi-criteria decision-making (MCDM) method. The implementation of the method used in finding the trend is the Fuzzy-AHP method in comparison with the AHP. The data used is data reviews, stories, likes, forums, blogs, and feedback from the web or social media. Because with these components, tourism can be developed according to visitors\\'' wishes. The research aims to rank facilities\\'' tourism attractions (trends) and development priorities. The priority and ranking used the fuzzy-AHP and AHP method to determine weight criteria and the ranking process. The highest ranking is on the Parks/Picnic Spots attraction, and make it a priority to develop. The methods have an average value MSE of all data is \\approx 0.0002, which can be used for this ranking. ",
    "url": "https://arxiv.org/abs/2209.14503",
    "authors": [
      "Shoffan Saifullah"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.14514",
    "title": "How Powerful is Implicit Denoising in Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs), which aggregate features from neighbors, are widely used for graph-structured data processing due to their powerful representation learning capabilities. It is generally believed that GNNs can implicitly remove the non-predictive noises. However, the analysis of implicit denoising effect in graph neural networks remains open. In this work, we conduct a comprehensive theoretical study and analyze when and why the implicit denoising happens in GNNs. Specifically, we study the convergence properties of noise matrix. Our theoretical analysis suggests that the implicit denoising largely depends on the connectivity, the graph size, and GNN architectures. Moreover, we formally define and propose the adversarial graph signal denoising (AGSD) problem by extending graph signal denoising problem. By solving such a problem, we derive a robust graph convolution, where the smoothness of the node representations and the implicit denoising effect can be enhanced. Extensive empirical evaluations verify our theoretical analyses and the effectiveness of our proposed model. ",
    "url": "https://arxiv.org/abs/2209.14514",
    "authors": [
      "Songtao Liu",
      "Rex Ying",
      "Hanze Dong",
      "Lu Lin",
      "Jinghui Chen",
      "Dinghao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14525",
    "title": "Self-Configurable Stabilized Real-Time Detection Learning for Autonomous  Driving Applications",
    "abstract": "Guaranteeing real-time and accurate object detection simultaneously is paramount in autonomous driving environments. However, the existing object detection neural network systems are characterized by a tradeoff between computation time and accuracy, making it essential to optimize such a tradeoff. Fortunately, in many autonomous driving environments, images come in a continuous form, providing an opportunity to use optical flow. In this paper, we improve the performance of an object detection neural network utilizing optical flow estimation. In addition, we propose a Lyapunov optimization framework for time-average performance maximization subject to stability. It adaptively determines whether to use optical flow to suit the dynamic vehicle environment, thereby ensuring the vehicle's queue stability and the time-average maximum performance simultaneously. To verify the key ideas, we conduct numerical experiments with various object detection neural networks and optical flow estimation networks. In addition, we demonstrate the self-configurable stabilized detection with YOLOv3-tiny and FlowNet2-S, which are the real-time object detection network and an optical flow estimation network, respectively. In the demonstration, our proposed framework improves the accuracy by 3.02%, the number of detected objects by 59.6%, and the queue stability for computing capabilities. ",
    "url": "https://arxiv.org/abs/2209.14525",
    "authors": [
      "Won Joon Yun",
      "Soohyun Park",
      "Joongheon Kim",
      "David Mohaisen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.14553",
    "title": "Regularizing Neural Network Training via Identity-wise Discriminative  Feature Suppression",
    "abstract": "It is well-known that a deep neural network has a strong fitting capability and can easily achieve a low training error even with randomly assigned class labels. When the number of training samples is small, or the class labels are noisy, networks tend to memorize patterns specific to individual instances to minimize the training error. This leads to the issue of overfitting and poor generalisation performance. This paper explores a remedy by suppressing the network's tendency to rely on instance-specific patterns for empirical error minimisation. The proposed method is based on an adversarial training framework. It suppresses features that can be utilized to identify individual instances among samples within each class. This leads to classifiers only using features that are both discriminative across classes and common within each class. We call our method Adversarial Suppression of Identity Features (ASIF), and demonstrate the usefulness of this technique in boosting generalisation accuracy when faced with small datasets or noisy labels. Our source code is available. ",
    "url": "https://arxiv.org/abs/2209.14553",
    "authors": [
      "Avraham Chapman",
      "Lingqiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14557",
    "title": "Neural Media Bias Detection Using Distant Supervision With BABE -- Bias  Annotations By Experts",
    "abstract": "Media coverage has a substantial effect on the public perception of events. Nevertheless, media outlets are often biased. One way to bias news articles is by altering the word choice. The automatic identification of bias by word choice is challenging, primarily due to the lack of a gold standard data set and high context dependencies. This paper presents BABE, a robust and diverse data set created by trained experts, for media bias research. We also analyze why expert labeling is essential within this domain. Our data set offers better annotation quality and higher inter-annotator agreement than existing work. It consists of 3,700 sentences balanced among topics and outlets, containing media bias labels on the word and sentence level. Based on our data, we also introduce a way to detect bias-inducing sentences in news articles automatically. Our best performing BERT-based model is pre-trained on a larger corpus consisting of distant labels. Fine-tuning and evaluating the model on our proposed supervised data set, we achieve a macro F1-score of 0.804, outperforming existing methods. ",
    "url": "https://arxiv.org/abs/2209.14557",
    "authors": [
      "Timo Spinde",
      "Manuel Plank",
      "Jan-David Krieger",
      "Terry Ruas",
      "Bela Gipp",
      "Akiko Aizawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.14583",
    "title": "Spatial Moment Pooling Improves Neural Image Assessment",
    "abstract": "In recent years, there has been widespread attention drawn to convolutional neural network (CNN) based blind image quality assessment (IQA). A large number of works start by extracting deep features from CNN. Then, those features are processed through spatial average pooling (SAP) and fully connected layers to predict quality. Inspired by full reference IQA and texture features, in this paper, we extend SAP ($1^{st}$ moment) into spatial moment pooling (SMP) by incorporating higher order moments (such as variance, skewness). Moreover, we provide learning friendly normalization to circumvent numerical issue when computing gradients of higher moments. Experimental results suggest that simply upgrading SAP to SMP significantly enhances CNN-based blind IQA methods and achieves state of the art performance. ",
    "url": "https://arxiv.org/abs/2209.14583",
    "authors": [
      "Tongda Xu",
      "Yifan Shao",
      "Yan Wang",
      "Hongwei Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14594",
    "title": "Bayesian Neural Network Versus Ex-Post Calibration For Prediction  Uncertainty",
    "abstract": "Probabilistic predictions from neural networks which account for predictive uncertainty during classification is crucial in many real-world and high-impact decision making settings. However, in practice most datasets are trained on non-probabilistic neural networks which by default do not capture this inherent uncertainty. This well-known problem has led to the development of post-hoc calibration procedures, such as Platt scaling (logistic), isotonic and beta calibration, which transforms the scores into well calibrated empirical probabilities. A plausible alternative to the calibration approach is to use Bayesian neural networks, which directly models a predictive distribution. Although they have been applied to images and text datasets, they have seen limited adoption in the tabular and small data regime. In this paper, we demonstrate that Bayesian neural networks yields competitive performance when compared to calibrated neural networks and conduct experiments across a wide array of datasets. ",
    "url": "https://arxiv.org/abs/2209.14594",
    "authors": [
      "Satya Borgohain",
      "Klaus Ackermann",
      "Ruben Loaiza-Maya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.14599",
    "title": "Online pseudo labeling for polyp segmentation with momentum networks",
    "abstract": "Semantic segmentation is an essential task in developing medical image diagnosis systems. However, building an annotated medical dataset is expensive. Thus, semi-supervised methods are significant in this circumstance. In semi-supervised learning, the quality of labels plays a crucial role in model performance. In this work, we present a new pseudo labeling strategy that enhances the quality of pseudo labels used for training student networks. We follow the multi-stage semi-supervised training approach, which trains a teacher model on a labeled dataset and then uses the trained teacher to render pseudo labels for student training. By doing so, the pseudo labels will be updated and more precise as training progress. The key difference between previous and our methods is that we update the teacher model during the student training process. So the quality of pseudo labels is improved during the student training process. We also propose a simple but effective strategy to enhance the quality of pseudo labels using a momentum model -- a slow copy version of the original model during training. By applying the momentum model combined with re-rendering pseudo labels during student training, we achieved an average of 84.1% Dice Score on five datasets (i.e., Kvarsir, CVC-ClinicDB, ETIS-LaribPolypDB, CVC-ColonDB, and CVC-300) with only 20% of the dataset used as labeled data. Our results surpass common practice by 3% and even approach fully-supervised results on some datasets. Our source code and pre-trained models are available at https://github.com/sun-asterisk-research/online learning ssl ",
    "url": "https://arxiv.org/abs/2209.14599",
    "authors": [
      "Toan Pham Van",
      "Linh Bao Doan",
      "Thanh Tung Nguyen",
      "Duc Trung Tran",
      "Quan Van Nguyen",
      "Dinh Viet Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14624",
    "title": "Is Complexity Required for Neural Network Pruning? A Case Study on  Global Magnitude Pruning",
    "abstract": "Pruning neural networks has become popular in the last decade when it was shown that a large number of weights can be safely removed from modern neural networks without compromising accuracy. Numerous pruning methods have been proposed since then, each claiming to be better than the previous. Many state-of-the-art (SOTA) techniques today rely on complex pruning methodologies utilizing importance scores, getting feedback through back-propagation or having heuristics-based pruning rules amongst others. We question this pattern of introducing complexity in order to achieve better pruning results. We benchmark these SOTA techniques against Global Magnitude Pruning (Global MP), a naive pruning baseline, to evaluate whether complexity is really needed to achieve higher performance. Global MP ranks weights in order of their magnitudes and prunes the smallest ones. Hence, in its vanilla form, it is one of the simplest pruning techniques. Surprisingly, we find that vanilla Global MP outperforms all the other SOTA techniques and achieves a new SOTA result. It also achieves good performance on FLOPs sparsification, which we find is enhanced, when pruning is conducted in a gradual fashion. We also find that Global MP is generalizable across tasks, datasets and models with superior performance. Moreover, a common issue that many pruning algorithms run into at high sparsity rates, namely, layer-collapse, can be easily fixed in Global MP by setting a minimum threshold of weights to be retained in each layer. Lastly, unlike many other SOTA techniques, Global MP does not require any additional algorithm specific hyper-parameters and is very straightforward to tune and implement. We showcase our findings on various models (WRN-28-8, ResNet-32, ResNet-50, MobileNet-V1 and FastGRNN) and multiple datasets (CIFAR-10, ImageNet and HAR-2). Code is available at https://github.com/manasgupta-1/GlobalMP. ",
    "url": "https://arxiv.org/abs/2209.14624",
    "authors": [
      "Manas Gupta",
      "Efe Camci",
      "Vishandi Rudy Keneta",
      "Abhishek Vaidyanathan",
      "Ritwik Kanodia",
      "Chuan-Sheng Foo",
      "Wu Min",
      "Lin Jie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14641",
    "title": "Scaling transformation of the multimode nonlinear Schr\u00f6dinger equation  for physics-informed neural networks",
    "abstract": "Single-mode optical fibers (SMFs) have become the backbone of modern communication systems. However, their throughput is expected to reach its theoretical limit in the nearest future. Utilization of multimode fibers (MMFs) is considered as one of the most promising solutions rectifying this capacity crunch. Nevertheless, differential equations describing light propagation in MMFs are a way more sophisticated than those for SMFs, which makes numerical modelling of MMF-based systems computationally demanding and impractical for the most part of realistic scenarios. Physics-informed neural networks (PINNs) are known to outperform conventional numerical approaches in various domains and have been successfully applied to the nonlinear Schr\\\"odinger equation (NLSE) describing light propagation in SMFs. A comprehensive study on application of PINN to the multimode NLSE (MMNLSE) is still lacking though. To the best of our knowledge, this paper is the first to deploy the paradigm of PINN for MMNLSE and to demonstrate that a straightforward implementation of PINNs by analogy with NLSE does not work out. We pinpoint all issues hindering PINN convergence and introduce a novel scaling transformation for the zero-order dispersion coefficient that makes PINN capture all relevant physical effects. Our simulations reveal good agreement with the split-step Fourier (SSF) method and extend numerically attainable propagation lengths up to several hundred meters. All major limitations are also highlighted. ",
    "url": "https://arxiv.org/abs/2209.14641",
    "authors": [
      "Ivan Chuprov",
      "Dmitry Efremenko",
      "Jiexing Gao",
      "Pavel Anisimov",
      "Viacheslav Zemlyakov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2209.14642",
    "title": "A Coarse-to-fine Cascaded Evidence-Distillation Neural Network for  Explainable Fake News Detection",
    "abstract": "Existing fake news detection methods aim to classify a piece of news as true or false and provide veracity explanations, achieving remarkable performances. However, they often tailor automated solutions on manual fact-checked reports, suffering from limited news coverage and debunking delays. When a piece of news has not yet been fact-checked or debunked, certain amounts of relevant raw reports are usually disseminated on various media outlets, containing the wisdom of crowds to verify the news claim and explain its verdict. In this paper, we propose a novel Coarse-to-fine Cascaded Evidence-Distillation (CofCED) neural network for explainable fake news detection based on such raw reports, alleviating the dependency on fact-checked ones. Specifically, we first utilize a hierarchical encoder for web text representation, and then develop two cascaded selectors to select the most explainable sentences for verdicts on top of the selected top-K reports in a coarse-to-fine manner. Besides, we construct two explainable fake news datasets, which are publicly available. Experimental results demonstrate that our model significantly outperforms state-of-the-art baselines and generates high-quality explanations from diverse evaluation perspectives. ",
    "url": "https://arxiv.org/abs/2209.14642",
    "authors": [
      "Zhiwei Yang",
      "Jing Ma",
      "Hechang Chen",
      "Hongzhan Lin",
      "Ziyang Luo",
      "Yi Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.14649",
    "title": "Factor Graph Fusion of Raw GNSS Sensing with IMU and Lidar for Precise  Robot Localization without a Base Station",
    "abstract": "Accurate localization is a core component of a robot's navigation system. To this end, global navigation satellite systems (GNSS) can provide absolute measurements outdoors and, therefore, eliminate long-term drift. However, fusing GNSS data with other sensor data is not trivial, especially when a robot moves between areas with and without sky view. We propose a robust approach that tightly fuses raw GNSS receiver data with inertial measurements and, optionally, lidar observations for precise and smooth mobile robot localization. A factor graph with two types of GNSS factors is proposed. First, factors based on pseudoranges, which allow for global localization on Earth. Second, factors based on carrier phases, which enable highly accurate relative localization, which is useful when other sensing modalities are challenged. Unlike traditional differential GNSS, this approach does not require a connection to a base station. On a public urban driving dataset, our approach achieves accuracy comparable to a state-of-the-art algorithm that fuses visual inertial odometry with GNSS data -- despite our approach not using the camera, just inertial and GNSS data. We also demonstrate the robustness of our approach using data from a car and a quadruped robot moving in environments with little sky visibility, such as a forest. The accuracy in the global Earth frame is still 1-2 m, while the estimated trajectories are discontinuity-free and smooth. We also show how lidar measurements can be tightly integrated. We believe this is the first system that fuses raw GNSS observations (as opposed to fixes) with lidar. ",
    "url": "https://arxiv.org/abs/2209.14649",
    "authors": [
      "Jonas Beuchert",
      "Marco Camurri",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14667",
    "title": "Domain-aware Self-supervised Pre-training for Label-Efficient Meme  Analysis",
    "abstract": "Existing self-supervised learning strategies are constrained to either a limited set of objectives or generic downstream tasks that predominantly target uni-modal applications. This has isolated progress for imperative multi-modal applications that are diverse in terms of complexity and domain-affinity, such as meme analysis. Here, we introduce two self-supervised pre-training methods, namely Ext-PIE-Net and MM-SimCLR that (i) employ off-the-shelf multi-modal hate-speech data during pre-training and (ii) perform self-supervised learning by incorporating multiple specialized pretext tasks, effectively catering to the required complex multi-modal representation learning for meme analysis. We experiment with different self-supervision strategies, including potential variants that could help learn rich cross-modality representations and evaluate using popular linear probing on the Hateful Memes task. The proposed solutions strongly compete with the fully supervised baseline via label-efficient training while distinctly outperforming them on all three tasks of the Memotion challenge with 0.18%, 23.64%, and 0.93% performance gain, respectively. Further, we demonstrate the generalizability of the proposed solutions by reporting competitive performance on the HarMeme task. Finally, we empirically establish the quality of the learned representations by analyzing task-specific learning, using fewer labeled training samples, and arguing that the complexity of the self-supervision strategy and downstream task at hand are correlated. Our efforts highlight the requirement of better multi-modal self-supervision methods involving specialized pretext tasks for efficient fine-tuning and generalizable performance. ",
    "url": "https://arxiv.org/abs/2209.14667",
    "authors": [
      "Shivam Sharma",
      "Mohd Khizir Siddiqui",
      "Md. Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2209.14670",
    "title": "Towards Equalised Odds as Fairness Metric in Academic Performance  Prediction",
    "abstract": "The literature for fairness-aware machine learning knows a plethora of different fairness notions. It is however wellknown, that it is impossible to satisfy all of them, as certain notions contradict each other. In this paper, we take a closer look at academic performance prediction (APP) systems and try to distil which fairness notions suit this task most. For this, we scan recent literature proposing guidelines as to which fairness notion to use and apply these guidelines onto APP. Our findings suggest equalised odds as most suitable notion for APP, based on APP's WYSIWYG worldview as well as potential long-term improvements for the population. ",
    "url": "https://arxiv.org/abs/2209.14670",
    "authors": [
      "Jannik Dunkelau",
      "Manh Khoi Duong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2209.14673",
    "title": "Chameleon Cache: Approximating Fully Associative Caches with Random  Replacement to Prevent Contention-Based Cache Attacks",
    "abstract": "Randomized, skewed caches (RSCs) such as CEASER-S have recently received much attention to defend against contention-based cache side channels. By randomizing and regularly changing the mapping(s) of addresses to cache sets, these techniques are designed to obfuscate the leakage of memory access patterns. However, new attack techniques, e.g., Prime+Prune+Probe, soon demonstrated the limits of RSCs as they allow attackers to more quickly learn which addresses contend in the cache and use this information to circumvent the randomization. To yet maintain side-channel resilience, RSCs must change the random mapping(s) more frequently with adverse effects on performance and implementation complexity. This work aims to make randomization-based approaches more robust to allow for reduced re-keying rates and presents Chameleon Cache. Chameleon Cache extends RSCs with a victim cache (VC) to decouple contention in the RSC from evictions observed by the user. The VC allows Chameleon Cache to make additional use of the multiple mappings RSCs provide to translate addresses to cache set indices: when a cache line is evicted from the RSC to the VC under one of its mappings, the VC automatically reinserts this evicted line back into the RSC by using a different mapping. As a result, the effects of previous RSC set contention are hidden and Chameleon Cache exhibits side-channel resistance and eviction patterns similar to fully associative caches with random replacement. We show that Chameleon Cache has performance overheads of < 1% and stress that VCs are more generically helpful to increase side-channel resistance and re-keying intervals of randomized caches. ",
    "url": "https://arxiv.org/abs/2209.14673",
    "authors": [
      "Thomas Unterluggauer",
      "Austin Harris",
      "Scott Constable",
      "Fangfei Liu",
      "Carlos Rozas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2209.14684",
    "title": "A canonical correlation-based framework for performance analysis of  radio access networks",
    "abstract": "Data driven optimization and machine learning based performance diagnostics of radio access networks entails significant challenges arising not only from the nature of underlying data sources but also due to complex spatio-temporal relationships and interdependencies between cells due to user mobility and varying traffic patterns. We discuss how to study these configuration and performance management data sets and identify relationships between cells in terms of key performance indicators using multivariate analysis. To this end, we leverage a novel framework based on canonical correlation analysis (CCA), which is a highly effective method for not only dimensionality reduction but also for analyzing relationships across different sets of multivariate data. As a case study, we discuss energy saving use-case based on cell shutdown in commercial cellular networks, where we apply CCA to analyze the impact of capacity cell shutdown on the KPIs of coverage cell in the same sector. Data from LTE Network is used to analyzed example case. We conclude that CCA is a viable approach for identifying key relationships not only between network planning and configuration data, but also dynamic performance data, paving the way for endeavors such as dimensionality reduction, performance analysis, and root cause analysis for performance diagnostics. ",
    "url": "https://arxiv.org/abs/2209.14684",
    "authors": [
      "Furqan Ahmed",
      "Muhammad Zeeshan Asghar",
      "Jyri H\u00e4m\u00e4l\u00e4inen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14699",
    "title": "ARQ-based Average Consensus over Unreliable Directed Network Topologies",
    "abstract": "In this paper, we address the problem of discrete-time average consensus, where agents (nodes) exchange information over unreliable communication links. We enhance the Robustified Ratio Consensus algorithm by embedding the Automatic Repeat ReQuest (ARQ) protocol used for error control of data transmissions, in order to allow the agents to reach asymptotic average consensus even when operating within unreliable directed networks. This strategy, apart from handling time-varying delays induced by retransmissions of erroneous packets (that can be captured by the Robustified Ratio Consensus as well), it is also possible to handle packet drops that occur due to excess of a predefined packet retransmission limit imposed by the ARQ protocol. Invoking the ARQ protocol allows nodes to: (a) exploit the incoming error-free acknowledgement feedback signals to initially acquire or later update their out-degree, (b) know whether a packet has arrived or not, and (c) determine a local upper-bound on the delays which is imposed by the retransmission limit. By augmenting the network's corresponding weighted adjacency matrix, to handle time-varying (yet bounded) delays and possible packet drops, we show that nodes can make use of the proposed algorithm, herein called the ARQ-based Ratio Consensus algorithm, to reach asymptotic average consensus, despite the fact that the communication links are unreliable. To the best of the authors' knowledge, this is the first consensus algorithm that incorporates a communication protocol for error control used in real communication systems with feedback. ",
    "url": "https://arxiv.org/abs/2209.14699",
    "authors": [
      "Evagoras Makridis",
      "Themistoklis Charalambous",
      "Christoforos N. Hadjicostis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.14719",
    "title": "In Search of Projectively Equivariant Neural Networks",
    "abstract": "Equivariance of linear neural network layers is well studied. In this work, we relax the equivariance condition to only be true in a projective sense. In particular, we study the relation of projective and ordinary equivariance and show that for important examples, the problems are in fact equivalent. The rotation group in 3D acts projectively on the projective plane. We experimentally study the practical importance of rotation equivariance when designing networks for filtering 2D-2D correspondences. Fully equivariant models perform poorly, and while a simple addition of invariant features to a strong baseline yields improvements, this seems to not be due to improved equivariance. ",
    "url": "https://arxiv.org/abs/2209.14719",
    "authors": [
      "Georg B\u00f6kman",
      "Axel Flinth",
      "Fredrik Kahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14727",
    "title": "FastPacket: Towards Pre-trained Packets Embedding based on FastText for  next-generation NIDS",
    "abstract": "New Attacks are increasingly used by attackers everyday but many of them are not detected by Intrusion Detection Systems as most IDS ignore raw packet information and only care about some basic statistical information extracted from PCAP files. Using networking programs to extract fixed statistical features from packets is good, but may not enough to detect nowadays challenges. We think that it is time to utilize big data and deep learning for automatic dynamic feature extraction from packets. It is time to get inspired by deep learning pre-trained models in computer vision and natural language processing, so security deep learning solutions will have its pre-trained models on big datasets to be used in future researches. In this paper, we proposed a new approach for embedding packets based on character-level embeddings, inspired by FastText success on text data. We called this approach FastPacket. Results are measured on subsets of CIC-IDS-2017 dataset, but we expect promising results on big data pre-trained models. We suggest building pre-trained FastPacket on MAWI big dataset and make it available to community, similar to FastText. To be able to outperform currently used NIDS, to start a new era of packet-level NIDS that can better detect complex attacks. ",
    "url": "https://arxiv.org/abs/2209.14727",
    "authors": [
      "Khloud Al Jallad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.14733",
    "title": "Hyper-Representations as Generative Models: Sampling Unseen Neural  Network Weights",
    "abstract": "Learning representations of neural network weights given a model zoo is an emerging and challenging area with many potential applications from model inspection, to neural architecture search or knowledge distillation. Recently, an autoencoder trained on a model zoo was able to learn a hyper-representation, which captures intrinsic and extrinsic properties of the models in the zoo. In this work, we extend hyper-representations for generative use to sample new model weights. We propose layer-wise loss normalization which we demonstrate is key to generate high-performing models and several sampling methods based on the topology of hyper-representations. The models generated using our methods are diverse, performant and capable to outperform strong baselines as evaluated on several downstream tasks: initialization, ensemble sampling and transfer learning. Our results indicate the potential of knowledge aggregation from model zoos to new models via hyper-representations thereby paving the avenue for novel research directions. ",
    "url": "https://arxiv.org/abs/2209.14733",
    "authors": [
      "Konstantin Sch\u00fcrholt",
      "Boris Knyazev",
      "Xavier Gir\u00f3-i-Nieto",
      "Damian Borth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14734",
    "title": "DiGress: Discrete Denoising diffusion for graph generation",
    "abstract": "This work introduces DiGress, a discrete denoising diffusion model for generating graphs with categorical node and edge attributes. Our model defines a diffusion process that progressively edits a graph with noise (adding or removing edges, changing the categories), and a graph transformer network that learns to revert this process. With these two ingredients in place, we reduce distribution learning over graphs to a simple sequence of classification tasks. We further improve sample quality by proposing a new Markovian noise model that preserves the marginal distribution of node and edge types during diffusion, and by adding auxiliary graph-theoretic features derived from the noisy graph at each diffusion step. Finally, we propose a guidance procedure for conditioning the generation on graph-level features. Overall, DiGress achieves state-of-the-art performance on both molecular and non-molecular datasets, with up to 3x validity improvement on a dataset of planar graphs. In particular, it is the first model that scales to the large GuacaMol dataset containing 1.3M drug-like molecules without using a molecule-specific representation such as SMILES or fragments. ",
    "url": "https://arxiv.org/abs/2209.14734",
    "authors": [
      "Clement Vignac",
      "Igor Krawczuk",
      "Antoine Siraudin",
      "Bohan Wang",
      "Volkan Cevher",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14764",
    "title": "Model Zoos: A Dataset of Diverse Populations of Neural Network Models",
    "abstract": "In the last years, neural networks (NN) have evolved from laboratory environments to the state-of-the-art for many real-world problems. It was shown that NN models (i.e., their weights and biases) evolve on unique trajectories in weight space during training. Following, a population of such neural network models (referred to as model zoo) would form structures in weight space. We think that the geometry, curvature and smoothness of these structures contain information about the state of training and can reveal latent properties of individual models. With such model zoos, one could investigate novel approaches for (i) model analysis, (ii) discover unknown learning dynamics, (iii) learn rich representations of such populations, or (iv) exploit the model zoos for generative modelling of NN weights and biases. Unfortunately, the lack of standardized model zoos and available benchmarks significantly increases the friction for further research about populations of NNs. With this work, we publish a novel dataset of model zoos containing systematically generated and diverse populations of NN models for further research. In total the proposed model zoo dataset is based on eight image datasets, consists of 27 model zoos trained with varying hyperparameter combinations and includes 50'360 unique NN models as well as their sparsified twins, resulting in over 3'844'360 collected model states. Additionally, to the model zoo data we provide an in-depth analysis of the zoos and provide benchmarks for multiple downstream tasks. The dataset can be found at www.modelzoos.cc. ",
    "url": "https://arxiv.org/abs/2209.14764",
    "authors": [
      "Konstantin Sch\u00fcrholt",
      "Diyar Taskiran",
      "Boris Knyazev",
      "Xavier Gir\u00f3-i-Nieto",
      "Damian Borth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14777",
    "title": "Real-Time Scheduling of Machine Learning Operations on Heterogeneous  Neuromorphic SoC",
    "abstract": "Neuromorphic Systems-on-Chip (NSoCs) are becoming heterogeneous by integrating general-purpose processors (GPPs) and neural processing units (NPUs) on the same SoC. For embedded systems, an NSoC may need to execute user applications built using a variety of machine learning models. We propose a real-time scheduler, called PRISM, which can schedule machine learning models on a heterogeneous NSoC either individually or concurrently to improve their system performance. PRISM consists of the following four key steps. First, it constructs an interprocessor communication (IPC) graph of a machine learning model from a mapping and a self-timed schedule. Second, it creates a transaction order for the communication actors and embeds this order into the IPC graph. Third, it schedules the graph on an NSoC by overlapping communication with the computation. Finally, it uses a Hill Climbing heuristic to explore the design space of mapping operations on GPPs and NPUs to improve the performance. Unlike existing schedulers which use only the NPUs of an NSoC, PRISM improves performance by enabling batch, pipeline, and operation parallelism via exploiting a platform's heterogeneity. For use-cases with concurrent applications, PRISM uses a heuristic resource sharing strategy and a non-preemptive scheduling to reduce the expected wait time before concurrent operations can be scheduled on contending resources. Our extensive evaluations with 20 machine learning workloads show that PRISM significantly improves the performance per watt for both individual applications and use-cases when compared to state-of-the-art schedulers. ",
    "url": "https://arxiv.org/abs/2209.14777",
    "authors": [
      "Anup Das"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2209.14780",
    "title": "Perturbations and Subpopulations for Testing Robustness in Token-Based  Argument Unit Recognition",
    "abstract": "Argument Unit Recognition and Classification aims at identifying argument units from text and classifying them as pro or against. One of the design choices that need to be made when developing systems for this task is what the unit of classification should be: segments of tokens or full sentences. Previous research suggests that fine-tuning language models on the token-level yields more robust results for classifying sentences compared to training on sentences directly. We reproduce the study that originally made this claim and further investigate what exactly token-based systems learned better compared to sentence-based ones. We develop systematic tests for analysing the behavioural differences between the token-based and the sentence-based system. Our results show that token-based models are generally more robust than sentence-based models both on manually perturbed examples and on specific subpopulations of the data. ",
    "url": "https://arxiv.org/abs/2209.14780",
    "authors": [
      "Jonathan Kamp",
      "Lisa Beinborn",
      "Antske Fokkens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.14785",
    "title": "EMF-Aware MU-MIMO Beamforming in RIS-Aided Cellular Networks",
    "abstract": "Reconfigurable Intelligent Surfaces (RISs) are one of the key emerging 6th Generation (6G) technologies that are expected to improve the link budgets between transmitters and receivers by adding artificial propagation paths. In such re-configured propagation environment, Downlink (DL) Multi-User Multi-Input Multi-Output (MU-MIMO) brings capacity improvement to cellular networks. It benefits from the spatial dimension offered by MIMO systems to enable simultaneous transmission of independent data streams to multiple users on the same radio resources by applying appropriate Beamforming (BF) schemes. However, in some cases, serving the same subset of users for a long period of time may cause some undesired regions where the average Electromagnetic Field Exposure (EMFE) exceeds the regulatory limits. To address this challenge, we propose in this paper a novel Electromagnetic Field (EMF) aware MU-MIMO BF scheme that aims to optimize the overall capacity under EMF constraints in RIS-aided cellular networks. ",
    "url": "https://arxiv.org/abs/2209.14785",
    "authors": [
      "Yi Yu",
      "Rita Ibrahim",
      "Dinh-Thuy Phan-Huy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.14804",
    "title": "Minimum Link Fencing",
    "abstract": "We study a variant of the geometric multicut problem, where we are given a set $\\mathcal{P}$ of colored and pairwise interior-disjoint polygons in the plane. The objective is to compute a set of simple closed polygon boundaries (fences) that separate the polygons in such a way that any two polygons that are enclosed by the same fence have the same color, and the total number of links of all fences is minimized. We call this the minimum link fencing (MLF) problem and consider the natural case of bounded minimum link fencing (BMLF), where $\\mathcal{P}$ contains a polygon $Q$ that is unbounded in all directions and can be seen as an outer polygon. We show that BMLF is NP-hard in general and that it is XP-time solvable when each fence contains at most two polygons and the number of segments per fence is the parameter. Finally, we present an $O(n \\log n)$-time algorithm for the case that the convex hull of $\\mathcal{P} \\setminus \\{Q\\}$ does not intersect $Q$. ",
    "url": "https://arxiv.org/abs/2209.14804",
    "authors": [
      "Sujoy Bhore",
      "Fabian Klute",
      "Maarten L\u00f6ffler",
      "Martin N\u00f6llenburg",
      "Soeren Terziadis",
      "Ana\u00efs Villedieu"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2209.14825",
    "title": "Trading off Quality for Efficiency of Community Detection: An Inductive  Method across Graphs",
    "abstract": "Many network applications can be formulated as NP-hard combinatorial optimization problems of community detection (CD). Due to the NP-hardness, to balance the CD quality and efficiency remains a challenge. Most existing CD methods are transductive, which are independently optimized only for the CD on a single graph. Some of these methods use advanced machine learning techniques to obtain high-quality CD results but usually have high complexity. Other approaches use fast heuristic approximation to ensure low runtime but may suffer from quality degradation. In contrast to these transductive methods, we propose an alternative inductive community detection (ICD) method across graphs of a system or scenario to alleviate the NP-hard challenge. ICD first conducts the offline training of an adversarial dual GNN on historical graphs to capture key properties of the system. The trained model is then directly generalized to new unseen graphs for online CD without additional optimization, where a better trade-off between quality and efficiency can be achieved. ICD can also capture the permutation invariant community labels in the offline training and tackle the online CD on new graphs with non-fixed number of nodes and communities. Experiments on a set of benchmarks demonstrate that ICD can achieve a significant trade-off between quality and efficiency over various baselines. ",
    "url": "https://arxiv.org/abs/2209.14825",
    "authors": [
      "Meng Qin",
      "Chaorui Zhang",
      "Bo Bai",
      "Gong Zhang",
      "Dit-Yan Yeung"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14826",
    "title": "Towards Lightweight Black-Box Attacks against Deep Neural Networks",
    "abstract": "Black-box attacks can generate adversarial examples without accessing the parameters of target model, largely exacerbating the threats of deployed deep neural networks (DNNs). However, previous works state that black-box attacks fail to mislead target models when their training data and outputs are inaccessible. In this work, we argue that black-box attacks can pose practical attacks in this extremely restrictive scenario where only several test samples are available. Specifically, we find that attacking the shallow layers of DNNs trained on a few test samples can generate powerful adversarial examples. As only a few samples are required, we refer to these attacks as lightweight black-box attacks. The main challenge to promoting lightweight attacks is to mitigate the adverse impact caused by the approximation error of shallow layers. As it is hard to mitigate the approximation error with few available samples, we propose Error TransFormer (ETF) for lightweight attacks. Namely, ETF transforms the approximation error in the parameter space into a perturbation in the feature space and alleviates the error by disturbing features. In experiments, lightweight black-box attacks with the proposed ETF achieve surprising results. For example, even if only 1 sample per category available, the attack success rate in lightweight black-box attacks is only about 3% lower than that of the black-box attacks with complete training data. ",
    "url": "https://arxiv.org/abs/2209.14826",
    "authors": [
      "Chenghao Sun",
      "Yonggang Zhang",
      "Wan Chaoqun",
      "Qizhou Wang",
      "Ya Li",
      "Tongliang Liu",
      "Bo Han",
      "Xinmei Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.14829",
    "title": "Lightweight Monocular Depth Estimation with an Edge Guided Network",
    "abstract": "Monocular depth estimation is an important task that can be applied to many robotic applications. Existing methods focus on improving depth estimation accuracy via training increasingly deeper and wider networks, however these suffer from large computational complexity. Recent studies found that edge information are important cues for convolutional neural networks (CNNs) to estimate depth. Inspired by the above observations, we present a novel lightweight Edge Guided Depth Estimation Network (EGD-Net) in this study. In particular, we start out with a lightweight encoder-decoder architecture and embed an edge guidance branch which takes as input image gradients and multi-scale feature maps from the backbone to learn the edge attention features. In order to aggregate the context information and edge attention features, we design a transformer-based feature aggregation module (TRFA). TRFA captures the long-range dependencies between the context information and edge attention features through cross-attention mechanism. We perform extensive experiments on the NYU depth v2 dataset. Experimental results show that the proposed method runs about 96 fps on a Nvidia GTX 1080 GPU whilst achieving the state-of-the-art performance in terms of accuracy. ",
    "url": "https://arxiv.org/abs/2209.14829",
    "authors": [
      "Xingshuai Dong",
      "Matthew A. Garratt",
      "Sreenatha G. Anavatti",
      "Hussein A. Abbass",
      "Junyu Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14831",
    "title": "Access Control with Encrypted Feature Maps for Object Detection Models",
    "abstract": "In this paper, we propose an access control method with a secret key for object detection models for the first time so that unauthorized users without a secret key cannot benefit from the performance of trained models. The method enables us not only to provide a high detection performance to authorized users but to also degrade the performance for unauthorized users. The use of transformed images was proposed for the access control of image classification models, but these images cannot be used for object detection models due to performance degradation. Accordingly, in this paper, selected feature maps are encrypted with a secret key for training and testing models, instead of input images. In an experiment, the protected models allowed authorized users to obtain almost the same performance as that of non-protected models but also with robustness against unauthorized access without a key. ",
    "url": "https://arxiv.org/abs/2209.14831",
    "authors": [
      "Teru Nagamori",
      "Hiroki Ito",
      "AprilPyone MaungMaung",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14842",
    "title": "Classification of Vocal Bursts for ACII 2022 A-VB-Type Competition using  Convolutional Network Networks and Deep Acoustic Embeddings",
    "abstract": "This report provides a brief description of our proposed solution for the Vocal Burst Type classification task of the ACII 2022 Affective Vocal Bursts (A-VB) Competition. We experimented with two approaches as part of our solution for the task at hand. The first of which is based on convolutional neural networks trained on Mel Spectrograms, and the second is based on average pooling of deep acoustic embeddings from a pretrained wav2vec2 model. Our best performing model achieves an unweighted average recall (UAR) of 0.5190 for the test partition, compared to the chance-level UAR of 0.1250 and a baseline of 0.4172. Thus, an improvement of around 20% over the challenge baseline. The results reported in this document demonstrate the efficacy of our proposed approaches to solve the AV-B Type Classification task. ",
    "url": "https://arxiv.org/abs/2209.14842",
    "authors": [
      "Muhammad Shehram Shah Syed",
      "Zafi Sherhan Syed",
      "Abbas Syed"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.14855",
    "title": "Continuous PDE Dynamics Forecasting with Implicit Neural Representations",
    "abstract": "Effective data-driven PDE forecasting methods often rely on fixed spatial and / or temporal discretizations. This raises limitations in real-world applications like weather prediction where flexible extrapolation at arbitrary spatiotemporal locations is required. We address this problem by introducing a new data-driven approach, DINo, that models a PDE's flow with continuous-time dynamics of spatially continuous functions. This is achieved by embedding spatial observations independently of their discretization via Implicit Neural Representations in a small latent space temporally driven by a learned ODE. This separate and flexible treatment of time and space makes DINo the first data-driven model to combine the following advantages. It extrapolates at arbitrary spatial and temporal locations; it can learn from sparse irregular grids or manifolds; at test time, it generalizes to new grids or resolutions. DINo outperforms alternative neural PDE forecasters in a variety of challenging generalization scenarios on representative PDE systems. ",
    "url": "https://arxiv.org/abs/2209.14855",
    "authors": [
      "Yuan Yin",
      "Matthieu Kirchmeyer",
      "Jean-Yves Franceschi",
      "Alain Rakotomamonjy",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.14868",
    "title": "ConvRNN-T: Convolutional Augmented Recurrent Neural Network Transducers  for Streaming Speech Recognition",
    "abstract": "The recurrent neural network transducer (RNN-T) is a prominent streaming end-to-end (E2E) ASR technology. In RNN-T, the acoustic encoder commonly consists of stacks of LSTMs. Very recently, as an alternative to LSTM layers, the Conformer architecture was introduced where the encoder of RNN-T is replaced with a modified Transformer encoder composed of convolutional layers at the frontend and between attention layers. In this paper, we introduce a new streaming ASR model, Convolutional Augmented Recurrent Neural Network Transducers (ConvRNN-T) in which we augment the LSTM-based RNN-T with a novel convolutional frontend consisting of local and global context CNN encoders. ConvRNN-T takes advantage of causal 1-D convolutional layers, squeeze-and-excitation, dilation, and residual blocks to provide both global and local audio context representation to LSTM layers. We show ConvRNN-T outperforms RNN-T, Conformer, and ContextNet on Librispeech and in-house data. In addition, ConvRNN-T offers less computational complexity compared to Conformer. ConvRNN-T's superior accuracy along with its low footprint make it a promising candidate for on-device streaming ASR technologies. ",
    "url": "https://arxiv.org/abs/2209.14868",
    "authors": [
      "Martin Radfar",
      "Rohit Barnwal",
      "Rupak Vignesh Swaminathan",
      "Feng-Ju Chang",
      "Grant P. Strimel",
      "Nathan Susanj",
      "Athanasios Mouchtaris"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.14884",
    "title": "Joint Embedding Self-Supervised Learning in the Kernel Regime",
    "abstract": "The fundamental goal of self-supervised learning (SSL) is to produce useful representations of data without access to any labels for classifying the data. Modern methods in SSL, which form representations based on known or constructed relationships between samples, have been particularly effective at this task. Here, we aim to extend this framework to incorporate algorithms based on kernel methods where embeddings are constructed by linear maps acting on the feature space of a kernel. In this kernel regime, we derive methods to find the optimal form of the output representations for contrastive and non-contrastive loss functions. This procedure produces a new representation space with an inner product denoted as the induced kernel which generally correlates points which are related by an augmentation in kernel space and de-correlates points otherwise. We analyze our kernel model on small datasets to identify common features of self-supervised learning algorithms and gain theoretical insights into their performance on downstream tasks. ",
    "url": "https://arxiv.org/abs/2209.14884",
    "authors": [
      "Bobak T. Kiani",
      "Randall Balestriero",
      "Yubei Chen",
      "Seth Lloyd",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.14887",
    "title": "Learning Low-Frequency Motion Control for Robust and Dynamic Robot  Locomotion",
    "abstract": "Robotic locomotion is often approached with the goal of maximizing robustness and reactivity by increasing motion control frequency. We challenge this intuitive notion by demonstrating robust and dynamic locomotion with a learned motion controller executing at as low as 8 Hz on a real ANYmal C quadruped. The robot is able to robustly and repeatably achieve a high heading velocity of 1.5 m/s, traverse uneven terrain, and resist unexpected external perturbations. We further present a comparative analysis of deep reinforcement learning (RL) based motion control policies trained and executed at frequencies ranging from 5 Hz to 200 Hz. We show that low-frequency policies are less sensitive to actuation latencies and variations in system dynamics. This is to the extent that a successful sim-to-real transfer can be performed even without any dynamics randomization or actuation modeling. We support this claim through a set of rigorous empirical evaluations. Moreover, to assist reproducibility, we provide the training and deployment code along with an extended analysis at https://ori-drs.github.io/lfmc/. ",
    "url": "https://arxiv.org/abs/2209.14887",
    "authors": [
      "Siddhant Gangapurwala",
      "Luigi Campanaro",
      "Ioannis Havoutis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14905",
    "title": "Variance Covariance Regularization Enforces Pairwise Independence in  Self-Supervised Representations",
    "abstract": "Self-Supervised Learning (SSL) methods such as VICReg, Barlow Twins or W-MSE avoid collapse of their joint embedding architectures by constraining or regularizing the covariance matrix of their projector's output. This study highlights important properties of such strategy, which we coin Variance-Covariance regularization (VCReg). More precisely, we show that VCReg enforces pairwise independence between the features of the learned representation. This result emerges by bridging VCReg applied on the projector's output to kernel independence criteria applied on the projector's input. This provides the first theoretical motivations and explanations of VCReg. We empirically validate our findings where (i) we observe that SSL methods employing VCReg learn visual representations with greater pairwise independence than other methods, (i) we put in evidence which projector's characteristics favor pairwise independence, and show it to emerge independently from learning the projector, (ii) we use these findings to obtain nontrivial performance gains for VICReg, (iii) we demonstrate that the scope of VCReg goes beyond SSL by using it to solve Independent Component Analysis. We hope that our findings will support the adoption of VCReg in SSL and beyond. ",
    "url": "https://arxiv.org/abs/2209.14905",
    "authors": [
      "Gr\u00e9goire Mialon",
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14910",
    "title": "Graph Modeling in Computer Assisted Automotive Development",
    "abstract": "We consider graph modeling for a knowledge graph for vehicle development, with a focus on crash safety. An organized schema that incorporates information from various structured and unstructured data sources is provided, which includes relevant concepts within the domain. In particular, we propose semantics for crash computer aided engineering (CAE) data, which enables searchability, filtering, recommendation, and prediction for crash CAE data during the development process. This graph modeling considers the CAE data in the context of the R\\&D development process and vehicle safety. Consequently, we connect CAE data to the protocols that are used to assess vehicle safety performances. The R\\&D process includes CAD engineering and safety attributes, with a focus on multidisciplinary problem-solving. We describe previous efforts in graph modeling in comparison to our proposal, discuss its strengths and limitations, and identify areas for future work. ",
    "url": "https://arxiv.org/abs/2209.14910",
    "authors": [
      "Anahita Pakiman",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2209.14914",
    "title": "Quantum invariants for the graph isomorphism problem",
    "abstract": "Graph Isomorphism is such an important problem in computer science, that it has been widely studied over the last decades. It is well known that it belongs to NP class, but is not NP-complete. It is thought to be of comparable difficulty to integer factorisation. The best known proved algorithm to solve this problem in general, was proposed by L\\'aszl\\'o Babai and Eugene Luks in 1983. Recently, there has been some research in the topic by using quantum computing, that also leads the present piece of research. In fact, we present a quantum computing algorithm that defines an invariant over Graph Isomorphism characterisation. This quantum algorithm is able to distinguish more non-isomorphic graphs than most of the known invariants so far. The proof of correctness and some hints illustrating the extent and reason of the improvement are also included in this paper. ",
    "url": "https://arxiv.org/abs/2209.14914",
    "authors": [
      "Hern\u00e1n I. de la Cruz",
      "Fernando L. Pelayo",
      "Vicente Pascual",
      "Jose J. Paulet",
      "Fernando Cuartero",
      "Luis Llana",
      "Mauro Mezzini"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2209.14915",
    "title": "Evaluating the temporal understanding of neural networks on event-based  action recognition with DVS-Gesture-Chain",
    "abstract": "Enabling artificial neural networks (ANNs) to have temporal understanding in visual tasks is an essential requirement in order to achieve complete perception of video sequences. A wide range of benchmark datasets is available to allow for the evaluation of such capabilities when using conventional frame-based video sequences. In contrast, evaluating them for systems targeting neuromorphic data is still a challenge due to the lack of appropriate datasets. In this work we define a new benchmark task for action recognition in event-based video sequences, DVS-Gesture-Chain (DVS-GC), which is based on the temporal combination of multiple gestures from the widely used DVS-Gesture dataset. This methodology allows to create datasets that are arbitrarily complex in the temporal dimension. Using our newly defined task, we evaluate the spatio-temporal understanding of different feed-forward convolutional ANNs and convolutional Spiking Neural Networks (SNNs). Our study proves how the original DVS Gesture benchmark could be solved by networks without temporal understanding, unlike the new DVS-GC which demands an understanding of the ordering of events. From there, we provide a study showing how certain elements such as spiking neurons or time-dependent weights allow for temporal understanding in feed-forward networks without the need for recurrent connections. Code available at: https://github.com/VicenteAlex/DVS-Gesture-Chain ",
    "url": "https://arxiv.org/abs/2209.14915",
    "authors": [
      "Alex Vicente-Sola",
      "Davide L. Manna",
      "Paul Kirkland",
      "Gaetano Di Caterina",
      "Trevor Bihl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14921",
    "title": "IvySyn: Automated Vulnerability Discovery for Deep Learning Frameworks",
    "abstract": "We present IvySyn: the first fully-automated framework for vulnerability discovery in Deep Learning (DL) frameworks. IvySyn leverages the statically-typed nature of native APIs in order to automatically perform type-aware mutation-based fuzzing on low-level kernel APIs. Given a set of offending inputs that trigger memory safety and fatal runtime errors in low-level, native DL (C/C++) code, IvySyn automatically synthesizes code snippets in high-level languages (e.g., in Python), which propagate offending inputs via high(er)-level APIs. Such code snippets essentially act as Proof of Vulnerability, as they demonstrate the existence of bugs in native code that attackers can target through various high-level APIs. Our experimental evaluation shows that IvySyn significantly outperforms past approaches, both in terms of efficiency and effectiveness, in finding real vulnerabilities in popular DL frameworks. Specifically, we used IvySyn to test TensorFlow and PyTorch: although still an early research prototype, IvySyn has already helped the corresponding TensorFlow and PyTorch framework developers to identify and fix 58 previously-unknown security vulnerabilities, and assign 36 unique CVEs. ",
    "url": "https://arxiv.org/abs/2209.14921",
    "authors": [
      "Neophytos Christou",
      "Di Jin",
      "Vaggelis Atlidakis",
      "Baishakhi Ray",
      "Vasileios P. Kemerlis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.14930",
    "title": "Graph Anomaly Detection with Graph Neural Networks: Current Status and  Challenges",
    "abstract": "Graphs are used widely to model complex systems, and detecting anomalies in a graph is an important task in the analysis of complex systems. Graph anomalies are patterns in a graph that do not conform to normal patterns expected of the attributes and/or structures of the graph. In recent years, graph neural networks (GNNs) have been studied extensively and have successfully performed difficult machine learning tasks in node classification, link prediction, and graph classification thanks to the highly expressive capability via message passing in effectively learning graph representations. To solve the graph anomaly detection problem, GNN-based methods leverage information about the graph attributes (or features) and/or structures to learn to score anomalies appropriately. In this survey, we review the recent advances made in detecting graph anomalies using GNN models. Specifically, we summarize GNN-based methods according to the graph type (i.e., static and dynamic), the anomaly type (i.e., node, edge, subgraph, and whole graph), and the network architecture (e.g., graph autoencoder, graph convolutional network). To the best of our knowledge, this survey is the first comprehensive review of graph anomaly detection methods based on GNNs. ",
    "url": "https://arxiv.org/abs/2209.14930",
    "authors": [
      "Hwan Kim",
      "Byung Suk Lee",
      "Won-Yong Shin",
      "Sungsu Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.14932",
    "title": "Contrastive Unsupervised Learning of World Model with Invariant Causal  Features",
    "abstract": "In this paper we present a world model, which learns causal features using the invariance principle. In particular, we use contrastive unsupervised learning to learn the invariant causal features, which enforces invariance across augmentations of irrelevant parts or styles of the observation. The world-model-based reinforcement learning methods independently optimize representation learning and the policy. Thus naive contrastive loss implementation collapses due to a lack of supervisory signals to the representation learning module. We propose an intervention invariant auxiliary task to mitigate this issue. Specifically, we utilize depth prediction to explicitly enforce the invariance and use data augmentation as style intervention on the RGB observation space. Our design leverages unsupervised representation learning to learn the world model with invariant causal features. Our proposed method significantly outperforms current state-of-the-art model-based and model-free reinforcement learning methods on out-of-distribution point navigation tasks on the iGibson dataset. Moreover, our proposed model excels at the sim-to-real transfer of our perception learning module. Finally, we evaluate our approach on the DeepMind control suite and enforce invariance only implicitly since depth is not available. Nevertheless, our proposed model performs on par with the state-of-the-art counterpart. ",
    "url": "https://arxiv.org/abs/2209.14932",
    "authors": [
      "Rudra P.K. Poudel",
      "Harit Pandya",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.14951",
    "title": "Distributed decentralized receding horizon control for very large-scale  networks with application to LEO satellite mega-constellations",
    "abstract": "The implementation feasibility of decentralized control algorithms over very large-scale networks ushers in limiting constraints regarding communication, computational, and memory requirements. Thus, befitting control solutions must be implemented distributively over the network of systems. In this paper, the decentralized receding horizon control problem for very large-scale networks of dynamically decoupled systems with a common, possibly time-varying, control objective is addressed. Each system is assumed to be modeled by linear time-varying dynamics, which can be leveraged to approximate nonlinear systems about successive points of operation. A distributed and decentralized receding horizon control solution is put forward, which: i) takes communication delays into account; ii) allows local communication exclusively; and iii) whose computational and memory requirements in each computational unit do not scale with the dimension of the network. The scalability of the proposed solution enables emerging very large-scale applications of swarm robotics and networked control. It is applied herein to the orbit control problem of LEO mega-constellations featuring high-fidelity numerical simulations for the Starlink constellation. ",
    "url": "https://arxiv.org/abs/2209.14951",
    "authors": [
      "Leonardo Pedroso",
      "Pedro Batista"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.14970",
    "title": "3D Rendering Framework for Data Augmentation in Optical Character  Recognition",
    "abstract": "In this paper, we propose a data augmentation framework for Optical Character Recognition (OCR). The proposed framework is able to synthesize new viewing angles and illumination scenarios, effectively enriching any available OCR dataset. Its modular structure allows to be modified to match individual user requirements. The framework enables to comfortably scale the enlargement factor of the available dataset. Furthermore, the proposed method is not restricted to single frame OCR but can also be applied to video OCR. We demonstrate the performance of our framework by augmenting a 15% subset of the common Brno Mobile OCR dataset. Our proposed framework is capable of leveraging the performance of OCR applications especially for small datasets. Applying the proposed method, improvements of up to 2.79 percentage points in terms of Character Error Rate (CER), and up to 7.88 percentage points in terms of Word Error Rate (WER) are achieved on the subset. Especially the recognition of challenging text lines can be improved. The CER may be decreased by up to 14.92 percentage points and the WER by up to 18.19 percentage points for this class. Moreover, we are able to achieve smaller error rates when training on the 15% subset augmented with the proposed method than on the original non-augmented full dataset. ",
    "url": "https://arxiv.org/abs/2209.14970",
    "authors": [
      "Andreas Spruck",
      "Maximiliane Hawesch",
      "Anatol Maier",
      "Christian Riess",
      "J\u00fcrgen Seiler",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.14971",
    "title": "Hyperspectral Remote Sensing Benchmark Database for Oil Spill Detection  with an Isolation Forest-Guided Unsupervised Detector",
    "abstract": "Oil spill detection has attracted increasing attention in recent years since marine oil spill accidents severely affect environments, natural resources, and the lives of coastal inhabitants. Hyperspectral remote sensing images provide rich spectral information which is beneficial for the monitoring of oil spills in complex ocean scenarios. However, most of the existing approaches are based on supervised and semi-supervised frameworks to detect oil spills from hyperspectral images (HSIs), which require a huge amount of effort to annotate a certain number of high-quality training sets. In this study, we make the first attempt to develop an unsupervised oil spill detection method based on isolation forest for HSIs. First, considering that the noise level varies among different bands, a noise variance estimation method is exploited to evaluate the noise level of different bands, and the bands corrupted by severe noise are removed. Second, kernel principal component analysis (KPCA) is employed to reduce the high dimensionality of the HSIs. Then, the probability of each pixel belonging to one of the classes of seawater and oil spills is estimated with the isolation forest, and a set of pseudo-labeled training samples is automatically produced using the clustering algorithm on the detected probability. Finally, an initial detection map can be obtained by performing the support vector machine (SVM) on the dimension-reduced data, and then, the initial detection result is further optimized with the extended random walker (ERW) model so as to improve the detection accuracy of oil spills. Experiments on airborne hyperspectral oil spill data (HOSD) created by ourselves demonstrate that the proposed method obtains superior detection performance with respect to other state-of-the-art detection approaches. ",
    "url": "https://arxiv.org/abs/2209.14971",
    "authors": [
      "Puhong Duan",
      "Xudong Kang",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14975",
    "title": "Causal Inference via Nonlinear Variable Decorrelation for Healthcare  Applications",
    "abstract": "Causal inference and model interpretability research are gaining increasing attention, especially in the domains of healthcare and bioinformatics. Despite recent successes in this field, decorrelating features under nonlinear environments with human interpretable representations has not been adequately investigated. To address this issue, we introduce a novel method with a variable decorrelation regularizer to handle both linear and nonlinear confounding. Moreover, we employ association rules as new representations using association rule mining based on the original features to further proximate human decision patterns to increase model interpretability. Extensive experiments are conducted on four healthcare datasets (one synthetically generated and three real-world collections on different diseases). Quantitative results in comparison to baseline approaches on parameter estimation and causality computation indicate the model's superior performance. Furthermore, expert evaluation given by healthcare professionals validates the effectiveness and interpretability of the proposed model. ",
    "url": "https://arxiv.org/abs/2209.14975",
    "authors": [
      "Junda Wang",
      "Weijian Li",
      "Han Wang",
      "Hanjia Lyu",
      "Caroline Thirukumaran",
      "Addisu Mesfin",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14297",
    "title": "Using Multivariate Linear Regression for Biochemical Oxygen Demand  Prediction in Waste Water",
    "abstract": "There exist opportunities for Multivariate Linear Regression (MLR) in the prediction of Biochemical Oxygen Demand (BOD) in waste water, using the diverse water quality parameters as the input variables. The goal of this work is to examine the capability of MLR in prediction of BOD in waste water through four input variables: Dissolved Oxygen (DO), Nitrogen, Fecal Coliform and Total Coliform. The four input variables have higher correlation strength to BOD out of the seven parameters examined for the strength of correlation. Machine Learning (ML) was done with both 80% and 90% of the data as the training set and 20% and 10% as the test set respectively. MLR performance was evaluated through the coefficient of correlation (r), Root Mean Square Error (RMSE) and the percentage accuracy in prediction of BOD. The performance indices for the input variables of Dissolved Oxygen, Nitrogen, Fecal Coliform and Total Coliform in prediction of BOD are: RMSE=6.77mg/L, r=0.60 and accuracy 70.3% for training dataset of 80% and RMSE=6.74mg/L, r=0.60 and accuracy of 87.5% for training set of 90% of the dataset. It was found that increasing the percentage of the training set above 80% of the dataset improved the accuracy of the model only but did not have a significant impact on the prediction capacity of the model. The results showed that MLR model could be successfully employed in the estimation of BOD in waste water using appropriately selected input parameters. ",
    "url": "https://arxiv.org/abs/2209.14297",
    "authors": [
      "Isaiah K. Mutai",
      "Kristof Van Laerhoven",
      "Nancy W. Karuri",
      "Robert K. Tewo"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2209.14358",
    "title": "The minimal canonical form of a tensor network",
    "abstract": "Tensor networks have a gauge degree of freedom on the virtual degrees of freedom that are contracted. A canonical form is a choice of fixing this degree of freedom. For matrix product states, choosing a canonical form is a powerful tool, both for theoretical and numerical purposes. On the other hand, for tensor networks in dimension two or greater there is only limited understanding of the gauge symmetry. Here we introduce a new canonical form, the minimal canonical form, which applies to projected entangled pair states (PEPS) in any dimension, and prove a corresponding fundamental theorem. Already for matrix product states this gives a new canonical form, while in higher dimensions it is the first rigorous definition of a canonical form valid for any choice of tensor. We show that two tensors have the same minimal canonical forms if and only if they are gauge equivalent up to taking limits; moreover, this is the case if and only if they give the same quantum state for any geometry. In particular, this implies that the latter problem is decidable - in contrast to the well-known undecidability for PEPS on grids. We also provide rigorous algorithms for computing minimal canonical forms. To achieve this we draw on geometric invariant theory and recent progress in theoretical computer science in non-commutative group optimization. ",
    "url": "https://arxiv.org/abs/2209.14358",
    "authors": [
      "Arturo Acuaviva",
      "Visu Makam",
      "Harold Nieuwboer",
      "David P\u00e9rez-Garc\u00eda",
      "Friedrich Sittner",
      "Michael Walter",
      "Freek Witteveen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Rings and Algebras (math.RA)"
    ]
  },
  {
    "id": "arXiv:2209.14397",
    "title": "Variational Bayes for robust radar single object tracking",
    "abstract": "We address object tracking by radar and the robustness of the current state-of-the-art methods to process outliers. The standard tracking algorithms extract detections from radar image space to use it in the filtering stage. Filtering is performed by a Kalman filter, which assumes Gaussian distributed noise. However, this assumption does not account for large modeling errors and results in poor tracking performance during abrupt motions. We take the Gaussian Sum Filter (single-object variant of the Multi Hypothesis Tracker) as our baseline and propose a modification by modelling process noise with a distribution that has heavier tails than a Gaussian. Variational Bayes provides a fast, computationally cheap inference algorithm. Our simulations show that - in the presence of process outliers - the robust tracker outperforms the Gaussian Sum filter when tracking single objects. ",
    "url": "https://arxiv.org/abs/2209.14397",
    "authors": [
      "Alp Sar\u0131",
      "Tak Kaneko",
      "Lense H.M. Swaenen",
      "Wouter M. Kouw"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14540",
    "title": "NAF: Neural Attenuation Fields for Sparse-View CBCT Reconstruction",
    "abstract": "This paper proposes a novel and fast self-supervised solution for sparse-view CBCT reconstruction (Cone Beam Computed Tomography) that requires no external training data. Specifically, the desired attenuation coefficients are represented as a continuous function of 3D spatial coordinates, parameterized by a fully-connected deep neural network. We synthesize projections discretely and train the network by minimizing the error between real and synthesized projections. A learning-based encoder entailing hash coding is adopted to help the network capture high-frequency details. This encoder outperforms the commonly used frequency-domain encoder in terms of having higher performance and efficiency, because it exploits the smoothness and sparsity of human organs. Experiments have been conducted on both human organ and phantom datasets. The proposed method achieves state-of-the-art accuracy and spends reasonably short computation time. ",
    "url": "https://arxiv.org/abs/2209.14540",
    "authors": [
      "Ruyi Zha",
      "Yanhao Zhang",
      "Hongdong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14566",
    "title": "Diffusion Adversarial Representation Learning for Self-supervised Vessel  Segmentation",
    "abstract": "Vessel segmentation in medical images is one of the important tasks in the diagnosis of vascular diseases and therapy planning. Although learning-based segmentation approaches have been extensively studied, a large amount of ground-truth labels are required in supervised methods and confusing background structures make neural networks hard to segment vessels in an unsupervised manner. To address this, here we introduce a novel diffusion adversarial representation learning (DARL) model that leverages a denoising diffusion probabilistic model with adversarial learning, and apply it for vessel segmentation. In particular, for self-supervised vessel segmentation, DARL learns background image distribution using a diffusion module, which lets a generation module effectively provide vessel representations. Also, by adversarial learning based on the proposed switchable spatially-adaptive denormalization, our model estimates synthetic fake vessel images as well as vessel segmentation masks, which further makes the model capture vessel-relevant semantic information. Once the proposed model is trained, the model generates segmentation masks by one step and can be applied to general vascular structure segmentation of coronary angiography and retinal images. Experimental results on various datasets show that our method significantly outperforms existing unsupervised and self-supervised methods in vessel segmentation. ",
    "url": "https://arxiv.org/abs/2209.14566",
    "authors": [
      "Boah Kim",
      "Yujin Oh",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14604",
    "title": "Spherical Image Inpainting with Frame Transformation and Data-driven  Prior Deep Networks",
    "abstract": "Spherical image processing has been widely applied in many important fields, such as omnidirectional vision for autonomous cars, global climate modelling, and medical imaging. It is non-trivial to extend an algorithm developed for flat images to the spherical ones. In this work, we focus on the challenging task of spherical image inpainting with deep learning-based regularizer. Instead of a naive application of existing models for planar images, we employ a fast directional spherical Haar framelet transform and develop a novel optimization framework based on a sparsity assumption of the framelet transform. Furthermore, by employing progressive encoder-decoder architecture, a new and better-performed deep CNN denoiser is carefully designed and works as an implicit regularizer. Finally, we use a plug-and-play method to handle the proposed optimization model, which can be implemented efficiently by training the CNN denoiser prior. Numerical experiments are conducted and show that the proposed algorithms can greatly recover damaged spherical images and achieve the best performance over purely using deep learning denoiser and plug-and-play model. ",
    "url": "https://arxiv.org/abs/2209.14604",
    "authors": [
      "Jianfei Li",
      "Chaoyan Huang",
      "Raymond Chan",
      "Han Feng",
      "Micheal Ng",
      "Tieyong Zeng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14664",
    "title": "Causal inference in drug discovery and development",
    "abstract": "To discover new drugs is to seek and to prove causality. As an emerging approach leveraging human knowledge and creativity, data, and machine intelligence, causal inference holds the promise of reducing cognitive bias and improving decision making in drug discovery. While it has been applied across the value chain, the concepts and practice of causal inference remain obscure to many practitioners. This article offers a non-technical introduction to causal inference, reviews its recent applications, and discusses opportunities and challenges of adopting the causal language in drug discovery and development. ",
    "url": "https://arxiv.org/abs/2209.14664",
    "authors": [
      "Tom Michoel",
      "Jitao David Zhang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2209.14754",
    "title": "On the Physics-Informed Neural Networks for Quantum Computers",
    "abstract": "Physics-Informed Neural Networks (PINN) emerged as a powerful tool for solving scientific computing problems, ranging from the solution of Partial Differential Equations to data assimilation tasks. One of the advantages of using PINN is to leverage the usage of Machine Learning computational frameworks relying on the combined usage of CPUs and co-processors, such as accelerators, to achieve maximum performance. This work investigates the feasibility and potential of using the Quantum Processing Unit (QPU) co-processor in PINNs. We design a simple Quantum PINN to solve the one-dimensional Poisson problem using a Continuous Variable quantum computing framework. We discuss the impact of different optimizers, PINN residual formulation, and quantum neural network depth on the quantum PINN accuracy. We show that the optimizer exploration of the training landscape in the case of quantum PINN is not as effective as in classical PINN, and basic SGD optimizers outperform adaptive and high-order optimizers. Finally, we highlight the difference in methods and algorithms between quantum and classical PINNs and outline future research challenges for quantum PINN development. ",
    "url": "https://arxiv.org/abs/2209.14754",
    "authors": [
      "Stefano Markidis"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2209.14863",
    "title": "Neural Networks Efficiently Learn Low-Dimensional Representations with  SGD",
    "abstract": "We study the problem of training a two-layer neural network (NN) of arbitrary width using stochastic gradient descent (SGD) where the input $\\boldsymbol{x}\\in \\mathbb{R}^d$ is Gaussian and the target $y \\in \\mathbb{R}$ follows a multiple-index model, i.e., $y=g(\\langle\\boldsymbol{u_1},\\boldsymbol{x}\\rangle,...,\\langle\\boldsymbol{u_k},\\boldsymbol{x}\\rangle)$ with a noisy link function $g$. We prove that the first-layer weights of the NN converge to the $k$-dimensional principal subspace spanned by the vectors $\\boldsymbol{u_1},...,\\boldsymbol{u_k}$ of the true model, when online SGD with weight decay is used for training. This phenomenon has several important consequences when $k \\ll d$. First, by employing uniform convergence on this smaller subspace, we establish a generalization error bound of $\\mathcal{O}(\\sqrt{{kd}/{T}})$ after $T$ iterations of SGD, which is independent of the width of the NN. We further demonstrate that, SGD-trained ReLU NNs can learn a single-index target of the form $y=f(\\langle\\boldsymbol{u},\\boldsymbol{x}\\rangle) + \\epsilon$ by recovering the principal direction, with a sample complexity linear in $d$ (up to log factors), where $f$ is a monotonic function with at most polynomial growth, and $\\epsilon$ is the noise. This is in contrast to the known $d^{\\Omega(p)}$ sample requirement to learn any degree $p$ polynomial in the kernel regime, and it shows that NNs trained with SGD can outperform the neural tangent kernel at initialization. Finally, we also provide compressibility guarantees for NNs using the approximate low-rank structure produced by SGD. ",
    "url": "https://arxiv.org/abs/2209.14863",
    "authors": [
      "Alireza Mousavi-Hosseini",
      "Sejun Park",
      "Manuela Girotti",
      "Ioannis Mitliagkas",
      "Murat A. Erdogdu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14937",
    "title": "NAG-GS: Semi-Implicit, Accelerated and Robust Stochastic Optimizers",
    "abstract": "Classical machine learning models such as deep neural networks are usually trained by using Stochastic Gradient Descent-based (SGD) algorithms. The classical SGD can be interpreted as a discretization of the stochastic gradient flow. In this paper we propose a novel, robust and accelerated stochastic optimizer that relies on two key elements: (1) an accelerated Nesterov-like Stochastic Differential Equation (SDE) and (2) its semi-implicit Gauss-Seidel type discretization. The convergence and stability of the obtained method, referred to as NAG-GS, are first studied extensively in the case of the minimization of a quadratic function. This analysis allows us to come up with an optimal step size (or learning rate) in terms of rate of convergence while ensuring the stability of NAG-GS. This is achieved by the careful analysis of the spectral radius of the iteration matrix and the covariance matrix at stationarity with respect to all hyperparameters of our method. We show that NAG-GS is competitive with state-of-the-art methods such as momentum SGD with weight decay and AdamW for the training of machine learning models such as the logistic regression model, the residual networks models on standard computer vision datasets, and Transformers in the frame of the GLUE benchmark. ",
    "url": "https://arxiv.org/abs/2209.14937",
    "authors": [
      "Valentin Leplat",
      "Daniil Merkulov",
      "Aleksandr Katrutsa",
      "Daniel Bershatsky",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:1908.01981",
    "title": "Monotonic Representations of Outerplanar Graphs as Edge Intersection  Graphs of Paths on a Grid",
    "abstract": " Title: Monotonic Representations of Outerplanar Graphs as Edge Intersection  Graphs of Paths on a Grid ",
    "url": "https://arxiv.org/abs/1908.01981",
    "authors": [
      "Eranda Cela",
      "Elisabeth Gaar"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2004.03107",
    "title": "The Economics of Social Data",
    "abstract": " Title: The Economics of Social Data ",
    "url": "https://arxiv.org/abs/2004.03107",
    "authors": [
      "Dirk Bergemann",
      "Alessandro Bonatti",
      "Tan Gan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2009.07916",
    "title": "Causal Bandits without prior knowledge using separating sets",
    "abstract": " Title: Causal Bandits without prior knowledge using separating sets ",
    "url": "https://arxiv.org/abs/2009.07916",
    "authors": [
      "Arnoud A.W.M. de Kroon",
      "Danielle Belgrave",
      "Joris M. Mooij"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2009.14233",
    "title": "Lip-reading with Densely Connected Temporal Convolutional Networks",
    "abstract": " Comments: WACV 2021. An improved code implementation is available at: this https URL ",
    "url": "https://arxiv.org/abs/2009.14233",
    "authors": [
      "Pingchuan Ma",
      "Yujiang Wang",
      "Jie Shen",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2011.03574",
    "title": "Single-Node Attacks for Fooling Graph Neural Networks",
    "abstract": " Comments: Appeared in Neurocomputing ",
    "url": "https://arxiv.org/abs/2011.03574",
    "authors": [
      "Ben Finkelshtein",
      "Chaim Baskin",
      "Evgenii Zheltonozhskii",
      "Uri Alon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2103.12541",
    "title": "A Survey on Multimodal Disinformation Detection",
    "abstract": " Comments: Accepted at COLING-2022, disinformation, misinformation, factuality, harmfulness, fake news, propaganda, multimodality, text, images, videos, network structure, temporality ",
    "url": "https://arxiv.org/abs/2103.12541",
    "authors": [
      "Firoj Alam",
      "Stefano Cresci",
      "Tanmoy Chakraborty",
      "Fabrizio Silvestri",
      "Dimiter Dimitrov",
      "Giovanni Da San Martino",
      "Shaden Shaar",
      "Hamed Firooz",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2104.02864",
    "title": "Self-Supervised Learning for Gastritis Detection with Gastric X-ray  Images",
    "abstract": " Title: Self-Supervised Learning for Gastritis Detection with Gastric X-ray  Images ",
    "url": "https://arxiv.org/abs/2104.02864",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.14559",
    "title": "Active Learning in Bayesian Neural Networks with Balanced Entropy  Learning Principle",
    "abstract": " Title: Active Learning in Bayesian Neural Networks with Balanced Entropy  Learning Principle ",
    "url": "https://arxiv.org/abs/2105.14559",
    "authors": [
      "Jae Oh Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.03535",
    "title": "Graph Neural Networks in Network Neuroscience",
    "abstract": " Title: Graph Neural Networks in Network Neuroscience ",
    "url": "https://arxiv.org/abs/2106.03535",
    "authors": [
      "Alaa Bessadok",
      "Mohamed Ali Mahjoub",
      "Islem Rekik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2106.04527",
    "title": "LaplaceNet: A Hybrid Graph-Energy Neural Network for Deep  Semi-Supervised Classification",
    "abstract": " Comments: this https URL ",
    "url": "https://arxiv.org/abs/2106.04527",
    "authors": [
      "Philip Sellars",
      "Angelica I. Aviles-Rivero",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.01312",
    "title": "Learning Causal Models from Conditional Moment Restrictions by  Importance Weighting",
    "abstract": " Title: Learning Causal Models from Conditional Moment Restrictions by  Importance Weighting ",
    "url": "https://arxiv.org/abs/2108.01312",
    "authors": [
      "Masahiro Kato",
      "Masaaki Imaizumi",
      "Kenichiro McAlinn",
      "Haruo Kakehi",
      "Shota Yasui"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.08465",
    "title": "Heterogeneous Graph-Based Multimodal Brain Network Learning",
    "abstract": " Title: Heterogeneous Graph-Based Multimodal Brain Network Learning ",
    "url": "https://arxiv.org/abs/2110.08465",
    "authors": [
      "Gen Shi",
      "Yifan Zhu",
      "Wenjin Liu",
      "Quanming Yao",
      "Xuesong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2111.08851",
    "title": "Deep Neural Networks for Rank-Consistent Ordinal Regression Based On  Conditional Probabilities",
    "abstract": " Title: Deep Neural Networks for Rank-Consistent Ordinal Regression Based On  Conditional Probabilities ",
    "url": "https://arxiv.org/abs/2111.08851",
    "authors": [
      "Xintong Shi",
      "Wenzhi Cao",
      "Sebastian Raschka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.14585",
    "title": "Similarity Contrastive Estimation for Self-Supervised Soft Contrastive  Learning",
    "abstract": " Comments: Accepted to IEEE Winter Conference on Applications of Computer Vision (WACV) 2023 ",
    "url": "https://arxiv.org/abs/2111.14585",
    "authors": [
      "Julien Denize",
      "Jaonary Rabarisoa",
      "Astrid Orcesi",
      "Romain H\u00e9rault",
      "St\u00e9phane Canu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.03237",
    "title": "From Coarse to Fine-grained Concept based Discrimination for Phrase  Detection",
    "abstract": " Title: From Coarse to Fine-grained Concept based Discrimination for Phrase  Detection ",
    "url": "https://arxiv.org/abs/2112.03237",
    "authors": [
      "Maan Qraitem",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11734",
    "title": "D-HYPR: Harnessing Neighborhood Modeling and Asymmetry Preservation for  Digraph Representation Learning",
    "abstract": " Comments: CIKM 2022 ",
    "url": "https://arxiv.org/abs/2112.11734",
    "authors": [
      "Honglu Zhou",
      "Advith Chegu",
      "Samuel S. Sohn",
      "Zuohui Fu",
      "Gerard de Melo",
      "Mubbasir Kapadia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03008",
    "title": "Algorithms that get old : the case of generative deep neural networks",
    "abstract": " Title: Algorithms that get old : the case of generative deep neural networks ",
    "url": "https://arxiv.org/abs/2202.03008",
    "authors": [
      "Gabriel Turinici"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04041",
    "title": "Physics-informed neural networks for solving parametric magnetostatic  problems",
    "abstract": " Comments: 12 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2202.04041",
    "authors": [
      "Andr\u00e9s Beltr\u00e1n-Pulido",
      "Ilias Bilionis",
      "Dionysios Aliprantis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2203.10749",
    "title": "STCGAT: A Spatio-temporal Causal Graph Attention Network for traffic  flow prediction in Intelligent Transportation Systems",
    "abstract": " Title: STCGAT: A Spatio-temporal Causal Graph Attention Network for traffic  flow prediction in Intelligent Transportation Systems ",
    "url": "https://arxiv.org/abs/2203.10749",
    "authors": [
      "Wei Zhao",
      "Shiqi Zhang",
      "Bing Zhou",
      "Bei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15021",
    "title": "Few-Shot Object Detection with Fully Cross-Transformer",
    "abstract": " Comments: CVPR 2022 (Oral). Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2203.15021",
    "authors": [
      "Guangxing Han",
      "Jiawei Ma",
      "Shiyuan Huang",
      "Long Chen",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2204.02782",
    "title": "GemNet-OC: Developing Graph Neural Networks for Large and Diverse  Molecular Simulation Datasets",
    "abstract": " Title: GemNet-OC: Developing Graph Neural Networks for Large and Diverse  Molecular Simulation Datasets ",
    "url": "https://arxiv.org/abs/2204.02782",
    "authors": [
      "Johannes Gasteiger",
      "Muhammed Shuaibi",
      "Anuroop Sriram",
      "Stephan G\u00fcnnemann",
      "Zachary Ulissi",
      "C. Lawrence Zitnick",
      "Abhishek Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2204.11641",
    "title": "Cryptography Is Not Enough: Relay Attacks on Authenticated GNSS Signals",
    "abstract": " Title: Cryptography Is Not Enough: Relay Attacks on Authenticated GNSS Signals ",
    "url": "https://arxiv.org/abs/2204.11641",
    "authors": [
      "Maryam Motallebighomi",
      "Harshad Sathaye",
      "Mridula Singh",
      "Aanjhan Ranganathan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.02885",
    "title": "Adversarial confound regression and uncertainty measurements to classify  heterogeneous clinical MRI in Mass General Brigham",
    "abstract": " Title: Adversarial confound regression and uncertainty measurements to classify  heterogeneous clinical MRI in Mass General Brigham ",
    "url": "https://arxiv.org/abs/2205.02885",
    "authors": [
      "Matthew Leming",
      "Sudeshna Das",
      "Hyungsoon Im"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2205.07848",
    "title": "Power and limitations of single-qubit native quantum neural networks",
    "abstract": " Comments: 22 pages including appendix. To appear at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.07848",
    "authors": [
      "Zhan Yu",
      "Hongshun Yao",
      "Mujin Li",
      "Xin Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2205.15638",
    "title": "Differentiable Invariant Causal Discovery",
    "abstract": " Comments: 22 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2205.15638",
    "authors": [
      "Yu Wang",
      "An Zhang",
      "Xiang Wang",
      "Yancheng Yuan",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2206.04951",
    "title": "Evolutionary Echo State Network: evolving reservoirs in the Fourier  space",
    "abstract": " Comments: This manuscript was accepted at the 2022 International Joint Conference on Neural Networks (IJCNN 2022) ",
    "url": "https://arxiv.org/abs/2206.04951",
    "authors": [
      "Sebastian Basterrech",
      "Gerardo Rubino"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.06602",
    "title": "Deep Isolation Forest for Anomaly Detection",
    "abstract": " Comments: 14 pages, 7 figures; the source code is available at this https URL ",
    "url": "https://arxiv.org/abs/2206.06602",
    "authors": [
      "Hongzuo Xu",
      "Guansong Pang",
      "Yijie Wang",
      "Yongjun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08515",
    "title": "ComENet: Towards Complete and Efficient Message Passing for 3D Molecular  Graphs",
    "abstract": " Comments: The paper has been accepted by NeurIPS 2022. You can also cite the conference version ",
    "url": "https://arxiv.org/abs/2206.08515",
    "authors": [
      "Limei Wang",
      "Yi Liu",
      "Yuchao Lin",
      "Haoran Liu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.12361",
    "title": "Robustness to corruption in pre-trained Bayesian neural networks",
    "abstract": " Title: Robustness to corruption in pre-trained Bayesian neural networks ",
    "url": "https://arxiv.org/abs/2206.12361",
    "authors": [
      "Xi Wang",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.15033",
    "title": "A Causal Approach to Detecting Multivariate Time-series Anomalies and  Root Causes",
    "abstract": " Comments: 19 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2206.15033",
    "authors": [
      "Wenzhuo Yang",
      "Kun Zhang",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09324",
    "title": "Signed Network Embedding with Application to Simultaneous Detection of  Communities and Anomalies",
    "abstract": " Comments: 24 pages, 4 figures. The appendix containing technical proof is not included, and will be uploaded in the future ",
    "url": "https://arxiv.org/abs/2207.09324",
    "authors": [
      "Haoran Zhang",
      "Junhui Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.00817",
    "title": "DSLA: Dynamic smooth label assignment for efficient anchor-free object  detection",
    "abstract": " Comments: single column, 33 pages, 7 figures, accepted by Pattern Recognition ",
    "url": "https://arxiv.org/abs/2208.00817",
    "authors": [
      "Hu Su",
      "Yonghao He",
      "Rui Jiang",
      "Jiabin Zhang",
      "Wei Zou",
      "Bin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.01886",
    "title": "Quantifying Temporal Privacy Leakage in Continuous Event Data Publishing",
    "abstract": " Title: Quantifying Temporal Privacy Leakage in Continuous Event Data Publishing ",
    "url": "https://arxiv.org/abs/2208.01886",
    "authors": [
      "Majid Rafiei",
      "Gamal Elkoumy",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.03211",
    "title": "Why do networks have inhibitory/negative connections?",
    "abstract": " Comments: Submitted ",
    "url": "https://arxiv.org/abs/2208.03211",
    "authors": [
      "Qingyang Wang",
      "Michael A. Powell",
      "Ali Geisa",
      "Eric Bridgeford",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2209.02765",
    "title": "Depression Symptoms Modelling from Social Media Text: A Semi-supervised  Learning Approach",
    "abstract": " Comments: Title and relevant changes are made ",
    "url": "https://arxiv.org/abs/2209.02765",
    "authors": [
      "Nawshad Farruque",
      "Randy Goebel",
      "Sudhakar Sivapalan",
      "Osmar Zaiane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.03807",
    "title": "Hardware Accelerator and Neural Network Co-Optimization for  Ultra-Low-Power Audio Processing Devices",
    "abstract": " Comments: Accepted Version for: EUROMICRO DSD 2022 ",
    "url": "https://arxiv.org/abs/2209.03807",
    "authors": [
      "Christoph Gerum",
      "Adrian Frischknecht",
      "Tobias Hald",
      "Paul Palomero Bernardo",
      "Konstantin L\u00fcbeck",
      "Oliver Bringmann"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.06620",
    "title": "Distributionally Robust Offline Reinforcement Learning with Linear  Function Approximation",
    "abstract": " Comments: First two authors contribute equally ",
    "url": "https://arxiv.org/abs/2209.06620",
    "authors": [
      "Xiaoteng Ma",
      "Zhipeng Liang",
      "Jose Blanchet",
      "Mingwen Liu",
      "Li Xia",
      "Jiheng Zhang",
      "Qianchuan Zhao",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.08378",
    "title": "Inducing Early Neural Collapse in Deep Neural Networks for Improved  Out-of-Distribution Detection",
    "abstract": " Comments: 11 pages, preprint, pending review with TMLR ",
    "url": "https://arxiv.org/abs/2209.08378",
    "authors": [
      "Jarrod Haas",
      "William Yolland",
      "Bernhard Rabus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.09338",
    "title": "Revisiting Embeddings for Graph Neural Networks",
    "abstract": " Title: Revisiting Embeddings for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2209.09338",
    "authors": [
      "S. Purchase",
      "A. Zhao",
      "R. D. Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.10428",
    "title": "An NWDAF Approach to 5G Core Network Signaling Traffic: Analysis and  Characterization",
    "abstract": " Comments: Accepted in IEEE GlobeCom 2022 ",
    "url": "https://arxiv.org/abs/2209.10428",
    "authors": [
      "Dimitrios Michael Manias",
      "Ali Chouman",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.13187",
    "title": "DAMO-NLP at NLPCC-2022 Task 2: Knowledge Enhanced Robust NER for Speech  Entity Linking",
    "abstract": " Comments: Accepted to NLPCC2022, 10 pages ",
    "url": "https://arxiv.org/abs/2209.13187",
    "authors": [
      "Shen Huang",
      "Yuchen Zhai",
      "Xinwei Long",
      "Yong Jiang",
      "Xiaobin Wang",
      "Yin Zhang",
      "Pengjun Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.13523",
    "title": "Watch What You Pretrain For: Targeted, Transferable Adversarial Examples  on Self-Supervised Speech Recognition models",
    "abstract": " Title: Watch What You Pretrain For: Targeted, Transferable Adversarial Examples  on Self-Supervised Speech Recognition models ",
    "url": "https://arxiv.org/abs/2209.13523",
    "authors": [
      "Raphael Olivier",
      "Hadi Abdullah",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.13708",
    "title": "Falsification before Extrapolation in Causal Effect Estimation",
    "abstract": " Comments: Conference on Neural Information Processing Systems, 2022 (to appear) ",
    "url": "https://arxiv.org/abs/2209.13708",
    "authors": [
      "Zeshan Hussain",
      "Michael Oberst",
      "Ming-Chieh Shih",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.13767",
    "title": "Internet Outage Detection using Passive Analysis (Poster Abstract and  Poster)",
    "abstract": " Title: Internet Outage Detection using Passive Analysis (Poster Abstract and  Poster) ",
    "url": "https://arxiv.org/abs/2209.13767",
    "authors": [
      "Asma Enayet",
      "John Heidemann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.14145",
    "title": "Multi-scale Attention Network for Single Image Super-Resolution",
    "abstract": " Title: Multi-scale Attention Network for Single Image Super-Resolution ",
    "url": "https://arxiv.org/abs/2209.14145",
    "authors": [
      "Yan Wang",
      "Yusen Li",
      "Gang Wang",
      "Xiaoguang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]