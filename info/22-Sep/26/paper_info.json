[
  {
    "id": "arXiv:2209.11229",
    "title": "Decomposition horizons: from graph sparsity to model-theoretic dividing  lines",
    "abstract": "Let $\\mathscr C$ be a hereditary class of graphs. Assume that for every $p$ there is a hereditary NIP class $\\mathscr D_p$ with the property that the vertex set of every graph $G\\in\\mathscr C$ can be partitioned into $N_p=N_p(G)$ parts in such a way that the union of any $p$ parts induce a subgraph in $\\mathscr D_p$ and $\\log N_p(G)\\in o(\\log |G|)$. We prove that $\\mathscr C$ is (monadically) NIP. Similarly, if every $\\mathscr D_p$ is stable, then $\\mathscr C$ is (monadically) stable. Results of this type lead to the definition of decomposition horizons as closure operators. We establish some of their basic properties and provide several further examples of decomposition horizons. ",
    "url": "https://arxiv.org/abs/2209.11229",
    "authors": [
      "Samuel Braunfeld",
      "Jaroslav Ne\u0161et\u0159il",
      "Patrice Ossona de Mendez",
      "Sebastian Siebertz"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2209.11268",
    "title": "Recurrence-free Survival Prediction under the Guidance of Automatic  Gross Tumor Volume Segmentation for Head and Neck Cancers",
    "abstract": "For Head and Neck Cancers (HNC) patient management, automatic gross tumor volume (GTV) segmentation and accurate pre-treatment cancer recurrence prediction are of great importance to assist physicians in designing personalized management plans, which have the potential to improve the treatment outcome and quality of life for HNC patients. In this paper, we developed an automated primary tumor (GTVp) and lymph nodes (GTVn) segmentation method based on combined pre-treatment positron emission tomography/computed tomography (PET/CT) scans of HNC patients. We extracted radiomics features from the segmented tumor volume and constructed a multi-modality tumor recurrence-free survival (RFS) prediction model, which fused the prediction results from separate CT radiomics, PET radiomics, and clinical models. We performed 5-fold cross-validation to train and evaluate our methods on the MICCAI 2022 HEad and neCK TumOR segmentation and outcome prediction challenge (HECKTOR) dataset. The ensemble prediction results on the testing cohort achieved Dice scores of 0.77 and 0.73 for GTVp and GTVn segmentation, respectively, and a C-index value of 0.67 for RFS prediction. The code is publicly available (https://github.com/wangkaiwan/HECKTOR-2022-AIRT). Our team's name is AIRT. ",
    "url": "https://arxiv.org/abs/2209.11268",
    "authors": [
      "Kai Wang",
      "Yunxiang Li",
      "Michael Dohopolski",
      "Tao Peng",
      "Weiguo Lu",
      "You Zhang",
      "Jing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11276",
    "title": "Capsule Network based Contrastive Learning of Unsupervised Visual  Representations",
    "abstract": "Capsule Networks have shown tremendous advancement in the past decade, outperforming the traditional CNNs in various task due to it's equivariant properties. With the use of vector I/O which provides information of both magnitude and direction of an object or it's part, there lies an enormous possibility of using Capsule Networks in unsupervised learning environment for visual representation tasks such as multi class image classification. In this paper, we propose Contrastive Capsule (CoCa) Model which is a Siamese style Capsule Network using Contrastive loss with our novel architecture, training and testing algorithm. We evaluate the model on unsupervised image classification CIFAR-10 dataset and achieve a top-1 test accuracy of 70.50% and top-5 test accuracy of 98.10%. Due to our efficient architecture our model has 31 times less parameters and 71 times less FLOPs than the current SOTA in both supervised and unsupervised learning. ",
    "url": "https://arxiv.org/abs/2209.11276",
    "authors": [
      "Harsh Panwar",
      "Ioannis Patras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11284",
    "title": "The Impact of Social Media in Learning and Teaching: A  Bibliometric-based Citation Analysis",
    "abstract": "This paper presents the results of a systematic review of the literature on the impact of social media in learning and teaching through bibliometric based Citation analysis. The objective of the review was to map the evolution of the current literature and identify the leading sources of knowledge in terms of the most influential journals, authors, and articles. From a total of 50 top most relevant articles selected from the Scopus database, a detailed citation analysis was conducted. The study explored the overall theoretical foundation of social media research involving in learning and studying and identified the leading sources of knowledge in terms of and papers and revealed research trends over the last four years by citation analysis. The analysis of citation data showed that International Journal of Management Education is the leading journal in social media in learning and teaching research. Author Abdullah Z was found to be the leading author in this field in terms of a total number of publications, total citations, and h index, while the most cited article was authored by Baaran S. and by Bapitha L. The contribution of this study is to clearly outline the current state of knowledge regarding social media in learning and teaching services in the literature. ",
    "url": "https://arxiv.org/abs/2209.11284",
    "authors": [
      "Abdul Shaikh",
      "Saqib Ali",
      "Ramla Al-Maamari"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.11304",
    "title": "Colonoscopy Landmark Detection using Vision Transformers",
    "abstract": "Colonoscopy is a routine outpatient procedure used to examine the colon and rectum for any abnormalities including polyps, diverticula and narrowing of colon structures. A significant amount of the clinician's time is spent in post-processing snapshots taken during the colonoscopy procedure, for maintaining medical records or further investigation. Automating this step can save time and improve the efficiency of the process. In our work, we have collected a dataset of 120 colonoscopy videos and 2416 snapshots taken during the procedure, that have been annotated by experts. Further, we have developed a novel, vision-transformer based landmark detection algorithm that identifies key anatomical landmarks (the appendiceal orifice, ileocecal valve/cecum landmark and rectum retroflexion) from snapshots taken during colonoscopy. Our algorithm uses an adaptive gamma correction during preprocessing to maintain a consistent brightness for all images. We then use a vision transformer as the feature extraction backbone and a fully connected network based classifier head to categorize a given frame into four classes: the three landmarks or a non-landmark frame. We compare the vision transformer (ViT-B/16) backbone with ResNet-101 and ConvNext-B backbones that have been trained similarly. We report an accuracy of 82% with the vision transformer backbone on a test dataset of snapshots. ",
    "url": "https://arxiv.org/abs/2209.11304",
    "authors": [
      "Aniruddha Tamhane",
      "Tse'ela Mida",
      "Erez Posner",
      "Moshe Bouhnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11328",
    "title": "Learning Certifiably Robust Controllers Using Fragile Perception",
    "abstract": "Advances in computer vision and machine learning enable robots to perceive their surroundings in powerful new ways, but these perception modules have well-known fragilities. We consider the problem of synthesizing a safe controller that is robust despite perception errors. The proposed method constructs a state estimator based on Gaussian processes with input-dependent noises. This estimator computes a high-confidence set for the actual state given a perceived state. Then, a robust neural network controller is synthesized that can provably handle the state uncertainty. Furthermore, an adaptive sampling algorithm is proposed to jointly improve the estimator and controller. Simulation experiments, including a realistic vision-based lane-keeping example in CARLA, illustrate the promise of the proposed approach in synthesizing robust controllers with deep-learning-based perception. ",
    "url": "https://arxiv.org/abs/2209.11328",
    "authors": [
      "Dawei Sun",
      "Negin Musavi",
      "Geir Dullerud",
      "Sanjay Shakkottai",
      "Sayan Mitra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.11335",
    "title": "Privacy-Preserving Person Detection Using Low-Resolution Infrared  Cameras",
    "abstract": "In intelligent building management, knowing the number of people and their location in a room are important for better control of its illumination, ventilation, and heating with reduced costs and improved comfort. This is typically achieved by detecting people using compact embedded devices that are installed on the room's ceiling, and that integrate low-resolution infrared camera, which conceals each person's identity. However, for accurate detection, state-of-the-art deep learning models still require supervised training using a large annotated dataset of images. In this paper, we investigate cost-effective methods that are suitable for person detection based on low-resolution infrared images. Results indicate that for such images, we can reduce the amount of supervision and computation, while still achieving a high level of detection accuracy. Going from single-shot detectors that require bounding box annotations of each person in an image, to auto-encoders that only rely on unlabelled images that do not contain people, allows for considerable savings in terms of annotation costs, and for models with lower computational costs. We validate these experimental findings on two challenging top-view datasets with low-resolution infrared images. ",
    "url": "https://arxiv.org/abs/2209.11335",
    "authors": [
      "Thomas Dubail",
      "Fidel Alejandro Guerrero Pe\u00f1a",
      "Heitor Rapela Medeiros",
      "Masih Aminbeidokhti",
      "Eric Granger",
      "Marco Pedersoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11338",
    "title": "A domain adaptive deep learning solution for scanpath prediction of  paintings",
    "abstract": "Cultural heritage understanding and preservation is an important issue for society as it represents a fundamental aspect of its identity. Paintings represent a significant part of cultural heritage, and are the subject of study continuously. However, the way viewers perceive paintings is strictly related to the so-called HVS (Human Vision System) behaviour. This paper focuses on the eye-movement analysis of viewers during the visual experience of a certain number of paintings. In further details, we introduce a new approach to predicting human visual attention, which impacts several cognitive functions for humans, including the fundamental understanding of a scene, and then extend it to painting images. The proposed new architecture ingests images and returns scanpaths, a sequence of points featuring a high likelihood of catching viewers' attention. We use an FCNN (Fully Convolutional Neural Network), in which we exploit a differentiable channel-wise selection and Soft-Argmax modules. We also incorporate learnable Gaussian distributions onto the network bottleneck to simulate visual attention process bias in natural scene images. Furthermore, to reduce the effect of shifts between different domains (i.e. natural images, painting), we urge the model to learn unsupervised general features from other domains using a gradient reversal classifier. The results obtained by our model outperform existing state-of-the-art ones in terms of accuracy and efficiency. ",
    "url": "https://arxiv.org/abs/2209.11338",
    "authors": [
      "Mohamed Amine Kerkouri",
      "Marouane Tliba",
      "Aladine Chetouani",
      "Alessandro Bruno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11350",
    "title": "Oracle Analysis of Representations for Deep Open Set Detection",
    "abstract": "The problem of detecting a novel class at run time is known as Open Set Detection & is important for various real-world applications like medical application, autonomous driving, etc. Open Set Detection within context of deep learning involves solving two problems: (i) Must map the input images into a latent representation that contains enough information to detect the outliers, and (ii) Must learn an anomaly scoring function that can extract this information from the latent representation to identify the anomalies. Research in deep anomaly detection methods has progressed slowly. One reason may be that most papers simultaneously introduce new representation learning techniques and new anomaly scoring approaches. The goal of this work is to improve this methodology by providing ways of separately measuring the effectiveness of the representation learning and anomaly scoring. This work makes two methodological contributions. The first is to introduce the notion of Oracle anomaly detection for quantifying the information available in a learned latent representation. The second is to introduce Oracle representation learning, which produces a representation that is guaranteed to be sufficient for accurate anomaly detection. These two techniques help researchers to separate the quality of the learned representation from the performance of the anomaly scoring mechanism so that they can debug and improve their systems. The methods also provide an upper limit on how much open category detection can be improved through better anomaly scoring mechanisms. The combination of the two oracles gives an upper limit on the performance that any open category detection method could achieve. This work introduces these two oracle techniques and demonstrates their utility by applying them to several leading open category detection methods. ",
    "url": "https://arxiv.org/abs/2209.11350",
    "authors": [
      "Risheek Garrepalli",
      "Alan Fern",
      "Thomas G. Dietterich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11354",
    "title": "Convolutional Learning on Multigraphs",
    "abstract": "Graph convolutional learning has led to many exciting discoveries in diverse areas. However, in some applications, traditional graphs are insufficient to capture the structure and intricacies of the data. In such scenarios, multigraphs arise naturally as discrete structures in which complex dynamics can be embedded. In this paper, we develop convolutional information processing on multigraphs and introduce convolutional multigraph neural networks (MGNNs). To capture the complex dynamics of information diffusion within and across each of the multigraph's classes of edges, we formalize a convolutional signal processing model, defining the notions of signals, filtering, and frequency representations on multigraphs. Leveraging this model, we develop a multigraph learning architecture, including a sampling procedure to reduce computational complexity. The introduced architecture is applied towards optimal wireless resource allocation and a hate speech localization task, offering improved performance over traditional graph neural networks. ",
    "url": "https://arxiv.org/abs/2209.11354",
    "authors": [
      "Landon Butler",
      "Alejandro Parada-Mayorga",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.11366",
    "title": "A Jensen-Shannon Divergence Based Loss Function for Bayesian Neural  Networks",
    "abstract": "Kullback-Leibler (KL) divergence is widely used for variational inference of Bayesian Neural Networks (BNNs). However, the KL divergence has limitations such as unboundedness and asymmetry. We examine the Jensen-Shannon (JS) divergence that is more general, bounded, and symmetric. We formulate a novel loss function for BNNs based on the geometric JS divergence and show that the conventional KL divergence-based loss function is its special case. We evaluate the divergence part of the proposed loss function in a closed form for a Gaussian prior. For any other general prior, Monte Carlo approximations can be used. We provide algorithms for implementing both of these cases. We demonstrate that the proposed loss function offers an additional parameter that can be tuned to control the degree of regularisation. We derive the conditions under which the proposed loss function regularises better than the KL divergence-based loss function for Gaussian priors and posteriors. We demonstrate performance improvements over the state-of-the-art KL divergence-based BNN on the classification of a noisy CIFAR data set and a biased histopathology data set. ",
    "url": "https://arxiv.org/abs/2209.11366",
    "authors": [
      "Ponkrshnan Thiagarajan",
      "Susanta Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11367",
    "title": "Towards Robust Autonomous Grasping with Reflexes Using High-Bandwidth  Sensing and Actuation",
    "abstract": "Modern robotic manipulation systems fall short of human manipulation skills partly because they rely on closing feedback loops exclusively around vision data, which reduces system bandwidth and speed. By developing autonomous grasping reflexes that rely on high-bandwidth force, contact, and proximity data, the overall system speed and robustness can be increased while reducing reliance on vision data. We are developing a new system built around a low-inertia, high-speed arm with nimble fingers that combines a high-level trajectory planner operating at less than 1 Hz with low-level autonomous reflex controllers running upwards of 300 Hz. We characterize the reflex system by comparing the volume of the set of successful grasps for a naive baseline controller and variations of our reflexive grasping controller, finding that our controller expands the set of successful grasps by 55% relative to the baseline. We also deploy our reflexive grasping controller with a simple vision-based planner in an autonomous clutter clearing task, achieving a grasp success rate above 90% while clearing over 100 items. ",
    "url": "https://arxiv.org/abs/2209.11367",
    "authors": [
      "Andrew SaLoutos",
      "Hongmin Kim",
      "Elijah Stanger-Jones",
      "Menglong Guo",
      "Sangbae Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.11382",
    "title": "Zero-Forcing Based Downlink Virtual MIMO-NOMA Communications in IoT  Networks",
    "abstract": "To support massive connectivity and boost spectral efficiency for internet of things (IoT), a downlink scheme combining virtual multiple-input multiple-output (MIMO) and nonorthogonal multiple access (NOMA) is proposed. All the single-antenna IoT devices in each cluster cooperate with each other to establish a virtual MIMO entity, and multiple independent data streams are requested by each cluster. NOMA is employed to superimpose all the requested data streams, and each cluster leverages zero-forcing detection to de-multiplex the input data streams. Only statistical channel state information (CSI) is available at base station to avoid the waste of the energy and bandwidth on frequent CSI estimations. The outage probability and goodput of the virtual MIMO-NOMA system are thoroughly investigated by considering Kronecker model, which embraces both the transmit and receive correlations. Furthermore, the asymptotic results facilitate not only the exploration of physical insights but also the goodput maximization. In particular, the asymptotic outage expressions provide quantitative impacts of various system parameters and enable the investigation of diversity-multiplexing tradeoff (DMT). Moreover, power allocation coefficients and/or transmission rates can be properly chosen to achieve the maximal goodput. By favor of Karush-Kuhn-Tucker conditions, the goodput maximization problems can be solved in closed-form, with which the joint power and rate selection is realized by using alternately iterating optimization.Besides, the optimization algorithms tend to allocate more power to clusters under unfavorable channel conditions and support clusters with higher transmission rate under benign channel conditions. ",
    "url": "https://arxiv.org/abs/2209.11382",
    "authors": [
      "Zheng Shi",
      "Hong Wang",
      "Yaru Fu",
      "Guanghua Yang",
      "Shaodan Ma",
      "Fen Hou",
      "Theodoros A. Tsiftsis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.11388",
    "title": "LGDN: Language-Guided Denoising Network for Video-Language Modeling",
    "abstract": "Video-language modeling has attracted much attention with the rapid growth of web videos. Most existing methods assume that the video frames and text description are semantically correlated, and focus on video-language modeling at video level. However, this hypothesis often fails for two reasons: (1) With the rich semantics of video contents, it is difficult to cover all frames with a single video-level description; (2) A raw video typically has noisy/meaningless information (e.g., scenery shot, transition or teaser). Although a number of recent works deploy attention mechanism to alleviate this problem, the irrelevant/noisy information still makes it very difficult to address. To overcome such challenge, we thus propose an efficient and effective model, termed Language-Guided Denoising Network (LGDN), for video-language modeling. Different from most existing methods that utilize all extracted video frames, LGDN dynamically filters out the misaligned or redundant frames under the language supervision and obtains only 2--4 salient frames per video for cross-modal token-level alignment. Extensive experiments on five public datasets show that our LGDN outperforms the state-of-the-arts by large margins. We also provide detailed ablation study to reveal the critical importance of solving the noise issue, in hope of inspiring future video-language work. ",
    "url": "https://arxiv.org/abs/2209.11388",
    "authors": [
      "Haoyu Lu",
      "Mingyu Ding",
      "Nanyi Fei",
      "Yuqi Huo",
      "Zhiwu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2209.11390",
    "title": "Outage Performance and Optimal Design of MIMO-NOMA Enhanced Small Cell  Networks With Imperfect Channel-State Information",
    "abstract": "This paper focuses on boosting the performance of small cell networks (SCNs) by integrating multiple-input multiple-output (MIMO) and non-orthogonal multiple access (NOMA) in consideration of imperfect channel-state information (CSI). The estimation error and the spatial randomness of base stations (BSs) are characterized by using Kronecker model and Poisson point process (PPP), respectively. The outage probabilities of MIMO-NOMA enhanced SCNs are first derived in closed-form by taking into account two grouping policies, including random grouping and distance-based grouping. It is revealed that the average outage probabilities are irrelevant to the intensity of BSs in the interference-limited regime, while the outage performance deteriorates if the intensity is sufficiently low. Besides, as the channel uncertainty lessens, the asymptotic analyses manifest that the target rates must be restricted up to a bound to achieve an arbitrarily low outage probability in the absence of the inter-cell interference.Moreover, highly correlated estimation error ameliorates the outage performance under a low quality of CSI, otherwise it behaves oppositely. Afterwards, the goodput is maximized by choosing appropriate precoding matrix, receiver filters and transmission rates. In the end, the numerical results verify our analysis and corroborate the superiority of our proposed algorithm. ",
    "url": "https://arxiv.org/abs/2209.11390",
    "authors": [
      "Zheng Shi",
      "Hong Wang",
      "Yaru Fu",
      "Guanghua Yang",
      "Shaodan Ma",
      "Xinrong Ye"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2209.11395",
    "title": "Achieve the Minimum Width of Neural Networks for Universal Approximation",
    "abstract": "The universal approximation property (UAP) of neural networks is fundamental for deep learning, and it is well known that wide neural networks are universal approximators of continuous functions within both the $L^p$ norm and the continuous/uniform norm. However, the exact minimum width, $w_{\\min}$, for the UAP has not been studied thoroughly. Recently, using a decoder-memorizer-encoder scheme, \\citet{Park2021Minimum} found that $w_{\\min} = \\max(d_x+1,d_y)$ for both the $L^p$-UAP of ReLU networks and the $C$-UAP of ReLU+STEP networks, where $d_x,d_y$ are the input and output dimensions, respectively. In this paper, we consider neural networks with an arbitrary set of activation functions. We prove that both $C$-UAP and $L^p$-UAP for functions on compact domains share a universal lower bound of the minimal width; that is, $w^*_{\\min} = \\max(d_x,d_y)$. In particular, the critical width, $w^*_{\\min}$, for $L^p$-UAP can be achieved by leaky-ReLU networks, provided that the input or output dimension is larger than one. Our construction is based on the approximation power of neural ordinary differential equations and the ability to approximate flow maps by neural networks. The nonmonotone or discontinuous activation functions case and the one-dimensional case are also discussed. ",
    "url": "https://arxiv.org/abs/2209.11395",
    "authors": [
      "Yongqiang Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11405",
    "title": "Quantum Locally Testable Code with Exotic Parameters",
    "abstract": "In this paper, we present a few simple constructions of quantum locally testable codes that achieve interesting parameters which were previously unknown. We introduce an operation which we give the name check product, and show how this operation gives rise to quantum locally testable codes of constant soundness and linear rate, with varying distance and locality. ",
    "url": "https://arxiv.org/abs/2209.11405",
    "authors": [
      "Andrew Cross",
      "Zhiyang He",
      "Anand Natarajan",
      "Mario Szegedy",
      "Guanyu Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2209.11407",
    "title": "IDEA: Interactive DoublE Attentions from Label Embedding for Text  Classification",
    "abstract": "Current text classification methods typically encode the text merely into embedding before a naive or complicated classifier, which ignores the suggestive information contained in the label text. As a matter of fact, humans classify documents primarily based on the semantic meaning of the subcategories. We propose a novel model structure via siamese BERT and interactive double attentions named IDEA ( Interactive DoublE Attentions) to capture the information exchange of text and label names. Interactive double attentions enable the model to exploit the inter-class and intra-class information from coarse to fine, which involves distinguishing among all labels and matching the semantical subclasses of ground truth labels. Our proposed method outperforms the state-of-the-art methods using label texts significantly with more stable results. ",
    "url": "https://arxiv.org/abs/2209.11407",
    "authors": [
      "Ziyuan Wang",
      "Hailiang Huang",
      "Songqiao Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11409",
    "title": "Zero-shot Domain Adaptation for Neural Machine Translation with  Retrieved Phrase-level Prompts",
    "abstract": "Domain adaptation is an important challenge for neural machine translation. However, the traditional fine-tuning solution requires multiple extra training and yields a high cost. In this paper, we propose a non-tuning paradigm, resolving domain adaptation with a prompt-based method. Specifically, we construct a bilingual phrase-level database and retrieve relevant pairs from it as a prompt for the input sentences. By utilizing Retrieved Phrase-level Prompts (RePP), we effectively boost the translation quality. Experiments show that our method improves domain-specific machine translation for 6.2 BLEU scores and improves translation constraints for 11.5% accuracy without additional training. ",
    "url": "https://arxiv.org/abs/2209.11409",
    "authors": [
      "Zewei Sun",
      "Qingnan Jiang",
      "Shujian Huang",
      "Jun Cao",
      "Shanbo Cheng",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.11414",
    "title": "Relation Embedding based Graph Neural Networks for Handling  Heterogeneous Graph",
    "abstract": "Heterogeneous graph learning has drawn significant attentions in recent years, due to the success of graph neural networks (GNNs) and the broad applications of heterogeneous information networks. Various heterogeneous graph neural networks have been proposed to generalize GNNs for processing the heterogeneous graphs. Unfortunately, these approaches model the heterogeneity via various complicated modules. This paper aims to propose a simple yet efficient framework to make the homogeneous GNNs have adequate ability to handle heterogeneous graphs. Specifically, we propose Relation Embedding based Graph Neural Networks (RE-GNNs), which employ only one parameter per relation to embed the importance of edge type relations and self-loop connections. To optimize these relation embeddings and the other parameters simultaneously, a gradient scaling factor is proposed to constrain the embeddings to converge to suitable values. Besides, we theoretically demonstrate that our RE-GNNs have more expressive power than the meta-path based heterogeneous GNNs. Extensive experiments on the node classification tasks validate the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2209.11414",
    "authors": [
      "Junfu Wang",
      "Yuanfang Guo",
      "Liang Yang",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11425",
    "title": "RIS-Aided MIMO Systems with Hardware Impairments: Robust Beamforming  Design and Analysis",
    "abstract": "Reconfigurable intelligent surface (RIS) has been anticipated to be a novel cost-effective technology to improve the performance of future wireless systems. In this paper, we investigate a practical RIS-aided multiple-input-multiple-output (MIMO) system in the presence of transceiver hardware impairments, RIS phase noise and imperfect channel state information (CSI). Joint design of the MIMO transceiver and RIS reflection matrix to minimize the total average mean-square-error (MSE) of all data streams is particularly considered. This joint design problem is non-convex and challenging to solve due to the newly considered practical imperfections. To tackle the issue, we first analyze the total average MSE by incorporating the impacts of the above system imperfections. Then, in order to handle the tightly coupled optimization variables and non-convex NP-hard constraints, an efficient iterative algorithm based on alternating optimization (AO) framework is proposed with guaranteed convergence, where each subproblem admits a closed-form optimal solution by leveraging the majorization-minimization (MM) technique. Moreover, via exploiting the special structure of the unit-modulus constraints, we propose a modified Riemannian gradient ascent (RGA) algorithm for the discrete RIS phase shift optimization. Furthermore, the optimality of the proposed algorithm is validated under line-of-sight (LoS) channel conditions, and the irreducible MSE floor effect induced by imperfections of both hardware and CSI is also revealed in the high signal-to-noise ratio (SNR) regime. Numerical results show the superior MSE performance of our proposed algorithm over the adopted benchmark schemes, and demonstrate that increasing the number of RIS elements is not always beneficial under the above system imperfections. ",
    "url": "https://arxiv.org/abs/2209.11425",
    "authors": [
      "Jintao Wang",
      "Shiqi Gong",
      "Qingqing Wu",
      "Shaodan Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.11427",
    "title": "A Robust and Explainable Data-Driven Anomaly Detection Approach For  Power Electronics",
    "abstract": "Timely and accurate detection of anomalies in power electronics is becoming increasingly critical for maintaining complex production systems. Robust and explainable strategies help decrease system downtime and preempt or mitigate infrastructure cyberattacks. This work begins by explaining the types of uncertainty present in current datasets and machine learning algorithm outputs. Three techniques for combating these uncertainties are then introduced and analyzed. We further present two anomaly detection and classification approaches, namely the Matrix Profile algorithm and anomaly transformer, which are applied in the context of a power electronic converter dataset. Specifically, the Matrix Profile algorithm is shown to be well suited as a generalizable approach for detecting real-time anomalies in streaming time-series data. The STUMPY python library implementation of the iterative Matrix Profile is used for the creation of the detector. A series of custom filters is created and added to the detector to tune its sensitivity, recall, and detection accuracy. Our numerical results show that, with simple parameter tuning, the detector provides high accuracy and performance in a variety of fault scenarios. ",
    "url": "https://arxiv.org/abs/2209.11427",
    "authors": [
      "Alexander Beattie",
      "Pavol Mulinka",
      "Subham Sahoo",
      "Ioannis T. Christou",
      "Charalampos Kalalas",
      "Daniel Gutierrez-Rojas",
      "Pedro H. J. Nardelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11436",
    "title": "Understanding Open-Set Recognition by Jacobian Norm of Representation",
    "abstract": "In contrast to conventional closed-set recognition, open-set recognition (OSR) assumes the presence of an unknown class, which is not seen to a model during training. One predominant approach in OSR is metric learning, where a model is trained to separate the inter-class representations of known class data. Numerous works in OSR reported that, even though the models are trained only with the known class data, the models become aware of the unknown, and learn to separate the unknown class representations from the known class representations. This paper analyzes this emergent phenomenon by observing the Jacobian norm of representation. We theoretically show that minimizing the intra-class distances within the known set reduces the Jacobian norm of known class representations while maximizing the inter-class distances within the known set increases the Jacobian norm of the unknown class. The closed-set metric learning thus separates the unknown from the known by forcing their Jacobian norm values to differ. We empirically validate our theoretical framework with ample pieces of evidence using standard OSR datasets. Moreover, under our theoretical framework, we explain how the standard deep learning techniques can be helpful for OSR and use the framework as a guiding principle to develop an effective OSR model. ",
    "url": "https://arxiv.org/abs/2209.11436",
    "authors": [
      "Jaewoo Park",
      "Hojin Park",
      "Eunju Jeong",
      "Andrew Beng Jin Teoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11448",
    "title": "Rethinking Performance Gains in Image Dehazing Networks",
    "abstract": "Image dehazing is an active topic in low-level vision, and many image dehazing networks have been proposed with the rapid development of deep learning. Although these networks' pipelines work fine, the key mechanism to improving image dehazing performance remains unclear. For this reason, we do not target to propose a dehazing network with fancy modules; rather, we make minimal modifications to popular U-Net to obtain a compact dehazing network. Specifically, we swap out the convolutional blocks in U-Net for residual blocks with the gating mechanism, fuse the feature maps of main paths and skip connections using the selective kernel, and call the resulting U-Net variant gUNet. As a result, with a significantly reduced overhead, gUNet is superior to state-of-the-art methods on multiple image dehazing datasets. Finally, we verify these key designs to the performance gain of image dehazing networks through extensive ablation studies. ",
    "url": "https://arxiv.org/abs/2209.11448",
    "authors": [
      "Yuda Song",
      "Yang Zhou",
      "Hui Qian",
      "Xin Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11475",
    "title": "Unsupervised Hashing with Semantic Concept Mining",
    "abstract": "Recently, to improve the unsupervised image retrieval performance, plenty of unsupervised hashing methods have been proposed by designing a semantic similarity matrix, which is based on the similarities between image features extracted by a pre-trained CNN model. However, most of these methods tend to ignore high-level abstract semantic concepts contained in images. Intuitively, concepts play an important role in calculating the similarity among images. In real-world scenarios, each image is associated with some concepts, and the similarity between two images will be larger if they share more identical concepts. Inspired by the above intuition, in this work, we propose a novel Unsupervised Hashing with Semantic Concept Mining, called UHSCM, which leverages a VLP model to construct a high-quality similarity matrix. Specifically, a set of randomly chosen concepts is first collected. Then, by employing a vision-language pretraining (VLP) model with the prompt engineering which has shown strong power in visual representation learning, the set of concepts is denoised according to the training images. Next, the proposed method UHSCM applies the VLP model with prompting again to mine the concept distribution of each image and construct a high-quality semantic similarity matrix based on the mined concept distributions. Finally, with the semantic similarity matrix as guiding information, a novel hashing loss with a modified contrastive loss based regularization item is proposed to optimize the hashing network. Extensive experiments on three benchmark datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task. ",
    "url": "https://arxiv.org/abs/2209.11475",
    "authors": [
      "Rong-Cheng Tu",
      "Xian-Ling Mao",
      "Kevin Qinghong Lin",
      "Chengfei Cai",
      "Weize Qin",
      "Hongfa Wang",
      "Wei Wei",
      "Heyan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2209.11477",
    "title": "Weakly Supervised Two-Stage Training Scheme for Deep Video Fight  Detection Model",
    "abstract": "Fight detection in videos is an emerging deep learning application with today's prevalence of surveillance systems and streaming media. Previous work has largely relied on action recognition techniques to tackle this problem. In this paper, we propose a simple but effective method that solves the task from a new perspective: we design the fight detection model as a composition of an action-aware feature extractor and an anomaly score generator. Also, considering that collecting frame-level labels for videos is too laborious, we design a weakly supervised two-stage training scheme, where we utilize multiple-instance-learning loss calculated on video-level labels to train the score generator, and adopt the self-training technique to further improve its performance. Extensive experiments on a publicly available large-scale dataset, UBI-Fights, demonstrate the effectiveness of our method, and the performance on the dataset exceeds several previous state-of-the-art approaches. Furthermore, we collect a new dataset, VFD-2000, that specializes in video fight detection, with a larger scale and more scenarios than existing datasets. The implementation of our method and the proposed dataset will be publicly available at https://github.com/Hepta-Col/VideoFightDetection. ",
    "url": "https://arxiv.org/abs/2209.11477",
    "authors": [
      "Zhenting Qi",
      "Ruike Zhu",
      "Zheyu Fu",
      "Wenhao Chai",
      "Volodymyr Kindratenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11478",
    "title": "Combining Motion Matching and Orientation Prediction to Animate Avatars  for Consumer-Grade VR Devices",
    "abstract": "The animation of user avatars plays a crucial role in conveying their pose, gestures, and relative distances to virtual objects or other users. Self-avatar animation in immersive VR helps improve the user experience and provides a Sense of Embodiment. However, consumer-grade VR devices typically include at most three trackers, one at the Head Mounted Display (HMD), and two at the handheld VR controllers. Since the problem of reconstruction the user pose from such sparse data is ill-defined, especially for the lower body, the approach adopted by most VR games consists of assuming the body orientation matches that of the HMD, and applying animation blending and time-warping from a reduced set of animations. Unfortunately, this approach produces noticeable mismatches between user and avatar movements. In this work we present a new approach to animate user avatars that is suitable for current mainstream VR devices. First, we use a neural network to estimate the user's body orientation based on the tracking information from the HMD and the hand controllers. Then we use this orientation together with the velocity and rotation of the HMD to build a feature vector that feeds a Motion Matching algorithm. We built a MoCap database with animations of VR users wearing a HMD and used it to test our approach on both self-avatars and other users' avatars. Our results show that our system can provide a large variety of lower body animations while correctly matching the user orientation, which in turn allows us to represent not only forward movements but also stepping in any direction. ",
    "url": "https://arxiv.org/abs/2209.11478",
    "authors": [
      "Jose Luis Ponton",
      "Haoran Yun",
      "Carlos Andujar",
      "Nuria Pelechano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2209.11485",
    "title": "Optimal Job Scheduling and Bandwidth Augmentation in Hybrid Data Center  Networks",
    "abstract": "Optimizing data transfers is critical for improving job performance in data-parallel frameworks. In the hybrid data center with both wired and wireless links, reconfigurable wireless links can provide additional bandwidth to speed up job execution. However, it requires the scheduler and transceivers to make joint decisions under coupled constraints. In this work, we identify that the joint job scheduling and bandwidth augmentation problem is a complex mixed integer nonlinear problem, which is not solvable by existing optimization methods. To address this bottleneck, we transform it into an equivalent problem based on the coupling of its heuristic bounds, the revised data transfer representation and non-linear constraints decoupling and reformulation, such that the optimal solution can be efficiently acquired by the Branch and Bound method. Based on the proposed method, the performance of job scheduling with and without bandwidth augmentation is studied. Experiments show that the performance gain depends on multiple factors, especially the data size. Compared with existing solutions, our method can averagely reduce the job completion time by up to 10% under the setting of production scenario. ",
    "url": "https://arxiv.org/abs/2209.11485",
    "authors": [
      "Binquan Guo",
      "Zhou Zhang",
      "Ye Yan",
      "Hongyan Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.11489",
    "title": "Social Robot Scenarios for Real-World Child and Family Care Settings  through Participatory Design",
    "abstract": "This paper discusses a 5-year PhD project, focused upon the implementation of social robots for general child and family care settings in the Netherlands. The project is a collaboration with general Dutch family care organisations as well as specialized child mental health care organisations. The project adapts a bottom-up, participatory design approach, where end users are included in all stages of the project. End users consist of children, parents, and family care professionals, who all have different needs, regarding the social robot behaviors as well as the participatory design methods. This paper provides suggestions to deal with these differences in designing social robots for child mental support in real-world settings. ",
    "url": "https://arxiv.org/abs/2209.11489",
    "authors": [
      "Anouk Neerincx"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2209.11493",
    "title": "Comparison of synthetic dataset generation methods for medical  intervention rooms using medical clothing detection as an example",
    "abstract": "The availability of real data from areas with high privacy requirements, such as the medical intervention space, is low and the acquisition legally complex. Therefore, this work presents a way to create a synthetic dataset for the medical context, using medical clothing as an example. The goal is to close the reality gap between the synthetic and real data. For this purpose, methods of 3D-scanned clothing and designed clothing are compared in a Domain-Randomization and Structured-Domain-Randomization scenario using an Unreal-Engine plugin or Unity. Additionally a Mixed-Reality dataset in front of a greenscreen and a target domain dataset were used. Our experiments show, that Structured-Domain-Randomization of designed clothing together with Mixed-Reality data provide a baseline achieving 72.0% mAP on a test dataset of the clinical target domain. When additionally using 15% of available target domain train data, the gap towards 100% (660 images) target domain train data could be nearly closed 80.05% mAP (81.95% mAP). Finally we show that when additionally using 100% target domain train data the accuracy could be increased to 83.35% mAP. ",
    "url": "https://arxiv.org/abs/2209.11493",
    "authors": [
      "Patrick Sch\u00fclein",
      "Hannah Teufel",
      "Ronja Vorpahl",
      "Indira Emter",
      "Yannick Bukschat",
      "Marcus Pfister",
      "Anke Siebert",
      "Nils Rathmann",
      "Steffen Diehl",
      "Marcus Vetter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11497",
    "title": "Sequential Causal Effect Variational Autoencoder: Time Series Causal  Link Estimation under Hidden Confounding",
    "abstract": "Estimating causal effects from observational data in the presence of latent variables sometimes leads to spurious relationships which can be misconceived as causal. This is an important issue in many fields such as finance and climate science. We propose Sequential Causal Effect Variational Autoencoder (SCEVAE), a novel method for time series causality analysis under hidden confounding. It is based on the CEVAE framework and recurrent neural networks. The causal link's intensity of the confounded variables is calculated by using direct causal criteria based on Pearl's do-calculus. We show the efficacy of SCEVAE by applying it to synthetic datasets with both linear and nonlinear causal links. Furthermore, we apply our method to real aerosol-cloud-climate observation data. We compare our approach to a time series deconfounding method with and without substitute confounders on the synthetic data. We demonstrate that our method performs better by comparing both methods to the ground truth. In the case of real data, we use the expert knowledge of causal links and show how the use of correct proxy variables aids data reconstruction. ",
    "url": "https://arxiv.org/abs/2209.11497",
    "authors": [
      "Violeta Teodora Trifunov",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2209.11523",
    "title": "WS-3D-Lane: Weakly Supervised 3D Lane Detection With 2D Lane Labels",
    "abstract": "Compared to 2D lanes, real 3D lane data is difficult to collect accurately. In this paper, we propose a novel method for training 3D lanes with only 2D lane labels, called weakly supervised 3D lane detection WS-3D-Lane. By assumptions of constant lane width and equal height on adjacent lanes, we indirectly supervise 3D lane heights in the training. To overcome the problem of the dynamic change of the camera pitch during data collection, a camera pitch self-calibration method is proposed. In anchor representation, we propose a double-layer anchor with a improved non-maximum suppression (NMS) method, which enables the anchor-based method to predict two lane lines that are close. Experiments are conducted on the base of 3D-LaneNet under two supervision methods. Under weakly supervised setting, our WS-3D-Lane outperforms previous 3D-LaneNet: F-score rises to 92.3% on Apollo 3D synthetic dataset, and F1 rises to 74.5% on ONCE-3DLanes. Meanwhile, WS-3D-Lane in purely supervised setting makes more increments and outperforms state-of-the-art. To the best of our knowledge, WS-3D-Lane is the first try of 3D lane detection under weakly supervised setting. ",
    "url": "https://arxiv.org/abs/2209.11523",
    "authors": [
      "Jianyong Ai",
      "Wenbo Ding",
      "Jiuhua Zhao",
      "Jiachen Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11527",
    "title": "An artificial neural network-based system for detecting machine failures  using tiny sound data: A case study",
    "abstract": "In an effort to advocate the research for a deep learning-based machine failure detection system, we present a case study of our proposed system based on a tiny sound dataset. Our case study investigates a variational autoencoder (VAE) for augmenting a small drill sound dataset from Valmet AB. A Valmet dataset contains 134 sounds that have been divided into two categories: \"Anomaly\" and \"Normal\" recorded from a drilling machine in Valmet AB, a company in Sundsvall, Sweden that supplies equipment and processes for the production of biofuels. Using deep learning models to detect failure drills on such a small sound dataset is typically unsuccessful. We employed a VAE to increase the number of sounds in the tiny dataset by synthesizing new sounds from original sounds. The augmented dataset was created by combining these synthesized sounds with the original sounds. We used a high-pass filter with a passband frequency of 1000 Hz and a low-pass filter with a passband frequency of 22\\kern 0.16667em000 Hz to pre-process sounds in the augmented dataset before transforming them to Mel spectrograms. The pre-trained 2D-CNN Alexnet was then trained using these Mel spectrograms. When compared to using the original tiny sound dataset to train pre-trained Alexnet, using the augmented sound dataset enhanced the CNN model's classification results by 6.62\\%(94.12\\% when trained on the augmented dataset versus 87.5\\% when trained on the original dataset). ",
    "url": "https://arxiv.org/abs/2209.11527",
    "authors": [
      "Thanh Tran",
      "Sebastian Bader",
      "Jan Lundgren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.11535",
    "title": "The path to 5G-Advanced and 6G Non-Terrestrial Network systems",
    "abstract": "Today, 5G networks are being worldwide rolled out, with significant benefits in our economy and society. However, 5G systems alone are not expected to be sufficient for the challenges that 2030 networks will experience, including, e.g., always-on networks, 1 Tbps peak data rate, <10 cm positioning, etc. Thus, the definition of evolutions of the 5G systems and their (r)evolutions are already being addressed by the scientific and industrial communities, targeting 5G-Advanced (5G-A) and 6G. In this framework, Non-Terrestrial Networks (NTN) have successfully been integrated in 3GPP Rel. 17 and it is expected that they will play an even more pivotal role for 5G-A (up to Rel. 20) and 6G systems (beyond Rel. 20). In this paper, we explore the path that will lead to 5G-A and 6G NTN communications, providing a clear perspective in terms of system architecture, services, technologies, and standardisation roadmap. ",
    "url": "https://arxiv.org/abs/2209.11535",
    "authors": [
      "Alessandro Guidotti",
      "Alessandro Vanelli-Coralli",
      "Vincenzo Schena",
      "Nicolas Chuberre",
      "Mohamed El Jaafari",
      "Jani Puttonen",
      "Stefano Cioni"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.11554",
    "title": "mmWall: A Transflective Metamaterial Surface for mmWave Networks",
    "abstract": "Mobile operators are poised to leverage millimeter wave technology as 5G evolves, but despite efforts to bolster their reliability indoors and outdoors, mmWave links remain vulnerable to blockage by walls, people, and obstacles. Further, there is significant interest in bringing outdoor mmWave coverage indoors, which for similar reasons remains challenging today. This paper presents the design, hardware implementation, and experimental evaluation of mmWall, the first electronically almost-360 degree steerable metamaterial surface that operates above 24 GHz and both refracts or reflects incoming mmWave transmissions. Our metamaterial design consists of arrays of varactor-split ring resonator unit cells, miniaturized for mmWave. Custom control circuitry drives each resonator, overcoming coupling challenges that arise at scale. Leveraging beam steering algorithms, we integrate mmWall into the link layer discovery protocols of common mmWave networks. We have fabricated a 10 cm by 20 cm mmWall prototype consisting of a 28 by 76 unit cell array, and evaluate in indoor, outdoor-to-indoor, and multi-beam scenarios. Indoors, mmWall guarantees 91% of locations outage-free under 128-QAM mmWave data rates and boosts SNR by up to 15 dB. Outdoors, mmWall reduces the probability of complete link failure by a ratio of up to 40% under 0-80% path blockage and boosts SNR by up to 30 dB. ",
    "url": "https://arxiv.org/abs/2209.11554",
    "authors": [
      "Kun Woo Cho",
      "Mohammad H. Mazaheri",
      "Jeremy Gummeson",
      "Omid Abari",
      "Kyle Jamieson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.11559",
    "title": "Query-based Hard-Image Retrieval for Object Detection at Test Time",
    "abstract": "There is a longstanding interest in capturing the error behaviour of object detectors by finding images where their performance is likely to be unsatisfactory. In real-world applications such as autonomous driving, it is also crucial to characterise potential failures beyond simple requirements of detection performance. For example, a missed detection of a pedestrian close to an ego vehicle will generally require closer inspection than a missed detection of a car in the distance. The problem of predicting such potential failures at test time has largely been overlooked in the literature and conventional approaches based on detection uncertainty fall short in that they are agnostic to such fine-grained characterisation of errors. In this work, we propose to reformulate the problem of finding \"hard\" images as a query-based hard image retrieval task, where queries are specific definitions of \"hardness\", and offer a simple and intuitive method that can solve this task for a large family of queries. Our method is entirely post-hoc, does not require ground-truth annotations, is independent of the choice of a detector, and relies on an efficient Monte Carlo estimation that uses a simple stochastic model in place of the ground-truth. We show experimentally that it can be applied successfully to a wide variety of queries for which it can reliably identify hard images for a given detector without any labelled data. We provide results on ranking and classification tasks using the widely used RetinaNet, Faster-RCNN, Mask-RCNN, and Cascade Mask-RCNN object detectors. ",
    "url": "https://arxiv.org/abs/2209.11559",
    "authors": [
      "Edward Ayers",
      "Jonathan Sadeghi",
      "John Redford",
      "Romain Mueller",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11572",
    "title": "Multi-Modal Cross-Domain Alignment Network for Video Moment Retrieval",
    "abstract": "As an increasingly popular task in multimedia information retrieval, video moment retrieval (VMR) aims to localize the target moment from an untrimmed video according to a given language query. Most previous methods depend heavily on numerous manual annotations (i.e., moment boundaries), which are extremely expensive to acquire in practice. In addition, due to the domain gap between different datasets, directly applying these pre-trained models to an unseen domain leads to a significant performance drop. In this paper, we focus on a novel task: cross-domain VMR, where fully-annotated datasets are available in one domain (``source domain''), but the domain of interest (``target domain'') only contains unannotated datasets. As far as we know, we present the first study on cross-domain VMR. To address this new task, we propose a novel Multi-Modal Cross-Domain Alignment (MMCDA) network to transfer the annotation knowledge from the source domain to the target domain. However, due to the domain discrepancy between the source and target domains and the semantic gap between videos and queries, directly applying trained models to the target domain generally leads to a performance drop. To solve this problem, we develop three novel modules: (i) a domain alignment module is designed to align the feature distributions between different domains of each modality; (ii) a cross-modal alignment module aims to map both video and query features into a joint embedding space and to align the feature distributions between different modalities in the target domain; (iii) a specific alignment module tries to obtain the fine-grained similarity between a specific frame and the given query for optimal localization. By jointly training these three modules, our MMCDA can learn domain-invariant and semantic-aligned cross-modal representations. ",
    "url": "https://arxiv.org/abs/2209.11572",
    "authors": [
      "Xiang Fang",
      "Daizong Liu",
      "Pan Zhou",
      "YuChong Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2209.11575",
    "title": "Robot Localization using Situational Graphs and Building Architectural  Plans",
    "abstract": "Robots in the construction industry can reduce costs through constant monitoring of the work progress, using high precision data capturing. Accurate data capturing requires precise localization of the mobile robot within the environment. In this paper we present our novel work on robot localization which extracts geometric, semantic as well as the topological information from the architectural plans in the form of walls and rooms, and creates the topological and metric-semantic layer of the Situational Graphs (S-Graphs) before navigating in the environment. When the robot navigates in the construction environment, it uses the robot odometry and the sensorial observations in the form of planar walls extracted from the 3D lidar measurements, to estimate its pose relying on a particle filter method, by exploiting the previously built situational graph and its available geometric, semantic and topological information. We validate our approach in both simulated and real datasets captured on actual on-going construction sites presenting state-of-the-art results when comparing it against traditional geometry based localization techniques. ",
    "url": "https://arxiv.org/abs/2209.11575",
    "authors": [
      "Muhammad Shaheer",
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.11582",
    "title": "Pose-Aided Video-based Person Re-Identification via Recurrent Graph  Convolutional Network",
    "abstract": "Existing methods for video-based person re-identification (ReID) mainly learn the appearance feature of a given pedestrian via a feature extractor and a feature aggregator. However, the appearance models would fail when different pedestrians have similar appearances. Considering that different pedestrians have different walking postures and body proportions, we propose to learn the discriminative pose feature beyond the appearance feature for video retrieval. Specifically, we implement a two-branch architecture to separately learn the appearance feature and pose feature, and then concatenate them together for inference. To learn the pose feature, we first detect the pedestrian pose in each frame through an off-the-shelf pose detector, and construct a temporal graph using the pose sequence. We then exploit a recurrent graph convolutional network (RGCN) to learn the node embeddings of the temporal pose graph, which devises a global information propagation mechanism to simultaneously achieve the neighborhood aggregation of intra-frame nodes and message passing among inter-frame graphs. Finally, we propose a dual-attention method consisting of node-attention and time-attention to obtain the temporal graph representation from the node embeddings, where the self-attention mechanism is employed to learn the importance of each node and each frame. We verify the proposed method on three video-based ReID datasets, i.e., Mars, DukeMTMC and iLIDS-VID, whose experimental results demonstrate that the learned pose feature can effectively improve the performance of existing appearance models. ",
    "url": "https://arxiv.org/abs/2209.11582",
    "authors": [
      "Honghu Pan",
      "Qiao Liu",
      "Yongyong Chen",
      "Yunqi He",
      "Yuan Zheng",
      "Feng Zheng",
      "Zhenyu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11584",
    "title": "Multi-Granularity Graph Pooling for Video-based Person Re-Identification",
    "abstract": "The video-based person re-identification (ReID) aims to identify the given pedestrian video sequence across multiple non-overlapping cameras. To aggregate the temporal and spatial features of the video samples, the graph neural networks (GNNs) are introduced. However, existing graph-based models, like STGCN, perform the \\textit{mean}/\\textit{max pooling} on node features to obtain the graph representation, which neglect the graph topology and node importance. In this paper, we propose the graph pooling network (GPNet) to learn the multi-granularity graph representation for the video retrieval, where the \\textit{graph pooling layer} is implemented to downsample the graph. We first construct a multi-granular graph, whose node features denote image embedding learned by backbone, and edges are established between the temporal and Euclidean neighborhood nodes. We then implement multiple graph convolutional layers to perform the neighborhood aggregation on the graphs. To downsample the graph, we propose a multi-head full attention graph pooling (MHFAPool) layer, which integrates the advantages of existing node clustering and node selection pooling methods. Specifically, MHFAPool takes the main eigenvector of full attention matrix as the aggregation coefficients to involve the global graph information in each pooled nodes. Extensive experiments demonstrate that our GPNet achieves the competitive results on four widely-used datasets, i.e., MARS, DukeMTMC-VideoReID, iLIDS-VID and PRID-2011. ",
    "url": "https://arxiv.org/abs/2209.11584",
    "authors": [
      "Honghu Pan",
      "Yongyong Chen",
      "Zhenyu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11585",
    "title": "Synthetic Voice Spoofing Detection Based On Online Hard Example Mining",
    "abstract": "The automatic speaker verification spoofing (ASVspoof) challenge series is crucial for enhancing the spoofing consideration and the countermeasures growth. Although the recent ASVspoof 2019 validation results indicate the significant capability to identify most attacks, the model's recognition effect is still poor for some attacks. This paper presents the Online Hard Example Mining (OHEM) algorithm for detecting unknown voice spoofing attacks. The OHEM is utilized to overcome the imbalance between simple and hard samples in the dataset. The presented system provides an equal error rate (EER) of 0.77% on the ASVspoof 2019 Challenge logical access scenario's evaluation set. ",
    "url": "https://arxiv.org/abs/2209.11585",
    "authors": [
      "Ruohua Zhou",
      "Chenlei Hu",
      "Qiuchen Yu",
      "Yuxuan Du"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.11588",
    "title": "Learning Rigid Body Dynamics with Lagrangian Graph Neural Network",
    "abstract": "Lagrangian and Hamiltonian neural networks (LNN and HNN respectively) encode strong inductive biases that allow them to outperform other models of physical systems significantly. However, these models have, thus far, mostly been limited to simple systems such as pendulums and springs or a single rigid body such as a gyroscope or a rigid rotor. Here, we present a Lagrangian graph neural network (LGNN) that can learn the dynamics of rigid bodies by exploiting their topology. We demonstrate the performance of LGNN by learning the dynamics of ropes, chains, and trusses with the bars modeled as rigid bodies. LGNN also exhibits generalizability -- LGNN trained on chains with a few segments exhibits generalizability to simulate a chain with large number of links and arbitrary link length. We also show that the LGNN can simulate unseen hybrid systems including bars and chains, on which they have not been trained on. Specifically, we show that the LGNN can be used to model the dynamics of complex real-world structures such as the stability of tensegrity structures. Finally, we discuss the non-diagonal nature of the mass matrix and it's ability to generalize in complex systems. ",
    "url": "https://arxiv.org/abs/2209.11588",
    "authors": [
      "Ravinder Bhattoo",
      "Sayan Ranu",
      "N. M. Anoop Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11596",
    "title": "Quantification before Selection: Active Dynamics Preference for Robust  Reinforcement Learning",
    "abstract": "Training a robust policy is critical for policy deployment in real-world systems or dealing with unknown dynamics mismatch in different dynamic systems. Domain Randomization~(DR) is a simple and elegant approach that trains a conservative policy to counter different dynamic systems without expert knowledge about the target system parameters. However, existing works reveal that the policy trained through DR tends to be over-conservative and performs poorly in target domains. Our key insight is that dynamic systems with different parameters provide different levels of difficulty for the policy, and the difficulty of behaving well in a system is constantly changing due to the evolution of the policy. If we can actively sample the systems with proper difficulty for the policy on the fly, it will stabilize the training process and prevent the policy from becoming over-conservative or over-optimistic. To operationalize this idea, we introduce Active Dynamics Preference~(ADP), which quantifies the informativeness and density of sampled system parameters. ADP actively selects system parameters with high informativeness and low density. We validate our approach in four robotic locomotion tasks with various discrepancies between the training and testing environments. Extensive results demonstrate that our approach has superior robustness for system inconsistency compared to several baselines. ",
    "url": "https://arxiv.org/abs/2209.11596",
    "authors": [
      "Kang Xu",
      "Yan Ma",
      "Wei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.11604",
    "title": "Neural Clamping: Joint Input Perturbation and Temperature Scaling for  Neural Network Calibration",
    "abstract": "Neural network calibration is an essential task in deep learning to ensure consistency between the confidence of model prediction and the true correctness likelihood. In this paper, we propose a new post-processing calibration method called Neural Clamping, which employs a simple joint input-output transformation on a pre-trained classifier via a learnable universal input perturbation and an output temperature scaling parameter. Moreover, we provide theoretical explanations on why Neural Clamping is provably better than temperature scaling. Evaluated on CIFAR-100 and ImageNet image recognition datasets and a variety of deep neural network models, our empirical results show that Neural Clamping significantly outperforms state-of-the-art post-processing calibration methods. ",
    "url": "https://arxiv.org/abs/2209.11604",
    "authors": [
      "Yung-Chen Tang",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11607",
    "title": "I-SPLIT: Deep Network Interpretability for Split Computing",
    "abstract": "This work makes a substantial step in the field of split computing, i.e., how to split a deep neural network to host its early part on an embedded device and the rest on a server. So far, potential split locations have been identified exploiting uniquely architectural aspects, i.e., based on the layer sizes. Under this paradigm, the efficacy of the split in terms of accuracy can be evaluated only after having performed the split and retrained the entire pipeline, making an exhaustive evaluation of all the plausible splitting points prohibitive in terms of time. Here we show that not only the architecture of the layers does matter, but the importance of the neurons contained therein too. A neuron is important if its gradient with respect to the correct class decision is high. It follows that a split should be applied right after a layer with a high density of important neurons, in order to preserve the information flowing until then. Upon this idea, we propose Interpretable Split (I-SPLIT): a procedure that identifies the most suitable splitting points by providing a reliable prediction on how well this split will perform in terms of classification accuracy, beforehand of its effective implementation. As a further major contribution of I-SPLIT, we show that the best choice for the splitting point on a multiclass categorization problem depends also on which specific classes the network has to deal with. Exhaustive experiments have been carried out on two networks, VGG16 and ResNet-50, and three datasets, Tiny-Imagenet-200, notMNIST, and Chest X-Ray Pneumonia. The source code is available at https://github.com/vips4/I-Split. ",
    "url": "https://arxiv.org/abs/2209.11607",
    "authors": [
      "Federico Cunico",
      "Luigi Capogrosso",
      "Francesco Setti",
      "Damiano Carra",
      "Franco Fummi",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11615",
    "title": "Robust Domain Adaptation for Machine Reading Comprehension",
    "abstract": "Most domain adaptation methods for machine reading comprehension (MRC) use a pre-trained question-answer (QA) construction model to generate pseudo QA pairs for MRC transfer. Such a process will inevitably introduce mismatched pairs (i.e., noisy correspondence) due to i) the unavailable QA pairs in target documents, and ii) the domain shift during applying the QA construction model to the target domain. Undoubtedly, the noisy correspondence will degenerate the performance of MRC, which however is neglected by existing works. To solve such an untouched problem, we propose to construct QA pairs by additionally using the dialogue related to the documents, as well as a new domain adaptation method for MRC. Specifically, we propose Robust Domain Adaptation for Machine Reading Comprehension (RMRC) method which consists of an answer extractor (AE), a question selector (QS), and an MRC model. Specifically, RMRC filters out the irrelevant answers by estimating the correlation to the document via the AE, and extracts the questions by fusing the candidate questions in multiple rounds of dialogue chats via the QS. With the extracted QA pairs, MRC is fine-tuned and provides the feedback to optimize the QS through a novel reinforced self-training method. Thanks to the optimization of the QS, our method will greatly alleviate the noisy correspondence problem caused by the domain shift. To the best of our knowledge, this could be the first study to reveal the influence of noisy correspondence in domain adaptation MRC models and show a feasible way to achieve robustness to mismatched pairs. Extensive experiments on three datasets demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2209.11615",
    "authors": [
      "Liang Jiang",
      "Zhenyu Huang",
      "Jia Liu",
      "Zujie Wen",
      "Xi Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.11617",
    "title": "Linear Clustering Process on Networks",
    "abstract": "We propose a linear clustering process on a network consisting of two opposite forces: attraction and repulsion between adjacent nodes. Each node is mapped to a position on a one-dimensional line. The attraction and repulsion forces move the nodal position on the line, depending on how similar or different the neighbourhoods of two adjacent nodes are. Based on each node position, the number of clusters in a network, together with each node's cluster membership, is estimated. The performance of the proposed linear clustering process is benchmarked on synthetic networks against widely accepted clustering algorithms such as modularity, the Louvain method and the non-back tracking matrix. The proposed linear clustering process outperforms the most popular modularity-based methods, such as the Louvain method, while possessing a comparable computational complexity. ",
    "url": "https://arxiv.org/abs/2209.11617",
    "authors": [
      "Ivan Joki\u0107",
      "Piet Van Mieghem"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2209.11628",
    "title": "A Neural Model for Regular Grammar Induction",
    "abstract": "Grammatical inference is a classical problem in computational learning theory and a topic of wider influence in natural language processing. We treat grammars as a model of computation and propose a novel neural approach to induction of regular grammars from positive and negative examples. Our model is fully explainable, its intermediate results are directly interpretable as partial parses, and it can be used to learn arbitrary regular grammars when provided with sufficient data. Our method consistently attains high recall and precision scores across a range of tests of varying complexity. We make the detailed results and code readily available. ",
    "url": "https://arxiv.org/abs/2209.11628",
    "authors": [
      "Peter Belc\u00e1k",
      "David Hofer",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.11669",
    "title": "Improved Distributed Network Decomposition, Hitting Sets, and Spanners,  via Derandomization",
    "abstract": "This paper presents significantly improved deterministic algorithms for some of the key problems in the area of distributed graph algorithms, including network decomposition, hitting sets, and spanners. As the main ingredient in these results, we develop novel randomized distributed algorithms that we can analyze using only pairwise independence, and we can thus derandomize efficiently. As our most prominent end-result, we obtain a deterministic construction for $O(\\log n)$-color $O(\\log n \\cdot \\log\\log\\log n)$-strong diameter network decomposition in $\\tilde{O}(\\log^3 n)$ rounds. This is the first construction that achieves almost $\\log n$ in both parameters, and it improves on a recent line of exciting progress on deterministic distributed network decompositions [Rozho\\v{n}, Ghaffari STOC'20; Ghaffari, Grunau, Rozho\\v{n} SODA'21; Chang, Ghaffari PODC'21; Elkin, Haeupler, Rozho\\v{n}, Grunau FOCS'22]. ",
    "url": "https://arxiv.org/abs/2209.11669",
    "authors": [
      "Mohsen Ghaffari",
      "Christoph Grunau",
      "Bernhard Haeupler",
      "Saeed Ilchi",
      "V\u00e1clav Rozho\u0148"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2209.11672",
    "title": "MiCellAnnGELo: Annotate microscopy time series of complex cell surfaces  with 3D Virtual Reality",
    "abstract": "Summary: Advances in 3D live cell microscopy are enabling high-resolution capture of previously unobserved processes. Unleashing the power of modern machine learning methods to fully benefit from these technologies is, however, frustrated by the difficulty of manually annotating 3D training data. MiCellAnnGELo virtual reality software offers an immersive environment for viewing and interacting with 4D microscopy data, including efficient tools for annotation. We present tools for labelling cell surfaces with a wide range of applications, including cell motility, endocytosis, and intracellular signalling. Availability and implementation: MiCellAnnGELo employs the cross platform (Mac/Unix/Windows) Unity game engine and is available under the MIT licence at https://github.com/CellDynamics/MiCellAnnGELo.git, together with sample data. MiCellAnnGELo can be run in desktop mode on a 2D screen or in 3D using a standard VR headset with compatible GPU. ",
    "url": "https://arxiv.org/abs/2209.11672",
    "authors": [
      "Adam Platt",
      "E. Josiah Lutton",
      "Till Bretschneider"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2209.11675",
    "title": "An analysis of the Internet of Things in wireless sensor network  technologies",
    "abstract": "Information may be accessed from a distance thanks to computer networks. Wireless or wired networks are also possible. Due to recent developments in wireless infrastructure, wireless sensor networks (WSNs) were developed. Activities or events occurring in the environment are monitored, recorded, and managed by WSN. Through a variety of routing techniques, data relaying is done in these systems. The fourth industrial revolution, or Industry 4.0, is defined as the integration of complex physical automation systems made up of machinery and devices connected by sensors and managed by software. This is done to boost the efficiency and reliability of operations. Industry 4.0 is viewed as a possibility because of industrial IoT, the concept of leveraging IoT technology in manufacturing. delivering, in an industrial setting, a means of connecting engines, power grids, and sensors to the cloud. In this essay, we'll try to comprehend how the Internet of Things (IoT) works in wireless sensor networks and how it might be used in various situations. ",
    "url": "https://arxiv.org/abs/2209.11675",
    "authors": [
      "Harshit Poddar",
      "Vansh Singh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.11677",
    "title": "PNeRF: Probabilistic Neural Scene Representations for Uncertain 3D  Visual Mapping",
    "abstract": "Recently neural scene representations have provided very impressive results for representing 3D scenes visually, however, their study and progress have mainly been limited to visualization of virtual models in computer graphics or scene reconstruction in computer vision without explicitly accounting for sensor and pose uncertainty. Using this novel scene representation in robotics applications, however, would require accounting for this uncertainty in the neural map. The aim of this paper is therefore to propose a novel method for training {\\em probabilistic neural scene representations} with uncertain training data that could enable the inclusion of these representations in robotics applications. Acquiring images using cameras or depth sensors contains inherent uncertainty, and furthermore, the camera poses used for learning a 3D model are also imperfect. If these measurements are used for training without accounting for their uncertainty, then the resulting models are non-optimal, and the resulting scene representations are likely to contain artifacts such as blur and un-even geometry. In this work, the problem of uncertainty integration to the learning process is investigated by focusing on training with uncertain information in a probabilistic manner. The proposed method involves explicitly augmenting the training likelihood with an uncertainty term such that the learnt probability distribution of the network is minimized with respect to the training uncertainty. It will be shown that this leads to more accurate image rendering quality, in addition to more precise and consistent geometry. Validation has been carried out on both synthetic and real datasets showing that the proposed approach outperforms state-of-the-art methods. The results show notably that the proposed method is capable of rendering novel high-quality views even when the training data is limited. ",
    "url": "https://arxiv.org/abs/2209.11677",
    "authors": [
      "Yassine Ahmine",
      "Arnab Dey",
      "Andrew I. Comport"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11680",
    "title": "An Overview of Violence Detection Techniques: Current Challenges and  Future Directions",
    "abstract": "The Big Video Data generated in today's smart cities has raised concerns from its purposeful usage perspective, where surveillance cameras, among many others are the most prominent resources to contribute to the huge volumes of data, making its automated analysis a difficult task in terms of computation and preciseness. Violence Detection (VD), broadly plunging under Action and Activity recognition domain, is used to analyze Big Video data for anomalous actions incurred due to humans. The VD literature is traditionally based on manually engineered features, though advancements to deep learning based standalone models are developed for real-time VD analysis. This paper focuses on overview of deep sequence learning approaches along with localization strategies of the detected violence. This overview also dives into the initial image processing and machine learning-based VD literature and their possible advantages such as efficiency against the current complex models. Furthermore,the datasets are discussed, to provide an analysis of the current models, explaining their pros and cons with future directions in VD domain derived from an in-depth analysis of the previous methods. ",
    "url": "https://arxiv.org/abs/2209.11680",
    "authors": [
      "Nadia Mumtaz",
      "Naveed Ejaz",
      "Shabana Habib",
      "Syed Muhammad Mohsin",
      "Prayag Tiwari",
      "Shahab S. Band",
      "Neeraj Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11682",
    "title": "Meteorological Satellite Images Prediction Based on Deep Multi-scales  Extrapolation Fusion",
    "abstract": "Meteorological satellite imagery is critical for meteorologists. The data have played an important role in monitoring and analyzing weather and climate changes. However, satellite imagery is a kind of observation data and exists a significant time delay when transmitting the data back to Earth. It is important to make accurate predictions for meteorological satellite images, especially the nowcasting prediction up to 2 hours ahead. In recent years, there has been growing interest in the research of nowcasting prediction applications of weather radar images based on deep learning. Compared to the weather radar images prediction problem, the main challenge for meteorological satellite images prediction is the large-scale observation areas and therefore the large sizes of the observation products. Here we present a deep multi-scales extrapolation fusion method, to address the challenge of the meteorological satellite images nowcasting prediction. First, we downsample the original satellite images dataset with large size to several images datasets with smaller resolutions, then we use a deep spatiotemporal sequences prediction method to generate the multi-scales prediction images with different resolutions separately. Second, we fuse the multi-scales prediction results to the targeting prediction images with the original size by a conditional generative adversarial network. The experiments based on the FY-4A meteorological satellite data show that the proposed method can generate realistic prediction images that effectively capture the evolutions of the weather systems in detail. We believe that the general idea of this work can be potentially applied to other spatiotemporal sequence prediction tasks with a large size. ",
    "url": "https://arxiv.org/abs/2209.11682",
    "authors": [
      "Fang Huang",
      "Wencong Cheng",
      "PanFeng Wang",
      "ZhiGang Wang",
      "HongHong He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.11693",
    "title": "T3VIP: Transformation-based 3D Video Prediction",
    "abstract": "For autonomous skill acquisition, robots have to learn about the physical rules governing the 3D world dynamics from their own past experience to predict and reason about plausible future outcomes. To this end, we propose a transformation-based 3D video prediction (T3VIP) approach that explicitly models the 3D motion by decomposing a scene into its object parts and predicting their corresponding rigid transformations. Our model is fully unsupervised, captures the stochastic nature of the real world, and the observational cues in image and point cloud domains constitute its learning signals. To fully leverage all the 2D and 3D observational signals, we equip our model with automatic hyperparameter optimization (HPO) to interpret the best way of learning from them. To the best of our knowledge, our model is the first generative model that provides an RGB-D video prediction of the future for a static camera. Our extensive evaluation with simulated and real-world datasets demonstrates that our formulation leads to interpretable 3D models that predict future depth videos while achieving on-par performance with 2D models on RGB video prediction. Moreover, we demonstrate that our model outperforms 2D baselines on visuomotor control. Videos, code, dataset, and pre-trained models are available at this http URL ",
    "url": "https://arxiv.org/abs/2209.11693",
    "authors": [
      "Iman Nematollahi",
      "Erick Rosete-Beas",
      "Seyed Mahdi B. Azad",
      "Raghu Rajan",
      "Frank Hutter",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.11697",
    "title": "Edge-oriented Implicit Neural Representation with Channel Tuning",
    "abstract": "Implicit neural representation, which expresses an image as a continuous function rather than a discrete grid form, is widely used for image processing. Despite its outperforming results, there are still remaining limitations on restoring clear shapes of a given signal such as the edges of an image. In this paper, we propose Gradient Magnitude Adjustment algorithm which calculates the gradient of an image for training the implicit representation. In addition, we propose Edge-oriented Representation Network (EoREN) that can reconstruct the image with clear edges by fitting gradient information (Edge-oriented module). Furthermore, we add Channel-tuning module to adjust the distribution of given signals so that it solves a chronic problem of fitting gradients. By separating backpropagation paths of the two modules, EoREN can learn true color of the image without hindering the role for gradients. We qualitatively show that our model can reconstruct complex signals and demonstrate general reconstruction ability of our model with quantitative results. ",
    "url": "https://arxiv.org/abs/2209.11697",
    "authors": [
      "Wonjoon Chang",
      "Dahee Kwon",
      "Bumjin Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11708",
    "title": "Multilevel Robustness for 2D Vector Field Feature Tracking, Selection,  and Comparison",
    "abstract": "Critical point tracking is a core topic in scientific visualization for understanding the dynamic behavior of time-varying vector field data. The topological notion of robustness has been introduced recently to quantify the structural stability of critical points, that is, the robustness of a critical point is the minimum amount of perturbation to the vector field necessary to cancel it. A theoretical basis has been established previously that relates critical point tracking with the notion of robustness, in particular, critical points could be tracked based on their closeness in stability, measured by robustness, instead of just distance proximities within the domain. However, in practice, the computation of classic robustness may produce artifacts when a critical point is close to the boundary of the domain; thus, we do not have a complete picture of the vector field behavior within its local neighborhood. To alleviate these issues, we introduce a multilevel robustness framework for the study of 2D time-varying vector fields. We compute the robustness of critical points across varying neighborhoods to capture the multiscale nature of the data and to mitigate the boundary effect suffered by the classic robustness computation. We demonstrate via experiments that such a new notion of robustness can be combined seamlessly with existing feature tracking algorithms to improve the visual interpretability of vector fields in terms of feature tracking, selection, and comparison for large-scale scientific simulations. We observe, for the first time, that the minimum multilevel robustness is highly correlated with physical quantities used by domain scientists in studying a real-world tropical cyclone dataset. Such observation helps to increase the physical interpretability of robustness. ",
    "url": "https://arxiv.org/abs/2209.11708",
    "authors": [
      "Lin Yan",
      "Paul Aaron Ullrich",
      "Luke P. Van Roekel",
      "Bei Wang",
      "Hanqi Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11713",
    "title": "Robust adaptive MPC using control contraction metrics",
    "abstract": "We present a robust adaptive model predictive control (MPC) framework for nonlinear continuous-time systems with bounded parametric uncertainty and additive disturbance. We utilize general control contraction metrics (CCMs) to parameterize a homothetic tube around a nominal prediction that contains all uncertain trajectories. Furthermore, we incorporate model adaptation using set-membership estimation. As a result, the proposed MPC formulation is applicable to a large class of nonlinear systems, reduces conservatism during online operation, and guarantees robust constraint satisfaction and convergence to a neighborhood of the desired setpoint. One of the main technical contributions is the derivation of corresponding tube dynamics based on CCMs that account for the state and input dependent nature of the model mismatch. Furthermore, we online optimize over the nominal parameter, which enables general set-membership updates for the parametric uncertainty in the MPC. Benefits of the proposed homothetic tube MPC and online adaptation are demonstrated using a numerical example involving a planar quadrotor. ",
    "url": "https://arxiv.org/abs/2209.11713",
    "authors": [
      "Andr\u00e1s Sasfi",
      "Melanie N. Zeilinger",
      "Johannes K\u00f6hler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.11715",
    "title": "The \"Beatrix'' Resurrections: Robust Backdoor Detection via Gram  Matrices",
    "abstract": "Deep Neural Networks (DNNs) are susceptible to backdoor attacks during training. The model corrupted in this way functions normally, but when triggered by certain patterns in the input, produces a predefined target label. Existing defenses usually rely on the assumption of the universal backdoor setting in which poisoned samples share the same uniform trigger. However, recent advanced backdoor attacks show that this assumption is no longer valid in dynamic backdoors where the triggers vary from input to input, thereby defeating the existing defenses. In this work, we propose a novel technique, Beatrix (backdoor detection via Gram matrix). Beatrix utilizes Gram matrix to capture not only the feature correlations but also the appropriately high-order information of the representations. By learning class-conditional statistics from activation patterns of normal samples, Beatrix can identify poisoned samples by capturing the anomalies in activation patterns. To further improve the performance in identifying target labels, Beatrix leverages kernel-based testing without making any prior assumptions on representation distribution. We demonstrate the effectiveness of our method through extensive evaluation and comparison with state-of-the-art defensive techniques. The experimental results show that our approach achieves an F1 score of 91.1% in detecting dynamic backdoors, while the state of the art can only reach 36.9%. ",
    "url": "https://arxiv.org/abs/2209.11715",
    "authors": [
      "Wanlun Ma",
      "Derui Wang",
      "Ruoxi Sun",
      "Minhui Xue",
      "Sheng Wen",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11727",
    "title": "Boost CTR Prediction for New Advertisements via Modeling Visual Content",
    "abstract": "Existing advertisements click-through rate (CTR) prediction models are mainly dependent on behavior ID features, which are learned based on the historical user-ad interactions. Nevertheless, behavior ID features relying on historical user behaviors are not feasible to describe new ads without previous interactions with users. To overcome the limitations of behavior ID features in modeling new ads, we exploit the visual content in ads to boost the performance of CTR prediction models. Specifically, we map each ad into a set of visual IDs based on its visual content. These visual IDs are further used for generating the visual embedding for enhancing CTR prediction models. We formulate the learning of visual IDs into a supervised quantization problem. Due to a lack of class labels for commercial images in advertisements, we exploit image textual descriptions as the supervision to optimize the image extractor for generating effective visual IDs. Meanwhile, since the hard quantization is non-differentiable, we soften the quantization operation to make it support the end-to-end network training. After mapping each image into visual IDs, we learn the embedding for each visual ID based on the historical user-ad interactions accumulated in the past. Since the visual ID embedding depends only on the visual content, it generalizes well to new ads. Meanwhile, the visual ID embedding complements the ad behavior ID embedding. Thus, it can considerably boost the performance of the CTR prediction models previously relying on behavior ID features for both new ads and ads that have accumulated rich user behaviors. After incorporating the visual ID embedding in the CTR prediction model of Baidu online advertising, the average CTR of ads improves by 1.46%, and the total charge increases by 1.10%. ",
    "url": "https://arxiv.org/abs/2209.11727",
    "authors": [
      "Tan Yu",
      "Zhipeng Jin",
      "Jie Liu",
      "Yi Yang",
      "Hongliang Fei",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11739",
    "title": "Catoptric Light can be Dangerous: Effective Physical-World Attack by  Natural Phenomenon",
    "abstract": "Deep neural networks (DNNs) have achieved great success in many tasks. Therefore, it is crucial to evaluate the robustness of advanced DNNs. The traditional methods use stickers as physical perturbations to fool the classifiers, which is difficult to achieve stealthiness and there exists printing loss. Some new types of physical attacks use light beam to perform attacks (e.g., laser, projector), whose optical patterns are artificial rather than natural. In this work, we study a new type of physical attack, called adversarial catoptric light (AdvCL), in which adversarial perturbations are generated by common natural phenomena, catoptric light, to achieve stealthy and naturalistic adversarial attacks against advanced DNNs in physical environments. Carefully designed experiments demonstrate the effectiveness of the proposed method in simulated and real-world environments. The attack success rate is 94.90% in a subset of ImageNet and 83.50% in the real-world environment. We also discuss some of AdvCL's transferability and defense strategy against this attack. ",
    "url": "https://arxiv.org/abs/2209.11739",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11740",
    "title": "On the Shift Invariance of Max Pooling Feature Maps in Convolutional  Neural Networks",
    "abstract": "In this paper, we aim to improve the mathematical interpretability of convolutional neural networks for image classification. When trained on natural image datasets, such networks tend to learn parameters in the first layer that closely resemble oriented Gabor filters. By leveraging the properties of discrete Gabor-like convolutions, we prove that, under specific conditions, feature maps computed by the subsequent max pooling operator tend to approximate the modulus of complex Gabor-like coefficients, and as such, are stable with respect to certain input shifts. We then compute a probabilistic measure of shift invariance for these layers. More precisely, we show that some filters, depending on their frequency and orientation, are more likely than others to produce stable image representations. We experimentally validate our theory by considering a deterministic feature extractor based on the dual-tree wavelet packet transform, a particular case of discrete Gabor-like decomposition. We demonstrate a strong correlation between shift invariance on the one hand and similarity with complex modulus on the other hand. ",
    "url": "https://arxiv.org/abs/2209.11740",
    "authors": [
      "Hubert Leterme",
      "K\u00e9vin Polisano",
      "Val\u00e9rie Perrier",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.11741",
    "title": "Adaptive-SpikeNet: Event-based Optical Flow Estimation using Spiking  Neural Networks with Learnable Neuronal Dynamics",
    "abstract": "Event-based cameras have recently shown great potential for high-speed motion estimation owing to their ability to capture temporally rich information asynchronously. Spiking Neural Networks (SNNs), with their neuro-inspired event-driven processing can efficiently handle such asynchronous data, while neuron models such as the leaky-integrate and fire (LIF) can keep track of the quintessential timing information contained in the inputs. SNNs achieve this by maintaining a dynamic state in the neuron memory, retaining important information while forgetting redundant data over time. Thus, we posit that SNNs would allow for better performance on sequential regression tasks compared to similarly sized Analog Neural Networks (ANNs). However, deep SNNs are difficult to train due to vanishing spikes at later layers. To that effect, we propose an adaptive fully-spiking framework with learnable neuronal dynamics to alleviate the spike vanishing problem. We utilize surrogate gradient-based backpropagation through time (BPTT) to train our deep SNNs from scratch. We validate our approach for the task of optical flow estimation on the Multi-Vehicle Stereo Event-Camera (MVSEC) dataset and the DSEC-Flow dataset. Our experiments on these datasets show an average reduction of 13% in average endpoint error (AEE) compared to state-of-the-art ANNs. We also explore several down-scaled models and observe that our SNN models consistently outperform similarly sized ANNs offering 10%-16% lower AEE. These results demonstrate the importance of SNNs for smaller models and their suitability at the edge. In terms of efficiency, our SNNs offer substantial savings in network parameters (48x) and computational energy (51x) while attaining ~10% lower EPE compared to the state-of-the-art ANN implementations. ",
    "url": "https://arxiv.org/abs/2209.11741",
    "authors": [
      "Adarsh Kumar Kosta",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11746",
    "title": "Evaluating Agent Interactions Through Episodic Knowledge Graphs",
    "abstract": "We present a new method based on episodic Knowledge Graphs (eKGs) for evaluating (multimodal) conversational agents in open domains. This graph is generated by interpreting raw signals during conversation and is able to capture the accumulation of knowledge over time. We apply structural and semantic analysis of the resulting graphs and translate the properties into qualitative measures. We compare these measures with existing automatic and manual evaluation metrics commonly used for conversational agents. Our results show that our Knowledge-Graph-based evaluation provides more qualitative insights into interaction and the agent's behavior. ",
    "url": "https://arxiv.org/abs/2209.11746",
    "authors": [
      "Selene B\u00e1ez Santamar\u00eda",
      "Piek Vossen",
      "Thomas Baier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11232",
    "title": "Hierarchical Graph Convolutional Network Built by Multiscale Atlases for  Brain Disorder Diagnosis Using Functional Connectivity",
    "abstract": "Functional connectivity network (FCN) data from functional magnetic resonance imaging (fMRI) is increasingly used for the diagnoses of brain disorders. However, state-of-the-art studies used to build the FCN using a single brain parcellation atlas at a certain spatial scale, which largely neglected functional interactions across different spatial scales in hierarchical manners. In this study, we propose a novel framework to perform multiscale FCN analysis for brain disorder diagnosis. We first use a set of well-defined multiscale atlases to compute multiscale FCNs. Then, we utilize biologically meaningful brain hierarchical relationships among the regions in multiscale atlases to perform nodal pooling across multiple spatial scales, namely \"Atlas-guided Pooling\". Accordingly, we propose a Multiscale-Atlases-based Hierarchical Graph Convolutional Network (MAHGCN), built on the stacked layers of graph convolution and the atlas-guided pooling, for a comprehensive extraction of diagnostic information from multiscale FCNs. Experiments on neuroimaging data from 1792 subjects demonstrate the effectiveness of our proposed method in the diagnoses of Alzheimer's disease (AD), the prodromal stage of AD (i.e., mild cognitive impairment [MCI]), as well as autism spectrum disorder (ASD), with accuracy of 88.9%, 78.6%, and 72.7% respectively. All results show significant advantages of our proposed method over other competing methods. This study not only demonstrates the feasibility of brain disorder diagnosis using resting-state fMRI empowered by deep learning, but also highlights that the functional interactions in the multiscale brain hierarchy are worth being explored and integrated into deep learning network architectures for better understanding the neuropathology of brain disorders. ",
    "url": "https://arxiv.org/abs/2209.11232",
    "authors": [
      "Mianxin Liu",
      "Han Zhang",
      "Feng Shi",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2209.11233",
    "title": "Assessing Robustness of EEG Representations under Data-shifts via Latent  Space and Uncertainty Analysis",
    "abstract": "The recent availability of large datasets in bio-medicine has inspired the development of representation learning methods for multiple healthcare applications. Despite advances in predictive performance, the clinical utility of such methods is limited when exposed to real-world data. Here we develop model diagnostic measures to detect potential pitfalls during deployment without assuming access to external data. Specifically, we focus on modeling realistic data shifts in electrophysiological signals (EEGs) via data transforms, and extend the conventional task-based evaluations with analyses of a) model's latent space and b) predictive uncertainty, under these transforms. We conduct experiments on multiple EEG feature encoders and two clinically relevant downstream tasks using publicly available large-scale clinical EEGs. Within this experimental setting, our results suggest that measures of latent space integrity and model uncertainty under the proposed data shifts may help anticipate performance degradation during deployment. ",
    "url": "https://arxiv.org/abs/2209.11233",
    "authors": [
      "Neeraj Wagh",
      "Jionghao Wei",
      "Samarth Rawal",
      "Brent M. Berry",
      "Yogatheesan Varatharajah"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11282",
    "title": "Automated detection of Alzheimer disease using MRI images and deep  neural networks- A review",
    "abstract": "Early detection of Alzheimer disease is crucial for deploying interventions and slowing the disease progression. A lot of machine learning and deep learning algorithms have been explored in the past decade with the aim of building an automated detection for Alzheimer. Advancements in data augmentation techniques and advanced deep learning architectures have opened up new frontiers in this field, and research is moving at a rapid speed. Hence, the purpose of this survey is to provide an overview of recent research on deep learning models for Alzheimer disease diagnosis. In addition to categorizing the numerous data sources, neural network architectures, and commonly used assessment measures, we also classify implementation and reproducibility. Our objective is to assist interested researchers in keeping up with the newest developments and in reproducing earlier investigations as benchmarks. In addition, we also indicate future research directions for this topic. ",
    "url": "https://arxiv.org/abs/2209.11282",
    "authors": [
      "Narotam Singh",
      "Patteshwari.D",
      "Neha Soni",
      "Amita Kapoor"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11418",
    "title": "Guaranteed Privacy of Distributed Nonconvex Optimization via  Mixed-Monotone Functional Perturbations",
    "abstract": "In this paper, we introduce a new notion of guaranteed privacy that requires that the change of the range of the corresponding inclusion function to the true function is small. In particular, leveraging mixed-monotone inclusion functions, we propose a privacy-preserving mechanism for nonconvex distributed optimization, which is based on deterministic, but unknown, affine perturbation of the local objective functions, which is stronger than probabilistic differential privacy. The design requires a robust optimization method to characterize the best accuracy that can be achieved by an optimal perturbation. Subsequently, this is used to guide the refinement of a guaranteed-private perturbation mechanism that can achieve a quantifiable accuracy via a theoretical upper bound that is shown to be independent of the chosen optimization algorithm. ",
    "url": "https://arxiv.org/abs/2209.11418",
    "authors": [
      "Mohammad Khajenejad",
      "Sonia Martinez"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.11452",
    "title": "From String Detection to Orthogonal Vector Problem",
    "abstract": "Considering Grover's Search Algorithm (GSA) with the standard diffuser stage applied, we revisit the $3$-qubit unique String Detection Problem (SDP) and extend the algorithm to $4$-qubit SDP with multiple winners. We then investigate unstructured search problems with non-uniform distributions and define the Orthogonal Vector Problem (OVP) under quantum settings. Although no numerically stable results is reached under the original GSA framework, we provide intuition behind our implementation and further observations on OVP. We further perform a special case analysis under the modified GSA framework which aims to stabilize the final measurement under arbitrary initial distribution. Based on the result of the analysis, we generalize the initial condition under which neither the original framework nor the modification works. Instead of utilizing GSA, we also propose a short-depth circuit that can calculate the orthogonal pair for a given vector represented as a binary string with constant runtime. ",
    "url": "https://arxiv.org/abs/2209.11452",
    "authors": [
      "Yunhao Wang",
      "Tianyuan Zheng",
      "Lior Horesh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2209.11456",
    "title": "Segmentation-based Information Extraction and Amalgamation in Fundus  Images for Glaucoma Detection",
    "abstract": "Glaucoma is a severe blinding disease, for which automatic detection methods are urgently needed to alleviate the scarcity of ophthalmologists. Many works have proposed to employ deep learning methods that involve the segmentation of optic disc and cup for glaucoma detection, in which the segmentation process is often considered merely as an upstream sub-task. The relationship between fundus images and segmentation masks in terms of joint decision-making in glaucoma assessment is rarely explored. We propose a novel segmentation-based information extraction and amalgamation method for the task of glaucoma detection, which leverages the robustness of segmentation masks without disregarding the rich information in the original fundus images. Experimental results on both private and public datasets demonstrate that our proposed method outperforms all models that utilize solely either fundus images or masks. ",
    "url": "https://arxiv.org/abs/2209.11456",
    "authors": [
      "Yanni Wang",
      "Gang Yang",
      "Dayong Ding",
      "Jianchun Zao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11520",
    "title": "Power Management in Smart Residential Building with Deep Learning Model  for Occupancy Detection by Usage Pattern of Electric Appliances",
    "abstract": "With the growth of smart building applications, occupancy information in residential buildings is becoming more and more significant. In the context of the smart buildings' paradigm, this kind of information is required for a wide range of purposes, including enhancing energy efficiency and occupant comfort. In this study, occupancy detection in residential building is implemented using deep learning based on technical information of electric appliances. To this end, a novel approach of occupancy detection for smart residential building system is proposed. The dataset of electric appliances, sensors, light, and HVAC, which is measured by smart metering system and is collected from 50 households, is used for simulations. To classify the occupancy among datasets, the support vector machine and autoencoder algorithm are used. Confusion matrix is utilized for accuracy, precision, recall, and F1 to demonstrate the comparative performance of the proposed method in occupancy detection. The proposed algorithm achieves occupancy detection using technical information of electric appliances by 95.7~98.4%. To validate occupancy detection data, principal component analysis and the t-distributed stochastic neighbor embedding (t-SNE) algorithm are employed. Power consumption with renewable energy system is reduced to 11.1~13.1% in smart buildings by using occupancy detection. ",
    "url": "https://arxiv.org/abs/2209.11520",
    "authors": [
      "Sangkeum Lee",
      "Sarvar Hussain Nengroo",
      "Hojun Jin",
      "Yoonmee Doh",
      "Chungho Lee",
      "Taewook Heo",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11522",
    "title": "Small coverage effect in epidemic network models shows that masks can  become more effective with less people wearing them",
    "abstract": "The effectiveness of non-pharmaceutical interventions to curb the spread of SARS-CoV-2 is determined by numerous contextual factors, including adherence. Conventional wisdom holds that the effectiveness of protective behaviour such as wearing masks always increases with the number of people adopting it. Here we show in a simulation study that this is not true in general. We employ a parsimonious network model based on the well-established empirical facts that (i) adherence to such interventions wanes over time and (ii) individuals tend to align their adoption strategies with their close social ties (homophily). When combining these assumptions, a broad dynamical regime emerges where the individual-level infection risk reduction for those adopting protective behaviour increases as the adherence to protective behavior decreases. For instance, for a protective coverage of 10% we find the infection risk for adopting individuals can be reduced by close to 30% compared to situations where the coverage is 60%. Using estimates for the effectiveness of surgical masks, we find that reductions in relative risk of masking versus non-masking individuals range between 5% and 15%, i.e., vary by a factor of three. This small coverage effect originates from system-dynamical network properties that conspire to increase the chance that an outbreak will be over before the pathogen is able to invade small but tightly connected groups of individuals that protect themselves. Our results contradict the popular belief that masking becomes ineffectual as more people drop their masks and might have far-reaching implications for the protection of vulnerable population groups under resurgent infection waves. ",
    "url": "https://arxiv.org/abs/2209.11522",
    "authors": [
      "Peter Klimek",
      "Katharina Ledebur",
      "Stefan Thurner"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.11531",
    "title": "Deep Learning-based Anonymization of Chest Radiographs: A  Utility-preserving Measure for Patient Privacy",
    "abstract": "Robust and reliable anonymization of chest radiographs constitutes an essential step before publishing large datasets of such for research purposes. The conventional anonymization process is carried out by obscuring personal information in the images with black boxes and removing or replacing meta-information. However, such simple measures retain biometric information in the chest radiographs, allowing patients to be re-identified by a linkage attack. Therefore, we see an urgent need to obfuscate the biometric information appearing in the images. To the best of our knowledge, we propose the first deep learning-based approach to targetedly anonymize chest radiographs while maintaining data utility for diagnostic and machine learning purposes. Our model architecture is a composition of three independent neural networks that, when collectively used, allow for learning a deformation field that is able to impede patient re-identification. The individual influence of each component is investigated with an ablation study. Quantitative results on the ChestX-ray14 dataset show a reduction of patient re-identification from 81.8% to 58.6% in the area under the receiver operating characteristic curve (AUC) with little impact on the abnormality classification performance. This indicates the ability to preserve underlying abnormality patterns while increasing patient privacy. Furthermore, we compare the proposed deep learning-based anonymization approach with differentially private image pixelization, and demonstrate the superiority of our method towards resolving the privacy-utility trade-off for chest radiographs. ",
    "url": "https://arxiv.org/abs/2209.11531",
    "authors": [
      "Kai Packh\u00e4user",
      "Sebastian G\u00fcndel",
      "Florian Thamm",
      "Felix Denzinger",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11537",
    "title": "Planar graph with twin-width seven",
    "abstract": "We construct a planar graph with twin-width equal to seven. ",
    "url": "https://arxiv.org/abs/2209.11537",
    "authors": [
      "Daniel Kral",
      "Ander Lamaison"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2209.11638",
    "title": "GSP-Based MAP Estimation of Graph Signals",
    "abstract": "In this paper, we consider the problem of recovering random graph signals from nonlinear measurements. We formulate the maximum a-posteriori probability (MAP) estimator, which results in a nonconvex optimization problem. Conventional iterative methods for minimizing nonconvex problems are sensitive to the initialization, have high computational complexity, and do not utilize the underlying graph structure behind the data. In this paper we propose two new estimators that are both based on the Gauss-Newton method: 1) the elementwise graph-frequency-domain MAP (eGFD-MAP) estimator; and 2) the graph signal processing MAP (GSP-MAP) estimator. At each iteration, these estimators are updated by the outputs of two graph filters, with the previous state estimator and the residual as the input graph signals. The eGFD-MAP estimator is an ad-hoc method that minimizes the MAP objective function in the graph frequency domain and neglects mixed-derivatives of different graph frequencies in the Jacobian matrix as well as off-diagonal elements in the covariance matrices. Consequently, it updates the elements of the graph signal independently, which reduces the computational complexity compared to the conventional MAP estimator. The GSP-MAP estimator is based on optimizing the graph filters at each iteration of the Gauss-Newton algorithm. We state conditions under which the eGFD-MAP and GSP- MAP estimators coincide with the MAP estimator, in the case of an observation model with orthogonal graph frequencies. We evaluate the performance of the estimators for nonlinear graph signal recovery tasks with synthetic data and with the real-world problem of state estimation in power systems. These simulations show the advantages of the proposed estimators in terms of computational complexity, mean-squared-error, and robustness to the initialization of the iterative algorithms. ",
    "url": "https://arxiv.org/abs/2209.11638",
    "authors": [
      "Guy Sagi",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2209.11661",
    "title": "Exact conservation laws for neural network integrators of dynamical  systems",
    "abstract": "The solution of time dependent differential equations with neural networks has attracted a lot of attention recently. The central idea is to learn the laws that govern the evolution of the solution from data, which might be polluted with random noise. However, in contrast to other machine learning applications, usually a lot is known about the system at hand. For example, for many dynamical systems physical quantities such as energy or (angular) momentum are exactly conserved. Hence, the neural network has to learn these conservation laws from data and they will only be satisfied approximately due to finite training time and random noise. In this paper we present an alternative approach which uses Noether's Theorem to inherently incorporate conservation laws into the architecture of the neural network. We demonstrate that this leads to better predictions for three model systems: the motion of a non-relativistic particle in a three-dimensional Newtonian gravitational potential, the motion of a massive relativistic particle in the Schwarzschild metric and a system of two interacting particles in four dimensions. ",
    "url": "https://arxiv.org/abs/2209.11661",
    "authors": [
      "Eike Hermann M\u00fcller"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2209.11729",
    "title": "Dual-Cycle: Self-Supervised Dual-View Fluorescence Microscopy Image  Reconstruction using CycleGAN",
    "abstract": "Three-dimensional fluorescence microscopy often suffers from anisotropy, where the resolution along the axial direction is lower than that within the lateral imaging plane. We address this issue by presenting Dual-Cycle, a new framework for joint deconvolution and fusion of dual-view fluorescence images. Inspired by the recent Neuroclear method, Dual-Cycle is designed as a cycle-consistent generative network trained in a self-supervised fashion by combining a dual-view generator and prior-guided degradation model. We validate Dual-Cycle on both synthetic and real data showing its state-of-the-art performance without any external training data. ",
    "url": "https://arxiv.org/abs/2209.11729",
    "authors": [
      "Tomas Kerepecky",
      "Jiaming Liu",
      "Xue Wen Ng",
      "David W. Piston",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2001.01456",
    "title": "Facial Emotions Recognition using Convolutional Neural Net",
    "abstract": " Comments: 6 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2001.01456",
    "authors": [
      "Faisal Ghaffar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2005.00611",
    "title": "Neural Lyapunov Control",
    "abstract": " Comments: NeurIPS 2019 ",
    "url": "https://arxiv.org/abs/2005.00611",
    "authors": [
      "Ya-Chien Chang",
      "Nima Roohi",
      "Sicun Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.00029",
    "title": "Monitoring the edges of a graph using distances",
    "abstract": " Comments: 19 pages; 5 figures. A preliminary version appeared in the proceedings of CALDAM 2020 ",
    "url": "https://arxiv.org/abs/2011.00029",
    "authors": [
      "Florent Foucaud",
      "Shih-Shun Kao",
      "Ralf Klasing",
      "Mirka Miller",
      "Joe Ryan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2102.09544",
    "title": "Combinatorial optimization and reasoning with graph neural networks",
    "abstract": " Title: Combinatorial optimization and reasoning with graph neural networks ",
    "url": "https://arxiv.org/abs/2102.09544",
    "authors": [
      "Quentin Cappart",
      "Didier Ch\u00e9telat",
      "Elias Khalil",
      "Andrea Lodi",
      "Christopher Morris",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2105.12033",
    "title": "TNet: A Model-Constrained Tikhonov Network Approach for Inverse Problems",
    "abstract": " Title: TNet: A Model-Constrained Tikhonov Network Approach for Inverse Problems ",
    "url": "https://arxiv.org/abs/2105.12033",
    "authors": [
      "Hai V. Nguyen",
      "Tan Bui-Thanh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2106.08746",
    "title": "Real-time Adversarial Perturbations against Deep Reinforcement Learning  Policies: Attacks and Defenses",
    "abstract": " Comments: Will appear in the proceedings of ESORICS 2022; 13 pages, 6 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2106.08746",
    "authors": [
      "Buse G. A. Tekgul",
      "Shelly Wang",
      "Samuel Marchal",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.13543",
    "title": "A Variance-aware Multiobjective Louvain-like Method for Community  Detection in Multiplex Networks",
    "abstract": " Title: A Variance-aware Multiobjective Louvain-like Method for Community  Detection in Multiplex Networks ",
    "url": "https://arxiv.org/abs/2106.13543",
    "authors": [
      "Sara Venturini",
      "Andrea Cristofari",
      "Francesco Rinaldi",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2107.01873",
    "title": "Detecting Concept Drift With Neural Network Model Uncertainty",
    "abstract": " Title: Detecting Concept Drift With Neural Network Model Uncertainty ",
    "url": "https://arxiv.org/abs/2107.01873",
    "authors": [
      "Lucas Baier",
      "Tim Schl\u00f6r",
      "Jakob Sch\u00f6ffer",
      "Niklas K\u00fchl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.00452",
    "title": "Self-supervised Point Cloud Representation Learning via Separating Mixed  Shapes",
    "abstract": " Title: Self-supervised Point Cloud Representation Learning via Separating Mixed  Shapes ",
    "url": "https://arxiv.org/abs/2109.00452",
    "authors": [
      "Chao Sun",
      "Zhedong Zheng",
      "Xiaohan Wang",
      "Mingliang Xu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12338",
    "title": "Distribution-sensitive Information Retention for Accurate Binary Neural  Network",
    "abstract": " Title: Distribution-sensitive Information Retention for Accurate Binary Neural  Network ",
    "url": "https://arxiv.org/abs/2109.12338",
    "authors": [
      "Haotong Qin",
      "Xiangguo Zhang",
      "Ruihao Gong",
      "Yifu Ding",
      "Yi Xu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.10934",
    "title": "Privacy-preserving Federated Adversarial Domain Adaption over Feature  Groups for Interpretability",
    "abstract": " Comments: Published in IEEE Transactions on Big Data ",
    "url": "https://arxiv.org/abs/2111.10934",
    "authors": [
      "Yan Kang",
      "Yang Liu",
      "Yuezhou Wu",
      "Guoqiang Ma",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01261",
    "title": "ViF-SD2E: A Robust Weakly-Supervised Method for Neural Decoding",
    "abstract": " Comments: 13 pages, 9 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2112.01261",
    "authors": [
      "Jingyi Feng",
      "Yong Luo",
      "Shuang Song"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.01465",
    "title": "Unifying information propagation models on networks and influence  maximization",
    "abstract": " Comments: 28 pages, 22 figures ",
    "url": "https://arxiv.org/abs/2112.01465",
    "authors": [
      "Yu Tian",
      "Renaud Lambiotte"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2112.09542",
    "title": "A Formal Model for Polarization under Confirmation Bias in Social  Networks",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2104.11538, arXiv:2012.02703 ",
    "url": "https://arxiv.org/abs/2112.09542",
    "authors": [
      "M\u00e1rio S. Alvim",
      "Bernardo Amorim",
      "Sophia Knight",
      "Santiago Quintero",
      "Frank Valencia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.10583",
    "title": "A singular Riemannian geometry approach to Deep Neural Networks II.  Reconstruction of 1-D equivalence classes",
    "abstract": " Title: A singular Riemannian geometry approach to Deep Neural Networks II.  Reconstruction of 1-D equivalence classes ",
    "url": "https://arxiv.org/abs/2112.10583",
    "authors": [
      "Alessandro Benfenati",
      "Alessio Marta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)",
      "Metric Geometry (math.MG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2201.09051",
    "title": "On the Robustness of Sparse Counterfactual Explanations to Adverse  Perturbations",
    "abstract": " Title: On the Robustness of Sparse Counterfactual Explanations to Adverse  Perturbations ",
    "url": "https://arxiv.org/abs/2201.09051",
    "authors": [
      "Marco Virgolin",
      "Saverio Fracaros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.09656",
    "title": "A singular Riemannian geometry approach to Deep Neural Networks I.  Theoretical foundations",
    "abstract": " Title: A singular Riemannian geometry approach to Deep Neural Networks I.  Theoretical foundations ",
    "url": "https://arxiv.org/abs/2201.09656",
    "authors": [
      "Alessandro Benfenati",
      "Alessio Marta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)"
    ]
  },
  {
    "id": "arXiv:2202.03176",
    "title": "Field-of-View IoU for Object Detection in 360\u00b0 Images",
    "abstract": " Title: Field-of-View IoU for Object Detection in 360\u00b0 Images ",
    "url": "https://arxiv.org/abs/2202.03176",
    "authors": [
      "Miao Cao",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.05226",
    "title": "Deadwooding: Robust Global Pruning for Deep Neural Networks",
    "abstract": " Comments: 21 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2202.05226",
    "authors": [
      "Sawinder Kaur",
      "Ferdinando Fioretto",
      "Asif Salekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09282",
    "title": "FinNet: Solving Time-Independent Differential Equations with Finite  Difference Neural Network",
    "abstract": " Title: FinNet: Solving Time-Independent Differential Equations with Finite  Difference Neural Network ",
    "url": "https://arxiv.org/abs/2202.09282",
    "authors": [
      "Son N. T. Tu",
      "Thu Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.02331",
    "title": "F2DNet: Fast Focal Detection Network for Pedestrian Detection",
    "abstract": " Comments: Accepted at ICPR 2022 ",
    "url": "https://arxiv.org/abs/2203.02331",
    "authors": [
      "Abdul Hannan Khan",
      "Mohsin Munir",
      "Ludger van Elst",
      "Andreas Dengel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03677",
    "title": "Object-centric and memory-guided normality reconstruction for video  anomaly detection",
    "abstract": " Comments: Accepted at ICIP 2022 ",
    "url": "https://arxiv.org/abs/2203.03677",
    "authors": [
      "Khalil Bergaoui",
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07657",
    "title": "Seamlessly Integrating Factual Information and Social Content with  Persuasive Dialogue",
    "abstract": " Comments: To appear in Proceedings of AACL-IJCNLP 2022; 16 pages, 4 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2203.07657",
    "authors": [
      "Maximillian Chen",
      "Weiyan Shi",
      "Feifan Yan",
      "Ryan Hou",
      "Jingwen Zhang",
      "Saurav Sahay",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.09242",
    "title": "Depth-aware Neural Style Transfer using Instance Normalization",
    "abstract": " Comments: 8 pages, 8 figures, Computer Graphics & Visual Computing (CGVC) 2022 ",
    "url": "https://arxiv.org/abs/2203.09242",
    "authors": [
      "Eleftherios Ioannou",
      "Steve Maddock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.10208",
    "title": "Message Flow Analysis with Complex Causal Links for Distributed ROS 2  Systems",
    "abstract": " Comments: 14 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2204.10208",
    "authors": [
      "Christophe B\u00e9dard",
      "Pierre-Yves Lajoie",
      "Giovanni Beltrame",
      "Michel Dagenais"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.02648",
    "title": "Multi-Freq-LDPy: Multiple Frequency Estimation Under Local Differential  Privacy in Python",
    "abstract": " Comments: Paper published in the proceedings of ESORICS 2022 ",
    "url": "https://arxiv.org/abs/2205.02648",
    "authors": [
      "H\u00e9ber H. Arcolezi",
      "Jean-Fran\u00e7ois Couchot",
      "S\u00e9bastien Gambs",
      "Catuscia Palamidessi",
      "Majid Zolfaghari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.08012",
    "title": "CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction",
    "abstract": " Comments: AKBC 2022 ",
    "url": "https://arxiv.org/abs/2205.08012",
    "authors": [
      "Tara Safavi",
      "Doug Downey",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11039",
    "title": "FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph  Reasoning",
    "abstract": " Title: FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph  Reasoning ",
    "url": "https://arxiv.org/abs/2205.11039",
    "authors": [
      "Xueyuan Lin",
      "Haihong E",
      "Gengxian Zhou",
      "Tianyi Hu",
      "Li Ningyuan",
      "Mingzhi Sun",
      "Haoran Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07941",
    "title": "MixTailor: Mixed Gradient Aggregation for Robust Learning Against  Tailored Attacks",
    "abstract": " Comments: To appear at the Transactions on Machine Learning Research (TMLR) ",
    "url": "https://arxiv.org/abs/2207.07941",
    "authors": [
      "Ali Ramezani-Kebrya",
      "Iman Tabrizian",
      "Fartash Faghri",
      "Petar Popovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.03070",
    "title": "Activity Detection in Distributed MIMO: Distributed AMP via Likelihood  Ratio Fusion",
    "abstract": " Comments: 5 pages, 2 figures. This paper has been accepted for publication in IEEE Wireless Communications Letters. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2208.03070",
    "authors": [
      "Jianan Bai",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.05456",
    "title": "Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in  Extending Existing Social Computing Systems",
    "abstract": " Comments: To appear at the 25th ACM Conference On Computer-Supported Cooperative Work And Social Computing (CSCW '22) ",
    "url": "https://arxiv.org/abs/2208.05456",
    "authors": [
      "Daniel A. Epstein",
      "Fannie Liu",
      "Andr\u00e9s Monroy-Hern\u00e1ndez",
      "Dennis Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.08485",
    "title": "Complex-Value Spatio-temporal Graph Convolutional Neural Networks and  its Applications to Electric Power Systems AI",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2208.08485",
    "authors": [
      "Tong Wu",
      "Anna Scaglione",
      "Daniel Arnold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.13085",
    "title": "Target Speaker Voice Activity Detection with Transformers and Its  Integration with End-to-End Neural Diarization",
    "abstract": " Title: Target Speaker Voice Activity Detection with Transformers and Its  Integration with End-to-End Neural Diarization ",
    "url": "https://arxiv.org/abs/2208.13085",
    "authors": [
      "Dongmei Wang",
      "Xiong Xiao",
      "Naoyuki Kanda",
      "Takuya Yoshioka",
      "Jian Wu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2208.14319",
    "title": "Representation Learning based and Interpretable Reactor System Diagnosis  Using Denoising Padded Autoencoder",
    "abstract": " Title: Representation Learning based and Interpretable Reactor System Diagnosis  Using Denoising Padded Autoencoder ",
    "url": "https://arxiv.org/abs/2208.14319",
    "authors": [
      "Chengyuan Li",
      "Zhifang Qiu",
      "Zhangrui Yan",
      "Meifu Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.05307",
    "title": "Data-driven Parametric Insurance Framework Using Bayesian Neural  Networks",
    "abstract": " Title: Data-driven Parametric Insurance Framework Using Bayesian Neural  Networks ",
    "url": "https://arxiv.org/abs/2209.05307",
    "authors": [
      "Subeen Pang",
      "Chanyeol Choi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2209.06430",
    "title": "CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language  Representation Alignment",
    "abstract": " Title: CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language  Representation Alignment ",
    "url": "https://arxiv.org/abs/2209.06430",
    "authors": [
      "Hongwei Xue",
      "Yuchong Sun",
      "Bei Liu",
      "Jianlong Fu",
      "Ruihua Song",
      "Houqiang Li",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.10178",
    "title": "Deep Learning based pipeline for anomaly detection and quality  enhancement in industrial binder jetting processes",
    "abstract": " Comments: Conference paper for: 17. Fachtagung \"Entwurf komplexer Automatisierungssysteme (EKA)\", Magdeburg/Germany, June 2022 ",
    "url": "https://arxiv.org/abs/2209.10178",
    "authors": [
      "Alexander Zeiser",
      "Bas van Stein",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.10292",
    "title": "Fast Few shot Self-attentive Semi-supervised Political Inclination  Prediction",
    "abstract": " Comments: Accepted to ICADL'22 ",
    "url": "https://arxiv.org/abs/2209.10292",
    "authors": [
      "Souvic Chakraborty",
      "Pawan Goyal",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.10807",
    "title": "SR-GCL: Session-Based Recommendation with Global Context Enhanced  Augmentation in Contrastive Learning",
    "abstract": " Comments: 11 pages. This paper has been accepted by DLG-AAAI'22 ",
    "url": "https://arxiv.org/abs/2209.10807",
    "authors": [
      "Eunkyu Oh",
      "Taehun Kim",
      "Minsoo Kim",
      "Yunhu Ji",
      "Sushil Khyalia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]