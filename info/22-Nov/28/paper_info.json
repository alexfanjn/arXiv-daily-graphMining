[
  {
    "id": "arXiv:2211.13234",
    "title": "RNTrajRec: Road Network Enhanced Trajectory Recovery with  Spatial-Temporal Transformer",
    "abstract": "GPS trajectories are the essential foundations for many trajectory-based applications, such as travel time estimation, traffic prediction and trajectory similarity measurement. Most applications require a large amount of high sample rate trajectories to achieve a good performance. However, many real-life trajectories are collected with low sample rate due to energy concern or other constraints.We study the task of trajectory recovery in this paper as a means for increasing the sample rate of low sample trajectories. Currently, most existing works on trajectory recovery follow a sequence-to-sequence diagram, with an encoder to encode a trajectory and a decoder to recover real GPS points in the trajectory. However, these works ignore the topology of road network and only use grid information or raw GPS points as input. Therefore, the encoder model is not able to capture rich spatial information of the GPS points along the trajectory, making the prediction less accurate and lack spatial consistency. In this paper, we propose a road network enhanced transformer-based framework, namely RNTrajRec, for trajectory recovery. RNTrajRec first uses a graph model, namely GridGNN, to learn the embedding features of each road segment. It next develops a Sub-Graph Generation module to represent each GPS point as a sub-graph structure of the road network around the GPS point. It then introduces a spatial-temporal transformer model, namely GPSFormer, to learn rich spatial and temporal features. It finally forwards the outputs of encoder model into a multi-task decoder model to recover the missing GPS points. Extensive experiments based on three large-scale real-life trajectory datasets confirm the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2211.13234",
    "authors": [
      "Yuqi Chen",
      "Hanyuan Zhang",
      "Weiwei Sun",
      "Baihua Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13236",
    "title": "MEGAN: Multi-Explanation Graph Attention Network",
    "abstract": "Explainable artificial intelligence (XAI) methods are expected to improve trust during human-AI interactions, provide tools for model analysis and extend human understanding of complex problems. Explanation-supervised training allows to improve explanation quality by training self-explaining XAI models on ground truth or human-generated explanations. However, existing explanation methods have limited expressiveness and interoperability due to the fact that only single explanations in form of node and edge importance are generated. To that end we propose the novel multi-explanation graph attention network (MEGAN). Our fully differentiable, attention-based model features multiple explanation channels, which can be chosen independently of the task specifications. We first validate our model on a synthetic graph regression dataset. We show that for the special single explanation case, our model significantly outperforms existing post-hoc and explanation-supervised baseline methods. Furthermore, we demonstrate significant advantages when using two explanations, both in quantitative explanation measures as well as in human interpretability. Finally, we demonstrate our model's capabilities on multiple real-world datasets. We find that our model produces sparse high-fidelity explanations consistent with human intuition about those tasks and at the same time matches state-of-the-art graph neural networks in predictive performance, indicating that explanations and accuracy are not necessarily a trade-off. ",
    "url": "https://arxiv.org/abs/2211.13236",
    "authors": [
      "Jonas Teufel",
      "Luca Torresi",
      "Patrick Reiser",
      "Pascal Friederich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13250",
    "title": "Lempel-Ziv Networks",
    "abstract": "Sequence processing has long been a central area of machine learning research. Recurrent neural nets have been successful in processing sequences for a number of tasks; however, they are known to be both ineffective and computationally expensive when applied to very long sequences. Compression-based methods have demonstrated more robustness when processing such sequences -- in particular, an approach pairing the Lempel-Ziv Jaccard Distance (LZJD) with the k-Nearest Neighbor algorithm has shown promise on long sequence problems (up to $T=200,000,000$ steps) involving malware classification. Unfortunately, use of LZJD is limited to discrete domains. To extend the benefits of LZJD to a continuous domain, we investigate the effectiveness of a deep-learning analog of the algorithm, the Lempel-Ziv Network. While we achieve successful proof of concept, we are unable to improve meaningfully on the performance of a standard LSTM across a variety of datasets and sequence processing tasks. In addition to presenting this negative result, our work highlights the problem of sub-par baseline tuning in newer research areas. ",
    "url": "https://arxiv.org/abs/2211.13250",
    "authors": [
      "Rebecca Saul",
      "Mohammad Mahmudul Alam",
      "John Hurwitz",
      "Edward Raff",
      "Tim Oates",
      "James Holt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13257",
    "title": "Representation Learning for Continuous Action Spaces is Beneficial for  Efficient Policy Learning",
    "abstract": "Deep reinforcement learning (DRL) breaks through the bottlenecks of traditional reinforcement learning (RL) with the help of the perception capability of deep learning and has been widely applied in real-world problems.While model-free RL, as a class of efficient DRL methods, performs the learning of state representations simultaneously with policy learning in an end-to-end manner when facing large-scale continuous state and action spaces. However, training such a large policy model requires a large number of trajectory samples and training time. On the other hand, the learned policy often fails to generalize to large-scale action spaces, especially for the continuous action spaces. To address this issue, in this paper we propose an efficient policy learning method in latent state and action spaces. More specifically, we extend the idea of state representations to action representations for better policy generalization capability. Meanwhile, we divide the whole learning task into learning with the large-scale representation models in an unsupervised manner and learning with the small-scale policy model in the RL manner.The small policy model facilitates policy learning, while not sacrificing generalization and expressiveness via the large representation model. Finally,the effectiveness of the proposed method is demonstrated by MountainCar,CarRacing and Cheetah experiments. ",
    "url": "https://arxiv.org/abs/2211.13257",
    "authors": [
      "Tingting Zhao",
      "Ying Wang",
      "Wei Sun",
      "Yarui Chen",
      "Gang Niub",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13264",
    "title": "Distilling Knowledge from Self-Supervised Teacher by Embedding Graph  Alignment",
    "abstract": "Recent advances have indicated the strengths of self-supervised pre-training for improving representation learning on downstream tasks. Existing works often utilize self-supervised pre-trained models by fine-tuning on downstream tasks. However, fine-tuning does not generalize to the case when one needs to build a customized model architecture different from the self-supervised model. In this work, we formulate a new knowledge distillation framework to transfer the knowledge from self-supervised pre-trained models to any other student network by a novel approach named Embedding Graph Alignment. Specifically, inspired by the spirit of instance discrimination in self-supervised learning, we model the instance-instance relations by a graph formulation in the feature embedding space and distill the self-supervised teacher knowledge to a student network by aligning the teacher graph and the student graph. Our distillation scheme can be flexibly applied to transfer the self-supervised knowledge to enhance representation learning on various student networks. We demonstrate that our model outperforms multiple representative knowledge distillation methods on three benchmark datasets, including CIFAR100, STL10, and TinyImageNet. Code is here: https://github.com/yccm/EGA. ",
    "url": "https://arxiv.org/abs/2211.13264",
    "authors": [
      "Yuchen Ma",
      "Yanbei Chen",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13286",
    "title": "Corn Yield Prediction based on Remotely Sensed Variables Using  Variational Autoencoder and Multiple Instance Regression",
    "abstract": "In the U.S., corn is the most produced crop and has been an essential part of the American diet. To meet the demand for supply chain management and regional food security, accurate and timely large-scale corn yield prediction is attracting more attention in precision agriculture. Recently, remote sensing technology and machine learning methods have been widely explored for crop yield prediction. Currently, most county-level yield prediction models use county-level mean variables for prediction, ignoring much detailed information. Moreover, inconsistent spatial resolution between crop area and satellite sensors results in mixed pixels, which may decrease the prediction accuracy. Only a few works have addressed the mixed pixels problem in large-scale crop yield prediction. To address the information loss and mixed pixels problem, we developed a variational autoencoder (VAE) based multiple instance regression (MIR) model for large-scaled corn yield prediction. We use all unlabeled data to train a VAE and the well-trained VAE for anomaly detection. As a preprocess method, anomaly detection can help MIR find a better representation of every bag than traditional MIR methods, thus better performing in large-scale corn yield prediction. Our experiments showed that variational autoencoder based multiple instance regression (VAEMIR) outperformed all baseline methods in large-scale corn yield prediction. Though a suitable meta parameter is required, VAEMIR shows excellent potential in feature learning and extraction for large-scale corn yield prediction. ",
    "url": "https://arxiv.org/abs/2211.13286",
    "authors": [
      "Zeyu Cao",
      "Yuchi Ma",
      "Zhou Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13292",
    "title": "Discovering Influencers in Opinion Formation over Social Graphs",
    "abstract": "The adaptive social learning paradigm helps model how networked agents are able to form opinions on a state of nature and track its drifts in a changing environment. In this framework, the agents repeatedly update their beliefs based on private observations and exchange the beliefs with their neighbors. In this work, it is shown how the sequence of publicly exchanged beliefs over time allows users to discover rich information about the underlying network topology and about the flow of information over graph. In particular, it is shown that it is possible (i) to identify the influence of each individual agent to the objective of truth learning, (ii) to discover how well informed each agent is, (iii) to quantify the pairwise influences between agents, and (iv) to learn the underlying network topology. The algorithm derived herein is also able to work under non-stationary environments where either the true state of nature or the network topology are allowed to drift over time. We apply the proposed algorithm to different subnetworks of Twitter users, and identify the most influential and central agents merely by using their public tweets (posts). ",
    "url": "https://arxiv.org/abs/2211.13292",
    "authors": [
      "Valentina Shumovskaia",
      "Mert Kayaalp",
      "Mert Cemri",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.13297",
    "title": "Multiple Imputation with Neural Network Gaussian Process for  High-dimensional Incomplete Data",
    "abstract": "Missing data are ubiquitous in real world applications and, if not adequately handled, may lead to the loss of information and biased findings in downstream analysis. Particularly, high-dimensional incomplete data with a moderate sample size, such as analysis of multi-omics data, present daunting challenges. Imputation is arguably the most popular method for handling missing data, though existing imputation methods have a number of limitations. Single imputation methods such as matrix completion methods do not adequately account for imputation uncertainty and hence would yield improper statistical inference. In contrast, multiple imputation (MI) methods allow for proper inference but existing methods do not perform well in high-dimensional settings. Our work aims to address these significant methodological gaps, leveraging recent advances in neural network Gaussian process (NNGP) from a Bayesian viewpoint. We propose two NNGP-based MI methods, namely MI-NNGP, that can apply multiple imputations for missing values from a joint (posterior predictive) distribution. The MI-NNGP methods are shown to significantly outperform existing state-of-the-art methods on synthetic and real datasets, in terms of imputation error, statistical inference, robustness to missing rates, and computation costs, under three missing data mechanisms, MCAR, MAR, and MNAR. ",
    "url": "https://arxiv.org/abs/2211.13297",
    "authors": [
      "Zongyu Dai",
      "Zhiqi Bu",
      "Qi Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.13305",
    "title": "Dual Graphs of Polyhedral Decompositions for the Detection of  Adversarial Attacks",
    "abstract": "Previous work has shown that a neural network with the rectified linear unit (ReLU) activation function leads to a convex polyhedral decomposition of the input space. These decompositions can be represented by a dual graph with vertices corresponding to polyhedra and edges corresponding to polyhedra sharing a facet, which is a subgraph of a Hamming graph. This paper illustrates how one can utilize the dual graph to detect and analyze adversarial attacks in the context of digital images. When an image passes through a network containing ReLU nodes, the firing or non-firing at a node can be encoded as a bit ($1$ for ReLU activation, $0$ for ReLU non-activation). The sequence of all bit activations identifies the image with a bit vector, which identifies it with a polyhedron in the decomposition and, in turn, identifies it with a vertex in the dual graph. We identify ReLU bits that are discriminators between non-adversarial and adversarial images and examine how well collections of these discriminators can ensemble vote to build an adversarial image detector. Specifically, we examine the similarities and differences of ReLU bit vectors for adversarial images, and their non-adversarial counterparts, using a pre-trained ResNet-50 architecture. While this paper focuses on adversarial digital images, ResNet-50 architecture, and the ReLU activation function, our methods extend to other network architectures, activation functions, and types of datasets. ",
    "url": "https://arxiv.org/abs/2211.13305",
    "authors": [
      "Huma Jamil",
      "Yajing Liu",
      "Christina Cole",
      "Nathaniel Blanchard",
      "Emily J. King",
      "Michael Kirby",
      "Christopher Peterson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13314",
    "title": "CoMadOut -- A Robust Outlier Detection Algorithm based on CoMAD",
    "abstract": "Unsupervised learning methods are well established in the area of anomaly detection and achieve state of the art performances on outlier data sets. Outliers play a significant role, since they bear the potential to distort the predictions of a machine learning algorithm on a given data set. Especially among PCA-based methods, outliers have an additional destructive potential regarding the result: they may not only distort the orientation and translation of the principal components, they also make it more complicated to detect outliers. To address this problem, we propose the robust outlier detection algorithm CoMadOut, which satisfies two required properties: (1) being robust towards outliers and (2) detecting them. Our outlier detection method using coMAD-PCA defines dependent on its variant an inlier region with a robust noise margin by measures of in-distribution (ID) and out-of-distribution (OOD). These measures allow distribution based outlier scoring for each principal component, and thus, for an appropriate alignment of the decision boundary between normal and abnormal instances. Experiments comparing CoMadOut with traditional, deep and other comparable robust outlier detection methods showed that the performance of the introduced CoMadOut approach is competitive to well established methods related to average precision (AP), recall and area under the receiver operating characteristic (AUROC) curve. In summary our approach can be seen as a robust alternative for outlier detection tasks. ",
    "url": "https://arxiv.org/abs/2211.13314",
    "authors": [
      "Andreas Lohrer",
      "Daniyal Kazempour",
      "Maximilian H\u00fcnem\u00f6rder",
      "Peer Kr\u00f6ger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13322",
    "title": "Group SELFIES: A Robust Fragment-Based Molecular String Representation",
    "abstract": "We introduce Group SELFIES, a molecular string representation that leverages group tokens to represent functional groups or entire substructures while maintaining chemical robustness guarantees. Molecular string representations, such as SMILES and SELFIES, serve as the basis for molecular generation and optimization in chemical language models, deep generative models, and evolutionary methods. While SMILES and SELFIES leverage atomic representations, Group SELFIES builds on top of the chemical robustness guarantees of SELFIES by enabling group tokens, thereby creating additional flexibility to the representation. Moreover, the group tokens in Group SELFIES can take advantage of inductive biases of molecular fragments that capture meaningful chemical motifs. The advantages of capturing chemical motifs and flexibility are demonstrated in our experiments, which show that Group SELFIES improves distribution learning of common molecular datasets. Further experiments also show that random sampling of Group SELFIES strings improves the quality of generated molecules compared to regular SELFIES strings. Our open-source implementation of Group SELFIES is available online, which we hope will aid future research in molecular generation and optimization. ",
    "url": "https://arxiv.org/abs/2211.13322",
    "authors": [
      "Austin Cheng",
      "Andy Cai",
      "Santiago Miret",
      "Gustavo Malkomes",
      "Mariano Phielipp",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2211.13327",
    "title": "A Report on the Euphemisms Detection Shared Task",
    "abstract": "This paper presents The Shared Task on Euphemism Detection for the Third Workshop on Figurative Language Processing (FigLang 2022) held in conjunction with EMNLP 2022. Participants were invited to investigate the euphemism detection task: given input text, identify whether it contains a euphemism. The input data is a corpus of sentences containing potentially euphemistic terms (PETs) collected from the GloWbE corpus (Davies and Fuchs, 2015), and are human-annotated as containing either a euphemistic or literal usage of a PET. In this paper, we present the results and analyze the common themes, methods and findings of the participating teams ",
    "url": "https://arxiv.org/abs/2211.13327",
    "authors": [
      "Patrick Lee",
      "Anna Feldman",
      "Jing Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13332",
    "title": "Learning Compact Features via In-Training Representation Alignment",
    "abstract": "Deep neural networks (DNNs) for supervised learning can be viewed as a pipeline of the feature extractor (i.e., last hidden layer) and a linear classifier (i.e., output layer) that are trained jointly with stochastic gradient descent (SGD) on the loss function (e.g., cross-entropy). In each epoch, the true gradient of the loss function is estimated using a mini-batch sampled from the training set and model parameters are then updated with the mini-batch gradients. Although the latter provides an unbiased estimation of the former, they are subject to substantial variances derived from the size and number of sampled mini-batches, leading to noisy and jumpy updates. To stabilize such undesirable variance in estimating the true gradients, we propose In-Training Representation Alignment (ITRA) that explicitly aligns feature distributions of two different mini-batches with a matching loss in the SGD training process. We also provide a rigorous analysis of the desirable effects of the matching loss on feature representation learning: (1) extracting compact feature representation; (2) reducing over-adaption on mini-batches via an adaptive weighting mechanism; and (3) accommodating to multi-modalities. Finally, we conduct large-scale experiments on both image and text classifications to demonstrate its superior performance to the strong baselines. ",
    "url": "https://arxiv.org/abs/2211.13332",
    "authors": [
      "Xin Li",
      "Xiangrui Li",
      "Deng Pan",
      "Yao Qiang",
      "Dongxiao Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13339",
    "title": "Robustness Analysis of Deep Learning Models for Population Synthesis",
    "abstract": "Deep generative models have become useful for synthetic data generation, particularly population synthesis. The models implicitly learn the probability distribution of a dataset and can draw samples from a distribution. Several models have been proposed, but their performance is only tested on a single cross-sectional sample. The implementation of population synthesis on single datasets is seen as a drawback that needs further studies to explore the robustness of the models on multiple datasets. While comparing with the real data can increase trust and interpretability of the models, techniques to evaluate deep generative models' robustness for population synthesis remain underexplored. In this study, we present bootstrap confidence interval for the deep generative models, an approach that computes efficient confidence intervals for mean errors predictions to evaluate the robustness of the models to multiple datasets. Specifically, we adopt the tabular-based Composite Travel Generative Adversarial Network (CTGAN) and Variational Autoencoder (VAE), to estimate the distribution of the population, by generating agents that have tabular data using several samples over time from the same study area. The models are implemented on multiple travel diaries of Montreal Origin- Destination Survey of 2008, 2013, and 2018 and compare the predictive performance under varying sample sizes from multiple surveys. Results show that the predictive errors of CTGAN have narrower confidence intervals indicating its robustness to multiple datasets of the varying sample sizes when compared to VAE. Again, the evaluation of model robustness against varying sample size shows a minimal decrease in model performance with decrease in sample size. This study directly supports agent-based modelling by enabling finer synthetic generation of populations in a reliable environment. ",
    "url": "https://arxiv.org/abs/2211.13339",
    "authors": [
      "Daniel Opoku Mensah",
      "Godwin Badu-Marfo",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13373",
    "title": "Tapping the Potential of Coherence and Syntactic Features in Neural  Models for Automatic Essay Scoring",
    "abstract": "In the prompt-specific holistic score prediction task for Automatic Essay Scoring, the general approaches include pre-trained neural model, coherence model, and hybrid model that incorporate syntactic features with neural model. In this paper, we propose a novel approach to extract and represent essay coherence features with prompt-learning NSP that shows to match the state-of-the-art AES coherence model, and achieves the best performance for long essays. We apply syntactic feature dense embedding to augment BERT-based model and achieve the best performance for hybrid methodology for AES. In addition, we explore various ideas to combine coherence, syntactic information and semantic embeddings, which no previous study has done before. Our combined model also performs better than the SOTA available for combined model, even though it does not outperform our syntactic enhanced neural model. We further offer analyses that can be useful for future study. ",
    "url": "https://arxiv.org/abs/2211.13373",
    "authors": [
      "Xinying Qiu",
      "Shuxuan Liao",
      "Jiajun Xie",
      "Jian-Yun Nie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.13375",
    "title": "Lifting Weak Supervision To Structured Prediction",
    "abstract": "Weak supervision (WS) is a rich set of techniques that produce pseudolabels by aggregating easily obtained but potentially noisy label estimates from a variety of sources. WS is theoretically well understood for binary classification, where simple approaches enable consistent estimation of pseudolabel noise rates. Using this result, it has been shown that downstream models trained on the pseudolabels have generalization guarantees nearly identical to those trained on clean labels. While this is exciting, users often wish to use WS for structured prediction, where the output space consists of more than a binary or multi-class label set: e.g. rankings, graphs, manifolds, and more. Do the favorable theoretical properties of WS for binary classification lift to this setting? We answer this question in the affirmative for a wide range of scenarios. For labels taking values in a finite metric space, we introduce techniques new to weak supervision based on pseudo-Euclidean embeddings and tensor decompositions, providing a nearly-consistent noise rate estimator. For labels in constant-curvature Riemannian manifolds, we introduce new invariants that also yield consistent noise rate estimation. In both cases, when using the resulting pseudolabels in concert with a flexible downstream model, we obtain generalization guarantees nearly identical to those for models trained on clean data. Several of our results, which can be viewed as robustness guarantees in structured prediction with noisy labels, may be of independent interest. Empirical evaluation validates our claims and shows the merits of the proposed method. ",
    "url": "https://arxiv.org/abs/2211.13375",
    "authors": [
      "Harit Vishwakarma",
      "Nicholas Roberts",
      "Frederic Sala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.13382",
    "title": "MaskPlace: Fast Chip Placement via Reinforced Visual Representation  Learning",
    "abstract": "Placement is an essential task in modern chip design, aiming at placing millions of circuit modules on a 2D chip canvas. Unlike the human-centric solution, which requires months of intense effort by hardware engineers to produce a layout to minimize delay and energy consumption, deep reinforcement learning has become an emerging autonomous tool. However, the learning-centric method is still in its early stage, impeded by a massive design space of size ten to the order of a few thousand. This work presents MaskPlace to automatically generate a valid chip layout design within a few hours, whose performance can be superior or comparable to recent advanced approaches. It has several appealing benefits that prior arts do not have. Firstly, MaskPlace recasts placement as a problem of learning pixel-level visual representation to comprehensively describe millions of modules on a chip, enabling placement in a high-resolution canvas and a large action space. It outperforms recent methods that represent a chip as a hypergraph. Secondly, it enables training the policy network by an intuitive reward function with dense reward, rather than a complicated reward function with sparse reward from previous methods. Thirdly, extensive experiments on many public benchmarks show that MaskPlace outperforms existing RL approaches in all key performance metrics, including wirelength, congestion, and density. For example, it achieves 60%-90% wirelength reduction and guarantees zero overlaps. We believe MaskPlace can improve AI-assisted chip layout design. The deliverables are released at https://laiyao1.github.io/maskplace. ",
    "url": "https://arxiv.org/abs/2211.13382",
    "authors": [
      "Yao Lai",
      "Yao Mu",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13389",
    "title": "FedCut: A Spectral Analysis Framework for Reliable Detection of  Byzantine Colluders",
    "abstract": "This paper proposes a general spectral analysis framework that thwarts a security risk in federated Learning caused by groups of malicious Byzantine attackers or colluders, who conspire to upload vicious model updates to severely debase global model performances. The proposed framework delineates the strong consistency and temporal coherence between Byzantine colluders' model updates from a spectral analysis lens, and, formulates the detection of Byzantine misbehaviours as a community detection problem in weighted graphs. The modified normalized graph cut is then utilized to discern attackers from benign participants. Moreover, the Spectral heuristics is adopted to make the detection robust against various attacks. The proposed Byzantine colluder resilient method, i.e., FedCut, is guaranteed to converge with bounded errors. Extensive experimental results under a variety of settings justify the superiority of FedCut, which demonstrates extremely robust model performance (MP) under various attacks. It was shown that FedCut's averaged MP is 2.1% to 16.5% better than that of the state of the art Byzantine-resilient methods. In terms of the worst-case model performance (MP), FedCut is 17.6% to 69.5% better than these methods. ",
    "url": "https://arxiv.org/abs/2211.13389",
    "authors": [
      "Hanlin Gu",
      "Lixin Fan",
      "Xingxing Tang",
      "Qiang Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13402",
    "title": "MP-GELU Bayesian Neural Networks: Moment Propagation by GELU  Nonlinearity",
    "abstract": "Bayesian neural networks (BNNs) have been an important framework in the study of uncertainty quantification. Deterministic variational inference, one of the inference methods, utilizes moment propagation to compute the predictive distributions and objective functions. Unfortunately, deriving the moments requires computationally expensive Taylor expansion in nonlinear functions, such as a rectified linear unit (ReLU) or a sigmoid function. Therefore, a new nonlinear function that realizes faster moment propagation than conventional functions is required. In this paper, we propose a novel nonlinear function named moment propagating-Gaussian error linear unit (MP-GELU) that enables the fast derivation of first and second moments in BNNs. MP-GELU enables the analytical computation of moments by applying nonlinearity to the input statistics, thereby reducing the computationally expensive calculations required for nonlinear functions. In empirical experiments on regression tasks, we observed that the proposed MP-GELU provides higher prediction accuracy and better quality of uncertainty with faster execution than those of ReLU-based BNNs. ",
    "url": "https://arxiv.org/abs/2211.13402",
    "authors": [
      "Yuki Hirayama",
      "Sinya Takamaeda-Yamazaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13408",
    "title": "Graph Contrastive Learning for Materials",
    "abstract": "Recent work has shown the potential of graph neural networks to efficiently predict material properties, enabling high-throughput screening of materials. Training these models, however, often requires large quantities of labelled data, obtained via costly methods such as ab initio calculations or experimental evaluation. By leveraging a series of material-specific transformations, we introduce CrystalCLR, a framework for constrastive learning of representations with crystal graph neural networks. With the addition of a novel loss function, our framework is able to learn representations competitive with engineered fingerprinting methods. We also demonstrate that via model finetuning, contrastive pretraining can improve the performance of graph neural networks for prediction of material properties and significantly outperform traditional ML models that use engineered fingerprints. Lastly, we observe that CrystalCLR produces material representations that form clusters by compound class. ",
    "url": "https://arxiv.org/abs/2211.13408",
    "authors": [
      "Teddy Koker",
      "Keegan Quigley",
      "Will Spaeth",
      "Nathan C. Frey",
      "Lin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2211.13409",
    "title": "Object Detection in Foggy Scenes by Embedding Depth and Reconstruction  into Domain Adaptation",
    "abstract": "Most existing domain adaptation (DA) methods align the features based on the domain feature distributions and ignore aspects related to fog, background and target objects, rendering suboptimal performance. In our DA framework, we retain the depth and background information during the domain feature alignment. A consistency loss between the generated depth and fog transmission map is introduced to strengthen the retention of the depth information in the aligned features. To address false object features potentially generated during the DA process, we propose an encoder-decoder framework to reconstruct the fog-free background image. This reconstruction loss also reinforces the encoder, i.e., our DA backbone, to minimize false object features.Moreover, we involve our target data in training both our DA module and our detection module in a semi-supervised manner, so that our detection module is also exposed to the unlabeled target data, the type of data used in the testing stage. Using these ideas, our method significantly outperforms the state-of-the-art method (47.6 mAP against the 44.3 mAP on the Foggy Cityscapes dataset), and obtains the best performance on multiple real-image public datasets. Code is available at: https://github.com/VIML-CVDL/Object-Detection-in-Foggy-Scenes ",
    "url": "https://arxiv.org/abs/2211.13409",
    "authors": [
      "Xin Yang",
      "Michael Bi Mi",
      "Yuan Yuan",
      "Xin Wang",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13411",
    "title": "Remote State Estimation with Privacy Against Eavesdroppers",
    "abstract": "We study the problem of remote state estimation in the presence of a passive eavesdropper, under the challenging network environment of no packet receipt acknowledgments. A remote legitimate user estimates the state of a linear plant from the state information received from a sensor via an insecure and unreliable network. The transmission from the sensor may be intercepted by the eavesdropper. To maintain state confidentiality, we propose an encoding scheme, which is activated on detection of an eavesdropper. Our scheme randomly transmits noise based on a pseudo-random indicator, pre-arranged at the legitimate user and sensor. The transmission of noise harms the eavesdropper's performance. Under our encoding scheme, we impair the eavesdropper's expected estimation performance, whilst minimising expected performance degradation at the legitimate user. We explore the trade-off between state secrecy and legitimate user performance degradation. ",
    "url": "https://arxiv.org/abs/2211.13411",
    "authors": [
      "Matthew Crimson",
      "Justin M. Kennedy",
      "Daniel E. Quevedo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.13419",
    "title": "Network Security Modelling with Distributional Data",
    "abstract": "We investigate the detection of botnet command and control (C2) hosts in massive IP traffic using machine learning methods. To this end, we use NetFlow data -- the industry standard for monitoring of IP traffic -- and ML models using two sets of features: conventional NetFlow variables and distributional features based on NetFlow variables. In addition to using static summaries of NetFlow features, we use quantiles of their IP-level distributions as input features in predictive models to predict whether an IP belongs to known botnet families. These models are used to develop intrusion detection systems to predict traffic traces identified with malicious attacks. The results are validated by matching predictions to existing denylists of published malicious IP addresses and deep packet inspection. The usage of our proposed novel distributional features, combined with techniques that enable modelling complex input feature spaces result in highly accurate predictions by our trained models. ",
    "url": "https://arxiv.org/abs/2211.13419",
    "authors": [
      "Subhabrata Majumdar",
      "Ganesh Subramaniam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.13424",
    "title": "Deepfake Detection via Joint Unsupervised Reconstruction and Supervised  Classification",
    "abstract": "Deep learning has enabled realistic face manipulation (i.e., deepfake), which poses significant concerns over the integrity of the media in circulation. Most existing deep learning techniques for deepfake detection can achieve promising performance in the intra-dataset evaluation setting (i.e., training and testing on the same dataset), but are unable to perform satisfactorily in the inter-dataset evaluation setting (i.e., training on one dataset and testing on another). Most of the previous methods use the backbone network to extract global features for making predictions and only employ binary supervision (i.e., indicating whether the training instances are fake or authentic) to train the network. Classification merely based on the learning of global features leads often leads to weak generalizability to unseen manipulation methods. In addition, the reconstruction task can improve the learned representations. In this paper, we introduce a novel approach for deepfake detection, which considers the reconstruction and classification tasks simultaneously to address these problems. This method shares the information learned by one task with the other, which focuses on a different aspect other existing works rarely consider and hence boosts the overall performance. In particular, we design a two-branch Convolutional AutoEncoder (CAE), in which the Convolutional Encoder used to compress the feature map into the latent representation is shared by both branches. Then the latent representation of the input data is fed to a simple classifier and the unsupervised reconstruction component simultaneously. Our network is trained end-to-end. Experiments demonstrate that our method achieves state-of-the-art performance on three commonly-used datasets, particularly in the cross-dataset evaluation setting. ",
    "url": "https://arxiv.org/abs/2211.13424",
    "authors": [
      "Bosheng Yan",
      "Xuequan Lu",
      "Chang-Tsun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13436",
    "title": "Solving Bilevel Knapsack Problem using Graph Neural Networks",
    "abstract": "The Bilevel Optimization Problem is a hierarchical optimization problem with two agents, a leader and a follower. The leader make their own decisions first, and the followers make the best choices accordingly. The leader knows the information of the followers, and the goal of the problem is to find the optimal solution by considering the reactions of the followers from the leader's point of view. For the Bilevel Optimization Problem, there are no general and efficient algorithms or commercial solvers to get an optimal solution, and it is very difficult to get a good solution even for a simple problem. In this paper, we propose a deep learning approach using Graph Neural Networks to solve the bilevel knapsack problem. We train the model to predict the leader's solution and use it to transform the hierarchical optimization problem into a single-level optimization problem to get the solution. Our model found the feasible solution that was about 500 times faster than the exact algorithm with $1.7\\%$ optimal gap. Also, our model performed well on problems of different size from the size it was trained on. ",
    "url": "https://arxiv.org/abs/2211.13436",
    "authors": [
      "Sunhyeon Kwon",
      "Sungsoo Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.13443",
    "title": "TESSP: Text-Enhanced Self-Supervised Speech Pre-training",
    "abstract": "Self-supervised speech pre-training empowers the model with the contextual structure inherent in the speech signal while self-supervised text pre-training empowers the model with linguistic information. Both of them are beneficial for downstream speech tasks such as ASR. However, the distinct pre-training objectives make it challenging to jointly optimize the speech and text representation in the same model. To solve this problem, we propose Text-Enhanced Self-Supervised Speech Pre-training (TESSP), aiming to incorporate the linguistic information into speech pre-training. Our model consists of three parts, i.e., a speech encoder, a text encoder and a shared encoder. The model takes unsupervised speech and text data as the input and leverages the common HuBERT and MLM losses respectively. We also propose phoneme up-sampling and representation swapping to enable joint modeling of the speech and text information. Specifically, to fix the length mismatching problem between speech and text data, we phonemize the text sequence and up-sample the phonemes with the alignment information extracted from a small set of supervised data. Moreover, to close the gap between the learned speech and text representations, we swap the text representation with the speech representation extracted by the respective private encoders according to the alignment information. Experiments on the Librispeech dataset shows the proposed TESSP model achieves more than 10% improvement compared with WavLM on the test-clean and test-other sets. We also evaluate our model on the SUPERB benchmark, showing our model has better performance on Phoneme Recognition, Acoustic Speech Recognition and Speech Translation compared with WavLM. ",
    "url": "https://arxiv.org/abs/2211.13443",
    "authors": [
      "Zhuoyuan Yao",
      "Shuo Ren",
      "Sanyuan Chen",
      "Ziyang Ma",
      "Pengcheng Guo",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.13445",
    "title": "Delving into Out-of-Distribution Detection with Vision-Language  Representations",
    "abstract": "Recognizing out-of-distribution (OOD) samples is critical for machine learning systems deployed in the open world. The vast majority of OOD detection methods are driven by a single modality (e.g., either vision or language), leaving the rich information in multi-modal representations untapped. Inspired by the recent success of vision-language pre-training, this paper enriches the landscape of OOD detection from a single-modal to a multi-modal regime. Particularly, we propose Maximum Concept Matching (MCM), a simple yet effective zero-shot OOD detection method based on aligning visual features with textual concepts. We contribute in-depth analysis and theoretical insights to understand the effectiveness of MCM. Extensive experiments demonstrate that MCM achieves superior performance on a wide variety of real-world tasks. MCM with vision-language features outperforms a common baseline with pure visual features on a hard OOD task with semantically similar classes by 13.1% (AUROC). Code is available at https://github.com/deeplearning-wisc/MCM. ",
    "url": "https://arxiv.org/abs/2211.13445",
    "authors": [
      "Yifei Ming",
      "Ziyang Cai",
      "Jiuxiang Gu",
      "Yiyou Sun",
      "Wei Li",
      "Yixuan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13448",
    "title": "Robust fractional-order fast terminal sliding mode control of aerial  manipulator derived from a mutable inertia parameters model",
    "abstract": "The coupling disturbance between the manipulator and the unmanned aerial vehicle (UAV) deteriorates the control performance of system. To get high performance of the aerial manipulator, a robust fractional order fast terminal sliding mode control (FOFTSMC) strategy based on mutable inertia parameters is proposed in this paper. First, the dynamics of aerial manipulator with consideration of the coupling disturbance is derived by utilizing mutable inertia parameters. Then, based on the dynamic model, a robust FOFTSMC algorithm is designed to make the system fly steadily under coupling disturbance. Furthermore, stability analysis is conducted to prove the convergence of tracking errors. Finally, comparative simulation results are given to show the validity and superiority of the proposed scheme. ",
    "url": "https://arxiv.org/abs/2211.13448",
    "authors": [
      "Wenlei Zheng",
      "Zhan Li",
      "Bingkai Xiu",
      "Bingliang Zhao",
      "Zhigang Guo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.13462",
    "title": "Estimation of Similarity between DNA Sequences and Its Graphical  Representation",
    "abstract": "Bioinformatics, which is now a well known field of study, originated in the context of biological sequence analysis. Recently graphical representation takes place for the research on DNA sequence. Research in biological sequence is mainly based on the function and its structure. Bioinformatics finds wide range of applications specifically in the domain of molecular biology which focuses on the analysis of molecules viz. DNA, RNA, Protein etc. In this review, we mainly deal with the similarity analysis between sequences and graphical representation of DNA sequence. ",
    "url": "https://arxiv.org/abs/2211.13462",
    "authors": [
      "Probir Mondal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.13464",
    "title": "Design of Turing Systems with Physics-Informed Neural Networks",
    "abstract": "Reaction-diffusion (Turing) systems are fundamental to the formation of spatial patterns in nature and engineering. These systems are governed by a set of non-linear partial differential equations containing parameters that determine the rate of constituent diffusion and reaction. Critically, these parameters, such as diffusion coefficient, heavily influence the mode and type of the final pattern, and quantitative characterization and knowledge of these parameters can aid in bio-mimetic design or understanding of real-world systems. However, the use of numerical methods to infer these parameters can be difficult and computationally expensive. Typically, adjoint solvers may be used, but they are frequently unstable for very non-linear systems. Alternatively, massive amounts of iterative forward simulations are used to find the best match, but this is extremely effortful. Recently, physics-informed neural networks have been proposed as a means for data-driven discovery of partial differential equations, and have seen success in various applications. Thus, we investigate the use of physics-informed neural networks as a tool to infer key parameters in reaction-diffusion systems in the steady-state for scientific discovery or design. Our proof-of-concept results show that the method is able to infer parameters for different pattern modes and types with errors of less than 10\\%. In addition, the stochastic nature of this method can be exploited to provide multiple parameter alternatives to the desired pattern, highlighting the versatility of this method for bio-mimetic design. This work thus demonstrates the utility of physics-informed neural networks for inverse parameter inference of reaction-diffusion systems to enhance scientific discovery and design. ",
    "url": "https://arxiv.org/abs/2211.13464",
    "authors": [
      "Jordon Kho",
      "Winston Koh",
      "Jian Cheng Wong",
      "Pao-Hsiung Chiu",
      "Chin Chun Ooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2211.13469",
    "title": "NQE: N-ary Query Embedding for Complex Query Answering over  Hyper-relational Knowledge Graphs",
    "abstract": "Complex query answering (CQA) is an essential task for multi-hop and logical reasoning on knowledge graphs (KGs). Currently, most approaches are limited to queries among binary relational facts and pay less attention to n-ary facts (n>=2) containing more than two entities, which are more prevalent in the real world. Moreover, previous CQA methods can only make predictions for a few given types of queries and cannot be flexibly extended to more complex logical queries, which significantly limits their applications. To overcome these challenges, in this work, we propose a novel N-ary Query Embedding (NQE) model for CQA over hyper-relational knowledge graphs (HKGs), which include massive n-ary facts. The NQE utilizes a dual-heterogeneous Transformer encoder and fuzzy logic theory to satisfy all n-ary FOL queries, including existential quantifiers, conjunction, disjunction, and negation. We also propose a parallel processing algorithm that can train or predict arbitrary n-ary FOL queries in a single batch, regardless of the kind of each query, with good flexibility and extensibility. In addition, we generate a new CQA dataset WD50K-NFOL, including diverse n-ary FOL queries over WD50K. Experimental results on WD50K-NFOL and other standard CQA datasets show that NQE is the state-of-the-art CQA method over HKGs with good generalization capability. Our code and dataset are publicly available. ",
    "url": "https://arxiv.org/abs/2211.13469",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Yuhao Yang",
      "Gengxian Zhou",
      "Yikai Guo",
      "Tianyu Yao",
      "Zichen Tang",
      "Xueyuan Lin",
      "Kaiyang Wan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13490",
    "title": "Pose-disentangled Contrastive Learning for Self-supervised Facial  Representation",
    "abstract": "Self-supervised facial representation has recently attracted increasing attention due to its ability to perform face understanding without relying on large-scale annotated datasets heavily. However, analytically, current contrastive-based self-supervised learning still performs unsatisfactorily for learning facial representation. More specifically, existing contrastive learning (CL) tends to learn pose-invariant features that cannot depict the pose details of faces, compromising the learning performance. To conquer the above limitation of CL, we propose a novel Pose-disentangled Contrastive Learning (PCL) method for general self-supervised facial representation. Our PCL first devises a pose-disentangled decoder (PDD) with a delicately designed orthogonalizing regulation, which disentangles the pose-related features from the face-aware features; therefore, pose-related and other pose-unrelated facial information could be performed in individual subnetworks and do not affect each other's training. Furthermore, we introduce a pose-related contrastive learning scheme that learns pose-related information based on data augmentation of the same image, which would deliver more effective face-aware representation for various downstream tasks. We conducted a comprehensive linear evaluation on three challenging downstream facial understanding tasks, i.e., facial expression recognition, face recognition, and AU detection. Experimental results demonstrate that our method outperforms cutting-edge contrastive and other self-supervised learning methods with a great margin. ",
    "url": "https://arxiv.org/abs/2211.13490",
    "authors": [
      "Yuanyuan Liu",
      "Wenbin Wang",
      "Yibing Zhan",
      "Zhe Chen",
      "Shaoze Feng",
      "Kejun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13494",
    "title": "Immersive Neural Graphics Primitives",
    "abstract": "Neural radiance field (NeRF), in particular its extension by instant neural graphics primitives, is a novel rendering method for view synthesis that uses real-world images to build photo-realistic immersive virtual scenes. Despite its potential, research on the combination of NeRF and virtual reality (VR) remains sparse. Currently, there is no integration into typical VR systems available, and the performance and suitability of NeRF implementations for VR have not been evaluated, for instance, for different scene complexities or screen resolutions. In this paper, we present and evaluate a NeRF-based framework that is capable of rendering scenes in immersive VR allowing users to freely move their heads to explore complex real-world scenes. We evaluate our framework by benchmarking three different NeRF scenes concerning their rendering performance at different scene complexities and resolutions. Utilizing super-resolution, our approach can yield a frame rate of 30 frames per second with a resolution of 1280x720 pixels per eye. We discuss potential applications of our framework and provide an open source implementation online. ",
    "url": "https://arxiv.org/abs/2211.13494",
    "authors": [
      "Ke Li",
      "Tim Rolff",
      "Susanne Schmidt",
      "Reinhard Bacher",
      "Simone Frintrop",
      "Wim Leemans",
      "Frank Steinicke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13495",
    "title": "Few-shot Object Detection with Refined Contrastive Learning",
    "abstract": "Due to the scarcity of sampling data in reality, few-shot object detection (FSOD) has drawn more and more attention because of its ability to quickly train new detection concepts with less data. However, there are still failure identifications due to the difficulty in distinguishing confusable classes. We also notice that the high standard deviation of average precisions reveals the inconsistent detection performance. To this end, we propose a novel FSOD method with Refined Contrastive Learning (FSRC). A pre-determination component is introduced to find out the Resemblance Group (GR) from novel classes which contains confusable classes. Afterwards, refined contrastive learning (RCL) is pointedly performed on this group of classes in order to increase the inter-class distances among them. In the meantime, the detection results distribute more uniformly which further improve the performance. Experimental results based on PASCAL VOC and COCO datasets demonstrate our proposed method outperforms the current state-of-the-art research. FSRC can not only decouple the relevance of confusable classes to get a better performance, but also makes predictions more consistent by reducing the standard deviation of the AP of classes to be detected. ",
    "url": "https://arxiv.org/abs/2211.13495",
    "authors": [
      "Zeyu Shangguan",
      "Lian Huai",
      "Tong Liu",
      "Xingqun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13514",
    "title": "Link Count Data-driven Static Traffic Assignment Models Through Network  Modularity Partitioning",
    "abstract": "Accurate static traffic assignment models are important tools for the assessment of strategic transportation policies. In this article we present a novel approach to partition road networks through network modularity to produce data-driven static traffic assignment models from loop detector data on large road systems. The use of partitioning allows the estimation of the key model input of Origin-Destination demand matrices from flow counts alone. Previous network tomography-based demand estimation techniques have been limited by the network size. The amount of partitioning changes the Origin-Destination estimation optimisation problems to different levels of computational difficulty. Different approaches to utilising the partitioning were tested, one which degenerated the road network to the scale of the partitions and others which left the network intact. Applied to a subnetwork of England's Strategic Road Network and other test networks, our results for the degenerate case showed flow and travel time errors are reasonable with a small amount of degeneration. The results for the non-degenerate cases showed that similar errors in model prediction with lower computation requirements can be obtained when using large partitions compared with the non-partitioned case. This work could be used to improve the effectiveness of national road systems planning and infrastructure models. ",
    "url": "https://arxiv.org/abs/2211.13514",
    "authors": [
      "Alexander Roocroft",
      "Giuliano Punzo",
      "Muhamad Azfar Ramli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.13523",
    "title": "Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark",
    "abstract": "The evaluation of object detection models is usually performed by optimizing a single metric, e.g. mAP, on a fixed set of datasets, e.g. Microsoft COCO and Pascal VOC. Due to image retrieval and annotation costs, these datasets consist largely of images found on the web and do not represent many real-life domains that are being modelled in practice, e.g. satellite, microscopic and gaming, making it difficult to assert the degree of generalization learned by the model. We introduce the Roboflow-100 (RF100) consisting of 100 datasets, 7 imagery domains, 224,714 images, and 805 class labels with over 11,170 labelling hours. We derived RF100 from over 90,000 public datasets, 60 million public images that are actively being assembled and labelled by computer vision practitioners in the open on the web application Roboflow Universe. By releasing RF100, we aim to provide a semantically diverse, multi-domain benchmark of datasets to help researchers test their model's generalizability with real-life data. RF100 download and benchmark replication are available on GitHub. ",
    "url": "https://arxiv.org/abs/2211.13523",
    "authors": [
      "Floriana Ciaglia",
      "Francesco Saverio Zuppichini",
      "Paul Guerrie",
      "Mark McQuade",
      "Jacob Solawetz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13527",
    "title": "Beyond Mahalanobis-Based Scores for Textual OOD Detection",
    "abstract": "Deep learning methods have boosted the adoption of NLP systems in real-life applications. However, they turn out to be vulnerable to distribution shifts over time which may cause severe dysfunctions in production systems, urging practitioners to develop tools to detect out-of-distribution (OOD) samples through the lens of the neural network. In this paper, we introduce TRUSTED, a new OOD detector for classifiers based on Transformer architectures that meets operational requirements: it is unsupervised and fast to compute. The efficiency of TRUSTED relies on the fruitful idea that all hidden layers carry relevant information to detect OOD examples. Based on this, for a given input, TRUSTED consists in (i) aggregating this information and (ii) computing a similarity score by exploiting the training distribution, leveraging the powerful concept of data depth. Our extensive numerical experiments involve 51k model configurations, including various checkpoints, seeds, and datasets, and demonstrate that TRUSTED achieves state-of-the-art performances. In particular, it improves previous AUROC over 3 points. ",
    "url": "https://arxiv.org/abs/2211.13527",
    "authors": [
      "Pierre Colombo",
      "Eduardo D. C. Gomes",
      "Guillaume Staerman",
      "Nathan Noiry",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.13529",
    "title": "3D Dual-Fusion: Dual-Domain Dual-Query Camera-LiDAR Fusion for 3D Object  Detection",
    "abstract": "Fusing data from cameras and LiDAR sensors is an essential technique to achieve robust 3D object detection. One key challenge in camera-LiDAR fusion involves mitigating the large domain gap between the two sensors in terms of coordinates and data distribution when fusing their features. In this paper, we propose a novel camera-LiDAR fusion architecture called, 3D Dual-Fusion, which is designed to mitigate the gap between the feature representations of camera and LiDAR data. The proposed method fuses the features of the camera-view and 3D voxel-view domain and models their interactions through deformable attention. We redesign the transformer fusion encoder to aggregate the information from the two domains. Two major changes include 1) dual query-based deformable attention to fuse the dual-domain features interactively and 2) 3D local self-attention to encode the voxel-domain queries prior to dual-query decoding. The results of an experimental evaluation show that the proposed camera-LiDAR fusion architecture achieved competitive performance on the KITTI and nuScenes datasets, with state-of-the-art performances in some 3D object detection benchmarks categories. ",
    "url": "https://arxiv.org/abs/2211.13529",
    "authors": [
      "Yecheol Kim",
      "Konyul Park",
      "Minwook Kim",
      "Dongsuk Kum",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13535",
    "title": "Tracking Dataset IP Use in Deep Neural Networks",
    "abstract": "Training highly performant deep neural networks (DNNs) typically requires the collection of a massive dataset and the use of powerful computing resources. Therefore, unauthorized redistribution of private pre-trained DNNs may cause severe economic loss for model owners. For protecting the ownership of DNN models, DNN watermarking schemes have been proposed by embedding secret information in a DNN model and verifying its presence for model ownership. However, existing DNN watermarking schemes compromise the model utility and are vulnerable to watermark removal attacks because a model is modified with a watermark. Alternatively, a new approach dubbed DEEPJUDGE was introduced to measure the similarity between a suspect model and a victim model without modifying the victim model. However, DEEPJUDGE would only be designed to detect the case where a suspect model's architecture is the same as a victim model's. In this work, we propose a novel DNN fingerprinting technique dubbed DEEPTASTER to prevent a new attack scenario in which a victim's data is stolen to build a suspect model. DEEPTASTER can effectively detect such data theft attacks even when a suspect model's architecture differs from a victim model's. To achieve this goal, DEEPTASTER generates a few adversarial images with perturbations, transforms them into the Fourier frequency domain, and uses the transformed images to identify the dataset used in a suspect model. The intuition is that those adversarial images can be used to capture the characteristics of DNNs built on a specific dataset. We evaluated the detection accuracy of DEEPTASTER on three datasets with three model architectures under various attack scenarios, including transfer learning, pruning, fine-tuning, and data augmentation. Overall, DEEPTASTER achieves a balanced accuracy of 94.95%, which is significantly better than 61.11% achieved by DEEPJUDGE in the same settings. ",
    "url": "https://arxiv.org/abs/2211.13535",
    "authors": [
      "Seonhye Park",
      "Alsharif Abuadbba",
      "Shuo Wang",
      "Kristen Moore",
      "Yansong Gao",
      "Hyoungshick Kim",
      "Surya Nepal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13551",
    "title": "SfM-TTR: Using Structure from Motion for Test-Time Refinement of  Single-View Depth Networks",
    "abstract": "Estimating a dense depth map from a single view is geometrically ill-posed, and state-of-the-art methods rely on learning depth's relation with visual appearance using deep neural networks. On the other hand, Structure from Motion (SfM) leverages multi-view constraints to produce very accurate but sparse maps, as accurate matching across images is limited by locally discriminative texture. In this work, we combine the strengths of both approaches by proposing a novel test-time refinement (TTR) method, denoted as SfM-TTR, that boosts the performance of single-view depth networks at test time using SfM multi-view cues. Specifically, and differently from the state of the art, we use sparse SfM point clouds as test-time self-supervisory signal, fine-tuning the network encoder to learn a better representation of the test scene. Our results show how the addition of SfM-TTR to several state-of-the-art self-supervised and supervised networks improves significantly their performance, outperforming previous TTR baselines mainly based on photometric multi-view consistency. ",
    "url": "https://arxiv.org/abs/2211.13551",
    "authors": [
      "Sergio Izquierdo",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13577",
    "title": "Towards Interpretable Anomaly Detection via Invariant Rule Mining",
    "abstract": "In the research area of anomaly detection, novel and promising methods are frequently developed. However, most existing studies, especially those leveraging deep neural networks, exclusively focus on the detection task only and ignore the interpretability of the underlying models as well as their detection results. However, anomaly interpretation, which aims to provide explanation of why specific data instances are identified as anomalies, is an equally (if not more) important task in many real-world applications. In this work, we pursue highly interpretable anomaly detection via invariant rule mining. Specifically, we leverage decision tree learning and association rule mining to automatically generate invariant rules that are consistently satisfied by the underlying data generation process. The generated invariant rules can provide explicit explanation of anomaly detection results and thus are extremely useful for subsequent decision-making. Furthermore, our empirical evaluation shows that the proposed method can also achieve comparable performance in terms of AUC and partial AUC with popular anomaly detection models in various benchmark datasets. ",
    "url": "https://arxiv.org/abs/2211.13577",
    "authors": [
      "Cheng Feng",
      "Pingge Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13594",
    "title": "Self-supervised vision-language pretraining for Medical visual question  answering",
    "abstract": "Medical image visual question answering (VQA) is a task to answer clinical questions, given a radiographic image, which is a challenging problem that requires a model to integrate both vision and language information. To solve medical VQA problems with a limited number of training data, pretrain-finetune paradigm is widely used to improve the model generalization. In this paper, we propose a self-supervised method that applies Masked image modeling, Masked language modeling, Image text matching and Image text alignment via contrastive learning (M2I2) for pretraining on medical image caption dataset, and finetunes to downstream medical VQA tasks. The proposed method achieves state-of-the-art performance on all the three public medical VQA datasets. Our codes and models are available at https://github.com/pengfeiliHEU/M2I2. ",
    "url": "https://arxiv.org/abs/2211.13594",
    "authors": [
      "Pengfei Li",
      "Gang Liu",
      "Lin Tan",
      "Jinying Liao",
      "Shenjun Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13626",
    "title": "Bidding Graph Games with Partially-Observable Budgets",
    "abstract": "Two-player zero-sum \"graph games\" are a central model, which proceeds as follows. A token is placed on a vertex of a graph, and the two players move it to produce an infinite \"play\", which determines the winner or payoff of the game. Traditionally, the players alternate turns in moving the token. In \"bidding games\", however, the players have budgets and in each turn, an auction (bidding) determines which player moves the token. So far, bidding games have only been studied as full-information games. In this work we initiate the study of partial-information bidding games: we study bidding games in which a player's initial budget is drawn from a known probability distribution. We show that while for some bidding mechanisms and objectives, it is straightforward to adapt the results from the full-information setting to the partial-information setting, for others, the analysis is significantly more challenging, requires new techniques, and gives rise to interesting results. Specifically, we study games with \"mean-payoff\" objectives in combination with \"poorman\" bidding. We construct optimal strategies for a partially-informed player who plays against a fully-informed adversary. We show that, somewhat surprisingly, the \"value\" under pure strategies does not necessarily exist in such games. ",
    "url": "https://arxiv.org/abs/2211.13626",
    "authors": [
      "Guy Avni",
      "Ismael Jecker",
      "Djordje Zikelic"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2211.13638",
    "title": "Prototypical Fine-tuning: Towards Robust Performance Under Varying Data  Sizes",
    "abstract": "In this paper, we move towards combining large parametric models with non-parametric prototypical networks. We propose prototypical fine-tuning, a novel prototypical framework for fine-tuning pretrained language models (LM), which automatically learns a bias to improve predictive performance for varying data sizes, especially low-resource settings. Our prototypical fine-tuning approach can automatically adjust the model capacity according to the number of data points and the model's inherent attributes. Moreover, we propose four principles for effective prototype fine-tuning towards the optimal solution. Experimental results across various datasets show that our work achieves significant performance improvements under various low-resource settings, as well as comparable and usually better performances in high-resource scenarios. ",
    "url": "https://arxiv.org/abs/2211.13638",
    "authors": [
      "Yiqiao Jin",
      "Xiting Wang",
      "Yaru Hao",
      "Yizhou Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13649",
    "title": "End-to-end Wind Turbine Wake Modelling with Deep Graph Representation  Learning",
    "abstract": "Wind turbine wake modelling is of crucial importance to accurate resource assessment, to layout optimisation, and to the operational control of wind farms. This work proposes a surrogate model for the representation of wind turbine wakes based on a state-of-the-art graph representation learning method termed a graph neural network. The proposed end-to-end deep learning model operates directly on unstructured meshes and has been validated against high-fidelity data, demonstrating its ability to rapidly make accurate 3D flow field predictions for various inlet conditions and turbine yaw angles. The specific graph neural network model employed here is shown to generalise well to unseen data and is less sensitive to over-smoothing compared to common graph neural networks. A case study based upon a real world wind farm further demonstrates the capability of the proposed approach to predict farm scale power generation. Moreover, the proposed graph neural network framework is flexible and highly generic and as formulated here can be applied to any steady state computational fluid dynamics simulations on unstructured meshes. ",
    "url": "https://arxiv.org/abs/2211.13649",
    "authors": [
      "Siyi Li",
      "Mingrui Zhang",
      "Matthew Piggott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2211.13670",
    "title": "SmartIntentNN: Towards Smart Contract Intent Detection",
    "abstract": "Researchers currently have been focusing on smart contract vulnerability detection, but we find that developers' intent to write smart contracts is a more noteworthy security concern because smart contracts with malicious intent have caused significant financial loss to users. A more unfortunate fact is that we can only rely on manual audits to check for unfriendly smart contracts. In this paper, we propose \\textsc{SmartIntentNN}, Smart Contract Intent Neural Network, a deep learning-based tool that aims to automate the process of developers' intent detection in smart contracts, saving human resources and overhead. The demo video is available on \\url{https://youtu.be/ho1SMtYm-wI}. ",
    "url": "https://arxiv.org/abs/2211.13670",
    "authors": [
      "Youwei Huang",
      "Tao Zhang",
      "Sen Fang",
      "Youshuai Tan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.13692",
    "title": "To be or not to be stable, that is the question: understanding neural  networks for inverse problems",
    "abstract": "The solution of linear inverse problems arising, for example, in signal and image processing is a challenging problem, since the ill-conditioning amplifies the noise on the data. Recently introduced deep-learning based algorithms overwhelm the more traditional model-based approaches but they typically suffer from instability with respect to data perturbation. In this paper, we theoretically analyse the trade-off between neural networks stability and accuracy in the solution of linear inverse problems. Moreover, we propose different supervised and unsupervised solutions, to increase network stability by maintaining good accuracy, by inheriting, in the network training, regularization from a model-based iterative scheme. Extensive numerical experiments on image deblurring confirm the theoretical results and the effectiveness of the proposed networks in solving inverse problems with stability with respect to noise. ",
    "url": "https://arxiv.org/abs/2211.13692",
    "authors": [
      "Davide Evangelista",
      "James Nagy",
      "Elena Morotti",
      "Elena Loli Piccolomini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13694",
    "title": "Hand Guided High Resolution Feature Enhancement for Fine-Grained Atomic  Action Segmentation within Complex Human Assemblies",
    "abstract": "Due to the rapid temporal and fine-grained nature of complex human assembly atomic actions, traditional action segmentation approaches requiring the spatial (and often temporal) down sampling of video frames often loose vital fine-grained spatial and temporal information required for accurate classification within the manufacturing domain. In order to fully utilise higher resolution video data (often collected within the manufacturing domain) and facilitate real time accurate action segmentation - required for human robot collaboration - we present a novel hand location guided high resolution feature enhanced model. We also propose a simple yet effective method of deploying offline trained action recognition models for real time action segmentation on temporally short fine-grained actions, through the use of surround sampling while training and temporally aware label cleaning at inference. We evaluate our model on a novel action segmentation dataset containing 24 (+background) atomic actions from video data of a real world robotics assembly production line. Showing both high resolution hand features as well as traditional frame wide features improve fine-grained atomic action classification, and that though temporally aware label clearing our model is capable of surpassing similar encoder/decoder methods, while allowing for real time classification. ",
    "url": "https://arxiv.org/abs/2211.13694",
    "authors": [
      "Matthew Kent Myers",
      "Nick Wright",
      "Stephen McGough",
      "Nicholas Martin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13702",
    "title": "CasFusionNet: A Cascaded Network for Point Cloud Semantic Scene  Completion by Dense Feature Fusion",
    "abstract": "Semantic scene completion (SSC) aims to complete a partial 3D scene and predict its semantics simultaneously. Most existing works adopt the voxel representations, thus suffering from the growth of memory and computation cost as the voxel resolution increases. Though a few works attempt to solve SSC from the perspective of 3D point clouds, they have not fully exploited the correlation and complementarity between the two tasks of scene completion and semantic segmentation. In our work, we present CasFusionNet, a novel cascaded network for point cloud semantic scene completion by dense feature fusion. Specifically, we design (i) a global completion module (GCM) to produce an upsampled and completed but coarse point set, (ii) a semantic segmentation module (SSM) to predict the per-point semantic labels of the completed points generated by GCM, and (iii) a local refinement module (LRM) to further refine the coarse completed points and the associated labels from a local perspective. We organize the above three modules via dense feature fusion in each level, and cascade a total of four levels, where we also employ feature fusion between each level for sufficient information usage. Both quantitative and qualitative results on our compiled two point-based datasets validate the effectiveness and superiority of our CasFusionNet compared to state-of-the-art methods in terms of both scene completion and semantic segmentation. The codes and datasets are available at: https://github.com/JinfengX/CasFusionNet. ",
    "url": "https://arxiv.org/abs/2211.13702",
    "authors": [
      "Jinfeng Xu",
      "Xianzhi Li",
      "Yuan Tang",
      "Qiao Yu",
      "Yixue Hao",
      "Long Hu",
      "Min Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13718",
    "title": "Emotion-guided Cross-domain Fake News Detection using Adversarial Domain  Adaptation",
    "abstract": "Recent works on fake news detection have shown the efficacy of using emotions as a feature or emotions-based features for improved performance. However, the impact of these emotion-guided features for fake news detection in cross-domain settings, where we face the problem of domain shift, is still largely unexplored. In this work, we evaluate the impact of emotion-guided features for cross-domain fake news detection, and further propose an emotion-guided, domain-adaptive approach using adversarial learning. We prove the efficacy of emotion-guided models in cross-domain settings for various combinations of source and target datasets from FakeNewsAMT, Celeb, Politifact and Gossipcop datasets. ",
    "url": "https://arxiv.org/abs/2211.13718",
    "authors": [
      "Arjun Choudhry",
      "Inder Khatri",
      "Arkajyoti Chakraborty",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.13724",
    "title": "Estimating Regression Predictive Distributions with Sample Networks",
    "abstract": "Estimating the uncertainty in deep neural network predictions is crucial for many real-world applications. A common approach to model uncertainty is to choose a parametric distribution and fit the data to it using maximum likelihood estimation. The chosen parametric form can be a poor fit to the data-generating distribution, resulting in unreliable uncertainty estimates. In this work, we propose SampleNet, a flexible and scalable architecture for modeling uncertainty that avoids specifying a parametric form on the output distribution. SampleNets do so by defining an empirical distribution using samples that are learned with the Energy Score and regularized with the Sinkhorn Divergence. SampleNets are shown to be able to well-fit a wide range of distributions and to outperform baselines on large-scale real-world regression tasks. ",
    "url": "https://arxiv.org/abs/2211.13724",
    "authors": [
      "Ali Harakeh",
      "Jordan Hu",
      "Naiqing Guan",
      "Steven L. Waslander",
      "Liam Paull"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13734",
    "title": "On Pitfalls of Measuring Occlusion Robustness through Data Distortion",
    "abstract": "Over the past years, the crucial role of data has largely been shadowed by the field's focus on architectures and training procedures. We often cause changes to the data without being aware of their wider implications. In this paper we show that distorting images without accounting for the artefacts introduced leads to biased results when establishing occlusion robustness. To ensure models behave as expected in real-world scenarios, we need to rule out the impact added artefacts have on evaluation. We propose a new approach, iOcclusion, as a fairer alternative for applications where the possible occluders are unknown. ",
    "url": "https://arxiv.org/abs/2211.13734",
    "authors": [
      "Antonia Marcu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13748",
    "title": "How We Express Ourselves Freely: Censorship, Self-censorship, and  Anti-censorship on a Chinese Social Media",
    "abstract": "Censorship, anti-censorship, and self-censorship in an authoritarian regime have been extensively studies, yet the relationship between these intertwined factors is not well understood. In this paper, we report results of a large-scale survey study (N = 526) with Sina Weibo users toward bridging this research gap. Through descriptive statistics, correlation analysis, and regression analysis, we uncover how users are being censored, how and why they conduct self-censorship on different topics and in different scenarios (i.e., post, repost, and comment), and their various anti-censorship strategies. We further identify the metrics of censorship and self-censorship, find the influence factors, and construct a mediation model to measure their relationship. Based on these findings, we discuss implications for democratic social media design and future censorship research. ",
    "url": "https://arxiv.org/abs/2211.13748",
    "authors": [
      "Xiang Chen",
      "Jiamu Xie",
      "Zixin Wang",
      "Bohui Shen",
      "Zhixuan Zhou"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.13755",
    "title": "TemporalStereo: Efficient Spatial-Temporal Stereo Matching Network",
    "abstract": "We present TemporalStereo, a coarse-to-fine based online stereo matching network which is highly efficient, and able to effectively exploit the past geometry and context information to boost the matching accuracy. Our network leverages sparse cost volume and proves to be effective when a single stereo pair is given, however, its peculiar ability to use spatio-temporal information across frames allows TemporalStereo to alleviate problems such as occlusions and reflective regions while enjoying high efficiency also in the case of stereo sequences. Notably our model trained, once with stereo videos, can run in both single-pair and temporal ways seamlessly. Experiments show that our network relying on camera motion is even robust to dynamic objects when running on videos. We validate TemporalStereo through extensive experiments on synthetic (SceneFlow, TartanAir) and real (KITTI 2012, KITTI 2015) datasets. Detailed results show that our model achieves state-of-the-art performance on any of these datasets. Code is available at \\url{https://github.com/youmi-zym/TemporalStereo.git}. ",
    "url": "https://arxiv.org/abs/2211.13755",
    "authors": [
      "Youmin Zhang",
      "Matteo Poggi",
      "Stefano Mattoccia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13756",
    "title": "Contrastive pretraining for semantic segmentation is robust to noisy  positive pairs",
    "abstract": "Domain-specific variants of contrastive learning can construct positive pairs from two distinct images, as opposed to augmenting the same image twice. Unlike in traditional contrastive methods, this can result in positive pairs not matching perfectly. Similar to false negative pairs, this could impede model performance. Surprisingly, we find that downstream semantic segmentation is either robust to the noisy pairs or even benefits from them. The experiments are conducted on the remote sensing dataset xBD, and a synthetic segmentation dataset, on which we have full control over the noise parameters. As a result, practitioners should be able to use such domain-specific contrastive methods without having to filter their positive pairs beforehand. ",
    "url": "https://arxiv.org/abs/2211.13756",
    "authors": [
      "Sebastian Gerard",
      "Josephine Sullivan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13762",
    "title": "ScanNeRF: a Scalable Benchmark for Neural Radiance Fields",
    "abstract": "In this paper, we propose the first-ever real benchmark thought for evaluating Neural Radiance Fields (NeRFs) and, in general, Neural Rendering (NR) frameworks. We design and implement an effective pipeline for scanning real objects in quantity and effortlessly. Our scan station is built with less than 500$ hardware budget and can collect roughly 4000 images of a scanned object in just 5 minutes. Such a platform is used to build ScanNeRF, a dataset characterized by several train/val/test splits aimed at benchmarking the performance of modern NeRF methods under different conditions. Accordingly, we evaluate three cutting-edge NeRF variants on it to highlight their strengths and weaknesses. The dataset is available on our project page, together with an online benchmark to foster the development of better and better NeRFs. ",
    "url": "https://arxiv.org/abs/2211.13762",
    "authors": [
      "Luca De Luigi",
      "Damiano Bolognini",
      "Federico Domeniconi",
      "Daniele De Gregorio",
      "Matteo Poggi",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13769",
    "title": "On designing light-weight object trackers through network pruning: Use  CNNs or transformers?",
    "abstract": "Object trackers deployed on low-power devices need to be light-weight, however, most of the current state-of-the-art (SOTA) methods rely on using compute-heavy backbones built using CNNs or transformers. Large sizes of such models do not allow their deployment in low-power conditions and designing compressed variants of large tracking models is of great importance. This paper demonstrates how highly compressed light-weight object trackers can be designed using neural architectural pruning of large CNN and transformer based trackers. Further, a comparative study on architectural choices best suited to design light-weight trackers is provided. A comparison between SOTA trackers using CNNs, transformers as well as the combination of the two is presented to study their stability at various compression ratios. Finally results for extreme pruning scenarios going as low as 1% in some cases are shown to study the limits of network pruning in object tracking. This work provides deeper insights into designing highly efficient trackers from existing SOTA methods. ",
    "url": "https://arxiv.org/abs/2211.13769",
    "authors": [
      "Saksham Aggarwal",
      "Taneesh Gupta",
      "Pawan Kumar Sahu",
      "Arnav Chavan",
      "Rishabh Tiwari",
      "Dilip K. Prasad",
      "Deepak K. Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13771",
    "title": "Towards Practical Control of Singular Values of Convolutional Layers",
    "abstract": "In general, convolutional neural networks (CNNs) are easy to train, but their essential properties, such as generalization error and adversarial robustness, are hard to control. Recent research demonstrated that singular values of convolutional layers significantly affect such elusive properties and offered several methods for controlling them. Nevertheless, these methods present an intractable computational challenge or resort to coarse approximations. In this paper, we offer a principled approach to alleviating constraints of the prior art at the expense of an insignificant reduction in layer expressivity. Our method is based on the tensor-train decomposition; it retains control over the actual singular values of convolutional mappings while providing structurally sparse and hardware-friendly representation. We demonstrate the improved properties of modern CNNs with our method and analyze its impact on the model performance, calibration, and adversarial robustness. The source code is available at: https://github.com/WhiteTeaDragon/practical_svd_conv ",
    "url": "https://arxiv.org/abs/2211.13771",
    "authors": [
      "Alexandra Senderovich",
      "Ekaterina Bulatova",
      "Anton Obukhov",
      "Maxim Rakhuba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13775",
    "title": "SAGA: Spectral Adversarial Geometric Attack on 3D Meshes",
    "abstract": "A triangular mesh is one of the most popular 3D data representations. As such, the deployment of deep neural networks for mesh processing is widely spread and is increasingly attracting more attention. However, neural networks are prone to adversarial attacks, where carefully crafted inputs impair the model's functionality. The need to explore these vulnerabilities is a fundamental factor in the future development of 3D-based applications. Recently, mesh attacks were studied on the semantic level, where classifiers are misled to produce wrong predictions. Nevertheless, mesh surfaces possess complex geometric attributes beyond their semantic meaning, and their analysis often includes the need to encode and reconstruct the geometry of the shape. We propose a novel framework for a geometric adversarial attack on a 3D mesh autoencoder. In this setting, an adversarial input mesh deceives the autoencoder by forcing it to reconstruct a different geometric shape at its output. The malicious input is produced by perturbing a clean shape in the spectral domain. Our method leverages the spectral decomposition of the mesh along with additional mesh-related properties to obtain visually credible results that consider the delicacy of surface distortions. Our code is publicly available at https://github.com/StolikTomer/SAGA. ",
    "url": "https://arxiv.org/abs/2211.13775",
    "authors": [
      "Tomer Stolik",
      "Itai Lang",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13776",
    "title": "German Phoneme Recognition with Text-to-Phoneme Data Augmentation",
    "abstract": "In this study, we experimented to examine the effect of adding the most frequent n phoneme bigrams to the basic vocabulary on the German phoneme recognition model using the text-to-phoneme data augmentation strategy. As a result, compared to the baseline model, the vowel30 model and the const20 model showed an increased BLEU score of more than 1 point, and the total30 model showed a significant decrease in the BLEU score of more than 20 points, showing that the phoneme bigrams could have a positive or negative effect on the model performance. In addition, we identified the types of errors that the models repeatedly showed through error analysis. ",
    "url": "https://arxiv.org/abs/2211.13776",
    "authors": [
      "Dojun Park",
      "Seohyun Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.13787",
    "title": "Semantic Communication Enabling Robust Edge Intelligence for  Time-Critical IoT Applications",
    "abstract": "This paper aims to design robust Edge Intelligence using semantic communication for time-critical IoT applications. We systematically analyze the effect of image DCT coefficients on inference accuracy and propose the channel-agnostic effectiveness encoding for offloading by transmitting the most meaningful task data first. This scheme can well utilize all available communication resource and strike a balance between transmission latency and inference accuracy. Then, we design an effectiveness decoding by implementing a novel image augmentation process for convolutional neural network (CNN) training, through which an original CNN model is transformed into a Robust CNN model. We use the proposed training method to generate Robust MobileNet-v2 and Robust ResNet-50. The proposed Edge Intelligence framework consists of the proposed effectiveness encoding and effectiveness decoding. The experimental results show that the effectiveness decoding using the Robust CNN models perform consistently better under various image distortions caused by channel errors or limited communication resource. The proposed Edge Intelligence framework using semantic communication significantly outperforms the conventional approach under latency and data rate constraints, in particular, under ultra stringent deadlines and low data rate. ",
    "url": "https://arxiv.org/abs/2211.13787",
    "authors": [
      "Andrea Cavagn",
      "Nan Li",
      "Alexandros Iosifidis",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.13800",
    "title": "Estimation of a Causal Directed Acyclic Graph Process using  Non-Gaussianity",
    "abstract": "Numerous approaches have been proposed to discover causal dependencies in machine learning and data mining; among them, the state-of-the-art VAR-LiNGAM (short for Vector Auto-Regressive Linear Non-Gaussian Acyclic Model) is a desirable approach to reveal both the instantaneous and time-lagged relationships. However, all the obtained VAR matrices need to be analyzed to infer the final causal graph, leading to a rise in the number of parameters. To address this issue, we propose the CGP-LiNGAM (short for Causal Graph Process-LiNGAM), which has significantly fewer model parameters and deals with only one causal graph for interpreting the causal relations by exploiting Graph Signal Processing (GSP). ",
    "url": "https://arxiv.org/abs/2211.13800",
    "authors": [
      "Aref Einizade",
      "Sepideh Hajipour Sardouie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.13808",
    "title": "Detecting Anomalies using Generative Adversarial Networks on Images",
    "abstract": "Automatic detection of anomalies such as weapons or threat objects in baggage security, or detecting impaired items in industrial production is an important computer vision task demanding high efficiency and accuracy. Most of the available data in the anomaly detection task is imbalanced as the number of positive/anomalous instances is sparse. Inadequate availability of the data makes training of a deep neural network architecture for anomaly detection challenging. This paper proposes a novel Generative Adversarial Network (GAN) based model for anomaly detection. It uses normal (non-anomalous) images to learn about the normality based on which it detects if an input image contains an anomalous/threat object. The proposed model uses a generator with an encoder-decoder network having dense convolutional skip connections for enhanced reconstruction and to capture the data distribution. A self-attention augmented discriminator is used having the ability to check the consistency of detailed features even in distant portions. We use spectral normalisation to facilitate stable and improved training of the GAN. Experiments are performed on three datasets, viz. CIFAR-10, MVTec AD (for industrial applications) and SIXray (for X-ray baggage security). On the MVTec AD and SIXray datasets, our model achieves an improvement of upto 21% and 4.6%, respectively ",
    "url": "https://arxiv.org/abs/2211.13808",
    "authors": [
      "Rushikesh Zawar",
      "Krupa Bhayani",
      "Neelanjan Bhowmik",
      "Kamlesh Tiwari",
      "Dhiraj Sangwan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.13812",
    "title": "Multi-Template Temporal Siamese Network for Long-Term Object Tracking",
    "abstract": "Siamese Networks are one of most popular visual object tracking methods for their high speed and high accuracy tracking ability as long as the target is well identified. However, most Siamese Network based trackers use the first frame as the ground truth of an object and fail when target appearance changes significantly in next frames. They also have dif iculty distinguishing the target from similar other objects in the frame. We propose two ideas to solve both problems. The first idea is using a bag of dynamic templates, containing diverse, similar, and recent target features and continuously updating it with diverse target appearances. The other idea is to let a network learn the path history and project a potential future target location in a next frame. This tracker achieves state-of-the-art performance on the long-term tracking dataset UAV20L by improving the success rate by a large margin of 15% (65.4 vs 56.6) compared to the state-of-the-art method, HiFT. The of icial python code of this paper is publicly available. ",
    "url": "https://arxiv.org/abs/2211.13812",
    "authors": [
      "Ali Sekhavati",
      "Won-Sook Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13818",
    "title": "Digital Twin-Driven Computing Resource Management for Vehicular Networks",
    "abstract": "This paper presents a novel approach for computing resource management of edge servers in vehicular networks based on digital twins and artificial intelligence (AI). Specifically, we construct two-tier digital twins tailored for vehicular networks to capture networking-related features of vehicles and edge servers. By exploiting such features, we propose a two-stage computing resource allocation scheme. First, the central controller periodically generates reference policies for real-time computing resource allocation according to the network dynamics and service demands captured by digital twins of edge servers. Second, computing resources of the edge servers are allocated in real time to individual vehicles via low-complexity matching-based allocation that complies with the reference policies. By leveraging digital twins, the proposed scheme can adapt to dynamic service demands and vehicle mobility in a scalable manner. Simulation results demonstrate that the proposed digital twin-driven scheme enables the vehicular network to support more computing tasks than benchmark schemes. ",
    "url": "https://arxiv.org/abs/2211.13818",
    "authors": [
      "Mushu Li",
      "Jie Gao",
      "Conghao Zhou",
      "Xuemin",
      "Shen",
      "Weihua Zhuang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.13823",
    "title": "Neural Weight Search for Scalable Task Incremental Learning",
    "abstract": "Task incremental learning aims to enable a system to maintain its performance on previously learned tasks while learning new tasks, solving the problem of catastrophic forgetting. One promising approach is to build an individual network or sub-network for future tasks. However, this leads to an ever-growing memory due to saving extra weights for new tasks and how to address this issue has remained an open problem in task incremental learning. In this paper, we introduce a novel Neural Weight Search technique that designs a fixed search space where the optimal combinations of frozen weights can be searched to build new models for novel tasks in an end-to-end manner, resulting in scalable and controllable memory growth. Extensive experiments on two benchmarks, i.e., Split-CIFAR-100 and CUB-to-Sketches, show our method achieves state-of-the-art performance with respect to both average inference accuracy and total memory cost. ",
    "url": "https://arxiv.org/abs/2211.13823",
    "authors": [
      "Jian Jiang",
      "Oya Celiktutan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13829",
    "title": "Learning-enhanced Nonlinear Model Predictive Control using  Knowledge-based Neural Ordinary Differential Equations and Deep Ensembles",
    "abstract": "Nonlinear model predictive control (MPC) is a flexible and increasingly popular framework used to synthesize feedback control strategies that can satisfy both state and control input constraints. In this framework, an optimization problem, subjected to a set of dynamics constraints characterized by a nonlinear dynamics model, is solved at each time step. Despite its versatility, the performance of nonlinear MPC often depends on the accuracy of the dynamics model. In this work, we leverage deep learning tools, namely knowledge-based neural ordinary differential equations (KNODE) and deep ensembles, to improve the prediction accuracy of this model. In particular, we learn an ensemble of KNODE models, which we refer to as the KNODE ensemble, to obtain an accurate prediction of the true system dynamics. This learned model is then integrated into a novel learning-enhanced nonlinear MPC framework. We provide sufficient conditions that guarantees asymptotic stability of the closed-loop system and show that these conditions can be implemented in practice. We show that the KNODE ensemble provides more accurate predictions and illustrate the efficacy and closed-loop performance of the proposed nonlinear MPC framework using two case studies. ",
    "url": "https://arxiv.org/abs/2211.13829",
    "authors": [
      "Kong Yao Chee",
      "M. Ani Hsieh",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.13838",
    "title": "Signed Binary Weight Networks: Improving Efficiency of Binary Weight  Networks by Exploiting Sparsity",
    "abstract": "Efficient inference of Deep Neural Networks (DNNs) is essential to making AI ubiquitous. Two important algorithmic techniques have shown promise for enabling efficient inference - sparsity and binarization. These techniques translate into weight sparsity and weight repetition at the hardware-software level allowing the deployment of DNNs with critically low power and latency requirements. We propose a new method called signed-binary networks to improve further efficiency (by exploiting both weight sparsity and weight repetition) while maintaining similar accuracy. Our method achieves comparable accuracy on ImageNet and CIFAR10 datasets with binary and can lead to $>69\\%$ sparsity. We observe real speedup when deploying these models on general-purpose devices. We show that this high percentage of unstructured sparsity can lead to a further ~2x reduction in energy consumption on ASICs with respect to binary. ",
    "url": "https://arxiv.org/abs/2211.13838",
    "authors": [
      "Sachit Kuhar",
      "Alexey Tumanov",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2211.13844",
    "title": "Ladder Siamese Network: a Method and Insights for Multi-level  Self-Supervised Learning",
    "abstract": "Siamese-network-based self-supervised learning (SSL) suffers from slow convergence and instability in training. To alleviate this, we propose a framework to exploit intermediate self-supervisions in each stage of deep nets, called the Ladder Siamese Network. Our self-supervised losses encourage the intermediate layers to be consistent with different data augmentations to single samples, which facilitates training progress and enhances the discriminative ability of the intermediate layers themselves. While some existing work has already utilized multi-level self supervisions in SSL, ours is different in that 1) we reveal its usefulness with non-contrastive Siamese frameworks in both theoretical and empirical viewpoints, and 2) ours improves image-level classification, instance-level detection, and pixel-level segmentation simultaneously. Experiments show that the proposed framework can improve BYOL baselines by 1.0% points in ImageNet linear classification, 1.2% points in COCO detection, and 3.1% points in PASCAL VOC segmentation. In comparison with the state-of-the-art methods, our Ladder-based model achieves competitive and balanced performances in all tested benchmarks without causing large degradation in one. ",
    "url": "https://arxiv.org/abs/2211.13844",
    "authors": [
      "Ryota Yoshihashi",
      "Shuhei Nishimura",
      "Dai Yonebayashi",
      "Yuya Otsuka",
      "Tomohiro Tanaka",
      "Takashi Miyazaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13853",
    "title": "Extreme Acceleration of Graph Neural Network-based Prediction Models for  Quantum Chemistry",
    "abstract": "Molecular property calculations are the bedrock of chemical physics. High-fidelity \\textit{ab initio} modeling techniques for computing the molecular properties can be prohibitively expensive, and motivate the development of machine-learning models that make the same predictions more efficiently. Training graph neural networks over large molecular databases introduces unique computational challenges such as the need to process millions of small graphs with variable size and support communication patterns that are distinct from learning over large graphs such as social networks. This paper demonstrates a novel hardware-software co-design approach to scale up the training of graph neural networks for molecular property prediction. We introduce an algorithm to coalesce the batches of molecular graphs into fixed size packs to eliminate redundant computation and memory associated with alternative padding techniques and improve throughput via minimizing communication. We demonstrate the effectiveness of our co-design approach by providing an implementation of a well-established molecular property prediction model on the Graphcore Intelligence Processing Units (IPU). We evaluate the training performance on multiple molecular graph databases with varying degrees of graph counts, sizes and sparsity. We demonstrate that such a co-design approach can reduce the training time of such molecular property prediction models from days to less than two hours, opening new possibilities for AI-driven scientific discovery. ",
    "url": "https://arxiv.org/abs/2211.13853",
    "authors": [
      "Hatem Helal",
      "Jesun Firoz",
      "Jenna Bilbrey",
      "Mario Michael Krell",
      "Tom Murray",
      "Ang Li",
      "Sotiris Xantheas",
      "Sutanay Choudhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2211.13856",
    "title": "WSSL: Weighted Self-supervised Learning Framework For Image-inpainting",
    "abstract": "Image inpainting is the process of regenerating lost parts of the image. Supervised algorithm-based methods have shown excellent results but have two significant drawbacks. They do not perform well when tested with unseen data. They fail to capture the global context of the image, resulting in a visually unappealing result. We propose a novel self-supervised learning framework for image-inpainting: Weighted Self-Supervised Learning (WSSL) to tackle these problems. We designed WSSL to learn features from multiple weighted pretext tasks. These features are then utilized for the downstream task, image-inpainting. To improve the performance of our framework and produce more visually appealing images, we also present a novel loss function for image inpainting. The loss function takes advantage of both reconstruction loss and perceptual loss functions to regenerate the image. Our experimentation shows WSSL outperforms previous methods, and our loss function helps produce better results. ",
    "url": "https://arxiv.org/abs/2211.13856",
    "authors": [
      "Shubham Gupta",
      "Rahul Kunigal Ravishankar",
      "Madhoolika Gangaraju",
      "Poojasree Dwarkanath",
      "Natarajan Subramanyam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13858",
    "title": "Far3Det: Towards Far-Field 3D Detection",
    "abstract": "We focus on the task of far-field 3D detection (Far3Det) of objects beyond a certain distance from an observer, e.g., $>$50m. Far3Det is particularly important for autonomous vehicles (AVs) operating at highway speeds, which require detections of far-field obstacles to ensure sufficient braking distances. However, contemporary AV benchmarks such as nuScenes underemphasize this problem because they evaluate performance only up to a certain distance (50m). One reason is that obtaining far-field 3D annotations is difficult, particularly for lidar sensors that produce very few point returns for far-away objects. Indeed, we find that almost 50% of far-field objects (beyond 50m) contain zero lidar points. Secondly, current metrics for 3D detection employ a \"one-size-fits-all\" philosophy, using the same tolerance thresholds for near and far objects, inconsistent with tolerances for both human vision and stereo disparities. Both factors lead to an incomplete analysis of the Far3Det task. For example, while conventional wisdom tells us that high-resolution RGB sensors should be vital for 3D detection of far-away objects, lidar-based methods still rank higher compared to RGB counterparts on the current benchmark leaderboards. As a first step towards a Far3Det benchmark, we develop a method to find well-annotated scenes from the nuScenes dataset and derive a well-annotated far-field validation set. We also propose a Far3Det evaluation protocol and explore various 3D detection methods for Far3Det. Our result convincingly justifies the long-held conventional wisdom that high-resolution RGB improves 3D detection in the far-field. We further propose a simple yet effective method that fuses detections from RGB and lidar detectors based on non-maximum suppression, which remarkably outperforms state-of-the-art 3D detectors in the far-field. ",
    "url": "https://arxiv.org/abs/2211.13858",
    "authors": [
      "Shubham Gupta",
      "Jeet Kanjani",
      "Mengtian Li",
      "Francesco Ferroni",
      "James Hays",
      "Deva Ramanan",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.13859",
    "title": "DATE: Dual Assignment for End-to-End Fully Convolutional Object  Detection",
    "abstract": "Fully convolutional detectors discard the one-to-many assignment and adopt a one-to-one assigning strategy to achieve end-to-end detection but suffer from the slow convergence issue. In this paper, we revisit these two assignment methods and find that bringing one-to-many assignment back to end-to-end fully convolutional detectors helps with model convergence. Based on this observation, we propose {\\em \\textbf{D}ual \\textbf{A}ssignment} for end-to-end fully convolutional de\\textbf{TE}ction (DATE). Our method constructs two branches with one-to-many and one-to-one assignment during training and speeds up the convergence of the one-to-one assignment branch by providing more supervision signals. DATE only uses the branch with the one-to-one matching strategy for model inference, which doesn't bring inference overhead. Experimental results show that Dual Assignment gives nontrivial improvements and speeds up model convergence upon OneNet and DeFCN. Code: https://github.com/YiqunChen1999/date. ",
    "url": "https://arxiv.org/abs/2211.13859",
    "authors": [
      "Yiqun Chen",
      "Qiang Chen",
      "Qinghao Hu",
      "Jian Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13860",
    "title": "Fast and Efficient Malware Detection with Joint Static and Dynamic  Features Through Transfer Learning",
    "abstract": "In malware detection, dynamic analysis extracts the runtime behavior of malware samples in a controlled environment and static analysis extracts features using reverse engineering tools. While the former faces the challenges of anti-virtualization and evasive behavior of malware samples, the latter faces the challenges of code obfuscation. To tackle these drawbacks, prior works proposed to develop detection models by aggregating dynamic and static features, thus leveraging the advantages of both approaches. However, simply concatenating dynamic and static features raises an issue of imbalanced contribution due to the heterogeneous dimensions of feature vectors to the performance of malware detection models. Yet, dynamic analysis is a time-consuming task and requires a secure environment, leading to detection delays and high costs for maintaining the analysis infrastructure. In this paper, we first introduce a method of constructing aggregated features via concatenating latent features learned through deep learning with equally-contributed dimensions. We then develop a knowledge distillation technique to transfer knowledge learned from aggregated features by a teacher model to a student model trained only on static features and use the trained student model for the detection of new malware samples. We carry out extensive experiments with a dataset of 86709 samples including both benign and malware samples. The experimental results show that the teacher model trained on aggregated features constructed by our method outperforms the state-of-the-art models with an improvement of up to 2.38% in detection accuracy. The distilled student model not only achieves high performance (97.81% in terms of accuracy) as that of the teacher model but also significantly reduces the detection time (from 70046.6 ms to 194.9 ms) without requiring dynamic analysis. ",
    "url": "https://arxiv.org/abs/2211.13860",
    "authors": [
      "Mao V. Ngo",
      "Tram Truong-Huu",
      "Dima Rabadi",
      "Jia Yi Loo",
      "Sin G. Teo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.13865",
    "title": "Competency-Aware Neural Machine Translation: Can Machine Translation  Know its Own Translation Quality?",
    "abstract": "Neural machine translation (NMT) is often criticized for failures that happen without awareness. The lack of competency awareness makes NMT untrustworthy. This is in sharp contrast to human translators who give feedback or conduct further investigations whenever they are in doubt about predictions. To fill this gap, we propose a novel competency-aware NMT by extending conventional NMT with a self-estimator, offering abilities to translate a source sentence and estimate its competency. The self-estimator encodes the information of the decoding procedure and then examines whether it can reconstruct the original semantics of the source sentence. Experimental results on four translation tasks demonstrate that the proposed method not only carries out translation tasks intact but also delivers outstanding performance on quality estimation. Without depending on any reference or annotated data typically required by state-of-the-art metric and quality estimation methods, our model yields an even higher correlation with human quality judgments than a variety of aforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and qualitative analyses show better robustness of competency awareness in our model. ",
    "url": "https://arxiv.org/abs/2211.13865",
    "authors": [
      "Pei Zhang",
      "Baosong Yang",
      "Haoran Wei",
      "Dayiheng Liu",
      "Kai Fan",
      "Luo Si",
      "Jun Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13868",
    "title": "Can Knowledge of End-to-End Text-to-Speech Models Improve Neural  MIDI-to-Audio Synthesis Systems?",
    "abstract": "With the similarity between music and speech synthesis from symbolic input and the rapid development of text-to-speech (TTS) techniques, it is worthwhile to explore ways to improve the MIDI-to-audio performance by borrowing from TTS techniques. In this study, we analyze the shortcomings of a TTS-based MIDI-to-audio system and improve it in terms of feature computation, model selection, and training strategy, aiming to synthesize highly natural-sounding audio. Moreover, we conducted an extensive model evaluation through listening tests, pitch measurement, and spectrogram analysis. This work demonstrates not only synthesis of highly natural music but offers a thorough analytical approach and useful outcomes for the community. Our code and pre-trained models are open sourced at https://github.com/nii-yamagishilab/midi-to-audio. ",
    "url": "https://arxiv.org/abs/2211.13868",
    "authors": [
      "Xuan Shi",
      "Erica Cooper",
      "Xin Wang",
      "Junichi Yamagishi",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.13896",
    "title": "MUSIED: A Benchmark for Event Detection from Multi-Source Heterogeneous  Informal Texts",
    "abstract": "Event detection (ED) identifies and classifies event triggers from unstructured texts, serving as a fundamental task for information extraction. Despite the remarkable progress achieved in the past several years, most research efforts focus on detecting events from formal texts (e.g., news articles, Wikipedia documents, financial announcements). Moreover, the texts in each dataset are either from a single source or multiple yet relatively homogeneous sources. With massive amounts of user-generated text accumulating on the Web and inside enterprises, identifying meaningful events in these informal texts, usually from multiple heterogeneous sources, has become a problem of significant practical value. As a pioneering exploration that expands event detection to the scenarios involving informal and heterogeneous texts, we propose a new large-scale Chinese event detection dataset based on user reviews, text conversations, and phone conversations in a leading e-commerce platform for food service. We carefully investigate the proposed dataset's textual informality and multi-source heterogeneity characteristics by inspecting data samples quantitatively and qualitatively. Extensive experiments with state-of-the-art event detection methods verify the unique challenges posed by these characteristics, indicating that multi-source informal event detection remains an open problem and requires further efforts. Our benchmark and code are released at \\url{https://github.com/myeclipse/MUSIED}. ",
    "url": "https://arxiv.org/abs/2211.13896",
    "authors": [
      "Xiangyu Xi",
      "Jianwei Lv",
      "Shuaipeng Liu",
      "Wei Ye",
      "Fan Yang",
      "Guanglu Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.13897",
    "title": "AFR-Net: Attention-Driven Fingerprint Recognition Network",
    "abstract": "The use of vision transformers (ViT) in computer vision is increasing due to limited inductive biases (e.g., locality, weight sharing, etc.) and increased scalability compared to other deep learning methods (e.g., convolutional neural networks (CNN)). This has led to some initial studies on the use of ViT for biometric recognition, including fingerprint recognition. In this work, we improve on these initial studies for transformers in fingerprint recognition by i.) evaluating additional attention-based architectures in addition to vanilla ViT, ii.) scaling to larger and more diverse training and evaluation datasets, and iii.) combining the complimentary representations of attention-based and CNN-based embeddings for improved state-of-the-art (SOTA) fingerprint recognition for both authentication (1:1 comparisons) and identification (1:N comparisions). Our combined architecture, AFR-Net (Attention-Driven Fingerprint Recognition Network), outperforms several baseline transformer and CNN-based models, including a SOTA commercial fingerprint system, Verifinger v12.3, across many intra-sensor, cross-sensor (including contact to contactless), and latent to rolled fingerprint matching datasets. Additionally, we propose a realignment strategy using local embeddings extracted from intermediate feature maps within the networks to refine the global embeddings in low certainty situations, which boosts the overall recognition accuracy significantly for all the evaluations across each of the models. This realignment strategy requires no additional training and can be applied as a wrapper to any existing deep learning network (including attention-based, CNN-based, or both) to boost its performance. ",
    "url": "https://arxiv.org/abs/2211.13897",
    "authors": [
      "Steven A. Grosz",
      "Anil K. Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13900",
    "title": "A Deep Learning Anomaly Detection Method in Textual Data",
    "abstract": "In this article, we propose using deep learning and transformer architectures combined with classical machine learning algorithms to detect and identify text anomalies in texts. Deep learning model provides a very crucial context information about the textual data which all textual context are converted to a numerical representation. We used multiple machine learning methods such as Sentence Transformers, Auto Encoders, Logistic Regression and Distance calculation methods to predict anomalies. The method are tested on the texts data and we used syntactic data from different source injected into the original text as anomalies or use them as target. Different methods and algorithm are explained in the field of outlier detection and the results of the best technique is presented. These results suggest that our algorithm could potentially reduce false positive rates compared with other anomaly detection methods that we are testing. ",
    "url": "https://arxiv.org/abs/2211.13900",
    "authors": [
      "Amir Jafari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.13902",
    "title": "TAOTF: A Two-stage Approximately Orthogonal Training Framework in Deep  Neural Networks",
    "abstract": "The orthogonality constraints, including the hard and soft ones, have been used to normalize the weight matrices of Deep Neural Network (DNN) models, especially the Convolutional Neural Network (CNN) and Vision Transformer (ViT), to reduce model parameter redundancy and improve training stability. However, the robustness to noisy data of these models with constraints is not always satisfactory. In this work, we propose a novel two-stage approximately orthogonal training framework (TAOTF) to find a trade-off between the orthogonal solution space and the main task solution space to solve this problem in noisy data scenarios. In the first stage, we propose a novel algorithm called polar decomposition-based orthogonal initialization (PDOI) to find a good initialization for the orthogonal optimization. In the second stage, unlike other existing methods, we apply soft orthogonal constraints for all layers of DNN model. We evaluate the proposed model-agnostic framework both on the natural image and medical image datasets, which show that our method achieves stable and superior performances to existing methods. ",
    "url": "https://arxiv.org/abs/2211.13902",
    "authors": [
      "Taoyong Cui",
      "Jianze Li",
      "Yuhan Dong",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13916",
    "title": "Towards Good Practices for Missing Modality Robust Action Recognition",
    "abstract": "Standard multi-modal models assume the use of the same modalities in training and inference stages. However, in practice, the environment in which multi-modal models operate may not satisfy such assumption. As such, their performances degrade drastically if any modality is missing in the inference stage. We ask: how can we train a model that is robust to missing modalities? This paper seeks a set of good practices for multi-modal action recognition, with a particular interest in circumstances where some modalities are not available at an inference time. First, we study how to effectively regularize the model during training (e.g., data augmentation). Second, we investigate on fusion methods for robustness to missing modalities: we find that transformer-based fusion shows better robustness for missing modality than summation or concatenation. Third, we propose a simple modular network, ActionMAE, which learns missing modality predictive coding by randomly dropping modality features and tries to reconstruct them with the remaining modality features. Coupling these good practices, we build a model that is not only effective in multi-modal action recognition but also robust to modality missing. Our model achieves the state-of-the-arts on multiple benchmarks and maintains competitive performances even in missing modality scenarios. Codes are available at https://github.com/sangminwoo/ActionMAE. ",
    "url": "https://arxiv.org/abs/2211.13916",
    "authors": [
      "Sangmin Woo",
      "Sumin Lee",
      "Yeonju Park",
      "Muhammad Adi Nugroho",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13929",
    "title": "XKD: Cross-modal Knowledge Distillation with Domain Alignment for Video  Representation Learning",
    "abstract": "We present XKD, a novel self-supervised framework to learn meaningful representations from unlabelled video clips. XKD is trained with two pseudo tasks. First, masked data reconstruction is performed to learn modality-specific representations. Next, self-supervised cross-modal knowledge distillation is performed between the two modalities through teacher-student setups to learn complementary information. To identify the most effective information to transfer and also to tackle the domain gap between audio and visual modalities which could hinder knowledge transfer, we introduce a domain alignment strategy for effective cross-modal distillation. Lastly, to develop a general-purpose solution capable of handling both audio and visual streams, a modality-agnostic variant of our proposed framework is introduced, which uses the same backbone for both audio and visual modalities. Our proposed cross-modal knowledge distillation improves linear evaluation top-1 accuracy of video action classification by 8.4% on UCF101, 8.1% on HMDB51, 13.8% on Kinetics-Sound, and 14.2% on Kinetics400. Additionally, our modality-agnostic variant shows promising results in developing a general-purpose network capable of handling different data streams. The code is released on the project website. ",
    "url": "https://arxiv.org/abs/2211.13929",
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13935",
    "title": "LU decomposition and Toeplitz decomposition of a neural network",
    "abstract": "It is well-known that any matrix $A$ has an LU decomposition. Less well-known is the fact that it has a 'Toeplitz decomposition' $A = T_1 T_2 \\cdots T_r$ where $T_i$'s are Toeplitz matrices. We will prove that any continuous function $f : \\mathbb{R}^n \\to \\mathbb{R}^m$ has an approximation to arbitrary accuracy by a neural network that takes the form $L_1 \\sigma_1 U_1 \\sigma_2 L_2 \\sigma_3 U_2 \\cdots L_r \\sigma_{2r-1} U_r$, i.e., where the weight matrices alternate between lower and upper triangular matrices, $\\sigma_i(x) := \\sigma(x - b_i)$ for some bias vector $b_i$, and the activation $\\sigma$ may be chosen to be essentially any uniformly continuous nonpolynomial function. The same result also holds with Toeplitz matrices, i.e., $f \\approx T_1 \\sigma_1 T_2 \\sigma_2 \\cdots \\sigma_{r-1} T_r$ to arbitrary accuracy, and likewise for Hankel matrices. A consequence of our Toeplitz result is a fixed-width universal approximation theorem for convolutional neural networks, which so far have only arbitrary width versions. Since our results apply in particular to the case when $f$ is a general neural network, we may regard them as LU and Toeplitz decompositions of a neural network. The practical implication of our results is that one may vastly reduce the number of weight parameters in a neural network without sacrificing its power of universal approximation. We will present several experiments on real data sets to show that imposing such structures on the weight matrices sharply reduces the number of training parameters with almost no noticeable effect on test accuracy. ",
    "url": "https://arxiv.org/abs/2211.13935",
    "authors": [
      "Yucong Liu",
      "Simiao Jiao",
      "Lek-Heng Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.13940",
    "title": "Spatial-Temporal Attention Network for Open-Set Fine-Grained Image  Recognition",
    "abstract": "Triggered by the success of transformers in various visual tasks, the spatial self-attention mechanism has recently attracted more and more attention in the computer vision community. However, we empirically found that a typical vision transformer with the spatial self-attention mechanism could not learn accurate attention maps for distinguishing different categories of fine-grained images. To address this problem, motivated by the temporal attention mechanism in brains, we propose a spatial-temporal attention network for learning fine-grained feature representations, called STAN, where the features learnt by implementing a sequence of spatial self-attention operations corresponding to multiple moments are aggregated progressively. The proposed STAN consists of four modules: a self-attention backbone module for learning a sequence of features with self-attention operations, a spatial feature self-organizing module for facilitating the model training, a spatial-temporal feature learning module for aggregating the re-organized features via a Long Short-Term Memory network, and a context-aware module that is implemented as the forget block of the spatial-temporal feature learning module for preserving/forgetting the long-term memory by utilizing contextual information. Then, we propose a STAN-based method for open-set fine-grained recognition by integrating the proposed STAN network with a linear classifier, called STAN-OSFGR. Extensive experimental results on 3 fine-grained datasets and 2 coarse-grained datasets demonstrate that the proposed STAN-OSFGR outperforms 9 state-of-the-art open-set recognition methods significantly in most cases. ",
    "url": "https://arxiv.org/abs/2211.13940",
    "authors": [
      "Jiayin Sun",
      "Hong Wang",
      "Qiulei Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13944",
    "title": "DMIS: Dynamic Mesh-based Importance Sampling for Training  Physics-Informed Neural Networks",
    "abstract": "Modeling dynamics in the form of partial differential equations (PDEs) is an effectual way to understand real-world physics processes. For complex physics systems, analytical solutions are not available and numerical solutions are widely-used. However, traditional numerical algorithms are computationally expensive and challenging in handling multiphysics systems. Recently, using neural networks to solve PDEs has made significant progress, called physics-informed neural networks (PINNs). PINNs encode physical laws into neural networks and learn the continuous solutions of PDEs. For the training of PINNs, existing methods suffer from the problems of inefficiency and unstable convergence, since the PDE residuals require calculating automatic differentiation. In this paper, we propose Dynamic Mesh-based Importance Sampling (DMIS) to tackle these problems. DMIS is a novel sampling scheme based on importance sampling, which constructs a dynamic triangular mesh to estimate sample weights efficiently. DMIS has broad applicability and can be easily integrated into existing methods. The evaluation of DMIS on three widely-used benchmarks shows that DMIS improves the convergence speed and accuracy in the meantime. Especially in solving the highly nonlinear Schr\\\"odinger Equation, compared with state-of-the-art methods, DMIS shows up to 46% smaller root mean square error and five times faster convergence speed. Code are available at https://github.com/MatrixBrain/DMIS. ",
    "url": "https://arxiv.org/abs/2211.13944",
    "authors": [
      "Zijiang Yang",
      "Zhongwei Qiu",
      "Dongmei Fu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.13955",
    "title": "MPCViT: Searching for MPC-friendly Vision Transformer with Heterogeneous  Attention",
    "abstract": "Secure multi-party computation (MPC) enables computation directly on encrypted data on non-colluding untrusted servers and protects both data and model privacy in deep learning inference. However, existing neural network (NN) architectures, including Vision Transformers (ViTs), are not designed or optimized for MPC protocols and incur significant latency overhead due to the Softmax function in the multi-head attention (MHA). In this paper, we propose an MPC-friendly ViT, dubbed MPCViT, to enable accurate yet efficient ViT inference in MPC. We systematically compare different attention variants in MPC and propose a heterogeneous attention search space, which combines the high-accuracy and MPC-efficient attentions with diverse structure granularities. We further propose a simple yet effective differentiable neural architecture search (NAS) algorithm for fast ViT optimization. MPCViT significantly outperforms prior-art ViT variants in MPC. With the proposed NAS algorithm, our extensive experiments demonstrate that MPCViT achieves 7.9x and 2.8x latency reduction with better accuracy compared to Linformer and MPCFormer on the Tiny-ImageNet dataset, respectively. Further, with proper knowledge distillation (KD), MPCViT even achieves 1.9% better accuracy compared to the baseline ViT with 9.9x latency reduction on the Tiny-ImageNet dataset. ",
    "url": "https://arxiv.org/abs/2211.13955",
    "authors": [
      "Wenxuan Zeng",
      "Meng Li",
      "Wenjie Xiong",
      "Wenjie Lu",
      "Jin Tan",
      "Runsheng Wang",
      "Ru Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13962",
    "title": "Video on Demand Streaming Using RL-based Edge Caching in 5G Networks",
    "abstract": "Edge caching can significantly improve the 5G networks' performance both in terms of delay and backhaul traffic. We use a reinforcement learning-based (RL-based) caching technique that can adapt to time-location-dependent popularity patterns for on-demand video contents. In a private 5G, we implement the proposed caching scheme as two virtual network functions (VNFs), edge and remote servers, and measure the cache hit ratio as a KPI. Combined with the HLS protocol, the proposed video-on-demand (VoD) streaming is a reliable and scalable service that can adapt to content popularity. ",
    "url": "https://arxiv.org/abs/2211.13962",
    "authors": [
      "Rasoul Nikbakht",
      "Sarang Kahvazadeh",
      "Josep Mangues-Bafalluy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.13964",
    "title": "Generating 2D and 3D Master Faces for Dictionary Attacks with a  Network-Assisted Latent Space Evolution",
    "abstract": "A master face is a face image that passes face-based identity authentication for a high percentage of the population. These faces can be used to impersonate, with a high probability of success, any user, without having access to any user information. We optimize these faces for 2D and 3D face verification models, by using an evolutionary algorithm in the latent embedding space of the StyleGAN face generator. For 2D face verification, multiple evolutionary strategies are compared, and we propose a novel approach that employs a neural network to direct the search toward promising samples, without adding fitness evaluations. The results we present demonstrate that it is possible to obtain a considerable coverage of the identities in the LFW or RFW datasets with less than 10 master faces, for six leading deep face recognition systems. In 3D, we generate faces using the 2D StyleGAN2 generator and predict a 3D structure using a deep 3D face reconstruction network. When employing two different 3D face recognition systems, we are able to obtain a coverage of 40%-50%. Additionally, we present the generation of paired 2D RGB and 3D master faces, which simultaneously match 2D and 3D models with high impersonation rates. ",
    "url": "https://arxiv.org/abs/2211.13964",
    "authors": [
      "Tomer Friedlander",
      "Ron Shmelkin",
      "Lior Wolf"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.13968",
    "title": "MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly  Detection",
    "abstract": "Visual anomaly detection plays a crucial role in not only manufacturing inspection to find defects of products during manufacturing processes, but also maintenance inspection to keep equipment in optimum working condition particularly outdoors. Due to the scarcity of the defective samples, unsupervised anomaly detection has attracted great attention in recent years. However, existing datasets for unsupervised anomaly detection are biased towards manufacturing inspection, not considering maintenance inspection which is usually conducted under outdoor uncontrolled environment such as varying camera viewpoints, messy background and degradation of object surface after long-term working. We focus on outdoor maintenance inspection and contribute a comprehensive Maintenance Inspection Anomaly Detection (MIAD) dataset which contains more than 100K high-resolution color images in various outdoor industrial scenarios. This dataset is generated by a 3D graphics software and covers both surface and logical anomalies with pixel-precise ground truth. Extensive evaluations of representative algorithms for unsupervised anomaly detection are conducted, and we expect MIAD and corresponding experimental results can inspire research community in outdoor unsupervised anomaly detection tasks. Worthwhile and related future work can be spawned from our new dataset. ",
    "url": "https://arxiv.org/abs/2211.13968",
    "authors": [
      "Tianpeng Bao",
      "Jiadong Chen",
      "Wei Li",
      "Xiang Wang",
      "Jingjing Fei",
      "Liwei Wu",
      "Rui Zhao",
      "Ye Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13969",
    "title": "Unsupervised Continual Semantic Adaptation through Neural Rendering",
    "abstract": "An increasing amount of applications rely on data-driven models that are deployed for perception tasks across a sequence of scenes. Due to the mismatch between training and deployment data, adapting the model on the new scenes is often crucial to obtain good performance. In this work, we study continual multi-scene adaptation for the task of semantic segmentation, assuming that no ground-truth labels are available during deployment and that performance on the previous scenes should be maintained. We propose training a Semantic-NeRF network for each scene by fusing the predictions of a segmentation model and then using the view-consistent rendered semantic labels as pseudo-labels to adapt the model. Through joint training with the segmentation model, the Semantic-NeRF model effectively enables 2D-3D knowledge transfer. Furthermore, due to its compact size, it can be stored in a long-term memory and subsequently used to render data from arbitrary viewpoints to reduce forgetting. We evaluate our approach on ScanNet, where we outperform both a voxel-based baseline and a state-of-the-art unsupervised domain adaptation method. ",
    "url": "https://arxiv.org/abs/2211.13969",
    "authors": [
      "Zhizheng Liu",
      "Francesco Milano",
      "Jonas Frey",
      "Marco Hutter",
      "Roland Siegwart",
      "Hermann Blum",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.13979",
    "title": "BatmanNet: Bi-branch Masked Graph Transformer Autoencoder for Molecular  Representation",
    "abstract": "Although substantial efforts have been made using graph neural networks (GNNs) for AI-driven drug discovery (AIDD), effective molecular representation learning remains an open challenge, especially in the case of insufficient labeled molecules. Recent studies suggest that big GNN models pre-trained by self-supervised learning on unlabeled datasets enable better transfer performance in downstream molecular property prediction tasks. However, they often require large-scale datasets and considerable computational resources, which is time-consuming, computationally expensive, and environmentally unfriendly. To alleviate these limitations, we propose a novel pre-training model for molecular representation learning, Bi-branch Masked Graph Transformer Autoencoder (BatmanNet). BatmanNet features two tailored and complementary graph autoencoders to reconstruct the missing nodes and edges from a masked molecular graph. To our surprise, BatmanNet discovered that the highly masked proportion (60%) of the atoms and bonds achieved the best performance. We further propose an asymmetric graph-based encoder-decoder architecture for either nodes and edges, where a transformer-based encoder only takes the visible subset of nodes or edges, and a lightweight decoder reconstructs the original molecule from the latent representation and mask tokens. With this simple yet effective asymmetrical design, our BatmanNet can learn efficiently even from a much smaller-scale unlabeled molecular dataset to capture the underlying structural and semantic information, overcoming a major limitation of current deep neural networks for molecular representation learning. For instance, using only 250K unlabelled molecules as pre-training data, our BatmanNet with 2.575M parameters achieves a 0.5% improvement on the average AUC compared with the current state-of-the-art method with 100M parameters pre-trained on 11M molecules. ",
    "url": "https://arxiv.org/abs/2211.13979",
    "authors": [
      "Zhen Wang",
      "Zheng Feng",
      "Yanjun Li",
      "Bowen Li",
      "Yongrui Wang",
      "Chulin Sha",
      "Min He",
      "Xiaolin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2211.13984",
    "title": "Aggregated Text Transformer for Scene Text Detection",
    "abstract": "This paper explores the multi-scale aggregation strategy for scene text detection in natural images. We present the Aggregated Text TRansformer(ATTR), which is designed to represent texts in scene images with a multi-scale self-attention mechanism. Starting from the image pyramid with multiple resolutions, the features are first extracted at different scales with shared weight and then fed into an encoder-decoder architecture of Transformer. The multi-scale image representations are robust and contain rich information on text contents of various sizes. The text Transformer aggregates these features to learn the interaction across different scales and improve text representation. The proposed method detects scene texts by representing each text instance as an individual binary mask, which is tolerant of curve texts and regions with dense instances. Extensive experiments on public scene text detection datasets demonstrate the effectiveness of the proposed framework. ",
    "url": "https://arxiv.org/abs/2211.13984",
    "authors": [
      "Zhao Zhou",
      "Xiangcheng Du",
      "Yingbin Zheng",
      "Cheng Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13991",
    "title": "TrustGAN: Training safe and trustworthy deep learning models through  generative adversarial networks",
    "abstract": "Deep learning models have been developed for a variety of tasks and are deployed every day to work in real conditions. Some of these tasks are critical and models need to be trusted and safe, e.g. military communications or cancer diagnosis. These models are given real data, simulated data or combination of both and are trained to be highly predictive on them. However, gathering enough real data or simulating them to be representative of all the real conditions is: costly, sometimes impossible due to confidentiality and most of the time impossible. Indeed, real conditions are constantly changing and sometimes are intractable. A solution is to deploy machine learning models that are able to give predictions when they are confident enough otherwise raise a flag or abstain. One issue is that standard models easily fail at detecting out-of-distribution samples where their predictions are unreliable. We present here TrustGAN, a generative adversarial network pipeline targeting trustness. It is a deep learning pipeline which improves a target model estimation of the confidence without impacting its predictive power. The pipeline can accept any given deep learning model which outputs a prediction and a confidence on this prediction. Moreover, the pipeline does not need to modify this target model. It can thus be easily deployed in a MLOps (Machine Learning Operations) setting. The pipeline is applied here to a target classification model trained on MNIST data to recognise numbers based on images. We compare such a model when trained in the standard way and with TrustGAN. We show that on out-of-distribution samples, here FashionMNIST and CIFAR10, the estimated confidence is largely reduced. We observe similar conclusions for a classification model trained on 1D radio signals from AugMod, tested on RML2016.04C. We also publicly release the code. ",
    "url": "https://arxiv.org/abs/2211.13991",
    "authors": [
      "H\u00e9lion du Mas des Bourboux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13993",
    "title": "Combating noisy labels in object detection datasets",
    "abstract": "The quality of training datasets for deep neural networks is a key factor contributing to the accuracy of resulting models. This is even more important in difficult tasks such as object detection. Dealing with errors in these datasets was in the past limited to accepting that some fraction of examples is incorrect or predicting their confidence and assigning appropriate weights during training. In this work, we propose a different approach. For the first time, we extended the confident learning algorithm to the object detection task. By focusing on finding incorrect labels in the original training datasets, we can eliminate erroneous examples in their root. Suspicious bounding boxes can be re-annotated in order to improve the quality of the dataset itself, thus leading to better models without complicating their already complex architectures. We can effectively point out 99\\% of artificially disturbed bounding boxes with FPR below 0.3. We see this method as a promising path to correcting well-known object detection datasets. ",
    "url": "https://arxiv.org/abs/2211.13993",
    "authors": [
      "Krystian Chachu\u0142a",
      "Adam Popowicz",
      "Jakub \u0141yskawa",
      "Bart\u0142omiej Olber",
      "Piotr Fr\u0105tczak",
      "Krystian Radlak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13994",
    "title": "Dynamic Neural Portraits",
    "abstract": "We present Dynamic Neural Portraits, a novel approach to the problem of full-head reenactment. Our method generates photo-realistic video portraits by explicitly controlling head pose, facial expressions and eye gaze. Our proposed architecture is different from existing methods that rely on GAN-based image-to-image translation networks for transforming renderings of 3D faces into photo-realistic images. Instead, we build our system upon a 2D coordinate-based MLP with controllable dynamics. Our intuition to adopt a 2D-based representation, as opposed to recent 3D NeRF-like systems, stems from the fact that video portraits are captured by monocular stationary cameras, therefore, only a single viewpoint of the scene is available. Primarily, we condition our generative model on expression blendshapes, nonetheless, we show that our system can be successfully driven by audio features as well. Our experiments demonstrate that the proposed method is 270 times faster than recent NeRF-based reenactment methods, with our networks achieving speeds of 24 fps for resolutions up to 1024 x 1024, while outperforming prior works in terms of visual quality. ",
    "url": "https://arxiv.org/abs/2211.13994",
    "authors": [
      "Michail Christos Doukas",
      "Stylianos Ploumpis",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14020",
    "title": "SCOOP: Self-Supervised Correspondence and Optimization-Based Scene Flow",
    "abstract": "Scene flow estimation is a long-standing problem in computer vision, where the goal is to find the 3D motion of a scene from its consecutive observations. Recently, there have been efforts to compute the scene flow from 3D point clouds. A common approach is to train a regression model that consumes source and target point clouds and outputs the per-point translation vectors. An alternative is to learn point matches between the point clouds concurrently with regressing a refinement of the initial correspondence flow. In both cases, the learning task is very challenging since the flow regression is done in the free 3D space, and a typical solution is to resort to a large annotated synthetic dataset. We introduce SCOOP, a new method for scene flow estimation that can be learned on a small amount of data without employing ground-truth flow supervision. In contrast to previous work, we train a pure correspondence model focused on learning point feature representation and initialize the flow as the difference between a source point and its softly corresponding target point. Then, in the run-time phase, we directly optimize a flow refinement component with a self-supervised objective, which leads to a coherent and accurate flow field between the point clouds. Experiments on widespread datasets demonstrate the performance gains achieved by our method compared to existing leading techniques while using a fraction of the training data. Our code is publicly available at https://github.com/itailang/SCOOP. ",
    "url": "https://arxiv.org/abs/2211.14020",
    "authors": [
      "Itai Lang",
      "Dror Aiger",
      "Forrester Cole",
      "Shai Avidan",
      "Michael Rubinstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14026",
    "title": "Cross-network transferable neural models for WLAN interference  estimation",
    "abstract": "Airtime interference is a key performance indicator for WLANs, measuring, for a given time period, the percentage of time during which a node is forced to wait for other transmissions before to transmitting or receiving. Being able to accurately estimate interference resulting from a given state change (e.g., channel, bandwidth, power) would allow a better control of WLAN resources, assessing the impact of a given configuration before actually implementing it. In this paper, we adopt a principled approach to interference estimation in WLANs. We first use real data to characterize the factors that impact it, and derive a set of relevant synthetic workloads for a controlled comparison of various deep learning architectures in terms of accuracy, generalization and robustness to outlier data. We find, unsurprisingly, that Graph Convolutional Networks (GCNs) yield the best performance overall, leveraging the graph structure inherent to campus WLANs. We notice that, unlike e.g. LSTMs, they struggle to learn the behavior of specific nodes, unless given the node indexes in addition. We finally verify GCN model generalization capabilities, by applying trained models on operational deployments unseen at training time. ",
    "url": "https://arxiv.org/abs/2211.14026",
    "authors": [
      "Danilo Marinho Fernandes",
      "Jonatan Krolikowski",
      "Zied Ben Houidi",
      "Fuxing Chen",
      "Dario Rossi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14042",
    "title": "Molecular Joint Representation Learning via Multi-modal Information",
    "abstract": "In recent years, artificial intelligence has played an important role on accelerating the whole process of drug discovery. Various of molecular representation schemes of different modals (e.g. textual sequence or graph) are developed. By digitally encoding them, different chemical information can be learned through corresponding network structures. Molecular graphs and Simplified Molecular Input Line Entry System (SMILES) are popular means for molecular representation learning in current. Previous works have done attempts by combining both of them to solve the problem of specific information loss in single-modal representation on various tasks. To further fusing such multi-modal imformation, the correspondence between learned chemical feature from different representation should be considered. To realize this, we propose a novel framework of molecular joint representation learning via Multi-Modal information of SMILES and molecular Graphs, called MMSG. We improve the self-attention mechanism by introducing bond level graph representation as attention bias in Transformer to reinforce feature correspondence between multi-modal information. We further propose a Bidirectional Message Communication Graph Neural Network (BMC GNN) to strengthen the information flow aggregated from graphs for further combination. Numerous experiments on public property prediction datasets have demonstrated the effectiveness of our model. ",
    "url": "https://arxiv.org/abs/2211.14042",
    "authors": [
      "Tianyu Wu",
      "Yang Tang",
      "Qiyu Sun",
      "Luolin Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2211.14047",
    "title": "On the Universal Approximation Property of Deep Fully Convolutional  Neural Networks",
    "abstract": "We study the approximation of shift-invariant or equivariant functions by deep fully convolutional networks from the dynamical systems perspective. We prove that deep residual fully convolutional networks and their continuous-layer counterpart can achieve universal approximation of these symmetric functions at constant channel width. Moreover, we show that the same can be achieved by non-residual variants with at least 2 channels in each layer and convolutional kernel size of at least 2. In addition, we show that these requirements are necessary, in the sense that networks with fewer channels or smaller kernels fail to be universal approximators. ",
    "url": "https://arxiv.org/abs/2211.14047",
    "authors": [
      "Ting Lin",
      "Zuowei Shen",
      "Qianxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14053",
    "title": "Re^2TAL: Rewiring Pretrained Video Backbones for Reversible Temporal  Action Localization",
    "abstract": "Temporal action localization (TAL) requires long-form reasoning to predict actions of various lengths and complex content. Given limited GPU memory, training TAL end-to-end on such long-form videos (i.e., from videos to predictions) is a significant challenge. Most methods can only train on pre-extracted features without optimizing them for the localization problem, consequently limiting localization performance. In this work, to extend the potential in TAL networks, we propose a novel end-to-end method Re2TAL, which rewires pretrained video backbones for reversible TAL. Re2TAL builds a backbone with reversible modules, where the input can be recovered from the output such that the bulky intermediate activations can be cleared from memory during training. Instead of designing one single type of reversible module, we propose a network rewiring mechanism, to transform any module with a residual connection to a reversible module without changing any parameters. This provides two benefits: (1) a large variety of reversible networks are easily obtained from existing and even future model designs, and (2) the reversible models require much less training effort as they reuse the pre-trained parameters of their original non-reversible versions. Re2TAL reaches 37.01% average mAP, a new state-of-the-art record on ActivityNet-v1.3, and mAP 64.9% at tIoU=0.5 on THUMOS-14 without using optimal flow. ",
    "url": "https://arxiv.org/abs/2211.14053",
    "authors": [
      "Chen Zhao",
      "Shuming Liu",
      "Karttikeya Mangalam",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.14065",
    "title": "Beyond Smoothing: Unsupervised Graph Representation Learning with Edge  Heterophily Discriminating",
    "abstract": "Unsupervised graph representation learning (UGRL) has drawn increasing research attention and achieved promising results in several graph analytic tasks. Relying on the homophily assumption, existing UGRL methods tend to smooth the learned node representations along all edges, ignoring the existence of heterophilic edges that connect nodes with distinct attributes. As a result, current methods are hard to generalize to heterophilic graphs where dissimilar nodes are widely connected, and also vulnerable to adversarial attacks. To address this issue, we propose a novel unsupervised Graph Representation learning method with Edge hEterophily discriminaTing (GREET) which learns representations by discriminating and leveraging homophilic edges and heterophilic edges. To distinguish two types of edges, we build an edge discriminator that infers edge homophily/heterophily from feature and structure information. We train the edge discriminator in an unsupervised way through minimizing the crafted pivot-anchored ranking loss, with randomly sampled node pairs acting as pivots. Node representations are learned through contrasting the dual-channel encodings obtained from the discriminated homophilic and heterophilic edges. With an effective interplaying scheme, edge discriminating and representation learning can mutually boost each other during the training phase. We conducted extensive experiments on 14 benchmark datasets and multiple learning scenarios to demonstrate the superiority of GREET. ",
    "url": "https://arxiv.org/abs/2211.14065",
    "authors": [
      "Yixin Liu",
      "Yizhen Zheng",
      "Daokun Zhang",
      "Vincent CS Lee",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.14073",
    "title": "EDGAR: Embedded Detection of Gunshots by AI in Real-time",
    "abstract": "Electronic shot counters allow armourers to perform preventive and predictive maintenance based on quantitative measurements, improving reliability, reducing the frequency of accidents, and reducing maintenance costs. To answer a market pressure for both low lead time to market and increased customisation, we aim to solve the shot detection and shot counting problem in a generic way through machine learning. In this study, we describe a method allowing one to construct a dataset with minimal labelling effort by only requiring the total number of shots fired in a time series. To our knowledge, this is the first study to propose a technique, based on learning from label proportions, that is able to exploit these weak labels to derive an instance-level classifier able to solve the counting problem and the more general discrimination problem. We also show that this technique can be deployed in heavily constrained microcontrollers while still providing hard real-time (<100ms) inference. We evaluate our technique against a state-of-the-art unsupervised algorithm and show a sizeable improvement, suggesting that the information from the weak labels is successfully leveraged. Finally, we evaluate our technique against human-generated state-of-the-art algorithms and show that it provides comparable performance and significantly outperforms them in some offline and real-world benchmarks. ",
    "url": "https://arxiv.org/abs/2211.14073",
    "authors": [
      "Nathan Morsa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.14079",
    "title": "Training Data Improvement for Image Forgery Detection using Comprint",
    "abstract": "Manipulated images are a threat to consumers worldwide, when they are used to spread disinformation. Therefore, Comprint enables forgery detection by utilizing JPEG-compression fingerprints. This paper evaluates the impact of the training set on Comprint's performance. Most interestingly, we found that including images compressed with low quality factors during training does not have a significant effect on the accuracy, whereas incorporating recompression boosts the robustness. As such, consumers can use Comprint on their smartphones to verify the authenticity of images. ",
    "url": "https://arxiv.org/abs/2211.14079",
    "authors": [
      "Hannes Mareen",
      "Dante Vanden Bussche",
      "Glenn Van Wallendael",
      "Luisa Verdoliva",
      "Peter Lambert"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14085",
    "title": "Positive unlabeled learning with tensor networks",
    "abstract": "Positive unlabeled learning is a binary classification problem with positive and unlabeled data. It is common in domains where negative labels are costly or impossible to obtain, e.g., medicine and personalized advertising. We apply the locally purified state tensor network to the positive unlabeled learning problem and test our model on the MNIST image and 15 categorical/mixed datasets. On the MNIST dataset, we achieve state-of-the-art results even with very few labeled positive samples. Similarly, we significantly improve the state-of-the-art on categorical datasets. Further, we show that the agreement fraction between outputs of different models on unlabeled samples is a good indicator of the model's performance. Finally, our method can generate new positive and negative instances, which we demonstrate on simple synthetic datasets. ",
    "url": "https://arxiv.org/abs/2211.14085",
    "authors": [
      "Bojan \u017dunkovi\u010d"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14086",
    "title": "ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision",
    "abstract": "By supervising camera rays between a scene and multi-view image planes, NeRF reconstructs a neural scene representation for the task of novel view synthesis. On the other hand, shadow rays between the light source and the scene have yet to be considered. Therefore, we propose a novel shadow ray supervision scheme that optimizes both the samples along the ray and the ray location. By supervising shadow rays, we successfully reconstruct a neural SDF of the scene from single-view pure shadow or RGB images under multiple lighting conditions. Given single-view binary shadows, we train a neural network to reconstruct a complete scene not limited by the camera's line of sight. By further modeling the correlation between the image colors and the shadow rays, our technique can also be effectively extended to RGB inputs. We compare our method with previous works on challenging tasks of shape reconstruction from single-view binary shadow or RGB images and observe significant improvements. The code and data will be released. ",
    "url": "https://arxiv.org/abs/2211.14086",
    "authors": [
      "Jingwang Ling",
      "Zhibo Wang",
      "Feng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14088",
    "title": "Boundary Adversarial Examples Against Adversarial Overfitting",
    "abstract": "Standard adversarial training approaches suffer from robust overfitting where the robust accuracy decreases when models are adversarially trained for too long. The origin of this problem is still unclear and conflicting explanations have been reported, i.e., memorization effects induced by large loss data or because of small loss data and growing differences in loss distribution of training samples as the adversarial training progresses. Consequently, several mitigation approaches including early stopping, temporal ensembling and weight perturbations on small loss data have been proposed to mitigate the effect of robust overfitting. However, a side effect of these strategies is a larger reduction in clean accuracy compared to standard adversarial training. In this paper, we investigate if these mitigation approaches are complimentary to each other in improving adversarial training performance. We further propose the use of helper adversarial examples that can be obtained with minimal cost in the adversarial example generation, and show how they increase the clean accuracy in the existing approaches without compromising the robust accuracy. ",
    "url": "https://arxiv.org/abs/2211.14088",
    "authors": [
      "Muhammad Zaid Hameed",
      "Beat Buesser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14114",
    "title": "Interval-censored Transformer Hawkes: Detecting Information Operations  using the Reaction of Social Systems",
    "abstract": "Social media is being increasingly weaponized by state-backed actors to elicit reactions, push narratives and sway public opinion. These are known as Information Operations (IO). The covert nature of IO makes their detection difficult. This is further amplified by missing data due to the user and content removal and privacy requirements. This work advances the hypothesis that the very reactions that Information Operations seek to elicit within the target social systems can be used to detect them. We propose an Interval-censored Transformer Hawkes (IC-TH) architecture and a novel data encoding scheme to account for both observed and missing data. We derive a novel log-likelihood function that we deploy together with a contrastive learning procedure. We showcase the performance of IC-TH on three real-world Twitter datasets and two learning tasks: future popularity prediction and item category prediction. The latter is particularly significant. Using the retweeting timing and patterns solely, we can predict the category of YouTube videos, guess whether news publishers are reputable or controversial and, most importantly, identify state-backed IO agent accounts. Additional qualitative investigations uncover that the automatically discovered clusters of Russian-backed agents appear to coordinate their behavior, activating simultaneously to push specific narratives. ",
    "url": "https://arxiv.org/abs/2211.14114",
    "authors": [
      "Quyu Kong",
      "Pio Calderon",
      "Rohit Ram",
      "Olga Boichak",
      "Marian-Andrei Rizoiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.14118",
    "title": "MS-PS: A Multi-Scale Network for Photometric Stereo With a New  Comprehensive Training Dataset",
    "abstract": "The photometric stereo (PS) problem consists in reconstructing the 3D-surface of an object, thanks to a set of photographs taken under different lighting directions. In this paper, we propose a multi-scale architecture for PS which, combined with a new dataset, yields state-of-the-art results. Our proposed architecture is flexible: it permits to consider a variable number of images as well as variable image size without loss of performance. In addition, we define a set of constraints to allow the generation of a relevant synthetic dataset to train convolutional neural networks for the PS problem. Our proposed dataset is much larger than pre-existing ones, and contains many objects with challenging materials having anisotropic reflectance (e.g. metals, glass). We show on publicly available benchmarks that the combination of both these contributions drastically improves the accuracy of the estimated normal field, in comparison with previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2211.14118",
    "authors": [
      "Cl\u00e9ment Hardy",
      "Yvain Qu\u00e9au",
      "David Tschumperl\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14119",
    "title": "A reduced-order model for dynamic simulation of district heating  networks",
    "abstract": "This study concerns the development of a data-based compact model for the prediction of the fluid temperature evolution in district heating (DH) pipeline networks. This so-called \"reduced-order model\" (ROM) is obtained from reduction of the conservation law for energy for each pipe segment to a semi-analytical input-output relation between the pipe outlet temperature and the pipe inlet and ground temperatures that can be identified from training data. The ROM basically is valid for generic pipe configurations involving 3D unsteady heat transfer and 3D steady flow as long as heat-transfer mechanisms are linearly dependent on the temperature field. Moreover, the training data can be generated by physics-based computational \"full-order\" models (FOMs) yet also by (calibration) experiments or field measurements. Performance tests using computational training data for a single 1D pipe configuration demonstrate that the ROM (i) can be successfully identified and (ii) can accurately describe the response of the outlet temperature to arbitrary input profiles for inlet and ground temperatures. Application of the ROM to two case studies, i.e. fast simulation of a small DH network and design of a controller for user-defined temperature regulation of a DH system, demonstrate its predictive ability and efficiency also for realistic systems. Dedicated cost analyses further reveal that the ROM may significantly reduce the computational costs compared to FOMs by (up to) orders of magnitude for higher-dimensional pipe configurations. These findings advance the proposed ROM as a robust and efficient simulation tool for practical DH systems with a far greater predictive ability than existing compact models. ",
    "url": "https://arxiv.org/abs/2211.14119",
    "authors": [
      "Mengting Jiang",
      "Michel Speetjens",
      "Camilo Rindt",
      "David Smeulders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.14130",
    "title": "Puffin: pitch-synchronous neural waveform generation for fullband speech  on modest devices",
    "abstract": "We present a neural vocoder designed with low-powered Alternative and Augmentative Communication devices in mind. By combining elements of successful modern vocoders with established ideas from an older generation of technology, our system is able to produce high quality synthetic speech at 48kHz on devices where neural vocoders are otherwise prohibitively complex. The system is trained adversarially using differentiable pitch synchronous overlap add, and reduces complexity by relying on pitch synchronous Inverse Short-Time Fourier Transform (ISTFT) to generate speech samples. Our system achieves comparable quality with a strong (HiFi-GAN) baseline while using only a fraction of the compute. We present results of a perceptual evaluation as well as an analysis of system complexity. ",
    "url": "https://arxiv.org/abs/2211.14130",
    "authors": [
      "Oliver Watts",
      "Lovisa Wihlborg",
      "Cassia Valentini-Botinhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.14144",
    "title": "Graph Convolutional Network-based Feature Selection for High-dimensional  and Low-sample Size Data",
    "abstract": "Feature selection is a powerful dimension reduction technique which selects a subset of relevant features for model construction. Numerous feature selection methods have been proposed, but most of them fail under the high-dimensional and low-sample size (HDLSS) setting due to the challenge of overfitting. In this paper, we present a deep learning-based method - GRAph Convolutional nEtwork feature Selector (GRACES) - to select important features for HDLSS data. We demonstrate empirical evidence that GRACES outperforms other feature selection methods on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2211.14144",
    "authors": [
      "Can Chen",
      "Scott T. Weiss",
      "Yang-Yu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14158",
    "title": "Isolation Scheme for Virtual Network Embedding Based on Reinforcement  Learning for Smart City Vertical Industries",
    "abstract": "Modern ICT infrastructure is built on virtualization technologies, which connect a diverse set of dedicated networks to support a variety of smart city vertical industries (SCVI), such as energy, healthcare, manufacturing, entertainment, and intelligent transportation. The wide range of SCVI use cases require services to operate continuously and reliably. The violation of isolation by a specific SCVI, that is, a SCVI network must operate independently of other SCVI networks, complicates service assurance for infrastructure providers (InPs) significantly. As a result, a solution must be considered from the standpoint of isolation, which raises two issues: first, these SCVI networks have diverse resource requirements, and second, they necessitate additional functionality requirements such as isolation. Based on the above two problems faced by SCVI use cases, we propose a virtual network embedding (VNE) algorithm with resource and isolation constraints based on deep reinforcement learning (DRL). The proposed DRL_VNE algorithm can automatically adapt to changing dynamics and outperforms existing three state-of-the-art solutions by 12.9%, 19.0% and 4% in terms of the acceptance rate, the long-term average revenue, and long-term average revenue to cost ratio. ",
    "url": "https://arxiv.org/abs/2211.14158",
    "authors": [
      "Ali Gohar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14175",
    "title": "MCFFA-Net: Multi-Contextual Feature Fusion and Attention Guided Network  for Apple Foliar Disease Classification",
    "abstract": "Numerous diseases cause severe economic loss in the apple production-based industry. Early disease identification in apple leaves can help to stop the spread of infections and provide better productivity. Therefore, it is crucial to study the identification and classification of different apple foliar diseases. Various traditional machine learning and deep learning methods have addressed and investigated this issue. However, it is still challenging to classify these diseases because of their complex background, variation in the diseased spot in the images, and the presence of several symptoms of multiple diseases on the same leaf. This paper proposes a novel transfer learning-based stacked ensemble architecture named MCFFA-Net, which is composed of three pre-trained architectures named MobileNetV2, DenseNet201, and InceptionResNetV2 as backbone networks. We also propose a novel multi-scale dilated residual convolution module to capture multi-scale contextual information with several dilated receptive fields from the extracted features. Channel-based attention mechanism is provided through squeeze and excitation networks to make the MCFFA-Net focused on the relevant information in the multi-receptive fields. The proposed MCFFA-Net achieves a classification accuracy of 90.86%. ",
    "url": "https://arxiv.org/abs/2211.14175",
    "authors": [
      "Md. Rayhan Ahmed",
      "Adnan Ferdous Ashrafi",
      "Raihan Uddin Ahmed",
      "Tanveer Ahmed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14208",
    "title": "GREAD: Graph Neural Reaction-Diffusion Equations",
    "abstract": "Graph neural networks (GNNs) are one of the most popular research topics for deep learning. GNN methods typically have been designed on top of the graph signal processing theory. In particular, diffusion equations have been widely used for designing the core processing layer of GNNs and therefore, they are inevitably vulnerable to the oversmoothing problem. Recently, a couple of papers paid attention to reaction equations in conjunctions with diffusion equations. However, they all consider limited forms of reaction equations. To this end, we present a reaction-diffusion equation-based GNN method that considers all popular types of reaction equations in addition to one special reaction equation designed by us. To our knowledge, our paper is one of the most comprehensive studies on reaction-diffusion equation-based GNNs. In our experiments with 9 datasets and 17 baselines, our method, called GREAD, outperforms them in almost all cases. Further synthetic data experiments show that GREAD mitigates the oversmoothing and performs well for various homophily rates. ",
    "url": "https://arxiv.org/abs/2211.14208",
    "authors": [
      "Jeongwhan Choi",
      "Seoyoung Hong",
      "Noseong Park",
      "Sung-Bae Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14221",
    "title": "High-Dimensional Causal Discovery: Learning from Inverse Covariance via  Independence-based Decomposition",
    "abstract": "Inferring causal relationships from observational data is a fundamental yet highly complex problem when the number of variables is large. Recent advances have made much progress in learning causal structure models (SEMs) but still face challenges in scalability. This paper aims to efficiently discover causal DAGs from high-dimensional data. We investigate a way of recovering causal DAGs from inverse covariance estimators of the observational data. The proposed algorithm, called ICID (inverse covariance estimation and {\\it independence-based} decomposition), searches for a decomposition of the inverse covariance matrix that preserves its nonzero patterns. This algorithm benefits from properties of positive definite matrices supported on {\\it chordal} graphs and the preservation of nonzero patterns in their Cholesky decomposition; we find exact mirroring between the support-preserving property and the independence-preserving property of our decomposition method, which explains its effectiveness in identifying causal structures from the data distribution. We show that the proposed algorithm recovers causal DAGs with a complexity of $O(d^2)$ in the context of sparse SEMs. The advantageously low complexity is reflected by good scalability of our algorithm in thorough experiments and comparisons with state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2211.14221",
    "authors": [
      "Shuyu Dong",
      "Kento Uemura",
      "Akito Fujii",
      "Shuang Chang",
      "Yusuke Koyanagi",
      "Koji Maruhashi",
      "Mich\u00e8le Sebag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.14227",
    "title": "Bypass Exponential Time Preprocessing: Fast Neural Network Training via  Weight-Data Correlation Preprocessing",
    "abstract": "Over the last decade, deep neural networks have transformed our society, and they are already widely applied in various machine learning applications. State-of-art deep neural networks are becoming larger in size every year to deliver increasing model accuracy, and as a result, model training consumes substantial computing resources and will only consume more in the future. Using current training methods, in each iteration, to process a data point $x \\in \\mathbb{R}^d$ in a layer, we need to spend $\\Theta(md)$ time to evaluate all the $m$ neurons in the layer. This means processing the entire layer takes $\\Theta(nmd)$ time for $n$ data points. Recent work [Song, Yang and Zhang, NeurIPS 2021] reduces this time per iteration to $o(nmd)$, but requires exponential time to preprocess either the data or the neural network weights, making it unlikely to have practical usage. In this work, we present a new preprocessing method that simply stores the weight-data correlation in a tree data structure in order to quickly, dynamically detect which neurons fire at each iteration. Our method requires only $O(nmd)$ time in preprocessing and still achieves $o(nmd)$ time per iteration. We complement our new algorithm with a lower bound, proving that assuming a popular conjecture from complexity theory, one could not substantially speed up our algorithm for dynamic detection of firing neurons. ",
    "url": "https://arxiv.org/abs/2211.14227",
    "authors": [
      "Josh Alman",
      "Jiehao Liang",
      "Zhao Song",
      "Ruizhe Zhang",
      "Danyang Zhuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14249",
    "title": "Neural Poisson: Indicator Functions for Neural Fields",
    "abstract": "Implicit neural field generating signed distance field representations (SDFs) of 3D shapes have shown remarkable progress in 3D shape reconstruction and generation. We introduce a new paradigm for neural field representations of 3D scenes; rather than characterizing surfaces as SDFs, we propose a Poisson-inspired characterization for surfaces as indicator functions optimized by neural fields. Crucially, for reconstruction of real scan data, the indicator function representation enables simple and effective constraints based on common range sensing inputs, which indicate empty space based on line of sight. Such empty space information is intrinsic to the scanning process, and incorporating this knowledge enables more accurate surface reconstruction. We show that our approach demonstrates state-of-the-art reconstruction performance on both synthetic and real scanned 3D scene data, with 9.5% improvement in Chamfer distance over state of the art. ",
    "url": "https://arxiv.org/abs/2211.14249",
    "authors": [
      "Angela Dai",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14265",
    "title": "Multiscale methods for solving wave equations on spatial networks",
    "abstract": "We present and analyze a multiscale method for wave propagation problems, posed on spatial networks. By introducing a coarse scale, using a finite element space interpolated onto the network, we construct a discrete multiscale space using the localized orthogonal decomposition (LOD) methodology. The spatial discretization is then combined with an energy conserving temporal scheme to form the proposed method. Under the assumption of well-prepared initial data, we derive an a priori error bound of optimal order with respect to the space and time discretization. In the analysis, we combine the theory derived for stationary elliptic problems on spatial networks with classical finite element results for hyperbolic problems. Finally, we present numerical experiments that confirm our theoretical findings. ",
    "url": "https://arxiv.org/abs/2211.14265",
    "authors": [
      "Morgan G\u00f6rtz",
      "Per Ljung",
      "Axel M\u00e5lqvist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.14279",
    "title": "Multiverse: Multilingual Evidence for Fake News Detection",
    "abstract": "Misleading information spreads on the Internet at an incredible speed, which can lead to irreparable consequences in some cases. It is becoming essential to develop fake news detection technologies. While substantial work has been done in this direction, one of the limitations of the current approaches is that these models are focused only on one language and do not use multilingual information. In this work, we propose Multiverse -- a new feature based on multilingual evidence that can be used for fake news detection and improve existing approaches. The hypothesis of the usage of cross-lingual evidence as a feature for fake news detection is confirmed, firstly, by manual experiment based on a set of known true and fake news. After that, we compared our fake news classification system based on the proposed feature with several baselines on two multi-domain datasets of general-topic news and one fake COVID-19 news dataset showing that in additional combination with linguistic features it yields significant improvements. ",
    "url": "https://arxiv.org/abs/2211.14279",
    "authors": [
      "Daryna Dementieva",
      "Mikhail Kuimov",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.14284",
    "title": "Multigrid solvers for the de Rham complex with optimal complexity in  polynomial degree",
    "abstract": "The Riesz maps of the $L^2$ de Rham complex frequently arise as subproblems in the construction of fast preconditioners for more complicated problems. In this work we present multigrid solvers for high-order finite element discretizations of these Riesz maps with the same time and space complexity as sum-factorized operator application, i.e.~with optimal complexity in polynomial degree in the context of Krylov methods. The key idea of our approach is to build new finite elements for each space in the de Rham complex with orthogonality properties in both the $L^2$- and $H(\\mathrm{d})$-inner products ($\\mathrm{d} \\in \\{\\mathrm{grad}, \\mathrm{curl}, \\mathrm{div}\\})$ on the reference hexahedron. The resulting sparsity enables the fast solution of the patch problems arising in the Pavarino, Arnold--Falk--Winther and Hiptmair space decompositions, in the separable case. In the non-separable case, the method can be applied to an auxiliary operator that is sparse by construction. With exact Cholesky factorizations of the sparse patch problems, the application complexity is optimal but the setup costs and storage are not. We overcome this with the finer Hiptmair space decomposition and the use of incomplete Cholesky factorizations imposing the sparsity pattern arising from static condensation, which applies whether static condensation is used for the solver or not. This yields multigrid relaxations with time and space complexity that are both optimal in the polynomial degree. ",
    "url": "https://arxiv.org/abs/2211.14284",
    "authors": [
      "Pablo D. Brubeck",
      "Patrick E. Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.14296",
    "title": "A System for Morphology-Task Generalization via Unified Representation  and Behavior Distillation",
    "abstract": "The rise of generalist large-scale models in natural language and vision has made us expect that a massive data-driven approach could achieve broader generalization in other domains such as continuous control. In this work, we explore a method for learning a single policy that manipulates various forms of agents to solve various tasks by distilling a large amount of proficient behavioral data. In order to align input-output (IO) interface among multiple tasks and diverse agent morphologies while preserving essential 3D geometric relations, we introduce morphology-task graph, which treats observations, actions and goals/task in a unified graph representation. We also develop MxT-Bench for fast large-scale behavior generation, which supports procedural generation of diverse morphology-task combinations with a minimal blueprint and hardware-accelerated simulator. Through efficient representation and architecture selection on MxT-Bench, we find out that a morphology-task graph representation coupled with Transformer architecture improves the multi-task performances compared to other baselines including recent discrete tokenization, and provides better prior knowledge for zero-shot transfer or sample efficiency in downstream multi-task imitation learning. Our work suggests large diverse offline datasets, unified IO representation, and policy representation and architecture selection through supervised learning form a promising approach for studying and advancing morphology-task generalization. ",
    "url": "https://arxiv.org/abs/2211.14296",
    "authors": [
      "Hiroki Furuta",
      "Yusuke Iwasawa",
      "Yutaka Matsuo",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14302",
    "title": "Neural DAEs: Constrained neural networks",
    "abstract": "In this article we investigate the effect of explicitly adding auxiliary trajectory information to neural networks for dynamical systems. We draw inspiration from the field of differential-algebraic equations and differential equations on manifolds and implement similar methods in residual neural networks. We discuss constraints through stabilization as well as projection methods, and show when to use which method based on experiments involving simulations of multi-body pendulums and molecular dynamics scenarios. Several of our methods are easy to implement in existing code and have limited impact on training performance while giving significant boosts in terms of inference. ",
    "url": "https://arxiv.org/abs/2211.14302",
    "authors": [
      "Tue Boesen",
      "Eldad Haber",
      "Uri M. Ascher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.14304",
    "title": "BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction",
    "abstract": "Stochastic human motion prediction (HMP) has generally been tackled with generative adversarial networks and variational autoencoders. Most prior works aim at predicting highly diverse movements in terms of the skeleton joints' dispersion. This has led to methods predicting fast and motion-divergent movements, which are often unrealistic and incoherent with past motion. Such methods also neglect contexts that need to anticipate diverse low-range behaviors, or actions, with subtle joint displacements. To address these issues, we present BeLFusion, a model that, for the first time, leverages latent diffusion models in HMP to sample from a latent space where behavior is disentangled from pose and motion. As a result, diversity is encouraged from a behavioral perspective. Thanks to our behavior coupler's ability to transfer sampled behavior to ongoing motion, BeLFusion's predictions display a variety of behaviors that are significantly more realistic than the state of the art. To support it, we introduce two metrics, the Area of the Cumulative Motion Distribution, and the Average Pairwise Distance Error, which are correlated to our definition of realism according to a qualitative study with 126 participants. Finally, we prove BeLFusion's generalization power in a new cross-dataset scenario for stochastic HMP. ",
    "url": "https://arxiv.org/abs/2211.14304",
    "authors": [
      "German Barquero",
      "Sergio Escalera",
      "Cristina Palmero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14305",
    "title": "SpaText: Spatio-Textual Representation for Controllable Image Generation",
    "abstract": "Recent text-to-image diffusion models are able to generate convincing results of unprecedented quality. However, it is nearly impossible to control the shapes of different regions/objects or their layout in a fine-grained fashion. Previous attempts to provide such controls were hindered by their reliance on a fixed set of labels. To this end, we present SpaText - a new method for text-to-image generation using open-vocabulary scene control. In addition to a global text prompt that describes the entire scene, the user provides a segmentation map where each region of interest is annotated by a free-form natural language description. Due to lack of large-scale datasets that have a detailed textual description for each region in the image, we choose to leverage the current large-scale text-to-image datasets and base our approach on a novel CLIP-based spatio-textual representation, and show its effectiveness on two state-of-the-art diffusion models: pixel-based and latent-based. In addition, we show how to extend the classifier-free guidance method in diffusion models to the multi-conditional case and present an alternative accelerated inference algorithm. Finally, we offer several automatic evaluation metrics and use them, in addition to FID scores and a user study, to evaluate our method and show that it achieves state-of-the-art results on image generation with free-form textual scene control. ",
    "url": "https://arxiv.org/abs/2211.14305",
    "authors": [
      "Omri Avrahami",
      "Thomas Hayes",
      "Oran Gafni",
      "Sonal Gupta",
      "Yaniv Taigman",
      "Devi Parikh",
      "Dani Lischinski",
      "Ohad Fried",
      "Xi Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14306",
    "title": "RUST: Latent Neural Scene Representations from Unposed Imagery",
    "abstract": "Inferring the structure of 3D scenes from 2D observations is a fundamental challenge in computer vision. Recently popularized approaches based on neural scene representations have achieved tremendous impact and have been applied across a variety of applications. One of the major remaining challenges in this space is training a single model which can provide latent representations which effectively generalize beyond a single scene. Scene Representation Transformer (SRT) has shown promise in this direction, but scaling it to a larger set of diverse scenes is challenging and necessitates accurately posed ground truth data. To address this problem, we propose RUST (Really Unposed Scene representation Transformer), a pose-free approach to novel view synthesis trained on RGB images alone. Our main insight is that one can train a Pose Encoder that peeks at the target image and learns a latent pose embedding which is used by the decoder for view synthesis. We perform an empirical investigation into the learned latent pose structure and show that it allows meaningful test-time camera transformations and accurate explicit pose readouts. Perhaps surprisingly, RUST achieves similar quality as methods which have access to perfect camera pose, thereby unlocking the potential for large-scale training of amortized neural scene representations. ",
    "url": "https://arxiv.org/abs/2211.14306",
    "authors": [
      "Mehdi S. M. Sajjadi",
      "Aravindh Mahendran",
      "Thomas Kipf",
      "Etienne Pot",
      "Daniel Duckworth",
      "Mario Lucic",
      "Klaus Greff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.14308",
    "title": "WALDO: Future Video Synthesis using Object Layer Decomposition and  Parametric Flow Prediction",
    "abstract": "This paper presents WALDO (WArping Layer-Decomposed Objects), a novel approach to the prediction of future video frames from past ones. Individual images are decomposed into multiple layers combining object masks and a small set of control points. The layer structure is shared across all frames in each video to build dense inter-frame connections. Complex scene motions are modeled by combining parametric geometric transformations associated with individual layers, and video synthesis is broken down into discovering the layers associated with past frames, predicting the corresponding transformations for upcoming ones and warping the associated object regions accordingly, and filling in the remaining image parts. Extensive experiments on the Cityscapes (resp. KITTI) dataset show that WALDO significantly outperforms prior works with, e.g., 3, 27, and 51% (resp. 5, 20 and 11%) relative improvement in SSIM, LPIPS and FVD metrics. Code, pretrained models, and video samples synthesized by our approach can be found in the project webpage https://16lemoing.github.io/waldo. ",
    "url": "https://arxiv.org/abs/2211.14308",
    "authors": [
      "Guillaume Le Moing",
      "Jean Ponce",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1810.05319",
    "title": "A Fully Time-domain Neural Model for Subband-based Speech Synthesizer",
    "abstract": "This paper introduces a deep neural network model for subband-based speech synthesizer. The model benefits from the short bandwidth of the subband signals to reduce the complexity of the time-domain speech generator. We employed the multi-level wavelet analysis/synthesis to decompose/reconstruct the signal into subbands in time domain. Inspired from the WaveNet, a convolutional neural network (CNN) model predicts subband speech signals fully in time domain. Due to the short bandwidth of the subbands, a simple network architecture is enough to train the simple patterns of the subbands accurately. In the ground truth experiments with teacher-forcing, the subband synthesizer outperforms the fullband model significantly in terms of both subjective and objective measures. In addition, by conditioning the model on the phoneme sequence using a pronunciation dictionary, we have achieved the fully time-domain neural model for subband-based text-to-speech (TTS) synthesizer, which is nearly end-to-end. The generated speech of the subband TTS shows comparable quality as the fullband one with a slighter network architecture for each subband. ",
    "url": "https://arxiv.org/abs/1810.05319",
    "authors": [
      "Azam Rabiee",
      "Geonmin Kim",
      "Tae-Ho Kim",
      "Soo-Young Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.13231",
    "title": "Predicting Biomedical Interactions with Probabilistic Model Selection  for Graph Neural Networks",
    "abstract": "A biological system is a complex network of heterogeneous molecular entities and their interactions contributing to various biological characteristics of the system. However, current biological networks are noisy, sparse, and incomplete, limiting our ability to create a holistic view of the biological system and understand the biological phenomena. Experimental identification of such interactions is both time-consuming and expensive. With the recent advancements in high-throughput data generation and significant improvement in computational power, various computational methods have been developed to predict novel interactions in the noisy network. Recently, deep learning methods such as graph neural networks have shown their effectiveness in modeling graph-structured data and achieved good performance in biomedical interaction prediction. However, graph neural networks-based methods require human expertise and experimentation to design the appropriate complexity of the model and significantly impact the performance of the model. Furthermore, deep graph neural networks face overfitting problems and tend to be poorly calibrated with high confidence on incorrect predictions. To address these challenges, we propose Bayesian model selection for graph convolutional networks to jointly infer the most plausible number of graph convolution layers (depth) warranted by data and perform dropout regularization simultaneously. Experiments on four interaction datasets show that our proposed method achieves accurate and calibrated predictions. Our proposed method enables the graph convolutional networks to dynamically adapt their depths to accommodate an increasing number of interactions. ",
    "url": "https://arxiv.org/abs/2211.13231",
    "authors": [
      "Kishan K C",
      "Rui Li",
      "Paribesh Regmi",
      "Anne R. Haake"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13440",
    "title": "Iterative Data Refinement for Self-Supervised MR Image Reconstruction",
    "abstract": "Magnetic Resonance Imaging (MRI) has become an important technique in the clinic for the visualization, detection, and diagnosis of various diseases. However, one bottleneck limitation of MRI is the relatively slow data acquisition process. Fast MRI based on k-space undersampling and high-quality image reconstruction has been widely utilized, and many deep learning-based methods have been developed in recent years. Although promising results have been achieved, most existing methods require fully-sampled reference data for training the deep learning models. Unfortunately, fully-sampled MRI data are difficult if not impossible to obtain in real-world applications. To address this issue, we propose a data refinement framework for self-supervised MR image reconstruction. Specifically, we first analyze the reason of the performance gap between self-supervised and supervised methods and identify that the bias in the training datasets between the two is one major factor. Then, we design an effective self-supervised training data refinement method to reduce this data bias. With the data refinement, an enhanced self-supervised MR image reconstruction framework is developed to prompt accurate MR imaging. We evaluate our method on an in-vivo MRI dataset. Experimental results show that without utilizing any fully sampled MRI data, our self-supervised framework possesses strong capabilities in capturing image details and structures at high acceleration factors. ",
    "url": "https://arxiv.org/abs/2211.13440",
    "authors": [
      "Xue Liu",
      "Juan Zou",
      "Xiawu Zheng",
      "Cheng Li",
      "Hairong Zheng",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13533",
    "title": "Prosody-controllable spontaneous TTS with neural HMMs",
    "abstract": "Spontaneous speech has many affective and pragmatic functions that are interesting and challenging to model in TTS (text-to-speech). However, the presence of reduced articulation, fillers, repetitions, and other disfluencies mean that text and acoustics are less well aligned than in read speech. This is problematic for attention-based TTS. We propose a TTS architecture that is particularly suited for rapidly learning to speak from irregular and small datasets while also reproducing the diversity of expressive phenomena present in spontaneous speech. Specifically, we modify an existing neural HMM-based TTS system, which is capable of stable, monotonic alignments for spontaneous speech, and add utterance-level prosody control, so that the system can represent the wide range of natural variability in a spontaneous speech corpus. We objectively evaluate control accuracy and perform a subjective listening test to compare to a system without prosody control. To exemplify the power of combining mid-level prosody control and ecologically valid data for reproducing intricate spontaneous speech phenomena, we evaluate the system's capability of synthesizing two types of creaky phonation. Audio samples are available at https://hfkml.github.io/pc_nhmm_tts/ ",
    "url": "https://arxiv.org/abs/2211.13533",
    "authors": [
      "Harm Lameris",
      "Shivam Mehta",
      "Gustav Eje Henter",
      "Joakim Gustafson",
      "\u00c9va Sz\u00e9kely"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.13715",
    "title": "Trust Your $\\nabla$: Gradient-based Intervention Targeting for Causal  Discovery",
    "abstract": "Inferring causal structure from data is a challenging task of fundamental importance in science. Observational data are often insufficient to identify a system's causal structure uniquely. While conducting interventions (i.e., experiments) can improve the identifiability, such samples are usually challenging and expensive to obtain. Hence, experimental design approaches for causal discovery aim to minimize the number of interventions by estimating the most informative intervention target. In this work, we propose a novel Gradient-based Intervention Targeting method, abbreviated GIT, that 'trusts' the gradient estimator of a gradient-based causal discovery framework to provide signals for the intervention acquisition function. We provide extensive experiments in simulated and real-world datasets and demonstrate that GIT performs on par with competitive baselines, surpassing them in the low-data regime. ",
    "url": "https://arxiv.org/abs/2211.13715",
    "authors": [
      "Mateusz Olko",
      "Micha\u0142 Zaj\u0105c",
      "Aleksandra Nowak",
      "Nino Scherrer",
      "Yashas Annadani",
      "Stefan Bauer",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.13767",
    "title": "Quantum Adversarial Learning in Emulation of Monte-Carlo Methods for  Max-cut Approximation: QAOA is not optimal",
    "abstract": "One of the leading candidates for near-term quantum advantage is the class of Variational Quantum Algorithms, but these algorithms suffer from classical difficulty in optimizing the variational parameters as the number of parameters increases. Therefore, it is important to understand the expressibility and power of various ans\\\"atze to produce target states and distributions. To this end, we apply notions of emulation to Variational Quantum Annealing and the Quantum Approximate Optimization Algorithm (QAOA) to show that QAOA is outperformed by variational annealing schedules with equivalent numbers of parameters. Our Variational Quantum Annealing schedule is based on a novel polynomial parameterization that can be optimized in a similar gradient-free way as QAOA, using the same physical ingredients. In order to compare the performance of ans\\\"atze types, we have developed statistical notions of Monte-Carlo methods. Monte-Carlo methods are computer programs that generate random variables that approximate a target number that is computationally hard to calculate exactly. While the most well-known Monte-Carlo method is Monte-Carlo integration (e.g. Diffusion Monte-Carlo or path-integral quantum Monte-Carlo), QAOA is itself a Monte-Carlo method that finds good solutions to NP-complete problems such as Max-cut. We apply these statistical Monte-Carlo notions to further elucidate the theoretical framework around these quantum algorithms. ",
    "url": "https://arxiv.org/abs/2211.13767",
    "authors": [
      "Cem M. Unsal",
      "Lucas T. Brady"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2211.13797",
    "title": "Data-Driven Distributionally Robust Electric Vehicle Balancing for  Autonomous Mobility-on-Demand Systems under Demand and Supply Uncertainties",
    "abstract": "Electric vehicles (EVs) are being rapidly adopted due to their economic and societal benefits. Autonomous mobility-on-demand (AMoD) systems also embrace this trend. However, the long charging time and high recharging frequency of EVs pose challenges to efficiently managing EV AMoD systems. The complicated dynamic charging and mobility process of EV AMoD systems makes the demand and supply uncertainties significant when designing vehicle balancing algorithms. In this work, we design a data-driven distributionally robust optimization (DRO) approach to balance EVs for both the mobility service and the charging process. The optimization goal is to minimize the worst-case expected cost under both passenger mobility demand uncertainties and EV supply uncertainties. We then propose a novel distributional uncertainty sets construction algorithm that guarantees the produced parameters are contained in desired confidence regions with a given probability. To solve the proposed DRO AMoD EV balancing problem, we derive an equivalent computationally tractable convex optimization problem. Based on real-world EV data of a taxi system, we show that with our solution the average total balancing cost is reduced by 14.49%, and the average mobility fairness and charging fairness are improved by 15.78% and 34.51%, respectively, compared to solutions that do not consider uncertainties. ",
    "url": "https://arxiv.org/abs/2211.13797",
    "authors": [
      "Sihong He",
      "Zhili Zhang",
      "Shuo Han",
      "Lynn Pepin",
      "Guang Wang",
      "Desheng Zhang",
      "John Stankovic",
      "Fei Miao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.13915",
    "title": "Confidence Interval Construction for Multivariate time series using Long  Short Term Memory Network",
    "abstract": "In this paper we propose a novel procedure to construct a confidence interval for multivariate time series predictions using long short term memory network. The construction uses a few novel block bootstrap techniques. We also propose an innovative block length selection procedure for each of these schemes. Two novel benchmarks help us to compare the construction of this confidence intervals by different bootstrap techniques. We illustrate the whole construction through S\\&P $500$ and Dow Jones Index datasets. ",
    "url": "https://arxiv.org/abs/2211.13915",
    "authors": [
      "Aryan Bhambu",
      "Arabin Kumar Dey"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2211.13931",
    "title": "Transitivity on subclasses of chordal graphs",
    "abstract": "Let $G=(V, E)$ be a graph, where $V$ and $E$ are the vertex and edge sets, respectively. For two disjoint subsets $A$ and $B$ of $V$, we say $A$ \\textit{dominates} $B$ if every vertex of $B$ is adjacent to at least one vertex of $A$ in $G$. A vertex partition $\\pi = \\{V_1, V_2, \\ldots, V_k\\}$ of $G$ is called a \\emph{transitive $k$-partition} if $V_i$ dominates $V_j$ for all $i,j$, where $1\\leq i<j\\leq k$. The maximum integer $k$ for which the above partition exists is called \\emph{transitivity} of $G$ and it is denoted by $Tr(G)$. The \\textsc{Maximum Transitivity Problem} is to find a transitive partition of a given graph with the maximum number of partitions. It was known that the decision version of \\textsc{Maximum Transitivity Problem} is NP-complete for chordal graphs [Iterated colorings of graphs, \\emph{Discrete Mathematics}, 278, 2004]. In this paper, we first prove that this problem can be solved in linear time for \\emph{split graphs} and for the \\emph{complement of bipartite chain graphs}, two subclasses of chordal graphs. We also discuss Nordhaus-Gaddum type relations for transitivity and provide counterexamples for an open problem posed by J. T. Hedetniemi and S. T. Hedetniemi [The transitivity of a graph, \\emph{J. Combin. Math. Combin. Comput}, 104, 2018]. Finally, we characterize transitively critical graphs having fixed transitivity. ",
    "url": "https://arxiv.org/abs/2211.13931",
    "authors": [
      "Subhabrata Paul",
      "Kamal Santra"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.13942",
    "title": "Affine Transformation Edited and Refined Deep Neural Network for  Quantitative Susceptibility Mapping",
    "abstract": "Deep neural networks have demonstrated great potential in solving dipole inversion for Quantitative Susceptibility Mapping (QSM). However, the performances of most existing deep learning methods drastically degrade with mismatched sequence parameters such as acquisition orientation and spatial resolution. We propose an end-to-end AFfine Transformation Edited and Refined (AFTER) deep neural network for QSM, which is robust against arbitrary acquisition orientation and spatial resolution up to 0.6 mm isotropic at the finest. The AFTER-QSM neural network starts with a forward affine transformation layer, followed by an Unet for dipole inversion, then an inverse affine transformation layer, followed by a Residual Dense Network (RDN) for QSM refinement. Simulation and in-vivo experiments demonstrated that the proposed AFTER-QSM network architecture had excellent generalizability. It can successfully reconstruct susceptibility maps from highly oblique and anisotropic scans, leading to the best image quality assessments in simulation tests and suppressed streaking artifacts and noise levels for in-vivo experiments compared with other methods. Furthermore, ablation studies showed that the RDN refinement network significantly reduced image blurring and susceptibility underestimation due to affine transformations. In addition, the AFTER-QSM network substantially shortened the reconstruction time from minutes using conventional methods to only a few seconds. ",
    "url": "https://arxiv.org/abs/2211.13942",
    "authors": [
      "Zhuang Xiong",
      "Yang Gao",
      "Feng Liu",
      "Hongfu Sun"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14043",
    "title": "Decisive role of fluctuations in the resource dependency networks",
    "abstract": "Individual components of many real-world complex networks produce and exchange resources among themselves. However, because the resource production in such networks is almost always stochastic, fluctuations in the production are unavoidable. In this paper, we study the effect of fluctuations on the resource dependencies in complex networks. To this end, we consider a modification of a threshold model of resource dependencies in networks that was recently proposed, where each vertex can either be in a fit or a degraded state. We study how the \"network fitness\" is affected as the fluctuation size is varied. We show that, the relative value of the average production with respect to the threshold, decides whether the fluctuations are beneficial or detrimental to the network fitness. We further show that the networks with a homogeneous degree distribution, such as the Erdos-Renyi network, perform better in terms of fitness and also produce lower wastage than the Scale-Free network. Our work shows that, in the study of resource dependencies in networks, the role of the fluctuations is as decisive as the average production. ",
    "url": "https://arxiv.org/abs/2211.14043",
    "authors": [
      "Saumitra Kulkarni",
      "Snehal M. Shekatkar"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2211.14218",
    "title": "Shotgun assembly of random graphs",
    "abstract": "Graph shotgun assembly refers to the problem of reconstructing a graph from the collection of $r$-balls around each vertex. We study this problem for an Erd\\H{o}s-R\\'enyi random graph $G\\in \\mathcal G(n,p)$, and for a wide range of values of $r$. We determine the exact thresholds for $r$-reconstructibility for $r\\geq 3$, which improves and generalises the result of Mossel and Ross for $r=3$. In addition, we give better upper and lower bounds on the threshold of 2-reconstructibility, improving the results of Gaudio and Mossel by polynomial factors. We also give an improved lower bound for the result of Huang and Tikhomirov for $r=1$. ",
    "url": "https://arxiv.org/abs/2211.14218",
    "authors": [
      "Tom Johnston",
      "Gal Kronenberg",
      "Alexander Roberts",
      "Alex Scott"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2211.14235",
    "title": "DoubleU-NetPlus: A Novel Attention and Context Guided Dual U-Net with  Multi-Scale Residual Feature Fusion Network for Semantic Segmentation of  Medical Images",
    "abstract": "Accurate segmentation of the region of interest in medical images can provide an essential pathway for devising effective treatment plans for life-threatening diseases. It is still challenging for U-Net, and its state-of-the-art variants, such as CE-Net and DoubleU-Net, to effectively model the higher-level output feature maps of the convolutional units of the network mostly due to the presence of various scales of the region of interest, intricacy of context environments, ambiguous boundaries, and multiformity of textures in medical images. In this paper, we exploit multi-contextual features and several attention strategies to increase networks' ability to model discriminative feature representation for more accurate medical image segmentation, and we present a novel dual U-Net-based architecture named DoubleU-NetPlus. The DoubleU-NetPlus incorporates several architectural modifications. In particular, we integrate EfficientNetB7 as the feature encoder module, a newly designed multi-kernel residual convolution module, and an adaptive feature re-calibrating attention-based atrous spatial pyramid pooling module to progressively and precisely accumulate discriminative multi-scale high-level contextual feature maps and emphasize the salient regions. In addition, we introduce a novel triple attention gate module and a hybrid triple attention module to encourage selective modeling of relevant medical image features. Moreover, to mitigate the gradient vanishing issue and incorporate high-resolution features with deeper spatial details, the standard convolution operation is replaced with the attention-guided residual convolution operations, ... ",
    "url": "https://arxiv.org/abs/2211.14235",
    "authors": [
      "Md. Rayhan Ahmed",
      "Adnan Ferdous Ashrafi",
      "Raihan Uddin Ahmed",
      "Swakkhar Shatabda",
      "A.K.M. Muzahidul Islam",
      "Salekul Islam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14282",
    "title": "Domain generalization in fetal brain MRI segmentation \\\\with  multi-reconstruction augmentation",
    "abstract": "Quantitative analysis of in utero human brain development is crucial for abnormal characterization. Magnetic resonance image (MRI) segmentation is therefore an asset for quantitative analysis. However, the development of automated segmentation methods is hampered by the scarce availability of fetal brain MRI annotated datasets and the limited variability within these cohorts. In this context, we propose to leverage the power of fetal brain MRI super-resolution (SR) reconstruction methods to generate multiple reconstructions of a single subject with different parameters, thus as an efficient tuning-free data augmentation strategy. Overall, the latter significantly improves the generalization of segmentation methods over SR pipelines. ",
    "url": "https://arxiv.org/abs/2211.14282",
    "authors": [
      "Priscille de Dumast",
      "Meritxell Bach Cuadra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14297",
    "title": "Doubly robust nearest neighbors in factor models",
    "abstract": "In this technical note, we introduce an improved variant of nearest neighbors for counterfactual inference in panel data settings where multiple units are assigned multiple treatments over multiple time points, each sampled with constant probabilities. We call this estimator a doubly robust nearest neighbor estimator and provide a high probability non-asymptotic error bound for the mean parameter corresponding to each unit at each time. Our guarantee shows that the doubly robust estimator provides a (near-)quadratic improvement in the error compared to nearest neighbor estimators analyzed in prior work for these settings. ",
    "url": "https://arxiv.org/abs/2211.14297",
    "authors": [
      "Raaz Dwivedi",
      "Katherine Tian",
      "Sabina Tomkins",
      "Predrag Klasnja",
      "Susan Murphy",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2005.08454",
    "title": "Reliability and Robustness analysis of Machine Learning based Phishing  URL Detectors",
    "abstract": " Comments: Accepted in Transactions of Dependable and Secure Computing (SI-Reliability and Robustness in AI-Based Cybersecurity Solutions) ",
    "url": "https://arxiv.org/abs/2005.08454",
    "authors": [
      "Bushra Sabir",
      "M. Ali Babar",
      "Raj Gaire",
      "Alsharif Abuadbba"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.01511",
    "title": "Temporal Representation Learning on Monocular Videos for 3D Human Pose  Estimation",
    "abstract": " Comments: Accepted in \"IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\" ",
    "url": "https://arxiv.org/abs/2012.01511",
    "authors": [
      "Sina Honari",
      "Victor Constantin",
      "Helge Rhodin",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.05013",
    "title": "Spherical Message Passing for 3D Graph Networks",
    "abstract": " Comments: The paper has been accepted by ICLR 2022. You can also cite the conference version ",
    "url": "https://arxiv.org/abs/2102.05013",
    "authors": [
      "Yi Liu",
      "Limei Wang",
      "Meng Liu",
      "Xuan Zhang",
      "Bora Oztekin",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.03864",
    "title": "Modeling Object Dissimilarity for Deep Saliency Prediction",
    "abstract": " Comments: Transactions on Machine Learning Research (TMLR 2022) this https URL ",
    "url": "https://arxiv.org/abs/2104.03864",
    "authors": [
      "Bahar Aydemir",
      "Deblina Bhattacharjee",
      "Tong Zhang",
      "Seungryong Kim",
      "Mathieu Salzmann",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.06152",
    "title": "On the Robustness of Average Losses for Partial-Label Learning",
    "abstract": " Title: On the Robustness of Average Losses for Partial-Label Learning ",
    "url": "https://arxiv.org/abs/2106.06152",
    "authors": [
      "Jiaqi Lv",
      "Biao Liu",
      "Lei Feng",
      "Ning Xu",
      "Miao Xu",
      "Bo An",
      "Gang Niu",
      "Xin Geng",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.10648",
    "title": "DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection",
    "abstract": " Comments: Accepted at IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM) 2022 ",
    "url": "https://arxiv.org/abs/2107.10648",
    "authors": [
      "Mohit Mayank",
      "Shakshi Sharma",
      "Rajesh Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.06717",
    "title": "Time delay estimation of traffic congestion propagation due to accidents  based on statistical causality",
    "abstract": " Comments: this http URL ",
    "url": "https://arxiv.org/abs/2108.06717",
    "authors": [
      "YongKyung Oh",
      "JiIn Kwak",
      "Sungil Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.08843",
    "title": "Graph Wedgelets: Adaptive Data Compression on Graphs based on Binary  Wedge Partitioning Trees and Geometric Wavelets",
    "abstract": " Comments: 12 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2110.08843",
    "authors": [
      "Wolfgang Erb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.09344",
    "title": "ifMixup: Interpolating Graph Pair to Regularize Graph Classification",
    "abstract": " Comments: To appear in AAAI2023 ",
    "url": "https://arxiv.org/abs/2110.09344",
    "authors": [
      "Hongyu Guo",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.05329",
    "title": "Self-Supervised Audio-Visual Representation Learning with Relaxed  Cross-Modal Synchronicity",
    "abstract": " Comments: Accepted in AAAI 2023 ",
    "url": "https://arxiv.org/abs/2111.05329",
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.11932",
    "title": "Modelling Direct Messaging Networks with Multiple Recipients for Cyber  Deception",
    "abstract": " Title: Modelling Direct Messaging Networks with Multiple Recipients for Cyber  Deception ",
    "url": "https://arxiv.org/abs/2111.11932",
    "authors": [
      "Kristen Moore",
      "Cody J. Christopher",
      "David Liebowitz",
      "Surya Nepal",
      "Renee Selvey"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.13304",
    "title": "Data Fusion Challenges Privacy: What Can Privacy Regulation Do?",
    "abstract": " Comments: 18 pages ",
    "url": "https://arxiv.org/abs/2111.13304",
    "authors": [
      "G\u00e1bor Erd\u00e9lyi",
      "Olivia J. Erd\u00e9lyi",
      "Andreas W. Kempa-Liehr"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.04768",
    "title": "Quantum Link Prediction in Complex Networks",
    "abstract": " Comments: Keywords: Complex Networks, Quantum Algorithms, Link Prediction, Social Networks, Protein-Protein Interaction Networks ",
    "url": "https://arxiv.org/abs/2112.04768",
    "authors": [
      "Jo\u00e3o P. Moutinho",
      "Andr\u00e9 Melo",
      "Bruno Coutinho",
      "Istv\u00e1n A. Kov\u00e1cs",
      "Yasser Omar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2112.08544",
    "title": "NewsClaims: A New Benchmark for Claim Detection from News with Attribute  Knowledge",
    "abstract": " Comments: Accepted at EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2112.08544",
    "authors": [
      "Revanth Gangi Reddy",
      "Sai Chetan",
      "Zhenhailong Wang",
      "Yi R. Fung",
      "Kathryn Conger",
      "Ahmed Elsayed",
      "Martha Palmer",
      "Preslav Nakov",
      "Eduard Hovy",
      "Kevin Small",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.00471",
    "title": "Causal effect of racial bias in data and machine learning algorithms on  user persuasiveness & discriminatory decision making: An Empirical Study",
    "abstract": " Comments: Fresh experiments need to be added to the design of experiments ",
    "url": "https://arxiv.org/abs/2202.00471",
    "authors": [
      "Kinshuk Sengupta",
      "Praveen Ranjan Srivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2202.01606",
    "title": "Graph Coloring with Physics-Inspired Graph Neural Networks",
    "abstract": " Comments: Manuscript: 8 pages, 5 figures, 2 tables. Supplemental Material: 1 page, 2 tables ",
    "url": "https://arxiv.org/abs/2202.01606",
    "authors": [
      "Martin J. A. Schuetz",
      "J. Kyle Brubaker",
      "Zhihuai Zhu",
      "Helmut G. Katzgraber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2202.02242",
    "title": "Dikaios: Privacy Auditing of Algorithmic Fairness via Attribute  Inference Attacks",
    "abstract": " Comments: The paper's results and conclusions underwent significant changes. The updated paper can be found at arXiv:2211.10209 ",
    "url": "https://arxiv.org/abs/2202.02242",
    "authors": [
      "Jan Aalmoes",
      "Vasisht Duddu",
      "Antoine Boutet"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10974",
    "title": "Towards Self-Supervised Gaze Estimation",
    "abstract": " Comments: BMVC 2022. For code and pre-trained models, visit this https URL ",
    "url": "https://arxiv.org/abs/2203.10974",
    "authors": [
      "Arya Farkhondeh",
      "Cristina Palmero",
      "Simone Scardapane",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.00313",
    "title": "Deep neural networks for solving large linear systems arising from  high-dimensional problems",
    "abstract": " Title: Deep neural networks for solving large linear systems arising from  high-dimensional problems ",
    "url": "https://arxiv.org/abs/2204.00313",
    "authors": [
      "Yiqi Gu",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.03316",
    "title": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "abstract": " Title: Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion ",
    "url": "https://arxiv.org/abs/2204.03316",
    "authors": [
      "HanQin Cai",
      "Jian-Feng Cai",
      "Juntao You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.03541",
    "title": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge  Distillation",
    "abstract": " Title: End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge  Distillation ",
    "url": "https://arxiv.org/abs/2204.03541",
    "authors": [
      "Mingrui Wu",
      "Jiaxin Gu",
      "Yunhang Shen",
      "Mingbao Lin",
      "Chao Chen",
      "Xiaoshuai Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.12586",
    "title": "Enhanced compound-protein binding affinity prediction by representing  protein multimodal information via a coevolutionary strategy",
    "abstract": " Comments: 53 pages, 14 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2204.12586",
    "authors": [
      "Binjie Guo",
      "Hanyu Zheng",
      "Haohan Jiang",
      "Xiaodan Li",
      "Naiyu Guan",
      "Yanming Zuo",
      "Yicheng Zhang",
      "Hengfu Yang",
      "Xuhua Wang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10023",
    "title": "Transition-based Semantic Role Labeling with Pointer Networks",
    "abstract": " Comments: Final peer-reviewed manuscript accepted for publication in Knowledge-Based Systems ",
    "url": "https://arxiv.org/abs/2205.10023",
    "authors": [
      "Daniel Fern\u00e1ndez-Gonz\u00e1lez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10366",
    "title": "Fast Change Identification in Multi-Play Bandits and its Applications in  Wireless Networks",
    "abstract": " Comments: Corrected the assumptions and removed the case-study due to an error ",
    "url": "https://arxiv.org/abs/2205.10366",
    "authors": [
      "Gourab Ghatak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.00241",
    "title": "Asymptotic Properties for Bayesian Neural Network in Besov Space",
    "abstract": " Title: Asymptotic Properties for Bayesian Neural Network in Besov Space ",
    "url": "https://arxiv.org/abs/2206.00241",
    "authors": [
      "Kyeongwon Lee",
      "Jaeyong Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.02095",
    "title": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "abstract": " Title: ARC -- Actor Residual Critic for Adversarial Imitation Learning ",
    "url": "https://arxiv.org/abs/2206.02095",
    "authors": [
      "Ankur Deka",
      "Changliu Liu",
      "Katia Sycara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.02993",
    "title": "False Consensus, Information Theory, and Prediction Markets",
    "abstract": " Comments: To appear in ITCS 2023 ",
    "url": "https://arxiv.org/abs/2206.02993",
    "authors": [
      "Yuqing Kong",
      "Grant Schoenebeck"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2206.04510",
    "title": "SsciBERT: A Pre-trained Language Model for Social Science Texts",
    "abstract": " Comments: 24 pages,2 figures ",
    "url": "https://arxiv.org/abs/2206.04510",
    "authors": [
      "Si Shen",
      "Jiangfeng Liu",
      "Litao Lin",
      "Ying Huang",
      "Lin Zhang",
      "Chang Liu",
      "Yutong Feng",
      "Dongbo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.06112",
    "title": "Vision-State Fusion: Improving Deep Neural Networks for Autonomous  Robotics",
    "abstract": " Comments: 8 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2206.06112",
    "authors": [
      "Elia Cereda",
      "Stefano Bonato",
      "Mirko Nava",
      "Alessandro Giusti",
      "Daniele Palossi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.06743",
    "title": "Weakly-Supervised Crack Detection",
    "abstract": " Comments: Submitted to IEEE Transactions on Intelligent Transportation Systems ",
    "url": "https://arxiv.org/abs/2206.06743",
    "authors": [
      "Yuki Inoue",
      "Hiroto Nagayoshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07293",
    "title": "FRCRN: Boosting Feature Representation using Frequency Recurrence for  Monaural Speech Enhancement",
    "abstract": " Comments: The paper has been accepted by ICASSP 2022. 5 pages, 2 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2206.07293",
    "authors": [
      "Shengkui Zhao",
      "Bin Ma",
      "Karn N. Watcharasupat",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.08657",
    "title": "BridgeTower: Building Bridges Between Encoders in Vision-Language  Representation Learning",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2206.08657",
    "authors": [
      "Xiao Xu",
      "Chenfei Wu",
      "Shachar Rosenman",
      "Vasudev Lal",
      "Wanxiang Che",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11134",
    "title": "Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization",
    "abstract": " Title: Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization ",
    "url": "https://arxiv.org/abs/2206.11134",
    "authors": [
      "Peixian Chen",
      "Kekai Sheng",
      "Mengdan Zhang",
      "Mingbao Lin",
      "Yunhang Shen",
      "Shaohui Lin",
      "Bo Ren",
      "Ke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.13263",
    "title": "Learning with Weak Annotations for Robust Maritime Obstacle Detection",
    "abstract": " Comments: Published in MDPI Sensors, 23 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2206.13263",
    "authors": [
      "Lojze \u017dust",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08562",
    "title": "DHGE: Dual-view Hyper-Relational Knowledge Graph Embedding for Link  Prediction and Entity Typing",
    "abstract": " Comments: Accepted by the 37th AAAI Conference on Artificial Intelligence (AAAI-2023) ",
    "url": "https://arxiv.org/abs/2207.08562",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Ling Tan",
      "Gengxian Zhou",
      "Tianyu Yao",
      "Kaiyang Wan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09088",
    "title": "XG-BoT: An Explainable Deep Graph Neural Network for Botnet Detection  and Forensics",
    "abstract": " Comments: 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2207.09088",
    "authors": [
      "Wai Weng Lo",
      "Gayan K. Kulatilleke",
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.11088",
    "title": "Layer-refined Graph Convolutional Networks for Recommendation",
    "abstract": " Comments: Accepted as a research track paper in ICDE 2023 ",
    "url": "https://arxiv.org/abs/2207.11088",
    "authors": [
      "Xin Zhou",
      "Donghui Lin",
      "Yong Liu",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.12391",
    "title": "SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and  Boosting Segmentation Robustness",
    "abstract": " Title: SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and  Boosting Segmentation Robustness ",
    "url": "https://arxiv.org/abs/2207.12391",
    "authors": [
      "Jindong Gu",
      "Hengshuang Zhao",
      "Volker Tresp",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.13339",
    "title": "ALBench: A Framework for Evaluating Active Learning in Object Detection",
    "abstract": " Title: ALBench: A Framework for Evaluating Active Learning in Object Detection ",
    "url": "https://arxiv.org/abs/2207.13339",
    "authors": [
      "Zhanpeng Feng",
      "Shiliang Zhang",
      "Rinyoichi Takezoe",
      "Wenze Hu",
      "Manmohan Chandraker",
      "Li-Jia Li",
      "Vijay K. Narayanan",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.01521",
    "title": "DSR -- A dual subspace re-projection network for surface anomaly  detection",
    "abstract": " Comments: Presented at ECCV2022 ",
    "url": "https://arxiv.org/abs/2208.01521",
    "authors": [
      "Vitjan Zavrtanik",
      "Matej Kristan",
      "Danijel Sko\u010daj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.03610",
    "title": "Blackbox Attacks via Surrogate Ensemble Search",
    "abstract": " Comments: Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2208.03610",
    "authors": [
      "Zikui Cai",
      "Chengyu Song",
      "Srikanth Krishnamurthy",
      "Amit Roy-Chowdhury",
      "M. Salman Asif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.04018",
    "title": "Hybrid-ARQ Based Relaying Strategies for Enhancing Reliability in  Delay-Bounded Networks",
    "abstract": " Comments: 30 pages. arXiv admin note: text overlap with arXiv:2203.08381 ",
    "url": "https://arxiv.org/abs/2208.04018",
    "authors": [
      "Jaya Goel",
      "J. Harshan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.06681",
    "title": "Modeling biological face recognition with deep convolutional neural  networks",
    "abstract": " Comments: 24 pages, 2 figures, 1 table ",
    "url": "https://arxiv.org/abs/2208.06681",
    "authors": [
      "Leonard E. van Dyck",
      "Walter R. Gruber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.08677",
    "title": "Enhancing Targeted Attack Transferability via Diversified Weight Pruning",
    "abstract": " Comments: 8 pages + Appendix ",
    "url": "https://arxiv.org/abs/2208.08677",
    "authors": [
      "Hung-Jui Wang",
      "Yu-Yu Wu",
      "Shang-Tse Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.13179",
    "title": "Learning Heterogeneous Interaction Strengths by Trajectory Prediction  with Graph Neural Network",
    "abstract": " Comments: 14 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2208.13179",
    "authors": [
      "Seungwoong Ha",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.06535",
    "title": "CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion  Transformer",
    "abstract": " Comments: Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI'23) ",
    "url": "https://arxiv.org/abs/2209.06535",
    "authors": [
      "Youngseok Kim",
      "Sanmin Kim",
      "Jun Won Choi",
      "Dongsuk Kum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.09108",
    "title": "Online Poisoning Attacks Against Data-Driven Predictive Control",
    "abstract": " Title: Online Poisoning Attacks Against Data-Driven Predictive Control ",
    "url": "https://arxiv.org/abs/2209.09108",
    "authors": [
      "Yue Yu",
      "Ruihan Zhao",
      "Sandeep Chinchali",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.09383",
    "title": "Distributed representations of graphs for drug pair scoring",
    "abstract": " Comments: Updated manuscript, 9 main pages, 8 pages reference and appendix ",
    "url": "https://arxiv.org/abs/2209.09383",
    "authors": [
      "Paul Scherer",
      "Pietro Li\u00f2",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2209.09732",
    "title": "Neural Graph Databases",
    "abstract": " Title: Neural Graph Databases ",
    "url": "https://arxiv.org/abs/2209.09732",
    "authors": [
      "Maciej Besta",
      "Patrick Iff",
      "Florian Scheidl",
      "Kazuki Osawa",
      "Nikoli Dryden",
      "Michal Podstawski",
      "Tiancheng Chen",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2209.12362",
    "title": "Multi-dataset Training of Transformers for Robust Action Recognition",
    "abstract": " Comments: NeurIPS 2022 Spotlight paper. Supplementary material at this https URL Code and models are available at this https URL ",
    "url": "https://arxiv.org/abs/2209.12362",
    "authors": [
      "Junwei Liang",
      "Enwei Zhang",
      "Jun Zhang",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.12894",
    "title": "Biologically-Plausible Determinant Maximization Neural Networks for  Blind Separation of Correlated Sources",
    "abstract": " Comments: NeurIPS 2022, 37 pages ",
    "url": "https://arxiv.org/abs/2209.12894",
    "authors": [
      "Bariscan Bozkurt",
      "Cengiz Pehlevan",
      "Alper T. Erdogan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.13410",
    "title": "Graph Neural Network Expressivity and Meta-Learning for Molecular  Property Regression",
    "abstract": " Title: Graph Neural Network Expressivity and Meta-Learning for Molecular  Property Regression ",
    "url": "https://arxiv.org/abs/2209.13410",
    "authors": [
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "Federico Barbero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.03919",
    "title": "CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features  for a Disentangled, Interpretable, and Controllable Text-Guided Image  Manipulation",
    "abstract": " Title: CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features  for a Disentangled, Interpretable, and Controllable Text-Guided Image  Manipulation ",
    "url": "https://arxiv.org/abs/2210.03919",
    "authors": [
      "Chenliang Zhou",
      "Fangcheng Zhong",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08219",
    "title": "Unveiling the Sampling Density in Non-Uniform Geometric Graphs",
    "abstract": " Comments: updated affiliations; improved references; more experiments; streamlined the paper; added justification for the geometric graph with hubs model ",
    "url": "https://arxiv.org/abs/2210.08219",
    "authors": [
      "Raffaele Paolino",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10886",
    "title": "Backdoor Attack and Defense in Federated Generative Adversarial  Network-based Medical Image Synthesis",
    "abstract": " Comments: 25 pages, 7 figures. arXiv admin note: text overlap with arXiv:2207.00762 ",
    "url": "https://arxiv.org/abs/2210.10886",
    "authors": [
      "Ruinan Jin",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11456",
    "title": "MixMask: Revisiting Masked Siamese Self-supervised Learning in  Asymmetric Distance",
    "abstract": " Comments: Technical report. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2210.11456",
    "authors": [
      "Kirill Vishniakov",
      "Eric Xing",
      "Zhiqiang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12681",
    "title": "Rethinking Rotation in Self-Supervised Contrastive Learning: Adaptive  Positive or Negative Data Augmentation",
    "abstract": " Comments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023 ",
    "url": "https://arxiv.org/abs/2210.12681",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Daiki Ikami",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15212",
    "title": "COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with  Contrastive and Distributionally Robust Learning",
    "abstract": " Comments: EMNLP 2022 (Main Conference). The code and Model can be found at this https URL ",
    "url": "https://arxiv.org/abs/2210.15212",
    "authors": [
      "Yue Yu",
      "Chenyan Xiong",
      "Si Sun",
      "Chao Zhang",
      "Arnold Overwijk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15936",
    "title": "A comprehensive study on self-supervised distillation for speaker  representation learning",
    "abstract": " Comments: Accepted by SLT2022 ",
    "url": "https://arxiv.org/abs/2210.15936",
    "authors": [
      "Zhengyang Chen",
      "Yao Qian",
      "Bing Han",
      "Yanmin Qian",
      "Michael Zeng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.06545",
    "title": "Self-Supervised Graph Structure Refinement for Graph Neural Networks",
    "abstract": " Comments: WSDM 2023 ",
    "url": "https://arxiv.org/abs/2211.06545",
    "authors": [
      "Jianan Zhao",
      "Qianlong Wen",
      "Mingxuan Ju",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.06666",
    "title": "Optimizing Bandwidth Sharing for Real-time Traffic in Wireless Networks",
    "abstract": " Title: Optimizing Bandwidth Sharing for Real-time Traffic in Wireless Networks ",
    "url": "https://arxiv.org/abs/2211.06666",
    "authors": [
      "Sushi Anna George",
      "Vinay Joseph"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.07400",
    "title": "Efficient Integration of Multi-Order Dynamics and Internal Dynamics in  Stock Movement Prediction",
    "abstract": " Comments: Technical report for accepted paper at WSDM 2023 ",
    "url": "https://arxiv.org/abs/2211.07400",
    "authors": [
      "Thanh Trung Huynh",
      "Minh Hieu Nguyen",
      "Thanh Tam Nguyen",
      "Phi Le Nguyen",
      "Matthias Weidlich",
      "Quoc Viet Hung Nguyen",
      "Karl Aberer"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.07915",
    "title": "Backdoor Attacks on Time Series: A Generative Approach",
    "abstract": " Title: Backdoor Attacks on Time Series: A Generative Approach ",
    "url": "https://arxiv.org/abs/2211.07915",
    "authors": [
      "Yujing Jiang",
      "Xingjun Ma",
      "Sarah Monazam Erfani",
      "James Bailey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10012",
    "title": "A Tale of Two Cities: Data and Configuration Variances in Robust Deep  Learning",
    "abstract": " Title: A Tale of Two Cities: Data and Configuration Variances in Robust Deep  Learning ",
    "url": "https://arxiv.org/abs/2211.10012",
    "authors": [
      "Guanqin Zhang",
      "Jiankun Sun",
      "Feng Xu",
      "H.M.N. Dilum Bandara",
      "Shiping Chen",
      "Yulei Sui",
      "Tim Menzies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.10738",
    "title": "Relational Symmetry based Knowledge Graph Contrastive Learning",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2211.10738",
    "authors": [
      "Ke Liang",
      "Yue Liu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Wenxuan Tu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10782",
    "title": "Let Graph be the Go Board: Gradient-free Node Injection Attack for Graph  Neural Networks via Reinforcement Learning",
    "abstract": " Comments: AAAI 2023. v2: update acknowledgement section. arXiv admin note: substantial text overlap with arXiv:2202.09389 ",
    "url": "https://arxiv.org/abs/2211.10782",
    "authors": [
      "Mingxuan Ju",
      "Yujie Fan",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.11349",
    "title": "Data-Driven Offline Decision-Making via Invariant Representation  Learning",
    "abstract": " Comments: This is an extended version of the NeurIPS 2022 conference paper titled: \"Data-Driven Offline Model-Based Optimization via Invariant Representation Learning\" ",
    "url": "https://arxiv.org/abs/2211.11349",
    "authors": [
      "Han Qi",
      "Yi Su",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11865",
    "title": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "abstract": " Title: Bayesian Learning for Neural Networks: an algorithmic survey ",
    "url": "https://arxiv.org/abs/2211.11865",
    "authors": [
      "Martin Magris",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12322",
    "title": "TranViT: An Integrated Vision Transformer Framework for Discrete Transit  Travel Time Range Prediction",
    "abstract": " Comments: Revised typographical errors, added more details to results and discussions ",
    "url": "https://arxiv.org/abs/2211.12322",
    "authors": [
      "Awad Abdelhalim",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12748",
    "title": "Dynamic Appearance: A Video Representation for Action Recognition with  Joint Training",
    "abstract": " Title: Dynamic Appearance: A Video Representation for Action Recognition with  Joint Training ",
    "url": "https://arxiv.org/abs/2211.12748",
    "authors": [
      "Guoxi Huang",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12759",
    "title": "NAS-LID: Efficient Neural Architecture Search with Local Intrinsic  Dimension",
    "abstract": " Comments: Accepted by AAAI2023, AutoML, NAS ",
    "url": "https://arxiv.org/abs/2211.12759",
    "authors": [
      "Xin He",
      "Jiangchao Yao",
      "Yuxin Wang",
      "Zhenheng Tang",
      "Ka Chu Cheung",
      "Simon See",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12875",
    "title": "A Survey of Deep Graph Clustering: Taxonomy, Challenge, and Application",
    "abstract": " Comments: 13 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2211.12875",
    "authors": [
      "Yue Liu",
      "Jun Xia",
      "Sihang Zhou",
      "Siwei Wang",
      "Xifeng Guo",
      "Xihong Yang",
      "Ke Liang",
      "Wenxuan Tu",
      "Stan Z. Li",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12879",
    "title": "Data Augmentation Vision Transformer for Fine-grained Image  Classification",
    "abstract": " Comments: IEEE Signal Processing Letters ",
    "url": "https://arxiv.org/abs/2211.12879",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu",
      "Weibin Qiu",
      "Weijie Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13090",
    "title": "TransVCL: Attention-enhanced Video Copy Localization Network with  Flexible Supervision",
    "abstract": " Comments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023) ",
    "url": "https://arxiv.org/abs/2211.13090",
    "authors": [
      "Sifeng He",
      "Yue He",
      "Minlong Lu",
      "Chen Jiang",
      "Xudong Yang",
      "Feng Qian",
      "Xiaobo Zhang",
      "Lei Yang",
      "Jiandong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13157",
    "title": "Physics-Informed Multi-Stage Deep Learning Framework Development for  Digital Twin-Centred State-Based Reactor Power Prediction",
    "abstract": " Title: Physics-Informed Multi-Stage Deep Learning Framework Development for  Digital Twin-Centred State-Based Reactor Power Prediction ",
    "url": "https://arxiv.org/abs/2211.13157",
    "authors": [
      "James Daniell",
      "Kazuma Kobayashi",
      "Susmita Naskar",
      "Dinesh Kumar",
      "Souvik Chakraborty",
      "Ayodeji Alajo",
      "Ethan Taber",
      "Joseph Graham",
      "Syed Alam"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  }
]