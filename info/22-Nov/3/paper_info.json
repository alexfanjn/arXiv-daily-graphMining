[
  {
    "id": "arXiv:2211.00642",
    "title": "Farm-wide virtual load monitoring for offshore wind structures via  Bayesian neural networks",
    "abstract": "Offshore wind structures are subject to deterioration mechanisms throughout their operational lifetime. Even if the deterioration evolution of structural elements can be estimated through physics-based deterioration models, the uncertainties involved in the process hurdle the selection of lifecycle management decisions. In this scenario, the collection of relevant information through an efficient monitoring system enables the reduction of uncertainties, ultimately driving more optimal lifecycle decisions. However, a full monitoring instrumentation implemented on all wind turbines in a farm might become unfeasible due to practical and economical constraints. Besides, certain load monitoring systems often become defective after a few years of marine environment exposure. Addressing the aforementioned concerns, a farm-wide virtual load monitoring scheme directed by a fleet-leader wind turbine offers an attractive solution. Fetched with data retrieved from a fully-instrumented wind turbine, a model can be trained and then deployed, thus yielding load predictions of non-fully monitored wind turbines, from which only standard data remains available. In this paper, we propose a virtual load monitoring framework formulated via Bayesian neural networks (BNNs) and we provide relevant implementation details needed for the construction, training, and deployment of BNN data-based virtual monitoring models. As opposed to their deterministic counterparts, BNNs intrinsically announce the uncertainties associated with generated load predictions and allow to detect inaccurate load estimations generated for non-fully monitored wind turbines. The proposed virtual load monitoring is thoroughly tested through an experimental campaign in an operational offshore wind farm and the results demonstrate the effectiveness of BNN models for fleet-leader-based farm-wide virtual monitoring. ",
    "url": "https://arxiv.org/abs/2211.00642",
    "authors": [
      "N. Hlaing",
      "Pablo G. Morato",
      "F. d. N. Santos",
      "W. Weijtjens",
      "C. Devriendt",
      "P. Rigo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2211.00680",
    "title": "On the detection of synthetic images generated by diffusion models",
    "abstract": "Over the past decade, there has been tremendous progress in creating synthetic media, mainly thanks to the development of powerful methods based on generative adversarial networks (GAN). Very recently, methods based on diffusion models (DM) have been gaining the spotlight. In addition to providing an impressive level of photorealism, they enable the creation of text-based visual content, opening up new and exciting opportunities in many different application fields, from arts to video games. On the other hand, this property is an additional asset in the hands of malicious users, who can generate and distribute fake media perfectly adapted to their attacks, posing new challenges to the media forensic community. With this work, we seek to understand how difficult it is to distinguish synthetic images generated by diffusion models from pristine ones and whether current state-of-the-art detectors are suitable for the task. To this end, first we expose the forensics traces left by diffusion models, then study how current detectors, developed for GAN-generated images, perform on these new synthetic images, especially in challenging social-networks scenarios involving image compression and resizing. Datasets and code are available at github.com/grip-unina/DMimageDetection. ",
    "url": "https://arxiv.org/abs/2211.00680",
    "authors": [
      "Riccardo Corvi",
      "Davide Cozzolino",
      "Giada Zingarini",
      "Giovanni Poggi",
      "Koki Nagano",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00684",
    "title": "TOE: A Grid-Tagging Discontinuous NER Model Enhanced by Embedding  Tag/Word Relations and More Fine-Grained Tags",
    "abstract": "So far, discontinuous named entity recognition (NER) has received increasing research attention and many related methods have surged such as hypergraph-based methods, span-based methods, and sequence-to-sequence (Seq2Seq) methods, etc. However, these methods more or less suffer from some problems such as decoding ambiguity and efficiency, which limit their performance. Recently, grid-tagging methods, which benefit from the flexible design of tagging systems and model architectures, have shown superiority to adapt for various information extraction tasks. In this paper, we follow the line of such methods and propose a competitive grid-tagging model for discontinuous NER. We call our model TOE because we incorporate two kinds of Tag-Oriented Enhancement mechanisms into a state-of-the-art (SOTA) grid-tagging model that casts the NER problem into word-word relationship prediction. First, we design a Tag Representation Embedding Module (TREM) to force our model to consider not only word-word relationships but also word-tag and tag-tag relationships. Concretely, we construct tag representations and embed them into TREM, so that TREM can treat tag and word representations as queries/keys/values and utilize self-attention to model their relationships. On the other hand, motivated by the Next-Neighboring-Word (NNW) and Tail-Head-Word (THW) tags in the SOTA model, we add two new symmetric tags, namely Previous-Neighboring-Word (PNW) and Head-Tail-Word (HTW), to model more fine-grained word-word relationships and alleviate error propagation from tag prediction. In the experiments of three benchmark datasets, namely CADEC, ShARe13 and ShARe14, our TOE model pushes the SOTA results by about 0.83%, 0.05% and 0.66% in F1, demonstrating its effectiveness. ",
    "url": "https://arxiv.org/abs/2211.00684",
    "authors": [
      "Jiang Liu",
      "Donghong Ji",
      "Jingye Li",
      "Dongdong Xie",
      "Chong Teng",
      "Liang Zhao",
      "Fei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00692",
    "title": "Towards Better Out-of-Distribution Generalization of Neural Algorithmic  Reasoning Tasks",
    "abstract": "In this paper, we study the OOD generalization of neural algorithmic reasoning tasks, where the goal is to learn an algorithm (e.g., sorting, breadth-first search, and depth-first search) from input-output pairs using deep neural networks. First, we argue that OOD generalization in this setting is significantly different than common OOD settings. For example, some phenomena in OOD generalization of image classifications such as \\emph{accuracy on the line} are not observed here, and techniques such as data augmentation methods do not help as assumptions underlying many augmentation techniques are often violated. Second, we analyze the main challenges (e.g., input distribution shift, non-representative data generation, and uninformative validation metrics) of the current leading benchmark, i.e., CLRS \\citep{deepmind2021clrs}, which contains 30 algorithmic reasoning tasks. We propose several solutions, including a simple-yet-effective fix to the input distribution shift and improved data generation. Finally, we propose an attention-based 2WL-graph neural network (GNN) processor which complements message-passing GNNs so their combination outperforms the state-of-the-art model by a 3% margin averaged over all algorithms. Our code is available at: \\url{https://github.com/smahdavi4/clrs}. ",
    "url": "https://arxiv.org/abs/2211.00692",
    "authors": [
      "Sadegh Mahdavi",
      "Kevin Swersky",
      "Thomas Kipf",
      "Milad Hashemi",
      "Christos Thrampoulidis",
      "Renjie Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00709",
    "title": "Semantic Pivoting Model for Effective Event Detection",
    "abstract": "Event Detection, which aims to identify and classify mentions of event instances from unstructured articles, is an important task in Natural Language Processing (NLP). Existing techniques for event detection only use homogeneous one-hot vectors to represent the event type classes, ignoring the fact that the semantic meaning of the types is important to the task. Such an approach is inefficient and prone to overfitting. In this paper, we propose a Semantic Pivoting Model for Effective Event Detection (SPEED), which explicitly incorporates prior information during training and captures semantically meaningful correlations between input and events. Experimental results show that our proposed model achieves state-of-the-art performance and outperforms the baselines in multiple settings without using any external resources. ",
    "url": "https://arxiv.org/abs/2211.00709",
    "authors": [
      "Anran Hao",
      "Siu Cheung Hui",
      "Jian Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.00713",
    "title": "MAgNET: A Graph U-Net Architecture for Mesh-Based Simulations",
    "abstract": "Mesh-based approaches are fundamental to solving physics-based simulations, however, they require significant computational efforts, especially for highly non-linear problems. Deep learning techniques accelerate physics-based simulations, however, they fail to perform efficiently as the size and complexity of the problem increases. Hence in this work, we propose MAgNET: Multi-channel Aggregation Network, a novel geometric deep learning framework for performing supervised learning on mesh-based graph data. MAgNET is based on the proposed MAg (Multichannel Aggregation) operation which generalises the concept of multi-channel local operations in convolutional neural networks to arbitrary non-grid inputs. MAg can efficiently perform non-linear regression mapping for graph-structured data. MAg layers are interleaved with the proposed novel graph pooling operations to constitute a graph U-Net architecture that is robust, handles arbitrary complex meshes and scales efficiently with the size of the problem. Although not limited to the type of discretisation, we showcase the predictive capabilities of MAgNET for several non-linear finite element simulations. ",
    "url": "https://arxiv.org/abs/2211.00713",
    "authors": [
      "Saurabh Deshpande",
      "Jakub Lengiewicz",
      "St\u00e9phane P.A. Bordas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2211.00718",
    "title": "SleepyWheels: An Ensemble Model for Drowsiness Detection leading to  Accident Prevention",
    "abstract": "Around 40 percent of accidents related to driving on highways in India occur due to the driver falling asleep behind the steering wheel. Several types of research are ongoing to detect driver drowsiness but they suffer from the complexity and cost of the models. In this paper, SleepyWheels a revolutionary method that uses a lightweight neural network in conjunction with facial landmark identification is proposed to identify driver fatigue in real time. SleepyWheels is successful in a wide range of test scenarios, including the lack of facial characteristics while covering the eye or mouth, the drivers varying skin tones, camera placements, and observational angles. It can work well when emulated to real time systems. SleepyWheels utilized EfficientNetV2 and a facial landmark detector for identifying drowsiness detection. The model is trained on a specially created dataset on driver sleepiness and it achieves an accuracy of 97 percent. The model is lightweight hence it can be further deployed as a mobile application for various platforms. ",
    "url": "https://arxiv.org/abs/2211.00718",
    "authors": [
      "Jomin Jose",
      "Andrew J",
      "Kumudha Raimond",
      "Shweta Vincent"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00722",
    "title": "VIINTER: View Interpolation with Implicit Neural Representations of  Images",
    "abstract": "We present VIINTER, a method for view interpolation by interpolating the implicit neural representation (INR) of the captured images. We leverage the learned code vector associated with each image and interpolate between these codes to achieve viewpoint transitions. We propose several techniques that significantly enhance the interpolation quality. VIINTER signifies a new way to achieve view interpolation without constructing 3D structure, estimating camera poses, or computing pixel correspondence. We validate the effectiveness of VIINTER on several multi-view scenes with different types of camera layout and scene composition. As the development of INR of images (as opposed to surface or volume) has centered around tasks like image fitting and super-resolution, with VIINTER, we show its capability for view interpolation and offer a promising outlook on using INR for image manipulation tasks. ",
    "url": "https://arxiv.org/abs/2211.00722",
    "authors": [
      "Brandon Yushan Feng",
      "Susmija Jabbireddy",
      "Amitabh Varshney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00731",
    "title": "Comparision Of Adversarial And Non-Adversarial LSTM Music Generative  Models",
    "abstract": "Algorithmic music composition is a way of composing musical pieces with minimal to no human intervention. While recurrent neural networks are traditionally applied to many sequence-to-sequence prediction tasks, including successful implementations of music composition, their standard supervised learning approach based on input-to-output mapping leads to a lack of note variety. These models can therefore be seen as potentially unsuitable for tasks such as music generation. Generative adversarial networks learn the generative distribution of data and lead to varied samples. This work implements and compares adversarial and non-adversarial training of recurrent neural network music composers on MIDI data. The resulting music samples are evaluated by human listeners, their preferences recorded. The evaluation indicates that adversarial training produces more aesthetically pleasing music. ",
    "url": "https://arxiv.org/abs/2211.00731",
    "authors": [
      "Moseli Mots'oehli",
      "Anna Sergeevna Bosman",
      "Johan Pieter De Villiers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00733",
    "title": "State-of-the-art Models for Object Detection in Various Fields of  Application",
    "abstract": "We present a list of datasets and their best models with the goal of advancing the state-of-the-art in object detection by placing the question of object recognition in the context of the two types of state-of-the-art methods: one-stage methods and two stage-methods. We provided an in-depth statistical analysis of the five top datasets in the light of recent developments in granulated Deep Learning models - COCO minival, COCO test, Pascal VOC 2007, ADE20K, and ImageNet. The datasets are handpicked after closely comparing them with the rest in terms of diversity, quality of data, minimal bias, labeling quality etc. More importantly, our work extends to provide the best combination of these datasets with the emerging models in the last two years. It lists the top models and their optimal use cases for each of the respective datasets. We have provided a comprehensive overview of a variety of both generic and specific object detection models, enlisting comparative results like inference time and average precision of box (AP) fixed at different Intersection Over Union (IoUs) and for different sized objects. The qualitative and quantitative analysis will allow experts to achieve new performance records using the best combination of datasets and models. ",
    "url": "https://arxiv.org/abs/2211.00733",
    "authors": [
      "Syed Ali John Naqvi",
      "Syed Bazil Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00734",
    "title": "On the Interaction Between Differential Privacy and Gradient Compression  in Deep Learning",
    "abstract": "While differential privacy and gradient compression are separately well-researched topics in machine learning, the study of interaction between these two topics is still relatively new. We perform a detailed empirical study on how the Gaussian mechanism for differential privacy and gradient compression jointly impact test accuracy in deep learning. The existing literature in gradient compression mostly evaluates compression in the absence of differential privacy guarantees, and demonstrate that sufficiently high compression rates reduce accuracy. Similarly, existing literature in differential privacy evaluates privacy mechanisms in the absence of compression, and demonstrates that sufficiently strong privacy guarantees reduce accuracy. In this work, we observe while gradient compression generally has a negative impact on test accuracy in non-private training, it can sometimes improve test accuracy in differentially private training. Specifically, we observe that when employing aggressive sparsification or rank reduction to the gradients, test accuracy is less affected by the Gaussian noise added for differential privacy. These observations are explained through an analysis how differential privacy and compression effects the bias and variance in estimating the average gradient. We follow this study with a recommendation on how to improve test accuracy under the context of differentially private deep learning and gradient compression. We evaluate this proposal and find that it can reduce the negative impact of noise added by differential privacy mechanisms on test accuracy by up to 24.6%, and reduce the negative impact of gradient sparsification on test accuracy by up to 15.1%. ",
    "url": "https://arxiv.org/abs/2211.00734",
    "authors": [
      "Jimmy Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.00746",
    "title": "3DMODT: Attention-Guided Affinities for Joint Detection & Tracking in 3D  Point Clouds",
    "abstract": "We propose a method for joint detection and tracking of multiple objects in 3D point clouds, a task conventionally treated as a two-step process comprising object detection followed by data association. Our method embeds both steps into a single end-to-end trainable network eliminating the dependency on external object detectors. Our model exploits temporal information employing multiple frames to detect objects and track them in a single network, thereby making it a utilitarian formulation for real-world scenarios. Computing affinity matrix by employing features similarity across consecutive point cloud scans forms an integral part of visual tracking. We propose an attention-based refinement module to refine the affinity matrix by suppressing erroneous correspondences. The module is designed to capture the global context in affinity matrix by employing self-attention within each affinity matrix and cross-attention across a pair of affinity matrices. Unlike competing approaches, our network does not require complex post-processing algorithms, and processes raw LiDAR frames to directly output tracking results. We demonstrate the effectiveness of our method on the three tracking benchmarks: JRDB, Waymo, and KITTI. Experimental evaluations indicate the ability of our model to generalize well across datasets. ",
    "url": "https://arxiv.org/abs/2211.00746",
    "authors": [
      "Jyoti Kini",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00748",
    "title": "Maximum Likelihood Distillation for Robust Modulation Classification",
    "abstract": "Deep Neural Networks are being extensively used in communication systems and Automatic Modulation Classification (AMC) in particular. However, they are very susceptible to small adversarial perturbations that are carefully crafted to change the network decision. In this work, we build on knowledge distillation ideas and adversarial training in order to build more robust AMC systems. We first outline the importance of the quality of the training data in terms of accuracy and robustness of the model. We then propose to use the Maximum Likelihood function, which could solve the AMC problem in offline settings, to generate better training labels. Those labels teach the model to be uncertain in challenging conditions, which permits to increase the accuracy, as well as the robustness of the model when combined with adversarial training. Interestingly, we observe that this increase in performance transfers to online settings, where the Maximum Likelihood function cannot be used in practice. Overall, this work highlights the potential of learning to be uncertain in difficult scenarios, compared to directly removing label noise. ",
    "url": "https://arxiv.org/abs/2211.00748",
    "authors": [
      "Javier Maroto",
      "G\u00e9r\u00f4me Bovet",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00758",
    "title": "Counterfactual Causality in Networks",
    "abstract": "In this abstract we propose a framework for explaining violations of safety properties in Software Defined Networks, using counterfactual causal reasoning. ",
    "url": "https://arxiv.org/abs/2211.00758",
    "authors": [
      "Georgiana Caltais",
      "Can Olmezoglu"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2211.00783",
    "title": "Impact Of Missing Data Imputation On The Fairness And Accuracy Of Graph  Node Classifiers",
    "abstract": "Analysis of the fairness of machine learning (ML) algorithms recently attracted many researchers' interest. Most ML methods show bias toward protected groups, which limits the applicability of ML models in many applications like crime rate prediction etc. Since the data may have missing values which, if not appropriately handled, are known to further harmfully affect fairness. Many imputation methods are proposed to deal with missing data. However, the effect of missing data imputation on fairness is not studied well. In this paper, we analyze the effect on fairness in the context of graph data (node attributes) imputation using different embedding and neural network methods. Extensive experiments on six datasets demonstrate severe fairness issues in missing data imputation under graph node classification. We also find that the choice of the imputation method affects both fairness and accuracy. Our results provide valuable insights into graph data fairness and how to handle missingness in graphs efficiently. This work also provides directions regarding theoretical studies on fairness in graph data. ",
    "url": "https://arxiv.org/abs/2211.00783",
    "authors": [
      "Haris Mansoor",
      "Sarwan Ali",
      "Shafiq Alam",
      "Muhammad Asad Khan",
      "Umair ul Hassan",
      "Imdadullah Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.00806",
    "title": "Optical Channel Impulse Response-Based Localization Using An Artificial  Neural Network",
    "abstract": "Visible light positioning has the potential to yield sub-centimeter accuracy in indoor environments, yet conventional received signal strength (RSS)-based localization algorithms cannot achieve this because their performance degrades from optical multipath reflection. However, this part of the optical received signal is deterministic due to the often static and predictable nature of the optical wireless channel. In this paper, the performance of optical channel impulse response (OCIR)-based localization is studied using an artificial neural network (ANN) to map embedded features of the OCIR to the user equipment's location. Numerical results show that OCIR-based localization outperforms conventional RSS techniques by two orders of magnitude using only two photodetectors as anchor points. The ANN technique can take advantage of multipath features in a wide range of scenarios, from using only the DC value to relying on high-resolution time sampling that can result in sub-centimeter accuracy. ",
    "url": "https://arxiv.org/abs/2211.00806",
    "authors": [
      "Hamid Hosseinianfar",
      "Hami Rabbani",
      "Maite Bradnt-Pearce"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2211.00817",
    "title": "An Information-Theoretic Approach for Estimating Scenario Generalization  in Crowd Motion Prediction",
    "abstract": "Learning-based approaches to modeling crowd motion have become increasingly successful but require training and evaluation on large datasets, coupled with complex model selection and parameter tuning. To circumvent this tremendously time-consuming process, we propose a novel scoring method, which characterizes generalization of models trained on source crowd scenarios and applied to target crowd scenarios using a training-free, model-agnostic Interaction + Diversity Quantification score, ISDQ. The Interaction component aims to characterize the difficulty of scenario domains, while the diversity of a scenario domain is captured in the Diversity score. Both scores can be computed in a computation tractable manner. Our experimental results validate the efficacy of the proposed method on several simulated and real-world (source,target) generalization tasks, demonstrating its potential to select optimal domain pairs before training and testing a model. ",
    "url": "https://arxiv.org/abs/2211.00817",
    "authors": [
      "Gang Qiao",
      "Kaidong Hu",
      "Seonghyeon Moon",
      "Samuel S. Sohn",
      "Sejong Yoon",
      "Mubbasir Kapadia",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2211.00818",
    "title": "CODEP: Grammatical Seq2Seq Model for General-Purpose Code Generation",
    "abstract": "General-purpose code generation aims to automatically convert the natural language (NL) description to code snippets in a general-purpose programming language (GPL) like Python. Intrinsically, code generation is a special type of text generation that generates well-formed text, i.e., code. However, existing sequence-to-sequence (Seq2Seq) approaches generate the GPL code neglecting the grammar rules. To this end, in this paper, we make the first attempt to consider grammatical Seq2Seq models for general-purpose code generation and propose CODEP, a grammatical Seq2Seq code generation framework equipped with a Pushdown automaton (PDA) module. In the training stage, CODEP additionally incorporates the state representation and the state prediction task, which leverages PDA states to help CODEP comprehend the parsing process of the PDA module. In the inference stage, CODEP generates well-formed code with the PDA module and the joint prediction of PDA states. Furthermore, the PDA module can be directly applied to Seq2Seq models without training to ensure the grammatical correctness of the generated code. To evaluate the effectiveness of our proposed method, we construct the DPA for the most popular GPL Python and conduct extensive experiments on four benchmark datasets. The experimental results demonstrate the superiority of CODEP compared to the state-of-the-art approaches without pre-training, and the DPA module also achieves significant improvements on the pre-trained models. ",
    "url": "https://arxiv.org/abs/2211.00818",
    "authors": [
      "Yihong Dong",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00824",
    "title": "Adversarial Auto-Augment with Label Preservation: A Representation  Learning Principle Guided Approach",
    "abstract": "Data augmentation is a critical contributing factor to the success of deep learning but heavily relies on prior domain knowledge which is not always available. Recent works on automatic data augmentation learn a policy to form a sequence of augmentation operations, which are still pre-defined and restricted to limited options. In this paper, we show that a prior-free autonomous data augmentation's objective can be derived from a representation learning principle that aims to preserve the minimum sufficient information of the labels. Given an example, the objective aims at creating a distant \"hard positive example\" as the augmentation, while still preserving the original label. We then propose a practical surrogate to the objective that can be optimized efficiently and integrated seamlessly into existing methods for a broad class of machine learning tasks, e.g., supervised, semi-supervised, and noisy-label learning. Unlike previous works, our method does not require training an extra generative model but instead leverages the intermediate layer representations of the end-task model for generating data augmentations. In experiments, we show that our method consistently brings non-trivial improvements to the three aforementioned learning tasks from both efficiency and final performance, either or not combined with strong pre-defined augmentations, e.g., on medical images when domain knowledge is unavailable and the existing augmentation techniques perform poorly. Code is available at: https://github.com/kai-wen-yang/LPA3}{https://github.com/kai-wen-yang/LPA3. ",
    "url": "https://arxiv.org/abs/2211.00824",
    "authors": [
      "Kaiwen Yang",
      "Yanchao Sun",
      "Jiahao Su",
      "Fengxiang He",
      "Xinmei Tian",
      "Furong Huang",
      "Tianyi Zhou",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00826",
    "title": "TSAA: A Two-Stage Anchor Assignment Method towards Anchor Drift in  Crowded Object Detection",
    "abstract": "Among current anchor-based detectors, a positive anchor box will be intuitively assigned to the object that overlaps it the most. The assigned label to each anchor will directly determine the optimization direction of the corresponding prediction box, including the direction of box regression and category prediction. In our practice of crowded object detection, however, the results show that a positive anchor does not always regress toward the object that overlaps it the most when multiple objects overlap. We name it anchor drift. The anchor drift reflects that the anchor-object matching relation, which is determined by the degree of overlap between anchors and objects, is not always optimal. Conflicts between the fixed matching relation and learned experience in the past training process may cause ambiguous predictions and thus raise the false-positive rate. In this paper, a simple but efficient adaptive two-stage anchor assignment (TSAA) method is proposed. It utilizes the final prediction boxes rather than the fixed anchors to calculate the overlap degree with objects to determine which object to regress for each anchor. The participation of the prediction box makes the anchor-object assignment mechanism adaptive. Extensive experiments are conducted on three classic detectors RetinaNet, Faster-RCNN and YOLOv3 on CrowdHuman and COCO to evaluate the effectiveness of TSAA. The results show that TSAA can significantly improve the detectors' performance without additional computational costs or network structure changes. ",
    "url": "https://arxiv.org/abs/2211.00826",
    "authors": [
      "Li Xiang",
      "He Miao",
      "Luo Haibo",
      "Yang Huiyuan",
      "Xiao Jiajie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00829",
    "title": "Exploiting Spatial-temporal Correlations for Video Anomaly Detection",
    "abstract": "Video anomaly detection (VAD) remains a challenging task in the pattern recognition community due to the ambiguity and diversity of abnormal events. Existing deep learning-based VAD methods usually leverage proxy tasks to learn the normal patterns and discriminate the instances that deviate from such patterns as abnormal. However, most of them do not take full advantage of spatial-temporal correlations among video frames, which is critical for understanding normal patterns. In this paper, we address unsupervised VAD by learning the evolution regularity of appearance and motion in the long and short-term and exploit the spatial-temporal correlations among consecutive frames in normal videos more adequately. Specifically, we proposed to utilize the spatiotemporal long short-term memory (ST-LSTM) to extract and memorize spatial appearances and temporal variations in a unified memory cell. In addition, inspired by the generative adversarial network, we introduce a discriminator to perform adversarial learning with the ST-LSTM to enhance the learning capability. Experimental results on standard benchmarks demonstrate the effectiveness of spatial-temporal correlations for unsupervised VAD. Our method achieves competitive performance compared to the state-of-the-art methods with AUCs of 96.7%, 87.8%, and 73.1% on the UCSD Ped2, CUHK Avenue, and ShanghaiTech, respectively. ",
    "url": "https://arxiv.org/abs/2211.00829",
    "authors": [
      "Mengyang Zhao",
      "Yang Liu",
      "Jing Li",
      "Xinhua Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00832",
    "title": "Distributed Massive MIMO for LEO Satellite Networks",
    "abstract": "The ultra-dense deployment of interconnected satellites will characterize future low Earth orbit (LEO) mega-constellations. Exploiting this towards a more efficient satellite network (SatNet), this paper proposes a novel LEO SatNet architecture based on distributed massive multiple-input multiple-output (DM-MIMO) technology allowing ground user terminals to be connected to a cluster of satellites. To this end, we investigate various aspects of DM-MIMO-based satellite network design, the benefits of using this architecture, the associated challenges, and the potential solutions. In addition, we propose a distributed joint power allocation and handover management (D-JPAHM) technique that jointly optimizes the power allocation and handover management processes in a cross-layer manner. This framework aims to maximize the network throughput and minimize the handover rate while considering the quality-of-service (QoS) demands of user terminals and the power capabilities of the satellites. Moreover, we devise an artificial intelligence (AI)-based solution to efficiently implement the proposed D-JPAHM framework in a manner suitable for real-time operation and the dynamic SatNet environment. To the best of our knowledge, this is the first work to introduce and study DM-MIMO technology in LEO SatNets. Extensive simulation results reveal the superiority of the proposed architecture and solutions compared to conventional approaches in the literature. ",
    "url": "https://arxiv.org/abs/2211.00832",
    "authors": [
      "Mohammed Y. Abdelsadek",
      "Gunes Karabulut Kurt",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00839",
    "title": "RCD-SGD: Resource-Constrained Distributed SGD in Heterogeneous  Environment via Submodular Partitioning",
    "abstract": "The convergence of SGD based distributed training algorithms is tied to the data distribution across workers. Standard partitioning techniques try to achieve equal-sized partitions with per-class population distribution in proportion to the total dataset. Partitions having the same overall population size or even the same number of samples per class may still have Non-IID distribution in the feature space. In heterogeneous computing environments, when devices have different computing capabilities, even-sized partitions across devices can lead to the straggler problem in distributed SGD. We develop a framework for distributed SGD in heterogeneous environments based on a novel data partitioning algorithm involving submodular optimization. Our data partitioning algorithm explicitly accounts for resource heterogeneity across workers while achieving similar class-level feature distribution and maintaining class balance. Based on this algorithm, we develop a distributed SGD framework that can accelerate existing SOTA distributed training algorithms by up to 32%. ",
    "url": "https://arxiv.org/abs/2211.00839",
    "authors": [
      "Haoze He",
      "Parijat Dube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.00848",
    "title": "Heterogeneous Trajectory Forecasting via Risk and Scene Graph Learning",
    "abstract": "Heterogeneous trajectory forecasting is critical for intelligent transportation systems, while it is challenging because of the difficulty for modeling the complex interaction relations among the heterogeneous road agents as well as their agent-environment constraint. In this work, we propose a risk and scene graph learning method for trajectory forecasting of heterogeneous road agents, which consists of a Heterogeneous Risk Graph (HRG) and a Hierarchical Scene Graph (HSG) from the aspects of agent category and their movable semantic regions. HRG groups each kind of road agents and calculates their interaction adjacency matrix based on an effective collision risk metric. HSG of driving scene is modeled by inferring the relationship between road agents and road semantic layout aligned by the road scene grammar. Based on this formulation, we can obtain an effective trajectory forecasting in driving situations, and superior performance to other state-of-the-art approaches is demonstrated by exhaustive experiments on the nuScenes, ApolloScape, and Argoverse datasets. ",
    "url": "https://arxiv.org/abs/2211.00848",
    "authors": [
      "Jianwu Fang",
      "Chen Zhu",
      "Pu Zhang",
      "Hongkai Yu",
      "Jianru Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00849",
    "title": "P$^3$OVD: Fine-grained Visual-Text Prompt-Driven Self-Training for  Open-Vocabulary Object Detection",
    "abstract": "Inspired by the success of visual-language methods (VLMs) in zero-shot classification, recent works attempt to extend this line of work into object detection by leveraging the localization ability of pre-trained VLMs and generating pseudo labels for unseen classes in a self-training manner. However, since the current VLMs are usually pre-trained with aligning sentence embedding with global image embedding, the direct use of them lacks fine-grained alignment for object instances, which is the core of detection. In this paper, we propose a simple but effective Pretrain-adaPt-Pseudo labeling paradigm for Open-Vocabulary Detection (P$^3$OVD) that introduces a fine-grained visual-text prompt adapting stage to enhance the current self-training paradigm with a more powerful fine-grained alignment. During the adapting stage, we enable VLM to obtain fine-grained alignment by using learnable text prompts to resolve an auxiliary dense pixel-wise prediction task. Furthermore, we propose a visual prompt module to provide the prior task information (i.e., the categories need to be predicted) for the vision branch to better adapt the pretrained VLM to the downstream tasks. Experiments show that our method achieves the state-of-the-art performance for open-vocabulary object detection, e.g., 31.5% mAP on unseen classes of COCO. ",
    "url": "https://arxiv.org/abs/2211.00849",
    "authors": [
      "Yanxin Long",
      "Jianhua Han",
      "Runhui Huang",
      "Xu Hang",
      "Yi Zhu",
      "Chunjing Xu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00856",
    "title": "Deep Virtual-to-Real Distillation for Pedestrian Crossing Prediction",
    "abstract": "Pedestrian crossing is one of the most typical behavior which conflicts with natural driving behavior of vehicles. Consequently, pedestrian crossing prediction is one of the primary task that influences the vehicle planning for safe driving. However, current methods that rely on the practically collected data in real driving scenes cannot depict and cover all kinds of scene condition in real traffic world. To this end, we formulate a deep virtual to real distillation framework by introducing the synthetic data that can be generated conveniently, and borrow the abundant information of pedestrian movement in synthetic videos for the pedestrian crossing prediction in real data with a simple and lightweight implementation. In order to verify this framework, we construct a benchmark with 4667 virtual videos owning about 745k frames (called Virtual-PedCross-4667), and evaluate the proposed method on two challenging datasets collected in real driving situations, i.e., JAAD and PIE datasets. State-of-the-art performance of this framework is demonstrated by exhaustive experiment analysis. The dataset and code can be downloaded from the website \\url{this http URL}. ",
    "url": "https://arxiv.org/abs/2211.00856",
    "authors": [
      "Jie Bai",
      "Xin Fang",
      "Jianwu Fang",
      "Jianru Xue",
      "Changwei Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00863",
    "title": "Behavior Prior Representation learning for Offline Reinforcement  Learning",
    "abstract": "Offline reinforcement learning (RL) struggles in environments with rich and noisy inputs, where the agent only has access to a fixed dataset without environment interactions. Past works have proposed common workarounds based on the pre-training of state representations, followed by policy training. In this work, we introduce a simple, yet effective approach for learning state representations. Our method, Behavior Prior Representation (BPR), learns state representations with an easy-to-integrate objective based on behavior cloning of the dataset: we first learn a state representation by mimicking actions from the dataset, and then train a policy on top of the fixed representation, using any off-the-shelf Offline RL algorithm. Theoretically, we prove that BPR carries out performance guarantees when integrated into algorithms that have either policy improvement guarantees (conservative algorithms) or produce lower bounds of the policy values (pessimistic algorithms). Empirically, we show that BPR combined with existing state-of-the-art Offline RL algorithms leads to significant improvements across several offline control benchmarks. ",
    "url": "https://arxiv.org/abs/2211.00863",
    "authors": [
      "Hongyu Zang",
      "Xin Li",
      "Jie Yu",
      "Chen Liu",
      "Riashat Islam",
      "Remi Tachet Des Combes",
      "Romain Laroche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00880",
    "title": "DeepTrace: Learning to Optimize Contact Tracing in Epidemic Networks  with Graph Neural Networks",
    "abstract": "The goal of digital contact tracing is to diminish the spread of an epidemic or pandemic by detecting and mitigating public health emergencies using digital technologies. Since the start of the COVID-$19$ pandemic, a wide variety of mobile digital apps have been deployed to identify people exposed to the SARS-CoV-2 coronavirus and to stop onward transmission. Tracing sources of spreading (i.e., backward contact tracing), as has been used in Japan and Australia, has proven crucial as going backwards can pick up infections that might otherwise be missed at superspreading events. How should robust backward contact tracing automated by mobile computing and network analytics be designed? In this paper, we formulate the forward and backward contact tracing problem for epidemic source inference as maximum-likelihood (ML) estimation subject to subgraph sampling. Besides its restricted case (inspired by the seminal work of Zaman and Shah in 2011) when the full infection topology is known, the general problem is more challenging due to its sheer combinatorial complexity, problem scale and the fact that the full infection topology is rarely accurately known. We propose a Graph Neural Network (GNN) framework, named DeepTrace, to compute the ML estimator by leveraging the likelihood structure to configure the training set with topological features of smaller epidemic networks as training sets. We demonstrate that the performance of our GNN approach improves over prior heuristics in the literature and serves as a basis to design robust contact tracing analytics to combat pandemics. ",
    "url": "https://arxiv.org/abs/2211.00880",
    "authors": [
      "Siya Chen",
      "Pei-Duo Yu",
      "Chee Wei Tan",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2211.00882",
    "title": "DyAnNet: A Scene Dynamicity Guided Self-Trained Video Anomaly Detection  Network",
    "abstract": "Unsupervised approaches for video anomaly detection may not perform as good as supervised approaches. However, learning unknown types of anomalies using an unsupervised approach is more practical than a supervised approach as annotation is an extra burden. In this paper, we use isolation tree-based unsupervised clustering to partition the deep feature space of the video segments. The RGB- stream generates a pseudo anomaly score and the flow stream generates a pseudo dynamicity score of a video segment. These scores are then fused using a majority voting scheme to generate preliminary bags of positive and negative segments. However, these bags may not be accurate as the scores are generated only using the current segment which does not represent the global behavior of a typical anomalous event. We then use a refinement strategy based on a cross-branch feed-forward network designed using a popular I3D network to refine both scores. The bags are then refined through a segment re-mapping strategy. The intuition of adding the dynamicity score of a segment with the anomaly score is to enhance the quality of the evidence. The method has been evaluated on three popular video anomaly datasets, i.e., UCF-Crime, CCTV-Fights, and UBI-Fights. Experimental results reveal that the proposed framework achieves competitive accuracy as compared to the state-of-the-art video anomaly detection methods. ",
    "url": "https://arxiv.org/abs/2211.00882",
    "authors": [
      "Kamalakar Thakare",
      "Yash Raghuwanshi",
      "Debi Prosad Dogra",
      "Heeseung Choi",
      "Ig-Jae Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00894",
    "title": "Community detection in overlapping weighted networks",
    "abstract": "Community detection in overlapping unweighted networks in which nodes can belong to multiple communities is one of the most popular topics in modern network science during the last decade. However, community detection in overlapping weighted networks in which elements of adjacency matrices can be any finite real values remains a challenge. In this article, we propose a degree-corrected mixed membership distribution-free (DCMMDF) model which extends the degree-corrected mixed membership model from overlapping unweighted networks to overlapping weighted networks. We address the community membership estimation of the DCMMDF by an application of a spectral algorithm and establish a theoretical guarantee of estimation consistency. The proposed model is applied to simulated data and real-world data. ",
    "url": "https://arxiv.org/abs/2211.00894",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2211.00898",
    "title": "SIMD-size aware weight regularization for fast neural vocoding on CPU",
    "abstract": "This paper proposes weight regularization for a faster neural vocoder. Pruning time-consuming DNN modules is a promising way to realize a real-time vocoder on a CPU (e.g. WaveRNN, LPCNet). Regularization that encourages sparsity is also effective in avoiding the quality degradation created by pruning. However, the orders of weight matrices must be contiguous in SIMD size for fast vocoding. To ensure this order, we propose explicit SIMD size aware regularization. Our proposed method reshapes a weight matrix into a tensor so that the weights are aligned by group size in advance, and then computes the group Lasso-like regularization loss. Experiments on 70% sparse subband WaveRNN show that pruning in conventional Lasso and column-wise group Lasso degrades the synthetic speech's naturalness. The vocoder with proposed regularization 1) achieves comparable naturalness to that without pruning and 2) performs meaningfully faster than other conventional vocoders using regularization. ",
    "url": "https://arxiv.org/abs/2211.00898",
    "authors": [
      "Hiroki Kanagawa",
      "Yusuke Ijima"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00901",
    "title": "A survey on the development status and application prospects of  knowledge graph in smart grids",
    "abstract": "With the advent of the electric power big data era, semantic interoperability and interconnection of power data have received extensive attention. Knowledge graph technology is a new method describing the complex relationships between concepts and entities in the objective world, which is widely concerned because of its robust knowledge inference ability. Especially with the proliferation of measurement devices and exponential growth of electric power data empowers, electric power knowledge graph provides new opportunities to solve the contradictions between the massive power resources and the continuously increasing demands for intelligent applications. In an attempt to fulfil the potential of knowledge graph and deal with the various challenges faced, as well as to obtain insights to achieve business applications of smart grids, this work first presents a holistic study of knowledge-driven intelligent application integration. Specifically, a detailed overview of electric power knowledge mining is provided. Then, the overview of the knowledge graph in smart grids is introduced. Moreover, the architecture of the big knowledge graph platform for smart grids and critical technologies are described. Furthermore, this paper comprehensively elaborates on the application prospects leveraged by knowledge graph oriented to smart grids, power consumer service, decision-making in dispatching, and operation and maintenance of power equipment. Finally, issues and challenges are summarised. ",
    "url": "https://arxiv.org/abs/2211.00901",
    "authors": [
      "Jian Wang",
      "Xi Wang",
      "Chaoqun Ma",
      "Lei Kou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00912",
    "title": "Bipartite Mixed Membership Distribution-Free Model. A novel model for  community detection in overlapping bipartite weighted networks",
    "abstract": "Modeling and estimating mixed memberships for un-directed un-weighted networks in which nodes can belong to multiple communities has been well studied in recent years. However, for a more general case, the bipartite weighted networks in which nodes can belong to multiple communities, row nodes can be different from column nodes, and all elements of adjacency matrices can be any finite real values, to our knowledge, there is no model for such bipartite weighted networks. To close this gap, this paper introduces a novel model, the Bipartite Mixed Membership Distribution-Free (BiMMDF) model. As a special case, bipartite signed networks with mixed memberships can also be generated from BiMMDF. Our model enjoys its advantage by allowing all elements of an adjacency matrix to be generated from any distribution as long as the expectation adjacency matrix has a block structure related to node memberships under BiMMDF. The proposed model can be viewed as an extension of many previous models, including the popular mixed membership stochastic blcokmodels. An efficient algorithm with a theoretical guarantee of consistent estimation is applied to fit BiMMDF. In particular, for a standard bipartite weighted network with two row (and column) communities, to make the algorithm's error rates small with high probability, separation conditions are obtained when adjacency matrices are generated from different distributions under BiMMDF. The behavior differences of different distributions on separation conditions are verified by extensive synthetic bipartite weighted networks generated under BiMMDF. Experiments on real-world directed weighted networks illustrate the advantage of the algorithm in studying highly mixed nodes and asymmetry between row and column communities. ",
    "url": "https://arxiv.org/abs/2211.00912",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.00914",
    "title": "Discover Important Paths in the Knowledge Graph Based on Dynamic  Relation Confidence",
    "abstract": "Most of the existing knowledge graphs are not usually complete and can be complemented by some reasoning algorithms. The reasoning method based on path features is widely used in the field of knowledge graph reasoning and completion on account of that its have strong interpretability. However, reasoning methods based on path features still have several problems in the following aspects: Path search isinefficient, insufficient paths for sparse tasks and some paths are not helpful for reasoning tasks. In order to solve the above problems, this paper proposes a method called DC-Path that combines dynamic relation confidence and other indicators to evaluate path features, and then guide path search, finally conduct relation reasoning. Experimental result show that compared with the existing relation reasoning algorithm, this method can select the most representative features in the current reasoning task from the knowledge graph and achieve better performance on the current relation reasoning task. ",
    "url": "https://arxiv.org/abs/2211.00914",
    "authors": [
      "Shanqing Yu",
      "Yijun Wu",
      "Ran Gan",
      "Jiajun Zhou",
      "Ziwan Zheng",
      "Qi Xuan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00923",
    "title": "SpeechBlender: Speech Augmentation Framework for Mispronunciation Data  Generation",
    "abstract": "One of the biggest challenges in designing mispronunciation detection models is the unavailability of labeled L2 speech data. To overcome such data scarcity, we introduce SpeechBlender -- a fine-grained data augmentation pipeline for generating mispronunciation errors. The SpeechBlender utilizes varieties of masks to target different regions of a phonetic unit, and use the mixing factors to linearly interpolate raw speech signals while generating erroneous pronunciation instances. The masks facilitate smooth blending of the signals, thus generating more effective samples than the `Cut/Paste' method. We show the effectiveness of our augmentation technique in a phoneme-level pronunciation quality assessment task, leveraging only a good pronunciation dataset. With SpeechBlender augmentation, we observed a 3% and 2% increase in Pearson correlation coefficient (PCC) compared to no-augmentation and goodness of pronunciation augmentation scenarios respectively for Speechocean762 testset. Moreover, a 2% rise in PCC is observed when comparing our single-task phoneme-level mispronunciation detection model with a multi-task learning model using multiple-granularity information. ",
    "url": "https://arxiv.org/abs/2211.00923",
    "authors": [
      "Yassine El Kheir",
      "Shammur Absar Chowdhury",
      "Hamdy Mubarak",
      "Shazia Afzal",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00928",
    "title": "Neural Active Learning on Heteroskedastic Distributions",
    "abstract": "Models that can actively seek out the best quality training data hold the promise of more accurate, adaptable, and efficient machine learning. State-of-the-art active learning techniques tend to prefer examples that are the most difficult to classify. While this works well on homogeneous datasets, we find that it can lead to catastrophic failures when performed on multiple distributions with different degrees of label noise or heteroskedasticity. These active learning algorithms strongly prefer to draw from the distribution with more noise, even if their examples have no informative structure (such as solid color images with random labels). To this end, we demonstrate the catastrophic failure of these active learning algorithms on heteroskedastic distributions and propose a fine-tuning-based approach to mitigate these failures. Further, we propose a new algorithm that incorporates a model difference scoring function for each data point to filter out the noisy examples and sample clean examples that maximize accuracy, outperforming the existing active learning techniques on the heteroskedastic datasets. We hope these observations and techniques are immediately helpful to practitioners and can help to challenge common assumptions in the design of active learning algorithms. ",
    "url": "https://arxiv.org/abs/2211.00928",
    "authors": [
      "Savya Khosla",
      "Chew Kin Whye",
      "Jordan T. Ash",
      "Cyril Zhang",
      "Kenji Kawaguchi",
      "Alex Lamb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00930",
    "title": "Nonverbal Social Behavior Generation for Social Robots Using End-to-End  Learning",
    "abstract": "To provide effective and enjoyable human-robot interaction, it is important for social robots to exhibit nonverbal behaviors, such as a handshake or a hug. However, the traditional approach of reproducing pre-coded motions allows users to easily predict the reaction of the robot, giving the impression that the robot is a machine rather than a real agent. Therefore, we propose a neural network architecture based on the Seq2Seq model that learns social behaviors from human-human interactions in an end-to-end manner. We adopted a generative adversarial network to prevent invalid pose sequences from occurring when generating long-term behavior. To verify the proposed method, experiments were performed using the humanoid robot Pepper in a simulated environment. Because it is difficult to determine success or failure in social behavior generation, we propose new metrics to calculate the difference between the generated behavior and the ground-truth behavior. We used these metrics to show how different network architectural choices affect the performance of behavior generation, and we compared the performance of learning multiple behaviors and that of learning a single behavior. We expect that our proposed method can be used not only with home service robots, but also for guide robots, delivery robots, educational robots, and virtual robots, enabling the users to enjoy and effectively interact with the robots. ",
    "url": "https://arxiv.org/abs/2211.00930",
    "authors": [
      "Woo-Ri Ko",
      "Minsu Jang",
      "Jaeyeon Lee",
      "Jaehong Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.00942",
    "title": "Model-based Reinforcement Learning with a Hamiltonian Canonical ODE  Network",
    "abstract": "Model-based reinforcement learning usually suffers from a high sample complexity in training the world model, especially for the environments with complex dynamics. To make the training for general physical environments more efficient, we introduce Hamiltonian canonical ordinary differential equations into the learning process, which inspires a novel model of neural ordinary differential auto-encoder (NODA). NODA can model the physical world by nature and is flexible to impose Hamiltonian mechanics (e.g., the dimension of the physical equations) which can further accelerate training of the environment models. It can consequentially empower an RL agent with the robust extrapolation using a small amount of samples as well as the guarantee on the physical plausibility. Theoretically, we prove that NODA has uniform bounds for multi-step transition errors and value errors under certain conditions. Extensive experiments show that NODA can learn the environment dynamics effectively with a high sample efficiency, making it possible to facilitate reinforcement learning agents at the early stage. ",
    "url": "https://arxiv.org/abs/2211.00942",
    "authors": [
      "Yao Feng",
      "Yuhong Jiang",
      "Hang Su",
      "Dong Yan",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00945",
    "title": "CarDD: A New Dataset for Vision-based Car Damage Detection",
    "abstract": "Automatic car damage detection has attracted significant attention in the car insurance business. However, due to the lack of high-quality and publicly available datasets, we can hardly learn a feasible model for car damage detection. To this end, we contribute with the Car Damage Detection (CarDD), the first public large-scale dataset designed for vision-based car damage detection and segmentation. Our CarDD contains 4,000 high-resolution car damage images with over 9,000 wellannotated instances of six damage categories (examples are shown in Fig. 1). We detail the image collection, selection, and annotation processes, and present a statistical dataset analysis. Furthermore, we conduct extensive experiments on CarDD with state-of-theart deep methods for different tasks and provide comprehensive analysis to highlight the specialty of car damage detection. ",
    "url": "https://arxiv.org/abs/2211.00945",
    "authors": [
      "Xinkuang Wang",
      "Wenjing Li",
      "Zhongcheng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00982",
    "title": "SpectroMap: Peak detection algorithm for audio fingerprinting",
    "abstract": "We present SpectroMap, an open source GitHub repository for audio fingerprinting written in Python programming language. It is composed of a peak search algorithm that extracts topological prominences from a spectrogram via time-frequency bands. In this paper, we introduce the algorithm functioning with two experimental applications in a high-quality urban sound dataset and environmental audio recordings to describe how it works and how effective it is in handling the input data. ",
    "url": "https://arxiv.org/abs/2211.00982",
    "authors": [
      "Aar\u00f3n L\u00f3pez-Garc\u00eda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00996",
    "title": "Singing Voice Synthesis with Vibrato Modeling and Latent Energy  Representation",
    "abstract": "This paper proposes an expressive singing voice synthesis system by introducing explicit vibrato modeling and latent energy representation. Vibrato is essential to the naturalness of synthesized sound, due to the inherent characteristics of human singing. Hence, a deep learning-based vibrato model is introduced in this paper to control the vibrato's likeliness, rate, depth and phase in singing, where the vibrato likeliness represents the existence probability of vibrato and it would help improve the singing voice's naturalness. Actually, there is no annotated label about vibrato likeliness in existing singing corpus. We adopt a novel vibrato likeliness labeling method to label the vibrato likeliness automatically. Meanwhile, the power spectrogram of audio contains rich information that can improve the expressiveness of singing. An autoencoder-based latent energy bottleneck feature is proposed for expressive singing voice synthesis. Experimental results on the open dataset NUS48E show that both the vibrato modeling and the latent energy representation could significantly improve the expressiveness of singing voice. The audio samples are shown in the demo website. ",
    "url": "https://arxiv.org/abs/2211.00996",
    "authors": [
      "Yingjie Song",
      "Wei Song",
      "Wei Zhang",
      "Zhengchen Zhang",
      "Dan Zeng",
      "Zhi Liu",
      "Yang Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.01022",
    "title": "Verifying And Interpreting Neural Networks using Finite Automata",
    "abstract": "Verifying properties and interpreting the behaviour of deep neural networks (DNN) is an important task given their ubiquitous use in applications, including safety-critical ones, and their blackbox nature. We propose an automata-theoric approach to tackling problems arising in DNN analysis. We show that the input-output behaviour of a DNN can be captured precisely by a (special) weak B\\\"uchi automaton of exponential size. We show how these can be used to address common verification and interpretation tasks like adversarial robustness, minimum sufficient reasons etc. We report on a proof-of-concept implementation translating DNN to automata on finite words for better efficiency at the cost of losing precision in analysis. ",
    "url": "https://arxiv.org/abs/2211.01022",
    "authors": [
      "Marco S\u00e4lzer",
      "Eric Alsmann",
      "Florian Bruse",
      "Martin Lange"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01069",
    "title": "Joint Correlation Detection and Alignment of Gaussian Databases",
    "abstract": "In this work, we propose an efficient two-stage algorithm solving a joint problem of correlation detection and permutation recovery between two Gaussian databases. Correlation detection is an hypothesis testing problem; under the null hypothesis, the databases are independent, and under the alternate hypothesis, they are correlated, under an unknown row permutation. We develop relatively tight bounds on the type-I and type-II error probabilities, and show that the analyzed detector performs better than a recently proposed detector, at least for some specific parameter choices. Since the proposed detector relies on a statistic, which is a sum of dependent indicator random variables, then in order to bound the type-I probability of error, we develop a novel graph-theoretic technique for bounding the $k$-th order moments of such statistics. When the databases are accepted as correlated, the algorithm also outputs an estimation for the underlying row permutation. By comparing to known converse results for this problem, we prove that the alignment error probability converges to zero under the asymptotically lowest possible correlation coefficient. ",
    "url": "https://arxiv.org/abs/2211.01069",
    "authors": [
      "Ran Tamir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2211.01077",
    "title": "Dominance of Smartphone Exposure in 5G Mobile Networks",
    "abstract": "The deployment of 5G networks is sometimes questioned due to the impact of ElectroMagnetic Field (EMF) generated by Radio Base Station (RBS) on users. The goal of this work is to analyze such issue from a novel perspective, by comparing RBS EMF against exposure generated by 5G smartphones in commercial deployments. The measurement of exposure from 5G is hampered by several implementation aspects, such as dual connectivity between 4G and 5G, spectrum fragmentation, and carrier aggregation. To face such issues, we deploy a novel framework, called 5G-EA, tailored to the assessment of smartphone and RBS exposure through an innovative measurement algorithm, able to remotely control a programmable spectrum analyzer. Results, obtained in both outdoor and indoor locations, reveal that smartphone exposure (upon generation of uplink traffic) dominates over the RBS one. Moreover, Line-of-Sight locations experience a reduction of around one order of magnitude on the overall exposure compared to Non-Line-of-Sight ones. In addition, 5G exposure always represents a small share (up to 28%) compared to 4G EMF. ",
    "url": "https://arxiv.org/abs/2211.01077",
    "authors": [
      "Luca Chiaraviglio",
      "Chiara Lodovisi",
      "Stefania Bartoletti",
      "Ahmed Elzanaty",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.01080",
    "title": "Spatial Reasoning for Few-Shot Object Detection",
    "abstract": "Although modern object detectors rely heavily on a significant amount of training data, humans can easily detect novel objects using a few training examples. The mechanism of the human visual system is to interpret spatial relationships among various objects and this process enables us to exploit contextual information by considering the co-occurrence of objects. Thus, we propose a spatial reasoning framework that detects novel objects with only a few training examples in a context. We infer geometric relatedness between novel and base RoIs (Region-of-Interests) to enhance the feature representation of novel categories using an object detector well trained on base categories. We employ a graph convolutional network as the RoIs and their relatedness are defined as nodes and edges, respectively. Furthermore, we present spatial data augmentation to overcome the few-shot environment where all objects and bounding boxes in an image are resized randomly. Using the PASCAL VOC and MS COCO datasets, we demonstrate that the proposed method significantly outperforms the state-of-the-art methods and verify its efficacy through extensive ablation studies. ",
    "url": "https://arxiv.org/abs/2211.01080",
    "authors": [
      "Geonuk Kim",
      "Hong-Gyu Jung",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01085",
    "title": "Coordinated Transmit Beamforming for Multi-antenna Network Integrated  Sensing and Communication",
    "abstract": "This paper studies a multi-antenna network integrated sensing and communication (ISAC) system, in which a set of multi-antenna base stations (BSs) employ the coordinated transmit beamforming to serve their respectively associated single-antenna communication users (CUs), and at the same time reuse the reflected information signals to perform joint target detection. In particular, we consider two target detection scenarios depending on the time synchronization among BSs. In Scenario \\uppercase\\expandafter{\\romannumeral1}, these BSs are synchronized and can exploit the target-reflected signals over both the direct links (from each BS to target to itself) and the cross links (from each BS to target to other BSs) for joint detection. In Scenario \\uppercase\\expandafter{\\romannumeral2}, these BSs are not synchronized and can only utilize target-reflected signals over the direct links for joint detection. For each scenario, we derive the detection probability under a specific false alarm probability at any given target location. Based on the derivation, we optimize the coordinated transmit beamforming at the BSs to maximize the minimum detection probability over a particular target area, while ensuring the minimum signal-to-interference-plus-noise ratio (SINR) constraints at the CUs, subject to the maximum transmit power constraints at the BSs. We use the semi-definite relaxation (SDR) technique to obtain highly-quality solutions to the formulated problems. Numerical results show that for each scenario, the proposed design achieves higher detection probability than the benchmark scheme based on communication design. It is also shown that the time synchronization among BSs is beneficial in enhancing the detection performance as more reflected signal paths are exploited. ",
    "url": "https://arxiv.org/abs/2211.01085",
    "authors": [
      "Gaoyuan Cheng",
      "Jie Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.01086",
    "title": "Generative Poisoning Using Random Discriminators",
    "abstract": "We introduce ShortcutGen, a new data poisoning attack that generates sample-dependent, error-minimizing perturbations by learning a generator. The key novelty of ShortcutGen is the use of a randomly-initialized discriminator, which provides spurious shortcuts needed for generating poisons. Different from recent, iterative methods, our ShortcutGen can generate perturbations with only one forward pass in a label-free manner, and compared to the only existing generative method, DeepConfuse, our ShortcutGen is faster and simpler to train while remaining competitive. We also demonstrate that integrating a simple augmentation strategy can further boost the robustness of ShortcutGen against early stopping, and combining augmentation and non-augmentation leads to new state-of-the-art results in terms of final validation accuracy, especially in the challenging, transfer scenario. Lastly, we speculate, through uncovering its working mechanism, that learning a more general representation space could allow ShortcutGen to work for unseen data. ",
    "url": "https://arxiv.org/abs/2211.01086",
    "authors": [
      "Dirren van Vlijmen",
      "Alex Kolmus",
      "Zhuoran Liu",
      "Zhengyu Zhao",
      "Martha Larson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01089",
    "title": "Transformer-based encoder-encoder architecture for Spoken Term Detection",
    "abstract": "The paper presents a method for spoken term detection based on the Transformer architecture. We propose the encoder-encoder architecture employing two BERT-like encoders with additional modifications, including convolutional and upsampling layers, attention masking, and shared parameters. The encoders project a recognized hypothesis and a searched term into a shared embedding space, where the score of the putative hit is computed using the calibrated dot product. In the experiments, we used the Wav2Vec 2.0 speech recognizer, and the proposed system outperformed a baseline method based on deep LSTMs on the English and Czech STD datasets based on USC Shoah Foundation Visual History Archive (MALACH). ",
    "url": "https://arxiv.org/abs/2211.01089",
    "authors": [
      "Jan \u0160vec",
      "Lubo\u0161 \u0160m\u00eddl",
      "Jan Lehe\u010dka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.01093",
    "title": "Improving transferability of 3D adversarial attacks with scale and shear  transformations",
    "abstract": "Previous work has shown that 3D point cloud classifiers can be vulnerable to adversarial examples. However, most of the existing methods are aimed at white-box attacks, where the parameters and other information of the classifiers are known in the attack, which is unrealistic for real-world applications. In order to improve the attack performance of the black-box classifiers, the research community generally uses the transfer-based black-box attack. However, the transferability of current 3D attacks is still relatively low. To this end, this paper proposes Scale and Shear (SS) Attack to generate 3D adversarial examples with strong transferability. Specifically, we randomly scale or shear the input point cloud, so that the attack will not overfit the white-box model, thereby improving the transferability of the attack. Extensive experiments show that the SS attack proposed in this paper can be seamlessly combined with the existing state-of-the-art (SOTA) 3D point cloud attack methods to form more powerful attack methods, and the SS attack improves the transferability over 3.6 times compare to the baseline. Moreover, while substantially outperforming the baseline methods, the SS attack achieves SOTA transferability under various defenses. Our code will be available online at https://github.com/cuge1995/SS-attack ",
    "url": "https://arxiv.org/abs/2211.01093",
    "authors": [
      "Jinali Zhang",
      "Yinpeng Dong",
      "Jun Zhu",
      "Jihong Zhu",
      "Minchi Kuang",
      "Xiaming Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.01107",
    "title": "Deep Reinforcement Learning for Power Control in Next-Generation WiFi  Network Systems",
    "abstract": "This paper presents a deep reinforcement learning (DRL) solution for power control in wireless communications, describes its embedded implementation with WiFi transceivers for a WiFi network system, and evaluates the performance with high-fidelity emulation tests. In a multi-hop wireless network, each mobile node measures its link quality and signal strength, and controls its transmit power. As a model-free solution, reinforcement learning allows nodes to adapt their actions by observing the states and maximize their cumulative rewards over time. For each node, the state consists of transmit power, link quality and signal strength; the action adjusts the transmit power; and the reward combines energy efficiency (throughput normalized by energy consumption) and penalty of changing the transmit power. As the state space is large, Q-learning is hard to implement on embedded platforms with limited memory and processing power. By approximating the Q-values with a DQN, DRL is implemented for the embedded platform of each node combining an ARM processor and a WiFi transceiver for 802.11n. Controllable and repeatable emulation tests are performed by inducing realistic channel effects on RF signals. Performance comparison with benchmark schemes of fixed and myopic power allocations shows that power control with DRL provides major improvements to energy efficiency and throughput in WiFi network systems. ",
    "url": "https://arxiv.org/abs/2211.01107",
    "authors": [
      "Ziad El Jamous",
      "Kemal Davaslioglu",
      "Yalin E. Sagduyu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.01109",
    "title": "The Impostor Among US(B): Off-Path Injection Attacks on USB  Communications",
    "abstract": "USB is the most prevalent peripheral interface in modern computer systems and its inherent insecurities make it an appealing attack vector. A well-known limitation of USB is that traffic is not encrypted. This allows on-path adversaries to trivially perform man-in-the-middle attacks. Off-path attacks that compromise the confidentiality of communications have also been shown to be possible. However, so far no off-path attacks that breach USB communications integrity have been demonstrated. In this work we show that the integrity of USB communications is not guaranteed even against off-path attackers.Specifically, we design and build malicious devices that, even when placed outside of the path between a victim device and the host, can inject data to that path. Using our developed injectors we can falsify the provenance of data input as interpreted by a host computer system. By injecting on behalf of trusted victim devices we can circumvent any software-based authorisation policy defences that computer systems employ against common USB attacks. We demonstrate two concrete attacks. The first injects keystrokes allowing an attacker to execute commands. The second demonstrates file-contents replacement including during system install from a USB disk. We test the attacks on 29 USB 2.0 and USB 3.x hubs and find 14 of them to be vulnerable. ",
    "url": "https://arxiv.org/abs/2211.01109",
    "authors": [
      "Robert Dumitru",
      "Andrew Wabnitz",
      "Daniel Genkin",
      "Yuval Yarom"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.01112",
    "title": "a-RNA: Adversarial Radio Noise Attack to Fool Radar-based Environment  Perception Systems",
    "abstract": "Due to their robustness to degraded capturing conditions, radars are widely used for environment perception, which is a critical task in applications like autonomous vehicles. More specifically, Ultra-Wide Band (UWB) radars are particularly efficient for short range settings as they carry rich information on the environment. Recent UWB-based systems rely on Machine Learning (ML) to exploit the rich signature of these sensors. However, ML classifiers are susceptible to adversarial examples, which are created from raw data to fool the classifier such that it assigns the input to the wrong class. These attacks represent a serious threat to systems integrity, especially for safety-critical applications. In this work, we present a new adversarial attack on UWB radars in which an adversary injects adversarial radio noise in the wireless channel to cause an obstacle recognition failure. First, based on signals collected in real-life environment, we show that conventional attacks fail to generate robust noise under realistic conditions. We propose a-RNA, i.e., Adversarial Radio Noise Attack to overcome these issues. Specifically, a-RNA generates an adversarial noise that is efficient without synchronization between the input signal and the noise. Moreover, a-RNA generated noise is, by-design, robust against pre-processing countermeasures such as filtering-based defenses. Moreover, in addition to the undetectability objective by limiting the noise magnitude budget, a-RNA is also efficient in the presence of sophisticated defenses in the spectral domain by introducing a frequency budget. We believe this work should alert about potentially critical implementations of adversarial attacks on radar systems that should be taken seriously. ",
    "url": "https://arxiv.org/abs/2211.01112",
    "authors": [
      "Amira Guesmi",
      "Ihsen Alouani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.01141",
    "title": "User-Entity Differential Privacy in Learning Natural Language Models",
    "abstract": "In this paper, we introduce a novel concept of user-entity differential privacy (UeDP) to provide formal privacy protection simultaneously to both sensitive entities in textual data and data owners in learning natural language models (NLMs). To preserve UeDP, we developed a novel algorithm, called UeDP-Alg, optimizing the trade-off between privacy loss and model utility with a tight sensitivity bound derived from seamlessly combining user and sensitive entity sampling processes. An extensive theoretical analysis and evaluation show that our UeDP-Alg outperforms baseline approaches in model utility under the same privacy budget consumption on several NLM tasks, using benchmark datasets. ",
    "url": "https://arxiv.org/abs/2211.01141",
    "authors": [
      "Phung Lai",
      "NhatHai Phan",
      "Tong Sun",
      "Rajiv Jain",
      "Franck Dernoncourt",
      "Jiuxiang Gu",
      "Nikolaos Barmpalios"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01142",
    "title": "OPA-3D: Occlusion-Aware Pixel-Wise Aggregation for Monocular 3D Object  Detection",
    "abstract": "Despite monocular 3D object detection having recently made a significant leap forward thanks to the use of pre-trained depth estimators for pseudo-LiDAR recovery, such two-stage methods typically suffer from overfitting and are incapable of explicitly encapsulating the geometric relation between depth and object bounding box. To overcome this limitation, we instead propose OPA-3D, a single-stage, end-to-end, Occlusion-Aware Pixel-Wise Aggregation network that to jointly estimate dense scene depth with depth-bounding box residuals and object bounding boxes, allowing a two-stream detection of 3D objects, leading to significantly more robust detections. Thereby, the geometry stream denoted as the Geometry Stream, combines visible depth and depth-bounding box residuals to recover the object bounding box via explicit occlusion-aware optimization. In addition, a bounding box based geometry projection scheme is employed in an effort to enhance distance perception. The second stream, named as the Context Stream, directly regresses 3D object location and size. This novel two-stream representation further enables us to enforce cross-stream consistency terms which aligns the outputs of both streams, improving the overall performance. Extensive experiments on the public benchmark demonstrate that OPA-3D outperforms state-of-the-art methods on the main Car category, whilst keeping a real-time inference speed. We plan to release all codes and trained models soon. ",
    "url": "https://arxiv.org/abs/2211.01142",
    "authors": [
      "Yongzhi Su",
      "Yan Di",
      "Fabian Manhardt",
      "Guangyao Zhai",
      "Jason Rambach",
      "Benjamin Busam",
      "Didier Stricker",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01144",
    "title": "UniASM: Binary Code Similarity Detection without Fine-tuning",
    "abstract": "Binary code similarity detection (BCSD) is widely used in various binary analysis tasks such as vulnerability search, malware detection, clone detection, and patch analysis. Recent studies have shown that the learning-based binary code embedding models perform better than the traditional feature-based approaches. In this paper, we proposed a novel transformer-based binary code embedding model, named UniASM, to learn representations of the binary functions. We designed two new training tasks to make the spatial distribution of the generated vectors more uniform, which can be used directly in BCSD without any fine-tuning. In addition, we proposed a new tokenization approach for binary functions, increasing the token's semantic information while mitigating the out-of-vocabulary (OOV) problem. The experimental results show that UniASM outperforms state-of-the-art (SOTA) approaches on the evaluation dataset. We achieved the average scores of recall@1 on cross-compilers, cross-optimization-levels and cross-obfuscations are 0.72, 0.63, and 0.77, which is higher than existing SOTA baselines. In a real-world task of known vulnerability searching, UniASM outperforms all the current baselines. ",
    "url": "https://arxiv.org/abs/2211.01144",
    "authors": [
      "Yeming Gu",
      "Hui Shu",
      "Fan Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.01147",
    "title": "An Easy-to-use and Robust Approach for the Differentially Private  De-Identification of Clinical Textual Documents",
    "abstract": "Unstructured textual data is at the heart of healthcare systems. For obvious privacy reasons, these documents are not accessible to researchers as long as they contain personally identifiable information. One way to share this data while respecting the legislative framework (notably GDPR or HIPAA) is, within the medical structures, to de-identify it, i.e. to detect the personal information of a person through a Named Entity Recognition (NER) system and then replacing it to make it very difficult to associate the document with the person. The challenge is having reliable NER and substitution tools without compromising confidentiality and consistency in the document. Most of the conducted research focuses on English medical documents with coarse substitutions by not benefiting from advances in privacy. This paper shows how an efficient and differentially private de-identification approach can be achieved by strengthening the less robust de-identification method and by adapting state-of-the-art differentially private mechanisms for substitution purposes. The result is an approach for de-identifying clinical documents in French language, but also generalizable to other languages and whose robustness is mathematically proven. ",
    "url": "https://arxiv.org/abs/2211.01147",
    "authors": [
      "Yakini Tchouka",
      "Jean-Fran\u00e7ois Couchot",
      "David Laiymani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.01153",
    "title": "A Two Step Approach to Weighted Bipartite Link Recommendations",
    "abstract": "Many real world person-person or person-product relationships can be modeled graphically. More specifically, bipartite graphs can be especially useful when modeling scenarios that involve two disjoint groups. As a result, many existing papers have utilized bipartite graphs for the classical link recommendation problem. In this paper, using the principle of bipartite graphs, we present another approach to this problem with a two step algorithm that takes into account frequency and similarity between common edges to make recommendations. We test this approach with bipartite data gathered from the Epinions and Movielens data sources, and find it to perform with roughly 14 percent error, which improves upon baseline results. This is a promising result, and can be refined to generate even more accurate recommendations. ",
    "url": "https://arxiv.org/abs/2211.01153",
    "authors": [
      "Nathan Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01156",
    "title": "Entropic Neural Optimal Transport via Diffusion Processes",
    "abstract": "We propose a novel neural algorithm for the fundamental problem of computing the entropic optimal transport (EOT) plan between probability distributions which are accessible by samples. Our algorithm is based on the saddle point reformulation of the dynamic version of EOT which is known as the Schr\\\"odinger Bridge problem. In contrast to the prior methods for large-scale EOT, our algorithm is end-to-end and consists of a single learning step, has fast inference procedure, and allows handling small values of the entropy regularization coefficient which is of particular importance in some applied problems. Empirically, we show the performance of the method on several large-scale EOT tasks. ",
    "url": "https://arxiv.org/abs/2211.01156",
    "authors": [
      "Nikita Gushchin",
      "Alexander Kolesov",
      "Alexander Korotin",
      "Dmitry Vetrov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01165",
    "title": "RegCLR: A Self-Supervised Framework for Tabular Representation Learning  in the Wild",
    "abstract": "Recent advances in self-supervised learning (SSL) using large models to learn visual representations from natural images are rapidly closing the gap between the results produced by fully supervised learning and those produced by SSL on downstream vision tasks. Inspired by this advancement and primarily motivated by the emergence of tabular and structured document image applications, we investigate which self-supervised pretraining objectives, architectures, and fine-tuning strategies are most effective. To address these questions, we introduce RegCLR, a new self-supervised framework that combines contrastive and regularized methods and is compatible with the standard Vision Transformer architecture. Then, RegCLR is instantiated by integrating masked autoencoders as a representative example of a contrastive method and enhanced Barlow Twins as a representative example of a regularized method with configurable input image augmentations in both branches. Several real-world table recognition scenarios (e.g., extracting tables from document images), ranging from standard Word and Latex documents to even more challenging electronic health records (EHR) computer screen images, have been shown to benefit greatly from the representations learned from this new framework, with detection average-precision (AP) improving relatively by 4.8% for Table, 11.8% for Column, and 11.1% for GUI objects over a previous fully supervised baseline on real-world EHR screen images. ",
    "url": "https://arxiv.org/abs/2211.01165",
    "authors": [
      "Weiyao Wang",
      "Byung-Hak Kim",
      "Varun Ganapathi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01174",
    "title": "Hypergraph Convolutional Network based Weakly Supervised Point Cloud  Semantic Segmentation with Scene-Level Annotations",
    "abstract": "Point cloud segmentation with scene-level annotations is a promising but challenging task. Currently, the most popular way is to employ the class activation map (CAM) to locate discriminative regions and then generate point-level pseudo labels from scene-level annotations. However, these methods always suffer from the point imbalance among categories, as well as the sparse and incomplete supervision from CAM. In this paper, we propose a novel weighted hypergraph convolutional network-based method, called WHCN, to confront the challenges of learning point-wise labels from scene-level annotations. Firstly, in order to simultaneously overcome the point imbalance among different categories and reduce the model complexity, superpoints of a training point cloud are generated by exploiting the geometrically homogeneous partition. Then, a hypergraph is constructed based on the high-confidence superpoint-level seeds which are converted from scene-level annotations. Secondly, the WHCN takes the hypergraph as input and learns to predict high-precision point-level pseudo labels by label propagation. Besides the backbone network consisting of spectral hypergraph convolution blocks, a hyperedge attention module is learned to adjust the weights of hyperedges in the WHCN. Finally, a segmentation network is trained by these pseudo point cloud labels. We comprehensively conduct experiments on the ScanNet and S3DIS segmentation datasets. Experimental results demonstrate that the proposed WHCN is effective to predict the point labels with scene annotations, and yields state-of-the-art results in the community. The source code is available at this http URL ",
    "url": "https://arxiv.org/abs/2211.01174",
    "authors": [
      "Zhuheng Lu",
      "Peng Zhang",
      "Yuewei Dai",
      "Weiqing Li",
      "Zhiyong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.01177",
    "title": "Neural Block-Slot Representations",
    "abstract": "In this paper, we propose a novel object-centric representation, called Block-Slot Representation. Unlike the conventional slot representation, the Block-Slot Representation provides concept-level disentanglement within a slot. A block-slot is constructed by composing a set of modular concept representations, called blocks, generated from a learned memory of abstract concept prototypes. We call this block-slot construction process Block-Slot Attention. Block-Slot Attention facilitates the emergence of abstract concept blocks within a slot such as color, position, and texture, without any supervision. This brings the benefits of disentanglement into slots and the representation becomes more interpretable. Similar to Slot Attention, this mechanism can be used as a drop-in module in any arbitrary neural architecture. In experiments, we show that our model disentangles object properties significantly better than the previous methods, including complex textured scenes. We also demonstrate the ability to compose novel scenes by composing slots at the block-level. ",
    "url": "https://arxiv.org/abs/2211.01177",
    "authors": [
      "Gautam Singh",
      "Yeongbin Kim",
      "Sungjin Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01182",
    "title": "Defending with Errors: Approximate Computing for Robustness of Deep  Neural Networks",
    "abstract": "Machine-learning architectures, such as Convolutional Neural Networks (CNNs) are vulnerable to adversarial attacks: inputs crafted carefully to force the system output to a wrong label. Since machine-learning is being deployed in safety-critical and security-sensitive domains, such attacks may have catastrophic security and safety consequences. In this paper, we propose for the first time to use hardware-supported approximate computing to improve the robustness of machine-learning classifiers. We show that successful adversarial attacks against the exact classifier have poor transferability to the approximate implementation. Surprisingly, the robustness advantages also apply to white-box attacks where the attacker has unrestricted access to the approximate classifier implementation: in this case, we show that substantially higher levels of adversarial noise are needed to produce adversarial examples. Furthermore, our approximate computing model maintains the same level in terms of classification accuracy, does not require retraining, and reduces resource utilization and energy consumption of the CNN. We conducted extensive experiments on a set of strong adversarial attacks; We empirically show that the proposed implementation increases the robustness of a LeNet-5, Alexnet and VGG-11 CNNs considerably with up to 50% by-product saving in energy consumption due to the simpler nature of the approximate logic. ",
    "url": "https://arxiv.org/abs/2211.01182",
    "authors": [
      "Amira Guesmi",
      "Ihsen Alouani",
      "Khaled N. Khasawneh",
      "Mouna Baklouti",
      "Tarek Frikha",
      "Mohamed Abid",
      "Nael Abu-Ghazaleh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.01184",
    "title": "Joint Data and Feature Augmentation for Self-Supervised Representation  Learning on Point Clouds",
    "abstract": "To deal with the exhausting annotations, self-supervised representation learning from unlabeled point clouds has drawn much attention, especially centered on augmentation-based contrastive methods. However, specific augmentations hardly produce sufficient transferability to high-level tasks on different datasets. Besides, augmentations on point clouds may also change underlying semantics. To address the issues, we propose a simple but efficient augmentation fusion contrastive learning framework to combine data augmentations in Euclidean space and feature augmentations in feature space. In particular, we propose a data augmentation method based on sampling and graph generation. Meanwhile, we design a data augmentation network to enable a correspondence of representations by maximizing consistency between augmented graph pairs. We further design a feature augmentation network that encourages the model to learn representations invariant to the perturbations using an encoder perturbation. We comprehensively conduct extensive object classification experiments and object part segmentation experiments to validate the transferability of the proposed framework. Experimental results demonstrate that the proposed framework is effective to learn the point cloud representation in a self-supervised manner, and yields state-of-the-art results in the community. The source code is publicly available at: https://zhiyongsu.github.io/Project/AFSRL.html. ",
    "url": "https://arxiv.org/abs/2211.01184",
    "authors": [
      "Zhuheng Lu",
      "Yuewei Dai",
      "Weiqing Li",
      "Zhiyong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.01201",
    "title": "Human alignment of neural network representations",
    "abstract": "Today's computer vision models achieve human or near-human level performance across a wide variety of vision tasks. However, their architectures, data, and learning algorithms differ in numerous ways from those that give rise to human vision. In this paper, we investigate the factors that affect alignment between the representations learned by neural networks and human concept representations. Human representations are inferred from behavioral responses in an odd-one-out triplet task, where humans were presented with three images and had to select the odd-one-out. We find that model scale and architecture have essentially no effect on alignment with human behavioral responses, whereas the training dataset and objective function have a much larger impact. Using a sparse Bayesian model of human conceptual representations, we partition triplets by the concept that distinguishes the two similar images from the odd-one-out, finding that some concepts such as food and animals are well-represented in neural network representations whereas others such as royal or sports-related objects are not. Overall, although models trained on larger, more diverse datasets achieve better alignment with humans than models trained on ImageNet alone, our results indicate that scaling alone is unlikely to be sufficient to train neural networks with conceptual representations that match those used by humans. ",
    "url": "https://arxiv.org/abs/2211.01201",
    "authors": [
      "Lukas Muttenthaler",
      "Jonas Dippel",
      "Lorenz Linhardt",
      "Robert A. Vandermeulen",
      "Simon Kornblith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.01207",
    "title": "Bias-Aware Face Mask Detection Dataset",
    "abstract": "In December 2019, a novel coronavirus (COVID-19) spread so quickly around the world that many countries had to set mandatory face mask rules in public areas to reduce the transmission of the virus. To monitor public adherence, researchers aimed to rapidly develop efficient systems that can detect faces with masks automatically. However, the lack of representative and novel datasets proved to be the biggest challenge. Early attempts to collect face mask datasets did not account for potential race, gender, and age biases. Therefore, the resulting models show inherent biases toward specific race groups, such as Asian or Caucasian. In this work, we present a novel face mask detection dataset that contains images posted on Twitter during the pandemic from around the world. Unlike previous datasets, the proposed Bias-Aware Face Mask Detection (BAFMD) dataset contains more images from underrepresented race and age groups to mitigate the problem for the face mask detection task. We perform experiments to investigate potential biases in widely used face mask detection datasets and illustrate that the BAFMD dataset yields models with better performance and generalization ability. The dataset is publicly available at https://github.com/Alpkant/BAFMD. ",
    "url": "https://arxiv.org/abs/2211.01207",
    "authors": [
      "Alperen Kantarc\u0131",
      "Ferda Ofli",
      "Muhammad Imran",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.01213",
    "title": "FiFo: Fishbone Forwarding in Massive IoT Networks",
    "abstract": "Massive Internet of Things (IoT) networks have a wide range of applications, including but not limited to the rapid delivery of emergency and disaster messages. Although various benchmark algorithms have been developed to date for message delivery in such applications, they pose several practical challenges such as insufficient network coverage and/or highly redundant transmissions to expand the coverage area, resulting in considerable energy consumption for each IoT device. To overcome this problem, we first characterize a new performance metric, forwarding efficiency, which is defined as the ratio of the coverage probability to the average number of transmissions per device, to evaluate the data dissemination performance more appropriately. Then, we propose a novel and effective forwarding method, fishbone forwarding (FiFo), which aims to improve the forwarding efficiency with acceptable computational complexity. Our FiFo method completes two tasks: 1) it clusters devices based on the unweighted pair group method with the arithmetic average; and 2) it creates the main axis and sub axes of each cluster using both the expectation-maximization algorithm for the Gaussian mixture model and principal component analysis. We demonstrate the superiority of FiFo by using a real-world dataset. Through intensive and comprehensive simulations, we show that the proposed FiFo method outperforms benchmark algorithms in terms of the forwarding efficiency. ",
    "url": "https://arxiv.org/abs/2211.01213",
    "authors": [
      "Hayoung Seong",
      "Junseon Kim",
      "Won-Yong Shin",
      "Howon Lee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.01214",
    "title": "Time-aware Random Walk Diffusion to Improve Dynamic Graph Learning",
    "abstract": "How can we augment a dynamic graph for improving the performance of dynamic graph neural networks? Graph augmentation has been widely utilized to boost the learning performance of GNN-based models. However, most existing approaches only enhance spatial structure within an input static graph by transforming the graph, and do not consider dynamics caused by time such as temporal locality, i.e., recent edges are more influential than earlier ones, which remains challenging for dynamic graph augmentation. In this work, we propose TiaRa (Time-aware Random Walk Diffusion), a novel diffusion-based method for augmenting a dynamic graph represented as a discrete-time sequence of graph snapshots. For this purpose, we first design a time-aware random walk proximity so that a surfer can walk along the time dimension as well as edges, resulting in spatially and temporally localized scores. We then derive our diffusion matrices based on the time-aware random walk, and show they become enhanced adjacency matrices that both spatial and temporal localities are augmented. Throughout extensive experiments, we demonstrate that TiaRaeffectively augments a given dynamic graph, and leads to significant improvements in dynamic GNN models for various graph datasets and tasks. ",
    "url": "https://arxiv.org/abs/2211.01214",
    "authors": [
      "Jong-whi Lee",
      "Jinhong Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01233",
    "title": "Attention-based Neural Cellular Automata",
    "abstract": "Recent extensions of Cellular Automata (CA) have incorporated key ideas from modern deep learning, dramatically extending their capabilities and catalyzing a new family of Neural Cellular Automata (NCA) techniques. Inspired by Transformer-based architectures, our work presents a new class of $\\textit{attention-based}$ NCAs formed using a spatially localized$\\unicode{x2014}$yet globally organized$\\unicode{x2014}$self-attention scheme. We introduce an instance of this class named $\\textit{Vision Transformer Cellular Automata}$ (ViTCA). We present quantitative and qualitative results on denoising autoencoding across six benchmark datasets, comparing ViTCA to a U-Net, a U-Net-based CA baseline (UNetCA), and a Vision Transformer (ViT). When comparing across architectures configured to similar parameter complexity, ViTCA architectures yield superior performance across all benchmarks and for nearly every evaluation metric. We present an ablation study on various architectural configurations of ViTCA, an analysis of its effect on cell states, and an investigation on its inductive biases. Finally, we examine its learned representations via linear probes on its converged cell state hidden representations, yielding, on average, superior results when compared to our U-Net, ViT, and UNetCA baselines. ",
    "url": "https://arxiv.org/abs/2211.01233",
    "authors": [
      "Mattie Tesfaldet",
      "Derek Nowrouzezahrai",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01236",
    "title": "Isometric Representations in Neural Networks Improve Robustness",
    "abstract": "Artificial and biological agents cannon learn given completely random and unstructured data. The structure of data is encoded in the metric relationships between data points. In the context of neural networks, neuronal activity within a layer forms a representation reflecting the transformation that the layer implements on its inputs. In order to utilize the structure in the data in a truthful manner, such representations should reflect the input distances and thus be continuous and isometric. Supporting this statement, recent findings in neuroscience propose that generalization and robustness are tied to neural representations being continuously differentiable. In machine learning, most algorithms lack robustness and are generally thought to rely on aspects of the data that differ from those that humans use, as is commonly seen in adversarial attacks. During cross-entropy classification, the metric and structural properties of network representations are usually broken both between and within classes. This side effect from training can lead to instabilities under perturbations near locations where such structure is not preserved. One of the standard solutions to obtain robustness is to add ad hoc regularization terms, but to our knowledge, forcing representations to preserve the metric structure of the input data as a stabilising mechanism has not yet been studied. In this work, we train neural networks to perform classification while simultaneously maintaining within-class metric structure, leading to isometric within-class representations. Such network representations turn out to be beneficial for accurate and robust inference. By stacking layers with this property we create a network architecture that facilitates hierarchical manipulation of internal neural representations. Finally, we verify that isometric regularization improves the robustness to adversarial attacks on MNIST. ",
    "url": "https://arxiv.org/abs/2211.01236",
    "authors": [
      "Kosio Beshkov",
      "Jonas Verhellen",
      "Mikkel Elle Lepper\u00f8d"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.01244",
    "title": "EquiMod: An Equivariance Module to Improve Self-Supervised Learning",
    "abstract": "Self-supervised visual representation methods are closing the gap with supervised learning performance. These methods rely on maximizing the similarity between embeddings of related synthetic inputs created through data augmentations. This can be seen as a task that encourages embeddings to leave out factors modified by these augmentations, i.e. to be invariant to them. However, this only considers one side of the trade-off in the choice of the augmentations: they need to strongly modify the images to avoid simple solution shortcut learning (e.g. using only color histograms), but on the other hand, augmentations-related information may be lacking in the representations for some downstream tasks (e.g. color is important for birds and flower classification). Few recent works proposed to mitigate the problem of using only an invariance task by exploring some form of equivariance to augmentations. This has been performed by learning additional embeddings space(s), where some augmentation(s) cause embeddings to differ, yet in a non-controlled way. In this work, we introduce EquiMod a generic equivariance module that structures the learned latent space, in the sense that our module learns to predict the displacement in the embedding space caused by the augmentations. We show that applying that module to state-of-the-art invariance models, such as SimCLR and BYOL, increases the performances on CIFAR10 and ImageNet datasets. Moreover, while our model could collapse to a trivial equivariance, i.e. invariance, we observe that it instead automatically learns to keep some augmentations-related information beneficial to the representations. ",
    "url": "https://arxiv.org/abs/2211.01244",
    "authors": [
      "Alexandre Devillers",
      "Mathieu Lefort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01254",
    "title": "CircleSnake: Instance Segmentation with Circle Representation",
    "abstract": "Circle representation has recently been introduced as a medical imaging optimized representation for more effective instance object detection on ball-shaped medical objects. With its superior performance on instance detection, it is appealing to extend the circle representation to instance medical object segmentation. In this work, we propose CircleSnake, a simple end-to-end circle contour deformation-based segmentation method for ball-shaped medical objects. Compared to the prevalent DeepSnake method, our contribution is three-fold: (1) We replace the complicated bounding box to octagon contour transformation with a computation-free and consistent bounding circle to circle contour adaption for segmenting ball-shaped medical objects; (2) Circle representation has fewer degrees of freedom (DoF=2) as compared with the octagon representation (DoF=8), thus yielding a more robust segmentation performance and better rotation consistency; (3) To the best of our knowledge, the proposed CircleSnake method is the first end-to-end circle representation deep segmentation pipeline method with consistent circle detection, circle contour proposal, and circular convolution. The key innovation is to integrate the circular graph convolution with circle detection into an end-to-end instance segmentation framework, enabled by the proposed simple and consistent circle contour representation. Glomeruli are used to evaluate the performance of the benchmarks. From the results, CircleSnake increases the average precision of glomerular detection from 0.559 to 0.614. The Dice score increased from 0.804 to 0.849. The code has been released: https://github.com/hrlblab/CircleSnake ",
    "url": "https://arxiv.org/abs/2211.01254",
    "authors": [
      "Ethan H. Nguyen",
      "Haichun Yang",
      "Zuhayr Asad",
      "Ruining Deng",
      "Agnes B. Fogo",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01270",
    "title": "Secure and Efficient Privacy-preserving Authentication Scheme using  Cuckoo Filter in Remote Patient Monitoring Network",
    "abstract": "With the ubiquitous advancement in smart medical devices and systems, the potential of Remote Patient Monitoring (RPM) network is evolving in modern healthcare systems. The medical professionals (doctors, nurses, or medical experts) can access vitals and sensitive physiological information about the patients and provide proper treatment to improve the quality of life through the RPM network. However, the wireless nature of communication in the RPM network makes it challenging to design an efficient mechanism for secure communication. Many authentication schemes have been proposed in recent years to ensure the security of the RPM network. Pseudonym, digital signature, and Authenticated Key Exchange (AKE) protocols are used for the Internet of Medical Things (IoMT) to develop secure authorization and privacy-preserving communication. However, traditional authentication protocols face overhead challenges due to maintaining a large set of key-pairs or pseudonyms results on the hospital cloud server. In this research work, we identify this research gap and propose a novel secure and efficient privacy-preserving authentication scheme using cuckoo filters for the RPM network. The use of cuckoo filters in our proposed scheme provides an efficient way for mutual anonymous authentication and a secret shared key establishment process between medical professionals and patients. Moreover, we identify the misbehaving sensor nodes using a correlation-based anomaly detection model to establish secure communication. The security analysis and formal security validation using SPAN and AVISPA tools show the robustness of our proposed scheme against message modification attacks, replay attacks, and man-in-the-middle attacks. ",
    "url": "https://arxiv.org/abs/2211.01270",
    "authors": [
      "Shafika Showkat Moni",
      "Deepti Gupta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.01294",
    "title": "Driver Digital Twin for Online Prediction of Personalized Lane Change  Behavior",
    "abstract": "Connected and automated vehicles (CAVs) are supposed to share the road with human-driven vehicles (HDVs) in a foreseeable future. Therefore, considering the mixed traffic environment is more pragmatic, as the well-planned operation of CAVs may be interrupted by HDVs. In the circumstance that human behaviors have significant impacts, CAVs need to understand HDV behaviors to make safe actions. In this study, we develop a Driver Digital Twin (DDT) for the online prediction of personalized lane change behavior, allowing CAVs to predict surrounding vehicles' behaviors with the help of the digital twin technology. DDT is deployed on a vehicle-edge-cloud architecture, where the cloud server models the driver behavior for each HDV based on the historical naturalistic driving data, while the edge server processes the real-time data from each driver with his/her digital twin on the cloud to predict the lane change maneuver. The proposed system is first evaluated on a human-in-the-loop co-simulation platform, and then in a field implementation with three passenger vehicles connected through the 4G/LTE cellular network. The lane change intention can be recognized in 6 seconds on average before the vehicle crosses the lane separation line, and the Mean Euclidean Distance between the predicted trajectory and GPS ground truth is 1.03 meters within a 4-second prediction window. Compared to the general model, using a personalized model can improve prediction accuracy by 27.8%. The demonstration video of the proposed system can be watched at https://youtu.be/5cbsabgIOdM. ",
    "url": "https://arxiv.org/abs/2211.01294",
    "authors": [
      "Xishun Liao",
      "Xuanpeng Zhao",
      "Ziran Wang",
      "Zhouqiao Zhao",
      "Kyungtae Han",
      "Rohit Gupta",
      "Matthew J. Barth",
      "Guoyuan Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.01297",
    "title": "C3SASR: Cheap Causal Convolutions for Self-Attentive Sequential  Recommendation",
    "abstract": "Sequential Recommendation is a prominent topic in current research, which uses user behavior sequence as an input to predict future behavior. By assessing the correlation strength of historical behavior through the dot product, the model based on the self-attention mechanism can capture the long-term preference of the sequence. However, it has two limitations. On the one hand, it does not effectively utilize the items' local context information when determining the attention and creating the sequence representation. On the other hand, the convolution and linear layers often contain redundant information, which limits the ability to encode sequences. In this paper, we propose a self-attentive sequential recommendation model based on cheap causal convolution. It utilizes causal convolutions to capture items' local information for calculating attention and generating sequence embedding. It also uses cheap convolutions to improve the representations by lightweight structure. We evaluate the effectiveness of the proposed model in terms of both accurate and calibrated sequential recommendation. Experiments on benchmark datasets show that the proposed model can perform better in single- and multi-objective recommendation scenarios. ",
    "url": "https://arxiv.org/abs/2211.01297",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.01317",
    "title": "Low-Resource Music Genre Classification with Advanced Neural Model  Reprogramming",
    "abstract": "Transfer learning (TL) approaches have shown promising results when handling tasks with limited training data. However, considerable memory and computational resources are often required for fine-tuning pre-trained neural networks with target domain data. In this work, we introduce a novel method for leveraging pre-trained models for low-resource (music) classification based on the concept of Neural Model Reprogramming (NMR). NMR aims at re-purposing a pre-trained model from a source domain to a target domain by modifying the input of a frozen pre-trained model. In addition to the known, input-independent, reprogramming method, we propose an advanced reprogramming paradigm: Input-dependent NMR, to increase adaptability to complex input data such as musical audio. Experimental results suggest that a neural model pre-trained on large-scale datasets can successfully perform music genre classification by using this reprogramming method. The two proposed Input-dependent NMR TL methods outperform fine-tuning-based TL methods on a small genre classification dataset. ",
    "url": "https://arxiv.org/abs/2211.01317",
    "authors": [
      "Yun-Ning Hung",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen",
      "Alexander Lerch"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.01327",
    "title": "Predicting phoneme-level prosody latents using AR and flow-based Prior  Networks for expressive speech synthesis",
    "abstract": "A large part of the expressive speech synthesis literature focuses on learning prosodic representations of the speech signal which are then modeled by a prior distribution during inference. In this paper, we compare different prior architectures at the task of predicting phoneme level prosodic representations extracted with an unsupervised FVAE model. We use both subjective and objective metrics to show that normalizing flow based prior networks can result in more expressive speech at the cost of a slight drop in quality. Furthermore, we show that the synthesized speech has higher variability, for a given text, due to the nature of normalizing flows. We also propose a Dynamical VAE model, that can generate higher quality speech although with decreased expressiveness and variability compared to the flow based models. ",
    "url": "https://arxiv.org/abs/2211.01327",
    "authors": [
      "Konstantinos Klapsas",
      "Karolos Nikitaras",
      "Nikolaos Ellinas",
      "June Sig Sung",
      "Inchul Hwang",
      "Spyros Raptis",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.01334",
    "title": "MemoNet:Memorizing Representations of All Cross Features Efficiently via  Multi-Hash Codebook Network for CTR Prediction",
    "abstract": "New findings in natural language processing(NLP) demonstrate that the strong memorization capability contributes a lot to the success of large language models.This inspires us to explicitly bring an independent memory mechanism into CTR ranking model to learn and memorize all cross features' representations.In this paper,we propose multi-Hash Codebook NETwork(HCNet) as the memory mechanism for efficiently learning and memorizing representations of all cross features in CTR tasks.HCNet uses multi-hash codebook as the main memory place and the whole memory procedure consists of three phases: multi-hash addressing,memory restoring and feature shrinking.HCNet can be regarded as a general module and can be incorporated into any current deep CTR model.We also propose a new CTR model named MemoNet which combines HCNet with a DNN backbone.Extensive experimental results on three public datasets show that MemoNet reaches superior performance over state-of-the-art approaches and validate the effectiveness of HCNet as a strong memory module.Besides, MemoNet shows the prominent feature of big models in NLP,which means we can enlarge the size of codebook in HCNet to sustainably obtain performance gains.Our work demonstrates the importance and feasibility of learning and memorizing representations of all cross features ,which sheds light on a new promising research direction. ",
    "url": "https://arxiv.org/abs/2211.01334",
    "authors": [
      "Pengtao Zhang",
      "Junlin Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01336",
    "title": "A Transformer-based Framework for POI-level Social Post Geolocation",
    "abstract": "POI-level geo-information of social posts is critical to many location-based applications and services. However, the multi-modality, complexity and diverse nature of social media data and their platforms limit the performance of inferring such fine-grained locations and their subsequent applications. To address this issue, we present a transformer-based general framework, which builds upon pre-trained language models and considers non-textual data, for social post geolocation at the POI level. To this end, inputs are categorized to handle different social data, and an optimal combination strategy is provided for feature representations. Moreover, a uniform representation of hierarchy is proposed to learn temporal information, and a concatenated version of encodings is employed to capture feature-wise positions better. Experimental results on various social datasets demonstrate that three variants of our proposed framework outperform multiple state-of-art baselines by a large margin in terms of accuracy and distance error metrics. ",
    "url": "https://arxiv.org/abs/2211.01336",
    "authors": [
      "Menglin Li",
      "Kwan Hui Lim",
      "Teng Guo",
      "Junhua Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.01340",
    "title": "POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural  Networks",
    "abstract": "Deep Neural Networks (DNNs) outshine alternative function approximators in many settings thanks to their modularity in composing any desired differentiable operator. The formed parametrized functional is then tuned to solve a task at hand from simple gradient descent. This modularity comes at the cost of making strict enforcement of constraints on DNNs, e.g. from a priori knowledge of the task, or from desired physical properties, an open challenge. In this paper we propose the first provable affine constraint enforcement method for DNNs that requires minimal changes into a given DNN's forward-pass, that is computationally friendly, and that leaves the optimization of the DNN's parameter to be unconstrained i.e. standard gradient-based method can be employed. Our method does not require any sampling and provably ensures that the DNN fulfills the affine constraint on a given input space's region at any point during training, and testing. We coin this method POLICE, standing for Provably Optimal LInear Constraint Enforcement. ",
    "url": "https://arxiv.org/abs/2211.01340",
    "authors": [
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.01361",
    "title": "My Face My Choice: Privacy Enhancing Deepfakes for Social Media  Anonymization",
    "abstract": "Recently, productization of face recognition and identification algorithms have become the most controversial topic about ethical AI. As new policies around digital identities are formed, we introduce three face access models in a hypothetical social network, where the user has the power to only appear in photos they approve. Our approach eclipses current tagging systems and replaces unapproved faces with quantitatively dissimilar deepfakes. In addition, we propose new metrics specific for this task, where the deepfake is generated at random with a guaranteed dissimilarity. We explain access models based on strictness of the data flow, and discuss impact of each model on privacy, usability, and performance. We evaluate our system on Facial Descriptor Dataset as the real dataset, and two synthetic datasets with random and equal class distributions. Running seven SOTA face recognizers on our results, MFMC reduces the average accuracy by 61%. Lastly, we extensively analyze similarity metrics, deepfake generators, and datasets in structural, visual, and generative spaces; supporting the design choices and verifying the quality. ",
    "url": "https://arxiv.org/abs/2211.01361",
    "authors": [
      "Umur A. Ciftci",
      "Gokturk Yuksek",
      "Ilke Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.01367",
    "title": "Two-Stream Network for Sign Language Recognition and Translation",
    "abstract": "Sign languages are visual languages using manual articulations and non-manual elements to convey information. For sign language recognition and translation, the majority of existing approaches directly encode RGB videos into hidden representations. RGB videos, however, are raw signals with substantial visual redundancy, leading the encoder to overlook the key information for sign language understanding. To mitigate this problem and better incorporate domain knowledge, such as handshape and body movement, we introduce a dual visual encoder containing two separate streams to model both the raw videos and the keypoint sequences generated by an off-the-shelf keypoint estimator. To make the two streams interact with each other, we explore a variety of techniques, including bidirectional lateral connection, sign pyramid network with auxiliary supervision, and frame-level self-distillation. The resulting model is called TwoStream-SLR, which is competent for sign language recognition (SLR). TwoStream-SLR is extended to a sign language translation (SLT) model, TwoStream-SLT, by simply attaching an extra translation network. Experimentally, our TwoStream-SLR and TwoStream-SLT achieve state-of-the-art performance on SLR and SLT tasks across a series of datasets including Phoenix-2014, Phoenix-2014T, and CSL-Daily. ",
    "url": "https://arxiv.org/abs/2211.01367",
    "authors": [
      "Yutong Chen",
      "Ronglai Zuo",
      "Fangyun Wei",
      "Yu Wu",
      "Shujie Liu",
      "Brian Mak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00643",
    "title": "A Federated Learning Scheme for Neuro-developmental Disorders:  Multi-Aspect ASD Detection",
    "abstract": "Autism Spectrum Disorder (ASD) is a neuro-developmental syndrome resulting from alterations in the embryological brain before birth. This disorder distinguishes its patients by special socially restricted and repetitive behavior in addition to specific behavioral traits. Hence, this would possibly deteriorate their social behavior among other individuals, as well as their overall interaction within their community. Moreover, medical research has proved that ASD also affects the facial characteristics of its patients, making the syndrome recognizable from distinctive signs within an individual's face. Given that as a motivation behind our work, we propose a novel privacy-preserving federated learning scheme to predict ASD in a certain individual based on their behavioral and facial features, embedding a merging process of both data features through facial feature extraction while respecting patient data privacy. After training behavioral and facial image data on federated machine learning models, promising results are achieved, with 70\\% accuracy for the prediction of ASD according to behavioral traits in a federated learning environment, and a 62\\% accuracy is reached for the prediction of ASD given an image of the patient's face. Then, we test the behavior of regular as well as federated ML on our merged data, behavioral and facial, where a 65\\% accuracy is achieved with the regular logistic regression model and 63\\% accuracy with the federated learning model. ",
    "url": "https://arxiv.org/abs/2211.00643",
    "authors": [
      "Hala Shamseddine",
      "Safa Otoum",
      "Azzam Mourad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00677",
    "title": "Semi-Supervised Domain Adaptation for Cross-Survey Galaxy Morphology  Classification and Anomaly Detection",
    "abstract": "In the era of big astronomical surveys, our ability to leverage artificial intelligence algorithms simultaneously for multiple datasets will open new avenues for scientific discovery. Unfortunately, simply training a deep neural network on images from one data domain often leads to very poor performance on any other dataset. Here we develop a Universal Domain Adaptation method DeepAstroUDA, capable of performing semi-supervised domain alignment that can be applied to datasets with different types of class overlap. Extra classes can be present in any of the two datasets, and the method can even be used in the presence of unknown classes. For the first time, we demonstrate the successful use of domain adaptation on two very different observational datasets (from SDSS and DECaLS). We show that our method is capable of bridging the gap between two astronomical surveys, and also performs well for anomaly detection and clustering of unknown data in the unlabeled dataset. We apply our model to two examples of galaxy morphology classification tasks with anomaly detection: 1) classifying spiral and elliptical galaxies with detection of merging galaxies (three classes including one unknown anomaly class); 2) a more granular problem where the classes describe more detailed morphological properties of galaxies, with the detection of gravitational lenses (ten classes including one unknown anomaly class). ",
    "url": "https://arxiv.org/abs/2211.00677",
    "authors": [
      "Aleksandra \u0106iprijanovi\u0107",
      "Ashia Lewis",
      "Kevin Pedro",
      "Sandeep Madireddy",
      "Brian Nord",
      "Gabriel N. Perdue",
      "Stefan Wild"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00724",
    "title": "Privacy Induces Robustness: Information-Computation Gaps and Sparse Mean  Estimation",
    "abstract": "We establish a simple connection between robust and differentially-private algorithms: private mechanisms which perform well with very high probability are automatically robust in the sense that they retain accuracy even if a constant fraction of the samples they receive are adversarially corrupted. Since optimal mechanisms typically achieve these high success probabilities, our results imply that optimal private mechanisms for many basic statistics problems are robust. We investigate the consequences of this observation for both algorithms and computational complexity across different statistical problems. Assuming the Brennan-Bresler secret-leakage planted clique conjecture, we demonstrate a fundamental tradeoff between computational efficiency, privacy leakage, and success probability for sparse mean estimation. Private algorithms which match this tradeoff are not yet known -- we achieve that (up to polylogarithmic factors) in a polynomially-large range of parameters via the Sum-of-Squares method. To establish an information-computation gap for private sparse mean estimation, we also design new (exponential-time) mechanisms using fewer samples than efficient algorithms must use. Finally, we give evidence for privacy-induced information-computation gaps for several other statistics and learning problems, including PAC learning parity functions and estimation of the mean of a multivariate Gaussian. ",
    "url": "https://arxiv.org/abs/2211.00724",
    "authors": [
      "Kristian Georgiev",
      "Samuel B. Hopkins"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00745",
    "title": "Self-supervised Physics-based Denoising for Computed Tomography",
    "abstract": "Computed Tomography (CT) imposes risk on the patients due to its inherent X-ray radiation, stimulating the development of low-dose CT (LDCT) imaging methods. Lowering the radiation dose reduces the health risks but leads to noisier measurements, which decreases the tissue contrast and causes artifacts in CT images. Ultimately, these issues could affect the perception of medical personnel and could cause misdiagnosis. Modern deep learning noise suppression methods alleviate the challenge but require low-noise-high-noise CT image pairs for training, rarely collected in regular clinical workflows. In this work, we introduce a new self-supervised approach for CT denoising Noise2NoiseTD-ANM that can be trained without the high-dose CT projection ground truth images. Unlike previously proposed self-supervised techniques, the introduced method exploits the connections between the adjacent projections and the actual model of CT noise distribution. Such a combination allows for interpretable no-reference denoising using nothing but the original noisy LDCT projections. Our experiments with LDCT data demonstrate that the proposed method reaches the level of the fully supervised models, sometimes superseding them, easily generalizes to various noise levels, and outperforms state-of-the-art self-supervised denoising algorithms. ",
    "url": "https://arxiv.org/abs/2211.00745",
    "authors": [
      "Elvira Zainulina",
      "Alexey Chernyavskiy",
      "Dmitry V. Dylov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00825",
    "title": "LMD: A Learnable Mask Network to Detect Adversarial Examples for Speaker  Verification",
    "abstract": "Although the security of automatic speaker verification (ASV) is seriously threatened by recently emerged adversarial attacks, there have been some countermeasures to alleviate the threat. However, many defense approaches not only require the prior knowledge of the attackers but also possess weak interpretability. To address this issue, in this paper, we propose an attacker-independent and interpretable method, named learnable mask detector (LMD), to separate adversarial examples from the genuine ones. It utilizes score variation as an indicator to detect adversarial examples, where the score variation is the absolute discrepancy between the ASV scores of an original audio recording and its transformed audio synthesized from its masked complex spectrogram. A core component of the score variation detector is to generate the masked spectrogram by a neural network. The neural network needs only genuine examples for training, which makes it an attacker-independent approach. Its interpretability lies that the neural network is trained to minimize the score variation of the targeted ASV, and maximize the number of the masked spectrogram bins of the genuine training examples. Its foundation is based on the observation that, masking out the vast majority of the spectrogram bins with little speaker information will inevitably introduce a large score variation to the adversarial example, and a small score variation to the genuine example. Experimental results with 12 attackers and two representative ASV systems show that our proposed method outperforms five state-of-the-art baselines. The extensive experimental results can also be a benchmark for the detection-based ASV defenses. ",
    "url": "https://arxiv.org/abs/2211.00825",
    "authors": [
      "Xing Chen",
      "Jie Wang",
      "Xiao-Lei Zhang",
      "Wei-Qiang Zhang",
      "Kunde Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.00878",
    "title": "Neural Fourier Shift for Binaural Speech Rendering",
    "abstract": "We present a neural network for rendering binaural speech from given monaural audio, position, and orientation of the source. Most of the previous works have focused on synthesizing binaural speeches by conditioning the positions and orientations in the feature space of convolutional neural networks. These synthesis approaches are powerful in estimating the target binaural speeches even for in-the-wild data but are difficult to generalize for rendering the audio from out-of-distribution domains. To alleviate this, we propose Neural Fourier Shift (NFS), a novel network architecture that enables binaural speech rendering in the Fourier space. Specifically, utilizing a geometric time delay based on the distance between the source and the receiver, NFS is trained to predict the delays and scales of various early reflections. NFS is efficient in both memory and computational cost, is interpretable, and operates independently of the source domain by its design. With up to 25 times lighter memory and 6 times fewer calculations, the experimental results show that NFS outperforms the previous studies on the benchmark dataset. ",
    "url": "https://arxiv.org/abs/2211.00878",
    "authors": [
      "Jin Woo Lee",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00887",
    "title": "Certified Robustness of Quantum Classifiers against Adversarial Examples  through Quantum Noise",
    "abstract": "Recently, quantum classifiers have been known to be vulnerable to adversarial attacks, where quantum classifiers are fooled by imperceptible noises to have misclassification. In this paper, we propose one first theoretical study that utilizing the added quantum random rotation noise can improve the robustness of quantum classifiers against adversarial attacks. We connect the definition of differential privacy and demonstrate the quantum classifier trained with the natural presence of additive noise is differentially private. Lastly, we derive a certified robustness bound to enable quantum classifiers to defend against adversarial examples supported by experimental results. ",
    "url": "https://arxiv.org/abs/2211.00887",
    "authors": [
      "Jhih-Cing Huang",
      "Yu-Lin Tsai",
      "Chao-Han Huck Yang",
      "Cheng-Fang Su",
      "Chia-Mu Yu",
      "Pin-Yu Chen",
      "Sy-Yen Kuo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00896",
    "title": "Factorized Blank Thresholding for Improved Runtime Efficiency of Neural  Transducers",
    "abstract": "We show how factoring the RNN-T's output distribution can significantly reduce the computation cost and power consumption for on-device ASR inference with no loss in accuracy. With the rise in popularity of neural-transducer type models like the RNN-T for on-device ASR, optimizing RNN-T's runtime efficiency is of great interest. While previous work has primarily focused on the optimization of RNN-T's acoustic encoder and predictor, this paper focuses the attention on the joiner. We show that despite being only a small part of RNN-T, the joiner has a large impact on the overall model's runtime efficiency. We propose to factorize the joiner into blank and non-blank portions for the purpose of skipping the more expensive non-blank computation when the blank probability exceeds a certain threshold. Since the blank probability can be computed very efficiently and the RNN-T output is dominated by blanks, our proposed method leads to a 26-30% decoding speed-up and 43-53% reduction in on-device power consumption, all the while incurring no accuracy degradation and being relatively simple to implement. ",
    "url": "https://arxiv.org/abs/2211.00896",
    "authors": [
      "Duc Le",
      "Frank Seide",
      "Yuhao Wang",
      "Yang Li",
      "Kjell Schubert",
      "Ozlem Kalinli",
      "Michael L. Seltzer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.00902",
    "title": "Spot the fake lungs: Generating Synthetic Medical Images using Neural  Diffusion Models",
    "abstract": "Generative models are becoming popular for the synthesis of medical images. Recently, neural diffusion models have demonstrated the potential to generate photo-realistic images of objects. However, their potential to generate medical images is not explored yet. In this work, we explore the possibilities of synthesis of medical images using neural diffusion models. First, we use a pre-trained DALLE2 model to generate lungs X-Ray and CT images from an input text prompt. Second, we train a stable diffusion model with 3165 X-Ray images and generate synthetic images. We evaluate the synthetic image data through a qualitative analysis where two independent radiologists label randomly chosen samples from the generated data as real, fake, or unsure. Results demonstrate that images generated with the diffusion model can translate characteristics that are otherwise very specific to certain medical conditions in chest X-Ray or CT images. Careful tuning of the model can be very promising. To the best of our knowledge, this is the first attempt to generate lungs X-Ray and CT images using neural diffusion models. This work aims to introduce a new dimension in artificial intelligence for medical imaging. Given that this is a new topic, the paper will serve as an introduction and motivation for the research community to explore the potential of diffusion models for medical image synthesis. We have released the synthetic images on https://www.kaggle.com/datasets/hazrat/awesomelungs. ",
    "url": "https://arxiv.org/abs/2211.00902",
    "authors": [
      "Hazrat Ali",
      "Shafaq Murad",
      "Zubair Shah"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00921",
    "title": "A Data-driven Case-based Reasoning in Bankruptcy Prediction",
    "abstract": "There has been intensive research regarding machine learning models for predicting bankruptcy in recent years. However, the lack of interpretability limits their growth and practical implementation. This study proposes a data-driven explainable case-based reasoning (CBR) system for bankruptcy prediction. Empirical results from a comparative study show that the proposed approach performs superior to existing, alternative CBR systems and is competitive with state-of-the-art machine learning models. We also demonstrate that the asymmetrical feature similarity comparison mechanism in the proposed CBR system can effectively capture the asymmetrically distributed nature of financial attributes, such as a few companies controlling more cash than the majority, hence improving both the accuracy and explainability of predictions. In addition, we delicately examine the explainability of the CBR system in the decision-making process of bankruptcy prediction. While much research suggests a trade-off between improving prediction accuracy and explainability, our findings show a prospective research avenue in which an explainable model that thoroughly incorporates data attributes by design can reconcile the dilemma. ",
    "url": "https://arxiv.org/abs/2211.00921",
    "authors": [
      "Wei Li",
      "Wolfgang Karl H\u00e4rdle",
      "Stefan Lessmann"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00943",
    "title": "Adversarial Guitar Amplifier Modelling With Unpaired Data",
    "abstract": "We propose an audio effects processing framework that learns to emulate a target electric guitar tone from a recording. We train a deep neural network using an adversarial approach, with the goal of transforming the timbre of a guitar, into the timbre of another guitar after audio effects processing has been applied, for example, by a guitar amplifier. The model training requires no paired data, and the resulting model emulates the target timbre well whilst being capable of real-time processing on a modern personal computer. To verify our approach we present two experiments, one which carries out unpaired training using paired data, allowing us to monitor training via objective metrics, and another that uses fully unpaired data, corresponding to a realistic scenario where a user wants to emulate a guitar timbre only using audio data from a recording. Our listening test results confirm that the models are perceptually convincing. ",
    "url": "https://arxiv.org/abs/2211.00943",
    "authors": [
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Lauri Juvela"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.01021",
    "title": "Data-Driven Modeling of Landau Damping by Physics-Informed Neural  Networks",
    "abstract": "Kinetic approaches are generally accurate in dealing with microscale plasma physics problems but are computationally expensive for large-scale or multiscale systems. One of the long-standing problems in plasma physics is the integration of kinetic physics into fluid models, which is often achieved through sophisticated analytical closure terms. In this study, we successfully construct a multi-moment fluid model with an implicit fluid closure included in the neural network using machine learning. The multi-moment fluid model is trained with a small fraction of sparsely sampled data from kinetic simulations of Landau damping, using the physics-informed neural network (PINN) and the gradient-enhanced physics-informed neural network (gPINN). The multi-moment fluid model constructed using either PINN or gPINN reproduces the time evolution of the electric field energy, including its damping rate, and the plasma dynamics from the kinetic simulations. For the first time, we introduce a new variant of the gPINN architecture, namely, gPINN$p$ to capture the Landau damping process. Instead of including the gradients of all the equation residuals, gPINN$p$ only adds the gradient of the pressure equation residual as one additional constraint. Among the three approaches, the gPINN$p$-constructed multi-moment fluid model offers the most accurate results. This work sheds new light on the accurate and efficient modeling of large-scale systems, which can be extended to complex multiscale laboratory, space, and astrophysical plasma physics problems. ",
    "url": "https://arxiv.org/abs/2211.01021",
    "authors": [
      "Yilan Qin",
      "Jiayu Ma",
      "Mingle Jiang",
      "Chuanfei Dong",
      "Haiyang Fu",
      "Liang Wang",
      "Wenjie Cheng",
      "Yaqiu Jin"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Space Physics (physics.space-ph)"
    ]
  },
  {
    "id": "arXiv:2211.01032",
    "title": "Random Embeddings of Graphs: The Expected Number of Faces in Most Graphs  is Logarithmic",
    "abstract": "A random 2-cell embedding of a connected graph $G$ in some orientable surface is obtained by choosing a random local rotation around each vertex. Under this setup, the number of faces or the genus of the corresponding 2-cell embedding becomes a random variable. Random embeddings of two particular graph classes -- those of a bouquet of $n$ loops and those of $n$ parallel edges connecting two vertices -- have been extensively studied and are well-understood. However, little is known about more general graphs despite their important connections with central problems in mainstream mathematics and in theoretical physics (see [Lando & Zvonkin, Springer 2004]). There are also tight connections with problems in computing (random generation, approximation algorithms). The results of this paper, in particular, explain why Monte Carlo methods (see, e.g., [Gross & Tucker, Ann. NY Acad. Sci 1979] and [Gross & Rieper, JGT 1991]) cannot work for approximating the minimum genus of graphs. In his breakthrough work ([Stahl, JCTB 1991] and a series of other papers), Stahl developed the foundation of \"random topological graph theory\". Most of his results have been unsurpassed until today. In our work, we analyze the expected number of faces of random embeddings (equivalently, the average genus) of a graph $G$. It was very recently shown [Campion Loth & Mohar, arXiv 2022] that for any graph $G$, the expected number of faces is at most linear. We show that the actual expected number of faces is usually much smaller. In particular, we prove the following results: 1) $\\frac{1}{2}\\ln n - 2 < \\mathbb{E}[F(K_n)] \\le 3.65\\ln n$, for $n$ sufficiently large. This greatly improves Stahl's $n+\\ln n$ upper bound for this case. 2) For random models $B(n,\\Delta)$ containing only graphs, whose maximum degree is at most $\\Delta$, we show that the expected number of faces is $\\Theta(\\ln n)$. ",
    "url": "https://arxiv.org/abs/2211.01032",
    "authors": [
      "Jesse Campion Loth",
      "Kevin Halasz",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Bojan Mohar",
      "Robert \u0160\u00e1mal"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.01111",
    "title": "On the Benefit of Dual-domain Denoising in a Self-supervised Low-dose CT  Setting",
    "abstract": "Computed tomography (CT) is routinely used for three-dimensional non-invasive imaging. Numerous data-driven image denoising algorithms were proposed to restore image quality in low-dose acquisitions. However, considerably less research investigates methods already intervening in the raw detector data due to limited access to suitable projection data or correct reconstruction algorithms. In this work, we present an end-to-end trainable CT reconstruction pipeline that contains denoising operators in both the projection and the image domain and that are optimized simultaneously without requiring ground-truth high-dose CT data. Our experiments demonstrate that including an additional projection denoising operator improved the overall denoising performance by 82.4-94.1%/12.5-41.7% (PSNR/SSIM) on abdomen CT and 1.5-2.9%/0.4-0.5% (PSNR/SSIM) on XRM data relative to the low-dose baseline. We make our entire helical CT reconstruction framework publicly available that contains a raw projection rebinning step to render helical projection data suitable for differentiable fan-beam reconstruction operators and end-to-end learning. ",
    "url": "https://arxiv.org/abs/2211.01111",
    "authors": [
      "Fabian Wagner",
      "Mareike Thies",
      "Laura Pfaff",
      "Oliver Aust",
      "Sabrina Pechmann",
      "Daniela Weidner",
      "Noah Maul",
      "Maximilian Rohleder",
      "Mingxuan Gu",
      "Jonas Utz",
      "Felix Denzinger",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01125",
    "title": "Style Augmentation improves Medical Image Segmentation",
    "abstract": "Due to the limitation of available labeled data, medical image segmentation is a challenging task for deep learning. Traditional data augmentation techniques have been shown to improve segmentation network performances by optimizing the usage of few training examples. However, current augmentation approaches for segmentation do not tackle the strong texture bias of convolutional neural networks, observed in several studies. This work shows on the MoNuSeg dataset that style augmentation, which is already used in classification tasks, helps reducing texture over-fitting and improves segmentation performance. ",
    "url": "https://arxiv.org/abs/2211.01125",
    "authors": [
      "Kevin Ginsburger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01131",
    "title": "RF signal classification in hardware with an RF spintronic neural  network",
    "abstract": "Extracting information from radiofrequency (RF) signals using artificial neural networks at low energy cost is a critical need for a wide range of applications. Here we show how to leverage the intrinsic dynamics of spintronic nanodevices called magnetic tunnel junctions to process multiple analogue RF inputs in parallel and perform synaptic operations. Furthermore, we achieve classification of RF signals with experimental data from magnetic tunnel junctions as neurons and synapses, with the same accuracy as an equivalent software neural network. These results are a key step for embedded radiofrequency artificial intelligence. ",
    "url": "https://arxiv.org/abs/2211.01131",
    "authors": [
      "Nathan Leroux",
      "Danijela Markovi\u0107",
      "D\u00e9dalo Sanz-Hern\u00e1ndez",
      "Juan Trastoy",
      "Paolo Bortolotti",
      "Alejandro Schulman",
      "Luana Benetti",
      "Alex Jenkins",
      "Ricardo Ferreira",
      "Julie Grollier",
      "Alice Mizrahi"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2211.01189",
    "title": "Inference and Denoise: Causal Inference-based Neural Speech Enhancement",
    "abstract": "This study addresses the speech enhancement (SE) task within the causal inference paradigm by modeling the noise presence as an intervention. Based on the potential outcome framework, the proposed causal inference-based speech enhancement (CISE) separates clean and noisy frames in an intervened noisy speech using a noise detector and assigns both sets of frames to two mask-based enhancement modules (EMs) to perform noise-conditional SE. Specifically, we use the presence of noise as guidance for EM selection during training, and the noise detector selects the enhancement module according to the prediction of the presence of noise for each frame. Moreover, we derived a SE-specific average treatment effect to quantify the causal effect adequately. Experimental evidence demonstrates that CISE outperforms a non-causal mask-based SE approach in the studied settings and has better performance and efficiency than more complex SE models. ",
    "url": "https://arxiv.org/abs/2211.01189",
    "authors": [
      "Tsun-An Hsieh",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen",
      "Sabato Marco Siniscalchi",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.01287",
    "title": "Evaluating Impact of Social Media Posts by Executives on Stock Prices",
    "abstract": "Predicting stock market movements has always been of great interest to investors and an active area of research. Research has proven that popularity of products is highly influenced by what people talk about. Social media like Twitter, Reddit have become hotspots of such influences. This paper investigates the impact of social media posts on close price prediction of stocks using Twitter and Reddit posts. Our objective is to integrate sentiment of social media data with historical stock data and study its effect on closing prices using time series models. We carried out rigorous experiments and deep analysis using multiple deep learning based models on different datasets to study the influence of posts by executives and general people on the close price. Experimental results on multiple stocks (Apple and Tesla) and decentralised currencies (Bitcoin and Ethereum) consistently show improvements in prediction on including social media data and greater improvements on including executive posts. ",
    "url": "https://arxiv.org/abs/2211.01287",
    "authors": [
      "Anubhav Sarkar",
      "Swagata Chakraborty",
      "Sohom Ghosh",
      "Sudip Kumar Naskar"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2009.09756",
    "title": "Demand Prediction Using Machine Learning Methods and Stacked  Generalization",
    "abstract": " Comments: Proceedings of the 6th International Conference on Data Science, Technology and Applications ",
    "url": "https://arxiv.org/abs/2009.09756",
    "authors": [
      "Resul Tugay",
      "Sule Gunduz Oguducu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.09694",
    "title": "Data Assimilation Networks",
    "abstract": " Title: Data Assimilation Networks ",
    "url": "https://arxiv.org/abs/2010.09694",
    "authors": [
      "Pierre Boudier",
      "Anthony Fillion",
      "Serge Gratton",
      "Selime G\u00fcrol",
      "Sixin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2103.08109",
    "title": "Boundary Proposal Network for Two-Stage Natural Language Video  Localization",
    "abstract": " Comments: AAAI 2021 ",
    "url": "https://arxiv.org/abs/2103.08109",
    "authors": [
      "Shaoning Xiao",
      "Long Chen",
      "Songyang Zhang",
      "Wei Ji",
      "Jian Shao",
      "Lu Ye",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.06176",
    "title": "COVID-19 detection using chest X-rays: is lung segmentation important  for generalization?",
    "abstract": " Comments: Text and figure improvements. Results did not change. Included DOI and reference to the published article (Research on Biomedical Engineering, Springer). Link for the published paper: this https URL ",
    "url": "https://arxiv.org/abs/2104.06176",
    "authors": [
      "Pedro R. A. S. Bassi",
      "Romis Attux"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.07014",
    "title": "Robust Beamforming Design for Rate Splitting Multiple Access-Aided MISO  Visible Light Communications",
    "abstract": " Title: Robust Beamforming Design for Rate Splitting Multiple Access-Aided MISO  Visible Light Communications ",
    "url": "https://arxiv.org/abs/2108.07014",
    "authors": [
      "Shuai Ma",
      "Guanjie Zhang",
      "Zhi Zhang",
      "Rongyan Gu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.06308",
    "title": "Improving Scheduled Sampling with Elastic Weight Consolidation for  Neural Machine Translation",
    "abstract": " Title: Improving Scheduled Sampling with Elastic Weight Consolidation for  Neural Machine Translation ",
    "url": "https://arxiv.org/abs/2109.06308",
    "authors": [
      "Michalis Korakakis",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.04629",
    "title": "The Neural Testbed: Evaluating Joint Predictions",
    "abstract": " Title: The Neural Testbed: Evaluating Joint Predictions ",
    "url": "https://arxiv.org/abs/2110.04629",
    "authors": [
      "Ian Osband",
      "Zheng Wen",
      "Seyed Mohammad Asghari",
      "Vikranth Dwaracherla",
      "Botao Hao",
      "Morteza Ibrahimi",
      "Dieterich Lawson",
      "Xiuyuan Lu",
      "Brendan O'Donoghue",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.15221",
    "title": "rustworkx: A High-Performance Graph Library for Python",
    "abstract": " Title: rustworkx: A High-Performance Graph Library for Python ",
    "url": "https://arxiv.org/abs/2110.15221",
    "authors": [
      "Matthew Treinish",
      "Ivan Carvalho",
      "Georgios Tsilimigkounakis",
      "Nahum S\u00e1"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2111.02673",
    "title": "Recurrent Neural Network Training with Convex Loss and Regularization  Functions by Extended Kalman Filtering",
    "abstract": " Comments: 21 pages, 3 figures, submitted for publication ",
    "url": "https://arxiv.org/abs/2111.02673",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2111.09902",
    "title": "A transformer-based model for default prediction in mid-cap corporate  markets",
    "abstract": " Comments: to be published in the European Journal of Operational Research ",
    "url": "https://arxiv.org/abs/2111.09902",
    "authors": [
      "Kamesh Korangi",
      "Christophe Mues",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.10552",
    "title": "Relational hyperevent models for polyadic interaction networks",
    "abstract": " Title: Relational hyperevent models for polyadic interaction networks ",
    "url": "https://arxiv.org/abs/2112.10552",
    "authors": [
      "J\u00fcrgen Lerner",
      "Alessandro Lomi"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.01134",
    "title": "Network Collaborator: Knowledge Transfer Between Network Reconstruction  and Community Detection",
    "abstract": " Comments: This work has been submitted to the IEEE Transactions on Emerging Topics in Computational Intelligence for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2201.01134",
    "authors": [
      "Kai Wu",
      "Chao Wang",
      "Junyuan Chen",
      "Jing Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.12498",
    "title": "Diffeomorphic Image Registration with Neural Velocity Field",
    "abstract": " Comments: WACV 2023 ",
    "url": "https://arxiv.org/abs/2202.12498",
    "authors": [
      "Kun Han",
      "Shanlin sun",
      "Xiangyi Yan",
      "Chenyu You",
      "Hao Tang",
      "Junayed Naushad",
      "Haoyu Ma",
      "Deying Kong",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.12993",
    "title": "Projective Ranking-based GNN Evasion Attacks",
    "abstract": " Comments: Accepted by IEEE Transactions on Knowledge and Data Engineering ",
    "url": "https://arxiv.org/abs/2202.12993",
    "authors": [
      "He Zhang",
      "Xingliang Yuan",
      "Chuan Zhou",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00281",
    "title": "Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for  Grammar Induction and Text Representation",
    "abstract": " Comments: EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2203.00281",
    "authors": [
      "Xiang Hu",
      "Haitao Mi",
      "Liang Li",
      "Gerard de Melo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.01978",
    "title": "Region-of-Interest Based Neural Video Compression",
    "abstract": " Comments: Updated arxiv version to the camera-ready version after acceptance at British Machine Vision Conference (BMVC) 2022 ",
    "url": "https://arxiv.org/abs/2203.01978",
    "authors": [
      "Yura Perugachi-Diaz",
      "Guillaume Sauti\u00e8re",
      "Davide Abati",
      "Yang Yang",
      "Amirhossein Habibian",
      "Taco S Cohen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03342",
    "title": "High-Resolution Peak Demand Estimation Using Generalized Additive Models  and Deep Neural Networks",
    "abstract": " Title: High-Resolution Peak Demand Estimation Using Generalized Additive Models  and Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2203.03342",
    "authors": [
      "Jonathan Berrisch",
      "Micha\u0142 Narajewski",
      "Florian Ziel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.04774",
    "title": "Tailored vertex ordering for faster triangle listing in large graphs",
    "abstract": " Comments: 11 pages, 4 figures. Open-source C++ code available at: this https URL ",
    "url": "https://arxiv.org/abs/2203.04774",
    "authors": [
      "Fabrice L\u00e9cuyer",
      "Louis Jachiet",
      "Cl\u00e9mence Magnien",
      "Lionel Tabourier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.16965",
    "title": "PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech  Representations",
    "abstract": " Comments: IEEE SLT 2022 ",
    "url": "https://arxiv.org/abs/2203.16965",
    "authors": [
      "Lodagala V S V Durga Prasad",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.17159",
    "title": "Preventing Over-Smoothing for Hypergraph Neural Networks",
    "abstract": " Title: Preventing Over-Smoothing for Hypergraph Neural Networks ",
    "url": "https://arxiv.org/abs/2203.17159",
    "authors": [
      "Guanzi Chen",
      "Jiying Zhang",
      "Xi Xiao",
      "Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03297",
    "title": "A Multi-Transformation Evolutionary Framework for Influence Maximization  in Social Networks",
    "abstract": " Comments: This work has been submitted to the IEEE Computational Intelligence Magazine for publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2204.03297",
    "authors": [
      "Chao Wang",
      "Jiaxuan Zhao",
      "Lingling Li",
      "Licheng Jiao",
      "Jing Liu",
      "Kai Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.05486",
    "title": "Neural Graph Matching for Modification Similarity Applied to Electronic  Document Comparison",
    "abstract": " Title: Neural Graph Matching for Modification Similarity Applied to Electronic  Document Comparison ",
    "url": "https://arxiv.org/abs/2204.05486",
    "authors": [
      "Po-Fang Hsu",
      "Chiching Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.11641",
    "title": "Cryptography Is Not Enough: Relay Attacks on Authenticated GNSS Signals",
    "abstract": " Title: Cryptography Is Not Enough: Relay Attacks on Authenticated GNSS Signals ",
    "url": "https://arxiv.org/abs/2204.11641",
    "authors": [
      "Maryam Motallebighomi",
      "Harshad Sathaye",
      "Mridula Singh",
      "Aanjhan Ranganathan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.10129",
    "title": "Topology-aware Graph Neural Networks for Learning Feasible and Adaptive  ac-OPF Solutions",
    "abstract": " Title: Topology-aware Graph Neural Networks for Learning Feasible and Adaptive  ac-OPF Solutions ",
    "url": "https://arxiv.org/abs/2205.10129",
    "authors": [
      "Shaohui Liu",
      "Chengyang Wu",
      "Hao Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.13790",
    "title": "BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework",
    "abstract": " Comments: NerIPS 2022 camera ready ",
    "url": "https://arxiv.org/abs/2205.13790",
    "authors": [
      "Tingting Liang",
      "Hongwei Xie",
      "Kaicheng Yu",
      "Zhongyu Xia",
      "Zhiwei Lin",
      "Yongtao Wang",
      "Tao Tang",
      "Bing Wang",
      "Zhi Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00006",
    "title": "COIN: Co-Cluster Infomax for Bipartite Graphs",
    "abstract": " Comments: NeurIPS 2022 GLFrontiers Workshop ",
    "url": "https://arxiv.org/abs/2206.00006",
    "authors": [
      "Baoyu Jing",
      "Yuchen Yan",
      "Yada Zhu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00373",
    "title": "A Flexible and Robust Vision Trap for Automated Part Feeder Design",
    "abstract": " Comments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022) ",
    "url": "https://arxiv.org/abs/2206.00373",
    "authors": [
      "Rasmus Laurvig Haugaard",
      "Thorbj\u00f8rn Mosekj\u00e6r Iversen",
      "Anders Glent Buch",
      "Aljaz Kramberger",
      "Simon Faarvang Mathiesen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.01163",
    "title": "Invertible Neural Networks for Graph Prediction",
    "abstract": " Title: Invertible Neural Networks for Graph Prediction ",
    "url": "https://arxiv.org/abs/2206.01163",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01178",
    "title": "Approximate Discretization Invariance for Deep Learning on Neural Fields",
    "abstract": " Comments: Presented at NeurIPS 2022 Symmetry and Geometry in Neural Representations (NeurReps) Workshop ",
    "url": "https://arxiv.org/abs/2206.01178",
    "authors": [
      "Clinton J. Wang",
      "Polina Golland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.02660",
    "title": "Port-Hamiltonian Neural Networks with State-Dependent Ports",
    "abstract": " Comments: 21 pages, 12 figures; v3: restructured the paper for more clarity, major changes to the text, updated plots ",
    "url": "https://arxiv.org/abs/2206.02660",
    "authors": [
      "S\u00f8lve Eidnes",
      "Alexander J. Stasik",
      "Camilla Sterud",
      "Eivind B\u00f8hn",
      "Signe Riemer-S\u00f8rensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.04497",
    "title": "One-shot Neural Backdoor Erasing via Adversarial Weight Masking",
    "abstract": " Comments: Accepted by NeurIPS 2022 (19 pages, 6 figures, 10 tables) ",
    "url": "https://arxiv.org/abs/2207.04497",
    "authors": [
      "Shuwen Chai",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.06010",
    "title": "Does GNN Pretraining Help Molecular Representation?",
    "abstract": " Title: Does GNN Pretraining Help Molecular Representation? ",
    "url": "https://arxiv.org/abs/2207.06010",
    "authors": [
      "Ruoxi Sun",
      "Hanjun Dai",
      "Adams Wei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2207.06874",
    "title": "Kernelization for Graph Packing Problems via Rainbow Matching",
    "abstract": " Comments: Accepted to SODA 2023 ",
    "url": "https://arxiv.org/abs/2207.06874",
    "authors": [
      "St\u00e9phane Bessy",
      "Marin Bougeret",
      "Dimitrios M. Thilikos",
      "Sebastian Wiederrecht"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2208.00627",
    "title": "A Rotation Meanout Network with Invariance for Dermoscopy Image  Classification and Retrieval",
    "abstract": " Title: A Rotation Meanout Network with Invariance for Dermoscopy Image  Classification and Retrieval ",
    "url": "https://arxiv.org/abs/2208.00627",
    "authors": [
      "Yilan Zhang",
      "Fengying Xie",
      "Xuedong Song",
      "Hangning Zhou",
      "Yiguang Yang",
      "Haopeng Zhang",
      "Jie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00671",
    "title": "RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports",
    "abstract": " Title: RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports ",
    "url": "https://arxiv.org/abs/2208.00671",
    "authors": [
      "Jiang Wu",
      "Dongyu Liu",
      "Ziyang Guo",
      "Yingcai Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2209.00721",
    "title": "Generalizing intrusion detection for heterogeneous networks: A  stacked-unsupervised federated learning approach",
    "abstract": " Comments: Preprint (Under revision), 32 pages. Added repository link, see this https URL ",
    "url": "https://arxiv.org/abs/2209.00721",
    "authors": [
      "Gustavo de Carvalho Bertoli",
      "Louren\u00e7o Alves Pereira Junior",
      "Aldri Luiz dos Santos",
      "Osamu Saotome"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.03625",
    "title": "Application of image-to-image translation in improving pedestrian  detection",
    "abstract": " Comments: This is a working draft and not indented for publication ",
    "url": "https://arxiv.org/abs/2209.03625",
    "authors": [
      "Devarsh Patel",
      "Sarthak Patel",
      "Megh Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15007",
    "title": "Understanding Collapse in Non-Contrastive Siamese Representation  Learning",
    "abstract": " Comments: Published at ECCV 2022. Project page at this https URL ",
    "url": "https://arxiv.org/abs/2209.15007",
    "authors": [
      "Alexander C. Li",
      "Alexei A. Efros",
      "Deepak Pathak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.02592",
    "title": "CCC-wav2vec 2.0: Clustering aided Cross Contrastive Self-supervised  learning of speech representations",
    "abstract": " Comments: IEEE SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.02592",
    "authors": [
      "Vasista Sai Lodagala",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.03064",
    "title": "A Toolkit for Robust Thresholds",
    "abstract": " Comments: 38 pages ",
    "url": "https://arxiv.org/abs/2210.03064",
    "authors": [
      "Huy Tuan Pham",
      "Ashwin Sah",
      "Mehtaab Sawhney",
      "Michael Simkin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2210.03739",
    "title": "Dual-Stage Deeply Supervised Attention-based Convolutional Neural  Networks for Mandibular Canal Segmentation in CBCT Scans",
    "abstract": " Comments: 7 Pages ",
    "url": "https://arxiv.org/abs/2210.03739",
    "authors": [
      "Azka Rehman",
      "Muhammad Usman",
      "Rabeea Jawaid",
      "Amal Muhammad Saleem",
      "Shi Sub Byon",
      "Sung Hyun Kim",
      "Byoung Dai Lee",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13012",
    "title": "CMU-Net: A Strong ConvMixer-based Medical Ultrasound Image Segmentation  Network",
    "abstract": " Comments: 5 pages, 13 figures, conference ",
    "url": "https://arxiv.org/abs/2210.13012",
    "authors": [
      "Fenghe Tang",
      "Lingtao Wang",
      "Chunping Ning",
      "Min Xian",
      "Jianrui Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13263",
    "title": "Driver Locations Harvesting Attack on pRide",
    "abstract": " Title: Driver Locations Harvesting Attack on pRide ",
    "url": "https://arxiv.org/abs/2210.13263",
    "authors": [
      "Shyam Murthy",
      "Srinivas Vivek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.13856",
    "title": "A Framework for Collaborative Multi-Robot Mapping using Spectral Graph  Wavelets",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2203.00308 ",
    "url": "https://arxiv.org/abs/2210.13856",
    "authors": [
      "Lukas Bernreiter",
      "Shehryar Khattak",
      "Lionel Ott",
      "Roland Siegwart",
      "Marco Hutter",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.14044",
    "title": "SeismicNet: Physics-informed neural networks for seismic wave modeling  in semi-infinite domain",
    "abstract": " Comments: 22 pages ",
    "url": "https://arxiv.org/abs/2210.14044",
    "authors": [
      "Pu Ren",
      "Chengping Rao",
      "Su Chen",
      "Jian-Xun Wang",
      "Hao Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14169",
    "title": "Weakly Supervised Data Augmentation Through Prompting for Dialogue  Understanding",
    "abstract": " Comments: To appear in SyntheticData4ML @ NeurIPS 2022. 16 pages, 10 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2210.14169",
    "authors": [
      "Maximillian Chen",
      "Alexandros Papangelis",
      "Chenyang Tao",
      "Andy Rosenbaum",
      "Seokhwan Kim",
      "Yang Liu",
      "Zhou Yu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14431",
    "title": "$N$-gram is Back: Residual Learning of Neural Text Generation with  $n$-gram Language Model",
    "abstract": " Comments: Accepted to findings of EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.14431",
    "authors": [
      "Huayang Li",
      "Deng Cai",
      "Jin Xu",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14880",
    "title": "Integrated Sensing and Communication in Distributed Antenna Networks",
    "abstract": " Comments: 18 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2210.14880",
    "authors": [
      "Dongfang Xu",
      "Ata Khalili",
      "Xianghao Yu",
      "Derrick Wing Kwan Ng",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.15058",
    "title": "Tangent Bundle Filters and Neural Networks: from Manifolds to Cellular  Sheaves and Back",
    "abstract": " Title: Tangent Bundle Filters and Neural Networks: from Manifolds to Cellular  Sheaves and Back ",
    "url": "https://arxiv.org/abs/2210.15058",
    "authors": [
      "Claudio Battiloro",
      "Zhiyang Wang",
      "Hans Riess",
      "Paolo Di Lorenzo",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15315",
    "title": "Noise in the Clouds: Influence of Network Performance Variability on  Application Scalability",
    "abstract": " Comments: To appear in SIGMETRICS 2023 ",
    "url": "https://arxiv.org/abs/2210.15315",
    "authors": [
      "Daniele De Sensi",
      "Tiziano De Matteis",
      "Konstantin Taranov",
      "Salvatore Di Girolamo",
      "Tobias Rahn",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2210.15366",
    "title": "Multi-dimensional Edge-based Audio Event Relational Graph Representation  Learning for Acoustic Scene Classification",
    "abstract": " Title: Multi-dimensional Edge-based Audio Event Relational Graph Representation  Learning for Acoustic Scene Classification ",
    "url": "https://arxiv.org/abs/2210.15366",
    "authors": [
      "Yuanbo Hou",
      "Siyang Song",
      "Chuang Yu",
      "Yuxin Song",
      "Wenwu Wang",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.16173",
    "title": "Deep Learning Object Detection Approaches to Signal Identification",
    "abstract": " Title: Deep Learning Object Detection Approaches to Signal Identification ",
    "url": "https://arxiv.org/abs/2210.16173",
    "authors": [
      "Luke Wood",
      "Kevin Anderson",
      "Peter Gerstoft",
      "Richard Bell",
      "Raghab Subbaraman",
      "Dinesh Bharadia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.16371",
    "title": "Distributed Black-box Attack against Image Classification Cloud Services",
    "abstract": " Comments: 10 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2210.16371",
    "authors": [
      "Han Wu",
      "Sareh Rowlands",
      "Johan Wahlstrom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16441",
    "title": "GowFed -- A novel Federated Network Intrusion Detection System",
    "abstract": " Comments: 16 pages, 12 figures, currently under review at Journal of Network and Computer Applications (JNCA). arXiv admin note: text overlap with arXiv:2204.12443 ",
    "url": "https://arxiv.org/abs/2210.16441",
    "authors": [
      "Aitor Belenguer",
      "Jose A. Pascual",
      "Javier Navaridas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.17030",
    "title": "Uncertainty Aware Trader-Company Method: Interpretable Stock Price  Prediction Capturing Uncertainty",
    "abstract": " Comments: IEEE BIGDATA 2022 Accepted ",
    "url": "https://arxiv.org/abs/2210.17030",
    "authors": [
      "Yugo Fujimoto",
      "Kei Nakagawa",
      "Kentaro Imajo",
      "Kentaro Minami"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.17349",
    "title": "Robust MelGAN: A robust universal neural vocoder for high-fidelity TTS",
    "abstract": " Comments: Accepted by ISCSLP 2022 ",
    "url": "https://arxiv.org/abs/2210.17349",
    "authors": [
      "Kun Song",
      "Jian Cong",
      "Xinsheng Wang",
      "Yongmao Zhang",
      "Lei Xie",
      "Ning Jiang",
      "Haiying Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00222",
    "title": "SDMuse: Stochastic Differential Music Editing and Generation via Hybrid  Representation",
    "abstract": " Title: SDMuse: Stochastic Differential Music Editing and Generation via Hybrid  Representation ",
    "url": "https://arxiv.org/abs/2211.00222",
    "authors": [
      "Chen Zhang",
      "Yi Ren",
      "Kejun Zhang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00277",
    "title": "HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly  Detection",
    "abstract": " Title: HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2211.00277",
    "authors": [
      "Jun Zhan",
      "Chengkun Wu",
      "Canqun Yang",
      "Qiucheng Miao",
      "Xiandong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.00385",
    "title": "Behavioral Intention Prediction in Driving Scenes: A Survey",
    "abstract": " Comments: Submitted to IEEE Transactions on Intelligent Transportation Systems ",
    "url": "https://arxiv.org/abs/2211.00385",
    "authors": [
      "Jianwu Fang",
      "Fan Wang",
      "Peining Shen",
      "Zhedong Zheng",
      "Jianru Xue",
      "Tat-seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00565",
    "title": "Revisiting Heterophily in Graph Convolution Networks by Learning  Representations Across Topological and Feature Spaces",
    "abstract": " Comments: Under Review Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2211.00565",
    "authors": [
      "Ashish Tiwari",
      "Sresth Tosniwal",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]