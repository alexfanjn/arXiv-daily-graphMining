[
  {
    "id": "arXiv:2211.00002",
    "title": "A Self-Supervised Approach to Reconstruction in Sparse X-Ray Computed  Tomography",
    "abstract": "Computed tomography has propelled scientific advances in fields from biology to materials science. This technology allows for the elucidation of 3-dimensional internal structure by the attenuation of x-rays through an object at different rotations relative to the beam. By imaging 2-dimensional projections, a 3-dimensional object can be reconstructed through a computational algorithm. Imaging at a greater number of rotation angles allows for improved reconstruction. However, taking more measurements increases the x-ray dose and may cause sample damage. Deep neural networks have been used to transform sparse 2-D projection measurements to a 3-D reconstruction by training on a dataset of known similar objects. However, obtaining high-quality object reconstructions for the training dataset requires high x-ray dose measurements that can destroy or alter the specimen before imaging is complete. This becomes a chicken-and-egg problem: high-quality reconstructions cannot be generated without deep learning, and the deep neural network cannot be learned without the reconstructions. This work develops and validates a self-supervised probabilistic deep learning technique, the physics-informed variational autoencoder, to solve this problem. A dataset consisting solely of sparse projection measurements from each object is used to jointly reconstruct all objects of the set. This approach has the potential to allow visualization of fragile samples with x-ray computed tomography. We release our code for reproducing our results at: https://github.com/vganapati/CT_PVAE . ",
    "url": "https://arxiv.org/abs/2211.00002",
    "authors": [
      "Rey Mendoza",
      "Minh Nguyen",
      "Judith Weng Zhu",
      "Vincent Dumont",
      "Talita Perciano",
      "Juliane Mueller",
      "Vidya Ganapati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2211.00074",
    "title": "IoT-based Efficient Streetlight Controlling, Monitoring and Real-time  Error Detection System in Major Bangladeshi Cities",
    "abstract": "A huge wastage of electricity can be seen in Bangladesh due to improper street light management which leads to an enormous financial loss every year. Many noteworthy works have been done by researchers from different parts of the world in tackling this issue by using the Internet of Things yet very few in Bangladeshi perspective. In this work, we propose an efficient Internet of Things-based integrated streetlight framework that offers cloud-powered monitoring, controlling through light dimming as per external lighting conditions and traffic detection, as well as a fault-detecting system to ensure low power and electricity consumption. We analyzed data from Dhaka North and South City Corporation, Narayanganj City Corporation, and Chattogram City Corporation where our proposed model demonstrates a reduction in energy cost of up to approximately 60 percent more than that of the existing system. ",
    "url": "https://arxiv.org/abs/2211.00074",
    "authors": [
      "A.T.M Mustafa Masud Chowdhury",
      "Jeenat Sultana",
      "Md Sakib Ullah Sourav"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.00080",
    "title": "Denoising neural networks for magnetic resonance spectroscopy",
    "abstract": "In many scientific applications, measured time series are corrupted by noise or distortions. Traditional denoising techniques often fail to recover the signal of interest, particularly when the signal-to-noise ratio is low or when certain assumptions on the signal and noise are violated. In this work, we demonstrate that deep learning-based denoising methods can outperform traditional techniques while exhibiting greater robustness to variation in noise and signal characteristics. Our motivating example is magnetic resonance spectroscopy, in which a primary goal is to detect the presence of short-duration, low-amplitude radio frequency signals that are often obscured by strong interference that can be difficult to separate from the signal using traditional methods. We explore various deep learning architecture choices to capture the inherently complex-valued nature of magnetic resonance signals. On both synthetic and experimental data, we show that our deep learning-based approaches can exceed performance of traditional techniques, providing a powerful new class of methods for analysis of scientific time series data. ",
    "url": "https://arxiv.org/abs/2211.00080",
    "authors": [
      "Natalie Klein",
      "Amber J. Day",
      "Harris Mason",
      "Michael W. Malone",
      "Sinead A. Williamson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.00082",
    "title": "Spatial-Temporal Synchronous Graph Transformer network (STSGT) for  COVID-19 forecasting",
    "abstract": "COVID-19 has become a matter of serious concern over the last few years. It has adversely affected numerous people around the globe and has led to the loss of billions of dollars of business capital. In this paper, we propose a novel Spatial-Temporal Synchronous Graph Transformer network (STSGT) to capture the complex spatial and temporal dependency of the COVID-19 time series data and forecast the future status of an evolving pandemic. The layers of STSGT combine the graph convolution network (GCN) with the self-attention mechanism of transformers on a synchronous spatial-temporal graph to capture the dynamically changing pattern of the COVID time series. The spatial-temporal synchronous graph simultaneously captures the spatial and temporal dependencies between the vertices of the graph at a given and subsequent time-steps, which helps capture the heterogeneity in the time series and improve the forecasting accuracy. Our extensive experiments on two publicly available real-world COVID-19 time series datasets demonstrate that STSGT significantly outperforms state-of-the-art algorithms that were designed for spatial-temporal forecasting tasks. Specifically, on average over a 12-day horizon, we observe a potential improvement of 12.19% and 3.42% in Mean Absolute Error(MAE) over the next best algorithm while forecasting the daily infected and death cases respectively for the 50 states of US and Washington, D.C. Additionally, STSGT also outperformed others when forecasting the daily infected cases at the state level, e.g., for all the counties in the State of Michigan. The code and models are publicly available at https://github.com/soumbane/STSGT. ",
    "url": "https://arxiv.org/abs/2211.00082",
    "authors": [
      "Soumyanil Banerjee",
      "Ming Dong",
      "Weisong Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00091",
    "title": "Road Damages Detection and Classification with YOLOv7",
    "abstract": "Maintaining the roadway infrastructure is one of the essential factors in enabling a safe, economic, and sustainable transportation system. Manual roadway damage data collection is laborious and unsafe for humans to perform. This area is poised to benefit from the rapid advance and diffusion of artificial intelligence technologies. Specifically, deep learning advancements enable the detection of road damages automatically from the collected road images. This work proposes to collect and label road damage data using Google Street View and use YOLOv7 (You Only Look Once version 7) together with coordinate attention and related accuracy fine-tuning techniques such as label smoothing and ensemble method to train deep learning models for automatic road damage detection and classification. The proposed approaches are applied to the Crowdsensing-based Road Damage Detection Challenge (CRDDC2022), IEEE BigData 2022. The results show that the data collection from Google Street View is efficient, and the proposed deep learning approach results in F1 scores of 81.7% on the road damage data collected from the United States using Google Street View and 74.1% on all test images of this dataset. ",
    "url": "https://arxiv.org/abs/2211.00091",
    "authors": [
      "Vung Pham",
      "Du Nguyen",
      "Christopher Donan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00098",
    "title": "Synthetic ID Card Image Generation for Improving Presentation Attack  Detection",
    "abstract": "Currently, it is ever more common to access online services for activities which formerly required physical attendance. From banking operations to visa applications, a significant number of processes have been digitised, especially since the advent of the COVID-19 pandemic, requiring remote biometric authentication of the user. On the downside, some subjects intend to interfere with the normal operation of remote systems for personal profit by using fake identity documents, such as passports and ID cards. Deep learning solutions to detect such frauds have been presented in the literature. However, due to privacy concerns and the sensitive nature of personal identity documents, developing a dataset with the necessary number of examples for training deep neural networks is challenging. This work explores three methods for synthetically generating ID card images to increase the amount of data while training fraud-detection networks. These methods include computer vision algorithms and Generative Adversarial Networks. Our results indicate that databases can be supplemented with synthetic images without any loss in performance for the print/scan Presentation Attack Instrument Species (PAIS) and a loss in performance of 1% for the screen capture PAIS. ",
    "url": "https://arxiv.org/abs/2211.00098",
    "authors": [
      "Daniel Benalcazar",
      "Juan E. Tapia",
      "Sebastian Gonzalez",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.00115",
    "title": "Textless Direct Speech-to-Speech Translation with Discrete Speech  Representation",
    "abstract": "Research on speech-to-speech translation (S2ST) has progressed rapidly in recent years. Many end-to-end systems have been proposed and show advantages over conventional cascade systems, which are often composed of recognition, translation and synthesis sub-systems. However, most of the end-to-end systems still rely on intermediate textual supervision during training, which makes it infeasible to work for languages without written forms. In this work, we propose a novel model, Textless Translatotron, which is based on Translatotron 2, for training an end-to-end direct S2ST model without any textual supervision. Instead of jointly training with an auxiliary task predicting target phonemes as in Translatotron 2, the proposed model uses an auxiliary task predicting discrete speech representations which are obtained from learned or random speech quantizers. When a speech encoder pre-trained with unsupervised speech data is used for both models, the proposed model obtains translation quality nearly on-par with Translatotron 2 on the multilingual CVSS-C corpus as well as the bilingual Fisher Spanish-English corpus. On the latter, it outperforms the prior state-of-the-art textless model by +18.5 BLEU. ",
    "url": "https://arxiv.org/abs/2211.00115",
    "authors": [
      "Xinjian Li",
      "Ye Jia",
      "Chung-Cheng Chiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.00147",
    "title": "A Machine Learning Tutorial for Operational Meteorology, Part II: Neural  Networks and Deep Learning",
    "abstract": "Over the past decade the use of machine learning in meteorology has grown rapidly. Specifically neural networks and deep learning have been being used at an unprecedented rate. In order to fill the dearth of resources covering neural networks with a meteorological lens, this paper discusses machine learning methods in a plain language format that is targeted for the operational meteorolgical community. This is the second paper in a pair that aim to serve as a machine learning resource for meteorologists. While the first paper focused on traditional machine learning methods (e.g., random forest), here a broad spectrum of neural networks and deep learning methods are discussed. Specifically this paper covers perceptrons, artificial neural networks, convolutional neural networks and U-networks. Like the part 1 paper, this manuscript discusses the terms associated with neural networks and their training. Then the manuscript provides some intuition behind every method and concludes by showing each method used in a meteorological example of diagnosing thunderstorms from satellite images (e.g., lightning flashes). This paper is accompanied by an open-source code repository to allow readers to explore neural networks using either the dataset provided (which is used in the paper) or as a template for alternate datasets. ",
    "url": "https://arxiv.org/abs/2211.00147",
    "authors": [
      "Randy J. Chase",
      "David R. Harrison",
      "Gary Lackmann",
      "Amy McGovern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2211.00181",
    "title": "The Numerical Stability of Hyperbolic Representation Learning",
    "abstract": "Given the exponential growth of the volume of the ball w.r.t. its radius, the hyperbolic space is capable of embedding trees with arbitrarily small distortion and hence has received wide attention for representing hierarchical datasets. However, this exponential growth property comes at a price of numerical instability such that training hyperbolic learning models will sometimes lead to catastrophic NaN problems, encountering unrepresentable values in floating point arithmetic. In this work, we carefully analyze the limitation of two popular models for the hyperbolic space, namely, the Poincar\\'e ball and the Lorentz model. We first show that, under the 64 bit arithmetic system, the Poincar\\'e ball has a relatively larger capacity than the Lorentz model for correctly representing points. Then, we theoretically validate the superiority of the Lorentz model over the Poincar\\'e ball from the perspective of optimization. Given the numerical limitations of both models, we identify one Euclidean parametrization of the hyperbolic space which can alleviate these limitations. We further extend this Euclidean parametrization to hyperbolic hyperplanes and exhibits its ability in improving the performance of hyperbolic SVM. ",
    "url": "https://arxiv.org/abs/2211.00181",
    "authors": [
      "Gal Mishne",
      "Zhengchao Wan",
      "Yusu Wang",
      "Sheng Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.00191",
    "title": "Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp  Detection",
    "abstract": "Given point cloud input, the problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. This important problem has many practical applications. Here we propose a novel method and neural network model that enables better grasp success rates relative to what is available in the literature. The method takes standard point cloud data as input and works well with single-view point clouds observed from arbitrary viewing directions. ",
    "url": "https://arxiv.org/abs/2211.00191",
    "authors": [
      "Haojie Huang",
      "Dian Wang",
      "Xupeng Zhu",
      "Robin Walters",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00214",
    "title": "Transfer Learning with Physics-Informed Neural Networks for Efficient  Simulation of Branched Flows",
    "abstract": "Physics-Informed Neural Networks (PINNs) offer a promising approach to solving differential equations and, more generally, to applying deep learning to problems in the physical sciences. We adopt a recently developed transfer learning approach for PINNs and introduce a multi-head model to efficiently obtain accurate solutions to nonlinear systems of ordinary differential equations with random potentials. In particular, we apply the method to simulate stochastic branched flows, a universal phenomenon in random wave dynamics. Finally, we compare the results achieved by feed forward and GAN-based PINNs on two physically relevant transfer learning tasks and show that our methods provide significant computational speedups in comparison to standard PINNs trained from scratch. ",
    "url": "https://arxiv.org/abs/2211.00214",
    "authors": [
      "Rapha\u00ebl Pellegrin",
      "Blake Bullwinkel",
      "Marios Mattheakis",
      "Pavlos Protopapas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.00216",
    "title": "Distributed Graph Neural Network Training: A Survey",
    "abstract": "Graph neural networks (GNNs) are a type of deep learning models that learning over graphs, and have been successfully applied in many domains. Despite the effectiveness of GNNs, it is still challenging for GNNs to efficiently scale to large graphs. As a remedy, distributed computing becomes a promising solution of training large-scale GNNs, since it is able to provide abundant computing resources. However, the dependency of graph structure increases the difficulty of achieving high-efficiency distributed GNN training, which suffers from the massive communication and workload imbalance. In recent years, many efforts have been made on distributed GNN training, and an array of training algorithms and systems have been proposed. Yet, there is a lack of systematic review on the optimization techniques from graph processing to distributed execution. In this survey, we analyze three major challenges in distributed GNN training that are massive feature communication, the loss of model accuracy and workload imbalance. Then we introduce a new taxonomy for the optimization techniques in distributed GNN training that address the above challenges. The new taxonomy classifies existing techniques into four categories that are GNN data partition, GNN batch generation, GNN execution model, and GNN communication protocol.We carefully discuss the techniques in each category. In the end, we summarize existing distributed GNN systems for multi-GPUs, GPU-clusters and CPU-clusters, respectively, and give a discussion about the future direction on scalable GNNs. ",
    "url": "https://arxiv.org/abs/2211.00216",
    "authors": [
      "Yingxia Shao",
      "Hongzheng Li",
      "Xizhi Gu",
      "Hongbo Yin",
      "Yawen Li",
      "Xupeng Miao",
      "Wentao Zhang",
      "Bin Cui",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.00222",
    "title": "SDMuse: Stochastic Differential Music Editing and Generation via Hybrid  Representation",
    "abstract": "While deep generative models have empowered music generation, it remains a challenging and under-explored problem to edit an existing musical piece at fine granularity. In this paper, we propose SDMuse, a unified Stochastic Differential Music editing and generation framework, which can not only compose a whole musical piece from scratch, but also modify existing musical pieces in many ways, such as combination, continuation, inpainting, and style transferring. The proposed SDMuse follows a two-stage pipeline to achieve music generation and editing on top of a hybrid representation including pianoroll and MIDI-event. In particular, SDMuse first generates/edits pianoroll by iteratively denoising through a stochastic differential equation (SDE) based on a diffusion model generative prior, and then refines the generated pianoroll and predicts MIDI-event tokens auto-regressively. We evaluate the generated music of our method on ailabs1k7 pop music dataset in terms of quality and controllability on various music editing and generation tasks. Experimental results demonstrate the effectiveness of our proposed stochastic differential music editing and generation process, as well as the hybrid representations. ",
    "url": "https://arxiv.org/abs/2211.00222",
    "authors": [
      "Chen Zhang",
      "Yi Ren",
      "Kejun Zhang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00225",
    "title": "Additive Schwarz algorithms for neural network approximate solutions",
    "abstract": "Additive Schwarz algorithms are proposed as an iterative procedure for neural network approximate solutions of partial differential equations. Based on the convergence analysis of the additive Schwarz algorithms in a general Hilbert space setting, the convergence of the neural network approximate solutions is analyzed for the one-level and two-level iterative schemes. Numerical results of the proposed methods are presented for test examples. ",
    "url": "https://arxiv.org/abs/2211.00225",
    "authors": [
      "Hee Jun Yang",
      "Hyea Hyun Kim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.00228",
    "title": "Fault diagnosis for three-phase PWM rectifier based on deep feedforward  network with transient synthetic features",
    "abstract": "Three-phase PWM rectifiers are adopted extensively in industry because of their excellent properties and potential advantages. However, while the IGBT has an open-circuit fault, the system does not crash suddenly, the performance will be reduced for instance voltages fluctuation and current harmonics. A fault diagnosis method based on deep feedforward network with transient synthetic features is proposed to reduce the dependence on the fault mathematical models in this paper, which mainly uses the transient phase current to train the deep feedforward network classifier. Firstly, the features of fault phase current are analyzed in this paper. Secondly, the historical fault data after feature synthesis is employed to train the deep feedforward network classifier, and the average fault diagnosis accuracy can reach 97.85% for transient synthetic fault data, the classifier trained by the transient synthetic features obtained more than 1% gain in performance compared with original transient features. Finally, the online fault diagnosis experiments show that the method can accurately locate the fault IGBTs, and the final diagnosis result is determined by multiple groups results, which has the ability to increase the accuracy and reliability of the diagnosis results. (c) 2020 ISA. Published by Elsevier Ltd. All rights reserved. ",
    "url": "https://arxiv.org/abs/2211.00228",
    "authors": [
      "Kou Lei",
      "Liu Chuang",
      "Cai Guo-Wei",
      "Zhang Zhe",
      "Zhou Jia-Ning",
      "Wang Xue-Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00233",
    "title": "Detection of (Hidden) Emotions from Videos using Muscles Movements and  Face Manifold Embedding",
    "abstract": "We provide a new non-invasive, easy-to-scale for large amounts of subjects and a remotely accessible method for (hidden) emotion detection from videos of human faces. Our approach combines face manifold detection for accurate location of the face in the video with local face manifold embedding to create a common domain for the measurements of muscle micro-movements that is invariant to the movement of the subject in the video. In the next step, we employ the Digital Image Speckle Correlation (DISC) and the optical flow algorithm to compute the pattern of micro-movements in the face. The corresponding vector field is mapped back to the original space and superimposed on the original frames of the videos. Hence, the resulting videos include additional information about the direction of the movement of the muscles in the face. We take the publicly available CK++ dataset of visible emotions and add to it videos of the same format but with hidden emotions. We process all the videos using our micro-movement detection and use the results to train a state-of-the-art network for emotions classification from videos -- Frame Attention Network (FAN). Although the original FAN model achieves very high out-of-sample performance on the original CK++ videos, it does not perform so well on hidden emotions videos. The performance improves significantly when the model is trained and tested on videos with the vector fields of muscle movements. Intuitively, the corresponding arrows serve as edges in the image that are easily captured by the convolutions filters in the FAN network. ",
    "url": "https://arxiv.org/abs/2211.00233",
    "authors": [
      "Juni Kim",
      "Zhikang Dong",
      "Eric Guan",
      "Judah Rosenthal",
      "Shi Fu",
      "Miriam Rafailovich",
      "Pawel Polak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00239",
    "title": "ARDIR: Improving Robustness using Knowledge Distillation of Internal  Representation",
    "abstract": "Adversarial training is the most promising method for learning robust models against adversarial examples. A recent study has shown that knowledge distillation between the same architectures is effective in improving the performance of adversarial training. Exploiting knowledge distillation is a new approach to improve adversarial training and has attracted much attention. However, its performance is still insufficient. Therefore, we propose Adversarial Robust Distillation with Internal Representation~(ARDIR) to utilize knowledge distillation even more effectively. In addition to the output of the teacher model, ARDIR uses the internal representation of the teacher model as a label for adversarial training. This enables the student model to be trained with richer, more informative labels. As a result, ARDIR can learn more robust student models. We show that ARDIR outperforms previous methods in our experiments. ",
    "url": "https://arxiv.org/abs/2211.00239",
    "authors": [
      "Tomokatsu Takahashi",
      "Masanori Yamada",
      "Yuuki Yamanaka",
      "Tomoya Yamashita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00241",
    "title": "Adversarial Policies Beat Professional-Level Go AIs",
    "abstract": "We attack the state-of-the-art Go-playing AI system, KataGo, by training an adversarial policy that plays against a frozen KataGo victim. Our attack achieves a >99% win-rate against KataGo without search, and a >50% win-rate when KataGo uses enough search to be near-superhuman. To the best of our knowledge, this is the first successful end-to-end attack against a Go AI playing at the level of a top human professional. Notably, the adversary does not win by learning to play Go better than KataGo -- in fact, the adversary is easily beaten by human amateurs. Instead, the adversary wins by tricking KataGo into ending the game prematurely at a point that is favorable to the adversary. Our results demonstrate that even professional-level AI systems may harbor surprising failure modes. See https://goattack.alignmentfund.org/ for example games. ",
    "url": "https://arxiv.org/abs/2211.00241",
    "authors": [
      "Tony Tong Wang",
      "Adam Gleave",
      "Nora Belrose",
      "Tom Tseng",
      "Joseph Miller",
      "Michael D Dennis",
      "Yawen Duan",
      "Viktor Pogrebniak",
      "Sergey Levine",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.00243",
    "title": "Why Is It Hate Speech? Masked Rationale Prediction for Explainable Hate  Speech Detection",
    "abstract": "In a hate speech detection model, we should consider two critical aspects in addition to detection performance-bias and explainability. Hate speech cannot be identified based solely on the presence of specific words: the model should be able to reason like humans and be explainable. To improve the performance concerning the two aspects, we propose Masked Rationale Prediction (MRP) as an intermediate task. MRP is a task to predict the masked human rationales-snippets of a sentence that are grounds for human judgment-by referring to surrounding tokens combined with their unmasked rationales. As the model learns its reasoning ability based on rationales by MRP, it performs hate speech detection robustly in terms of bias and explainability. The proposed method generally achieves state-of-the-art performance in various metrics, demonstrating its effectiveness for hate speech detection. ",
    "url": "https://arxiv.org/abs/2211.00243",
    "authors": [
      "Jiyun Kim",
      "Byounghan Lee",
      "Kyung-Ah Sohn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.00250",
    "title": "FADO: Feedback-Aware Double COntrolling Network for Emotional Support  Conversation",
    "abstract": "Emotional Support Conversation (ESConv) aims to reduce help-seekers'emotional distress with the supportive strategy and response. It is essential for the supporter to select an appropriate strategy with the feedback of the help-seeker (e.g., emotion change during dialog turns, etc) in ESConv. However, previous methods mainly focus on the dialog history to select the strategy and ignore the help-seeker's feedback, leading to the wrong and user-irrelevant strategy prediction. In addition, these approaches only model the context-to-strategy flow and pay less attention to the strategy-to-context flow that can focus on the strategy-related context for generating the strategy-constrain response. In this paper, we propose a Feedback-Aware Double COntrolling Network (FADO) to make a strategy schedule and generate the supportive response. The core module in FADO consists of a dual-level feedback strategy selector and a double control reader. Specifically, the dual-level feedback strategy selector leverages the turn-level and conversation-level feedback to encourage or penalize strategies. The double control reader constructs the novel strategy-to-context flow for generating the strategy-constrain response. Furthermore, a strategy dictionary is designed to enrich the semantic information of the strategy and improve the quality of strategy-constrain response. Experimental results on ESConv show that the proposed FADO has achieved the state-of-the-art performance in terms of both strategy selection and response generation. Our code is available at https://github/after/reviewing. ",
    "url": "https://arxiv.org/abs/2211.00250",
    "authors": [
      "Wei Peng",
      "Ziyuan Qin",
      "Yue Hu",
      "Yuqiang Xie",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.00255",
    "title": "CARE: Causality Reasoning for Empathetic Responses by Conditional Graph  Generation",
    "abstract": "Recent approaches to empathetic response generation incorporate emotion causalities to enhance comprehension of both the user's feelings and experiences. However, these approaches suffer from two critical issues. First, they only consider causalities between the user's emotion and the user's experiences, and ignore those between the user's experiences. Second, they neglect interdependence among causalities and reason them independently. To solve the above problems, we expect to reason all plausible causalities interdependently and simultaneously, given the user's emotion, dialogue history, and future dialogue content. Then, we infuse these causalities into response generation for empathetic responses. Specifically, we design a new model, i.e., the Conditional Variational Graph Auto-Encoder (CVGAE), for the causality reasoning, and adopt a multi-source attention mechanism in the decoder for the causality infusion. We name the whole framework as CARE, abbreviated for CAusality Reasoning for Empathetic conversation. Experimental results indicate that our method achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2211.00255",
    "authors": [
      "Jiashuo Wang",
      "Yi Cheng",
      "Wenjie Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.00266",
    "title": "Two Low-complexity Efficient Beamformers for IRS-aided Directional  Modulation Networks",
    "abstract": "As an excellent tool for aiding communication, intelligent reflecting surface (IRS) can extend the coverage area, remove blind area, and achieve a dramatic rate improvement. In this paper, we improve the secret rate (SR) performance at directional modulation (DM) networks using IRS. To fully explore the benefits of IRS, two efficient methods are proposed to enhance SR performance. The first approach computes the confidential message (CM) beamforming vector by maximizing the SR, and the signal-to-leakage-noise ratio (SLNR) method is used to optimize the IRS phase shift matrix, which is called Max-SR-SLNR. Here, Eve is maximally interfered by transmiting artificial noise (AN) along the direct path and null-space projection (NSP) on the remaining two channels. To reduce the computational complexity, the CM, AN beamforming and IRS phase shift design are independently designed in the following methods. The CM beamforming vector is constructed based on maximum ratio transmission (MRT) criteria along the channel from Alice-to-IRS, and phase shift matrix of IRS is directly given by phase alignment (PA) method. This method is called MRT-NSP-PA. Simulation results show that the SR performance of the Max-SR-SLNR method outperforms the MRT-NSP-PA method in the cases of small-scale and medium-scale IRSs, and the latter approaches the former as IRS tends to lager-scale. ",
    "url": "https://arxiv.org/abs/2211.00266",
    "authors": [
      "Yeqing Lin",
      "Rongen Dong",
      "Xun Chen",
      "Yue Wu",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00269",
    "title": "Adversarial Training with Complementary Labels: On the Benefit of  Gradually Informative Attacks",
    "abstract": "Adversarial training (AT) with imperfect supervision is significant but receives limited attention. To push AT towards more practical scenarios, we explore a brand new yet challenging setting, i.e., AT with complementary labels (CLs), which specify a class that a data sample does not belong to. However, the direct combination of AT with existing methods for CLs results in consistent failure, but not on a simple baseline of two-stage training. In this paper, we further explore the phenomenon and identify the underlying challenges of AT with CLs as intractable adversarial optimization and low-quality adversarial examples. To address the above problems, we propose a new learning strategy using gradually informative attacks, which consists of two critical components: 1) Warm-up Attack (Warm-up) gently raises the adversarial perturbation budgets to ease the adversarial optimization with CLs; 2) Pseudo-Label Attack (PLA) incorporates the progressively informative model predictions into a corrected complementary loss. Extensive experiments are conducted to demonstrate the effectiveness of our method on a range of benchmarked datasets. The code is publicly available at: https://github.com/RoyalSkye/ATCL. ",
    "url": "https://arxiv.org/abs/2211.00269",
    "authors": [
      "Jianan Zhou",
      "Jianing Zhu",
      "Jingfeng Zhang",
      "Tongliang Liu",
      "Gang Niu",
      "Bo Han",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.00273",
    "title": "ActGraph: Prioritization of Test Cases Based on Deep Neural Network  Activation Graph",
    "abstract": "Widespread applications of deep neural networks (DNNs) benefit from DNN testing to guarantee their quality. In the DNN testing, numerous test cases are fed into the model to explore potential vulnerabilities, but they require expensive manual cost to check the label. Therefore, test case prioritization is proposed to solve the problem of labeling cost, e.g., activation-based and mutation-based prioritization methods. However, most of them suffer from limited scenarios (i.e. high confidence adversarial or false positive cases) and high time complexity. To address these challenges, we propose the concept of the activation graph from the perspective of the spatial relationship of neurons. We observe that the activation graph of cases that triggers the models' misbehavior significantly differs from that of normal cases. Motivated by it, we design a test case prioritization method based on the activation graph, ActGraph, by extracting the high-order node features of the activation graph for prioritization. ActGraph explains the difference between the test cases to solve the problem of scenario limitation. Without mutation operations, ActGraph is easy to implement, leading to lower time complexity. Extensive experiments on three datasets and four models demonstrate that ActGraph has the following key characteristics. (i) Effectiveness and generalizability: ActGraph shows competitive performance in all of the natural, adversarial and mixed scenarios, especially in RAUC-100 improvement (~1.40). (ii) Efficiency: ActGraph does not use complex mutation operations and runs in less time (~1/50) than the state-of-the-art method. ",
    "url": "https://arxiv.org/abs/2211.00273",
    "authors": [
      "Jinyin Chen",
      "Jie Ge",
      "Haibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.00277",
    "title": "HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly  Detection",
    "abstract": "Network or physical attacks on industrial equipment or computer systems may cause massive losses. Therefore, a quick and accurate anomaly detection (AD) based on monitoring data, especially the multivariate time-series (MTS) data, is of great significance. As the key step of anomaly detection for MTS data, learning the relations among different variables has been explored by many approaches. However, most of the existing approaches do not consider the heterogeneity between variables, that is, different types of variables (continuous numerical variables, discrete categorical variables or hybrid variables) may have different and distinctive edge distributions. In this paper, we propose a novel semi-supervised anomaly detection framework based on a heterogeneous feature network (HFN) for MTS, learning heterogeneous structure information from a mass of unlabeled time-series data to improve the accuracy of anomaly detection, and using attention coefficient to provide an explanation for the detected anomalies. Specifically, we first combine the embedding similarity subgraph generated by sensor embedding and feature value similarity subgraph generated by sensor values to construct a time-series heterogeneous graph, which fully utilizes the rich heterogeneous mutual information among variables. Then, a prediction model containing nodes and channel attentions is jointly optimized to obtain better time-series representations. This approach fuses the state-of-the-art technologies of heterogeneous graph structure learning (HGSL) and representation learning. The experiments on four sensor datasets from real-world applications demonstrate that our approach detects the anomalies more accurately than those baseline approaches, thus providing a basis for the rapid positioning of anomalies. ",
    "url": "https://arxiv.org/abs/2211.00277",
    "authors": [
      "Jun Zhan",
      "Chengkun Wu",
      "Canqun Yang",
      "Qiucheng Miao",
      "Xiandong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.00288",
    "title": "Self-supervised Character-to-Character Distillation",
    "abstract": "Handling complicated text images (e.g., irregular structures, low resolution, heavy occlusion, and even illumination), existing supervised text recognition methods are data-hungry. Although these methods employ large-scale synthetic text images to reduce the dependence on annotated real images, the domain gap limits the recognition performance. Therefore, exploring the robust text feature representation on unlabeled real images by self-supervised learning is a good solution. However, existing self-supervised text recognition methods only execute sequence-to-sequence representation learning by roughly splitting the visual features along the horizontal axis, which will damage the character structures. Besides, these sequential-level self-learning methods limit the availability of geometric-based data augmentation, as large-scale geometry augmentation leads to sequence-to-sequence inconsistency. To address the above-mentioned issues, we proposed a novel self-supervised character-to-character distillation method, CCD. Specifically, we delineate the character structures of unlabeled real images by designing a self-supervised character segmentation module, and further apply the segmentation results to build character-level representation learning. CCD differs from prior works in that we propose a character-level pretext task to learn more fine-grained feature representations. Besides, compared with the inflexible augmentations of sequence-to-sequence models, our work satisfies character-to-character representation consistency, across various transformations (e.g., geometry and colour), to generate robust text features in the representative space. Experiments demonstrate that CCD achieves state-of-the-art performance on publicly available text recognition benchmarks. ",
    "url": "https://arxiv.org/abs/2211.00288",
    "authors": [
      "Tongkun Guan",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00294",
    "title": "FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual  Robustness",
    "abstract": "Despite being able to generate fluent and grammatical text, current Seq2Seq summarization models still suffering from the unfaithful generation problem. In this paper, we study the faithfulness of existing systems from a new perspective of factual robustness which is the ability to correctly generate factual information over adversarial unfaithful information. We first measure a model's factual robustness by its success rate to defend against adversarial attacks when generating factual information. The factual robustness analysis on a wide range of current systems shows its good consistency with human judgments on faithfulness. Inspired by these findings, we propose to improve the faithfulness of a model by enhancing its factual robustness. Specifically, we propose a novel training strategy, namely FRSUM, which teaches the model to defend against both explicit adversarial samples and implicit factual adversarial perturbations. Extensive automatic and human evaluation results show that FRSUM consistently improves the faithfulness of various Seq2Seq models, such as T5, BART. ",
    "url": "https://arxiv.org/abs/2211.00294",
    "authors": [
      "Wenhao Wu",
      "Wei Li",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Ziqiang Cao",
      "Sujian Li",
      "Hua Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.00312",
    "title": "HDNet: Hierarchical Dynamic Network for Gait Recognition using  Millimeter-Wave Radar",
    "abstract": "Gait recognition is widely used in diversified practical applications. Currently, the most prevalent approach is to recognize human gait from RGB images, owing to the progress of computer vision technologies. Nevertheless, the perception capability of RGB cameras deteriorates in rough circumstances, and visual surveillance may cause privacy invasion. Due to the robustness and non-invasive feature of millimeter wave (mmWave) radar, radar-based gait recognition has attracted increasing attention in recent years. In this research, we propose a Hierarchical Dynamic Network (HDNet) for gait recognition using mmWave radar. In order to explore more dynamic information, we propose point flow as a novel point clouds descriptor. We also devise a dynamic frame sampling module to promote the efficiency of computation without deteriorating performance noticeably. To prove the superiority of our methods, we perform extensive experiments on two public mmWave radar-based gait recognition datasets, and the results demonstrate that our model is superior to existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2211.00312",
    "authors": [
      "Yanyan Huang",
      "Yong Wang",
      "Kun Shi",
      "Chaojie Gu",
      "Yu Fu",
      "Cheng Zhuo",
      "Zhiguo Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00313",
    "title": "RGMIM: Region-Guided Masked Image Modeling for COVID-19 Detection",
    "abstract": "Self-supervised learning has developed rapidly and also advances computer-aided diagnosis in the medical field. Masked image modeling (MIM) is one of the self-supervised learning methods that masks a portion of input pixels and tries to predict the masked pixels. Traditional MIM methods often use a random masking strategy. However, medical images often have a small region of interest for disease detection compared to ordinary images. For example, the regions outside the lung do not contain the information for decision, which may cause the random masking strategy not to learn enough information for COVID-19 detection. Hence, we propose a novel region-guided masked image modeling method (RGMIM) for COVID-19 detection in this paper. In our method, we design a new masking strategy that uses lung mask information to locate valid regions to learn more helpful information for COVID-19 detection. Experimental results show that RGMIM can outperform other state-of-the-art self-supervised learning methods on an open COVID-19 radiography dataset. ",
    "url": "https://arxiv.org/abs/2211.00313",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.00322",
    "title": "DensePure: Understanding Diffusion Models towards Adversarial Robustness",
    "abstract": "Diffusion models have been recently employed to improve certified robustness through the process of denoising. However, the theoretical understanding of why diffusion models are able to improve the certified robustness is still lacking, preventing from further improvement. In this study, we close this gap by analyzing the fundamental properties of diffusion models and establishing the conditions under which they can enhance certified robustness. This deeper understanding allows us to propose a new method DensePure, designed to improve the certified robustness of a pretrained model (i.e. classifier). Given an (adversarial) input, DensePure consists of multiple runs of denoising via the reverse process of the diffusion model (with different random seeds) to get multiple reversed samples, which are then passed through the classifier, followed by majority voting of inferred labels to make the final prediction. This design of using multiple runs of denoising is informed by our theoretical analysis of the conditional distribution of the reversed sample. Specifically, when the data density of a clean sample is high, its conditional density under the reverse process in a diffusion model is also high; thus sampling from the latter conditional distribution can purify the adversarial example and return the corresponding clean sample with a high probability. By using the highest density point in the conditional distribution as the reversed sample, we identify the robust region of a given instance under the diffusion model's reverse process. We show that this robust region is a union of multiple convex sets, and is potentially much larger than the robust regions identified in previous works. In practice, DensePure can approximate the label of the high density region in the conditional distribution so that it can enhance certified robustness. ",
    "url": "https://arxiv.org/abs/2211.00322",
    "authors": [
      "Chaowei Xiao",
      "Zhongzhu Chen",
      "Kun Jin",
      "Jiongxiao Wang",
      "Weili Nie",
      "Mingyan Liu",
      "Anima Anandkumar",
      "Bo Li",
      "Dawn Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.00332",
    "title": "Computational Power of A Single Oblivious Mobile Agent in  Two-Edge-Connected Graphs",
    "abstract": "We investigate the computational power of a single mobile agent in an $n$-node graph with storage (i.e., node memory). It has been shown that the system with one-bit agent memory and $O(1)$-bit storage is as powerful as the one with $O(n)$-bit agent memory and $O(1)$-bit storage, and thus we focus on the difference between one-bit memory agents and oblivious (i.e. zero-bit memory) agents. While it has been also shown that their computational powers are not equivalent, all the known results exhibiting such a difference rely on the fact that oblivious agents cannot transfer any information from one side to the other side across the bridge edge. Then our main question is stated as follows: Are the computational powers of one-bit memory agents and oblivious agents equivalent in 2-edge-connected graphs or not? The main contribution of this paper is to answer this question positively under the relaxed assumption that each node has $O(\\log\\Delta)$-bit storage ($\\Delta$ is the maximum degree of the graph). We present an algorithm of simulating any algorithm for a single one-bit memory agent by one oblivious agent with $O(n^2)$-time overhead per round. Our result implies that the topological structure of graphs differentiating the computational powers of oblivious and non-oblivious agents is completely characterized by the existence of bridge edges. ",
    "url": "https://arxiv.org/abs/2211.00332",
    "authors": [
      "Taichi Inoue",
      "Naoki Kitamura",
      "Taisuke Izumi",
      "Toshimitsu Masuzawa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.00342",
    "title": "Investigating Content-Aware Neural Text-To-Speech MOS Prediction Using  Prosodic and Linguistic Features",
    "abstract": "Current state-of-the-art methods for automatic synthetic speech evaluation are based on MOS prediction neural models. Such MOS prediction models include MOSNet and LDNet that use spectral features as input, and SSL-MOS that relies on a pretrained self-supervised learning model that directly uses the speech signal as input. In modern high-quality neural TTS systems, prosodic appropriateness with regard to the spoken content is a decisive factor for speech naturalness. For this reason, we propose to include prosodic and linguistic features as additional inputs in MOS prediction systems, and evaluate their impact on the prediction outcome. We consider phoneme level F0 and duration features as prosodic inputs, as well as Tacotron encoder outputs, POS tags and BERT embeddings as higher-level linguistic inputs. All MOS prediction systems are trained on SOMOS, a neural TTS-only dataset with crowdsourced naturalness MOS evaluations. Results show that the proposed additional features are beneficial in the MOS prediction task, by improving the predicted MOS scores' correlation with the ground truths, both at utterance-level and system-level predictions. ",
    "url": "https://arxiv.org/abs/2211.00342",
    "authors": [
      "Alexandra Vioni",
      "Georgia Maniati",
      "Nikolaos Ellinas",
      "June Sig Sung",
      "Inchul Hwang",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00347",
    "title": "Carbon Footprints on Inter-Domain Paths: Uncovering CO2 Tracks on Global  Networks",
    "abstract": "In the years after signing the Paris agreement, corporations have been experiencing increasing pressure to monitor and reduce their carbon footprint. Nevertheless, the information and communication technology sector lacks an effective tool for monitoring and optimizing the carbon footprint of data transmissions over the public Internet. In this work, we propose a carbon-footprint transparency system based on a path-aware Internet architecture that enables endpoints to monitor the carbon footprint of their inter-domain communications, and optimize it through carbon-aware path selection. Furthermore, we show by means of simulations that in a realistic inter-domain topology, 85% of traffic sources could reduce the carbon footprint of their outbound inter-domain traffic by at least 50% through carbon-aware path selection. ",
    "url": "https://arxiv.org/abs/2211.00347",
    "authors": [
      "Seyedali Tabaeiaghdaei",
      "Simon Scherrer",
      "Adrian Perrig"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.00348",
    "title": "Informed Priors for Knowledge Integration in Trajectory Prediction",
    "abstract": "Informed machine learning methods allow the integration of prior knowledge into learning systems. This can increase accuracy and robustness or reduce data needs. However, existing methods often assume hard constraining knowledge, that does not require to trade-off prior knowledge with observations, but can be used to directly reduce the problem space. Other approaches use specific, architectural changes as representation of prior knowledge, limiting applicability. We propose an informed machine learning method, based on continual learning. This allows the integration of arbitrary, prior knowledge, potentially from multiple sources, and does not require specific architectures. Furthermore, our approach enables probabilistic and multi-modal predictions, that can improve predictive accuracy and robustness. We exemplify our approach by applying it to a state-of-the-art trajectory predictor for autonomous driving. This domain is especially dependent on informed learning approaches, as it is subject to an overwhelming large variety of possible environments and very rare events, while requiring robust and accurate predictions. We evaluate our model on a commonly used benchmark dataset, only using data already available in a conventional setup. We show that our method outperforms both non-informed and informed learning methods, that are often used in the literature. Furthermore, we are able to compete with a conventional baseline, even using half as many observation examples. ",
    "url": "https://arxiv.org/abs/2211.00348",
    "authors": [
      "Christian Schlauch",
      "Nadja Klein",
      "Christian Wirth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.00366",
    "title": "Universal Perturbation Attack on Differentiable No-Reference Image- and  Video-Quality Metrics",
    "abstract": "Universal adversarial perturbation attacks are widely used to analyze image classifiers that employ convolutional neural networks. Nowadays, some attacks can deceive image- and video-quality metrics. So sustainability analysis of these metrics is important. Indeed, if an attack can confuse the metric, an attacker can easily increase quality scores. When developers of image- and video-algorithms can boost their scores through detached processing, algorithm comparisons are no longer fair. Inspired by the idea of universal adversarial perturbation for classifiers, we suggest a new method to attack differentiable no-reference quality metrics through universal perturbation. We applied this method to seven no-reference image- and video-quality metrics (PaQ-2-PiQ, Linearity, VSFA, MDTVSFA, KonCept512, Nima and SPAQ). For each one, we trained a universal perturbation that increases the respective scores. We also propose a method for assessing metric stability and identify the metrics that are the most vulnerable and the most resistant to our attack. The existence of successful universal perturbations appears to diminish the metric's ability to provide reliable scores. We therefore recommend our proposed method as an additional verification of metric reliability to complement traditional subjective tests and benchmarks. ",
    "url": "https://arxiv.org/abs/2211.00366",
    "authors": [
      "Ekaterina Shumitskaya",
      "Anastasia Antsiferova",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.00372",
    "title": "Meta-Learning for Unsupervised Outlier Detection with Optimal Transport",
    "abstract": "Automated machine learning has been widely researched and adopted in the field of supervised classification and regression, but progress in unsupervised settings has been limited. We propose a novel approach to automate outlier detection based on meta-learning from previous datasets with outliers. Our premise is that the selection of the optimal outlier detection technique depends on the inherent properties of the data distribution. We leverage optimal transport in particular, to find the dataset with the most similar underlying distribution, and then apply the outlier detection techniques that proved to work best for that data distribution. We evaluate the robustness of our approach and find that it outperforms the state of the art methods in unsupervised outlier detection. This approach can also be easily generalized to automate other unsupervised settings. ",
    "url": "https://arxiv.org/abs/2211.00372",
    "authors": [
      "Prabhant Singh",
      "Joaquin Vanschoren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00381",
    "title": "LinkFormer: Automatic Contextualised Link Recovery of Software Artifacts  in both Project-based and Transfer Learning Settings",
    "abstract": "Software artifacts often interact with each other throughout the software development cycle. Associating related artifacts is a common practice for effective documentation and maintenance of software projects. Conventionally, to register the link between an issue report and its associated commit, developers manually include the issue identifier in the message of the relevant commit. Research has shown that developers tend to forget to connect said artifacts manually, resulting in a loss of links. Hence, several link recovery techniques were proposed to discover and revive such links automatically. However, the literature mainly focuses on improving the prediction accuracy on a randomly-split test set, while neglecting other important aspects of this problem, including the effect of time and generalizability of the predictive models. In this paper, we propose LinkFormer to address this problem from three aspects; 1) Accuracy: To better utilize contextual information for prediction, we employ the Transformer architecture and fine-tune multiple pre-trained models on textual and metadata of issues and commits. 2) Data leakage: To empirically assess the impact of time through the splitting policy, we train and test our proposed model along with several existing approaches on both randomly- and temporally split data. 3) Generalizability: To provide a generic model that can perform well across different projects, we further fine-tune LinkFormer in two transfer learning settings. We empirically show that researchers should preserve the temporal flow of data when training learning-based models to resemble the real-world setting. In addition, LinkFormer significantly outperforms the state-of-the-art by large margins. LinkFormer is also capable of extending the knowledge it learned to unseen projects with little to no historical data. ",
    "url": "https://arxiv.org/abs/2211.00381",
    "authors": [
      "Maliheh Izadi",
      "Pooya Rostami Mazrae",
      "Tom Mens",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00384",
    "title": "The future is different: Large pre-trained language models fail in  prediction tasks",
    "abstract": "Large pre-trained language models (LPLM) have shown spectacular success when fine-tuned on downstream supervised tasks. Yet, it is known that their performance can drastically drop when there is a distribution shift between the data used during training and that used at inference time. In this paper we focus on data distributions that naturally change over time and introduce four new REDDIT datasets, namely the WALLSTREETBETS, ASKSCIENCE, THE DONALD, and POLITICS sub-reddits. First, we empirically demonstrate that LPLM can display average performance drops of about 88% (in the best case!) when predicting the popularity of future posts from sub-reddits whose topic distribution changes with time. We then introduce a simple methodology that leverages neural variational dynamic topic models and attention mechanisms to infer temporal language model representations for regression tasks. Our models display performance drops of only about 40% in the worst cases (2% in the best ones) when predicting the popularity of future posts, while using only about 7% of the total number of parameters of LPLM and providing interpretable representations that offer insight into real-world events, like the GameStop short squeeze of 2021 ",
    "url": "https://arxiv.org/abs/2211.00384",
    "authors": [
      "Kostadin Cvejoski",
      "Rams\u00e9s J. S\u00e1nchez",
      "C\u00e9sar Ojeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.00385",
    "title": "Behavioral Intention Prediction in Driving Scenes: A Survey",
    "abstract": "In the driving scene, the road participants usually show frequent interaction and intention understanding with the surrounding. Ego-agent (each road participant itself) conducts the prediction of what behavior will be done by other road users all the time and expects a shared and consistent understanding. For instance, we need to predict the next movement of other road users and expect a consistent joint action to avoid unexpected accident. Behavioral Intention Prediction (BIP) is to simulate such a human consideration process and fulfill the beginning time prediction of specific behaviors. It provides an earlier signal promptly than the specific behaviors for whether the surrounding road participants will present specific behavior (crossing, overtaking, and turning, etc.) in near future or not. More and more works in BIP are based on deep learning models to take advantage of big data, and focus on developing effective inference approaches (e.g., explainable inference, cross-modality fusion, and simulation augmentation). Therefore, in this work, we focus on BIP-conditioned prediction tasks, including trajectory prediction, behavior prediction, and accident prediction and explore the differences among various works in this field. Based on this investigation and the findings, we discuss the open problems in behavioral intention prediction and propose future research directions. ",
    "url": "https://arxiv.org/abs/2211.00385",
    "authors": [
      "Jianwu Fang",
      "Fan Wang",
      "Peining Shen",
      "Zhedong Zheng",
      "Jianru Xue",
      "Tat-seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00387",
    "title": "Reasoning on Property Graphs with Graph Generating Dependencies",
    "abstract": "Graph Generating Dependencies (GGDs) informally express constraints between two (possibly different) graph patterns which enforce relationships on both graph's data (via property value constraints) and its structure (via topological constraints). Graph Generating Dependencies (GGDs) can express tuple- and equality-generating dependencies on property graphs, both of which find broad application in graph data management. In this paper, we discuss the reasoning behind GGDs. We propose algorithms to solve the satisfiability, implication, and validation problems for GGDs and analyze their complexity. To demonstrate the practical use of GGDs, we propose an algorithm which finds inconsistencies in data through validation of GGDs. Our experiments show that even though the validation of GGDs has high computational complexity, GGDs can be used to find data inconsistencies in a feasible execution time on both synthetic and real-world data. ",
    "url": "https://arxiv.org/abs/2211.00387",
    "authors": [
      "Larissa C. Shimomura",
      "Nikolay Yakovets",
      "George Fletcher"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2211.00396",
    "title": "Wavelet Neural Networks versus Wavelet-based Neural Networks",
    "abstract": "This is the first paper in a sequence of studies in which we introduce a new type of neural networks (NNs) -- wavelet-based neural networks (WBNNs) -- and study their properties and potential for applications. We begin this study with a comparison to the currently existing type of wavelet neural networks (WNNs) and show that WBNNs vastly outperform WNNs. One reason for the vast superiority of WBNNs is their advanced hierarchical tree structure based on biorthonormal multiresolution analysis (MRA). Another reason for this is the implementation of our new idea to incorporate the wavelet tree depth into the neural width of the NN. The separation of the roles of wavelet depth and neural depth provides a conceptually and algorithmically simple but highly efficient methodology for sharp increase in functionality of swarm and deep WBNNs and rapid acceleration of the machine learning process. ",
    "url": "https://arxiv.org/abs/2211.00396",
    "authors": [
      "Lubomir T. Dechevsky",
      "Kristoffer M. Tangrand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00421",
    "title": "Order-sensitive Neural Constituency Parsing",
    "abstract": "We propose a novel algorithm that improves on the previous neural span-based CKY decoder for constituency parsing. In contrast to the traditional span-based decoding, where spans are combined only based on the sum of their scores, we introduce an order-sensitive strategy, where the span combination scores are more carefully derived from an order-sensitive basis. Our decoder can be regarded as a generalization over existing span-based decoder in determining a finer-grain scoring scheme for the combination of lower-level spans into higher-level spans, where we emphasize on the order of the lower-level spans and use order-sensitive span scores as well as order-sensitive combination grammar rule scores to enhance prediction accuracy. We implement the proposed decoding strategy harnessing GPU parallelism and achieve a decoding speed on par with state-of-the-art span-based parsers. Using the previous state-of-the-art model without additional data as our baseline, we outperform it and improve the F1 score on the Penn Treebank Dataset by 0.26% and on the Chinese Treebank Dataset by 0.35%. ",
    "url": "https://arxiv.org/abs/2211.00421",
    "authors": [
      "Zhicheng Wang",
      "Tianyu Shi",
      "Liyin Xiao",
      "Cong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00441",
    "title": "Zero Day Threat Detection Using Metric Learning Autoencoders",
    "abstract": "The proliferation of zero-day threats (ZDTs) to companies' networks has been immensely costly and requires novel methods to scan traffic for malicious behavior at massive scale. The diverse nature of normal behavior along with the huge landscape of attack types makes deep learning methods an attractive option for their ability to capture highly-nonlinear behavior patterns. In this paper, the authors demonstrate an improvement upon a previously introduced methodology, which used a dual-autoencoder approach to identify ZDTs in network flow telemetry. In addition to the previously-introduced asset-level graph features, which help abstractly represent the role of a host in its network, this new model uses metric learning to train the second autoencoder on labeled attack data. This not only produces stronger performance, but it has the added advantage of improving the interpretability of the model by allowing for multiclass classification in the latent space. This can potentially save human threat hunters time when they investigate predicted ZDTs by showing them which known attack classes were nearby in the latent space. The models presented here are also trained and evaluated with two more datasets, and continue to show promising results even when generalizing to new network topologies. ",
    "url": "https://arxiv.org/abs/2211.00441",
    "authors": [
      "Dhruv Nandakumar",
      "Robert Schiller",
      "Christopher Redino",
      "Kevin Choi",
      "Abdul Rahman",
      "Edward Bowen",
      "Marc Vucovich",
      "Joe Nehila",
      "Matthew Weeks",
      "Aaron Shaha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00448",
    "title": "Signing Outside the Studio: Benchmarking Background Robustness for  Continuous Sign Language Recognition",
    "abstract": "The goal of this work is background-robust continuous sign language recognition. Most existing Continuous Sign Language Recognition (CSLR) benchmarks have fixed backgrounds and are filmed in studios with a static monochromatic background. However, signing is not limited only to studios in the real world. In order to analyze the robustness of CSLR models under background shifts, we first evaluate existing state-of-the-art CSLR models on diverse backgrounds. To synthesize the sign videos with a variety of backgrounds, we propose a pipeline to automatically generate a benchmark dataset utilizing existing CSLR benchmarks. Our newly constructed benchmark dataset consists of diverse scenes to simulate a real-world environment. We observe even the most recent CSLR method cannot recognize glosses well on our new dataset with changed backgrounds. In this regard, we also propose a simple yet effective training scheme including (1) background randomization and (2) feature disentanglement for CSLR models. The experimental results on our dataset demonstrate that our method generalizes well to other unseen background data with minimal additional training images. ",
    "url": "https://arxiv.org/abs/2211.00448",
    "authors": [
      "Youngjoon Jang",
      "Youngtaek Oh",
      "Jae Won Cho",
      "Dong-Jin Kim",
      "Joon Son Chung",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00453",
    "title": "The Perils of Learning From Unlabeled Data: Backdoor Attacks on  Semi-supervised Learning",
    "abstract": "Semi-supervised machine learning (SSL) is gaining popularity as it reduces the cost of training ML models. It does so by using very small amounts of (expensive, well-inspected) labeled data and large amounts of (cheap, non-inspected) unlabeled data. SSL has shown comparable or even superior performances compared to conventional fully-supervised ML techniques. In this paper, we show that the key feature of SSL that it can learn from (non-inspected) unlabeled data exposes SSL to strong poisoning attacks. In fact, we argue that, due to its reliance on non-inspected unlabeled data, poisoning is a much more severe problem in SSL than in conventional fully-supervised ML. Specifically, we design a backdoor poisoning attack on SSL that can be conducted by a weak adversary with no knowledge of target SSL pipeline. This is unlike prior poisoning attacks in fully-supervised settings that assume strong adversaries with practically-unrealistic capabilities. We show that by poisoning only 0.2% of the unlabeled training data, our attack can cause misclassification of more than 80% of test inputs (when they contain the adversary's backdoor trigger). Our attacks remain effective across twenty combinations of benchmark datasets and SSL algorithms, and even circumvent the state-of-the-art defenses against backdoor attacks. Our work raises significant concerns about the practical utility of existing SSL algorithms. ",
    "url": "https://arxiv.org/abs/2211.00453",
    "authors": [
      "Virat Shejwalkar",
      "Lingjuan Lyu",
      "Amir Houmansadr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.00463",
    "title": "Amplifying Membership Exposure via Data Poisoning",
    "abstract": "As in-the-wild data are increasingly involved in the training stage, machine learning applications become more susceptible to data poisoning attacks. Such attacks typically lead to test-time accuracy degradation or controlled misprediction. In this paper, we investigate the third type of exploitation of data poisoning - increasing the risks of privacy leakage of benign training samples. To this end, we demonstrate a set of data poisoning attacks to amplify the membership exposure of the targeted class. We first propose a generic dirty-label attack for supervised classification algorithms. We then propose an optimization-based clean-label attack in the transfer learning scenario, whereby the poisoning samples are correctly labeled and look \"natural\" to evade human moderation. We extensively evaluate our attacks on computer vision benchmarks. Our results show that the proposed attacks can substantially increase the membership inference precision with minimum overall test-time model performance degradation. To mitigate the potential negative impacts of our attacks, we also investigate feasible countermeasures. ",
    "url": "https://arxiv.org/abs/2211.00463",
    "authors": [
      "Yufei Chen",
      "Chao Shen",
      "Yun Shen",
      "Cong Wang",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.00486",
    "title": "Causal DAG extraction from a library of books or videos/movies",
    "abstract": "Determining a causal DAG (directed acyclic graph) for a problem under consideration, is a major roadblock when doing Judea Pearl's Causal Inference (CI) in Statistics. The same problem arises when doing CI in Artificial Intelligence (AI) and Machine Learning (ML). As with many problems in Science, we think Nature has found an effective solution to this problem. We argue that human and animal brains contain an explicit engine for doing CI, and that such an engine uses as input an atlas (i.e., collection) of causal DAGs. We propose a simple algorithm for constructing such an atlas from a library of books or videos/movies. We illustrate our method by applying it to a database of randomly generated Tic-Tac-Toe games. The software used to generate this Tic-Tac-Toe example is open source and available at GitHub. ",
    "url": "https://arxiv.org/abs/2211.00486",
    "authors": [
      "Robert R. Tucci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00495",
    "title": "Efficient Graph Neural Network Inference at Large Scale",
    "abstract": "Graph neural networks (GNNs) have demonstrated excellent performance in a wide range of applications. However, the enormous size of large-scale graphs hinders their applications under real-time inference scenarios. Although existing scalable GNNs leverage linear propagation to preprocess the features and accelerate the training and inference procedure, these methods still suffer from scalability issues when making inferences on unseen nodes, as the feature preprocessing requires the graph is known and fixed. To speed up the inference in the inductive setting, we propose a novel adaptive propagation order approach that generates the personalized propagation order for each node based on its topological information. This could successfully avoid the redundant computation of feature propagation. Moreover, the trade-off between accuracy and inference latency can be flexibly controlled by simple hyper-parameters to match different latency constraints of application scenarios. To compensate for the potential inference accuracy loss, we further propose Inception Distillation to exploit the multi scale reception information and improve the inference performance. Extensive experiments are conducted on four public datasets with different scales and characteristics, and the experimental results show that our proposed inference acceleration framework outperforms the SOTA graph inference acceleration baselines in terms of both accuracy and efficiency. In particular, the advantage of our proposed method is more significant on larger-scale datasets, and our framework achieves $75\\times$ inference speedup on the largest Ogbn-products dataset. ",
    "url": "https://arxiv.org/abs/2211.00495",
    "authors": [
      "Xinyi Gao",
      "Wentao Zhang",
      "Yingxia Shao",
      "Quoc Viet Hung Nguyen",
      "Bin Cui",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00509",
    "title": "Self-Supervised Intensity-Event Stereo Matching",
    "abstract": "Event cameras are novel bio-inspired vision sensors that output pixel-level intensity changes in microsecond accuracy with a high dynamic range and low power consumption. Despite these advantages, event cameras cannot be directly applied to computational imaging tasks due to the inability to obtain high-quality intensity and events simultaneously. This paper aims to connect a standalone event camera and a modern intensity camera so that the applications can take advantage of both two sensors. We establish this connection through a multi-modal stereo matching task. We first convert events to a reconstructed image and extend the existing stereo networks to this multi-modality condition. We propose a self-supervised method to train the multi-modal stereo network without using ground truth disparity data. The structure loss calculated on image gradients is used to enable self-supervised learning on such multi-modal data. Exploiting the internal stereo constraint between views with different modalities, we introduce general stereo loss functions, including disparity cross-consistency loss and internal disparity loss, leading to improved performance and robustness compared to existing approaches. The experiments demonstrate the effectiveness of the proposed method, especially the proposed general stereo loss functions, on both synthetic and real datasets. At last, we shed light on employing the aligned events and intensity images in downstream tasks, e.g., video interpolation application. ",
    "url": "https://arxiv.org/abs/2211.00509",
    "authors": [
      "Jinjin Gu",
      "Jinan Zhou",
      "Ringo Sai Wo Chu",
      "Yan Chen",
      "Jiawei Zhang",
      "Xuanye Cheng",
      "Song Zhang",
      "Jimmy S. Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00514",
    "title": "MDC Enhanced IoT Networks: Network Modeling and Performance Analysis",
    "abstract": "As a promising architecture, Mobile Data Collector (MDC) enhanced Internet of Things (IoT) exhibits broad prospects in efficient data collection and data aggregation especially for sparse deployment scenarios. Combining the tools from queueing theory and stochastic geometry, we propose an analytical framework to study the network performance of an MDC enhanced IoT network, in terms of coverage probability, end-to-end delay and energy consumption. We derive the closed-form expressions for average contact and inter-contact time between a sensor and its associated MDC. By modeling the data collection system between a sensor and its associated MDCs as an M/G/1 queue system with vacations and general limited (G-limited) service, we first derive the queueing delay at the tagged sensor, and further obtain the end-to-end delay. The proposed analytical framework enables us to quantify the effect on network performance of key system parameters, such as MDC velocity, packet arrival rate, densities of sensors and MDCs, and contact radius. This study reveals that the MDC velocity has little impact on the coverage probability, and provides guidelines to minimize the end-to-end delay by optimizing the density and contact radius of sensors, and the velocity and density of MDCs. ",
    "url": "https://arxiv.org/abs/2211.00514",
    "authors": [
      "Hongguang Sun",
      "Yajun Ma",
      "Tony Q. S. Quek",
      "Xijun Wang",
      "Kun Guo",
      "Hongming Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.00519",
    "title": "Learning Neural Implicit Representations with Surface Signal  Parameterizations",
    "abstract": "Neural implicit surface representations have recently emerged as popular alternative to explicit 3D object encodings, such as polygonal meshes, tabulated points, or voxels. While significant work has improved the geometric fidelity of these representations, much less attention is given to their final appearance. Traditional explicit object representations commonly couple the 3D shape data with auxiliary surface-mapped image data, such as diffuse color textures and fine-scale geometric details in normal maps that typically require a mapping of the 3D surface onto a plane, i.e., a surface parameterization; implicit representations, on the other hand, cannot be easily textured due to lack of configurable surface parameterization. Inspired by this digital content authoring methodology, we design a neural network architecture that implicitly encodes the underlying surface parameterization suitable for appearance data. As such, our model remains compatible with existing mesh-based digital content with appearance data. Motivated by recent work that overfits compact networks to individual 3D objects, we present a new weight-encoded neural implicit representation that extends the capability of neural implicit surfaces to enable various common and important applications of texture mapping. Our method outperforms reasonable baselines and state-of-the-art alternatives. ",
    "url": "https://arxiv.org/abs/2211.00519",
    "authors": [
      "Yanran Guan",
      "Andrei Chubarau",
      "Ruby Rao",
      "Derek Nowrouzezahrai"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00523",
    "title": "Learning utterance-level representations through token-level acoustic  latents prediction for Expressive Speech Synthesis",
    "abstract": "This paper proposes an Expressive Speech Synthesis model that utilizes token-level latent prosodic variables in order to capture and control utterance-level attributes, such as character acting voice and speaking style. Current works aim to explicitly factorize such fine-grained and utterance-level speech attributes into different representations extracted by modules that operate in the corresponding level. We show that the fine-grained latent space also captures coarse-grained information, which is more evident as the dimension of latent space increases in order to capture diverse prosodic representations. Therefore, a trade-off arises between the diversity of the token-level and utterance-level representations and their disentanglement. We alleviate this issue by first capturing rich speech attributes into a token-level latent space and then, separately train a prior network that given the input text, learns utterance-level representations in order to predict the phoneme-level, posterior latents extracted during the previous step. Both qualitative and quantitative evaluations are used to demonstrate the effectiveness of the proposed approach. Audio samples are available in our demo page. ",
    "url": "https://arxiv.org/abs/2211.00523",
    "authors": [
      "Karolos Nikitaras",
      "Konstantinos Klapsas",
      "Nikolaos Ellinas",
      "Georgia Maniati",
      "June Sig Sung",
      "Inchul Hwang",
      "Spyros Raptis",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00525",
    "title": "The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for  Improving Adversarial Training",
    "abstract": "Although current deep learning techniques have yielded superior performance on various computer vision tasks, yet they are still vulnerable to adversarial examples. Adversarial training and its variants have been shown to be the most effective approaches to defend against adversarial examples. These methods usually regularize the difference between output probabilities for an adversarial and its corresponding natural example. However, it may have a negative impact if the model misclassifies a natural example. To circumvent this issue, we propose a novel adversarial training scheme that encourages the model to produce similar outputs for an adversarial example and its ``inverse adversarial'' counterpart. These samples are generated to maximize the likelihood in the neighborhood of natural examples. Extensive experiments on various vision datasets and architectures demonstrate that our training method achieves state-of-the-art robustness as well as natural accuracy. Furthermore, using a universal version of inverse adversarial examples, we improve the performance of single-step adversarial training techniques at a low computational cost. ",
    "url": "https://arxiv.org/abs/2211.00525",
    "authors": [
      "Junhao Dong",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Jianhuang Lai",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00526",
    "title": "Leveraging Graph-based Cross-modal Information Fusion for Neural Sign  Language Translation",
    "abstract": "Sign Language (SL), as the mother tongue of the deaf community, is a special visual language that most hearing people cannot understand. In recent years, neural Sign Language Translation (SLT), as a possible way for bridging communication gap between the deaf and the hearing people, has attracted widespread academic attention. We found that the current mainstream end-to-end neural SLT models, which tries to learning language knowledge in a weakly supervised manner, could not mine enough semantic information under the condition of low data resources. Therefore, we propose to introduce additional word-level semantic knowledge of sign language linguistics to assist in improving current end-to-end neural SLT models. Concretely, we propose a novel neural SLT model with multi-modal feature fusion based on the dynamic graph, in which the cross-modal information, i.e. text and video, is first assembled as a dynamic graph according to their correlation, and then the graph is processed by a multi-modal graph encoder to generate the multi-modal embeddings for further usage in the subsequent neural translation models. To the best of our knowledge, we are the first to introduce graph neural networks, for fusing multi-modal information, into neural sign language translation models. Moreover, we conducted experiments on a publicly available popular SLT dataset RWTH-PHOENIX-Weather-2014T. and the quantitative experiments show that our method can improve the model. ",
    "url": "https://arxiv.org/abs/2211.00526",
    "authors": [
      "Jiangbin Zheng",
      "Siyuan Li",
      "Cheng Tan",
      "Chong Wu",
      "Yidong Chen",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00533",
    "title": "Optimal Complexity in Non-Convex Decentralized Learning over  Time-Varying Networks",
    "abstract": "Decentralized optimization with time-varying networks is an emerging paradigm in machine learning. It saves remarkable communication overhead in large-scale deep training and is more robust in wireless scenarios especially when nodes are moving. Federated learning can also be regarded as decentralized optimization with time-varying communication patterns alternating between global averaging and local updates. While numerous studies exist to clarify its theoretical limits and develop efficient algorithms, it remains unclear what the optimal complexity is for non-convex decentralized stochastic optimization over time-varying networks. The main difficulties lie in how to gauge the effectiveness when transmitting messages between two nodes via time-varying communications, and how to establish the lower bound when the network size is fixed (which is a prerequisite in stochastic optimization). This paper resolves these challenges and establish the first lower bound complexity. We also develop a new decentralized algorithm to nearly attain the lower bound, showing the tightness of the lower bound and the optimality of our algorithm. ",
    "url": "https://arxiv.org/abs/2211.00533",
    "authors": [
      "Xinmeng Huang",
      "Kun Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.00543",
    "title": "Geo-Information Harvesting from Social Media Data",
    "abstract": "As unconventional sources of geo-information, massive imagery and text messages from open platforms and social media form a temporally quasi-seamless, spatially multi-perspective stream, but with unknown and diverse quality. Due to its complementarity to remote sensing data, geo-information from these sources offers promising perspectives, but harvesting is not trivial due to its data characteristics. In this article, we address key aspects in the field, including data availability, analysis-ready data preparation and data management, geo-information extraction from social media text messages and images, and the fusion of social media and remote sensing data. We then showcase some exemplary geographic applications. In addition, we present the first extensive discussion of ethical considerations of social media data in the context of geo-information harvesting and geographic applications. With this effort, we wish to stimulate curiosity and lay the groundwork for researchers who intend to explore social media data for geo-applications. We encourage the community to join forces by sharing their code and data. ",
    "url": "https://arxiv.org/abs/2211.00543",
    "authors": [
      "Xiao Xiang Zhu",
      "Yuanyuan Wang",
      "Mrinalini Kochupillai",
      "Martin Werner",
      "Matthias H\u00e4berle",
      "Eike Jens Hoffmann",
      "Hannes Taubenb\u00f6ck",
      "Devis Tuia",
      "Alex Levering",
      "Nathan Jacobs",
      "Anna Kruspe",
      "Karam Abdulahhad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00549",
    "title": "No-audio speaking status detection in crowded settings via visual  pose-based filtering and wearable acceleration",
    "abstract": "Recognizing who is speaking in a crowded scene is a key challenge towards the understanding of the social interactions going on within. Detecting speaking status from body movement alone opens the door for the analysis of social scenes in which personal audio is not obtainable. Video and wearable sensors make it possible recognize speaking in an unobtrusive, privacy-preserving way. When considering the video modality, in action recognition problems, a bounding box is traditionally used to localize and segment out the target subject, to then recognize the action taking place within it. However, cross-contamination, occlusion, and the articulated nature of the human body, make this approach challenging in a crowded scene. Here, we leverage articulated body poses for subject localization and in the subsequent speech detection stage. We show that the selection of local features around pose keypoints has a positive effect on generalization performance while also significantly reducing the number of local features considered, making for a more efficient method. Using two in-the-wild datasets with different viewpoints of subjects, we investigate the role of cross-contamination in this effect. We additionally make use of acceleration measured through wearable sensors for the same task, and present a multimodal approach combining both methods. ",
    "url": "https://arxiv.org/abs/2211.00549",
    "authors": [
      "Jose Vargas-Quiros",
      "Laura Cabrera-Quiros",
      "Hayley Hung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00550",
    "title": "GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous  Graphs",
    "abstract": "In graph learning, there have been two predominant inductive biases regarding graph-inspired architectures: On the one hand, higher-order interactions and message passing work well on homophilous graphs and are leveraged by GCNs and GATs. Such architectures, however, cannot easily scale to large real-world graphs. On the other hand, shallow (or node-level) models using ego features and adjacency embeddings work well in heterophilous graphs. In this work, we propose a novel scalable shallow method -- GLINKX -- that can work both on homophilous and heterophilous graphs. GLINKX leverages (i) novel monophilous label propagations, (ii) ego/node features, (iii) knowledge graph embeddings as positional embeddings, (iv) node-level training, and (v) low-dimensional message passing. Formally, we prove novel error bounds and justify the components of GLINKX. Experimentally, we show its effectiveness on several homophilous and heterophilous datasets. ",
    "url": "https://arxiv.org/abs/2211.00550",
    "authors": [
      "Marios Papachristou",
      "Rishab Goel",
      "Frank Portman",
      "Matthew Miller",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.00565",
    "title": "Revisiting Heterophily in Graph Convolution Networks by Learning  Representations Across Topological and Feature Spaces",
    "abstract": "Graph convolution networks (GCNs) have been enormously successful in learning representations over several graph-based machine learning tasks. Specific to learning rich node representations, most of the methods have solely relied on the homophily assumption and have shown limited performance on the heterophilous graphs. While several methods have been developed with new architectures to address heterophily, we argue that by learning graph representations across two spaces i.e., topology and feature space GCNs can address heterophily. In this work, we experimentally demonstrate the performance of the proposed GCN framework over semi-supervised node classification task on both homophilous and heterophilous graph benchmarks by learning and combining representations across the topological and the feature spaces. ",
    "url": "https://arxiv.org/abs/2211.00565",
    "authors": [
      "Ashish Tiwari",
      "Sresth Tosniwal",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00572",
    "title": "Position-Aware Subgraph Neural Networks with Data-Efficient Learning",
    "abstract": "Data-efficient learning on graphs (GEL) is essential in real-world applications. Existing GEL methods focus on learning useful representations for nodes, edges, or entire graphs with ``small'' labeled data. But the problem of data-efficient learning for subgraph prediction has not been explored. The challenges of this problem lie in the following aspects: 1) It is crucial for subgraphs to learn positional features to acquire structural information in the base graph in which they exist. Although the existing subgraph neural network method is capable of learning disentangled position encodings, the overall computational complexity is very high. 2) Prevailing graph augmentation methods for GEL, including rule-based, sample-based, adaptive, and automated methods, are not suitable for augmenting subgraphs because a subgraph contains fewer nodes but richer information such as position, neighbor, and structure. Subgraph augmentation is more susceptible to undesirable perturbations. 3) Only a small number of nodes in the base graph are contained in subgraphs, which leads to a potential ``bias'' problem that the subgraph representation learning is dominated by these ``hot'' nodes. By contrast, the remaining nodes fail to be fully learned, which reduces the generalization ability of subgraph representation learning. In this paper, we aim to address the challenges above and propose a Position-Aware Data-Efficient Learning framework for subgraph neural networks called PADEL. Specifically, we propose a novel node position encoding method that is anchor-free, and design a new generative subgraph augmentation method based on a diffused variational subgraph autoencoder, and we propose exploratory and exploitable views for subgraph contrastive learning. Extensive experiment results on three real-world datasets show the superiority of our proposed method over state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2211.00572",
    "authors": [
      "Chang Liu",
      "Yuwen Yang",
      "Zhe Xie",
      "Hongtao Lu",
      "Yue Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00582",
    "title": "ClassActionPrediction: A Challenging Benchmark for Legal Judgment  Prediction of Class Action Cases in the US",
    "abstract": "The research field of Legal Natural Language Processing (NLP) has been very active recently, with Legal Judgment Prediction (LJP) becoming one of the most extensively studied tasks. To date, most publicly released LJP datasets originate from countries with civil law. In this work, we release, for the first time, a challenging LJP dataset focused on class action cases in the US. It is the first dataset in the common law system that focuses on the harder and more realistic task involving the complaints as input instead of the often used facts summary written by the court. Additionally, we study the difficulty of the task by collecting expert human predictions, showing that even human experts can only reach 53% accuracy on this dataset. Our Longformer model clearly outperforms the human baseline (63%), despite only considering the first 2,048 tokens. Furthermore, we perform a detailed error analysis and find that the Longformer model is significantly better calibrated than the human experts. Finally, we publicly release the dataset and the code used for the experiments. ",
    "url": "https://arxiv.org/abs/2211.00582",
    "authors": [
      "Gil Semo",
      "Dor Bernsohn",
      "Ben Hagag",
      "Gila Hayat",
      "Joel Niklaus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.00586",
    "title": "T5lephone: Bridging Speech and Text Self-supervised Models for Spoken  Language Understanding via Phoneme level T5",
    "abstract": "In Spoken language understanding (SLU), a natural solution is concatenating pre-trained speech models (e.g. HuBERT) and pretrained language models (PLM, e.g. T5). Most previous works use pretrained language models with subword-based tokenization. However, the granularity of input units affects the alignment of speech model outputs and language model inputs, and PLM with character-based tokenization is underexplored. In this work, we conduct extensive studies on how PLMs with different tokenization strategies affect spoken language understanding task including spoken question answering (SQA) and speech translation (ST). We further extend the idea to create T5lephone(pronounced as telephone), a variant of T5 that is pretrained using phonemicized text. We initialize T5lephone with existing PLMs to pretrain it using relatively lightweight computational resources. We reached state-of-the-art on NMSQA, and the T5lephone model exceeds T5 with other types of units on end-to-end SQA and ST. ",
    "url": "https://arxiv.org/abs/2211.00586",
    "authors": [
      "Chan-Jan Hsu",
      "Ho-Lam Chung",
      "Hung-yi Lee",
      "Yu Tsao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.00608",
    "title": "ReachLipBnB: A branch-and-bound method for reachability analysis of  neural autonomous systems using Lipschitz bounds",
    "abstract": "We propose a novel Branch-and-Bound method for reachability analysis of neural networks in both open-loop and closed-loop settings. Our idea is to first compute accurate bounds on the Lipschitz constant of the neural network in certain directions of interest offline using a convex program. We then use these bounds to obtain an instantaneous but conservative polyhedral approximation of the reachable set using Lipschitz continuity arguments. To reduce conservatism, we incorporate our bounding algorithm within a branching strategy to decrease the over-approximation error within an arbitrary accuracy. We then extend our method to reachability analysis of control systems with neural network controllers. Finally, to capture the shape of the reachable sets as accurately as possible, we use sample trajectories to inform the directions of the reachable set over-approximations using Principal Component Analysis (PCA). We evaluate the performance of the proposed method in several open-loop and closed-loop settings. ",
    "url": "https://arxiv.org/abs/2211.00608",
    "authors": [
      "Taha Entesari",
      "Sina Sharifi",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.00609",
    "title": "A Simple, Yet Effective Approach to Finding Biases in Code Generation",
    "abstract": "Recently, scores of high-performing code generation systems have surfaced. As has become a popular choice in many domains, code generation is often approached using large language models as a core, trained under the masked or causal language modeling schema. This work shows that current code generation systems exhibit biases inherited from large language model backbones, which might leak into generated code under specific circumstances. To investigate the effect, we propose a framework that automatically removes hints and exposes various biases that these code generation models use. We apply our framework to three coding challenges and test it across top-performing coding generation models. Our experiments reveal biases towards specific prompt structure and exploitation of keywords during code generation. Finally, we demonstrate how to use our framework as a data transformation technique, which we find a promising direction toward more robust code generation. ",
    "url": "https://arxiv.org/abs/2211.00609",
    "authors": [
      "Spyridon Mouselinos",
      "Mateusz Malinowski",
      "Henryk Michalewski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2211.00610",
    "title": "Fast Staircase Detection and Estimation using 3D Point Clouds with  Multi-detection Merging for Heterogeneous Robots",
    "abstract": "Robotic systems need advanced mobility capabilities to operate in complex, three-dimensional environments designed for human use, e.g., multi-level buildings. Incorporating some level of autonomy enables robots to operate robustly, reliably, and efficiently in such complex environments, e.g., automatically ``returning home'' if communication between an operator and robot is lost during deployment. This work presents a novel method that enables mobile robots to robustly operate in multi-level environments by making it possible to autonomously locate and climb a range of different staircases. We present results wherein a wheeled robot works together with a quadrupedal system to quickly detect different staircases and reliably climb them. The performance of this novel staircase detection algorithm that is able to run on the heterogeneous platforms is compared to the current state-of-the-art detection algorithm. We show that our approach significantly increases the accuracy and speed at which detections occur. ",
    "url": "https://arxiv.org/abs/2211.00610",
    "authors": [
      "Prasanna Sriganesh",
      "Namya Bagree",
      "Bhaskar Vundurthy",
      "Matthew Travers"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.00619",
    "title": "Asymmetric Hashing for Fast Ranking via Neural Network Measures",
    "abstract": "Fast item ranking is an important task in recommender systems. In previous works, graph-based Approximate Nearest Neighbor (ANN) approaches have demonstrated good performance on item ranking tasks with generic searching/matching measures (including complex measures such as neural network measures). However, since these ANN approaches must go through the neural measures several times during ranking, the computation is not practical if the neural measure is a large network. On the other hand, fast item ranking using existing hashing-based approaches, such as Locality Sensitive Hashing (LSH), only works with a limited set of measures. Previous learning-to-hash approaches are also not suitable to solve the fast item ranking problem since they can take a significant amount of time and computation to train the hash functions. Hashing approaches, however, are attractive because they provide a principle and efficient way to retrieve candidate items. In this paper, we propose a simple and effective learning-to-hash approach for the fast item ranking problem that can be used for any type of measure, including neural network measures. Specifically, we solve this problem with an asymmetric hashing framework based on discrete inner product fitting. We learn a pair of related hash functions that map heterogeneous objects (e.g., users and items) into a common discrete space where the inner product of their binary codes reveals their true similarity defined via the original searching measure. The fast ranking problem is reduced to an ANN search via this asymmetric hashing scheme. Then, we propose a sampling strategy to efficiently select relevant and contrastive samples to train the hashing model. We empirically validate the proposed method against the existing state-of-the-art fast item ranking methods in several combinations of non-linear searching functions and prominent datasets. ",
    "url": "https://arxiv.org/abs/2211.00619",
    "authors": [
      "Khoa Doan",
      "Shulong Tan",
      "Weijie Zhao",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.00639",
    "title": "A General Language for Modeling Social Media Account Behavior",
    "abstract": "Malicious actors exploit social media to inflate stock prices, sway elections, spread misinformation, and sow discord. To these ends, they employ tactics that include the use of inauthentic accounts and campaigns. Methods to detect these abuses currently rely on features specifically designed to target suspicious behaviors. However, the effectiveness of these methods decays as malicious behaviors evolve. To address this challenge, we propose a general language for modeling social media account behavior. Words in this language, called BLOC, consist of symbols drawn from distinct alphabets representing user actions and content. The language is highly flexible and can be applied to model a broad spectrum of legitimate and suspicious online behaviors without extensive fine-tuning. Using BLOC to represent the behaviors of Twitter accounts, we achieve performance comparable to or better than state-of-the-art methods in the detection of social bots and coordinated inauthentic behavior. ",
    "url": "https://arxiv.org/abs/2211.00639",
    "authors": [
      "Alexander C. Nwala",
      "Alessandro Flammini",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.11147",
    "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
    "abstract": "Self-supervised protein language models have proved their effectiveness in learning the proteins representations. With the increasing computational power, current protein language models pre-trained with millions of diverse sequences can advance the parameter scale from million-level to billion-level and achieve remarkable improvement. However, those prevailing approaches rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better protein representations. We argue that informative biology knowledge in KGs can enhance protein representation with external knowledge. In this work, we propose OntoProtein, the first general framework that makes use of structure in GO (Gene Ontology) into protein pre-training models. We construct a novel large-scale knowledge graph that consists of GO and its related proteins, and gene annotation texts or protein sequences describe all nodes in the graph. We propose novel contrastive learning with knowledge-aware negative sampling to jointly optimize the knowledge graph and protein embedding during pre-training. Experimental results show that OntoProtein can surpass state-of-the-art methods with pre-trained protein language models in TAPE benchmark and yield better performance compared with baselines in protein-protein interaction and protein function prediction. Code and datasets are available in https://github.com/zjunlp/OntoProtein. ",
    "url": "https://arxiv.org/abs/2201.11147",
    "authors": [
      "Ningyu Zhang",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Siyuan Cheng",
      "Haosen Hong",
      "Shumin Deng",
      "Jiazhang Lian",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10080",
    "title": "Multi-modal Protein Knowledge Graph Construction and Applications",
    "abstract": "Existing data-centric methods for protein science generally cannot sufficiently capture and leverage biology knowledge, which may be crucial for many protein tasks. To facilitate research in this field, we create ProteinKG65, a knowledge graph for protein science. Using gene ontology and Uniprot knowledge base as a basis, we transform and integrate various kinds of knowledge with aligned descriptions and protein sequences, respectively, to GO terms and protein entities. ProteinKG65 is mainly dedicated to providing a specialized protein knowledge graph, bringing the knowledge of Gene Ontology to protein function and structure prediction. The current version contains about 614,099 entities, 5,620,437 triples (including 5,510,437 protein-go triplets and 110,000 GO-GO triplets). We also illustrate the potential applications of ProteinKG65 with a prototype. Our dataset can be downloaded at https://w3id.org/proteinkg65. ",
    "url": "https://arxiv.org/abs/2207.10080",
    "authors": [
      "Siyuan Cheng",
      "Xiaozhuan Liang",
      "Zhen Bi",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00003",
    "title": "MEDS-Net: Self-Distilled Multi-Encoders Network with Bi-Direction  Maximum Intensity projections for Lung Nodule Detection",
    "abstract": "In this study, we propose a lung nodule detection scheme which fully incorporates the clinic workflow of radiologists. Particularly, we exploit Bi-Directional Maximum intensity projection (MIP) images of various thicknesses (i.e., 3, 5 and 10mm) along with a 3D patch of CT scan, consisting of 10 adjacent slices to feed into self-distillation-based Multi-Encoders Network (MEDS-Net). The proposed architecture first condenses 3D patch input to three channels by using a dense block which consists of dense units which effectively examine the nodule presence from 2D axial slices. This condensed information, along with the forward and backward MIP images, is fed to three different encoders to learn the most meaningful representation, which is forwarded into the decoded block at various levels. At the decoder block, we employ a self-distillation mechanism by connecting the distillation block, which contains five lung nodule detectors. It helps to expedite the convergence and improves the learning ability of the proposed architecture. Finally, the proposed scheme reduces the false positives by complementing the main detector with auxiliary detectors. The proposed scheme has been rigorously evaluated on 888 scans of LUNA16 dataset and obtained a CPM score of 93.6\\%. The results demonstrate that incorporating of bi-direction MIP images enables MEDS-Net to effectively distinguish nodules from surroundings which help to achieve the sensitivity of 91.5% and 92.8% with false positives rate of 0.25 and 0.5 per scan, respectively. ",
    "url": "https://arxiv.org/abs/2211.00003",
    "authors": [
      "Muhammad Usman",
      "Azka Rehman",
      "Abdullah Shahid",
      "Siddique Latif",
      "Shi Sub Byon",
      "Byoung Dai Lee",
      "Sung Hyun Kim",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00004",
    "title": "Classical ensemble of Quantum-classical ML algorithms for Phishing  detection in Ethereum transaction networks",
    "abstract": "Ethereum is one of the most valuable blockchain networks in terms of the total monetary value locked in it, and arguably been the most active network where new blockchain innovations in research and applications are demonstrated. But, this also leads to Ethereum network being susceptible to a wide variety of threats and attacks in an attempt to gain unreasonable advantage or to undermine the value of the users. Even with the state-of-art classical ML algorithms, detecting such attacks is still hard. This motivated us to build a hybrid system of quantum-classical algorithms that improves phishing detection in financial transaction networks. This paper presents a classical ensemble pipeline of classical and quantum algorithms and a detailed study benchmarking existing Quantum Machine Learning algorithms such as Quantum Support Vector Machine and Variational Quantum Classifier. With the current generation of quantum hardware available, smaller datasets are more suited to the QML models and most research restricts to hundreds of samples. However, we experimented on different data sizes and report results with a test data of 12K transaction nodes, which is to the best of the authors knowledge the largest QML experiment run so far on any real quantum hardware. The classical ensembles of quantum-classical models improved the macro F-score and phishing F-score. One key observation is QSVM constantly gives lower false positives, thereby higher precision compared with any other classical or quantum network, which is always preferred for any anomaly detection problem. This is true for QSVMs when used individually or via bagging of same models or in combination with other classical/quantum models making it the most advantageous quantum algorithm so far. The proposed ensemble framework is generic and can be applied for any classification task ",
    "url": "https://arxiv.org/abs/2211.00004",
    "authors": [
      "Anupama Ray",
      "Sai Sakunthala Guddanti",
      "Vishnu Ajith",
      "Dhinakaran Vinayagamurthy"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00024",
    "title": "A robust estimator of mutual information for deep learning  interpretability",
    "abstract": "We develop the use of mutual information (MI), a well-established metric in information theory, to interpret the inner workings of deep learning models. To accurately estimate MI from a finite number of samples, we present GMM-MI (pronounced $``$Jimmie$\"$), an algorithm based on Gaussian mixture models that can be applied to both discrete and continuous settings. GMM-MI is computationally efficient, robust to the choice of hyperparameters and provides the uncertainty on the MI estimate due to the finite sample size. We extensively validate GMM-MI on toy data for which the ground truth MI is known, comparing its performance against established mutual information estimators. We then demonstrate the use of our MI estimator in the context of representation learning, working with synthetic data and physical datasets describing highly non-linear processes. We train deep learning models to encode high-dimensional data within a meaningful compressed (latent) representation, and use GMM-MI to quantify both the level of disentanglement between the latent variables, and their association with relevant physical quantities, thus unlocking the interpretability of the latent representation. We make GMM-MI publicly available. ",
    "url": "https://arxiv.org/abs/2211.00024",
    "authors": [
      "Davide Piras",
      "Hiranya V. Peiris",
      "Andrew Pontzen",
      "Luisa Lucie-Smith",
      "Ningyuan Guo",
      "Brian Nord"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00109",
    "title": "ImagineNET: Target Speaker Extraction with Intermittent Visual Cue  through Embedding Inpainting",
    "abstract": "The speaker extraction technique seeks to single out the voice of a target speaker from the interfering voices in a speech mixture. Typically an auxiliary reference of the target speaker is used to form voluntary attention. Either a pre-recorded utterance or a synchronized lip movement in a video clip can serve as the auxiliary reference. The use of visual cue is not only feasible, but also effective due to its noise robustness, and becoming popular. However, it is difficult to guarantee that such parallel visual cue is always available in real-world applications where visual occlusion or intermittent communication can occur. In this paper, we study the audio-visual speaker extraction algorithms with intermittent visual cue. We propose a joint speaker extraction and visual embedding inpainting framework to explore the mutual benefits. To encourage the interaction between the two tasks, they are performed alternately with an interlacing structure and optimized jointly. We also propose two types of visual inpainting losses and study our proposed method with two types of popularly used visual embeddings. The experimental results show that we outperform the baseline in terms of signal quality, perceptual quality, and intelligibility. ",
    "url": "https://arxiv.org/abs/2211.00109",
    "authors": [
      "Zexu Pan",
      "Wupeng Wang",
      "Marvin Borsdorf",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.00128",
    "title": "SIMPLE-RC: Group Network Inference with Non-Sharp Nulls and Weak Signals",
    "abstract": "Large-scale network inference with uncertainty quantification has important applications in natural, social, and medical sciences. The recent work of Fan, Fan, Han and Lv (2022) introduced a general framework of statistical inference on membership profiles in large networks (SIMPLE) for testing the sharp null hypothesis that a pair of given nodes share the same membership profiles. In real applications, there are often groups of nodes under investigation that may share similar membership profiles at the presence of relatively weaker signals than the setting considered in SIMPLE. To address these practical challenges, in this paper we propose a SIMPLE method with random coupling (SIMPLE-RC) for testing the non-sharp null hypothesis that a group of given nodes share similar (not necessarily identical) membership profiles under weaker signals. Utilizing the idea of random coupling, we construct our test as the maximum of the SIMPLE tests for subsampled node pairs from the group. Such technique reduces significantly the correlation among individual SIMPLE tests while largely maintaining the power, enabling delicate analysis on the asymptotic distributions of the SIMPLE-RC test. Our method and theory cover both the cases with and without node degree heterogeneity. These new theoretical developments are empowered by a second-order expansion of spiked eigenvectors under the $\\ell_\\infty$-norm, built upon our work for random matrices with weak spikes. Our theoretical results and the practical advantages of the newly suggested method are demonstrated through several simulation and real data examples. ",
    "url": "https://arxiv.org/abs/2211.00128",
    "authors": [
      "Jianqing Fan",
      "Yingying Fan",
      "Jinchi Lv",
      "Fan Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.00172",
    "title": "Infusing known operators in convolutional neural networks for lateral  strain imaging in ultrasound elastography",
    "abstract": "Convolutional Neural Networks (CNN) have been employed for displacement estimation in ultrasound elastography (USE). High-quality axial strains (derivative of the axial displacement in the axial direction) can be estimated by the proposed networks. In contrast to axial strain, lateral strain, which is highly required in Poisson's ratio imaging and elasticity reconstruction, has a poor quality. The main causes include low sampling frequency, limited motion, and lack of phase information in the lateral direction. Recently, physically inspired constraint in unsupervised regularized elastography (PICTURE) has been proposed. This method took into account the range of the feasible lateral strain defined by the rules of physics of motion and employed a regularization strategy to improve the lateral strains. Despite the substantial improvement, the regularization was only applied during the training; hence it did not guarantee during the test that the lateral strain is within the feasible range. Furthermore, only the feasible range was employed, other constraints such as incompressibility were not investigated. In this paper, we address these two issues and propose kPICTURE in which two iterative algorithms were infused into the network architecture in the form of known operators to ensure the lateral strain is within the feasible range and impose incompressibility during the test phase. ",
    "url": "https://arxiv.org/abs/2211.00172",
    "authors": [
      "Ali K. Z. Tehrani",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00175",
    "title": "Homodyned K-distribution: parameter estimation and uncertainty  quantification using Bayesian neural networks",
    "abstract": "Quantitative ultrasound (QUS) allows estimating the intrinsic tissue properties. Speckle statistics are the QUS parameters that describe the first order statistics of ultrasound (US) envelope data. The parameters of Homodyned K-distribution (HK-distribution) are the speckle statistics that can model the envelope data in diverse scattering conditions. However, they require a large amount of data to be estimated reliably. Consequently, finding out the intrinsic uncertainty of the estimated parameters can help us to have a better understanding of the estimated parameters. In this paper, we propose a Bayesian Neural Network (BNN) to estimate the parameters of HK-distribution and quantify the uncertainty of the estimator. ",
    "url": "https://arxiv.org/abs/2211.00175",
    "authors": [
      "Ali K. Z. Tehrani",
      "Ivan M. Rosado-Mendez",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.00226",
    "title": "Waveform Boundary Detection for Partially Spoofed Audio",
    "abstract": "The present paper proposes a waveform boundary detection system for audio spoofing attacks containing partially manipulated segments. Partially spoofed/fake audio, where part of the utterance is replaced, either with synthetic or natural audio clips, has recently been reported as one scenario of audio deepfakes. As deepfakes can be a threat to social security, the detection of such spoofing audio is essential. Accordingly, we propose to address the problem with a deep learning-based frame-level detection system that can detect partially spoofed audio and locate the manipulated pieces. Our proposed method is trained and evaluated on data provided by the ADD2022 Challenge. We evaluate our detection model concerning various acoustic features and network configurations. As a result, our detection system achieves an equal error rate (EER) of 6.58% on the ADD2022 challenge test set, which is the best performance in partially spoofed audio detection systems that can locate manipulated clips. ",
    "url": "https://arxiv.org/abs/2211.00226",
    "authors": [
      "Zexin Cai",
      "Weiqing Wang",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00249",
    "title": "Robust Direct Learning for Causal Data Fusion",
    "abstract": "In the era of big data, the explosive growth of multi-source heterogeneous data offers many exciting challenges and opportunities for improving the inference of conditional average treatment effects. In this paper, we investigate homogeneous and heterogeneous causal data fusion problems under a general setting that allows for the presence of source-specific covariates. We provide a direct learning framework for integrating multi-source data that separates the treatment effect from other nuisance functions, and achieves double robustness against certain misspecification. To improve estimation precision and stability, we propose a causal information-aware weighting function motivated by theoretical insights from the semiparametric efficiency theory; it assigns larger weights to samples containing more causal information with high interpretability. We introduce a two-step algorithm, the weighted multi-source direct learner, based on constructing a pseudo-outcome and regressing it on covariates under a weighted least square criterion; it offers us a powerful tool for causal data fusion, enjoying the advantages of easy implementation, double robustness and model flexibility. In simulation studies, we demonstrate the effectiveness of our proposed methods in both homogeneous and heterogeneous causal data fusion scenarios. ",
    "url": "https://arxiv.org/abs/2211.00249",
    "authors": [
      "Xinyu Li",
      "Yilin Li",
      "Qing Cui",
      "Longfei Li",
      "Jun Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.00261",
    "title": "Learning Task-Aware Effective Brain Connectivity for fMRI Analysis with  Graph Neural Networks",
    "abstract": "Functional magnetic resonance imaging (fMRI) has become one of the most common imaging modalities for brain function analysis. Recently, graph neural networks (GNN) have been adopted for fMRI analysis with superior performance. Unfortunately, traditional functional brain networks are mainly constructed based on similarities among region of interests (ROI), which are noisy and agnostic to the downstream prediction tasks and can lead to inferior results for GNN-based models. To better adapt GNNs for fMRI analysis, we propose TBDS, an end-to-end framework based on \\underline{T}ask-aware \\underline{B}rain connectivity \\underline{D}AG (short for Directed Acyclic Graph) \\underline{S}tructure generation for fMRI analysis. The key component of TBDS is the brain network generator which adopts a DAG learning approach to transform the raw time-series into task-aware brain connectivities. Besides, we design an additional contrastive regularization to inject task-specific knowledge during the brain network generation process. Comprehensive experiments on two fMRI datasets, namely Adolescent Brain Cognitive Development (ABCD) and Philadelphia Neuroimaging Cohort (PNC) datasets demonstrate the efficacy of TBDS. In addition, the generated brain networks also highlight the prediction-related brain regions and thus provide unique interpretations of the prediction results. Our implementation will be published to https://github.com/yueyu1030/TBDS upon acceptance. ",
    "url": "https://arxiv.org/abs/2211.00261",
    "authors": [
      "Yue Yu",
      "Xuan Kan",
      "Hejie Cui",
      "Ran Xu",
      "Yujia Zheng",
      "Xiangchen Song",
      "Yanqiao Zhu",
      "Kun Zhang",
      "Razieh Nabi",
      "Ying Guo",
      "Chao Zhang",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.00335",
    "title": "Recurrent Neural Networks and Universal Approximation of Bayesian  Filters",
    "abstract": "We consider the Bayesian optimal filtering problem: i.e. estimating some conditional statistics of a latent time-series signal from an observation sequence. Classical approaches often rely on the use of assumed or estimated transition and observation models. Instead, we formulate a generic recurrent neural network framework and seek to learn directly a recursive mapping from observational inputs to the desired estimator statistics. The main focus of this article is the approximation capabilities of this framework. We provide approximation error bounds for filtering in general non-compact domains. We also consider strong time-uniform approximation error bounds that guarantee good long-time performance. We discuss and illustrate a number of practical concerns and implications of these results. ",
    "url": "https://arxiv.org/abs/2211.00335",
    "authors": [
      "Adrian N. Bishop",
      "Edwin V. Bonilla"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.00435",
    "title": "Spreading dynamics in networks under context-dependent behavior",
    "abstract": "The constituent units of certain systems are able to define a `context' that, altering the behavior of other units, indirectly modifies the (direct) interactions occurring among the latter.Motivated by mechanisms of `indirect modification' -- as they are called in ecology -- identified in real systems, we present a minimal model of context-dependent spreading where, during an interaction, an agent either actively behaves to alter (impede/favor) the diffusion or not depending on the behavior it observes among the co-present peers. Considering populations where agents are divided into two behavioral types, encoding different intrinsic inclinations to take on active behavior, we provide a mean-field theory able to parametrize mixing patterns of any type-(dis)assortativity within groups of arbitrary size. As an application, we consider an epidemic spreading model under context-dependent adoption of prophylactic behavior like face-masks wearing. Assuming individuals gathering in pairs and triads, we characterize the rich phenomenology found for the basic reproduction number and the endemic state in relation to the distributions of size and type-composition of the groups. We demonstrate that changes in such features of the contact organization either facilitate or hinder epidemic spreading depending mainly on sociological factors (hardness to induce active behavior and types' proportions) and, secondarily, on technical ones (prophylactic efficacy). More generally, our work provides a way to model a higher-order context for processes under heterogeneous mixing, and reaffirms how higher-order interactions can lead to significant deviations from what is expected based on pairwise information alone, opening new questions for a series of complex systems. ",
    "url": "https://arxiv.org/abs/2211.00435",
    "authors": [
      "Giulio Burgio",
      "Sergio G\u00f3mez",
      "Alex Arenas"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.00437",
    "title": "Disentangled representation learning for multilingual speaker  recognition",
    "abstract": "The goal of this paper is to train speaker embeddings that are robust to bilingual speaking scenario. The majority of the world's population speak at least two languages; however, most speaker recognition systems fail to recognise the same speaker when speaking in different languages. Popular speaker recognition evaluation sets do not consider the bilingual scenario, making it difficult to analyse the effect of bilingual speakers on speaker recognition performance. This paper proposes a new large-scale evaluation set derived from VoxCeleb that considers bilingual scenarios. We also introduce a representation learning strategy, which disentangles language information from speaker representation to account for the bilingual scenario. This language-disentangled representation learning strategy can be adapted to existing models with small changes to the training pipeline. Experimental results demonstrate that the baseline models suffer significant performance degradation when evaluated on the proposed bilingual test set. On the contrary, the model trained with the proposed disentanglement strategy shows significant improvement under the bilingual evaluation scenario while simultaneously retaining competitive performance on existing monolingual test sets. ",
    "url": "https://arxiv.org/abs/2211.00437",
    "authors": [
      "Kihyun Nam",
      "Youkyum Kim",
      "Hee Soo Heo",
      "Jee-weon Jung",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.00454",
    "title": "PELICAN: Permutation Equivariant and Lorentz Invariant or Covariant  Aggregator Network for Particle Physics",
    "abstract": "Many current approaches to machine learning in particle physics use generic architectures that require large numbers of parameters and disregard underlying physics principles, limiting their applicability as scientific modeling tools. In this work, we present a machine learning architecture that uses a set of inputs maximally reduced with respect to the full 6-dimensional Lorentz symmetry, and is fully permutation-equivariant throughout. We study the application of this network architecture to the standard task of top quark tagging and show that the resulting network outperforms all existing competitors despite much lower model complexity. In addition, we present a Lorentz-covariant variant of the same network applied to a 4-momentum regression task. ",
    "url": "https://arxiv.org/abs/2211.00454",
    "authors": [
      "Alexander Bogatskiy",
      "Timothy Hoffman",
      "David W. Miller",
      "Jan T. Offermann"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2211.00460",
    "title": "Augmentation Invariant Manifold Learning",
    "abstract": "Data augmentation is a widely used technique and an essential ingredient in the recent advance in self-supervised representation learning. By preserving the similarity between augmented data, the resulting data representation can improve various downstream analyses and achieve state-of-art performance in many applications. To demystify the role of data augmentation, we develop a statistical framework on a low-dimension product manifold to theoretically understand why the unlabeled augmented data can lead to useful data representation. Under this framework, we propose a new representation learning method called augmentation invariant manifold learning and develop the corresponding loss function, which can work with a deep neural network to learn data representations. Compared with existing methods, the new data representation simultaneously exploits the manifold's geometric structure and invariant property of augmented data. Our theoretical investigation precisely characterizes how the data representation learned from augmented data can improve the $k$-nearest neighbor classifier in the downstream analysis, showing that a more complex data augmentation leads to more improvement in downstream analysis. Finally, numerical experiments on simulated and real datasets are presented to support the theoretical results in this paper. ",
    "url": "https://arxiv.org/abs/2211.00460",
    "authors": [
      "Shulei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.00482",
    "title": "Adapting self-supervised models to multi-talker speech recognition using  speaker embeddings",
    "abstract": "Self-supervised learning (SSL) methods which learn representations of data without explicit supervision have gained popularity in speech-processing tasks, particularly for single-talker applications. However, these models often have degraded performance for multi-talker scenarios -- possibly due to the domain mismatch -- which severely limits their use for such applications. In this paper, we investigate the adaptation of upstream SSL models to the multi-talker automatic speech recognition (ASR) task under two conditions. First, when segmented utterances are given, we show that adding a target speaker extraction (TSE) module based on enrollment embeddings is complementary to mixture-aware pre-training. Second, for unsegmented mixtures, we propose a novel joint speaker modeling (JSM) approach, which aggregates information from all speakers in the mixture through their embeddings. With controlled experiments on Libri2Mix, we show that using speaker embeddings provides relative WER improvements of 9.1% and 42.1% over strong baselines for the segmented and unsegmented cases, respectively. We also demonstrate the effectiveness of our models for real conversational mixtures through experiments on the AMI dataset. ",
    "url": "https://arxiv.org/abs/2211.00482",
    "authors": [
      "Zili Huang",
      "Desh Raj",
      "Paola Garc\u00eda",
      "Sanjeev Khudanpur"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.00527",
    "title": "Self-Supervised Learning with Limited Labeled Data for Prostate Cancer  Detection in High Frequency Ultrasound",
    "abstract": "Deep learning-based analysis of high-frequency, high-resolution micro-ultrasound data shows great promise for prostate cancer detection. Previous approaches to analysis of ultrasound data largely follow a supervised learning paradigm. Ground truth labels for ultrasound images used for training deep networks often include coarse annotations generated from the histopathological analysis of tissue samples obtained via biopsy. This creates inherent limitations on the availability and quality of labeled data, posing major challenges to the success of supervised learning methods. On the other hand, unlabeled prostate ultrasound data are more abundant. In this work, we successfully apply self-supervised representation learning to micro-ultrasound data. Using ultrasound data from 1028 biopsy cores of 391 subjects obtained in two clinical centres, we demonstrate that feature representations learnt with this method can be used to classify cancer from non-cancer tissue, obtaining an AUROC score of 91% on an independent test set. To the best of our knowledge, this is the first successful end-to-end self-supervised learning approach for prostate cancer detection using ultrasound data. Our method outperforms baseline supervised learning approaches, generalizes well between different data centers, and scale well in performance as more unlabeled data are added, making it a promising approach for future research using large volumes of unlabeled data. ",
    "url": "https://arxiv.org/abs/2211.00527",
    "authors": [
      "Paul F. R. Wilson",
      "Mahdi Gilany",
      "Amoon Jamzad",
      "Fahimeh Fooladgar",
      "Minh Nguyen Nhat To",
      "Brian Wodlinger",
      "Purang Abolmaesumi",
      "Parvin Mousavi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00531",
    "title": "Robustness of Deep Equilibrium Architectures to Changes in the  Measurement Model",
    "abstract": "Deep model-based architectures (DMBAs) are widely used in imaging inverse problems to integrate physical measurement models and learned image priors. Plug-and-play priors (PnP) and deep equilibrium models (DEQ) are two DMBA frameworks that have received significant attention. The key difference between the two is that the image prior in DEQ is trained by using a specific measurement model, while that in PnP is trained as a general image denoiser. This difference is behind a common assumption that PnP is more robust to changes in the measurement models compared to DEQ. This paper investigates the robustness of DEQ priors to changes in the measurement models. Our results on two imaging inverse problems suggest that DEQ priors trained under mismatched measurement models outperform image denoisers. ",
    "url": "https://arxiv.org/abs/2211.00531",
    "authors": [
      "Junhao Hu",
      "Shirin Shoushtari",
      "Zihao Zou",
      "Jiaming Liu",
      "Zhixin Sun",
      "Ulugbek S.Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00569",
    "title": "Few-shot Bioacoustic Event Detection with Machine Learning Methods",
    "abstract": "Few-shot learning is a type of classification through which predictions are made based on a limited number of samples for each class. This type of classification is sometimes referred to as a meta-learning problem, in which the model learns how to learn to identify rare cases. We seek to extract information from five exemplar vocalisations of mammals or birds and detect and classify these sounds in field recordings [2]. This task was provided in the Detection and Classification of Acoustic Scenes and Events (DCASE) Challenge of 2021. Rather than utilize deep learning, as is most commonly done, we formulated a novel solution using only machine learning methods. Various models were tested, and it was found that logistic regression outperformed both linear regression and template matching. However, all of these methods over-predicted the number of events in the field recordings. ",
    "url": "https://arxiv.org/abs/2211.00569",
    "authors": [
      "Leah Chowenhill",
      "Gaurav Satyanath",
      "Shubhranshu Singh",
      "Madhav Mahendra Wagh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.00577",
    "title": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "abstract": "In medical image analysis, low-resolution images negatively affect the performance of medical image interpretation and may cause misdiagnosis. Single image super-resolution (SISR) methods can improve the resolution and quality of medical images. Currently, super-resolution methods based on generative adversarial networks (GAN) are widely used and have shown very good performance. In this work, we use the Real-Enhanced Super-Resolution Generative Adversarial Network (Real-ESRGAN) model to enhance the resolution and quality of medical images. Unlike natural datasets, medical datasets do not have very high spatial resolution. Transfer learning is one of the effective methods which uses models trained with external datasets (often natural datasets), and fine-tunes them to enhance medical images. In our proposed approach, the pre-trained generator and discriminator networks of the Real-ESRGAN model are fine-tuned using medical image datasets. In this paper, we worked on retinal images and chest X-ray images. We used the STARE dataset of retinal images and Tuberculosis Chest X-rays (Shenzhen) dataset. The proposed model produces more accurate and natural textures, and the output images have better detail and resolution compared to the original Real-ESRGAN model. ",
    "url": "https://arxiv.org/abs/2211.00577",
    "authors": [
      "Alireza Aghelan",
      "Modjtaba Rouhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1605.03205",
    "title": "Profit-Driven Team Grouping in Social Networks",
    "abstract": " Title: Profit-Driven Team Grouping in Social Networks ",
    "url": "https://arxiv.org/abs/1605.03205",
    "authors": [
      "Shaojie Tang",
      "Jing Yuan",
      "Tao Li",
      "Yao Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2004.05465",
    "title": "Robust Large-Margin Learning in Hyperbolic Space",
    "abstract": " Comments: Revision corrects error in section 3.1 ",
    "url": "https://arxiv.org/abs/2004.05465",
    "authors": [
      "Melanie Weber",
      "Manzil Zaheer",
      "Ankit Singh Rawat",
      "Aditya Menon",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2005.03161",
    "title": "MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient  Estimation",
    "abstract": " Title: MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient  Estimation ",
    "url": "https://arxiv.org/abs/2005.03161",
    "authors": [
      "Sanjay Kariyappa",
      "Atul Prakash",
      "Moinuddin Qureshi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2007.06169",
    "title": "An Adversarial Approach to Structural Estimation",
    "abstract": " Comments: 56 pages, 3 tables, 11 figures ",
    "url": "https://arxiv.org/abs/2007.06169",
    "authors": [
      "Tetsuya Kaji",
      "Elena Manresa",
      "Guillaume Pouliot"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.08838",
    "title": "Training Matters: Unlocking Potentials of Deeper Graph Convolutional  Neural Networks",
    "abstract": " Title: Training Matters: Unlocking Potentials of Deeper Graph Convolutional  Neural Networks ",
    "url": "https://arxiv.org/abs/2008.08838",
    "authors": [
      "Sitao Luan",
      "Mingde Zhao",
      "Xiao-Wen Chang",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2101.05974",
    "title": "Inductive Representation Learning in Temporal Networks via Causal  Anonymous Walks",
    "abstract": " Comments: Published in ICLR 2021. A bug in previous versions is fixed ",
    "url": "https://arxiv.org/abs/2101.05974",
    "authors": [
      "Yanbang Wang",
      "Yen-Yu Chang",
      "Yunyu Liu",
      "Jure Leskovec",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2101.09617",
    "title": "A Comprehensive Evaluation Framework for Deep Model Robustness",
    "abstract": " Comments: Submitted to Pattern Recognition ",
    "url": "https://arxiv.org/abs/2101.09617",
    "authors": [
      "Jun Guo",
      "Wei Bao",
      "Jiakai Wang",
      "Yuqing Ma",
      "Xinghai Gao",
      "Gang Xiao",
      "Aishan Liu",
      "Jian Dong",
      "Xianglong Liu",
      "Wenjun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.12531",
    "title": "CLIP: Cheap Lipschitz Training of Neural Networks",
    "abstract": " Comments: 12 pages, 2 figures, fixed a small mistake in the proof of Proposition 3, published at SSVM 2021 ",
    "url": "https://arxiv.org/abs/2103.12531",
    "authors": [
      "Leon Bungert",
      "Ren\u00e9 Raab",
      "Tim Roith",
      "Leo Schwinn",
      "Daniel Tenbrinck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.10771",
    "title": "Multirate Training of Neural Networks",
    "abstract": " Comments: Appeared in ICML 2022 (errata added on 19 Oct., 2022) ",
    "url": "https://arxiv.org/abs/2106.10771",
    "authors": [
      "Tiffany Vlaar",
      "Benedict Leimkuhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.03799",
    "title": "Contrastive Learning for Robust Android Malware Familial Classification",
    "abstract": " Title: Contrastive Learning for Robust Android Malware Familial Classification ",
    "url": "https://arxiv.org/abs/2107.03799",
    "authors": [
      "Yueming Wu",
      "Shihan Dou",
      "Deqing Zou",
      "Wei Yang",
      "Weizhong Qiang",
      "Hai Jin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.11078",
    "title": "IE-GAN: An Improved Evolutionary Generative Adversarial Network Using a  New Fitness Function and a Generic Crossover Operator",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2101.11186 ",
    "url": "https://arxiv.org/abs/2109.11078",
    "authors": [
      "Junjie Li",
      "Jingyao Li",
      "Wenbo Zhou",
      "Shuai L\u00fc"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.00528",
    "title": "Calibrating the Dice loss to handle neural network overconfidence for  biomedical image segmentation",
    "abstract": " Title: Calibrating the Dice loss to handle neural network overconfidence for  biomedical image segmentation ",
    "url": "https://arxiv.org/abs/2111.00528",
    "authors": [
      "Michael Yeung",
      "Leonardo Rundo",
      "Yang Nan",
      "Evis Sala",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2112.13747",
    "title": "Modeling Occasion Evolution in Frequency Domain for Promotion-Aware  Click-Through Rate Prediction",
    "abstract": " Title: Modeling Occasion Evolution in Frequency Domain for Promotion-Aware  Click-Through Rate Prediction ",
    "url": "https://arxiv.org/abs/2112.13747",
    "authors": [
      "Xiaofeng Pan",
      "Yibin Shen",
      "Jing Zhang",
      "Xu He",
      "Yang Huang",
      "Hong Wen",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2201.00818",
    "title": "Graph Neural Networks for Multivariate Time Series Regression with  Application to Seismic Data",
    "abstract": " Comments: 18 pages, LaTeX; final revision; published in: International Journal of Data Science and Analytics, pages 1-16, 2022 ",
    "url": "https://arxiv.org/abs/2201.00818",
    "authors": [
      "Stefan Bloemheuvel",
      "Jurgen van den Hoogen",
      "Dario Jozinovi\u0107",
      "Alberto Michelini",
      "Martin Atzmueller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11917",
    "title": "Task-Aware Network Coding Over Butterfly Network",
    "abstract": " Title: Task-Aware Network Coding Over Butterfly Network ",
    "url": "https://arxiv.org/abs/2201.11917",
    "authors": [
      "Jiangnan Cheng",
      "Sandeep Chinchali",
      "Ao Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11926",
    "title": "Focal Modulation Networks",
    "abstract": " Comments: NeurIPS 2022 camera-ready extension ",
    "url": "https://arxiv.org/abs/2203.11926",
    "authors": [
      "Jianwei Yang",
      "Chunyuan Li",
      "Xiyang Dai",
      "Lu Yuan",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16794",
    "title": "Speech Emotion Recognition using Multi-task learning and a multimodal  dynamic fusion network",
    "abstract": " Comments: 6 + 2 pages ",
    "url": "https://arxiv.org/abs/2203.16794",
    "authors": [
      "Sreyan Ghosh",
      "S Ramaneswaran",
      "Harshvardhan Srivastava",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.17149",
    "title": "AEGNN: Asynchronous Event-based Graph Neural Networks",
    "abstract": " Comments: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), New Orleans, 2022 ",
    "url": "https://arxiv.org/abs/2203.17149",
    "authors": [
      "Simon Schaefer",
      "Daniel Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.00783",
    "title": "Supervised Robustness-preserving Data-free Neural Network Pruning",
    "abstract": " Title: Supervised Robustness-preserving Data-free Neural Network Pruning ",
    "url": "https://arxiv.org/abs/2204.00783",
    "authors": [
      "Mark Huasong Meng",
      "Guangdong Bai",
      "Sin Gee Teo",
      "Jin Song Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.11454",
    "title": "Natural Language to Code Translation with Execution",
    "abstract": " Comments: EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2204.11454",
    "authors": [
      "Freda Shi",
      "Daniel Fried",
      "Marjan Ghazvininejad",
      "Luke Zettlemoyer",
      "Sida I. Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.02357",
    "title": "Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge  Graph Completion",
    "abstract": " Comments: Accepted by SIGIR 2022. Fix a severe bug ",
    "url": "https://arxiv.org/abs/2205.02357",
    "authors": [
      "Xiang Chen",
      "Ningyu Zhang",
      "Lei Li",
      "Shumin Deng",
      "Chuanqi Tan",
      "Changliang Xu",
      "Fei Huang",
      "Luo Si",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.06938",
    "title": "Generating Literal and Implied Subquestions to Fact-check Complex Claims",
    "abstract": " Title: Generating Literal and Implied Subquestions to Fact-check Complex Claims ",
    "url": "https://arxiv.org/abs/2205.06938",
    "authors": [
      "Jifan Chen",
      "Aniruddh Sriram",
      "Eunsol Choi",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10309",
    "title": "A Fully Implicit Method for Robust Frictional Contact Handling in  Elastic Rods",
    "abstract": " Comments: * Equal contribution. A video summarizing this work is available on YouTube: this https URL ",
    "url": "https://arxiv.org/abs/2205.10309",
    "authors": [
      "Dezhong Tong",
      "Andrew Choi",
      "Jungseock Joo",
      "M. Khalid Jawed"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.10489",
    "title": "Social Fragmentation Transitions in Large-Scale Parameter Sweep  Simulations of Adaptive Social Networks",
    "abstract": " Comments: 11 pages, 4 figures; to appear in the Proceedings of the 14th International Conference on Parallel Processing and Applied Mathematics (PPAM 2022), Springer, in press ",
    "url": "https://arxiv.org/abs/2205.10489",
    "authors": [
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2205.11463",
    "title": "Context Limitations Make Neural Language Models More Human-Like",
    "abstract": " Comments: Accepted by EMNLP2022 (main long) ",
    "url": "https://arxiv.org/abs/2205.11463",
    "authors": [
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Ana Brassard",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.15031",
    "title": "Neural Copula: A unified framework for estimating generic  high-dimensional Copula functions",
    "abstract": " Title: Neural Copula: A unified framework for estimating generic  high-dimensional Copula functions ",
    "url": "https://arxiv.org/abs/2205.15031",
    "authors": [
      "Zhi Zeng",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03956",
    "title": "The number of small-degree vertices in matchstick graphs",
    "abstract": " Title: The number of small-degree vertices in matchstick graphs ",
    "url": "https://arxiv.org/abs/2206.03956",
    "authors": [
      "J\u00e9r\u00e9my Lavoll\u00e9e",
      "Konrad J. Swanepoel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2206.08514",
    "title": "A Unified Evaluation of Textual Backdoor Learning: Frameworks and  Benchmarks",
    "abstract": " Comments: NeurIPS 2022 Datasets & Benchmarks; Toolkits avaliable at this https URL ",
    "url": "https://arxiv.org/abs/2206.08514",
    "authors": [
      "Ganqu Cui",
      "Lifan Yuan",
      "Bingxiang He",
      "Yangyi Chen",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09103",
    "title": "Identifying Source Speakers for Voice Conversion based Spoofing Attacks  on Speaker Verification Systems",
    "abstract": " Title: Identifying Source Speakers for Voice Conversion based Spoofing Attacks  on Speaker Verification Systems ",
    "url": "https://arxiv.org/abs/2206.09103",
    "authors": [
      "Danwei Cai",
      "Zexin Cai",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.10898",
    "title": "Q-rMinRank attack: The first quantum approach for key recovery attacks  on Rainbow",
    "abstract": " Comments: The paper has been withdrawn because the research work is still in progress ",
    "url": "https://arxiv.org/abs/2206.10898",
    "authors": [
      "Seong-Min Cho",
      "Seung-Hyun Seo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.11253",
    "title": "Towards Robust Blind Face Restoration with Codebook Lookup Transformer",
    "abstract": " Comments: Accepted by NeurIPS 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2206.11253",
    "authors": [
      "Shangchen Zhou",
      "Kelvin C.K. Chan",
      "Chongyi Li",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.03046",
    "title": "Self-Supervised RF Signal Representation Learning for NextG Signal  Classification with Deep Learning",
    "abstract": " Comments: 5 pages, 3 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2207.03046",
    "authors": [
      "Kemal Davaslioglu",
      "Serdar Boztas",
      "Mehmet Can Ertem",
      "Yalin E. Sagduyu",
      "Ender Ayanoglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.01721",
    "title": "Rumor Stance Classification in Online Social Networks: The  State-of-the-Art, Prospects, and Future Challenges",
    "abstract": " Comments: 16 pages, 3 figures, journal ",
    "url": "https://arxiv.org/abs/2208.01721",
    "authors": [
      "Sarina Jami",
      "Iman Sahebi",
      "Mohammad M. Sabermahani",
      "Seyed P. Shariatpanahi",
      "Aresh Dadlani",
      "Behrouz Maham"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.07541",
    "title": "Social Interactions for Autonomous Driving: A Review and Perspectives",
    "abstract": " Comments: 183 pages, 36 figures ",
    "url": "https://arxiv.org/abs/2208.07541",
    "authors": [
      "Wenshuo Wang",
      "Letian Wang",
      "Chengyuan Zhang",
      "Changliu Liu",
      "Lijun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.13070",
    "title": "Self-Supervised Face Presentation Attack Detection with Dynamic  Grayscale Snippets",
    "abstract": " Title: Self-Supervised Face Presentation Attack Detection with Dynamic  Grayscale Snippets ",
    "url": "https://arxiv.org/abs/2208.13070",
    "authors": [
      "Usman Muhammad",
      "Mourad Oussalah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.13723",
    "title": "Bayesian Continual Learning via Spiking Neural Networks",
    "abstract": " Comments: Accepted for publication in Frontiers in Computational Neuroscience ",
    "url": "https://arxiv.org/abs/2208.13723",
    "authors": [
      "Nicolas Skatchkovsky",
      "Hyeryung Jang",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.04113",
    "title": "Robust and Lossless Fingerprinting of Deep Neural Networks via Pooled  Membership Inference",
    "abstract": " Comments: this https URL&hl=en ",
    "url": "https://arxiv.org/abs/2209.04113",
    "authors": [
      "Hanzhou Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.06640",
    "title": "Revisiting Neural Scaling Laws in Language and Vision",
    "abstract": " Title: Revisiting Neural Scaling Laws in Language and Vision ",
    "url": "https://arxiv.org/abs/2209.06640",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Behnam Neyshabur",
      "Xiaohua Zhai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": " Title: Sketch of a novel approach to a neural model ",
    "url": "https://arxiv.org/abs/2209.06865",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2209.10866",
    "title": "One-Shot Federated Learning for Model Clustering and Learning in  Heterogeneous Environments",
    "abstract": " Comments: Edited text, added figures, added funding information ",
    "url": "https://arxiv.org/abs/2209.10866",
    "authors": [
      "Aleksandar Armacki",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12243",
    "title": "Safety-compliant Generative Adversarial Networks for Human Trajectory  Forecasting",
    "abstract": " Comments: 12 pages, 7 figures, 8 tables; Added acknowledgement ",
    "url": "https://arxiv.org/abs/2209.12243",
    "authors": [
      "Parth Kothari",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01741",
    "title": "Neural Conservation Laws: A Divergence-Free Perspective",
    "abstract": " Comments: Accepted for publication at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.01741",
    "authors": [
      "Jack Richter-Powell",
      "Yaron Lipman",
      "Ricky T. Q. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02071",
    "title": "Advanced Deep Learning Architectures for Accurate Detection of  Subsurface Tile Drainage Pipes from Remote Sensing Images",
    "abstract": " Comments: Accepted at the SPIE Image and Signal Processing for Remote Sensing 2022. For code visit: this https URL ",
    "url": "https://arxiv.org/abs/2210.02071",
    "authors": [
      "Tom-Lukas Breitkopf",
      "Leonard W. Hackel",
      "Mahdyar Ravanbakhsh",
      "Anne-Karin Cooke",
      "Sandra Willkommen",
      "Stefan Broda",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.06983",
    "title": "Denoising Masked AutoEncoders are Certifiable Robust Vision Learners",
    "abstract": " Title: Denoising Masked AutoEncoders are Certifiable Robust Vision Learners ",
    "url": "https://arxiv.org/abs/2210.06983",
    "authors": [
      "Quanlin Wu",
      "Hang Ye",
      "Yuntian Gu",
      "Huishuai Zhang",
      "Liwei Wang",
      "Di He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08355",
    "title": "A Simple and Strong Baseline for End-to-End Neural RST-style Discourse  Parsing",
    "abstract": " Comments: Accepted in Findings of EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.08355",
    "authors": [
      "Naoki Kobayashi",
      "Tsutomu Hirao",
      "Hidetaka Kamigaito",
      "Manabu Okumura",
      "Masaaki Nagata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08753",
    "title": "MCP: Self-supervised Pre-training for Personalized Chatbots with  Multi-level Contrastive Sampling",
    "abstract": " Title: MCP: Self-supervised Pre-training for Personalized Chatbots with  Multi-level Contrastive Sampling ",
    "url": "https://arxiv.org/abs/2210.08753",
    "authors": [
      "Zhaoheng Huang",
      "Zhicheng Dou",
      "Yutao Zhu",
      "Zhengyi Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08821",
    "title": "MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph  Completion",
    "abstract": " Comments: Accepted by EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.08821",
    "authors": [
      "Yu Zhao",
      "Xiangrui Cai",
      "Yike Wu",
      "Haiwei Zhang",
      "Ying Zhang",
      "Guoqing Zhao",
      "Ning Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.09017",
    "title": "Robust Data-Driven Moving Horizon Estimation for Linear Discrete-Time  Systems",
    "abstract": " Comments: Submitted to IEEE Transactions on Automatic Control ",
    "url": "https://arxiv.org/abs/2210.09017",
    "authors": [
      "Tobias M. Wolff",
      "Victor G. Lopez",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.10946",
    "title": "Causally-guided Regularization of Graph Attention Improves  Generalizability",
    "abstract": " Title: Causally-guided Regularization of Graph Attention Improves  Generalizability ",
    "url": "https://arxiv.org/abs/2210.10946",
    "authors": [
      "Alexander P. Wu",
      "Thomas Markovich",
      "Bonnie Berger",
      "Nils Hammerla",
      "Rohit Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12767",
    "title": "Falsehoods that ML researchers believe about OOD detection",
    "abstract": " Comments: 5 pages ",
    "url": "https://arxiv.org/abs/2210.12767",
    "authors": [
      "Andi Zhang",
      "Damon Wischik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14044",
    "title": "SeismicNet: Physics-informed neural networks for seismic wave modeling  in semi-infinite domain",
    "abstract": " Comments: 22 pages ",
    "url": "https://arxiv.org/abs/2210.14044",
    "authors": [
      "Pu Ren",
      "Chengping Rao",
      "Su Chen",
      "Jian-sun Wang",
      "Hao Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14531",
    "title": "Unifying Data Perspectivism and Personalization: An Application to  Social Norms",
    "abstract": " Title: Unifying Data Perspectivism and Personalization: An Application to  Social Norms ",
    "url": "https://arxiv.org/abs/2210.14531",
    "authors": [
      "Joan Plepi",
      "B\u00e9la Neuendorf",
      "Lucie Flek",
      "Charles Welch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14891",
    "title": "Broken Neural Scaling Laws",
    "abstract": " Title: Broken Neural Scaling Laws ",
    "url": "https://arxiv.org/abs/2210.14891",
    "authors": [
      "Ethan Caballero",
      "Kshitij Gupta",
      "Irina Rish",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15787",
    "title": "Convolutional Codes with Optimum Bidirectional Distance Profile",
    "abstract": " Comments: Submitted to IEEE Communications Letters ",
    "url": "https://arxiv.org/abs/2210.15787",
    "authors": [
      "Ivan Stanojevi\u0107",
      "Vojin \u0160enk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.16107",
    "title": "SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water",
    "abstract": " Title: SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water ",
    "url": "https://arxiv.org/abs/2210.16107",
    "authors": [
      "Xiaomin Lin",
      "Cheng Liu",
      "Miao Yu",
      "Yiannis Aloimonous"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.16346",
    "title": "Improving Hyperspectral Adversarial Robustness using Ensemble Networks  in the Presences of Multiple Attacks",
    "abstract": " Comments: 6 pages, 2 figures, 1 table, 1 algorithm ",
    "url": "https://arxiv.org/abs/2210.16346",
    "authors": [
      "Nicholas Soucy",
      "Salimeh Yasaei Sekeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16636",
    "title": "Speaker Representation Learning via Contrastive Loss with Maximal  Speaker Separability",
    "abstract": " Comments: Accept by APSIPA ASC 2022, 6 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2210.16636",
    "authors": [
      "Zhe Li",
      "Man-Wai Mak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.16751",
    "title": "Formalizing Statistical Causality via Modal Logic",
    "abstract": " Title: Formalizing Statistical Causality via Modal Logic ",
    "url": "https://arxiv.org/abs/2210.16751",
    "authors": [
      "Yusuke Kawamoto",
      "Tetsuya Sato",
      "Kohei Suenaga"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.16791",
    "title": "Adaptive Speech Quality Aware Complex Neural Network for Acoustic Echo  Cancellation with Supervised Contrastive Learning",
    "abstract": " Title: Adaptive Speech Quality Aware Complex Neural Network for Acoustic Echo  Cancellation with Supervised Contrastive Learning ",
    "url": "https://arxiv.org/abs/2210.16791",
    "authors": [
      "Bozhong Liu",
      "Xiaoxi Yu",
      "Hantao Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.16819",
    "title": "Relative Attention-based One-Class Adversarial Autoencoder for  Continuous Authentication of Smartphone Users",
    "abstract": " Title: Relative Attention-based One-Class Adversarial Autoencoder for  Continuous Authentication of Smartphone Users ",
    "url": "https://arxiv.org/abs/2210.16819",
    "authors": [
      "Mingming Hu",
      "Kun Zhang",
      "Ruibang You",
      "Bibo Tu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.16835",
    "title": "Robust Data Valuation via Variance Reduced Data Shapley",
    "abstract": " Title: Robust Data Valuation via Variance Reduced Data Shapley ",
    "url": "https://arxiv.org/abs/2210.16835",
    "authors": [
      "Mengmeng Wu",
      "Ruoxi Jia",
      "Changle Lin",
      "Wei Huang",
      "Xiangyu Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16875",
    "title": "A Multi-modal Deformable Land-air Robot for Complex Environments",
    "abstract": " Title: A Multi-modal Deformable Land-air Robot for Complex Environments ",
    "url": "https://arxiv.org/abs/2210.16875",
    "authors": [
      "Xinyu Zhang",
      "Yuanhao Huang",
      "Kangyao Huang",
      "Xiaoyu Wang",
      "Dafeng Jin",
      "Huaping Liu",
      "Jun Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.17016",
    "title": "Wespeaker: A Research and Production oriented Speaker Embedding Learning  Toolkit",
    "abstract": " Title: Wespeaker: A Research and Production oriented Speaker Embedding Learning  Toolkit ",
    "url": "https://arxiv.org/abs/2210.17016",
    "authors": [
      "Hongji Wang",
      "Chengdong Liang",
      "Shuai Wang",
      "Zhengyang Chen",
      "Binbin Zhang",
      "Xu Xiang",
      "Yanlei Deng",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.17349",
    "title": "Robust MelGAN: A robust universal neural vocoder for high-fidelity TTS",
    "abstract": " Title: Robust MelGAN: A robust universal neural vocoder for high-fidelity TTS ",
    "url": "https://arxiv.org/abs/2210.17349",
    "authors": [
      "Kun Song",
      "Jian Cong",
      "Xinsheng Wang",
      "Yongmao Zhang",
      "Lei Xie",
      "Ning Jiang",
      "Haiying Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  }
]