[
  {
    "id": "arXiv:2211.12506",
    "title": "Dynamic Loss For Robust Learning",
    "abstract": "Label noise and class imbalance commonly coexist in real-world data. Previous works for robust learning, however, usually address either one type of the data biases and underperform when facing them both. To mitigate this gap, this work presents a novel meta-learning based dynamic loss that automatically adjusts the objective functions with the training process to robustly learn a classifier from long-tailed noisy data. Concretely, our dynamic loss comprises a label corrector and a margin generator, which respectively correct noisy labels and generate additive per-class classification margins by perceiving the underlying data distribution as well as the learning state of the classifier. Equipped with a new hierarchical sampling strategy that enriches a small amount of unbiased metadata with diverse and hard samples, the two components in the dynamic loss are optimized jointly through meta-learning and cultivate the classifier to well adapt to clean and balanced test data. Extensive experiments show our method achieves state-of-the-art accuracy on multiple real-world and synthetic datasets with various types of data biases, including CIFAR-10/100, Animal-10N, ImageNet-LT, and Webvision. Code will soon be publicly available. ",
    "url": "https://arxiv.org/abs/2211.12506",
    "authors": [
      "Shenwang Jiang",
      "Jianan Li",
      "Jizhou Zhang",
      "Ying Wang",
      "Tingfa Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12511",
    "title": "Scalable and Effective Conductance-based Graph Clustering",
    "abstract": "Conductance-based graph clustering has been recognized as a fundamental operator in numerous graph analysis applications. Despite the significant success of conductance-based graph clustering, existing algorithms are either hard to obtain satisfactory clustering qualities, or have high time and space complexity to achieve provable clustering qualities. To overcome these limitations, we devise a powerful \\textit{peeling}-based graph clustering framework \\textit{PCon}. We show that many existing solutions can be reduced to our framework. Namely, they first define a score function for each vertex, then iteratively remove the vertex with the smallest score. Finally, they output the result with the smallest conductance during the peeling process. Based on our framework, we propose two novel algorithms \\textit{PCon\\_core} and \\emph{PCon\\_de} with linear time and space complexity, which can efficiently and effectively identify clusters from massive graphs with more than a few billion edges. Surprisingly, we prove that \\emph{PCon\\_de} can identify clusters with near-constant approximation ratio, resulting in an important theoretical improvement over the well-known quadratic Cheeger bound. Empirical results on real-life and synthetic datasets show that our algorithms can achieve 5$\\sim$42 times speedup with a high clustering accuracy, while using 1.4$\\sim$7.8 times less memory than the baseline algorithms. ",
    "url": "https://arxiv.org/abs/2211.12511",
    "authors": [
      "Longlong Lin",
      "Rong-Hua Li",
      "Tao Jia"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12514",
    "title": "AugOp: Inject Transformation into Neural Operator",
    "abstract": "In this paper, we propose a simple and general approach to augment regular convolution operator by injecting extra group-wise transformation during training and recover it during inference. Extra transformation is carefully selected to ensure it can be merged with regular convolution in each group and will not change the topological structure of regular convolution during inference. Compared with regular convolution operator, our approach (AugConv) can introduce larger learning capacity to improve model performance during training but will not increase extra computational overhead for model deployment. Based on ResNet, we utilize AugConv to build convolutional neural networks named AugResNet. Result on image classification dataset Cifar-10 shows that AugResNet outperforms its baseline in terms of model performance. ",
    "url": "https://arxiv.org/abs/2211.12514",
    "authors": [
      "Longqing Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12560",
    "title": "Contextually Aware Intelligent Control Agents for Heterogeneous Swarms",
    "abstract": "An emerging challenge in swarm shepherding research is to design effective and efficient artificial intelligence algorithms that maintain a low-computational ceiling while increasing the swarm's abilities to operate in diverse contexts. We propose a methodology to design a context-aware swarm-control intelligent agent. The intelligent control agent (shepherd) first uses swarm metrics to recognise the type of swarm it interacts with to then select a suitable parameterisation from its behavioural library for that particular swarm type. The design principle of our methodology is to increase the situation awareness (i.e. information contents) of the control agent without sacrificing the low-computational cost necessary for efficient swarm control. We demonstrate successful shepherding in both homogeneous and heterogeneous swarms. ",
    "url": "https://arxiv.org/abs/2211.12560",
    "authors": [
      "Adam Hepworth",
      "Aya Hussein",
      "Darryn Reid",
      "Hussein Abbass"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12565",
    "title": "A Novel Center-based Deep Contrastive Metric Learning Method for the  Detection of Polymicrogyria in Pediatric Brain MRI",
    "abstract": "Polymicrogyria (PMG) is a disorder of cortical organization mainly seen in children, which can be associated with seizures, developmental delay and motor weakness. PMG is typically diagnosed on magnetic resonance imaging (MRI) but some cases can be challenging to detect even for experienced radiologists. In this study, we create an open pediatric MRI dataset (PPMR) with PMG and controls from the Children's Hospital of Eastern Ontario (CHEO), Ottawa, Canada. The differences between PMG MRIs and control MRIs are subtle and the true distribution of the features of the disease is unknown. This makes automatic detection of cases of potential PMG in MRI difficult. We propose an anomaly detection method based on a novel center-based deep contrastive metric learning loss function (cDCM) which enables the automatic detection of cases of potential PMG. Additionally, based on our proposed loss function, we customize a deep learning model structure that integrates dilated convolution, squeeze-and-excitation blocks and feature fusion for our PPMR dataset. Despite working with a small and imbalanced dataset our method achieves 92.01% recall at 55.04% precision. This will facilitate a computer aided tool for radiologists to select potential PMG MRIs. To the best of our knowledge, this research is the first to apply machine learning techniques to identify PMG from MRI only. ",
    "url": "https://arxiv.org/abs/2211.12565",
    "authors": [
      "Lingfeng Zhang",
      "Nishard Abdeen",
      "Jochen Lang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12570",
    "title": "Predicting the Type and Target of Offensive Social Media Posts in  Marathi",
    "abstract": "The presence of offensive language on social media is very common motivating platforms to invest in strategies to make communities safer. This includes developing robust machine learning systems capable of recognizing offensive content online. Apart from a few notable exceptions, most research on automatic offensive language identification has dealt with English and a few other high resource languages such as French, German, and Spanish. In this paper we address this gap by tackling offensive language identification in Marathi, a low-resource Indo-Aryan language spoken in India. We introduce the Marathi Offensive Language Dataset v.2.0 or MOLD 2.0 and present multiple experiments on this dataset. MOLD 2.0 is a much larger version of MOLD with expanded annotation to the levels B (type) and C (target) of the popular OLID taxonomy. MOLD 2.0 is the first hierarchical offensive language dataset compiled for Marathi, thus opening new avenues for research in low-resource Indo-Aryan languages. Finally, we also introduce SeMOLD, a larger dataset annotated following the semi-supervised methods presented in SOLID. ",
    "url": "https://arxiv.org/abs/2211.12570",
    "authors": [
      "Marcos Zampieri",
      "Tharindu Ranasinghe",
      "Mrinal Chaudhari",
      "Saurabh Gaikwad",
      "Prajwal Krishna",
      "Mayuresh Nene",
      "Shrunali Paygude"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.12578",
    "title": "Online Federated Learning via Non-Stationary Detection and Adaptation  amidst Concept Drift",
    "abstract": "Federated Learning (FL) is an emerging domain in the broader context of artificial intelligence research. Methodologies pertaining to FL assume distributed model training, consisting of a collection of clients and a server, with the main goal of achieving optimal global model with restrictions on data sharing due to privacy concerns. It is worth highlighting that the diverse existing literature in FL mostly assume stationary data generation processes; such an assumption is unrealistic in real-world conditions where concept drift occurs due to, for instance, seasonal or period observations, faults in sensor measurements. In this paper, we introduce a multiscale algorithmic framework which combines theoretical guarantees of \\textit{FedAvg} and \\textit{FedOMD} algorithms in near stationary settings with a non-stationary detection and adaptation technique to ameliorate FL generalization performance in the presence of model/concept drifts. We present a multi-scale algorithmic framework leading to $\\Tilde{\\mathcal{O}} ( \\min \\{ \\sqrt{LT} , \\Delta^{\\frac{1}{3}}T^{\\frac{2}{3}} + \\sqrt{T} \\})$ \\textit{dynamic regret} for $T$ rounds with an underlying general convex loss function, where $L$ is the number of times non-stationary drifts occured and $\\Delta$ is the cumulative magnitude of drift experienced within $T$ rounds. ",
    "url": "https://arxiv.org/abs/2211.12578",
    "authors": [
      "Bhargav Ganguly",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.12603",
    "title": "Reachability in Restricted Chemical Reaction Networks",
    "abstract": "The popularity of molecular computation has given rise to several models of abstraction, one of the more recent ones being Chemical Reaction Networks (CRNs). These are equivalent to other popular computational models, such as Vector Addition Systems and Petri-Nets, and restricted versions are equivalent to Population Protocols. This paper continues the work on core reachability questions related to Chemical Reaction Networks; given two configurations, can one reach the other according to the system's rules? With no restrictions, reachability was recently shown to be Ackermann-complete, this resolving a decades-old problem. Here, we fully characterize monotone reachability problems based on various restrictions such as the rule size, the number of rules that may create a species (k-source) or consume a species (k-consuming), the volume, and whether the rules have an acyclic production order (feed-forward). We show PSPACE-completeness of reachability with only bimolecular reactions with two-source and two-consuming rules. This proves hardness of reachability in Population Protocols, which was unknown. Further, this shows reachability in CRNs is PSPACE-complete with size-2 rules, which was previously only known with size-5 rules. This is achieved using techniques within the motion planning framework. We provide many important results for feed-forward CRNs where rules are single-source or single-consuming. We show that reachability is solvable in polynomial time if the system does not contain special void or autogenesis rules. We then fully characterize all systems of this type and show that if you allow void/autogenesis rules, or have more than one source and one consuming, the problems become NP-complete. Finally, we show several interesting special cases of CRNs based on these restrictions or slight relaxations and note future significant open questions related to this taxonomy. ",
    "url": "https://arxiv.org/abs/2211.12603",
    "authors": [
      "Robert M. Alaniz",
      "Bin Fu",
      "Timothy Gomez",
      "Elise Grizzell",
      "Andrew Rodriguez",
      "Robert Schweller",
      "Tim Wylie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2211.12624",
    "title": "Improving Robust Generalization by Direct PAC-Bayesian Bound  Minimization",
    "abstract": "Recent research in robust optimization has shown an overfitting-like phenomenon in which models trained against adversarial attacks exhibit higher robustness on the training set compared to the test set. Although previous work provided theoretical explanations for this phenomenon using a robust PAC-Bayesian bound over the adversarial test error, related algorithmic derivations are at best only loosely connected to this bound, which implies that there is still a gap between their empirical success and our understanding of adversarial robustness theory. To close this gap, in this paper we consider a different form of the robust PAC-Bayesian bound and directly minimize it with respect to the model posterior. The derivation of the optimal solution connects PAC-Bayesian learning to the geometry of the robust loss surface through a Trace of Hessian (TrH) regularizer that measures the surface flatness. In practice, we restrict the TrH regularizer to the top layer only, which results in an analytical solution to the bound whose computational cost does not depend on the network depth. Finally, we evaluate our TrH regularization approach over CIFAR-10/100 and ImageNet using Vision Transformers (ViT) and compare against baseline adversarial robustness algorithms. Experimental results show that TrH regularization leads to improved ViT robustness that either matches or surpasses previous state-of-the-art approaches while at the same time requires less memory and computational cost. ",
    "url": "https://arxiv.org/abs/2211.12624",
    "authors": [
      "Zifan Wang",
      "Nan Ding",
      "Tomer Levinboim",
      "Xi Chen",
      "Radu Soricut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12627",
    "title": "$\u03b2$-Multivariational Autoencoder for Entangled Representation  Learning in Video Frames",
    "abstract": "It is crucial to choose actions from an appropriate distribution while learning a sequential decision-making process in which a set of actions is expected given the states and previous reward. Yet, if there are more than two latent variables and every two variables have a covariance value, learning a known prior from data becomes challenging. Because when the data are big and diverse, many posterior estimate methods experience posterior collapse. In this paper, we propose the $\\beta$-Multivariational Autoencoder ($\\beta$MVAE) to learn a Multivariate Gaussian prior from video frames for use as part of a single object-tracking in form of a decision-making process. We present a novel formulation for object motion in videos with a set of dependent parameters to address a single object-tracking task. The true values of the motion parameters are obtained through data analysis on the training set. The parameters population is then assumed to have a Multivariate Gaussian distribution. The $\\beta$MVAE is developed to learn this entangled prior $p = N(\\mu, \\Sigma)$ directly from frame patches where the output is the object masks of the frame patches. We devise a bottleneck to estimate the posterior's parameters, i.e. $\\mu', \\Sigma'$. Via a new reparameterization trick, we learn the likelihood $p(\\hat{x}|z)$ as the object mask of the input. Furthermore, we alter the neural network of $\\beta$MVAE with the U-Net architecture and name the new network $\\beta$Multivariational U-Net ($\\beta$MVUnet). Our networks are trained from scratch via over 85k video frames for 24 ($\\beta$MVUnet) and 78 ($\\beta$MVAE) million steps. We show that $\\beta$MVUnet enhances both posterior estimation and segmentation functioning over the test set. Our code and the trained networks are publicly released. ",
    "url": "https://arxiv.org/abs/2211.12627",
    "authors": [
      "Fatemeh Nouri",
      "Robert Bergevin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12633",
    "title": "Near-optimal learning of Banach-valued, high-dimensional functions via  deep neural networks",
    "abstract": "The past decade has seen increasing interest in applying Deep Learning (DL) to Computational Science and Engineering (CSE). Driven by impressive results in applications such as computer vision, Uncertainty Quantification (UQ), genetics, simulations and image processing, DL is increasingly supplanting classical algorithms, and seems poised to revolutionize scientific computing. However, DL is not yet well-understood from the standpoint of numerical analysis. Little is known about the efficiency and reliability of DL from the perspectives of stability, robustness, accuracy, and sample complexity. In particular, approximating solutions to parametric PDEs is an objective of UQ for CSE. Training data for such problems is often scarce and corrupted by errors. Moreover, the target function is a possibly infinite-dimensional smooth function taking values in the PDE solution space, generally an infinite-dimensional Banach space. This paper provides arguments for Deep Neural Network (DNN) approximation of such functions, with both known and unknown parametric dependence, that overcome the curse of dimensionality. We establish practical existence theorems that describe classes of DNNs with dimension-independent architecture size and training procedures based on minimizing the (regularized) $\\ell^2$-loss which achieve near-optimal algebraic rates of convergence. These results involve key extensions of compressed sensing for Banach-valued recovery and polynomial emulation with DNNs. When approximating solutions of parametric PDEs, our results account for all sources of error, i.e., sampling, optimization, approximation and physical discretization, and allow for training high-fidelity DNN approximations from coarse-grained sample data. Our theoretical results fall into the category of non-intrusive methods, providing a theoretical alternative to classical methods for high-dimensional approximation. ",
    "url": "https://arxiv.org/abs/2211.12633",
    "authors": [
      "Ben Adcock",
      "Simone Brugiapaglia",
      "Nick Dexter",
      "Sebastian Moraga"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.12634",
    "title": "Image Anomaly Detection and Localization with Position and Neighborhood  Information",
    "abstract": "Anomaly detection and localization are essential in many areas, where collecting enough anomalous samples for training is almost impossible. To overcome this difficulty, many existing methods use a pre-trained network to encode input images and non-parametric modeling to estimate the encoded feature distribution. In the modeling process, however, they overlook that position and neighborhood information affect the distribution of normal features. To use the information, in this paper, the normal distribution is estimated with conditional probability given neighborhood features, which is modeled with a multi-layer perceptron network. At the same time, positional information can be used by building a histogram of representative features at each position. While existing methods simply resize the anomaly map into the resolution of an input image, the proposed method uses an additional refine network that is trained from synthetic anomaly images to perform better interpolation considering the shape and edge of the input image. For the popular industrial dataset, MVTec AD benchmark, the experimental results show \\textbf{99.52\\%} and \\textbf{98.91\\%} AUROC scores in anomaly detection and localization, which is state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2211.12634",
    "authors": [
      "Jaehyeok Bae",
      "Jae-Han Lee",
      "Seyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12650",
    "title": "FRE: A Fast Method For Anomaly Detection And Segmentation",
    "abstract": "This paper presents a fast and principled approach for solving the visual anomaly detection and segmentation problem. In this setup, we have access to only anomaly-free training data and want to detect and identify anomalies of an arbitrary nature on test data. We propose the application of linear statistical dimensionality reduction techniques on the intermediate features produced by a pretrained DNN on the training data, in order to capture the low-dimensional subspace truly spanned by said features. We show that the \\emph{feature reconstruction error} (FRE), which is the $\\ell_2$-norm of the difference between the original feature in the high-dimensional space and the pre-image of its low-dimensional reduced embedding, is extremely effective for anomaly detection. Further, using the same feature reconstruction error concept on intermediate convolutional layers, we derive FRE maps that provide pixel-level spatial localization of the anomalies in the image (i.e. segmentation). Experiments using standard anomaly detection datasets and DNN architectures demonstrate that our method matches or exceeds best-in-class quality performance, but at a fraction of the computational and memory cost required by the state of the art. It can be trained and run very efficiently, even on a traditional CPU. ",
    "url": "https://arxiv.org/abs/2211.12650",
    "authors": [
      "Ibrahima Ndiour",
      "Nilesh Ahuja",
      "Utku Genc",
      "Omesh Tickoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12677",
    "title": "Word-Level Representation From Bytes For Language Modeling",
    "abstract": "Modern language models mostly take sub-words as input, a design that balances the trade-off between vocabulary size, number of parameters, and performance. However, sub-word tokenization still has disadvantages like not being robust to noise and difficult to generalize to new languages. Also, the current trend of scaling up models reveals that larger models require larger embeddings but that makes parallelization hard. Previous work on image classification proves splitting raw input into a sequence of chucks is a strong, model-agnostic inductive bias. Based on this observation, we rethink the existing character-aware method that takes character-level inputs but makes word-level sequence modeling and prediction. We overhaul this method by introducing a cross-attention network that builds word-level representation directly from bytes, and a sub-word level prediction based on word-level hidden states to avoid the time and space requirement of word-level prediction. With these two improvements combined, we have a token free model with slim input embeddings for downstream tasks. We name our method Byte2Word and perform evaluations on language modeling and text classification. Experiments show that Byte2Word is on par with the strong sub-word baseline BERT but only takes up 10\\% of embedding size. We further test our method on synthetic noise and cross-lingual transfer and find it competitive to baseline methods on both settings. ",
    "url": "https://arxiv.org/abs/2211.12677",
    "authors": [
      "Chu-Tak Lee",
      "Qipeng Guo",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.12698",
    "title": "Rega-Net:Retina Gabor Attention for Deep Convolutional Neural Networks",
    "abstract": "Extensive research works demonstrate that the attention mechanism in convolutional neural networks (CNNs) effectively improves accuracy. But little works design attention mechanisms using large receptive fields. In this work, we propose a novel attention method named Rega-net to increase CNN accuracy by enlarging the receptive field. Inspired by the mechanism of the human retina, we design convolutional kernels to resemble the non-uniformly distributed structure of the human retina. Then, we sample variable-resolution values in the Gabor function distribution and fill these values in retina-like kernels. This distribution allows important features to be more visible in the center position of the receptive field. We further design an attention module including these retina-like kernels. Experiments demonstrate that our Rega-Net achieves 79.963\\% top-1 accuracy on ImageNet-1K classification and 43.1\\% mAP on COCO2017 object detection. The mAP of the Rega-Net increased by up to 3.5\\% compared to baseline networks. ",
    "url": "https://arxiv.org/abs/2211.12698",
    "authors": [
      "Chun Bao",
      "Jie Cao",
      "Yaqian Ning",
      "Yang Cheng",
      "Qun Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12703",
    "title": "Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation",
    "abstract": "Researchers have proposed many methods for fair and robust machine learning, but comprehensive empirical evaluation of their subgroup robustness is lacking. In this work, we address this gap in the context of tabular data, where sensitive subgroups are clearly-defined, real-world fairness problems abound, and prior works often do not compare to state-of-the-art tree-based models as baselines. We conduct an empirical comparison of several previously-proposed methods for fair and robust learning alongside state-of-the-art tree-based methods and other baselines. Via experiments with more than $340{,}000$ model configurations on eight datasets, we show that tree-based methods have strong subgroup robustness, even when compared to robustness- and fairness-enhancing methods. Moreover, the best tree-based models tend to show good performance over a range of metrics, while robust or group-fair models can show brittleness, with significant performance differences across different metrics for a fixed model. We also demonstrate that tree-based models show less sensitivity to hyperparameter configurations, and are less costly to train. Our work suggests that tree-based ensemble models make an effective baseline for tabular data, and are a sensible default when subgroup robustness is desired. For associated code and detailed results, see https://github.com/jpgard/subgroup-robustness-grows-on-trees . ",
    "url": "https://arxiv.org/abs/2211.12703",
    "authors": [
      "Josh Gardner",
      "Zoran Popovi\u0107",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.12713",
    "title": "Reliable Robustness Evaluation via Automatically Constructed Attack  Ensembles",
    "abstract": "Attack Ensemble (AE), which combines multiple attacks together, provides a reliable way to evaluate adversarial robustness. In practice, AEs are often constructed and tuned by human experts, which however tends to be sub-optimal and time-consuming. In this work, we present AutoAE, a conceptually simple approach for automatically constructing AEs. In brief, AutoAE repeatedly adds the attack and its iteration steps to the ensemble that maximizes ensemble improvement per additional iteration consumed. We show theoretically that AutoAE yields AEs provably within a constant factor of the optimal for a given defense. We then use AutoAE to construct two AEs for $l_{\\infty}$ and $l_2$ attacks, and apply them without any tuning or adaptation to 45 top adversarial defenses on the RobustBench leaderboard. In all except one cases we achieve equal or better (often the latter) robustness evaluation than existing AEs, and notably, in 29 cases we achieve better robustness evaluation than the best known one. Such performance of AutoAE shows itself as a reliable evaluation protocol for adversarial robustness, which further indicates the huge potential of automatic AE construction. Code is available at \\url{https://github.com/LeegerPENG/AutoAE}. ",
    "url": "https://arxiv.org/abs/2211.12713",
    "authors": [
      "Shengcai Liu",
      "Fu Peng",
      "Ke Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.12714",
    "title": "Developmental Plasticity-inspired Adaptive Pruning for Deep Spiking and  Artificial Neural Networks",
    "abstract": "Developmental plasticity plays a vital role in shaping the brain's structure during ongoing learning in response to the dynamically changing environments. However, the existing network compression methods for deep artificial neural networks (ANNs) and spiking neural networks (SNNs) draw little inspiration from the brain's developmental plasticity mechanisms, thus limiting their ability to learn efficiently, rapidly, and accurately. This paper proposed a developmental plasticity-inspired adaptive pruning (DPAP) method, with inspiration from the adaptive developmental pruning of dendritic spines, synapses, and neurons according to the \"use it or lose it, gradually decay\" principle. The proposed DPAP model considers multiple biologically realistic mechanisms (such as dendritic spine dynamic plasticity, activity-dependent neural spiking trace, local synaptic plasticity), with the addition of an adaptive pruning strategy, so that the network structure can be dynamically optimized during learning without any pre-training and retraining. We demonstrated that the proposed DPAP method applied to deep ANNs and SNNs could learn efficient network architectures that retain only relevant important connections and neurons. Extensive comparative experiments show consistent and remarkable performance and speed boost with the extremely compressed networks on a diverse set of benchmark tasks, especially neuromorphic datasets for SNNs. This work explores how developmental plasticity enables the complex deep networks to gradually evolve into brain-like efficient and compact structures, eventually achieving state-of-the-art (SOTA) performance for biologically realistic SNNs. ",
    "url": "https://arxiv.org/abs/2211.12714",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Yi Zeng",
      "Guobin Shen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12715",
    "title": "Embedding Compression for Text Classification Using Dictionary Screening",
    "abstract": "In this paper, we propose a dictionary screening method for embedding compression in text classification tasks. The key purpose of this method is to evaluate the importance of each keyword in the dictionary. To this end, we first train a pre-specified recurrent neural network-based model using a full dictionary. This leads to a benchmark model, which we then use to obtain the predicted class probabilities for each sample in a dataset. Next, to evaluate the impact of each keyword in affecting the predicted class probabilities, we develop a novel method for assessing the importance of each keyword in a dictionary. Consequently, each keyword can be screened, and only the most important keywords are reserved. With these screened keywords, a new dictionary with a considerably reduced size can be constructed. Accordingly, the original text sequence can be substantially compressed. The proposed method leads to significant reductions in terms of parameters, average text sequence, and dictionary size. Meanwhile, the prediction power remains very competitive compared to the benchmark model. Extensive numerical studies are presented to demonstrate the empirical performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2211.12715",
    "authors": [
      "Jing Zhou",
      "Xinru Jing",
      "Muyu Liu",
      "Hansheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.12735",
    "title": "Integrally Pre-Trained Transformer Pyramid Networks",
    "abstract": "In this paper, we present an integral pre-training framework based on masked image modeling (MIM). We advocate for pre-training the backbone and neck jointly so that the transfer gap between MIM and downstream recognition tasks is minimal. We make two technical contributions. First, we unify the reconstruction and recognition necks by inserting a feature pyramid into the pre-training stage. Second, we complement mask image modeling (MIM) with masked feature modeling (MFM) that offers multi-stage supervision to the feature pyramid. The pre-trained models, termed integrally pre-trained transformer pyramid networks (iTPNs), serve as powerful foundation models for visual recognition. In particular, the base/large-level iTPN achieves an 86.2%/87.8% top-1 accuracy on ImageNet-1K, a 53.2%/55.6% box AP on COCO object detection with 1x training schedule using Mask-RCNN, and a 54.7%/57.7% mIoU on ADE20K semantic segmentation using UPerHead -- all these results set new records. Our work inspires the community to work on unifying upstream pre-training and downstream fine-tuning tasks. Code and the pre-trained models will be released at https://github.com/sunsmarterjie/iTPN. ",
    "url": "https://arxiv.org/abs/2211.12735",
    "authors": [
      "Yunjie Tian",
      "Lingxi Xie",
      "Zhaozhi Wang",
      "Longhui Wei",
      "Xiaopeng Zhang",
      "Jianbin Jiao",
      "Yaowei Wang",
      "Qi Tian",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12748",
    "title": "Dynamic Appearance: A Video Representation for Action Recognition with  Joint Training",
    "abstract": "Static appearance of video may impede the ability of a deep neural network to learn motion-relevant features in video action recognition. In this paper, we introduce a new concept, Dynamic Appearance (DA), summarizing the appearance information relating to movement in a video while filtering out the static information considered unrelated to motion. We consider distilling the dynamic appearance from raw video data as a means of efficient video understanding. To this end, we propose the Pixel-Wise Temporal Projection (PWTP), which projects the static appearance of a video into a subspace within its original vector space, while the dynamic appearance is encoded in the projection residual describing a special motion pattern. Moreover, we integrate the PWTP module with a CNN or Transformer into an end-to-end training framework, which is optimized by utilizing multi-objective optimization algorithms. We provide extensive experimental results on four action recognition benchmarks: Kinetics400, Something-Something V1, UCF101 and HMDB51. ",
    "url": "https://arxiv.org/abs/2211.12748",
    "authors": [
      "Guoxi Huang",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12752",
    "title": "Agent-Specific Deontic Modality Detection in Legal Language",
    "abstract": "Legal documents are typically long and written in legalese, which makes it particularly difficult for laypeople to understand their rights and duties. While natural language understanding technologies can be valuable in supporting such understanding in the legal domain, the limited availability of datasets annotated for deontic modalities in the legal domain, due to the cost of hiring experts and privacy issues, is a bottleneck. To this end, we introduce, LEXDEMOD, a corpus of English contracts annotated with deontic modality expressed with respect to a contracting party or agent along with the modal triggers. We benchmark this dataset on two tasks: (i) agent-specific multi-label deontic modality classification, and (ii) agent-specific deontic modality and trigger span detection using Transformer-based (Vaswani et al., 2017) language models. Transfer learning experiments show that the linguistic diversity of modal expressions in LEXDEMOD generalizes reasonably from lease to employment and rental agreements. A small case study indicates that a model trained on LEXDEMOD can detect red flags with high recall. We believe our work offers a new research direction for deontic modality detection in the legal domain. ",
    "url": "https://arxiv.org/abs/2211.12752",
    "authors": [
      "Abhilasha Sancheti",
      "Aparna Garimella",
      "Balaji Vasan Srinivasan",
      "Rachel Rudinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.12758",
    "title": "PANeRF: Pseudo-view Augmentation for Improved Neural Radiance Fields  Based on Few-shot Inputs",
    "abstract": "The method of neural radiance fields (NeRF) has been developed in recent years, and this technology has promising applications for synthesizing novel views of complex scenes. However, NeRF requires dense input views, typically numbering in the hundreds, for generating high-quality images. With a decrease in the number of input views, the rendering quality of NeRF for unseen viewpoints tends to degenerate drastically. To overcome this challenge, we propose pseudo-view augmentation of NeRF, a scheme that expands a sufficient amount of data by considering the geometry of few-shot inputs. We first initialized the NeRF network by leveraging the expanded pseudo-views, which efficiently minimizes uncertainty when rendering unseen views. Subsequently, we fine-tuned the network by utilizing sparse-view inputs containing precise geometry and color information. Through experiments under various settings, we verified that our model faithfully synthesizes novel-view images of superior quality and outperforms existing methods for multi-view datasets. ",
    "url": "https://arxiv.org/abs/2211.12758",
    "authors": [
      "Young Chun Ahn",
      "Seokhwan Jang",
      "Sungheon Park",
      "Ji-Yeon Kim",
      "Nahyup Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12759",
    "title": "NAS-LID: Efficient Neural Architecture Search with Local Intrinsic  Dimension",
    "abstract": "One-shot neural architecture search (NAS) substantially improves the search efficiency by training one supernet to estimate the performance of every possible child architecture (i.e., subnet). However, the inconsistency of characteristics among subnets incurs serious interference in the optimization, resulting in poor performance ranking correlation of subnets. Subsequent explorations decompose supernet weights via a particular criterion, e.g., gradient matching, to reduce the interference; yet they suffer from huge computational cost and low space separability. In this work, we propose a lightweight and effective local intrinsic dimension (LID)-based method NAS-LID. NAS-LID evaluates the geometrical properties of architectures by calculating the low-cost LID features layer-by-layer, and the similarity characterized by LID enjoys better separability compared with gradients, which thus effectively reduces the interference among subnets. Extensive experiments on NASBench-201 indicate that NAS-LID achieves superior performance with better efficiency. Specifically, compared to the gradient-driven method, NAS-LID can save up to 86% of GPU memory overhead when searching on NASBench-201. We also demonstrate the effectiveness of NAS-LID on ProxylessNAS and OFA spaces. Source code:https://github.com/marsggbo/NAS-LID. ",
    "url": "https://arxiv.org/abs/2211.12759",
    "authors": [
      "Xin He",
      "Jiangchao Yao",
      "Yuxin Wang",
      "Zhenheng Tang",
      "Ka Chu Cheung",
      "Simon See",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12767",
    "title": "Cambrian Explosion Algorithm for Multi-Objective Association Rules  Mining",
    "abstract": "Association rule mining is one of the most studied research fields of data mining, with applications ranging from grocery basket problems to highly explainable classification systems. Classical association rule mining algorithms have several flaws especially with regards to their execution times, memory usage and number of rules produced. An alternative is the use of meta-heuristics, which have been used on several optimisation problems. This paper has two objectives. First, we provide a comparison of the performances of state-of-the-art meta-heuristics on the association rule mining problem. We use the multi-objective versions of those algorithms using support, confidence and cosine. Second, we propose a new algorithm designed to mine rules efficiently from massive datasets by exploring a large variety of solutions, akin to the explosion of species diversity of the Cambrian Explosion. We compare our algorithm to 20 benchmark algorithms on 22 real-world data-sets, and show that our algorithm present good results and outperform several state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2211.12767",
    "authors": [
      "Th\u00e9ophile Berteloot",
      "Richard Khoury",
      "Audrey Durand"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.12773",
    "title": "Learning Regularized Positional Encoding for Molecular Prediction",
    "abstract": "Machine learning has become a promising approach for molecular modeling. Positional quantities, such as interatomic distances and bond angles, play a crucial role in molecule physics. The existing works rely on careful manual design of their representation. To model the complex nonlinearity in predicting molecular properties in an more end-to-end approach, we propose to encode the positional quantities with a learnable embedding that is continuous and differentiable. A regularization technique is employed to encourage embedding smoothness along the physical dimension. We experiment with a variety of molecular property and force field prediction tasks. Improved performance is observed for three different model architectures after plugging in the proposed positional encoding method. In addition, the learned positional encoding allows easier physics-based interpretation. We observe that tasks of similar physics have the similar learned positional encoding. ",
    "url": "https://arxiv.org/abs/2211.12773",
    "authors": [
      "Xiang Gao",
      "Weihao Gao",
      "Wenzhi Xiao",
      "Zhirui Wang",
      "Chong Wang",
      "Liang Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2211.12781",
    "title": "Breaking the Representation Bottleneck of Chinese Characters: Neural  Machine Translation with Stroke Sequence Modeling",
    "abstract": "Existing research generally treats Chinese character as a minimum unit for representation. However, such Chinese character representation will suffer two bottlenecks: 1) Learning bottleneck, the learning cannot benefit from its rich internal features (e.g., radicals and strokes); and 2) Parameter bottleneck, each individual character has to be represented by a unique vector. In this paper, we introduce a novel representation method for Chinese characters to break the bottlenecks, namely StrokeNet, which represents a Chinese character by a Latinized stroke sequence (e.g., \"ao1 (concave)\" to \"ajaie\" and \"tu1 (convex)\" to \"aeaqe\"). Specifically, StrokeNet maps each stroke to a specific Latin character, thus allowing similar Chinese characters to have similar Latin representations. With the introduction of StrokeNet to neural machine translation (NMT), many powerful but not applicable techniques to non-Latin languages (e.g., shared subword vocabulary learning and ciphertext-based data augmentation) can now be perfectly implemented. Experiments on the widely-used NIST Chinese-English, WMT17 Chinese-English and IWSLT17 Japanese-English NMT tasks show that StrokeNet can provide a significant performance boost over the strong baselines with fewer model parameters, achieving 26.5 BLEU on the WMT17 Chinese-English task which is better than any previously reported results without using monolingual data. Code and scripts are freely available at https://github.com/zjwang21/StrokeNet. ",
    "url": "https://arxiv.org/abs/2211.12781",
    "authors": [
      "Zhijun Wang",
      "Xuebo Liu",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12791",
    "title": "An ensemble of VisNet, Transformer-M, and pretraining models for  molecular property prediction in OGB Large-Scale Challenge @ NeurIPS 2022",
    "abstract": "In the technical report, we provide our solution for OGB-LSC 2022 Graph Regression Task. The target of this task is to predict the quantum chemical property, HOMO-LUMO gap for a given molecule on PCQM4Mv2 dataset. In the competition, we designed two kinds of models: Transformer-M-ViSNet which is an geometry-enhanced graph neural network for fully connected molecular graphs and Pretrained-3D-ViSNet which is a pretrained ViSNet by distilling geomeotric information from optimized structures. With an ensemble of 22 models, ViSNet Team achieved the MAE of 0.0723 eV on the test-challenge set, dramatically reducing the error by 39.75% compared with the best method in the last year competition. ",
    "url": "https://arxiv.org/abs/2211.12791",
    "authors": [
      "Yusong Wang",
      "Shaoning Li",
      "Tong Wang",
      "Zun Wang",
      "Xinheng He",
      "Bin Shao",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2211.12792",
    "title": "MECCH: Metapath Context Convolution-based Heterogeneous Graph Neural  Networks",
    "abstract": "Heterogeneous graph neural networks (HGNNs) were proposed for representation learning on structural data with multiple types of nodes and edges. Researchers have developed metapath-based HGNNs to deal with the over-smoothing problem of relation-based HGNNs. However, existing metapath-based models suffer from either information loss or high computation costs. To address these problems, we design a new Metapath Context Convolution-based Heterogeneous Graph Neural Network (MECCH). Specifically, MECCH applies three novel components after feature preprocessing to extract comprehensive information from the input graph efficiently: (1) metapath context construction, (2) metapath context encoder, and (3) convolutional metapath fusion. Experiments on five real-world heterogeneous graph datasets for node classification and link prediction show that MECCH achieves superior prediction accuracy compared with state-of-the-art baselines with improved computational efficiency. ",
    "url": "https://arxiv.org/abs/2211.12792",
    "authors": [
      "Xinyu Fu",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12794",
    "title": "Zero Forcing Uplink Detection through Large-Scale RIS: System  Performance and Phase Shift Design",
    "abstract": "A multiple-input multiple-output wireless communication system is analytically studied, which operates with the aid of a large-scale reconfigurable intelligent surface (LRIS). LRIS is equipped with multiple passive elements with discrete phase adjustment capabilities, and independent Rician fading conditions are assumed for both the transmitter-to-LRIS and LRIS-to-receiver links. A direct transceiver link is also considered which is modeled by Rayleigh fading distribution. The system performance is analytically studied when the linear yet efficient zero-forcing detection is implemented at the receiver. In particular, the outage performance is derived in closed-form expression for different system configuration setups with regards to the available channel state information (CSI) at the receiver. In fact, the case of both perfect and imperfect CSI is analyzed. Also, an efficient phase shift design approach at LRIS is introduced, which is linear on the number of passive elements and receive antennas. The proposed phase shift design can be applied on two different modes of operation; namely, when the system strives to adapt either on the instantaneous or statistical CSI. Finally, some impactful engineering insights are provided, such as how the channel fading conditions, CSI, discrete phase shift resolution, and volume of antenna/LRIS element arrays impact on the overall system performance. ",
    "url": "https://arxiv.org/abs/2211.12794",
    "authors": [
      "Nikolaos I. Miridakis",
      "Theodoros A. Tsiftsis",
      "Rugui Yao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.12817",
    "title": "Reason from Context with Self-supervised Learning",
    "abstract": "A tiny object in the sky cannot be an elephant. Context reasoning is critical in visual recognition, where current inputs need to be interpreted in the light of previous experience and knowledge. To date, research into contextual reasoning in visual recognition has largely proceeded with supervised learning methods. The question of whether contextual knowledge can be captured with self-supervised learning regimes remains under-explored. Here, we established a methodology for context-aware self-supervised learning. We proposed a novel Self-supervised Learning Method for Context Reasoning (SeCo), where the only inputs to SeCo are unlabeled images with multiple objects present in natural scenes. Similar to the distinction between fovea and periphery in human vision, SeCo processes self-proposed target object regions and their contexts separately, and then employs a learnable external memory for retrieving and updating context-relevant target information. To evaluate the contextual associations learned by the computational models, we introduced two evaluation protocols, lift-the-flap and object priming, addressing the problems of \"what\" and \"where\" in context reasoning. In both tasks, SeCo outperformed all state-of-the-art (SOTA) self-supervised learning methods by a significant margin. Our network analysis revealed that the external memory in SeCo learns to store prior contextual knowledge, facilitating target identity inference in lift-the-flap task. Moreover, we conducted psychophysics experiments and introduced a Human benchmark in Object Priming dataset (HOP). Our quantitative and qualitative results demonstrate that SeCo approximates human-level performance and exhibits human-like behavior. All our source code and data are publicly available here. ",
    "url": "https://arxiv.org/abs/2211.12817",
    "authors": [
      "Xiao Liu",
      "Ankur Sikarwar",
      "Joo Hwee Lim",
      "Gabriel Kreiman",
      "Zenglin Shi",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12819",
    "title": "Tracking biomedical articles along the translational continuum: a  measure based on biomedical knowledge representation",
    "abstract": "Keeping track of translational research is essential to evaluating the performance of programs on translational medicine. Despite several indicators in previous studies, a consensus measure is still needed to represent the translational features of biomedical research at the article level. In this study, we first trained semantic representations of biomedical entities and documents (i.e., bio entity2vec and bio doc2vec) based on over 30 million PubMed articles. With these vectors, we then developed a new measure called Translational Progression (TP) for tracking biomedical articles along the translational continuum. We validated the effectiveness of TP from two perspectives (Clinical trial phase identification and ACH classification), which showed excellent consistency between TP and other indicators. Meanwhile, TP has several advantages. First, it can track the degree of translation of biomedical research dynamically and in real time. Second, it is straightforward to interpret and operationalize. Third, it doesn%u2019t require labor-intensive MeSH labeling and it is suitable for big scholarly data as well as papers that are not indexed in PubMed. In addition, we examined the translational progressions of biomedical research from three dimensions (including overall distribution, time, and research topic), which revealed three significant findings. The proposed measure in this study could be used by policymakers to monitor biomedical research with high translational potential in real time and make better decisions. It can also be adopted and improved for other domains, such as physics or computer science, to assess the application value of scientific discoveries. ",
    "url": "https://arxiv.org/abs/2211.12819",
    "authors": [
      "Xin Li",
      "Xuli Tang",
      "Wei Lu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2211.12821",
    "title": "Explainable AI for Pre-Trained Code Models: What Do They Learn? When  They Do Not Work?",
    "abstract": "In recent years, there has been a wide interest in designing deep neural network-based models that automate downstream software engineering tasks, such as program document generation, code search, and program repair. Although the main objective of these studies is to improve the effectiveness of the downstream task, many studies only attempt to employ the next best neural network model, without a proper in-depth analysis of why a particular solution works or does not, on particular tasks or scenarios. In this paper, using an eXplainable AI (XAI) method (attention mechanism), we study state-of-the-art Transformer-based models (CodeBERT and GraphCodeBERT) on a set of software engineering downstream tasks: code document generation (CDG), code refinement (CR), and code translation (CT). We first evaluate the validity of the attention mechanism on each particular task. Then, through quantitative and qualitative studies, we identify what CodeBERT and GraphCodeBERT learn (put the highest attention on, in terms of source code token types), on these tasks. Finally, we show some of the common patterns when the model does not work as expected (perform poorly while the problem in hand is easy) and suggest recommendations that may alleviate the observed challenges. ",
    "url": "https://arxiv.org/abs/2211.12821",
    "authors": [
      "Ahmad Haji Mohammadkhani",
      "Chakkrit Tantithamthavorn",
      "Hadi Hemmati"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.12827",
    "title": "Video Instance Shadow Detection",
    "abstract": "Video instance shadow detection aims to simultaneously detect, segment, associate, and track paired shadow-object associations in videos. This work has three key contributions to the task. First, we design SSIS-Track, a new framework to extract shadow-object associations in videos with paired tracking and without category specification; especially, we strive to maintain paired tracking even the objects/shadows are temporarily occluded for several frames. Second, we leverage both labeled images and unlabeled videos, and explore temporal coherence by augmenting the tracking ability via an association cycle consistency loss to optimize SSIS-Track's performance. Last, we build $\\textit{SOBA-VID}$, a new dataset with 232 unlabeled videos of ${5,863}$ frames for training and 60 labeled videos of ${1,182}$ frames for testing. Experimental results show that SSIS-Track surpasses baselines built from SOTA video tracking and instance-shadow-detection methods by a large margin. In the end, we showcase several video-level applications. ",
    "url": "https://arxiv.org/abs/2211.12827",
    "authors": [
      "Zhenghao Xing",
      "Tianyu Wang",
      "Xiaowei Hu",
      "Haoran Wu",
      "Chi-Wing Fu",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12850",
    "title": "OOD-DiskANN: Efficient and Scalable Graph ANNS for Out-of-Distribution  Queries",
    "abstract": "State-of-the-art algorithms for Approximate Nearest Neighbor Search (ANNS) such as DiskANN, FAISS-IVF, and HNSW build data dependent indices that offer substantially better accuracy and search efficiency over data-agnostic indices by overfitting to the index data distribution. When the query data is drawn from a different distribution - e.g., when index represents image embeddings and query represents textual embeddings - such algorithms lose much of this performance advantage. On a variety of datasets, for a fixed recall target, latency is worse by an order of magnitude or more for Out-Of-Distribution (OOD) queries as compared to In-Distribution (ID) queries. The question we address in this work is whether ANNS algorithms can be made efficient for OOD queries if the index construction is given access to a small sample set of these queries. We answer positively by presenting OOD-DiskANN, which uses a sparing sample (1% of index set size) of OOD queries, and provides up to 40% improvement in mean query latency over SoTA algorithms of a similar memory footprint. OOD-DiskANN is scalable and has the efficiency of graph-based ANNS indices. Some of our contributions can improve query efficiency for ID queries as well. ",
    "url": "https://arxiv.org/abs/2211.12850",
    "authors": [
      "Shikhar Jaiswal",
      "Ravishankar Krishnaswamy",
      "Ankit Garg",
      "Harsha Vardhan Simhadri",
      "Sheshansh Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.12851",
    "title": "A Streamlit-based Artificial Intelligence Trust Platform for  Next-Generation Wireless Networks",
    "abstract": "With the rapid development and integration of artificial intelligence (AI) methods in next-generation networks (NextG), AI algorithms have provided significant advantages for NextG in terms of frequency spectrum usage, bandwidth, latency, and security. A key feature of NextG is the integration of AI, i.e., self-learning architecture based on self-supervised algorithms, to improve the performance of the network. A secure AI-powered structure is also expected to protect NextG networks against cyber-attacks. However, AI itself may be attacked, i.e., model poisoning targeted by attackers, and it results in cybersecurity violations. This paper proposes an AI trust platform using Streamlit for NextG networks that allows researchers to evaluate, defend, certify, and verify their AI models and applications against adversarial threats of evasion, poisoning, extraction, and interference. ",
    "url": "https://arxiv.org/abs/2211.12851",
    "authors": [
      "M. Kuzlu",
      "F. O. Catak",
      "S. Sarp",
      "U. Cali",
      "O Gueler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.12852",
    "title": "GraphWOZ: Dialogue Management with Conversational Knowledge Graphs",
    "abstract": "We present a new approach to dialogue management using conversational knowledge graphs as core representation of the dialogue state. To this end, we introduce a new dataset, GraphWOZ, which comprises Wizard-of-Oz dialogues in which human participants interact with a robot acting as a receptionist. In contrast to most existing work on dialogue management, GraphWOZ relies on a dialogue state explicitly represented as a dynamic knowledge graph instead of a fixed set of slots. This graph is composed of a varying number of entities (such as individuals, places, events, utterances and mentions) and relations between them (such as persons being part of a group or attending an event). The graph is then regularly updated on the basis of new observations and system actions. GraphWOZ is released along with detailed manual annotations related to the user intents, system responses, and reference relations occurring in both user and system turns. Based on GraphWOZ, we present experimental results for two dialogue management tasks, namely conversational entity linking and response ranking. For conversational entity linking, we show how to connect utterance mentions to their corresponding entity in the knowledge graph with a neural model relying on a combination of both string and graph-based features. Response ranking is then performed by summarizing the relevant content of the graph into a text, which is concatenated with the dialogue history and employed as input to score possible responses to a given dialogue state. ",
    "url": "https://arxiv.org/abs/2211.12852",
    "authors": [
      "Nicholas Thomas Walker",
      "Stefan Ultes",
      "Pierre Lison"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12853",
    "title": "BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) have received considerable attention recently, due to its impressive capability in photo-realistic 3D reconstruction and novel view synthesis, given a set of posed camera images. Earlier work usually assumes the input images are in good quality. However, image degradation (e.g. image motion blur in low-light conditions) can easily happen in real-world scenarios, which would further affect the rendering quality of NeRF. In this paper, we present a novel bundle adjusted deblur Neural Radiance Fields (BAD-NeRF), which can be robust to severe motion blurred images and inaccurate camera poses. Our approach models the physical image formation process of a motion blurred image, and jointly learns the parameters of NeRF and recovers the camera motion trajectories during exposure time. In experiments, we show that by directly modeling the real physical image formation process, BAD-NeRF achieves superior performance over prior works on both synthetic and real datasets. ",
    "url": "https://arxiv.org/abs/2211.12853",
    "authors": [
      "Peng Wang",
      "Lingzhe Zhao",
      "Ruijie Ma",
      "Peidong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12857",
    "title": "Explaining Image Classifiers with Multiscale Directional Image  Representation",
    "abstract": "Image classifiers are known to be difficult to interpret and therefore require explanation methods to understand their decisions. We present ShearletX, a novel mask explanation method for image classifiers based on the shearlet transform -- a multiscale directional image representation. Current mask explanation methods are regularized by smoothness constraints that protect against undesirable fine-grained explanation artifacts. However, the smoothness of a mask limits its ability to separate fine-detail patterns, that are relevant for the classifier, from nearby nuisance patterns, that do not affect the classifier. ShearletX solves this problem by avoiding smoothness regularization all together, replacing it by shearlet sparsity constraints. The resulting explanations consist of a few edges, textures, and smooth parts of the original image, that are the most relevant for the decision of the classifier. To support our method, we propose a mathematical definition for explanation artifacts and an information theoretic score to evaluate the quality of mask explanations. We demonstrate the superiority of ShearletX over previous mask based explanation methods using these new metrics, and present exemplary situations where separating fine-detail patterns allows explaining phenomena that were not explainable before. ",
    "url": "https://arxiv.org/abs/2211.12857",
    "authors": [
      "Stefan Kolek",
      "Robert Windesheim",
      "Hector Andrade Loarca",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12875",
    "title": "A Survey of Deep Graph Clustering: Taxonomy, Challenge, and Application",
    "abstract": "Graph clustering, which aims to divide the nodes in the graph into several distinct clusters, is a fundamental and challenging task. In recent years, deep graph clustering methods have been increasingly proposed and achieved promising performance. However, the corresponding survey paper is scarce and it is imminent to make a summary in this field. From this motivation, this paper makes the first comprehensive survey of deep graph clustering. Firstly, the detailed definition of deep graph clustering and the important baseline methods are introduced. Besides, the taxonomy of deep graph clustering methods is proposed based on four different criteria including graph type, network architecture, learning paradigm, and clustering method. In addition, through the careful analysis of the existing works, the challenges and opportunities from five perspectives are summarized. At last, the applications of deep graph clustering in four domains are presented. It is worth mentioning that a collection of state-of-the-art deep graph clustering methods including papers, codes, and datasets is available on GitHub. We hope this work will serve as a quick guide and help researchers to overcome challenges in this vibrant field. ",
    "url": "https://arxiv.org/abs/2211.12875",
    "authors": [
      "Liu Yue",
      "Xia Jun",
      "Zhou Sihang",
      "Wang Siwei",
      "Guo Xifeng",
      "Yang Xihong",
      "Liang Ke",
      "Tu Wenxuan",
      "Li Stan Z.",
      "Liu Xin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12879",
    "title": "Data Augmentation Vision Transformer for Fine-grained Image  Classification",
    "abstract": "Recently, the vision transformer (ViT) has made breakthroughs in image recognition. Its self-attention mechanism (MSA) can extract discriminative labeling information of different pixel blocks to improve image classification accuracy. However, the classification marks in their deep layers tend to ignore local features between layers. In addition, the embedding layer will be fixed-size pixel blocks. Input network Inevitably introduces additional image noise. To this end, this paper studies a data augmentation vision transformer (DAVT) based on data augmentation and proposes a data augmentation method for attention cropping, which uses attention weights as the guide to crop images and improve the ability of the network to learn critical features. Secondly, this paper also proposes a hierarchical attention selection (HAS) method, which improves the ability of discriminative markers between levels of learning by filtering and fusing labels between levels. Experimental results show that the accuracy of this method on the two general datasets, CUB-200-2011, and Stanford Dogs, is better than the existing mainstream methods, and its accuracy is 1.4\\% and 1.6\\% higher than the original ViT, respectively. ",
    "url": "https://arxiv.org/abs/2211.12879",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu",
      "Weibin Qiu",
      "Weijie Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12881",
    "title": "DGEKT: A Dual Graph Ensemble Learning Method for Knowledge Tracing",
    "abstract": "Knowledge tracing aims to trace students' evolving knowledge states by predicting their future performance on concept-related exercises. Recently, some graph-based models have been developed to incorporate the relationships between exercises to improve knowledge tracing, but only a single type of relationship information is generally explored. In this paper, we present a novel Dual Graph Ensemble learning method for Knowledge Tracing (DGEKT), which establishes a dual graph structure of students' learning interactions to capture the heterogeneous exercise-concept associations and interaction transitions by hypergraph modeling and directed graph modeling, respectively. To ensemble the dual graph models, we introduce the technique of online knowledge distillation, due to the fact that although the knowledge tracing model is expected to predict students' responses to the exercises related to different concepts, it is optimized merely with respect to the prediction accuracy on a single exercise at each step. With online knowledge distillation, the dual graph models are adaptively combined to form a stronger teacher model, which in turn provides its predictions on all exercises as extra supervision for better modeling ability. In the experiments, we compare DGEKT against eight knowledge tracing baselines on three benchmark datasets, and the results demonstrate that DGEKT achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2211.12881",
    "authors": [
      "Chaoran Cui",
      "Yumo Yao",
      "Chunyun Zhang",
      "Hebo Ma",
      "Yuling Ma",
      "Zhaochun Ren",
      "Chen Zhang",
      "James Ko"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.12886",
    "title": "OReX: Object Reconstruction from Planner Cross-sections Using Neural  Fields",
    "abstract": "Reconstructing 3D shapes from planar cross-sections is a challenge inspired by downstream applications like medical imaging and geographic informatics. The input is an in/out indicator function fully defined on a sparse collection of planes in space, and the output is an interpolation of the indicator function to the entire volume. Previous works addressing this sparse and ill-posed problem either produce low quality results, or rely on additional priors such as target topology, appearance information, or input normal directions. In this paper, we present OReX, a method for 3D shape reconstruction from slices alone, featuring a Neural Field as the interpolation prior. A simple neural network is trained on the input planes to receive a 3D coordinate and return an inside/outside estimate for the query point. This prior is powerful in inducing smoothness and self-similarities. The main challenge for this approach is high-frequency details, as the neural prior is overly smoothing. To alleviate this, we offer an iterative estimation architecture and a hierarchical input sampling scheme that encourage coarse-to-fine training, allowing focusing on high frequencies at later stages. In addition, we identify and analyze a common ripple-like effect stemming from the mesh extraction step. We mitigate it by regularizing the spatial gradients of the indicator function around input in/out boundaries, cutting the problem at the root. Through extensive qualitative and quantitative experimentation, we demonstrate our method is robust, accurate, and scales well with the size of the input. We report state-of-the-art results compared to previous approaches and recent potential solutions, and demonstrate the benefit of our individual contributions through analysis and ablation studies. ",
    "url": "https://arxiv.org/abs/2211.12886",
    "authors": [
      "Haim Sawdayee",
      "Amir Vaxman",
      "Amit H. Bermano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12899",
    "title": "Emerging Biometric Modalities and their Use: Loopholes in the  Terminology of the GDPR and Resulting Privacy Risks",
    "abstract": "Technological advancements allow biometric applications to be more omnipresent than in any other time before. This paper argues that in the current EU data protection regulation, classification applications using biometric data receive less protection compared to biometric recognition. We analyse preconditions in the regulatory language and explore how this has the potential to be the source of unique privacy risks for processing operations classifying individuals based on soft traits like emotions. This can have high impact on personal freedoms and human rights and therefore, should be subject to data protection impact assessment. ",
    "url": "https://arxiv.org/abs/2211.12899",
    "authors": [
      "Tamas Bisztray",
      "Nils Gruschka",
      "Thirimachos Bourlai",
      "Lothar Fritsch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.12914",
    "title": "Open-vocabulary Attribute Detection",
    "abstract": "Vision-language modeling has enabled open-vocabulary tasks where predictions can be queried using any text prompt in a zero-shot manner. Existing open-vocabulary tasks focus on object classes, whereas research on object attributes is limited due to the lack of a reliable attribute-focused evaluation benchmark. This paper introduces the Open-Vocabulary Attribute Detection (OVAD) task and the corresponding OVAD benchmark. The objective of the novel task and benchmark is to probe object-level attribute information learned by vision-language models. To this end, we created a clean and densely annotated test set covering 117 attribute classes on the 80 object classes of MS COCO. It includes positive and negative annotations, which enables open-vocabulary evaluation. Overall, the benchmark consists of 1.4 million annotations. For reference, we provide a first baseline method for open-vocabulary attribute detection. Moreover, we demonstrate the benchmark's value by studying the attribute detection performance of several foundation models. Project page https://ovad-benchmark.github.io/ ",
    "url": "https://arxiv.org/abs/2211.12914",
    "authors": [
      "Mar\u00eda A. Bravo",
      "Sudhanshu Mittal",
      "Simon Ging",
      "Thomas Brox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12916",
    "title": "An information security monitoring and management system for 5G and 6G  Networks based on SDN/NFV",
    "abstract": "An approach to using the concept of Software-Defined Networking and Network Functions Virtualization (SDN/NFV) for the implementation of an information security monitoring and management system in 5G and 6G networks is proposed. SDN switches based on the OpenFlow protocol are offered as network sensors. In order to reduce the time for finding a subset of the right rules in the vast array of all rules on traffic filtering systems that are logically located on sensors, a method of processing and filtering traffic in 5G and 6G transport networks is proposed. This method is based on DPDK with the LPM algorithm and is capable of processing up to 8 megapackets per second on 1 CPU core; the packet processing takes O(1), which is significantly lower than with similar algorithms. The managing subsystem consists of regional monitoring centres and a main one. The main Monitoring Centre includes a main cluster of SDN controllers along with Active/Active redundancy scheme. The regional centres represent SDN software controllers that manage locally subordinate sensors. All the managing centres are interconnected via the Transport subsystem and form a network. An algorithm for network sensor load balancing between SDN controllers has been developed in order to provide fault tolerance, load balancing and network connectivity. The algorithm results in a set of optimal sensor groups with total load not exceeding the maximum capacity of the SDN controllers. ",
    "url": "https://arxiv.org/abs/2211.12916",
    "authors": [
      "Igor Buzhin",
      "Veronica Antonova",
      "Yury Mironov",
      "Vladislav Gnezdilov",
      "Eldar Gaifutdinov",
      "Mikhail Gorodnichev"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.12931",
    "title": "Can we Adopt Self-supervised Pretraining for Chest X-Rays?",
    "abstract": "Chest radiograph (or Chest X-Ray, CXR) is a popular medical imaging modality that is used by radiologists across the world to diagnose heart or lung conditions. Over the last decade, Convolutional Neural Networks (CNN), have seen success in identifying pathologies in CXR images. Typically, these CNNs are pretrained on the standard ImageNet classification task, but this assumes availability of large-scale annotated datasets. In this work, we analyze the utility of pretraining on unlabeled ImageNet or Chest X-Ray (CXR) datasets using various algorithms and in multiple settings. Some findings of our work include: (i) supervised training with labeled ImageNet learns strong representations that are hard to beat; (ii) self-supervised pretraining on ImageNet (~1M images) shows performance similar to self-supervised pretraining on a CXR dataset (~100K images); and (iii) the CNN trained on supervised ImageNet can be trained further with self-supervised CXR images leading to improvements, especially when the downstream dataset is on the order of a few thousand images. ",
    "url": "https://arxiv.org/abs/2211.12931",
    "authors": [
      "Arsh Verma",
      "Makarand Tapaswi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12933",
    "title": "Join the High Accuracy Club on ImageNet with A Binary Neural Network  Ticket",
    "abstract": "Binary neural networks are the extreme case of network quantization, which has long been thought of as a potential edge machine learning solution. However, the significant accuracy gap to the full-precision counterparts restricts their creative potential for mobile applications. In this work, we revisit the potential of binary neural networks and focus on a compelling but unanswered problem: how can a binary neural network achieve the crucial accuracy level (e.g., 80%) on ILSVRC-2012 ImageNet? We achieve this goal by enhancing the optimization process from three complementary perspectives: (1) We design a novel binary architecture BNext based on a comprehensive study of binary architectures and their optimization process. (2) We propose a novel knowledge-distillation technique to alleviate the counter-intuitive overfitting problem observed when attempting to train extremely accurate binary models. (3) We analyze the data augmentation pipeline for binary networks and modernize it with up-to-date techniques from full-precision models. The evaluation results on ImageNet show that BNext, for the first time, pushes the binary model accuracy boundary to 80.57% and significantly outperforms all the existing binary networks. Code and trained models are available at: (blind URL, see appendix). ",
    "url": "https://arxiv.org/abs/2211.12933",
    "authors": [
      "Nianhui Guo",
      "Joseph Bethge",
      "Christoph Meinel",
      "Haojin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12964",
    "title": "Petroleum prices prediction using data mining techniques -- A Review",
    "abstract": "Over the past 20 years, Kenya's demand for petroleum products has proliferated. This is mainly because this particular commodity is used in many sectors of the country's economy. Exchange rates are impacted by constantly shifting prices, which also impact Kenya's industrial output of commodities. The cost of other items produced and even the expansion of the economy is significantly impacted by any change in the price of petroleum products. Therefore, accurate petroleum price forecasting is critical for devising policies that are suitable to curb fuel-related shocks. Data mining techniques are the tools used to find valuable patterns in data. Data mining techniques used in petroleum price prediction, including artificial neural networks (ANNs), support vector machines (SVMs), and intelligent optimization techniques like the genetic algorithm (GA), have grown increasingly popular. This study provides a comprehensive review of the existing data mining techniques for making predictions on petroleum prices. The data mining techniques are classified into regression models, deep neural network models, fuzzy sets and logic, and hybrid models. A detailed discussion of how these models are developed and the accuracy of the models is provided. ",
    "url": "https://arxiv.org/abs/2211.12964",
    "authors": [
      "Kiplang'at Weldon",
      "John Ngechu",
      "Ngatho Everlyne",
      "Nancy Njambi",
      "Kinyua Gikunda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12990",
    "title": "Adversarial Attacks are a Surprisingly Strong Baseline for Poisoning  Few-Shot Meta-Learners",
    "abstract": "This paper examines the robustness of deployed few-shot meta-learning systems when they are fed an imperceptibly perturbed few-shot dataset. We attack amortized meta-learners, which allows us to craft colluding sets of inputs that are tailored to fool the system's learning algorithm when used as training data. Jointly crafted adversarial inputs might be expected to synergistically manipulate a classifier, allowing for very strong data-poisoning attacks that would be hard to detect. We show that in a white box setting, these attacks are very successful and can cause the target model's predictions to become worse than chance. However, in opposition to the well-known transferability of adversarial examples in general, the colluding sets do not transfer well to different classifiers. We explore two hypotheses to explain this: 'overfitting' by the attack, and mismatch between the model on which the attack is generated and that to which the attack is transferred. Regardless of the mitigation strategies suggested by these hypotheses, the colluding inputs transfer no better than adversarial inputs that are generated independently in the usual way. ",
    "url": "https://arxiv.org/abs/2211.12990",
    "authors": [
      "Elre T. Oldewage",
      "John Bronskill",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.12996",
    "title": "Converting OpenStreetMap (OSM) Data to Functional Road Networks for  Downstream Applications",
    "abstract": "In this work, we study the OpenStreetMap (OSM) data that contains Extensible Markup Language (XML) formatted data. OpenStreetMap data has many different formats. OSM XML format is one of them. OSM data has information in the form of nodes (points), ways (lines and boundaries), and relations (relationships between two or more nodes or ways). Here, we preprocess OSM XML data to extract the ways and nodes information using python to get the whole map of the streets for the Memphis area. We parse the OSM data in such a way that gives us the whole map of the Memphis area. We can further use this map for different Neural Networks (NN) and Machine learning (ML) applications. The steps that are included in this work downloading the Memphis area OSM data, understanding and parsing the OSM XML file, converting the nodes and ways information into the Pandas DataFrame, and visualizing these data into the whole map by using python's available data visualization libraries. ",
    "url": "https://arxiv.org/abs/2211.12996",
    "authors": [
      "Md Kaisar Ahmed"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13000",
    "title": "A Network Classification Method based on Density Time Evolution Patterns  Extracted from Network Automata",
    "abstract": "Network modeling has proven to be an efficient tool for many interdisciplinary areas, including social, biological, transport, and many other real world complex systems. In addition, cellular automata (CA) are a formalism that has been studied in the last decades as a model for exploring patterns in the dynamic spatio-temporal behavior of these systems based on local rules. Some studies explore the use of cellular automata to analyze the dynamic behavior of networks, denominating them as network automata (NA). Recently, NA proved to be efficient for network classification, since it uses a time-evolution pattern (TEP) for the feature extraction. However, the TEPs explored by previous studies are composed of binary values, which does not represent detailed information on the network analyzed. Therefore, in this paper, we propose alternate sources of information to use as descriptor for the classification task, which we denominate as density time-evolution pattern (D-TEP) and state density time-evolution pattern (SD-TEP). We explore the density of alive neighbors of each node, which is a continuous value, and compute feature vectors based on histograms of the TEPs. Our results show a significant improvement compared to previous studies at five synthetic network databases and also seven real world databases. Our proposed method demonstrates not only a good approach for pattern recognition in networks, but also shows great potential for other kinds of data, such as images. ",
    "url": "https://arxiv.org/abs/2211.13000",
    "authors": [
      "Kallil M. C. Zielinski",
      "Lucas C. Ribas",
      "Jeaneth Machicao",
      "Odemir M. Bruno"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13009",
    "title": "Federated Learning on Non-IID Graphs via Structural Knowledge Sharing",
    "abstract": "Graph neural networks (GNNs) have shown their superiority in modeling graph data. Owing to the advantages of federated learning, federated graph learning (FGL) enables clients to train strong GNN models in a distributed manner without sharing their private data. A core challenge in federated systems is the non-IID problem, which also widely exists in real-world graph data. For example, local data of clients may come from diverse datasets or even domains, e.g., social networks and molecules, increasing the difficulty for FGL methods to capture commonly shared knowledge and learn a generalized encoder. From real-world graph datasets, we observe that some structural properties are shared by various domains, presenting great potential for sharing structural knowledge in FGL. Inspired by this, we propose FedStar, an FGL framework that extracts and shares the common underlying structure information for inter-graph federated learning tasks. To explicitly extract the structure information rather than encoding them along with the node features, we define structure embeddings and encode them with an independent structure encoder. Then, the structure encoder is shared across clients while the feature-based knowledge is learned in a personalized way, making FedStar capable of capturing more structure-based domain-invariant information and avoiding feature misalignment issues. We perform extensive experiments over both cross-dataset and cross-domain non-IID FGL settings, demonstrating the superiority of FedStar. ",
    "url": "https://arxiv.org/abs/2211.13009",
    "authors": [
      "Yue Tan",
      "Yixin Liu",
      "Guodong Long",
      "Jing Jiang",
      "Qinghua Lu",
      "Chengqi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.13014",
    "title": "Sarcasm Detection Framework Using Emotion and Sentiment Features",
    "abstract": "Sarcasm detection is an essential task that can help identify the actual sentiment in user-generated data, such as discussion forums or tweets. Sarcasm is a sophisticated form of linguistic expression because its surface meaning usually contradicts its inner, deeper meaning. Such incongruity is the essential component of sarcasm, however, it makes sarcasm detection quite a challenging task. In this paper, we propose a model which incorporates emotion and sentiment features to capture the incongruity intrinsic to sarcasm. Moreover, we use CNN and pre-trained Transformer to capture context features. Our approach achieved state-of-the-art results on four datasets from social networking platforms and online media. ",
    "url": "https://arxiv.org/abs/2211.13014",
    "authors": [
      "Oxana Vitman",
      "Yevhen Kostiuk",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13015",
    "title": "Semantics-Preserving Sketch Embedding for Face Generation",
    "abstract": "With recent advances in image-to-image translation tasks, remarkable progress has been witnessed in generating face images from sketches. However, existing methods frequently fail to generate images with details that are semantically and geometrically consistent with the input sketch, especially when various decoration strokes are drawn. To address this issue, we introduce a novel W-W+ encoder architecture to take advantage of the high expressive power of W+ space and semantic controllability of W space. We introduce an explicit intermediate representation for sketch semantic embedding. With a semantic feature matching loss for effective semantic supervision, our sketch embedding precisely conveys the semantics in the input sketches to the synthesized images. Moreover, a novel sketch semantic interpretation approach is designed to automatically extract semantics from vectorized sketches. We conduct extensive experiments on both synthesized sketches and hand-drawn sketches, and the results demonstrate the superiority of our method over existing approaches on both semantics-preserving and generalization ability. ",
    "url": "https://arxiv.org/abs/2211.13015",
    "authors": [
      "Binxin Yang",
      "Xuejin Chen",
      "Chaoqun Wang",
      "Chi Zhang",
      "Zihan Chen",
      "Xiaoyan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13041",
    "title": "A new Privacy Preserving and Scalable Revocation Method for Self  Sovereign Identity -- The Perfect Revocation Method does not exist yet",
    "abstract": "Digital Identities are playing an essential role in our digital lives. Today, used Digital Identities are based on central architectures. Central Digital Identity providers control and know our data and, thereby, our Identity. Self Sovereign Identities (SSI) are based on a decentralized data storage and data exchange architecture, where the user is in sole control of his data and identity. Most of the issued credentials need the possibility of revocation. For a Central Digital Identity, revocation is easy. In decentral architectures, revocation is more challenging. Revocation can be done with different methods e.g. lists, compressed lists and cryptographic accumulators. A revocation method must be privacy preserving and must scale. This paper gives an overview about the available revocation methods, include a survey to define requirements, assess different revocation groups against the requirements, highlights shortcomings of the methods and introduce a new revocation method called Linked Validity Verifiable Credentials. ",
    "url": "https://arxiv.org/abs/2211.13041",
    "authors": [
      "Andreas Freitag"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.13067",
    "title": "Sparse2Dense: Learning to Densify 3D Features for 3D Object Detection",
    "abstract": "LiDAR-produced point clouds are the major source for most state-of-the-art 3D object detectors. Yet, small, distant, and incomplete objects with sparse or few points are often hard to detect. We present Sparse2Dense, a new framework to efficiently boost 3D detection performance by learning to densify point clouds in latent space. Specifically, we first train a dense point 3D detector (DDet) with a dense point cloud as input and design a sparse point 3D detector (SDet) with a regular point cloud as input. Importantly, we formulate the lightweight plug-in S2D module and the point cloud reconstruction module in SDet to densify 3D features and train SDet to produce 3D features, following the dense 3D features in DDet. So, in inference, SDet can simulate dense 3D features from regular (sparse) point cloud inputs without requiring dense inputs. We evaluate our method on the large-scale Waymo Open Dataset and the Waymo Domain Adaptation Dataset, showing its high performance and efficiency over the state of the arts. ",
    "url": "https://arxiv.org/abs/2211.13067",
    "authors": [
      "Tianyu Wang",
      "Xiaowei Hu",
      "Zhengzhe Liu",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13081",
    "title": "Robust Mean Teacher for Continual and Gradual Test-Time Adaptation",
    "abstract": "Since experiencing domain shifts during test-time is inevitable in practice, test-time adaption (TTA) continues to adapt the model during deployment. Recently, the area of continual and gradual test-time adaptation (TTA) emerged. In contrast to standard TTA, continual TTA considers not only a single domain shift, but a sequence of shifts. Gradual TTA further exploits the property that some shifts evolve gradually over time. Since in both settings long test sequences are present, error accumulation needs to be addressed for methods relying on self-training. In this work, we propose and show that in the setting of TTA, the symmetric cross-entropy is better suited as a consistency loss for mean teachers compared to the commonly used cross-entropy. This is justified by our analysis with respect to the (symmetric) cross-entropy's gradient properties. To pull the test feature space closer to the source domain, where the pre-trained model is well posed, contrastive learning is leveraged. Since applications differ in their requirements, we address different settings, namely having source data available and the more challenging source-free setting. We demonstrate the effectiveness of our proposed method 'robust mean teacher' (RMT) on the continual and gradual corruption benchmarks CIFAR10C, CIFAR100C, and Imagenet-C. We further consider ImageNet-R and propose a new continual DomainNet-126 benchmark. State-of-the-art results are achieved on all benchmarks. ",
    "url": "https://arxiv.org/abs/2211.13081",
    "authors": [
      "Mario D\u00f6bler",
      "Robert A. Marsden",
      "Bin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13090",
    "title": "TransVCL: Attention-enhanced Video Copy Localization Network with  Flexible Supervision",
    "abstract": "Video copy localization aims to precisely localize all the copied segments within a pair of untrimmed videos in video retrieval applications. Previous methods typically start from frame-to-frame similarity matrix generated by cosine similarity between frame-level features of the input video pair, and then detect and refine the boundaries of copied segments on similarity matrix under temporal constraints. In this paper, we propose TransVCL: an attention-enhanced video copy localization network, which is optimized directly from initial frame-level features and trained end-to-end with three main components: a customized Transformer for feature enhancement, a correlation and softmax layer for similarity matrix generation, and a temporal alignment module for copied segments localization. In contrast to previous methods demanding the handcrafted similarity matrix, TransVCL incorporates long-range temporal information between feature sequence pair using self- and cross- attention layers. With the joint design and optimization of three components, the similarity matrix can be learned to present more discriminative copied patterns, leading to significant improvements over previous methods on segment-level labeled datasets (VCSL and VCDB). Besides the state-of-the-art performance in fully supervised setting, the attention architecture facilitates TransVCL to further exploit unlabeled or simply video-level labeled data. Additional experiments of supplementing video-level labeled datasets including SVD and FIVR reveal the high flexibility of TransVCL from full supervision to semi-supervision (with or without video-level annotation). Code is publicly available at https://github.com/transvcl/TransVCL. ",
    "url": "https://arxiv.org/abs/2211.13090",
    "authors": [
      "Sifeng He",
      "Yue He",
      "Minlong Lu",
      "Chen Jiang",
      "Xudong Yang",
      "Feng Qian",
      "Xiaobo Zhang",
      "Lei Yang",
      "Jiandong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13094",
    "title": "Characterizing a Neutron-Induced Fault Model for Deep Neural Networks",
    "abstract": "The reliability evaluation of Deep Neural Networks (DNNs) executed on Graphic Processing Units (GPUs) is a challenging problem since the hardware architecture is highly complex and the software frameworks are composed of many layers of abstraction. While software-level fault injection is a common and fast way to evaluate the reliability of complex applications, it may produce unrealistic results since it has limited access to the hardware resources and the adopted fault models may be too naive (i.e., single and double bit flip). Contrarily, physical fault injection with neutron beam provides realistic error rates but lacks fault propagation visibility. This paper proposes a characterization of the DNN fault model combining both neutron beam experiments and fault injection at software level. We exposed GPUs running General Matrix Multiplication (GEMM) and DNNs to beam neutrons to measure their error rate. On DNNs, we observe that the percentage of critical errors can be up to 61%, and show that ECC is ineffective in reducing critical errors. We then performed a complementary software-level fault injection, using fault models derived from RTL simulations. Our results show that by injecting complex fault models, the YOLOv3 misdetection rate is validated to be very close to the rate measured with beam experiments, which is 8.66x higher than the one measured with fault injection using only single-bit flips. ",
    "url": "https://arxiv.org/abs/2211.13094",
    "authors": [
      "Fernando Fernandes dos Santos",
      "Angeliki Kritikakou",
      "Josie Esteban Rodriguez Condia",
      "Juan David Guerrero Balaguera",
      "Matteo Sonza Reorda",
      "Olivier Sentieys",
      "Paolo Rech"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2211.13097",
    "title": "DeepVulSeeker: A Novel Vulnerability Identification Framework via Code  Graph Structure and Pre-training Mechanism",
    "abstract": "Software vulnerabilities can pose severe harms to a computing system. They can lead to system crash, privacy leakage, or even physical damage. Correctly identifying vulnerabilities among enormous software codes in a timely manner is so far the essential prerequisite to patch them. Unfortantely, the current vulnerability identification methods, either the classic ones or the deep-learning-based ones, have several critical drawbacks, making them unable to meet the present-day demands put forward by the software industry. To overcome the drawbacks, in this paper, we propose DeepVulSeeker, a novel fully automated vulnerability identification framework, which leverages both code graph structures and the semantic features with the help of the recently advanced Graph Representation Self-Attention and pre-training mechanisms. Our experiments show that DeepVulSeeker not only reaches an accuracy as high as 0.99 on traditional CWE datasets, but also outperforms all other exisiting methods on two highly-complicated datasets. We also testified DeepVulSeeker based on three case studies, and found that DeepVulSeeker is able to understand the implications of the vulnerbilities. We have fully implemented DeepVulSeeker and open-sourced it for future follow-up research. ",
    "url": "https://arxiv.org/abs/2211.13097",
    "authors": [
      "Jin Wang",
      "Hui Xiao",
      "Shuwen Zhong",
      "Yinhao Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.13116",
    "title": "Fed-TDA: Federated Tabular Data Augmentation on Non-IID Data",
    "abstract": "Non-independent and identically distributed (non-IID) data is a key challenge in federated learning (FL), which usually hampers the optimization convergence and the performance of FL. Existing data augmentation methods based on federated generative models or raw data sharing strategies for solving the non-IID problem still suffer from low performance, privacy protection concerns, and high communication overhead in decentralized tabular data. To tackle these challenges, we propose a federated tabular data augmentation method, named Fed-TDA. The core idea of Fed-TDA is to synthesize tabular data for data augmentation using some simple statistics (e.g., distributions of each column and global covariance). Specifically, we propose the multimodal distribution transformation and inverse cumulative distribution mapping respectively synthesize continuous and discrete columns in tabular data from a noise according to the pre-learned statistics. Furthermore, we theoretically analyze that our Fed-TDA not only preserves data privacy but also maintains the distribution of the original data and the correlation between columns. Through extensive experiments on five real-world tabular datasets, we demonstrate the superiority of Fed-TDA over the state-of-the-art in test performance and communication efficiency. ",
    "url": "https://arxiv.org/abs/2211.13116",
    "authors": [
      "Shaoming Duan",
      "Chuanyi Liu",
      "Peiyi Han",
      "Tianyu He",
      "Yifeng Xu",
      "Qiyuan Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.13118",
    "title": "Branch-and-Bound with Barrier: Dominance and Suboptimality Detection for  DD-Based Branch-and-Bound",
    "abstract": "The branch-and-bound algorithm based on decision diagrams introduced by Bergman et al. in 2016 is a framework for solving discrete optimization problems with a dynamic programming formulation. It works by compiling a series of bounded-width decision diagrams that can provide lower and upper bounds for any given subproblem. Eventually, every part of the search space will be either explored or pruned by the algorithm, thus proving optimality. This paper presents new ingredients to speed up the search by exploiting the structure of dynamic programming models. The key idea is to prevent the repeated exploration of nodes corresponding to the same dynamic programming states by storing and querying thresholds in a data structure called the Barrier. These thresholds are based on dominance relations between partial solutions previously found. They can be further strengthened by integrating the filtering techniques introduced by Gillard et al. in 2021. Computational experiments show that the pruning brought by the Barrier allows to significantly reduce the number of nodes expanded by the algorithm. This results in more benchmark instances of difficult optimization problems being solved in less time while using narrower decision diagrams. ",
    "url": "https://arxiv.org/abs/2211.13118",
    "authors": [
      "Vianney Copp\u00e9",
      "Xavier Gillard",
      "Pierre Schaus"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.13123",
    "title": "Motif-aware temporal GCN for fraud detection in signed cryptocurrency  trust networks",
    "abstract": "Graph convolutional networks (GCNs) is a class of artificial neural networks for processing data that can be represented as graphs. Since financial transactions can naturally be constructed as graphs, GCNs are widely applied in the financial industry, especially for financial fraud detection. In this paper, we focus on fraud detection on cryptocurrency truct networks. In the literature, most works focus on static networks. Whereas in this study, we consider the evolving nature of cryptocurrency networks, and use local structural as well as the balance theory to guide the training process. More specifically, we compute motif matrices to capture the local topological information, then use them in the GCN aggregation process. The generated embedding at each snapshot is a weighted average of embeddings within a time window, where the weights are learnable parameters. Since the trust networks is signed on each edge, balance theory is used to guide the training process. Experimental results on bitcoin-alpha and bitcoin-otc datasets show that the proposed model outperforms those in the literature. ",
    "url": "https://arxiv.org/abs/2211.13123",
    "authors": [
      "Chong Mo",
      "Song Li",
      "Geoffrey K. F. Tso",
      "Jiandong Zhou",
      "Yiyan Qi",
      "Mingjie Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Trading and Market Microstructure (q-fin.TR)"
    ]
  },
  {
    "id": "arXiv:2211.13126",
    "title": "Crown-CAM: Reliable Visual Explanations for Tree Crown Detection in  Aerial Images",
    "abstract": "Visual explanation of \"black-box\" models has enabled researchers and experts in artificial intelligence (AI) to exploit the localization abilities of such methods to a much greater extent. Despite most of the developed visual explanation methods applied to single object classification problems, they are not well-explored in the detection task, where the challenges may go beyond simple coarse area-based discrimination. This is of particular importance when a detector should face several objects with different scales from various viewpoints or if the objects of interest are absent. In this paper, we propose CrownCAM to generate reliable visual explanations for the challenging and dynamic problem of tree crown detection in aerial images. It efficiently provides fine-grain localization of tree crowns and non-contextual background suppression for scenarios with highly dense forest trees in the presence of potential distractors or scenes without tree crowns. Additionally, two Intersection over Union (IoU)-based metrics are introduced that can effectively quantify both the accuracy and inaccuracy of generated visual explanations with respect to regions with or without tree crowns in the image. Empirical evaluations demonstrate that the proposed Crown-CAM outperforms the Score-CAM, Augmented ScoreCAM, and Eigen-CAM methods by an average IoU margin of 8.7, 5.3, and 21.7 (and 3.3, 9.8, and 16.5) respectively in improving the accuracy (and decreasing inaccuracy) of visual explanations on the challenging NEON tree crown dataset. ",
    "url": "https://arxiv.org/abs/2211.13126",
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Devin Goodsman",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13133",
    "title": "Structural Knowledge Distillation for Object Detection",
    "abstract": "Knowledge Distillation (KD) is a well-known training paradigm in deep neural networks where knowledge acquired by a large teacher model is transferred to a small student. KD has proven to be an effective technique to significantly improve the student's performance for various tasks including object detection. As such, KD techniques mostly rely on guidance at the intermediate feature level, which is typically implemented by minimizing an lp-norm distance between teacher and student activations during training. In this paper, we propose a replacement for the pixel-wise independent lp-norm based on the structural similarity (SSIM). By taking into account additional contrast and structural cues, feature importance, correlation and spatial dependence in the feature space are considered in the loss formulation. Extensive experiments on MSCOCO demonstrate the effectiveness of our method across different training schemes and architectures. Our method adds only little computational overhead, is straightforward to implement and at the same time it significantly outperforms the standard lp-norms. Moreover, more complex state-of-the-art KD methods using attention-based sampling mechanisms are outperformed, including a +3.5 AP gain using a Faster R-CNN R-50 compared to a vanilla model. ",
    "url": "https://arxiv.org/abs/2211.13133",
    "authors": [
      "Philip de Rijk",
      "Lukas Schneider",
      "Marius Cordts",
      "Dariu M. Gavrila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13152",
    "title": "Introducing topography in convolutional neural networks",
    "abstract": "Parts of the brain that carry sensory tasks are organized topographically: nearby neurons are responsive to the same properties of input signals. Thus, in this work, inspired by the neuroscience literature, we proposed a new topographic inductive bias in Convolutional Neural Networks (CNNs). To achieve this, we introduced a new topographic loss and an efficient implementation to topographically organize each convolutional layer of any CNN. We benchmarked our new method on 4 datasets and 3 models in vision and audio tasks and showed equivalent performance to all benchmarks. Besides, we also showcased the generalizability of our topographic loss with how it can be used with different topographic organizations in CNNs. Finally, we demonstrated that adding the topographic inductive bias made CNNs more resistant to pruning. Our approach provides a new avenue to obtain models that are more memory efficient while maintaining better accuracy. ",
    "url": "https://arxiv.org/abs/2211.13152",
    "authors": [
      "Maxime Poli",
      "Emmanuel Dupoux",
      "Rachid Riad"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.13170",
    "title": "The World of Graph Databases from An Industry Perspective",
    "abstract": "Rapidly growing social networks and other graph data have created a high demand for graph technologies in the market. A plethora of graph databases, systems, and solutions have emerged, as a result. On the other hand, graph has long been a well studied area in the database research community. Despite the numerous surveys on various graph research topics, there is a lack of survey on graph technologies from an industry perspective. The purpose of this paper is to provide the research community with an industrial perspective on the graph database landscape, so that graph researcher can better understand the industry trend and the challenges that the industry is facing, and work on solutions to help address these problems. ",
    "url": "https://arxiv.org/abs/2211.13170",
    "authors": [
      "Yuanyuan Tian"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2211.13171",
    "title": "Query Efficient Cross-Dataset Transferable Black-Box Attack on Action  Recognition",
    "abstract": "Black-box adversarial attacks present a realistic threat to action recognition systems. Existing black-box attacks follow either a query-based approach where an attack is optimized by querying the target model, or a transfer-based approach where attacks are generated using a substitute model. While these methods can achieve decent fooling rates, the former tends to be highly query-inefficient while the latter assumes extensive knowledge of the black-box model's training data. In this paper, we propose a new attack on action recognition that addresses these shortcomings by generating perturbations to disrupt the features learned by a pre-trained substitute model to reduce the number of queries. By using a nearly disjoint dataset to train the substitute model, our method removes the requirement that the substitute model be trained using the same dataset as the target model, and leverages queries to the target model to retain the fooling rate benefits provided by query-based methods. This ultimately results in attacks which are more transferable than conventional black-box attacks. Through extensive experiments, we demonstrate highly query-efficient black-box attacks with the proposed framework. Our method achieves 8% and 12% higher deception rates compared to state-of-the-art query-based and transfer-based attacks, respectively. ",
    "url": "https://arxiv.org/abs/2211.13171",
    "authors": [
      "Rohit Gupta",
      "Naveed Akhtar",
      "Gaurav Kumar Nayak",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.13174",
    "title": "Evolutionary Generalized Zero-Shot Learning",
    "abstract": "An open problem on the path to artificial intelligence is generalization from the known to the unknown, which is instantiated as Generalized Zero-Shot Learning (GZSL) task. In this work, we propose a novel Evolutionary Generalized Zero-Shot Learning setting, which (i) avoids the domain shift problem in inductive GZSL, and (ii) is more in line with the needs of real-world deployments than transductive GZSL. In the proposed setting, a zero-shot model with poor initial performance is able to achieve online evolution during application. We elaborate on three challenges of this special task, i.e., catastrophic forgetting, initial prediction bias, and evolutionary data class bias. Moreover, we propose targeted solutions for each challenge, resulting in a generic method capable of continuing to evolve on a given initial IGZSL model. Experiments on three popular GZSL benchmark datasets show that our model can learn from the test data stream while other baselines fail. ",
    "url": "https://arxiv.org/abs/2211.13174",
    "authors": [
      "Dubing Chen",
      "Haofeng Zhang",
      "Yuming Shen",
      "Yang Long",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.13189",
    "title": "ASiT: Audio Spectrogram vIsion Transformer for General Audio  Representation",
    "abstract": "Vision transformers, which were originally developed for natural language processing, have recently generated significant interest in the computer vision and audio communities due to their flexibility in learning long-range relationships. Constrained by data hungry nature of transformers and limited labelled data most transformer-based models for audio tasks are finetuned from ImageNet pretrained models, despite the huge gap between the natural images domain and audio domain. This has motivated the research in self-supervised pretraining of audio transformers, which reduces the dependency on large amounts of labeled data and focuses on extracting concise representation of the audio spectrograms. In this paper, we propose ASiT, a novel self-supervised transformer for general audio representations that captures local and global contextual information employing group masked model learning and self-distillation. We evaluate our pretrained models on both audio and speech classification tasks including audio event classification, keyword spotting, and speaker identification. We further conduct comprehensive ablation studies, including evaluations of different pretraining strategies. The proposed ASiT framework significantly boosts the performance on all tasks and sets a new state-of-the-art performance on five audio and speech classification tasks, outperforming recent methods, including the approaches that use additional datasets for pretraining. The code and pretrained weights will be made publicly available for the scientific community. ",
    "url": "https://arxiv.org/abs/2211.13189",
    "authors": [
      "Sara Atito",
      "Muhammad Awais",
      "Wenwu Wang",
      "Mark D Plumbley",
      "Josef Kittler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.13194",
    "title": "Indian Commercial Truck License Plate Detection and Recognition for  Weighbridge Automation",
    "abstract": "Detection and recognition of a licence plate is important when automating weighbridge services. While many large databases are available for Latin and Chinese alphanumeric license plates, data for Indian License Plates is inadequate. In particular, databases of Indian commercial truck license plates are inadequate, despite the fact that commercial vehicle license plate recognition plays a profound role in terms of logistics management and weighbridge automation. Moreover, models to recognise license plates are not effectively able to generalise to such data due to its challenging nature, and due to the abundant frequency of handwritten license plates, leading to the usage of diverse font styles. Thus, a database and effective models to recognise and detect such license plates are crucial. This paper provides a database on commercial truck license plates, and using state-of-the-art models in real-time object Detection: You Only Look Once Version 7, and SceneText Recognition: Permuted Autoregressive Sequence Models, our method outperforms the other cited references where the maximum accuracy obtained was less than 90%, while we have achieved 95.82% accuracy in our algorithm implementation on the presented challenging license plate dataset. Index Terms- Automatic License Plate Recognition, character recognition, license plate detection, vision transformer. ",
    "url": "https://arxiv.org/abs/2211.13194",
    "authors": [
      "Siddharth Agrawal",
      "Keyur D. Joshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13202",
    "title": "Lite-Mono: A Lightweight CNN and Transformer Architecture for  Self-Supervised Monocular Depth Estimation",
    "abstract": "Self-supervised monocular depth estimation that does not require ground-truth for training has attracted attention in recent years. It is of high interest to design lightweight but effective models, so that they can be deployed on edge devices. Many existing architectures benefit from using heavier backbones at the expense of model sizes. In this paper we achieve comparable results with a lightweight architecture. Specifically, we investigate the efficient combination of CNNs and Transformers, and design a hybrid architecture Lite-Mono. A Consecutive Dilated Convolutions (CDC) module and a Local-Global Features Interaction (LGFI) module are proposed. The former is used to extract rich multi-scale local features, and the latter takes advantage of the self-attention mechanism to encode long-range global information into the features. Experiments demonstrate that our full model outperforms Monodepth2 by a large margin in accuracy, with about 80% fewer trainable parameters. ",
    "url": "https://arxiv.org/abs/2211.13202",
    "authors": [
      "Ning Zhang",
      "Francesco Nex",
      "George Vosselman",
      "Norman Kerle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13206",
    "title": "ManVatar : Fast 3D Head Avatar Reconstruction Using Motion-Aware Neural  Voxels",
    "abstract": "With NeRF widely used for facial reenactment, recent methods can recover photo-realistic 3D head avatar from just a monocular video. Unfortunately, the training process of the NeRF-based methods is quite time-consuming, as MLP used in the NeRF-based methods is inefficient and requires too many iterations to converge. To overcome this problem, we propose ManVatar, a fast 3D head avatar reconstruction method using Motion-Aware Neural Voxels. ManVatar is the first to decouple expression motion from canonical appearance for head avatar, and model the expression motion by neural voxels. In particular, the motion-aware neural voxels is generated from the weighted concatenation of multiple 4D tensors. The 4D tensors semantically correspond one-to-one with 3DMM expression bases and share the same weights as 3DMM expression coefficients. Benefiting from our novel representation, the proposed ManVatar can recover photo-realistic head avatars in just 5 minutes (implemented with pure PyTorch), which is significantly faster than the state-of-the-art facial reenactment methods. ",
    "url": "https://arxiv.org/abs/2211.13206",
    "authors": [
      "Yuelang Xu",
      "Lizhen Wang",
      "Xiaochen Zhao",
      "Hongwen Zhang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13223",
    "title": "Generalizable Implicit Neural Representations via Instance Pattern  Composers",
    "abstract": "Despite recent advances in implicit neural representations (INRs), it remains challenging for a coordinate-based multi-layer perceptron (MLP) of INRs to learn a common representation across data instances and generalize it for unseen instances. In this work, we introduce a simple yet effective framework for generalizable INRs that enables a coordinate-based MLP to represent complex data instances by modulating only a small set of weights in an early MLP layer as an instance pattern composer; the remaining MLP weights learn pattern composition rules for common representations across instances. Our generalizable INR framework is fully compatible with existing meta-learning and hypernetworks in learning to predict the modulated weight for unseen instances. Extensive experiments demonstrate that our method achieves high performance on a wide range of domains such as an audio, image, and 3D object, while the ablation study validates our weight modulation. ",
    "url": "https://arxiv.org/abs/2211.13223",
    "authors": [
      "Chiheon Kim",
      "Doyup Lee",
      "Saehoon Kim",
      "Minsu Cho",
      "Wook-Shin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13226",
    "title": "ClimateNeRF: Physically-based Neural Rendering for Extreme Climate  Synthesis",
    "abstract": "Physical simulations produce excellent predictions of weather effects. Neural radiance fields produce SOTA scene models. We describe a novel NeRF-editing procedure that can fuse physical simulations with NeRF models of scenes, producing realistic movies of physical phenomena inthose scenes. Our application -- Climate NeRF -- allows people to visualize what climate change outcomes will do to them. ClimateNeRF allows us to render realistic weather effects, including smog, snow, and flood. Results can be controlled with physically meaningful variables like water level. Qualitative and quantitative studies show that our simulated results are significantly more realistic than those from state-of-the-art 2D image editing and 3D NeRF stylization. ",
    "url": "https://arxiv.org/abs/2211.13226",
    "authors": [
      "Yuan Li",
      "Zhi-Hao Lin",
      "David Forsyth",
      "Jia-Bin Huang",
      "Shenlong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.13228",
    "title": "Self-Supervised Learning based on Heat Equation",
    "abstract": "This paper presents a new perspective of self-supervised learning based on extending heat equation into high dimensional feature space. In particular, we remove time dependence by steady-state condition, and extend the remaining 2D Laplacian from x--y isotropic to linear correlated. Furthermore, we simplify it by splitting x and y axes as two first-order linear differential equations. Such simplification explicitly models the spatial invariance along horizontal and vertical directions separately, supporting prediction across image blocks. This introduces a very simple masked image modeling (MIM) method, named QB-Heat. QB-Heat leaves a single block with size of quarter image unmasked and extrapolates other three masked quarters linearly. It brings MIM to CNNs without bells and whistles, and even works well for pre-training light-weight networks that are suitable for both image classification and object detection without fine-tuning. Compared with MoCo-v2 on pre-training a Mobile-Former with 5.8M parameters and 285M FLOPs, QB-Heat is on par in linear probing on ImageNet, but clearly outperforms in non-linear probing that adds a transformer block before linear classifier (65.6% vs. 52.9%). When transferring to object detection with frozen backbone, QB-Heat outperforms MoCo-v2 and supervised pre-training on ImageNet by 7.9 and 4.5 AP respectively. This work provides an insightful hypothesis on the invariance within visual representation over different shapes and textures: the linear relationship between horizontal and vertical derivatives. The code will be publicly released. ",
    "url": "https://arxiv.org/abs/2211.13228",
    "authors": [
      "Yinpeng Chen",
      "Xiyang Dai",
      "Dongdong Chen",
      "Mengchen Liu",
      "Lu Yuan",
      "Zicheng Liu",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12549",
    "title": "WarpPINN: Cine-MR image registration with physics-informed neural  networks",
    "abstract": "Heart failure is typically diagnosed with a global function assessment, such as ejection fraction. However, these metrics have low discriminate power, failing to distinguish different types of this disease. Quantifying local deformations in the form of cardiac strain can provide helpful information, but it remains a challenge. In this work, we introduce WarpPINN, a physics-informed neural network to perform image registration to obtain local metrics of the heart deformation. We apply this method to cine magnetic resonance images to estimate the motion during the cardiac cycle. We inform our neural network of near-incompressibility of cardiac tissue by penalizing the jacobian of the deformation field. The loss function has two components: an intensity-based similarity term between the reference and the warped template images, and a regularizer that represents the hyperelastic behavior of the tissue. The architecture of the neural network allows us to easily compute the strain via automatic differentiation to assess cardiac activity. We use Fourier feature mappings to overcome the spectral bias of neural networks, allowing us to capture discontinuities in the strain field. We test our algorithm on a synthetic example and on a cine-MRI benchmark of 15 healthy volunteers. We outperform current methodologies both landmark tracking and strain estimation. We expect that WarpPINN will enable more precise diagnostics of heart failure based on local deformation information. Source code is available at https://github.com/fsahli/WarpPINN. ",
    "url": "https://arxiv.org/abs/2211.12549",
    "authors": [
      "Pablo Arratia L\u00f3pez",
      "Hern\u00e1n Mella",
      "Sergio Uribe",
      "Daniel E. Hurtado",
      "Francisco Sahli Costabal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12590",
    "title": "Deep Neural Mel-Subband Beamformer for In-car Speech Separation",
    "abstract": "While current deep learning (DL)-based beamforming techniques have been proved effective in speech separation, they are often designed to process narrow-band (NB) frequencies independently which results in higher computational costs and inference times, making them unsuitable for real-world use. In this paper, we propose DL-based mel-subband spatio-temporal beamformer to perform speech separation in a car environment with reduced computation cost and inference time. As opposed to conventional subband (SB) approaches, our framework uses a mel-scale based subband selection strategy which ensures a fine-grained processing for lower frequencies where most speech formant structure is present, and coarse-grained processing for higher frequencies. In a recursive way, robust frame-level beamforming weights are determined for each speaker location/zone in a car from the estimated subband speech and noise covariance matrices. Furthermore, proposed framework also estimates and suppresses any echoes from the loudspeaker(s) by using the echo reference signals. We compare the performance of our proposed framework to several NB, SB, and full-band (FB) processing techniques in terms of speech quality and recognition metrics. Based on experimental evaluations on simulated and real-world recordings, we find that our proposed framework achieves better separation performance over all SB and FB approaches and achieves performance closer to NB processing techniques while requiring lower computing cost. ",
    "url": "https://arxiv.org/abs/2211.12590",
    "authors": [
      "Vinay Kothapally",
      "Yong Xu",
      "Meng Yu",
      "Shi-Xiong Zhang",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.12623",
    "title": "SkipConvGAN: Monaural Speech Dereverberation using Generative  Adversarial Networks via Complex Time-Frequency Masking",
    "abstract": "With the advancements in deep learning approaches, the performance of speech enhancing systems in the presence of background noise have shown significant improvements. However, improving the system's robustness against reverberation is still a work in progress, as reverberation tends to cause loss of formant structure due to smearing effects in time and frequency. A wide range of deep learning-based systems either enhance the magnitude response and reuse the distorted phase or enhance complex spectrogram using a complex time-frequency mask. Though these approaches have demonstrated satisfactory performance, they do not directly address the lost formant structure caused by reverberation. We believe that retrieving the formant structure can help improve the efficiency of existing systems. In this study, we propose SkipConvGAN - an extension of our prior work SkipConvNet. The proposed system's generator network tries to estimate an efficient complex time-frequency mask, while the discriminator network aids in driving the generator to restore the lost formant structure. We evaluate the performance of our proposed system on simulated and real recordings of reverberant speech from the single-channel task of the REVERB challenge corpus. The proposed system shows a consistent improvement across multiple room configurations over other deep learning-based generative adversarial frameworks. ",
    "url": "https://arxiv.org/abs/2211.12623",
    "authors": [
      "Vinay Kothapally",
      "J. H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.12670",
    "title": "Expressibility-Enhancing Strategies for Quantum Neural Networks",
    "abstract": "Quantum neural networks (QNNs), represented by parameterized quantum circuits, can be trained in the paradigm of supervised learning to map input data to predictions. Much work has focused on theoretically analyzing the expressive power of QNNs. However, in almost all literature, QNNs' expressive power is numerically validated using only simple univariate functions. We surprisingly discover that state-of-the-art QNNs with strong expressive power can have poor performance in approximating even just a simple sinusoidal function. To fill the gap, we propose four expressibility-enhancing strategies for QNNs: Sinusoidal-friendly embedding, redundant measurement, post-measurement function, and random training data. We analyze the effectiveness of these strategies via mathematical analysis and/or numerical studies including learning complex sinusoidal-based functions. Our results from comparative experiments validate that the four strategies can significantly increase the QNNs' performance in approximating complex multivariable functions and reduce the quantum circuit depth and qubits required. ",
    "url": "https://arxiv.org/abs/2211.12670",
    "authors": [
      "Yalin Liao",
      "Junpeng Zhan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12681",
    "title": "Benchmarking Adversarially Robust Quantum Machine Learning at Scale",
    "abstract": "Machine learning (ML) methods such as artificial neural networks are rapidly becoming ubiquitous in modern science, technology and industry. Despite their accuracy and sophistication, neural networks can be easily fooled by carefully designed malicious inputs known as adversarial attacks. While such vulnerabilities remain a serious challenge for classical neural networks, the extent of their existence is not fully understood in the quantum ML setting. In this work, we benchmark the robustness of quantum ML networks, such as quantum variational classifiers (QVC), at scale by performing rigorous training for both simple and complex image datasets and through a variety of high-end adversarial attacks. Our results show that QVCs offer a notably enhanced robustness against classical adversarial attacks by learning features which are not detected by the classical neural networks, indicating a possible quantum advantage for ML tasks. Contrarily, and remarkably, the converse is not true, with attacks on quantum networks also capable of deceiving classical neural networks. By combining quantum and classical network outcomes, we propose a novel adversarial attack detection technology. Traditionally quantum advantage in ML systems has been sought through increased accuracy or algorithmic speed-up, but our work has revealed the potential for a new kind of quantum advantage through superior robustness of ML models, whose practical realisation will address serious security concerns and reliability issues of ML algorithms employed in a myriad of applications including autonomous vehicles, cybersecurity, and surveillance robotic systems. ",
    "url": "https://arxiv.org/abs/2211.12681",
    "authors": [
      "Maxwell T. West",
      "Sarah M. Erfani",
      "Christopher Leckie",
      "Martin Sevior",
      "Lloyd C.L. Hollenberg",
      "Muhammad Usman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.12717",
    "title": "Benchmarking Bayesian Deep Learning on Diabetic Retinopathy Detection  Tasks",
    "abstract": "Bayesian deep learning seeks to equip deep neural networks with the ability to precisely quantify their predictive uncertainty, and has promised to make deep learning more reliable for safety-critical real-world applications. Yet, existing Bayesian deep learning methods fall short of this promise; new methods continue to be evaluated on unrealistic test beds that do not reflect the complexities of downstream real-world tasks that would benefit most from reliable uncertainty quantification. We propose the RETINA Benchmark, a set of real-world tasks that accurately reflect such complexities and are designed to assess the reliability of predictive models in safety-critical scenarios. Specifically, we curate two publicly available datasets of high-resolution human retina images exhibiting varying degrees of diabetic retinopathy, a medical condition that can lead to blindness, and use them to design a suite of automated diagnosis tasks that require reliable predictive uncertainty quantification. We use these tasks to benchmark well-established and state-of-the-art Bayesian deep learning methods on task-specific evaluation metrics. We provide an easy-to-use codebase for fast and easy benchmarking following reproducibility and software design principles. We provide implementations of all methods included in the benchmark as well as results computed over 100 TPU days, 20 GPU days, 400 hyperparameter configurations, and evaluation on at least 6 random seeds each. ",
    "url": "https://arxiv.org/abs/2211.12717",
    "authors": [
      "Neil Band",
      "Tim G. J. Rudner",
      "Qixuan Feng",
      "Angelos Filos",
      "Zachary Nado",
      "Michael W. Dusenberry",
      "Ghassen Jerfel",
      "Dustin Tran",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12935",
    "title": "Functional Connectome: Approximating Brain Networks with Artificial  Neural Networks",
    "abstract": "We aimed to explore the capability of deep learning to approximate the function instantiated by biological neural circuits-the functional connectome. Using deep neural networks, we performed supervised learning with firing rate observations drawn from synthetically constructed neural circuits, as well as from an empirically supported Boundary Vector Cell-Place Cell network. The performance of trained networks was quantified using a range of criteria and tasks. Our results show that deep neural networks were able to capture the computations performed by synthetic biological networks with high accuracy, and were highly data efficient and robust to biological plasticity. We show that trained deep neural networks are able to perform zero-shot generalisation in novel environments, and allows for a wealth of tasks such as decoding the animal's location in space with high accuracy. Our study reveals a novel and promising direction in systems neuroscience, and can be expanded upon with a multitude of downstream applications, for example, goal-directed reinforcement learning. ",
    "url": "https://arxiv.org/abs/2211.12935",
    "authors": [
      "Sihao Liu",
      "Augustine N Mavor-Parker",
      "Caswell Barry"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.12944",
    "title": "SS-CXR: Multitask Representation Learning using Self Supervised  Pre-training from Chest X-Rays",
    "abstract": "Chest X-rays (CXRs) are a widely used imaging modality for the diagnosis and prognosis of lung disease. The image analysis tasks vary. Examples include pathology detection and lung segmentation. There is a large body of work where machine learning algorithms are developed for specific tasks. A significant recent example is Coronavirus disease (covid-19) detection using CXR data. However, the traditional diagnostic tool design methods based on supervised learning are burdened by the need to provide training data annotation, which should be of good quality for better clinical outcomes. Here, we propose an alternative solution, a new self-supervised paradigm, where a general representation from CXRs is learned using a group-masked self-supervised framework. The pre-trained model is then fine-tuned for domain-specific tasks such as covid-19, pneumonia detection, and general health screening. We show that the same pre-training can be used for the lung segmentation task. Our proposed paradigm shows robust performance in multiple downstream tasks which demonstrates the success of the pre-training. Moreover, the performance of the pre-trained models on data with significant drift during test time proves the learning of a better generic representation. The methods are further validated by covid-19 detection in a unique small-scale pediatric data set. The performance gain in accuracy (~25\\%) is significant when compared to a supervised transformer-based method. This adds credence to the strength and reliability of our proposed framework and pre-training strategy. ",
    "url": "https://arxiv.org/abs/2211.12944",
    "authors": [
      "Syed Muhammad Anwar",
      "Abhijeet Parida",
      "Sara Atito",
      "Muhammad Awais",
      "Gustavo Nino",
      "Josef Kitler",
      "Marius George Linguraru"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12983",
    "title": "Causal Analysis of the TOPCAT Trial: Spironolactone for Preserved  Cardiac Function Heart Failure",
    "abstract": "We describe the results of applying causal discovery methods on the data from a multi-site clinical trial, on the Treatment of Preserved Cardiac Function Heart Failure with an Aldosterone Antagonist (TOPCAT). The trial was inconclusive, with no clear benefits consistently shown for the whole cohort. However, there were questions regarding the reliability of the diagnosis and treatment protocol for a geographic subgroup of the cohort. With the inclusion of medical context in the form of domain knowledge, causal discovery is used to demonstrate regional discrepancies and to frame the regional transportability of the results. Furthermore, we show that, globally and especially for some subgroups, the treatment has significant causal effects, thus offering a more refined view of the trial results. ",
    "url": "https://arxiv.org/abs/2211.12983",
    "authors": [
      "Francesca E. D. Raimondi",
      "Tadhg O'Keeffe",
      "Hana Chockler",
      "Andrew R. Lawrence",
      "Tamara Stemberga",
      "Andre Franca",
      "Maksim Sipos",
      "Javed Butler",
      "Shlomo Ben-Haim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.12986",
    "title": "Physics-informed neural networks for pathloss prediction",
    "abstract": "This paper introduces a physics-informed machine learning approach for pathloss prediction. This is achieved by including in the training phase simultaneously (i) physical dependencies between spatial loss field and (ii) measured pathloss values in the field. It is shown that the solution to a proposed learning problem improves generalization and prediction quality with a small number of neural network layers and parameters. The latter leads to fast inference times which are favorable for downstream tasks such as localization. Moreover, the physics-informed formulation allows training and prediction with small amount of training data which makes it appealing for a wide range of practical pathloss prediction scenarios. ",
    "url": "https://arxiv.org/abs/2211.12986",
    "authors": [
      "Steffen Limmer",
      "Alberto Martinez Alba",
      "Nicola Michailow"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13072",
    "title": "A note on graphs with purely imaginary per-spectrum",
    "abstract": "In 1983, Borowiecki and J\\'o\\'zwiak posed an open problem of characterizing graphs with purely imaginary per-spectrum. The most general result, although a partial solution, was given in 2004 by Yan and Zhang, who show that if a graph contains no subgraph which is an even subdivision of $K_{2,3}$, then it has purely imaginary per-spectrum. Zhang and Li in 2012 proved that such graphs are planar and admit a pfaffian orientation. In this article, we describe how to construct graphs with purely imaginary per-spectrum having a subgraph which is an even subdivision of $K_{2,3}$ (planar and nonplanar) using coalescence of rooted graphs. ",
    "url": "https://arxiv.org/abs/2211.13072",
    "authors": [
      "Hitesh Wankhede",
      "Ranveer Singh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.13117",
    "title": "On the Empirical Association between Trade Network Complexity and Global  Gross Domestic Product",
    "abstract": "In recent decades, trade between nations has constituted an important component of global Gross Domestic Product (GDP), with official estimates showing that it likely accounted for a quarter of total global production. While evidence of association already exists in macro-economic data between trade volume and GDP growth, there is considerably less work on whether, at the level of individual granular sectors (such as vehicles or minerals), associations exist between the complexity of trading networks and global GDP. In this paper, we explore this question by using publicly available data from the Atlas of Economic Complexity project to rigorously construct global trade networks between nations across multiple sectors, and studying the correlation between network-theoretic measures computed on these networks (such as average clustering coefficient and density) and global GDP. We find that there is indeed significant association between trade networks' complexity and global GDP across almost every sector, and that network metrics also correlate with business cycle phenomena such as the Great Recession of 2007-2008. Our results show that trade volume alone cannot explain global GDP growth, and that network science may prove to be a valuable empirical avenue for studying complexity in macro-economic phenomena such as trade. ",
    "url": "https://arxiv.org/abs/2211.13117",
    "authors": [
      "Mayank Kejriwal",
      "Yuesheng Luo"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.13119",
    "title": "Performance of Cooperative Detection in Joint Communication-Sensing  Vehicular Network: A Data Analytic and Stochastic Geometry Approach",
    "abstract": "The increasing complexity of urban environments introduces additional uncertainty to the deployment of the autonomous vehicular network. A novel road infrastructure cooperative detection model using Joint Communication and Sensing (JCS) technology is proposed in this article to simultaneously achieve high-efficient communication and obstacle detection for urban autonomous vehicles. To suppress the performance fluctuation caused by shadowing and obstruction to the JCS signals, we first derive the statistic of road obstacles from the Geographic Information System (GIS). Then, the analysis of JCS channel characteristics and shadowing factors are presented using Line-of-Sight and Non-Line-of-Sight (LoS and NLoS) channel models under the complex urban scenario. A stochastic geometry approach is applied to analyze the interference factors and the probability distribution of successful JCS detection and communication. Simulations have been made to verify the cooperative detection model by probability analysis based on LoS and NLoS channels, and the numerical results demonstrate several different optimization methods for the deployment of JCS road infrastructures. Finally, we simulated and analyzed a deployment optimization method for JCS road infrastructures that complied with the standard of urban traffic-spot structure placement. ",
    "url": "https://arxiv.org/abs/2211.13119",
    "authors": [
      "Hao Ma",
      "Zhiqing Wei",
      "Zening Li",
      "Fan Ning",
      "Xu Chen",
      "Zhiyong Feng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.13157",
    "title": "Physics-Informed Multi-Stage Deep Learning Framework Development for  Digital Twin-Centred State-Based Reactor Power Prediction",
    "abstract": "Computationally efficient and trustworthy machine learning algorithms are necessary for Digital Twin (DT) framework development. Generally speaking, DT-enabling technologies consist of five major components: (i) Machine learning (ML)-driven prediction algorithm, (ii) Temporal synchronization between physics and digital assets utilizing advanced sensors/instrumentation, (iii) uncertainty propagation, and (iv) DT operational framework. Unfortunately, there is still a significant gap in developing those components for nuclear plant operation. In order to address this gap, this study specifically focuses on the \"ML-driven prediction algorithms\" as a viable component for the nuclear reactor operation while assessing the reliability and efficacy of the proposed model. Therefore, as a DT prediction component, this study develops a multi-stage predictive model consisting of two feedforward Deep Learning using Neural Networks (DNNs) to determine the final steady-state power of a reactor transient for a nuclear reactor/plant. The goal of the multi-stage model architecture is to convert probabilistic classification to continuous output variables to improve reliability and ease of analysis. Four regression models are developed and tested with input from the first stage model to predict a single value representing the reactor power output. The combined model yields 96% classification accuracy for the first stage and 92% absolute prediction accuracy for the second stage. The development procedure is discussed so that the method can be applied generally to similar systems. An analysis of the role similar models would fill in DTs is performed. ",
    "url": "https://arxiv.org/abs/2211.13157",
    "authors": [
      "James Daniell",
      "Kazuma Kobayashi",
      "Dinesh Kumar",
      "Souvik Chakraborty",
      "Ayodeji Alajo",
      "Ethan Taber",
      "Joseph Graham",
      "Syed Alam"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2012.10713",
    "title": "Fundamental Limits and Tradeoffs in Invariant Representation Learning",
    "abstract": " Comments: JMLR camera-ready version ",
    "url": "https://arxiv.org/abs/2012.10713",
    "authors": [
      "Han Zhao",
      "Chen Dan",
      "Bryon Aragam",
      "Tommi S. Jaakkola",
      "Geoffrey J. Gordon",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.00065",
    "title": "Gradient Descent on Neural Networks Typically Occurs at the Edge of  Stability",
    "abstract": " Comments: ICLR 2021. v3 moves several figures from the appendix into the main text, and adds more discussion regarding Jastrz\\k{e}bski et al (2020): this https URL ",
    "url": "https://arxiv.org/abs/2103.00065",
    "authors": [
      "Jeremy M. Cohen",
      "Simran Kaur",
      "Yuanzhi Li",
      "J. Zico Kolter",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2104.07128",
    "title": "Audio feature ranking for sound-based COVID-19 patient detection",
    "abstract": " Comments: 12 pages, 3 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2104.07128",
    "authors": [
      "Julia A. Meister",
      "Khuong An Nguyen",
      "Zhiyuan Luo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2108.12732",
    "title": "Feature Analysis for Machine Learning-based IoT Intrusion Detection",
    "abstract": " Comments: 22 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2108.12722 ",
    "url": "https://arxiv.org/abs/2108.12732",
    "authors": [
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2109.07744",
    "title": "Optimizing Hardware-Based Network Computation DAGs for Multiple Tenants  with SuperNIC",
    "abstract": " Comments: 17 pages ",
    "url": "https://arxiv.org/abs/2109.07744",
    "authors": [
      "Yizhou Shan",
      "Will Lin",
      "Ryan Kosta",
      "Arvind Krishnamurthy",
      "Yiying Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2109.09943",
    "title": "Identifiability of Chemical Reaction Networks with Intrinsic and  Extrinsic Noise from Stationary Distributions",
    "abstract": " Comments: 27 pages, 1 figure, 1 table. The extrinsic noise section is revised, and minor edits have been made throughout ",
    "url": "https://arxiv.org/abs/2109.09943",
    "authors": [
      "Theodore W. Grunberg",
      "Domitilla Del Vecchio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.06320",
    "title": "Anomaly Crossing: New Horizons for Video Anomaly Detection as  Cross-domain Few-shot Learning",
    "abstract": " Title: Anomaly Crossing: New Horizons for Video Anomaly Detection as  Cross-domain Few-shot Learning ",
    "url": "https://arxiv.org/abs/2112.06320",
    "authors": [
      "Guangyu Sun",
      "Zhang Liu",
      "Lianggong Wen",
      "Jing Shi",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.07532",
    "title": "Consensus of Homogeneous Agents with General Linear Dynamics under  Switching Communication Networks",
    "abstract": " Title: Consensus of Homogeneous Agents with General Linear Dynamics under  Switching Communication Networks ",
    "url": "https://arxiv.org/abs/2201.07532",
    "authors": [
      "Chong Jin Ong",
      "Ilayda Canyakmaz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.08363",
    "title": "Physics-informed neural networks for modeling rate- and  temperature-dependent plasticity",
    "abstract": " Comments: 11 pages, 7 figures; Accepted in NeurIPS 2022, Machine Learning and the Physical Sciences workshop ",
    "url": "https://arxiv.org/abs/2201.08363",
    "authors": [
      "Rajat Arora",
      "Pratik Kakkar",
      "Biswadip Dey",
      "Amit Chakraborty"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04629",
    "title": "Reducing Redundancy in the Bottleneck Representation of the Autoencoders",
    "abstract": " Comments: 6 pages,4 figures. The paper is under consideration at Pattern Recognition Letters ",
    "url": "https://arxiv.org/abs/2202.04629",
    "authors": [
      "Firas Laakom",
      "Jenni Raitoharju",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.08408",
    "title": "Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs",
    "abstract": " Comments: 14 pages, 6 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2202.08408",
    "authors": [
      "Ming Jin",
      "Yu Zheng",
      "Yuan-Fang Li",
      "Siheng Chen",
      "Bin Yang",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13696",
    "title": "Speech-enhanced and Noise-aware Networks for Robust Speech Recognition",
    "abstract": " Comments: Published in ISCSLP 2022 ",
    "url": "https://arxiv.org/abs/2203.13696",
    "authors": [
      "Hung-Shin Lee",
      "Pin-Yuan Chen",
      "Yao-Fei Cheng",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.13964",
    "title": "Fusing Global and Local Features for Generalized AI-Synthesized Image  Detection",
    "abstract": " Comments: 5 pages, 3 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2203.13964",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Lipeng Ke",
      "Hongfei Xue",
      "Koki Nagano",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03726",
    "title": "Decentralized Event-Triggered Federated Learning with Heterogeneous  Communication Thresholds",
    "abstract": " Title: Decentralized Event-Triggered Federated Learning with Heterogeneous  Communication Thresholds ",
    "url": "https://arxiv.org/abs/2204.03726",
    "authors": [
      "Shahryar Zehtabi",
      "Seyyedali Hosseinalipour",
      "Christopher G. Brinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.11515",
    "title": "Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor  Detection",
    "abstract": " Comments: There is an error in the experimental recording process, and the results reported in the article need to be re-checked ",
    "url": "https://arxiv.org/abs/2204.11515",
    "authors": [
      "Ge Wang",
      "Li Tan",
      "Ziliang Shang",
      "He Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.12436",
    "title": "Incentives in Social Decision Schemes with Pairwise Comparison  Preferences",
    "abstract": " Comments: A preliminary version appeared in the 31st International Joint Conference on Artificial Intelligence (IJCAI), 2022. The current version is significantly extended ",
    "url": "https://arxiv.org/abs/2204.12436",
    "authors": [
      "Felix Brandt",
      "Patrick Lederer",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2205.01491",
    "title": "A Comprehensive Survey of Image Augmentation Techniques for Deep  Learning",
    "abstract": " Comments: Revision ",
    "url": "https://arxiv.org/abs/2205.01491",
    "authors": [
      "Mingle Xu",
      "Sook Yoon",
      "Alvaro Fuentes",
      "Dong Sun Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15448",
    "title": "FeatER: An Efficient Network for Human Reconstruction via Feature  Map-Based TransformER",
    "abstract": " Title: FeatER: An Efficient Network for Human Reconstruction via Feature  Map-Based TransformER ",
    "url": "https://arxiv.org/abs/2205.15448",
    "authors": [
      "Ce Zheng",
      "Matias Mendieta",
      "Taojiannan Yang",
      "Guo-Jun Qi",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2206.01178",
    "title": "Discretization Invariant Learning on Neural Fields",
    "abstract": " Comments: Presented at NeurIPS 2022 Symmetry and Geometry in Neural Representations (NeurReps) Workshop ",
    "url": "https://arxiv.org/abs/2206.01178",
    "authors": [
      "Clinton J. Wang",
      "Polina Golland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.07665",
    "title": "Region-enhanced Deep Graph Convolutional Networks for Rumor Detection",
    "abstract": " Comments: Due to the error in the hyperparameter record during the repeated experiment, there are problems in reproducing the results ",
    "url": "https://arxiv.org/abs/2206.07665",
    "authors": [
      "Ge Wang",
      "Li Tan",
      "Tianbao Song",
      "Wei Wang",
      "Ziliang Shang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09900",
    "title": "Voxel-MAE: Masked Autoencoders for Self-supervised Pre-training  Large-scale Point Clouds",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2206.09900",
    "authors": [
      "Chen Min",
      "Xinli Xu",
      "Dawei Zhao",
      "Liang Xiao",
      "Yiming Nie",
      "Bin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10897",
    "title": "How to Combine Variational Bayesian Networks in Federated Learning",
    "abstract": " Title: How to Combine Variational Bayesian Networks in Federated Learning ",
    "url": "https://arxiv.org/abs/2206.10897",
    "authors": [
      "Atahan Ozer",
      "Kadir Burak Buldu",
      "Abdullah Akg\u00fcl",
      "Gozde Unal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.11134",
    "title": "Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization",
    "abstract": " Title: Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization ",
    "url": "https://arxiv.org/abs/2206.11134",
    "authors": [
      "Peixian Chen",
      "Kekai Sheng",
      "Mengdan Zhang",
      "Mingbao Lin",
      "Yunhang Shen",
      "Ke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15457",
    "title": "PhySRNet: Physics informed super-resolution network for application in  computational solid mechanics",
    "abstract": " Comments: 14 pages, 3 figures, arXiv admin note: text overlap with arXiv:2112.08676 ",
    "url": "https://arxiv.org/abs/2206.15457",
    "authors": [
      "Rajat Arora"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.03809",
    "title": "UDRN: Unified Dimensional Reduction Neural Network for Feature Selection  and Feature Projection",
    "abstract": " Comments: 14 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2207.03809",
    "authors": [
      "Zelin Zang",
      "Yongjie Xu",
      "Linyan Lu",
      "Yulan Geng",
      "Senqiao Yang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10397",
    "title": "CodeT: Code Generation with Generated Tests",
    "abstract": " Title: CodeT: Code Generation with Generated Tests ",
    "url": "https://arxiv.org/abs/2207.10397",
    "authors": [
      "Bei Chen",
      "Fengji Zhang",
      "Anh Nguyen",
      "Daoguang Zan",
      "Zeqi Lin",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.13572",
    "title": "Membership Inference Attacks via Adversarial Examples",
    "abstract": " Comments: Trustworthy and Socially Responsible Machine Learning (TSRML 2022) co-located with NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.13572",
    "authors": [
      "Hamid Jalalzai",
      "Elie Kadoche",
      "R\u00e9mi Leluc",
      "Vincent Plassier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.01711",
    "title": "Optimal Rates for Regularized Conditional Mean Embedding Learning",
    "abstract": " Title: Optimal Rates for Regularized Conditional Mean Embedding Learning ",
    "url": "https://arxiv.org/abs/2208.01711",
    "authors": [
      "Zhu Li",
      "Dimitri Meunier",
      "Mattes Mollenhauer",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.03288",
    "title": "Convolutional Ensembling based Few-Shot Defect Detection Technique",
    "abstract": " Comments: 7 pages, 7 images ",
    "url": "https://arxiv.org/abs/2208.03288",
    "authors": [
      "Soumyajit Karmakar",
      "Abeer Banerjee",
      "Prashant Sadashiv Gidde",
      "Sumeet Saurav",
      "Sanjay Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.03571",
    "title": "Transformer-based assignment decision network for multiple object  tracking",
    "abstract": " Comments: Preprint version. Under consideration at Computer Vision and Image Understanding ",
    "url": "https://arxiv.org/abs/2208.03571",
    "authors": [
      "Athena Psalta",
      "Vasileios Tsironis",
      "Konstantinos Karantzalos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.04405",
    "title": "Recovering the Graph Underlying Networked Dynamical Systems under  Partial Observability: A Deep Learning Approach",
    "abstract": " Comments: Accepted at The 37th AAAI Conference on Artificial Intelligence (main track) ",
    "url": "https://arxiv.org/abs/2208.04405",
    "authors": [
      "S\u00e9rgio Machado",
      "Anirudh Sridhar",
      "Paulo Gil",
      "Jorge Henriques",
      "Jos\u00e9 M. F. Moura",
      "Augusto Santos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2208.05192",
    "title": "Real-Time Oil Leakage Detection on Aftermarket Motorcycle Damping System  with Convolutional Neural Networks",
    "abstract": " Comments: analysis of literature reviewed, n.2 figures added, minor corrections ",
    "url": "https://arxiv.org/abs/2208.05192",
    "authors": [
      "Federico Bianchi",
      "Stefano Speziali",
      "Andrea Marini",
      "Massimiliano Proietti",
      "Lorenzo Menculini",
      "Alberto Garinei",
      "Gabriele Bellani",
      "Marcello Marconi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.06081",
    "title": "Slicing4Meta: An Intelligent Integration Framework with  Multi-dimensional Network Resources for Metaverse-as-a-Service in Web 3.0",
    "abstract": " Title: Slicing4Meta: An Intelligent Integration Framework with  Multi-dimensional Network Resources for Metaverse-as-a-Service in Web 3.0 ",
    "url": "https://arxiv.org/abs/2208.06081",
    "authors": [
      "Yi-Jing Liu",
      "Hongyang Du",
      "Dusit Niyato",
      "Gang Feng",
      "Jiawen Kang",
      "Zehui Xiong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.09046",
    "title": "Self-Supervised Primal-Dual Learning for Constrained Optimization",
    "abstract": " Comments: Accepted at AAAI23 ",
    "url": "https://arxiv.org/abs/2208.09046",
    "authors": [
      "Seonho Park",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2208.11266",
    "title": "SCALE: Online Self-Supervised Lifelong Learning without Prior Knowledge",
    "abstract": " Comments: Submitted for review ",
    "url": "https://arxiv.org/abs/2208.11266",
    "authors": [
      "Xiaofan Yu",
      "Yunhui Guo",
      "Sicun Gao",
      "Tajana Rosing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.11290",
    "title": "ADMoE: Anomaly Detection with Mixture-of-Experts from Noisy Labels",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2208.11290",
    "authors": [
      "Yue Zhao",
      "Guoqing Zheng",
      "Subhabrata Mukherjee",
      "Robert McCann",
      "Ahmed Awadallah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.06860",
    "title": "Reconstruction of Three-dimensional Scroll Waves in Excitable Media from  Two-Dimensional Observations using Deep Neural Networks",
    "abstract": " Title: Reconstruction of Three-dimensional Scroll Waves in Excitable Media from  Two-Dimensional Observations using Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2209.06860",
    "authors": [
      "Jan Lebert",
      "Meenakshi Mittal",
      "Jan Christoph"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2209.15180",
    "title": "SCI: A Spectrum Concentrated Implicit Neural Compression for Biomedical  Data",
    "abstract": " Comments: accepted to AAAI2023 ",
    "url": "https://arxiv.org/abs/2209.15180",
    "authors": [
      "Runzhao Yang",
      "Tingxiong Xiao",
      "Yuxiao Cheng",
      "Qianni Cao",
      "Jinyuan Qu",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.15304",
    "title": "Visual Information Hiding Based on Obfuscating Adversarial Perturbations",
    "abstract": " Title: Visual Information Hiding Based on Obfuscating Adversarial Perturbations ",
    "url": "https://arxiv.org/abs/2209.15304",
    "authors": [
      "Zhigang Su",
      "Dawei Zhou",
      "Decheng Liu",
      "Nannan Wang",
      "Zhen Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00053",
    "title": "Kernel Normalized Convolutional Networks for Privacy-Preserving Machine  Learning",
    "abstract": " Comments: To appear in the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), February 2023 ",
    "url": "https://arxiv.org/abs/2210.00053",
    "authors": [
      "Reza Nasirigerdeh",
      "Javad Torkzadehmahani",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.01506",
    "title": "How deep convolutional neural networks lose spatial information with  training",
    "abstract": " Title: How deep convolutional neural networks lose spatial information with  training ",
    "url": "https://arxiv.org/abs/2210.01506",
    "authors": [
      "Umberto M. Tomasini",
      "Leonardo Petrini",
      "Francesco Cagnetta",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03274",
    "title": "TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts",
    "abstract": " Title: TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts ",
    "url": "https://arxiv.org/abs/2210.03274",
    "authors": [
      "Zhihao Wang",
      "Chuang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07236",
    "title": "Improved Bounds on Neural Complexity for Representing Piecewise Linear  Functions",
    "abstract": " Comments: 31 pages. Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.07236",
    "authors": [
      "Kuan-Lin Chen",
      "Harinath Garudadri",
      "Bhaskar D. Rao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.15787",
    "title": "Convolutional Codes with Optimum Bidirectional Distance Profile",
    "abstract": " Title: Convolutional Codes with Optimum Bidirectional Distance Profile ",
    "url": "https://arxiv.org/abs/2210.15787",
    "authors": [
      "Ivan Stanojevi\u0107",
      "Vojin \u0160enk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.16118",
    "title": "Imitation Learning-based Implicit Semantic-aware Communication Networks:  Multi-layer Representation and Collaborative Reasoning",
    "abstract": " Comments: Accepted at IEEE Journal on Selected Areas in Communications ",
    "url": "https://arxiv.org/abs/2210.16118",
    "authors": [
      "Yong Xiao",
      "Zijian Sun",
      "Guangming Shi",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.16993",
    "title": "STN: a new tensor network method to identify stimulus category from  brain activity pattern",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2210.16993",
    "authors": [
      "Chunyu Liu",
      "Jiacai Zhang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01207",
    "title": "Bias-Aware Face Mask Detection Dataset",
    "abstract": " Comments: submitted to IEEE Transactions on Computational Social Systems, 7 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2211.01207",
    "authors": [
      "Alperen Kantarc\u0131",
      "Ferda Ofli",
      "Muhammad Imran",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.03017",
    "title": "Learning-based Inverse Rendering of Complex Indoor Scenes with  Differentiable Monte Carlo Raytracing",
    "abstract": " Title: Learning-based Inverse Rendering of Complex Indoor Scenes with  Differentiable Monte Carlo Raytracing ",
    "url": "https://arxiv.org/abs/2211.03017",
    "authors": [
      "Jingsen Zhu",
      "Fujun Luan",
      "Yuchi Huo",
      "Zihao Lin",
      "Zhihua Zhong",
      "Dianbing Xi",
      "Jiaxiang Zheng",
      "Rui Tang",
      "Hujun Bao",
      "Rui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.05697",
    "title": "Bayesian hierarchical modelling for battery lifetime early prediction",
    "abstract": " Comments: 7 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2211.05697",
    "authors": [
      "Zihao Zhou",
      "David A. Howey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.07220",
    "title": "Constant Function Market Making, Social Welfare and Maximal Extractable  Value",
    "abstract": " Title: Constant Function Market Making, Social Welfare and Maximal Extractable  Value ",
    "url": "https://arxiv.org/abs/2211.07220",
    "authors": [
      "Bruno Mazorra",
      "Nicol\u00e1s Della Penna"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2211.08615",
    "title": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "abstract": " Title: GLFF: Global and Local Feature Fusion for Face Forgery Detection ",
    "url": "https://arxiv.org/abs/2211.08615",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Jialing Cai",
      "Haiying Guan",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08939",
    "title": "Augmented Physics-Informed Neural Networks (APINNs): A gating  network-based soft domain decomposition methodology",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2211.08939",
    "authors": [
      "Zheyuan Hu",
      "Ameya D. Jagtap",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.11188",
    "title": "Simultaneous Multiple Object Detection and Pose Estimation using 3D  Model Infusion with Monocular Vision",
    "abstract": " Title: Simultaneous Multiple Object Detection and Pose Estimation using 3D  Model Infusion with Monocular Vision ",
    "url": "https://arxiv.org/abs/2211.11188",
    "authors": [
      "Congliang Li",
      "Shijie Sun",
      "Xiangyu Song",
      "Huansheng Song",
      "Naveed Akhtar",
      "Ajmal Saeed Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11202",
    "title": "FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields",
    "abstract": " Comments: Hao Zhang and Tianyuan Dai contributed equally. Project website: this https URL ",
    "url": "https://arxiv.org/abs/2211.11202",
    "authors": [
      "Hao Zhang",
      "Tianyuan Dai",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.11210",
    "title": "Contrastive Masked Autoencoders for Self-Supervised Video Hashing",
    "abstract": " Comments: This work is accepted by the AAAI 2023. 9 pages, 6 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2211.11210",
    "authors": [
      "Yuting Wang",
      "Jinpeng Wang",
      "Bin Chen",
      "Ziyun Zeng",
      "Shutao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.11238",
    "title": "RobustLoc: Robust Camera Pose Regression in Challenging Driving  Environments",
    "abstract": " Title: RobustLoc: Robust Camera Pose Regression in Challenging Driving  Environments ",
    "url": "https://arxiv.org/abs/2211.11238",
    "authors": [
      "Sijie Wang",
      "Qiyu Kang",
      "Rui She",
      "Wee Peng Tay",
      "Andreas Hartmannsgruber",
      "Diego Navarro Navarro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11378",
    "title": "Learning on tree architectures outperforms a convolutional feedforward  network",
    "abstract": " Comments: 20 pages, 4 figures, 1 table (improved figures resolution) ",
    "url": "https://arxiv.org/abs/2211.11378",
    "authors": [
      "Yuval Meir",
      "Itamar Ben-Noam",
      "Yarden Tzach",
      "Shiri Hodassman",
      "Ido Kanter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11835",
    "title": "Fairness Increases Adversarial Vulnerability",
    "abstract": " Title: Fairness Increases Adversarial Vulnerability ",
    "url": "https://arxiv.org/abs/2211.11835",
    "authors": [
      "Cuong Tran",
      "Keyu Zhu",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.11865",
    "title": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "abstract": " Title: Bayesian Learning for Neural Networks: an algorithmic survey ",
    "url": "https://arxiv.org/abs/2211.11865",
    "authors": [
      "Martin Magris",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11959",
    "title": "Robust High-dimensional Tuning Free Multiple Testing",
    "abstract": " Comments: In this paper, we develop tuning-free and moment-free high dimensional inference procedures; ",
    "url": "https://arxiv.org/abs/2211.11959",
    "authors": [
      "Jianqing Fan",
      "Zhipeng Lou",
      "Mengxin Yu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.11962",
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.11962",
    "authors": [
      "Hai Wu",
      "Chenglu Wen",
      "Wei Li",
      "Xin Li",
      "Ruigang Yang",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12040",
    "title": "Rethinking Implicit Neural Representations for Vision Learners",
    "abstract": " Title: Rethinking Implicit Neural Representations for Vision Learners ",
    "url": "https://arxiv.org/abs/2211.12040",
    "authors": [
      "Yiran Song",
      "Qianyu Zhou",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12044",
    "title": "Backdoor Cleansing with Unlabeled Data",
    "abstract": " Title: Backdoor Cleansing with Unlabeled Data ",
    "url": "https://arxiv.org/abs/2211.12044",
    "authors": [
      "Lu Pang",
      "Tao Sun",
      "Haibin Ling",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.12084",
    "title": "Accelerated Solutions of Coupled Phase-Field Problems using Generative  Adversarial Networks",
    "abstract": " Comments: 18 pages, 21 figures (including subfigures). Will be submitted to the journal: \"Computational Materials Science\" soon ",
    "url": "https://arxiv.org/abs/2211.12084",
    "authors": [
      "Vir Karan",
      "A. Maruthi Indresh",
      "Saswata Bhattacharyya"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.12244",
    "title": "FE-Fusion-VPR: Attention-based Multi-Scale Network Architecture for  Visual Place Recognition by Fusing Frames and Events",
    "abstract": " Title: FE-Fusion-VPR: Attention-based Multi-Scale Network Architecture for  Visual Place Recognition by Fusing Frames and Events ",
    "url": "https://arxiv.org/abs/2211.12244",
    "authors": [
      "Kuanxu Hou",
      "Delei Kong",
      "Junjie Jiang",
      "Hao Zhuang",
      "Xinjie Huang",
      "Zheng Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.12421",
    "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
    "abstract": " Title: Data-Driven Network Neuroscience: On Data Collection and Benchmark ",
    "url": "https://arxiv.org/abs/2211.12421",
    "authors": [
      "David Tse Jung Huang",
      "Sophi Shilpa Gururajapathy",
      "Yiping Ke",
      "Miao Qiao",
      "Alan Wang",
      "Haribalan Kumar",
      "Yunhan Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  }
]