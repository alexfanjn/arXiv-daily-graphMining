[
  {
    "id": "arXiv:2211.14314",
    "title": "The applicability of transperceptual and deep learning approaches to the  study and mimicry of complex cartilaginous tissues",
    "abstract": "Complex soft tissues, for example the knee meniscus, play a crucial role in mobility and joint health, but when damaged are incredibly difficult to repair and replace. This is due to their highly hierarchical and porous nature which in turn leads to their unique mechanical properties. In order to design tissue substitutes, the internal architecture of the native tissue needs to be understood and replicated. Here we explore a combined audio-visual approach - so called transperceptual - to generate artificial architectures mimicking the native ones. The proposed method uses both traditional imagery, and sound generated from each image as a method of rapidly comparing and contrasting the porosity and pore size within the samples. We have trained and tested a generative adversarial network (GAN) on the 2D image stacks. The impact of the training set of images on the similarity of the artificial to the original dataset was assessed by analyzing two samples. The first consisting of n=478 pairs of audio and image files for which the images were downsampled to 64 $\\times$ 64 pixels, the second one consisting of n=7640 pairs of audio and image files for which the full resolution 256 $\\times$ 256 pixels is retained but each image is divided into 16 squares to maintain the limit of 64 $\\times$ 64 pixels required by the GAN. We reconstruct the 2D stacks of artificially generated datasets into 3D objects and run image analysis algorithms to characterize statistically the architectural parameters - pore size, tortuosity and pore connectivity - and compare them with the original dataset. Results show that the artificially generated dataset that undergoes downsampling performs better in terms of parameter matching. Our audiovisual approach has the potential to be extended to larger data sets to explore both how similarities and differences can be audibly recognized across multiple samples. ",
    "url": "https://arxiv.org/abs/2211.14314",
    "authors": [
      "J. Waghorne",
      "C. Howard",
      "H. Hu",
      "J. Pang",
      "W.J. Peveler",
      "L. Harris",
      "O. Barrera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.14316",
    "title": "Identifying discreditable firms in a large-scale ownership network",
    "abstract": "Violations of laws and regulations about food safety, production safety, quality standard and environmental protection, or negative consequences from loan, guarantee and pledge contracts, may result in operating and credit risks of firms. The above illegal or trust-breaking activities are collectively called discreditable activities, and firms with discreditable activities are named as discreditable firms. Identification of discreditable firms is of great significance for investment attraction, bank lending, equity investment, supplier selection, job seeking, and so on. In this paper, we collect registration records of about 113 million Chinese firms and construct an ownership network with about 6 million nodes, where each node is a firm who has invested at least one firm or has been invested by at least one firm. Analysis of publicly available records of discreditable activities show strong network effect, namely the probability of a firm to be discreditable is remarkably higher than the average probability given the fact that one of its investors or investees is discreditable. In comparison, for the risk of being a discreditable firm, an investee has higher impact than an investor in average. The impact of a firm on surrounding firms decays along with the increasing topological distance, analogous to the well-known \"three degrees of separation\" phenomenon. The uncovered correlation of discreditable activities can be considered as a representative example of network effect, in addition to the propagation of diseases, opinions and human behaviors. Lastly, we show that the utilization of the network effect largely improves the accuracy of the algorithm to identify discreditable firms. ",
    "url": "https://arxiv.org/abs/2211.14316",
    "authors": [
      "Tao Zhou",
      "Yan-Li Lee",
      "Qian Li",
      "Duanbing Chen",
      "Wenbo Xie",
      "Tong Wu",
      "Tu Zeng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.14343",
    "title": "Less Data, More Knowledge: Building Next Generation Semantic  Communication Networks",
    "abstract": "Semantic communication is viewed as a revolutionary paradigm that can potentially transform how we design and operate wireless communication systems. However, despite a recent surge of research activities in this area, the research landscape remains limited. In this tutorial, we present the first rigorous vision of a scalable end-to-end semantic communication network that is founded on novel concepts from artificial intelligence (AI), causal reasoning, and communication theory. We first discuss how the design of semantic communication networks requires a move from data-driven networks towards knowledge-driven ones. Subsequently, we highlight the necessity of creating semantic representations of data that satisfy the key properties of minimalism, generalizability, and efficiency so as to do more with less. We then explain how those representations can form the basis a so-called semantic language. By using semantic representation and languages, we show that the traditional transmitter and receiver now become a teacher and apprentice. Then, we define the concept of reasoning by investigating the fundamentals of causal representation learning and their role in designing semantic communication networks. We demonstrate that reasoning faculties are majorly characterized by the ability to capture causal and associational relationships in datastreams. For such reasoning-driven networks, we propose novel and essential semantic communication metrics that include new \"reasoning capacity\" measures that could go beyond Shannon's bound to capture the convergence of computing and communication. Finally, we explain how semantic communications can be scaled to large-scale networks (6G and beyond). In a nutshell, we expect this tutorial to provide a comprehensive reference on how to properly build, analyze, and deploy future semantic communication networks. ",
    "url": "https://arxiv.org/abs/2211.14343",
    "authors": [
      "Christina Chaccour",
      "Walid Saad",
      "Merouane Debbah",
      "Zhu Han",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.14347",
    "title": "The smooth output assumption, and why deep networks are better than wide  ones",
    "abstract": "When several models have similar training scores, classical model selection heuristics follow Occam's razor and advise choosing the ones with least capacity. Yet, modern practice with large neural networks has often led to situations where two networks with exactly the same number of parameters score similar on the training set, but the deeper one generalizes better to unseen examples. With this in mind, it is well accepted that deep networks are superior to shallow wide ones. However, theoretically there is no difference between the two. In fact, they are both universal approximators. In this work we propose a new unsupervised measure that predicts how well a model will generalize. We call it the output sharpness, and it is based on the fact that, in reality, boundaries between concepts are generally unsharp. We test this new measure on several neural network settings, and architectures, and show how generally strong the correlation is between our metric, and test set performance. Having established this measure, we give a mathematical probabilistic argument that predicts network depth to be correlated with our proposed measure. After verifying this in real data, we are able to formulate the key argument of the work: output sharpness hampers generalization; deep networks have an in built bias against it; therefore, deep networks beat wide ones. All in all the work not only provides a helpful predictor of overfitting that can be used in practice for model selection (or even regularization), but also provides a much needed theoretical grounding for the success of modern deep neural networks. ",
    "url": "https://arxiv.org/abs/2211.14347",
    "authors": [
      "Luis Sa-Couto",
      "Jose Miguel Ramos",
      "Andreas Wichert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14364",
    "title": "Safe and Robust Observer-Controller Synthesis using Control Barrier  Functions",
    "abstract": "This paper addresses the synthesis of safety-critical controllers using estimate feedback. We propose an observer-controller interconnection to ensure that the nonlinear system remains safe despite bounded disturbances on the system dynamics and measurements that correspond to partial state information. The co-design of observers and controllers is critical, since even in undisturbed cases, observers and controllers designed independently may not render the system safe. We propose two approaches to synthesize observer-controller interconnections. The first approach utilizes Input-to-State Stable observers, and the second uses Bounded Error observers. Using these stability and boundedness properties of the observation error, we construct novel Control Barrier Functions that impose inequality constraints on the control inputs which, when satisfied, certifies safety. We propose quadratic program-based controllers to satisfy these constraints, and prove Lipschitz continuity of the derived controllers. Simulations and experiments on a quadrotor demonstrate the efficacy of the proposed methods. ",
    "url": "https://arxiv.org/abs/2211.14364",
    "authors": [
      "Devansh R. Agrawal",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.14375",
    "title": "Designing Neural Networks for Hyperbolic Conservation Laws",
    "abstract": "We propose a new data-driven method to learn the dynamics of an unknown hyperbolic system of conservation laws using deep neural networks. Inspired by classical methods in numerical conservation laws, we develop a new conservative form network (CFN) in which the network learns the flux function of the unknown system. Our numerical examples demonstrate that the CFN yields significantly better prediction accuracy than what is obtained using a standard non-conservative form network, even when it is enhanced with constraints to promote conservation. In particular, solutions obtained using the CFN consistently capture the correct shock propagation speed without introducing non-physical oscillations into the solution. They are furthermore robust to noisy and sparse observation environments. ",
    "url": "https://arxiv.org/abs/2211.14375",
    "authors": [
      "Zhen Chen",
      "Anne Gelb",
      "Yoonsang Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.14383",
    "title": "Interpreting Unfairness in Graph Neural Networks via Training Node  Attribution",
    "abstract": "Graph Neural Networks (GNNs) have emerged as the leading paradigm for solving graph analytical problems in various real-world applications. Nevertheless, GNNs could potentially render biased predictions towards certain demographic subgroups. Understanding how the bias in predictions arises is critical, as it guides the design of GNN debiasing mechanisms. However, most existing works overwhelmingly focus on GNN debiasing, but fall short on explaining how such bias is induced. In this paper, we study a novel problem of interpreting GNN unfairness through attributing it to the influence of training nodes. Specifically, we propose a novel strategy named Probabilistic Distribution Disparity (PDD) to measure the bias exhibited in GNNs, and develop an algorithm to efficiently estimate the influence of each training node on such bias. We verify the validity of PDD and the effectiveness of influence estimation through experiments on real-world datasets. Finally, we also demonstrate how the proposed framework could be used for debiasing GNNs. Open-source code can be found at https://github.com/yushundong/BIND. ",
    "url": "https://arxiv.org/abs/2211.14383",
    "authors": [
      "Yushun Dong",
      "Song Wang",
      "Jing Ma",
      "Ninghao Liu",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.14394",
    "title": "Link Prediction with Non-Contrastive Learning",
    "abstract": "A recent focal area in the space of graph neural networks (GNNs) is graph self-supervised learning (SSL), which aims to derive useful node representations without labeled data. Notably, many state-of-the-art graph SSL methods are contrastive methods, which use a combination of positive and negative samples to learn node representations. Owing to challenges in negative sampling (slowness and model sensitivity), recent literature introduced non-contrastive methods, which instead only use positive samples. Though such methods have shown promising performance in node-level tasks, their suitability for link prediction tasks, which are concerned with predicting link existence between pairs of nodes (and have broad applicability to recommendation systems contexts) is yet unexplored. In this work, we extensively evaluate the performance of existing non-contrastive methods for link prediction in both transductive and inductive settings. While most existing non-contrastive methods perform poorly overall, we find that, surprisingly, BGRL generally performs well in transductive settings. However, it performs poorly in the more realistic inductive settings where the model has to generalize to links to/from unseen nodes. We find that non-contrastive models tend to overfit to the training graph and use this analysis to propose T-BGRL, a novel non-contrastive framework that incorporates cheap corruptions to improve the generalization ability of the model. This simple modification strongly improves inductive performance in 5/6 of our datasets, with up to a 120% improvement in Hits@50--all with comparable speed to other non-contrastive baselines and up to 14x faster than the best-performing contrastive baseline. Our work imparts interesting findings about non-contrastive learning for link prediction and paves the way for future researchers to further expand upon this area. ",
    "url": "https://arxiv.org/abs/2211.14394",
    "authors": [
      "William Shiao",
      "Zhichun Guo",
      "Tong Zhao",
      "Evangelos E. Papalexakis",
      "Yozen Liu",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.14396",
    "title": "A Comprehensive Study of Radiomics-based Machine Learning for Fibrosis  Detection",
    "abstract": "Objectives: Early detection of liver fibrosis can help cure the disease or prevent disease progression. We perform a comprehensive study of machine learning-based fibrosis detection in CT images using radiomic features to develop a non-invasive approach to fibrosis detection. Methods: Two sets of radiomic features were extracted from spherical ROIs in CT images of 182 patients who underwent simultaneous liver biopsy and CT examinations, one set corresponding to biopsy locations and another distant from biopsy locations. Combinations of contrast, normalization, machine learning model, feature selection method, bin width, and kernel radius were investigated, each of which were trained and evaluated 100 times with randomized development and test cohorts. The best settings were evaluated based on their mean test AUC and the best features were determined based on their frequency among the best settings. Results: Logistic regression models with NC images normalized using Gamma correction with $\\gamma = 1.5$ performed best for fibrosis detection. Boruta was the best for radiomic feature selection method. Training a model using these optimal settings and features consisting of first order energy, first order kurtosis, and first order skewness, resulted in a model that achieved mean test AUCs of 0.7549 and 0.7166 on biopsy-based and non-biopsy ROIs respectively, outperforming a baseline and best models found during the initial study. Conclusions: Logistic regression models trained on radiomic features from NC images normalized using Gamma correction with $\\gamma = 1.5$ that underwent Boruta feature selection are effective for liver fibrosis detection. Energy, kurtosis, and skewness are particularly effective features for fibrosis detection. ",
    "url": "https://arxiv.org/abs/2211.14396",
    "authors": [
      "Jay J. Yoo",
      "Khashayar Namdar",
      "Chris McIntosh",
      "Farzad Khalvati",
      "Patrik Rogalla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.14402",
    "title": "An Analysis of Social Biases Present in BERT Variants Across Multiple  Languages",
    "abstract": "Although large pre-trained language models have achieved great success in many NLP tasks, it has been shown that they reflect human biases from their pre-training corpora. This bias may lead to undesirable outcomes when these models are applied in real-world settings. In this paper, we investigate the bias present in monolingual BERT models across a diverse set of languages (English, Greek, and Persian). While recent research has mostly focused on gender-related biases, we analyze religious and ethnic biases as well and propose a template-based method to measure any kind of bias, based on sentence pseudo-likelihood, that can handle morphologically complex languages with gender-based adjective declensions. We analyze each monolingual model via this method and visualize cultural similarities and differences across different dimensions of bias. Ultimately, we conclude that current methods of probing for bias are highly language-dependent, necessitating cultural insights regarding the unique ways bias is expressed in each language and culture (e.g. through coded language, synecdoche, and other similar linguistic concepts). We also hypothesize that higher measured social biases in the non-English BERT models correlate with user-generated content in their training. ",
    "url": "https://arxiv.org/abs/2211.14402",
    "authors": [
      "Aristides Milios",
      "Parishad BehnamGhader"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14405",
    "title": "Learning Branching Heuristics from Graph Neural Networks",
    "abstract": "Backtracking has been widely used for solving problems in artificial intelligence (AI), including constraint satisfaction problems and combinatorial optimization problems. Good branching heuristics can efficiently improve the performance of backtracking by helping prune the search space and leading the search to the most promising direction. In this paper, we first propose a new graph neural network (GNN) model designed using the probabilistic method. From the GNN model, we introduce an approach to learn a branching heuristic for combinatorial optimization problems. In particular, our GNN model learns appropriate probability distributions on vertices in given graphs from which the branching heuristic is extracted and used in a backtracking search. Our experimental results for the (minimum) dominating-clique problem show that this learned branching heuristic performs better than the minimum-remaining-values heuristic in terms of the number of branches of the whole search tree. Our approach introduces a new way of applying GNNs towards enhancing the classical backtracking algorithm used in AI. ",
    "url": "https://arxiv.org/abs/2211.14405",
    "authors": [
      "Congsong Zhang",
      "Yong Gao",
      "James Nastos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14406",
    "title": "Exploring Temporal Information Dynamics in Spiking Neural Networks",
    "abstract": "Most existing Spiking Neural Network (SNN) works state that SNNs may utilize temporal information dynamics of spikes. However, an explicit analysis of temporal information dynamics is still missing. In this paper, we ask several important questions for providing a fundamental understanding of SNNs: What are temporal information dynamics inside SNNs? How can we measure the temporal information dynamics? How do the temporal information dynamics affect the overall learning performance? To answer these questions, we estimate the Fisher Information of the weights to measure the distribution of temporal information during training in an empirical manner. Surprisingly, as training goes on, Fisher information starts to concentrate in the early timesteps. After training, we observe that information becomes highly concentrated in earlier few timesteps, a phenomenon we refer to as temporal information concentration. We observe that the temporal information concentration phenomenon is a common learning feature of SNNs by conducting extensive experiments on various configurations such as architecture, dataset, optimization strategy, time constant, and timesteps. Furthermore, to reveal how temporal information concentration affects the performance of SNNs, we design a loss function to change the trend of temporal information. We find that temporal information concentration is crucial to building a robust SNN but has little effect on classification accuracy. Finally, we propose an efficient iterative pruning method based on our observation on temporal information concentration. Code is available at https://github.com/Intelligent-Computing-Lab-Yale/Exploring-Temporal-Information-Dynamics-in-Spiking-Neural-Networks. ",
    "url": "https://arxiv.org/abs/2211.14406",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Anna Hambitzer",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.14419",
    "title": "Panoramic Video Salient Object Detection with Ambisonic Audio Guidance",
    "abstract": "Video salient object detection (VSOD), as a fundamental computer vision problem, has been extensively discussed in the last decade. However, all existing works focus on addressing the VSOD problem in 2D scenarios. With the rapid development of VR devices, panoramic videos have been a promising alternative to 2D videos to provide immersive feelings of the real world. In this paper, we aim to tackle the video salient object detection problem for panoramic videos, with their corresponding ambisonic audios. A multimodal fusion module equipped with two pseudo-siamese audio-visual context fusion (ACF) blocks is proposed to effectively conduct audio-visual interaction. The ACF block equipped with spherical positional encoding enables the fusion in the 3D context to capture the spatial correspondence between pixels and sound sources from the equirectangular frames and ambisonic audios. Experimental results verify the effectiveness of our proposed components and demonstrate that our method achieves state-of-the-art performance on the ASOD60K dataset. ",
    "url": "https://arxiv.org/abs/2211.14419",
    "authors": [
      "Xiang Li",
      "Haoyuan Cao",
      "Shijie Zhao",
      "Junlin Li",
      "Li Zhang",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14422",
    "title": "Quantitative Method for Security Situation of the Power Information  Network Based on the Evolutionary Neural Network",
    "abstract": "Cybersecurity is the security cornerstone of digital transformation of the power grid and construction of new power systems. The traditional network security situation quantification method only analyzes from the perspective of network performance, ignoring the impact of various power application services on the security situation, so the quantification results cannot fully reflect the power information network risk state. This study proposes a method for quantifying security situation of the power information network based on the evolutionary neural network. First, the security posture system architecture is designed by analyzing the business characteristics of power information network applications. Second, combining the importance of power application business, the spatial element index system of coupled interconnection is established from three dimensions of network reliability, threat, and vulnerability. Then, the BP neural network optimized by the genetic evolutionary algorithm is incorporated into the element index calculation process, and the quantitative model of security posture of the power information network based on the evolutionary neural network is constructed. Finally, a simulation experiment environment is built according to a power sector network topology, and the effectiveness and robustness of the method proposed in the study are verified. ",
    "url": "https://arxiv.org/abs/2211.14422",
    "authors": [
      "Quande Yuan",
      "Yuzhen Pi",
      "Lei Kou",
      "Fangfang Zhang",
      "Bo Ye"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14424",
    "title": "Supervised Contrastive Prototype Learning: Augmentation Free Robust  Neural Network",
    "abstract": "Transformations in the input space of Deep Neural Networks (DNN) lead to unintended changes in the feature space. Almost perceptually identical inputs, such as adversarial examples, can have significantly distant feature representations. On the contrary, Out-of-Distribution (OOD) samples can have highly similar feature representations to training set samples. Our theoretical analysis for DNNs trained with a categorical classification head suggests that the inflexible logit space restricted by the classification problem size is one of the root causes for the lack of $\\textit{robustness}$. Our second observation is that DNNs over-fit to the training augmentation technique and do not learn $\\textit{nuance invariant}$ representations. Inspired by the recent success of prototypical and contrastive learning frameworks for both improving robustness and learning nuance invariant representations, we propose a training framework, $\\textbf{Supervised Contrastive Prototype Learning}$ (SCPL). We use N-pair contrastive loss with prototypes of the same and opposite classes and replace a categorical classification head with a $\\textbf{Prototype Classification Head}$ (PCH). Our approach is $\\textit{sample efficient}$, does not require $\\textit{sample mining}$, can be implemented on any existing DNN without modification to their architecture, and combined with other training augmentation techniques. We empirically evaluate the $\\textbf{clean}$ robustness of our method on out-of-distribution and adversarial samples. Our framework outperforms other state-of-the-art contrastive and prototype learning approaches in $\\textit{robustness}$. ",
    "url": "https://arxiv.org/abs/2211.14424",
    "authors": [
      "Iordanis Fostiropoulos",
      "Laurent Itti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14425",
    "title": "PatchGT: Transformer over Non-trainable Clusters for Learning Graph  Representations",
    "abstract": "Recently the Transformer structure has shown good performances in graph learning tasks. However, these Transformer models directly work on graph nodes and may have difficulties learning high-level information. Inspired by the vision transformer, which applies to image patches, we propose a new Transformer-based graph neural network: Patch Graph Transformer (PatchGT). Unlike previous transformer-based models for learning graph representations, PatchGT learns from non-trainable graph patches, not from nodes directly. It can help save computation and improve the model performance. The key idea is to segment a graph into patches based on spectral clustering without any trainable parameters, with which the model can first use GNN layers to learn patch-level representations and then use Transformer to obtain graph-level representations. The architecture leverages the spectral information of graphs and combines the strengths of GNNs and Transformers. Further, we show the limitations of previous hierarchical trainable clusters theoretically and empirically. We also prove the proposed non-trainable spectral clustering method is permutation invariant and can help address the information bottlenecks in the graph. PatchGT achieves higher expressiveness than 1-WL-type GNNs, and the empirical study shows that PatchGT achieves competitive performances on benchmark datasets and provides interpretability to its predictions. The implementation of our algorithm is released at our Github repo: https://github.com/tufts-ml/PatchGT. ",
    "url": "https://arxiv.org/abs/2211.14425",
    "authors": [
      "Han Gao",
      "Xu Han",
      "Jiaoyang Huang",
      "Jian-Xun Wang",
      "Li-Ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2211.14434",
    "title": "Multistep prediction for short-term wind speed based on the MLP and LSTM  method with rankpooling",
    "abstract": "The actual wind speed data suffers from the intermittent and fluctuating property, which implies that it is very difficult to forecast wind speed with high accuracy by applying single or shallow models. Hence, with the purpose of improving the forecasting accuracy and obtain better forecasting results, in this paper, a novel hybrid deep learning model is proposed for multistep forecasting of wind speed, which is intuitively abbreviated as LR-FFT-RP-LSTM and LR-FFT-RP-LSTM. Under these formulated model, the rankpooling method is firstly presented to extract local features of the raw meteorological data, and the Fast Fourier Transformation (FFT) is adopted to extract local and global features of the raw meteorological data to obtain pre-processed data, and the data obtained is then integrated with the original data using the two procedures to produce two input datasets. Then, deep learning model named multi-layer perceptron method (MLP) and long short-term memory (LSTM) are adopted to predict the wind speed dataset. The target prediction results are then obtained by integrating the preliminary prediction findings using the linear regression method.Practical wind speed data from 2010 to 2020 are exploited to evaluate the performance of the proposed model. Case study results indicate that the proposed model for wind speed has a superior forecasting capability. Moreover, the proposed hybrid model is very competitive compared to the state-of-the-art single model and other hybrid models involved in this paper. ",
    "url": "https://arxiv.org/abs/2211.14434",
    "authors": [
      "Hailong Shu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2211.14437",
    "title": "Unsupervised User-Based Insider Threat Detection Using Bayesian Gaussian  Mixture Models",
    "abstract": "Insider threats are a growing concern for organizations due to the amount of damage that their members can inflict by combining their privileged access and domain knowledge. Nonetheless, the detection of such threats is challenging, precisely because of the ability of the authorized personnel to easily conduct malicious actions and because of the immense size and diversity of audit data produced by organizations in which the few malicious footprints are hidden. In this paper, we propose an unsupervised insider threat detection system based on audit data using Bayesian Gaussian Mixture Models. The proposed approach leverages a user-based model to optimize specific behaviors modelization and an automatic feature extraction system based on Word2Vec for ease of use in a real-life scenario. The solution distinguishes itself by not requiring data balancing nor to be trained only on normal instances, and by its little domain knowledge required to implement. Still, results indicate that the proposed method competes with state-of-the-art approaches, presenting a good recall of 88\\%, accuracy and true negative rate of 93%, and a false positive rate of 6.9%. For our experiments, we used the benchmark dataset CERT version 4.2. ",
    "url": "https://arxiv.org/abs/2211.14437",
    "authors": [
      "Simon Bertrand",
      "Nadia Tawbi",
      "Jos\u00e9e Desharnais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14438",
    "title": "BERN-NN: Tight Bound Propagation For Neural Networks Using Bernstein  Polynomial Interval Arithmetic",
    "abstract": "In this paper, we present BERN-NN as an efficient tool to perform bound propagation of Neural Networks (NNs). Bound propagation is a critical step in wide range of NN model checkers and reachability analysis tools. Given a bounded input set, bound propagation algorithms aim to compute tight bounds on the output of the NN. So far, linear and convex optimizations have been used to perform bound propagation. Since neural networks are highly non-convex, state-of-the-art bound propagation techniques suffer from introducing large errors. To circumvent such drawback, BERN-NN approximates the bounds of each neuron using a class of polynomials called Bernstein polynomials. Bernstein polynomials enjoy several interesting properties that allow BERN-NN to obtain tighter bounds compared to those relying on linear and convex approximations. BERN-NN is efficiently parallelized on graphic processing units (GPUs). Extensive numerical results show that bounds obtained by BERN-NN are orders of magnitude tighter than those obtained by state-of-the-art verifiers such as linear programming and linear interval arithmetic. Moreoveer, BERN-NN is both faster and produces tighter outputs compared to convex programming approaches like alpha-CROWN. ",
    "url": "https://arxiv.org/abs/2211.14438",
    "authors": [
      "Wael Fatnassi",
      "Haitham Khedr",
      "Valen Yamamoto",
      "Yasser Shoukry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.14440",
    "title": "Don't Watch Me: A Spatio-Temporal Trojan Attack on  Deep-Reinforcement-Learning-Augment Autonomous Driving",
    "abstract": "Deep reinforcement learning (DRL) is one of the most popular algorithms to realize an autonomous driving (AD) system. The key success factor of DRL is that it embraces the perception capability of deep neural networks which, however, have been proven vulnerable to Trojan attacks. Trojan attacks have been widely explored in supervised learning (SL) tasks (e.g., image classification), but rarely in sequential decision-making tasks solved by DRL. Hence, in this paper, we explore Trojan attacks on DRL for AD tasks. First, we propose a spatio-temporal DRL algorithm based on the recurrent neural network and attention mechanism to prove that capturing spatio-temporal traffic features is the key factor to the effectiveness and safety of a DRL-augment AD system. We then design a spatial-temporal Trojan attack on DRL policies, where the trigger is hidden in a sequence of spatial and temporal traffic features, rather than a single instant state used in existing Trojan on SL and DRL tasks. With our Trojan, the adversary acts as a surrounding normal vehicle and can trigger attacks via specific spatial-temporal driving behaviors, rather than physical or wireless access. Through extensive experiments, we show that while capturing spatio-temporal traffic features can improve the performance of DRL for different AD tasks, they suffer from Trojan attacks since our designed Trojan shows high stealthy (various spatio-temporal trigger patterns), effective (less than 3.1\\% performance variance rate and more than 98.5\\% attack success rate), and sustainable to existing advanced defenses. ",
    "url": "https://arxiv.org/abs/2211.14440",
    "authors": [
      "Yinbo Yu",
      "Jiajia Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14443",
    "title": "Siamese based Neural Network for Offline Writer Identification on word  level data",
    "abstract": "Handwriting recognition is one of the desirable attributes of document comprehension and analysis. It is concerned with the documents writing style and characteristics that distinguish the authors. The diversity of text images, notably in images with varying handwriting, makes the process of learning good features difficult in cases where little data is available. In this paper, we propose a novel scheme to identify the author of a document based on the input word image. Our method is text independent and does not impose any constraint on the size of the input image under examination. To begin with, we detect crucial components in handwriting and extract regions surrounding them using Scale Invariant Feature Transform (SIFT). These patches are designed to capture individual writing features (including allographs, characters, or combinations of characters) that are likely to be unique for an individual writer. These features are then passed through a deep Convolutional Neural Network (CNN) in which the weights are learned by applying the concept of Similarity learning using Siamese network. Siamese network enhances the discrimination power of CNN by mapping similarity between different pairs of input image. Features learned at different scales of the extracted SIFT key-points are encoded using Sparse PCA, each components of the Sparse PCA is assigned a saliency score signifying its level of significance in discriminating different writers effectively. Finally, the weighted Sparse PCA corresponding to each SIFT key-points is combined to arrive at a final classification score for each writer. The proposed algorithm was evaluated on two publicly available databases (namely IAM and CVL) and is able to achieve promising result, when compared with other deep learning based algorithm. ",
    "url": "https://arxiv.org/abs/2211.14443",
    "authors": [
      "Vineet Kumar",
      "Suresh Sundaram"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14445",
    "title": "LAPTNet: LiDAR-Aided Perspective Transform Network",
    "abstract": "Semantic grids are a useful representation of the environment around a robot. They can be used in autonomous vehicles to concisely represent the scene around the car, capturing vital information for downstream tasks like navigation or collision assessment. Information from different sensors can be used to generate these grids. Some methods rely only on RGB images, whereas others choose to incorporate information from other sensors, such as radar or LiDAR. In this paper, we present an architecture that fuses LiDAR and camera information to generate semantic grids. By using the 3D information from a LiDAR point cloud, the LiDAR-Aided Perspective Transform Network (LAPTNet) is able to associate features in the camera plane to the bird's eye view without having to predict any depth information about the scene. Compared to state-of-theart camera-only methods, LAPTNet achieves an improvement of up to 8.8 points (or 38.13%) over state-of-art competing approaches for the classes proposed in the NuScenes dataset validation split. ",
    "url": "https://arxiv.org/abs/2211.14445",
    "authors": [
      "Manuel Alejandro Diaz-Zapata",
      "\u00d6zg\u00fcr Erkent",
      "Christian Laugier",
      "Jilles Dibangoye",
      "David Sierra Gonz\u00e1lez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.14450",
    "title": "Text-Aware Dual Routing Network for Visual Question Answering",
    "abstract": "Visual question answering (VQA) is a challenging task to provide an accurate natural language answer given an image and a natural language question about the image. It involves multi-modal learning, i.e., computer vision (CV) and natural language processing (NLP), as well as flexible answer prediction for free-form and open-ended answers. Existing approaches often fail in cases that require reading and understanding text in images to answer questions. In practice, they cannot effectively handle the answer sequence derived from text tokens because the visual features are not text-oriented. To address the above issues, we propose a Text-Aware Dual Routing Network (TDR) which simultaneously handles the VQA cases with and without understanding text information in the input images. Specifically, we build a two-branch answer prediction network that contains a specific branch for each case and further develop a dual routing scheme to dynamically determine which branch should be chosen. In the branch that involves text understanding, we incorporate the Optical Character Recognition (OCR) features into the model to help understand the text in the images. Extensive experiments on the VQA v2.0 dataset demonstrate that our proposed TDR outperforms existing methods, especially on the ''number'' related VQA questions. ",
    "url": "https://arxiv.org/abs/2211.14450",
    "authors": [
      "Luoqian Jiang",
      "Yifan He",
      "Jian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14455",
    "title": "Information Geometry of Dynamics on Graphs and Hypergraphs",
    "abstract": "We introduce a new information-geometric structure of dynamics on discrete objects such as graphs and hypergraphs. The setup consists of two dually flat structures built on the vertex and edge spaces, respectively. The former is the conventional duality between density and potential, e.g., the probability density and its logarithmic form induced by a convex thermodynamic function. The latter is the duality between flux and force induced by a convex and symmetric dissipation function, which drives the dynamics on the manifold. These two are connected topologically by the homological algebraic relation induced by the underlying discrete objects. The generalized gradient flow in this doubly dual flat structure is an extension of the gradient flows on Riemannian manifolds, which include Markov jump processes and nonlinear chemical reaction dynamics as well as the natural gradient and mirror descent. The information-geometric projections on this doubly dual flat structure lead to the information-geometric generalizations of Helmholtz-Hodge-Kodaira decomposition and Otto structure in $L^{2}$ Wasserstein geometry. The structure can be extended to non-gradient nonequilibrium flow, from which we also obtain the induced dually flat structure on cycle spaces. This abstract but general framework can extend the applicability of information geometry to various problems of linear and nonlinear dynamics. ",
    "url": "https://arxiv.org/abs/2211.14455",
    "authors": [
      "Tetsuya J. Kobayashi",
      "Dimitri Loutchko",
      "Atsushi Kamimura",
      "Shuhei Horiguchi",
      "Yuki Sughiyama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Differential Geometry (math.DG)",
      "Statistics Theory (math.ST)",
      "Chemical Physics (physics.chem-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2211.14456",
    "title": "TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud  Classification",
    "abstract": "Rotation invariance is an important requirement for the analysis of 3D point clouds. In this paper, we present TetraSphere -- a learnable descriptor for rotation- and reflection-invariant 3D point cloud classification based on recently introduced steerable 3D spherical neurons and vector neurons, as well as the Gram matrix method. Taking 3D points as input, TetraSphere performs TetraTransform -- lifts the 3D input to 4D -- and extracts rotation-equivariant features, subsequently computing pair-wise O(3)-invariant inner products of these features. Remarkably, TetraSphere can be embedded into common point cloud processing models. We demonstrate its effectiveness and versatility by integrating it into DGCNN and VN-DGCNN, performing the classification of arbitrarily rotated ModelNet40 shapes. We show that using TetraSphere improves the performance and reduces the computational complexity by about 10% of the respective baseline methods. ",
    "url": "https://arxiv.org/abs/2211.14456",
    "authors": [
      "Pavlo Melnyk",
      "Andreas Robinson",
      "M\u00e5rten Wadenb\u00e4ck",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14467",
    "title": "Self-Supervised Surgical Instrument 3D Reconstruction from a Single  Camera Image",
    "abstract": "Surgical instrument tracking is an active research area that can provide surgeons feedback about the location of their tools relative to anatomy. Recent tracking methods are mainly divided into two parts: segmentation and object detection. However, both can only predict 2D information, which is limiting for application to real-world surgery. An accurate 3D surgical instrument model is a prerequisite for precise predictions of the pose and depth of the instrument. Recent single-view 3D reconstruction methods are only used in natural object reconstruction and do not achieve satisfying reconstruction accuracy without 3D attribute-level supervision. Further, those methods are not suitable for the surgical instruments because of their elongated shapes. In this paper, we firstly propose an end-to-end surgical instrument reconstruction system -- Self-supervised Surgical Instrument Reconstruction (SSIR). With SSIR, we propose a multi-cycle-consistency strategy to help capture the texture information from a slim instrument while only requiring a binary instrument label map. Experiments demonstrate that our approach improves the reconstruction quality of surgical instruments compared to other self-supervised methods and achieves promising results. ",
    "url": "https://arxiv.org/abs/2211.14467",
    "authors": [
      "Ange Lou",
      "Xing Yao",
      "Ziteng Liu",
      "Jintong Han",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.14477",
    "title": "PCRED: Zero-shot Relation Triplet Extraction with Potential Candidate  Relation Selection and Entity Boundary Detection",
    "abstract": "Zero-shot relation triplet extraction (ZeroRTE) aims to extract relation triplets from unstructured texts, while the relation sets at the training and testing stages are disjoint. Previous state-of-the-art method handles this challenging task by leveraging pretrained language models to generate data as additional training samples, which increases the training cost and severely constrains the model performance. We tackle this task from a new perspective and propose a novel method named PCRED for ZeroRTE with Potential Candidate Relation selection and Entity boundary Detection. The model adopts a relation-first paradigm, which firstly recognizes unseen relations through candidate relation selection. By this approach, the semantics of relations are naturally infused in the context. Entities are extracted based on the context and the semantics of relations subsequently. We evaluate our model on two ZeroRTE datasets. The experiment result shows that our method consistently outperforms previous works. Besides, our model does not rely on any additional data, which boasts the advantages of simplicity and effectiveness. Our code is available at https://anonymous.4open.science/r/PCRED. ",
    "url": "https://arxiv.org/abs/2211.14477",
    "authors": [
      "Yuquan Lan",
      "Dongxu Li",
      "Hui Zhao",
      "Gang Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14487",
    "title": "Receptive Field Refinement for Convolutional Neural Networks Reliably  Improves Predictive Performance",
    "abstract": "Minimal changes to neural architectures (e.g. changing a single hyperparameter in a key layer), can lead to significant gains in predictive performance in Convolutional Neural Networks (CNNs). In this work, we present a new approach to receptive field analysis that can yield these types of theoretical and empirical performance gains across twenty well-known CNN architectures examined in our experiments. By further developing and formalizing the analysis of receptive field expansion in convolutional neural networks, we can predict unproductive layers in an automated manner before ever training a model. This allows us to optimize the parameter-efficiency of a given architecture at low cost. Our method is computationally simple and can be done in an automated manner or even manually with minimal effort for most common architectures. We demonstrate the effectiveness of this approach by increasing parameter efficiency across past and current top-performing CNN-architectures. Specifically, our approach is able to improve ImageNet1K performance across a wide range of well-known, state-of-the-art (SOTA) model classes, including: VGG Nets, MobileNetV1, MobileNetV3, NASNet A (mobile), MnasNet, EfficientNet, and ConvNeXt - leading to a new SOTA result for each model class. ",
    "url": "https://arxiv.org/abs/2211.14487",
    "authors": [
      "Mats L. Richter",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14489",
    "title": "Mitigating Relational Bias on Knowledge Graphs",
    "abstract": "Knowledge graph data are prevalent in real-world applications, and knowledge graph neural networks (KGNNs) are essential techniques for knowledge graph representation learning. Although KGNN effectively models the structural information from knowledge graphs, these frameworks amplify the underlying data bias that leads to discrimination towards certain groups or individuals in resulting applications. Additionally, as existing debiasing approaches mainly focus on the entity-wise bias, eliminating the multi-hop relational bias that pervasively exists in knowledge graphs remains an open question. However, it is very challenging to eliminate relational bias due to the sparsity of the paths that generate the bias and the non-linear proximity structure of knowledge graphs. To tackle the challenges, we propose Fair-KGNN, a KGNN framework that simultaneously alleviates multi-hop bias and preserves the proximity information of entity-to-relation in knowledge graphs. The proposed framework is generalizable to mitigate the relational bias for all types of KGNN. We develop two instances of Fair-KGNN incorporating with two state-of-the-art KGNN models, RGCN and CompGCN, to mitigate gender-occupation and nationality-salary bias. The experiments carried out on three benchmark knowledge graph datasets demonstrate that the Fair-KGNN can effectively mitigate unfair situations during representation learning while preserving the predictive performance of KGNN models. ",
    "url": "https://arxiv.org/abs/2211.14489",
    "authors": [
      "Yu-Neng Chuang",
      "Kwei-Herng Lai",
      "Ruixiang Tang",
      "Mengnan Du",
      "Chia-Yuan Chang",
      "Na Zou",
      "Xia Hu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14490",
    "title": "Resampling community detection to maximize propagation in complex  network",
    "abstract": "Identifying important nodes in complex networks is essential in theoretical and applied fields. A small number of such nodes have deterministic power to decide information spreading, so it is of importance to find a set of nodes that maximize the propagation in networks. Based on baseline ranking methods, various improved methods were proposed, but there does not exist one enhanced method that covers all the base methods. In this paper, we propose a penalized method called RCD-Map, which is short for resampling community detection to maximize propagation, on five baseline ranking methods(Degree centrality, Closeness centrality, Betweennees centrality, K-shell and PageRank) with nodes' local community information. We perturbed the original graph by resampling to decrease the biases and randomness brought by community detection methods-both overlapping and non-overlapping methods. To assess the performance of our identifying method, SIR(susceptible-infected-recovered) model is applied to simulate the information propagation process. The result shows that methods with penalties perform better with a vaster propagation range in general. ",
    "url": "https://arxiv.org/abs/2211.14490",
    "authors": [
      "Xintong Zhai",
      "Zhonghao Xu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.14499",
    "title": "Deep neuroevolution for limited, heterogeneous data: proof-of-concept  application to Neuroblastoma brain metastasis using a small virtual pooled  image collection",
    "abstract": "Artificial intelligence (AI) in radiology has made great strides in recent years, but many hurdles remain. Overfitting and lack of generalizability represent important ongoing challenges hindering accurate and dependable clinical deployment. If AI algorithms can avoid overfitting and achieve true generalizability, they can go from the research realm to the forefront of clinical work. Recently, small data AI approaches such as deep neuroevolution (DNE) have avoided overfitting small training sets. We seek to address both overfitting and generalizability by applying DNE to a virtually pooled data set consisting of images from various institutions. Our use case is classifying neuroblastoma brain metastases on MRI. Neuroblastoma is well-suited for our goals because it is a rare cancer. Hence, studying this pediatric disease requires a small data approach. As a tertiary care center, the neuroblastoma images in our local Picture Archiving and Communication System (PACS) are largely from outside institutions. These multi-institutional images provide a heterogeneous data set that can simulate real world clinical deployment. As in prior DNE work, we used a small training set, consisting of 30 normal and 30 metastasis-containing post-contrast MRI brain scans, with 37% outside images. The testing set was enriched with 83% outside images. DNE converged to a testing set accuracy of 97%. Hence, the algorithm was able to predict image class with near-perfect accuracy on a testing set that simulates real-world data. Hence, the work described here represents a considerable contribution toward clinically feasible AI. ",
    "url": "https://arxiv.org/abs/2211.14499",
    "authors": [
      "Subhanik Purkayastha",
      "Hrithwik Shalu",
      "David Gutman",
      "Shakeel Modak",
      "Ellen Basu",
      "Brian Kushner",
      "Kim Kramer",
      "Sofia Haque",
      "Joseph Stember"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14503",
    "title": "Simple initialization and parametrization of sinusoidal networks via  their kernel bandwidth",
    "abstract": "Neural networks with sinusoidal activations have been proposed as an alternative to networks with traditional activation functions. Despite their promise, particularly for learning implicit models, their training behavior is not yet fully understood, leading to a number of empirical design choices that are not well justified. In this work, we first propose a simplified version of such sinusoidal neural networks, which allows both for easier practical implementation and simpler theoretical analysis. We then analyze the behavior of these networks from the neural tangent kernel perspective and demonstrate that their kernel approximates a low-pass filter with an adjustable bandwidth. Finally, we utilize these insights to inform the sinusoidal network initialization, optimizing their performance for each of a series of tasks, including learning implicit models and solving differential equations. ",
    "url": "https://arxiv.org/abs/2211.14503",
    "authors": [
      "Filipe de Avila Belbute-Peres",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14506",
    "title": "Progressive Disentangled Representation Learning for Fine-Grained  Controllable Talking Head Synthesis",
    "abstract": "We present a novel one-shot talking head synthesis method that achieves disentangled and fine-grained control over lip motion, eye gaze&blink, head pose, and emotional expression. We represent different motions via disentangled latent representations and leverage an image generator to synthesize talking heads from them. To effectively disentangle each motion factor, we propose a progressive disentangled representation learning strategy by separating the factors in a coarse-to-fine manner, where we first extract unified motion feature from the driving signal, and then isolate each fine-grained motion from the unified feature. We introduce motion-specific contrastive learning and regressing for non-emotional motions, and feature-level decorrelation and self-reconstruction for emotional expression, to fully utilize the inherent properties of each motion factor in unstructured video data to achieve disentanglement. Experiments show that our method provides high quality speech&lip-motion synchronization along with precise and disentangled control over multiple extra facial motions, which can hardly be achieved by previous methods. ",
    "url": "https://arxiv.org/abs/2211.14506",
    "authors": [
      "Duomin Wang",
      "Yu Deng",
      "Zixin Yin",
      "Heung-Yeung Shum",
      "Baoyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14512",
    "title": "Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection  in Semantic Segmentation",
    "abstract": "Semantic segmentation models classify pixels into a set of known (``in-distribution'') visual classes. When deployed in an open world, the reliability of these models depends on their ability not only to classify in-distribution pixels but also to detect out-of-distribution (OoD) pixels. Historically, the poor OoD detection performance of these models has motivated the design of methods based on model re-training using synthetic training images that include OoD visual objects. Although successful, these re-trained methods have two issues: 1) their in-distribution segmentation accuracy may drop during re-training, and 2) their OoD detection accuracy does not generalise well to new contexts (e.g., country surroundings) outside the training set (e.g., city surroundings). In this paper, we mitigate these issues with: (i) a new residual pattern learning (RPL) module that assists the segmentation model to detect OoD pixels without affecting the inlier segmentation performance; and (ii) a novel context-robust contrastive learning (CoroCL) that enforces RPL to robustly detect OoD pixels among various contexts. Our approach improves by around 10\\% FPR and 7\\% AuPRC the previous state-of-the-art in Fishyscapes, Segment-Me-If-You-Can, and RoadAnomaly datasets. Our code is available at: https://github.com/yyliu01/RPL. ",
    "url": "https://arxiv.org/abs/2211.14512",
    "authors": [
      "Yuyuan Liu",
      "Choubo Ding",
      "Yu Tian",
      "Guansong Pang",
      "Vasileios Belagiannis",
      "Ian Reid",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14515",
    "title": "Instance-level Heterogeneous Domain Adaptation for Limited-labeled  Sketch-to-Photo Retrieval",
    "abstract": "Although sketch-to-photo retrieval has a wide range of applications, it is costly to obtain paired and rich-labeled ground truth. Differently, photo retrieval data is easier to acquire. Therefore, previous works pre-train their models on rich-labeled photo retrieval data (i.e., source domain) and then fine-tune them on the limited-labeled sketch-to-photo retrieval data (i.e., target domain). However, without co-training source and target data, source domain knowledge might be forgotten during the fine-tuning process, while simply co-training them may cause negative transfer due to domain gaps. Moreover, identity label spaces of source data and target data are generally disjoint and therefore conventional category-level Domain Adaptation (DA) is not directly applicable. To address these issues, we propose an Instance-level Heterogeneous Domain Adaptation (IHDA) framework. We apply the fine-tuning strategy for identity label learning, aiming to transfer the instance-level knowledge in an inductive transfer manner. Meanwhile, labeled attributes from the source data are selected to form a shared label space for source and target domains. Guided by shared attributes, DA is utilized to bridge cross-dataset domain gaps and heterogeneous domain gaps, which transfers instance-level knowledge in a transductive transfer manner. Experiments show that our method has set a new state of the art on three sketch-to-photo image retrieval benchmarks without extra annotations, which opens the door to train more effective models on limited-labeled heterogeneous image retrieval tasks. Related codes are available at \\url{https://github.com/fandulu/IHDA. ",
    "url": "https://arxiv.org/abs/2211.14515",
    "authors": [
      "Fan Yang",
      "Yang Wu",
      "Zheng Wang",
      "Xiang Li",
      "Sakriani Sakti",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14521",
    "title": "Robust One-shot Segmentation of Brain Tissues via Image-aligned Style  Transformation",
    "abstract": "One-shot segmentation of brain tissues is typically a dual-model iterative learning: a registration model (reg-model) warps a carefully-labeled atlas onto unlabeled images to initialize their pseudo masks for training a segmentation model (seg-model); the seg-model revises the pseudo masks to enhance the reg-model for a better warping in the next iteration. However, there is a key weakness in such dual-model iteration that the spatial misalignment inevitably caused by the reg-model could misguide the seg-model, which makes it converge on an inferior segmentation performance eventually. In this paper, we propose a novel image-aligned style transformation to reinforce the dual-model iterative learning for robust one-shot segmentation of brain tissues. Specifically, we first utilize the reg-model to warp the atlas onto an unlabeled image, and then employ the Fourier-based amplitude exchange with perturbation to transplant the style of the unlabeled image into the aligned atlas. This allows the subsequent seg-model to learn on the aligned and style-transferred copies of the atlas instead of unlabeled images, which naturally guarantees the correct spatial correspondence of an image-mask training pair, without sacrificing the diversity of intensity patterns carried by the unlabeled images. Furthermore, we introduce a feature-aware content consistency in addition to the image-level similarity to constrain the reg-model for a promising initialization, which avoids the collapse of image-aligned style transformation in the first iteration. Experimental results on two public datasets demonstrate 1) a competitive segmentation performance of our method compared to the fully-supervised method, and 2) a superior performance over other state-of-the-arts with an increase of average Dice by up to 4.67%. The source code is available. ",
    "url": "https://arxiv.org/abs/2211.14521",
    "authors": [
      "Jinxin Lv",
      "Xiaoyu Zeng",
      "Sheng Wang",
      "Ran Duan",
      "Zhiwei Wang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14522",
    "title": "Visual Fault Detection of Multi-scale Key Components in Freight Trains",
    "abstract": "Fault detection for key components in the braking system of freight trains is critical for ensuring railway transportation safety. Despite the frequently employed methods based on deep learning, these fault detectors are highly reliant on hardware resources and are complex to implement. In addition, no train fault detectors consider the drop in accuracy induced by scale variation of fault parts. This paper proposes a lightweight anchor-free framework to solve the above problems. Specifically, to reduce the amount of computation and model size, we introduce a lightweight backbone and adopt an anchor-free method for localization and regression. To improve detection accuracy for multi-scale parts, we design a feature pyramid network to generate rectangular layers of different sizes to map parts with similar aspect ratios. Experiments on four fault datasets show that our framework achieves 98.44% accuracy while the model size is only 22.5 MB, outperforming state-of-the-art detectors. ",
    "url": "https://arxiv.org/abs/2211.14522",
    "authors": [
      "Yang Zhang",
      "Yang Zhou",
      "Huilin Pan",
      "Bo Wu",
      "Guodong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.14523",
    "title": "VR-GNN: Variational Relation Vector Graph Neural Network for Modeling  both Homophily and Heterophily",
    "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success in diverse real-world applications. Traditional GNNs are designed based on homophily, which leads to poor performance under heterophily scenarios. Current solutions deal with heterophily mainly by mixing high-order neighbors or passing signed messages. However, mixing high-order neighbors destroys the original graph structure and passing signed messages utilizes an inflexible message-passing mechanism, which is prone to producing unsatisfactory effects. To overcome the above problems, we propose a novel GNN model based on relation vector translation named Variational Relation Vector Graph Neural Network (VR-GNN). VR-GNN models relation generation and graph aggregation into an end-to-end model based on Variational Auto-Encoder. The encoder utilizes the structure, feature and label to generate a proper relation vector. The decoder achieves superior node representation by incorporating the relation translation into the message-passing framework. VR-GNN can fully capture the homophily and heterophily between nodes due to the great flexibility of relation translation in modeling neighbor relationships. We conduct extensive experiments on eight real-world datasets with different homophily-heterophily properties to verify the effectiveness of our model. The experimental results show that VR-GNN gains consistent and significant improvements against state-of-the-art GNN methods under heterophily, and competitive performance under homophily. ",
    "url": "https://arxiv.org/abs/2211.14523",
    "authors": [
      "Fengzhao Shi",
      "Ren Li",
      "Yanan Cao",
      "Yanmin Shang",
      "Lanxue Zhang",
      "Chuan Zhou",
      "Jia Wu",
      "Shirui Pan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.14545",
    "title": "Ensemble Multi-Quantile: Adaptively Flexible Distribution Prediction for  Uncertainty Quantification",
    "abstract": "We propose a novel, succinct, and effective approach to quantify uncertainty in machine learning. It incorporates adaptively flexible distribution prediction for $\\mathbb{P}(\\mathbf{y}|\\mathbf{X}=x)$ in regression tasks. For predicting this conditional distribution, its quantiles of probability levels spreading the interval $(0,1)$ are boosted by additive models which are designed by us with intuitions and interpretability. We seek an adaptive balance between the structural integrity and the flexibility for $\\mathbb{P}(\\mathbf{y}|\\mathbf{X}=x)$, while Gaussian assumption results in a lack of flexibility for real data and highly flexible approaches (e.g., estimating the quantiles separately without a distribution structure) inevitably have drawbacks and may not lead to good generalization. This ensemble multi-quantiles approach called EMQ proposed by us is totally data-driven, and can gradually depart from Gaussian and discover the optimal conditional distribution in the boosting. On extensive regression tasks from UCI datasets, we show that EMQ achieves state-of-the-art performance comparing to many recent uncertainty quantification methods including Gaussian assumption-based, Bayesian methods, quantile regression-based, and traditional tree models, under the metrics of calibration, sharpness, and tail-side calibration. Visualization results show what we actually learn from the real data and how, illustrating the necessity and the merits of such an ensemble model. ",
    "url": "https://arxiv.org/abs/2211.14545",
    "authors": [
      "Xing Yan",
      "Yonghua Su",
      "Wenxuan Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14547",
    "title": "Profile-Guided Parallel Task Extraction and Execution for Domain  Specific Heterogeneous SoC",
    "abstract": "In this study, we introduce a methodology for automatically transforming user applications in the radar and communication domain written in C/C++ based on dynamic profiling to a parallel representation targeted for a heterogeneous SoC. We present our approach for instrumenting the user application binary during the compilation process with barrier synchronization primitives that enable runtime system schedule and execute independent tasks concurrently over the available compute resources. We demonstrate the capabilities of our integrated compile time and runtime flow through task-level parallel and functionally correct execution of real-life applications. We perform validation of our integrated system by executing four distinct applications each carrying various degrees of task level parallelism over the Xeon-based multi-core homogeneous processor. We use the proposed compilation and code transformation methodology to re-target each application for execution on a heterogeneous SoC composed of three ARM cores and one FFT accelerator that is emulated on the Xilinx Zynq UltraScale+ platform. We demonstrate our runtime's ability to process application binary, dispatch independent tasks over the available compute resources of the emulated SoC on the Zynq FPGA based on three different scheduling heuristics. Finally we demonstrate execution of each application individually with task level parallelism on the Zynq FPGA and execution of workload scenarios composed of multiple instances of the same application as well as mixture of two distinct applications to demonstrate ability to realize both application and task level parallel execution. Our integrated approach offers a path forward for application developers to take full advantage of the target SoC without requiring users to become hardware and parallel programming experts. ",
    "url": "https://arxiv.org/abs/2211.14547",
    "authors": [
      "Liangliang Chang",
      "Joshua Mack",
      "Benjamin Willis",
      "Xing Chen",
      "John Brunhaver",
      "Ali Akoglu",
      "Chaitali Chakrabarti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2211.14568",
    "title": "BeGin: Extensive Benchmark Scenarios and An Easy-to-use Framework for  Graph Continual Learning",
    "abstract": "Continual Learning (CL) is the process of learning ceaselessly a sequence of tasks. Most existing CL methods deal with independent data (e.g., images and text) for which many benchmark frameworks and results under standard experimental settings are available. CL methods for graph data, however, are surprisingly underexplored because of (a) the lack of standard experimental settings, especially regarding how to deal with the dependency between instances, (b) the lack of benchmark datasets and scenarios, and (c) high complexity in implementation and evaluation due to the dependency. In this paper, regarding (a), we define four standard incremental settings (task-, class-, domain-, and time-incremental settings) for graph data, which are naturally applied to many node-, link-, and graph-level problems. Regarding (b), we provide 23 benchmark scenarios based on 14 real-world graphs. Regarding (c), we develop BeGin, an easy and fool-proof framework for graph CL. BeGin is easily extended since it is modularized with reusable modules for data processing, algorithm design, and evaluation. Especially, the evaluation module is completely separated from user code to eliminate potential mistakes in evaluation. Using all above, we report extensive benchmark results of seven graph CL methods. Compared to the latest benchmark for graph CL, using BeGin, we cover three times more combinations of incremental settings and levels of problems. ",
    "url": "https://arxiv.org/abs/2211.14568",
    "authors": [
      "Jihoon Ko",
      "Shinhwan Kang",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14575",
    "title": "Randomized Conditional Flow Matching for Video Prediction",
    "abstract": "We introduce a novel generative model for video prediction based on latent flow matching, an efficient alternative to diffusion-based models. In contrast to prior work that either incurs a high training cost by modeling the past through a memory state, as in recurrent neural networks, or limits the computational load by conditioning only on a predefined window of past frames, we efficiently and effectively take the past into account by conditioning at inference time only on a small random set of past frames at each integration step of the learned flow. Moreover, to enable the generation of high-resolution videos and speed up the training, we work in the latent space of a pretrained VQGAN. Furthermore, we propose to approximate the initial condition of the flow ODE with the previous noisy frame. This allows to reduce the number of integration steps and hence, speed up the sampling at inference time. We call our model Random frame conditional flow Integration for VidEo pRediction, or, in short, RIVER. We show that RIVER achieves superior or on par performance compared to prior work on common video prediction benchmarks. ",
    "url": "https://arxiv.org/abs/2211.14575",
    "authors": [
      "Aram Davtyan",
      "Sepehr Sameni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14577",
    "title": "Distribution estimation and change-point detection for time series via  DNN-based GANs",
    "abstract": "The generative adversarial networks (GANs) have recently been applied to estimating the distribution of independent and identically distributed data, and got excellent performances. In this paper, we use the blocking technique to demonstrate the effectiveness of GANs for estimating the distribution of stationary time series. Theoretically, we obtain a non-asymptotic error bound for the Deep Neural Network (DNN)-based GANs estimator for the stationary distribution of the time series. Based on our theoretical analysis, we put forward an algorithm for detecting the change-point in time series. We simulate in our first experiment a stationary time series by the multivariate autoregressive model to test our GAN estimator, while the second experiment is to use our proposed algorithm to detect the change-point in a time series sequence. Both perform very well. The third experiment is to use our GAN estimator to learn the distribution of a real financial time series data, which is not stationary, we can see from the experiment results that our estimator cannot match the distribution of the time series very well but give the right changing tendency. ",
    "url": "https://arxiv.org/abs/2211.14577",
    "authors": [
      "Jianya Lu",
      "Yingjun Mo",
      "Zhijie Xiao",
      "Lihu Xu",
      "Qiuran Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2211.14582",
    "title": "Demystifying Bitcoin Address Behavior via Graph Neural Networks",
    "abstract": "Bitcoin is one of the decentralized cryptocurrencies powered by a peer-to-peer blockchain network. Parties who trade in the bitcoin network are not required to disclose any personal information. Such property of anonymity, however, precipitates potential malicious transactions to a certain extent. Indeed, various illegal activities such as money laundering, dark network trading, and gambling in the bitcoin network are nothing new now. While a proliferation of work has been developed to identify malicious bitcoin transactions, the behavior analysis and classification of bitcoin addresses are largely overlooked by existing tools. In this paper, we propose BAClassifier, a tool that can automatically classify bitcoin addresses based on their behaviors. Technically, we come up with the following three key designs. First, we consider casting the transactions of the bitcoin address into an address graph structure, of which we introduce a graph node compression technique and a graph structure augmentation method to characterize a unified graph representation. Furthermore, we leverage a graph feature network to learn the graph representations of each address and generate the graph embeddings. Finally, we aggregate all graph embeddings of an address into the address-level representation, and engage in a classification model to give the address behavior classification. As a side contribution, we construct and release a large-scale annotated dataset that consists of over 2 million real-world bitcoin addresses and concerns 4 types of address behaviors. Experimental results demonstrate that our proposed framework outperforms state-of-the-art bitcoin address classifiers and existing classification models, where the precision and F1-score are 96% and 95%, respectively. Our implementation and dataset are released, hoping to inspire others. ",
    "url": "https://arxiv.org/abs/2211.14582",
    "authors": [
      "Zhengjie Huang",
      "Yunyang Huang",
      "Peng Qian",
      "Jianhai Chen",
      "Qinming He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14591",
    "title": "A Survey of Text Representation Methods and Their Genealogy",
    "abstract": "In recent years, with the advent of highly scalable artificial-neural-network-based text representation methods the field of natural language processing has seen unprecedented growth and sophistication. It has become possible to distill complex linguistic information of text into multidimensional dense numeric vectors with the use of the distributional hypothesis. As a consequence, text representation methods have been evolving at such a quick pace that the research community is struggling to retain knowledge of the methods and their interrelations. We contribute threefold to this lack of compilation, composition, and systematization by providing a survey of current approaches, by arranging them in a genealogy, and by conceptualizing a taxonomy of text representation methods to examine and explain the state-of-the-art. Our research is a valuable guide and reference for artificial intelligence researchers and practitioners interested in natural language processing applications such as recommender systems, chatbots, and sentiment analysis. ",
    "url": "https://arxiv.org/abs/2211.14591",
    "authors": [
      "Philipp Siebers",
      "Christian Janiesch",
      "Patrick Zschech"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14595",
    "title": "Tube-based Distributionally Robust Model Predictive Control for  Nonlinear Process Systems via Linearization",
    "abstract": "Model predictive control (MPC) is an effective approach to control multivariable dynamic systems with constraints. Most real dynamic models are however affected by plant-model mismatch and process uncertainties, which can lead to closed-loop performance deterioration and constraint violations. Methods such as stochastic MPC (SMPC) have been proposed to alleviate these problems; however, the resulting closed-loop state trajectory might still significantly violate the prescribed constraints if the real system deviates from the assumed disturbance distributions made during the controller design. In this work we propose a novel data-driven distributionally robust MPC scheme for nonlinear systems. Unlike SMPC, which requires the exact knowledge of the disturbance distribution, our scheme decides the control action with respect to the worst distribution from a distribution ambiguity set. This ambiguity set is defined as a Wasserstein ball centered at the empirical distribution. Due to the potential model errors that cause off-sets, the scheme is also extended by leveraging an offset-free method. The favorable results of this control scheme are demonstrated and empirically verified with a nonlinear mass spring system and a nonlinear CSTR case study. ",
    "url": "https://arxiv.org/abs/2211.14595",
    "authors": [
      "Zhengang Zhong",
      "Ehecatl Antonio del Rio-Chanona",
      "Panagiotis Petsagkourakis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.14603",
    "title": "Analysis of Molecule Harvesting by Heterogeneous Receptors on MC  Transmitters",
    "abstract": "This paper designs a molecule harvesting transmitter (TX) model, where the surface of a spherical TX is covered by heterogeneous receptors with different sizes and arbitrary locations. If molecules hit any receptor, they are absorbed by the TX immediately. Within the TX, molecules are stored in vesicles that are continuously generated and released by the TX via the membrane fusion process. Considering a transparent receiver (RX) and molecular degradation during the propagation from the TX to the RX, we derive the molecule release rate and the fraction of molecules absorbed by the TX as well as the received signal at the RX. Notably, this analytical result is applicable for different numbers, sizes, and locations of receptors, and its accuracy is verified via particle-based simulations. Numerical results show that different vesicle generation rates result in the same number of molecules absorbed by the TX, but different peak received signals at the RX. ",
    "url": "https://arxiv.org/abs/2211.14603",
    "authors": [
      "Xinyu Huang",
      "Yu Huang",
      "Miaowen Wen",
      "Nan Yang",
      "Robert Schober"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2211.14604",
    "title": "Reduced Representation of Deformation Fields for Effective Non-rigid  Shape Matching",
    "abstract": "In this work we present a novel approach for computing correspondences between non-rigid objects, by exploiting a reduced representation of deformation fields. Different from existing works that represent deformation fields by training a general-purpose neural network, we advocate for an approximation based on mesh-free methods. By letting the network learn deformation parameters at a sparse set of positions in space (nodes), we reconstruct the continuous deformation field in a closed-form with guaranteed smoothness. With this reduction in degrees of freedom, we show significant improvement in terms of data-efficiency thus enabling limited supervision. Furthermore, our approximation provides direct access to first-order derivatives of deformation fields, which facilitates enforcing desirable regularization effectively. Our resulting model has high expressive power and is able to capture complex deformations. We illustrate its effectiveness through state-of-the-art results across multiple deformable shape matching benchmarks. Our code and data are publicly available at: https://github.com/Sentient07/DeformationBasis. ",
    "url": "https://arxiv.org/abs/2211.14604",
    "authors": [
      "Ramana Sundararaman",
      "Riccardo Marin",
      "Emanuele Rodola",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.14607",
    "title": "Sketch2FullStack: Generating Skeleton Code of Full Stack Website and  Application from Sketch using Deep Learning and Computer Vision",
    "abstract": "For a full-stack web or app development, it requires a software firm or more specifically a team of experienced developers to contribute a large portion of their time and resources to design the website and then convert it to code. As a result, the efficiency of the development team is significantly reduced when it comes to converting UI wireframes and database schemas into an actual working system. It would save valuable resources and fasten the overall workflow if the clients or developers can automate this process of converting the pre-made full-stack website design to get a partially working if not fully working code. In this paper, we present a novel approach of generating the skeleton code from sketched images using Deep Learning and Computer Vision approaches. The dataset for training are first-hand sketched images of low fidelity wireframes, database schemas and class diagrams. The approach consists of three parts. First, the front-end or UI elements detection and extraction from custom-made UI wireframes. Second, individual database table creation from schema designs and lastly, creating a class file from class diagrams. ",
    "url": "https://arxiv.org/abs/2211.14607",
    "authors": [
      "Somoy Subandhu Barua",
      "Imam Mohammad Zulkarnain",
      "Abhishek Roy",
      "Md. Golam Rabiul Alam",
      "Md Zia Uddin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.14619",
    "title": "A Quantum Approach Towards the Adaptive Prediction of Cloud Workloads",
    "abstract": "This work presents a novel Evolutionary Quantum Neural Network (EQNN) based workload prediction model for Cloud datacenter. It exploits the computational efficiency of quantum computing by encoding workload information into qubits and propagating this information through the network to estimate the workload or resource demands with enhanced accuracy proactively. The rotation and reverse rotation effects of the Controlled-NOT (C-NOT) gate serve activation function at the hidden and output layers to adjust the qubit weights. In addition, a Self Balanced Adaptive Differential Evolution (SB-ADE) algorithm is developed to optimize qubit network weights. The accuracy of the EQNN prediction model is extensively evaluated and compared with seven state-of-the-art methods using eight real world benchmark datasets of three different categories. Experimental results reveal that the use of the quantum approach to evolutionary neural network substantially improves the prediction accuracy up to 91.6% over the existing approaches. ",
    "url": "https://arxiv.org/abs/2211.14619",
    "authors": [
      "Ashutosh Kumar Singh",
      "Deepika Saxena",
      "Jitendra Kumar",
      "Vrinda Gupta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.14632",
    "title": "Why Neural Networks Work",
    "abstract": "We argue that many properties of fully-connected feedforward neural networks (FCNNs), also called multi-layer perceptrons (MLPs), are explainable from the analysis of a single pair of operations, namely a random projection into a higher-dimensional space than the input, followed by a sparsification operation. For convenience, we call this pair of successive operations expand-and-sparsify following the terminology of Dasgupta. We show how expand-and-sparsify can explain the observed phenomena that have been discussed in the literature, such as the so-called Lottery Ticket Hypothesis, the surprisingly good performance of randomly-initialized untrained neural networks, the efficacy of Dropout in training and most importantly, the mysterious generalization ability of overparameterized models, first highlighted by Zhang et al. and subsequently identified even in non-neural network models by Belkin et al. ",
    "url": "https://arxiv.org/abs/2211.14632",
    "authors": [
      "Sayandev Mukherjee",
      "Bernardo A. Huberman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14633",
    "title": "A Contextual Master-Slave Framework on Urban Region Graph for Urban  Village Detection",
    "abstract": "Urban villages (UVs) refer to the underdeveloped informal settlement falling behind the rapid urbanization in a city. Since there are high levels of social inequality and social risks in these UVs, it is critical for city managers to discover all UVs for making appropriate renovation policies. Existing approaches to detecting UVs are labor-intensive or have not fully addressed the unique challenges in UV detection such as the scarcity of labeled UVs and the diverse urban patterns in different regions. To this end, we first build an urban region graph (URG) to model the urban area in a hierarchically structured way. Then, we design a novel contextual master-slave framework to effectively detect the urban village from the URG. The core idea of such a framework is to firstly pre-train a basis (or master) model over the URG, and then to adaptively derive specific (or slave) models from the basis model for different regions. The proposed framework can learn to balance the generality and specificity for UV detection in an urban area. Finally, we conduct extensive experiments in three cities to demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2211.14633",
    "authors": [
      "Congxi Xiao",
      "Jingbo Zhou",
      "Jizhou Huang",
      "Hengshu Zhu",
      "Tong Xu",
      "Dejing Dou",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.14642",
    "title": "SCAPHY: Detecting Modern ICS Attacks by Correlating Behaviors in SCADA  and PHYsical",
    "abstract": "Modern Industrial Control Systems (ICS) attacks evade existing tools by using knowledge of ICS processes to blend their activities with benign Supervisory Control and Data Acquisition (SCADA) operation, causing physical world damages. We present SCAPHY to detect ICS attacks in SCADA by leveraging the unique execution phases of SCADA to identify the limited set of legitimate behaviors to control the physical world in different phases, which differentiates from attackers activities. For example, it is typical for SCADA to setup ICS device objects during initialization, but anomalous during processcontrol. To extract unique behaviors of SCADA execution phases, SCAPHY first leverages open ICS conventions to generate a novel physical process dependency and impact graph (PDIG) to identify disruptive physical states. SCAPHY then uses PDIG to inform a physical process-aware dynamic analysis, whereby code paths of SCADA process-control execution is induced to reveal API call behaviors unique to legitimate process-control phases. Using this established behavior, SCAPHY selectively monitors attackers physical world-targeted activities that violates legitimate processcontrol behaviors. We evaluated SCAPHY at a U.S. national lab ICS testbed environment. Using diverse ICS deployment scenarios and attacks across 4 ICS industries, SCAPHY achieved 95% accuracy & 3.5% false positives (FP), compared to 47.5% accuracy and 25% FP of existing work. We analyze SCAPHYs resilience to futuristic attacks where attacker knows our approach. ",
    "url": "https://arxiv.org/abs/2211.14642",
    "authors": [
      "Moses Ike",
      "Kandy Phan",
      "Keaton Sadoski",
      "Romuald Valme",
      "Wenke Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.14646",
    "title": "Towards Better Input Masking for Convolutional Neural Networks",
    "abstract": "The ability to remove features from the input of machine learning models is very important to understand and interpret model predictions. However, this is non-trivial for vision models since masking out parts of the input image and replacing them with a baseline color like black or grey typically causes large distribution shifts. Masking may even make the model focus on the masking patterns for its prediction rather than the unmasked portions of the image. In recent work, it has been shown that vision transformers are less affected by such issues as one can simply drop the tokens corresponding to the masked image portions. They are thus more easily interpretable using techniques like LIME which rely on input perturbation. Using the same intuition, we devise a masking technique for CNNs called layer masking, which simulates running the CNN on only the unmasked input. We find that our method is (i) much less disruptive to the model's output and its intermediate activations, and (ii) much better than commonly used masking techniques for input perturbation based interpretability techniques like LIME. Thus, layer masking is able to close the interpretability gap between CNNs and transformers, and even make CNNs more interpretable in many cases. ",
    "url": "https://arxiv.org/abs/2211.14646",
    "authors": [
      "Sriram Balasubramanian",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14654",
    "title": "Unsupervised Wildfire Change Detection based on Contrastive Learning",
    "abstract": "The accurate characterization of the severity of the wildfire event strongly contributes to the characterization of the fuel conditions in fire-prone areas, and provides valuable information for disaster response. The aim of this study is to develop an autonomous system built on top of high-resolution multispectral satellite imagery, with an advanced deep learning method for detecting burned area change. This work proposes an initial exploration of using an unsupervised model for feature extraction in wildfire scenarios. It is based on the contrastive learning technique SimCLR, which is trained to minimize the cosine distance between augmentations of images. The distance between encoded images can also be used for change detection. We propose changes to this method that allows it to be used for unsupervised burned area detection and following downstream tasks. We show that our proposed method outperforms the tested baseline approaches. ",
    "url": "https://arxiv.org/abs/2211.14654",
    "authors": [
      "Beichen Zhang",
      "Huiqi Wang",
      "Amani Alabri",
      "Karol Bot",
      "Cole McCall",
      "Dale Hamilton",
      "V\u00edt R\u016f\u017ei\u010dka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14656",
    "title": "Robust fast direct integral equation solver for three-dimensional  quasi-periodic scattering problems with a large number of layers",
    "abstract": "A boundary integral equation method for the 3-D Helmholtz equation in multilayered media with many quasi-periodic layers is presented. Compared with conventional quasi-periodic Green's function method, the new method is robust at all scattering parameters. A periodizing scheme is used to decompose the solution into near- and far-field contributions. The near-field contribution uses the free-space Green's function in an integral equation on the interface in the unit cell and its immediate eight neighbors; the far-field contribution uses proxy point sources that enclose the unit cell. A specialized high-order quadrature is developed to discretize the underlying surface integral operators to keep the number of unknowns per layer small. We achieve overall linear computational complexity in the number of layers by reducing the linear system into block tridiagonal form and then solving the system directly via block LU decomposition. The new solver is capable of handling a 100-interface structure with 961.3k unknowns to $10^{-5}$ accuracy in less than 2 hours on a desktop workstation. ",
    "url": "https://arxiv.org/abs/2211.14656",
    "authors": [
      "Bowei Wu",
      "Min Hyung Cho"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.14662",
    "title": "3D Reconstruction of Protein Complex Structures Using Synthesized  Multi-View AFM Images",
    "abstract": "Recent developments in deep learning-based methods demonstrated its potential to predict the 3D protein structures using inputs such as protein sequences, Cryo-Electron microscopy (Cryo-EM) images of proteins, etc. However, these methods struggle to predict the protein complexes (PC), structures with more than one protein. In this work, we explore the atomic force microscope (AFM) assisted deep learning-based methods to predict the 3D structure of PCs. The images produced by AFM capture the protein structure in different and random orientations. These multi-view images can help train the neural network to predict the 3D structure of protein complexes. However, obtaining the dataset of actual AFM images is time-consuming and not a pragmatic task. We propose a virtual AFM imaging pipeline that takes a 'PDB' protein file and generates multi-view 2D virtual AFM images using volume rendering techniques. With this, we created a dataset of around 8K proteins. We train a neural network for 3D reconstruction called Pix2Vox++ using the synthesized multi-view 2D AFM images dataset. We compare the predicted structure obtained using a different number of views and get the intersection over union (IoU) value of 0.92 on the training dataset and 0.52 on the validation dataset. We believe this approach will lead to better prediction of the structure of protein complexes. ",
    "url": "https://arxiv.org/abs/2211.14662",
    "authors": [
      "Jaydeep Rade",
      "Soumik Sarkar",
      "Anwesha Sarkar",
      "Adarsh Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.14669",
    "title": "Game Theoretic Mixed Experts for Combinational Adversarial Machine  Learning",
    "abstract": "Recent advances in adversarial machine learning have shown that defenses considered to be robust are actually susceptible to adversarial attacks which are specifically tailored to target their weaknesses. These defenses include Barrage of Random Transforms (BaRT), Friendly Adversarial Training (FAT), Trash is Treasure (TiT) and ensemble models made up of Vision Transformers (ViTs), Big Transfer models and Spiking Neural Networks (SNNs). A natural question arises: how can one best leverage a combination of adversarial defenses to thwart such attacks? In this paper, we provide a game-theoretic framework for ensemble adversarial attacks and defenses which answers this question. In addition to our framework we produce the first adversarial defense transferability study to further motivate a need for combinational defenses utilizing a diverse set of defense architectures. Our framework is called Game theoretic Mixed Experts (GaME) and is designed to find the Mixed-Nash strategy for a defender when facing an attacker employing compositional adversarial attacks. We show that this framework creates an ensemble of defenses with greater robustness than multiple state-of-the-art, single-model defenses in addition to combinational defenses with uniform probability distributions. Overall, our framework and analyses advance the field of adversarial machine learning by yielding new insights into compositional attack and defense formulations. ",
    "url": "https://arxiv.org/abs/2211.14669",
    "authors": [
      "Ethan Rathbun",
      "Kaleel Mahmood",
      "Sohaib Ahmad",
      "Caiwen Ding",
      "Marten van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2211.14672",
    "title": "Multi-Transmitter Coded Caching with Secure Delivery over Linear  Networks -- Extended Version",
    "abstract": "In this paper, we consider multiple cache-enabled end-users connected to multiple transmitters through a linear network. We also prevent a totally passive eavesdropper, who sniffs the packets in the delivery phase, from obtaining any information about the original files in cache-aided networks. Three different secure centralized multi-transmitter coded caching scenarios namely, secure multi-transmitter coded caching, secure multi-transmitter coded caching with reduced subpacketization, and secure multi-transmitter coded caching with reduced feedback, are considered and closed-form coding delay and secret shared key storage expressions are provided. As our security guarantee, we show that the delivery phase does not reveal any information to the eavesdropper using the mutual information metric. Moreover, we investigate the secure decentralized multi-transmitter coded caching scenario, in which there is no cooperation between the clients and transmitters during the cache content placement phase and study its performance compared to the centralized scheme. We analyze the system's performance in terms of Coding Delay and guarantee the security of our presented schemes using the Mutual Information metric. Numerical evaluations verify that security incurs a negligible cost in terms of memory usage when the number of files and users are scaled up, in both centralized and decentralized scenarios. Also, we numerically show that by increasing the number of files and users, the secure coding delay of centralized and decentralized schemes became asymptotically equal. ",
    "url": "https://arxiv.org/abs/2211.14672",
    "authors": [
      "Mohammad Javad Sojdeh",
      "Mehdi Letafati",
      "Seyed Pooya Shariatpanahi",
      "Babak Hossein Khalaj"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.14700",
    "title": "A novel multimodal dynamic fusion network for disfluency detection in  spoken utterances",
    "abstract": "Disfluency, though originating from human spoken utterances, is primarily studied as a uni-modal text-based Natural Language Processing (NLP) task. Based on early-fusion and self-attention-based multimodal interaction between text and acoustic modalities, in this paper, we propose a novel multimodal architecture for disfluency detection from individual utterances. Our architecture leverages a multimodal dynamic fusion network that adds minimal parameters over an existing text encoder commonly used in prior art to leverage the prosodic and acoustic cues hidden in speech. Through experiments, we show that our proposed model achieves state-of-the-art results on the widely used English Switchboard for disfluency detection and outperforms prior unimodal and multimodal systems in literature by a significant margin. In addition, we make a thorough qualitative analysis and show that, unlike text-only systems, which suffer from spurious correlations in the data, our system overcomes this problem through additional cues from speech signals. We make all our codes publicly available on GitHub. ",
    "url": "https://arxiv.org/abs/2211.14700",
    "authors": [
      "Sreyan Ghosh",
      "Utkarsh Tyagi",
      "Sonal Kumar",
      "Manan Suri",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.14706",
    "title": "Neural Network Verification as Piecewise Linear Optimization:  Formulations for the Composition of Staircase Functions",
    "abstract": "We present a technique for neural network verification using mixed-integer programming (MIP) formulations. We derive a \\emph{strong formulation} for each neuron in a network using piecewise linear activation functions. Additionally, as in general, these formulations may require an exponential number of inequalities, we also derive a separation procedure that runs in super-linear time in the input dimension. We first introduce and develop our technique on the class of \\emph{staircase} functions, which generalizes the ReLU, binarized, and quantized activation functions. We then use results for staircase activation functions to obtain a separation method for general piecewise linear activation functions. Empirically, using our strong formulation and separation technique, we can reduce the computational time in exact verification settings based on MIP and improve the false negative rate for inexact verifiers relying on the relaxation of the MIP formulation. ",
    "url": "https://arxiv.org/abs/2211.14706",
    "authors": [
      "Tu Anh-Nguyen",
      "Joey Huchette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.14710",
    "title": "3D Point Positional Encoding for Multi-Camera 3D Object Detection  Transformers",
    "abstract": "Multi-camera 3D object detection, a critical component for vision-only driving systems, has achieved impressive progress. Notably, transformer-based methods with 2D features augmented by 3D positional encodings (PE) have enjoyed great success. However, the mechanism and options of 3D PE have not been thoroughly explored. In this paper, we first explore, analyze and compare various 3D positional encodings. In particular, we devise 3D point PE and show its superior performance since more precise positioning may lead to superior 3D detection. In practice, we utilize monocular depth estimation to obtain the 3D point positions for multi-camera 3D object detection. The PE with estimated 3D point locations can bring significant improvements compared to the commonly used camera-ray PE. Among DETR-based strategies, our method achieves state-of-the-art 45.6 mAP and 55.1 NDS on the competitive nuScenes valuation set. It's the first time that the performance gap between the vision-only (DETR-based) and LiDAR-based methods is reduced within 5\\% mAP and 6\\% NDS. ",
    "url": "https://arxiv.org/abs/2211.14710",
    "authors": [
      "Changyong Shu",
      "Fisher Yu",
      "Yifan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14715",
    "title": "A Knowledge-based Learning Framework for Self-supervised Pre-training  Towards Enhanced Recognition of Medical Images",
    "abstract": "Self-supervised pre-training has become the priory choice to establish reliable models for automated recognition of massive medical images, which are routinely annotation-free, without semantics, and without guarantee of quality. Note that this paradigm is still at its infancy and limited by closely related open issues: 1) how to learn robust representations in an unsupervised manner from unlabelled medical images of low diversity in samples? and 2) how to obtain the most significant representations demanded by a high-quality segmentation? Aiming at these issues, this study proposes a knowledge-based learning framework towards enhanced recognition of medical images, which works in three phases by synergizing contrastive learning and generative learning models: 1) Sample Space Diversification: Reconstructive proxy tasks have been enabled to embed a priori knowledge with context highlighted to diversify the expanded sample space; 2) Enhanced Representation Learning: Informative noise-contrastive estimation loss regularizes the encoder to enhance representation learning of annotation-free images; 3) Correlated Optimization: Optimization operations in pre-training the encoder and the decoder have been correlated via image restoration from proxy tasks, targeting the need for semantic segmentation. Extensive experiments have been performed on various public medical image datasets (e.g., CheXpert and DRIVE) against the state-of-the-art counterparts (e.g., SimCLR and MoCo), and results demonstrate that: The proposed framework statistically excels in self-supervised benchmarks, achieving 2.08, 1.23, 1.12, 0.76 and 1.38 percentage points improvements over SimCLR in AUC/Dice. The proposed framework achieves label-efficient semi-supervised learning, e.g., reducing the annotation cost by up to 99% in pathological classification. ",
    "url": "https://arxiv.org/abs/2211.14715",
    "authors": [
      "Wei Chen",
      "Chen Li",
      "Dan Chen",
      "Xin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14719",
    "title": "BadPrompt: Backdoor Attacks on Continuous Prompts",
    "abstract": "The prompt-based learning paradigm has gained much research attention recently. It has achieved state-of-the-art performance on several NLP tasks, especially in the few-shot scenarios. While steering the downstream tasks, few works have been reported to investigate the security problems of the prompt-based models. In this paper, we conduct the first study on the vulnerability of the continuous prompt learning algorithm to backdoor attacks. We observe that the few-shot scenarios have posed a great challenge to backdoor attacks on the prompt-based models, limiting the usability of existing NLP backdoor methods. To address this challenge, we propose BadPrompt, a lightweight and task-adaptive algorithm, to backdoor attack continuous prompts. Specially, BadPrompt first generates candidate triggers which are indicative for predicting the targeted label and dissimilar to the samples of the non-targeted labels. Then, it automatically selects the most effective and invisible trigger for each sample with an adaptive trigger optimization algorithm. We evaluate the performance of BadPrompt on five datasets and two continuous prompt models. The results exhibit the abilities of BadPrompt to effectively attack continuous prompts while maintaining high performance on the clean test sets, outperforming the baseline models by a large margin. The source code of BadPrompt is publicly available at https://github.com/papersPapers/BadPrompt. ",
    "url": "https://arxiv.org/abs/2211.14719",
    "authors": [
      "Xiangrui Cai",
      "Haidong Xu",
      "Sihan Xu",
      "Ying Zhang",
      "Xiaojie Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14732",
    "title": "Deep representation learning: Fundamentals, Perspectives, Applications,  and Open Challenges",
    "abstract": "Machine Learning algorithms have had a profound impact on the field of computer science over the past few decades. These algorithms performance is greatly influenced by the representations that are derived from the data in the learning process. The representations learned in a successful learning process should be concise, discrete, meaningful, and able to be applied across a variety of tasks. A recent effort has been directed toward developing Deep Learning models, which have proven to be particularly effective at capturing high-dimensional, non-linear, and multi-modal characteristics. In this work, we discuss the principles and developments that have been made in the process of learning representations, and converting them into desirable applications. In addition, for each framework or model, the key issues and open challenges, as well as the advantages, are examined. ",
    "url": "https://arxiv.org/abs/2211.14732",
    "authors": [
      "Kourosh T. Baghaei",
      "Amirreza Payandeh",
      "Pooya Fayyazsanavi",
      "Shahram Rahimi",
      "Zhiqian Chen",
      "Somayeh Bakhtiari Ramezani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14734",
    "title": "X-PuDu at SemEval-2022 Task 7: A Replaced Token Detection Task  Pre-trained Model with Pattern-aware Ensembling for Identifying Plausible  Clarifications",
    "abstract": "This paper describes our winning system on SemEval 2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts. A replaced token detection pre-trained model is utilized with minorly different task-specific heads for SubTask-A: Multi-class Classification and SubTask-B: Ranking. Incorporating a pattern-aware ensemble method, our system achieves a 68.90% accuracy score and 0.8070 spearman's rank correlation score surpassing the 2nd place with a large margin by 2.7 and 2.2 percent points for SubTask-A and SubTask-B, respectively. Our approach is simple and easy to implement, and we conducted ablation studies and qualitative and quantitative analyses for the working strategies used in our system. ",
    "url": "https://arxiv.org/abs/2211.14734",
    "authors": [
      "Junyuan Shang",
      "Shuohuan Wang",
      "Yu Sun",
      "Yanjun Yu",
      "Yue Zhou",
      "Li Xiang",
      "Guixiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14750",
    "title": "Conditioning Covert Geo-Location (CGL) Detection on Semantic Class  Information",
    "abstract": "The primary goal of artificial intelligence is to mimic humans. Therefore, to advance toward this goal, the AI community attempts to imitate qualities/skills possessed by humans and imbibes them into machines with the help of datasets/tasks. Earlier, many tasks which require knowledge about the objects present in an image are satisfactorily solved by vision models. Recently, with the aim to incorporate knowledge about non-object image regions (hideouts, turns, and other obscured regions), a task for identification of potential hideouts termed Covert Geo-Location (CGL) detection was proposed by Saha et al. It involves identification of image regions which have the potential to either cause an imminent threat or appear as target zones to be accessed for further investigation to identify any occluded objects. Only certain occluding items belonging to certain semantic classes can give rise to CGLs. This fact was overlooked by Saha et al. and no attempts were made to utilize semantic class information, which is crucial for CGL detection. In this paper, we propose a multitask-learning-based approach to achieve 2 goals - i) extraction of features having semantic class information; ii) robust training of the common encoder, exploiting large standard annotated datasets as training set for the auxiliary task (semantic segmentation). To explicitly incorporate class information in the features extracted by the encoder, we have further employed attention mechanism in a novel manner. We have also proposed a better evaluation metric for CGL detection that gives more weightage to recognition rather than precise localization. Experimental evaluations performed on the CGL dataset, demonstrate a significant increase in performance of about 3% to 14% mIoU and 3% to 16% DaR on split 1, and 1% mIoU and 1% to 2% DaR on split 2 over SOTA, serving as a testimony to the superiority of our approach. ",
    "url": "https://arxiv.org/abs/2211.14750",
    "authors": [
      "Binoy Saha",
      "Sukhendu Das"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14752",
    "title": "Differentiable Meta Multigraph Search with Partial Message Propagation  on Heterogeneous Information Networks",
    "abstract": "Heterogeneous information networks (HINs) are widely employed for describing real-world data with intricate entities and relationships. To automatically utilize their semantic information, graph neural architecture search has recently been developed on various tasks of HINs. Existing works, on the other hand, show weaknesses in instability and inflexibility. To address these issues, we propose a novel method called Partial Message Meta Multigraph search (PMMM) to automatically optimize the neural architecture design on HINs. Specifically, to learn how graph neural networks (GNNs) propagate messages along various types of edges, PMMM adopts an efficient differentiable framework to search for a meaningful meta multigraph, which can capture more flexible and complex semantic relations than a meta graph. The differentiable search typically suffers from performance instability, so we further propose a stable algorithm called partial message search to ensure that the searched meta multigraph consistently surpasses the manually designed meta-structures, i.e., meta-paths. Extensive experiments on six benchmark datasets over two representative tasks, including node classification and recommendation, demonstrate the effectiveness of the proposed method. Our approach outperforms the state-of-the-art heterogeneous GNNs, finds out meaningful meta multigraphs, and is significantly more stable. ",
    "url": "https://arxiv.org/abs/2211.14752",
    "authors": [
      "Chao Li",
      "Hao Xu",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14753",
    "title": "A Self-adaptive Neuroevolution Approach to Constructing Deep Neural  Network Architectures Across Different Types",
    "abstract": "Neuroevolution has greatly promoted Deep Neural Network (DNN) architecture design and its applications, while there is a lack of methods available across different DNN types concerning both their scale and performance. In this study, we propose a self-adaptive neuroevolution (SANE) approach to automatically construct various lightweight DNN architectures for different tasks. One of the key settings in SANE is the search space defined by cells and organs self-adapted to different DNN types. Based on this search space, a constructive evolution strategy with uniform evolution settings and operations is designed to grow DNN architectures gradually. SANE is able to self-adaptively adjust evolution exploration and exploitation to improve search efficiency. Moreover, a speciation scheme is developed to protect evolution from early convergence by restricting selection competition within species. To evaluate SANE, we carry out neuroevolution experiments to generate different DNN architectures including convolutional neural network, generative adversarial network and long short-term memory. The results illustrate that the obtained DNN architectures could have smaller scale with similar performance compared to existing DNN architectures. Our proposed SANE provides an efficient approach to self-adaptively search DNN architectures across different types. ",
    "url": "https://arxiv.org/abs/2211.14753",
    "authors": [
      "Zhenhao Shuai",
      "Hongbo Liu",
      "Zhaolin Wan",
      "Wei-Jie Yu",
      "Jun Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14763",
    "title": "Multi-Label Continual Learning using Augmented Graph Convolutional  Network",
    "abstract": "Multi-Label Continual Learning (MLCL) builds a class-incremental framework in a sequential multi-label image recognition data stream. The critical challenges of MLCL are the construction of label relationships on past-missing and future-missing partial labels of training data and the catastrophic forgetting on old classes, resulting in poor generalization. To solve the problems, the study proposes an Augmented Graph Convolutional Network (AGCN++) that can construct the cross-task label relationships in MLCL and sustain catastrophic forgetting. First, we build an Augmented Correlation Matrix (ACM) across all seen classes, where the intra-task relationships derive from the hard label statistics. In contrast, the inter-task relationships leverage hard and soft labels from data and a constructed expert network. Then, we propose a novel partial label encoder (PLE) for MLCL, which can extract dynamic class representation for each partial label image as graph nodes and help generate soft labels to create a more convincing ACM and suppress forgetting. Last, to suppress the forgetting of label dependencies across old tasks, we propose a relationship-preserving constrainter to construct label relationships. The inter-class topology can be augmented automatically, which also yields effective class representations. The proposed method is evaluated using two multi-label image benchmarks. The experimental results show that the proposed way is effective for MLCL image recognition and can build convincing correlations across tasks even if the labels of previous tasks are missing. ",
    "url": "https://arxiv.org/abs/2211.14763",
    "authors": [
      "Kaile Du",
      "Fan Lyu",
      "Linyan Li",
      "Fuyuan Hu",
      "Wei Feng",
      "Fenglei Xu",
      "Xuefeng Xi",
      "Hanjing Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14770",
    "title": "ReGrAt: Regularization in Graphs using Attention to handle class  imbalance",
    "abstract": "Node classification is an important task to solve in graph-based learning. Even though a lot of work has been done in this field, imbalance is neglected. Real-world data is not perfect, and is imbalanced in representations most of the times. Apart from text and images, data can be represented using graphs, and thus addressing the imbalance in graphs has become of paramount importance. In the context of node classification, one class has less examples than others. Changing data composition is a popular way to address the imbalance in node classification. This is done by resampling the data to balance the dataset. However, that can sometimes lead to loss of information or add noise to the dataset. Therefore, in this work, we implicitly solve the problem by changing the model loss. Specifically, we study how attention networks can help tackle imbalance. Moreover, we observe that using a regularizer to assign larger weights to minority nodes helps to mitigate this imbalance. We achieve State of the Art results than the existing methods on several standard citation benchmark datasets. ",
    "url": "https://arxiv.org/abs/2211.14770",
    "authors": [
      "Neeraja Kirtane",
      "Jeshuren Chelladurai",
      "Balaraman Ravindran",
      "Ashish Tendulkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14781",
    "title": "Architecture, Protocols, and Algorithms for Location-Aware Services in  Beyond 5G Networks",
    "abstract": "The automotive and railway industries are rapidly transforming with a strong drive towards automation and digitalization, with the goal of increased convenience, safety, efficiency, and sustainability. Since assisted and fully automated automotive and train transport services increasingly rely on vehicle-to-everything communications, and high-accuracy real-time positioning, it is necessary to continuously maintain high-accuracy localization, even in occlusion scenes such as tunnels, urban canyons, or areas covered by dense foliage. In this paper, we review the 5G positioning framework of the 3rd Generation Partnership Project in terms of methods and architecture and propose enhancements to meet the stringent requirements imposed by the transport industry. In particular, we highlight the benefit of fusing cellular and sensor measurements and discuss required architecture and protocol support for achieving this at the network side. We also propose a positioning framework to fuse cellular network measurements with measurements by onboard sensors. We illustrate the viability of the proposed fusion-based positioning approach using a numerical example. ",
    "url": "https://arxiv.org/abs/2211.14781",
    "authors": [
      "Peter Hammarberg",
      "Julia Vinogradova",
      "G\u00e1bor Fodor",
      "Ritesh Shreevastav",
      "Satyam Dwivedi",
      "Fredrik Gunnarsson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.14782",
    "title": "Breaking Immutable: Information-Coupled Prototype Elaboration for  Few-Shot Object Detection",
    "abstract": "Few-shot object detection, expecting detectors to detect novel classes with a few instances, has made conspicuous progress. However, the prototypes extracted by existing meta-learning based methods still suffer from insufficient representative information and lack awareness of query images, which cannot be adaptively tailored to different query images. Firstly, only the support images are involved for extracting prototypes, resulting in scarce perceptual information of query images. Secondly, all pixels of all support images are treated equally when aggregating features into prototype vectors, thus the salient objects are overwhelmed by the cluttered background. In this paper, we propose an Information-Coupled Prototype Elaboration (ICPE) method to generate specific and representative prototypes for each query image. Concretely, a conditional information coupling module is introduced to couple information from the query branch to the support branch, strengthening the query-perceptual information in support features. Besides, we design a prototype dynamic aggregation module that dynamically adjusts intra-image and inter-image aggregation weights to highlight the salient information useful for detecting query images. Experimental results on both Pascal VOC and MS COCO demonstrate that our method achieves state-of-the-art performance in almost all settings. ",
    "url": "https://arxiv.org/abs/2211.14782",
    "authors": [
      "Xiaonan Lu",
      "Wenhui Diao",
      "Yongqiang Mao",
      "Junxi Li",
      "Peijin Wang",
      "Xian Sun",
      "Kun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14790",
    "title": "Devils in the Clouds: An Evolutionary Study of Telnet Bot Loaders",
    "abstract": "One of the innovations brought by Mirai and its derived malware is the adoption of self-contained loaders for infecting IoT devices and recruiting them in botnets. Functionally decoupled from other botnet components and not embedded in the payload, loaders cannot be analysed using conventional approaches that rely on honeypots for capturing samples. Different approaches are necessary for studying the loaders evolution and defining a genealogy. To address the insufficient knowledge about loaders' lineage in existing studies, in this paper, we propose a semantic-aware method to measure, categorize, and compare different loader servers, with the goal of highlighting their evolution, independent from the payload evolution. Leveraging behavior-based metrics, we cluster the discovered loaders and define eight families to determine the genealogy and draw a homology map. Our study shows that the source code of Mirai is evolving and spawning new botnets with new capabilities, both on the client side and the server side. In turn, shedding light on the infection loaders can help the cybersecurity community to improve detection and prevention tools. ",
    "url": "https://arxiv.org/abs/2211.14790",
    "authors": [
      "Yuhui Zhu",
      "Zhenxiang Chen",
      "Qiben Yan",
      "Shanshan Wang",
      "Alberto Giaretta",
      "Enlong Li",
      "Lizhi Peng",
      "Chuan Zhao",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.14794",
    "title": "Traditional Classification Neural Networks are Good Generators: They are  Competitive with DDPMs and GANs",
    "abstract": "Classifiers and generators have long been separated. We break down this separation and showcase that conventional neural network classifiers can generate high-quality images of a large number of categories, being comparable to the state-of-the-art generative models (e.g., DDPMs and GANs). We achieve this by computing the partial derivative of the classification loss function with respect to the input to optimize the input to produce an image. Since it is widely known that directly optimizing the inputs is similar to targeted adversarial attacks incapable of generating human-meaningful images, we propose a mask-based stochastic reconstruction module to make the gradients semantic-aware to synthesize plausible images. We further propose a progressive-resolution technique to guarantee fidelity, which produces photorealistic images. Furthermore, we introduce a distance metric loss and a non-trivial distribution loss to ensure classification neural networks can synthesize diverse and high-fidelity images. Using traditional neural network classifiers, we can generate good-quality images of 256$\\times$256 resolution on ImageNet. Intriguingly, our method is also applicable to text-to-image generation by regarding image-text foundation models as generalized classifiers. Proving that classifiers have learned the data distribution and are ready for image generation has far-reaching implications, for classifiers are much easier to train than generative models like DDPMs and GANs. We don't even need to train classification models because tons of public ones are available for download. Also, this holds great potential for the interpretability and robustness of classifiers. ",
    "url": "https://arxiv.org/abs/2211.14794",
    "authors": [
      "Guangrun Wang",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14799",
    "title": "Sampling Neural Radiance Fields for Refractive Objects",
    "abstract": "Recently, differentiable volume rendering in neural radiance fields (NeRF) has gained a lot of popularity, and its variants have attained many impressive results. However, existing methods usually assume the scene is a homogeneous volume so that a ray is cast along the straight path. In this work, the scene is instead a heterogeneous volume with a piecewise-constant refractive index, where the path will be curved if it intersects the different refractive indices. For novel view synthesis of refractive objects, our NeRF-based framework aims to optimize the radiance fields of bounded volume and boundary from multi-view posed images with refractive object silhouettes. To tackle this challenging problem, the refractive index of a scene is reconstructed from silhouettes. Given the refractive index, we extend the stratified and hierarchical sampling techniques in NeRF to allow drawing samples along a curved path tracked by the Eikonal equation. The results indicate that our framework outperforms the state-of-the-art method both quantitatively and qualitatively, demonstrating better performance on the perceptual similarity metric and an apparent improvement in the rendering quality on several synthetic and real scenes. ",
    "url": "https://arxiv.org/abs/2211.14799",
    "authors": [
      "Jen-I Pan",
      "Jheng-Wei Su",
      "Kai-Wen Hsiao",
      "Ting-Yu Yen",
      "Hung-Kuo Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14802",
    "title": "Neural Font Rasterization",
    "abstract": "Recent advances in deep learning techniques and applications have revolutionized artistic creation and manipulation in many domains (text, images, music); however, fonts have not yet been integrated with deep learning architectures in a manner that supports their multi-scale nature. In this work we aim to bridge this gap, proposing a network architecture capable of rasterizing glyphs in multiple sizes, potentially paving the way for easy and accessible creation and manipulation of fonts. ",
    "url": "https://arxiv.org/abs/2211.14802",
    "authors": [
      "Daniel Anderson",
      "Ariel Shamir",
      "Ohad Fried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14805",
    "title": "Rethinking Data Augmentation for Single-source Domain Generalization in  Medical Image Segmentation",
    "abstract": "Single-source domain generalization (SDG) in medical image segmentation is a challenging yet essential task as domain shifts are quite common among clinical image datasets. Previous attempts most conduct global-only/random augmentation. Their augmented samples are usually insufficient in diversity and informativeness, thus failing to cover the possible target domain distribution. In this paper, we rethink the data augmentation strategy for SDG in medical image segmentation. Motivated by the class-level representation invariance and style mutability of medical images, we hypothesize that unseen target data can be sampled from a linear combination of $C$ (the class number) random variables, where each variable follows a location-scale distribution at the class level. Accordingly, data augmented can be readily made by sampling the random variables through a general form. On the empirical front, we implement such strategy with constrained B$\\acute{\\rm e}$zier transformation on both global and local (i.e. class-level) regions, which can largely increase the augmentation diversity. A Saliency-balancing Fusion mechanism is further proposed to enrich the informativeness by engaging the gradient information, guiding augmentation with proper orientation and magnitude. As an important contribution, we prove theoretically that our proposed augmentation can lead to an upper bound of the generalization risk on the unseen target domain, thus confirming our hypothesis. Combining the two strategies, our Saliency-balancing Location-scale Augmentation (SLAug) exceeds the state-of-the-art works by a large margin in two challenging SDG tasks. Code is available at https://github.com/Kaiseem/SLAug . ",
    "url": "https://arxiv.org/abs/2211.14805",
    "authors": [
      "Zixian Su",
      "Kai Yao",
      "Xi Yang",
      "Qiufeng Wang",
      "Jie Sun",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14810",
    "title": "A Kernel Perspective of Skip Connections in Convolutional Networks",
    "abstract": "Over-parameterized residual networks (ResNets) are amongst the most successful convolutional neural architectures for image processing. Here we study their properties through their Gaussian Process and Neural Tangent kernels. We derive explicit formulas for these kernels, analyze their spectra, and provide bounds on their implied condition numbers. Our results indicate that (1) with ReLU activation, the eigenvalues of these residual kernels decay polynomially at a similar rate compared to the same kernels when skip connections are not used, thus maintaining a similar frequency bias; (2) however, residual kernels are more locally biased. Our analysis further shows that the matrices obtained by these residual kernels yield favorable condition numbers at finite depths than those obtained without the skip connections, enabling therefore faster convergence of training with gradient descent. ",
    "url": "https://arxiv.org/abs/2211.14810",
    "authors": [
      "Daniel Barzilai",
      "Amnon Geifman",
      "Meirav Galun",
      "Ronen Basri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14827",
    "title": "Domain Generalization for Robust Model-Based Offline Reinforcement  Learning",
    "abstract": "Existing offline reinforcement learning (RL) algorithms typically assume that training data is either: 1) generated by a known policy, or 2) of entirely unknown origin. We consider multi-demonstrator offline RL, a middle ground where we know which demonstrators generated each dataset, but make no assumptions about the underlying policies of the demonstrators. This is the most natural setting when collecting data from multiple human operators, yet remains unexplored. Since different demonstrators induce different data distributions, we show that this can be naturally framed as a domain generalization problem, with each demonstrator corresponding to a different domain. Specifically, we propose Domain-Invariant Model-based Offline RL (DIMORL), where we apply Risk Extrapolation (REx) (Krueger et al., 2020) to the process of learning dynamics and rewards models. Our results show that models trained with REx exhibit improved domain generalization performance when compared with the natural baseline of pooling all demonstrators' data. We observe that the resulting models frequently enable the learning of superior policies in the offline model-based RL setting, can improve the stability of the policy learning process, and potentially enable increased exploration. ",
    "url": "https://arxiv.org/abs/2211.14827",
    "authors": [
      "Alan Clark",
      "Shoaib Ahmed Siddiqui",
      "Robert Kirk",
      "Usman Anwar",
      "Stephen Chung",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14843",
    "title": "Learning Object-Language Alignments for Open-Vocabulary Object Detection",
    "abstract": "Existing object detection methods are bounded in a fixed-set vocabulary by costly labeled data. When dealing with novel categories, the model has to be retrained with more bounding box annotations. Natural language supervision is an attractive alternative for its annotation-free attributes and broader object concepts. However, learning open-vocabulary object detection from language is challenging since image-text pairs do not contain fine-grained object-language alignments. Previous solutions rely on either expensive grounding annotations or distilling classification-oriented vision models. In this paper, we propose a novel open-vocabulary object detection framework directly learning from image-text pair data. We formulate object-language alignment as a set matching problem between a set of image region features and a set of word embeddings. It enables us to train an open-vocabulary object detector on image-text pairs in a much simple and effective way. Extensive experiments on two benchmark datasets, COCO and LVIS, demonstrate our superior performance over the competing approaches on novel categories, e.g. achieving 32.0% mAP on COCO and 21.7% mask mAP on LVIS. Code is available at: https://github.com/clin1223/VLDet. ",
    "url": "https://arxiv.org/abs/2211.14843",
    "authors": [
      "Chuang Lin",
      "Peize Sun",
      "Yi Jiang",
      "Ping Luo",
      "Lizhen Qu",
      "Gholamreza Haffari",
      "Zehuan Yuan",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14844",
    "title": "Estimating the number of communities in weighted networks",
    "abstract": "Community detection in weighted networks has been a popular topic in recent years. However, while there exist several flexible methods for estimating communities in weighted networks, these methods usually assume that the number of communities is known. It is usually unclear how to determine the exact number of communities one should use. Here, to estimate the number of communities for weighted networks generated from arbitrary distribution under the degree-corrected distribution-free model, we propose one approach that combines weighted modularity with spectral clustering. This approach allows a weighted network to have negative edge weights and it also works for signed networks. We compare the proposed method to several existing methods and show that our method is more accurate for estimating the number of communities both numerically and empirically. ",
    "url": "https://arxiv.org/abs/2211.14844",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2211.14860",
    "title": "Foiling Explanations in Deep Neural Networks",
    "abstract": "Deep neural networks (DNNs) have greatly impacted numerous fields over the past decade. Yet despite exhibiting superb performance over many problems, their black-box nature still poses a significant challenge with respect to explainability. Indeed, explainable artificial intelligence (XAI) is crucial in several fields, wherein the answer alone -- sans a reasoning of how said answer was derived -- is of little value. This paper uncovers a troubling property of explanation methods for image-based DNNs: by making small visual changes to the input image -- hardly influencing the network's output -- we demonstrate how explanations may be arbitrarily manipulated through the use of evolution strategies. Our novel algorithm, AttaXAI, a model-agnostic, adversarial attack on XAI algorithms, only requires access to the output logits of a classifier and to the explanation map; these weak assumptions render our approach highly useful where real-world models and data are concerned. We compare our method's performance on two benchmark datasets -- CIFAR100 and ImageNet -- using four different pretrained deep-learning models: VGG16-CIFAR100, VGG16-ImageNet, MobileNet-CIFAR100, and Inception-v3-ImageNet. We find that the XAI methods can be manipulated without the use of gradients or other model internals. Our novel algorithm is successfully able to manipulate an image in a manner imperceptible to the human eye, such that the XAI method outputs a specific explanation map. To our knowledge, this is the first such method in a black-box setting, and we believe it has significant value where explainability is desired, required, or legally mandatory. ",
    "url": "https://arxiv.org/abs/2211.14860",
    "authors": [
      "Snir Vitrack Tamam",
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14896",
    "title": "Knowledge Retrieval Using Functional Object-Oriented Networks",
    "abstract": "Robotic agents often perform tasks that transform sets of input objects into output objects through functional motions. This work describes the FOON knowledge representation model for robotic tasks. We define the structure and key components of FOON and describe the process we followed to create our universal FOON dataset. The paper describes various search algorithms and heuristic functions we used to search for objects within the FOON. We performed multiple searches on our universal FOON using these algorithms and discussed the effectiveness of each algorithm. ",
    "url": "https://arxiv.org/abs/2211.14896",
    "authors": [
      "Gabriel Laverghetta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14905",
    "title": "Multi-Modal Few-Shot Temporal Action Detection via Vision-Language  Meta-Adaptation",
    "abstract": "Few-shot (FS) and zero-shot (ZS) learning are two different approaches for scaling temporal action detection (TAD) to new classes. The former adapts a pretrained vision model to a new task represented by as few as a single video per class, whilst the latter requires no training examples by exploiting a semantic description of the new class. In this work, we introduce a new multi-modality few-shot (MMFS) TAD problem, which can be considered as a marriage of FS-TAD and ZS-TAD by leveraging few-shot support videos and new class names jointly. To tackle this problem, we further introduce a novel MUlti-modality PromPt mETa-learning (MUPPET) method. This is enabled by efficiently bridging pretrained vision and language models whilst maximally reusing already learned capacity. Concretely, we construct multi-modal prompts by mapping support videos into the textual token space of a vision-language model using a meta-learned adapter-equipped visual semantics tokenizer. To tackle large intra-class variation, we further design a query feature regulation scheme. Extensive experiments on ActivityNetv1.3 and THUMOS14 demonstrate that our MUPPET outperforms state-of-the-art alternative methods, often by a large margin. We also show that our MUPPET can be easily extended to tackle the few-shot object detection problem and again achieves the state-of-the-art performance on MS-COCO dataset. The code will be available in https://github.com/sauradip/MUPPET ",
    "url": "https://arxiv.org/abs/2211.14905",
    "authors": [
      "Sauradip Nag",
      "Mengmeng Xu",
      "Xiatian Zhu",
      "Juan-Manuel Perez-Rua",
      "Bernard Ghanem",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.14917",
    "title": "CorrectNet: Robustness Enhancement of Analog In-Memory Computing for  Neural Networks by Error Suppression and Compensation",
    "abstract": "The last decade has witnessed the breakthrough of deep neural networks (DNNs) in many fields. With the increasing depth of DNNs, hundreds of millions of multiply-and-accumulate (MAC) operations need to be executed. To accelerate such operations efficiently, analog in-memory computing platforms based on emerging devices, e.g., resistive RAM (RRAM), have been introduced. These acceleration platforms rely on analog properties of the devices and thus suffer from process variations and noise. Consequently, weights in neural networks configured into these platforms can deviate from the expected values, which may lead to feature errors and a significant degradation of inference accuracy. To address this issue, in this paper, we propose a framework to enhance the robustness of neural networks under variations and noise. First, a modified Lipschitz constant regularization is proposed during neural network training to suppress the amplification of errors propagated through network layers. Afterwards, error compensation is introduced at necessary locations determined by reinforcement learning to rescue the feature maps with remaining errors. Experimental results demonstrate that inference accuracy of neural networks can be recovered from as low as 1.69% under variations and noise back to more than 95% of their original accuracy, while the training and hardware cost are negligible. ",
    "url": "https://arxiv.org/abs/2211.14917",
    "authors": [
      "Amro Eldebiky",
      "Grace Li Zhang",
      "Georg Boecherer",
      "Bing Li",
      "Ulf Schlichtmann"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14924",
    "title": "Post-Processing Temporal Action Detection",
    "abstract": "Existing Temporal Action Detection (TAD) methods typically take a pre-processing step in converting an input varying-length video into a fixed-length snippet representation sequence, before temporal boundary estimation and action classification. This pre-processing step would temporally downsample the video, reducing the inference resolution and hampering the detection performance in the original temporal resolution. In essence, this is due to a temporal quantization error introduced during the resolution downsampling and recovery. This could negatively impact the TAD performance, but is largely ignored by existing methods. To address this problem, in this work we introduce a novel model-agnostic post-processing method without model redesign and retraining. Specifically, we model the start and end points of action instances with a Gaussian distribution for enabling temporal boundary inference at a sub-snippet level. We further introduce an efficient Taylor-expansion based approximation, dubbed as Gaussian Approximated Post-processing (GAP). Extensive experiments demonstrate that our GAP can consistently improve a wide variety of pre-trained off-the-shelf TAD models on the challenging ActivityNet (+0.2% -0.7% in average mAP) and THUMOS (+0.2% -0.5% in average mAP) benchmarks. Such performance gains are already significant and highly comparable to those achieved by novel model designs. Also, GAP can be integrated with model training for further performance gain. Importantly, GAP enables lower temporal resolutions for more efficient inference, facilitating low-resource applications. The code will be available in https://github.com/sauradip/GAP ",
    "url": "https://arxiv.org/abs/2211.14924",
    "authors": [
      "Sauradip Nag",
      "Xiatian Zhu",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14926",
    "title": "SteppingNet: A Stepping Neural Network with Incremental Accuracy  Enhancement",
    "abstract": "Deep neural networks (DNNs) have successfully been applied in many fields in the past decades. However, the increasing number of multiply-and-accumulate (MAC) operations in DNNs prevents their application in resource-constrained and resource-varying platforms, e.g., mobile phones and autonomous vehicles. In such platforms, neural networks need to provide acceptable results quickly and the accuracy of the results should be able to be enhanced dynamically according to the computational resources available in the computing system. To address these challenges, we propose a design framework called SteppingNet. SteppingNet constructs a series of subnets whose accuracy is incrementally enhanced as more MAC operations become available. Therefore, this design allows a trade-off between accuracy and latency. In addition, the larger subnets in SteppingNet are built upon smaller subnets, so that the results of the latter can directly be reused in the former without recomputation. This property allows SteppingNet to decide on-the-fly whether to enhance the inference accuracy by executing further MAC operations. Experimental results demonstrate that SteppingNet provides an effective incremental accuracy improvement and its inference accuracy consistently outperforms the state-of-the-art work under the same limit of computational resources. ",
    "url": "https://arxiv.org/abs/2211.14926",
    "authors": [
      "Wenhao Sun",
      "Grace Li Zhang",
      "Xunzhao Yin",
      "Cheng Zhuo",
      "Huaxi Gu",
      "Bing Li",
      "Ulf Schlichtmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14927",
    "title": "BEV-Locator: An End-to-end Visual Semantic Localization Network Using  Multi-View Images",
    "abstract": "Accurate localization ability is fundamental in autonomous driving. Traditional visual localization frameworks approach the semantic map-matching problem with geometric models, which rely on complex parameter tuning and thus hinder large-scale deployment. In this paper, we propose BEV-Locator: an end-to-end visual semantic localization neural network using multi-view camera images. Specifically, a visual BEV (Birds-Eye-View) encoder extracts and flattens the multi-view images into BEV space. While the semantic map features are structurally embedded as map queries sequence. Then a cross-model transformer associates the BEV features and semantic map queries. The localization information of ego-car is recursively queried out by cross-attention modules. Finally, the ego pose can be inferred by decoding the transformer outputs. We evaluate the proposed method in large-scale nuScenes and Qcraft datasets. The experimental results show that the BEV-locator is capable to estimate the vehicle poses under versatile scenarios, which effectively associates the cross-model information from multi-view images and global semantic maps. The experiments report satisfactory accuracy with mean absolute errors of 0.052m, 0.135m and 0.251$^\\circ$ in lateral, longitudinal translation and heading angle degree. ",
    "url": "https://arxiv.org/abs/2211.14927",
    "authors": [
      "Zhihuang Zhang",
      "Meng Xu",
      "Wenqiang Zhou",
      "Tao Peng",
      "Liang Li",
      "Stefan Poslad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14928",
    "title": "Class-based Quantization for Neural Networks",
    "abstract": "In deep neural networks (DNNs), there are a huge number of weights and multiply-and-accumulate (MAC) operations. Accordingly, it is challenging to apply DNNs on resource-constrained platforms, e.g., mobile phones. Quantization is a method to reduce the size and the computational complexity of DNNs. Existing quantization methods either require hardware overhead to achieve a non-uniform quantization or focus on model-wise and layer-wise uniform quantization, which are not as fine-grained as filter-wise quantization. In this paper, we propose a class-based quantization method to determine the minimum number of quantization bits for each filter or neuron in DNNs individually. In the proposed method, the importance score of each filter or neuron with respect to the number of classes in the dataset is first evaluated. The larger the score is, the more important the filter or neuron is and thus the larger the number of quantization bits should be. Afterwards, a search algorithm is adopted to exploit the different importance of filters and neurons to determine the number of quantization bits of each filter or neuron. Experimental results demonstrate that the proposed method can maintain the inference accuracy with low bit-width quantization. Given the same number of quantization bits, the proposed method can also achieve a better inference accuracy than the existing methods. ",
    "url": "https://arxiv.org/abs/2211.14928",
    "authors": [
      "Wenhao Sun",
      "Grace Li Zhang",
      "Huaxi Gu",
      "Bing Li",
      "Ulf Schlichtmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14938",
    "title": "An Anomaly Detection Method for Satellites Using Monte Carlo Dropout",
    "abstract": "Recently, there has been a significant amount of interest in satellite telemetry anomaly detection (AD) using neural networks (NN). For AD purposes, the current approaches focus on either forecasting or reconstruction of the time series, and they cannot measure the level of reliability or the probability of correct detection. Although the Bayesian neural network (BNN)-based approaches are well known for time series uncertainty estimation, they are computationally intractable. In this paper, we present a tractable approximation for BNN based on the Monte Carlo (MC) dropout method for capturing the uncertainty in the satellite telemetry time series, without sacrificing accuracy. For time series forecasting, we employ an NN, which consists of several Long Short-Term Memory (LSTM) layers followed by various dense layers. We employ the MC dropout inside each LSTM layer and before the dense layers for uncertainty estimation. With the proposed uncertainty region and by utilizing a post-processing filter, we can effectively capture the anomaly points. Numerical results show that our proposed time series AD approach outperforms the existing methods from both prediction accuracy and AD perspectives. ",
    "url": "https://arxiv.org/abs/2211.14938",
    "authors": [
      "Mohammad Amin Maleki Sadr",
      "Yeying Zhu",
      "Peng Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.14939",
    "title": "Applying Deep Reinforcement Learning to the HP Model for Protein  Structure Prediction",
    "abstract": "A central problem in computational biophysics is protein structure prediction, i.e., finding the optimal folding of a given amino acid sequence. This problem has been studied in a classical abstract model, the HP model, where the protein is modeled as a sequence of H (hydrophobic) and P (polar) amino acids on a lattice. The objective is to find conformations maximizing H-H contacts. It is known that even in this reduced setting, the problem is intractable (NP-hard). In this work, we apply deep reinforcement learning (DRL) to the two-dimensional HP model. We can obtain the conformations of best known energies for benchmark HP sequences with lengths from 20 to 50. Our DRL is based on a deep Q-network (DQN). We find that a DQN based on long short-term memory (LSTM) architecture greatly enhances the RL learning ability and significantly improves the search process. DRL can sample the state space efficiently, without the need of manual heuristics. Experimentally we show that it can find multiple distinct best-known solutions per trial. This study demonstrates the effectiveness of deep reinforcement learning in the HP model for protein folding. ",
    "url": "https://arxiv.org/abs/2211.14939",
    "authors": [
      "Kaiyuan Yang",
      "Houjing Huang",
      "Olafs Vandans",
      "Adithya Murali",
      "Fujia Tian",
      "Roland H.C. Yap",
      "Liang Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2211.14944",
    "title": "HULK-V: a Heterogeneous Ultra-low-power Linux capable RISC-V SoC",
    "abstract": "IoT applications span a wide range in performance and memory footprint, under tight cost and power constraints. High-end applications rely on power-hungry Systems-on-Chip (SoCs) featuring powerful processors, large LPDDR/DDR3/4/5 memories, and supporting full-fledged Operating Systems (OS). On the contrary, low-end applications typically rely on Ultra-Low-Power ucontrollers with a \"close to metal\" software environment and simple micro-kernel-based runtimes. Emerging applications and trends of IoT require the \"best of both worlds\": cheap and low-power SoC systems with a well-known and agile software environment based on full-fledged OS (e.g., Linux), coupled with extreme energy efficiency and parallel digital signal processing capabilities. We present HULK-V: an open-source Heterogeneous Linux-capable RISC-V-based SoC coupling a 64-bit RISC-V processor with an 8-core Programmable Multi-Core Accelerator (PMCA), delivering up to 13.8 GOps, up to 157 GOps/W and accelerating the execution of complex DSP and ML tasks by up to 112x over the host processor. HULK-V leverages a lightweight, fully digital memory hierarchy based on HyperRAM IoT DRAM that exposes up to 512 MB of DRAM memory to the host CPU. Featuring HyperRAMs, HULK-V doubles the energy efficiency without significant performance loss compared to featuring power-hungry LPDDR memories, requiring expensive and large mixed-signal PHYs. HULK-V, implemented in Global Foundries 22nm FDX technology, is a fully digital ultra-low-cost SoC running a 64-bit Linux software stack with OpenMP host-to-PMCA offload within a power envelope of just 250 mW. ",
    "url": "https://arxiv.org/abs/2211.14944",
    "authors": [
      "Luca Valente",
      "Yvan Tortorella",
      "Mattia Sinigaglia",
      "Giuseppe Tagliavini",
      "Alessandro Capotondi",
      "Luca Benini",
      "Davide Rossi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2211.14952",
    "title": "Federated Learning Attacks and Defenses: A Survey",
    "abstract": "In terms of artificial intelligence, there are several security and privacy deficiencies in the traditional centralized training methods of machine learning models by a server. To address this limitation, federated learning (FL) has been proposed and is known for breaking down ``data silos\" and protecting the privacy of users. However, FL has not yet gained popularity in the industry, mainly due to its security, privacy, and high cost of communication. For the purpose of advancing the research in this field, building a robust FL system, and realizing the wide application of FL, this paper sorts out the possible attacks and corresponding defenses of the current FL system systematically. Firstly, this paper briefly introduces the basic workflow of FL and related knowledge of attacks and defenses. It reviews a great deal of research about privacy theft and malicious attacks that have been studied in recent years. Most importantly, in view of the current three classification criteria, namely the three stages of machine learning, the three different roles in federated learning, and the CIA (Confidentiality, Integrity, and Availability) guidelines on privacy protection, we divide attack approaches into two categories according to the training stage and the prediction stage in machine learning. Furthermore, we also identify the CIA property violated for each attack method and potential attack role. Various defense mechanisms are then analyzed separately from the level of privacy and security. Finally, we summarize the possible challenges in the application of FL from the aspect of attacks and defenses and discuss the future development direction of FL systems. In this way, the designed FL system has the ability to resist different attacks and is more secure and stable. ",
    "url": "https://arxiv.org/abs/2211.14952",
    "authors": [
      "Yao Chen",
      "Yijie Gui",
      "Hong Lin",
      "Wensheng Gan",
      "Yongdong Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14963",
    "title": "Neural Architecture for Online Ensemble Continual Learning",
    "abstract": "Continual learning with an increasing number of classes is a challenging task. The difficulty rises when each example is presented exactly once, which requires the model to learn online. Recent methods with classic parameter optimization procedures have been shown to struggle in such setups or have limitations like non-differentiable components or memory buffers. For this reason, we present the fully differentiable ensemble method that allows us to efficiently train an ensemble of neural networks in the end-to-end regime. The proposed technique achieves SOTA results without a memory buffer and clearly outperforms the reference methods. The conducted experiments have also shown a significant increase in the performance for small ensembles, which demonstrates the capability of obtaining relatively high classification accuracy with a reduced number of classifiers. ",
    "url": "https://arxiv.org/abs/2211.14963",
    "authors": [
      "Mateusz W\u00f3jcik",
      "Witold Ko\u015bciukiewicz",
      "Tomasz Kajdanowicz",
      "Adam Gonczarek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14966",
    "title": "Adversarial Rademacher Complexity of Deep Neural Networks",
    "abstract": "Deep neural networks are vulnerable to adversarial attacks. Ideally, a robust model shall perform well on both the perturbed training data and the unseen perturbed test data. It is found empirically that fitting perturbed training data is not hard, but generalizing to perturbed test data is quite difficult. To better understand adversarial generalization, it is of great interest to study the adversarial Rademacher complexity (ARC) of deep neural networks. However, how to bound ARC in multi-layers cases is largely unclear due to the difficulty of analyzing adversarial loss in the definition of ARC. There have been two types of attempts of ARC. One is to provide the upper bound of ARC in linear and one-hidden layer cases. However, these approaches seem hard to extend to multi-layer cases. Another is to modify the adversarial loss and provide upper bounds of Rademacher complexity on such surrogate loss in multi-layer cases. However, such variants of Rademacher complexity are not guaranteed to be bounds for meaningful robust generalization gaps (RGG). In this paper, we provide a solution to this unsolved problem. Specifically, we provide the first bound of adversarial Rademacher complexity of deep neural networks. Our approach is based on covering numbers. We provide a method to handle the robustify function classes of DNNs such that we can calculate the covering numbers. Finally, we provide experiments to study the empirical implication of our bounds and provide an analysis of poor adversarial generalization. ",
    "url": "https://arxiv.org/abs/2211.14966",
    "authors": [
      "Jiancong Xiao",
      "Yanbo Fan",
      "Ruoyu Sun",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14985",
    "title": "CoMMA Protocol: Towards Complete Mitigation of Maximal Extractable Value  (MEV) Attacks",
    "abstract": "MEV attacks have been an omnipresent evil in the blockchain world, an implicit tax that uninformed users pay for using the service. The problem arises from the miners' ability to reorder and insert arbitrary transactions in the blocks they mine. This paper proposes a 2-phased transaction protocol to eliminate MEV attacks. The user requests an interaction token from the on-chain counter-party. This token serves as a blind preemption for the counter-party and prevents the reordering of transactions at lower levels in the blockchain framework. We prove the correctness of the CoMMA protocol and demonstrate its efficacy against MEV attacks. ",
    "url": "https://arxiv.org/abs/2211.14985",
    "authors": [
      "Dev Churiwala",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.14987",
    "title": "Dual Information Enhanced Multi-view Attributed Graph Clustering",
    "abstract": "Multi-view attributed graph clustering is an important approach to partition multi-view data based on the attribute feature and adjacent matrices from different views. Some attempts have been made in utilizing Graph Neural Network (GNN), which have achieved promising clustering performance. Despite this, few of them pay attention to the inherent specific information embedded in multiple views. Meanwhile, they are incapable of recovering the latent high-level representation from the low-level ones, greatly limiting the downstream clustering performance. To fill these gaps, a novel Dual Information enhanced multi-view Attributed Graph Clustering (DIAGC) method is proposed in this paper. Specifically, the proposed method introduces the Specific Information Reconstruction (SIR) module to disentangle the explorations of the consensus and specific information from multiple views, which enables GCN to capture the more essential low-level representations. Besides, the Mutual Information Maximization (MIM) module maximizes the agreement between the latent high-level representation and low-level ones, and enables the high-level representation to satisfy the desired clustering structure with the help of the Self-supervised Clustering (SC) module. Extensive experiments on several real-world benchmarks demonstrate the effectiveness of the proposed DIAGC method compared with the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2211.14987",
    "authors": [
      "Jia-Qi Lin",
      "Man-Sheng Chen",
      "Xi-Ran Zhu",
      "Chang-Dong Wang",
      "Haizhang Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15013",
    "title": "Enhancing Data Security for Cloud Computing Applications through  Distributed Blockchain-based SDN Architecture in IoT Networks",
    "abstract": "Blockchain (BC) and Software Defined Networking (SDN) are some of the most prominent emerging technologies in recent research. These technologies provide security, integrity, as well as confidentiality in their respective applications. Cloud computing has also been a popular comprehensive technology for several years. Confidential information is often shared with the cloud infrastructure to give customers access to remote resources, such as computation and storage operations. However, cloud computing also presents substantial security threats, issues, and challenges. Therefore, to overcome these difficulties, we propose integrating Blockchain and SDN in the cloud computing platform. In this research, we introduce the architecture to better secure clouds. Moreover, we leverage a distributed Blockchain approach to convey security, confidentiality, privacy, integrity, adaptability, and scalability in the proposed architecture. BC provides a distributed or decentralized and efficient environment for users. Also, we present an SDN approach to improving the reliability, stability, and load balancing capabilities of the cloud infrastructure. Finally, we provide an experimental evaluation of the performance of our SDN and BC-based implementation using different parameters, also monitoring some attacks in the system and proving its efficacy. ",
    "url": "https://arxiv.org/abs/2211.15013",
    "authors": [
      "Anichur Rahman",
      "Md. Jahidul Islam",
      "Rafiqul Islam",
      "Ayesha Aziz",
      "Dipanjali Kundu",
      "Sadia Sazzad",
      "Md. Razaul Karim",
      "Mahedi Hasan",
      "Ziaur Rahman",
      "Said Elnaffar",
      "Shahab S. Band"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.15022",
    "title": "Summer: WeChat Neural Machine Translation Systems for the WMT22  Biomedical Translation Task",
    "abstract": "This paper introduces WeChat's participation in WMT 2022 shared biomedical translation task on Chinese to English. Our systems are based on the Transformer, and use several different Transformer structures to improve the quality of translation. In our experiments, we employ data filtering, data generation, several variants of Transformer, fine-tuning and model ensemble. Our Chinese$\\to$English system, named Summer, achieves the highest BLEU score among all submissions. ",
    "url": "https://arxiv.org/abs/2211.15022",
    "authors": [
      "Ernan Li",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.15025",
    "title": "Biot model with generalized eigenvalue problems for scalability and  robustness to parameters",
    "abstract": "We consider Biot model with block preconditioners and generalized eigenvalue problems for scalability and robustness to parameters. A discontinuous Galerkin discretization is employed with the displacement and Darcy flow flux discretized as piecewise continuous in $P_1$ elements, and the pore pressure as piecewise constant in the $P_0$ element with a stabilizing term. Parallel algorithms are designed to solve the resulting linear system. Specifically, the GMRES method is employed as the outer iteration algorithm and block-triangular preconditioners are designed to accelerate the convergence. In the preconditioners, the elliptic operators are further approximated by using incomplete Cholesky factorization or two-level additive overlapping Schwartz method where coarse grids are constructed by generalized eigenvalue problems in the overlaps (GenEO). Extensive numerical experiments show a scalability and parametric robustness of the resulting parallel algorithms. ",
    "url": "https://arxiv.org/abs/2211.15025",
    "authors": [
      "Pilhwa Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2211.15028",
    "title": "Joint Multimodal Entity-Relation Extraction Based on Edge-enhanced Graph  Alignment Network and Word-pair Relation Tagging",
    "abstract": "Multimodal named entity recognition (MNER) and multimodal relation extraction (MRE) are two fundamental subtasks in the multimodal knowledge graph construction task. However, the existing methods usually handle two tasks independently, which ignores the bidirectional interaction between them. This paper is the first to propose jointly performing MNER and MRE as a joint multimodal entity-relation extraction task (JMERE). Besides, the current MNER and MRE models only consider aligning the visual objects with textual entities in visual and textual graphs but ignore the entity-entity relationships and object-object relationships. To address the above challenges, we propose an edge-enhanced graph alignment network and a word-pair relation tagging (EEGA) for JMERE task. Specifically, we first design a word-pair relation tagging to exploit the bidirectional interaction between MNER and MRE and avoid the error propagation. Then, we propose an edge-enhanced graph alignment network to enhance the JMERE task by aligning nodes and edges in the cross-graph. Compared with previous methods, the proposed method can leverage the edge information to auxiliary alignment between objects and entities and find the correlations between entity-entity relationships and object-object relationships. Experiments are conducted to show the effectiveness of our model. ",
    "url": "https://arxiv.org/abs/2211.15028",
    "authors": [
      "Li Yuan",
      "Yi Cai",
      "Jin Wang",
      "Qing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.15030",
    "title": "Imperceptible Adversarial Attack via Invertible Neural Networks",
    "abstract": "Adding perturbations via utilizing auxiliary gradient information or discarding existing details of the benign images are two common approaches for generating adversarial examples. Though visual imperceptibility is the desired property of adversarial examples, conventional adversarial attacks still generate traceable adversarial perturbations. In this paper, we introduce a novel Adversarial Attack via Invertible Neural Networks (AdvINN) method to produce robust and imperceptible adversarial examples. Specifically, AdvINN fully takes advantage of the information preservation property of Invertible Neural Networks and thereby generates adversarial examples by simultaneously adding class-specific semantic information of the target class and dropping discriminant information of the original class. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that the proposed AdvINN method can produce less imperceptible adversarial images than the state-of-the-art methods and AdvINN yields more robust adversarial examples with high confidence compared to other adversarial attacks. ",
    "url": "https://arxiv.org/abs/2211.15030",
    "authors": [
      "Zihan Chen",
      "Ziyue Wang",
      "Junjie Huang",
      "Wentao Zhao",
      "Xiao Liu",
      "Dejian Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.15043",
    "title": "Higher-order Knowledge Transfer for Dynamic Community Detection with  Great Changes",
    "abstract": "Network structure evolves with time in the real world, and the discovery of changing communities in dynamic networks is an important research topic that poses challenging tasks. Most existing methods assume that no significant change in the network occurs; namely, the difference between adjacent snapshots is slight. However, great change exists in the real world usually. The great change in the network will result in the community detection algorithms are difficulty obtaining valuable information from the previous snapshot, leading to negative transfer for the next time steps. This paper focuses on dynamic community detection with substantial changes by integrating higher-order knowledge from the previous snapshots to aid the subsequent snapshots. Moreover, to improve search efficiency, a higher-order knowledge transfer strategy is designed to determine first-order and higher-order knowledge by detecting the similarity of the adjacency matrix of snapshots. In this way, our proposal can better keep the advantages of previous community detection results and transfer them to the next task. We conduct the experiments on four real-world networks, including the networks with great or minor changes. Experimental results in the low-similarity datasets demonstrate that higher-order knowledge is more valuable than first-order knowledge when the network changes significantly and keeps the advantage even if handling the high-similarity datasets. Our proposal can also guide other dynamic optimization problems with great changes. ",
    "url": "https://arxiv.org/abs/2211.15043",
    "authors": [
      "Huixin Ma",
      "Kai Wu",
      "Handing Wang",
      "Jing Liu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.15069",
    "title": "FeatureBooster: Boosting Feature Descriptors with a Lightweight Neural  Network",
    "abstract": "We introduce a lightweight network to improve descriptors of keypoints within the same image. The network takes the original descriptors and the geometric properties of keypoints as the input, and uses an MLP-based self-boosting stage and a Transformer-based cross-boosting stage to enhance the descriptors. The enhanced descriptors can be either real-valued or binary ones. We use the proposed network to boost both hand-crafted (ORB, SIFT) and the state-of-the-art learning-based descriptors (SuperPoint, ALIKE) and evaluate them on image matching, visual localization, and structure-from-motion tasks. The results show that our method significantly improves the performance of each task, particularly in challenging cases such as large illumination changes or repetitive patterns. Our method requires only 3.2ms on desktop GPU and 27ms on embedded GPU to process 2000 features, which is fast enough to be applied to a practical system. ",
    "url": "https://arxiv.org/abs/2211.15069",
    "authors": [
      "Xinjiang Wang",
      "Zeyu Liu",
      "Yu Hu",
      "Wei Xi",
      "Wenxian Yu",
      "Danping Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15081",
    "title": "Flip Initial Features: Generalization of Neural Networks for  Semi-supervised Node Classification",
    "abstract": "Graph neural networks (GNNs) have been widely used under semi-supervised settings. Prior studies have mainly focused on finding appropriate graph filters (e.g., aggregation schemes) to generalize well for both homophilic and heterophilic graphs. Even though these approaches are essential and effective, they still suffer from the sparsity in initial node features inherent in the bag-of-words representation. Common in semi-supervised learning where the training samples often fail to cover the entire dimensions of graph filters (hyperplanes), this can precipitate over-fitting of specific dimensions in the first projection matrix. To deal with this problem, we suggest a simple and novel strategy; create additional space by flipping the initial features and hyperplane simultaneously. Training in both the original and in the flip space can provide precise updates of learnable parameters. To the best of our knowledge, this is the first attempt that effectively moderates the overfitting problem in GNN. Extensive experiments on real-world datasets demonstrate that the proposed technique improves the node classification accuracy up to 40.2 % ",
    "url": "https://arxiv.org/abs/2211.15081",
    "authors": [
      "Yoonhyuk Choi",
      "Chong-Kwon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15088",
    "title": "Class Adaptive Network Calibration",
    "abstract": "Recent studies have revealed that, beyond conventional accuracy, calibration should also be considered for training modern deep neural networks. To address miscalibration during learning, some methods have explored different penalty functions as part of the learning objective, alongside a standard classification loss, with a hyper-parameter controlling the relative contribution of each term. Nevertheless, these methods share two major drawbacks: 1) the scalar balancing weight is the same for all classes, hindering the ability to address different intrinsic difficulties or imbalance among classes; and 2) the balancing weight is usually fixed without an adaptive strategy, which may prevent from reaching the best compromise between accuracy and calibration, and requires hyper-parameter search for each application. We propose Class Adaptive Label Smoothing (CALS) for calibrating deep networks, which allows to learn class-wise multipliers during training, yielding a powerful alternative to common label smoothing penalties. Our method builds on a general Augmented Lagrangian approach, a well-established technique in constrained optimization, but we introduce several modifications to tailor it for large-scale, class-adaptive training. Comprehensive evaluation and multiple comparisons on a variety of benchmarks, including standard and long-tailed image classification, semantic segmentation, and text classification, demonstrate the superiority of the proposed method. The code is available at https://github.com/by-liu/CALS. ",
    "url": "https://arxiv.org/abs/2211.15088",
    "authors": [
      "Bingyuan Liu",
      "J\u00e9r\u00f4me Rony",
      "Adrian Galdran",
      "Jose Dolz",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15098",
    "title": "MGFN: Magnitude-Contrastive Glance-and-Focus Network for  Weakly-Supervised Video Anomaly Detection",
    "abstract": "Weakly supervised detection of anomalies in surveillance videos is a challenging task. Going beyond existing works that have deficient capabilities to localize anomalies in long videos, we propose a novel glance and focus network to effectively integrate spatial-temporal information for accurate anomaly detection. In addition, we empirically found that existing approaches that use feature magnitudes to represent the degree of anomalies typically ignore the effects of scene variations, and hence result in sub-optimal performance due to the inconsistency of feature magnitudes across scenes. To address this issue, we propose the Feature Amplification Mechanism and a Magnitude Contrastive Loss to enhance the discriminativeness of feature magnitudes for detecting anomalies. Experimental results on two large-scale benchmarks UCF-Crime and XD-Violence manifest that our method outperforms state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2211.15098",
    "authors": [
      "Yingxian Chen",
      "Zhengzhe Liu",
      "Baoheng Zhang",
      "Wilton Fok",
      "Xiaojuan Qi",
      "Yik-Chung Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15104",
    "title": "Approximate Predictive Control Barrier Functions using Neural Networks:  A Computationally Cheap and Permissive Safety Filter",
    "abstract": "A predictive control barrier function (PCBF) based safety filter allows for verifying arbitrary control inputs with respect to future constraint satisfaction. The approach relies on the solution of two optimization problems computing the minimal constraint relaxations given the current state, and then computing the minimal deviation from a proposed input such that the relaxed constraints are satisfied. This paper presents an approximation procedure that uses a neural network to approximate the optimal value function of the first optimization problem from samples, such that the computation becomes independent of the prediction horizon. It is shown that this approximation guarantees that states converge to a neighborhood of the implicitly defined safe set of the original problem, where system constraints can be satisfied for all times forward. The convergence result relies on a novel class $\\mathcal{K}$ lower bound on the PCBF decrease and depends on the approximation error of the neural network. Lastly, we demonstrate our approach in simulation for an autonomous driving example and show that the proposed approximation leads to a significant decrease in computation time compared to the original approach. ",
    "url": "https://arxiv.org/abs/2211.15104",
    "authors": [
      "Alexandre Didier",
      "Robin C. Jacobs",
      "Jerome Sieber",
      "Kim P. Wabersich",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.15114",
    "title": "LoNe Sampler: Graph node embeddings by coordinated local neighborhood  sampling",
    "abstract": "Local graph neighborhood sampling is a fundamental computational problem that is at the heart of algorithms for node representation learning. Several works have presented algorithms for learning discrete node embeddings where graph nodes are represented by discrete features such as attributes of neighborhood nodes. Discrete embeddings offer several advantages compared to continuous word2vec-like node embeddings: ease of computation, scalability, and interpretability. We present LoNe Sampler, a suite of algorithms for generating discrete node embeddings by Local Neighborhood Sampling, and address two shortcomings of previous work. First, our algorithms have rigorously understood theoretical properties. Second, we show how to generate approximate explicit vector maps that avoid the expensive computation of a Gram matrix for the training of a kernel model. Experiments on benchmark datasets confirm the theoretical findings and demonstrate the advantages of the proposed methods. ",
    "url": "https://arxiv.org/abs/2211.15114",
    "authors": [
      "Konstantin Kutzkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.15115",
    "title": "Generalized Category Discovery with Decoupled Prototypical Network",
    "abstract": "Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model's generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high-level semantics. Furthermore, DPN can learn more discriminative features for both known and novel categories through our proposed Semantic-aware Prototypical Learning (SPL). Besides capturing meaningful semantic information, SPL can also alleviate the noise of hard pseudo labels through semantic-weighted soft assignment. Extensive experiments show that DPN outperforms state-of-the-art models by a large margin on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/Lackel/DPN. ",
    "url": "https://arxiv.org/abs/2211.15115",
    "authors": [
      "Wenbin An",
      "Feng Tian",
      "Qinghua Zheng",
      "Wei Ding",
      "QianYing Wang",
      "Ping Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15120",
    "title": "Improved Representation of Asymmetrical Distances with Interval  Quasimetric Embeddings",
    "abstract": "Asymmetrical distance structures (quasimetrics) are ubiquitous in our lives and are gaining more attention in machine learning applications. Imposing such quasimetric structures in model representations has been shown to improve many tasks, including reinforcement learning (RL) and causal relation learning. In this work, we present four desirable properties in such quasimetric models, and show how prior works fail at them. We propose Interval Quasimetric Embedding (IQE), which is designed to satisfy all four criteria. On three quasimetric learning experiments, IQEs show strong approximation and generalization abilities, leading to better performance and improved efficiency over prior methods. Project Page: https://www.tongzhouwang.info/interval_quasimetric_embedding Quasimetric Learning Code Package: https://www.github.com/quasimetric-learning/torch-quasimetric ",
    "url": "https://arxiv.org/abs/2211.15120",
    "authors": [
      "Tongzhou Wang",
      "Phillip Isola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15133",
    "title": "SI-GAT: A method based on improved Graph Attention Network for sonar  image classification",
    "abstract": "The existing sonar image classification methods based on deep learning are often analyzed in Euclidean space, only considering the local image features. For this reason, this paper presents a sonar classification method based on improved Graph Attention Network (GAT), namely SI-GAT, which is applicable to multiple types imaging sonar. This method quantifies the correlation relationship between nodes based on the joint calculation of color proximity and spatial proximity that represent the sonar characteristics in non-Euclidean space, then the KNN (K-Nearest Neighbor) algorithm is used to determine the neighborhood range and adjacency matrix in the graph attention mechanism, which are jointly considered with the attention coefficient matrix to construct the key part of the SI-GAT. This SI-GAT is superior to several CNN (Convolutional Neural Network) methods based on Euclidean space through validation of real data. ",
    "url": "https://arxiv.org/abs/2211.15133",
    "authors": [
      "Can Lei",
      "Huigang Wang",
      "Juan Lei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15143",
    "title": "Explaining Deep Convolutional Neural Networks for Image Classification  by Evolving Local Interpretable Model-agnostic Explanations",
    "abstract": "Deep convolutional neural networks have proven their effectiveness, and have been acknowledged as the most dominant method for image classification. However, a severe drawback of deep convolutional neural networks is poor explainability. Unfortunately, in many real-world applications, users need to understand the rationale behind the predictions of deep convolutional neural networks when determining whether they should trust the predictions or not. To resolve this issue, a novel genetic algorithm-based method is proposed for the first time to automatically evolve local explanations that can assist users to assess the rationality of the predictions. Furthermore, the proposed method is model-agnostic, i.e., it can be utilised to explain any deep convolutional neural network models. In the experiments, ResNet is used as an example model to be explained, and the ImageNet dataset is selected as the benchmark dataset. DenseNet and MobileNet are further explained to demonstrate the model-agnostic characteristic of the proposed method. The evolved local explanations on four images, randomly selected from ImageNet, are presented, which show that the evolved local explanations are straightforward to be recognised by humans. Moreover, the evolved explanations can explain the predictions of deep convolutional neural networks on all four images very well by successfully capturing meaningful interpretable features of the sample images. Further analysis based on the 30 runs of the experiments exhibits that the evolved local explanations can also improve the probabilities/confidences of the deep convolutional neural network models in making the predictions. The proposed method can obtain local explanations within one minute, which is more than ten times faster than LIME (the state-of-the-art method). ",
    "url": "https://arxiv.org/abs/2211.15143",
    "authors": [
      "Bin Wang",
      "Wenbin Pei",
      "Bing Xue",
      "Mengjie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15155",
    "title": "GraphPNAS: Learning Distribution of Good Neural Architectures via Deep  Graph Generative Models",
    "abstract": "Neural architectures can be naturally viewed as computational graphs. Motivated by this perspective, we, in this paper, study neural architecture search (NAS) through the lens of learning random graph models. In contrast to existing NAS methods which largely focus on searching for a single best architecture, i.e, point estimation, we propose GraphPNAS a deep graph generative model that learns a distribution of well-performing architectures. Relying on graph neural networks (GNNs), our GraphPNAS can better capture topologies of good neural architectures and relations between operators therein. Moreover, our graph generator leads to a learnable probabilistic search method that is more flexible and efficient than the commonly used RNN generator and random search methods. Finally, we learn our generator via an efficient reinforcement learning formulation for NAS. To assess the effectiveness of our GraphPNAS, we conduct extensive experiments on three search spaces, including the challenging RandWire on TinyImageNet, ENAS on CIFAR10, and NAS-Bench-101/201. The complexity of RandWire is significantly larger than other search spaces in the literature. We show that our proposed graph generator consistently outperforms RNN-based one and achieves better or comparable performances than state-of-the-art NAS methods. ",
    "url": "https://arxiv.org/abs/2211.15155",
    "authors": [
      "Muchen Li",
      "Jeffrey Yunfan Liu",
      "Leonid Sigal",
      "Renjie Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15156",
    "title": "Matrix representations of spiking neural P systems: Revisited",
    "abstract": "In the 2010, matrix representation of SN P system without delay was presented while in the case of SN P systems with delay, matrix representation was suggested in the 2017. These representations brought about series of simulation of SN P systems using computer software and hardware technology. In this work, we revisit these representation and provide some observations on the behavior of the computations of SN P systems. The concept of reachability of configuration is considered in both SN P systems with and without delays. A better computation of next configuration is proposed in the case of SN P system with delay. ",
    "url": "https://arxiv.org/abs/2211.15156",
    "authors": [
      "Henry N. Adorna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.15158",
    "title": "Heterogeneous Graph Learning for Multi-modal Medical Data Analysis",
    "abstract": "Routine clinical visits of a patient produce not only image data, but also non-image data containing clinical information regarding the patient, i.e., medical data is multi-modal in nature. Such heterogeneous modalities offer different and complementary perspectives on the same patient, resulting in more accurate clinical decisions when they are properly combined. However, despite its significance, how to effectively fuse the multi-modal medical data into a unified framework has received relatively little attention. In this paper, we propose an effective graph-based framework called HetMed (Heterogeneous Graph Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal medical data. Specifically, we construct a multiplex network that incorporates multiple types of non-image features of patients to capture the complex relationship between patients in a systematic way, which leads to more accurate clinical decisions. Extensive experiments on various real-world datasets demonstrate the superiority and practicality of HetMed. The source code for HetMed is available at https://github.com/Sein-Kim/Multimodal-Medical. ",
    "url": "https://arxiv.org/abs/2211.15158",
    "authors": [
      "Sein Kim",
      "Namkyeong Lee",
      "Junseok Lee",
      "Dongmin Hyun",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15159",
    "title": "Properties of SN P system and its Configuration Graph",
    "abstract": "Several studies have been reported in the literature about SN P system and its variants. Often, the results provide universality of various variants and the classes of languages that these variants generate and recognize. The state of SN P system is its configuration. We refer to our previous result on reachability of configuration as the {\\it Fundamental state equation for SN P system.} This paper provides a preliminary investigation on the behavioral and structural properties of SN P system without delay that depend primarily to this fundamental state equation. Also, we introduce the idea of configuration graph $CG_{\\Pi}$ of an SN P system $\\Pi$ without delay to characterize behavioral properties of $\\Pi$ with respect to $CG_{\\Pi}.$ The matrix $M_{\\Pi}$ of an SN P system $\\Pi$ without delay is used to characterize structural properties of $\\Pi.$ ",
    "url": "https://arxiv.org/abs/2211.15159",
    "authors": [
      "Henry N. Adorna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.15166",
    "title": "Toward Global Sensing Quality Maximization: A Configuration Optimization  Scheme for Camera Networks",
    "abstract": "The performance of a camera network monitoring a set of targets depends crucially on the configuration of the cameras. In this paper, we investigate the reconfiguration strategy for the parameterized camera network model, with which the sensing qualities of the multiple targets can be optimized globally and simultaneously. We first propose to use the number of pixels occupied by a unit-length object in image as a metric of the sensing quality of the object, which is determined by the parameters of the camera, such as intrinsic, extrinsic, and distortional coefficients. Then, we form a single quantity that measures the sensing quality of the targets by the camera network. This quantity further serves as the objective function of our optimization problem to obtain the optimal camera configuration. We verify the effectiveness of our approach through extensive simulations and experiments, and the results reveal its improved performance on the AprilTag detection tasks. Codes and related utilities for this work are open-sourced and available at https://github.com/sszxc/MultiCam-Simulation. ",
    "url": "https://arxiv.org/abs/2211.15166",
    "authors": [
      "Xuechao Zhang",
      "Xuda Ding",
      "Yi Ren",
      "Yu Zheng",
      "Chongrong Fang",
      "Jianping He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.15180",
    "title": "Rethinking the Number of Shots in Robust Model-Agnostic Meta-Learning",
    "abstract": "Robust Model-Agnostic Meta-Learning (MAML) is usually adopted to train a meta-model which may fast adapt to novel classes with only a few exemplars and meanwhile remain robust to adversarial attacks. The conventional solution for robust MAML is to introduce robustness-promoting regularization during meta-training stage. With such a regularization, previous robust MAML methods simply follow the typical MAML practice that the number of training shots should match with the number of test shots to achieve an optimal adaptation performance. However, although the robustness can be largely improved, previous methods sacrifice clean accuracy a lot. In this paper, we observe that introducing robustness-promoting regularization into MAML reduces the intrinsic dimension of clean sample features, which results in a lower capacity of clean representations. This may explain why the clean accuracy of previous robust MAML methods drops severely. Based on this observation, we propose a simple strategy, i.e., increasing the number of training shots, to mitigate the loss of intrinsic dimension caused by robustness-promoting regularization. Though simple, our method remarkably improves the clean accuracy of MAML without much loss of robustness, producing a robust yet accurate model. Extensive experiments demonstrate that our method outperforms prior arts in achieving a better trade-off between accuracy and robustness. Besides, we observe that our method is less sensitive to the number of fine-tuning steps during meta-training, which allows for a reduced number of fine-tuning steps to improve training efficiency. ",
    "url": "https://arxiv.org/abs/2211.15180",
    "authors": [
      "Xiaoyue Duan",
      "Guoliang Kang",
      "Runqi Wang",
      "Shumin Han",
      "Song Xue",
      "Tian Wang",
      "Baochang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15182",
    "title": "Easy Begun is Half Done: Spatial-Temporal Graph Modeling with  ST-Curriculum Dropout",
    "abstract": "Spatial-temporal (ST) graph modeling, such as traffic speed forecasting and taxi demand prediction, is an important task in deep learning area. However, for the nodes in graph, their ST patterns can vary greatly in difficulties for modeling, owning to the heterogeneous nature of ST data. We argue that unveiling the nodes to the model in a meaningful order, from easy to complex, can provide performance improvements over traditional training procedure. The idea has its root in Curriculum Learning which suggests in the early stage of training models can be sensitive to noise and difficult samples. In this paper, we propose ST-Curriculum Dropout, a novel and easy-to-implement strategy for spatial-temporal graph modeling. Specifically, we evaluate the learning difficulty of each node in high-level feature space and drop those difficult ones out to ensure the model only needs to handle fundamental ST relations at the beginning, before gradually moving to hard ones. Our strategy can be applied to any canonical deep learning architecture without extra trainable parameters, and extensive experiments on a wide range of datasets are conducted to illustrate that, by controlling the difficulty level of ST relations as the training progresses, the model is able to capture better representation of the data and thus yields better generalization. ",
    "url": "https://arxiv.org/abs/2211.15182",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Tong Pan",
      "Zipei Fan",
      "Boyuan Zhang",
      "Renhe Jiang",
      "Lingyu Zhang",
      "Yi Xie",
      "Zhongyi Wang",
      "Xuan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2211.15188",
    "title": "Incremental Fourier Neural Operator",
    "abstract": "Recently, neural networks have proven their impressive ability to solve partial differential equations (PDEs). Among them, Fourier neural operator (FNO) has shown success in learning solution operators for highly non-linear problems such as turbulence flow. FNO is discretization-invariant, where it can be trained on low-resolution data and generalizes to problems with high-resolution. This property is related to the low-pass filters in FNO, where only a limited number of frequency modes are selected to propagate information. However, it is still a challenge to select an appropriate number of frequency modes and training resolution for different PDEs. Too few frequency modes and low-resolution data hurt generalization, while too many frequency modes and high-resolution data are computationally expensive and lead to over-fitting. To this end, we propose Incremental Fourier Neural Operator (IFNO), which augments both the frequency modes and data resolution incrementally during training. We show that IFNO achieves better generalization (around 15% reduction on testing L2 loss) while reducing the computational cost by 35%, compared to the standard FNO. In addition, we observe that IFNO follows the behavior of implicit regularization in FNO, which explains its excellent generalization ability. ",
    "url": "https://arxiv.org/abs/2211.15188",
    "authors": [
      "Jiawei Zhao",
      "Robert Joseph George",
      "Yifei Zhang",
      "Zongyi Li",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15196",
    "title": "Forged Image Detection using SOTA Image Classification Deep Learning  Methods for Image Forensics with Error Level Analysis",
    "abstract": "The advancement in the area of computer vision has been brought using deep learning mechanisms. Image Forensics is one of the major areas of computer vision application. Forgery of images is sub-category of image forensics and can be detected using Error Level Analysis. Using such images as an input, this can turn out to be a binary classification problem which can be leveraged using variations of convolutional neural networks. In this paper we perform transfer learning with state-of-the-art image classification models over error level analysis induced CASIA ITDE v.2 dataset. The algorithms used are VGG-19, Inception-V3, ResNet-152-V2, XceptionNet and EfficientNet-V2L with their respective methodologies and results. ",
    "url": "https://arxiv.org/abs/2211.15196",
    "authors": [
      "Raunak Joshi",
      "Abhishek Gupta",
      "Nandan Kanvinde",
      "Pandharinath Ghonge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15197",
    "title": "Metric Learning as a Service with Covariance Embedding",
    "abstract": "With the emergence of deep learning, metric learning has gained significant popularity in numerous machine learning tasks dealing with complex and large-scale datasets, such as information retrieval, object recognition and recommendation systems. Metric learning aims to maximize and minimize inter- and intra-class similarities. However, existing models mainly rely on distance measures to obtain a separable embedding space and implicitly maximize the intra-class similarity while neglecting the inter-class relationship. We argue that to enable metric learning as a service for high-performance deep learning applications, we should also wisely deal with inter-class relationships to obtain a more advanced and meaningful embedding space representation. In this paper, a novel metric learning is presented as a service methodology that incorporates covariance to signify the direction of the linear relationship between data points in an embedding space. Unlike conventional metric learning, our covariance-embedding-enhanced approach enables metric learning as a service to be more expressive for computing similar or dissimilar measures and can capture positive, negative, or neutral relationships. Extensive experiments conducted using various benchmark datasets, including natural, biomedical, and facial images, demonstrate that the proposed model as a service with covariance-embedding optimizations can obtain higher-quality, more separable, and more expressive embedding representations than existing models. ",
    "url": "https://arxiv.org/abs/2211.15197",
    "authors": [
      "Imam Mustafa Kamal",
      "Hyerim Bae",
      "Ling Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15218",
    "title": "Application of the YOLOv5 Model for the Detection of Microobjects in the  Marine Environment",
    "abstract": "The efficiency of using the YOLOV5 machine learning model for solving the problem of automatic de-tection and recognition of micro-objects in the marine environment is studied. Samples of microplankton and microplastics were prepared, according to which a database of classified images was collected for training an image recognition neural network. The results of experiments using a trained network to find micro-objects in photo and video images in real time are presented. Experimental studies have shown high efficiency, comparable to manual recognition, of the proposed model in solving problems of detect-ing micro-objects in the marine environment. ",
    "url": "https://arxiv.org/abs/2211.15218",
    "authors": [
      "Aleksandr N. Grekov",
      "Yurii E. Shishkin",
      "Sergei S. Peliushenko",
      "Aleksandr S. Mavrin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2211.15226",
    "title": "RAMP: A Flat Nanosecond Optical Network and MPI Operations for  Distributed Deep Learning Systems",
    "abstract": "Distributed deep learning (DDL) systems strongly depend on network performance. Current electronic packet switched (EPS) network architectures and technologies suffer from variable diameter topologies, low-bisection bandwidth and over-subscription affecting completion time of communication and collective operations. We introduce a near-exascale, full-bisection bandwidth, all-to-all, single-hop, all-optical network architecture with nanosecond reconfiguration called RAMP, which supports large-scale distributed and parallel computing systems (12.8~Tbps per node for up to 65,536 nodes). For the first time, a custom RAMP-x MPI strategy and a network transcoder is proposed to run MPI collective operations across the optical circuit switched (OCS) network in a schedule-less and contention-less manner. RAMP achieves 7.6-171$\\times$ speed-up in completion time across all MPI operations compared to realistic EPS and OCS counterparts. It can also deliver a 1.3-16$\\times$ and 7.8-58$\\times$ reduction in Megatron and DLRM training time respectively} while offering 42-53$\\times$ and 3.3-12.4$\\times$ improvement in energy consumption and cost respectively. ",
    "url": "https://arxiv.org/abs/2211.15226",
    "authors": [
      "Alessandro Ottino",
      "Joshua Benjamin",
      "Georgios Zervas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.15253",
    "title": "Lipschitz constant estimation for 1D convolutional neural networks",
    "abstract": "In this work, we propose a dissipativity-based method for Lipschitz constant estimation of 1D convolutional neural networks (CNNs). In particular, we analyze the dissipativity properties of convolutional, pooling, and fully connected layers making use of incremental quadratic constraints for nonlinear activation functions and pooling operations. The Lipschitz constant of the concatenation of these mappings is then estimated by solving a semidefinite program which we derive from dissipativity theory. To make our method as efficient as possible, we take the structure of convolutional layers into account realizing these finite impulse response filters as causal dynamical systems in state space and carrying out the dissipativity analysis for the state space realizations. The examples we provide show that our Lipschitz bounds are advantageous in terms of accuracy and scalability. ",
    "url": "https://arxiv.org/abs/2211.15253",
    "authors": [
      "Patricia Pauli",
      "Dennis Gramlich",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.15255",
    "title": "GADMSL: Graph Anomaly Detection on Attributed Networks via Multi-scale  Substructure Learning",
    "abstract": "Recently, graph anomaly detection has attracted increasing attention in data mining and machine learning communities. Apart from existing attribute anomalies, graph anomaly detection also captures suspicious topological-abnormal nodes that differ from the major counterparts. Although massive graph-based detection approaches have been proposed, most of them focus on node-level comparison while pay insufficient attention on the surrounding topology structures. Nodes with more dissimilar neighborhood substructures have more suspicious to be abnormal. To enhance the local substructure detection ability, we propose a novel Graph Anomaly Detection framework via Multi-scale Substructure Learning (GADMSL for abbreviation). Unlike previous algorithms, we manage to capture anomalous substructures where the inner similarities are relatively low in dense-connected regions. Specifically, we adopt a region proposal module to find high-density substructures in the network as suspicious regions. Their inner-node embedding similarities indicate the anomaly degree of the detected substructures. Generally, a lower degree of embedding similarities means a higher probability that the substructure contains topology anomalies. To distill better embeddings of node attributes, we further introduce a graph contrastive learning scheme, which observes attribute anomalies in the meantime. In this way, GADMSL can detect both topology and attribute anomalies. Ultimately, extensive experiments on benchmark datasets show that GADMSL greatly improves detection performance (up to 7.30% AUC and 17.46% AUPRC gains) compared to state-of-the-art attributed networks anomaly detection algorithms. ",
    "url": "https://arxiv.org/abs/2211.15255",
    "authors": [
      "Duan Jingcan",
      "Wang Siwei",
      "Liu Xinwang",
      "Zhou Haifang",
      "Hu Jingtao",
      "Jin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15258",
    "title": "Bayesian Network Models of Causal Interventions in Healthcare Decision  Making: Literature Review and Software Evaluation",
    "abstract": "This report summarises the outcomes of a systematic literature search to identify Bayesian network models used to support decision making in healthcare. After describing the search methodology, the selected research papers are briefly reviewed, with the view to identify publicly available models and datasets that are well suited to analysis using the causal interventional analysis software tool developed in Wang B, Lyle C, Kwiatkowska M (2021). Finally, an experimental evaluation of applying the software on a selection of models is carried out and preliminary results are reported. ",
    "url": "https://arxiv.org/abs/2211.15258",
    "authors": [
      "Artem Velikzhanin",
      "Benjie Wang",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15259",
    "title": "A Call to Reflect on Evaluation Practices for Failure Detection in Image  Classification",
    "abstract": "Reliable application of machine learning-based decision systems in the wild is one of the major challenges currently investigated by the field. A large portion of established approaches aims to detect erroneous predictions by means of assigning confidence scores. This confidence may be obtained by either quantifying the model's predictive uncertainty, learning explicit scoring functions, or assessing whether the input is in line with the training distribution. Curiously, while these approaches all state to address the same eventual goal of detecting failures of a classifier upon real-life application, they currently constitute largely separated research fields with individual evaluation protocols, which either exclude a substantial part of relevant methods or ignore large parts of relevant failure sources. In this work, we systematically reveal current pitfalls caused by these inconsistencies and derive requirements for a holistic and realistic evaluation of failure detection. To demonstrate the relevance of this unified perspective, we present a large-scale empirical study for the first time enabling benchmarking confidence scoring functions w.r.t all relevant methods and failure sources. The revelation of a simple softmax response baseline as the overall best performing method underlines the drastic shortcomings of current evaluation in the abundance of publicized research on confidence scoring. Code and trained models are at https://github.com/IML-DKFZ/fd-shifts. ",
    "url": "https://arxiv.org/abs/2211.15259",
    "authors": [
      "Paul F. Jaeger",
      "Carsten T. L\u00fcth",
      "Lukas Klein",
      "Till J. Bungert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15279",
    "title": "Establishment of Neural Networks Robust to Label Noise",
    "abstract": "Label noise is a significant obstacle in deep learning model training. It can have a considerable impact on the performance of image classification models, particularly deep neural networks, which are especially susceptible because they have a strong propensity to memorise noisy labels. In this paper, we have examined the fundamental concept underlying related label noise approaches. A transition matrix estimator has been created, and its effectiveness against the actual transition matrix has been demonstrated. In addition, we examined the label noise robustness of two convolutional neural network classifiers with LeNet and AlexNet designs. The two FashionMINIST datasets have revealed the robustness of both models. We are not efficiently able to demonstrate the influence of the transition matrix noise correction on robustness enhancements due to our inability to correctly tune the complex convolutional neural network model due to time and computing resource constraints. There is a need for additional effort to fine-tune the neural network model and explore the precision of the estimated transition model in future research. ",
    "url": "https://arxiv.org/abs/2211.15279",
    "authors": [
      "Pengwei Yang",
      "Angel Teng",
      "Jack Mangos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15294",
    "title": "Fairness Scheduling in Dense User-Centric Cell-Free Massive MIMO  Networks",
    "abstract": "We consider a user-centric scalable cell-free massive MIMO network with a total of $LM$ distributed remote radio unit antennas serving $K$ user equipments (UEs). Many works in the current literature assume $LM\\gg K$, enabling high UE data rates but also leading to a system not operating at its maximum performance in terms of sum throughput. We provide a new perspective on cell-free massive MIMO networks, investigating rate allocation and the UE density regime in which the network makes use of its full capability. The UE density $K$ approximately equal to $\\frac{LM}{2}$ is the range in which the system reaches the largest sum throughput. In addition, there is a significant fraction of UEs with relatively low throughput, when serving $K>\\frac{LM}{2}$ UEs simultaneously. We propose to reduce the number of active UEs per time slot, such that the system does not operate at ``full load'', and impose throughput fairness among all users via a scheduler designed to maximize a suitably defined concave componentwise non-decreasing network utility function. Our numerical simulations show that we can tune the system such that a desired distribution of the UE throughput, depending on the utility function, is achieved. ",
    "url": "https://arxiv.org/abs/2211.15294",
    "authors": [
      "Fabian G\u00f6ttsch",
      "Noboru Osawa",
      "Takeo Ohseki",
      "Yoshiaki Amano",
      "Issei Kanno",
      "Kosuke Yamazaki",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.15301",
    "title": "Learning Coherent Clusters in Weakly-Connected Network Systems",
    "abstract": "We propose a structure-preserving model-reduction methodology for large-scale dynamic networks with tightly-connected components. First, the coherent groups are identified by a spectral clustering algorithm on the graph Laplacian matrix that models the network feedback. Then, a reduced network is built, where each node represents the aggregate dynamics of each coherent group, and the reduced network captures the dynamic coupling between the groups. We provide an upper bound on the approximation error when the network graph is randomly generated from a weight stochastic block model. Finally, numerical experiments align with and validate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2211.15301",
    "authors": [
      "Hancheng Min",
      "Enrique Mallada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.15303",
    "title": "Conditional Progressive Generative Adversarial Network for satellite  image generation",
    "abstract": "Image generation and image completion are rapidly evolving fields, thanks to machine learning algorithms that are able to realistically replace missing pixels. However, generating large high resolution images, with a large level of details, presents important computational challenges. In this work, we formulate the image generation task as completion of an image where one out of three corners is missing. We then extend this approach to iteratively build larger images with the same level of detail. Our goal is to obtain a scalable methodology to generate high resolution samples typically found in satellite imagery data sets. We introduce a conditional progressive Generative Adversarial Networks (GAN), that generates the missing tile in an image, using as input three initial adjacent tiles encoded in a latent vector by a Wasserstein auto-encoder. We focus on a set of images used by the United Nations Satellite Centre (UNOSAT) to train flood detection tools, and validate the quality of synthetic images in a realistic setup. ",
    "url": "https://arxiv.org/abs/2211.15303",
    "authors": [
      "Renato Cardoso",
      "Sofia Vallecorsa",
      "Edoardo Nemni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15322",
    "title": "Transductive Kernels for Gaussian Processes on Graphs",
    "abstract": "Kernels on graphs have had limited options for node-level problems. To address this, we present a novel, generalized kernel for graphs with node feature data for semi-supervised learning. The kernel is derived from a regularization framework by treating the graph and feature data as two Hilbert spaces. We also show how numerous kernel-based models on graphs are instances of our design. A kernel defined this way has transductive properties, and this leads to improved ability to learn on fewer training points, as well as better handling of highly non-Euclidean data. We demonstrate these advantages using synthetic data where the distribution of the whole graph can inform the pattern of the labels. Finally, by utilizing a flexible polynomial of the graph Laplacian within the kernel, the model also performed effectively in semi-supervised classification on graphs of various levels of homophily. ",
    "url": "https://arxiv.org/abs/2211.15322",
    "authors": [
      "Yin-Cong Zhi",
      "Felix L. Opolka",
      "Yin Cheng Ng",
      "Pietro Li\u00f2",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.15324",
    "title": "Low-resource Personal Attribute Prediction from Conversation",
    "abstract": "Personal knowledge bases (PKBs) are crucial for a broad range of applications such as personalized recommendation and Web-based chatbots. A critical challenge to build PKBs is extracting personal attribute knowledge from users' conversation data. Given some users of a conversational system, a personal attribute and these users' utterances, our goal is to predict the ranking of the given personal attribute values for each user. Previous studies often rely on a relative number of resources such as labeled utterances and external data, yet the attribute knowledge embedded in unlabeled utterances is underutilized and their performance of predicting some difficult personal attributes is still unsatisfactory. In addition, it is found that some text classification methods could be employed to resolve this task directly. However, they also perform not well over those difficult personal attributes. In this paper, we propose a novel framework PEARL to predict personal attributes from conversations by leveraging the abundant personal attribute knowledge from utterances under a low-resource setting in which no labeled utterances or external data are utilized. PEARL combines the biterm semantic information with the word co-occurrence information seamlessly via employing the updated prior attribute knowledge to refine the biterm topic model's Gibbs sampling process in an iterative manner. The extensive experimental results show that PEARL outperforms all the baseline methods not only on the task of personal attribute prediction from conversations over two data sets, but also on the more general weakly supervised text classification task over one data set. ",
    "url": "https://arxiv.org/abs/2211.15324",
    "authors": [
      "Yinan Liu",
      "Hu Chen",
      "Wei Shen",
      "Jiaoyan Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15334",
    "title": "Beyond S-curves: Recurrent Neural Networks for Technology Forecasting",
    "abstract": "Because of the considerable heterogeneity and complexity of the technological landscape, building accurate models to forecast is a challenging endeavor. Due to their high prevalence in many complex systems, S-curves are a popular forecasting approach in previous work. However, their forecasting performance has not been directly compared to other technology forecasting approaches. Additionally, recent developments in time series forecasting that claim to improve forecasting accuracy are yet to be applied to technological development data. This work addresses both research gaps by comparing the forecasting performance of S-curves to a baseline and by developing an autencoder approach that employs recent advances in machine learning and time series forecasting. S-curves forecasts largely exhibit a mean average percentage error (MAPE) comparable to a simple ARIMA baseline. However, for a minority of emerging technologies, the MAPE increases by two magnitudes. Our autoencoder approach improves the MAPE by 13.5% on average over the second-best result. It forecasts established technologies with the same accuracy as the other approaches. However, it is especially strong at forecasting emerging technologies with a mean MAPE 18% lower than the next best result. Our results imply that a simple ARIMA model is preferable over the S-curve for technology forecasting. Practitioners looking for more accurate forecasts should opt for the presented autoencoder approach. ",
    "url": "https://arxiv.org/abs/2211.15334",
    "authors": [
      "Alexander Glavackij",
      "Dimitri Percia David",
      "Alain Mermoud",
      "Angelika Romanou",
      "Karl Aberer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15335",
    "title": "You Can Have Better Graph Neural Networks by Not Training Weights at  All: Finding Untrained GNNs Tickets",
    "abstract": "Recent works have impressively demonstrated that there exists a subnetwork in randomly initialized convolutional neural networks (CNNs) that can match the performance of the fully trained dense networks at initialization, without any optimization of the weights of the network (i.e., untrained networks). However, the presence of such untrained subnetworks in graph neural networks (GNNs) still remains mysterious. In this paper we carry out the first-of-its-kind exploration of discovering matching untrained GNNs. With sparsity as the core tool, we can find \\textit{untrained sparse subnetworks} at the initialization, that can match the performance of \\textit{fully trained dense} GNNs. Besides this already encouraging finding of comparable performance, we show that the found untrained subnetworks can substantially mitigate the GNN over-smoothing problem, hence becoming a powerful tool to enable deeper GNNs without bells and whistles. We also observe that such sparse untrained subnetworks have appealing performance in out-of-distribution detection and robustness of input perturbations. We evaluate our method across widely-used GNN architectures on various popular datasets including the Open Graph Benchmark (OGB). ",
    "url": "https://arxiv.org/abs/2211.15335",
    "authors": [
      "Tianjin Huang",
      "Tianlong Chen",
      "Meng Fang",
      "Vlado Menkovski",
      "Jiaxu Zhao",
      "Lu Yin",
      "Yulong Pei",
      "Decebal Constantin Mocanu",
      "Zhangyang Wang",
      "Mykola Pechenizkiy",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15338",
    "title": "Learning Integrable Dynamics with Action-Angle Networks",
    "abstract": "Machine learning has become increasingly popular for efficiently modelling the dynamics of complex physical systems, demonstrating a capability to learn effective models for dynamics which ignore redundant degrees of freedom. Learned simulators typically predict the evolution of the system in a step-by-step manner with numerical integration techniques. However, such models often suffer from instability over long roll-outs due to the accumulation of both estimation and integration error at each prediction step. Here, we propose an alternative construction for learned physical simulators that are inspired by the concept of action-angle coordinates from classical mechanics for describing integrable systems. We propose Action-Angle Networks, which learn a nonlinear transformation from input coordinates to the action-angle space, where evolution of the system is linear. Unlike traditional learned simulators, Action-Angle Networks do not employ any higher-order numerical integration methods, making them extremely efficient at modelling the dynamics of integrable physical systems. ",
    "url": "https://arxiv.org/abs/2211.15338",
    "authors": [
      "Ameya Daigavane",
      "Arthur Kosmala",
      "Miles Cranmer",
      "Tess Smidt",
      "Shirley Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.15352",
    "title": "Interactive Image Manipulation with Complex Text Instructions",
    "abstract": "Recently, text-guided image manipulation has received increasing attention in the research field of multimedia processing and computer vision due to its high flexibility and controllability. Its goal is to semantically manipulate parts of an input reference image according to the text descriptions. However, most of the existing works have the following problems: (1) text-irrelevant content cannot always be maintained but randomly changed, (2) the performance of image manipulation still needs to be further improved, (3) only can manipulate descriptive attributes. To solve these problems, we propose a novel image manipulation method that interactively edits an image using complex text instructions. It allows users to not only improve the accuracy of image manipulation but also achieve complex tasks such as enlarging, dwindling, or removing objects and replacing the background with the input image. To make these tasks possible, we apply three strategies. First, the given image is divided into text-relevant content and text-irrelevant content. Only the text-relevant content is manipulated and the text-irrelevant content can be maintained. Second, a super-resolution method is used to enlarge the manipulation region to further improve the operability and to help manipulate the object itself. Third, a user interface is introduced for editing the segmentation map interactively to re-modify the generated image according to the user's desires. Extensive experiments on the Caltech-UCSD Birds-200-2011 (CUB) dataset and Microsoft Common Objects in Context (MS COCO) datasets demonstrate our proposed method can enable interactive, flexible, and accurate image manipulation in real-time. Through qualitative and quantitative evaluations, we show that the proposed model outperforms other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2211.15352",
    "authors": [
      "Ryugo Morita",
      "Zhiqiang Zhang",
      "Man M. Ho",
      "Jinjia Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15353",
    "title": "Copula Density Neural Estimation",
    "abstract": "Probability density estimation from observed data constitutes a central task in statistics. Recent advancements in machine learning offer new tools but also pose new challenges. The big data era demands analysis of long-range spatial and long-term temporal dependencies in large collections of raw data, rendering neural networks an attractive solution for density estimation. In this paper, we exploit the concept of copula to explicitly build an estimate of the probability density function associated to any observed data. In particular, we separate univariate marginal distributions from the joint dependence structure in the data, the copula itself, and we model the latter with a neural network-based method referred to as copula density neural estimation (CODINE). Results show that the novel learning approach is capable of modeling complex distributions and it can be applied for mutual information estimation and data generation. ",
    "url": "https://arxiv.org/abs/2211.15353",
    "authors": [
      "Nunzio A. Letizia",
      "Andrea M. Tonello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.15355",
    "title": "Causal Deep Reinforcement Learning using Observational Data",
    "abstract": "Deep reinforcement learning (DRL) requires the collection of plenty of interventional data, which is sometimes expensive and even unethical in the real world, such as in the autonomous driving and the medical field. Offline reinforcement learning promises to alleviate this issue by exploiting the vast amount of observational data available in the real world. However, observational data may mislead the learning agent to undesirable outcomes if the behavior policy that generates the data depends on unobserved random variables (i.e., confounders). In this paper, we propose two deconfounding methods in DRL to address this problem. The methods first calculate the importance degree of different samples based on the causal inference technique, and then adjust the impact of different samples on the loss function by reweighting or resampling the offline dataset to ensure its unbiasedness. These deconfounding methods can be flexibly combined with the existing model-free DRL algorithms such as soft actor-critic and deep Q-learning, provided that a weak condition can be satisfied by the loss functions of these algorithms. We prove the effectiveness of our deconfounding methods and validate them experimentally. ",
    "url": "https://arxiv.org/abs/2211.15355",
    "authors": [
      "Wenxuan Zhu",
      "Chao Yu",
      "Qiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.15382",
    "title": "Neural Network Complexity of Chaos and Turbulence",
    "abstract": "We study the complexity of chaos and turbulence as viewed by deep neural networks by considering network classification tasks of distinguishing turbulent from chaotic fluid flows, noise and real world images of cats or dogs. We analyze the relative difficulty of these classification tasks and quantify the complexity of the computation at the intermediate and final stages. We analyze incompressible as well as weakly compressible fluid flows and provide evidence for the feature identified by the neural network to distinguish turbulence from chaos. ",
    "url": "https://arxiv.org/abs/2211.15382",
    "authors": [
      "Tim Whittaker",
      "Romuald A. Janik",
      "Yaron Oz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Chaotic Dynamics (nlin.CD)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2211.15386",
    "title": "PC-SNN: Supervised Learning with Local Hebbian Synaptic Plasticity based  on Predictive Coding in Spiking Neural Networks",
    "abstract": "Deemed as the third generation of neural networks, the event-driven Spiking Neural Networks(SNNs) combined with bio-plausible local learning rules make it promising to build low-power, neuromorphic hardware for SNNs. However, because of the non-linearity and discrete property of spiking neural networks, the training of SNN remains difficult and is still under discussion. Originating from gradient descent, backprop has achieved stunning success in multi-layer SNNs. Nevertheless, it is assumed to lack biological plausibility, while consuming relatively high computational resources. In this paper, we propose a novel learning algorithm inspired by predictive coding theory and show that it can perform supervised learning fully autonomously and successfully as the backprop, utilizing only local Hebbian plasticity. Furthermore, this method achieves a favorable performance compared to the state-of-the-art multi-layer SNNs: test accuracy of 99.25% for the Caltech Face/Motorbike dataset, 84.25% for the ETH-80 dataset, 98.1% for the MNIST dataset and 98.5% for the neuromorphic dataset: N-MNIST. Furthermore, our work provides a new perspective on how supervised learning algorithms are directly implemented in spiking neural circuitry, which may give some new insights into neuromorphological calculation in neuroscience. ",
    "url": "https://arxiv.org/abs/2211.15386",
    "authors": [
      "Mengting Lan",
      "Xiaogang Xiong",
      "Zixuan Jiang",
      "Yunjiang Lou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.15387",
    "title": "AIREPAIR: A Repair Platform for Neural Networks",
    "abstract": "We present AIREPAIR, a platform for repairing neural networks. It features the integration of existing network repair tools. Based on AIREPAIR, one can run different repair methods on the same model, thus enabling the fair comparison of different repair techniques. We evaluate AIREPAIR with three state-of-the-art repair tools on popular deep-learning datasets and models. Our evaluation confirms the utility of AIREPAIR, by comparing and analyzing the results from different repair techniques. A demonstration is available at https://youtu.be/UkKw5neeWhw. ",
    "url": "https://arxiv.org/abs/2211.15387",
    "authors": [
      "Xidan Song",
      "Youcheng Sun",
      "Mustafa A. Mustafa",
      "Lucas Cordeiro"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15395",
    "title": "CodeExp: Explanatory Code Document Generation",
    "abstract": "Developing models that can automatically generate detailed code explanation can greatly benefit software maintenance and programming education. However, existing code-to-text generation models often produce only high-level summaries of code that do not capture implementation-level choices essential for these scenarios. To fill in this gap, we propose the code explanation generation task. We first conducted a human study to identify the criteria for high-quality explanatory docstring for code. Based on that, we collected and refined a large-scale code docstring corpus and formulated automatic evaluation metrics that best match human assessments. Finally, we present a multi-stage fine-tuning strategy and baseline models for the task. Our experiments show that (1) our refined training dataset lets models achieve better performance in the explanation generation tasks compared to larger unrefined data (15x larger), and (2) fine-tuned models can generate well-structured long docstrings comparable to human-written ones. We envision our training dataset, human-evaluation protocol, recommended metrics, and fine-tuning strategy can boost future code explanation research. The code and annotated data are available at https://github.com/subercui/CodeExp. ",
    "url": "https://arxiv.org/abs/2211.15395",
    "authors": [
      "Haotian Cui",
      "Chenglong Wang",
      "Junjie Huang",
      "Jeevana Priya Inala",
      "Todd Mytkowicz",
      "Bo Wang",
      "Jianfeng Gao",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15402",
    "title": "Perceive, Ground, Reason, and Act: A Benchmark for General-purpose  Visual Representation",
    "abstract": "Current computer vision models, unlike the human visual system, cannot yet achieve general-purpose visual understanding. Existing efforts to create a general vision model are limited in the scope of assessed tasks and offer no overarching framework to perform them holistically. We present a new comprehensive benchmark, General-purpose Visual Understanding Evaluation (G-VUE), covering the full spectrum of visual cognitive abilities with four functional domains $\\unicode{x2014}$ Perceive, Ground, Reason, and Act. The four domains are embodied in 11 carefully curated tasks, from 3D reconstruction to visual reasoning and manipulation. Along with the benchmark, we provide a general encoder-decoder framework to allow for the evaluation of arbitrary visual representation on all 11 tasks. We evaluate various pre-trained visual representations with our framework and observe that (1) Transformer-based visual backbone generally outperforms CNN-based backbone on G-VUE, (2) visual representations from vision-language pre-training are superior to those with vision-only pre-training across visual tasks. With G-VUE, we provide a holistic evaluation standard to motivate research toward building general-purpose visual systems via obtaining more general-purpose visual representations. ",
    "url": "https://arxiv.org/abs/2211.15402",
    "authors": [
      "Jiangyong Huang",
      "William Yicheng Zhu",
      "Baoxiong Jia",
      "Zan Wang",
      "Xiaojian Ma",
      "Qing Li",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15404",
    "title": "Modern DDoS Attacks and Defences -- Survey",
    "abstract": "Denial of Service (DoS) and Distributed Denial of Service of Service (DDoS) attacks are commonly used to disrupt network services. Attack techniques are always improving and due to the structure of the internet and properties of network protocols it is difficult to keep detection and mitigation techniques up to date. A lot of research has been conducted in this area which has demonstrated the difficulty of preventing DDoS attacks altogether, therefore the primary aim of most research is to maximize quality of service (QoS) for legitimate users. This survey paper aims to provide a clear summary of DDoS attacks and focuses on some recently proposed techniques for defence. The research papers that are analysed in depth primarily focused on the use of virtual machines (VMs) (HoneyMesh) and network function virtualization (NFV) (VGuard and VFence). ",
    "url": "https://arxiv.org/abs/2211.15404",
    "authors": [
      "Jonah Burgess"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.15406",
    "title": "Automated Detection of Dolphin Whistles with Convolutional Networks and  Transfer Learning",
    "abstract": "Effective conservation of maritime environments and wildlife management of endangered species require the implementation of efficient, accurate and scalable solutions for environmental monitoring. Ecoacoustics offers the advantages of non-invasive, long-duration sampling of environmental sounds and has the potential to become the reference tool for biodiversity surveying. However, the analysis and interpretation of acoustic data is a time-consuming process that often requires a great amount of human supervision. This issue might be tackled by exploiting modern techniques for automatic audio signal analysis, which have recently achieved impressive performance thanks to the advances in deep learning research. In this paper we show that convolutional neural networks can indeed significantly outperform traditional automatic methods in a challenging detection task: identification of dolphin whistles from underwater audio recordings. The proposed system can detect signals even in the presence of ambient noise, at the same time consistently reducing the likelihood of producing false positives and false negatives. Our results further support the adoption of artificial intelligence technology to improve the automatic monitoring of marine ecosystems. ",
    "url": "https://arxiv.org/abs/2211.15406",
    "authors": [
      "Burla Nur Korkmaz",
      "Roee Diamant",
      "Gil Danino",
      "Alberto Testolin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.15407",
    "title": "Fine-tuned Sentiment Analysis of COVID-19 Vaccine-Related Social Media  Data: Comparative Study",
    "abstract": "This study investigated and compared public sentiment related to COVID-19 vaccines expressed on two popular social media platforms, Reddit and Twitter, harvested from January 1, 2020, to March 1, 2022. To accomplish this task, we created a fine-tuned DistilRoBERTa model to predict sentiments of approximately 9.5 million Tweets and 70 thousand Reddit comments. To fine-tune our model, our team manually labeled the sentiment of 3600 Tweets and then augmented our dataset by the method of back-translation. Text sentiment for each social media platform was then classified with our fine-tuned model using Python and the Huggingface sentiment analysis pipeline. Our results determined that the average sentiment expressed on Twitter was more negative (52% positive) than positive and the sentiment expressed on Reddit was more positive than negative (53% positive). Though average sentiment was found to vary between these social media platforms, both displayed similar behavior related to sentiment shared at key vaccine-related developments during the pandemic. Considering this similar trend in shared sentiment demonstrated across social media platforms, Twitter and Reddit continue to be valuable data sources that public health officials can utilize to strengthen vaccine confidence and combat misinformation. As the spread of misinformation poses a range of psychological and psychosocial risks (anxiety, fear, etc.), there is an urgency in understanding the public perspective and attitude toward shared falsities. Comprehensive educational delivery systems tailored to the population's expressed sentiments that facilitate digital literacy, health information-seeking behavior, and precision health promotion could aid in clarifying such misinformation. ",
    "url": "https://arxiv.org/abs/2211.15407",
    "authors": [
      "Chad A Melton",
      "Brianna M White",
      "Robert L Davis",
      "Robert A Bednarczyk",
      "Arash Shaban-Nejad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.15416",
    "title": "Development of a Neural Network-Based Mathematical Operation Protocol  for Embedded Hexadecimal Digits Using Neural Architecture Search (NAS)",
    "abstract": "It is beneficial to develop an efficient machine-learning based method for addition using embedded hexadecimal digits. Through a comparison between human-developed machine learning model and models sampled through Neural Architecture Search (NAS) we determine an efficient approach to solve this problem with a final testing loss of 0.2937 for a human-developed model. ",
    "url": "https://arxiv.org/abs/2211.15416",
    "authors": [
      "Victor Robila",
      "Kexin Pei",
      "Junfeng Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15421",
    "title": "A Benchmark for Structured Extractions from Complex Documents",
    "abstract": "Understanding visually-rich business documents to extract structured data and automate business workflows has been receiving attention both in academia and industry. Although recent multi-modal language models have achieved impressive results, we find that existing benchmarks do not reflect the complexity of real documents seen in industry. In this work, we identify the desiderata for a more comprehensive benchmark and propose one we call Visually Rich Document Understanding (VRDU). VRDU contains two datasets that represent several challenges: rich schema including diverse data types as well as nested entities, complex templates including tables and multi-column layouts, and diversity of different layouts (templates) within a single document type. We design few-shot and conventional experiment settings along with a carefully designed matching algorithm to evaluate extraction results. We report the performance of strong baselines and three observations: (1) generalizing to new document templates is very challenging, (2) few-shot performance has a lot of headroom, and (3) models struggle with nested fields such as line-items in an invoice. We plan to open source the benchmark and the evaluation toolkit. We hope this helps the community make progress on these challenging tasks in extracting structured data from visually rich documents. ",
    "url": "https://arxiv.org/abs/2211.15421",
    "authors": [
      "Zilong Wang",
      "Yichao Zhou",
      "Wei Wei",
      "Chen-Yu Lee",
      "Sandeep Tata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15424",
    "title": "DeepParliament: A Legal domain Benchmark & Dataset for Parliament Bills  Prediction",
    "abstract": "This paper introduces DeepParliament, a legal domain Benchmark Dataset that gathers bill documents and metadata and performs various bill status classification tasks. The proposed dataset text covers a broad range of bills from 1986 to the present and contains richer information on parliament bill content. Data collection, detailed statistics and analyses are provided in the paper. Moreover, we experimented with different types of models ranging from RNN to pretrained and reported the results. We are proposing two new benchmarks: Binary and Multi-Class Bill Status classification. Models developed for bill documents and relevant supportive tasks may assist Members of Parliament (MPs), presidents, and other legal practitioners. It will help review or prioritise bills, thus speeding up the billing process, improving the quality of decisions and reducing the time consumption in both houses. Considering that the foundation of the country's democracy is Parliament and state legislatures, we anticipate that our research will be an essential addition to the Legal NLP community. This work will be the first to present a Parliament bill prediction task. In order to improve the accessibility of legal AI resources and promote reproducibility, we have made our code and dataset publicly accessible at github.com/monk1337/DeepParliament ",
    "url": "https://arxiv.org/abs/2211.15424",
    "authors": [
      "Ankit Pal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15429",
    "title": "Detecting Methane Plumes using PRISMA: Deep Learning Model and Data  Augmentation",
    "abstract": "The new generation of hyperspectral imagers, such as PRISMA, has improved significantly our detection capability of methane (CH4) plumes from space at high spatial resolution (30m). We present here a complete framework to identify CH4 plumes using images from the PRISMA satellite mission and a deep learning model able to detect plumes over large areas. To compensate for the relative scarcity of PRISMA images, we trained our model by transposing high resolution plumes from Sentinel-2 to PRISMA. Our methodology thus avoids computationally expensive synthetic plume generation from Large Eddy Simulations by generating a broad and realistic training database, and paves the way for large-scale detection of methane plumes using future hyperspectral sensors (EnMAP, EMIT, CarbonMapper). ",
    "url": "https://arxiv.org/abs/2211.15429",
    "authors": [
      "Alexis Groshenry",
      "Clement Giron",
      "Thomas Lauvaux",
      "Alexandre d'Aspremont",
      "Thibaud Ehret"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15436",
    "title": "Context-Adaptive Deep Neural Networks via Bridge-Mode Connectivity",
    "abstract": "The deployment of machine learning models in safety-critical applications comes with the expectation that such models will perform well over a range of contexts (e.g., a vision model for classifying street signs should work in rural, city, and highway settings under varying lighting/weather conditions). However, these one-size-fits-all models are typically optimized for average case performance, encouraging them to achieve high performance in nominal conditions but exposing them to unexpected behavior in challenging or rare contexts. To address this concern, we develop a new method for training context-dependent models. We extend Bridge-Mode Connectivity (BMC) (Garipov et al., 2018) to train an infinite ensemble of models over a continuous measure of context such that we can sample model parameters specifically tuned to the corresponding evaluation context. We explore the definition of context in image classification tasks through multiple lenses including changes in the risk profile, long-tail image statistics/appearance, and context-dependent distribution shift. We develop novel extensions of the BMC optimization for each of these cases and our experiments demonstrate that model performance can be successfully tuned to context in each scenario. ",
    "url": "https://arxiv.org/abs/2211.15436",
    "authors": [
      "Nathan Drenkow",
      "Alvin Tan",
      "Chace Ashcraft",
      "Kiran Karra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15443",
    "title": "Replacing Automatic Differentiation by Sobolev Cubatures fastens Physics  Informed Neural Nets and strengthens their Approximation Power",
    "abstract": "We present a novel class of approximations for variational losses, being applicable for the training of physics-informed neural nets (PINNs). The loss formulation reflects classic Sobolev space theory for partial differential equations and their weak formulations. The loss computation rests on an extension of Gauss-Legendre cubatures, we term Sobolev cubatures, replacing automatic differentiation (A.D.). We prove the runtime complexity of training the resulting Soblev-PINNs (SC-PINNs) to be less than required by PINNs relying on A.D. On top of one-to-two order of magnitude speed-up the SC-PINNs are demonstrated to achieve closer solution approximations for prominent forward and inverse PDE problems than established PINNs achieve. ",
    "url": "https://arxiv.org/abs/2211.15443",
    "authors": [
      "Juan Esteban Suarez Cardona",
      "Michael Hecht"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15444",
    "title": "DAMO-YOLO : A Report on Real-Time Object Detection Design",
    "abstract": "In this report, we present a fast and accurate object detection method dubbed DAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO series. DAMO-YOLO is extended from YOLO with some new technologies, including Neural Architecture Search (NAS), efficient Reparameterized Generalized-FPN (RepGFPN), a lightweight head with AlignedOTA label assignment, and distillation enhancement. In particular, we use MAE-NAS, a method guided by the principle of maximum entropy, to search our detection backbone under the constraints of low latency and high performance, producing ResNet-like / CSP-like structures with spatial pyramid pooling and focus modules. In the design of necks and heads, we follow the rule of \"large neck, small head\". We import Generalized-FPN with accelerated queen-fusion to build the detector neck and upgrade its CSPNet with efficient layer aggregation networks (ELAN) and reparameterization. Then we investigate how detector head size affects detection performance and find that a heavy neck with only one task projection layer would yield better results. In addition, AlignedOTA is proposed to solve the misalignment problem in label assignment. And a distillation schema is introduced to improve performance to a higher level. Based on these new techs, we build a suite of models at various scales to meet the needs of different scenarios, i.e., DAMO-YOLO-Tiny/Small/Medium. They can achieve 43.0/46.8/50.0 mAPs on COCO with the latency of 2.78/3.83/5.62 ms on T4 GPUs respectively. The code is available at https://github.com/tinyvision/damo-yolo. ",
    "url": "https://arxiv.org/abs/2211.15444",
    "authors": [
      "Xianzhe Xu",
      "Yiqi Jiang",
      "Weihua Chen",
      "Yilun Huang",
      "Yuan Zhang",
      "Xiuyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15474",
    "title": "Unsupervised Superpixel Generation using Edge-Sparse Embedding",
    "abstract": "Partitioning an image into superpixels based on the similarity of pixels with respect to features such as colour or spatial location can significantly reduce data complexity and improve subsequent image processing tasks. Initial algorithms for unsupervised superpixel generation solely relied on local cues without prioritizing significant edges over arbitrary ones. On the other hand, more recent methods based on unsupervised deep learning either fail to properly address the trade-off between superpixel edge adherence and compactness or lack control over the generated number of superpixels. By using random images with strong spatial correlation as input, \\ie, blurred noise images, in a non-convolutional image decoder we can reduce the expected number of contrasts and enforce smooth, connected edges in the reconstructed image. We generate edge-sparse pixel embeddings by encoding additional spatial information into the piece-wise smooth activation maps from the decoder's last hidden layer and use a standard clustering algorithm to extract high quality superpixels. Our proposed method reaches state-of-the-art performance on the BSDS500, PASCAL-Context and a microscopy dataset. ",
    "url": "https://arxiv.org/abs/2211.15474",
    "authors": [
      "Jakob Geusen",
      "Gustav Bredell",
      "Tianfei Zhou",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15478",
    "title": "EVNet: An Explainable Deep Network for Dimension Reduction",
    "abstract": "Dimension reduction (DR) is commonly utilized to capture the intrinsic structure and transform high-dimensional data into low-dimensional space while retaining meaningful properties of the original data. It is used in various applications, such as image recognition, single-cell sequencing analysis, and biomarker discovery. However, contemporary parametric-free and parametric DR techniques suffer from several significant shortcomings, such as the inability to preserve global and local features and the pool generalization performance. On the other hand, regarding explainability, it is crucial to comprehend the embedding process, especially the contribution of each part to the embedding process, while understanding how each feature affects the embedding results that identify critical components and help diagnose the embedding process. To address these problems, we have developed a deep neural network method called EVNet, which provides not only excellent performance in structural maintainability but also explainability to the DR therein. EVNet starts with data augmentation and a manifold-based loss function to improve embedding performance. The explanation is based on saliency maps and aims to examine the trained EVNet parameters and contributions of components during the embedding process. The proposed techniques are integrated with a visual interface to help the user to adjust EVNet to achieve better DR performance and explainability. The interactive visual interface makes it easier to illustrate the data features, compare different DR techniques, and investigate DR. An in-depth experimental comparison shows that EVNet consistently outperforms the state-of-the-art methods in both performance measures and explainability. ",
    "url": "https://arxiv.org/abs/2211.15478",
    "authors": [
      "Zelin Zang",
      "Shenghui Cheng",
      "Linyan Lu",
      "Hanchen Xia",
      "Liangyu Li",
      "Yaoting Sun",
      "Yongjie Xu",
      "Lei Shang",
      "Baigui Sun",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15479",
    "title": "Object Detection in Aerial Imagery",
    "abstract": "Object detection in natural images has achieved remarkable results over the years. However, a similar progress has not yet been observed in aerial object detection due to several challenges, such as high resolution images, instances scale variation, class imbalance etc. We show the performance of two-stage, one-stage and attention based object detectors on the iSAID dataset. Furthermore, we describe some modifications and analysis performed for different models - a) In two stage detector: introduced weighted attention based FPN, class balanced sampler and density prediction head. b) In one stage detector: used weighted focal loss and introduced FPN. c) In attention based detector: compare single,multi-scale attention and demonstrate effect of different backbones. Finally, we show a comparative study highlighting the pros and cons of different models in aerial imagery setting. ",
    "url": "https://arxiv.org/abs/2211.15479",
    "authors": [
      "Dmitry Demidov",
      "Rushali Grandhe",
      "Salem AlMarri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15504",
    "title": "Semantic Table Detection with LayoutLMv3",
    "abstract": "This paper presents an application of the LayoutLMv3 model for semantic table detection on financial documents from the IIIT-AR-13K dataset. The motivation behind this paper's experiment was that LayoutLMv3's official paper had no results for table detection using semantic information. We concluded that our approach did not improve the model's table detection capabilities, for which we can give several possible reasons. Either the model's weights were unsuitable for our purpose, or we needed to invest more time in optimising the model's hyperparameters. It is also possible that semantic information does not improve a model's table detection accuracy. ",
    "url": "https://arxiv.org/abs/2211.15504",
    "authors": [
      "Ivan Silajev",
      "Niels Victor",
      "Phillip Mortimer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.15505",
    "title": "Object Permanence in Object Detection Leveraging Temporal Priors at  Inference Time",
    "abstract": "Object permanence is the concept that objects do not suddenly disappear in the physical world. Humans understand this concept at young ages and know that another person is still there, even though it is temporarily occluded. Neural networks currently often struggle with this challenge. Thus, we introduce explicit object permanence into two stage detection approaches drawing inspiration from particle filters. At the core, our detector uses the predictions of previous frames as additional proposals for the current one at inference time. Experiments confirm the feedback loop improving detection performance by a up to 10.3 mAP with little computational overhead. Our approach is suited to extend two-stage detectors for stabilized and reliable detections even under heavy occlusion. Additionally, the ability to apply our method without retraining an existing model promises wide application in real-world tasks. ",
    "url": "https://arxiv.org/abs/2211.15505",
    "authors": [
      "Michael F\u00fcrst",
      "Priyash Bhugra",
      "Ren\u00e9 Schuster",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15508",
    "title": "Self Supervised Clustering of Traffic Scenes using Graph Representations",
    "abstract": "Examining graphs for similarity is a well-known challenge, but one that is mandatory for grouping graphs together. We present a data-driven method to cluster traffic scenes that is self-supervised, i.e. without manual labelling. We leverage the semantic scene graph model to create a generic graph embedding of the traffic scene, which is then mapped to a low-dimensional embedding space using a Siamese network, in which clustering is performed. In the training process of our novel approach, we augment existing traffic scenes in the Cartesian space to generate positive similarity samples. This allows us to overcome the challenge of reconstructing a graph and at the same time obtain a representation to describe the similarity of traffic scenes. We could show, that the resulting clusters possess common semantic characteristics. The approach was evaluated on the INTERACTION dataset. ",
    "url": "https://arxiv.org/abs/2211.15508",
    "authors": [
      "Maximilian Zipfl",
      "Moritz Jarosch",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.15513",
    "title": "Composite Score for Anomaly Detection in Imbalanced Real-World  Industrial Dataset",
    "abstract": "In recent years, the industrial sector has evolved towards its fourth revolution. The quality control domain is particularly interested in advanced machine learning for computer vision anomaly detection. Nevertheless, several challenges have to be faced, including imbalanced datasets, the image complexity, and the zero-false-negative (ZFN) constraint to guarantee the high-quality requirement. This paper illustrates a use case for an industrial partner, where Printed Circuit Board Assembly (PCBA) images are first reconstructed with a Vector Quantized Generative Adversarial Network (VQGAN) trained on normal products. Then, several multi-level metrics are extracted on a few normal and abnormal images, highlighting anomalies through reconstruction differences. Finally, a classifer is trained to build a composite anomaly score thanks to the metrics extracted. This three-step approach is performed on the public MVTec-AD datasets and on the partner PCBA dataset, where it achieves a regular accuracy of 95.69% and 87.93% under the ZFN constraint. ",
    "url": "https://arxiv.org/abs/2211.15513",
    "authors": [
      "Arnaud Bougaham",
      "Mohammed El Adoui",
      "Isabelle Linden",
      "Beno\u00eet Fr\u00e9nay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15516",
    "title": "DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and  Grounding",
    "abstract": "In this paper, we study the problem of visual grounding by considering both phrase extraction and grounding (PEG). In contrast to the previous phrase-known-at-test setting, PEG requires a model to extract phrases from text and locate objects from images simultaneously, which is a more practical setting in real applications. As phrase extraction can be regarded as a $1$D text segmentation problem, we formulate PEG as a dual detection problem and propose a novel DQ-DETR model, which introduces dual queries to probe different features from image and text for object prediction and phrase mask prediction. Each pair of dual queries is designed to have shared positional parts but different content parts. Such a design effectively alleviates the difficulty of modality alignment between image and text (in contrast to a single query design) and empowers Transformer decoder to leverage phrase mask-guided attention to improve performance. To evaluate the performance of PEG, we also propose a new metric CMAP (cross-modal average precision), analogous to the AP metric in object detection. The new metric overcomes the ambiguity of Recall@1 in many-box-to-one-phrase cases in phrase grounding. As a result, our PEG pre-trained DQ-DETR establishes new state-of-the-art results on all visual grounding benchmarks with a ResNet-101 backbone. For example, it achieves $91.04\\%$ and $83.51\\%$ in terms of recall rate on RefCOCO testA and testB with a ResNet-101 backbone. Code will be availabl at \\url{https://github.com/IDEA-Research/DQ-DETR}. ",
    "url": "https://arxiv.org/abs/2211.15516",
    "authors": [
      "Shilong Liu",
      "Yaoyuan Liang",
      "Feng Li",
      "Shijia Huang",
      "Hao Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15525",
    "title": "Multi-User Privacy Mechanism Design with Non-zero Leakage",
    "abstract": "A privacy mechanism design problem is studied through the lens of information theory. In this work, an agent observes useful data $Y=(Y_1,...,Y_N)$ that is correlated with private data $X=(X_1,...,X_N)$ which is assumed to be also accessible by the agent. Here, we consider $K$ users where user $i$ demands a sub-vector of $Y$, denoted by $C_{i}$. The agent wishes to disclose $C_{i}$ to user $i$. Since $C_{i}$ is correlated with $X$ it can not be disclosed directly. A privacy mechanism is designed to generate disclosed data $U$ which maximizes a linear combinations of the users utilities while satisfying a bounded privacy constraint in terms of mutual information. In a similar work it has been assumed that $X_i$ is a deterministic function of $Y_i$, however in this work we let $X_i$ and $Y_i$ be arbitrarily correlated. First, an upper bound on the privacy-utility trade-off is obtained by using a specific transformation, Functional Representation Lemma and Strong Functional Representaion Lemma, then we show that the upper bound can be decomposed into $N$ parallel problems. Next, lower bounds on privacy-utility trade-off are derived using Functional Representation Lemma and Strong Functional Representaion Lemma. The upper bound is tight within a constant and the lower bounds assert that the disclosed data is independent of all $\\{X_j\\}_{i=1}^N$ except one which we allocate the maximum allowed leakage to it. Finally, the obtained bounds are studied in special cases. ",
    "url": "https://arxiv.org/abs/2211.15525",
    "authors": [
      "Amirreza Zamani",
      "Tobias J. Oechtering",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.15532",
    "title": "YZR-net : Self-supervised Hidden representations Invariant to  Transformations for profanity detection",
    "abstract": "On current {\\it e-}learning platforms, live classes are an important tool that provides students with an opportunity to get more involved while learning new concepts. In such classes, the element of interaction with teachers and fellow peers helps in removing learning silos and gives each student a chance to experience some aspects relevant to offline learning in this era of virtual classes. One common way of interaction in a class is through the chats / messaging framework, where the teacher can broadcast messages as well as get instant feedback from the students in the live class. This freedom of interaction is a crucial aspect for any student's learning growth but misuse of it can have serious repercussions. Some miscreants use this framework to send profane messages which can have a negative impact on other students as well as the teacher of the class. These rare but high impact situations obviate the need for automatic detection mechanisms that prevent the posting of such chats on any platform. In this work we develop YZR-Net which is a self-supervised framework that is able to robustly detect profane words used in a chat even if the student tries to add clever modifications to fool the system. The matching mechanism on token / word level allows us to maintain a compact as well as dynamic profane vocabulary which can be updated without retraining the underlying model. Our profanity detection framework is language independent and can handle abuses in both English as well as its transliterated counterpart Hinglish (Hindi language words written in English). ",
    "url": "https://arxiv.org/abs/2211.15532",
    "authors": [
      "Vedant Sandeep Joshi",
      "Sivanagaraja Tatinati",
      "Yubo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.15533",
    "title": "The Stack: 3 TB of permissively licensed source code",
    "abstract": "Large Language Models (LLMs) play an ever-increasing role in the field of Artificial Intelligence (AI)--not only for natural language processing but also for code understanding and generation. To stimulate open and responsible research on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting of permissively licensed source code in 30 programming languages. We describe how we collect the full dataset, construct a permissively licensed subset, present a data governance plan, discuss limitations, and show promising results on text2code benchmarks by training 350M-parameter decoders on different Python subsets. We find that (1) near-deduplicating the data significantly boosts performance across all experiments, and (2) it is possible to match previously reported HumanEval and MBPP performance using only permissively licensed data. We make the dataset available at https://hf.co/BigCode, provide a tool called \"Am I in The Stack\" (https://hf.co/spaces/bigcode/in-the-stack) for developers to search The Stack for copies of their code, and provide a process for code to be removed from the dataset by following the instructions at https://www.bigcode-project.org/docs/about/the-stack/. ",
    "url": "https://arxiv.org/abs/2211.15533",
    "authors": [
      "Denis Kocetkov",
      "Raymond Li",
      "Loubna Ben Allal",
      "Jia Li",
      "Chenghao Mou",
      "Carlos Mu\u00f1oz Ferrandis",
      "Yacine Jernite",
      "Margaret Mitchell",
      "Sean Hughes",
      "Thomas Wolf",
      "Dzmitry Bahdanau",
      "Leandro von Werra",
      "Harm de Vries"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15536",
    "title": "Sentiment analysis and opinion mining on E-commerce site",
    "abstract": "Sentiment analysis or opinion mining help to illustrate the phrase NLP (Natural Language Processing). Sentiment analysis has been the most significant topic in recent years. The goal of this study is to solve the sentiment polarity classification challenges in sentiment analysis. A broad technique for categorizing sentiment opposition is presented, along with comprehensive process explanations. With the results of the analysis, both sentence-level classification and review-level categorization are conducted. Finally, we discuss our plans for future sentiment analysis research. ",
    "url": "https://arxiv.org/abs/2211.15536",
    "authors": [
      "Fatema Tuz Zohra Anny",
      "Oahidul Islam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15538",
    "title": "Graph Convolutional Network for Multi-Target Multi-Camera Vehicle  Tracking",
    "abstract": "This letter focuses on the task of Multi-Target Multi-Camera vehicle tracking. We propose to associate single-camera trajectories into multi-camera global trajectories by training a Graph Convolutional Network. Our approach simultaneously processes all cameras providing a global solution, and it is also robust to large cameras unsynchronizations. Furthermore, we design a new loss function to deal with class imbalance. Our proposal outperforms the related work showing better generalization and without requiring ad-hoc manual annotations or thresholds, unlike compared approaches. ",
    "url": "https://arxiv.org/abs/2211.15538",
    "authors": [
      "Elena Luna",
      "Juan Carlos San Miguel",
      "Jos\u00e9 Mar\u00eda Mart\u00ednez",
      "Marcos Escudero-Vi\u00f1olo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15556",
    "title": "Attack on Unfair ToS Clause Detection: A Case Study using Universal  Adversarial Triggers",
    "abstract": "Recent work has demonstrated that natural language processing techniques can support consumer protection by automatically detecting unfair clauses in the Terms of Service (ToS) Agreement. This work demonstrates that transformer-based ToS analysis systems are vulnerable to adversarial attacks. We conduct experiments attacking an unfair-clause detector with universal adversarial triggers. Experiments show that a minor perturbation of the text can considerably reduce the detection performance. Moreover, to measure the detectability of the triggers, we conduct a detailed human evaluation study by collecting both answer accuracy and response time from the participants. The results show that the naturalness of the triggers remains key to tricking readers. ",
    "url": "https://arxiv.org/abs/2211.15556",
    "authors": [
      "Shanshan Xu",
      "Irina Broda",
      "Rashid Haddad",
      "Marco Negrini",
      "Matthias Grabmair"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.15557",
    "title": "Beyond CAGE: Investigating Generalization of Learned Autonomous Network  Defense Policies",
    "abstract": "Advancements in reinforcement learning (RL) have inspired new directions in intelligent automation of network defense. However, many of these advancements have either outpaced their application to network security or have not considered the challenges associated with implementing them in the real-world. To understand these problems, this work evaluates several RL approaches implemented in the second edition of the CAGE Challenge, a public competition to build an autonomous network defender agent in a high-fidelity network simulator. Our approaches all build on the Proximal Policy Optimization (PPO) family of algorithms, and include hierarchical RL, action masking, custom training, and ensemble RL. We find that the ensemble RL technique performs strongest, outperforming our other models and taking second place in the competition. To understand applicability to real environments we evaluate each method's ability to generalize to unseen networks and against an unknown attack strategy. In unseen environments, all of our approaches perform worse, with degradation varied based on the type of environmental change. Against an unknown attacker strategy, we found that our models had reduced overall performance even though the new strategy was less efficient than the ones our models trained on. Together, these results highlight promising research directions for autonomous network defense in the real world. ",
    "url": "https://arxiv.org/abs/2211.15557",
    "authors": [
      "Melody Wolk",
      "Andy Applebaum",
      "Camron Denver",
      "Patrick Dwyer",
      "Marina Moskowitz",
      "Harold Nguyen",
      "Nicole Nichols",
      "Nicole Park",
      "Paul Rachwalski",
      "Frank Rau",
      "Adrian Webster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.15561",
    "title": "Graph Neural Networks for Breast Cancer Data Integration",
    "abstract": "International initiatives such as METABRIC (Molecular Taxonomy of Breast Cancer International Consortium) have collected several multigenomic and clinical data sets to identify the undergoing molecular processes taking place throughout the evolution of various cancers. Numerous Machine Learning and statistical models have been designed and trained to analyze these types of data independently, however, the integration of such differently shaped and sourced information streams has not been extensively studied. To better integrate these data sets and generate meaningful representations that can ultimately be leveraged for cancer detection tasks could lead to giving well-suited treatments to patients. Hence, we propose a novel learning pipeline comprising three steps - the integration of cancer data modalities as graphs, followed by the application of Graph Neural Networks in an unsupervised setting to generate lower-dimensional embeddings from the combined data, and finally feeding the new representations on a cancer sub-type classification model for evaluation. The graph construction algorithms are described in-depth as METABRIC does not store relationships between the patient modalities, with a discussion of their influence over the quality of the generated embeddings. We also present the models used to generate the lower-latent space representations: Graph Neural Networks, Variational Graph Autoencoders and Deep Graph Infomax. In parallel, the pipeline is tested on a synthetic dataset to demonstrate that the characteristics of the underlying data, such as homophily levels, greatly influence the performance of the pipeline, which ranges between 51\\% to 98\\% accuracy on artificial data, and 13\\% and 80\\% on METABRIC. This project has the potential to improve cancer data understanding and encourages the transition of regular data sets to graph-shaped data. ",
    "url": "https://arxiv.org/abs/2211.15561",
    "authors": [
      "Teodora Reu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2211.15578",
    "title": "Mutual Exclusivity Training and Primitive Augmentation to Induce  Compositionality",
    "abstract": "Recent datasets expose the lack of the systematic generalization ability in standard sequence-to-sequence models. In this work, we analyze this behavior of seq2seq models and identify two contributing factors: a lack of mutual exclusivity bias (i.e., a source sequence already mapped to a target sequence is less likely to be mapped to other target sequences), and the tendency to memorize whole examples rather than separating structures from contents. We propose two techniques to address these two issues respectively: Mutual Exclusivity Training that prevents the model from producing seen generations when facing novel, unseen examples via an unlikelihood-based loss; and prim2primX data augmentation that automatically diversifies the arguments of every syntactic function to prevent memorizing and provide a compositional inductive bias without exposing test-set data. Combining these two techniques, we show substantial empirical improvements using standard sequence-to-sequence models (LSTMs and Transformers) on two widely-used compositionality datasets: SCAN and COGS. Finally, we provide analysis characterizing the improvements as well as the remaining challenges, and provide detailed ablations of our method. Our code is available at https://github.com/owenzx/met-primaug ",
    "url": "https://arxiv.org/abs/2211.15578",
    "authors": [
      "Yichen Jiang",
      "Xiang Zhou",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15590",
    "title": "A Bayesian Approach to Reconstructing Interdependent Infrastructure  Networks from Cascading Failures",
    "abstract": "Analyzing the behavior of complex interdependent networks requires complete information about the network topology and the interdependent links across networks. For many applications such as critical infrastructure systems, understanding network interdependencies is crucial to anticipate cascading failures and plan for disruptions. However, data on the topology of individual networks are often publicly unavailable due to privacy and security concerns. Additionally, interdependent links are often only revealed in the aftermath of a disruption as a result of cascading failures. We propose a scalable nonparametric Bayesian approach to reconstruct the topology of interdependent infrastructure networks from observations of cascading failures. Metropolis-Hastings algorithm coupled with the infrastructure-dependent proposal are employed to increase the efficiency of sampling possible graphs. Results of reconstructing a synthetic system of interdependent infrastructure networks demonstrate that the proposed approach outperforms existing methods in both accuracy and computational time. We further apply this approach to reconstruct the topology of one synthetic and two real-world systems of interdependent infrastructure networks, including gas-power-water networks in Shelby County, TN, USA, and an interdependent system of power-water networks in Italy, to demonstrate the general applicability of the approach. ",
    "url": "https://arxiv.org/abs/2211.15590",
    "authors": [
      "Yu Wang",
      "Jin-Zhu Yu",
      "Hiba Baroud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.15597",
    "title": "Lightning Fast Video Anomaly Detection via Adversarial Knowledge  Distillation",
    "abstract": "We propose a very fast frame-level model for anomaly detection in video, which learns to detect anomalies by distilling knowledge from multiple highly accurate object-level teacher models. To improve the fidelity of our student, we distill the low-resolution anomaly maps of the teachers by jointly applying standard and adversarial distillation, introducing an adversarial discriminator for each teacher to distinguish between target and generated anomaly maps. We conduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2), showing that our method is over 7 times faster than the fastest competing method, and between 28 and 62 times faster than object-centric models, while obtaining comparable results to recent methods. Our evaluation also indicates that our model achieves the best trade-off between speed and accuracy, due to its previously unheard-of speed of 1480 FPS. In addition, we carry out a comprehensive ablation study to justify our architectural design choices. ",
    "url": "https://arxiv.org/abs/2211.15597",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Florinel-Alin Croitoru",
      "Dana Dascalescu",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.15600",
    "title": "Measurement, Analysis, and Insight of NFTs Transaction Networks",
    "abstract": "Non-fungible tokens (NFTs) are unique digital items with blockchain managed ownership. Ethereum blockchain based smart contract created the environment for NFTs (ERC721) to reach its one of the most important future application domains. Non fungible tokens got more attention when the market saw record breaking sales in 2021. Virtually anything of value can be traced and traded on the blockchain network by minting them as NFTs. NFTs provide the users with a decentralized proof of ownership representation, as every transaction and trade of NFTs gets recorded in the Ethereum network blocks. The value of NFTs is derived from their being non fungible meaning that the token cannot be replaced with an identical token (giving it inherent scarcity). In this paper, we study the growth rate and evolutionary nature of the NFT network and try to understand the NFT ecosystem. We explore the evolving nature of the NFT interaction network from a temporal graph perspective. We study the growth rate and observer the semantics of the network. Here on the observer network, we will run two graph algorithms on the dataset. Lastly, observe and forecast the survival of NFTs bubble by applying the Logarithmic periodic power law (LPPL) model to the time series data on one of the most famous NFT collections CryptoPunks (predicting price increase), which has seen sales of around $23.7 million around mid of 2021. ",
    "url": "https://arxiv.org/abs/2211.15600",
    "authors": [
      "Prakhyat Khati"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.15601",
    "title": "Fast-SNARF: A Fast Deformer for Articulated Neural Fields",
    "abstract": "Neural fields have revolutionized the area of 3D reconstruction and novel view synthesis of rigid scenes. A key challenge in making such methods applicable to articulated objects, such as the human body, is to model the deformation of 3D locations between the rest pose (a canonical space) and the deformed space. We propose a new articulation module for neural fields, Fast-SNARF, which finds accurate correspondences between canonical space and posed space via iterative root finding. Fast-SNARF is a drop-in replacement in functionality to our previous work, SNARF, while significantly improving its computational efficiency. We contribute several algorithmic and implementation improvements over SNARF, yielding a speed-up of $150\\times$. These improvements include voxel-based correspondence search, pre-computing the linear blend skinning function, and an efficient software implementation with CUDA kernels. Fast-SNARF enables efficient and simultaneous optimization of shape and skinning weights given deformed observations without correspondences (e.g. 3D meshes). Because learning of deformation maps is a crucial component in many 3D human avatar methods and since Fast-SNARF provides a computationally efficient solution, we believe that this work represents a significant step towards the practical creation of 3D virtual humans. ",
    "url": "https://arxiv.org/abs/2211.15601",
    "authors": [
      "Xu Chen",
      "Tianjian Jiang",
      "Jie Song",
      "Max Rietmann",
      "Andreas Geiger",
      "Michael J. Black",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15608",
    "title": "Representation with Incomplete Votes",
    "abstract": "Platforms for online civic participation rely heavily on methods for condensing thousands of comments into a relevant handful based on whether participants agree or disagree with them. We argue that these methods should guarantee fair representation of the participants, as their outcomes may affect the health of the conversation and inform impactful downstream decisions. To that end, we draw on the literature on approval-based committee elections. Our setting is novel in that the approval votes are incomplete since participants will typically not vote on all comments. We prove that this complication renders non-adaptive algorithms impractical in terms of the amount of information they must gather. Therefore, we develop an adaptive algorithm that uses information more efficiently by presenting incoming participants with statements that appear promising based on votes by previous participants. We prove that this method satisfies commonly used notions of fair representation, even when participants only vote on a small fraction of comments. Finally, an empirical evaluation on real data shows that the proposed algorithm provides representative outcomes in practice. ",
    "url": "https://arxiv.org/abs/2211.15608",
    "authors": [
      "Daniel Halpern",
      "Gregory Kehne",
      "Ariel D. Procaccia",
      "Jamie Tucker-Foltz",
      "Manuel W\u00fcthrich"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2211.15616",
    "title": "Weight Predictor Network with Feature Selection for Small Sample Tabular  Biomedical Data",
    "abstract": "Tabular biomedical data is often high-dimensional but with a very small number of samples. Although recent work showed that well-regularised simple neural networks could outperform more sophisticated architectures on tabular data, they are still prone to overfitting on tiny datasets with many potentially irrelevant features. To combat these issues, we propose Weight Predictor Network with Feature Selection (WPFS) for learning neural networks from high-dimensional and small sample data by reducing the number of learnable parameters and simultaneously performing feature selection. In addition to the classification network, WPFS uses two small auxiliary networks that together output the weights of the first layer of the classification model. We evaluate on nine real-world biomedical datasets and demonstrate that WPFS outperforms other standard as well as more recent methods typically applied to tabular data. Furthermore, we investigate the proposed feature selection mechanism and show that it improves performance while providing useful insights into the learning task. ",
    "url": "https://arxiv.org/abs/2211.15616",
    "authors": [
      "Andrei Margeloiu",
      "Nikola Simidjievski",
      "Pietro Lio",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15644",
    "title": "Efficient Mirror Detection via Multi-level Heterogeneous Learning",
    "abstract": "We present HetNet (Multi-level \\textbf{Het}erogeneous \\textbf{Net}work), a highly efficient mirror detection network. Current mirror detection methods focus more on performance than efficiency, limiting the real-time applications (such as drones). Their lack of efficiency is aroused by the common design of adopting homogeneous modules at different levels, which ignores the difference between different levels of features. In contrast, HetNet detects potential mirror regions initially through low-level understandings (\\textit{e.g.}, intensity contrasts) and then combines with high-level understandings (contextual discontinuity for instance) to finalize the predictions. To perform accurate yet efficient mirror detection, HetNet follows an effective architecture that obtains specific information at different stages to detect mirrors. We further propose a multi-orientation intensity-based contrasted module (MIC) and a reflection semantic logical module (RSL), equipped on HetNet, to predict potential mirror regions by low-level understandings and analyze semantic logic in scenarios by high-level understandings, respectively. Compared to the state-of-the-art method, HetNet runs 664$\\%$ faster and draws an average performance gain of 8.9$\\%$ on MAE, 3.1$\\%$ on IoU, and 2.0$\\%$ on F-measure on two mirror detection benchmarks. ",
    "url": "https://arxiv.org/abs/2211.15644",
    "authors": [
      "Ruozhen He",
      "Jiaying Lin",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15656",
    "title": "SuperFusion: Multilevel LiDAR-Camera Fusion for Long-Range HD Map  Generation and Prediction",
    "abstract": "High-definition (HD) semantic map generation of the environment is an essential component of autonomous driving. Existing methods have achieved good performance in this task by fusing different sensor modalities, such as LiDAR and camera. However, current works are based on raw data or network feature-level fusion and only consider short-range HD map generation, limiting their deployment to realistic autonomous driving applications. In this paper, we focus on the task of building the HD maps in both short ranges, i.e., within 30 m, and also predicting long-range HD maps up to 90 m, which is required by downstream path planning and control tasks to improve the smoothness and safety of autonomous driving. To this end, we propose a novel network named SuperFusion, exploiting the fusion of LiDAR and camera data at multiple levels. We benchmark our SuperFusion on the nuScenes dataset and a self-recorded dataset and show that it outperforms the state-of-the-art baseline methods with large margins. Furthermore, we propose a new metric to evaluate the long-range HD map prediction and apply the generated HD map to a downstream path planning task. The results show that by using the long-range HD maps predicted by our method, we can make better path planning for autonomous vehicles. The code will be available at https://github.com/haomo-ai/SuperFusion. ",
    "url": "https://arxiv.org/abs/2211.15656",
    "authors": [
      "Hao Dong",
      "Xianjing Zhang",
      "Xuan Jiang",
      "Jun Zhang",
      "Jintao Xu",
      "Rui Ai",
      "Weihao Gu",
      "Huimin Lu",
      "Juho Kannala",
      "Xieyuanli Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.14312",
    "title": "Automated Deep Aberration Detection from Chromosome Karyotype Images",
    "abstract": "Chromosome analysis is essential for diagnosing genetic disorders. For hematologic malignancies, identification of somatic clonal aberrations by karyotype analysis remains the standard of care. However, karyotyping is costly and time-consuming because of the largely manual process and the expertise required in identifying and annotating aberrations. Efforts to automate karyotype analysis to date fell short in aberration detection. Using a training set of ~10k patient specimens and ~50k karyograms from over 5 years from the Fred Hutchinson Cancer Center, we created a labeled set of images representing individual chromosomes. These individual chromosomes were used to train and assess deep learning models for classifying the 24 human chromosomes and identifying chromosomal aberrations. The top-accuracy models utilized the recently introduced Topological Vision Transformers (TopViTs) with 2-level-block-Toeplitz masking, to incorporate structural inductive bias. TopViT outperformed CNN (Inception) models with >99.3% accuracy for chromosome identification, and exhibited accuracies >99% for aberration detection in most aberrations. Notably, we were able to show high-quality performance even in \"few shot\" learning scenarios. Incorporating the definition of clonality substantially improved both precision and recall (sensitivity). When applied to \"zero shot\" scenarios, the model captured aberrations without training, with perfect precision at >50% recall. Together these results show that modern deep learning models can approach expert-level performance for chromosome aberration detection. To our knowledge, this is the first study demonstrating the downstream effectiveness of TopViTs. These results open up exciting opportunities for not only expediting patient results but providing a scalable technology for early screening of low-abundance chromosomal lesions. ",
    "url": "https://arxiv.org/abs/2211.14312",
    "authors": [
      "Zahra Shamsi",
      "Drew Bryant",
      "Jacob Wilson",
      "Xiaoyu Qu",
      "Avinava Dubey",
      "Konik Kothari",
      "Mostafa Dehghani",
      "Mariya Chavarha",
      "Valerii Likhosherstov",
      "Brian Williams",
      "Michael Frumkin",
      "Fred Appelbaum",
      "Krzysztof Choromanski",
      "Ali Bashir",
      "Min Fang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14372",
    "title": "Interpretability Analysis of Deep Models for COVID-19 Detection",
    "abstract": "During the outbreak of COVID-19 pandemic, several research areas joined efforts to mitigate the damages caused by SARS-CoV-2. In this paper we present an interpretability analysis of a convolutional neural network based model for COVID-19 detection in audios. We investigate which features are important for model decision process, investigating spectrograms, F0, F0 standard deviation, sex and age. Following, we analyse model decisions by generating heat maps for the trained models to capture their attention during the decision process. Focusing on a explainable Inteligence Artificial approach, we show that studied models can taken unbiased decisions even in the presence of spurious data in the training set, given the adequate preprocessing steps. Our best model has 94.44% of accuracy in detection, with results indicating that models favors spectrograms for the decision process, particularly, high energy areas in the spectrogram related to prosodic domains, while F0 also leads to efficient COVID-19 detection. ",
    "url": "https://arxiv.org/abs/2211.14372",
    "authors": [
      "Daniel Peixoto Pinto da Silva",
      "Edresson Casanova",
      "Lucas Rafael Stefanel Gris",
      "Arnaldo Candido Junior",
      "Marcelo Finger",
      "Flaviane Svartman",
      "Beatriz Raposo",
      "Marcus Vin\u00edcius Moreira Martins",
      "Sandra Maria Alu\u00edsio",
      "Larissa Cristina Berti",
      "Jo\u00e3o Paulo Teixeira"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.14400",
    "title": "Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev  Spaces",
    "abstract": "We study the problem of how efficiently, in terms of the number of parameters, deep neural networks with the ReLU activation function can approximate functions in the Sobolev space $W^s(L_q(\\Omega))$ on a bounded domain $\\Omega$, where the error is measured in $L_p(\\Omega)$. This problem is important for studying the application of neural networks in scientific computing and has previously been solved only in the case $p=q=\\infty$. Our contribution is to provide a solution for all $1\\leq p,q\\leq \\infty$ and $s > 0$. Our results show that deep ReLU networks significantly outperform classical methods of approximation, but that this comes at the cost of parameters which are not encodable. ",
    "url": "https://arxiv.org/abs/2211.14400",
    "authors": [
      "Jonathan W. Siegel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.14429",
    "title": "Supervised Pretraining for Molecular Force Fields and Properties  Prediction",
    "abstract": "Machine learning approaches have become popular for molecular modeling tasks, including molecular force fields and properties prediction. Traditional supervised learning methods suffer from scarcity of labeled data for particular tasks, motivating the use of large-scale dataset for other relevant tasks. We propose to pretrain neural networks on a dataset of 86 millions of molecules with atom charges and 3D geometries as inputs and molecular energies as labels. Experiments show that, compared to training from scratch, fine-tuning the pretrained model can significantly improve the performance for seven molecular property prediction tasks and two force field tasks. We also demonstrate that the learned representations from the pretrained model contain adequate information about molecular structures, by showing that linear probing of the representations can predict many molecular information including atom types, interatomic distances, class of molecular scaffolds, and existence of molecular fragments. Our results show that supervised pretraining is a promising research direction in molecular modeling ",
    "url": "https://arxiv.org/abs/2211.14429",
    "authors": [
      "Xiang Gao",
      "Weihao Gao",
      "Wenzhi Xiao",
      "Zhirui Wang",
      "Chong Wang",
      "Liang Xiang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2211.14543",
    "title": "When Spectral Modeling Meets Convolutional Networks: A Method for  Discovering Reionization-era Lensed Quasars in Multi-band Imaging Data",
    "abstract": "Over the last two decades, around three hundred quasars have been discovered at $z\\gtrsim6$, yet only one was identified as being strong-gravitationally lensed. We explore a new approach, enlarging the permitted spectral parameter space while introducing a new spatial geometry veto criterion, implemented via image-based deep learning. We made the first application of this approach in a systematic search for reionization-era lensed quasars, using data from the Dark Energy Survey, the Visible and Infrared Survey Telescope for Astronomy Hemisphere Survey, and the Wide-field Infrared Survey Explorer. Our search method consists of two main parts: (i) pre-selection of the candidates based on their spectral energy distributions (SEDs) using catalog-level photometry and (ii) relative probabilities calculation of being a lens or some contaminant utilizing a convolutional neural network (CNN) classification. The training datasets are constructed by painting deflected point-source lights over actual galaxy images to generate realistic galaxy-quasar lens models, optimized to find systems with small image separations, i.e., Einstein radii of $\\theta_\\mathrm{E} \\leq 1$ arcsec. Visual inspection is then performed for sources with CNN scores of $P_\\mathrm{lens} > 0.1$, which led us to obtain 36 newly-selected lens candidates, waiting for spectroscopic confirmation. These findings show that automated SED modeling and deep learning pipelines, supported by modest human input, are a promising route for detecting strong lenses from large catalogs that can overcome the veto limitations of primarily dropout-based SED selection approaches. ",
    "url": "https://arxiv.org/abs/2211.14543",
    "authors": [
      "Irham Taufik Andika",
      "Knud Jahnke",
      "Arjen van der Wel",
      "Eduardo Ba\u00f1ados",
      "Sarah E. I. Bosman",
      "Frederick B. Davies",
      "Anna-Christina Eilers",
      "Anton Timur Jaelani",
      "Chiara Mazzucchelli",
      "Masafusa Onoue",
      "Jan-Torge Schindler"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14555",
    "title": "Distribution Free Prediction Sets for Node Classification",
    "abstract": "Graph Neural Networks (GNNs) are able to achieve high classification accuracy on many large real world datasets, but provide no rigorous notion of predictive uncertainty. We leverage recent advances in conformal prediction to construct prediction sets for node classification in inductive learning scenarios, and verify the efficacy of our approach across standard benchmark datasets using popular GNN models. The code is available at \\href{https://github.com/jase-clarkson/graph_cp}{this link}. ",
    "url": "https://arxiv.org/abs/2211.14555",
    "authors": [
      "Jase Clarkson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14557",
    "title": "CMC v2: Towards More Accurate COVID-19 Detection with Discriminative  Video Priors",
    "abstract": "This paper presents our solution for the 2nd COVID-19 Competition, occurring in the framework of the AIMIA Workshop at the European Conference on Computer Vision (ECCV 2022). In our approach, we employ the winning solution last year which uses a strong 3D Contrastive Mixup Classifcation network (CMC v1) as the baseline method, composed of contrastive representation learning and mixup classification. In this paper, we propose CMC v2 by introducing natural video priors to COVID-19 diagnosis. Specifcally, we adapt a pre-trained (on video dataset) video transformer backbone to COVID-19 detection. Moreover, advanced training strategies, including hybrid mixup and cutmix, slicelevel augmentation, and small resolution training are also utilized to boost the robustness and the generalization ability of the model. Among 14 participating teams, CMC v2 ranked 1st in the 2nd COVID-19 Competition with an average Macro F1 Score of 89.11%. ",
    "url": "https://arxiv.org/abs/2211.14557",
    "authors": [
      "Junlin Hou",
      "Jilan Xu",
      "Nan Zhang",
      "Yi Wang",
      "Yuejie Zhang",
      "Xiaobo Zhang",
      "Rui Feng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14559",
    "title": "Boosting COVID-19 Severity Detection with Infection-aware Contrastive  Mixup Classifcation",
    "abstract": "This paper presents our solution for the 2nd COVID-19 Severity Detection Competition. This task aims to distinguish the Mild, Moderate, Severe, and Critical grades in COVID-19 chest CT images. In our approach, we devise a novel infection-aware 3D Contrastive Mixup Classifcation network for severity grading. Specifcally, we train two segmentation networks to frst extract the lung region and then the inner lesion region. The lesion segmentation mask serves as complementary information for the original CT slices. To relieve the issue of imbalanced data distribution, we further improve the advanced Contrastive Mixup Classifcation network by weighted cross-entropy loss. On the COVID-19 severity detection leaderboard, our approach won the frst place with a Macro F1 Score of 51.76%. It signifcantly outperforms the baseline method by over 11.46%. ",
    "url": "https://arxiv.org/abs/2211.14559",
    "authors": [
      "Junlin Hou",
      "Jilan Xu",
      "Nan Zhang",
      "Yuejie Zhang",
      "Xiaobo Zhang",
      "Rui Feng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14811",
    "title": "Improved Quasi-Recurrent Neural Network for Hyperspectral Image  Denoising",
    "abstract": "Hyperspectral image is unique and useful for its abundant spectral bands, but it subsequently requires extra elaborated treatments of the spatial-spectral correlation as well as the global correlation along the spectrum for building a robust and powerful HSI restoration algorithm. By considering such HSI characteristics, 3D Quasi-Recurrent Neural Network (QRNN3D) is one of the HSI denoising networks that has been shown to achieve excellent performance and flexibility. In this paper, we show that with a few simple modifications, the performance of QRNN3D could be substantially improved further. Our modifications are based on the finding that through QRNN3D is powerful for modeling spectral correlation, it neglects the proper treatment between features from different sources and its training strategy is suboptimal. We, therefore, introduce an adaptive fusion module to replace its vanilla additive skip connection to better fuse the features of the encoder and decoder. We additionally identify several important techniques to further enhance the performance, which includes removing batch normalization, use of extra frequency loss, and learning rate warm-up. Experimental results on various noise settings demonstrate the effectiveness and superior performance of our method. ",
    "url": "https://arxiv.org/abs/2211.14811",
    "authors": [
      "Zeqiang Lai",
      "Ying Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14847",
    "title": "Deep Learning-Based Prediction of Molecular Tumor Biomarkers from H&E: A  Practical Review",
    "abstract": "Molecular and genomic properties are critical in selecting cancer treatments to target individual tumors, particularly for immunotherapy. However, the methods to assess such properties are expensive, time-consuming, and often not routinely performed. Applying machine learning to H&E images can provide a more cost-effective screening method. Dozens of studies over the last few years have demonstrated that a variety of molecular biomarkers can be predicted from H&E alone using the advancements of deep learning: molecular alterations, genomic subtypes, protein biomarkers, and even the presence of viruses. This article reviews the diverse applications across cancer types and the methodology to train and validate these models on whole slide images. From bottom-up to pathologist-driven to hybrid approaches, the leading trends include a variety of weakly supervised deep learning-based approaches, as well as mechanisms for training strongly supervised models in select situations. While results of these algorithms look promising, some challenges still persist, including small training sets, rigorous validation, and model explainability. Biomarker prediction models may yield a screening method to determine when to run molecular tests or an alternative when molecular tests are not possible. They also create new opportunities in quantifying intratumoral heterogeneity and predicting patient outcomes. ",
    "url": "https://arxiv.org/abs/2211.14847",
    "authors": [
      "Heather D. Couture"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14961",
    "title": "Linear Classification of Neural Manifolds with Correlated Variability",
    "abstract": "Understanding how the statistical and geometric properties of neural activations relate to network performance is a key problem in theoretical neuroscience and deep learning. In this letter, we calculate how correlations between object representations affect the capacity, a measure of linear separability. We show that for spherical object manifolds, introducing correlations between centroids effectively pushes the spheres closer together, while introducing correlations between the spheres' axes effectively shrinks their radii, revealing a duality between neural correlations and geometry. We then show that our results can be used to accurately estimate the capacity with real neural data. ",
    "url": "https://arxiv.org/abs/2211.14961",
    "authors": [
      "Albert J. Wakhloo",
      "Tamara J. Sussman",
      "SueYeon Chung"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14962",
    "title": "Fault-Tolerant Detection Systems on the King's Grid",
    "abstract": "A detection system, modeled in a graph, uses \"detectors\" on a subset of vertices to uniquely identify an \"intruder\" at any vertex. We consider two types of detection systems: open-locating-dominating (OLD) sets and identifying codes (ICs). An OLD set gives each vertex a unique, non-empty open neighborhood of detectors, while an IC provides a unique, non-empty closed neighborhood of detectors. We explore their fault-tolerant variants: redundant OLD (RED:OLD) sets and redundant ICs (RED:ICs), which ensure that removing/disabling at most one detector guarantees the properties of OLD sets and ICs, respectively. This paper focuses on constructing optimal RED:OLD sets and RED:ICs on the infinite king's grid, and presents the proof for the bounds on their minimum densities; [3/10, 1/3] for RED:OLD sets and [3/11, 1/3] for RED:ICs. ",
    "url": "https://arxiv.org/abs/2211.14962",
    "authors": [
      "Devin Jean",
      "Suk Seo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.14986",
    "title": "An Unpaired Cross-modality Segmentation Framework Using Data  Augmentation and Hybrid Convolutional Networks for Segmenting Vestibular  Schwannoma and Cochlea",
    "abstract": "The crossMoDA challenge aims to automatically segment the vestibular schwannoma (VS) tumor and cochlea regions of unlabeled high-resolution T2 scans by leveraging labeled contrast-enhanced T1 scans. The 2022 edition extends the segmentation task by including multi-institutional scans. In this work, we proposed an unpaired cross-modality segmentation framework using data augmentation and hybrid convolutional networks. Considering heterogeneous distributions and various image sizes for multi-institutional scans, we apply the min-max normalization for scaling the intensities of all scans between -1 and 1, and use the voxel size resampling and center cropping to obtain fixed-size sub-volumes for training. We adopt two data augmentation methods for effectively learning the semantic information and generating realistic target domain scans: generative and online data augmentation. For generative data augmentation, we use CUT and CycleGAN to generate two groups of realistic T2 volumes with different details and appearances for supervised segmentation training. For online data augmentation, we design a random tumor signal reducing method for simulating the heterogeneity of VS tumor signals. Furthermore, we utilize an advanced hybrid convolutional network with multi-dimensional convolutions to adaptively learn sparse inter-slice information and dense intra-slice information for accurate volumetric segmentation of VS tumor and cochlea regions in anisotropic scans. On the crossMoDA2022 validation dataset, our method produces promising results and achieves the mean DSC values of 72.47% and 76.48% and ASSD values of 3.42 mm and 0.53 mm for VS tumor and cochlea regions, respectively. ",
    "url": "https://arxiv.org/abs/2211.14986",
    "authors": [
      "Yuzhou Zhuang",
      "Hong Liu",
      "Enmin Song",
      "Coskun Cetinkaya",
      "Chih-Cheng Hung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15002",
    "title": "A Model-data-driven Network Embedding Multidimensional Features for  Tomographic SAR Imaging",
    "abstract": "Deep learning (DL)-based tomographic SAR imaging algorithms are gradually being studied. Typically, they use an unfolding network to mimic the iterative calculation of the classical compressive sensing (CS)-based methods and process each range-azimuth unit individually. However, only one-dimensional features are effectively utilized in this way. The correlation between adjacent resolution units is ignored directly. To address that, we propose a new model-data-driven network to achieve tomoSAR imaging based on multi-dimensional features. Guided by the deep unfolding methodology, a two-dimensional deep unfolding imaging network is constructed. On the basis of it, we add two 2D processing modules, both convolutional encoder-decoder structures, to enhance multi-dimensional features of the imaging scene effectively. Meanwhile, to train the proposed multifeature-based imaging network, we construct a tomoSAR simulation dataset consisting entirely of simulation data of buildings. Experiments verify the effectiveness of the model. Compared with the conventional CS-based FISTA method and DL-based gamma-Net method, the result of our proposed method has better performance on completeness while having decent imaging accuracy. ",
    "url": "https://arxiv.org/abs/2211.15002",
    "authors": [
      "Yu Ren",
      "Xiaoling Zhang",
      "Xu Zhan",
      "Jun Shi",
      "Shunjun Wei",
      "Tianjiao Zeng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15105",
    "title": "PlasmoID: A dataset for Indonesian malaria parasite detection and  segmentation in thin blood smear",
    "abstract": "Indonesia holds the second-highest-ranking country for the highest number of malaria cases in Southeast Asia. A different malaria parasite semantic segmentation technique based on a deep learning approach is an alternative to reduce the limitations of traditional methods. However, the main problem of the semantic segmentation technique is raised since large parasites are dominant, and the tiny parasites are suppressed. In addition, the amount and variance of data are important influences in establishing their models. In this study, we conduct two contributions. First, we collect 559 microscopic images containing 691 malaria parasites of thin blood smears. The dataset is named PlasmoID, and most data comes from rural Indonesia. PlasmoID also provides ground truth for parasite detection and segmentation purposes. Second, this study proposes a malaria parasite segmentation and detection scheme by combining Faster RCNN and a semantic segmentation technique. The proposed scheme has been evaluated on the PlasmoID dataset. It has been compared with recent studies of semantic segmentation techniques, namely UNet, ResFCN-18, DeepLabV3, DeepLabV3plus and ResUNet-18. The result shows that our proposed scheme can improve the segmentation and detection of malaria parasite performance compared to original semantic segmentation techniques. ",
    "url": "https://arxiv.org/abs/2211.15105",
    "authors": [
      "Hanung Adi Nugroho",
      "Rizki Nurfauzi",
      "E. Elsa Herdiana Murhandarwati",
      "Purwono Purwono"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15129",
    "title": "On the Sample Complexity of Representation Learning in Multi-task  Bandits with Global and Local structure",
    "abstract": "We investigate the sample complexity of learning the optimal arm for multi-task bandit problems. Arms consist of two components: one that is shared across tasks (that we call representation) and one that is task-specific (that we call predictor). The objective is to learn the optimal (representation, predictor)-pair for each task, under the assumption that the optimal representation is common to all tasks. Within this framework, efficient learning algorithms should transfer knowledge across tasks. We consider the best-arm identification problem for a fixed confidence, where, in each round, the learner actively selects both a task, and an arm, and observes the corresponding reward. We derive instance-specific sample complexity lower bounds satisfied by any $(\\delta_G,\\delta_H)$-PAC algorithm (such an algorithm identifies the best representation with probability at least $1-\\delta_G$, and the best predictor for a task with probability at least $1-\\delta_H$). We devise an algorithm OSRL-SC whose sample complexity approaches the lower bound, and scales at most as $H(G\\log(1/\\delta_G)+ X\\log(1/\\delta_H))$, with $X,G,H$ being, respectively, the number of tasks, representations and predictors. By comparison, this scaling is significantly better than the classical best-arm identification algorithm that scales as $HGX\\log(1/\\delta)$. ",
    "url": "https://arxiv.org/abs/2211.15129",
    "authors": [
      "Alessio Russo",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15164",
    "title": "To what extent homophily and influencer networks explain song popularity",
    "abstract": "Forecasting the popularity of new songs has become a standard practice in the music industry and provides a comparative advantage for those that do it well. Considerable efforts were put into machine learning prediction models for that purpose. It is known that in these models, relevant predictive parameters include intrinsic lyrical and acoustic characteristics, extrinsic factors (e.g., publisher influence and support), and the previous popularity of the artists. Much less attention was given to the social components of the spreading of song popularity. Recently, evidence for musical homophily - the tendency that people who are socially linked also share musical tastes - was reported. Here we determine how musical homophily can be used to predict song popularity. The study is based on an extensive dataset from the last.fm online music platform from which we can extract social links between listeners and their listening patterns. To quantify the importance of networks in the spreading of songs that eventually determines their popularity, we use musical homophily to design a predictive influence parameter and show that its inclusion in state-of-the-art machine learning models enhances predictions of song popularity. The influence parameter improves the prediction precision (TP/(TP+FN)) by about 50% from 0.14 to 0.21, indicating that the social component in the spreading of music plays at least as significant a role as the artist's popularity or the impact of the genre. ",
    "url": "https://arxiv.org/abs/2211.15164",
    "authors": [
      "Niklas Reisz",
      "Vito D. P. Servedio",
      "Stefan Thurner"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.15223",
    "title": "Gamma-convergence of a nonlocal perimeter arising in adversarial machine  learning",
    "abstract": "In this paper we prove Gamma-convergence of a nonlocal perimeter of Minkowski type to a local anisotropic perimeter. The nonlocal model describes the regularizing effect of adversarial training in binary classifications. The energy essentially depends on the interaction between two distributions modelling likelihoods for the associated classes. We overcome typical strict regularity assumptions for the distributions by only assuming that they have bounded $BV$ densities. In the natural topology coming from compactness, we prove Gamma-convergence to a weighted perimeter with weight determined by an anisotropic function of the two densities. Despite being local, this sharp interface limit reflects classification stability with respect to adversarial perturbations. We further apply our results to deduce Gamma-convergence of the associated total variations, to study the asymptotics of adversarial training, and to prove Gamma-convergence of graph discretizations for the nonlocal perimeter. ",
    "url": "https://arxiv.org/abs/2211.15223",
    "authors": [
      "Leon Bungert",
      "Kerrek Stinson"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.15348",
    "title": "Learning Feynman Diagrams using Graph Neural Networks",
    "abstract": "In the wake of the growing popularity of machine learning in particle physics, this work finds a new application of geometric deep learning on Feynman diagrams to make accurate and fast matrix element predictions with the potential to be used in analysis of quantum field theory. This research uses the graph attention layer which makes matrix element predictions to 1 significant figure accuracy above 90% of the time. Peak performance was achieved in making predictions to 3 significant figure accuracy over 10% of the time with less than 200 epochs of training, serving as a proof of concept on which future works can build upon for better performance. Finally, a procedure is suggested, to use the network to make advancements in quantum field theory by constructing Feynman diagrams with effective particles that represent non-perturbative calculations. ",
    "url": "https://arxiv.org/abs/2211.15348",
    "authors": [
      "Harrison Mitchell",
      "Alexander Norcliffe",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15377",
    "title": "Whose Emotion Matters? Speaker Detection without Prior Knowledge",
    "abstract": "The task of emotion recognition in conversations (ERC) benefits from the availability of multiple modalities, as offered, for example, in the video-based MELD dataset. However, only a few research approaches use both acoustic and visual information from the MELD videos. There are two reasons for this: First, label-to-video alignments in MELD are noisy, making those videos an unreliable source of emotional speech data. Second, conversations can involve several people in the same scene, which requires the detection of the person speaking the utterance. In this paper we demonstrate that by using recent automatic speech recognition and active speaker detection models, we are able to realign the videos of MELD, and capture the facial expressions from uttering speakers in 96.92% of the utterances provided in MELD. Experiments with a self-supervised voice recognition model indicate that the realigned MELD videos more closely match the corresponding utterances offered in the dataset. Finally, we devise a model for emotion recognition in conversations trained on the face and audio information of the MELD realigned videos, which outperforms state-of-the-art models for ERC based on vision alone. This indicates that active speaker detection is indeed effective for extracting facial expressions from the uttering speakers, and that faces provide more informative visual cues than the visual features state-of-the-art models have been using so far. ",
    "url": "https://arxiv.org/abs/2211.15377",
    "authors": [
      "Hugo Carneiro",
      "Cornelius Weber",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.15420",
    "title": "Equivariant Networks for Crystal Structures",
    "abstract": "Supervised learning with deep models has tremendous potential for applications in materials science. Recently, graph neural networks have been used in this context, drawing direct inspiration from models for molecules. However, materials are typically much more structured than molecules, which is a feature that these models do not leverage. In this work, we introduce a class of models that are equivariant with respect to crystalline symmetry groups. We do this by defining a generalization of the message passing operations that can be used with more general permutation groups, or that can alternatively be seen as defining an expressive convolution operation on the crystal graph. Empirically, these models achieve competitive results with state-of-the-art on property prediction tasks. ",
    "url": "https://arxiv.org/abs/2211.15420",
    "authors": [
      "S\u00e9kou-Oumar Kaba",
      "Siamak Ravanbakhsh"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15423",
    "title": "Effective Data Sampling Strategies and Boundary Condition Constraints of  Physics-Informed Neural Networks for Identifying Material Properties in Solid  Mechanics",
    "abstract": "Material identification is critical for understanding the relationship between mechanical properties and the associated mechanical functions. However, material identification is a challenging task, especially when the characteristic of the material is highly nonlinear in nature, as is common in biological tissue. In this work, we identify unknown material properties in continuum solid mechanics via physics-informed neural networks (PINNs). To improve the accuracy and efficiency of PINNs, we developed efficient strategies to nonuniformly sample observational data. We also investigated different approaches to enforce Dirichlet boundary conditions as soft or hard constraints. Finally, we apply the proposed methods to a diverse set of time-dependent and time-independent solid mechanic examples that span linear elastic and hyperelastic material space. The estimated material parameters achieve relative errors of less than 1%. As such, this work is relevant to diverse applications, including optimizing structural integrity and developing novel materials. ",
    "url": "https://arxiv.org/abs/2211.15423",
    "authors": [
      "Wensi Wu",
      "Mitchell Daneker",
      "Matthew A. Jolley",
      "Kevin T. Turner",
      "Lu Lu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.15498",
    "title": "Physics-informed neural networks with unknown measurement noise",
    "abstract": "Physics-informed neural networks (PINNs) constitute a flexible approach to both finding solutions and identifying parameters of partial differential equations. Most works on the topic assume noiseless data, or data contaminated by weak Gaussian noise. We show that the standard PINN framework breaks down in case of non-Gaussian noise. We give a way of resolving this fundamental issue and we propose to jointly train an energy-based model (EBM) to learn the correct noise distribution. We illustrate the improved performance of our approach using multiple examples. ",
    "url": "https://arxiv.org/abs/2211.15498",
    "authors": [
      "Philipp Pilar",
      "Niklas Wahlstr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15527",
    "title": "A Study of Representational Properties of Unsupervised Anomaly Detection  in Brain MRI",
    "abstract": "Anomaly detection in MRI is of high clinical value in imaging and diagnosis. Unsupervised methods for anomaly detection provide interesting formulations based on reconstruction or latent embedding, offering a way to observe properties related to factorization. We study four existing modeling methods, and report our empirical observations using simple data science tools, to seek outcomes from the perspective of factorization as it would be most relevant to the task of unsupervised anomaly detection, considering the case of brain structural MRI. Our study indicates that anomaly detection algorithms that exhibit factorization related properties are well capacitated with delineatory capabilities to distinguish between normal and anomaly data. We have validated our observations in multiple anomaly and normal datasets. ",
    "url": "https://arxiv.org/abs/2211.15527",
    "authors": [
      "Ayantika Das",
      "Arun Palla",
      "Keerthi Ram",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15577",
    "title": "Exoplanet Detection by Machine Learning with Data Augmentation",
    "abstract": "It has recently been demonstrated that deep learning has significant potential to automate parts of the exoplanet detection pipeline using light curve data from satellites such as Kepler \\cite{borucki2010kepler} \\cite{koch2010kepler} and NASA's Transiting Exoplanet Survey Satellite (TESS) \\cite{ricker2010transiting}. Unfortunately, the smallness of the available datasets makes it difficult to realize the level of performance one expects from powerful network architectures. In this paper, we investigate the use of data augmentation techniques on light curve data from to train neural networks to identify exoplanets. The augmentation techniques used are of two classes: Simple (e.g. additive noise augmentation) and learning-based (e.g. first training a GAN \\cite{goodfellow2020generative} to generate new examples). We demonstrate that data augmentation has a potential to improve model performance for the exoplanet detection problem, and recommend the use of augmentation based on generative models as more data becomes available. ",
    "url": "https://arxiv.org/abs/2211.15577",
    "authors": [
      "Koray Aydo\u011fan"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1711.07214",
    "title": "Maximizing Submodular or Monotone Approximately Submodular Functions by  Multi-objective Evolutionary Algorithms",
    "abstract": " Title: Maximizing Submodular or Monotone Approximately Submodular Functions by  Multi-objective Evolutionary Algorithms ",
    "url": "https://arxiv.org/abs/1711.07214",
    "authors": [
      "Chao Qian",
      "Yang Yu",
      "Ke Tang",
      "Xin Yao",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:1810.05045",
    "title": "Analysis of Noisy Evolutionary Optimization When Sampling Fails",
    "abstract": " Title: Analysis of Noisy Evolutionary Optimization When Sampling Fails ",
    "url": "https://arxiv.org/abs/1810.05045",
    "authors": [
      "Chao Qian",
      "Chao Bian",
      "Yang Yu",
      "Ke Tang",
      "Xin Yao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:1901.10112",
    "title": "Evaluating Generalization Ability of Convolutional Neural Networks and  Capsule Networks for Image Classification via Top-2 Classification",
    "abstract": " Title: Evaluating Generalization Ability of Convolutional Neural Networks and  Capsule Networks for Image Classification via Top-2 Classification ",
    "url": "https://arxiv.org/abs/1901.10112",
    "authors": [
      "Hao Ren",
      "Jianlin Su",
      "Hong Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1904.07693",
    "title": "Frequent Itemset Mining using QUBO",
    "abstract": " Title: Frequent Itemset Mining using QUBO ",
    "url": "https://arxiv.org/abs/1904.07693",
    "authors": [
      "Jonas N\u00fc\u00dflein"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:1907.08759",
    "title": "Latency Minimization for Multiuser Computation Offloading in Fog-Radio  Access Networks",
    "abstract": " Comments: submitted for publication ",
    "url": "https://arxiv.org/abs/1907.08759",
    "authors": [
      "Wei Zhang",
      "Shafei Wang",
      "Ye Pan",
      "Qiang Li",
      "Jingran Lin",
      "Xiaoxiao Wu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:1907.13100",
    "title": "On the Robustness of Median Sampling in Noisy Evolutionary Optimization",
    "abstract": " Comments: 19 pages. arXiv admin note: text overlap with arXiv:1810.05045, arXiv:1711.00956 ",
    "url": "https://arxiv.org/abs/1907.13100",
    "authors": [
      "Chao Bian",
      "Chao Qian",
      "Yang Yu",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1909.06988",
    "title": "Explicit near-Ramanujan graphs of every degree",
    "abstract": " Comments: 26 pages ",
    "url": "https://arxiv.org/abs/1909.06988",
    "authors": [
      "Sidhanth Mohanty",
      "Ryan O'Donnell",
      "Pedro Paredes"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:1910.05492",
    "title": "Multi-objective Evolutionary Algorithms are Still Good: Maximizing  Monotone Approximately Submodular Minus Modular Functions",
    "abstract": " Title: Multi-objective Evolutionary Algorithms are Still Good: Maximizing  Monotone Approximately Submodular Minus Modular Functions ",
    "url": "https://arxiv.org/abs/1910.05492",
    "authors": [
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2003.08080",
    "title": "Improving the Robustness to Data Inconsistency between Training and  Testing for Code Completion by Hierarchical Language Model",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2003.08080",
    "authors": [
      "Yixiao Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2003.11313",
    "title": "Fair allocation of indivisible items with conflict graphs",
    "abstract": " Comments: A preliminary version containing some of the results presented here appeared in the proceedings of IWOCA 2020 ",
    "url": "https://arxiv.org/abs/2003.11313",
    "authors": [
      "Nina Chiarelli",
      "Matja\u017e Krnc",
      "Martin Milani\u010d",
      "Ulrich Pferschy",
      "Nevena Piva\u010d",
      "Joachim Schauer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2009.04975",
    "title": "Forecasting financial markets with semantic network analysis in the  COVID-19 crisis",
    "abstract": " Title: Forecasting financial markets with semantic network analysis in the  COVID-19 crisis ",
    "url": "https://arxiv.org/abs/2009.04975",
    "authors": [
      "A. Fronzetti Colladon",
      "S. Grassi",
      "F. Ravazzolo",
      "F. Violante"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2106.03844",
    "title": "Mean-Shifted Contrastive Loss for Anomaly Detection",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2106.03844",
    "authors": [
      "Tal Reiss",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.11299",
    "title": "Boundary Graph Neural Networks for 3D Simulations",
    "abstract": " Comments: accepted for presentation at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23) ",
    "url": "https://arxiv.org/abs/2106.11299",
    "authors": [
      "Andreas Mayr",
      "Sebastian Lehner",
      "Arno Mayrhofer",
      "Christoph Kloss",
      "Sepp Hochreiter",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.09543",
    "title": "Data synthesis and adversarial networks: A review and meta-analysis in  cancer imaging",
    "abstract": " Comments: v2, 51 pages, 15 Figures, 9 Tables, accepted for publication in Medical Image Analysis ",
    "url": "https://arxiv.org/abs/2107.09543",
    "authors": [
      "Richard Osuala",
      "Kaisar Kushibar",
      "Lidia Garrucho",
      "Akis Linardos",
      "Zuzanna Szafranowska",
      "Stefan Klein",
      "Ben Glocker",
      "Oliver Diaz",
      "Karim Lekadir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.00207",
    "title": "The Separation Capacity of Random Neural Networks",
    "abstract": " Comments: The current version of the manuscript has been accepted to Journal of Machine Learning Research ",
    "url": "https://arxiv.org/abs/2108.00207",
    "authors": [
      "Sjoerd Dirksen",
      "Martin Genzel",
      "Laurent Jacques",
      "Alexander Stollenwerk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2109.12769",
    "title": "Heterogeneous Treatment Effect Estimation using machine learning for  Healthcare application: tutorial and benchmark",
    "abstract": " Comments: 52 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2109.12769",
    "authors": [
      "Yaobin Ling",
      "Pulakesh Upadhyaya",
      "Luyao Chen",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2110.08298",
    "title": "Non-Euclidean Contraction Analysis of Continuous-Time Neural Networks",
    "abstract": " Title: Non-Euclidean Contraction Analysis of Continuous-Time Neural Networks ",
    "url": "https://arxiv.org/abs/2110.08298",
    "authors": [
      "Alexander Davydov",
      "Anton V. Proskurnikov",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2111.12958",
    "title": "Self-Distilled Self-Supervised Representation Learning",
    "abstract": " Comments: WACV 23, 11 pages ",
    "url": "https://arxiv.org/abs/2111.12958",
    "authors": [
      "Jiho Jang",
      "Seonhoon Kim",
      "Kiyoon Yoo",
      "Chaerin Kong",
      "Jangho Kim",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.00639",
    "title": "A Systematic Review of Robustness in Deep Learning for Computer Vision:  Mind the gap?",
    "abstract": " Title: A Systematic Review of Robustness in Deep Learning for Computer Vision:  Mind the gap? ",
    "url": "https://arxiv.org/abs/2112.00639",
    "authors": [
      "Nathan Drenkow",
      "Numair Sani",
      "Ilya Shpitser",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01517",
    "title": "Efficient Neural Radiance Fields for Interactive Free-viewpoint Video",
    "abstract": " Comments: SIGGRAPH Asia 2022; Project page: this https URL ",
    "url": "https://arxiv.org/abs/2112.01517",
    "authors": [
      "Haotong Lin",
      "Sida Peng",
      "Zhen Xu",
      "Yunzhi Yan",
      "Qing Shuai",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.02731",
    "title": "Detecting DeFi Securities Violations from Token Smart Contract Code",
    "abstract": " Title: Detecting DeFi Securities Violations from Token Smart Contract Code ",
    "url": "https://arxiv.org/abs/2112.02731",
    "authors": [
      "Arianna Trozze",
      "Bennett Kleinberg",
      "Toby Davies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.10644",
    "title": "Self-attention Presents Low-dimensional Knowledge Graph Embeddings for  Link Prediction",
    "abstract": " Comments: 14 pages, 3 figure, 6 tables ",
    "url": "https://arxiv.org/abs/2112.10644",
    "authors": [
      "Peyman Baghershahi",
      "Reshad Hosseini",
      "Hadi Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.01825",
    "title": "Planted Dense Subgraphs in Dense Random Graphs Can Be Recovered using  Graph-based Machine Learning",
    "abstract": " Title: Planted Dense Subgraphs in Dense Random Graphs Can Be Recovered using  Graph-based Machine Learning ",
    "url": "https://arxiv.org/abs/2201.01825",
    "authors": [
      "Itay Levinas",
      "Yoram Louzoun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.05242",
    "title": "Neural Circuit Architectural Priors for Embodied Control",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2201.05242",
    "authors": [
      "Nikhil X. Bhattasali",
      "Anthony M. Zador",
      "Tatiana A. Engel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2201.06714",
    "title": "AdaTerm: Adaptive T-Distribution Estimated Robust Moments towards  Noise-Robust Stochastic Gradient Optimizer",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2201.06714",
    "authors": [
      "Wendyam Eric Lionel Ilboudo",
      "Taisuke Kobayashi",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06464",
    "title": "Synthetic Data Can Also Teach: Synthesizing Effective Data for  Unsupervised Visual Representation Learning",
    "abstract": " Title: Synthetic Data Can Also Teach: Synthesizing Effective Data for  Unsupervised Visual Representation Learning ",
    "url": "https://arxiv.org/abs/2202.06464",
    "authors": [
      "Yawen Wu",
      "Zhepeng Wang",
      "Dewen Zeng",
      "Yiyu Shi",
      "Jingtong Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01442",
    "title": "Deformable Radar Polygon: A Lightweight and Predictable Occupancy  Representation for Short-range Collision Avoidance",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2203.01442",
    "authors": [
      "Gao Xiangyu",
      "Ding Sihao",
      "Vanas Karl",
      "Dasari Harshavardhan Reddy",
      "Soderlund Henrik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.03805",
    "title": "Discrete Robust Control of Robot Manipulators using an Uncertainty and  Disturbance Estimator",
    "abstract": " Comments: 20 pages, 7 figures, 1 table ",
    "url": "https://arxiv.org/abs/2203.03805",
    "authors": [
      "Ram Padmanabhan",
      "Maithili Shetty",
      "T. S. Chandar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.05550",
    "title": "Back to the Feature: Classical 3D Features are (Almost) All You Need for  3D Anomaly Detection",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2203.05550",
    "authors": [
      "Eliahu Horwitz",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15368",
    "title": "Multiclass classification using quantum convolutional neural networks  with hybrid quantum-classical learning",
    "abstract": " Comments: 7 pages, 5 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2203.15368",
    "authors": [
      "Denis Bokhan",
      "Alena S. Mastiukova",
      "Aleksey S. Boev",
      "Dmitrii N. Trubnikov",
      "Aleksey K. Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.06365",
    "title": "Fractional-Step Runge--Kutta Methods: Representation and Linear  Stability Analysis",
    "abstract": " Title: Fractional-Step Runge--Kutta Methods: Representation and Linear  Stability Analysis ",
    "url": "https://arxiv.org/abs/2205.06365",
    "authors": [
      "Raymond J. Spiteri",
      "Siqi Wei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.07134",
    "title": "ETAD: Training Action Detection End to End on a Laptop",
    "abstract": " Title: ETAD: Training Action Detection End to End on a Laptop ",
    "url": "https://arxiv.org/abs/2205.07134",
    "authors": [
      "Shuming Liu",
      "Mengmeng Xu",
      "Chen Zhao",
      "Xu Zhao",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13189",
    "title": "AI for Porosity and Permeability Prediction from Geologic Core X-Ray  Micro-Tomography",
    "abstract": " Title: AI for Porosity and Permeability Prediction from Geologic Core X-Ray  Micro-Tomography ",
    "url": "https://arxiv.org/abs/2205.13189",
    "authors": [
      "Zangir Iklassov",
      "Dmitrii Medvedev",
      "Otabek Nazarov",
      "Shakhboz Razzokov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00803",
    "title": "Robust recovery of low-rank matrices and low-tubal-rank tensors from  noisy sketches",
    "abstract": " Comments: Major revision. 21 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2206.00803",
    "authors": [
      "Anna Ma",
      "Dominik St\u00f6ger",
      "Yizhe Zhu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2206.01506",
    "title": "Can Hybrid Geometric Scattering Networks Help Solve the Maximum Clique  Problem?",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.01506",
    "authors": [
      "Yimeng Min",
      "Frederik Wenkel",
      "Michael Perlmutter",
      "Guy Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04281",
    "title": "Local Spatiotemporal Representation Learning for  Longitudinally-consistent Neuroimage Analysis",
    "abstract": " Comments: Camera ready for NeurIPS. Code available at this https URL; Project page: this https URL ",
    "url": "https://arxiv.org/abs/2206.04281",
    "authors": [
      "Mengwei Ren",
      "Neel Dey",
      "Martin A. Styner",
      "Kelly Botteron",
      "Guido Gerig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05498",
    "title": "A Review of Causality for Learning Algorithms in Medical Image Analysis",
    "abstract": " Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL\". ; Paper ID: 2022:028 ",
    "url": "https://arxiv.org/abs/2206.05498",
    "authors": [
      "Athanasios Vlontzos",
      "Daniel Rueckert",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)"
    ]
  },
  {
    "id": "arXiv:2206.10999",
    "title": "Neural Networks as Paths through the Space of Representations",
    "abstract": " Comments: 10 pages, submitted to ICLR 2023 ",
    "url": "https://arxiv.org/abs/2206.10999",
    "authors": [
      "Richard D. Lange",
      "Devin Kwok",
      "Jordan Matelsky",
      "Xinyue Wang",
      "David S. Rolnick",
      "Konrad P. Kording"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.11896",
    "title": "EventNeRF: Neural Radiance Fields from a Single Colour Event Camera",
    "abstract": " Comments: 18 pages, 18 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2206.11896",
    "authors": [
      "Viktor Rudnev",
      "Mohamed Elgharib",
      "Christian Theobalt",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.12933",
    "title": "Wiener Graph Deconvolutional Network Improves Graph Self-Supervised  Learning",
    "abstract": " Comments: 13 pages; Accepted to AAAI'23 ",
    "url": "https://arxiv.org/abs/2206.12933",
    "authors": [
      "Jiashun Cheng",
      "Man Li",
      "Jia Li",
      "Fugee Tsung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02108",
    "title": "AI-based Malware and Ransomware Detection Models",
    "abstract": " Title: AI-based Malware and Ransomware Detection Models ",
    "url": "https://arxiv.org/abs/2207.02108",
    "authors": [
      "Benjamin Marais",
      "Tony Quertier",
      "St\u00e9phane Morucci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04491",
    "title": "DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in  Transformer",
    "abstract": " Comments: Accepted to AAAI 2023 ",
    "url": "https://arxiv.org/abs/2207.04491",
    "authors": [
      "Maoyuan Ye",
      "Jing Zhang",
      "Shanshan Zhao",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07933",
    "title": "Consistency of Implicit and Explicit Features Matters for Monocular 3D  Object Detection",
    "abstract": " Comments: 10 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2207.07933",
    "authors": [
      "Qian Ye",
      "Ling Jiang",
      "Wang Zhen",
      "Yuyang Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08779",
    "title": "Simplifying Clustering with Graph Neural Networks",
    "abstract": " Title: Simplifying Clustering with Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2207.08779",
    "authors": [
      "Filippo Maria Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12673",
    "title": "A Data Driven Method for Multi-step Prediction of Ship Roll Motion in  High Sea States",
    "abstract": " Title: A Data Driven Method for Multi-step Prediction of Ship Roll Motion in  High Sea States ",
    "url": "https://arxiv.org/abs/2207.12673",
    "authors": [
      "Dan Zhang",
      "Xi Zhou",
      "Zi-Hao Wang",
      "Yan Peng",
      "Shao-Rong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2207.14083",
    "title": "Weakly-Supervised Camouflaged Object Detection with Scribble Annotations",
    "abstract": " Comments: Accepted to AAAI 2023. The code and dataset are available at this https URL ",
    "url": "https://arxiv.org/abs/2207.14083",
    "authors": [
      "Ruozhen He",
      "Qihua Dong",
      "Jiaying Lin",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00671",
    "title": "RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports",
    "abstract": " Title: RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports ",
    "url": "https://arxiv.org/abs/2208.00671",
    "authors": [
      "Jiang Wu",
      "Dongyu Liu",
      "Ziyang Guo",
      "Yingcai Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.03111",
    "title": "Data-free Backdoor Removal based on Channel Lipschitzness",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2208.03111",
    "authors": [
      "Runkai Zheng",
      "Rongjun Tang",
      "Jianze Li",
      "Li Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.03523",
    "title": "Generalizing Downsampling from Regular Data to Graphs",
    "abstract": " Comments: Accepted at AAAI 2023; Extended version with proofs ",
    "url": "https://arxiv.org/abs/2208.03523",
    "authors": [
      "Davide Bacciu",
      "Alessio Conte",
      "Francesco Landolfi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.07541",
    "title": "Social Interactions for Autonomous Driving: A Review and Perspectives",
    "abstract": " Comments: 183 pages, 36 figures ",
    "url": "https://arxiv.org/abs/2208.07541",
    "authors": [
      "Wenshuo Wang",
      "Letian Wang",
      "Chengyuan Zhang",
      "Changliu Liu",
      "Lijun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.10244",
    "title": "Unit Testing for Concepts in Neural Networks",
    "abstract": " Comments: TACL, In Press. 12 Pages ",
    "url": "https://arxiv.org/abs/2208.10244",
    "authors": [
      "Charles Lovering",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10364",
    "title": "Scaling Up Dynamic Graph Representation Learning via Spiking Neural  Networks",
    "abstract": " Comments: Accepted by AAAI 2023.Contains appendix with additional details about algorithms and experiments. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2208.10364",
    "authors": [
      "Jintang Li",
      "Zhouxin Yu",
      "Zulun Zhu",
      "Liang Chen",
      "Qi Yu",
      "Zibin Zheng",
      "Sheng Tian",
      "Ruofan Wu",
      "Changhua Meng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.12866",
    "title": "Reducing Computational Complexity of Neural Networks in Optical Channel  Equalization: From Concepts to Implementation",
    "abstract": " Title: Reducing Computational Complexity of Neural Networks in Optical Channel  Equalization: From Concepts to Implementation ",
    "url": "https://arxiv.org/abs/2208.12866",
    "authors": [
      "Pedro J. Freire",
      "Antonio Napoli",
      "Diego Arguello Ron",
      "Bernhard Spinnler",
      "Michael Anderson",
      "Wolfgang Schairer",
      "Thomas Bex",
      "Nelson Costa",
      "Sergei K. Turitsyn",
      "Jaroslaw E. Prilepsky"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computational Complexity (cs.CC)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.14226",
    "title": "Unsupervised Representation Learning in Deep Reinforcement Learning: A  Review",
    "abstract": " Title: Unsupervised Representation Learning in Deep Reinforcement Learning: A  Review ",
    "url": "https://arxiv.org/abs/2208.14226",
    "authors": [
      "Nicol\u00f2 Botteghi",
      "Mannes Poel",
      "Christoph Brune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.00721",
    "title": "Generalizing intrusion detection for heterogeneous networks: A  stacked-unsupervised federated learning approach",
    "abstract": " Comments: Preprint (Under revision), 35 pages. Added repository link, see this https URL ",
    "url": "https://arxiv.org/abs/2209.00721",
    "authors": [
      "Gustavo de Carvalho Bertoli",
      "Louren\u00e7o Alves Pereira Junior",
      "Aldri Luiz dos Santos",
      "Osamu Saotome"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.04903",
    "title": "Cores of Games via Total Dual Integrality, with Applications to Perfect  Graphs and Polymatroids",
    "abstract": " Comments: 14 pages. arXiv admin note: text overlap with arXiv:2202.00619 ",
    "url": "https://arxiv.org/abs/2209.04903",
    "authors": [
      "Vijay V. Vazirani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2209.06434",
    "title": "ConvNeXt Based Neural Network for Audio Anti-Spoofing",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2209.06434",
    "authors": [
      "Qiaowei Ma",
      "Jinghui Zhong",
      "Yitao Yang",
      "Weiheng Liu",
      "Ying Gao",
      "Wing W.Y. Ng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.06896",
    "title": "Persistently Feasible Robust Safe Control by Safety Index Synthesis and  Convex Semi-Infinite Programming",
    "abstract": " Title: Persistently Feasible Robust Safe Control by Safety Index Synthesis and  Convex Semi-Infinite Programming ",
    "url": "https://arxiv.org/abs/2209.06896",
    "authors": [
      "Tianhao Wei",
      "Shucheng Kang",
      "Weiye Zhao",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.11979",
    "title": "Robust Hyperspectral Image Fusion with Simultaneous Guide Image  Denoising via Constrained Convex Optimization",
    "abstract": " Comments: Accepted to IEEE Transactions on Geoscience and Remote Sensing ",
    "url": "https://arxiv.org/abs/2209.11979",
    "authors": [
      "Saori Takeyama",
      "Shunsuke Ono"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01869",
    "title": "Memory in humans and deep language models: Linking hypotheses for model  augmentation",
    "abstract": " Comments: 6 figures ",
    "url": "https://arxiv.org/abs/2210.01869",
    "authors": [
      "Omri Raccah",
      "Phoebe Chen",
      "Ted L. Willke",
      "David Poeppel",
      "Vy A. Vo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05976",
    "title": "Human Joint Kinematics Diffusion-Refinement for Stochastic Motion  Prediction",
    "abstract": " Comments: Accepted by AAAI2023 ",
    "url": "https://arxiv.org/abs/2210.05976",
    "authors": [
      "Dong Wei",
      "Huaijiang Sun",
      "Bin Li",
      "Jianfeng Lu",
      "Weiqing Li",
      "Xiaoning Sun",
      "Shengxiang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06853",
    "title": "NeuralRoom: Geometry-Constrained Neural Implicit Surfaces for Indoor  Scene Reconstruction",
    "abstract": " Title: NeuralRoom: Geometry-Constrained Neural Implicit Surfaces for Indoor  Scene Reconstruction ",
    "url": "https://arxiv.org/abs/2210.06853",
    "authors": [
      "Yusen Wang",
      "Zongcheng Li",
      "Yu Jiang",
      "Kaixuan Zhou",
      "Tuo Cao",
      "Yanping Fu",
      "Chunxia Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.17274",
    "title": "Anomaly Detection in Additive Manufacturing Processes using Supervised  Classification with Imbalanced Sensor Data based on Generative Adversarial  Network",
    "abstract": " Title: Anomaly Detection in Additive Manufacturing Processes using Supervised  Classification with Imbalanced Sensor Data based on Generative Adversarial  Network ",
    "url": "https://arxiv.org/abs/2210.17274",
    "authors": [
      "Jihoon Chung",
      "Bo Shen",
      "Zhenyu",
      "Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.01112",
    "title": "Adversarial Attack on Radar-based Environment Perception Systems",
    "abstract": " Title: Adversarial Attack on Radar-based Environment Perception Systems ",
    "url": "https://arxiv.org/abs/2211.01112",
    "authors": [
      "Amira Guesmi",
      "Ihsen Alouani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.02213",
    "title": "SSDA-YOLO: Semi-supervised Domain Adaptive YOLO for Cross-Domain Object  Detection",
    "abstract": " Comments: submitted to CVIU ",
    "url": "https://arxiv.org/abs/2211.02213",
    "authors": [
      "Huayi Zhou",
      "Fei Jiang",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.02396",
    "title": "Rethinking the positive role of cluster structure in complex networks  for link prediction tasks",
    "abstract": " Comments: 15 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2211.02396",
    "authors": [
      "Shanfan Zhang",
      "Wenjiao Zhang",
      "Zhan Bu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.03550",
    "title": "Underwater Image Super-Resolution using Generative Adversarial  Network-based Model",
    "abstract": " Title: Underwater Image Super-Resolution using Generative Adversarial  Network-based Model ",
    "url": "https://arxiv.org/abs/2211.03550",
    "authors": [
      "Alireza Aghelan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.04442",
    "title": "Algorithmic Bias in Machine Learning Based Delirium Prediction",
    "abstract": " Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages ",
    "url": "https://arxiv.org/abs/2211.04442",
    "authors": [
      "Sandhya Tripathi",
      "Bradley A Fritz",
      "Michael S Avidan",
      "Yixin Chen",
      "Christopher R King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05172",
    "title": "Speech separation with large-scale self-supervised learning",
    "abstract": " Title: Speech separation with large-scale self-supervised learning ",
    "url": "https://arxiv.org/abs/2211.05172",
    "authors": [
      "Zhuo Chen",
      "Naoyuki Kanda",
      "Jian Wu",
      "Yu Wu",
      "Xiaofei Wang",
      "Takuya Yoshioka",
      "Jinyu Li",
      "Sunit Sivasankaran",
      "Sefik Emre Eskimez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.08615",
    "title": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "abstract": " Title: GLFF: Global and Local Feature Fusion for Face Forgery Detection ",
    "url": "https://arxiv.org/abs/2211.08615",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Jialing Cai",
      "Haiying Guan",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.09184",
    "title": "An Empirical Analysis of the Advantages of Finite- v.s. Infinite-Width  Bayesian Neural Networks",
    "abstract": " Title: An Empirical Analysis of the Advantages of Finite- v.s. Infinite-Width  Bayesian Neural Networks ",
    "url": "https://arxiv.org/abs/2211.09184",
    "authors": [
      "Jiayu Yao",
      "Yaniv Yacoby",
      "Beau Coker",
      "Weiwei Pan",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10052",
    "title": "Pedestrian Spatio-Temporal Information Fusion For Video Anomaly  Detection",
    "abstract": " Comments: International Conference on Intelligent Media, Big Data and Knowledge Mining ",
    "url": "https://arxiv.org/abs/2211.10052",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10227",
    "title": "Adversarial Detection by Approximation of Ensemble Boundary",
    "abstract": " Comments: 6 pages, 3 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2211.10227",
    "authors": [
      "T. Windeatt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10486",
    "title": "DGRec: Graph Neural Network for Recommendation with Diversified  Embedding Generation",
    "abstract": " Comments: 9 pages, WSDM 2023 ",
    "url": "https://arxiv.org/abs/2211.10486",
    "authors": [
      "Liangwei Yang",
      "Shengjie Wang",
      "Yunzhe Tao",
      "Jiankai Sun",
      "Xiaolong Liu",
      "Philip S. Yu",
      "Taiqing Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.11082",
    "title": "DynIBaR: Neural Dynamic Image-Based Rendering",
    "abstract": " Comments: Project page: dynibar.github.io ",
    "url": "https://arxiv.org/abs/2211.11082",
    "authors": [
      "Zhengqi Li",
      "Qianqian Wang",
      "Forrester Cole",
      "Richard Tucker",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12051",
    "title": "Adaptive Dynamic Filtering Network for Image Denoising",
    "abstract": " Comments: 9 pages, Accepted in AAAI Conference on Artificial Intelligence (AAAI) 2023 ",
    "url": "https://arxiv.org/abs/2211.12051",
    "authors": [
      "Hao Shen",
      "Zhong-Qiu Zhao",
      "Wandi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12141",
    "title": "MGADN: A Multi-task Graph Anomaly Detection Network for Multivariate  Time Series",
    "abstract": " Title: MGADN: A Multi-task Graph Anomaly Detection Network for Multivariate  Time Series ",
    "url": "https://arxiv.org/abs/2211.12141",
    "authors": [
      "Weixuan Xiong",
      "Xiaochen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12311",
    "title": "Generalizable Industrial Visual Anomaly Detection with Self-Induction  Vision Transformer",
    "abstract": " Comments: 8 pages, 6 figures, ",
    "url": "https://arxiv.org/abs/2211.12311",
    "authors": [
      "Haiming Yao",
      "Xue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12857",
    "title": "Explaining Image Classifiers with Multiscale Directional Image  Representation",
    "abstract": " Title: Explaining Image Classifiers with Multiscale Directional Image  Representation ",
    "url": "https://arxiv.org/abs/2211.12857",
    "authors": [
      "Stefan Kolek",
      "Robert Windesheim",
      "Hector Andrade Loarca",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13226",
    "title": "ClimateNeRF: Physically-based Neural Rendering for Extreme Climate  Synthesis",
    "abstract": " Comments: project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.13226",
    "authors": [
      "Yuan Li",
      "Zhi-Hao Lin",
      "David Forsyth",
      "Jia-Bin Huang",
      "Shenlong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.13234",
    "title": "RNTrajRec: Road Network Enhanced Trajectory Recovery with  Spatial-Temporal Transformer",
    "abstract": " Title: RNTrajRec: Road Network Enhanced Trajectory Recovery with  Spatial-Temporal Transformer ",
    "url": "https://arxiv.org/abs/2211.13234",
    "authors": [
      "Yuqi Chen",
      "Hanyuan Zhang",
      "Weiwei Sun",
      "Baihua Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13649",
    "title": "End-to-end Wind Turbine Wake Modelling with Deep Graph Representation  Learning",
    "abstract": " Comments: 20 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2211.13649",
    "authors": [
      "Siyi Li",
      "Mingrui Zhang",
      "Matthew D. Piggott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2211.13670",
    "title": "SmartIntentNN: Towards Smart Contract Intent Detection",
    "abstract": " Comments: 4 pages, 3 figures, conference tool track. arXiv admin note: substantial text overlap with arXiv:2211.10724 ",
    "url": "https://arxiv.org/abs/2211.13670",
    "authors": [
      "Youwei Huang",
      "Tao Zhang",
      "Sen Fang",
      "Youshuai Tan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.13787",
    "title": "Semantic Communication Enabling Robust Edge Intelligence for  Time-Critical IoT Applications",
    "abstract": " Title: Semantic Communication Enabling Robust Edge Intelligence for  Time-Critical IoT Applications ",
    "url": "https://arxiv.org/abs/2211.13787",
    "authors": [
      "Andrea Cavagna",
      "Nan Li",
      "Alexandros Iosifidis",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.13964",
    "title": "Generating 2D and 3D Master Faces for Dictionary Attacks with a  Network-Assisted Latent Space Evolution",
    "abstract": " Comments: accepted for publication in IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM). This paper extends arXiv:2108.01077 that was accepted to IEEE FG 2021 ",
    "url": "https://arxiv.org/abs/2211.13964",
    "authors": [
      "Tomer Friedlander",
      "Ron Shmelkin",
      "Lior Wolf"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.13968",
    "title": "MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly  Detection",
    "abstract": " Title: MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2211.13968",
    "authors": [
      "Tianpeng Bao",
      "Jiadong Chen",
      "Wei Li",
      "Xiang Wang",
      "Jingjing Fei",
      "Liwei Wu",
      "Rui Zhao",
      "Ye Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14297",
    "title": "Doubly robust nearest neighbors in factor models",
    "abstract": " Title: Doubly robust nearest neighbors in factor models ",
    "url": "https://arxiv.org/abs/2211.14297",
    "authors": [
      "Raaz Dwivedi",
      "Katherine Tian",
      "Sabina Tomkins",
      "Predrag Klasnja",
      "Susan Murphy",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  }
]