[
  {
    "id": "arXiv:2211.08429",
    "title": "An Automatic ICD Coding Network Using Partition-Based Label Attention",
    "abstract": "International Classification of Diseases (ICD) is a global medical classification system which provides unique codes for diagnoses and procedures appropriate to a patient's clinical record. However, manual coding by human coders is expensive and error-prone. Automatic ICD coding has the potential to solve this problem. With the advancement of deep learning technologies, many deep learning-based methods for automatic ICD coding are being developed. In particular, a label attention mechanism is effective for multi-label classification, i.e., the ICD coding. It effectively obtains the label-specific representations from the input clinical records. However, because the existing label attention mechanism finds key tokens in the entire text at once, the important information dispersed in each paragraph may be omitted from the attention map. To overcome this, we propose a novel neural network architecture composed of two parts of encoders and two kinds of label attention layers. The input text is segmentally encoded in the former encoder and integrated by the follower. Then, the conventional and partition-based label attention mechanisms extract important global and local feature representations. Our classifier effectively integrates them to enhance the ICD coding performance. We verified the proposed method using the MIMIC-III, a benchmark dataset of the ICD coding. Our results show that our network improves the ICD coding performance based on the partition-based mechanism. ",
    "url": "https://arxiv.org/abs/2211.08429",
    "authors": [
      "Daeseong Kim",
      "Haanju Yoo",
      "Sewon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.08447",
    "title": "SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic  Specialisation for Chinese Sexism Detection in Social Media",
    "abstract": "The goal of sexism detection is to mitigate negative online content targeting certain gender groups of people. However, the limited availability of labeled sexism-related datasets makes it problematic to identify online sexism for low-resource languages. In this paper, we address the task of automatic sexism detection in social media for one low-resource language -- Chinese. Rather than collecting new sexism data or building cross-lingual transfer learning models, we develop a cross-lingual domain-aware semantic specialisation system in order to make the most of existing data. Semantic specialisation is a technique for retrofitting pre-trained distributional word vectors by integrating external linguistic knowledge (such as lexico-semantic relations) into the specialised feature space. To do this, we leverage semantic resources for sexism from a high-resource language (English) to specialise pre-trained word vectors in the target language (Chinese) to inject domain knowledge. We demonstrate the benefit of our sexist word embeddings (SexWEs) specialised by our framework via intrinsic evaluation of word similarity and extrinsic evaluation of sexism detection. Compared with other specialisation approaches and Chinese baseline word vectors, our SexWEs shows an average score improvement of 0.033 and 0.064 in both intrinsic and extrinsic evaluations, respectively. The ablative results and visualisation of SexWEs also prove the effectiveness of our framework on retrofitting word vectors in low-resource languages. Our code and sexism-related word vectors will be publicly available. ",
    "url": "https://arxiv.org/abs/2211.08447",
    "authors": [
      "Aiqi Jiang",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.08453",
    "title": "Improved techniques for deterministic l2 robustness",
    "abstract": "Training convolutional neural networks (CNNs) with a strict 1-Lipschitz constraint under the $l_{2}$ norm is useful for adversarial robustness, interpretable gradients and stable training. 1-Lipschitz CNNs are usually designed by enforcing each layer to have an orthogonal Jacobian matrix (for all inputs) to prevent the gradients from vanishing during backpropagation. However, their performance often significantly lags behind that of heuristic methods to enforce Lipschitz constraints where the resulting CNN is not \\textit{provably} 1-Lipschitz. In this work, we reduce this gap by introducing (a) a procedure to certify robustness of 1-Lipschitz CNNs by replacing the last linear layer with a 1-hidden layer MLP that significantly improves their performance for both standard and provably robust accuracy, (b) a method to significantly reduce the training time per epoch for Skew Orthogonal Convolution (SOC) layers (>30\\% reduction for deeper networks) and (c) a class of pooling layers using the mathematical property that the $l_{2}$ distance of an input to a manifold is 1-Lipschitz. Using these methods, we significantly advance the state-of-the-art for standard and provable robust accuracies on CIFAR-10 (gains of +1.79\\% and +3.82\\%) and similarly on CIFAR-100 (+3.78\\% and +4.75\\%) across all networks. Code is available at \\url{https://github.com/singlasahil14/improved_l2_robustness}. ",
    "url": "https://arxiv.org/abs/2211.08453",
    "authors": [
      "Sahil Singla",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08458",
    "title": "Latent Bottlenecked Attentive Neural Processes",
    "abstract": "Neural Processes (NPs) are popular methods in meta-learning that can estimate predictive uncertainty on target datapoints by conditioning on a context dataset. Previous state-of-the-art method Transformer Neural Processes (TNPs) achieve strong performance but require quadratic computation with respect to the number of context datapoints, significantly limiting its scalability. Conversely, existing sub-quadratic NP variants perform significantly worse than that of TNPs. Tackling this issue, we propose Latent Bottlenecked Attentive Neural Processes (LBANPs), a new computationally efficient sub-quadratic NP variant, that has a querying computational complexity independent of the number of context datapoints. The model encodes the context dataset into a constant number of latent vectors on which self-attention is performed. When making predictions, the model retrieves higher-order information from the context dataset via multiple cross-attention mechanisms on the latent vectors. We empirically show that LBANPs achieve results competitive with the state-of-the-art on meta-regression, image completion, and contextual multi-armed bandits. We demonstrate that LBANPs can trade-off the computational cost and performance according to the number of latent vectors. Finally, we show LBANPs can scale beyond existing attention-based NP variants to larger dataset settings. ",
    "url": "https://arxiv.org/abs/2211.08458",
    "authors": [
      "Leo Feng",
      "Hossein Hajimirsadeghi",
      "Yoshua Bengio",
      "Mohamed Osama Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08461",
    "title": "Mind Your Bias: A Critical Review of Bias Detection Methods for  Contextual Language Models",
    "abstract": "The awareness and mitigation of biases are of fundamental importance for the fair and transparent use of contextual language models, yet they crucially depend on the accurate detection of biases as a precursor. Consequently, numerous bias detection methods have been proposed, which vary in their approach, the considered type of bias, and the data used for evaluation. However, while most detection methods are derived from the word embedding association test for static word embeddings, the reported results are heterogeneous, inconsistent, and ultimately inconclusive. To address this issue, we conduct a rigorous analysis and comparison of bias detection methods for contextual language models. Our results show that minor design and implementation decisions (or errors) have a substantial and often significant impact on the derived bias scores. Overall, we find the state of the field to be both worse than previously acknowledged due to systematic and propagated errors in implementations, yet better than anticipated since divergent results in the literature homogenize after accounting for implementation errors. Based on our findings, we conclude with a discussion of paths towards more robust and consistent bias detection methods. ",
    "url": "https://arxiv.org/abs/2211.08461",
    "authors": [
      "Silke Husse",
      "Andreas Spitz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.08469",
    "title": "Deep learning for table detection and structure recognition: A survey",
    "abstract": "Tables are everywhere, from scientific journals, papers, websites, and newspapers all the way to items we buy at the supermarket. Detecting them is thus of utmost importance to automatically understanding the content of a document. The performance of table detection has substantially increased thanks to the rapid development of deep learning networks. The goals of this survey are to provide a profound comprehension of the major developments in the field of Table Detection, offer insight into the different methodologies, and provide a systematic taxonomy of the different approaches. Furthermore, we provide an analysis of both classic and new applications in the field. Lastly, the datasets and source code of the existing models are organized to provide the reader with a compass on this vast literature. Finally, we go over the architecture of utilizing various object detection and table structure recognition methods to create an effective and efficient system, as well as a set of development trends to keep up with state-of-the-art algorithms and future research. We have also set up a public GitHub repository where we will be updating the most recent publications, open data, and source code. The GitHub repository is available at https://github.com/abdoelsayed2016/table-detection-structure-recognition. ",
    "url": "https://arxiv.org/abs/2211.08469",
    "authors": [
      "Mahmoud Kasem",
      "Abdelrahman Abdallah",
      "Alexander Berendeyev",
      "Ebrahem Elkady",
      "Mahmoud Abdalla",
      "Mohamed Mahmoud",
      "Mohamed Hamada",
      "Daniyar Nurseitov",
      "Islam Taj-Eddin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08479",
    "title": "Context-Matched Collage Generation for Underwater Invertebrate Detection",
    "abstract": "The quality and size of training sets often limit the performance of many state of the art object detectors. However, in many scenarios, it can be difficult to collect images for training, not to mention the costs associated with collecting annotations suitable for training these object detectors. For these reasons, on challenging video datasets such as the Dataset for Underwater Substrate and Invertebrate Analysis (DUSIA), budgets may only allow for collecting and providing partial annotations. To aid in the challenges associated with training with limited and partial annotations, we introduce Context Matched Collages, which leverage explicit context labels to combine unused background examples with existing annotated data to synthesize additional training samples that ultimately improve object detection performance. By combining a set of our generated collage images with the original training set, we see improved performance using three different object detectors on DUSIA, ultimately achieving state of the art object detection performance on the dataset. ",
    "url": "https://arxiv.org/abs/2211.08479",
    "authors": [
      "R. Austin McEver",
      "Bowen Zhang",
      "B.S. Manjunath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.08480",
    "title": "LiePoseNet: Heterogeneous Loss Function Based on Lie Group for  Significant Speed-up of PoseNet Training Process",
    "abstract": "Visual localization is an essential modern technology for robotics and computer vision. Popular approaches for solving this task are image-based methods. Nowadays, these methods have low accuracy and a long training time. The reasons are the lack of rigid-body and projective geometry awareness, landmark symmetry, and homogeneous error assumption. We propose a heterogeneous loss function based on concentrated Gaussian distribution with the Lie group to overcome these difficulties. Following our experiment, the proposed method allows us to speed up the training process significantly (from 300 to 10 epochs) with acceptable error values. ",
    "url": "https://arxiv.org/abs/2211.08480",
    "authors": [
      "Mikhail Kurenkov",
      "Ivan Kalinov",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.08486",
    "title": "Scalar Invariant Networks with Zero Bias",
    "abstract": "Just like weights, bias terms are the learnable parameters of many popular machine learning models, including neural networks. Biases are believed to effectively increase the representational power of neural networks to solve a wide range of tasks in computer vision. However, we argue that if we consider the intrinsic distribution of images in the input space as well as some desired properties a model should have from the first principles, biases can be completely ignored in addressing many image-related tasks, such as image classification. Our observation indicates that zero-bias neural networks could perform comparably to neural networks with bias at least on practical image classification tasks. In addition, we prove that zero-bias neural networks possess a nice property called scalar (multiplication) invariance, which has great potential in learning and understanding images captured under poor illumination conditions. We then extend scalar invariance to more general cases that allow us to verify certain convex regions of the input space. Our experimental results show that zero-bias models could outperform the state-of-art models by a very large margin (over 60%) when predicting images under a low illumination condition (multiplying a scalar of 0.01); while achieving the same-level performance as normal models. ",
    "url": "https://arxiv.org/abs/2211.08486",
    "authors": [
      "Chuqin Geng",
      "Xiaojie Xu",
      "Haolin Ye",
      "Xujie Si"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08501",
    "title": "Social Mechanism Design: A Low-Level Introduction",
    "abstract": "How do we deal with the fact that agents have preferences over both decision outcomes and the rules or procedures used to make decisions? If we create rules for aggregating preferences over rules, it would appear that we run into infinite regress with preferences and rules at successively higher \"levels.\" The starting point of our analysis is the claim that infinite regress should not be a problem in practice, as any such preferences will necessarily be bounded in complexity and structured coherently in accordance with some (possibly latent) normative principles. Our core contributions are (1) the identification of simple, intuitive preference structures at low levels that can be generalized to form the building blocks of preferences at higher levels, and (2) the development of algorithms for maximizing the number of agents with such low-level preferences who will \"accept\" a decision. We analyze algorithms for acceptance maximization in two different domains: asymmetric dichotomous choice and constitutional amendment. In both settings we study the worst-case performance of the appropriate algorithms, and reveal circumstances under which universal acceptance is possible. In particular, we show that constitutional amendment procedures proposed recently by Abramowitz, Shapiro, and Talmon (2021) can achieve universal acceptance. ",
    "url": "https://arxiv.org/abs/2211.08501",
    "authors": [
      "Ben Abramowitz",
      "Nicholas Mattei"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2211.08502",
    "title": "Active ReLU Linearized Neural Network based Frequency-Constrained Unit  Commitment in Low-Inertia Power Systems",
    "abstract": "Conventional synchronous generators are gradually being replaced by inverter-based resources. Such transition introduces more complicated operation conditions, and also imposes challenges for system operators on maintaining system frequency and rate-of-change-of-frequency (RoCoF) security due to reduction in system inertia. To ensure the system wide frequency security, this paper presents an active rectified linear unit (ReLU) linearized neural network (ARLNN) based RoCoF-constrained unit commitment (ARLNN-RCUC) model. A predictor is first trained to predict the highest locational RoCoF based on a high-fidelity simulation dataset. Instead of incorporating the complete trained neural network into unit commitment, a ReLU linearization method is implemented on selected neurons to improve the algorithm efficiency. The effectiveness of proposed ARLNN-RCUC model is demonstrated on the IEEE 24-bus system by conducting time domain simulation on PSS/E. ",
    "url": "https://arxiv.org/abs/2211.08502",
    "authors": [
      "Mingjian Tuo",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.08506",
    "title": "ParticleGrid: Enabling Deep Learning using 3D Representation of  Materials",
    "abstract": "From AlexNet to Inception, autoencoders to diffusion models, the development of novel and powerful deep learning models and learning algorithms has proceeded at breakneck speeds. In part, we believe that rapid iteration of model architecture and learning techniques by a large community of researchers over a common representation of the underlying entities has resulted in transferable deep learning knowledge. As a result, model scale, accuracy, fidelity, and compute performance have dramatically increased in computer vision and natural language processing. On the other hand, the lack of a common representation for chemical structure has hampered similar progress. To enable transferable deep learning, we identify the need for a robust 3-dimensional representation of materials such as molecules and crystals. The goal is to enable both materials property prediction and materials generation with 3D structures. While computationally costly, such representations can model a large set of chemical structures. We propose $\\textit{ParticleGrid}$, a SIMD-optimized library for 3D structures, that is designed for deep learning applications and to seamlessly integrate with deep learning frameworks. Our highly optimized grid generation allows for generating grids on the fly on the CPU, reducing storage and GPU compute and memory requirements. We show the efficacy of 3D grids generated via $\\textit{ParticleGrid}$ and accurately predict molecular energy properties using a 3D convolutional neural network. Our model is able to get 0.006 mean square error and nearly match the values calculated using computationally costly density functional theory at a fraction of the time. ",
    "url": "https://arxiv.org/abs/2211.08506",
    "authors": [
      "Shehtab Zaman",
      "Ethan Ferguson",
      "Cecile Pereira",
      "Denis Akhiyarov",
      "Mauricio Araya-Polo",
      "Kenneth Chiu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08508",
    "title": "Characterizing and Utilizing the Interplay between Quantum Technologies  and Non-Terrestrial Networks",
    "abstract": "Quantum technologies have been widely recognized as one of the milestones towards the ongoing digital transformation, which will also trigger new disruptive innovations. Quantum technologies encompassing quantum computing, communications, and sensing offer an interesting set of advantages such as unconditional security and ultra-fast computing capabilities. However, deploying quantum services at a global scale requires circumventing the limitations due to the geographical boundaries and terrestrial obstacles, which can be adequately addressed by considering non-terrestrial networks (NTNs). In the recent few years, establishing multi-layer NTNs has been extensively studied to integrate space-airborne-terrestrial communications systems, particularly by the international standardization organizations such as the third-generation partnership project (3GPP) and the international telecommunication union (ITU), in order to support future wireless ecosystems. Indeed, amalgamating quantum technologies and NTNs will scale up the quantum communications ranges and provide unprecedented levels of security and processing solutions that are safer and faster than the traditional offerings. This paper provides some insights into the interplay between the evolving NTN architectures and quantum technologies with a particular focus on the integration challenges and their potential solutions for enhancing the quantum-NTN interoperability among various space-air-ground communications nodes. The emphasis is on how the quantum technologies can benefit from satellites and aerial platforms as an integrated network and vice versa. Moreover, a set of future research directions and new opportunities are identified. ",
    "url": "https://arxiv.org/abs/2211.08508",
    "authors": [
      "Hayder Al-Hraishawi",
      "Junaid ur Rehman",
      "Mohsen Razavi",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.08512",
    "title": "N2V2 -- Fixing Noise2Void Checkerboard Artifacts with Modified Sampling  Strategies and a Tweaked Network Architecture",
    "abstract": "In recent years, neural network based image denoising approaches have revolutionized the analysis of biomedical microscopy data. Self-supervised methods, such as Noise2Void (N2V), are applicable to virtually all noisy datasets, even without dedicated training data being available. Arguably, this facilitated the fast and widespread adoption of N2V throughout the life sciences. Unfortunately, the blind-spot training underlying N2V can lead to rather visible checkerboard artifacts, thereby reducing the quality of final predictions considerably. In this work, we present two modifications to the vanilla N2V setup that both help to reduce the unwanted artifacts considerably. Firstly, we propose a modified network architecture, i.e., using BlurPool instead of MaxPool layers throughout the used U-Net, rolling back the residual U-Net to a non-residual U-Net, and eliminating the skip connections at the uppermost U-Net level. Additionally, we propose new replacement strategies to determine the pixel intensity values that fill in the elected blind-spot pixels. We validate our modifications on a range of microscopy and natural image data. Based on added synthetic noise from multiple noise types and at varying amplitudes, we show that both proposed modifications push the current state-of-the-art for fully self-supervised image denoising. ",
    "url": "https://arxiv.org/abs/2211.08512",
    "authors": [
      "Eva H\u00f6ck",
      "Tim-Oliver Buchholz",
      "Anselm Brachmann",
      "Florian Jug",
      "Alexander Freytag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08517",
    "title": "A Hierarchical Deep Neural Network for Detecting Lines of Codes with  Vulnerabilities",
    "abstract": "Software vulnerabilities, caused by unintentional flaws in source codes, are the main root cause of cyberattacks. Source code static analysis has been used extensively to detect the unintentional defects, i.e. vulnerabilities, introduced into the source codes by software developers. In this paper, we propose a deep learning approach to detect vulnerabilities from their LLVM IR representations based on the techniques that have been used in natural language processing. The proposed approach uses a hierarchical process to first identify source codes with vulnerabilities, and then it identifies the lines of codes that contribute to the vulnerability within the detected source codes. This proposed two-step approach reduces the false alarm of detecting vulnerable lines. Our extensive experiment on real-world and synthetic codes collected in NVD and SARD shows high accuracy (about 98\\%) in detecting source code vulnerabilities. ",
    "url": "https://arxiv.org/abs/2211.08517",
    "authors": [
      "Arash Mahyari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.08525",
    "title": "LEAN-DMKDE: Quantum Latent Density Estimation for Anomaly Detection",
    "abstract": "This paper presents an anomaly detection model that combines the strong statistical foundation of density-estimation-based anomaly detection methods with the representation-learning ability of deep-learning models. The method combines an autoencoder, for learning a low-dimensional representation of the data, with a density-estimation model based on random Fourier features and density matrices in an end-to-end architecture that can be trained using gradient-based optimization techniques. The method predicts a degree of normality for new samples based on the estimated density. A systematic experimental evaluation was performed on different benchmark datasets. The experimental results show that the method performs on par with or outperforms other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2211.08525",
    "authors": [
      "Joseph Gallego-Mejia",
      "Oscar Bustos-Brinez",
      "Fabio A. Gonz\u00e1lez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2211.08526",
    "title": "Alzheimer's Dementia Detection through Spontaneous Dialogue with  Proactive Robotic Listeners",
    "abstract": "As the aging of society continues to accelerate, Alzheimer's Disease (AD) has received more and more attention from not only medical but also other fields, such as computer science, over the past decade. Since speech is considered one of the effective ways to diagnose cognitive decline, AD detection from speech has emerged as a hot topic. Nevertheless, such approaches fail to tackle several key issues: 1) AD is a complex neurocognitive disorder which means it is inappropriate to conduct AD detection using utterance information alone while ignoring dialogue information; 2) Utterances of AD patients contain many disfluencies that affect speech recognition yet are helpful to diagnosis; 3) AD patients tend to speak less, causing dialogue breakdown as the disease progresses. This fact leads to a small number of utterances, which may cause detection bias. Therefore, in this paper, we propose a novel AD detection architecture consisting of two major modules: an ensemble AD detector and a proactive listener. This architecture can be embedded in the dialogue system of conversational robots for healthcare. ",
    "url": "https://arxiv.org/abs/2211.08526",
    "authors": [
      "Yuanchao Li",
      "Catherine Lai",
      "Divesh Lala",
      "Koji Inoue",
      "Tatsuya Kawahara"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.08533",
    "title": "A Point in the Right Direction: Vector Prediction for Spatially-aware  Self-supervised Volumetric Representation Learning",
    "abstract": "High annotation costs and limited labels for dense 3D medical imaging tasks have recently motivated an assortment of 3D self-supervised pretraining methods that improve transfer learning performance. However, these methods commonly lack spatial awareness despite its centrality in enabling effective 3D image analysis. More specifically, position, scale, and orientation are not only informative but also automatically available when generating image crops for training. Yet, to date, no work has proposed a pretext task that distills all key spatial features. To fulfill this need, we develop a new self-supervised method, VectorPOSE, which promotes better spatial understanding with two novel pretext tasks: Vector Prediction (VP) and Boundary-Focused Reconstruction (BFR). VP focuses on global spatial concepts (i.e., properties of 3D patches) while BFR addresses weaknesses of recent reconstruction methods to learn more effective local representations. We evaluate VectorPOSE on three 3D medical image segmentation tasks, showing that it often outperforms state-of-the-art methods, especially in limited annotation settings. ",
    "url": "https://arxiv.org/abs/2211.08533",
    "authors": [
      "Yejia Zhang",
      "Pengfei Gu",
      "Nishchal Sapkota",
      "Hao Zheng",
      "Peixian Liang",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08540",
    "title": "VGFlow: Visibility guided Flow Network for Human Reposing",
    "abstract": "The task of human reposing involves generating a realistic image of a person standing in an arbitrary conceivable pose. There are multiple difficulties in generating perceptually accurate images, and existing methods suffer from limitations in preserving texture, maintaining pattern coherence, respecting cloth boundaries, handling occlusions, manipulating skin generation, etc. These difficulties are further exacerbated by the fact that the possible space of pose orientation for humans is large and variable, the nature of clothing items is highly non-rigid, and the diversity in body shape differs largely among the population. To alleviate these difficulties and synthesize perceptually accurate images, we propose VGFlow. Our model uses a visibility-guided flow module to disentangle the flow into visible and invisible parts of the target for simultaneous texture preservation and style manipulation. Furthermore, to tackle distinct body shapes and avoid network artifacts, we also incorporate a self-supervised patch-wise \"realness\" loss to improve the output. VGFlow achieves state-of-the-art results as observed qualitatively and quantitatively on different image quality metrics (SSIM, LPIPS, FID). ",
    "url": "https://arxiv.org/abs/2211.08540",
    "authors": [
      "Rishabh Jain",
      "Krishna Kumar Singh",
      "Mayur Hemani",
      "Jingwan Lu",
      "Mausooom Sarkar",
      "Duygu Ceylan",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08541",
    "title": "GC-GRU-N for Traffic Prediction using Loop Detector Data",
    "abstract": "Because traffic characteristics display stochastic nonlinear spatiotemporal dependencies, traffic prediction is a challenging task. In this paper develop a graph convolution gated recurrent unit (GC GRU N) network to extract the essential Spatio temporal features. we use Seattle loop detector data aggregated over 15 minutes and reframe the problem through space and time. The model performance is compared o benchmark models; Historical Average, Long Short Term Memory (LSTM), and Transformers. The proposed model ranked second with the fastest inference time and a very close performance to first place (Transformers). Our model also achieves a running time that is six times faster than transformers. Finally, we present a comparative study of our model and the available benchmarks using metrics such as training time, inference time, MAPE, MAE and RMSE. Spatial and temporal aspects are also analyzed for each of the trained models. ",
    "url": "https://arxiv.org/abs/2211.08541",
    "authors": [
      "Maged Shoman",
      "Armstrong Aboah",
      "Abdulateef Daud",
      "Yaw Adu-Gyamfi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.08547",
    "title": "ALIGN-MLM: Word Embedding Alignment is Crucial for Multilingual  Pre-training",
    "abstract": "Multilingual pre-trained models exhibit zero-shot cross-lingual transfer, where a model fine-tuned on a source language achieves surprisingly good performance on a target language. While studies have attempted to understand transfer, they focus only on MLM, and the large number of differences between natural languages makes it hard to disentangle the importance of different properties. In this work, we specifically highlight the importance of word embedding alignment by proposing a pre-training objective (ALIGN-MLM) whose auxiliary loss guides similar words in different languages to have similar word embeddings. ALIGN-MLM either outperforms or matches three widely adopted objectives (MLM, XLM, DICT-MLM) when we evaluate transfer between pairs of natural languages and their counterparts created by systematically modifying specific properties like the script. In particular, ALIGN-MLM outperforms XLM and MLM by 35 and 30 F1 points on POS-tagging for transfer between languages that differ both in their script and word order (left-to-right v.s. right-to-left). We also show a strong correlation between alignment and transfer for all objectives (e.g., rho=0.727 for XNLI), which together with ALIGN-MLM's strong performance calls for explicitly aligning word embeddings for multilingual models. ",
    "url": "https://arxiv.org/abs/2211.08547",
    "authors": [
      "Henry Tang",
      "Ameet Deshpande",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08557",
    "title": "Unsupervised Feature Clustering Improves Contrastive Representation  Learning for Medical Image Segmentation",
    "abstract": "Self-supervised instance discrimination is an effective contrastive pretext task to learn feature representations and address limited medical image annotations. The idea is to make features of transformed versions of the same images similar while forcing all other augmented images' representations to contrast. However, this instance-based contrastive learning leaves performance on the table by failing to maximize feature affinity between images with similar content while counter-productively pushing their representations apart. Recent improvements on this paradigm (e.g., leveraging multi-modal data, different images in longitudinal studies, spatial correspondences) either relied on additional views or made stringent assumptions about data properties, which can sacrifice generalizability and applicability. To address this challenge, we propose a new self-supervised contrastive learning method that uses unsupervised feature clustering to better select positive and negative image samples. More specifically, we produce pseudo-classes by hierarchically clustering features obtained by an auto-encoder in an unsupervised manner, and prevent destructive interference during contrastive learning by avoiding the selection of negatives from the same pseudo-class. Experiments on 2D skin dermoscopic image segmentation and 3D multi-class whole heart CT segmentation demonstrate that our method outperforms state-of-the-art self-supervised contrastive techniques on these tasks. ",
    "url": "https://arxiv.org/abs/2211.08557",
    "authors": [
      "Yejia Zhang",
      "Xinrong Hu",
      "Nishchal Sapkota",
      "Yiyu Shi",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08559",
    "title": "Cross-Domain Self-Supervised Deep Learning for Robust Alzheimer's  Disease Progression Modeling",
    "abstract": "Developing successful artificial intelligence systems in practice depends both on robust deep learning models as well as large high quality data. Acquiring and labeling data can become prohibitively expensive and time-consuming in many real-world applications such as clinical disease models. Self-supervised learning has demonstrated great potential in increasing model accuracy and robustness in small data regimes. In addition, many clinical imaging and disease modeling applications rely heavily on regression of continuous quantities. However, the applicability of self-supervised learning for these medical-imaging regression tasks has not been extensively studied. In this study, we develop a cross-domain self-supervised learning approach for disease prognostic modeling as a regression problem using 3D images as input. We demonstrate that self-supervised pre-training can improve the prediction of Alzheimer's Disease progression from brain MRI. We also show that pre-training on extended (but not labeled) brain MRI data outperforms pre-training on natural images. We further observe that the highest performance is achieved when both natural images and extended brain-MRI data are used for pre-training. ",
    "url": "https://arxiv.org/abs/2211.08559",
    "authors": [
      "Saba Dadsetan",
      "Mohsen Hejrati",
      "Shandong Wu",
      "Somaye Hashemifar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08568",
    "title": "Graph Sequential Neural ODE Process for Link Prediction on Dynamic and  Sparse Graphs",
    "abstract": "Link prediction on dynamic graphs is an important task in graph mining. Existing approaches based on dynamic graph neural networks (DGNNs) typically require a significant amount of historical data (interactions over time), which is not always available in practice. The missing links over time, which is a common phenomenon in graph data, further aggravates the issue and thus creates extremely sparse and dynamic graphs. To address this problem, we propose a novel method based on the neural process, called Graph Sequential Neural ODE Process (GSNOP). Specifically, GSNOP combines the advantage of the neural process and neural ordinary differential equation that models the link prediction on dynamic graphs as a dynamic-changing stochastic process. By defining a distribution over functions, GSNOP introduces the uncertainty into the predictions, making it generalize to more situations instead of overfitting to the sparse data. GSNOP is also agnostic to model structures that can be integrated with any DGNN to consider the chronological and geometrical information for link prediction. Extensive experiments on three dynamic graph datasets show that GSNOP can significantly improve the performance of existing DGNNs and outperform other neural process variants. ",
    "url": "https://arxiv.org/abs/2211.08568",
    "authors": [
      "Linhao Luo",
      "Reza Haffari",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.08573",
    "title": "Realization of Causal Representation Learning to Adjust Confounding Bias  in Latent Space",
    "abstract": "Applying Deep Learning (DL) models to graphical causal learning has brought outstanding effectiveness and efficiency but is still far from widespread use in domain sciences. In research of EHR (Electronic Healthcare Records), we realize that some confounding bias inherently exists in the causally formed data, which DL cannot automatically adjust. Trace to the source is because the Acyclic Causal Graph can be Multi-Dimensional, so the bias and causal learning happen in two subspaces, which makes it unobservable from the learning process. This paper initially raises the concept of Dimensionality for causal graphs. In our case, the 3-Dimensional DAG (Directed Acyclic Graph) space is defined by the axes of causal variables, the Absolute timeline, and Relative timelines; This is also the essential difference between Causality and Correlation problems. We propose a novel new framework Causal Representation Learning (CRL), to realize Graphical Causal Learning in latent space, which aims to provide general solutions for 1) the inherent bias adjustment and 2) the DL causal models generalization problem. We will also demonstrate the realization of CRL with originally designed architecture and experimentally confirm its feasibility. ",
    "url": "https://arxiv.org/abs/2211.08573",
    "authors": [
      "Jia Li",
      "Xiang Li",
      "Xiaowei Jia",
      "Michael Steinbach",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.08585",
    "title": "Cyrus2D base: Source Code Base for RoboCup 2D Soccer Simulation League",
    "abstract": "Soccer Simulation 2D League is one of the major leagues of RoboCup competitions. In a Soccer Simulation 2D (SS2D) game, two teams of 11 players and one coach compete against each other. Several base codes have been released for the RoboCup soccer simulation 2D (RCSS2D) community that have promoted the application of multi-agent and AI algorithms in this field. In this paper, we introduce \"Cyrus2D Base\", which is derived from the base code of the RCSS2D 2021 champion. We merged Gliders2D base V2.6 with the newest version of the Helios base. We applied several features of Cyrus2021 to improve the performance and capabilities of this base alongside a Data Extractor to facilitate the implementation of machine learning in the field. We have tested this base code in different teams and scenarios, and the obtained results demonstrate significant improvements in the defensive and offensive strategy of the team. ",
    "url": "https://arxiv.org/abs/2211.08585",
    "authors": [
      "Nader Zare",
      "Omid Amini",
      "Aref Sayareh",
      "Mahtab Sarvmaili",
      "Arad Firouzkouhi",
      "Saba Ramezani Rad",
      "Stan Matwin",
      "Amilcar Soares"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.08588",
    "title": "Disentangling Task Relations for Few-shot Text Classification via  Self-Supervised Hierarchical Task Clustering",
    "abstract": "Few-Shot Text Classification (FSTC) imitates humans to learn a new text classifier efficiently with only few examples, by leveraging prior knowledge from historical tasks. However, most prior works assume that all the tasks are sampled from a single data source, which cannot adapt to real-world scenarios where tasks are heterogeneous and lie in different distributions. As such, existing methods may suffer from their globally knowledge-shared mechanisms to handle the task heterogeneity. On the other hand, inherent task relation are not explicitly captured, making task knowledge unorganized and hard to transfer to new tasks. Thus, we explore a new FSTC setting where tasks can come from a diverse range of data sources. To address the task heterogeneity, we propose a self-supervised hierarchical task clustering (SS-HTC) method. SS-HTC not only customizes cluster-specific knowledge by dynamically organizing heterogeneous tasks into different clusters in hierarchical levels but also disentangles underlying relations between tasks to improve the interpretability. Extensive experiments on five public FSTC benchmark datasets demonstrate the effectiveness of SS-HTC. ",
    "url": "https://arxiv.org/abs/2211.08588",
    "authors": [
      "Juan Zha",
      "Zheng Li",
      "Ying Wei",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08603",
    "title": "Asynchronous Bayesian Learning over a Network",
    "abstract": "We present a practical asynchronous data fusion model for networked agents to perform distributed Bayesian learning without sharing raw data. Our algorithm uses a gossip-based approach where pairs of randomly selected agents employ unadjusted Langevin dynamics for parameter sampling. We also introduce an event-triggered mechanism to further reduce communication between gossiping agents. These mechanisms drastically reduce communication overhead and help avoid bottlenecks commonly experienced with distributed algorithms. In addition, the reduced link utilization by the algorithm is expected to increase resiliency to occasional link failure. We establish mathematical guarantees for our algorithm and demonstrate its effectiveness via numerical experiments. ",
    "url": "https://arxiv.org/abs/2211.08603",
    "authors": [
      "Kinjal Bhar",
      "He Bai",
      "Jemin George",
      "Carl Busart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.08604",
    "title": "PU GNN: Chargeback Fraud Detection in P2E MMORPGs via Graph Attention  Networks with Imbalanced PU Labels",
    "abstract": "The recent advent of play-to-earn (P2E) systems in massively multiplayer online role-playing games (MMORPGs) has made in-game goods interchangeable with real-world values more than ever before. The goods in the P2E MMORPGs can be directly exchanged with cryptocurrencies such as Bitcoin, Ethereum, or Klaytn via blockchain networks. Unlike traditional in-game goods, once they had been written to the blockchains, P2E goods cannot be restored by the game operation teams even with chargeback fraud such as payment fraud, cancellation, or refund. To tackle the problem, we propose a novel chargeback fraud prediction method, PU GNN, which leverages graph attention networks with PU loss to capture both the players' in-game behavior with P2E token transaction patterns. With the adoption of modified GraphSMOTE, the proposed model handles the imbalanced distribution of labels in chargeback fraud datasets. The conducted experiments on two real-world P2E MMORPG datasets demonstrate that PU GNN achieves superior performances over previously suggested methods. ",
    "url": "https://arxiv.org/abs/2211.08604",
    "authors": [
      "Jiho Choi",
      "Junghoon Park",
      "Woocheol Kim",
      "Jin-Hyeok Park",
      "Yumin Suh",
      "Minchang Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.08605",
    "title": "A Dichotomy Theorem for Linear Time Homomorphism Orbit Counting in  Bounded Degeneracy Graphs",
    "abstract": "Counting the number of homomorphisms of a pattern graph H in a large input graph G is a fundamental problem in computer science. There are myriad applications of this problem in databases, graph algorithms, and network science. Often, we need more than just the total count. Especially in large network analysis, we wish to compute, for each vertex v of G, the number of H-homomorphisms that v participates in. This problem is referred to as homomorphism orbit counting, as it relates to the orbits of vertices of H under its automorphisms. Given the need for fast algorithms for this problem, we study when near-linear time algorithms are possible. A natural restriction is to assume that the input graph G has bounded degeneracy, a commonly observed property in modern massive networks. Can we characterize the patterns H for which homomorphism orbit counting can be done in linear time? We discover a dichotomy theorem that resolves this problem. For pattern H, let l be the length of the longest induced path between any two vertices of the same orbit (under the automorphisms of H). If l <= 5, then H-homomorphism orbit counting can be done in linear time for bounded degeneracy graphs. If l > 5, then (assuming fine-grained complexity conjectures) there is no near-linear time algorithm for this problem. We build on existing work on dichotomy theorems for counting the total H-homomorphism count. Somewhat surprisingly, there exist (and we characterize) patterns H for which the total homomorphism count can be computed in linear time, but the corresponding orbit counting problem cannot be done in near-linear time. ",
    "url": "https://arxiv.org/abs/2211.08605",
    "authors": [
      "Daniel Paul-Pena",
      "C. Seshadhri"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.08609",
    "title": "R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based  Trajectory Refinement",
    "abstract": "Predicting the future motion of dynamic agents is of paramount importance to ensure safety or assess risks in motion planning for autonomous robots. In this paper, we propose a two-stage motion prediction method, referred to as R-Pred, that effectively utilizes both the scene and interaction context using a cascade of the initial trajectory proposal network and the trajectory refinement network. The initial trajectory proposal network produces M trajectory proposals corresponding to M modes of a future trajectory distribution. The trajectory refinement network enhances each of M proposals using 1) the tube-query scene attention (TQSA) and 2) the proposal-level interaction attention (PIA). TQSA uses tube-queries to aggregate the local scene context features pooled from proximity around the trajectory proposals of interest. PIA further enhances the trajectory proposals by modeling inter-agent interactions using a group of trajectory proposals selected based on their distances from neighboring agents. Our experiments conducted on the Argoverse and nuScenes datasets demonstrate that the proposed refinement network provides significant performance improvements compared to the single-stage baseline and that R-Pred achieves state-of-the-art performance in some categories of the benchmark. ",
    "url": "https://arxiv.org/abs/2211.08609",
    "authors": [
      "Sehwan Choi",
      "Jungho Kim",
      "Junyong Yun",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08610",
    "title": "CoNFies: Controllable Neural Face Avatars",
    "abstract": "Neural Radiance Fields (NeRF) are compelling techniques for modeling dynamic 3D scenes from 2D image collections. These volumetric representations would be well suited for synthesizing novel facial expressions but for two problems. First, deformable NeRFs are object agnostic and model holistic movement of the scene: they can replay how the motion changes over time, but they cannot alter it in an interpretable way. Second, controllable volumetric representations typically require either time-consuming manual annotations or 3D supervision to provide semantic meaning to the scene. We propose a controllable neural representation for face self-portraits (CoNFies), that solves both of these problems within a common framework, and it can rely on automated processing. We use automated facial action recognition (AFAR) to characterize facial expressions as a combination of action units (AU) and their intensities. AUs provide both the semantic locations and control labels for the system. CoNFies outperformed competing methods for novel view and expression synthesis in terms of visual and anatomic fidelity of expressions. ",
    "url": "https://arxiv.org/abs/2211.08610",
    "authors": [
      "Heng Yu",
      "Koichiro Niinuma",
      "Laszlo A. Jeni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08615",
    "title": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "abstract": "With the rapid development of the deep generative models (such as Generative Adversarial Networks and Auto-encoders), AI-synthesized images of human face are now of such high qualities that humans can hardly distinguish them from pristine ones. Although existing detection methods have shown high performance in specific evaluation settings, e.g., on images from seen models or on images without real-world post-processings, they tend to suffer serious performance degradation in real-world scenarios where testing images can be generated by more powerful generation models or combined with various post-processing operations. To address this issue, we propose a Global and Local Feature Fusion (GLFF) to learn rich and discriminative representations by combining multi-scale global features from the whole image with refined local features from informative patches for face forgery detection. GLFF fuses information from two branches: global branch to extract multi-scale semantic features and local branch to select informative patches for detailed local artifacts extraction. Due to the lack of face forgery dataset simulating real-world applications for evaluation, we further create a challenging face forgery dataset, named DeepFakeFaceForensics (DF$^3$), which contains 6 state-of-the-art generation models and a variety of post-processing techniques to approach the real-world scenarios. Experimental results demonstrate the superiority of our method to the state-of-the-art methods on the proposed DF^3 dataset and three other open-source datasets. ",
    "url": "https://arxiv.org/abs/2211.08615",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Jialing Cai",
      "Haiying Guan",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08624",
    "title": "Leveraging Heteroscedastic Uncertainty in Learning Complex Spectral  Mapping for Single-channel Speech Enhancement",
    "abstract": "Most speech enhancement (SE) models learn a point estimate, and do not make use of uncertainty estimation in the learning process. In this paper, we show that modeling heteroscedastic uncertainty by minimizing a multivariate Gaussian negative log-likelihood (NLL) improves SE performance at no extra cost. During training, our approach augments a model learning complex spectral mapping with a temporary submodel to predict the covariance of the enhancement error at each time-frequency bin. Due to unrestricted heteroscedastic uncertainty, the covariance introduces an undersampling effect, detrimental to SE performance. To mitigate undersampling, our approach inflates the uncertainty lower bound and weights each loss component with their uncertainty, effectively compensating severely undersampled components with more penalties. Our multivariate setting reveals common covariance assumptions such as scalar and diagonal matrices. By weakening these assumptions, we show that the NLL achieves superior performance compared to popular losses including the mean squared error (MSE), mean absolute error (MAE), and scale-invariant signal-to-distortion ratio (SI-SDR). ",
    "url": "https://arxiv.org/abs/2211.08624",
    "authors": [
      "Kuan-Lin Chen",
      "Daniel D. E. Wong",
      "Ke Tan",
      "Buye Xu",
      "Anurag Kumar",
      "Vamsi Krishna Ithapu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.08635",
    "title": "One-bit mmWave MIMO Channel Estimation using Deep Generative Networks",
    "abstract": "As future wireless systems trend towards higher carrier frequencies and large antenna arrays, receivers with one-bit analog-to-digital converters (ADCs) are being explored owing to their reduced power consumption. However, the combination of large antenna arrays and one-bit ADCs makes channel estimation challenging. In this paper, we formulate channel estimation from a limited number of one-bit quantized pilot measurements as an inverse problem and reconstruct the channel by optimizing the input vector of a pre-trained deep generative model with the objective of maximizing a novel correlation-based loss function. We observe that deep generative priors adapted to the underlying channel model significantly outperform Bernoulli-Gaussian Approximate Message Passing (BG-GAMP), while a single generative model that uses a conditional input to distinguish between Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS) channel realizations outperforms BG-GAMP on LOS channels and achieves comparable performance on NLOS channels in terms of the normalized channel reconstruction error. ",
    "url": "https://arxiv.org/abs/2211.08635",
    "authors": [
      "Akash Doshi",
      "Jeffrey G. Andrews"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.08644",
    "title": "Coronavirus statistics causes emotional bias: a social media text mining  perspective",
    "abstract": "While COVID-19 has impacted humans for a long time, people search the web for pandemic-related information, causing anxiety. From a theoretic perspective, previous studies have confirmed that the number of COVID-19 cases can cause negative emotions, but how statistics of different dimensions, such as the number of imported cases, the number of local cases, and the number of government-designated lockdown zones, stimulate people's emotions requires detailed understanding. In order to obtain the views of people on COVID-19, this paper first proposes a deep learning model which classifies texts related to the pandemic from text data with place labels. Next, it conducts a sentiment analysis based on multi-task learning. Finally, it carries out a fixed-effect panel regression with outputs of the sentiment analysis. The performance of the algorithm shows a promising result. The empirical study demonstrates while the number of local cases is positively associated with risk perception, the number of imported cases is negatively associated with confidence levels, which explains why citizens tend to ascribe the protracted pandemic to foreign factors. Besides, this study finds that previous pandemic hits cities recover slowly from the suffering, while local governments' spending on healthcare can improve the situation. Our study illustrates the reasons for risk perception and confidence based on different sources of statistical information due to cognitive bias. It complements the knowledge related to epidemic information. It also contributes to a framework that combines sentiment analysis using advanced deep learning technology with the empirical regression method. ",
    "url": "https://arxiv.org/abs/2211.08644",
    "authors": [
      "Linjiang Guo",
      "Zijian Feng",
      "Yuxue Chi",
      "Mingzhu Wang",
      "Yijun Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.08648",
    "title": "Efficiently Answering Quality Constrained Shortest Distance Queries in  Large Graphs",
    "abstract": "The shortest-path distance is a fundamental concept in graph analytics and has been extensively studied in the literature. In many real-world applications, quality constraints are naturally associated with edges in the graphs and finding the shortest distance between two vertices $s$ and $t$ along only valid edges (i.e., edges that satisfy a given quality constraint) is also critical. In this paper, we investigate this novel and important problem of quality constraint shortest distance queries. We propose an efficient index structure based on 2-hop labeling approaches. Supported by a path dominance relationship incorporating both quality and length information, we demonstrate the minimal property of the new index. An efficient query processing algorithm is also developed. Extensive experimental studies over real-life datasets demonstrates efficiency and effectiveness of our techniques. ",
    "url": "https://arxiv.org/abs/2211.08648",
    "authors": [
      "You Peng",
      "Zhuo Ma",
      "Wenjie Zhang",
      "Xuemin Lin",
      "Ying Zhang",
      "Xiaoshuang Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.08650",
    "title": "Deep Intention-Aware Network for Click-Through Rate Prediction",
    "abstract": "E-commerce platforms provide entrances for customers to enter mini-apps that can meet their specific shopping requirements. Trigger items displayed on entrance icons can attract more entering. However, conventional Click-Through-Rate (CTR) prediction models, which ignore user instant interest in trigger item, fail to be applied to the new recommendation scenario dubbed Trigger-Induced Recommendation in Mini-Apps (TIRA). Moreover, due to the high stickiness of customers to mini-apps, we argue that existing trigger-based methods that over-emphasize the importance of trigger items, are undesired for TIRA, since a large portion of customer entries are because of their routine shopping habits instead of triggers. We identify that the key to TIRA is to extract customers' personalized entering intention and weigh the impact of triggers based on this intention. To achieve this goal, we convert CTR prediction for TIRA into a separate estimation form, and present Deep Intention-Aware Network (DIAN) with three key elements: 1) Intent Net that estimates user's entering intention, i.e., whether he/she is affected by the trigger or by the habits; 2) Trigger-Aware Net and 3) Trigger-Free Net that estimate CTRs given user's intention is to the trigger-item and the mini-app respectively. Following a joint learning way, DIAN can both accurately predict user intention and dynamically balance the results of trigger-free and trigger-based recommendations based on the estimated intention. Experiments show that DIAN advances state-of-the-art performance in a large real-world dataset, and brings a 9.39% lift of online Item Page View and 4.74% CTR for Juhuasuan, a famous mini-app of Taobao. ",
    "url": "https://arxiv.org/abs/2211.08650",
    "authors": [
      "Yaxian Xia",
      "Yi Cao",
      "Sihao Hu",
      "Tong Liu",
      "Lingling Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08653",
    "title": "#maskUp: Selective Attribute Encryption for Sensitive Vocalization for  English language on Social Media Platforms",
    "abstract": "Social media has become a platform for people to stand up and raise their voices against social and criminal acts. Vocalization of such information has allowed the investigation and identification of criminals. However, revealing such sensitive information may jeopardize the victim's safety. We propose #maskUp, a safe method for information communication in a secure fashion to the relevant authorities, discouraging potential bullying of the victim. This would ensure security by conserving their privacy through natural language processing supplemented with selective encryption for sensitive attribute masking. To our knowledge, this is the first work that aims to protect the privacy of the victims by masking their private details as well as emboldening them to come forward to report crimes. The use of masking technology allows only binding authorities to view/un-mask this data. We construct and evaluate the proposed methodology on continual learning tasks, allowing practical implementation of the same in a real-world scenario. #maskUp successfully demonstrates this integration on sample datasets validating the presented objective. ",
    "url": "https://arxiv.org/abs/2211.08653",
    "authors": [
      "Supriti Vijay",
      "Aman Priyanshu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.08657",
    "title": "Person Text-Image Matching via Text-Featur Interpretability Embedding  and External Attack Node Implantation",
    "abstract": "Person text-image matching, also known as textbased person search, aims to retrieve images of specific pedestrians using text descriptions. Although person text-image matching has made great research progress, existing methods still face two challenges. First, the lack of interpretability of text features makes it challenging to effectively align them with their corresponding image features. Second, the same pedestrian image often corresponds to multiple different text descriptions, and a single text description can correspond to multiple different images of the same identity. The diversity of text descriptions and images makes it difficult for a network to extract robust features that match the two modalities. To address these problems, we propose a person text-image matching method by embedding text-feature interpretability and an external attack node. Specifically, we improve the interpretability of text features by providing them with consistent semantic information with image features to achieve the alignment of text and describe image region features.To address the challenges posed by the diversity of text and the corresponding person images, we treat the variation caused by diversity to features as caused by perturbation information and propose a novel adversarial attack and defense method to solve it. In the model design, graph convolution is used as the basic framework for feature representation and the adversarial attacks caused by text and image diversity on feature extraction is simulated by implanting an additional attack node in the graph convolution layer to improve the robustness of the model against text and image diversity. Extensive experiments demonstrate the effectiveness and superiority of text-pedestrian image matching over existing methods. The source code of the method is published at ",
    "url": "https://arxiv.org/abs/2211.08657",
    "authors": [
      "Fan Li",
      "Hang Zhou",
      "Huafeng Li",
      "Yafei Zhang",
      "Zhengtao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08684",
    "title": "Neural Unsupervised Reconstruction of Protolanguage Word Forms",
    "abstract": "We present a state-of-the-art neural approach to the unsupervised reconstruction of ancient word forms. Previous work in this domain used expectation-maximization to predict simple phonological changes between ancient word forms and their cognates in modern languages. We extend this work with neural models that can capture more complicated phonological and morphological changes. At the same time, we preserve the inductive biases from classical methods by building monotonic alignment constraints into the model and deliberately underfitting during the maximization step. We evaluate our performance on the task of reconstructing Latin from a dataset of cognates across five Romance languages, achieving a notable reduction in edit distance from the target word forms compared to previous methods. ",
    "url": "https://arxiv.org/abs/2211.08684",
    "authors": [
      "Andre He",
      "Nicholas Tomlin",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.08686",
    "title": "Improving Interpretability via Regularization of Neural Activation  Sensitivity",
    "abstract": "State-of-the-art deep neural networks (DNNs) are highly effective at tackling many real-world tasks. However, their wide adoption in mission-critical contexts is hampered by two major weaknesses - their susceptibility to adversarial attacks and their opaqueness. The former raises concerns about the security and generalization of DNNs in real-world conditions, whereas the latter impedes users' trust in their output. In this research, we (1) examine the effect of adversarial robustness on interpretability and (2) present a novel approach for improving the interpretability of DNNs that is based on regularization of neural activation sensitivity. We evaluate the interpretability of models trained using our method to that of standard models and models trained using state-of-the-art adversarial robustness techniques. Our results show that adversarially robust models are superior to standard models and that models trained using our proposed method are even better than adversarially robust models in terms of interpretability. ",
    "url": "https://arxiv.org/abs/2211.08686",
    "authors": [
      "Ofir Moshe",
      "Gil Fidel",
      "Ron Bitton",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08691",
    "title": "Towards Long-Tailed 3D Detection",
    "abstract": "Contemporary autonomous vehicle (AV) benchmarks have advanced techniques for training 3D detectors, particularly on large-scale lidar data. Surprisingly, although semantic class labels naturally follow a long-tailed distribution, contemporary benchmarks focus on only a few common classes (e.g., pedestrian and car) and neglect many rare classes in-the-tail (e.g., debris and stroller). However, AVs must still detect rare classes to ensure safe operation. Moreover, semantic classes are often organized within a hierarchy, e.g., tail classes such as child and construction-worker are arguably subclasses of pedestrian. However, such hierarchical relationships are often ignored, which may lead to misleading estimates of performance and missed opportunities for algorithmic innovation. We address these challenges by formally studying the problem of Long-Tailed 3D Detection (LT3D), which evaluates on all classes, including those in-the-tail. We evaluate and innovate upon popular 3D detection codebases, such as CenterPoint and PointPillars, adapting them for LT3D. We develop hierarchical losses that promote feature sharing across common-vs-rare classes, as well as improved detection metrics that award partial credit to \"reasonable\" mistakes respecting the hierarchy (e.g., mistaking a child for an adult). Finally, we point out that fine-grained tail class accuracy is particularly improved via multimodal fusion of RGB images with LiDAR; simply put, small fine-grained classes are challenging to identify from sparse (lidar) geometry alone, suggesting that multimodal cues are crucial to long-tailed 3D detection. Our modifications improve accuracy by 5% AP on average for all classes, and dramatically improve AP for rare classes (e.g., stroller AP improves from 3.6 to 31.6)! ",
    "url": "https://arxiv.org/abs/2211.08691",
    "authors": [
      "Neehar Peri",
      "Achal Dave",
      "Deva Ramanan",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.08695",
    "title": "Distributed and Adversarial Resistant Workflow Execution on the Algorand  Blockchain",
    "abstract": "We provide a practical translation from the Dynamic Condition Response (DCR) process modelling language to the Transaction Execution Approval Language (TEAL) used by the Algorand blockchain. Compared to earlier implementations of business process notations on blockchains, particularly Ethereum, the present implementation is four orders of magnitude cheaper. This translation has the following immediate ramifications: (1) It allows decentralised execution of DCR-specified business processes in the absence of expensive intermediaries (lawyers, brokers) or counterparty risk. (2) It provides a possibly helpful high-level language for implementing business processes on Algorand. (3) It demonstrates that despite the strict limitations on Algorand smart contracts, they are powerful enough to encode models of a modern process notation. ",
    "url": "https://arxiv.org/abs/2211.08695",
    "authors": [
      "Yibin Xu",
      "Tijs Slaats",
      "Boris D\u00fcdder",
      "S\u00f8ren Debois",
      "Haiqin Wu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.08697",
    "title": "PBSM: Backdoor attack against Keyword spotting based on pitch boosting  and sound masking",
    "abstract": "Keyword spotting (KWS) has been widely used in various speech control scenarios. The training of KWS is usually based on deep neural networks and requires a large amount of data. Manufacturers often use third-party data to train KWS. However, deep neural networks are not sufficiently interpretable to manufacturers, and attackers can manipulate third-party training data to plant backdoors during the model training. An effective backdoor attack can force the model to make specified judgments under certain conditions, i.e., triggers. In this paper, we design a backdoor attack scheme based on Pitch Boosting and Sound Masking for KWS, called PBSM. Experimental results demonstrated that PBSM is feasible to achieve an average attack success rate close to 90% in three victim models when poisoning less than 1% of the training data. ",
    "url": "https://arxiv.org/abs/2211.08697",
    "authors": [
      "Hanbo Cai",
      "Pengcheng Zhang",
      "Hai Dong",
      "Yan Xiao",
      "Shunhui Ji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.08701",
    "title": "Interpretable Self-Aware Neural Networks for Robust Trajectory  Prediction",
    "abstract": "Although neural networks have seen tremendous success as predictive models in a variety of domains, they can be overly confident in their predictions on out-of-distribution (OOD) data. To be viable for safety-critical applications, like autonomous vehicles, neural networks must accurately estimate their epistemic or model uncertainty, achieving a level of system self-awareness. Techniques for epistemic uncertainty quantification often require OOD data during training or multiple neural network forward passes during inference. These approaches may not be suitable for real-time performance on high-dimensional inputs. Furthermore, existing methods lack interpretability of the estimated uncertainty, which limits their usefulness both to engineers for further system development and to downstream modules in the autonomy stack. We propose the use of evidential deep learning to estimate the epistemic uncertainty over a low-dimensional, interpretable latent space in a trajectory prediction setting. We introduce an interpretable paradigm for trajectory prediction that distributes the uncertainty among the semantic concepts: past agent behavior, road structure, and social context. We validate our approach on real-world autonomous driving data, demonstrating superior performance over state-of-the-art baselines. Our code is available at: https://github.com/sisl/InterpretableSelfAwarePrediction. ",
    "url": "https://arxiv.org/abs/2211.08701",
    "authors": [
      "Masha Itkina",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08706",
    "title": "Efficiently Finding Adversarial Examples with DNN Preprocessing",
    "abstract": "Deep Neural Networks (DNNs) are everywhere, frequently performing a fairly complex task that used to be unimaginable for machines to carry out. In doing so, they do a lot of decision making which, depending on the application, may be disastrous if gone wrong. This necessitates a formal argument that the underlying neural networks satisfy certain desirable properties. Robustness is one such key property for DNNs, particularly if they are being deployed in safety or business critical applications. Informally speaking, a DNN is not robust if very small changes to its input may affect the output in a considerable way (e.g. changes the classification for that input). The task of finding an adversarial example is to demonstrate this lack of robustness, whenever applicable. While this is doable with the help of constrained optimization techniques, scalability becomes a challenge due to large-sized networks. This paper proposes the use of information gathered by preprocessing the DNN to heavily simplify the optimization problem. Our experiments substantiate that this is effective, and does significantly better than the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2211.08706",
    "authors": [
      "Avriti Chauhan",
      "Mohammad Afzal",
      "Hrishikesh Karmarkar",
      "Yizhak Elboher",
      "Kumar Madhukar",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08715",
    "title": "Conditional variational autoencoder to improve neural audio synthesis  for polyphonic music sound",
    "abstract": "Deep generative models for audio synthesis have recently been significantly improved. However, the task of modeling raw-waveforms remains a difficult problem, especially for audio waveforms and music signals. Recently, the realtime audio variational autoencoder (RAVE) method was developed for high-quality audio waveform synthesis. The RAVE method is based on the variational autoencoder and utilizes the two-stage training strategy. Unfortunately, the RAVE model is limited in reproducing wide-pitch polyphonic music sound. Therefore, to enhance the reconstruction performance, we adopt the pitch activation data as an auxiliary information to the RAVE model. To handle the auxiliary information, we propose an enhanced RAVE model with a conditional variational autoencoder structure and an additional fully-connected layer. To evaluate the proposed structure, we conducted a listening experiment based on multiple stimulus tests with hidden references and an anchor (MUSHRA) with the MAESTRO. The obtained results indicate that the proposed model exhibits a more significant performance and stability improvement than the conventional RAVE model. ",
    "url": "https://arxiv.org/abs/2211.08715",
    "authors": [
      "Seokjin Lee",
      "Minhan Kim",
      "Seunghyeon Shin",
      "Daeho Lee",
      "Inseon Jang",
      "Wootaek Lim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.08724",
    "title": "PAANet:Visual Perception based Four-stage Framework for Salient Object  Detection using High-order Contrast Operator",
    "abstract": "It is believed that human vision system (HVS) consists of pre-attentive process and attention process when performing salient object detection (SOD). Based on this fact, we propose a four-stage framework for SOD, in which the first two stages match the \\textbf{P}re-\\textbf{A}ttentive process consisting of general feature extraction (GFE) and feature preprocessing (FP), and the last two stages are corresponding to \\textbf{A}ttention process containing saliency feature extraction (SFE) and the feature aggregation (FA), namely \\textbf{PAANet}. According to the pre-attentive process, the GFE stage applies the fully-trained backbone and needs no further finetuning for different datasets. This modification can greatly increase the training speed. The FP stage plays the role of finetuning but works more efficiently because of its simpler structure and fewer parameters. Moreover, in SFE stage we design for saliency feature extraction a novel contrast operator, which works more semantically in contrast with the traditional convolution operator when extracting the interactive information between the foreground and its surroundings. Interestingly, this contrast operator can be cascaded to form a deeper structure and extract higher-order saliency more effective for complex scene. Comparative experiments with the state-of-the-art methods on 5 datasets demonstrate the effectiveness of our framework. ",
    "url": "https://arxiv.org/abs/2211.08724",
    "authors": [
      "Yanbo Yuan",
      "Hua Zhong",
      "Haixiong Li",
      "Xiao cheng",
      "Linmei Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.08726",
    "title": "Streaming Joint Speech Recognition and Disfluency Detection",
    "abstract": "Disfluency detection has mainly been solved in a pipeline approach, as post-processing of speech recognition. In this study, we propose Transformer-based encoder-decoder models that jointly solve speech recognition and disfluency detection, which work in a streaming manner. Compared to pipeline approaches, the joint models can leverage acoustic information that makes disfluency detection robust to recognition errors and provide non-verbal clues. Moreover, joint modeling results in low-latency and lightweight inference. We investigate two joint model variants for streaming disfluency detection: a transcript-enriched model and a multi-task model. The transcript-enriched model is trained on text with special tags indicating the starting and ending points of the disfluent part. However, it has problems with latency and standard language model adaptation, which arise from the additional disfluency tags. We propose a multi-task model to solve such problems, which has two output layers at the Transformer decoder; one for speech recognition and the other for disfluency detection. It is modeled to be conditioned on the currently recognized token with an additional token-dependency mechanism. We show that the proposed joint models outperformed a BERT-based pipeline approach in both accuracy and latency, on both the Switchboard and the corpus of spontaneous Japanese. ",
    "url": "https://arxiv.org/abs/2211.08726",
    "authors": [
      "Hayato Futami",
      "Emiru Tsunoo",
      "Kentaro Shibata",
      "Yosuke Kashiwagi",
      "Takao Okuda",
      "Siddhant Arora",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.08728",
    "title": "Exploring State Change Capture of Heterogeneous Backbones @ Ego4D Hands  and Objects Challenge 2022",
    "abstract": "Capturing the state changes of interacting objects is a key technology for understanding human-object interactions. This technical report describes our method using heterogeneous backbones for the Ego4D Object State Change Classification and PNR Temporal Localization Challenge. In the challenge, we used the heterogeneous video understanding backbones, namely CSN with 3D convolution as operator and VideoMAE with Transformer as operator. Our method achieves an accuracy of 0.796 on OSCC while achieving an absolute temporal localization error of 0.516 on PNR. These excellent results rank 1st on the leaderboard of Ego4D OSCC & PNR-TL Challenge 2022. ",
    "url": "https://arxiv.org/abs/2211.08728",
    "authors": [
      "Yin-Dong Zheng",
      "Guo Chen",
      "Jiahao Wang",
      "Tong Lu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08735",
    "title": "Can Strategic Data Collection Improve the Performance of Poverty  Prediction Models?",
    "abstract": "Machine learning-based estimates of poverty and wealth are increasingly being used to guide the targeting of humanitarian aid and the allocation of social assistance. However, the ground truth labels used to train these models are typically borrowed from existing surveys that were designed to produce national statistics -- not to train machine learning models. Here, we test whether adaptive sampling strategies for ground truth data collection can improve the performance of poverty prediction models. Through simulations, we compare the status quo sampling strategies (uniform at random and stratified random sampling) to alternatives that prioritize acquiring training data based on model uncertainty or model performance on sub-populations. Perhaps surprisingly, we find that none of these active learning methods improve over uniform-at-random sampling. We discuss how these results can help shape future efforts to refine machine learning-based estimates of poverty. ",
    "url": "https://arxiv.org/abs/2211.08735",
    "authors": [
      "Satej Soman",
      "Emily Aiken",
      "Esther Rolf",
      "Joshua Blumenstock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08738",
    "title": "Distributed Node Covering Optimization for Large Scale Networks and Its  Application on Social Advertising",
    "abstract": "Combinatorial optimizations are usually complex and inefficient, which limits their applications in large-scale networks with billions of links. We introduce a distributed computational method for solving a node-covering problem at the scale of factual scenarios. We first construct a genetic algorithm and then design a two-step strategy to initialize the candidate solutions. All the computational operations are designed and developed in a distributed form on \\textit{Apache Spark} enabling fast calculation for practical graphs. We apply our method to social advertising of recalling back churn users in online mobile games, which was previously only treated as a traditional item recommending or ranking problem. ",
    "url": "https://arxiv.org/abs/2211.08738",
    "authors": [
      "Qiang Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.08752",
    "title": "Indoor Positioning via Gradient Boosting Enhanced with Feature  Augmentation using Deep Learning",
    "abstract": "With the emerge of the Internet of Things (IoT), localization within indoor environments has become inevitable and has attracted a great deal of attention in recent years. Several efforts have been made to cope with the challenges of accurate positioning systems in the presence of signal interference. In this paper, we propose a novel deep learning approach through Gradient Boosting Enhanced with Step-Wise Feature Augmentation using Artificial Neural Network (AugBoost-ANN) for indoor localization applications as it trains over labeled data. For this purpose, we propose an IoT architecture using a star network topology to collect the Received Signal Strength Indicator (RSSI) of Bluetooth Low Energy (BLE) modules by means of a Raspberry Pi as an Access Point (AP) in an indoor environment. The dataset for the experiments is gathered in the real world in different periods to match the real environments. Next, we address the challenges of the AugBoost-ANN training which augments features in each iteration of making a decision tree using a deep neural network and the transfer learning technique. Experimental results show more than 8\\% improvement in terms of accuracy in comparison with the existing gradient boosting and deep learning methods recently proposed in the literature, and our proposed model acquires a mean location accuracy of 0.77 m. ",
    "url": "https://arxiv.org/abs/2211.08752",
    "authors": [
      "Ashkan Goharfar",
      "Jaber Babaki",
      "Mehdi Rasti",
      "Pedro H. J. Nardelli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08754",
    "title": "Advanced Situational Graphs for Robot Navigation in Structured Indoor  Environments",
    "abstract": "Mobile robots extract information from its environment to understand their current situation to enable intelligent decision making and autonomous task execution. In our previous work, we introduced the concept of Situation Graphs (S-Graphs) which combines in a single optimizable graph, the robot keyframes and the representation of the environment with geometric, semantic and topological abstractions. Although S-Graphs were built and optimized in real-time and demonstrated state-of-the-art results, they are limited to specific structured environments with specific hand-tuned dimensions of rooms and corridors. In this work, we present an advanced version of the Situational Graphs (S-Graphs+), consisting of the five layered optimizable graph that includes (1) metric layer along with the graph of free-space clusters (2) keyframe layer where the robot poses are registered (3) metric-semantic layer consisting of the extracted planar walls (4) novel rooms layer constraining the extracted planar walls (5) novel floors layer encompassing the rooms within a given floor level. S-Graphs+ demonstrates improved performance over S-Graphs efficiently extracting the room information while simultaneously improving the pose estimate of the robot, thus extending the robots situational awareness in the form of a five layered environmental model. ",
    "url": "https://arxiv.org/abs/2211.08754",
    "authors": [
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Muhammad Shaheer",
      "Javier Civera",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08760",
    "title": "SVD-PINNs: Transfer Learning of Physics-Informed Neural Networks via  Singular Value Decomposition",
    "abstract": "Physics-informed neural networks (PINNs) have attracted significant attention for solving partial differential equations (PDEs) in recent years because they alleviate the curse of dimensionality that appears in traditional methods. However, the most disadvantage of PINNs is that one neural network corresponds to one PDE. In practice, we usually need to solve a class of PDEs, not just one. With the explosive growth of deep learning, many useful techniques in general deep learning tasks are also suitable for PINNs. Transfer learning methods may reduce the cost for PINNs in solving a class of PDEs. In this paper, we proposed a transfer learning method of PINNs via keeping singular vectors and optimizing singular values (namely SVD-PINNs). Numerical experiments on high dimensional PDEs (10-d linear parabolic equations and 10-d Allen-Cahn equations) show that SVD-PINNs work for solving a class of PDEs with different but close right-hand-side functions. ",
    "url": "https://arxiv.org/abs/2211.08760",
    "authors": [
      "Yihang Gao",
      "Ka Chun Cheung",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.08761",
    "title": "Separable PINN: Mitigating the Curse of Dimensionality in  Physics-Informed Neural Networks",
    "abstract": "Physics-informed neural networks (PINNs) have emerged as new data-driven PDE solvers for both forward and inverse problems. While promising, the expensive computational costs to obtain solutions often restrict their broader applicability. We demonstrate that the computations in automatic differentiation (AD) can be significantly reduced by leveraging forward-mode AD when training PINN. However, a naive application of forward-mode AD to conventional PINNs results in higher computation, losing its practical benefit. Therefore, we propose a network architecture, called separable PINN (SPINN), which can facilitate forward-mode AD for more efficient computation. SPINN operates on a per-axis basis instead of point-wise processing in conventional PINNs, decreasing the number of network forward passes. Besides, while the computation and memory costs of standard PINNs grow exponentially along with the grid resolution, that of our model is remarkably less susceptible, mitigating the curse of dimensionality. We demonstrate the effectiveness of our model in various PDE systems by significantly reducing the training run-time while achieving comparable accuracy. Project page: \\url{https://jwcho5576.github.io/spinn/} ",
    "url": "https://arxiv.org/abs/2211.08761",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Hyunmo Yang",
      "Seok-Bae Yun",
      "Youngjoon Hong",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08771",
    "title": "Symmetries in the dynamics of wide two-layer neural networks",
    "abstract": "We consider the idealized setting of gradient flow on the population risk for infinitely wide two-layer ReLU neural networks (without bias), and study the effect of symmetries on the learned parameters and predictors. We first describe a general class of symmetries which, when satisfied by the target function $f^*$ and the input distribution, are preserved by the dynamics. We then study more specific cases. When $f^*$ is odd, we show that the dynamics of the predictor reduces to that of a (non-linearly parameterized) linear predictor, and its exponential convergence can be guaranteed. When $f^*$ has a low-dimensional structure, we prove that the gradient flow PDE reduces to a lower-dimensional PDE. Furthermore, we present informal and numerical arguments that suggest that the input neurons align with the lower-dimensional structure of the problem. ",
    "url": "https://arxiv.org/abs/2211.08771",
    "authors": [
      "Karl Hajjar",
      "Lenaic Chizat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.08794",
    "title": "Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed  Representations",
    "abstract": "Due to the huge amount of parameters, fine-tuning of pretrained language models (PLMs) is prone to overfitting in the low resource scenarios. In this work, we present a novel method that operates on the hidden representations of a PLM to reduce overfitting. During fine-tuning, our method inserts random autoencoders between the hidden layers of a PLM, which transform activations from the previous layers into a multi-view compressed representation before feeding it into the upper layers. The autoencoders are plugged out after fine-tuning, so our method does not add extra parameters or increase computation cost during inference. Our method demonstrates promising performance improvement across a wide range of sequence- and token-level low-resource NLP tasks. ",
    "url": "https://arxiv.org/abs/2211.08794",
    "authors": [
      "Linlin Liu",
      "Xingxuan Li",
      "Megh Thakkar",
      "Xin Li",
      "Lidong Bing",
      "Shafiq Joty",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08804",
    "title": "Analysis and Detectability of Offline Data Poisoning Attacks on Linear  Systems",
    "abstract": "A recent body of literature has investigated the effect of data poisoning attacks on data-driven control methods. Data poisoning attacks are well-known to the Machine Learning community, which, however, make use of assumptions, such as cross-sample independence, that in general do not hold for dynamical systems. As a consequence, attacks, and detection methods, operate differently from the i.i.d. setting studied in classical supervised problems. In particular, data poisoning attacks against data-driven control methods can be fundamentally seen as changing the behavior of the dynamical system described by the data. In this work, we study this phenomenon through the lens of statistical testing, and verify the detectability of different attacks for a linear dynamical system. On the basis of the arguments hereby presented, we propose a stealthy data poisoning attack that can escape classical detection tests, and conclude by showing the efficiency of the proposed attack. ",
    "url": "https://arxiv.org/abs/2211.08804",
    "authors": [
      "Alessio Russo",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08840",
    "title": "Semi-Supervised and Self-Supervised Collaborative Learning for Prostate  3D MR Image Segmentation",
    "abstract": "Volumetric magnetic resonance (MR) image segmentation plays an important role in many clinical applications. Deep learning (DL) has recently achieved state-of-the-art or even human-level performance on various image segmentation tasks. Nevertheless, manually annotating volumetric MR images for DL model training is labor-exhaustive and time-consuming. In this work, we aim to train a semi-supervised and self-supervised collaborative learning framework for prostate 3D MR image segmentation while using extremely sparse annotations, for which the ground truth annotations are provided for just the central slice of each volumetric MR image. Specifically, semi-supervised learning and self-supervised learning methods are used to generate two independent sets of pseudo labels. These pseudo labels are then fused by Boolean operation to extract a more confident pseudo label set. The images with either manual or network self-generated labels are then employed to train a segmentation model for target volume extraction. Experimental results on a publicly available prostate MR image dataset demonstrate that, while requiring significantly less annotation effort, our framework generates very encouraging segmentation results. The proposed framework is very useful in clinical applications when training data with dense annotations are difficult to obtain. ",
    "url": "https://arxiv.org/abs/2211.08840",
    "authors": [
      "Yousuf Babiker M. Osman",
      "Cheng Li",
      "Weijian Huang",
      "Nazik Elsayed",
      "Zhenzhen Xue",
      "Hairong Zheng",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08843",
    "title": "Data Augmentation with Unsupervised Speaking Style Transfer for Speech  Emotion Recognition",
    "abstract": "Currently, the performance of Speech Emotion Recognition (SER) systems is mainly constrained by the absence of large-scale labelled corpora. Data augmentation is regarded as a promising approach, which borrows methods from Automatic Speech Recognition (ASR), for instance, perturbation on speed and pitch, or generating emotional speech utilizing generative adversarial networks. In this paper, we propose EmoAug, a novel style transfer model to augment emotion expressions, in which a semantic encoder and a paralinguistic encoder represent verbal and non-verbal information respectively. Additionally, a decoder reconstructs speech signals by conditioning on the aforementioned two information flows in an unsupervised fashion. Once training is completed, EmoAug enriches expressions of emotional speech in different prosodic attributes, such as stress, rhythm and intensity, by feeding different styles into the paralinguistic encoder. In addition, we can also generate similar numbers of samples for each class to tackle the data imbalance issue. Experimental results on the IEMOCAP dataset demonstrate that EmoAug can successfully transfer different speaking styles while retaining the speaker identity and semantic content. Furthermore, we train a SER model with data augmented by EmoAug and show that it not only surpasses the state-of-the-art supervised and self-supervised methods but also overcomes overfitting problems caused by data imbalance. Some audio samples can be found on our demo website. ",
    "url": "https://arxiv.org/abs/2211.08843",
    "authors": [
      "Leyuan Qu",
      "Wei Wang",
      "Taihao Li",
      "Cornelius Weber",
      "Stefan Wermter",
      "Fuji Ren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.08859",
    "title": "Attacking Object Detector Using A Universal Targeted Label-Switch Patch",
    "abstract": "Adversarial attacks against deep learning-based object detectors (ODs) have been studied extensively in the past few years. These attacks cause the model to make incorrect predictions by placing a patch containing an adversarial pattern on the target object or anywhere within the frame. However, none of prior research proposed a misclassification attack on ODs, in which the patch is applied on the target object. In this study, we propose a novel, universal, targeted, label-switch attack against the state-of-the-art object detector, YOLO. In our attack, we use (i) a tailored projection function to enable the placement of the adversarial patch on multiple target objects in the image (e.g., cars), each of which may be located a different distance away from the camera or have a different view angle relative to the camera, and (ii) a unique loss function capable of changing the label of the attacked objects. The proposed universal patch, which is trained in the digital domain, is transferable to the physical domain. We performed an extensive evaluation using different types of object detectors, different video streams captured by different cameras, and various target classes, and evaluated different configurations of the adversarial patch in the physical domain. ",
    "url": "https://arxiv.org/abs/2211.08859",
    "authors": [
      "Avishag Shapira",
      "Ron Bitton",
      "Dan Avraham",
      "Alon Zolfi",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08864",
    "title": "PrivacyProber: Assessment and Detection of Soft-Biometric  Privacy-Enhancing Techniques",
    "abstract": "Soft-biometric privacy-enhancing techniques represent machine learning methods that aim to: (i) mitigate privacy concerns associated with face recognition technology by suppressing selected soft-biometric attributes in facial images (e.g., gender, age, ethnicity) and (ii) make unsolicited extraction of sensitive personal information infeasible. Because such techniques are increasingly used in real-world applications, it is imperative to understand to what extent the privacy enhancement can be inverted and how much attribute information can be recovered from privacy-enhanced images. While these aspects are critical, they have not been investigated in the literature. We, therefore, study the robustness of several state-of-the-art soft-biometric privacy-enhancing techniques to attribute recovery attempts. We propose PrivacyProber, a high-level framework for restoring soft-biometric information from privacy-enhanced facial images, and apply it for attribute recovery in comprehensive experiments on three public face datasets, i.e., LFW, MUCT and Adience. Our experiments show that the proposed framework is able to restore a considerable amount of suppressed information, regardless of the privacy-enhancing technique used, but also that there are significant differences between the considered privacy models. These results point to the need for novel mechanisms that can improve the robustness of existing privacy-enhancing techniques and secure them against potential adversaries trying to restore suppressed information. ",
    "url": "https://arxiv.org/abs/2211.08864",
    "authors": [
      "Peter Rot",
      "Peter Peer",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08878",
    "title": "Video-Music Retrieval:A Dual-Path Cross-Modal Network",
    "abstract": "We propose a method to recommend background music for videos. Current work rarely considers the emotional information of music, which is essential for video music retrieval. To achieve this, we design two paths to process content information and emotional information between modal. Based on characteristics of video and music, we design various feature extraction schemes and common representation spaces. More importantly, we propose a way to combine content information with emotional information. Additionally, we make improvements to the classical metric loss to be more suited to this task. Experiments show that this dual path video music retrieval network can effectively merge information. Compare with existing methods, the retrieval task evaluation index: increasing Recall@1 by 3.94 and Recall@25 by 16.36. ",
    "url": "https://arxiv.org/abs/2211.08878",
    "authors": [
      "Xin Gu",
      "Yinghua Shen",
      "Chaohui Lv"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.08892",
    "title": "Fast Graph Generative Model via Spectral Diffusion",
    "abstract": "Generating graph-structured data is a challenging problem, which requires learning the underlying distribution of graphs. Various models such as graph VAE, graph GANs and graph diffusion models have been proposed to generate meaningful and reliable graphs, among which the diffusion models have achieved state-of-the-art performance. In this paper, we argue that running full-rank diffusion SDEs on the whole space hinders diffusion models from learning graph topology generation, and hence significantly deteriorates the quality of generated graph data. To address this limitation, we propose an efficient yet effective Graph Spectral Diffusion Model (GSDM), which is driven by low-rank diffusion SDEs on the graph spectrum space. Our spectral diffusion model is further proven to enjoy a substantially stronger theoretical guarantee than standard diffusion models. Extensive experiments across various datasets demonstrate that, our proposed GSDM turns out to be the SOTA model, by exhibiting either significantly higher generation quality or much less computational consumption than the baselines. ",
    "url": "https://arxiv.org/abs/2211.08892",
    "authors": [
      "Tianze Luo",
      "Zhanfeng Mo",
      "Sinno Jialin Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08900",
    "title": "Convergence analysis of unsupervised Legendre-Galerkin neural networks  for linear second-order elliptic PDEs",
    "abstract": "In this paper, we perform the convergence analysis of unsupervised Legendre--Galerkin neural networks (ULGNet), a deep-learning-based numerical method for solving partial differential equations (PDEs). Unlike existing deep learning-based numerical methods for PDEs, the ULGNet expresses the solution as a spectral expansion with respect to the Legendre basis and predicts the coefficients with deep neural networks by solving a variational residual minimization problem. Since the corresponding loss function is equivalent to the residual induced by the linear algebraic system depending on the choice of basis functions, we prove that the minimizer of the discrete loss function converges to the weak solution of the PDEs. Numerical evidence will also be provided to support the theoretical result. Key technical tools include the variant of the universal approximation theorem for bounded neural networks, the analysis of the stiffness and mass matrices, and the uniform law of large numbers in terms of the Rademacher complexity. ",
    "url": "https://arxiv.org/abs/2211.08900",
    "authors": [
      "Seungchan Ko",
      "Seok-Bae Yun",
      "Youngjoon Hong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08903",
    "title": "Cross-Mode Knowledge Adaptation for Bike Sharing Demand Prediction using  Domain-Adversarial Graph Neural Networks",
    "abstract": "For bike sharing systems, demand prediction is crucial to ensure the timely re-balancing of available bikes according to predicted demand. Existing methods for bike sharing demand prediction are mostly based on its own historical demand variation, essentially regarding it as a closed system and neglecting the interaction between different transportation modes. This is particularly important for bike sharing because it is often used to complement travel through other modes (e.g., public transit). Despite some recent progress, no existing method is capable of leveraging spatiotemporal information from multiple modes and explicitly considers the distribution discrepancy between them, which can easily lead to negative transfer. To address these challenges, this study proposes a domain-adversarial multi-relational graph neural network (DA-MRGNN) for bike sharing demand prediction with multimodal historical data as input. A temporal adversarial adaptation network is introduced to extract shareable features from demand patterns of different modes. To capture correlations between spatial units across modes, we adapt a multi-relational graph neural network (MRGNN) considering both cross-mode similarity and difference. In addition, an explainable GNN technique is developed to understand how our proposed model makes predictions. Extensive experiments are conducted using real-world bike sharing, subway and ride-hailing data from New York City. The results demonstrate the superior performance of our proposed approach compared to existing methods and the effectiveness of different model components. ",
    "url": "https://arxiv.org/abs/2211.08903",
    "authors": [
      "Yuebing Liang",
      "Guan Huang",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08904",
    "title": "Self-supervised Egomotion and Depth Learning via Bi-directional  Coarse-to-Fine Scale Recovery",
    "abstract": "Self-supervised learning of egomotion and depth has recently attracted great attentions. These learning models can provide pose and depth maps to support navigation and perception task for autonomous driving and robots, while they do not require high-precision ground-truth labels to train the networks. However, monocular vision based methods suffer from pose scale-ambiguity problem, so that can not generate physical meaningful trajectory, and thus their applications are limited in real-world. We propose a novel self-learning deep neural network framework that can learn to estimate egomotion and depths with absolute metric scale from monocular images. Coarse depth scale is recovered via comparing point cloud data against a pretrained model that ensures the consistency of photometric loss. The scale-ambiguity problem is solved by introducing a novel two-stages coarse-to-fine scale recovery strategy that jointly refines coarse poses and depths. Our model successfully produces pose and depth estimates in global scale-metric, even in low-light condition, i.e. driving at night. The evaluation on the public datasets demonstrates that our model outperforms both representative traditional and learning based VOs and VIOs, e.g. VINS-mono, ORB-SLAM, SC-Learner, and UnVIO. ",
    "url": "https://arxiv.org/abs/2211.08904",
    "authors": [
      "Hao Qu",
      "Lilian Zhang",
      "Xiaoping Hu",
      "Xiaofeng He",
      "Xianfei Pan",
      "Changhao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.08910",
    "title": "On the Connection of Generative Models and Discriminative Models for  Anomaly Detection",
    "abstract": "Anomaly detection (AD) has attracted considerable attention in both academia and industry. Due to the lack of anomalous data in many practical cases, AD is usually solved by first modeling the normal data pattern and then determining if data fit this model. Generative models (GMs) seem a natural tool to achieve this purpose, which learn the normal data distribution and estimate it using a probability density function (PDF). However, some works have observed the ideal performance of such GM-based AD methods. In this paper, we propose a new perspective on the ideal performance of GM-based AD methods. We state that in these methods, the implicit assumption that connects GMs'results to AD's goal is usually implausible due to normal data's multi-peaked distribution characteristic, which is quite common in practical cases. We first qualitatively formulate this perspective, and then focus on the Gaussian mixture model (GMM) to intuitively illustrate the perspective, which is a typical GM and has the natural property to approximate multi-peaked distributions. Based on the proposed perspective, in order to bypass the implicit assumption in the GMM-based AD method, we suggest integrating the Discriminative idea to orient GMM to AD tasks (DiGMM). With DiGMM, we establish a connection of generative and discriminative models, which are two key paradigms for AD and are usually treated separately before. This connection provides a possible direction for future works to jointly consider the two paradigms and incorporate their complementary characteristics for AD. ",
    "url": "https://arxiv.org/abs/2211.08910",
    "authors": [
      "Jingxuan Pang",
      "Chunguang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.08916",
    "title": "Privacy Engineering in the Wild: Understanding the Practitioners'  Mindset, Organisational Culture, and Current Practices",
    "abstract": "Privacy engineering, as an emerging field of research and practice, comprises the technical capabilities and management processes needed to implement, deploy, and operate privacy features and controls in working systems. For that, software practitioners and other stakeholders in software companies need to work cooperatively toward building privacy-preserving businesses and engineering solutions. Significant research has been done to understand the software practitioners' perceptions of information privacy, but more emphasis should be given to the uptake of concrete privacy engineering components. This research delves into the software practitioners' perspectives and mindset, organisational aspects, and current practices on privacy and its engineering processes. A total of 30 practitioners from various countries and backgrounds were interviewed, sharing their experiences and voicing their opinions on a broad range of privacy topics. The thematic analysis methodology was adopted to code the interview data qualitatively and construct a rich and nuanced thematic framework. As a result, we identified three critical interconnected themes that compose our thematic framework for privacy engineering \"in the wild\": (1) personal privacy mindset and stance, categorised into practitioners' privacy knowledge, attitudes and behaviours; (2) organisational privacy culture, such as decision-power and positive and negative examples of privacy climate; and, (3) privacy engineering practices, such as procedures and controls concretely used in the industry. Among the main findings, this study provides many insights about the state-of-the-practice of privacy engineering, pointing to a positive influence of privacy laws (e.g., EU General Data Protection Regulation) on practitioners' behaviours and organisations' cultures. Aspects such as organisational privacy culture and climate were also confirmed to [...] ",
    "url": "https://arxiv.org/abs/2211.08916",
    "authors": [
      "Leonardo Horn Iwaya",
      "Muhammad Ali Babar",
      "Awais Rashid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.08927",
    "title": "Benchmarking Graph Neural Networks for FMRI analysis",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool to learn from graph-structured data. A paramount example of such data is the brain, which operates as a network, from the micro-scale of neurons, to the macro-scale of regions. This organization deemed GNNs a natural tool of choice to model brain activity, and have consequently attracted a lot of attention in the neuroimaging community. Yet, the advantage of adopting these models over conventional methods has not yet been assessed in a systematic way to gauge if GNNs are capable of leveraging the underlying structure of the data to improve learning. In this work, we study and evaluate the performance of five popular GNN architectures in diagnosing major depression disorder and autism spectrum disorder in two multi-site clinical datasets, and sex classification on the UKBioBank, from functional brain scans under a general uniform framework. Our results show that GNNs fail to outperform kernel-based and structure-agnostic deep learning models, in which 1D CNNs outperform the other methods in all scenarios. We highlight that creating optimal graph structures for functional brain data is a major bottleneck hindering the performance of GNNs, where existing works use arbitrary measures to define the edges resulting in noisy graphs. We therefore propose to integrate graph diffusion into existing architectures and show that it can alleviate this problem and improve their performance. Our results call for increased moderation and rigorous validation when evaluating graph methods and advocate for more data-centeric approaches in developing GNNs for functional neuroimaging applications. ",
    "url": "https://arxiv.org/abs/2211.08927",
    "authors": [
      "Ahmed ElGazzar",
      "Rajat Thomas",
      "Guido van Wingen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08930",
    "title": "How Far Are Wireless Networks from Being Truly Deterministic?",
    "abstract": "With the rapid development of Internet-of-Things (IoT) technology and machine-type communications, various emerging applications appear in industrial productions and our daily lives. Among these, applications like industrial sensing and controlling, remote surgery, and automatic driving require an extremely low latency and a very small jitter. Delivering information deterministically has become one of the the biggest challenges for modern wire-line and wireless communications. In this paper, we present a review of currently available wire-line deterministic networks and discuss the main challenges to build wireless deterministic networks. We also discuss and propose several potential techniques enabling wireless networks to provide deterministic communications. By elaborating the coding/modulation schemes of the physical layer and managing the channel-access/packet-scheduling at the media access control (MAC) layer, it is believed that wireless deterministic communications can be realized in the near future. ",
    "url": "https://arxiv.org/abs/2211.08930",
    "authors": [
      "Yan Li",
      "Yunquan Dong",
      "Pingyi Fan",
      "Khaled Ben Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.08932",
    "title": "Semantic Communications in Multi-user Wireless Networks",
    "abstract": "This article investigates the exploitation of semantic communications in multi-user networks. We propose a novel heterogeneous semantic and bit multi-user framework for providing flawless, customized, and intelligent information transmission. We discuss both orthogonal multiple access (OMA) and non-orthogonal multiple access (NOMA) for the proposed heterogeneous framework, with an emphasis on investigating the attractive interplay between semantic communications and NOMA, namely NOMA enabled semantic communications and semantic communications enhanced NOMA. 1) For NOMA enabled semantic communications, we propose a semi-NOMA scheme for efficiently facilitating the heterogeneous semantic and bit multi-user communication, which unifies conventional NOMA and OMA schemes. The fundamental performance limit, namely semantic-versus-bit rate region, is characterized, which shows the superiority of the proposed semi-NOMA. 2) For semantic communications enhanced NOMA, we propose an opportunistic semantic and bit communication approach to alleviate the early-late rate disparity issue in NOMA. Numerical case studies demonstrate that significant performance gain can be achieved for NOMA by employing semantic communications than bit communications. Finally, several open research directions are highlighted. ",
    "url": "https://arxiv.org/abs/2211.08932",
    "authors": [
      "Xidong Mu",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.08939",
    "title": "Augmented Physics-Informed Neural Networks (APINNs): A gating  network-based soft domain decomposition methodology",
    "abstract": "In this paper, we propose the augmented physics-informed neural network (APINN), which adopts soft and trainable domain decomposition and flexible parameter sharing to further improve the extended PINN (XPINN) as well as the vanilla PINN methods. In particular, a trainable gate network is employed to mimic the hard and discrete decomposition of XPINN, which can be flexibly fine-tuned for discovering a potentially better partition. It weight-averages several sub-nets as the output of APINN. APINN does not require complex interface conditions, and its sub-nets can take advantage of all training samples rather than just part of the training data in their subdomains. Lastly, each sub-net shares part of the common parameters to capture the similar components in each decomposed function. Furthermore, following the PINN generalization theory in Hu et al. [2021], we show that APINN can improve generalization by proper gate network initialization and general domain & function decomposition. Extensive experiments on different types of PDEs demonstrate how APINN improves the PINN and XPINN methods. Specifically, we present examples where XPINN performs similarly to or worse than PINN, so that APINN can significantly improve both. We also show cases where XPINN is already better than PINN, so APINN can still slightly improve XPINN. Furthermore, we visualize the optimized gating networks and their optimization trajectories, and connect them with their performance, which helps discover the possibly optimal decomposition. Interestingly, if initialized by different decomposition, the performances of corresponding APINNs can differ drastically. This, in turn, shows the potential to design an optimal domain decomposition for the differential equation problem under consideration. ",
    "url": "https://arxiv.org/abs/2211.08939",
    "authors": [
      "Zheyuan Hu",
      "Ameya D. Jagtap",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.08942",
    "title": "Differentially Private Optimizers Can Learn Adversarially Robust Models",
    "abstract": "Machine learning models have shone in a variety of domains and attracted increasing attention from both the security and the privacy communities. One important yet worrying question is: will training models under the differential privacy (DP) constraint unfavorably impact on the adversarial robustness? While previous works have postulated that privacy comes at the cost of worse robustness, we give the first theoretical analysis to show that DP models can indeed be robust and accurate, even sometimes more robust than their naturally-trained non-private counterparts. We observe three key factors that influence the privacy-robustness-accuracy tradeoff: (1) hyperparameters for DP optimizers are critical; (2) pre-training on public data significantly mitigates the accuracy and robustness drop; (3) choice of DP optimizers makes a difference. With these factors set properly, we achieve 90\\% natural accuracy, 72\\% robust accuracy ($+9\\%$ than the non-private model) under $l_2(0.5)$ attack, and 69\\% robust accuracy ($+16\\%$ than the non-private model) with pre-trained SimCLRv2 model under $l_\\infty(4/255)$ attack on CIFAR10 with $\\epsilon=2$. In fact, we show both theoretically and empirically that DP models are Pareto optimal on the accuracy-robustness tradeoff. Empirically, the robustness of DP models is consistently observed on MNIST, Fashion MNIST and CelebA datasets, with ResNet and Vision Transformer. We believe our encouraging results are a significant step towards training models that are private as well as robust. ",
    "url": "https://arxiv.org/abs/2211.08942",
    "authors": [
      "Yuan Zhang",
      "Zhiqi Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08972",
    "title": "New Frontiers in Graph Autoencoders: Joint Community Detection and Link  Prediction",
    "abstract": "Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as powerful methods for link prediction (LP). Their performances are less impressive on community detection (CD), where they are often outperformed by simpler alternatives such as the Louvain method. It is still unclear to what extent one can improve CD with GAE and VGAE, especially in the absence of node features. It is moreover uncertain whether one could do so while simultaneously preserving good performances on LP in a multi-task setting. In this workshop paper, summarizing results from our journal publication (Salha-Galvan et al. 2022), we show that jointly addressing these two tasks with high accuracy is possible. For this purpose, we introduce a community-preserving message passing scheme, doping our GAE and VGAE encoders by considering both the initial graph and Louvain-based prior communities when computing embedding spaces. Inspired by modularity-based clustering, we further propose novel training and optimization strategies specifically designed for joint LP and CD. We demonstrate the empirical effectiveness of our approach, referred to as Modularity-Aware GAE and VGAE, on various real-world graphs. ",
    "url": "https://arxiv.org/abs/2211.08972",
    "authors": [
      "Guillaume Salha-Galvan",
      "Johannes F. Lutzeyer",
      "George Dasoulas",
      "Romain Hennequin",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.08975",
    "title": "Region Embedding with Intra and Inter-View Contrastive Learning",
    "abstract": "Unsupervised region representation learning aims to extract dense and effective features from unlabeled urban data. While some efforts have been made for solving this problem based on multiple views, existing methods are still insufficient in extracting representations in a view and/or incorporating representations from different views. Motivated by the success of contrastive learning for representation learning, we propose to leverage it for multi-view region representation learning and design a model called ReMVC (Region Embedding with Multi-View Contrastive Learning) by following two guidelines: i) comparing a region with others within each view for effective representation extraction and ii) comparing a region with itself across different views for cross-view information sharing. We design the intra-view contrastive learning module which helps to learn distinguished region embeddings and the inter-view contrastive learning module which serves as a soft co-regularizer to constrain the embedding parameters and transfer knowledge across multi-views. We exploit the learned region embeddings in two downstream tasks named land usage clustering and region popularity prediction. Extensive experiments demonstrate that our model achieves impressive improvements compared with seven state-of-the-art baseline methods, and the margins are over 30% in the land usage clustering task. ",
    "url": "https://arxiv.org/abs/2211.08975",
    "authors": [
      "Liang Zhang",
      "Cheng Long",
      "Gao Cong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08982",
    "title": "Normative Modeling via Conditional Variational Autoencoder and  Adversarial Learning to Identify Brain Dysfunction in Alzheimer's Disease",
    "abstract": "Normative modeling is an emerging and promising approach to effectively study disorder heterogeneity in individual participants. In this study, we propose a novel normative modeling method by combining conditional variational autoencoder with adversarial learning (ACVAE) to identify brain dysfunction in Alzheimer's Disease (AD). Specifically, we first train a conditional VAE on the healthy control (HC) group to create a normative model conditioned on covariates like age, gender and intracranial volume. Then we incorporate an adversarial training process to construct a discriminative feature space that can better generalize to unseen data. Finally, we compute deviations from the normal criterion at the patient level to determine which brain regions were associated with AD. Our experiments on OASIS-3 database show that the deviation maps generated by our model exhibit higher sensitivity to AD compared to other deep normative models, and are able to better identify differences between the AD and HC groups. ",
    "url": "https://arxiv.org/abs/2211.08982",
    "authors": [
      "Xuetong Wang",
      "Kanhao Zhao",
      "Rong Zhou",
      "Alex Leow",
      "Ricardo Osorio",
      "Yu Zhang",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.08989",
    "title": "Avoid Overthinking in Self-Supervised Models for Speech Recognition",
    "abstract": "Self-supervised learning (SSL) models reshaped our approach to speech, language and vision. However their huge size and the opaque relations between their layers and tasks result in slow inference and network overthinking, where predictions made from the last layer of large models is worse than those made from intermediate layers. Early exit (EE) strategies can solve both issues by dynamically reducing computations at inference time for certain samples. Although popular for classification tasks in vision and language, EE has seen less use for sequence-to-sequence speech recognition (ASR) tasks where outputs from early layers are often degenerate. This challenge is further compounded when speech SSL models are applied on out-of-distribution (OOD) data. This paper first shows that SSL models do overthinking in ASR. We then motivate further research in EE by computing an optimal bound for performance versus speed trade-offs. To approach this bound we propose two new strategies for ASR: (1) we adapt the recently proposed patience strategy to ASR; and (2) we design a new EE strategy specific to ASR that performs better than all strategies previously introduced. ",
    "url": "https://arxiv.org/abs/2211.08989",
    "authors": [
      "Dan Berrebbi",
      "Brian Yan",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.09011",
    "title": "Detecting train driveshaft damages using accelerometer signals and  Differential Convolutional Neural Networks",
    "abstract": "Railway axle maintenance is critical to avoid catastrophic failures. Nowadays, condition monitoring techniques are becoming more prominent in the industry to prevent enormous costs and damage to human lives. This paper proposes the development of a railway axle condition monitoring system based on advanced 2D-Convolutional Neural Network (CNN) architectures applied to time-frequency representations of vibration signals. For this purpose, several preprocessing steps and different types of Deep Learning (DL) and Machine Learning (ML) architectures are discussed to design an accurate classification system. The resultant system converts the railway axle vibration signals into time-frequency domain representations, i.e., spectrograms, and, thus, trains a two-dimensional CNN to classify them depending on their cracks. The results showed that the proposed approach outperforms several alternative methods tested. The CNN architecture has been tested in 3 different wheelset assemblies, achieving AUC scores of 0.93, 0.86, and 0.75 outperforming any other architecture and showing a high level of reliability when classifying 4 different levels of defects. ",
    "url": "https://arxiv.org/abs/2211.09011",
    "authors": [
      "Ant\u00eda L\u00f3pez Galdo",
      "Alejandro Guerrero-L\u00f3pez",
      "Pablo M. Olmos",
      "Mar\u00eda Jes\u00fas G\u00f3mez Garc\u00eda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.09018",
    "title": "Real Estate Attribute Prediction from Multiple Visual Modalities with  Missing Data",
    "abstract": "The assessment and valuation of real estate requires large datasets with real estate information. Unfortunately, real estate databases are usually sparse in practice, i.e., not for each property every important attribute is available. In this paper, we study the potential of predicting high-level real estate attributes from visual data, specifically from two visual modalities, namely indoor (interior) and outdoor (facade) photos. We design three models using different multimodal fusion strategies and evaluate them for three different use cases. Thereby, a particular challenge is to handle missing modalities. We evaluate different fusion strategies, present baselines for the different prediction tasks, and find that enriching the training data with additional incomplete samples can lead to an improvement in prediction accuracy. Furthermore, the fusion of information from indoor and outdoor photos results in a performance boost of up to 5% in Macro F1-score. ",
    "url": "https://arxiv.org/abs/2211.09018",
    "authors": [
      "Eric Stumpe",
      "Miroslav Despotovic",
      "Zedong Zhang",
      "Matthias Zeppelzauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09022",
    "title": "Region Proposal Network Pre-Training Helps Label-Efficient Object  Detection",
    "abstract": "Self-supervised pre-training, based on the pretext task of instance discrimination, has fueled the recent advance in label-efficient object detection. However, existing studies focus on pre-training only a feature extractor network to learn transferable representations for downstream detection tasks. This leads to the necessity of training multiple detection-specific modules from scratch in the fine-tuning phase. We argue that the region proposal network (RPN), a common detection-specific module, can additionally be pre-trained towards reducing the localization error of multi-stage detectors. In this work, we propose a simple pretext task that provides an effective pre-training for the RPN, towards efficiently improving downstream object detection performance. We evaluate the efficacy of our approach on benchmark object detection tasks and additional downstream tasks, including instance segmentation and few-shot detection. In comparison with multi-stage detectors without RPN pre-training, our approach is able to consistently improve downstream task performance, with largest gains found in label-scarce settings. ",
    "url": "https://arxiv.org/abs/2211.09022",
    "authors": [
      "Linus Ericsson",
      "Nanqing Dong",
      "Yongxin Yang",
      "Ales Leonardis",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.09027",
    "title": "LLEDA -- Lifelong Self-Supervised Domain Adaptation",
    "abstract": "Lifelong domain adaptation remains a challenging task in machine learning due to the differences among the domains and the unavailability of historical data. The ultimate goal is to learn the distributional shifts while retaining the previously gained knowledge. Inspired by the Complementary Learning Systems (CLS) theory, we propose a novel framework called Lifelong Self-Supervised Domain Adaptation (LLEDA). LLEDA addresses catastrophic forgetting by replaying hidden representations rather than raw data pixels and domain-agnostic knowledge transfer using self-supervised learning. LLEDA does not access labels from the source or the target domain and only has access to a single domain at any given time. Extensive experiments demonstrate that the proposed method outperforms several other methods and results in a long-term adaptation, while being less prone to catastrophic forgetting when transferred to new domains. ",
    "url": "https://arxiv.org/abs/2211.09027",
    "authors": [
      "Mamatha Thota",
      "Dewei Yi",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.09039",
    "title": "UniRel: Unified Representation and Interaction for Joint Relational  Triple Extraction",
    "abstract": "Relational triple extraction is challenging for its difficulty in capturing rich correlations between entities and relations. Existing works suffer from 1) heterogeneous representations of entities and relations, and 2) heterogeneous modeling of entity-entity interactions and entity-relation interactions. Therefore, the rich correlations are not fully exploited by existing works. In this paper, we propose UniRel to address these challenges. Specifically, we unify the representations of entities and relations by jointly encoding them within a concatenated natural language sequence, and unify the modeling of interactions with a proposed Interaction Map, which is built upon the off-the-shelf self-attention mechanism within any Transformer block. With comprehensive experiments on two popular relational triple extraction datasets, we demonstrate that UniRel is more effective and computationally efficient. The source code is available at https://github.com/wtangdev/UniRel. ",
    "url": "https://arxiv.org/abs/2211.09039",
    "authors": [
      "Wei Tang",
      "Benfeng Xu",
      "Yuyue Zhao",
      "Zhendong Mao",
      "Yifeng Liu",
      "Yong Liao",
      "Haiyong Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.09041",
    "title": "Anomaly Detection via Multi-Scale Contrasted Memory",
    "abstract": "Deep anomaly detection (AD) aims to provide robust and efficient classifiers for one-class and unbalanced settings. However current AD models still struggle on edge-case normal samples and are often unable to keep high performance over different scales of anomalies. Moreover, there currently does not exist a unified framework efficiently covering both one-class and unbalanced learnings. In the light of these limitations, we introduce a new two-stage anomaly detector which memorizes during training multi-scale normal prototypes to compute an anomaly deviation score. First, we simultaneously learn representations and memory modules on multiple scales using a novel memory-augmented contrastive learning. Then, we train an anomaly distance detector on the spatial deviation maps between prototypes and observations. Our model highly improves the state-of-the-art performance on a wide range of object, style and local anomalies with up to 35\\% error relative improvement on CIFAR-10. It is also the first model to keep high performance across the one-class and unbalanced settings. ",
    "url": "https://arxiv.org/abs/2211.09041",
    "authors": [
      "Loic Jezequel",
      "Ngoc-Son Vu",
      "Jean Beaudet",
      "Aymeric Histace"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.09043",
    "title": "Community gifting groups on Facebook",
    "abstract": "We use de-identified data from Facebook Groups to study and provide a descriptive analysis of local gift-giving communities, in particular buy nothing (BN) groups. These communities allow people to give items they no longer need, reduce waste, and connect to local community. Millions of people have joined BN groups on Facebook, with an increasing pace through the COVID-19 pandemic. BN groups are more popular in dense and urban US counties with higher educational attainment. Compared to other local groups, BN groups have lower Facebook friendship densities, suggesting they bring together people who are not already connected. The interaction graphs in BN groups form larger strongly connected components, indicative of norms of generalized reciprocity. The interaction patterns in BN groups are similar to other local online gift-giving groups, with names containing terms such as `free stuff\" and `pay it forward\". This points to an interaction signature for local online gift-giving communities. ",
    "url": "https://arxiv.org/abs/2211.09043",
    "authors": [
      "Ama\u00e7 Herda\u011fdelen",
      "Lada Adamic",
      "Bogdan State"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.09053",
    "title": "A moving horizon state and parameter estimation scheme with guaranteed  robust convergence",
    "abstract": "We propose a moving horizon estimation scheme for joint state and parameter estimation for nonlinear uncertain discrete-time systems. We establish robust exponential convergence of the combined estimation error subject to process disturbances and measurement noise. We employ a joint incremental input/output-to-state stability ($\\delta$-IOSS) Lyapunov function to characterize nonlinear detectability for the states and (constant) parameters of the system. Sufficient conditions for the construction of a joint $\\delta$-IOSS Lyapunov function are provided for a special class of nonlinear systems using a persistence of excitation condition. The theoretical results are illustrated by a numerical example. ",
    "url": "https://arxiv.org/abs/2211.09053",
    "authors": [
      "Julian D. Schiller",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.09061",
    "title": "Squeeze flow of micro-droplets: convolutional neural network with  trainable and tunable refinement",
    "abstract": "We propose a platform based on neural networks to solve the image-to-image translation problem in the context of squeeze flow of micro-droplets. In the first part of this paper, we present the governing partial differential equations to lay out the underlying physics of the problem. We also discuss our developed Python package, sqflow, which can potentially serve as free, flexible, and scalable standardized benchmarks in the fields of machine learning and computer vision. In the second part of this paper, we introduce a residual convolutional neural network to solve the corresponding inverse problem: to translate a high-resolution (HR) imprint image with a specific liquid film thickness to a low-resolution (LR) droplet pattern image capable of producing the given imprint image for an appropriate spread time of droplets. We propose a neural network architecture that learns to systematically tune the refinement level of its residual convolutional blocks by using the function approximators that are trained to map a given input parameter (film thickness) to an appropriate refinement level indicator. We use multiple stacks of convolutional layers the output of which is translated according to the refinement level indicators provided by the directly-connected function approximators. Together with a non-linear activation function, such a translation mechanism enables the HR imprint image to be refined sequentially in multiple steps until the target LR droplet pattern image is revealed. The proposed platform can be potentially applied to data compression and data encryption. The developed package and datasets are publicly available on GitHub at https://github.com/sqflow/sqflow. ",
    "url": "https://arxiv.org/abs/2211.09061",
    "authors": [
      "Aryan Mehboudi",
      "Shrawan Singhal",
      "S.V. Sreenivasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09064",
    "title": "Renewing Iterative Self-labeling Domain Adaptation with Application to  the Spine Motion Prediction",
    "abstract": "The area of transfer learning comprises supervised machine learning methods that cope with the issue when the training and testing data have different input feature spaces or distributions. In this work, we propose a novel transfer learning algorithm called Renewing Iterative Self-labeling Domain Adaptation (Re-ISDA). In this work, we propose a novel transfer learning algorithm called Renewing Iterative Self-labeling Domain Adaptation (Re-ISDA). ",
    "url": "https://arxiv.org/abs/2211.09064",
    "authors": [
      "Gecheng Chen",
      "Yu Zhou",
      "Xudong Zhang",
      "Rui Tuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.09067",
    "title": "Egocentric Hand-object Interaction Detection",
    "abstract": "In this paper, we propose a method to jointly determine the status of hand-object interaction. This is crucial for egocentric human activity understanding and interaction. From a computer vision perspective, we believe that determining whether a hand is interacting with an object depends on whether there is an interactive hand pose and whether the hand is touching the object. Thus, we extract the hand pose, hand-object masks to jointly determine the interaction status. In order to solve the problem of hand pose estimation due to in-hand object occlusion, we use a multi-cam system to capture hand pose data from multiple perspectives. We evaluate and compare our method with the most recent work from Shan et al. \\cite{Shan20} on selected images from EPIC-KITCHENS \\cite{damen2018scaling} dataset and achieve $89\\%$ accuracy on HOI (hand-object interaction) detection which is comparative to Shan's ($92\\%$). However, for real-time performance, our method can run over $\\textbf{30}$ FPS which is much more efficient than Shan's ($\\textbf{1}\\sim\\textbf{2}$ FPS). A demo can be found from https://www.youtube.com/watch?v=XVj3zBuynmQ ",
    "url": "https://arxiv.org/abs/2211.09067",
    "authors": [
      "Yao Lu",
      "Yanan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2211.09081",
    "title": "Secure SWIPT in STAR-RIS Aided Downlink MISO Rate-Splitting Multiple  Access Networks",
    "abstract": "Recently, simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) have emerged as a novel technology that facilitates sustainable communication by providing 360 coverage and new degrees-of-freedom (DoF) for manipulating signal propagation as well as simultaneous wireless information and power transfer (SWIPT). Inspired by these applications, this paper presents a novel STAR-RIS-aided secure SWIPT system for downlink multiple input single output (MISO) Rate-Splitting multiple access (RSMA) networks. The transmitter concurrently communicates with the information receivers (IRs) and sends energy to untrusted energy receivers (UERs). UERs are also able to wiretap the IR streams. The paper assumes that the channel state information (CSI) of the IRs is known at the transmitter. However, only imperfect CSI (ICSI) for the UERs is available at the transmitter. The paper aims to maximize the achievable worst-case sum secrecy rate (WCSSR) of the IRs under a total transmit power constraint, a sum energy constraint for the UERs, and constraints on the transmission and reflection coefficients by jointly optimizing the precoders and the transmission and reflection beamforming at the STAR-RIS. The formulated problem is non-convex with intricately coupled variables, and to tackle this challenge a suboptimal two-step iterative algorithm based on the sequential parametric convex approximation (SPCA) method is proposed. Specifically, the precoders and the transmission and reflection beamforming vectors are optimized alternatingly. Simulations are conducted to show that the proposed RSMA-based algorithm in a STAR-RIS aided network can improve the secrecy of the confidential information and the overall spectral efficiency. ",
    "url": "https://arxiv.org/abs/2211.09081",
    "authors": [
      "Hamid Reza Hashempour",
      "Hamed Bastami",
      "Majid Moradikia",
      "Seyed A.Zekavat",
      "Hamid Behroozi",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.09084",
    "title": "Technical Report on Neural Language Models and Few-Shot Learning for  Systematic Requirements Processing in MDSE",
    "abstract": "Systems engineering, in particular in the automotive domain, needs to cope with the massively increasing numbers of requirements that arise during the development process. To guarantee a high product quality and make sure that functional safety standards such as ISO26262 are fulfilled, the exploitation of potentials of model-driven systems engineering in the form of automatic analyses, consistency checks, and tracing mechanisms is indispensable. However, the language in which requirements are written, and the tools needed to operate on them, are highly individual and require domain-specific tailoring. This hinders automated processing of requirements as well as the linking of requirements to models. Introducing formal requirement notations in existing projects leads to the challenge of translating masses of requirements and process changes on the one hand and to the necessity of the corresponding training for the requirements engineers. In this paper, based on the analysis of an open-source set of automotive requirements, we derive domain-specific language constructs helping us to avoid ambiguities in requirements and increase the level of formality. The main contribution is the adoption and evaluation of few-shot learning with large pretrained language models for the automated translation of informal requirements to structured languages such as a requirement DSL. We show that support sets of less than ten translation examples can suffice to few-shot train a language model to incorporate keywords and implement syntactic rules into informal natural language requirements. ",
    "url": "https://arxiv.org/abs/2211.09084",
    "authors": [
      "Vincent Bertram",
      "Miriam Bo\u00df",
      "Evgeny Kusmenko",
      "Imke Helene Nachmann",
      "Bernhard Rumpe",
      "Danilo Trotta",
      "Louis Wachtmeister"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.09086",
    "title": "Molecular Fingerprints for Robust and Efficient ML-Driven Molecular  Generation",
    "abstract": "We propose a novel molecular fingerprint-based variational autoencoder applied for molecular generation on real-world drug molecules. We define more suitable and pharma-relevant baseline metrics and tests, focusing on the generation of diverse, drug-like, novel small molecules and scaffolds. When we apply these molecular generation metrics to our novel model, we observe a substantial improvement in chemical synthetic accessibility ($\\Delta\\bar{{SAS}}$ = -0.83) and in computational efficiency up to 5.9x in comparison to an existing state-of-the-art SMILES-based architecture. ",
    "url": "https://arxiv.org/abs/2211.09086",
    "authors": [
      "Ruslan N. Tazhigulov",
      "Joshua Schiller",
      "Jacob Oppenheim",
      "Max Winston"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09108",
    "title": "Robust Online Video Instance Segmentation with Track Queries",
    "abstract": "Recently, transformer-based methods have achieved impressive results on Video Instance Segmentation (VIS). However, most of these top-performing methods run in an offline manner by processing the entire video clip at once to predict instance mask volumes. This makes them incapable of handling the long videos that appear in challenging new video instance segmentation datasets like UVO and OVIS. We propose a fully online transformer-based video instance segmentation model that performs comparably to top offline methods on the YouTube-VIS 2019 benchmark and considerably outperforms them on UVO and OVIS. This method, called Robust Online Video Segmentation (ROVIS), augments the Mask2Former image instance segmentation model with track queries, a lightweight mechanism for carrying track information from frame to frame, originally introduced by the TrackFormer method for multi-object tracking. We show that, when combined with a strong enough image segmentation architecture, track queries can exhibit impressive accuracy while not being constrained to short videos. ",
    "url": "https://arxiv.org/abs/2211.09108",
    "authors": [
      "Zitong Zhan",
      "Daniel McKee",
      "Svetlana Lazebnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.09117",
    "title": "MAGE: MAsked Generative Encoder to Unify Representation Learning and  Image Synthesis",
    "abstract": "Generative modeling and representation learning are two key tasks in computer vision. However, these models are typically trained independently, which ignores the potential for each task to help the other, and leads to training and model maintenance overheads. In this work, we propose MAsked Generative Encoder (MAGE), the first framework to unify SOTA image generation and self-supervised representation learning. Our key insight is that using variable masking ratios in masked image modeling pre-training can allow generative training (very high masking ratio) and representation learning (lower masking ratio) under the same training framework. Inspired by previous generative models, MAGE uses semantic tokens learned by a vector-quantized GAN at inputs and outputs, combining this with masking. We can further improve the representation by adding a contrastive loss to the encoder output. We extensively evaluate the generation and representation learning capabilities of MAGE. On ImageNet-1K, a single MAGE ViT-L model obtains 9.10 FID in the task of class-unconditional image generation and 78.9% top-1 accuracy for linear probing, achieving state-of-the-art performance in both image generation and representation learning. Code is available at https://github.com/LTH14/mage. ",
    "url": "https://arxiv.org/abs/2211.09117",
    "authors": [
      "Tianhong Li",
      "Huiwen Chang",
      "Shlok Kumar Mishra",
      "Han Zhang",
      "Dina Katabi",
      "Dilip Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08424",
    "title": "Cyclic Generative Adversarial Networks With Congruent Image-Report  Generation For Explainable Medical Image Analysis",
    "abstract": "We present a novel framework for explainable labeling and interpretation of medical images. Medical images require specialized professionals for interpretation, and are explained (typically) via elaborate textual reports. Different from prior methods that focus on medical report generation from images or vice-versa, we novelly generate congruent image--report pairs employing a cyclic-Generative Adversarial Network (cycleGAN); thereby, the generated report will adequately explain a medical image, while a report-generated image that effectively characterizes the text visually should (sufficiently) resemble the original. The aim of the work is to generate trustworthy and faithful explanations for the outputs of a model diagnosing chest x-ray images by pointing a human user to similar cases in support of a diagnostic decision. Apart from enabling transparent medical image labeling and interpretation, we achieve report and image-based labeling comparable to prior methods, including state-of-the-art performance in some cases as evidenced by experiments on the Indiana Chest X-ray dataset ",
    "url": "https://arxiv.org/abs/2211.08424",
    "authors": [
      "Dwarikanath Mahapatra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08511",
    "title": "A Heuristic Subexponential Algorithm to Find Paths in Markoff Graphs  Over Finite Fields",
    "abstract": "Charles, Goren, and Lauter [J. Cryptology 22(1), 2009] explained how one can construct hash functions using expander graphs in which it is hard to find paths between specified vertices. The set of solutions to the classical Markoff equation $X^2+Y^2+Z^2=XYZ$ in a finite field $\\mathbb{F}_q$ has a natural structure as a tri-partite graph using three non-commuting polynomial automorphisms to connect the points. These graphs conjecturally form an expander family, and Fuchs, Lauter, Litman, and Tran [Mathematical Cryptology 1(1), 2022] suggest using this family of Markoff graphs in the CGL construction. In this note we show that in both a theoretical and a practical sense, assuming two randomness hypotheses, the path problem in a Markoff graph over $\\mathbb{F}_q$ can be solved in subexponential time, and is more-or-less equivalent in difficulty to factoring $q-1$ and solving three discrete logarithm problem in $\\mathbb{F}_q^*$. ",
    "url": "https://arxiv.org/abs/2211.08511",
    "authors": [
      "Joseph H. Silverman"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.08516",
    "title": "Phenotype Search Trajectory Networks for Linear Genetic Programming",
    "abstract": "Genotype-to-phenotype mappings translate genotypic variations such as mutations into phenotypic changes. Neutrality is the observation that some mutations do not lead to phenotypic changes. Studying the search trajectories in genotypic and phenotypic spaces, especially through neutral mutations, helps us to better understand the progression of evolution and its algorithmic behaviour. In this study, we visualise the search trajectories of a genetic programming system as graph-based models, where nodes are genotypes/phenotypes and edges represent their mutational transitions. We also quantitatively measure the characteristics of phenotypes including their genotypic abundance (the requirement for neutrality) and Kolmogorov complexity. We connect these quantified metrics with search trajectory visualisations, and find that more complex phenotypes are under-represented by fewer genotypes and are harder for evolution to discover. Less complex phenotypes, on the other hand, are over-represented by genotypes, are easier to find, and frequently serve as stepping-stones for evolution. ",
    "url": "https://arxiv.org/abs/2211.08516",
    "authors": [
      "Ting Hu",
      "Gabriela Ochoa",
      "Wolfgang Banzhaf"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08522",
    "title": "The scaling of goals via homeostasis: an evolutionary simulation,  experiment and analysis",
    "abstract": "All cognitive agents are composite beings. Specifically, complex living agents consist of cells, which are themselves competent sub-agents navigating physiological and metabolic spaces. Behavior science, evolutionary developmental biology, and the field of machine intelligence all seek an answer to the scaling of biological cognition: what evolutionary dynamics enable individual cells to integrate their activities to result in the emergence of a novel, higher-level intelligence that has goals and competencies that belong to it and not to its parts? Here, we report the results of simulations based on the TAME framework, which proposes that evolution pivoted the collective intelligence of cells during morphogenesis of the body into traditional behavioral intelligence by scaling up the goal states at the center of homeostatic processes. We tested the hypothesis that a minimal evolutionary framework is sufficient for small, low-level setpoints of metabolic homeostasis in cells to scale up into collectives (tissues) which solve a problem in morphospace: the organization of a body-wide positional information axis (the classic French Flag problem). We found that these emergent morphogenetic agents exhibit a number of predicted features, including the use of stress propagation dynamics to achieve its target morphology as well as the ability to recover from perturbation (robustness) and long-term stability (even though neither of these was directly selected for). Moreover we observed unexpected behavior of sudden remodeling long after the system stabilizes. We tested this prediction in a biological system - regenerating planaria - and observed a very similar phenomenon. We propose that this system is a first step toward a quantitative understanding of how evolution scales minimal goal-directed behavior (homeostatic loops) into higher-level problem-solving agents in morphogenetic and other spaces. ",
    "url": "https://arxiv.org/abs/2211.08522",
    "authors": [
      "Leo Pio-Lopez",
      "Johanna Bischof",
      "Jennifer V. LaPalme",
      "Michael Levin"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2211.08597",
    "title": "SketchySGD: Reliable Stochastic Optimization via Robust Curvature  Estimates",
    "abstract": "We introduce SketchySGD, a stochastic quasi-Newton method that uses sketching to approximate the curvature of the loss function. Quasi-Newton methods are among the most effective algorithms in traditional optimization, where they converge much faster than first-order methods such as SGD. However, for contemporary deep learning, quasi-Newton methods are considered inferior to first-order methods like SGD and Adam owing to higher per-iteration complexity and fragility due to inexact gradients. SketchySGD circumvents these issues by a novel combination of subsampling, randomized low-rank approximation, and dynamic regularization. In the convex case, we show SketchySGD with a fixed stepsize converges to a small ball around the optimum at a faster rate than SGD. In the non-convex case, SketchySGD converges linearly under two additional assumptions, interpolation and the Polyak-Lojaciewicz condition, the latter of which holds with high probability for wide neural networks. Numerical experiments on image and tabular data demonstrate the improved reliability and speed of SketchySGD for deep learning, compared to standard optimizers such as SGD and Adam and existing quasi-Newton methods. ",
    "url": "https://arxiv.org/abs/2211.08597",
    "authors": [
      "Zachary Frangella",
      "Pratik Rathore",
      "Shipu Zhao",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08654",
    "title": "Prediction and Uncertainty Quantification of SAFARI-1 Axial Neutron Flux  Profiles with Neural Networks",
    "abstract": "Artificial Neural Networks (ANNs) have been successfully used in various nuclear engineering applications, such as predicting reactor physics parameters within reasonable time and with a high level of accuracy. Despite this success, they cannot provide information about the model prediction uncertainties, making it difficult to assess ANN prediction credibility, especially in extrapolated domains. In this study, Deep Neural Networks (DNNs) are used to predict the assembly axial neutron flux profiles in the SAFARI-1 research reactor, with quantified uncertainties in the ANN predictions and extrapolation to cycles not used in the training process. The training dataset consists of copper-wire activation measurements, the axial measurement locations and the measured control bank positions obtained from the reactor's historical cycles. Uncertainty Quantification of the regular DNN models' predictions is performed using Monte Carlo Dropout (MCD) and Bayesian Neural Networks solved by Variational Inference (BNN VI). The regular DNNs, DNNs solved with MCD and BNN VI results agree very well among each other as well as with the new measured dataset not used in the training process, thus indicating good prediction and generalization capability. The uncertainty bands produced by MCD and BNN VI agree very well, and in general, they can fully envelop the noisy measurement data points. The developed ANNs are useful in supporting the experimental measurements campaign and neutronics code Verification and Validation (V&V). ",
    "url": "https://arxiv.org/abs/2211.08654",
    "authors": [
      "Lesego E. Moloko",
      "Pavel M. Bokov",
      "Xu Wu",
      "Kostadin N. Ivanov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.08849",
    "title": "L2 proficiency assessment using self-supervised speech representations",
    "abstract": "There has been a growing demand for automated spoken language assessment systems in recent years. A standard pipeline for this process is to start with a speech recognition system and derive features, either hand-crafted or based on deep-learning, that exploit the transcription and audio. Though these approaches can yield high performance systems, they require speech recognition systems that can be used for L2 speakers, and preferably tuned to the specific form of test being deployed. Recently a self-supervised speech representation based scheme, requiring no speech recognition, was proposed. This work extends the initial analysis conducted on this approach to a large scale proficiency test, Linguaskill, that comprises multiple parts, each designed to assess different attributes of a candidate's speaking proficiency. The performance of the self-supervised, wav2vec 2.0, system is compared to a high performance hand-crafted assessment system and a BERT-based text system both of which use speech transcriptions. Though the wav2vec 2.0 based system is found to be sensitive to the nature of the response, it can be configured to yield comparable performance to systems requiring a speech transcription, and yields gains when appropriately combined with standard approaches. ",
    "url": "https://arxiv.org/abs/2211.08849",
    "authors": [
      "Stefano Bann\u00f2",
      "Kate M. Knill",
      "Marco Matassoni",
      "Vyas Raina",
      "Mark J. F. Gales"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.08854",
    "title": "Graph Filters for Signal Processing and Machine Learning on Graphs",
    "abstract": "Filters are fundamental in extracting information from data. For time series and image data that reside on Euclidean domains, filters are the crux of many signal processing and machine learning techniques, including convolutional neural networks. Increasingly, modern data also reside on networks and other irregular domains whose structure is better captured by a graph. To process and learn from such data, graph filters account for the structure of the underlying data domain. In this article, we provide a comprehensive overview of graph filters, including the different filtering categories, design strategies for each type, and trade-offs between different types of graph filters. We discuss how to extend graph filters into filter banks and graph neural networks to enhance the representational power; that is, to model a broader variety of signal classes, data patterns, and relationships. We also showcase the fundamental role of graph filters in signal processing and machine learning applications. Our aim is that this article serves the dual purpose of providing a unifying framework for both beginner and experienced researchers, as well as a common understanding that promotes collaborations between signal processing, machine learning, and application domains. ",
    "url": "https://arxiv.org/abs/2211.08854",
    "authors": [
      "Elvin Isufi",
      "Fernando Gama",
      "David I. Shuman",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09024",
    "title": "Phenomenological Causality",
    "abstract": "Discussions on causal relations in real life often consider variables for which the definition of causality is unclear since the notion of interventions on the respective variables is obscure. Asking 'what qualifies an action for being an intervention on the variable X' raises the question whether the action impacted all other variables only through X or directly, which implicitly refers to a causal model. To avoid this known circularity, we instead suggest a notion of 'phenomenological causality' whose basic concept is a set of elementary actions. Then the causal structure is defined such that elementary actions change only the causal mechanism at one node (e.g. one of the causal conditionals in the Markov factorization). This way, the Principle of Independent Mechanisms becomes the defining property of causal structure in domains where causality is a more abstract phenomenon rather than being an objective fact relying on hard-wired causal links between tangible objects. We describe this phenomenological approach to causality for toy and hypothetical real-world examples and argue that it is consistent with the causal Markov condition when the system under consideration interacts with other variables that control the elementary actions. ",
    "url": "https://arxiv.org/abs/2211.09024",
    "authors": [
      "Dominik Janzing",
      "Sergio Hernan Garrido Mejia"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.09068",
    "title": "Ischemic Stroke Lesion Prediction using imbalanced Temporal Deep  Gaussian Process (iTDGP)",
    "abstract": "As one of the leading causes of mortality and disability worldwide, Acute Ischemic Stroke (AIS) occurs when the blood supply to the brain is suddenly interrupted because of a blocked artery. Within seconds of AIS onset, the brain cells surrounding the blocked artery die, which leads to the progression of the lesion. The automated and precise prediction of the existing lesion plays a vital role in the AIS treatment planning and prevention of further injuries. The current standard AIS assessment method, which thresholds the 3D measurement maps extracted from Computed Tomography Perfusion (CTP) images, is not accurate enough. Due to this fact, in this article, we propose the imbalanced Temporal Deep Gaussian Process (iTDGP), a probabilistic model that can improve AIS lesions prediction by using baseline CTP time series. Our proposed model can effectively extract temporal information from the CTP time series and map it to the class labels of the brain's voxels. In addition, by using batch training and voxel-level analysis iTDGP can learn from a few patients and it is robust against imbalanced classes. Moreover, our model incorporates a post-processor capable of improving prediction accuracy using spatial information. Our comprehensive experiments, on the ISLES 2018 and the University of Alberta Hospital (UAH) datasets, show that iTDGP performs better than state-of-the-art AIS lesion predictors, obtaining the (cross-validation) Dice score of 71.42% and 65.37% with a significant p<0.05, respectively. ",
    "url": "https://arxiv.org/abs/2211.09068",
    "authors": [
      "Mohsen Soltanpour",
      "Muhammad Yousefnezhad",
      "Russ Greiner",
      "Pierre Boulanger",
      "Brian Buck"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.09096",
    "title": "Testing geometric representation hypotheses from simulated place cell  recordings",
    "abstract": "Hippocampal place cells can encode spatial locations of an animal in physical or task-relevant spaces. We simulated place cell populations that encoded either Euclidean- or graph-based positions of a rat navigating to goal nodes in a maze with a graph topology, and used manifold learning methods such as UMAP and Autoencoders (AE) to analyze these neural population activities. The structure of the latent spaces learned by the AE reflects their true geometric structure, while PCA fails to do so and UMAP is less robust to noise. Our results support future applications of AE architectures to decipher the geometry of spatial encoding in the brain. ",
    "url": "https://arxiv.org/abs/2211.09096",
    "authors": [
      "Thibault Niederhauser",
      "Adam Lester",
      "Nina Miolane",
      "Khanh Dao Duc",
      "Manu S. Madhav"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:1910.09083",
    "title": "Spectral CUSUM for Online Network Structure Change Detection",
    "abstract": " Comments: In revision for IEEE Transactions on Information Theory ",
    "url": "https://arxiv.org/abs/1910.09083",
    "authors": [
      "Minghe Zhang",
      "Liyan Xie",
      "Yao Xie"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2012.09654",
    "title": "Detection and Prediction of Nutrient Deficiency Stress using  Longitudinal Aerial Imagery",
    "abstract": " Title: Detection and Prediction of Nutrient Deficiency Stress using  Longitudinal Aerial Imagery ",
    "url": "https://arxiv.org/abs/2012.09654",
    "authors": [
      "Saba Dadsetan",
      "Gisele Rose",
      "Naira Hovakimyan",
      "Jennifer Hobbs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2102.09708",
    "title": "Back Translation Survey for Improving Text Augmentation",
    "abstract": " Comments: 18 Pages, 10 Figures, 4 Tables, 37 References ",
    "url": "https://arxiv.org/abs/2102.09708",
    "authors": [
      "Matthew Ciolino",
      "David Noever",
      "Josh Kalin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2103.10502",
    "title": "Ano-Graph: Learning Normal Scene Contextual Graphs to Detect Video  Anomalies",
    "abstract": " Comments: Inconsistencies in the results ",
    "url": "https://arxiv.org/abs/2103.10502",
    "authors": [
      "Masoud Pourreza",
      "Mohammadreza Salehi",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.10249",
    "title": "Superpixels and Graph Convolutional Neural Networks for Efficient  Detection of Nutrient Deficiency Stress from Aerial Imagery",
    "abstract": " Title: Superpixels and Graph Convolutional Neural Networks for Efficient  Detection of Nutrient Deficiency Stress from Aerial Imagery ",
    "url": "https://arxiv.org/abs/2104.10249",
    "authors": [
      "Saba Dadsetan",
      "David Pichler",
      "David Wilson",
      "Naira Hovakimyan",
      "Jennifer Hobbs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.11270",
    "title": "Evolutionary game model of group choice dilemmas on hypergraphs",
    "abstract": " Comments: Main text (4 pages, 2 figures) and Supplemental Material (8 pages, 3 figures, 1 table) ",
    "url": "https://arxiv.org/abs/2104.11270",
    "authors": [
      "Andrea Civilini",
      "Nejat Anbarci",
      "Vito Latora"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2105.05516",
    "title": "Object-Based Augmentation Improves Quality of Remote Sensing Semantic  Segmentation",
    "abstract": " Title: Object-Based Augmentation Improves Quality of Remote Sensing Semantic  Segmentation ",
    "url": "https://arxiv.org/abs/2105.05516",
    "authors": [
      "Svetlana Illarionova",
      "Sergey Nesteruk",
      "Dmitrii Shadrin",
      "Vladimir Ignatiev",
      "Mariia Pukalchik",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.05250",
    "title": "The zero-rate threshold for adversarial bit-deletions is less than 1/2",
    "abstract": " Comments: 36 pages ",
    "url": "https://arxiv.org/abs/2106.05250",
    "authors": [
      "Venkatesan Guruswami",
      "Xiaoyu He",
      "Ray Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2107.02168",
    "title": "DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data",
    "abstract": " Title: DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data ",
    "url": "https://arxiv.org/abs/2107.02168",
    "authors": [
      "Dongqi Fu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.05853",
    "title": "Making Auctions Robust to Aftermarkets",
    "abstract": " Title: Making Auctions Robust to Aftermarkets ",
    "url": "https://arxiv.org/abs/2107.05853",
    "authors": [
      "Moshe Babaioff",
      "Nicole Immorlica",
      "Yingkai Li",
      "Brendan Lucier"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2108.01852",
    "title": "Semi-supervised Conditional GAN for Simultaneous Generation and  Detection of Phishing URLs: A Game theoretic Perspective",
    "abstract": " Comments: 5 Pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2108.01852",
    "authors": [
      "Sharif Amit Kamran",
      "Shamik Sengupta",
      "Alireza Tavakkoli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2109.03975",
    "title": "Membership Inference Attacks Against Temporally Correlated Data in Deep  Reinforcement Learning",
    "abstract": " Title: Membership Inference Attacks Against Temporally Correlated Data in Deep  Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2109.03975",
    "authors": [
      "Maziar Gomrokchi",
      "Susan Amin",
      "Hossein Aboutalebi",
      "Alexander Wong",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.07933",
    "title": "Relation Preserving Triplet Mining for Stabilising the Triplet Loss in  Re-identification Systems",
    "abstract": " Comments: WACV 2023 ",
    "url": "https://arxiv.org/abs/2110.07933",
    "authors": [
      "Adhiraj Ghosh",
      "Kuruparan Shanmugalingam",
      "Wen-Yan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.04964",
    "title": "On Representation Knowledge Distillation for Graph Neural Networks",
    "abstract": " Comments: Accepted to IEEE Transactions on Neural Networks and Learning Representation (TNNLS) ",
    "url": "https://arxiv.org/abs/2111.04964",
    "authors": [
      "Chaitanya K. Joshi",
      "Fayao Liu",
      "Xu Xun",
      "Jie Lin",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.08374",
    "title": "Literature-Augmented Clinical Outcome Prediction",
    "abstract": " Comments: Published at Findings of NAACL 2022. Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages. Code available at: this https URL ",
    "url": "https://arxiv.org/abs/2111.08374",
    "authors": [
      "Aakanksha Naik",
      "Sravanthi Parasa",
      "Sergey Feldman",
      "Lucy Lu Wang",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.05856",
    "title": "An Adaptive Bounded-Confidence Model of Opinion Dynamics on Networks",
    "abstract": " Comments: submitted to Journal of Complex Networks; revised version ",
    "url": "https://arxiv.org/abs/2112.05856",
    "authors": [
      "Unchitta Kan",
      "Michelle Feng",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2112.06044",
    "title": "Achieving Low Complexity Neural Decoders via Iterative Pruning",
    "abstract": " Comments: Machine Learning For Systems Workshop at NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2112.06044",
    "authors": [
      "Vikrant Malik",
      "Rohan Ghosh",
      "Mehul Motani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.12052",
    "title": "Improved Overparametrization Bounds for Global Convergence of Stochastic  Gradient Descent for Shallow Neural Networks",
    "abstract": " Title: Improved Overparametrization Bounds for Global Convergence of Stochastic  Gradient Descent for Shallow Neural Networks ",
    "url": "https://arxiv.org/abs/2201.12052",
    "authors": [
      "Bart\u0142omiej Polaczyk",
      "Jacek Cyranka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.00756",
    "title": "Ranging-Based Localizability Optimization for Mobile Robotic Networks",
    "abstract": " Comments: 19 pages, 16 figures, version 2 ",
    "url": "https://arxiv.org/abs/2202.00756",
    "authors": [
      "Justin Cano",
      "Jerome Le Ny"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2202.07178",
    "title": "Federated Learning with Sparsified Model Perturbation: Improving  Accuracy under Client-Level Differential Privacy",
    "abstract": " Title: Federated Learning with Sparsified Model Perturbation: Improving  Accuracy under Client-Level Differential Privacy ",
    "url": "https://arxiv.org/abs/2202.07178",
    "authors": [
      "Rui Hu",
      "Yanmin Gong",
      "Yuanxiong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.09620",
    "title": "Message recovery attack to NTRU using a lattice independent from the  public key",
    "abstract": " Comments: We added some references and some minor improvements ",
    "url": "https://arxiv.org/abs/2203.09620",
    "authors": [
      "Marios Adamoudis",
      "K. A. Draziotis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10989",
    "title": "Hierarchical autoregressive neural networks for statistical systems",
    "abstract": " Comments: 14 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2203.10989",
    "authors": [
      "Piotr Bia\u0142as",
      "Piotr Korcyl",
      "Tomasz Stebel"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.06891",
    "title": "Unsupervised Representation Learning for 3D MRI Super Resolution with  Degradation Adaptation",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2205.06891",
    "authors": [
      "Jianan Liu",
      "Hao Li",
      "Tao Huang",
      "Euijoon Ahn",
      "Kang Han",
      "Adeel Razi",
      "Wei Xiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2206.01175",
    "title": "Robust Longitudinal Control for Vehicular Autonomous Platoons Using Deep  Reinforcement Learning",
    "abstract": " Title: Robust Longitudinal Control for Vehicular Autonomous Platoons Using Deep  Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2206.01175",
    "authors": [
      "Armando Alves Neto",
      "Leonardo Amaral Mozelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01204",
    "title": "Siamese Image Modeling for Self-Supervised Vision Representation  Learning",
    "abstract": " Title: Siamese Image Modeling for Self-Supervised Vision Representation  Learning ",
    "url": "https://arxiv.org/abs/2206.01204",
    "authors": [
      "Chenxin Tao",
      "Xizhou Zhu",
      "Weijie Su",
      "Gao Huang",
      "Bin Li",
      "Jie Zhou",
      "Yu Qiao",
      "Xiaogang Wang",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14486",
    "title": "Beyond neural scaling laws: beating power law scaling via data pruning",
    "abstract": " Comments: Oral @ NeurIPS 2022 (camera ready version) ",
    "url": "https://arxiv.org/abs/2206.14486",
    "authors": [
      "Ben Sorscher",
      "Robert Geirhos",
      "Shashank Shekhar",
      "Surya Ganguli",
      "Ari S. Morcos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.10771",
    "title": "Reticula: A temporal network and hypergraph analysis software package",
    "abstract": " Title: Reticula: A temporal network and hypergraph analysis software package ",
    "url": "https://arxiv.org/abs/2207.10771",
    "authors": [
      "Arash Badie-Modiri",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.01819",
    "title": "Adversarial Camouflage for Node Injection Attack on Graphs",
    "abstract": " Title: Adversarial Camouflage for Node Injection Attack on Graphs ",
    "url": "https://arxiv.org/abs/2208.01819",
    "authors": [
      "Shuchang Tao",
      "Qi Cao",
      "Huawei Shen",
      "Yunfan Wu",
      "Liang Hou",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.14153",
    "title": "Identifying Weight-Variant Latent Causal Models",
    "abstract": " Title: Identifying Weight-Variant Latent Causal Models ",
    "url": "https://arxiv.org/abs/2208.14153",
    "authors": [
      "Yuhang Liu",
      "Zhen Zhang",
      "Dong Gong",
      "Mingming Gong",
      "Biwei Huang",
      "Anton van den Hengel",
      "Kun Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.01814",
    "title": "RLIP: Relational Language-Image Pre-training for Human-Object  Interaction Detection",
    "abstract": " Comments: Accepted to NeurIPS 2022 as a Spotlight paper ",
    "url": "https://arxiv.org/abs/2209.01814",
    "authors": [
      "Hangjie Yuan",
      "Jianwen Jiang",
      "Samuel Albanie",
      "Tao Feng",
      "Ziyuan Huang",
      "Dong Ni",
      "Mingqian Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03102",
    "title": "MSMDFusion: A Gated Multi-Scale LiDAR-Camera Fusion Framework with  Multi-Depth Seeds for 3D Object Detection",
    "abstract": " Title: MSMDFusion: A Gated Multi-Scale LiDAR-Camera Fusion Framework with  Multi-Depth Seeds for 3D Object Detection ",
    "url": "https://arxiv.org/abs/2209.03102",
    "authors": [
      "Yang Jiao",
      "Zequn Jie",
      "Shaoxiang Chen",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03402",
    "title": "Counting Subgraphs in Somewhere Dense Graphs",
    "abstract": " Comments: 35 pages, 3 figures, 4 tables, abstract shortened due to ArXiv requirements ",
    "url": "https://arxiv.org/abs/2209.03402",
    "authors": [
      "Marco Bressan",
      "Leslie Ann Goldberg",
      "Kitty Meeks",
      "Marc Roth"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": " Title: Sketch of a novel approach to a neural model ",
    "url": "https://arxiv.org/abs/2209.06865",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2209.08446",
    "title": "Dual Contrastive Network for Sequential Recommendation with User and  Item-Centric Perspectives",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2209.08446",
    "authors": [
      "Guanyu Lin",
      "Chen Gao",
      "Yinfeng Li",
      "Yu Zheng",
      "Zhiheng Li",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2209.09475",
    "title": "Revisiting Image Pyramid Structure for High Resolution Salient Object  Detection",
    "abstract": " Comments: 27 pages, 15 figures, 7 tables. To appear in the 16th Asian Conference on Computer Vision (ACCV2022), December 4-8, 2022, Macau SAR, China. DOI will be added soon. Results on DIS5K are added in appendices which will not be in the published version ",
    "url": "https://arxiv.org/abs/2209.09475",
    "authors": [
      "Taehun Kim",
      "Kunhee Kim",
      "Joonyeong Lee",
      "Dongmin Cha",
      "Jiho Lee",
      "Daijin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.12573",
    "title": "Digital Audio Forensics: Blind Human Voice Mimicry Detection",
    "abstract": " Comments: 11 pages, 4 figures (6 if you count subfigures), 2 tables ",
    "url": "https://arxiv.org/abs/2209.12573",
    "authors": [
      "Sahar Al Ajmi",
      "Khizar Hayat",
      "Alaa M. Al Obaidi",
      "Naresh Kumar",
      "Munaf Najmuldeen",
      "Baptiste Magnier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.00486",
    "title": "pMPL: A Robust Multi-Party Learning Framework with a Privileged Party",
    "abstract": " Comments: This paper is the full version of a paper to appear in CCS 2022 ",
    "url": "https://arxiv.org/abs/2210.00486",
    "authors": [
      "Lushan Song",
      "Jiaxuan Wang",
      "Zhexuan Wang",
      "Xinyu Tu",
      "Guopeng Lin",
      "Wenqiang Ruan",
      "Haoqi Wu",
      "Weili Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.09958",
    "title": "Layer-wise Relevance Propagation for Echo State Networks applied to  Earth System Variability",
    "abstract": " Comments: Shortened title, corrected author affiliation, added citation reference: Accepted at 3rd International Conference on Machine Learning Techniques (MLTEC 2022), Zurich, Switzerland ",
    "url": "https://arxiv.org/abs/2210.09958",
    "authors": [
      "Marco Landt-Hayen",
      "Peer Kr\u00f6ger",
      "Martin Claus",
      "Willi Rath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13801",
    "title": "Deep Boosting Robustness of DNN-based Image Watermarking via DBMark",
    "abstract": " Title: Deep Boosting Robustness of DNN-based Image Watermarking via DBMark ",
    "url": "https://arxiv.org/abs/2210.13801",
    "authors": [
      "Guanhui Ye",
      "Jiashi Gao",
      "Wei Xie",
      "Bo Yin",
      "Xuetao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14449",
    "title": "Modeling of dendritic solidification and numerical analysis of the  phase-field approach to model complex morphologies in alloys",
    "abstract": " Comments: manuscript under review; 10 figures; 3 tables; updated figure caption and added clarifications to certain section ",
    "url": "https://arxiv.org/abs/2210.14449",
    "authors": [
      "Kunal Bhagat",
      "Shiva Rudraraju"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.17367",
    "title": "Analysis and Detection of Singing Techniques in Repertoires of J-POP  Solo Singers",
    "abstract": " Comments: Accepted at ISMIR 2022, appendix website: this https URL ",
    "url": "https://arxiv.org/abs/2210.17367",
    "authors": [
      "Yuya Yamamoto",
      "Juhan Nam",
      "Hiroko Terasawa"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.01830",
    "title": "Ranking-based Group Identification via Factorized Attention on Social  Tripartite Graph",
    "abstract": " Comments: 9 pages. Accepted by WSDM'23. Github: this https URL ",
    "url": "https://arxiv.org/abs/2211.01830",
    "authors": [
      "Mingdai Yang",
      "Zhiwei Liu",
      "Liangwei Yang",
      "Xiaolong Liu",
      "Chen Wang",
      "Hao Peng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.03037",
    "title": "Knowledge Retrieval using Functional Object-Oriented Network",
    "abstract": " Title: Knowledge Retrieval using Functional Object-Oriented Network ",
    "url": "https://arxiv.org/abs/2211.03037",
    "authors": [
      "Naseem Shaik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.03418",
    "title": "QRF: Implicit Neural Representations with Quantum Radiance Fields",
    "abstract": " Title: QRF: Implicit Neural Representations with Quantum Radiance Fields ",
    "url": "https://arxiv.org/abs/2211.03418",
    "authors": [
      "YuanFu Yang",
      "Min Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05637",
    "title": "Description Graphs, Matrix-Power Stabilizations and Graph Isomorphism in  Polynomial Time",
    "abstract": " Comments: Some examples are supplied as illustrations to the contexts, and a brief suggestion to implementation of SaS process is also given in the appendix ",
    "url": "https://arxiv.org/abs/2211.05637",
    "authors": [
      "Rui Xue"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2211.05913",
    "title": "Twitter Spam and False Accounts Prevalence, Detection and  Characterization: A Survey",
    "abstract": " Comments: Submitted to First Monday ",
    "url": "https://arxiv.org/abs/2211.05913",
    "authors": [
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.06689",
    "title": "TINC: Tree-structured Implicit Neural Compression",
    "abstract": " Title: TINC: Tree-structured Implicit Neural Compression ",
    "url": "https://arxiv.org/abs/2211.06689",
    "authors": [
      "Runzhao Yang",
      "Tingxiong Xiao",
      "Yuxiao Cheng",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.07004",
    "title": "Advancing Learned Video Compression with In-loop Frame Prediction",
    "abstract": " Title: Advancing Learned Video Compression with In-loop Frame Prediction ",
    "url": "https://arxiv.org/abs/2211.07004",
    "authors": [
      "Ren Yang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.07047",
    "title": "Language Model Classifier Aligns Better with Physician Word Sensitivity  than XGBoost on Readmission Prediction",
    "abstract": " Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 13 pages ",
    "url": "https://arxiv.org/abs/2211.07047",
    "authors": [
      "Grace Yang",
      "Ming Cao",
      "Lavender Y. Jiang",
      "Xujin C. Liu",
      "Alexander T.M. Cheung",
      "Hannah Weiss",
      "David Kurland",
      "Kyunghyun Cho",
      "Eric K. Oermann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.07479",
    "title": "Spreading processes with population heterogeneity over multi-layer  networks",
    "abstract": " Comments: Submitted to ICC 2023 ",
    "url": "https://arxiv.org/abs/2211.07479",
    "authors": [
      "Yurun Tian",
      "Osman Yagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.08071",
    "title": "Knowledge Distillation for Detection Transformer with Consistent  Distillation Points Sampling",
    "abstract": " Title: Knowledge Distillation for Detection Transformer with Consistent  Distillation Points Sampling ",
    "url": "https://arxiv.org/abs/2211.08071",
    "authors": [
      "Yu Wang",
      "Xin Li",
      "Shengzhao Wen",
      "Fukui Yang",
      "Wanping Zhang",
      "Gang Zhang",
      "Haocheng Feng",
      "Junyu Han",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08237",
    "title": "Multilingual Speech Emotion Recognition With Multi-Gating Mechanism and  Neural Architecture Search",
    "abstract": " Title: Multilingual Speech Emotion Recognition With Multi-Gating Mechanism and  Neural Architecture Search ",
    "url": "https://arxiv.org/abs/2211.08237",
    "authors": [
      "Zihan Wang",
      "Qi Meng",
      "HaiFeng Lan",
      "XinRui Zhang",
      "KeHao Guo",
      "Akshat Gupta"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  }
]