[
  {
    "id": "arXiv:2211.11751",
    "title": "Robust AUC Optimization under the Supervision of Clean Data",
    "abstract": "AUC (area under the ROC curve) optimization algorithms have drawn much attention due to the incredible adaptability for seriously imbalanced data. Real-world datasets usually contain extensive noisy samples that seriously hinder the model performance, but a limited number of clean samples can be obtained easily. Although some AUC optimization studies make an effort to dispose of noisy samples, they do not utilize such clean samples well. In this paper, we propose a robust AUC optimization algorithm (RAUCO) with good use of available clean samples. Expressly, our RAUCO algorithm can exclude noisy samples from the training by employing the technology of self-paced learning (SPL) under the supervision of clean samples. Moreover, considering the impact of the data enhancement technology on SPL, we innovatively introduce the consistency regularization term to SPL. Theoretical results on the convergence of our RAUCO algorithm are provided under mild assumptions. Comprehensive experiments demonstrate that our RAUCO algorithm holds better robustness than existing algorithms. ",
    "url": "https://arxiv.org/abs/2211.11751",
    "authors": [
      "Chenkang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11752",
    "title": "RHCO: A Relation-aware Heterogeneous Graph Neural Network with  Contrastive Learning for Large-scale Graphs",
    "abstract": "Heterogeneous graph neural networks (HGNNs) have been widely applied in heterogeneous information network tasks, while most HGNNs suffer from poor scalability or weak representation when they are applied to large-scale heterogeneous graphs. To address these problems, we propose a novel Relation-aware Heterogeneous Graph Neural Network with Contrastive Learning (RHCO) for large-scale heterogeneous graph representation learning. Unlike traditional heterogeneous graph neural networks, we adopt the contrastive learning mechanism to deal with the complex heterogeneity of large-scale heterogeneous graphs. We first learn relation-aware node embeddings under the network schema view. Then we propose a novel positive sample selection strategy to choose meaningful positive samples. After learning node embeddings under the positive sample graph view, we perform a cross-view contrastive learning to obtain the final node representations. Moreover, we adopt the label smoothing technique to boost the performance of RHCO. Extensive experiments on three large-scale academic heterogeneous graph datasets show that RHCO achieves best performance over the state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2211.11752",
    "authors": [
      "Ziming Wan",
      "Deqing Wang",
      "Xuehua Ming",
      "Fuzhen Zhuang",
      "Chenguang Du",
      "Ting Jiang",
      "Zhengyang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11758",
    "title": "A Graph Regularized Point Process Model For Event Propagation Sequence",
    "abstract": "Point process is the dominant paradigm for modeling event sequences occurring at irregular intervals. In this paper we aim at modeling latent dynamics of event propagation in graph, where the event sequence propagates in a directed weighted graph whose nodes represent event marks (e.g., event types). Most existing works have only considered encoding sequential event history into event representation and ignored the information from the latent graph structure. Besides they also suffer from poor model explainability, i.e., failing to uncover causal influence across a wide variety of nodes. To address these problems, we propose a Graph Regularized Point Process (GRPP) that can be decomposed into: 1) a graph propagation model that characterizes the event interactions across nodes with neighbors and inductively learns node representations; 2) a temporal attentive intensity model, whose excitation and time decay factors of past events on the current event are constructed via the contextualization of the node embedding. Moreover, by applying a graph regularization method, GRPP provides model interpretability by uncovering influence strengths between nodes. Numerical experiments on various datasets show that GRPP outperforms existing models on both the propagation time and node prediction by notable margins. ",
    "url": "https://arxiv.org/abs/2211.11758",
    "authors": [
      "Siqiao Xue",
      "Xiaoming Shi",
      "Hongyan Hao",
      "Lintao Ma",
      "Shiyu Wang",
      "Shijun Wang",
      "James Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11761",
    "title": "From Node Interaction to Hop Interaction: New Effective and Scalable  Graph Learning Paradigm",
    "abstract": "Existing Graph Neural Networks (GNNs) follow the message-passing mechanism that conducts information interaction among nodes iteratively. While considerable progress has been made, such node interaction paradigms still have the following limitation. First, the scalability limitation precludes the wide application of GNNs in large-scale industrial settings since the node interaction among rapidly expanding neighbors incurs high computation and memory costs. Second, the over-smoothing problem restricts the discrimination ability of nodes, i.e., node representations of different classes will converge to indistinguishable after repeated node interactions. In this work, we propose a novel hop interaction paradigm to address these limitations simultaneously. The core idea of hop interaction is to convert the target of message-passing from nodes into multi-hop features inside each node. Specifically, it first pre-computed multi-hop features of nodes to reduce computation costs during training and inference. Then, it conducts a non-linear interaction among multi-hop features to enhance the discrimination of nodes. We design a simple yet effective HopGNN framework that can easily utilize existing GNNs to achieve hop interaction. Furthermore, we propose a multi-task learning strategy with a self-supervised learning objective to enhance HopGNN. We conduct extensive experiments on 12 benchmark datasets in a wide range of domains, scales, and smoothness of graphs. Experimental results show that our methods achieve superior performance while maintaining high scalability and efficiency. ",
    "url": "https://arxiv.org/abs/2211.11761",
    "authors": [
      "Jie Chen",
      "Zilong Li",
      "Yin Zhu",
      "Junping Zhang",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11762",
    "title": "Hierarchical Graph Structures for Congestion and ETA Prediction",
    "abstract": "Traffic4cast is an annual competition to predict spatio temporal traffic based on real world data. We propose an approach using Graph Neural Networks that directly works on the road graph topology which was extracted from OpenStreetMap data. Our architecture can incorporate a hierarchical graph representation to improve the information flow between key intersections of the graph and the shortest paths connecting them. Furthermore, we investigate how the road graph can be compacted to ease the flow of information and make use of a multi-task approach to predict congestion classes and ETA simultaneously. Our code and models are released here: https://github.com/floriangroetschla/NeurIPS2022-traffic4cast ",
    "url": "https://arxiv.org/abs/2211.11762",
    "authors": [
      "Florian Gr\u00f6tschla",
      "Jo\u00ebl Mathys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11763",
    "title": "DS-GPS : A Deep Statistical Graph Poisson Solver (for faster CFD  simulations)",
    "abstract": "This paper proposes a novel Machine Learning-based approach to solve a Poisson problem with mixed boundary conditions. Leveraging Graph Neural Networks, we develop a model able to process unstructured grids with the advantage of enforcing boundary conditions by design. By directly minimizing the residual of the Poisson equation, the model attempts to learn the physics of the problem without the need for exact solutions, in contrast to most previous data-driven processes where the distance with the available solutions is minimized. ",
    "url": "https://arxiv.org/abs/2211.11763",
    "authors": [
      "Matthieu Nastorg",
      "Marc Schoenauer",
      "Guillaume Charpiat",
      "Thibault Faney",
      "Jean-Marc Gratien",
      "Michele-Alessandro Bucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.11801",
    "title": "Self-Supervised Pre-training of 3D Point Cloud Networks with Image Data",
    "abstract": "Reducing the quantity of annotations required for supervised training is vital when labels are scarce and costly. This reduction is especially important for semantic segmentation tasks involving 3D datasets that are often significantly smaller and more challenging to annotate than their image-based counterparts. Self-supervised pre-training on large unlabelled datasets is one way to reduce the amount of manual annotations needed. Previous work has focused on pre-training with point cloud data exclusively; this approach often requires two or more registered views. In the present work, we combine image and point cloud modalities, by first learning self-supervised image features and then using these features to train a 3D model. By incorporating image data, which is often included in many 3D datasets, our pre-training method only requires a single scan of a scene. We demonstrate that our pre-training approach, despite using single scans, achieves comparable performance to other multi-scan, point cloud-only methods. ",
    "url": "https://arxiv.org/abs/2211.11801",
    "authors": [
      "Andrej Janda",
      "Brandon Wagstaff",
      "Edwin G. Ng",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11812",
    "title": "RIC-CNN: Rotation-Invariant Coordinate Convolutional Neural Network",
    "abstract": "In recent years, convolutional neural network has shown good performance in many image processing and computer vision tasks. However, a standard CNN model is not invariant to image rotations. In fact, even slight rotation of an input image will seriously degrade its performance. This shortcoming precludes the use of CNN in some practical scenarios. Thus, in this paper, we focus on designing convolutional layer with good rotation invariance. Specifically, based on a simple rotation-invariant coordinate system, we propose a new convolutional operation, called Rotation-Invariant Coordinate Convolution (RIC-C). Without additional trainable parameters and data augmentation, RIC-C is naturally invariant to arbitrary rotations around the input center. Furthermore, we find the connection between RIC-C and deformable convolution, and propose a simple but efficient approach to implement RIC-C using Pytorch. By replacing all standard convolutional layers in a CNN with the corresponding RIC-C, a RIC-CNN can be derived. Using MNIST dataset, we first evaluate the rotation invariance of RIC-CNN and compare its performance with most of existing rotation-invariant CNN models. It can be observed that RIC-CNN achieves the state-of-the-art classification on the rotated test dataset of MNIST. Then, we deploy RIC-C to VGG, ResNet and DenseNet, and conduct the classification experiments on two real image datasets. Also, a shallow CNN and the corresponding RIC-CNN are trained to extract image patch descriptors, and we compare their performance in patch verification. These experimental results again show that RIC-C can be easily used as drop in replacement for standard convolutions, and greatly enhances the rotation invariance of CNN models designed for different applications. ",
    "url": "https://arxiv.org/abs/2211.11812",
    "authors": [
      "Hanlin Mo",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11817",
    "title": "High-Quality Fault-Resiliency in Fat-Tree Networks (Extended Abstract)",
    "abstract": "Coupling regular topologies with optimized routing algorithms is key in pushing the performance of interconnection networks of HPC systems. In this paper we present Dmodc, a fast deterministic routing algorithm for Parallel Generalized Fat-Trees (PGFTs) which minimizes congestion risk even under massive topology degradation caused by equipment failure. It applies a modulo-based computation of forwarding tables among switches closer to the destination, using only knowledge of subtrees for pre-modulo division. Dmodc allows complete rerouting of topologies with tens of thousands of nodes in less than a second, which greatly helps centralized fabric management react to faults with high-quality routing tables and no impact to running applications in current and future very large-scale HPC clusters. We compare Dmodc against routing algorithms available in the InfiniBand control software (OpenSM) first for routing execution time to show feasibility at scale, and then for congestion risk under degradation to demonstrate robustness. The latter comparison is done using static analysis of routing tables under random permutation (RP), shift permutation (SP) and all-to-all (A2A) traffic patterns. Results for Dmodc show A2A and RP congestion risks similar under heavy degradation as the most stable algorithms compared, and near-optimal SP congestion risk up to 1% of random degradation. ",
    "url": "https://arxiv.org/abs/2211.11817",
    "authors": [
      "John Gliksberg",
      "Antoine Capra",
      "Alexandre Louvet",
      "Pedro Javier Garcia",
      "Devan Sohier"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.11835",
    "title": "Fairness Increases Adversarial Vulnerability",
    "abstract": "The remarkable performance of deep learning models and their applications in consequential domains (e.g., facial recognition) introduces important challenges at the intersection of equity and security. Fairness and robustness are two desired notions often required in learning models. Fairness ensures that models do not disproportionately harm (or benefit) some groups over others, while robustness measures the models' resilience against small input perturbations. This paper shows the existence of a dichotomy between fairness and robustness, and analyzes when achieving fairness decreases the model robustness to adversarial samples. The reported analysis sheds light on the factors causing such contrasting behavior, suggesting that distance to the decision boundary across groups as a key explainer for this behavior. Extensive experiments on non-linear models and different architectures validate the theoretical findings in multiple vision domains. Finally, the paper proposes a simple, yet effective, solution to construct models achieving good tradeoffs between fairness and robustness. ",
    "url": "https://arxiv.org/abs/2211.11835",
    "authors": [
      "Cuong Tran",
      "Keyu Zhu",
      "Ferdinando Fioretto",
      "Pascal Van Henternyck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.11853",
    "title": "Learnable Graph Convolutional Attention Networks",
    "abstract": "Existing Graph Neural Networks (GNNs) compute the message exchange between nodes by either aggregating uniformly (convolving) the features of all the neighboring nodes, or by applying a non-uniform score (attending) to the features. Recent works have shown the strengths and weaknesses of the resulting GNN architectures, respectively, GCNs and GATs. In this work, we aim at exploiting the strengths of both approaches to their full extent. To this end, we first introduce the graph convolutional attention layer (CAT), which relies on convolutions to compute the attention scores. Unfortunately, as in the case of GCNs and GATs, we show that there exists no clear winner between the three (neither theoretically nor in practice) as their performance directly depends on the nature of the data (i.e., of the graph and features). This result brings us to the main contribution of our work, the learnable graph convolutional attention network (L-CAT): a GNN architecture that automatically interpolates between GCN, GAT and CAT in each layer, by adding only two scalar parameters. Our results demonstrate that L-CAT is able to efficiently combine different GNN layers along the network, outperforming competing methods in a wide range of datasets, and resulting in a more robust model that reduces the need of cross-validating. ",
    "url": "https://arxiv.org/abs/2211.11853",
    "authors": [
      "Adri\u00e1n Javaloy",
      "Pablo Sanchez-Martin",
      "Amit Levi",
      "Isabel Valera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11880",
    "title": "Addressing Mistake Severity in Neural Networks with Semantic Knowledge",
    "abstract": "Robustness in deep neural networks and machine learning algorithms in general is an open research challenge. In particular, it is difficult to ensure algorithmic performance is maintained on out-of-distribution inputs or anomalous instances that cannot be anticipated at training time. Embodied agents will be deployed in these conditions, and are likely to make incorrect predictions. An agent will be viewed as untrustworthy unless it can maintain its performance in dynamic environments. Most robust training techniques aim to improve model accuracy on perturbed inputs; as an alternate form of robustness, we aim to reduce the severity of mistakes made by neural networks in challenging conditions. We leverage current adversarial training methods to generate targeted adversarial attacks during the training process in order to increase the semantic similarity between a model's predictions and true labels of misclassified instances. Results demonstrate that our approach performs better with respect to mistake severity compared to standard and adversarially trained models. We also find an intriguing role that non-robust features play with regards to semantic similarity. ",
    "url": "https://arxiv.org/abs/2211.11880",
    "authors": [
      "Natalie Abreu",
      "Nathan Vaska",
      "Victoria Helus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11907",
    "title": "Robust Faber--Schauder approximation based on discrete observations of  an antiderivative",
    "abstract": "We study the problem of reconstructing the Faber--Schauder coefficients of a continuous function $f$ from discrete observations of its antiderivative $F$. Our approach starts with formulating this problem through piecewise quadratic spline interpolation. We then provide a closed-form solution and an in-depth error analysis. These results lead to some surprising observations, which also throw new light on the classical topic of quadratic spline interpolation itself: They show that the well-known instabilities of this method can be located exclusively within the final generation of estimated Faber--Schauder coefficients, which suffer from non-locality and strong dependence on the initial value and the given data. By contrast, all other Faber--Schauder coefficients depend only locally on the data, are independent of the initial value, and admit uniform error bounds. We thus conclude that a robust and well-behaved estimator for our problem can be obtained by simply dropping the final-generation coefficients from the estimated Faber--Schauder coefficients. ",
    "url": "https://arxiv.org/abs/2211.11907",
    "authors": [
      "Xiyue Han",
      "Alexander Schied"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2211.11912",
    "title": "Quasi-stable Coloring for Graph Compression: Approximating Max-Flow,  Linear Programs, and Centrality",
    "abstract": "We propose quasi-stable coloring, an approximate version of stable coloring. Stable coloring, also called color refinement, is a well-studied technique in graph theory for classifying vertices, which can be used to build compact, lossless representations of graphs. However, its usefulness is limited due to its reliance on strict symmetries. Real data compresses very poorly using color refinement. We propose the first, to our knowledge, approximate color refinement scheme, which we call quasi-stable coloring. By using approximation, we alleviate the need for strict symmetry, and allow for a tradeoff between the degree of compression and the accuracy of the representation. We study three applications: Linear Programming, Max-Flow, and Betweenness Centrality, and provide theoretical evidence in each case that a quasi-stable coloring can lead to good approximations on the reduced graph. Next, we consider how to compute a maximal quasi-stable coloring: we prove that, in general, this problem is NP-hard, and propose a simple, yet effective algorithm based on heuristics. Finally, we evaluate experimentally the quasi-stable coloring technique on several real graphs and applications, comparing with prior approximation techniques. A reference implementation and the experiment code are available at https://github.com/mkyl/QuasiStableColors.jl ",
    "url": "https://arxiv.org/abs/2211.11912",
    "authors": [
      "Moe Kayali",
      "Dan Suciu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.11924",
    "title": "Best-$k$ Search Algorithm for Neural Text Generation",
    "abstract": "Modern natural language generation paradigms require a good decoding strategy to obtain quality sequences out of the model. Beam search yields high-quality but low diversity outputs; stochastic approaches suffer from high variance and sometimes low quality, but the outputs tend to be more natural and creative. In this work, we propose a deterministic search algorithm balancing both quality and diversity. We first investigate the vanilla best-first search (BFS) algorithm and then propose the Best-$k$ Search algorithm. Inspired by BFS, we greedily expand the top $k$ nodes, instead of only the first node, to boost efficiency and diversity. Upweighting recently discovered nodes accompanied by heap pruning ensures the completeness of the search procedure. Experiments on four NLG tasks, including question generation, commonsense generation, text summarization, and translation, show that best-$k$ search yields more diverse and natural outputs compared to strong baselines, while our approach maintains high text quality. The proposed algorithm is parameter-free, lightweight, efficient, and easy to use. ",
    "url": "https://arxiv.org/abs/2211.11924",
    "authors": [
      "Jiacheng Xu",
      "Caiming Xiong",
      "Silvio Savarese",
      "Yingbo Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.11925",
    "title": "Multimodal Data Augmentation for Visual-Infrared Person ReID with  Corrupted Data",
    "abstract": "The re-identification (ReID) of individuals over a complex network of cameras is a challenging task, especially under real-world surveillance conditions. Several deep learning models have been proposed for visible-infrared (V-I) person ReID to recognize individuals from images captured using RGB and IR cameras. However, performance may decline considerably if RGB and IR images captured at test time are corrupted (e.g., noise, blur, and weather conditions). Although various data augmentation (DA) methods have been explored to improve the generalization capacity, these are not adapted for V-I person ReID. In this paper, a specialized DA strategy is proposed to address this multimodal setting. Given both the V and I modalities, this strategy allows to diminish the impact of corruption on the accuracy of deep person ReID models. Corruption may be modality-specific, and an additional modality often provides complementary information. Our multimodal DA strategy is designed specifically to encourage modality collaboration and reinforce generalization capability. For instance, punctual masking of modalities forces the model to select the informative modality. Local DA is also explored for advanced selection of features within and among modalities. The impact of training baseline fusion models for V-I person ReID using the proposed multimodal DA strategy is assessed on corrupted versions of the SYSU-MM01, RegDB, and ThermalWORLD datasets in terms of complexity and efficiency. Results indicate that using our strategy provides V-I ReID models the ability to exploit both shared and individual modality knowledge so they can outperform models trained with no or unimodal DA. GitHub code: https://github.com/art2611/ML-MDA. ",
    "url": "https://arxiv.org/abs/2211.11925",
    "authors": [
      "Arthur Josi",
      "Mahdi Alehdaghi",
      "Rafael M. O. Cruz",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11944",
    "title": "COVID-Net Assistant: A Deep Learning-Driven Virtual Assistant for  COVID-19 Symptom Prediction and Recommendation",
    "abstract": "As the COVID-19 pandemic continues to put a significant burden on healthcare systems worldwide, there has been growing interest in finding inexpensive symptom pre-screening and recommendation methods to assist in efficiently using available medical resources such as PCR tests. In this study, we introduce the design of COVID-Net Assistant, an efficient virtual assistant designed to provide symptom prediction and recommendations for COVID-19 by analyzing users' cough recordings through deep convolutional neural networks. We explore a variety of highly customized, lightweight convolutional neural network architectures generated via machine-driven design exploration (which we refer to as COVID-Net Assistant neural networks) on the Covid19-Cough benchmark dataset. The Covid19-Cough dataset comprises 682 cough recordings from a COVID-19 positive cohort and 642 from a COVID-19 negative cohort. Among the 682 cough recordings labeled positive, 382 recordings were verified by PCR test. Our experimental results show promising, with the COVID-Net Assistant neural networks demonstrating robust predictive performance, achieving AUC scores of over 0.93, with the best score over 0.95 while being fast and efficient in inference. The COVID-Net Assistant models are made available in an open source manner through the COVID-Net open initiative and, while not a production-ready solution, we hope their availability acts as a good resource for clinical scientists, machine learning researchers, as well as citizen scientists to develop innovative solutions. ",
    "url": "https://arxiv.org/abs/2211.11944",
    "authors": [
      "Pengyuan Shi",
      "Yuetong Wang",
      "Saad Abbasi",
      "Alexander Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.11949",
    "title": "A Reinforcement Learning Approach to Optimize Available Network  Bandwidth Utilization",
    "abstract": "Efficient data transfers over high-speed, long-distance shared networks require proper utilization of available network bandwidth. Using parallel TCP streams enables an application to utilize network parallelism and can improve transfer throughput; however, finding the optimum number of parallel TCP streams is challenging due to nondeterministic background traffic sharing the same network. Additionally, the non-stationary, multi-objectiveness, and partially-observable nature of network signals in the host systems add extra complexity in finding the current network condition. In this work, we present a novel approach to finding the optimum number of parallel TCP streams using deep reinforcement learning (RL). We devise a learning-based algorithm capable of generalizing different network conditions and utilizing the available network bandwidth intelligently. Contrary to rule-based heuristics that do not generalize well in unknown network scenarios, our RL-based solution can dynamically discover and adapt the parallel TCP stream numbers to maximize the network bandwidth utilization without congesting the network and ensure fairness among contending transfers. We extensively evaluated our RL-based algorithm's performance, comparing it with several state-of-the-art online optimization algorithms. The results show that our RL-based algorithm can find near-optimal solutions 40% faster while achieving up to 15% higher throughput. We also show that, unlike a greedy algorithm, our devised RL-based algorithm can avoid network congestion and fairly share the available network resources among contending transfers. ",
    "url": "https://arxiv.org/abs/2211.11949",
    "authors": [
      "Hasibul Jamil",
      "Elvis Rodrigues",
      "Jacob Goldverg",
      "Tevfik Kosar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2211.11950",
    "title": "UpCycling: Semi-supervised 3D Object Detection without Sharing Raw-level  Unlabeled Scenes",
    "abstract": "Semi-supervised Learning (SSL) has received increasing attention in autonomous driving to relieve enormous burden for 3D annotation. In this paper, we propose UpCycling, a novel SSL framework for 3D object detection with zero additional raw-level point cloud: learning from unlabeled de-identified intermediate features (i.e., smashed data) for privacy preservation. The intermediate features do not require additional computation on autonomous vehicles since they are naturally produced by the inference pipeline. However, augmenting 3D scenes at a feature level turns out to be a critical issue: applying the augmentation methods in the latest semi-supervised 3D object detectors distorts intermediate features, which causes the pseudo-labels to suffer from significant noise. To solve the distortion problem while achieving highly effective SSL, we introduce hybrid pseudo labels, feature-level Ground Truth sampling (F-GT) and Rotation (F-RoT), which safely augment unlabeled multi-type 3D scene features and provide high-quality supervision. We implement UpCycling on two representative 3D object detection models, SECOND-IoU and PV-RCNN, and perform experiments on widely-used datasets (Waymo, KITTI, and Lyft). While preserving privacy with zero raw-point scene, UpCycling significantly outperforms the state-of-the-art SSL methods that utilize raw-point scenes, in both domain adaptation and partial-label scenarios. ",
    "url": "https://arxiv.org/abs/2211.11950",
    "authors": [
      "Sunwook Hwang",
      "Youngseok Kim",
      "Seongwon Kim",
      "Saewoong Bahk",
      "Hyung-Sin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11958",
    "title": "A Survey on Backdoor Attack and Defense in Natural Language Processing",
    "abstract": "Deep learning is becoming increasingly popular in real-life applications, especially in natural language processing (NLP). Users often choose training outsourcing or adopt third-party data and models due to data and computation resources being limited. In such a situation, training data and models are exposed to the public. As a result, attackers can manipulate the training process to inject some triggers into the model, which is called backdoor attack. Backdoor attack is quite stealthy and difficult to be detected because it has little inferior influence on the model's performance for the clean samples. To get a precise grasp and understanding of this problem, in this paper, we conduct a comprehensive review of backdoor attacks and defenses in the field of NLP. Besides, we summarize benchmark datasets and point out the open issues to design credible systems to defend against backdoor attacks. ",
    "url": "https://arxiv.org/abs/2211.11958",
    "authors": [
      "Xuan Sheng",
      "Zhaoyang Han",
      "Piji Li",
      "Xiangmao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.11960",
    "title": "Disentangled Feature Learning for Real-Time Neural Speech Coding",
    "abstract": "Recently end-to-end neural audio/speech coding has shown its great potential to outperform traditional signal analysis based audio codecs. This is mostly achieved by following the VQ-VAE paradigm where blind features are learned, vector-quantized and coded. In this paper, instead of blind end-to-end learning, we propose to learn disentangled features for real-time neural speech coding. Specifically, more global-like speaker identity and local content features are learned with disentanglement to represent speech. Such a compact feature decomposition not only achieves better coding efficiency by exploiting bit allocation among different features but also provides the flexibility to do audio editing in embedding space, such as voice conversion in real-time communications. Both subjective and objective results demonstrate its coding efficiency and we find that the learned disentangled features show comparable performance on any-to-any voice conversion with modern self-supervised speech representation learning models with far less parameters and low latency, showing the potential of our neural coding framework. ",
    "url": "https://arxiv.org/abs/2211.11960",
    "authors": [
      "Xue Jiang",
      "Xiulian Peng",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.11962",
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "abstract": "3D object detection received increasing attention in autonomous driving recently. Objects in 3D scenes are distributed with diverse orientations. Ordinary detectors do not explicitly model the variations of rotation and reflection transformations. Consequently, large networks and extensive data augmentation are required for robust detection. Recent equivariant networks explicitly model the transformation variations by applying shared networks on multiple transformed point clouds, showing great potential in object geometry modeling. However, it is difficult to apply such networks to 3D object detection in autonomous driving due to its large computation cost and slow reasoning speed. In this work, we present TED, an efficient Transformation-Equivariant 3D Detector to overcome the computation cost and speed issues. TED first applies a sparse convolution backbone to extract multi-channel transformation-equivariant voxel features; and then aligns and aggregates these equivariant features into lightweight and compact representations for high-performance 3D object detection. On the highly competitive KITTI 3D car detection leaderboard, TED ranked 1st among all submissions with competitive efficiency. ",
    "url": "https://arxiv.org/abs/2211.11962",
    "authors": [
      "Hai Wu",
      "Chenglu Wen",
      "Wei Li",
      "Xin Li",
      "Ruigang Yang",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11963",
    "title": "Learning-based social coordination to improve safety and robustness of  cooperative autonomous vehicles in mixed traffic",
    "abstract": "It is expected that autonomous vehicles(AVs) and heterogeneous human-driven vehicles(HVs) will coexist on the same road. The safety and reliability of AVs will depend on their social awareness and their ability to engage in complex social interactions in a socially accepted manner. However, AVs are still inefficient in terms of cooperating with HVs and struggle to understand and adapt to human behavior, which is particularly challenging in mixed autonomy. In a road shared by AVs and HVs, the social preferences or individual traits of HVs are unknown to the AVs and different from AVs, which are expected to follow a policy, HVs are particularly difficult to forecast since they do not necessarily follow a stationary policy. To address these challenges, we frame the mixed-autonomy problem as a multi-agent reinforcement learning (MARL) problem and propose an approach that allows AVs to learn the decision-making of HVs implicitly from experience, account for all vehicles' interests, and safely adapt to other traffic situations. In contrast with existing works, we quantify AVs' social preferences and propose a distributed reward structure that introduces altruism into their decision-making process, allowing the altruistic AVs to learn to establish coalitions and influence the behavior of HVs. ",
    "url": "https://arxiv.org/abs/2211.11963",
    "authors": [
      "Rodolfo Valiente",
      "Behrad Toghi",
      "Mahdi Razzaghpour",
      "Ramtin Pedarsani",
      "Yaser P. Fallah"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11971",
    "title": "Multi-View Neural Surface Reconstruction with Structured Light",
    "abstract": "Three-dimensional (3D) object reconstruction based on differentiable rendering (DR) is an active research topic in computer vision. DR-based methods minimize the difference between the rendered and target images by optimizing both the shape and appearance and realizing a high visual reproductivity. However, most approaches perform poorly for textureless objects because of the geometrical ambiguity, which means that multiple shapes can have the same rendered result in such objects. To overcome this problem, we introduce active sensing with structured light (SL) into multi-view 3D object reconstruction based on DR to learn the unknown geometry and appearance of arbitrary scenes and camera poses. More specifically, our framework leverages the correspondences between pixels in different views calculated by structured light as an additional constraint in the DR-based optimization of implicit surface, color representations, and camera poses. Because camera poses can be optimized simultaneously, our method realizes high reconstruction accuracy in the textureless region and reduces efforts for camera pose calibration, which is required for conventional SL-based methods. Experiment results on both synthetic and real data demonstrate that our system outperforms conventional DR- and SL-based methods in a high-quality surface reconstruction, particularly for challenging objects with textureless or shiny surfaces. ",
    "url": "https://arxiv.org/abs/2211.11971",
    "authors": [
      "Chunyu Li",
      "Taisuke Hashimoto",
      "Eiichi Matsumoto",
      "Hiroharu Kato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11975",
    "title": "Pred&Guide: Labeled Target Class Prediction for Guiding Semi-Supervised  Domain Adaptation",
    "abstract": "Semi-supervised domain adaptation aims to classify data belonging to a target domain by utilizing a related label-rich source domain and very few labeled examples of the target domain. Here, we propose a novel framework, Pred&Guide, which leverages the inconsistency between the predicted and the actual class labels of the few labeled target examples to effectively guide the domain adaptation in a semi-supervised setting. Pred&Guide consists of three stages, as follows (1) First, in order to treat all the target samples equally, we perform unsupervised domain adaptation coupled with self-training; (2) Second is the label prediction stage, where the current model is used to predict the labels of the few labeled target examples, and (3) Finally, the correctness of the label predictions are used to effectively weigh source examples class-wise to better guide the domain adaptation process. Extensive experiments show that the proposed Pred&Guide framework achieves state-of-the-art results for two large-scale benchmark datasets, namely Office-Home and DomainNet. ",
    "url": "https://arxiv.org/abs/2211.11975",
    "authors": [
      "Megh Manoj Bhalerao",
      "Anurag Singh",
      "Soma Biswas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11977",
    "title": "SemanticLoop: loop closure with 3D semantic graph matching",
    "abstract": "Loop closure can effectively correct the accumulated error in robot localization, which plays a critical role in the long-term navigation of the robot. Traditional appearance-based methods rely on local features and are prone to failure in ambiguous environments. On the other hand, object recognition can infer objects' category, pose, and extent. These objects can serve as stable semantic landmarks for viewpoint-independent and non-ambiguous loop closure. However, there is a critical object-level data association problem due to the lack of efficient and robust algorithms. We introduce a novel object-level data association algorithm, which incorporates IoU, instance-level embedding, and detection uncertainty, formulated as a linear assignment problem. Then, we model the objects as TSDF volumes and represent the environment as a 3D graph with semantics and topology. Next, we propose a graph matching-based loop detection based on the reconstructed 3D semantic graphs and correct the accumulated error by aligning the matched objects. Finally, we refine the object poses and camera trajectory in an object-level pose graph optimization. Experimental results show that the proposed object-level data association method significantly outperforms the commonly used nearest-neighbor method in accuracy. Our graph matching-based loop closure is more robust to environmental appearance changes than existing appearance-based methods. ",
    "url": "https://arxiv.org/abs/2211.11977",
    "authors": [
      "Junfeng Yu",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11978",
    "title": "A Bioinspired Bidirectional Stiffening Soft Actuator for Multimodal,  Compliant, and Robust Grasping",
    "abstract": "The stiffness modulation mechanism for soft robotics has gained considerable attention to improve deformability, controllability, and stability. However, for the existing stiffness soft actuator, high lateral stiffness and a wide range of bending stiffness are hard to be provided at the same time. This paper presents a bioinspired bidirectional stiffening soft actuator (BISA) combining the air-tendon hybrid actuation (ATA) and a bone-like structure (BLS). The ATA is the main actuation of the BISA, and the bending stiffness can be modulated with a maximum stiffness of about 0.7 N/mm and a maximum magnification of 3 times when the bending angle is 45 deg. Inspired by the morphological structure of the phalanx, the lateral stiffness can be modulated by changing the pulling force of the BLS. The lateral stiffness can be modulated by changing the pulling force to it. The actuator with BLSs can improve the lateral stiffness about 3.9 times compared to the one without BLSs. The maximum lateral stiffness can reach 0.46 N/mm. And the lateral stiffness can be modulated decoupling about 1.3 times (e.g., from 0.35 N/mm to 0.46 when the bending angle is 45 deg). The test results show the influence of the rigid structures on bending is small with about 1.5 mm maximum position errors of the distal point of actuator bending in different pulling forces. The advantages brought by the proposed method enable a soft four-finger gripper to operate in three modes: normal grasping, inverse grasping, and horizontal lifting. The performance of this gripper is further characterized and versatile grasping on various objects is conducted, proving the robust performance and potential application of the proposed design method. ",
    "url": "https://arxiv.org/abs/2211.11978",
    "authors": [
      "Jianfeng Lin",
      "Ruikang Xiao",
      "Miao Li",
      "Xiaohui Xiao",
      "Zhao Guo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11979",
    "title": "Learnable Spectral Wavelets on Dynamic Graphs to Capture Global  Interactions",
    "abstract": "Learning on evolving(dynamic) graphs has caught the attention of researchers as static methods exhibit limited performance in this setting. The existing methods for dynamic graphs learn spatial features by local neighborhood aggregation, which essentially only captures the low pass signals and local interactions. In this work, we go beyond current approaches to incorporate global features for effectively learning representations of a dynamically evolving graph. We propose to do so by capturing the spectrum of the dynamic graph. Since static methods to learn the graph spectrum would not consider the history of the evolution of the spectrum as the graph evolves with time, we propose a novel approach to learn the graph wavelets to capture this evolving spectra. Further, we propose a framework that integrates the dynamically captured spectra in the form of these learnable wavelets into spatial features for incorporating local and global interactions. Experiments on eight standard datasets show that our method significantly outperforms related methods on various tasks for dynamic graphs. ",
    "url": "https://arxiv.org/abs/2211.11979",
    "authors": [
      "Anson Bastos",
      "Abhishek Nadgeri",
      "Kuldeep Singh",
      "Toyotaro Suzumura",
      "Manish Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11981",
    "title": "Bayesian Inversion with Neural Operator (BINO) for Modeling  Subdiffusion: Forward and Inverse Problems",
    "abstract": "Fractional diffusion equations have been an effective tool for modeling anomalous diffusion in complicated systems. However, traditional numerical methods require expensive computation cost and storage resources because of the memory effect brought by the convolution integral of time fractional derivative. We propose a Bayesian Inversion with Neural Operator (BINO) to overcome the difficulty in traditional methods as follows. We employ a deep operator network to learn the solution operators for the fractional diffusion equations, allowing us to swiftly and precisely solve a forward problem for given inputs (including fractional order, diffusion coefficient, source terms, etc.). In addition, we integrate the deep operator network with a Bayesian inversion method for modelling a problem by subdiffusion process and solving inverse subdiffusion problems, which reduces the time costs (without suffering from overwhelm storage resources) significantly. A large number of numerical experiments demonstrate that the operator learning method proposed in this work can efficiently solve the forward problems and Bayesian inverse problems of the subdiffusion equation. ",
    "url": "https://arxiv.org/abs/2211.11981",
    "authors": [
      "Xiong-bin Yan",
      "Zhi-Qin John Xu",
      "Zheng Ma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11997",
    "title": "REFINE: Reachability-based Trajectory Design using Robust Feedback  Linearization and Zonotopes",
    "abstract": "Performing real-time receding horizon motion planning for autonomous vehicles while providing safety guarantees remains difficult. This is because existing methods to accurately predict ego vehicle behavior under a chosen controller use online numerical integration that requires a fine time discretization and thereby adversely affects real-time performance. To address this limitation, several recent papers have proposed to apply offline reachability analysis to conservatively predict the behavior of the ego vehicle. This reachable set can be constructed by utilizing a simplified model whose behavior is assumed a priori to conservatively bound the dynamics of a full-order model. However, guaranteeing that one satisfies this assumption is challenging. This paper proposes a framework named REFINE to overcome the limitations of these existing approaches. REFINE utilizes a parameterized robust controller that partially linearizes the vehicle dynamics even in the presence of modeling error. Zonotope-based reachability analysis is then performed on the closed-loop, full-order vehicle dynamics to compute the corresponding control-parameterized, over-approximate Forward Reachable Sets (FRS). Because reachability analysis is applied to the full-order model, the potential conservativeness introduced by using a simplified model is avoided. The pre-computed, control-parameterized FRS is then used online in an optimization framework to ensure safety. The proposed method is compared to several state of the art methods during a simulation-based evaluation on a full-size vehicle model and is evaluated on a 1/10th race car robot in real hardware testing. In contrast to existing methods, REFINE is shown to enable the vehicle to safely navigate itself through complex environments. ",
    "url": "https://arxiv.org/abs/2211.11997",
    "authors": [
      "Jinsun Liu",
      "Yifei Shao",
      "Lucas Lymburner",
      "Hansen Qin",
      "Vishrut Kaushik",
      "Lena Trang",
      "Ruiyang Wang",
      "Vladimir Ivanovic",
      "H. Eric Tseng",
      "Ram Vasudevan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.12006",
    "title": "Differentiable Fuzzy $\\mathcal{ALC}$: A Neural-Symbolic Representation  Language for Symbol Grounding",
    "abstract": "Neural-symbolic computing aims at integrating robust neural learning and sound symbolic reasoning into a single framework, so as to leverage the complementary strengths of both of these, seemingly unrelated (maybe even contradictory) AI paradigms. The central challenge in neural-symbolic computing is to unify the formulation of neural learning and symbolic reasoning into a single framework with common semantics, that is, to seek a joint representation between a neural model and a logical theory that can support the basic grounding learned by the neural model and also stick to the semantics of the logical theory. In this paper, we propose differentiable fuzzy $\\mathcal{ALC}$ (DF-$\\mathcal{ALC}$) for this role, as a neural-symbolic representation language with the desired semantics. DF-$\\mathcal{ALC}$ unifies the description logic $\\mathcal{ALC}$ and neural models for symbol grounding; in particular, it infuses an $\\mathcal{ALC}$ knowledge base into neural models through differentiable concept and role embeddings. We define a hierarchical loss to the constraint that the grounding learned by neural models must be semantically consistent with $\\mathcal{ALC}$ knowledge bases. And we find that capturing the semantics in grounding solely by maximizing satisfiability cannot revise grounding rationally. We further define a rule-based loss for DF adapting to symbol grounding problems. The experiment results show that DF-$\\mathcal{ALC}$ with rule-based loss can improve the performance of image object detectors in an unsupervised learning way, even in low-resource situations. ",
    "url": "https://arxiv.org/abs/2211.12006",
    "authors": [
      "Xuan Wu",
      "Xinhao Zhu",
      "Yizheng Zhao",
      "Xinyu Dai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12018",
    "title": "Level-S$^2$fM: Structure from Motion on Neural Level Set of Implicit  Surfaces",
    "abstract": "This paper presents a neural incremental Structure-from-Motion (SfM) approach, Level-S$^2$fM. In our formulation, we aim at simultaneously learning coordinate MLPs for the implicit surfaces and the radiance fields, and estimating the camera poses and scene geometry, which is mainly sourced from the established keypoint correspondences by SIFT. Our formulation would face some new challenges due to inevitable two-view and few-view configurations at the beginning of incremental SfM pipeline for the optimization of coordinate MLPs, but we found that the strong inductive biases conveying in the 2D correspondences are feasible and promising to avoid those challenges by exploiting the relationship between the ray sampling schemes used in volumetric rendering and the sphere tracing of finding the zero-level set of implicit surfaces. Based on this, we revisit the pipeline of incremental SfM and renew the key components of two-view geometry initialization, the camera pose registration, and the 3D points triangulation, as well as the Bundle Adjustment in a novel perspective of neural implicit surfaces. Because the coordinate MLPs unified the scene geometry in small MLP networks, our Level-S$^2$fM treats the zero-level set of the implicit surface as an informative top-down regularization to manage the reconstructed 3D points, reject the outlier of correspondences by querying SDF, adjust the estimated geometries by NBA (Neural BA), finally yielding promising results of 3D reconstruction. Furthermore, our Level-S$^2$fM alleviated the requirement of camera poses for neural 3D reconstruction. ",
    "url": "https://arxiv.org/abs/2211.12018",
    "authors": [
      "Yuxi Xiao",
      "Nan Xue",
      "Tianfu Wu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12035",
    "title": "FastFlow: AI for Fast Urban Wind Velocity Prediction",
    "abstract": "Data-driven approaches, including deep learning, have shown great promise as surrogate models across many domains. These extend to various areas in sustainability. An interesting direction for which data-driven methods have not been applied much yet is in the quick quantitative evaluation of urban layouts for planning and design. In particular, urban designs typically involve complex trade-offs between multiple objectives, including limits on urban build-up and/or consideration of urban heat island effect. Hence, it can be beneficial to urban planners to have a fast surrogate model to predict urban characteristics of a hypothetical layout, e.g. pedestrian-level wind velocity, without having to run computationally expensive and time-consuming high-fidelity numerical simulations. This fast surrogate can then be potentially integrated into other design optimization frameworks, including generative models or other gradient-based methods. Here we present the use of CNNs for urban layout characterization that is typically done via high-fidelity numerical simulation. We further apply this model towards a first demonstration of its utility for data-driven pedestrian-level wind velocity prediction. The data set in this work comprises results from high-fidelity numerical simulations of wind velocities for a diverse set of realistic urban layouts, based on randomized samples from a real-world, highly built-up urban city. We then provide prediction results obtained from the trained CNN, demonstrating test errors of under 0.1 m/s for previously unseen urban layouts. We further illustrate how this can be useful for purposes such as rapid evaluation of pedestrian wind velocity for a potential new layout. It is hoped that this data set will further accelerate research in data-driven urban AI, even as our baseline model facilitates quantitative comparison to future methods. ",
    "url": "https://arxiv.org/abs/2211.12035",
    "authors": [
      "Shi Jer Low",
      "Venugopalan",
      "S.G. Raghavan",
      "Harish Gopalan",
      "Jian Cheng Wong",
      "Justin Yeoh",
      "Chin Chun Ooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2211.12040",
    "title": "Rethinking Implicit Neural Representations for vision Learners",
    "abstract": "Implicit Neural Representations (INRs) are powerful to parameterize continuous signals in computer vision. However, almost all INRs methods are limited to low-level tasks, e.g., image/video compression, super-resolution, and image generation. The questions on how to explore INRs to high-level tasks and deep networks are still under-explored. Existing INRs methods suffer from two problems: 1) narrow theoretical definitions of INRs are inapplicable to high-level tasks; 2) lack of representation capabilities to deep networks. Motivated by the above facts, we reformulate the definitions of INRs from a novel perspective and propose an innovative Implicit Neural Representation Network (INRN), which is the first study of INRs to tackle both low-level and high-level tasks. Specifically, we present three key designs for basic blocks in INRN along with two different stacking ways and corresponding loss functions. Extensive experiments with analysis on both low-level tasks (image fitting) and high-level vision tasks (image classification, object detection, instance segmentation) demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2211.12040",
    "authors": [
      "Yiran Song",
      "Qianyu Zhou",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12042",
    "title": "Robustness of Physics-Informed Neural Networks to Noise in Sensor Data",
    "abstract": "Physics-Informed Neural Networks (PINNs) have been shown to be an effective way of incorporating physics-based domain knowledge into neural network models for many important real-world systems. They have been particularly effective as a means of inferring system information based on data, even in cases where data is scarce. Most of the current work however assumes the availability of high-quality data. In this work, we further conduct a preliminary investigation of the robustness of physics-informed neural networks to the magnitude of noise in the data. Interestingly, our experiments reveal that the inclusion of physics in the neural network is sufficient to negate the impact of noise in data originating from hypothetical low quality sensors with high signal-to-noise ratios of up to 1. The resultant predictions for this test case are seen to still match the predictive value obtained for equivalent data obtained from high-quality sensors with potentially 10x less noise. This further implies the utility of physics-informed neural network modeling for making sense of data from sensor networks in the future, especially with the advent of Industry 4.0 and the increasing trend towards ubiquitous deployment of low-cost sensors which are typically noisier. ",
    "url": "https://arxiv.org/abs/2211.12042",
    "authors": [
      "Jian Cheng Wong",
      "Pao-Hsiung Chiu",
      "Chin Chun Ooi",
      "My Ha Da"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.12044",
    "title": "Backdoor Cleansing with Unlabeled Data",
    "abstract": "Due to the increasing computational demand of Deep Neural Networks (DNNs), companies and organizations have begun to outsource the training process. However, the externally trained DNNs can potentially be backdoor attacked. It is crucial to defend against such attacks, i.e., to postprocess a suspicious model so that its backdoor behavior is mitigated while its normal prediction power on clean inputs remain uncompromised. To remove the abnormal backdoor behavior, existing methods mostly rely on additional labeled clean samples. However, such requirement may be unrealistic as the training data are often unavailable to end users. In this paper, we investigate the possibility of circumventing such barrier. We propose a novel defense method that does not require training labels. Through a carefully designed layer-wise weight re-initialization and knowledge distillation, our method can effectively cleanse backdoor behaviors of a suspicious network {with negligible compromise in} its normal behavior. In experiments, we show that our method, trained without labels, is on-par with state-of-the-art defense methods trained using labels. We also observe promising defense results even on out-of-distribution data. This makes our method very practical. ",
    "url": "https://arxiv.org/abs/2211.12044",
    "authors": [
      "Lu Pang",
      "Tao Sun",
      "Haibin Ling",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.12046",
    "title": "Deblurred Neural Radiance Field with Physical Scene Priors",
    "abstract": "Neural Radiance Field(NeRF) has exhibited outstanding three-dimensional(3D) reconstruction quality via the novel view synthesis from multi-view images and paired calibrated camera parameters. However, previous NeRF-based systems have been demonstrated under strictly controlled settings, with little attention paid to less ideal scenarios, including with the presence of noise such as exposure, illumination changes, and blur. In particular, though blur frequently occurs in real situations, NeRF that can handle blurred images has received little attention. The few studies that have investigated NeRF for blurred images have not considered geometric and appearance consistency in 3D space, which is one of the most important factors in 3D reconstruction. This leads to inconsistency and the degradation of the perceptual quality of the constructed scene. Hence, this paper proposes a DP-NeRF, a novel clean NeRF framework for blurred images, which is constrained with two physical priors. These priors are derived from the actual blurring process during image acquisition by the camera. DP-NeRF proposes rigid blurring kernel to impose 3D consistency utilizing the physical priors and adaptive weight proposal to refine the color composition error in consideration of the relationship between depth and blur. We present extensive experimental results for synthetic and real scenes with two types of blur: camera motion blur and defocus blur. The results demonstrate that DP-NeRF successfully improves the perceptual quality of the constructed NeRF ensuring 3D geometric and appearance consistency. We further demonstrate the effectiveness of our model with comprehensive ablation analysis. ",
    "url": "https://arxiv.org/abs/2211.12046",
    "authors": [
      "Dogyoon Lee",
      "Minhyeok Lee",
      "Chajin Shin",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12047",
    "title": "Convolutional Neural Generative Coding: Scaling Predictive Coding to  Natural Images",
    "abstract": "In this work, we develop convolutional neural generative coding (Conv-NGC), a generalization of predictive coding to the case of convolution/deconvolution-based computation. Specifically, we concretely implement a flexible neurobiologically-motivated algorithm that progressively refines latent state maps in order to dynamically form a more accurate internal representation/reconstruction model of natural images. The performance of the resulting sensory processing system is evaluated on several benchmark datasets such as Color-MNIST, CIFAR-10, and Street House View Numbers (SVHN). We study the effectiveness of our brain-inspired neural system on the tasks of reconstruction and image denoising and find that it is competitive with convolutional auto-encoding systems trained by backpropagation of errors and notably outperforms them with respect to out-of-distribution reconstruction (including on the full 90k CINIC-10 test set). ",
    "url": "https://arxiv.org/abs/2211.12047",
    "authors": [
      "Alexander Ororbia",
      "Ankur Mali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12048",
    "title": "Global-Local Aggregation with Deformable Point Sampling for Camouflaged  Object Detection",
    "abstract": "The camouflaged object detection (COD) task aims to find and segment objects that have a color or texture that is very similar to that of the background. Despite the difficulties of the task, COD is attracting attention in medical, lifesaving, and anti-military fields. To overcome the difficulties of COD, we propose a novel global-local aggregation architecture with a deformable point sampling method. Further, we propose a global-local aggregation transformer that integrates an object's global information, background, and boundary local information, which is important in COD tasks. The proposed transformer obtains global information from feature channels and effectively extracts important local information from the subdivided patch using the deformable point sampling method. Accordingly, the model effectively integrates global and local information for camouflaged objects and also shows that important boundary information in COD can be efficiently utilized. Our method is evaluated on three popular datasets and achieves state-of-the-art performance. We prove the effectiveness of the proposed method through comparative experiments. ",
    "url": "https://arxiv.org/abs/2211.12048",
    "authors": [
      "Minhyeok Lee",
      "Suhwan Cho",
      "Chaewon Park",
      "Dogyoon Lee",
      "Jungho Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12051",
    "title": "Adaptive Dynamic Filtering Network for Image Denoising",
    "abstract": "In image denoising networks, feature scaling is widely used to enlarge the receptive field size and reduce computational costs. This practice, however, also leads to the loss of high-frequency information and fails to consider within-scale characteristics. Recently, dynamic convolution has exhibited powerful capabilities in processing high-frequency information (e.g., edges, corners, textures), but previous works lack sufficient spatial contextual information in filter generation. To alleviate these issues, we propose to employ dynamic convolution to improve the learning of high-frequency and multi-scale features. Specifically, we design a spatially enhanced kernel generation (SEKG) module to improve dynamic convolution, enabling the learning of spatial context information with a very low computational complexity. Based on the SEKG module, we propose a dynamic convolution block (DCB) and a multi-scale dynamic convolution block (MDCB). The former enhances the high-frequency information via dynamic convolution and preserves low-frequency information via skip connections. The latter utilizes shared adaptive dynamic kernels and the idea of dilated convolution to achieve efficient multi-scale feature extraction. The proposed multi-dimension feature integration (MFI) mechanism further fuses the multi-scale features, providing precise and contextually enriched feature representations. Finally, we build an efficient denoising network with the proposed DCB and MDCB, named ADFNet. It achieves better performance with low computational complexity on real-world and synthetic Gaussian noisy datasets. The source code is available at https://github.com/it-hao/ADFNet. ",
    "url": "https://arxiv.org/abs/2211.12051",
    "authors": [
      "Hao Shen",
      "Zhong-Qiu Zhao",
      "Wandi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12075",
    "title": "Greedy based Value Representation for Optimal Coordination in  Multi-agent Reinforcement Learning",
    "abstract": "Due to the representation limitation of the joint Q value function, multi-agent reinforcement learning methods with linear value decomposition (LVD) or monotonic value decomposition (MVD) suffer from relative overgeneralization. As a result, they can not ensure optimal consistency (i.e., the correspondence between individual greedy actions and the maximal true Q value). In this paper, we derive the expression of the joint Q value function of LVD and MVD. According to the expression, we draw a transition diagram, where each self-transition node (STN) is a possible convergence. To ensure optimal consistency, the optimal node is required to be the unique STN. Therefore, we propose the greedy-based value representation (GVR), which turns the optimal node into an STN via inferior target shaping and further eliminates the non-optimal STNs via superior experience replay. In addition, GVR achieves an adaptive trade-off between optimality and stability. Our method outperforms state-of-the-art baselines in experiments on various benchmarks. Theoretical proofs and empirical results on matrix games demonstrate that GVR ensures optimal consistency under sufficient exploration. ",
    "url": "https://arxiv.org/abs/2211.12075",
    "authors": [
      "Lipeng Wan",
      "Zeyang Liu",
      "Xingyu Chen",
      "Xuguang Lan",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12077",
    "title": "Design of an Autonomous Agriculture Robot for Real Time Weed Detection  using CNN",
    "abstract": "Agriculture has always remained an integral part of the world. As the human population keeps on rising, the demand for food also increases, and so is the dependency on the agriculture industry. But in today's scenario, because of low yield, less rainfall, etc., a dearth of manpower is created in this agricultural sector, and people are moving to live in the cities, and villages are becoming more and more urbanized. On the other hand, the field of robotics has seen tremendous development in the past few years. The concepts like Deep Learning (DL), Artificial Intelligence (AI), and Machine Learning (ML) are being incorporated with robotics to create autonomous systems for various sectors like automotive, agriculture, assembly line management, etc. Deploying such autonomous systems in the agricultural sector help in many aspects like reducing manpower, better yield, and nutritional quality of crops. So, in this paper, the system design of an autonomous agricultural robot which primarily focuses on weed detection is described. A modified deep-learning model for the purpose of weed detection is also proposed. The primary objective of this robot is the detection of weed on a real-time basis without any human involvement, but it can also be extended to design robots in various other applications involved in farming like weed removal, plowing, harvesting, etc., in turn making the farming industry more efficient. Source code and other details can be found at https://github.com/Dhruv2012/Autonomous-Farm-Robot ",
    "url": "https://arxiv.org/abs/2211.12077",
    "authors": [
      "Dhruv Patel",
      "Meet Gandhi",
      "Shankaranarayanan H.",
      "Anand D. Darji"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.12081",
    "title": "CDDSA: Contrastive Domain Disentanglement and Style Augmentation for  Generalizable Medical Image Segmentation",
    "abstract": "Generalization to previously unseen images with potential domain shifts and different styles is essential for clinically applicable medical image segmentation, and the ability to disentangle domain-specific and domain-invariant features is key for achieving Domain Generalization (DG). However, existing DG methods can hardly achieve effective disentanglement to get high generalizability. To deal with this problem, we propose an efficient Contrastive Domain Disentanglement and Style Augmentation (CDDSA) framework for generalizable medical image segmentation. First, a disentangle network is proposed to decompose an image into a domain-invariant anatomical representation and a domain-specific style code, where the former is sent to a segmentation model that is not affected by the domain shift, and the disentangle network is regularized by a decoder that combines the anatomical and style codes to reconstruct the input image. Second, to achieve better disentanglement, a contrastive loss is proposed to encourage the style codes from the same domain and different domains to be compact and divergent, respectively. Thirdly, to further improve generalizability, we propose a style augmentation method based on the disentanglement representation to synthesize images in various unseen styles with shared anatomical structures. Our method was validated on a public multi-site fundus image dataset for optic cup and disc segmentation and an in-house multi-site Nasopharyngeal Carcinoma Magnetic Resonance Image (NPC-MRI) dataset for nasopharynx Gross Tumor Volume (GTVnx) segmentation. Experimental results showed that the proposed CDDSA achieved remarkable generalizability across different domains, and it outperformed several state-of-the-art methods in domain-generalizable segmentation. ",
    "url": "https://arxiv.org/abs/2211.12081",
    "authors": [
      "Ran Gu",
      "Guotai Wang",
      "Jiangshan Lu",
      "Jingyang Zhang",
      "Wenhui Lei",
      "Yinan Chen",
      "Wenjun Liao",
      "Shichuan Zhang",
      "Kang Li",
      "Dimitris N. Metaxas",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12082",
    "title": "Brain MRI-to-PET Synthesis using 3D Convolutional Attention Networks",
    "abstract": "Accurate quantification of cerebral blood flow (CBF) is essential for the diagnosis and assessment of a wide range of neurological diseases. Positron emission tomography (PET) with radiolabeled water (15O-water) is considered the gold-standard for the measurement of CBF in humans. PET imaging, however, is not widely available because of its prohibitive costs and use of short-lived radiopharmaceutical tracers that typically require onsite cyclotron production. Magnetic resonance imaging (MRI), in contrast, is more readily accessible and does not involve ionizing radiation. This study presents a convolutional encoder-decoder network with attention mechanisms to predict gold-standard 15O-water PET CBF from multi-sequence MRI scans, thereby eliminating the need for radioactive tracers. Inputs to the prediction model include several commonly used MRI sequences (T1-weighted, T2-FLAIR, and arterial spin labeling). The model was trained and validated using 5-fold cross-validation in a group of 126 subjects consisting of healthy controls and cerebrovascular disease patients, all of whom underwent simultaneous $15O-water PET/MRI. The results show that such a model can successfully synthesize high-quality PET CBF measurements (with an average SSIM of 0.924 and PSNR of 38.8 dB) and is more accurate compared to concurrent and previous PET synthesis methods. We also demonstrate the clinical significance of the proposed algorithm by evaluating the agreement for identifying the vascular territories with abnormally low CBF. Such methods may enable more widespread and accurate CBF evaluation in larger cohorts who cannot undergo PET imaging due to radiation concerns, lack of access, or logistic challenges. ",
    "url": "https://arxiv.org/abs/2211.12082",
    "authors": [
      "Ramy Hussein",
      "David Shin",
      "Moss Zhao",
      "Jia Guo",
      "Guido Davidzon",
      "Michael Moseley",
      "Greg Zaharchuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.12087",
    "title": "SoK: Inference Attacks and Defenses in Human-Centered Wireless Sensing",
    "abstract": "Human-centered wireless sensing aims to understand the fine-grained environment and activities of a human using the diverse wireless signals around her. The wireless sensing community has demonstrated the superiority of such techniques in many applications such as smart homes, human-computer interactions, and smart cities. Like many other technologies, wireless sensing is also a double-edged sword. While the sensed information about a human can be used for many good purposes such as enhancing life quality, an adversary can also abuse it to steal private information about the human (e.g., location, living habits, and behavioral biometric characteristics). However, the literature lacks a systematic understanding of the privacy vulnerabilities of wireless sensing and the defenses against them. In this work, we aim to bridge this gap. First, we propose a framework to systematize wireless sensing-based inference attacks. Our framework consists of three key steps: deploying a sniffing device, sniffing wireless signals, and inferring private information. Our framework can be used to guide the design of new inference attacks since different attacks can instantiate these three steps differently. Second, we propose a defense-in-depth framework to systematize defenses against such inference attacks. The prevention component of our framework aims to prevent inference attacks via obfuscating the wireless signals around a human, while the detection component aims to detect and respond to attacks. Third, based on our attack and defense frameworks, we identify gaps in the existing literature and discuss future research directions. ",
    "url": "https://arxiv.org/abs/2211.12087",
    "authors": [
      "Wei Sun",
      "Tingjun Chen",
      "Neil Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.12091",
    "title": "Online Detection Of Supply Chain Network Disruptions Using Sequential  Change-Point Detection for Hawkes Processes",
    "abstract": "In this paper, we attempt to detect an inflection or change-point resulting from the Covid-19 pandemic on supply chain data received from a large furniture company. To accomplish this, we utilize a modified CUSUM (Cumulative Sum) procedure on the company's spatial-temporal order data as well as a GLR (Generalized Likelihood Ratio) based method. We model the order data using the Hawkes Process Network, a multi-dimensional self and mutually exciting point process, by discretizing the spatial data and treating each order as an event that has a corresponding node and time. We apply the methodologies on the company's most ordered item on a national scale and perform a deep dive into a single state. Because the item was ordered infrequently in the state compared to the nation, this approach allows us to show efficacy upon different degrees of data sparsity. Furthermore, it showcases use potential across differing levels of spatial detail. ",
    "url": "https://arxiv.org/abs/2211.12091",
    "authors": [
      "Khurram Yamin",
      "Haoyun Wang",
      "Benoit Montreuil",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12094",
    "title": "Fast Multiplex Graph Association Rules for Link Prediction",
    "abstract": "Multiplex networks allow us to study a variety of complex systems where nodes connect to each other in multiple ways, for example friend, family, and co-worker relations in social networks. Link prediction is the branch of network analysis allowing us to forecast the future status of a network: which new connections are the most likely to appear in the future? In multiplex link prediction we also ask: of which type? Because this last question is unanswerable with classical link prediction, here we investigate the use of graph association rules to inform multiplex link prediction. We derive such rules by identifying all frequent patterns in a network via multiplex graph mining, and then score each unobserved link's likelihood by finding the occurrences of each rule in the original network. Association rules add new abilities to multiplex link prediction: to predict new node arrivals, to consider higher order structures with four or more nodes, and to be memory efficient. We improve over previous work by creating a framework that is also efficient in terms of runtime, which enables an increase in prediction performance. This increase in efficiency allows us to improve a case study on a signed multiplex network, showing how graph association rules can provide valuable insights to extend social balance theory. ",
    "url": "https://arxiv.org/abs/2211.12094",
    "authors": [
      "Michele Coscia",
      "Christian Borgelt",
      "Michael Szell"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.12098",
    "title": "Weak scalability of domain decomposition methods for discrete fracture  networks",
    "abstract": "Discrete Fracture Networks (DFNs) are complex three-dimensional structures characterized by the intersections of planar polygonal fractures, and are used to model flows in fractured media. Despite being suitable for Domain Decomposition (DD) techniques, there are relatively few works on the application of DD methods to DFNs. In this manuscript, we present a theoretical study of Optimized Schwarz Methods (OSMs) applied to DFNs. Interestingly, we prove that the OSMs can be weakly scalable (that is, they converge to a given tolerance in a number of iterations independent of the number of fractures) under suitable assumptions on the domain decomposition. This contribution fits in the renewed interest on the weak scalability of DD methods after recent works showed weak scalability of DD methods for specific geometric configurations, even without coarse spaces. Despite simplifying assumptions which may be violated in practice, our analysis provides heuristics to minimize the computational efforts in realistic settings. Finally, we emphasize that the methodology proposed can be straightforwardly generalized to study other classical DD methods applied to DFNs. ",
    "url": "https://arxiv.org/abs/2211.12098",
    "authors": [
      "Stefano Berrone",
      "Tommaso Vanzan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.12100",
    "title": "Simulating Human Gaze with Neural Visual Attention",
    "abstract": "Existing models of human visual attention are generally unable to incorporate direct task guidance and therefore cannot model an intent or goal when exploring a scene. To integrate guidance of any downstream visual task into attention modeling, we propose the Neural Visual Attention (NeVA) algorithm. To this end, we impose to neural networks the biological constraint of foveated vision and train an attention mechanism to generate visual explorations that maximize the performance with respect to the downstream task. We observe that biologically constrained neural networks generate human-like scanpaths without being trained for this objective. Extensive experiments on three common benchmark datasets show that our method outperforms state-of-the-art unsupervised human attention models in generating human-like scanpaths. ",
    "url": "https://arxiv.org/abs/2211.12100",
    "authors": [
      "Leo Schwinn",
      "Doina Precup",
      "Bjoern Eskofier",
      "Dario Zanca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12101",
    "title": "Efficient Sampling Algorithms for Approximate Motif Counting in Temporal  Graph Streams",
    "abstract": "A great variety of complex systems, from user interactions in communication networks to transactions in financial markets, can be modeled as temporal graphs consisting of a set of vertices and a series of timestamped and directed edges. Temporal motifs are generalized from subgraph patterns in static graphs which consider edge orderings and durations in addition to topologies. Counting the number of occurrences of temporal motifs is a fundamental problem for temporal network analysis. However, existing methods either cannot support temporal motifs or suffer from performance issues. Moreover, they cannot work in the streaming model where edges are observed incrementally over time. In this paper, we focus on approximate temporal motif counting via random sampling. We first propose two sampling algorithms for temporal motif counting in the offline setting. The first is an edge sampling (ES) algorithm for estimating the number of instances of any temporal motif. The second is an improved edge-wedge sampling (EWS) algorithm that hybridizes edge sampling with wedge sampling for counting temporal motifs with $3$ vertices and $3$ edges. Furthermore, we propose two algorithms to count temporal motifs incrementally in temporal graph streams by extending the ES and EWS algorithms referred to as SES and SEWS. We provide comprehensive analyses of the theoretical bounds and complexities of our proposed algorithms. Finally, we perform extensive experimental evaluations of our proposed algorithms on several real-world temporal graphs. The results show that ES and EWS have higher efficiency, better accuracy, and greater scalability than state-of-the-art sampling methods for temporal motif counting in the offline setting. Moreover, SES and SEWS achieve up to three orders of magnitude speedups over ES and EWS while having comparable estimation errors for temporal motif counting in the streaming setting. ",
    "url": "https://arxiv.org/abs/2211.12101",
    "authors": [
      "Jingjing Wang",
      "Yanhao Wang",
      "Wenjun Jiang",
      "Yuchen Li",
      "Kian-Lee Tan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.12105",
    "title": "AdaptDHM: Adaptive Distribution Hierarchical Model for Multi-Domain CTR  Prediction",
    "abstract": "Large-scale commercial platforms usually involve numerous business domains for diverse business strategies and expect their recommendation systems to provide click-through rate (CTR) predictions for multiple domains simultaneously. Existing promising and widely-used multi-domain models discover domain relationships by explicitly constructing domain-specific networks, but the computation and memory boost significantly with the increase of domains. To reduce computational complexity, manually grouping domains with particular business strategies is common in industrial applications. However, this pre-defined data partitioning way heavily relies on prior knowledge, and it may neglect the underlying data distribution of each domain, hence limiting the model's representation capability. Regarding the above issues, we propose an elegant and flexible multi-distribution modeling paradigm, named Adaptive Distribution Hierarchical Model (AdaptDHM), which is an end-to-end optimization hierarchical structure consisting of a clustering process and classification process. Specifically, we design a distribution adaptation module with a customized dynamic routing mechanism. Instead of introducing prior knowledge for pre-defined data allocation, this routing algorithm adaptively provides a distribution coefficient for each sample to determine which cluster it belongs to. Each cluster corresponds to a particular distribution so that the model can sufficiently capture the commonalities and distinctions between these distinct clusters. Extensive experiments on both public and large-scale Alibaba industrial datasets verify the effectiveness and efficiency of AdaptDHM: Our model achieves impressive prediction accuracy and its time cost during the training stage is more than 50% less than that of other models. ",
    "url": "https://arxiv.org/abs/2211.12105",
    "authors": [
      "Jinyun Li",
      "Huiwen Zheng",
      "Yuanlin Liu",
      "Minfang Lu",
      "Lixia Wu",
      "Haoyuan Hu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12110",
    "title": "Improving Crowded Object Detection via Copy-Paste",
    "abstract": "Crowdedness caused by overlapping among similar objects is a ubiquitous challenge in the field of 2D visual object detection. In this paper, we first underline two main effects of the crowdedness issue: 1) IoU-confidence correlation disturbances (ICD) and 2) confused de-duplication (CDD). Then we explore a pathway of cracking these nuts from the perspective of data augmentation. Primarily, a particular copy-paste scheme is proposed towards making crowded scenes. Based on this operation, we first design a \"consensus learning\" method to further resist the ICD problem and then find out the pasting process naturally reveals a pseudo \"depth\" of object in the scene, which can be potentially used for alleviating CDD dilemma. Both methods are derived from magical using of the copy-pasting without extra cost for hand-labeling. Experiments show that our approach can easily improve the state-of-the-art detector in typical crowded detection task by more than 2% without any bells and whistles. Moreover, this work can outperform existing data augmentation strategies in crowded scenario. ",
    "url": "https://arxiv.org/abs/2211.12110",
    "authors": [
      "Jiangfan Deng",
      "Dewen Fan",
      "Xiaosong Qiu",
      "Feng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12117",
    "title": "Flow Guidance Deformable Compensation Network for Video Frame  Interpolation",
    "abstract": "Motion-based video frame interpolation (VFI) methods have made remarkable progress with the development of deep convolutional networks over the past years. While their performance is often jeopardized by the inaccuracy of flow map estimation, especially in the case of large motion and occlusion. In this paper, we propose a flow guidance deformable compensation network (FGDCN) to overcome the drawbacks of existing motion-based methods. FGDCN decomposes the frame sampling process into two steps: a flow step and a deformation step. Specifically, the flow step utilizes a coarse-to-fine flow estimation network to directly estimate the intermediate flows and synthesizes an anchor frame simultaneously. To ensure the accuracy of the estimated flow, a distillation loss and a task-oriented loss are jointly employed in this step. Under the guidance of the flow priors learned in step one, the deformation step designs a pyramid deformable compensation network to compensate for the missing details of the flow step. In addition, a pyramid loss is proposed to supervise the model in both the image and frequency domain. Experimental results show that the proposed algorithm achieves excellent performance on various datasets with fewer parameters. ",
    "url": "https://arxiv.org/abs/2211.12117",
    "authors": [
      "Pengcheng Lei",
      "Faming Fang",
      "Guixu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12141",
    "title": "MGADN: A Multi-task Graph Anomaly Detection Network for Multivariate  Time Series",
    "abstract": "Anomaly detection of time series, especially multivariate time series(time series with multiple sensors), has been focused on for several years. Though existing method has achieved great progress, there are several challenging problems to be solved. Firstly, existing method including neural network only concentrate on the relationship in terms of timestamp. To be exact, they only want to know how does the data in the past influence which in the future. However, one sensor sometimes intervenes in other sensor such as the speed of wind may cause decrease of temperature. Secondly, there exist two categories of model for time series anomaly detection: prediction model and reconstruction model. Prediction model is adept at learning timely representation while short of capability when faced with sparse anomaly. Conversely, reconstruction model is opposite. Therefore, how can we efficiently get the relationship both in terms of both timestamp and sensors becomes our main topic. Our approach uses GAT, which is originated from graph neural network, to obtain connection between sensors. And LSTM is used to obtain relationships timely. Our approach is also designed to be double headed to calculate both prediction loss and reconstruction loss via VAE(Variational Auto-Encoder). In order to take advantage of two sorts of model, multi-task optimization algorithm is used in this model. ",
    "url": "https://arxiv.org/abs/2211.12141",
    "authors": [
      "Weixuan Xiong",
      "Xiaochen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12151",
    "title": "Reinforcement Causal Structure Learning on Order Graph",
    "abstract": "Learning directed acyclic graph (DAG) that describes the causality of observed data is a very challenging but important task. Due to the limited quantity and quality of observed data, and non-identifiability of causal graph, it is almost impossible to infer a single precise DAG. Some methods approximate the posterior distribution of DAGs to explore the DAG space via Markov chain Monte Carlo (MCMC), but the DAG space is over the nature of super-exponential growth, accurately characterizing the whole distribution over DAGs is very intractable. In this paper, we propose {Reinforcement Causal Structure Learning on Order Graph} (RCL-OG) that uses order graph instead of MCMC to model different DAG topological orderings and to reduce the problem size. RCL-OG first defines reinforcement learning with a new reward mechanism to approximate the posterior distribution of orderings in an efficacy way, and uses deep Q-learning to update and transfer rewards between nodes. Next, it obtains the probability transition model of nodes on order graph, and computes the posterior probability of different orderings. In this way, we can sample on this model to obtain the ordering with high probability. Experiments on synthetic and benchmark datasets show that RCL-OG provides accurate posterior probability approximation and achieves better results than competitive causal discovery algorithms. ",
    "url": "https://arxiv.org/abs/2211.12151",
    "authors": [
      "Dezhi Yang",
      "Guoxian Yu",
      "Jun Wang",
      "Zhengtian Wu",
      "Maozu Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.12154",
    "title": "Event Causality Identification with Causal News Corpus -- Shared Task 3,  CASE 2022",
    "abstract": "The Event Causality Identification Shared Task of CASE 2022 involved two subtasks working on the Causal News Corpus. Subtask 1 required participants to predict if a sentence contains a causal relation or not. This is a supervised binary classification task. Subtask 2 required participants to identify the Cause, Effect and Signal spans per causal sentence. This could be seen as a supervised sequence labeling task. For both subtasks, participants uploaded their predictions for a held-out test set, and ranking was done based on binary F1 and macro F1 scores for Subtask 1 and 2, respectively. This paper summarizes the work of the 17 teams that submitted their results to our competition and 12 system description papers that were received. The best F1 scores achieved for Subtask 1 and 2 were 86.19% and 54.15%, respectively. All the top-performing approaches involved pre-trained language models fine-tuned to the targeted task. We further discuss these approaches and analyze errors across participants' systems in this paper. ",
    "url": "https://arxiv.org/abs/2211.12154",
    "authors": [
      "Fiona Anting Tan",
      "Hansi Hettiarachchi",
      "Ali H\u00fcrriyeto\u011flu",
      "Tommaso Caselli",
      "Onur Uca",
      "Farhana Ferdousi Liza",
      "Nelleke Oostdijk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.12156",
    "title": "MSS-DepthNet: Depth Prediction with Multi-Step Spiking Neural Network",
    "abstract": "Event cameras are considered to have great potential for computer vision and robotics applications because of their high temporal resolution and low power consumption characteristics. However, the event stream output from event cameras has asynchronous, sparse characteristics that existing computer vision algorithms cannot handle. Spiking neural network is a novel event-based computational paradigm that is considered to be well suited for processing event camera tasks. However, direct training of deep SNNs suffers from degradation problems. This work addresses these problems by proposing a spiking neural network architecture with a novel residual block designed and multi-dimension attention modules combined, focusing on the problem of depth prediction. In addition, a novel event stream representation method is explicitly proposed for SNNs. This model outperforms previous ANN networks of the same size on the MVSEC dataset and shows great computational efficiency. ",
    "url": "https://arxiv.org/abs/2211.12156",
    "authors": [
      "Xiaoshan Wu",
      "Weihua He",
      "Man Yao",
      "Ziyang Zhang",
      "Yaoyuan Wang",
      "Guoqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12157",
    "title": "PESE: Event Structure Extraction using Pointer Network based  Encoder-Decoder Architecture",
    "abstract": "The task of event extraction (EE) aims to find the events and event-related argument information from the text and represent them in a structured format. Most previous works try to solve the problem by separately identifying multiple substructures and aggregating them to get the complete event structure. The problem with the methods is that it fails to identify all the interdependencies among the event participants (event-triggers, arguments, and roles). In this paper, we represent each event record in a unique tuple format that contains trigger phrase, trigger type, argument phrase, and corresponding role information. Our proposed pointer network-based encoder-decoder model generates an event tuple in each time step by exploiting the interactions among event participants and presenting a truly end-to-end solution to the EE task. We evaluate our model on the ACE2005 dataset, and experimental results demonstrate the effectiveness of our model by achieving competitive performance compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2211.12157",
    "authors": [
      "Alapan Kuila",
      "Sudeshan Sarkar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.12181",
    "title": "User-Conditioned Neural Control Policies for Mobile Robotics",
    "abstract": "Recently, learning-based controllers have been shown to push mobile robotic systems to their limits and provide the robustness needed for many real-world applications. However, only classical optimization-based control frameworks offer the inherent flexibility to be dynamically adjusted during execution by, for example, setting target speeds or actuator limits. We present a framework to overcome this shortcoming of neural controllers by conditioning them on an auxiliary input. This advance is enabled by including a feature-wise linear modulation layer (FiLM). We use model-free reinforcement-learning to train quadrotor control policies for the task of navigating through a sequence of waypoints in minimum time. By conditioning the policy on the maximum available thrust or the viewing direction relative to the next waypoint, a user can regulate the aggressiveness of the quadrotor's flight during deployment. We demonstrate in simulation and in real-world experiments that a single control policy can achieve close to time-optimal flight performance across the entire performance envelope of the robot, reaching up to 60 km/h and 4.5g in acceleration. The ability to guide a learned controller during task execution has implications beyond agile quadrotor flight, as conditioning the control policy on human intent helps safely bringing learning based systems out of the well-defined laboratory environment into the wild. ",
    "url": "https://arxiv.org/abs/2211.12181",
    "authors": [
      "Leonard Bauersfeld",
      "Elia Kaufmann",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.12190",
    "title": "A Combined Approach of Process Mining and Rule-based AI for Study  Planning and Monitoring in Higher Education",
    "abstract": "This paper presents an approach of using methods of process mining and rule-based artificial intelligence to analyze and understand study paths of students based on campus management system data and study program models. Process mining techniques are used to characterize successful study paths, as well as to detect and visualize deviations from expected plans. These insights are combined with recommendations and requirements of the corresponding study programs extracted from examination regulations. Here, event calculus and answer set programming are used to provide models of the study programs which support planning and conformance checking while providing feedback on possible study plan violations. In its combination, process mining and rule-based artificial intelligence are used to support study planning and monitoring by deriving rules and recommendations for guiding students to more suitable study paths with higher success rates. Two applications will be implemented, one for students and one for study program designers. ",
    "url": "https://arxiv.org/abs/2211.12190",
    "authors": [
      "Miriam Wagner",
      "Hayyan Helal",
      "Rene Roepke",
      "Sven Judel",
      "Jens Doveren",
      "Sergej Goerzen",
      "Pouya Soudmand",
      "Gerhard Lakemeyer",
      "Ulrik Schroeder",
      "Wil van der Aalst"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.12203",
    "title": "Edge Multiway Cut and Node Multiway Cut are NP-complete on subcubic  graphs",
    "abstract": "We show that Edge Multiway Cut (also called Multiterminal Cut) and Node Multiway Cut are NP-complete on graphs of maximum degree $3$ (also known as subcubic graphs). This improves on a previous degree bound of $11$. Our NP-completeness result holds even for subcubic graphs that are planar. ",
    "url": "https://arxiv.org/abs/2211.12203",
    "authors": [
      "Matthew Johnson",
      "Barnaby Martin",
      "Siani Smith",
      "Sukanya Pandey",
      "Daniel Paulusma",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.12206",
    "title": "Twitter has a Binary Privacy Setting, are Users Aware of How It Works?",
    "abstract": "Twitter accounts are public by default, but Twitter gives the option to create protected accounts, where only approved followers can see their tweets. The publicly visible information changes based on the account type and the visibility of tweets also depends solely on the poster's account type which can cause unintended disclosures especially when users interact. We surveyed 336 Twitter users to understand users' awareness of account information visibility, as well as the tweet visibility when users interact. We find that our participants are aware of the visibility of their profile information and individual tweets. However, the visibility of followed topics, lists, and interactions with protected accounts is confusing. Only 31% of the participants were aware that a reply by a public account to a protected account's tweet would be publicly visible. Surprisingly, having a protected account does not result in a better understanding of the account information or tweet visibility. ",
    "url": "https://arxiv.org/abs/2211.12206",
    "authors": [
      "Dilara Kek\u00fcll\u00fco\u011flu",
      "Kami Vaniea",
      "Maria K. Wolters",
      "Walid Magdy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2211.12216",
    "title": "Watch out! There may be a Human. Addressing Invisible Humans in Social  Navigation",
    "abstract": "Current approaches in human-aware or social robot navigation address the humans that are visible to the robot. However, it is also important to address the possible emergences of humans to avoid shocks or surprises to humans and erratic behavior of the robot planner. In this paper, we propose a novel approach to detect and address these human emergences called `invisible humans'. We determine the places from which a human, currently not visible to the robot, can appear suddenly and then adapt the path and speed of the robot with the anticipation of potential collisions. This is done while still considering and adapting humans present in the robot's field of view. We also show how this detection can be exploited to identify and address the doorways or narrow passages. Finally, the effectiveness of the proposed methodology is shown through several simulated and real-world experiments. ",
    "url": "https://arxiv.org/abs/2211.12216",
    "authors": [
      "Phani Teja Singamaneni",
      "Anthony Favier",
      "Rachid Alami"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.12217",
    "title": "Where Will Players Move Next? Dynamic Graphs and Hierarchical Fusion for  Movement Forecasting in Badminton",
    "abstract": "Sports analytics has captured increasing attention since analysis of the various data enables insights for training strategies, player evaluation, etc. In this paper, we focus on predicting what types of returning strokes will be made, and where players will move to based on previous strokes. As this problem has not been addressed to date, movement forecasting can be tackled through sequence-based and graph-based models by formulating as a sequence prediction task. However, existing sequence-based models neglect the effects of interactions between players, and graph-based models still suffer from multifaceted perspectives on the next movement. Moreover, there is no existing work on representing strategic relations among players' shot types and movements. To address these challenges, we first introduce the procedure of the Player Movements (PM) graph to exploit the structural movements of players with strategic relations. Based on the PM graph, we propose a novel Dynamic Graphs and Hierarchical Fusion for Movement Forecasting model (DyMF) with interaction style extractors to capture the mutual interactions of players themselves and between both players within a rally, and dynamic players' tactics across time. In addition, hierarchical fusion modules are designed to incorporate the style influence of both players and rally interactions. Extensive experiments show that our model empirically outperforms both sequence- and graph-based methods and demonstrate the practical usage of movement forecasting. ",
    "url": "https://arxiv.org/abs/2211.12217",
    "authors": [
      "Kai-Shiang Chang",
      "Wei-Yao Wang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12219",
    "title": "Adaptive Sparse Structure Development with Pruning and Regeneration for  Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) are more biologically plausible and computationally efficient. Therefore, SNNs have the natural advantage of drawing the sparse structural plasticity of brain development to alleviate the energy problems of deep neural networks caused by their complex and fixed structures. However, previous SNNs compression works are lack of in-depth inspiration from the brain development plasticity mechanism. This paper proposed a novel method for the adaptive structural development of SNN (SD-SNN), introducing dendritic spine plasticity-based synaptic constraint, neuronal pruning and synaptic regeneration. We found that synaptic constraint and neuronal pruning can detect and remove a large amount of redundancy in SNNs, coupled with synaptic regeneration can effectively prevent and repair over-pruning. Moreover, inspired by the neurotrophic hypothesis, neuronal pruning rate and synaptic regeneration rate were adaptively adjusted during the learning-while-pruning process, which eventually led to the structural stability of SNNs. Experimental results on spatial (MNIST, CIFAR-10) and temporal neuromorphic (N-MNIST, DVS-Gesture) datasets demonstrate that our method can flexibly learn appropriate compression rate for various tasks and effectively achieve superior performance while massively reducing the network energy consumption. Specifically, for the spatial MNIST dataset, our SD-SNN achieves 99.51\\% accuracy at the pruning rate 49.83\\%, which has a 0.05\\% accuracy improvement compared to the baseline without compression. For the neuromorphic DVS-Gesture dataset, 98.20\\% accuracy with 1.09\\% improvement is achieved by our method when the compression rate reaches 55.50\\%. ",
    "url": "https://arxiv.org/abs/2211.12219",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Yi Zeng",
      "Wenxuan Pan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12223",
    "title": "KGMM -- A Maturity Model for Scholarly Knowledge Graphs based on  Intertwined Human-Machine Collaboration",
    "abstract": "Knowledge Graphs (KG) have gained increasing importance in science, business and society in the last years. However, most knowledge graphs were either extracted or compiled from existing sources. There are only relatively few examples where knowledge graphs were genuinely created by an intertwined human-machine collaboration. Also, since the quality of data and knowledge graphs is of paramount importance, a number of data quality assessment models have been proposed. However, they do not take the specific aspects of intertwined human-machine curated knowledge graphs into account. In this work, we propose a graded maturity model for scholarly knowledge graphs (KGMM), which specifically focuses on aspects related to the joint, evolutionary curation of knowledge graphs for digital libraries. Our model comprises 5 maturity stages with 20 quality measures. We demonstrate the implementation of our model in a large scale scholarly knowledge graph curation effort. ",
    "url": "https://arxiv.org/abs/2211.12223",
    "authors": [
      "Hassan Hussein",
      "Allard Oelen",
      "Oliver Karras",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2211.12239",
    "title": "Photonic Spiking Neural Networks with Highly Efficient Training  Protocols for Ultrafast Neuromorphic Computing Systems",
    "abstract": "Photonic technologies offer great prospects for novel ultrafast, energy-efficient and hardware-friendly neuromorphic (brain-like) computing platforms. Moreover, neuromorphic photonic approaches based upon ubiquitous, technology-mature and low-cost Vertical-Cavity Surface Emitting Lasers (VCSELs) (devices found in fibre-optic transmitters, mobile phones, automotive sensors, etc.) are of particular interest. Given VCSELs have shown the ability to realise neuronal optical spiking responses (at ultrafast GHz rates), their use for spike-based information processing systems has been proposed. In this work, Spiking Neural Network (SNN) operation, based on a hardware-friendly photonic system of just one Vertical Cavity Surface Emitting Laser (VCSEL), is reported alongside a novel binary weight 'significance' training scheme that fully capitalises on the discrete nature of the optical spikes used by the SNN to process input information. The VCSEL-based photonic SNN is tested with a highly complex, multivariate, classification task (MADELON) before performance is compared using a traditional least-squares training method and the alternative novel binary weighting scheme. Excellent classification accuracies of >94% are reached by both training methods, exceeding the benchmark performance of the dataset in a fraction of processing time. The newly reported training scheme also dramatically reduces training set size requirements as well as the number of trained nodes (<1% of the total network node count). This VCSEL-based photonic SNN, in combination with the reported 'significance' weighting scheme, therefore grants ultrafast spike-based optical processing with highly reduced training requirements and hardware complexity for potential application in future neuromorphic systems and artificial intelligence applications. ",
    "url": "https://arxiv.org/abs/2211.12239",
    "authors": [
      "Dafydd Owen-Newns",
      "Joshua Robertson",
      "Matej Hejda",
      "Antonio Hurtado"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2211.12244",
    "title": "FE-Fusion-VPR: Attention-based Multi-Scale Network Architecture for  Visual Place Recognition by Fusing Frames and Events",
    "abstract": "Traditional visual place recognition (VPR), usually using standard cameras, is easy to fail due to glare or high-speed motion. By contrast, event cameras have the advantages of low latency, high temporal resolution, and high dynamic range, which can deal with the above issues. Nevertheless, event cameras are prone to failure in weakly textured or motionless scenes, while standard cameras can still provide appearance information in this case. Thus, exploiting the complementarity of standard cameras and event cameras can effectively improve the performance of VPR algorithms. In the paper, we propose FE-Fusion-VPR, an attention-based multi-scale network architecture for VPR by fusing frames and events. First, the intensity frame and event volume are fed into the two-stream feature extraction network for shallow feature fusion. Next, the three-scale features are obtained through the multi-scale fusion network and aggregated into three sub-descriptors using the VLAD layer. Finally, the weight of each sub-descriptor is learned through the descriptor re-weighting network to obtain the final refined descriptor. Experimental results show that on the Brisbane-Event-VPR and DDD20 datasets, the Recall@1 of our FE-Fusion-VPR is 25.20% and 37.21% higher than Event-VPR and Ensemble-EventVPR, and is 2.55% and 15.89% higher than MultiRes-NetVLAD and NetVLAD. To our knowledge, this is the first end-to-end network that goes beyond the existing event-based and frame-based SOTA methods to fuse frame and events directly for VPR. ",
    "url": "https://arxiv.org/abs/2211.12244",
    "authors": [
      "Kuanxu Hou",
      "Delei Kong",
      "Junjie Jiang",
      "Hao Zhuang",
      "Xinjie Huang",
      "Zheng Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.12254",
    "title": "SPIn-NeRF: Multiview Segmentation and Perceptual Inpainting with Neural  Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRFs) have emerged as a popular approach for novel view synthesis. While NeRFs are quickly being adapted for a wider set of applications, intuitively editing NeRF scenes is still an open challenge. One important editing task is the removal of unwanted objects from a 3D scene, such that the replaced region is visually plausible and consistent with its context. We refer to this task as 3D inpainting. In 3D, solutions must be both consistent across multiple views and geometrically valid. In this paper, we propose a novel 3D inpainting method that addresses these challenges. Given a small set of posed images and sparse annotations in a single input image, our framework first rapidly obtains a 3D segmentation mask for a target object. Using the mask, a perceptual optimizationbased approach is then introduced that leverages learned 2D image inpainters, distilling their information into 3D space, while ensuring view consistency. We also address the lack of a diverse benchmark for evaluating 3D scene inpainting methods by introducing a dataset comprised of challenging real-world scenes. In particular, our dataset contains views of the same scene with and without a target object, enabling more principled benchmarking of the 3D inpainting task. We first demonstrate the superiority of our approach on multiview segmentation, comparing to NeRFbased methods and 2D segmentation approaches. We then evaluate on the task of 3D inpainting, establishing state-ofthe-art performance against other NeRF manipulation algorithms, as well as a strong 2D image inpainter baseline ",
    "url": "https://arxiv.org/abs/2211.12254",
    "authors": [
      "Ashkan Mirzaei",
      "Tristan Aumentado-Armstrong",
      "Konstantinos G. Derpanis",
      "Jonathan Kelly",
      "Marcus A. Brubaker",
      "Igor Gilitschenski",
      "Alex Levinshtein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12266",
    "title": "Relation-dependent Contrastive Learning with Cluster Sampling for  Inductive Relation Prediction",
    "abstract": "Relation prediction is a task designed for knowledge graph completion which aims to predict missing relationships between entities. Recent subgraph-based models for inductive relation prediction have received increasing attention, which can predict relation for unseen entities based on the extracted subgraph surrounding the candidate triplet. However, they are not completely inductive because of their disability of predicting unseen relations. Moreover, they fail to pay sufficient attention to the role of relation as they only depend on the model to learn parameterized relation embedding, which leads to inaccurate prediction on long-tail relations. In this paper, we introduce Relation-dependent Contrastive Learning (ReCoLe) for inductive relation prediction, which adapts contrastive learning with a novel sampling method based on clustering algorithm to enhance the role of relation and improve the generalization ability to unseen relations. Instead of directly learning embedding for relations, ReCoLe allocates a pre-trained GNN-based encoder to each relation to strengthen the influence of relation. The GNN-based encoder is optimized by contrastive learning, which ensures satisfactory performance on long-tail relations. In addition, the cluster sampling method equips ReCoLe with the ability to handle both unseen relations and entities. Experimental results suggest that ReCoLe outperforms state-of-the-art methods on commonly used inductive datasets. ",
    "url": "https://arxiv.org/abs/2211.12266",
    "authors": [
      "Jianfeng Wu",
      "Sijie Mai",
      "Haifeng Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.12270",
    "title": "Causal Abstraction with Soft Interventions",
    "abstract": "Causal abstraction provides a theory describing how several causal models can represent the same system at different levels of detail. Existing theoretical proposals limit the analysis of abstract models to \"hard\" interventions fixing causal variables to be constant values. In this work, we extend causal abstraction to \"soft\" interventions, which assign possibly non-constant functions to variables without adding new causal connections. Specifically, (i) we generalize $\\tau$-abstraction from Beckers and Halpern (2019) to soft interventions, (ii) we propose a further definition of soft abstraction to ensure a unique map $\\omega$ between soft interventions, and (iii) we prove that our constructive definition of soft abstraction guarantees the intervention map $\\omega$ has a specific and necessary explicit form. ",
    "url": "https://arxiv.org/abs/2211.12270",
    "authors": [
      "Riccardo Massidda",
      "Atticus Geiger",
      "Thomas Icard",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12277",
    "title": "Semantic Guided Level-Category Hybrid Prediction Network for  Hierarchical Image Classification",
    "abstract": "Hierarchical classification (HC) assigns each object with multiple labels organized into a hierarchical structure. The existing deep learning based HC methods usually predict an instance starting from the root node until a leaf node is reached. However, in the real world, images interfered by noise, occlusion, blur, or low resolution may not provide sufficient information for the classification at subordinate levels. To address this issue, we propose a novel semantic guided level-category hybrid prediction network (SGLCHPN) that can jointly perform the level and category prediction in an end-to-end manner. SGLCHPN comprises two modules: a visual transformer that extracts feature vectors from the input images, and a semantic guided cross-attention module that uses categories word embeddings as queries to guide learning category-specific representations. In order to evaluate the proposed method, we construct two new datasets in which images are at a broad range of quality and thus are labeled to different levels (depths) in the hierarchy according to their individual quality. Experimental results demonstrate the effectiveness of our proposed HC method. ",
    "url": "https://arxiv.org/abs/2211.12277",
    "authors": [
      "Peng Wang",
      "Jingzhou Chen",
      "Yuntao Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12281",
    "title": "BESS: Balanced Entity Sampling and Sharing for Large-Scale Knowledge  Graph Completion",
    "abstract": "We present the award-winning submission to the WikiKG90Mv2 track of OGB-LSC@NeurIPS 2022. The task is link-prediction on the large-scale knowledge graph WikiKG90Mv2, consisting of 90M+ nodes and 600M+ edges. Our solution uses a diverse ensemble of $85$ Knowledge Graph Embedding models combining five different scoring functions (TransE, TransH, RotatE, DistMult, ComplEx) and two different loss functions (log-sigmoid, sampled softmax cross-entropy). Each individual model is trained in parallel on a Graphcore Bow Pod$_{16}$ using BESS (Balanced Entity Sampling and Sharing), a new distribution framework for KGE training and inference based on balanced collective communications between workers. Our final model achieves a validation MRR of 0.2922 and a test-challenge MRR of 0.2562, winning the first place in the competition. The code is publicly available at: https://github.com/graphcore/distributed-kge-poplar/tree/2022-ogb-submission. ",
    "url": "https://arxiv.org/abs/2211.12281",
    "authors": [
      "Alberto Cattaneo",
      "Daniel Justus",
      "Harry Mellor",
      "Douglas Orr",
      "Jerome Maloberti",
      "Zhenying Liu",
      "Thorin Farnsworth",
      "Andrew Fitzgibbon",
      "Blazej Banaszewski",
      "Carlo Luschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12285",
    "title": "Exact-NeRF: An Exploration of a Precise Volumetric Parameterization for  Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) have attracted significant attention due to their ability to synthesize novel scene views with great accuracy. However, inherent to their underlying formulation, the sampling of points along a ray with zero width may result in ambiguous representations that lead to further rendering artifacts such as aliasing in the final scene. To address this issue, the recent variant mip-NeRF proposes an Integrated Positional Encoding (IPE) based on a conical view frustum. Although this is expressed with an integral formulation, mip-NeRF instead approximates this integral as the expected value of a multivariate Gaussian distribution. This approximation is reliable for short frustums but degrades with highly elongated regions, which arises when dealing with distant scene objects under a larger depth of field. In this paper, we explore the use of an exact approach for calculating the IPE by using a pyramid-based integral formulation instead of an approximated conical-based one. We denote this formulation as Exact-NeRF and contribute the first approach to offer a precise analytical solution to the IPE within the NeRF domain. Our exploratory work illustrates that such an exact formulation Exact-NeRF matches the accuracy of mip-NeRF and furthermore provides a natural extension to more challenging scenarios without further modification, such as in the case of unbounded scenes. Our contribution aims to both address the hitherto unexplored issues of frustum approximation in earlier NeRF work and additionally provide insight into the potential future consideration of analytical solutions in future NeRF extensions. ",
    "url": "https://arxiv.org/abs/2211.12285",
    "authors": [
      "Brian K. S. Isaac-Medina",
      "Chris G. Willcocks",
      "Toby P. Breckon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.12294",
    "title": "PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models  Against Adversarial Examples",
    "abstract": "Point cloud completion, as the upstream procedure of 3D recognition and segmentation, has become an essential part of many tasks such as navigation and scene understanding. While various point cloud completion models have demonstrated their powerful capabilities, their robustness against adversarial attacks, which have been proven to be fatally malicious towards deep neural networks, remains unknown. In addition, existing attack approaches towards point cloud classifiers cannot be applied to the completion models due to different output forms and attack purposes. In order to evaluate the robustness of the completion models, we propose PointCA, the first adversarial attack against 3D point cloud completion models. PointCA can generate adversarial point clouds that maintain high similarity with the original ones, while being completed as another object with totally different semantic information. Specifically, we minimize the representation discrepancy between the adversarial example and the target point set to jointly explore the adversarial point clouds in the geometry space and the feature space. Furthermore, to launch a stealthier attack, we innovatively employ the neighbourhood density information to tailor the perturbation constraint, leading to geometry-aware and distribution-adaptive modifications for each point. Extensive experiments against different premier point cloud completion networks show that PointCA can cause a performance degradation from 77.9% to 16.7%, with the structure chamfer distance kept below 0.01. We conclude that existing completion models are severely vulnerable to adversarial examples, and state-of-the-art defenses for point cloud classification will be partially invalid when applied to incomplete and uneven point cloud data. ",
    "url": "https://arxiv.org/abs/2211.12294",
    "authors": [
      "Shengshan Hu",
      "Junwei Zhang",
      "Wei Liu",
      "Junhui Hou",
      "Minghui Li",
      "Leo Yu Zhang",
      "Hai Jin",
      "Lichao Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.12311",
    "title": "Generalizable Industrial Visual Anomaly Detection with Self-Induction  Vision Transformer",
    "abstract": "Industrial vision anomaly detection plays a critical role in the advanced intelligent manufacturing process, while some limitations still need to be addressed under such a context. First, existing reconstruction-based methods struggle with the identity mapping of trivial shortcuts where the reconstruction error gap is legible between the normal and abnormal samples, leading to inferior detection capabilities. Then, the previous studies mainly concentrated on the convolutional neural network (CNN) models that capture the local semantics of objects and neglect the global context, also resulting in inferior performance. Moreover, existing studies follow the individual learning fashion where the detection models are only capable of one category of the product while the generalizable detection for multiple categories has not been explored. To tackle the above limitations, we proposed a self-induction vision Transformer(SIVT) for unsupervised generalizable multi-category industrial visual anomaly detection and localization. The proposed SIVT first extracts discriminatory features from pre-trained CNN as property descriptors. Then, the self-induction vision Transformer is proposed to reconstruct the extracted features in a self-supervisory fashion, where the auxiliary induction tokens are additionally introduced to induct the semantics of the original signal. Finally, the abnormal properties can be detected using the semantic feature residual difference. We experimented with the SIVT on existing Mvtec AD benchmarks, the results reveal that the proposed method can advance state-of-the-art detection performance with an improvement of 2.8-6.3 in AUROC, and 3.3-7.6 in AP. ",
    "url": "https://arxiv.org/abs/2211.12311",
    "authors": [
      "Haiming Yao",
      "Xue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12312",
    "title": "Interpreting Neural Networks through the Polytope Lens",
    "abstract": "Mechanistic interpretability aims to explain what a neural network has learned at a nuts-and-bolts level. What are the fundamental primitives of neural network representations? Previous mechanistic descriptions have used individual neurons or their linear combinations to understand the representations a network has learned. But there are clues that neurons and their linear combinations are not the correct fundamental units of description: directions cannot describe how neural networks use nonlinearities to structure their representations. Moreover, many instances of individual neurons and their combinations are polysemantic (i.e. they have multiple unrelated meanings). Polysemanticity makes interpreting the network in terms of neurons or directions challenging since we can no longer assign a specific feature to a neural unit. In order to find a basic unit of description that does not suffer from these problems, we zoom in beyond just directions to study the way that piecewise linear activation functions (such as ReLU) partition the activation space into numerous discrete polytopes. We call this perspective the polytope lens. The polytope lens makes concrete predictions about the behavior of neural networks, which we evaluate through experiments on both convolutional image classifiers and language models. Specifically, we show that polytopes can be used to identify monosemantic regions of activation space (while directions are not in general monosemantic) and that the density of polytope boundaries reflect semantic boundaries. We also outline a vision for what mechanistic interpretability might look like through the polytope lens. ",
    "url": "https://arxiv.org/abs/2211.12312",
    "authors": [
      "Sid Black",
      "Lee Sharkey",
      "Leo Grinsztajn",
      "Eric Winsor",
      "Dan Braun",
      "Jacob Merizian",
      "Kip Parker",
      "Carlos Ram\u00f3n Guevara",
      "Beren Millidge",
      "Gabriel Alfour",
      "Connor Leahy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12322",
    "title": "TranViT: An Integrated Vision Transformer Framework for Discrete Transit  Travel Time Range Prediction",
    "abstract": "Accurate travel time estimation is paramount for providing transit users with reliable schedules and dependable real-time information. This paper proposes and evaluates a novel end-to-end framework for transit and roadside image data acquisition, labeling, and model training to predict transit travel times across a segment of interest. General Transit Feed Specification (GTFS) real-time data is used as an activation mechanism for a roadside camera unit monitoring a segment of Massachusetts Avenue in Cambridge, MA. Ground truth labels are generated for the acquired images dataset based on transit travel time across the monitored segment acquired from Automated Vehicle Location (AVL) data. The generated labeled image dataset is then used to train and evaluate a Vision Transformer (ViT) model to predict a discrete transit travel time range (band) based on the observed travel time percentiles. The results of this exploratory study illustrate that the ViT model is able to learn image features and contents that best help it deduce the expected travel time range with an average validation accuracy ranging between 80%-85%. We also demonstrate how this discrete travel time band prediction can subsequently be utilized to improve continuous transit travel time estimation. The workflow and results presented in this study provide an end-to-end, scalable, automated, and highly efficient approach for integrating traditional transit data sources and roadside imagery to estimate traffic states and predict transit travel duration, which can have major implications for improving operations and passenger real-time information. ",
    "url": "https://arxiv.org/abs/2211.12322",
    "authors": [
      "Awad Abdelhalim",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12324",
    "title": "Pushing the Limits of Asynchronous Graph-based Object Detection with  Event Cameras",
    "abstract": "State-of-the-art machine-learning methods for event cameras treat events as dense representations and process them with conventional deep neural networks. Thus, they fail to maintain the sparsity and asynchronous nature of event data, thereby imposing significant computation and latency constraints on downstream systems. A recent line of work tackles this issue by modeling events as spatiotemporally evolving graphs that can be efficiently and asynchronously processed using graph neural networks. These works showed impressive computation reductions, yet their accuracy is still limited by the small scale and shallow depth of their network, both of which are required to reduce computation. In this work, we break this glass ceiling by introducing several architecture choices which allow us to scale the depth and complexity of such models while maintaining low computation. On object detection tasks, our smallest model shows up to 3.7 times lower computation, while outperforming state-of-the-art asynchronous methods by 7.4 mAP. Even when scaling to larger model sizes, we are 13% more efficient than state-of-the-art while outperforming it by 11.5 mAP. As a result, our method runs 3.7 times faster than a dense graph neural network, taking only 8.4 ms per forward pass. This opens the door to efficient, and accurate object detection in edge-case scenarios. ",
    "url": "https://arxiv.org/abs/2211.12324",
    "authors": [
      "Daniel Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12339",
    "title": "Neural Dependencies Emerging from Learning Massive Categories",
    "abstract": "This work presents two astonishing findings on neural networks learned for large-scale image classification. 1) Given a well-trained model, the logits predicted for some category can be directly obtained by linearly combining the predictions of a few other categories, which we call \\textbf{neural dependency}. 2) Neural dependencies exist not only within a single model, but even between two independently learned models, regardless of their architectures. Towards a theoretical analysis of such phenomena, we demonstrate that identifying neural dependencies is equivalent to solving the Covariance Lasso (CovLasso) regression problem proposed in this paper. Through investigating the properties of the problem solution, we confirm that neural dependency is guaranteed by a redundant logit covariance matrix, which condition is easily met given massive categories, and that neural dependency is highly sparse, implying that one category correlates to only a few others. We further empirically show the potential of neural dependencies in understanding internal data correlations, generalizing models to unseen categories, and improving model robustness with a dependency-derived regularizer. Code for this work will be made publicly available. ",
    "url": "https://arxiv.org/abs/2211.12339",
    "authors": [
      "Ruili Feng",
      "Kecheng Zheng",
      "Kai Zhu",
      "Yujun Shen",
      "Jian Zhao",
      "Yukun Huang",
      "Deli Zhao",
      "Jingren Zhou",
      "Michael Jordan",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12345",
    "title": "Learning Deep Neural Networks by Iterative Linearisation",
    "abstract": "The excellent real-world performance of deep neural networks has received increasing attention. Despite the capacity to overfit significantly, such large models work better than smaller ones. This phenomenon is often referred to as the scaling law by practitioners. It is of fundamental interest to study why the scaling law exists and how it avoids/controls overfitting. One approach has been looking at infinite width limits of neural networks (e.g., Neural Tangent Kernels, Gaussian Processes); however, in practise, these do not fully explain finite networks as their infinite counterparts do not learn features. Furthermore, the empirical kernel for finite networks (i.e., the inner product of feature vectors), changes significantly during training in contrast to infinite width networks. In this work we derive an iterative linearised training method. We justify iterative lineralisation as an interpolation between finite analogs of the infinite width regime, which do not learn features, and standard gradient descent training which does. We show some preliminary results where iterative linearised training works well, noting in particular how much feature learning is required to achieve comparable performance. We also provide novel insights into the training behaviour of neural networks. ",
    "url": "https://arxiv.org/abs/2211.12345",
    "authors": [
      "Adrian Goldwaser",
      "Hong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.12353",
    "title": "U-Flow: A U-shaped Normalizing Flow for Anomaly Detection with  Unsupervised Threshold",
    "abstract": "In this work we propose a non-contrastive method for anomaly detection and segmentation in images, that benefits both from a modern machine learning approach and a more classic statistical detection theory. The method consists of three phases. First, features are extracted by making use of a multi-scale image Transformer architecture. Then, these features are fed into a U-shaped Normalizing Flow that lays the theoretical foundations for the last phase, which computes a pixel-level anomaly map, and performs a segmentation based on the a contrario framework. This multiple hypothesis testing strategy permits to derive a robust automatic detection threshold, which is key in many real-world applications, where an operational point is needed. The segmentation results are evaluated using the Intersection over Union (IoU) metric, and for assessing the generated anomaly maps we report the area under the Receiver Operating Characteristic curve (ROC-AUC) at both image and pixel level. For both metrics, the proposed approach produces state-of-the-art results, ranking first in most MvTec-AD categories, with a mean pixel-level ROC- AUC of 98.74%. Code and trained models are available at https://github.com/mtailanian/uflow. ",
    "url": "https://arxiv.org/abs/2211.12353",
    "authors": [
      "Mat\u00edas Tailanian",
      "\u00c1lvaro Pardo",
      "Pablo Mus\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12368",
    "title": "Real-time Neural Radiance Talking Portrait Synthesis via Audio-spatial  Decomposition",
    "abstract": "While dynamic Neural Radiance Fields (NeRF) have shown success in high-fidelity 3D modeling of talking portraits, the slow training and inference speed severely obstruct their potential usage. In this paper, we propose an efficient NeRF-based framework that enables real-time synthesizing of talking portraits and faster convergence by leveraging the recent success of grid-based NeRF. Our key insight is to decompose the inherently high-dimensional talking portrait representation into three low-dimensional feature grids. Specifically, a Decomposed Audio-spatial Encoding Module models the dynamic head with a 3D spatial grid and a 2D audio grid. The torso is handled with another 2D grid in a lightweight Pseudo-3D Deformable Module. Both modules focus on efficiency under the premise of good rendering quality. Extensive experiments demonstrate that our method can generate realistic and audio-lips synchronized talking portrait videos, while also being highly efficient compared to previous methods. ",
    "url": "https://arxiv.org/abs/2211.12368",
    "authors": [
      "Jiaxiang Tang",
      "Kaisiyuan Wang",
      "Hang Zhou",
      "Xiaokang Chen",
      "Dongliang He",
      "Tianshu Hu",
      "Jingtuo Liu",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12374",
    "title": "An Emotion-Aware Multi-Task Approach to Fake News and Rumour Detection  using Transfer Learning",
    "abstract": "Social networking sites, blogs, and online articles are instant sources of news for internet users globally. However, in the absence of strict regulations mandating the genuineness of every text on social media, it is probable that some of these texts are fake news or rumours. Their deceptive nature and ability to propagate instantly can have an adverse effect on society. This necessitates the need for more effective detection of fake news and rumours on the web. In this work, we annotate four fake news detection and rumour detection datasets with their emotion class labels using transfer learning. We show the correlation between the legitimacy of a text with its intrinsic emotion for fake news and rumour detection, and prove that even within the same emotion class, fake and real news are often represented differently, which can be used for improved feature extraction. Based on this, we propose a multi-task framework for fake news and rumour detection, predicting both the emotion and legitimacy of the text. We train a variety of deep learning models in single-task and multi-task settings for a more comprehensive comparison. We further analyze the performance of our multi-task approach for fake news detection in cross-domain settings to verify its efficacy for better generalization across datasets, and to verify that emotions act as a domain-independent feature. Experimental results verify that our multi-task models consistently outperform their single-task counterparts in terms of accuracy, precision, recall, and F1 score, both for in-domain and cross-domain settings. We also qualitatively analyze the difference in performance in single-task and multi-task learning models. ",
    "url": "https://arxiv.org/abs/2211.12374",
    "authors": [
      "Arjun Choudhry",
      "Inder Khatri",
      "Minni Jain",
      "Dinesh Kumar Vishwakarma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12385",
    "title": "MCD: A Modified Community Diversity Approach for Detecting Influential  Nodes in Social Networks",
    "abstract": "Over the last couple of decades, Social Networks have connected people on the web from across the globe and have become a crucial part of our daily life. These networks have also rapidly grown as platforms for propagating products, ideas, and opinions to target a wider audience. This calls for the need to find influential nodes in a network for a variety of reasons, including the curb of misinformation being spread across the networks, advertising products efficiently, finding prominent protein structures in biological networks, etc. In this paper, we propose Modified Community Diversity (MCD), a novel method for finding influential nodes in a network by exploiting community detection and a modified community diversity approach. We extend the concept of community diversity to a two-hop scenario. This helps us evaluate a node's possible influence over a network more accurately and also avoids the selection of seed nodes with an overlapping scope of influence. Experimental results verify that MCD outperforms various other state-of-the-art approaches on eight datasets cumulatively across three performance metrics. ",
    "url": "https://arxiv.org/abs/2211.12385",
    "authors": [
      "Aaryan Gupta",
      "Inder Khatri",
      "Arjun Choudhry",
      "Sanjay Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.12386",
    "title": "A Recursively Recurrent Neural Network (R2N2) Architecture for Learning  Iterative Algorithms",
    "abstract": "Meta-learning of numerical algorithms for a given task consist of the data-driven identification and adaptation of an algorithmic structure and the associated hyperparameters. To limit the complexity of the meta-learning problem, neural architectures with a certain inductive bias towards favorable algorithmic structures can, and should, be used. We generalize our previously introduced Runge-Kutta neural network to a recursively recurrent neural network (R2N2) superstructure for the design of customized iterative algorithms. In contrast to off-the-shelf deep learning approaches, it features a distinct division into modules for generation of information and for the subsequent assembly of this information towards a solution. Local information in the form of a subspace is generated by subordinate, inner, iterations of recurrent function evaluations starting at the current outer iterate. The update to the next outer iterate is computed as a linear combination of these evaluations, reducing the residual in this space, and constitutes the output of the network. We demonstrate that regular training of the weight parameters inside the proposed superstructure on input/output data of various computational problem classes yields iterations similar to Krylov solvers for linear equation systems, Newton-Krylov solvers for nonlinear equation systems, and Runge-Kutta integrators for ordinary differential equations. Due to its modularity, the superstructure can be readily extended with functionalities needed to represent more general classes of iterative algorithms traditionally based on Taylor series expansions. ",
    "url": "https://arxiv.org/abs/2211.12386",
    "authors": [
      "Danimir T. Doncevic",
      "Alexander Mitsos",
      "Yue Guo",
      "Qianxiao Li",
      "Felix Dietrich",
      "Manuel Dahmen",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.12419",
    "title": "Accuracy Prediction for NAS Acceleration using Feature Selection and  Extrapolation",
    "abstract": "Predicting the accuracy of candidate neural architectures is an important capability of NAS-based solutions. When a candidate architecture has properties that are similar to other known architectures, the prediction task is rather straightforward using off-the-shelf regression algorithms. However, when a candidate architecture lies outside of the known space of architectures, a regression model has to perform extrapolated predictions, which is not only a challenging task, but also technically impossible using the most popular regression algorithm families, which are based on decision trees. In this work, we are trying to address two problems. The first one is improving regression accuracy using feature selection, whereas the other one is the evaluation of regression algorithms on extrapolating accuracy prediction tasks. We extend the NAAP-440 dataset with new tabular features and introduce NAAP-440e, which we use for evaluation. We observe a dramatic improvement from the old baseline, namely, the new baseline requires 3x shorter training processes of candidate architectures, while maintaining the same mean-absolute-error and achieving almost 2x fewer monotonicity violations, compared to the old baseline's best reported performance. The extended dataset and code used in the study have been made public in the NAAP-440 repository. ",
    "url": "https://arxiv.org/abs/2211.12419",
    "authors": [
      "Tal Hakim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12422",
    "title": "PiRL: Participant-Invariant Representation Learning for Healthcare",
    "abstract": "Due to individual heterogeneity, performance gaps are observed between generic (one-size-fits-all) models and person-specific models in data-driven health applications. However, in real-world applications, generic models are usually more favorable due to new-user-adaptation issues and system complexities, etc. To improve the performance of the generic model, we propose a representation learning framework that learns participant-invariant representations, named PiRL. The proposed framework utilizes maximum mean discrepancy (MMD) loss and domain-adversarial training to encourage the model to learn participant-invariant representations. Further, a triplet loss, which constrains the model for inter-class alignment of the representations, is utilized to optimize the learned representations for downstream health applications. We evaluated our frameworks on two public datasets related to physical and mental health, for detecting sleep apnea and stress, respectively. As preliminary results, we found the proposed approach shows around a 5% increase in accuracy compared to the baseline. ",
    "url": "https://arxiv.org/abs/2211.12422",
    "authors": [
      "Zhaoyang Cao",
      "Han Yu",
      "Huiyuan Yang",
      "Akane Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.12424",
    "title": "One Venue, Two Conferences: The Separation of Chinese and American  Citation Networks",
    "abstract": "At NeurIPS, American and Chinese institutions cite papers from each other's regions substantially less than they cite endogamously. We build a citation graph to quantify this divide, compare it to European connectivity, and discuss the causes and consequences of the separation. ",
    "url": "https://arxiv.org/abs/2211.12424",
    "authors": [
      "Bingchen Zhao",
      "Yuling Gu",
      "Jessica Zosa Forde",
      "Naomi Saphra"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12479",
    "title": "Adaptive Prototypical Networks",
    "abstract": "Prototypical network for Few shot learning tries to learn an embedding function in the encoder that embeds images with similar features close to one another in the embedding space. However, in this process, the support set samples for a task are embedded independently of one other, and hence, the inter-class closeness is not taken into account. Thus, in the presence of similar-looking classes in a task, the embeddings will tend to be close to each other in the embedding space and even possibly overlap in some regions, which is not desirable for classification. In this paper, we propose an approach that intuitively pushes the embeddings of each of the classes away from the others in the meta-testing phase, thereby grouping them closely based on the distinct class labels rather than only the similarity of spatial features. This is achieved by training the encoder network for classification using the support set samples and labels of the new task. Extensive experiments conducted on benchmark data sets show improvements in meta-testing accuracy when compared with Prototypical Networks and also other standard few-shot learning models. ",
    "url": "https://arxiv.org/abs/2211.12479",
    "authors": [
      "Manas Gogoi",
      "Sambhavi Tiwari",
      "Shekhar Verma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12482",
    "title": "GRATIS: Deep Learning Graph Representation with Task-specific Topology  and Multi-dimensional Edge Features",
    "abstract": "Graph is powerful for representing various types of real-world data. The topology (edges' presence) and edges' features of a graph decides the message passing mechanism among vertices within the graph. While most existing approaches only manually define a single-value edge to describe the connectivity or strength of association between a pair of vertices, task-specific and crucial relationship cues may be disregarded by such manually defined topology and single-value edge features. In this paper, we propose the first general graph representation learning framework (called GRATIS) which can generate a strong graph representation with a task-specific topology and task-specific multi-dimensional edge features from any arbitrary input. To learn each edge's presence and multi-dimensional feature, our framework takes both of the corresponding vertices pair and their global contextual information into consideration, enabling the generated graph representation to have a globally optimal message passing mechanism for different down-stream tasks. The principled investigation results achieved for various graph analysis tasks on 11 graph and non-graph datasets show that our GRATIS can not only largely enhance pre-defined graphs but also learns a strong graph representation for non-graph data, with clear performance improvements on all tasks. In particular, the learned topology and multi-dimensional edge features provide complementary task-related cues for graph analysis tasks. Our framework is effective, robust and flexible, and is a plug-and-play module that can be combined with different backbones and Graph Neural Networks (GNNs) to generate a task-specific graph representation from various graph and non-graph data. Our code is made publicly available at https://github.com/SSYSteve/Learning-Graph-Representation-with-Task-specific-Topology-and-Multi-dimensional-Edge-Features. ",
    "url": "https://arxiv.org/abs/2211.12482",
    "authors": [
      "Siyang Song",
      "Yuxin Song",
      "Cheng Luo",
      "Zhiyuan Song",
      "Selim Kuzucu",
      "Xi Jia",
      "Zhijiang Guo",
      "Weicheng Xie",
      "Linlin Shen",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12486",
    "title": "Shortcomings of Top-Down Randomization-Based Sanity Checks for  Evaluations of Deep Neural Network Explanations",
    "abstract": "While the evaluation of explanations is an important step towards trustworthy models, it needs to be done carefully, and the employed metrics need to be well-understood. Specifically model randomization testing is often overestimated and regarded as a sole criterion for selecting or discarding certain explanation methods. To address shortcomings of this test, we start by observing an experimental gap in the ranking of explanation methods between randomization-based sanity checks [1] and model output faithfulness measures (e.g. [25]). We identify limitations of model-randomization-based sanity checks for the purpose of evaluating explanations. Firstly, we show that uninformative attribution maps created with zero pixel-wise covariance easily achieve high scores in this type of checks. Secondly, we show that top-down model randomization preserves scales of forward pass activations with high probability. That is, channels with large activations have a high probility to contribute strongly to the output, even after randomization of the network on top of them. Hence, explanations after randomization can only be expected to differ to a certain extent. This explains the observed experimental gap. In summary, these results demonstrate the inadequacy of model-randomization-based sanity checks as a criterion to rank attribution methods. ",
    "url": "https://arxiv.org/abs/2211.12486",
    "authors": [
      "Alexander Binder",
      "Leander Weber",
      "Sebastian Lapuschkin",
      "Gr\u00e9goire Montavon",
      "Klaus-Robert M\u00fcller",
      "Wojciech Samek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12501",
    "title": "AeDet: Azimuth-invariant Multi-view 3D Object Detection",
    "abstract": "Recent LSS-based multi-view 3D object detection has made tremendous progress, by processing the features in Brid-Eye-View (BEV) via the convolutional detector. However, the typical convolution ignores the radial symmetry of the BEV features and increases the difficulty of the detector optimization. To preserve the inherent property of the BEV features and ease the optimization, we propose an azimuth-equivariant convolution (AeConv) and an azimuth-equivariant anchor. The sampling grid of AeConv is always in the radial direction, thus it can learn azimuth-invariant BEV features. The proposed anchor enables the detection head to learn predicting azimuth-irrelevant targets. In addition, we introduce a camera-decoupled virtual depth to unify the depth prediction for the images with different camera intrinsic parameters. The resultant detector is dubbed Azimuth-equivariant Detector (AeDet). Extensive experiments are conducted on nuScenes, and AeDet achieves a 62.0% NDS, surpassing the recent multi-view 3D object detectors such as PETRv2 (58.2% NDS) and BEVDepth (60.0% NDS) by a large margin. Project page: https://fcjian.github.io/aedet. ",
    "url": "https://arxiv.org/abs/2211.12501",
    "authors": [
      "Chengjian Feng",
      "Zequn Jie",
      "Yujie Zhong",
      "Xiangxiang Chu",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11749",
    "title": "Towards Automatic Prediction of Outcome in Treatment of Cerebral  Aneurysms",
    "abstract": "Intrasaccular flow disruptors treat cerebral aneurysms by diverting the blood flow from the aneurysm sac. Residual flow into the sac after the intervention is a failure that could be due to the use of an undersized device, or to vascular anatomy and clinical condition of the patient. We report a machine learning model based on over 100 clinical and imaging features that predict the outcome of wide-neck bifurcation aneurysm treatment with an intravascular embolization device. We combine clinical features with a diverse set of common and novel imaging measurements within a random forest model. We also develop neural network segmentation algorithms in 2D and 3D to contour the sac in angiographic images and automatically calculate the imaging features. These deliver 90% overlap with manual contouring in 2D and 83% in 3D. Our predictive model classifies complete vs. partial occlusion outcomes with an accuracy of 75.31%, and weighted F1-score of 0.74. ",
    "url": "https://arxiv.org/abs/2211.11749",
    "authors": [
      "Ashutosh Jadhav",
      "Satyananda Kashyap",
      "Hakan Bulu",
      "Ronak Dholakia",
      "Amon Y. Liu",
      "Tanveer Syeda-Mahmood",
      "William R. Patterson",
      "Hussain Rangwala",
      "Mehdi Moradi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2211.11750",
    "title": "Self-attention based high order sequence feature reconstruction of  dynamic functional connectivity networks with rs-fMRI for brain disease  classification",
    "abstract": "Dynamic functional connectivity networks (dFCN) based on rs-fMRI have demonstrated tremendous potential for brain function analysis and brain disease classification. Recently, studies have applied deep learning techniques (i.e., convolutional neural network, CNN) to dFCN classification, and achieved better performance than the traditional machine learning methods. Nevertheless, previous deep learning methods usually perform successive convolutional operations on the input dFCNs to obtain high-order brain network aggregation features, extracting them from each sliding window using a series split, which may neglect non-linear correlations among different regions and the sequentiality of information. Thus, important high-order sequence information of dFCNs, which could further improve the classification performance, is ignored in these studies. Nowadays, inspired by the great success of Transformer in natural language processing and computer vision, some latest work has also emerged on the application of Transformer for brain disease diagnosis based on rs-fMRI data. Although Transformer is capable of capturing non-linear correlations, it lacks accounting for capturing local spatial feature patterns and modelling the temporal dimension due to parallel computing, even equipped with a positional encoding technique. To address these issues, we propose a self-attention (SA) based convolutional recurrent network (SA-CRN) learning framework for brain disease classification with rs-fMRI data. The experimental results on a public dataset (i.e., ADNI) demonstrate the effectiveness of our proposed SA-CRN method. ",
    "url": "https://arxiv.org/abs/2211.11750",
    "authors": [
      "Zhixiang Zhang",
      "Biao Jie",
      "Zhengdong Wang",
      "Jie Zhou",
      "Yang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.11865",
    "title": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "abstract": "The last decade witnessed a growing interest in Bayesian learning. Yet, the technicality of the topic and the multitude of ingredients involved therein, besides the complexity of turning theory into practical implementations, limit the use of the Bayesian learning paradigm, preventing its widespread adoption across different fields and applications. This self-contained survey engages and introduces readers to the principles and algorithms of Bayesian Learning for Neural Networks. It provides an introduction to the topic from an accessible, practical-algorithmic perspective. Upon providing a general introduction to Bayesian Neural Networks, we discuss and present both standard and recent approaches for Bayesian inference, with an emphasis on solutions relying on Variational Inference and the use of Natural gradients. We also discuss the use of manifold optimization as a state-of-the-art approach to Bayesian learning. We examine the characteristic properties of all the discussed methods, and provide pseudo-codes for their implementation, paying attention to practical aspects, such as the computation of the gradients ",
    "url": "https://arxiv.org/abs/2211.11865",
    "authors": [
      "Martin Magris",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11959",
    "title": "Robust High-dimensional Tuning Free Multiple Testing",
    "abstract": "A stylized feature of high-dimensional data is that many variables have heavy tails, and robust statistical inference is critical for valid large-scale statistical inference. Yet, the existing developments such as Winsorization, Huberization and median of means require the bounded second moments and involve variable-dependent tuning parameters, which hamper their fidelity in applications to large-scale problems. To liberate these constraints, this paper revisits the celebrated Hodges-Lehmann (HL) estimator for estimating location parameters in both the one- and two-sample problems, from a non-asymptotic perspective. Our study develops Berry-Esseen inequality and Cram\\'{e}r type moderate deviation for the HL estimator based on newly developed non-asymptotic Bahadur representation, and builds data-driven confidence intervals via a weighted bootstrap approach. These results allow us to extend the HL estimator to large-scale studies and propose \\emph{tuning-free} and \\emph{moment-free} high-dimensional inference procedures for testing global null and for large-scale multiple testing with false discovery proportion control. It is convincingly shown that the resulting tuning-free and moment-free methods control false discovery proportion at a prescribed level. The simulation studies lend further support to our developed theory. ",
    "url": "https://arxiv.org/abs/2211.11959",
    "authors": [
      "Jianqing Fan",
      "Zhipeng Lou",
      "Mengxin Yu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.12084",
    "title": "Accelerated Solutions of Coupled Phase-Field Problems using Generative  Adversarial Networks",
    "abstract": "Multiphysics problems such as multicomponent diffusion, phase transformations in multiphase systems and alloy solidification involve numerical solution of a coupled system of nonlinear partial differential equations (PDEs). Numerical solutions of these PDEs using mesh-based methods require spatiotemporal discretization of these equations. Hence, the numerical solutions are often sensitive to discretization parameters and may have inaccuracies (resulting from grid-based approximations). Moreover, choice of finer mesh for higher accuracy make these methods computationally expensive. Neural network-based PDE solvers are emerging as robust alternatives to conventional numerical methods because these use machine learnable structures that are grid-independent, fast and accurate. However, neural network based solvers require large amount of training data, thus affecting their generalizabilty and scalability. These concerns become more acute for coupled systems of time-dependent PDEs. To address these issues, we develop a new neural network based framework that uses encoder-decoder based conditional Generative Adversarial Networks with ConvLSTM layers to solve a system of Cahn-Hilliard equations. These equations govern microstructural evolution of a ternary alloy undergoing spinodal decomposition when quenched inside a three-phase miscibility gap. We show that the trained models are mesh and scale-independent, thereby warranting application as effective neural operators. ",
    "url": "https://arxiv.org/abs/2211.12084",
    "authors": [
      "Vir Karan",
      "A. Maruthi Indresh",
      "Saswata Bhattacharya"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.12089",
    "title": "Ultrasound Detection of Subquadricipital Recess Distension",
    "abstract": "Joint bleeding is a common condition for people with hemophilia and, if untreated, can result in hemophilic arthropathy. Ultrasound imaging has recently emerged as an effective tool to diagnose joint recess distension caused by joint bleeding. However, no computer-aided diagnosis tool exists to support the practitioner in the diagnosis process. This paper addresses the problem of automatically detecting the recess and assessing whether it is distended in knee ultrasound images collected in patients with hemophilia. After framing the problem, we propose two different approaches: the first one adopts a one-stage object detection algorithm, while the second one is a multi-task approach with a classification and a detection branch. The experimental evaluation, conducted with $483$ annotated images, shows that the solution based on object detection alone has a balanced accuracy score of $0.74$ with a mean IoU value of $0.66$, while the multi-task approach has a higher balanced accuracy value ($0.78$) at the cost of a slightly lower mean IoU value. ",
    "url": "https://arxiv.org/abs/2211.12089",
    "authors": [
      "Marco Colussi",
      "Gabriele Civitarese",
      "Dragan Ahmetovic",
      "Claudio Bettini",
      "Roberta Gualtierotti",
      "Flora Peyvandi",
      "Sergio Mascetti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12116",
    "title": "Network coevolution drives segregation and enhances Pareto optimal  equilibrium selection in coordination games",
    "abstract": "In this work we assess the role played by the dynamical adaptation of the interactions network, among agents playing Coordination Games, in reaching global coordination and in the equilibrium selection. Specifically, we analyze a coevolution model that couples the changes in agents' actions with the network dynamics, so that while agents play the game, they are able to sever some of their current connections and connect with others. We focus on two update rules: Replicator Dynamics (RD) and Unconditional Imitation (UI). We investigate a Pure Coordination Game (PCG), in which choices are equivalent, and on a General Coordination Game (GCG), for which there is a risk-dominant action and a payoff-dominant one. The network plasticity is measured by the probability to rewire links. Changing this plasticity parameter, there is a transition from a regime in which the system fully coordinates in a single connected component to a regime in which the system fragments in two connected components, each one coordinated on a different action (either if both actions are equivalent or not). The nature of this fragmentation transition is different for different update rules. Second, we find that both for RD and UI in a GCG, there is a regime of intermediate values of plasticity, before the fragmentation transition, for which the system is able to fully coordinate in a single component network on the payoff-dominant action, i. e., coevolution enhances payoff-dominant equilibrium selection for both update rules. ",
    "url": "https://arxiv.org/abs/2211.12116",
    "authors": [
      "Miguel A. Gonz\u00e1lez Casado",
      "Angel S\u00e1nchez",
      "Maxi San Miguel"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2211.12180",
    "title": "SRTGAN: Triplet Loss based Generative Adversarial Network for Real-World  Super-Resolution",
    "abstract": "Many applications such as forensics, surveillance, satellite imaging, medical imaging, etc., demand High-Resolution (HR) images. However, obtaining an HR image is not always possible due to the limitations of optical sensors and their costs. An alternative solution called Single Image Super-Resolution (SISR) is a software-driven approach that aims to take a Low-Resolution (LR) image and obtain the HR image. Most supervised SISR solutions use ground truth HR image as a target and do not include the information provided in the LR image, which could be valuable. In this work, we introduce Triplet Loss-based Generative Adversarial Network hereafter referred as SRTGAN for Image Super-Resolution problem on real-world degradation. We introduce a new triplet-based adversarial loss function that exploits the information provided in the LR image by using it as a negative sample. Allowing the patch-based discriminator with access to both HR and LR images optimizes to better differentiate between HR and LR images; hence, improving the adversary. Further, we propose to fuse the adversarial loss, content loss, perceptual loss, and quality loss to obtain Super-Resolution (SR) image with high perceptual fidelity. We validate the superior performance of the proposed method over the other existing methods on the RealSR dataset in terms of quantitative and qualitative metrics. ",
    "url": "https://arxiv.org/abs/2211.12180",
    "authors": [
      "Dhruv Patel",
      "Abhinav Jain",
      "Simran Bawkar",
      "Manav Khorasiya",
      "Kalpesh Prajapati",
      "Kishor Upla",
      "Kiran Raja",
      "Raghavendra Ramachandra",
      "Christoph Busch"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12314",
    "title": "Attacking Image Splicing Detection and Localization Algorithms Using  Synthetic Traces",
    "abstract": "Recent advances in deep learning have enabled forensics researchers to develop a new class of image splicing detection and localization algorithms. These algorithms identify spliced content by detecting localized inconsistencies in forensic traces using Siamese neural networks, either explicitly during analysis or implicitly during training. At the same time, deep learning has enabled new forms of anti-forensic attacks, such as adversarial examples and generative adversarial network (GAN) based attacks. Thus far, however, no anti-forensic attack has been demonstrated against image splicing detection and localization algorithms. In this paper, we propose a new GAN-based anti-forensic attack that is able to fool state-of-the-art splicing detection and localization algorithms such as EXIF-Net, Noiseprint, and Forensic Similarity Graphs. This attack operates by adversarially training an anti-forensic generator against a set of Siamese neural networks so that it is able to create synthetic forensic traces. Under analysis, these synthetic traces appear authentic and are self-consistent throughout an image. Through a series of experiments, we demonstrate that our attack is capable of fooling forensic splicing detection and localization algorithms without introducing visually detectable artifacts into an attacked image. Additionally, we demonstrate that our attack outperforms existing alternative attack approaches. % ",
    "url": "https://arxiv.org/abs/2211.12314",
    "authors": [
      "Shengbang Fang",
      "Matthew C Stamm"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.12421",
    "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
    "abstract": "This paper presents a comprehensive and quality collection of functional human brain network data for potential research in the intersection of neuroscience, machine learning, and graph analytics. Anatomical and functional MRI images of the brain have been used to understand the functional connectivity of the human brain and are particularly important in identifying underlying neurodegenerative conditions such as Alzheimer's, Parkinson's, and Autism. Recently, the study of the brain in the form of brain networks using machine learning and graph analytics has become increasingly popular, especially to predict the early onset of these conditions. A brain network, represented as a graph, retains richer structural and positional information that traditional examination methods are unable to capture. However, the lack of brain network data transformed from functional MRI images prevents researchers from data-driven explorations. One of the main difficulties lies in the complicated domain-specific preprocessing steps and the exhaustive computation required to convert data from MRI images into brain networks. We bridge this gap by collecting a large amount of available MRI images from existing studies, working with domain experts to make sensible design choices, and preprocessing the MRI images to produce a collection of brain network datasets. The datasets originate from 5 different sources, cover 3 neurodegenerative conditions, and consist of a total of 2,642 subjects. We test our graph datasets on 5 machine learning models commonly used in neuroscience and on a recent graph-based analysis model to validate the data quality and to provide domain baselines. To lower the barrier to entry and promote the research in this interdisciplinary field, we release our complete preprocessing details, codes, and brain network data. ",
    "url": "https://arxiv.org/abs/2211.12421",
    "authors": [
      "David Tse Jung Huang",
      "Sophi Shilpa Gururajapathy",
      "Yiping Ke",
      "Miao Qiao",
      "Alan Wang",
      "Haribalan Kumar",
      "Yunhan Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.12459",
    "title": "A generalized machine learning framework for brittle crack problems  using transfer learning and graph neural networks",
    "abstract": "Despite their recent success, machine learning (ML) models such as graph neural networks (GNNs), suffer from drawbacks such as the need for large training datasets and poor performance for unseen cases. In this work, we use transfer learning (TL) approaches to circumvent the need for retraining with large datasets. We apply TL to an existing ML framework, trained to predict multiple crack propagation and stress evolution in brittle materials under Mode-I loading. The new framework, ACCelerated Universal fRAcTure Emulator (ACCURATE), is generalized to a variety of crack problems by using a sequence of TL update steps including (i) arbitrary crack lengths, (ii) arbitrary crack orientations, (iii) square domains, (iv) horizontal domains, and (v) shear loadings. We show that using small training datasets of 20 simulations for each TL update step, ACCURATE achieved high prediction accuracy in Mode-I and Mode-II stress intensity factors, and crack paths for these problems. %case studies (i) - (iv). We demonstrate ACCURATE's ability to predict crack growth and stress evolution with high accuracy for unseen cases involving the combination of new boundary dimensions with arbitrary crack lengths and crack orientations in both tensile and shear loading. We also demonstrate significantly accelerated simulation times of up to 2 orders of magnitude faster (200x) compared to an XFEM-based fracture model. The ACCURATE framework provides a universal computational fracture mechanics model that can be easily modified or extended in future work. ",
    "url": "https://arxiv.org/abs/2211.12459",
    "authors": [
      "Roberto Perera",
      "Vinamra Agrawal"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12475",
    "title": "The impact of moving expenses on social segregation: a simulation with  RL and ABM",
    "abstract": "Over the past decades, breakthroughs such as Reinforcement Learning (RL) and Agent-based modeling (ABM) have made simulations of economic models feasible. Recently, there has been increasing interest in applying ABM to study the impact of residential preferences on neighborhood segregation in the Schelling Segregation Model. In this paper, RL is combined with ABM to simulate a modified Schelling Segregation model, which incorporates moving expenses as an input parameter. In particular, deep Q network (DQN) is adopted as RL agents' learning algorithm to simulate the behaviors of households and their preferences. This paper studies the impact of moving expenses on the overall segregation pattern and its role in social integration. A more comprehensive simulation of the segregation model is built for policymakers to forecast the potential consequences of their policies. ",
    "url": "https://arxiv.org/abs/2211.12475",
    "authors": [
      "Xinyu Li"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:1908.07092",
    "title": "Linear stability analysis for large dynamical systems on directed random  graphs",
    "abstract": " Comments: 35 pages, 8 figures, a few typo's have been corrected in the new version ",
    "url": "https://arxiv.org/abs/1908.07092",
    "authors": [
      "Izaak Neri",
      "Fernando Lucas Metz"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2103.09118",
    "title": "Balancing Biases and Preserving Privacy on Balanced Faces in the Wild",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2102.08941 ",
    "url": "https://arxiv.org/abs/2103.09118",
    "authors": [
      "Joseph P Robinson",
      "Can Qin",
      "Yann Henon",
      "Samson Timoner",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.15010",
    "title": "QueryNet: Attack by Multi-Identity Surrogates",
    "abstract": " Comments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks ",
    "url": "https://arxiv.org/abs/2105.15010",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2108.03388",
    "title": "Jointly Attacking Graph Neural Network and its Explanations",
    "abstract": " Comments: Accepted by ICDE 2023 (39th IEEE International Conference on Data Engineering) ",
    "url": "https://arxiv.org/abs/2108.03388",
    "authors": [
      "Wenqi Fan",
      "Wei Jin",
      "Xiaorui Liu",
      "Han Xu",
      "Xianfeng Tang",
      "Suhang Wang",
      "Qing Li",
      "Jiliang Tang",
      "Jianping Wang",
      "Charu Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2109.07270",
    "title": "Distract Your Attention: Multi-head Cross Attention Network for Facial  Expression Recognition",
    "abstract": " Title: Distract Your Attention: Multi-head Cross Attention Network for Facial  Expression Recognition ",
    "url": "https://arxiv.org/abs/2109.07270",
    "authors": [
      "Zhengyao Wen",
      "Wenzhong Lin",
      "Tao Wang",
      "Ge Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.05329",
    "title": "Self-Supervised Audio-Visual Representation Learning with Relaxed  Cross-Modal Synchronicity",
    "abstract": " Comments: Accepted in AAAI 2023 ",
    "url": "https://arxiv.org/abs/2111.05329",
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.02884",
    "title": "Social Sourcing: Incorporating Social Networks Into Crowdsourcing  Contest Design",
    "abstract": " Comments: IEEE/ACM Transactions on Networking ",
    "url": "https://arxiv.org/abs/2112.02884",
    "authors": [
      "Qi Shi",
      "Dong Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2112.05666",
    "title": "An Ensemble 1D-CNN-LSTM-GRU Model with Data Augmentation for Speech  Emotion Recognition",
    "abstract": " Comments: This paper is currently under revision process at expert systems with applications journal ",
    "url": "https://arxiv.org/abs/2112.05666",
    "authors": [
      "Md. Rayhan Ahmed",
      "Salekul Islam",
      "Ph. D",
      "A. K. M. Muzahidul Islam",
      "Ph. D",
      "Swakkhar Shatabda",
      "Ph. D"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.00785",
    "title": "IAE: Implicit Autoencoder for Point Cloud Self-supervised Representation  Learning",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2201.00785",
    "authors": [
      "Siming Yan",
      "Zhenpei Yang",
      "Haoxiang Li",
      "Li Guan",
      "Hao Kang",
      "Gang Hua",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05047",
    "title": "TransVOD: End-to-End Video Object Detection with Spatial-Temporal  Transformers",
    "abstract": " Comments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI), extended version of arXiv:2105.10920 ",
    "url": "https://arxiv.org/abs/2201.05047",
    "authors": [
      "Qianyu Zhou",
      "Xiangtai Li",
      "Lu He",
      "Yibo Yang",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Lizhuang Ma",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04769",
    "title": "Spectral Propagation Graph Network for Few-shot Time Series  Classification",
    "abstract": " Title: Spectral Propagation Graph Network for Few-shot Time Series  Classification ",
    "url": "https://arxiv.org/abs/2202.04769",
    "authors": [
      "Ling Yang",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.06464",
    "title": "Synthetic Data Can Also Teach: Synthesizing Effective Data for  Unsupervised Visual Representation Learning",
    "abstract": " Title: Synthetic Data Can Also Teach: Synthesizing Effective Data for  Unsupervised Visual Representation Learning ",
    "url": "https://arxiv.org/abs/2202.06464",
    "authors": [
      "Yawen Wu",
      "Zhepeng Wang",
      "Dewen Zeng",
      "Yiyu Shi",
      "Jingtong Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09115",
    "title": "Towards Simple and Accurate Human Pose Estimation with Stair Network",
    "abstract": " Comments: The paper has been accepted by IEEE Transactions on Emerging Topics in Computational Intelligence ",
    "url": "https://arxiv.org/abs/2202.09115",
    "authors": [
      "Chenru Jiang",
      "Kaizhu Huang",
      "Shufei Zhang",
      "Shufei Zhang",
      "Jimin Xiao",
      "Zhenxing Niu",
      "Amir Hussain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.11550",
    "title": "Robust Geometric Metric Learning",
    "abstract": " Comments: Published in EUSIPCO 2022. Best student paper award ",
    "url": "https://arxiv.org/abs/2202.11550",
    "authors": [
      "Antoine Collas",
      "Arnaud Breloy",
      "Guillaume Ginolhac",
      "Chengfang Ren",
      "Jean-Philippe Ovarlez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.13870",
    "title": "Simulating Network Paths with Recurrent Buffering Units",
    "abstract": " Comments: Accepted in AAAI 2023, 20 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2202.13870",
    "authors": [
      "Divyam Anshumaan",
      "Sriram Balasubramanian",
      "Shubham Tiwari",
      "Nagarajan Natarajan",
      "Sundararajan Sellamanickam",
      "Venkata N. Padmanabhan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.03382",
    "title": "Self-supervised Implicit Glyph Attention for Text Recognition",
    "abstract": " Title: Self-supervised Implicit Glyph Attention for Text Recognition ",
    "url": "https://arxiv.org/abs/2203.03382",
    "authors": [
      "Tongkun Guan",
      "Chaochen Gu",
      "Jingzheng Tu",
      "Xue Yang",
      "Qi Feng",
      "Yudi Zhao",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.01434",
    "title": "Circuit Model Reduction with Scaled Relative Graphs",
    "abstract": " Comments: Submitted to CDC2022 ",
    "url": "https://arxiv.org/abs/2204.01434",
    "authors": [
      "Thomas Chaffey",
      "Alberto Padoan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.09911",
    "title": "STFT-Domain Neural Speech Enhancement with Very Low Algorithmic Latency",
    "abstract": " Comments: in IEEE/ACM Transactions on Audio, Speech, and Language Processing ",
    "url": "https://arxiv.org/abs/2204.09911",
    "authors": [
      "Zhong-Qiu Wang",
      "Gordon Wichern",
      "Shinji Watanabe",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.10972",
    "title": "Global Extreme Heat Forecasting Using Neural Weather Models",
    "abstract": " Title: Global Extreme Heat Forecasting Using Neural Weather Models ",
    "url": "https://arxiv.org/abs/2205.10972",
    "authors": [
      "Ignacio Lopez-Gomez",
      "Amy McGovern",
      "Shreya Agrawal",
      "Jason Hickey"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02671",
    "title": "Canonical Cortical Graph Neural Networks and its Application for Speech  Enhancement in Future Audio-Visual Hearing Aids",
    "abstract": " Title: Canonical Cortical Graph Neural Networks and its Application for Speech  Enhancement in Future Audio-Visual Hearing Aids ",
    "url": "https://arxiv.org/abs/2206.02671",
    "authors": [
      "Leandro A. Passos",
      "Jo\u00e3o Paulo Papa",
      "Amir Hussain",
      "Ahsan Adeel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.03171",
    "title": "Look Back When Surprised: Stabilizing Reverse Experience Replay for  Neural Approximation",
    "abstract": " Title: Look Back When Surprised: Stabilizing Reverse Experience Replay for  Neural Approximation ",
    "url": "https://arxiv.org/abs/2206.03171",
    "authors": [
      "Ramnath Kumar",
      "Dheeraj Nagaraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05876",
    "title": "Description and Discussion on DCASE 2022 Challenge Task 2: Unsupervised  Anomalous Sound Detection for Machine Condition Monitoring Applying Domain  Generalization Techniques",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2106.04492 ",
    "url": "https://arxiv.org/abs/2206.05876",
    "authors": [
      "Kota Dohi",
      "Keisuke Imoto",
      "Noboru Harada",
      "Daisuke Niizumi",
      "Yuma Koizumi",
      "Tomoya Nishida",
      "Harsh Purohit",
      "Takashi Endo",
      "Masaaki Yamamoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.15316",
    "title": "Interpretable Anomaly Detection in Echocardiograms with Dynamic  Variational Trajectory Models",
    "abstract": " Comments: accepted at IMLH workshop ICML 2022 ",
    "url": "https://arxiv.org/abs/2206.15316",
    "authors": [
      "Alain Ryser",
      "Laura Manduchi",
      "Fabian Laumer",
      "Holger Michel",
      "Sven Wellmann",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.00610",
    "title": "A Temporal Fusion Transformer for Long-term Explainable Prediction of  Emergency Department Overcrowding",
    "abstract": " Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages ",
    "url": "https://arxiv.org/abs/2207.00610",
    "authors": [
      "Francisco M. Caldas",
      "Cl\u00e1udia Soares"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04308",
    "title": "Dynamic Time Warping based Adversarial Framework for Time-Series Domain",
    "abstract": " Comments: Accepted for publication at IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) ",
    "url": "https://arxiv.org/abs/2207.04308",
    "authors": [
      "Taha Belkhouja",
      "Yan Yan",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.00517",
    "title": "The Neural Process Family: Survey, Applications and Perspectives",
    "abstract": " Comments: 55 pages, 13 figures, Added up-to-date literature ",
    "url": "https://arxiv.org/abs/2209.00517",
    "authors": [
      "Saurav Jha",
      "Dong Gong",
      "Xuesong Wang",
      "Richard E. Turner",
      "Lina Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.02045",
    "title": "Visualization Of Class Activation Maps To Explain AI Classification Of  Network Packet Captures",
    "abstract": " Title: Visualization Of Class Activation Maps To Explain AI Classification Of  Network Packet Captures ",
    "url": "https://arxiv.org/abs/2209.02045",
    "authors": [
      "Igor Cherepanov",
      "Alex Ulmer",
      "Jonathan Geraldi Joewono",
      "J\u00f6rn Kohlhammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.04142",
    "title": "Joint Non-parametric Point Process model for Treatments and Outcomes:  Counterfactual Time-series Prediction Under Policy Interventions",
    "abstract": " Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 7 pages. This article is the extended abstract version of the long article arXiv:2209.04142v1 (previous version) ",
    "url": "https://arxiv.org/abs/2209.04142",
    "authors": [
      "\u00c7a\u011flar H\u0131zl\u0131",
      "ST John",
      "Anne Juuti",
      "Tuure Saarinen",
      "Kirsi Pietil\u00e4inen",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2209.06434",
    "title": "ConvNext Based Neural Network for Audio Anti-Spoofing",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2209.06434",
    "authors": [
      "Qiaowei Ma",
      "Jinghui Zhong",
      "Yitao Yang",
      "Weiheng Liu",
      "Ying Gao",
      "Wing W.Y. Ng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.09658",
    "title": "Lazy vs hasty: linearization in deep networks impacts learning schedule  based on example difficulty",
    "abstract": " Comments: 25 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2209.09658",
    "authors": [
      "Thomas George",
      "Guillaume Lajoie",
      "Aristide Baratin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.10411",
    "title": "Metaball-Imaging Discrete Element Lattice Boltzmann Method for  fluid-particle system of complex morphologies with settling case study",
    "abstract": " Title: Metaball-Imaging Discrete Element Lattice Boltzmann Method for  fluid-particle system of complex morphologies with settling case study ",
    "url": "https://arxiv.org/abs/2209.10411",
    "authors": [
      "Yifeng Zhao",
      "Pei Zhang",
      "Liang Lei",
      "S.A. Galindo-Torres",
      "Stan Z.Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2209.11767",
    "title": "Mental arithmetic task classification with convolutional neural network  based on spectral-temporal features from EEG",
    "abstract": " Comments: Updated Figure ",
    "url": "https://arxiv.org/abs/2209.11767",
    "authors": [
      "Zaineb Ajra",
      "Binbin Xu",
      "G\u00e9rard Dray",
      "Jacky Montmain",
      "Stephane Perrey"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2209.15425",
    "title": "Spikformer: When Spiking Neural Network Meets Transformer",
    "abstract": " Title: Spikformer: When Spiking Neural Network Meets Transformer ",
    "url": "https://arxiv.org/abs/2209.15425",
    "authors": [
      "Zhaokun Zhou",
      "Yuesheng Zhu",
      "Chao He",
      "Yaowei Wang",
      "Shuicheng Yan",
      "Yonghong Tian",
      "Li Yuan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15575",
    "title": "Match to Win: Analysing Sequences Lengths for Efficient Self-supervised  Learning in Speech and Audio",
    "abstract": " Title: Match to Win: Analysing Sequences Lengths for Efficient Self-supervised  Learning in Speech and Audio ",
    "url": "https://arxiv.org/abs/2209.15575",
    "authors": [
      "Yan Gao",
      "Javier Fernandez-Marques",
      "Titouan Parcollet",
      "Pedro P. B. de Gusmao",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.05979",
    "title": "Adversarial Speaker-Consistency Learning Using Untranscribed Speech Data  for Zero-Shot Multi-Speaker Text-to-Speech",
    "abstract": " Comments: APSIPA 2022 ",
    "url": "https://arxiv.org/abs/2210.05979",
    "authors": [
      "Byoung Jin Choi",
      "Myeonghun Jeong",
      "Minchan Kim",
      "Sung Hwan Mun",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.11833",
    "title": "Improving the Anomaly Detection in GPR Images by Fine-Tuning CNNs with  Synthetic Data",
    "abstract": " Title: Improving the Anomaly Detection in GPR Images by Fine-Tuning CNNs with  Synthetic Data ",
    "url": "https://arxiv.org/abs/2210.11833",
    "authors": [
      "Xiren Zhou",
      "Shikang Liu",
      "Ao Chen",
      "Yizhan Fan",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.16107",
    "title": "SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water",
    "abstract": " Title: SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water ",
    "url": "https://arxiv.org/abs/2210.16107",
    "authors": [
      "Xiaomin Lin",
      "Cheng Liu",
      "Allen Pattillo",
      "Miao Yu",
      "Yiannis Aloimonous"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.08229",
    "title": "CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning",
    "abstract": " Title: CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning ",
    "url": "https://arxiv.org/abs/2211.08229",
    "authors": [
      "Jinghuai Zhang",
      "Hongbin Liu",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08405",
    "title": "Using multimodal learning and deep generative models for corporate  bankruptcy prediction",
    "abstract": " Title: Using multimodal learning and deep generative models for corporate  bankruptcy prediction ",
    "url": "https://arxiv.org/abs/2211.08405",
    "authors": [
      "Rogelio A. Mancisidor"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.08864",
    "title": "PrivacyProber: Assessment and Detection of Soft-Biometric  Privacy-Enhancing Techniques",
    "abstract": " Title: PrivacyProber: Assessment and Detection of Soft-Biometric  Privacy-Enhancing Techniques ",
    "url": "https://arxiv.org/abs/2211.08864",
    "authors": [
      "Peter Rot",
      "Peter Peer",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10024",
    "title": "Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks",
    "abstract": " Title: Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks ",
    "url": "https://arxiv.org/abs/2211.10024",
    "authors": [
      "Stephen Casper",
      "Kaivalya Hariharan",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10381",
    "title": "Active Learning with Convolutional Gaussian Neural Processes for  Environmental Sensor Placement",
    "abstract": " Comments: Accepted to the NeurIPS 2022 Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems ",
    "url": "https://arxiv.org/abs/2211.10381",
    "authors": [
      "Tom R. Andersson",
      "Wessel P. Bruinsma",
      "Stratis Markou",
      "James Requeima",
      "Alejandro Coca-Castro",
      "Anna Vaughan",
      "Anna-Louise Ellis",
      "Matthew Lazzara",
      "Daniel C. Jones",
      "J. Scott Hosking",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10546",
    "title": "Evaluating COVID-19 Sequence Data Using Nearest-Neighbors Based Network  Model",
    "abstract": " Comments: Accepted at IEEE BigData 2022 ",
    "url": "https://arxiv.org/abs/2211.10546",
    "authors": [
      "Sarwan Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2211.10670",
    "title": "Towards Adversarial Robustness of Deep Vision Algorithms",
    "abstract": " Comments: PhD thesis ",
    "url": "https://arxiv.org/abs/2211.10670",
    "authors": [
      "Hanshu Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11070",
    "title": "Who Tracks Who? A Surveillance Capitalist Examination of Commercial  Bluetooth Tracking Networks",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2211.11070",
    "authors": [
      "Hongrui Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.11215",
    "title": "SegNeRF: 3D Part Segmentation with Neural Radiance Fields",
    "abstract": " Comments: Fixed abstract typo ",
    "url": "https://arxiv.org/abs/2211.11215",
    "authors": [
      "Jesus Zarzar",
      "Sara Rojas",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11220",
    "title": "STGlow: A Flow-based Generative Framework with Dual Graphormer for  Pedestrian Trajectory Prediction",
    "abstract": " Comments: 12 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2211.11220",
    "authors": [
      "Rongqin Liang",
      "Yuanman Li",
      "Jiantao Zhou",
      "Xia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11308",
    "title": "Novel transfer learning schemes based on Siamese networks and synthetic  data",
    "abstract": " Title: Novel transfer learning schemes based on Siamese networks and synthetic  data ",
    "url": "https://arxiv.org/abs/2211.11308",
    "authors": [
      "Dominik Stallmann",
      "Philip Kenneweg",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.11379",
    "title": "Modelling spatiotemporal turbulent dynamics with the convolutional  autoencoder echo state network",
    "abstract": " Title: Modelling spatiotemporal turbulent dynamics with the convolutional  autoencoder echo state network ",
    "url": "https://arxiv.org/abs/2211.11379",
    "authors": [
      "Alberto Racca",
      "Nguyen Anh Khoa Doan",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2211.11396",
    "title": "A Curriculum-Training-Based Strategy for Distributing Collocation Points  during Physics-Informed Neural Network Training",
    "abstract": " Title: A Curriculum-Training-Based Strategy for Distributing Collocation Points  during Physics-Informed Neural Network Training ",
    "url": "https://arxiv.org/abs/2211.11396",
    "authors": [
      "Marcus M\u00fcnzer",
      "Chris Bard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2211.11534",
    "title": "How Fraudster Detection Contributes to Robust Recommendation",
    "abstract": " Title: How Fraudster Detection Contributes to Robust Recommendation ",
    "url": "https://arxiv.org/abs/2211.11534",
    "authors": [
      "Yuni Lai",
      "Kai Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11646",
    "title": "NeRF-RPN: A general framework for object detection in NeRFs",
    "abstract": " Title: NeRF-RPN: A general framework for object detection in NeRFs ",
    "url": "https://arxiv.org/abs/2211.11646",
    "authors": [
      "Benran Hu",
      "Junkai Huang",
      "Yichen Liu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11673",
    "title": "Asymptotically Normal Estimation of Local Latent Network Curvature",
    "abstract": " Comments: 77 pages ",
    "url": "https://arxiv.org/abs/2211.11673",
    "authors": [
      "Steven Wilkins-Reeves",
      "Tyler McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.11711",
    "title": "CLAWSAT: Towards Both Robust and Accurate Code Models",
    "abstract": " Title: CLAWSAT: Towards Both Robust and Accurate Code Models ",
    "url": "https://arxiv.org/abs/2211.11711",
    "authors": [
      "Jinghan Jia",
      "Shashank Srikant",
      "Tamara Mitrovska",
      "Chuang Gan",
      "Shiyu Chang",
      "Sijia Liu",
      "Una-May O'Reilly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.11736",
    "title": "Robotic Skill Acquisition via Instruction Augmentation with  Vision-Language Models",
    "abstract": " Title: Robotic Skill Acquisition via Instruction Augmentation with  Vision-Language Models ",
    "url": "https://arxiv.org/abs/2211.11736",
    "authors": [
      "Ted Xiao",
      "Harris Chan",
      "Pierre Sermanet",
      "Ayzaan Wahid",
      "Anthony Brohan",
      "Karol Hausman",
      "Sergey Levine",
      "Jonathan Tompson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]