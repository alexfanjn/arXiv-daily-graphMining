[
  {
    "id": "arXiv:2211.05119",
    "title": "The $[1,0]$-twisted generalized Reed-Solomon code",
    "abstract": "In this paper, we not only give the parity check matrix for the $[1,0]$-twisted generalized Reed-Solomon (in short, TGRS) code, but also determine the weight distribution. Especially, we show that the $[1,0]$-TGRS code is not GRS or EGRS. Furthermore, we present a sufficient and necessary condition for any punctured code of the $[1,0]$-TGRS code to be self-orthogonal, and then construct several classes of self-dual or almost self-dual $[1,0]$-TGRS codes. Finally, basing on these self-dual or almost self-dual $[1,0]$-TGRS codes, we obtain some LCD $[1,0]$-TGRS codes. ",
    "url": "https://arxiv.org/abs/2211.05119",
    "authors": [
      "Canze Zhu",
      "Qunying Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.05120",
    "title": "Deep Learning based Computer Vision Methods for Complex Traffic  Environments Perception: A Review",
    "abstract": "Computer vision applications in intelligent transportation systems (ITS) and autonomous driving (AD) have gravitated towards deep neural network architectures in recent years. While performance seems to be improving on benchmark datasets, many real-world challenges are yet to be adequately considered in research. This paper conducted an extensive literature review on the applications of computer vision in ITS and AD, and discusses challenges related to data, models, and complex urban environments. The data challenges are associated with the collection and labeling of training data and its relevance to real world conditions, bias inherent in datasets, the high volume of data needed to be processed, and privacy concerns. Deep learning (DL) models are commonly too complex for real-time processing on embedded hardware, lack explainability and generalizability, and are hard to test in real-world settings. Complex urban traffic environments have irregular lighting and occlusions, and surveillance cameras can be mounted at a variety of angles, gather dirt, shake in the wind, while the traffic conditions are highly heterogeneous, with violation of rules and complex interactions in crowded scenarios. Some representative applications that suffer from these problems are traffic flow estimation, congestion detection, autonomous driving perception, vehicle interaction, and edge computing for practical deployment. The possible ways of dealing with the challenges are also explored while prioritizing practical deployment. ",
    "url": "https://arxiv.org/abs/2211.05120",
    "authors": [
      "Talha Azfar",
      "Jinlong Li",
      "Hongkai Yu",
      "Ruey Long Cheu",
      "Yisheng Lv",
      "Ruimin Ke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.05151",
    "title": "QCNN: Quadrature Convolutional Neural Network with Application to  Unstructured Data Compression",
    "abstract": "We present a new convolution layer for deep learning architectures which we call QuadConv -- an approximation to continuous convolution via quadrature. Our operator is developed explicitly for use on unstructured data, and accomplishes this by learning a continuous kernel that can be sampled at arbitrary locations. In the setting of neural compression, we show that a QuadConv-based autoencoder, resulting in a Quadrature Convolutional Neural Network (QCNN), can match the performance of standard discrete convolutions on structured uniform data, as in CNNs, and maintain this accuracy on unstructured data. ",
    "url": "https://arxiv.org/abs/2211.05151",
    "authors": [
      "Kevin Doherty",
      "Cooper Simpson",
      "Stephen Becker",
      "Alireza Doostan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.05184",
    "title": "Are All Edges Necessary? A Unified Framework for Graph Purification",
    "abstract": "Graph Neural Networks (GNNs) as deep learning models working on graph-structure data have achieved advanced performance in many works. However, it has been proved repeatedly that, not all edges in a graph are necessary for the training of machine learning models. In other words, some of the connections between nodes may bring redundant or even misleading information to downstream tasks. In this paper, we try to provide a method to drop edges in order to purify the graph data from a new perspective. Specifically, it is a framework to purify graphs with the least loss of information, under which the core problems are how to better evaluate the edges and how to delete the relatively redundant edges with the least loss of information. To address the above two problems, we propose several measurements for the evaluation and different judges and filters for the edge deletion. We also introduce a residual-iteration strategy and a surrogate model for measurements requiring unknown information. The experimental results show that our proposed measurements for KL divergence with constraints to maintain the connectivity of the graph and delete edges in an iterative way can find out the most edges while keeping the performance of GNNs. What's more, further experiments show that this method also achieves the best defense performance against adversarial attacks. ",
    "url": "https://arxiv.org/abs/2211.05184",
    "authors": [
      "Zishan Gu",
      "Jintang Li",
      "Liang Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05189",
    "title": "From NetLogo Modeling of Deterministic Random Walk to the Identification  of Asymmetric Saturation Time in Random Graphs",
    "abstract": "Interactive programming environments are powerful tools for promoting innovative network thinking, teaching complexity science, and exploring emergent phenomena. This paper reports on our recent development of the deterministic random walk model in NetLogo, a leading platform for computational thinking, eco-system thinking, and multi-agent cross-platform programming environment. The deterministic random walk is foundational to modeling dynamical processes on complex networks. Inspired by the temporal visualizations offered in NetLogo, we investigated the relationship between network topology and diffusion saturation time for the deterministic random walk model. Our analysis uncovers that in Erdos-Renyi graphs, the saturation time exhibits an asymmetric pattern with a considerable probability of occurrence. This behavior occurs when the hubs, defined as nodes with relatively higher number of connections, emerge in Erdos-Renyi graphs. Yet, our analysis yields that the Barabasi-Albert model hubs stabilize the the convergence time of the deterministic random walk model. These findings strongly suggest that depending on the dynamical process running on complex networks, complementing characteristics other than the degree need to be taken into account for considering a node as a hub. We have made our development open-source, available to the public at no cost at https://github.com/bravandi/NetLogo-Dynamical-Processes. ",
    "url": "https://arxiv.org/abs/2211.05189",
    "authors": [
      "Ayan Chatterjee",
      "Qingtao Cao",
      "Amirhossein Sajadi",
      "Babak Ravandi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.05200",
    "title": "Affordance detection with Dynamic-Tree Capsule Networks",
    "abstract": "Affordance detection from visual input is a fundamental step in autonomous robotic manipulation. Existing solutions to the problem of affordance detection rely on convolutional neural networks. However, these networks do not consider the spatial arrangement of the input data and miss parts-to-whole relationships. Therefore, they fall short when confronted with novel, previously unseen object instances or new viewpoints. One solution to overcome such limitations can be to resort to capsule networks. In this paper, we introduce the first affordance detection network based on dynamic tree-structured capsules for sparse 3D point clouds. We show that our capsule-based network outperforms current state-of-the-art models on viewpoint invariance and parts-segmentation of new object instances through a novel dataset we only used for evaluation and it is publicly available from github.com/gipfelen/DTCG-Net. In the experimental evaluation we will show that our algorithm is superior to current affordance detection methods when faced with grasping previously unseen objects thanks to our Capsule Network enforcing a parts-to-whole representation. ",
    "url": "https://arxiv.org/abs/2211.05200",
    "authors": [
      "Antonio Rodr\u00edguez-S\u00e1nchez",
      "Simon Haller-Seeber",
      "David Peer",
      "Chris Engelhardt",
      "Jakob Mittelberger",
      "Matteo Saveriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.05203",
    "title": "Data-driven Cyberattack Synthesis against Network Control Systems",
    "abstract": "Network Control Systems (NCSs) pose unique vulnerabilities to cyberattacks due to a heavy reliance on communication channels. These channels can be susceptible to eavesdropping, false data injection (FDI), and denial of service (DoS). As a result, smarter cyberattacks can employ a combination of techniques to cause degradation of the considered NCS performance. We consider a white-box cyberattack synthesis technique in which the attacker initially eavesdrops to gather system data, and constructs equivalent system model. We utilize the equivalent model to synthesize hybrid cyberattacks -- a combination of FDI and DoS attacks against the NCS. Reachable sets for the equivalent NCS model provide rapid, real-time directives towards selecting NCS agents to be attacked. The devised method provides a significantly more realistic approach toward cyberattack synthesis against NCSs with unknown parameters. We demonstrate the proposed method using a multi-aerial vehicle formation control scenario. ",
    "url": "https://arxiv.org/abs/2211.05203",
    "authors": [
      "Omanshu Thapliyal",
      "Inseok Hwang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.05232",
    "title": "MuMIC -- Multimodal Embedding for Multi-label Image Classification with  Tempered Sigmoid",
    "abstract": "Multi-label image classification is a foundational topic in various domains. Multimodal learning approaches have recently achieved outstanding results in image representation and single-label image classification. For instance, Contrastive Language-Image Pretraining (CLIP) demonstrates impressive image-text representation learning abilities and is robust to natural distribution shifts. This success inspires us to leverage multimodal learning for multi-label classification tasks, and benefit from contrastively learnt pretrained models. We propose the Multimodal Multi-label Image Classification (MuMIC) framework, which utilizes a hardness-aware tempered sigmoid based Binary Cross Entropy loss function, thus enables the optimization on multi-label objectives and transfer learning on CLIP. MuMIC is capable of providing high classification performance, handling real-world noisy data, supporting zero-shot predictions, and producing domain-specific image embeddings. In this study, a total of 120 image classes are defined, and more than 140K positive annotations are collected on approximately 60K Booking.com images. The final MuMIC model is deployed on Booking.com Content Intelligence Platform, and it outperforms other state-of-the-art models with 85.6% GAP@10 and 83.8% GAP on all 120 classes, as well as a 90.1% macro mAP score across 32 majority classes. We summarize the modeling choices which are extensively tested through ablation studies. To the best of our knowledge, we are the first to adapt contrastively learnt multimodal pretraining for real-world multi-label image classification problems, and the innovation can be transferred to other domains. ",
    "url": "https://arxiv.org/abs/2211.05232",
    "authors": [
      "Fengjun Wang",
      "Sarai Mizrachi",
      "Moran Beladev",
      "Guy Nadav",
      "Gil Amsalem",
      "Karen Lastmann Assaraf",
      "Hadas Harush Boker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05234",
    "title": "Generating Clear Images From Images With Distortions Caused by Adverse  Weather Using Generative Adversarial Networks",
    "abstract": "We presented a method for improving computer vision tasks on images affected by adverse weather conditions, including distortions caused by adherent raindrops. Overcoming the challenge of applying computer vision to images affected by adverse weather conditions is essential for autonomous vehicles utilizing RGB cameras. For this purpose, we trained an appropriate generative adversarial network and showed that it was effective at removing the effect of the distortions, in the context of image reconstruction and computer vision tasks. We showed that object recognition, a vital task for autonomous driving vehicles, is completely impaired by the distortions and occlusions caused by adherent raindrops and that performance can be restored by our de-raining model. The approach described in this paper could be applied to all adverse weather conditions. ",
    "url": "https://arxiv.org/abs/2211.05234",
    "authors": [
      "Nuriel Shalom Mor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05237",
    "title": "SimuShips -- A High Resolution Simulation Dataset for Ship Detection  with Precise Annotations",
    "abstract": "Obstacle detection is a fundamental capability of an autonomous maritime surface vessel (AMSV). State-of-the-art obstacle detection algorithms are based on convolutional neural networks (CNNs). While CNNs provide higher detection accuracy and fast detection speed, they require enormous amounts of data for their training. In particular, the availability of domain-specific datasets is a challenge for obstacle detection. The difficulty in conducting onsite experiments limits the collection of maritime datasets. Owing to the logistic cost of conducting on-site operations, simulation tools provide a safe and cost-efficient alternative for data collection. In this work, we introduce SimuShips, a publicly available simulation-based dataset for maritime environments. Our dataset consists of 9471 high-resolution (1920x1080) images which include a wide range of obstacle types, atmospheric and illumination conditions along with occlusion, scale and visible proportion variations. We provide annotations in the form of bounding boxes. In addition, we conduct experiments with YOLOv5 to test the viability of simulation data. Our experiments indicate that the combination of real and simulated images improves the recall for all classes by 2.9%. ",
    "url": "https://arxiv.org/abs/2211.05237",
    "authors": [
      "Minahil Raza",
      "Hanna Prokopova",
      "Samir Huseynzade",
      "Sepinoud Azimi",
      "Sebastien Lafond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.05249",
    "title": "QuerySnout: Automating the Discovery of Attribute Inference Attacks  against Query-Based Systems",
    "abstract": "Although query-based systems (QBS) have become one of the main solutions to share data anonymously, building QBSes that robustly protect the privacy of individuals contributing to the dataset is a hard problem. Theoretical solutions relying on differential privacy guarantees are difficult to implement correctly with reasonable accuracy, while ad-hoc solutions might contain unknown vulnerabilities. Evaluating the privacy provided by QBSes must thus be done by evaluating the accuracy of a wide range of privacy attacks. However, existing attacks require time and expertise to develop, need to be manually tailored to the specific systems attacked, and are limited in scope. In this paper, we develop QuerySnout (QS), the first method to automatically discover vulnerabilities in QBSes. QS takes as input a target record and the QBS as a black box, analyzes its behavior on one or more datasets, and outputs a multiset of queries together with a rule to combine answers to them in order to reveal the sensitive attribute of the target record. QS uses evolutionary search techniques based on a novel mutation operator to find a multiset of queries susceptible to lead to an attack, and a machine learning classifier to infer the sensitive attribute from answers to the queries selected. We showcase the versatility of QS by applying it to two attack scenarios, three real-world datasets, and a variety of protection mechanisms. We show the attacks found by QS to consistently equate or outperform, sometimes by a large margin, the best attacks from the literature. We finally show how QS can be extended to QBSes that require a budget, and apply QS to a simple QBS based on the Laplace mechanism. Taken together, our results show how powerful and accurate attacks against QBSes can already be found by an automated system, allowing for highly complex QBSes to be automatically tested \"at the pressing of a button\". ",
    "url": "https://arxiv.org/abs/2211.05249",
    "authors": [
      "Ana-Maria Cretu",
      "Florimond Houssiau",
      "Antoine Cully",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.05262",
    "title": "Stabilizing Machine Learning Prediction of Dynamics: Noise and  Noise-inspired Regularization",
    "abstract": "Recent work has shown that machine learning (ML) models can be trained to accurately forecast the dynamics of unknown chaotic dynamical systems. Such ML models can be used to produce both short-term predictions of the state evolution and long-term predictions of the statistical patterns of the dynamics (``climate''). Both of these tasks can be accomplished by employing a feedback loop, whereby the model is trained to predict forward one time step, then the trained model is iterated for multiple time steps with its output used as the input. In the absence of mitigating techniques, however, this technique can result in artificially rapid error growth, leading to inaccurate predictions and/or climate instability. In this article, we systematically examine the technique of adding noise to the ML model input during training as a means to promote stability and improve prediction accuracy. Furthermore, we introduce Linearized Multi-Noise Training (LMNT), a regularization technique that deterministically approximates the effect of many small, independent noise realizations added to the model input during training. Our case study uses reservoir computing, a machine-learning method using recurrent neural networks, to predict the spatiotemporal chaotic Kuramoto-Sivashinsky equation. We find that reservoir computers trained with noise or with LMNT produce climate predictions that appear to be indefinitely stable and have a climate very similar to the true system, while reservoir computers trained without regularization are unstable. Compared with other types of regularization that yield stability in some cases, we find that both short-term and climate predictions from reservoir computers trained with noise or with LMNT are substantially more accurate. Finally, we show that the deterministic aspect of our LMNT regularization facilitates fast hyperparameter tuning when compared to training with noise. ",
    "url": "https://arxiv.org/abs/2211.05262",
    "authors": [
      "Alexander Wikner",
      "Brian R. Hunt",
      "Joseph Harvey",
      "Michelle Girvan",
      "Edward Ott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2211.05273",
    "title": "BERT-Based Combination of Convolutional and Recurrent Neural Network for  Indonesian Sentiment Analysis",
    "abstract": "Sentiment analysis is the computational study of opinions and emotions ex-pressed in text. Deep learning is a model that is currently producing state-of-the-art in various application domains, including sentiment analysis. Many researchers are using a hybrid approach that combines different deep learning models and has been shown to improve model performance. In sentiment analysis, input in text data is first converted into a numerical representation. The standard method used to obtain a text representation is the fine-tuned embedding method. However, this method does not pay attention to each word's context in the sentence. Therefore, the Bidirectional Encoder Representation from Transformer (BERT) model is used to obtain text representations based on the context and position of words in sentences. This research extends the previous hybrid deep learning using BERT representation for Indonesian sentiment analysis. Our simulation shows that the BERT representation improves the accuracies of all hybrid architectures. The BERT-based LSTM-CNN also reaches slightly better accuracies than other BERT-based hybrid architectures. ",
    "url": "https://arxiv.org/abs/2211.05273",
    "authors": [
      "Hendri Murfi",
      "Syamsyuriani",
      "Theresia Gowandi",
      "Gianinna Ardaneswari",
      "Siti Nurrohmah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05276",
    "title": "PhotoFourier: A Photonic Joint Transform Correlator-Based Neural Network  Accelerator",
    "abstract": "The last few years have seen a lot of work to address the challenge of low-latency and high-throughput convolutional neural network inference. Integrated photonics has the potential to dramatically accelerate neural networks because of its low-latency nature. Combined with the concept of Joint Transform Correlator (JTC), the computationally expensive convolution functions can be computed instantaneously (time of flight of light) with almost no cost. This 'free' convolution computation provides the theoretical basis of the proposed PhotoFourier JTC-based CNN accelerator. PhotoFourier addresses a myriad of challenges posed by on-chip photonic computing in the Fourier domain including 1D lenses and high-cost optoelectronic conversions. The proposed PhotoFourier accelerator achieves more than 28X better energy-delay product compared to state-of-art photonic neural network accelerators. ",
    "url": "https://arxiv.org/abs/2211.05276",
    "authors": [
      "Shurui Li",
      "Hangbo Yang",
      "Chee Wei Wong",
      "Volker J. Sorger",
      "Puneet Gupta"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05278",
    "title": "Network Security Roadmap",
    "abstract": "Users may already have some perception of provided security based on experience with earlier generations. To maintain the stability and coherent integration of 5G services, it is imperative that security and privacy features prevalent in earlier generations are also present in 5G. However, it is not sufficient just to provide the same security features as in the legacy systems due to the new threat model introduced by the integration of new technologies like SDN, virtualization and SBA. 5G systems are expected to be more service-oriented. This suggests there will be an additional emphasis on security and privacy requirements that spawn from the new dimension of service-oriented security architecture. ",
    "url": "https://arxiv.org/abs/2211.05278",
    "authors": [
      "Praveen Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.05288",
    "title": "The Friendship Paradox and Social Network Participation",
    "abstract": "The friendship paradox implies that a person will, on average, have fewer friends than their friends do. Prior work has shown how the friendship paradox can lead to perception biases regarding behaviors that correlate with the number of friends: for example, people tend to perceive their friends as being more socially engaged than they are. Here, we investigate the consequences of this type of social comparison in the conceptual setting of content creation (\"sharing\") in an online social network. Suppose people compare the amount of feedback that their content receives to the amount of feedback that their friends' content receives, and suppose they modify their sharing behavior as a result of that comparison. How does that impact overall sharing on the social network over time? We run simulations over model-generated synthetic networks, assuming initially uniform sharing and feedback rates. Thus, people's initial modifications of their sharing behavior in response to social comparisons are entirely driven by the friendship paradox. These modifications induce inhomogeneities in sharing rates that can further alter perception biases. If people's responses to social comparisons are monotonic (i.e., the larger the disparity, the larger the modification in sharing behavior), our simulations suggest that overall sharing in the network gradually declines. Meanwhile, convex responses can sustain or grow overall sharing in the network. We focus entirely on synthetic graphs in the present work and have not yet extended our simulations to real-world network topologies. Nevertheless, we do discuss practical implications, such as how interventions can be tailored to sustain long-term sharing, even in the presence of adverse social-comparison effects. ",
    "url": "https://arxiv.org/abs/2211.05288",
    "authors": [
      "Ahmed Medhat",
      "Shankar Iyer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.05289",
    "title": "Combating Health Misinformation in Social Media: Characterization,  Detection, Intervention, and Open Issues",
    "abstract": "Social media has been one of the main information consumption sources for the public, allowing people to seek and spread information more quickly and easily. However, the rise of various social media platforms also enables the proliferation of online misinformation. In particular, misinformation in the health domain has significant impacts on our society such as the COVID-19 infodemic. Therefore, health misinformation in social media has become an emerging research direction that attracts increasing attention from researchers of different disciplines. Compared to misinformation in other domains, the key differences of health misinformation include the potential of causing actual harm to humans' bodies and even lives, the hardness to identify for normal people, and the deep connection with medical science. In addition, health misinformation on social media has distinct characteristics from conventional channels such as television on multiple dimensions including the generation, dissemination, and consumption paradigms. Because of the uniqueness and importance of combating health misinformation in social media, we conduct this survey to further facilitate interdisciplinary research on this problem. In this survey, we present a comprehensive review of existing research about online health misinformation in different disciplines. Furthermore, we also systematically organize the related literature from three perspectives: characterization, detection, and intervention. Lastly, we conduct a deep discussion on the pressing open issues of combating health misinformation in social media and provide future directions for multidisciplinary researchers. ",
    "url": "https://arxiv.org/abs/2211.05289",
    "authors": [
      "Canyu Chen",
      "Haoran Wang",
      "Matthew Shapiro",
      "Yunyu Xiao",
      "Fei Wang",
      "Kai Shu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.05294",
    "title": "Artificial Neural Network Solver for Time-Dependent Fokker-Planck  Equations",
    "abstract": "Stochastic differential equations play an important role in various applications when modeling systems that have either random perturbations or chaotic dynamics at faster time scales. The time evolution of the probability distribution of a stochastic differential equation is described by the Fokker-Planck equation, which is a second order parabolic partial differential equation. Previous work combined artificial neural network and Monte Carlo data to solve stationary Fokker-Planck equations. This paper extends this approach to time dependent Fokker-Planck equations. The focus is on the investigation of algorithms for training a neural network that has multi-scale loss functions. Additionally, a new approach for collocation point sampling is proposed. A few 1D and 2D numerical examples are demonstrated. ",
    "url": "https://arxiv.org/abs/2211.05294",
    "authors": [
      "Yao Li",
      "Caleb Meredith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.05304",
    "title": "Contrastive Self-Supervised Learning for Skeleton Representations",
    "abstract": "Human skeleton point clouds are commonly used to automatically classify and predict the behaviour of others. In this paper, we use a contrastive self-supervised learning method, SimCLR, to learn representations that capture the semantics of skeleton point clouds. This work focuses on systematically evaluating the effects that different algorithmic decisions (including augmentations, dataset partitioning and backbone architecture) have on the learned skeleton representations. To pre-train the representations, we normalise six existing datasets to obtain more than 40 million skeleton frames. We evaluate the quality of the learned representations with three downstream tasks: skeleton reconstruction, motion prediction, and activity classification. Our results demonstrate the importance of 1) combining spatial and temporal augmentations, 2) including additional datasets for encoder training, and 3) and using a graph neural network as an encoder. ",
    "url": "https://arxiv.org/abs/2211.05304",
    "authors": [
      "Nico Lingg",
      "Miguel Sarabia",
      "Luca Zappella",
      "Barry-John Theobald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05307",
    "title": "Winner Determination Algorithms for Graph Games with Matching Structures",
    "abstract": "Cram, Domineering, and Arc Kayles are well-studied combinatorial games. They are interpreted as edge-selecting-type games on graphs, and the selected edges during a game form a matching. In this paper, we define a generalized game called Colored Arc Kayles, which includes these games. Colored Arc Kayles is played on a graph whose edges are colored in black, white, or gray, and black (resp., white) edges can be selected only by the black (resp., white) player, although gray edges can be selected by both black and white players. We first observe that the winner determination for Colored Arc Kayles can be done in $O^*(2^n)$ time by a simple algorithm, where $n$ is the order of a graph. We then focus on the vertex cover number, which is linearly related to the number of turns, and show that Colored Arc Kayles, BW-Arc Kayles, and Arc Kayles are solved in time $O^*(1.4143^{\\tau^2+3.17\\tau})$, $O^*(1.3161^{\\tau^2+4{\\tau}})$, and $O^*(1.1893^{\\tau^2+6.34{\\tau}})$, respectively, where $\\tau$ is the vertex cover number. Furthermore, we present an $O^*((n/\\nu+1)^{\\nu})$-time algorithm for Arc Kayles, where $\\nu$ is neighborhood diversity. We finally show that Arc Kayles on trees can be solved in $O^* (2^{n/2})(=O(1.4143^n))$ time, which improves $O^*(3^{n/3})(=O(1.4423^n))$ by a direct adjustment of the analysis of Bodlaender et al.'s $O^*(3^{n/3})$-time algorithm for Node Kayles. ",
    "url": "https://arxiv.org/abs/2211.05307",
    "authors": [
      "Tesshu Hanaka",
      "Hironori Kiya",
      "Hirotaka Ono",
      "Kanae Yoshiwatari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2211.05308",
    "title": "Cancer-Net BCa: Breast Cancer Pathologic Complete Response Prediction  using Volumetric Deep Radiomic Features from Synthetic Correlated Diffusion  Imaging",
    "abstract": "Breast cancer is the second most common type of cancer in women in Canada and the United States, representing over 25% of all new female cancer cases. Neoadjuvant chemotherapy treatment has recently risen in usage as it may result in a patient having a pathologic complete response (pCR), and it can shrink inoperable breast cancer tumors prior to surgery so that the tumor becomes operable, but it is difficult to predict a patient's pathologic response to neoadjuvant chemotherapy. In this paper, we investigate the efficacy of leveraging learnt volumetric deep features from a newly introduced magnetic resonance imaging (MRI) modality called synthetic correlated diffusion imaging (CDI$^s$) for the purpose of pCR prediction. More specifically, we leverage a volumetric convolutional neural network to learn volumetric deep radiomic features from a pre-treatment cohort and construct a predictor based on the learnt features using the post-treatment response. As the first study to explore the utility of CDI$^s$ within a deep learning perspective for clinical decision support, we evaluated the proposed approach using the ACRIN-6698 study against those learnt using gold-standard imaging modalities, and found that the proposed approach can provide enhanced pCR prediction performance and thus may be a useful tool to aid oncologists in improving recommendation of treatment of patients. Subsequently, this approach to leverage volumetric deep radiomic features (which we name Cancer-Net BCa) can be further extended to other applications of CDI$^s$ in the cancer domain to further improve prediction performance. ",
    "url": "https://arxiv.org/abs/2211.05308",
    "authors": [
      "Chi-en Amy Tai",
      "Nedim Hodzic",
      "Nic Flanagan",
      "Hayden Gunraj",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05327",
    "title": "Ultraverse: Efficient Retroactive Operation for Attack Recovery in  Database Systems and Web Frameworks",
    "abstract": "Retroactive operation is an operation that changes a past operation in a series of committed ones (e.g., cancelling the past insertion of '5' into a queue committed at t=3). Retroactive operation has many important security applications such as attack recovery or private data removal (e.g., for GDPR compliance). While prior efforts designed retroactive algorithms for low-level data structures (e.g., queue, set), none explored retroactive operation for higher levels, such as database systems or web applications. This is challenging, because: (i) SQL semantics of database systems is complex; (ii) data records can flow through various web application components, such as HTML's DOM trees, server-side user request handlers, and client-side JavaScript code. We propose Ultraverse, the first retroactive operation framework comprised of two components: a database system and a web application framework. The former enables users to retroactively change committed SQL queries; the latter does the same for web applications with preserving correctness of application semantics. Our experimental results show that Ultraverse achieves 10.5x~693.3x speedup on retroactive database update compared to a regular DBMS's flashback and redo. ",
    "url": "https://arxiv.org/abs/2211.05327",
    "authors": [
      "Ronny Ko",
      "Chuan Xiao",
      "Makoto Onizuka",
      "Yihe Huang",
      "Zhiqiang Lin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.05345",
    "title": "Finding Triangles and Other Small Subgraphs in Geometric Intersection  Graphs",
    "abstract": "We consider problems related to finding short cycles, small cliques, small independent sets, and small subgraphs in geometric intersection graphs. We obtain a plethora of new results. For example: * For the intersection graph of $n$ line segments in the plane, we give algorithms to find a 3-cycle in $O(n^{1.408})$ time, a size-3 independent set in $O(n^{1.652})$ time, a 4-clique in near-$O(n^{24/13})$ time, and a $k$-clique (or any $k$-vertex induced subgraph) in $O(n^{0.565k+O(1)})$ time for any constant $k$; we can also compute the girth in near-$O(n^{3/2})$ time. * For the intersection graph of $n$ axis-aligned boxes in a constant dimension $d$, we give algorithms to find a 3-cycle in $O(n^{1.408})$ time for any $d$, a 4-clique (or any 4-vertex induced subgraph) in $O(n^{1.715})$ time for any $d$, a size-4 independent set in near-$O(n^{3/2})$ time for any $d$, a size-5 independent set in near-$O(n^{4/3})$ time for $d=2$, and a $k$-clique (or any $k$-vertex induced subgraph) in $O(n^{0.429k+O(1)})$ time for any $d$ and any constant $k$. * For the intersection graph of $n$ fat objects in any constant dimension $d$, we give an algorithm to find any $k$-vertex (non-induced) subgraph in $O(n\\log n)$ time for any constant $k$, generalizing a result by Kaplan, Klost, Mulzer, Roddity, Seiferth, and Sharir (1999) for 3-cycles in 2D disk graphs. A variety of techniques is used, including geometric range searching, biclique covers, \"high-low\" tricks, graph degeneracy and separators, and shifted quadtrees. We also prove a near-$\\Omega(n^{4/3})$ conditional lower bound for finding a size-4 independent set for boxes. ",
    "url": "https://arxiv.org/abs/2211.05345",
    "authors": [
      "Timothy M. Chan"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.05351",
    "title": "Biomedical Multi-hop Question Answering Using Knowledge Graph Embeddings  and Language Models",
    "abstract": "Biomedical knowledge graphs (KG) are heterogenous networks consisting of biological entities as nodes and relations between them as edges. These entities and relations are extracted from millions of research papers and unified in a single resource. The goal of biomedical multi-hop question-answering over knowledge graph (KGQA) is to help biologist and scientist to get valuable insights by asking questions in natural language. Relevant answers can be found by first understanding the question and then querying the KG for right set of nodes and relationships to arrive at an answer. To model the question, language models such as RoBERTa and BioBERT are used to understand context from natural language question. One of the challenges in KGQA is missing links in the KG. Knowledge graph embeddings (KGE) help to overcome this problem by encoding nodes and edges in a dense and more efficient way. In this paper, we use a publicly available KG called Hetionet which is an integrative network of biomedical knowledge assembled from 29 different databases of genes, compounds, diseases, and more. We have enriched this KG dataset by creating a multi-hop biomedical question-answering dataset in natural language for testing the biomedical multi-hop question-answering system and this dataset will be made available to the research community. The major contribution of this research is an integrated system that combines language models with KG embeddings to give highly relevant answers to free-form questions asked by biologists in an intuitive interface. Biomedical multi-hop question-answering system is tested on this data and results are highly encouraging. ",
    "url": "https://arxiv.org/abs/2211.05351",
    "authors": [
      "Dattaraj J. Rao",
      "Shraddha S. Mane",
      "Mukta A. Paliwal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.05352",
    "title": "3D-CSL: self-supervised 3D context similarity learning for  Near-Duplicate Video Retrieval",
    "abstract": "In this paper, we introduce 3D-CSL, a compact pipeline for Near-Duplicate Video Retrieval (NDVR), and explore a novel self-supervised learning strategy for video similarity learning. Most previous methods only extract video spatial features from frames separately and then design kinds of complex mechanisms to learn the temporal correlations among frame features. However, parts of spatiotemporal dependencies have already been lost. To address this, our 3D-CSL extracts global spatiotemporal dependencies in videos end-to-end with a 3D transformer and find a good balance between efficiency and effectiveness by matching on clip-level. Furthermore, we propose a two-stage self-supervised similarity learning strategy to optimize the entire network. Firstly, we propose PredMAE to pretrain the 3D transformer with video prediction task; Secondly, ShotMix, a novel video-specific augmentation, and FCS loss, a novel triplet loss, are proposed further promote the similarity learning results. The experiments on FIVR-200K and CC_WEB_VIDEO demonstrate the superiority and reliability of our method, which achieves the state-of-the-art performance on clip-level NDVR. ",
    "url": "https://arxiv.org/abs/2211.05352",
    "authors": [
      "Rui Deng",
      "Qian Wu",
      "Yuke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05359",
    "title": "A Reliable and Low Latency Synchronizing Middleware for Co-simulation of  a Heterogeneous Multi-Robot Systems",
    "abstract": "Search and rescue, wildfire monitoring, and flood/hurricane impact assessment are mission-critical services for recent IoT networks. Communication synchronization, dependability, and minimal communication jitter are major simulation and system issues for the time-based physics-based ROS simulator, event-based network-based wireless simulator, and complex dynamics of mobile and heterogeneous IoT devices deployed in actual environments. Simulating a heterogeneous multi-robot system before deployment is difficult due to synchronizing physics (robotics) and network simulators. Due to its master-based architecture, most TCP/IP-based synchronization middlewares use ROS1. A real-time ROS2 architecture with masterless packet discovery synchronizes robotics and wireless network simulations. A velocity-aware Transmission Control Protocol (TCP) technique for ground and aerial robots using Data Distribution Service (DDS) publish-subscribe transport minimizes packet loss, synchronization, transmission, and communication jitters. Gazebo and NS-3 simulate and test. Simulator-agnostic middleware. LOS/NLOS and TCP/UDP protocols tested our ROS2-based synchronization middleware for packet loss probability and average latency. A thorough ablation research replaced NS-3 with EMANE, a real-time wireless network simulator, and masterless ROS2 with master-based ROS1. Finally, we tested network synchronization and jitter using one aerial drone (Duckiedrone) and two ground vehicles (TurtleBot3 Burger) on different terrains in masterless (ROS2) and master-enabled (ROS1) clusters. Our middleware shows that a large-scale IoT infrastructure with a diverse set of stationary and robotic devices can achieve low-latency communications (12% and 11% reduction in simulation and real) while meeting mission-critical application reliability (10% and 15% packet loss reduction) and high-fidelity requirements. ",
    "url": "https://arxiv.org/abs/2211.05359",
    "authors": [
      "Emon Dey",
      "Mikolaj Walczak",
      "Mohammad Saeid Anwar",
      "Nirmalya Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.05363",
    "title": "EMOFAKE: An Initial Dataset For Emotion Fake Audio Detection",
    "abstract": "There are already some datasets used for fake audio detection, such as the ASVspoof and ADD datasets. However, these databases do not consider a situation that the emotion of the audio has been changed from one to another, while other information (e.g. speaker identity and content) remains the same. Changing emotions often leads to semantic changes. This may be a great threat to social stability. Therefore, this paper reports our progress in developing such an emotion fake audio detection dataset involving changing emotion state of the original audio. The dataset is named EmoFake. The fake audio in EmoFake is generated using the state-of-the-art emotion voice conversion models. Some benchmark experiments are conducted on this dataset. The results show that our designed dataset poses a challenge to the LCNN and RawNet2 baseline models of ASVspoof 2021. ",
    "url": "https://arxiv.org/abs/2211.05363",
    "authors": [
      "Yan Zhao",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Chenglong Wang",
      "Chu Yuan Zhang",
      "Tao Wang",
      "Yongfeng Dong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.05364",
    "title": "Efficient Unsupervised Video Object Segmentation Network Based on Motion  Guidance",
    "abstract": "Considerable unsupervised video object segmentation algorithms based on deep learning have the problem of substantive model parameters and computation, which significantly limits the application of the algorithm in practice. This paper proposes a video object segmentation network based on motion guidance, considerably reducing the number of model parameters and computation and improving the video object segmentation performance. The model comprises a dual-stream network, motion guidance module, and multi-scale progressive fusion module. Specifically, RGB images and optical flow estimation are fed into dual-stream network to extract object appearance features and motion features. Then, the motion guidance module extracts the semantic information from the motion features through local attention, which guides the appearance features to learn rich semantic information. Finally, the multi-scale progressive fusion module obtains the output features at each stage of the dual-stream network. It gradually integrates the deep features into the shallow ones yet improves the edge segmentation effect. In this paper, numerous evaluations are conducted on three standard datasets, and the experimental results prove the superior performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2211.05364",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05368",
    "title": "A Comprehensive Survey on Distributed Training of Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have been demonstrated to be a powerful algorithmic model in broad application fields for their effectiveness in learning over graphs. To scale GNN training up for large-scale and ever-growing graphs, the most promising solution is distributed training which distributes the workload of training across multiple computing nodes. However, the workflows, computational patterns, communication patterns, and optimization techniques of distributed GNN training remain preliminarily understood. In this paper, we provide a comprehensive survey of distributed GNN training by investigating various optimization techniques used in distributed GNN training. First, distributed GNN training is classified into several categories according to their workflows. In addition, their computational patterns and communication patterns, as well as the optimization techniques proposed by recent work are introduced. Second, the software frameworks and hardware platforms of distributed GNN training are also introduced for a deeper understanding. Third, distributed GNN training is compared with distributed training of deep neural networks, emphasizing the uniqueness of distributed GNN training. Finally, interesting issues and opportunities in this field are discussed. ",
    "url": "https://arxiv.org/abs/2211.05368",
    "authors": [
      "Haiyang Lin",
      "Mingyu Yan",
      "Xiaochun Ye",
      "Dongrui Fan",
      "Shirui Pan",
      "Wenguang Chen",
      "Yuan Xie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05371",
    "title": "MSDT: Masked Language Model Scoring Defense in Text Domain",
    "abstract": "Pre-trained language models allowed us to process downstream tasks with the help of fine-tuning, which aids the model to achieve fairly high accuracy in various Natural Language Processing (NLP) tasks. Such easily-downloaded language models from various websites empowered the public users as well as some major institutions to give a momentum to their real-life application. However, it was recently proven that models become extremely vulnerable when they are backdoor attacked with trigger-inserted poisoned datasets by malicious users. The attackers then redistribute the victim models to the public to attract other users to use them, where the models tend to misclassify when certain triggers are detected within the training sample. In this paper, we will introduce a novel improved textual backdoor defense method, named MSDT, that outperforms the current existing defensive algorithms in specific datasets. The experimental results illustrate that our method can be effective and constructive in terms of defending against backdoor attack in text domain. Code is available at https://github.com/jcroh0508/MSDT. ",
    "url": "https://arxiv.org/abs/2211.05371",
    "authors": [
      "Jaechul Roh",
      "Minhao Cheng",
      "Yajun Fang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.05372",
    "title": "Multi-Scenario Bimetric-Balanced IoT Resource Allocation: An  Evolutionary Approach",
    "abstract": "In this paper, we allocate IoT devices as resources for smart services with time-constrained resource requirements. The allocation method named as BRAD can work under multiple resource scenarios with diverse resource richnesses, availabilities and costs, such as the intelligent healthcare system deployed by Harbin Institute of Technology (HIT-IHC). The allocation aims for bimetric-balancing under the multi-scenario case, i.e., the profit and cost associated with service satisfaction are jointly optimised and balanced wisely. Besides, we abstract IoT devices as digital objects (DO) to make them easier to interact with during resource allocation. Considering that the problem is NP-Hard and the optimisation objective is not differentiable, we utilise Grey Wolf Optimisation (GWO) algorithm as the model optimiser. Specifically, we tackle the deficiencies of GWO and significantly improve its performance by introducing three new mechanisms to form the BRAD-GWA algorithm. Comprehensive experiments are conducted on realistic HIT-IHC IoT testbeds and several algorithms are compared, including the allocation method originally used by HIT-IHC system to verify the effectiveness of the BRAD-GWA. The BRAD-GWA achieves a 3.14 times and 29.6% objective reduction compared with the HIT-IHC and the original GWO algorithm, respectively. ",
    "url": "https://arxiv.org/abs/2211.05372",
    "authors": [
      "Jiashu Wu",
      "Hao Dai",
      "Yang Wang",
      "Zhiying Tu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.05385",
    "title": "GANStrument: Adversarial Instrument Sound Synthesis with Pitch-invariant  Instance Conditioning",
    "abstract": "We propose GANStrument, a generative adversarial model for instrument sound synthesis. Given a one-shot sound as input, it is able to generate pitched instrument sounds that reflect the timbre of the input within an interactive time. By exploiting instance conditioning, GANStrument achieves better fidelity and diversity of synthesized sounds and generalization ability to various inputs. In addition, we introduce an adversarial training scheme for a pitch-invariant feature extractor that significantly improves the pitch accuracy and timbre consistency. Experimental results show that GANStrument outperforms strong baselines that do not use instance conditioning in terms of generation quality and input editability. Qualitative examples are available online. ",
    "url": "https://arxiv.org/abs/2211.05385",
    "authors": [
      "Gaku Narita",
      "Junichi Shimizu",
      "Taketo Akama"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.05396",
    "title": "Learning Visual Representation of Underwater Acoustic Imagery Using  Transformer-Based Style Transfer Method",
    "abstract": "Underwater automatic target recognition (UATR) has been a challenging research topic in ocean engineering. Although deep learning brings opportunities for target recognition on land and in the air, underwater target recognition techniques based on deep learning have lagged due to sensor performance and the size of trainable data. This letter proposed a framework for learning the visual representation of underwater acoustic imageries, which takes a transformer-based style transfer model as the main body. It could replace the low-level texture features of optical images with the visual features of underwater acoustic imageries while preserving their raw high-level semantic content. The proposed framework could fully use the rich optical image dataset to generate a pseudo-acoustic image dataset and use it as the initial sample to train the underwater acoustic target recognition model. The experiments select the dual-frequency identification sonar (DIDSON) as the underwater acoustic data source and also take fish, the most common marine creature, as the research subject. Experimental results show that the proposed method could generate high-quality and high-fidelity pseudo-acoustic samples, achieve the purpose of acoustic data enhancement and provide support for the underwater acoustic-optical images domain transfer research. ",
    "url": "https://arxiv.org/abs/2211.05396",
    "authors": [
      "Xiaoteng Zhou",
      "Changli Yu",
      "Shihao Yuan",
      "Xin Yuan",
      "Hangchi Yu",
      "Citong Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.05400",
    "title": "onlineFGO: Online Continuous-Time Factor Graph Optimization with  Time-Centric Multi-Sensor Fusion for Robust Localization in Large-Scale  Environments",
    "abstract": "Accurate and consistent vehicle localization in urban areas is challenging due to the large-scale and complicated environments. In this paper, we propose onlineFGO, a novel time-centric graph-optimization-based localization method that fuses multiple sensor measurements with the continuous-time trajectory representation for vehicle localization tasks. We generalize the graph construction independent of any spatial sensor measurements by creating the states deterministically on time. As the trajectory representation in continuous-time enables querying states at arbitrary times, incoming sensor measurements can be factorized on the graph without requiring state alignment. We integrate different GNSS observations: pseudorange, deltarange, and time-differenced carrier phase (TDCP) to ensure global reference and fuse the relative motion from a LiDAR-odometry to improve the localization consistency while GNSS observations are not available. Experiments on general performance, effects of different factors, and hyper-parameter settings are conducted in a real-world measurement campaign in Aachen city that contains different urban scenarios. Our results show an average 2D error of 0.99m and consistent state estimation in urban scenarios. ",
    "url": "https://arxiv.org/abs/2211.05400",
    "authors": [
      "Haoming Zhang",
      "Felix Widmayer",
      "Lars L\u00fcnnemann",
      "Dirk Abel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.05403",
    "title": "Zebra: Deeply Integrating System-Level Provenance Search and Tracking  for Efficient Attack Investigation",
    "abstract": "System auditing has emerged as a key approach for monitoring system call events and investigating sophisticated attacks. Based on the collected audit logs, research has proposed to search for attack patterns or track the causal dependencies of system events to reveal the attack sequence. However, existing approaches either cannot reveal long-range attack sequences or suffer from the dependency explosion problem due to a lack of focus on attack-relevant parts, and thus are insufficient for investigating complex attacks. To bridge the gap, we propose Zebra, a system that synergistically integrates attack pattern search and causal dependency tracking for efficient attack investigation. With Zebra, security analysts can alternate between search and tracking to reveal the entire attack sequence in a progressive, user-guided manner, while mitigating the dependency explosion problem by prioritizing the attack-relevant parts. To enable this, Zebra provides (1) an expressive and concise domain-specific language, Tstl, for performing various types of search and tracking analyses, and (2) an optimized language execution engine for efficient execution over a big amount of auditing data. Evaluations on a broad set of attack cases demonstrate the effectiveness of Zebra in facilitating a timely attack investigation. ",
    "url": "https://arxiv.org/abs/2211.05403",
    "authors": [
      "Xinyu Yang",
      "Haoyuan Liu",
      "Ziyu Wang",
      "Peng Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2211.05412",
    "title": "Desire Backpropagation: A Lightweight Training Algorithm for Multi-Layer  Spiking Neural Networks based on Spike-Timing-Dependent Plasticity",
    "abstract": "Spiking neural networks (SNN) are a viable alternative to conventional artificial neural networks when energy efficiency and computational complexity are of importance. A major advantage of SNNs is their binary information transfer through spike trains. The training of SNN has, however, been a challenge, since neuron models are non-differentiable and traditional gradient-based backpropagation algorithms cannot be applied directly. Furthermore, spike-timing-dependent plasticity (STDP), albeit being a spike-based learning rule, updates weights locally and does not optimize for the output error of the network. We present desire backpropagation, a method to derive the desired spike activity of neurons from the output error. The loss function can then be evaluated locally for every neuron. Incorporating the desire values into the STDP weight update leads to global error minimization and increasing classification accuracy. At the same time, the neuron dynamics and computational efficiency of STDP are maintained, making it a spike-based supervised learning rule. We trained three-layer networks to classify MNIST and Fashion-MNIST images and reached an accuracy of 98.41% and 87.56%, respectively. Furthermore, we show that desire backpropagation is computationally less complex than backpropagation in traditional neural networks. ",
    "url": "https://arxiv.org/abs/2211.05412",
    "authors": [
      "Daniel Gerlinghoff",
      "Tao Luo",
      "Rick Siow Mong Goh",
      "Weng-Fai Wong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2211.05427",
    "title": "On the Privacy Risks of Algorithmic Recourse",
    "abstract": "As predictive models are increasingly being employed to make consequential decisions, there is a growing emphasis on developing techniques that can provide algorithmic recourse to affected individuals. While such recourses can be immensely beneficial to affected individuals, potential adversaries could also exploit these recourses to compromise privacy. In this work, we make the first attempt at investigating if and how an adversary can leverage recourses to infer private information about the underlying model's training data. To this end, we propose a series of novel membership inference attacks which leverage algorithmic recourse. More specifically, we extend the prior literature on membership inference attacks to the recourse setting by leveraging the distances between data instances and their corresponding counterfactuals output by state-of-the-art recourse methods. Extensive experimentation with real world and synthetic datasets demonstrates significant privacy leakage through recourses. Our work establishes unintended privacy leakage as an important risk in the widespread adoption of recourse methods. ",
    "url": "https://arxiv.org/abs/2211.05427",
    "authors": [
      "Martin Pawelczyk",
      "Himabindu Lakkaraju",
      "Seth Neel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.05429",
    "title": "DrawMon: A Distributed System for Detection of Atypical Sketch Content  in Concurrent Pictionary Games",
    "abstract": "Pictionary, the popular sketch-based guessing game, provides an opportunity to analyze shared goal cooperative game play in restricted communication settings. However, some players occasionally draw atypical sketch content. While such content is occasionally relevant in the game context, it sometimes represents a rule violation and impairs the game experience. To address such situations in a timely and scalable manner, we introduce DrawMon, a novel distributed framework for automatic detection of atypical sketch content in concurrently occurring Pictionary game sessions. We build specialized online interfaces to collect game session data and annotate atypical sketch content, resulting in AtyPict, the first ever atypical sketch content dataset. We use AtyPict to train CanvasNet, a deep neural atypical content detection network. We utilize CanvasNet as a core component of DrawMon. Our analysis of post deployment game session data indicates DrawMon's effectiveness for scalable monitoring and atypical sketch content detection. Beyond Pictionary, our contributions also serve as a design guide for customized atypical content response systems involving shared and interactive whiteboards. Code and datasets are available at https://drawm0n.github.io. ",
    "url": "https://arxiv.org/abs/2211.05429",
    "authors": [
      "Nikhil Bansal",
      "Kartik Gupta",
      "Kiruthika Kannan",
      "Sivani Pentapati",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.05432",
    "title": "Speech Enhancement with Fullband-Subband Cross-Attention Network",
    "abstract": "FullSubNet has shown its promising performance on speech enhancement by utilizing both fullband and subband information. However, the relationship between fullband and subband in FullSubNet is achieved by simply concatenating the output of fullband model and subband units. It only supplements the subband units with a small quantity of global information and has not considered the interaction between fullband and subband. This paper proposes a fullband-subband cross-attention (FSCA) module to interactively fuse the global and local information and applies it to FullSubNet. This new framework is called as FS-CANet. Moreover, different from FullSubNet, the proposed FS-CANet optimize the fullband extractor by temporal convolutional network (TCN) blocks to further reduce the model size. Experimental results on DNS Challenge - Interspeech 2021 dataset show that the proposed FS-CANet outperforms other state-of-the-art speech enhancement approaches, and demonstrate the effectiveness of fullband-subband cross-attention. ",
    "url": "https://arxiv.org/abs/2211.05432",
    "authors": [
      "Jun Chen",
      "Wei Rao",
      "Zilin Wang",
      "Zhiyong Wu",
      "Yannan Wang",
      "Tao Yu",
      "Shidong Shang",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.05441",
    "title": "Semantic Learning and Emulation Based Cross-platform Binary  Vulnerability Seeker",
    "abstract": "Clone detection is widely exploited for software vulnerability search. The approaches based on source code analysis cannot be applied to binary clone detection because the same source code can produce significantly different binaries. In this paper, we present BinSeeker, a cross-platform binary seeker that integrates semantic learning and emulation. With the help of the labeled semantic flow graph, BinSeeker can quickly identify M candidate functions that are most similar to the vulnerability from the target binary. The value of M is relatively large so this semantic learning procedure essentially eliminates those functions that are very unlikely to have the vulnerability. Then, semantic emulation is conducted on these M candidates to obtain their dynamic signature sequences. By comparing signature sequences, BinSeeker produces top-N functions that exhibit most similar behavior to that of the vulnerability. With fast filtering of semantic learning and accurate comparison of semantic emulation, BinSeeker seeks vulnerability precisely with little overhead. The experiments on six widely used programs with fifteen known CVE vulnerabilities demonstrate that BinSeeker outperforms three state-of-the-art tools Genius, Gemini and CACompare. Regarding search accuracy, BinSeeker achieves an MRR value of 0.65 in the target programs, whereas the MRR values by Genius, Gemini and CACompare are 0.17, 0.07 and 0.42, respectively. If we consider ranking a function with the targeted vulnerability in the top-5 as accurate, BinSeeker achieves the accuracy of 93.33 percent, while the accuracy of the other three tools is merely 33.33, 13.33 and 53.33 percent, respectively. Such accuracy is achieved with 0.27s on average to determine whether the target binary function contains a known vulnerability, and the time for the other three tools are 1.57s, 0.15s and 0.98s, respectively. ",
    "url": "https://arxiv.org/abs/2211.05441",
    "authors": [
      "Jian Gao",
      "Yu Jiang",
      "Zhe Liu",
      "Xin Yang",
      "Cong Wang",
      "Xun Jiao",
      "Zijiang Yang",
      "Jiaguang Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.05446",
    "title": "Privacy-Utility Balanced Voice De-Identification Using Adversarial  Examples",
    "abstract": "Faced with the threat of identity leakage during voice data publishing, users are engaged in a privacy-utility dilemma when enjoying convenient voice services. Existing studies employ direct modification or text-based re-synthesis to de-identify users' voices, but resulting in inconsistent audibility in the presence of human participants. In this paper, we propose a voice de-identification system, which uses adversarial examples to balance the privacy and utility of voice services. Instead of typical additive examples inducing perceivable distortions, we design a novel convolutional adversarial example that modulates perturbations into real-world room impulse responses. Benefit from this, our system could preserve user identity from exposure by Automatic Speaker Identification (ASI) while remaining the voice perceptual quality for non-intrusive de-identification. Moreover, our system learns a compact speaker distribution through a conditional variational auto-encoder to sample diverse target embeddings on demand. Combining diverse target generation and input-specific perturbation construction, our system enables any-to-any identify transformation for adaptive de-identification. Experimental results show that our system could achieve 98% and 79% successful de-identification on mainstream ASIs and commercial systems with an objective Mel cepstral distortion of 4.31dB and a subjective mean opinion score of 4.48. ",
    "url": "https://arxiv.org/abs/2211.05446",
    "authors": [
      "Meng Chen",
      "Li Lu",
      "Jiadi Yu",
      "Yingying Chen",
      "Zhongjie Ba",
      "Feng Lin",
      "Kui Ren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.05486",
    "title": "HSGNet: Object Re-identification with Hierarchical Similarity Graph  Network",
    "abstract": "Object re-identification method is made up of backbone network, feature aggregation, and loss function. However, most backbone networks lack a special mechanism to handle rich scale variations and mine discriminative feature representations. In this paper, we firstly design a hierarchical similarity graph module (HSGM) to reduce the conflict of backbone and re-identification networks. The designed HSGM builds a rich hierarchical graph to mine the mapping relationships between global-local and local-local. Secondly, we divide the feature map along with the spatial and channel directions in each hierarchical graph. The HSGM applies the spatial features and channel features extracted from different locations as nodes, respectively, and utilizes the similarity scores between nodes to construct spatial and channel similarity graphs. During the learning process of HSGM, we utilize a learnable parameter to re-optimize the importance of each position, as well as evaluate the correlation between different nodes. Thirdly, we develop a novel hierarchical similarity graph network (HSGNet) by embedding the HSGM in the backbone network. Furthermore, HSGM can be easily embedded into backbone networks of any depth to improve object re-identification ability. Finally, extensive experiments on three large-scale object datasets demonstrate that the proposed HSGNet is superior to state-of-the-art object re-identification approaches. ",
    "url": "https://arxiv.org/abs/2211.05486",
    "authors": [
      "Fei Shen",
      "Mengwan Wei",
      "Junchi Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05488",
    "title": "ClassPruning: Speed Up Image Restoration Networks by Dynamic N:M Pruning",
    "abstract": "Image restoration tasks have achieved tremendous performance improvements with the rapid advancement of deep neural networks. However, most prevalent deep learning models perform inference statically, ignoring that different images have varying restoration difficulties and lightly degraded images can be well restored by slimmer subnetworks. To this end, we propose a new solution pipeline dubbed ClassPruning that utilizes networks with different capabilities to process images with varying restoration difficulties. In particular, we use a lightweight classifier to identify the image restoration difficulty, and then the sparse subnetworks with different capabilities can be sampled based on predicted difficulty by performing dynamic N:M fine-grained structured pruning on base restoration networks. We further propose a novel training strategy along with two additional loss terms to stabilize training and improve performance. Experiments demonstrate that ClassPruning can help existing methods save approximately 40% FLOPs while maintaining performance. ",
    "url": "https://arxiv.org/abs/2211.05488",
    "authors": [
      "Yang Zhou",
      "Yuda Song",
      "Hui Qian",
      "Xin Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05494",
    "title": "Two conjectures on the Stokes complex in three dimensions on Freudenthal  meshes",
    "abstract": "In recent years a great deal of attention has been paid to discretizations of the incompressible Stokes equations that exactly preserve the incompressibility constraint. These are of substantial interest because these discretizations are pressure-robust, i.e. the error estimates for the velocity do not depend on the error in the pressure. Similar considerations arise in nearly incompressible linear elastic solids. Conforming discretizations with this property are now well understood in two dimensions, but remain poorly understood in three dimensions. In this work we state two conjectures on this subject. The first is that the Scott-Vogelius element pair is inf-sup stable on uniform meshes for velocity degree $k \\ge 4$; the best result available in the literature is for $k \\ge 6$. The second is that there exists a stable space decomposition of the kernel of the divergence for $k \\ge 5$. We present numerical evidence supporting our conjectures. ",
    "url": "https://arxiv.org/abs/2211.05494",
    "authors": [
      "Patrick E. Farrell",
      "Lawrence Mitchell",
      "L. Ridgway Scott"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.05497",
    "title": "Effect of Device Mismatches in Differential Oscillatory Neural Networks",
    "abstract": "Analog implementation of Oscillatory Neural Networks (ONNs) has the potential to implement fast and ultra-low-power computing capabilities. One of the drawbacks of analog implementation is component mismatches which cause desynchronization and instability in ONNs. Emerging devices like memristors and VO2 are particularly prone to variations. In this paper, we study the effect of component mismatches on the performance of differential ONNs (DONNs). Mismatches were considered in two main blocks: differential oscillatory neurons and synaptic circuits. To measure DONN tolerance to mismatches in each block, performance was evaluated with mismatches being present separately in each block. Memristor-bridge circuits with four memristors were used as the synaptic circuits. The differential oscillatory neurons were based on VO2-devices. The simulation results showed that DONN performance was more vulnerable to mismatches in the components of the differential oscillatory neurons than to mismatches in the synaptic circuits. DONNs were found to tolerate up to 20% mismatches in the memristance of the synaptic circuits. However, mismatches in the differential oscillatory neurons resulted in non-uniformity of the natural frequencies, causing desynchronization and instability. Simulations showed that 0.5% relative standard deviation (RSD) in natural frequencies can reduce DONN performance dramatically. In addition, sensitivity analyses showed that the high threshold voltage of VO2-devices is the most sensitive parameter for frequency non-uniformity and desynchronization. ",
    "url": "https://arxiv.org/abs/2211.05497",
    "authors": [
      "Jafar Shamsi",
      "Mar\u00eda Jos\u00e9 Avedillo",
      "Bernab\u00e9 Linares-Barranco",
      "Teresa Serrano-Gotarredona"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.05520",
    "title": "Unravelling the Performance of Physics-informed Graph Neural Networks  for Dynamical Systems",
    "abstract": "Recently, graph neural networks have been gaining a lot of attention to simulate dynamical systems due to their inductive nature leading to zero-shot generalizability. Similarly, physics-informed inductive biases in deep-learning frameworks have been shown to give superior performance in learning the dynamics of physical systems. There is a growing volume of literature that attempts to combine these two approaches. Here, we evaluate the performance of thirteen different graph neural networks, namely, Hamiltonian and Lagrangian graph neural networks, graph neural ODE, and their variants with explicit constraints and different architectures. We briefly explain the theoretical formulation highlighting the similarities and differences in the inductive biases and graph architecture of these systems. We evaluate these models on spring, pendulum, gravitational, and 3D deformable solid systems to compare the performance in terms of rollout error, conserved quantities such as energy and momentum, and generalizability to unseen system sizes. Our study demonstrates that GNNs with additional inductive biases, such as explicit constraints and decoupling of kinetic and potential energies, exhibit significantly enhanced performance. Further, all the physics-informed GNNs exhibit zero-shot generalizability to system sizes an order of magnitude larger than the training system, thus providing a promising route to simulate large-scale realistic systems. ",
    "url": "https://arxiv.org/abs/2211.05520",
    "authors": [
      "Abishek Thangamuthu",
      "Gunjan Kumar",
      "Suresh Bishnoi",
      "Ravinder Bhattoo",
      "N M Anoop Krishnan",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.05521",
    "title": "Zero-shot Visual Commonsense Immorality Prediction",
    "abstract": "Artificial intelligence is currently powering diverse real-world applications. These applications have shown promising performance, but raise complicated ethical issues, i.e. how to embed ethics to make AI applications behave morally. One way toward moral AI systems is by imitating human prosocial behavior and encouraging some form of good behavior in systems. However, learning such normative ethics (especially from images) is challenging mainly due to a lack of data and labeling complexity. Here, we propose a model that predicts visual commonsense immorality in a zero-shot manner. We train our model with an ETHICS dataset (a pair of text and morality annotation) via a CLIP-based image-text joint embedding. In a testing phase, the immorality of an unseen image is predicted. We evaluate our model with existing moral/immoral image datasets and show fair prediction performance consistent with human intuitions. Further, we create a visual commonsense immorality benchmark with more general and extensive immoral visual contents. Codes and dataset are available at https://github.com/ku-vai/Zero-shot-Visual-Commonsense-Immorality-Prediction. Note that this paper might contain images and descriptions that are offensive in nature. ",
    "url": "https://arxiv.org/abs/2211.05521",
    "authors": [
      "Yujin Jeong",
      "Seongbeom Park",
      "Suhong Moon",
      "Jinkyu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.05523",
    "title": "Impact of Adversarial Training on Robustness and Generalizability of  Language Models",
    "abstract": "Adversarial training is widely acknowledged as the most effective defense against adversarial attacks. However, it is also well established that achieving both robustness and generalization in adversarially trained models involves a trade-off. The goal of this work is to provide an in depth comparison of different approaches for adversarial training in language models. Specifically, we study the effect of pre-training data augmentation as well as training time input perturbations vs. embedding space perturbations on the robustness and generalization of BERT-like language models. Our findings suggest that better robustness can be achieved by pre-training data augmentation or by training with input space perturbation. However, training with embedding space perturbation significantly improves generalization. A linguistic correlation analysis of neurons of the learned models reveal that the improved generalization is due to `more specialized' neurons. To the best of our knowledge, this is the first work to carry out a deep qualitative analysis of different methods of generating adversarial examples in adversarial training of language models. ",
    "url": "https://arxiv.org/abs/2211.05523",
    "authors": [
      "Enes Altinisik",
      "Hassan Sajjad",
      "Husrev Taha Sencar",
      "Safa Messaoud",
      "Sanjay Chawla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.05525",
    "title": "MGiaD: Multigrid in all dimensions. Efficiency and robustness by  coarsening in resolution and channel dimensions",
    "abstract": "Current state-of-the-art deep neural networks for image classification are made up of 10 - 100 million learnable weights and are therefore inherently prone to overfitting. The complexity of the weight count can be seen as a function of the number of channels, the spatial extent of the input and the number of layers of the network. Due to the use of convolutional layers the scaling of weight complexity is usually linear with regards to the resolution dimensions, but remains quadratic with respect to the number of channels. Active research in recent years in terms of using multigrid inspired ideas in deep neural networks have shown that on one hand a significant number of weights can be saved by appropriate weight sharing and on the other that a hierarchical structure in the channel dimension can improve the weight complexity to linear. In this work, we combine these multigrid ideas to introduce a joint framework of multigrid inspired architectures, that exploit multigrid structures in all relevant dimensions to achieve linear weight complexity scaling and drastically reduced weight counts. Our experiments show that this structured reduction in weight count is able to reduce overfitting and thus shows improved performance over state-of-the-art ResNet architectures on typical image classification benchmarks at lower network complexity. ",
    "url": "https://arxiv.org/abs/2211.05525",
    "authors": [
      "Antonia van Betteray",
      "Matthias Rottmann",
      "Karsten Kahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05528",
    "title": "Cherry Hypothesis: Identifying the Cherry on the Cake for Dynamic  Networks",
    "abstract": "Dynamic networks have been extensively explored as they can considerably improve the model's representation power with acceptable computational cost. The common practice in implementing dynamic networks is to convert given static layers into fully dynamic ones where all parameters are dynamic and vary with the input. Recent studies empirically show the trend that the more dynamic layers contribute to ever-increasing performance. However, such a fully dynamic setting 1) may cause redundant parameters and high deployment costs, limiting the applicability of dynamic networks to a broader range of tasks and models, and more importantly, 2) contradicts the previous discovery in the human brain that \\textit{when human brains process an attention-demanding task, only partial neurons in the task-specific areas are activated by the input, while the rest neurons leave in a baseline state.} Critically, there is no effort to understand and resolve the above contradictory finding, leaving the primal question -- to make the computational parameters fully dynamic or not? -- unanswered. The main contributions of our work are challenging the basic commonsense in dynamic networks, and, proposing and validating the \\textsc{cherry hypothesis} -- \\textit{A fully dynamic network contains a subset of dynamic parameters that when transforming other dynamic parameters into static ones, can maintain or even exceed the performance of the original network.} Technically, we propose a brain-inspired partially dynamic network, namely PAD-Net, to transform the redundant dynamic parameters into static ones. Also, we further design Iterative Mode Partition to partition the dynamic- and static-subnet, which alleviates the redundancy in traditional fully dynamic networks. Our hypothesis and method are comprehensively supported by large-scale experiments with typical advanced dynamic methods. ",
    "url": "https://arxiv.org/abs/2211.05528",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Boan Liu",
      "Fuqiang Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05533",
    "title": "GREENER: Graph Neural Networks for News Media Profiling",
    "abstract": "We study the problem of profiling news media on the Web with respect to their factuality of reporting and bias. This is an important but under-studied problem related to disinformation and \"fake news\" detection, but it addresses the issue at a coarser granularity compared to looking at an individual article or an individual claim. This is useful as it allows to profile entire media outlets in advance. Unlike previous work, which has focused primarily on text (e.g.,~on the text of the articles published by the target website, or on the textual description in their social media profiles or in Wikipedia), here our main focus is on modeling the similarity between media outlets based on the overlap of their audience. This is motivated by homophily considerations, i.e.,~the tendency of people to have connections to people with similar interests, which we extend to media, hypothesizing that similar types of media would be read by similar kinds of users. In particular, we propose GREENER (GRaph nEural nEtwork for News mEdia pRofiling), a model that builds a graph of inter-media connections based on their audience overlap, and then uses graph neural networks to represent each medium. We find that such representations are quite useful for predicting the factuality and the bias of news media outlets, yielding improvements over state-of-the-art results reported on two datasets. When augmented with conventionally used representations obtained from news articles, Twitter, YouTube, Facebook, and Wikipedia, prediction accuracy is found to improve by 2.5-27 macro-F1 points for the two tasks. ",
    "url": "https://arxiv.org/abs/2211.05533",
    "authors": [
      "Panayot Panayotov",
      "Utsav Shukla",
      "Husrev Taha Sencar",
      "Mohamed Nabeel",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.05543",
    "title": "Vis2Mus: Exploring Multimodal Representation Mapping for Controllable  Music Generation",
    "abstract": "In this study, we explore the representation mapping from the domain of visual arts to the domain of music, with which we can use visual arts as an effective handle to control music generation. Unlike most studies in multimodal representation learning that are purely data-driven, we adopt an analysis-by-synthesis approach that combines deep music representation learning with user studies. Such an approach enables us to discover \\textit{interpretable} representation mapping without a huge amount of paired data. In particular, we discover that visual-to-music mapping has a nice property similar to equivariant. In other words, we can use various image transformations, say, changing brightness, changing contrast, style transfer, to control the corresponding transformations in the music domain. In addition, we released the Vis2Mus system as a controllable interface for symbolic music generation. ",
    "url": "https://arxiv.org/abs/2211.05543",
    "authors": [
      "Runbang Zhang",
      "Yixiao Zhang",
      "Kai Shao",
      "Ying Shan",
      "Gus Xia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.05544",
    "title": "Near-infrared and visible-light periocular recognition with Gabor  features using frequency-adaptive automatic eye detection",
    "abstract": "Periocular recognition has gained attention recently due to demands of increased robustness of face or iris in less controlled scenarios. We present a new system for eye detection based on complex symmetry filters, which has the advantage of not needing training. Also, separability of the filters allows faster detection via one-dimensional convolutions. This system is used as input to a periocular algorithm based on retinotopic sampling grids and Gabor spectrum decomposition. The evaluation framework is composed of six databases acquired both with near-infrared and visible sensors. The experimental setup is complemented with four iris matchers, used for fusion experiments. The eye detection system presented shows very high accuracy with near-infrared data, and a reasonable good accuracy with one visible database. Regarding the periocular system, it exhibits great robustness to small errors in locating the eye centre, as well as to scale changes of the input image. The density of the sampling grid can also be reduced without sacrificing accuracy. Lastly, despite the poorer performance of the iris matchers with visible data, fusion with the periocular system can provide an improvement of more than 20%. The six databases used have been manually annotated, with the annotation made publicly available. ",
    "url": "https://arxiv.org/abs/2211.05544",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Josef Bigun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.05547",
    "title": "Column Generation for Optimization Problems in Communication Networks",
    "abstract": "Numerous communication networks are emerging to serve the various demands and improve the quality of service. Heterogeneous users have different requirements on quality metrics such as delay and service efficiency. Besides, the networks are equipped with different types and amounts of resources, and how to efficiently optimize the usage of such limited resources to serve more users is the key issue for communication networks. One powerful mathematical optimization mechanism to solve the above issue is column generation (CG), which can deal with the optimization problems with complicating constraints and block angular structures. In this paper, we first review the preliminaries of CG. Further, the branch-and-price (BP) algorithm is elaborated, which is designed by embedding CG into the branch-and-bound scheme to efficiently obtain the optimal solution. The applications of CG and BP in various communication networks are then provided, such as space-air-ground networks and device-to-device networks. In short, our goal is to help readers refine the applications of the CG optimization tool in terms of problem formulation and solution. We also discuss the possible challenges and prospective directions when applying CG in the communication networks. ",
    "url": "https://arxiv.org/abs/2211.05547",
    "authors": [
      "Ziye Jia",
      "Qihui Wu",
      "Chao Dong",
      "Chau Yuen",
      "Zhu Han"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.05551",
    "title": "Causal Counterfactuals for Improving the Robustness of Reinforcement  Learning",
    "abstract": "Reinforcement learning (RL) is applied in a wide variety of fields. RL enables agents to learn tasks autonomously by interacting with the environment. The more critical the tasks are, the higher the demand for the robustness of the RL systems. Causal RL combines RL and causal inference to make RL more robust. Causal RL agents use a causal representation to capture the invariant causal mechanisms that can be transferred from one task to another. Currently, there is limited research in Causal RL, and existing solutions are usually not complete or feasible for real-world applications. In this work, we propose CausalCF, the first complete Causal RL solution incorporating ideas from Causal Curiosity and CoPhy. Causal Curiosity provides an approach for using interventions, and CoPhy is modified to enable the RL agent to perform counterfactuals. We apply CausalCF to complex robotic tasks and show that it improves the RL agent's robustness using a realistic simulation environment called CausalWorld. ",
    "url": "https://arxiv.org/abs/2211.05551",
    "authors": [
      "Tom He",
      "Jasmina Gajcin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.05554",
    "title": "Optimizing Server-side Aggregation For Robust Federated Learning via  Subspace Training",
    "abstract": "Non-IID data distribution across clients and poisoning attacks are two main challenges in real-world federated learning systems. While both of them have attracted great research interest with specific strategies developed, no known solution manages to address them in a unified framework. To jointly overcome both challenges, we propose SmartFL, a generic approach that optimizes the server-side aggregation process with a small clean server-collected proxy dataset (e.g., around one hundred samples, 0.2% of the dataset) via a subspace training technique. Specifically, the aggregation weight of each participating client at each round is optimized using the server-collected proxy data, which is essentially the optimization of the global model in the convex hull spanned by client models. Since at each round, the number of tunable parameters optimized on the server side equals the number of participating clients (thus independent of the model size), we are able to train a global model with massive parameters using only a small amount of proxy data. We provide theoretical analyses of the convergence and generalization capacity for SmartFL. Empirically, SmartFL achieves state-of-the-art performance on both federated learning with non-IID data distribution and federated learning with malicious clients. The source code will be released. ",
    "url": "https://arxiv.org/abs/2211.05554",
    "authors": [
      "Yueqi Xie",
      "Weizhong Zhang",
      "Renjie Pi",
      "Fangzhao Wu",
      "Qifeng Chen",
      "Xing Xie",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.05560",
    "title": "Finite basis physics-informed neural networks as a Schwarz domain  decomposition method",
    "abstract": "Physics-informed neural networks (PINNs) [4, 10] are an approach for solving boundary value problems based on differential equations (PDEs). The key idea of PINNs is to use a neural network to approximate the solution to the PDE and to incorporate the residual of the PDE as well as boundary conditions into its loss function when training it. This provides a simple and mesh-free approach for solving problems relating to PDEs. However, a key limitation of PINNs is their lack of accuracy and efficiency when solving problems with larger domains and more complex, multi-scale solutions. In a more recent approach, finite basis physics-informed neural networks (FBPINNs) [8] use ideas from domain decomposition to accelerate the learning process of PINNs and improve their accuracy. In this work, we show how Schwarz-like additive, multiplicative, and hybrid iteration methods for training FBPINNs can be developed. We present numerical experiments on the influence of these different training strategies on convergence and accuracy. Furthermore, we propose and evaluate a preliminary implementation of coarse space correction for FBPINNs. ",
    "url": "https://arxiv.org/abs/2211.05560",
    "authors": [
      "Victorita Dolean",
      "Alexander Heinlein",
      "Siddhartha Mishra",
      "Ben Moseley"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.05561",
    "title": "Estimating Soft Labels for Out-of-Domain Intent Detection",
    "abstract": "Out-of-Domain (OOD) intent detection is important for practical dialog systems. To alleviate the issue of lacking OOD training samples, some works propose synthesizing pseudo OOD samples and directly assigning one-hot OOD labels to these pseudo samples. However, these one-hot labels introduce noises to the training process because some hard pseudo OOD samples may coincide with In-Domain (IND) intents. In this paper, we propose an adaptive soft pseudo labeling (ASoul) method that can estimate soft labels for pseudo OOD samples when training OOD detectors. Semantic connections between pseudo OOD samples and IND intents are captured using an embedding graph. A co-training framework is further introduced to produce resulting soft labels following the smoothness assumption, i.e., close samples are likely to have similar labels. Extensive experiments on three benchmark datasets show that ASoul consistently improves the OOD detection performance and outperforms various competitive baselines. ",
    "url": "https://arxiv.org/abs/2211.05561",
    "authors": [
      "Hao Lang",
      "Yinhe Zheng",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05562",
    "title": "Robust Security Energy Efficiency Optimization for RIS-Aided Cell-Free  Networks with Multiple Eavesdroppers",
    "abstract": "In this paper, we investigate the energy efficiency (EE) problem under reconfigurable intelligent surface (RIS)-aided secure cell-free networks, where multiple legitimate users and eavesdroppers (Eves) exist. We formulate a max-min secure EE optimization problem by jointly designing the distributed active beamforming and artificial noise at base stations as well as the passive beamforming at RISs under practical constraints. To deal with it, we first divide the original optimization problem into two sub-ones, and then propose an iterative optimization algorithm to solve each sub-problem based on the fractional programming, constrained convex-convex procedure (CCCP) and semi-definite programming (SDP) techniques. After that, these two sub-problems are alternatively solved until convergence, and the final solutions are obtained. Next, we extend to the imperfect channel state information of the Eves' links, and investigate the robust SEE beamforming optimization problem by bringing the outage probability constraints. Based on this, we first transform the uncertain outage probability constraints into the certain ones by the bernstein-type inequality and sphere boundary techniques, and then propose an alternatively iterative algorithm to obtain the solutions of the original problem based on the S-procedure, successive convex approximation, CCCP and SDP techniques. Finally, the simulation results are conducted to show the effectiveness of the proposed schemes. ",
    "url": "https://arxiv.org/abs/2211.05562",
    "authors": [
      "Wanming Hao",
      "Junjie Li",
      "Gangcan Sun",
      "Chongwen Huang",
      "Ming Zeng",
      "Octavia A. Dobre",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.05566",
    "title": "Secure State Estimation against Sparse Attacks on a Time-varying Set of  Sensors",
    "abstract": "This paper studies the problem of secure state estimation of a linear time-invariant (LTI) system with bounded noise in the presence of sparse attacks on an unknown, time-varying set of sensors. In other words, at each time, the attacker has the freedom to choose an arbitrary set of no more that $p$ sensors and manipulate their measurements without restraint. To this end, we propose a secure state estimation scheme and guarantee a bounded estimation error subject to $2p$-sparse observability and a mild, technical assumption that the system matrix has no degenerate eigenvalues. The proposed scheme comprises a design of decentralized observer for each sensor based on the local observable subspace decomposition. At each time step, the local estimates of sensors are fused by solving an optimization problem to obtain a secure estimation, which is then followed by a local detection-and-resetting process of the decentralized observers. The estimation error is shown to be upper-bounded by a constant which is determined only by the system parameters and noise magnitudes. Moreover, we optimize the detector threshold to ensure that the benign sensors do not trigger the detector. The efficacy of the proposed algorithm is demonstrated by its application on a benchmark example of IEEE 14-bus system. ",
    "url": "https://arxiv.org/abs/2211.05566",
    "authors": [
      "Zishuo Li",
      "Muhammad Umar B. Niazi",
      "Changxin Liu",
      "Yilin Mo",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.05567",
    "title": "Partial Differential Equations Meet Deep Neural Networks: A Survey",
    "abstract": "Many problems in science and engineering can be represented by a set of partial differential equations (PDEs) through mathematical modeling. Mechanism-based computation following PDEs has long been an essential paradigm for studying topics such as computational fluid dynamics, multiphysics simulation, molecular dynamics, or even dynamical systems. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. At the same time, solving PDEs efficiently has been a long-standing challenge. Generally, except for a few differential equations for which analytical solutions are directly available, many more equations must rely on numerical approaches such as the finite difference method, finite element method, finite volume method, and boundary element method to be solved approximately. These numerical methods usually divide a continuous problem domain into discrete points and then concentrate on solving the system at each of those points. Though the effectiveness of these traditional numerical methods, the vast number of iterative operations accompanying each step forward significantly reduces the efficiency. Recently, another equally important paradigm, data-based computation represented by deep learning, has emerged as an effective means of solving PDEs. Surprisingly, a comprehensive review for this interesting subfield is still lacking. This survey aims to categorize and review the current progress on Deep Neural Networks (DNNs) for PDEs. We discuss the literature published in this subfield over the past decades and present them in a common taxonomy, followed by an overview and classification of applications of these related methods in scientific research and engineering scenarios. The origin, developing history, character, sort, as well as the future trends in each potential direction of this subfield are also introduced. ",
    "url": "https://arxiv.org/abs/2211.05567",
    "authors": [
      "Shudong Huang",
      "Wentao Feng",
      "Chenwei Tang",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.05574",
    "title": "Filtration-Domination in Bifiltered Graphs",
    "abstract": "Bifiltered graphs are a versatile tool for modelling relations between data points across multiple grades of a two-dimensional scale. They are especially popular in topological data analysis, where the homological properties of the induced clique complexes are studied. To reduce the large size of these clique complexes, we identify filtration-dominated edges of the graph, whose removal preserves the relevant topological properties. We give two algorithms to detect filtration-dominated edges in a bifiltered graph and analyze their complexity. These two algorithms work directly on the bifiltered graph, without first extracting the clique complexes, which are generally much bigger. We present extensive experimental evaluation which shows that in most cases, more than 90% of the edges can be removed. In turn, we demonstrate that this often leads to a substantial speedup, and reduction in the memory usage, of the computational pipeline of multiparameter topological data analysis. ",
    "url": "https://arxiv.org/abs/2211.05574",
    "authors": [
      "\u00c1ngel Javier Alonso",
      "Michael Kerber",
      "Siddharth Pritam"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2211.05580",
    "title": "Hyperbolic Cosine Transformer for LiDAR 3D Object Detection",
    "abstract": "Recently, Transformer has achieved great success in computer vision. However, it is constrained because the spatial and temporal complexity grows quadratically with the number of large points in 3D object detection applications. Previous point-wise methods are suffering from time consumption and limited receptive fields to capture information among points. In this paper, we propose a two-stage hyperbolic cosine transformer (ChTR3D) for 3D object detection from LiDAR point clouds. The proposed ChTR3D refines proposals by applying cosh-attention in linear computation complexity to encode rich contextual relationships among points. The cosh-attention module reduces the space and time complexity of the attention operation. The traditional softmax operation is replaced by non-negative ReLU activation and hyperbolic-cosine-based operator with re-weighting mechanism. Extensive experiments on the widely used KITTI dataset demonstrate that, compared with vanilla attention, the cosh-attention significantly improves the inference speed with competitive performance. Experiment results show that, among two-stage state-of-the-art methods using point-level features, the proposed ChTR3D is the fastest one. ",
    "url": "https://arxiv.org/abs/2211.05580",
    "authors": [
      "Jigang Tong",
      "Fanhang Yang",
      "Sen Yang",
      "Enzeng Dong",
      "Shengzhi Du",
      "Xing Wang",
      "Xianlin Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05584",
    "title": "Exploring Robustness of Prefix Tuning in Noisy Data: A Case Study in  Financial Sentiment Analysis",
    "abstract": "The invention of transformer-based models such as BERT, GPT, and RoBERTa has enabled researchers and financial companies to finetune these powerful models and use them in different downstream tasks to achieve state-of-the-art performance. Recently, a lightweight alternative (approximately 0.1% - 3% of the original model parameters) to fine-tuning, known as prefix tuning has been introduced. This method freezes the model parameters and only updates the prefix to achieve performance comparable to full fine-tuning. Prefix tuning enables researchers and financial practitioners to achieve similar results with much fewer parameters. In this paper, we explore the robustness of prefix tuning when facing noisy data. Our experiments demonstrate that fine-tuning is more robust to noise than prefix tuning -- the latter method faces a significant decrease in performance on most corrupted data sets with increasing noise levels. Furthermore, prefix tuning has high variances in the F1 scores compared to fine-tuning in many corruption methods. We strongly advocate that caution should be carefully taken when applying the state-of-the-art prefix tuning method to noisy data. ",
    "url": "https://arxiv.org/abs/2211.05584",
    "authors": [
      "Sudhandar Balakrishnan",
      "Yihao Fang",
      "Xioadan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05590",
    "title": "A Practical Introduction to Side-Channel Extraction of Deep Neural  Network Parameters",
    "abstract": "Model extraction is a major threat for embedded deep neural network models that leverages an extended attack surface. Indeed, by physically accessing a device, an adversary may exploit side-channel leakages to extract critical information of a model (i.e., its architecture or internal parameters). Different adversarial objectives are possible including a fidelity-based scenario where the architecture and parameters are precisely extracted (model cloning). We focus this work on software implementation of deep neural networks embedded in a high-end 32-bit microcontroller (Cortex-M7) and expose several challenges related to fidelity-based parameters extraction through side-channel analysis, from the basic multiplication operation to the feed-forward connection through the layers. To precisely extract the value of parameters represented in the single-precision floating point IEEE-754 standard, we propose an iterative process that is evaluated with both simulations and traces from a Cortex-M7 target. To our knowledge, this work is the first to target such an high-end 32-bit platform. Importantly, we raise and discuss the remaining challenges for the complete extraction of a deep neural network model, more particularly the critical case of biases. ",
    "url": "https://arxiv.org/abs/2211.05590",
    "authors": [
      "Raphael Joud",
      "Pierre-Alain Moellic",
      "Simon Pontie",
      "Jean-Baptiste Rigaud"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05594",
    "title": "A Brief Survey on Representation Learning based Graph Dimensionality  Reduction Techniques",
    "abstract": "Dimensionality reduction techniques map data represented on higher dimensions onto lower dimensions with varying degrees of information loss. Graph dimensionality reduction techniques adopt the same principle of providing latent representations of the graph structure with minor adaptations to the output representations along with the input data. There exist several cutting edge techniques that are efficient at generating embeddings from graph data and projecting them onto low dimensional latent spaces. Due to variations in the operational philosophy, the benefits of a particular graph dimensionality reduction technique might not prove advantageous to every scenario or rather every dataset. As a result, some techniques are efficient at representing the relationship between nodes at lower dimensions, while others are good at encapsulating the entire graph structure on low dimensional space. We present this survey to outline the benefits as well as problems associated with the existing graph dimensionality reduction techniques. We also attempted to connect the dots regarding the potential improvements to some of the techniques. This survey could be helpful for upcoming researchers interested in exploring the usage of graph representation learning to effectively produce low-dimensional graph embeddings with varying degrees of granularity. ",
    "url": "https://arxiv.org/abs/2211.05594",
    "authors": [
      "Akhil Pandey Akella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05613",
    "title": "Adjustment formulas for learning causal steady-state models from  closed-loop operational data",
    "abstract": "Steady-state models which have been learned from historical operational data may be unfit for model-based optimization unless correlations in the training data which are introduced by control are accounted for. Using recent results from work on structural dynamical causal models, we derive a formula for adjusting for this control confounding, enabling the estimation of a causal steady-state model from closed-loop steady-state data. The formula assumes that the available data have been gathered under some fixed control law. It works by estimating and taking into account the disturbance which the controller is trying to counteract, and enables learning from data gathered under both feedforward and feedback control. ",
    "url": "https://arxiv.org/abs/2211.05613",
    "authors": [
      "Kristian L\u00f8vland",
      "Bjarne Grimstad",
      "Lars Struen Imsland"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.05617",
    "title": "Debiasing Methods for Fairer Neural Models in Vision and Language  Research: A Survey",
    "abstract": "Despite being responsible for state-of-the-art results in several computer vision and natural language processing tasks, neural networks have faced harsh criticism due to some of their current shortcomings. One of them is that neural networks are correlation machines prone to model biases within the data instead of focusing on actual useful causal relationships. This problem is particularly serious in application domains affected by aspects such as race, gender, and age. To prevent models from incurring on unfair decision-making, the AI community has concentrated efforts in correcting algorithmic biases, giving rise to the research area now widely known as fairness in AI. In this survey paper, we provide an in-depth overview of the main debiasing methods for fairness-aware neural networks in the context of vision and language research. We propose a novel taxonomy to better organize the literature on debiasing methods for fairness, and we discuss the current challenges, trends, and important future work directions for the interested researcher and practitioner. ",
    "url": "https://arxiv.org/abs/2211.05617",
    "authors": [
      "Ot\u00e1vio Parraga",
      "Martin D. More",
      "Christian M. Oliveira",
      "Nathan S. Gavenski",
      "Lucas S. Kupssinsk\u00fc",
      "Adilson Medronha",
      "Luis V. Moura",
      "Gabriel S. Sim\u00f5es",
      "Rodrigo C. Barros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.05624",
    "title": "Improving the Robustness of Neural Multiplication Units with Reversible  Stochasticity",
    "abstract": "Multilayer Perceptrons struggle to learn certain simple arithmetic tasks. Specialist neural modules for arithmetic can outperform classical architectures with gains in extrapolation, interpretability and convergence speeds, but are highly sensitive to the training range. In this paper, we show that Neural Multiplication Units (NMUs) are unable to reliably learn tasks as simple as multiplying two inputs when given different training ranges. Causes of failure are linked to inductive and input biases which encourage convergence to solutions in undesirable optima. A solution, the stochastic NMU (sNMU), is proposed to apply reversible stochasticity, encouraging avoidance of such optima whilst converging to the true solution. Empirically, we show that stochasticity provides improved robustness with the potential to improve learned representations of upstream networks for numerical and image tasks. ",
    "url": "https://arxiv.org/abs/2211.05624",
    "authors": [
      "Bhumika Mistry",
      "Katayoun Farrahi",
      "Jonathon Hare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.05627",
    "title": "Representing LLVM-IR in a Code Property Graph",
    "abstract": "In the past years, a number of static application security testing tools have been proposed which make use of so-called code property graphs, a graph model which keeps rich information about the source code while enabling its user to write language-agnostic analyses. However, they suffer from several shortcomings. They work mostly on source code and exclude the analysis of third-party dependencies if they are only available as compiled binaries. Furthermore, they are limited in their analysis to whether an individual programming language is supported or not. While often support for well-established languages such as C/C++ or Java is included, languages that are still heavily evolving, such as Rust, are not considered because of the constant changes in the language design. To overcome these limitations, we extend an open source implementation of a code property graph to support LLVM-IR which can be used as output by many compilers and binary lifters. In this paper, we discuss how we address challenges that arise when mapping concepts of an intermediate representation to a CPG. At the same time, we optimize the resulting graph to be minimal and close to the representation of equivalent source code. Our evaluation indicates that existing analyses can be reused without modifications and that the performance requirements are comparable to operating on source code. This makes the approach suitable for an analysis of large-scale projects. ",
    "url": "https://arxiv.org/abs/2211.05627",
    "authors": [
      "Alexander K\u00fcchler",
      "Christian Banse"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2211.05630",
    "title": "Quorum Systems in Permissionless Network",
    "abstract": "Fail-prone systems, and their quorum systems, are useful tools for the design of distributed algorithms. However, fail-prone systems as studied so far require every process to know the full system membership in order to guarantee safety through globally intersecting quorums. Thus, they are of little help in an open, permissionless setting, where such knowledge may not be available. We propose to generalize the theory of fail-prone systems to make it applicable to permissionless systems. We do so by enabling processes not only to make assumptions about failures, but also to make assumptions about the assumptions of other processes. Thus, by transitivity, processes that do not even know of any common process may nevertheless have intersecting quorums and solve, for example, reliable broadcast. Our model generalizes existing models such as the classic fail-prone system model [Malkhi and Reiter, 1998] and the asymmetric fail-prone system model [Cachin and Tackmann, OPODIS 2019]. Moreover, it gives a characterization with standard formalism of the model used by the Stellar blockchain. ",
    "url": "https://arxiv.org/abs/2211.05630",
    "authors": [
      "Christian Cachin",
      "Giuliano Losa",
      "Luca Zanolini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.05631",
    "title": "Backdoor Defense via Suppressing Model Shortcuts",
    "abstract": "Recent studies have demonstrated that deep neural networks (DNNs) are vulnerable to backdoor attacks during the training process. Specifically, the adversaries intend to embed hidden backdoors in DNNs so that malicious model predictions can be activated through pre-defined trigger patterns. In this paper, we explore the backdoor mechanism from the angle of the model structure. We select the skip connection for discussions, inspired by the understanding that it helps the learning of model `shortcuts' where backdoor triggers are usually easier to be learned. Specifically, we demonstrate that the attack success rate (ASR) decreases significantly when reducing the outputs of some key skip connections. Based on this observation, we design a simple yet effective backdoor removal method by suppressing the skip connections in critical layers selected by our method. We also implement fine-tuning on these layers to recover high benign accuracy and to further reduce ASR. Extensive experiments on benchmark datasets verify the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2211.05631",
    "authors": [
      "Sheng Yang",
      "Yiming Li",
      "Yong Jiang",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05635",
    "title": "Generalized Wardrop Equilibrium for Charging Station Selection and Route  Choice of Electric Vehicles in Joint Power Distribution and Transportation  Networks",
    "abstract": "This paper presents the equilibrium analysis of a game composed of heterogeneous electric vehicles (EVs) and a power distribution system operator (DSO) as players in the game, and charging station operators (CSOs) and a transportation network operator (TNO) as coordinators. Each EV tries to pick a charging station as its destination and a route to get there at the same time. However, the traffic and electrical load congestion on the roads and charging stations lead to the interdependencies between the optimal decisions of EVs. In addition, CSOs and the TNO need to apply some tolling to control such congestion. On the other hand, the pricing in charging stations depends on real-time distributional locational marginal pricing, which is determined by the DSO after solving the optimal power flow over the power distribution network. This paper also takes into account the local and the coupling/infrastructure constraints of EVs as well as transportation and distribution networks. This problem is modeled as a generalized aggregative game, and then a decentralized learning method is proposed to obtain an equilibrium point of the game, which is known as variational generalized Wardrop equilibrium. The existence of such an equilibrium point and the convergence of the proposed algorithm to it are theoretically proven. The proposed decentralized learning method is scalable and privacy-preserving for EVs. We undertake numerical studies on the Savannah city model and the IEEE 33-bus distribution network and investigate the impact of various characteristics on demand and prices. ",
    "url": "https://arxiv.org/abs/2211.05635",
    "authors": [
      "Babak Ghaffarzadeh Bakhshayesh",
      "Hamed Kebriaei"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.05636",
    "title": "Rare Wildlife Recognition with Self-Supervised Representation Learning",
    "abstract": "Automated animal censuses with aerial imagery are a vital ingredient towards wildlife conservation. Recent models are generally based on supervised learning and thus require vast amounts of training data. Due to their scarcity and minuscule size, annotating animals in aerial imagery is a highly tedious process. In this project, we present a methodology to reduce the amount of required training data by resorting to self-supervised pretraining. In detail, we examine a combination of recent contrastive learning methodologies like Momentum Contrast (MoCo) and Cross-Level Instance-Group Discrimination (CLD) to condition our model on the aerial images without the requirement for labels. We show that a combination of MoCo, CLD, and geometric augmentations outperforms conventional models pretrained on ImageNet by a large margin. Meanwhile, strategies for smoothing label or prediction distribution in supervised learning have been proven useful in preventing the model from overfitting. We combine the self-supervised contrastive models with image mixup strategies and find that it is useful for learning more robust visual representations. Crucially, our methods still yield favorable results even if we reduce the number of training animals to just 10%, at which point our best model scores double the recall of the baseline at similar precision. This effectively allows reducing the number of required annotations to a fraction while still being able to train high-accuracy models in such highly challenging settings. ",
    "url": "https://arxiv.org/abs/2211.05636",
    "authors": [
      "Xiaochen Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05637",
    "title": "Description Graphs, Matrix-Power Stabilizations and Graph Isomorphism in  Polynomial Time",
    "abstract": "It is confirmed in this work that the graph isomorphism can be tested in polynomial time, which resolves a longstanding problem in the theory of computation. The contributions are in three phases as follows. 1. A description graph $\\tilde{A}$ to a given graph $A$ is introduced so that labels to vertices and edges of $\\tilde{A}$ indicate the identical or different amounts of walks of any sort in any length between vertices in $A$. Three processes are then developed to obtain description graphs. They reveal relations among matrix power, spectral decomposition and adjoint matrices, which is of independent interest. 2. We show that the stabilization of description graphs can be implemented via matrix-power stabilization, a new approach to distinguish vertices and edges to graphs. The approach is proven to be equivalent in the partition of vertices to Weisfeiler-Lehman (WL for short) process. The specific Square-and-Substitution (SaS) process is more succinct than WL process. The vertex partitions to our stable graphs are proven to be \\emph{strongly} equitable partitions, which is important in the proofs of our main conclusion. Some properties on stable graphs are also explored. 3. A class of graphs named binding graphs is proposed and proven to be graph-isomorphism complete. The vertex partition to the stable graph of a binding graph is the automorphism partition, which allows us to confirm graph-isomorphism problem is in complexity class $\\mathtt{P}$. Since the binding graph to a graph is so simple in construction, our approach can be readily applied in practice. ",
    "url": "https://arxiv.org/abs/2211.05637",
    "authors": [
      "Rui Xue"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2211.05638",
    "title": "Untargeted Backdoor Attack against Object Detection",
    "abstract": "Recent studies revealed that deep neural networks (DNNs) are exposed to backdoor threats when training with third-party resources (such as training samples or backbones). The backdoored model has promising performance in predicting benign samples, whereas its predictions can be maliciously manipulated by adversaries based on activating its backdoors with pre-defined trigger patterns. Currently, most of the existing backdoor attacks were conducted on the image classification under the targeted manner. In this paper, we reveal that these threats could also happen in object detection, posing threatening risks to many mission-critical applications ($e.g.$, pedestrian detection and intelligent surveillance systems). Specifically, we design a simple yet effective poison-only backdoor attack in an untargeted manner, based on task characteristics. We show that, once the backdoor is embedded into the target model by our attack, it can trick the model to lose detection of any object stamped with our trigger patterns. We conduct extensive experiments on the benchmark dataset, showing its effectiveness in both digital and physical-world settings and its resistance to potential defenses. ",
    "url": "https://arxiv.org/abs/2211.05638",
    "authors": [
      "Chengxiao Luo",
      "Yiming Li",
      "Yong Jiang",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05641",
    "title": "Regression as Classification: Influence of Task Formulation on Neural  Network Features",
    "abstract": "Neural networks can be trained to solve regression problems by using gradient-based methods to minimize the square loss. However, practitioners often prefer to reformulate regression as a classification problem, observing that training on the cross entropy loss results in better performance. By focusing on two-layer ReLU networks, which can be fully characterized by measures over their feature space, we explore how the implicit bias induced by gradient-based optimization could partly explain the above phenomenon. We provide theoretical evidence that the regression formulation yields a measure whose support can differ greatly from that for classification, in the case of one-dimensional data. Our proposed optimal supports correspond directly to the features learned by the input layer of the network. The different nature of these supports sheds light on possible optimization difficulties the square loss could encounter during training, and we present empirical results illustrating this phenomenon. ",
    "url": "https://arxiv.org/abs/2211.05641",
    "authors": [
      "Lawrence Stewart",
      "Francis Bach",
      "Quentin Berthet",
      "Jean-Philippe Vert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.05654",
    "title": "Efficient Joint Detection and Multiple Object Tracking with Spatially  Aware Transformer",
    "abstract": "We propose a light-weight and highly efficient Joint Detection and Tracking pipeline for the task of Multi-Object Tracking using a fully-transformer architecture. It is a modified version of TransTrack, which overcomes the computational bottleneck associated with its design, and at the same time, achieves state-of-the-art MOTA score of 73.20%. The model design is driven by a transformer based backbone instead of CNN, which is highly scalable with the input resolution. We also propose a drop-in replacement for Feed Forward Network of transformer encoder layer, by using Butterfly Transform Operation to perform channel fusion and depth-wise convolution to learn spatial context within the feature maps, otherwise missing within the attention maps of the transformer. As a result of our modifications, we reduce the overall model size of TransTrack by 58.73% and the complexity by 78.72%. Therefore, we expect our design to provide novel perspectives for architecture optimization in future research related to multi-object tracking. ",
    "url": "https://arxiv.org/abs/2211.05654",
    "authors": [
      "Siddharth Sagar Nijhawan",
      "Leo Hoshikawa",
      "Atsushi Irie",
      "Masakazu Yoshimura",
      "Junji Otsuka",
      "Takeshi Ohashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05656",
    "title": "Probabilistically Robust PAC Learning",
    "abstract": "Recently, Robey et al. propose a notion of probabilistic robustness, which, at a high-level, requires a classifier to be robust to most but not all perturbations. They show that for certain hypothesis classes where proper learning under worst-case robustness is \\textit{not} possible, proper learning under probabilistic robustness \\textit{is} possible with sample complexity exponentially smaller than in the worst-case robustness setting. This motivates the question of whether proper learning under probabilistic robustness is always possible. In this paper, we show that this is \\textit{not} the case. We exhibit examples of hypothesis classes $\\mathcal{H}$ with finite VC dimension that are \\textit{not} probabilistically robustly PAC learnable with \\textit{any} proper learning rule. However, if we compare the output of the learner to the best hypothesis for a slightly \\textit{stronger} level of probabilistic robustness, we show that not only is proper learning \\textit{always} possible, but it is possible via empirical risk minimization. ",
    "url": "https://arxiv.org/abs/2211.05656",
    "authors": [
      "VInod Raman",
      "Unique Subedi",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.05657",
    "title": "Stochastic Network Calculus with Localized Application of Martingales",
    "abstract": "Stochastic Network Calculus is a probabilistic method to compute performance bounds in networks, such as end-to-end delays. It relies on the analysis of stochastic processes using formalism of (Deterministic) Network Calculus. However, unlike the deterministic theory, the computed bounds are usually very loose compared to the simulation. This is mainly due to the intensive use of the Boole's inequality. On the other hand, analyses based on martingales can achieve tight bounds, but until now, they have not been applied to sequences of servers. In this paper, we improve the accuracy of Stochastic Network Calculus by combining this martingale analysis with a recent Stochastic Network Calculus results based on the Pay-Multiplexing-Only-Once property, well-known from the Deterministic Network calculus. We exhibit a non-trivial class of networks that can benefit from this analysis and compare our bounds with simulation. ",
    "url": "https://arxiv.org/abs/2211.05657",
    "authors": [
      "Anne Bouillard"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2211.05659",
    "title": "Finding Critical Nodes in Interdependent Networks with SAT and ILP  Solvers",
    "abstract": "Infrastructure systems, such as power systems, often experience cascading failures. Modeling an infrastructure system as a collection of interdependent networks has recently received attention as a way to explain cascading failures. In this study, we propose an approach to find the set of critical nodes in an interdependent network. For an integer k, we say that a set of k nodes is critical if the initial failures of these k nodes result in the most severe cascading failure among all sets of k nodes. This approach adopts the seminal model of interdependent networks proposed by Buldyrev et al., in which new link failures occur in a network if the connectivity is lost in the paired network. The problem of finding critical nodes is NP-hard; thus the aim of the approach is to accurately solve the problem in feasible time for moderate-size problem instances. The proposed approach consists of two phases. In the first phase, the maximum number of failure propagation stages is computed by repeatedly solving the Boolean satisfiability problem. This number is then used in the second phase, where the set of critical nodes is computed using integer linear programming. The results of applying this approach to a variety of problem instances demonstrate that the approach is feasible for up to at least 30 nodes and can be used as the baseline to compare the performance of heuristic solutions. ",
    "url": "https://arxiv.org/abs/2211.05659",
    "authors": [
      "Kyozo Hida",
      "Tatsuhiro Tsuchiya"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.05675",
    "title": "Causal Modeling of Soil Processes for Improved Generalization",
    "abstract": "Measuring and monitoring soil organic carbon is critical for agricultural productivity and for addressing critical environmental problems. Soil organic carbon not only enriches nutrition in soil, but also has a gamut of co-benefits such as improving water storage and limiting physical erosion. Despite a litany of work in soil organic carbon estimation, current approaches do not generalize well across soil conditions and management practices. We empirically show that explicit modeling of cause-and-effect relationships among the soil processes improves the out-of-distribution generalizability of prediction models. We provide a comparative analysis of soil organic carbon estimation models where the skeleton is estimated using causal discovery methods. Our framework provide an average improvement of 81% in test mean squared error and 52% in test mean absolute error. ",
    "url": "https://arxiv.org/abs/2211.05675",
    "authors": [
      "Somya Sharma",
      "Swati Sharma",
      "Andy Neal",
      "Sara Malvar",
      "Eduardo Rodrigues",
      "John Crawford",
      "Emre Kiciman",
      "Ranveer Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.05697",
    "title": "Bayesian hierarchical modelling for battery lifetime early prediction",
    "abstract": "Accurate prediction of battery health is essential for real-world system management and lab-based experiment design. However, building a life-prediction model from different cycling conditions is still a challenge. Large lifetime variability results from both cycling conditions and initial manufacturing variability, and this -- along with the limited experimental resources usually available for each cycling condition -- makes data-driven lifetime prediction challenging. Here, a hierarchical Bayesian linear model is proposed for battery life prediction, combining both individual cell features (reflecting manufacturing variability) with population-wide features (reflecting the impact of cycling conditions on the population average). The individual features were collected from the first 100 cycles of data, which is around 5-10% of lifetime. The model is able to predict end of life with a root mean square error of 3.2 days and mean absolute percentage error of 8.6%, measured through 5-fold cross-validation, overperforming the baseline (non-hierarchical) model by around 12-13%. ",
    "url": "https://arxiv.org/abs/2211.05697",
    "authors": [
      "Zihao Zhou",
      "David A. Howey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05716",
    "title": "Resource-Aware Heterogeneous Federated Learning using Neural  Architecture Search",
    "abstract": "Federated Learning (FL) is extensively used to train AI/ML models in distributed and privacy-preserving settings. Participant edge devices in FL systems typically contain non-independent and identically distributed~(Non-IID) private data and unevenly distributed computational resources. Preserving user data privacy while optimizing AI/ML models in a heterogeneous federated network requires us to address data heterogeneity and system/resource heterogeneity. Hence, we propose \\underline{R}esource-\\underline{a}ware \\underline{F}ederated \\underline{L}earning~(RaFL) to address these challenges. RaFL allocates resource-aware models to edge devices using Neural Architecture Search~(NAS) and allows heterogeneous model architecture deployment by knowledge extraction and fusion. Integrating NAS into FL enables on-demand customized model deployment for resource-diverse edge devices. Furthermore, we propose a multi-model architecture fusion scheme allowing the aggregation of the distributed learning results. Results demonstrate RaFL's superior resource efficiency compared to SoTA. ",
    "url": "https://arxiv.org/abs/2211.05716",
    "authors": [
      "Sixing Yu",
      "Phuong Nguyen",
      "Waqwoya Abebe",
      "Justin Stanley",
      "Pablo Munoz",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05730",
    "title": "NEON: Enabling Efficient Support for Nonlinear Operations in Resistive  RAM-based Neural Network Accelerators",
    "abstract": "Resistive Random-Access Memory (RRAM) is well-suited to accelerate neural network (NN) workloads as RRAM-based Processing-in-Memory (PIM) architectures natively support highly-parallel multiply-accumulate (MAC) operations that form the backbone of most NN workloads. Unfortunately, NN workloads such as transformers require support for non-MAC operations (e.g., softmax) that RRAM cannot provide natively. Consequently, state-of-the-art works either integrate additional digital logic circuits to support the non-MAC operations or offload the non-MAC operations to CPU/GPU, resulting in significant performance and energy efficiency overheads due to data movement. In this work, we propose NEON, a novel compiler optimization to enable the end-to-end execution of the NN workload in RRAM. The key idea of NEON is to transform each non-MAC operation into a lightweight yet highly-accurate neural network. Utilizing neural networks to approximate the non-MAC operations provides two advantages: 1) We can exploit the key strength of RRAM, i.e., highly-parallel MAC operation, to flexibly and efficiently execute non-MAC operations in memory. 2) We can simplify RRAM's microarchitecture by eliminating the additional digital logic circuits while reducing the data movement overheads. Acceleration of the non-MAC operations in memory enables NEON to achieve a 2.28x speedup compared to an idealized digital logic-based RRAM. We analyze the trade-offs associated with the transformation and demonstrate feasible use cases for NEON across different substrates. ",
    "url": "https://arxiv.org/abs/2211.05730",
    "authors": [
      "Aditya Manglik",
      "Minesh Patel",
      "Haiyu Mao",
      "Behzad Salami",
      "Jisung Park",
      "Lois Orosa",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.05766",
    "title": "Heterogeneous Randomized Response for Differential Privacy in Graph  Neural Networks",
    "abstract": "Graph neural networks (GNNs) are susceptible to privacy inference attacks (PIAs), given their ability to learn joint representation from features and edges among nodes in graph data. To prevent privacy leakages in GNNs, we propose a novel heterogeneous randomized response (HeteroRR) mechanism to protect nodes' features and edges against PIAs under differential privacy (DP) guarantees without an undue cost of data and model utility in training GNNs. Our idea is to balance the importance and sensitivity of nodes' features and edges in redistributing the privacy budgets since some features and edges are more sensitive or important to the model utility than others. As a result, we derive significantly better randomization probabilities and tighter error bounds at both levels of nodes' features and edges departing from existing approaches, thus enabling us to maintain high data utility for training GNNs. An extensive theoretical and empirical analysis using benchmark datasets shows that HeteroRR significantly outperforms various baselines in terms of model utility under rigorous privacy protection for both nodes' features and edges. That enables us to defend PIAs in DP-preserving GNNs effectively. ",
    "url": "https://arxiv.org/abs/2211.05766",
    "authors": [
      "Khang Tran",
      "Phung Lai",
      "NhatHai Phan",
      "Issa Khalil",
      "Yao Ma",
      "Abdallah Khreishah",
      "My Thai",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.05769",
    "title": "Steiner Connectivity Augmentation and Splitting-off in Poly-logarithmic  Maximum Flows",
    "abstract": "We give an almost-linear time algorithm for the Steiner connectivity augmentation problem: given an undirected graph, find a smallest (or minimum weight) set of edges whose addition makes a given set of terminals $\\tau$-connected (for any given $\\tau > 0$). The running time of our algorithm is dominated by polylogarithmic calls to any maximum flow subroutine; using the recent almost-linear time maximum flow algorithm (Chen et al., FOCS 2022), we get an almost-linear running time for our algorithm as well. This is tight up to the polylogarithmic factor even for just two terminals. Prior to our work, an almost-linear (in fact, near-linear) running time was known only for the special case of global connectivity augmentation, i.e., when all vertices are terminals (Cen et al., STOC 2022). We also extend our algorithm to the closely related Steiner splitting-off problem, where the edges incident on a vertex have to be {\\em split-off} while maintaining the (Steiner) connectivity of a given set of terminals. Prior to our work, a nearly-linear time algorithm was known only for the special case of global connectivity (Cen et al., STOC 2022). The only known generalization beyond global connectivity was to preserve all pairwise connectivities using a much slower algorithm that makes $n$ calls to an all-pairs maximum flow (or Gomory-Hu tree) subroutine (Lau and Yung, SICOMP 2013), as against polylog(n) calls to a (single-pair) maximum flow subroutine in this work. ",
    "url": "https://arxiv.org/abs/2211.05769",
    "authors": [
      "Ruoxu Cen",
      "William He",
      "Jason Li",
      "Debmalya Panigrahi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.05773",
    "title": "Scaling Neural Face Synthesis to High FPS and Low Latency by Neural  Caching",
    "abstract": "Recent neural rendering approaches greatly improve image quality, reaching near photorealism. However, the underlying neural networks have high runtime, precluding telepresence and virtual reality applications that require high resolution at low latency. The sequential dependency of layers in deep networks makes their optimization difficult. We break this dependency by caching information from the previous frame to speed up the processing of the current one with an implicit warp. The warping with a shallow network reduces latency and the caching operations can further be parallelized to improve the frame rate. In contrast to existing temporal neural networks, ours is tailored for the task of rendering novel views of faces by conditioning on the change of the underlying surface mesh. We test the approach on view-dependent rendering of 3D portrait avatars, as needed for telepresence, on established benchmark sequences. Warping reduces latency by 70$\\%$ (from 49.4ms to 14.9ms on commodity GPUs) and scales frame rates accordingly over multiple GPUs while reducing image quality by only 1$\\%$, making it suitable as part of end-to-end view-dependent 3D teleconferencing applications. Our project page can be found at: https://yu-frank.github.io/lowlatency/. ",
    "url": "https://arxiv.org/abs/2211.05773",
    "authors": [
      "Frank Yu",
      "Sid Fels",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05781",
    "title": "Demystify Transformers & Convolutions in Modern Image Deep Networks",
    "abstract": "Recent success of vision transformers has inspired a series of vision backbones with novel feature transformation paradigms, which report steady performance gain. Although the novel feature transformation designs are often claimed as the source of gain, some backbones may benefit from advanced engineering techniques, which makes it hard to identify the real gain from the key feature transformation operators. In this paper, we aim to identify real gain of popular convolution and attention operators and make an in-depth study of them. We observe that the main difference among these feature transformation modules, e.g., attention or convolution, lies in the way of spatial feature aggregation, or the so-called \"spatial token mixer\" (STM). Hence, we first elaborate a unified architecture to eliminate the unfair impact of different engineering techniques, and then fit STMs into this architecture for comparison. Based on various experiments on upstream/downstream tasks and the analysis of inductive bias, we find that the engineering techniques boost the performance significantly, but the performance gap still exists among different STMs. The detailed analysis also reveals some interesting findings of different STMs, such as effective receptive fields and invariance tests. The code and trained models will be publicly available at https://github.com/OpenGVLab/STM-Evaluation ",
    "url": "https://arxiv.org/abs/2211.05781",
    "authors": [
      "Jifeng Dai",
      "Min Shi",
      "Weiyun Wang",
      "Sitong Wu",
      "Linjie Xing",
      "Wenhai Wang",
      "Xizhou Zhu",
      "Lewei Lu",
      "Jie Zhou",
      "Xiaogang Wang",
      "Yu Qiao",
      "Xiaowei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.02292",
    "title": "Boosting Binary Neural Networks via Dynamic Thresholds Learning",
    "abstract": "Developing lightweight Deep Convolutional Neural Networks (DCNNs) and Vision Transformers (ViTs) has become one of the focuses in vision research since the low computational cost is essential for deploying vision models on edge devices. Recently, researchers have explored highly computational efficient Binary Neural Networks (BNNs) by binarizing weights and activations of Full-precision Neural Networks. However, the binarization process leads to an enormous accuracy gap between BNN and its full-precision version. One of the primary reasons is that the Sign function with predefined or learned static thresholds limits the representation capacity of binarized architectures since single-threshold binarization fails to utilize activation distributions. To overcome this issue, we introduce the statistics of channel information into explicit thresholds learning for the Sign Function dubbed DySign to generate various thresholds based on input distribution. Our DySign is a straightforward method to reduce information loss and boost the representative capacity of BNNs, which can be flexibly applied to both DCNNs and ViTs (i.e., DyBCNN and DyBinaryCCT) to achieve promising performance improvement. As shown in our extensive experiments. For DCNNs, DyBCNNs based on two backbones (MobileNetV1 and ResNet18) achieve 71.2% and 67.4% top1-accuracy on ImageNet dataset, outperforming baselines by a large margin (i.e., 1.8% and 1.5% respectively). For ViTs, DyBinaryCCT presents the superiority of the convolutional embedding layer in fully binarized ViTs and achieves 56.1% on the ImageNet dataset, which is nearly 9% higher than the baseline. ",
    "url": "https://arxiv.org/abs/2211.02292",
    "authors": [
      "Jiehua Zhang",
      "Xueyang Zhang",
      "Zhuo Su",
      "Zitong Yu",
      "Yanghe Feng",
      "Xin Lu",
      "Matti Pietik\u00e4inen",
      "Li Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05172",
    "title": "Speech separation with large-scale self-supervised learning",
    "abstract": "Self-supervised learning (SSL) methods such as WavLM have shown promising speech separation (SS) results in small-scale simulation-based experiments. In this work, we extend the exploration of the SSL-based SS by massively scaling up both the pre-training data (more than 300K hours) and fine-tuning data (10K hours). We also investigate various techniques to efficiently integrate the pre-trained model with the SS network under a limited computation budget, including a low frame rate SSL model training setup and a fine-tuning scheme using only the part of the pre-trained model. Compared with a supervised baseline and the WavLM-based SS model using feature embeddings obtained with the previously released 94K hours trained WavLM, our proposed model obtains 15.9% and 11.2% of relative word error rate (WER) reductions, respectively, for a simulated far-field speech mixture test set. For conversation transcription on real meeting recordings using continuous speech separation, the proposed model achieves 6.8% and 10.6% of relative WER reductions over the purely supervised baseline on AMI and ICSI evaluation sets, respectively, while reducing the computational cost by 38%. ",
    "url": "https://arxiv.org/abs/2211.05172",
    "authors": [
      "Zhuo Chen",
      "Naoyuki Kanda",
      "Jian Wu",
      "Yu Wu",
      "Xiaofei Wang",
      "Takuya Yoshioka",
      "Jinyu Li",
      "Sunit Sivasankaran",
      "Sefik Emre Eskimez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.05235",
    "title": "Improved Prediction of Beta-Amyloid and Tau Burden Using Hippocampal  Surface Multivariate Morphometry Statistics and Sparse Coding",
    "abstract": "Background: Beta-amyloid (A$\\beta$) plaques and tau protein tangles in the brain are the defining 'A' and 'T' hallmarks of Alzheimer's disease (AD), and together with structural atrophy detectable on brain magnetic resonance imaging (MRI) scans as one of the neurodegenerative ('N') biomarkers comprise the ''ATN framework'' of AD. Current methods to detect A$\\beta$/tau pathology include cerebrospinal fluid (CSF; invasive), positron emission tomography (PET; costly and not widely available), and blood-based biomarkers (BBBM; promising but mainly still in development). Objective: To develop a non-invasive and widely available structural MRI-based framework to quantitatively predict the amyloid and tau measurements. Methods: With MRI-based hippocampal multivariate morphometry statistics (MMS) features, we apply our Patch Analysis-based Surface Correntropy-induced Sparse coding and max-pooling (PASCS-MP) method combined with the ridge regression model to individual amyloid/tau measure prediction. Results: We evaluate our framework on amyloid PET/MRI and tau PET/MRI datasets from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Each subject has one pair consisting of a PET image and MRI scan, collected at about the same time. Experimental results suggest that amyloid/tau measurements predicted with our PASCP-MP representations are closer to the real values than the measures derived from other approaches, such as hippocampal surface area, volume, and shape morphometry features based on spherical harmonics (SPHARM). Conclusion: The MMS-based PASCP-MP is an efficient tool that can bridge hippocampal atrophy with amyloid and tau pathology and thus help assess disease burden, progression, and treatment effects. ",
    "url": "https://arxiv.org/abs/2211.05235",
    "authors": [
      "Jianfeng Wu",
      "Yi Su",
      "Wenhui Zhu",
      "Negar Jalili Mallak",
      "Natasha Lepore",
      "Eric M. Reiman",
      "Richard J. Caselli",
      "Paul M. Thompson",
      "Kewei Chen",
      "Yalin Wang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05409",
    "title": "Radiomics-enhanced Deep Multi-task Learning for Outcome Prediction in  Head and Neck Cancer",
    "abstract": "Outcome prediction is crucial for head and neck cancer patients as it can provide prognostic information for early treatment planning. Radiomics methods have been widely used for outcome prediction from medical images. However, these methods are limited by their reliance on intractable manual segmentation of tumor regions. Recently, deep learning methods have been proposed to perform end-to-end outcome prediction so as to remove the reliance on manual segmentation. Unfortunately, without segmentation masks, these methods will take the whole image as input, such that makes them difficult to focus on tumor regions and potentially unable to fully leverage the prognostic information within the tumor regions. In this study, we propose a radiomics-enhanced deep multi-task framework for outcome prediction from PET/CT images, in the context of HEad and neCK TumOR segmentation and outcome prediction challenge (HECKTOR 2022). In our framework, our novelty is to incorporate radiomics as an enhancement to our recently proposed Deep Multi-task Survival model (DeepMTS). The DeepMTS jointly learns to predict the survival risk scores of patients and the segmentation masks of tumor regions. Radiomics features are extracted from the predicted tumor regions and combined with the predicted survival risk scores for final outcome prediction, through which the prognostic information in tumor regions can be further leveraged. Our method achieved a C-index of 0.681 on the testing set, placing the 2nd on the leaderboard with only 0.00068 lower in C-index than the 1st place. ",
    "url": "https://arxiv.org/abs/2211.05409",
    "authors": [
      "Mingyuan Meng",
      "Lei Bi",
      "Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05421",
    "title": "Improving Uncertainty-based Out-of-Distribution Detection for Medical  Image Segmentation",
    "abstract": "Deep Learning models are easily disturbed by variations in the input images that were not seen during training, resulting in unpredictable behaviours. Such Out-of-Distribution (OOD) images represent a significant challenge in the context of medical image analysis, where the range of possible abnormalities is extremely wide, including artifacts, unseen pathologies, or different imaging protocols. In this work, we evaluate various uncertainty frameworks to detect OOD inputs in the context of Multiple Sclerosis lesions segmentation. By implementing a comprehensive evaluation scheme including 14 sources of OOD of various nature and strength, we show that methods relying on the predictive uncertainty of binary segmentation models often fails in detecting outlying inputs. On the contrary, learning to segment anatomical labels alongside lesions highly improves the ability to detect OOD inputs. ",
    "url": "https://arxiv.org/abs/2211.05421",
    "authors": [
      "Benjamin Lambert",
      "Florence Forbes",
      "Senan Doyle",
      "Alan Tucholka",
      "Michel Dojat"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05442",
    "title": "Self-supervised learning of audio representations using angular  contrastive loss",
    "abstract": "In Self-Supervised Learning (SSL), various pretext tasks are designed for learning feature representations through contrastive loss. However, previous studies have shown that this loss is less tolerant to semantically similar samples due to the inherent defect of instance discrimination objectives, which may harm the quality of learned feature embeddings used in downstream tasks. To improve the discriminative ability of feature embeddings in SSL, we propose a new loss function called Angular Contrastive Loss (ACL), a linear combination of angular margin and contrastive loss. ACL improves contrastive learning by explicitly adding an angular margin between positive and negative augmented pairs in SSL. Experimental results show that using ACL for both supervised and unsupervised learning significantly improves performance. We validated our new loss function using the FSDnoisy18k dataset, where we achieved 73.6% and 77.1% accuracy in sound event classification using supervised and self-supervised learning, respectively. ",
    "url": "https://arxiv.org/abs/2211.05442",
    "authors": [
      "Shanshan Wang",
      "Soumya Tripathy",
      "Annamaria Mesaros"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.05460",
    "title": "Polyominoes and graphs built from Fibonacci words",
    "abstract": "We introduce the $k$-bonacci polyominoes, a new family of polyominoes associated with the binary words avoiding $k$ consecutive $1$'s, also called generalized $k$-bonacci words. The polyominoes are very entrancing objects, considered in combinatorics and computer science. The study of polyominoes generates a rich source of combinatorial ideas. In this paper we study some properties of $k$-bonacci polyominoes. Specifically, we determine their recursive structure and, using this structure, we enumerate them according to their area, semiperimeter, and length of the corresponding words. We also introduce the $k$-bonacci graphs, then we obtain the generating functions for the total number of vertices and edges, the distribution of the degrees, and the total number of $k$-bonacci graphs that have a Hamiltonian cycle. ",
    "url": "https://arxiv.org/abs/2211.05460",
    "authors": [
      "Sergey Kirgizov",
      "Jos\u00e9 Luis Ram\u00edrez"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.05548",
    "title": "Dual Multi-scale Mean Teacher Network for Semi-supervised Infection  Segmentation in Chest CT Volume for COVID-19",
    "abstract": "Automated detecting lung infections from computed tomography (CT) data plays an important role for combating COVID-19. However, there are still some challenges for developing AI system. 1) Most current COVID-19 infection segmentation methods mainly relied on 2D CT images, which lack 3D sequential constraint. 2) Existing 3D CT segmentation methods focus on single-scale representations, which do not achieve the multiple level receptive field sizes on 3D volume. 3) The emergent breaking out of COVID-19 makes it hard to annotate sufficient CT volumes for training deep model. To address these issues, we first build a multiple dimensional-attention convolutional neural network (MDA-CNN) to aggregate multi-scale information along different dimension of input feature maps and impose supervision on multiple predictions from different CNN layers. Second, we assign this MDA-CNN as a basic network into a novel dual multi-scale mean teacher network (DM${^2}$T-Net) for semi-supervised COVID-19 lung infection segmentation on CT volumes by leveraging unlabeled data and exploring the multi-scale information. Our DM${^2}$T-Net encourages multiple predictions at different CNN layers from the student and teacher networks to be consistent for computing a multi-scale consistency loss on unlabeled data, which is then added to the supervised loss on the labeled data from multiple predictions of MDA-CNN. Third, we collect two COVID-19 segmentation datasets to evaluate our method. The experimental results show that our network consistently outperforms the compared state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2211.05548",
    "authors": [
      "Liansheng Wang",
      "Jiacheng Wang",
      "Lei Zhu",
      "Huazhu Fu",
      "Ping Li",
      "Gary Cheng",
      "Zhipeng Feng",
      "Shuo Li",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05564",
    "title": "Self-supervised learning with bi-label masked speech prediction for  streaming multi-talker speech recognition",
    "abstract": "Self-supervised learning (SSL), which utilizes the input data itself for representation learning, has achieved state-of-the-art results for various downstream speech tasks. However, most of the previous studies focused on offline single-talker applications, with limited investigations in multi-talker cases, especially for streaming scenarios. In this paper, we investigate SSL for streaming multi-talker speech recognition, which generates transcriptions of overlapping speakers in a streaming fashion. We first observe that conventional SSL techniques do not work well on this task due to the poor representation of overlapping speech. We then propose a novel SSL training objective, referred to as bi-label masked speech prediction, which explicitly preserves representations of all speakers in overlapping speech. We investigate various aspects of the proposed system including data configuration and quantizer selection. The proposed SSL setup achieves substantially better word error rates on the LibriSpeechMix dataset. ",
    "url": "https://arxiv.org/abs/2211.05564",
    "authors": [
      "Zili Huang",
      "Zhuo Chen",
      "Naoyuki Kanda",
      "Jian Wu",
      "Yiming Wang",
      "Jinyu Li",
      "Takuya Yoshioka",
      "Xiaofei Wang",
      "Peidong Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.05633",
    "title": "Transfer learning and Local interpretable model agnostic based visual  approach in Monkeypox Disease Detection and Classification: A Deep Learning  insights",
    "abstract": "The recent development of Monkeypox disease among various nations poses a global pandemic threat when the world is still fighting Coronavirus Disease-2019 (COVID-19). At its dawn, the slow and steady transmission of Monkeypox disease among individuals needs to be addressed seriously. Over the years, Deep learning (DL) based disease prediction has demonstrated true potential by providing early, cheap, and affordable diagnosis facilities. Considering this opportunity, we have conducted two studies where we modified and tested six distinct deep learning models-VGG16, InceptionResNetV2, ResNet50, ResNet101, MobileNetV2, and VGG19-using transfer learning approaches. Our preliminary computational results show that the proposed modified InceptionResNetV2 and MobileNetV2 models perform best by achieving an accuracy ranging from 93% to 99%. Our findings are reinforced by recent academic work that demonstrates improved performance in constructing multiple disease diagnosis models using transfer learning approaches. Lastly, we further explain our model prediction using Local Interpretable Model-Agnostic Explanations (LIME), which play an essential role in identifying important features that characterize the onset of Monkeypox disease. ",
    "url": "https://arxiv.org/abs/2211.05633",
    "authors": [
      "Md Manjurul Ahsan",
      "Tareque Abu Abdullah",
      "Md Shahin Ali",
      "Fatematuj Jahora",
      "Md Khairul Islam",
      "Amin G. Alhashim",
      "Kishor Datta Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05658",
    "title": "Multi-objective optimization via evolutionary algorithm (MOVEA) for  high-definition transcranial electrical stimulation of the human brain",
    "abstract": "Transcranial temporal interference stimulation (tTIS) has been reported to be effective in stimulating deep brain structures in experimental studies. However, a computational framework for optimizing the tTIS strategy and simulating the impact of tTIS on the brain is still lacking, as previous methods rely on predefined parameters and hardly adapt to additional constraints. Here, we propose a general framework, namely multi-objective optimization via evolutionary algorithm (MOVEA), to solve the nonconvex optimization problem for various stimulation techniques, including tTIS and transcranial alternating current stimulation (tACS). By optimizing the electrode montage in a two-stage structure, MOVEA can be compatible with additional constraints (e.g., the number of electrodes, additional avoidance regions), and MOVEA can accelerate to obtain the Pareto fronts. These Pareto fronts consist of a set of optimal solutions under different requirements, suggesting a trade-off relationship between conflicting objectives, such as intensity and focality. Based on MOVEA, we make comprehensive comparisons between tACS and tTIS in terms of intensity, focality and maneuverability for targets of different depths. Our results show that although the tTIS can only obtain a relatively low maximum achievable electric field strength, for example, the maximum intensity of motor area under tTIS is 0.42V /m, while 0.51V /m under tACS, it helps improve the focality by reducing 60% activated volume outside the target. We further perform ANOVA on the stimulation results of eight subjects with tACS and tTIS. Despite the individual differences in head models, our results suggest that tACS has a greater intensity and tTIS has a higher focality. These findings provide guidance on the choice between tACS and tTIS and indicate a great potential in tTIS-based personalized neuromodulation. Code will be released soon. ",
    "url": "https://arxiv.org/abs/2211.05658",
    "authors": [
      "Mo Wang",
      "Kexin Lou",
      "Zeming Liu",
      "Pengfei Wei",
      "Quanying Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.05690",
    "title": "Robust Model Selection of Non Tree-Structured Gaussian Graphical Models",
    "abstract": "We consider the problem of learning the structure underlying a Gaussian graphical model when the variables (or subsets thereof) are corrupted by independent noise. A recent line of work establishes that even for tree-structured graphical models, only partial structure recovery is possible and goes on to devise algorithms to identify the structure up to an (unavoidable) equivalence class of trees. We extend these results beyond trees and consider the model selection problem under noise for non tree-structured graphs, as tree graphs cannot model several real-world scenarios. Although unidentifiable, we show that, like the tree-structured graphs, the ambiguity is limited to an equivalence class. This limited ambiguity can help provide meaningful clustering information (even with noise), which is helpful in computer and social networks, protein-protein interaction networks, and power networks. Furthermore, we devise an algorithm based on a novel ancestral testing method for recovering the equivalence class. We complement these results with finite sample guarantees for the algorithm in the high-dimensional regime. ",
    "url": "https://arxiv.org/abs/2211.05690",
    "authors": [
      "Abrar Zahin",
      "Rajasekhar Anguluri",
      "Oliver Kosut",
      "Lalitha Sankar",
      "Gautam Dasarathy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2211.05698",
    "title": "Probabilistic thermal stability prediction through sparsity promoting  transformer representation",
    "abstract": "Pre-trained protein language models have demonstrated significant applicability in different protein engineering task. A general usage of these pre-trained transformer models latent representation is to use a mean pool across residue positions to reduce the feature dimensions to further downstream tasks such as predicting bio-physics properties or other functional behaviours. In this paper we provide a two-fold contribution to machine learning (ML) driven drug design. Firstly, we demonstrate the power of sparsity by promoting penalization of pre-trained transformer models to secure more robust and accurate melting temperature (Tm) prediction of single-chain variable fragments with a mean absolute error of 0.23C. Secondly, we demonstrate the power of framing our prediction problem in a probabilistic framework. Specifically, we advocate for the need of adopting probabilistic frameworks especially in the context of ML driven drug design. ",
    "url": "https://arxiv.org/abs/2211.05698",
    "authors": [
      "Yevgen Zainchkovskyy",
      "Jesper Ferkinghoff-Borg",
      "Anja Bennett",
      "Thomas Egebjerg",
      "Nikolai Lorenzen",
      "Per Jr. Greisen",
      "S\u00f8ren Hauberg",
      "Carsten Stahlhut"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05762",
    "title": "Efficient brain age prediction from 3D MRI volumes using 2D projections",
    "abstract": "Using 3D CNNs on high resolution medical volumes is very computationally demanding, especially for large datasets like the UK Biobank which aims to scan 100,000 subjects. Here we demonstrate that using 2D CNNs on a few 2D projections (representing mean and standard deviation across axial, sagittal and coronal slices) of the 3D volumes leads to reasonable test accuracy when predicting the age from brain volumes. Using our approach, one training epoch with 20,324 subjects takes 40 - 70 seconds using a single GPU, which is almost 100 times faster compared to a small 3D CNN. These results are important for researchers who do not have access to expensive GPU hardware for 3D CNNs. ",
    "url": "https://arxiv.org/abs/2211.05762",
    "authors": [
      "Johan J\u00f6nemo",
      "Muhammad Usman Akbar",
      "Robin K\u00e4mpe",
      "J Paul Hamilton",
      "Anders Eklund"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05777",
    "title": "Hybrid quantum neural network for drug response prediction",
    "abstract": "Cancer is one of the leading causes of death worldwide. It is caused by a variety of genetic mutations, which makes every instance of the disease unique. Since chemotherapy can have extremely severe side effects, each patient requires a personalized treatment plan. Finding the dosages that maximize the beneficial effects of the drugs and minimize their adverse side effects is vital. Deep neural networks automate and improve drug selection. However, they require a lot of data to be trained on. Therefore, there is a need for machine-learning approaches that require less data. Hybrid quantum neural networks were shown to provide a potential advantage in problems where training data availability is limited. We propose a novel hybrid quantum neural network for drug response prediction, based on a combination of convolutional, graph convolutional, and deep quantum neural layers of 8 qubits with 363 layers. We test our model on the reduced Genomics of Drug Sensitivity in Cancer dataset and show that the hybrid quantum model outperforms its classical analog by 15% in predicting IC50 drug effectiveness values. The proposed hybrid quantum machine learning model is a step towards deep quantum data-efficient algorithms with thousands of quantum gates for solving problems in personalized medicine, where data collection is a challenge. ",
    "url": "https://arxiv.org/abs/2211.05777",
    "authors": [
      "Asel Sagingalieva",
      "Mohammad Kordzanganeh",
      "Nurbolat Kenbayev",
      "Daria Kosichkina",
      "Tatiana Tomashuk",
      "Alexey Melnikov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:1707.06808",
    "title": "The Complexity Landscape of Fixed-Parameter Directed Steiner Network  Problems",
    "abstract": " Comments: Appeared at the 43rd International Colloquium on Automata, Languages, and Programming (ICALP 2016) ",
    "url": "https://arxiv.org/abs/1707.06808",
    "authors": [
      "Andreas Emil Feldmann",
      "Daniel Marx"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:1811.12231",
    "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias  improves accuracy and robustness",
    "abstract": " Comments: Accepted at ICLR 2019 (oral) ",
    "url": "https://arxiv.org/abs/1811.12231",
    "authors": [
      "Robert Geirhos",
      "Patricia Rubisch",
      "Claudio Michaelis",
      "Matthias Bethge",
      "Felix A. Wichmann",
      "Wieland Brendel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1903.07138",
    "title": "A Brain-inspired Algorithm for Training Highly Sparse Neural Networks",
    "abstract": " Title: A Brain-inspired Algorithm for Training Highly Sparse Neural Networks ",
    "url": "https://arxiv.org/abs/1903.07138",
    "authors": [
      "Zahra Atashgahi",
      "Joost Pieterse",
      "Shiwei Liu",
      "Decebal Constantin Mocanu",
      "Raymond Veldhuis",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.12450",
    "title": "Are Neural Language Models Good Plagiarists? A Benchmark for Neural  Paraphrase Detection",
    "abstract": " Title: Are Neural Language Models Good Plagiarists? A Benchmark for Neural  Paraphrase Detection ",
    "url": "https://arxiv.org/abs/2103.12450",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2104.08101",
    "title": "Embedding Dependencies Between Wind Farms in Distributionally Robust  Optimal Power Flow",
    "abstract": " Title: Embedding Dependencies Between Wind Farms in Distributionally Robust  Optimal Power Flow ",
    "url": "https://arxiv.org/abs/2104.08101",
    "authors": [
      "Adriano Arrigo",
      "Jalal Kazempour",
      "Zacharie De Gr\u00e8ve",
      "Jean-Fran\u00e7ois Toubeau",
      "Fran\u00e7ois Vall\u00e9e"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2104.10004",
    "title": "Toward the Prevention of Privacy Threats: How Can We Persuade Our Social  Network Platform Users?",
    "abstract": " Comments: HCIS accepted version ",
    "url": "https://arxiv.org/abs/2104.10004",
    "authors": [
      "Ramon Ruiz-Dolz",
      "Jose Alemany",
      "Stella Heras",
      "Ana Garc\u00eda-Fornes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2109.05585",
    "title": "U-Net Convolutional Network for Recognition of Vessels and Materials in  Chemistry Lab",
    "abstract": " Comments: Some models need to be improved to get exact results ",
    "url": "https://arxiv.org/abs/2109.05585",
    "authors": [
      "Zhihao Shang",
      "Di Bo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.07819",
    "title": "Testing the Generalization of Neural Language Models for COVID-19  Misinformation Detection",
    "abstract": " Title: Testing the Generalization of Neural Language Models for COVID-19  Misinformation Detection ",
    "url": "https://arxiv.org/abs/2111.07819",
    "authors": [
      "Jan Philip Wahle",
      "Nischal Ashok",
      "Terry Ruas",
      "Norman Meuschke",
      "Tirthankar Ghosal",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.00350",
    "title": "LSTM Architecture for Oil Stocks Prices Prediction",
    "abstract": " Comments: 22 figures, 13 tables, one more section and some part and analysis were added ",
    "url": "https://arxiv.org/abs/2201.00350",
    "authors": [
      "Javad T. Firouzjaee",
      "Pouriya Khaliliyan"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.03965",
    "title": "Few-Sample Traffic Prediction with Graph Networks using Locale as  Relational Inductive Biases",
    "abstract": " Title: Few-Sample Traffic Prediction with Graph Networks using Locale as  Relational Inductive Biases ",
    "url": "https://arxiv.org/abs/2203.03965",
    "authors": [
      "Mingxi Li",
      "Yihong Tang",
      "Wei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2204.01089",
    "title": "VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation",
    "abstract": " Title: VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation ",
    "url": "https://arxiv.org/abs/2204.01089",
    "authors": [
      "Lingyun Lu",
      "Bang Wang",
      "Zizhuo Zhang",
      "Shenghao Liu",
      "Han Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.12674",
    "title": "A Span-level Bidirectional Network for Aspect Sentiment Triplet  Extraction",
    "abstract": " Title: A Span-level Bidirectional Network for Aspect Sentiment Triplet  Extraction ",
    "url": "https://arxiv.org/abs/2204.12674",
    "authors": [
      "Yuqi Chen",
      "Keming Chen",
      "Xian Sun",
      "Zequn Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01663",
    "title": "Adversarial Training for High-Stakes Reliability",
    "abstract": " Comments: 30 pages, 7 figures, NeurIPS camera-ready ",
    "url": "https://arxiv.org/abs/2205.01663",
    "authors": [
      "Daniel M. Ziegler",
      "Seraphina Nix",
      "Lawrence Chan",
      "Tim Bauman",
      "Peter Schmidt-Nielsen",
      "Tao Lin",
      "Adam Scherlis",
      "Noa Nabeshima",
      "Ben Weinstein-Raun",
      "Daniel de Haas",
      "Buck Shlegeris",
      "Nate Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.01677",
    "title": "ASTROMER: A transformer-based embedding for the representation of light  curves",
    "abstract": " Title: ASTROMER: A transformer-based embedding for the representation of light  curves ",
    "url": "https://arxiv.org/abs/2205.01677",
    "authors": [
      "C. Donoso-Oliva",
      "I. Becker",
      "P. Protopapas",
      "G. Cabrera-Vives",
      "Vishnu M.",
      "Harsh Vardhan"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12514",
    "title": "Machine Translation Robustness to Natural Asemantic Variation",
    "abstract": " Comments: Accepted to EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2205.12514",
    "authors": [
      "Jacob Bremerman",
      "Xiang Ren",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12755",
    "title": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems",
    "abstract": " Title: An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems ",
    "url": "https://arxiv.org/abs/2205.12755",
    "authors": [
      "Andrea Gesmundo",
      "Jeff Dean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.13673",
    "title": "Diffusion of Community Fact-Checked Misinformation on Twitter",
    "abstract": " Title: Diffusion of Community Fact-Checked Misinformation on Twitter ",
    "url": "https://arxiv.org/abs/2205.13673",
    "authors": [
      "Chiara Drolsbach",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.02405",
    "title": "Robust Image Protection Countering Cropping Manipulation",
    "abstract": " Comments: Withdrawn for further modifications ",
    "url": "https://arxiv.org/abs/2206.02405",
    "authors": [
      "Qichao Ying",
      "Hang Zhou",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09349",
    "title": "Quantifying Uncertainty In Traffic State Estimation Using Generative  Adversarial Networks",
    "abstract": " Title: Quantifying Uncertainty In Traffic State Estimation Using Generative  Adversarial Networks ",
    "url": "https://arxiv.org/abs/2206.09349",
    "authors": [
      "Zhaobin Mo",
      "Yongjie Fu",
      "Xuan Di"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04806",
    "title": "Repairing Neural Networks by Leaving the Right Past Behind",
    "abstract": " Comments: 24 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2207.04806",
    "authors": [
      "Ryutaro Tanno",
      "Melanie F. Pradier",
      "Aditya Nori",
      "Yingzhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.01440",
    "title": "Viskositas: Viscosity Prediction of Multicomponent Chemical Systems",
    "abstract": " Comments: 16 pages, 7 figures, 5 tables, 1 appendix ",
    "url": "https://arxiv.org/abs/2208.01440",
    "authors": [
      "Patrick dos Anjos"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.03115",
    "title": "Multi-fidelity surrogate modeling using long short-term memory networks",
    "abstract": " Title: Multi-fidelity surrogate modeling using long short-term memory networks ",
    "url": "https://arxiv.org/abs/2208.03115",
    "authors": [
      "Paolo Conti",
      "Mengwu Guo",
      "Andrea Manzoni",
      "Jan S. Hesthaven"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06885",
    "title": "Global Priors Guided Modulation Network for Joint Super-Resolution and  Inverse Tone-Mapping",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2208.06885",
    "authors": [
      "Gang He",
      "Shaoyi Long",
      "Li Xu",
      "Chang Wu",
      "Jinjia Zhou",
      "Ming Sun",
      "Xing Wen",
      "Yurong Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.07216",
    "title": "Class-attention Video Transformer for Engagement Intensity Prediction",
    "abstract": " Comments: 5 figures ",
    "url": "https://arxiv.org/abs/2208.07216",
    "authors": [
      "Xusheng Ai",
      "Victor S. Sheng",
      "Chunhua Li",
      "Zhiming Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.09992",
    "title": "Efficient construction of canonical polyadic approximations of tensor  networks",
    "abstract": " Comments: 25 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2208.09992",
    "authors": [
      "Karl Pierce",
      "Edward F Valeev"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2208.10973",
    "title": "Robust DNN Watermarking via Fixed Embedding Weights with Optimized  Distribution",
    "abstract": " Comments: 13 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2208.10973",
    "authors": [
      "Benedetta Tondi",
      "Andrea Costanzo",
      "Mauro Barni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.03561",
    "title": "Video Vision Transformers for Violence Detection",
    "abstract": " Title: Video Vision Transformers for Violence Detection ",
    "url": "https://arxiv.org/abs/2209.03561",
    "authors": [
      "Sanskar Singh",
      "Shivaibhav Dewangan",
      "Ghanta Sai Krishna",
      "Vandit Tyagi",
      "Sainath Reddy",
      "Prathistith Raj Medi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.04954",
    "title": "Reinforcement Recommendation Reasoning through Knowledge Graphs for  Explanation Path Quality",
    "abstract": " Comments: Accepted for publication in Knowledge-Based Systems (Elsevier) ",
    "url": "https://arxiv.org/abs/2209.04954",
    "authors": [
      "Giacomo Balloccu",
      "Ludovico Boratto",
      "Gianni Fenu",
      "Mirko Marras"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": " Title: Sketch of a novel approach to a neural model ",
    "url": "https://arxiv.org/abs/2209.06865",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2209.12266",
    "title": "Enforcing safety for vision-based controllers via Control Barrier  Functions and Neural Radiance Fields",
    "abstract": " Title: Enforcing safety for vision-based controllers via Control Barrier  Functions and Neural Radiance Fields ",
    "url": "https://arxiv.org/abs/2209.12266",
    "authors": [
      "Mukun Tong",
      "Charles Dawson",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.05152",
    "title": "TriangleNet: Edge Prior Augmented Network for Semantic Segmentation  through Cross-Task Consistency",
    "abstract": " Title: TriangleNet: Edge Prior Augmented Network for Semantic Segmentation  through Cross-Task Consistency ",
    "url": "https://arxiv.org/abs/2210.05152",
    "authors": [
      "Dan Zhang",
      "Rui Zheng",
      "Luosang Gadeng",
      "Pei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13012",
    "title": "CMU-Net: A Strong ConvMixer-based Medical Ultrasound Image Segmentation  Network",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2210.13012",
    "authors": [
      "Fenghe Tang",
      "Lingtao Wang",
      "Chunping Ning",
      "Min Xian",
      "Jianrui Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13979",
    "title": "Meta-learning Pathologies from Radiology Reports using Variance Aware  Prototypical Networks",
    "abstract": " Comments: EMNLP'22 Industry Track. Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages ",
    "url": "https://arxiv.org/abs/2210.13979",
    "authors": [
      "Arijit Sehanobish",
      "Kawshik Kannan",
      "Nabila Abraham",
      "Anasuya Das",
      "Benjamin Odry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14891",
    "title": "Broken Neural Scaling Laws",
    "abstract": " Title: Broken Neural Scaling Laws ",
    "url": "https://arxiv.org/abs/2210.14891",
    "authors": [
      "Ethan Caballero",
      "Kshitij Gupta",
      "Irina Rish",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15011",
    "title": "Using Deception in Markov Game to Understand Adversarial Behaviors  through a Capture-The-Flag Environment",
    "abstract": " Comments: Accepted at GameSec 2022 ",
    "url": "https://arxiv.org/abs/2210.15011",
    "authors": [
      "Siddhant Bhambri",
      "Purv Chauhan",
      "Frederico Araujo",
      "Adam Doup\u00e9",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.15956",
    "title": "Generalized Laplacian Positional Encoding for Graph Representation  Learning",
    "abstract": " Comments: Accepted at NeurIPS Workshop on Symmetry and Geometry in Neural Representations: Extended Abstract Track 2022 ",
    "url": "https://arxiv.org/abs/2210.15956",
    "authors": [
      "Sohir Maskey",
      "Ali Parviz",
      "Maximilian Thiessen",
      "Hannes St\u00e4rk",
      "Ylli Sadikaj",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16835",
    "title": "Robust Data Valuation via Variance Reduced Data Shapley",
    "abstract": " Title: Robust Data Valuation via Variance Reduced Data Shapley ",
    "url": "https://arxiv.org/abs/2210.16835",
    "authors": [
      "Mengmeng Wu",
      "Ruoxi Jia",
      "Changle Lin",
      "Wei Huang",
      "Xiangyu Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00577",
    "title": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "abstract": " Title: Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution ",
    "url": "https://arxiv.org/abs/2211.00577",
    "authors": [
      "Alireza Aghelan",
      "Modjtaba Rouhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.01297",
    "title": "C3SASR: Cheap Causal Convolutions for Self-Attentive Sequential  Recommendation",
    "abstract": " Title: C3SASR: Cheap Causal Convolutions for Self-Attentive Sequential  Recommendation ",
    "url": "https://arxiv.org/abs/2211.01297",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Liye Shi",
      "Yu Ji",
      "Wenxin Hu",
      "Xi Chen",
      "Wei Zheng",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.02369",
    "title": "A Jigsaw Puzzle Solver-based Attack on Block-wise Image Encryption for  Privacy-preserving DNNs",
    "abstract": " Comments: To be appeared in IWAIT2023 ",
    "url": "https://arxiv.org/abs/2211.02369",
    "authors": [
      "Tatsuya Chuman",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.03231",
    "title": "Graph Neural Networks for Community Detection on Sparse Graphs",
    "abstract": " Comments: Submitted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.03231",
    "authors": [
      "Luana Ruiz",
      "Ningyuan Huang",
      "Soledad Villar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.03553",
    "title": "Learning Causal Representations of Single Cells via Sparse Mechanism  Shift Modeling",
    "abstract": " Title: Learning Causal Representations of Single Cells via Sparse Mechanism  Shift Modeling ",
    "url": "https://arxiv.org/abs/2211.03553",
    "authors": [
      "Romain Lopez",
      "Nata\u0161a Tagasovska",
      "Stephen Ra",
      "Kyunghyn Cho",
      "Jonathan K. Pritchard",
      "Aviv Regev"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.03685",
    "title": "On a Network Centrality Maximization Game",
    "abstract": " Comments: 40 pages, 21 figures ",
    "url": "https://arxiv.org/abs/2211.03685",
    "authors": [
      "Costanza Catalano",
      "Maria Castaldo",
      "Giacomo Como",
      "Fabio Fagnani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2211.04071",
    "title": "Improving performance of real-time full-band blind packet-loss  concealment with predictive network",
    "abstract": " Comments: Submitted to ICASSP 2023, 5 pages, 1 figure, 4 tables ",
    "url": "https://arxiv.org/abs/2211.04071",
    "authors": [
      "Viet-Anh Nguyen",
      "Anh H. T. Nguyen",
      "Andy W. H. Khong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.04693",
    "title": "Deep Explainable Learning with Graph Based Data Assessing and Rule  Reasoning",
    "abstract": " Title: Deep Explainable Learning with Graph Based Data Assessing and Rule  Reasoning ",
    "url": "https://arxiv.org/abs/2211.04693",
    "authors": [
      "Yuanlong Li",
      "Gaopan Huang",
      "Min Zhou",
      "Chuan Fu",
      "Honglin Qiao",
      "Yan He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.04774",
    "title": "ARNet: Automatic Refinement Network for Noisy Partial Label Learning",
    "abstract": " Title: ARNet: Automatic Refinement Network for Noisy Partial Label Learning ",
    "url": "https://arxiv.org/abs/2211.04774",
    "authors": [
      "Zheng Lian",
      "Mingyu Xu",
      "Lan Chen",
      "Licai Sun",
      "Bin Liu",
      "Jianhua Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.05020",
    "title": "Duality for Neural Networks through Reproducing Kernel Banach Spaces",
    "abstract": " Title: Duality for Neural Networks through Reproducing Kernel Banach Spaces ",
    "url": "https://arxiv.org/abs/2211.05020",
    "authors": [
      "Len Spek",
      "Tjeerd Jan Heeringa",
      "Christoph Brune"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ]
  }
]