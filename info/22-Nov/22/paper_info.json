[
  {
    "id": "arXiv:2211.10443",
    "title": "Social media mining for toxicovigilance of prescription medications:  End-to-end pipeline, challenges and future work",
    "abstract": "Substance use, substance use disorder, and overdoses related to substance use are major public health problems globally and in the United States. A key aspect of addressing these problems from a public health standpoint is improved surveillance. Traditional surveillance systems are laggy, and social media are potentially useful sources of timely data. However, mining knowledge from social media is challenging, and requires the development of advanced artificial intelligence, specifically natural language processing (NLP) and machine learning methods. We developed a sophisticated end-to-end pipeline for mining information about nonmedical prescription medication use from social media, namely Twitter and Reddit. Our pipeline employs supervised machine learning and NLP for filtering out noise and characterizing the chatter. In this paper, we describe our end-to-end pipeline developed over four years. In addition to describing our data mining infrastructure, we discuss existing challenges in social media mining for toxicovigilance, and possible future research directions. ",
    "url": "https://arxiv.org/abs/2211.10443",
    "authors": [
      "Abeed Sarker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10459",
    "title": "A Unified Framework for Quantifying Privacy Risk in Synthetic Data",
    "abstract": "Synthetic data is often presented as a method for sharing sensitive information in a privacy-preserving manner by reproducing the global statistical properties of the original data without disclosing sensitive information about any individual. In practice, as with other anonymization methods, privacy risks cannot be entirely eliminated. The residual privacy risks need instead to be ex-post assessed. We present Anonymeter, a statistical framework to jointly quantify different types of privacy risks in synthetic tabular datasets. We equip this framework with attack-based evaluations for the singling out, linkability, and inference risks, the three key indicators of factual anonymization according to the European General Data Protection Regulation (GDPR). To the best of our knowledge, we are the first to introduce a coherent and legally aligned evaluation of these three privacy risks for synthetic data, and to design privacy attacks which model directly the singling out and linkability risks. We demonstrate the effectiveness of our methods by conducting an extensive set of experiments that measure the privacy risks of data with deliberately inserted privacy leakages, and of synthetic data generated with and without differential privacy. Our results highlight that the three privacy risks reported by our framework scale linearly with the amount of privacy leakage in the data. Furthermore, we observe that synthetic data exhibits the lowest vulnerability against linkability, indicating one-to-one relationships between real and synthetic data records are not preserved. Finally, we demonstrate quantitatively that Anonymeter outperforms existing synthetic data privacy evaluation frameworks both in terms of detecting privacy leaks, as well as computation speed. To contribute to a privacy-conscious usage of synthetic data, we open source Anonymeter at https://github.com/statice/anonymeter. ",
    "url": "https://arxiv.org/abs/2211.10459",
    "authors": [
      "Matteo Giomi",
      "Franziska Boenisch",
      "Christoph Wehmeyer",
      "Borb\u00e1la Tasn\u00e1di"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10460",
    "title": "Knowledge Graph Refinement based on Triplet BERT-Networks",
    "abstract": "Knowledge graph embedding techniques are widely used for knowledge graph refinement tasks such as graph completion and triple classification. These techniques aim at embedding the entities and relations of a Knowledge Graph (KG) in a low dimensional continuous feature space. This paper adopts a transformer-based triplet network creating an embedding space that clusters the information about an entity or relation in the KG. It creates textual sequences from facts and fine-tunes a triplet network of pre-trained transformer-based language models. It adheres to an evaluation paradigm that relies on an efficient spatial semantic search technique. We show that this evaluation protocol is more adapted to a few-shot setting for the relation prediction task. Our proposed GilBERT method is evaluated on triplet classification and relation prediction tasks on multiple well-known benchmark knowledge graphs such as FB13, WN11, and FB15K. We show that GilBERT achieves better or comparable results to the state-of-the-art performance on these two refinement tasks. ",
    "url": "https://arxiv.org/abs/2211.10460",
    "authors": [
      "Armita Khajeh Nassiri",
      "Nathalie Pernelle",
      "Fatiha Sais",
      "Gianluca Quercini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10473",
    "title": "Dynamic Interactional And Cooperative Network For Shield Machine",
    "abstract": "The shield machine (SM) is a complex mechanical device used for tunneling. However, the monitoring and deciding were mainly done by artificial experience during traditional construction, which brought some limitations, such as hidden mechanical failures, human operator error, and sensor anomalies. To deal with these challenges, many scholars have studied SM intelligent methods. Most of these methods only take SM into account but do not consider the SM operating environment. So, this paper discussed the relationship among SM, geological information, and control terminals. Then, according to the relationship, models were established for the control terminal, including SM rate prediction and SM anomaly detection. The experimental results show that compared with baseline models, the proposed models in this paper perform better. In the proposed model, the R2 and MSE of rate prediction can reach 92.2\\%, and 0.0064 respectively. The abnormal detection rate of anomaly detection is up to 98.2\\%. ",
    "url": "https://arxiv.org/abs/2211.10473",
    "authors": [
      "Dazhi Gao",
      "Rongyang Li",
      "Hongbo Wang",
      "Lingfeng Mao",
      "Huansheng Ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.10486",
    "title": "DGRec: Graph Neural Network for Recommendation with Diversified  Embedding Generation",
    "abstract": "Graph Neural Network (GNN) based recommender systems have been attracting more and more attention in recent years due to their excellent performance in accuracy. Representing user-item interactions as a bipartite graph, a GNN model generates user and item representations by aggregating embeddings of their neighbors. However, such an aggregation procedure often accumulates information purely based on the graph structure, overlooking the redundancy of the aggregated neighbors and resulting in poor diversity of the recommended list. In this paper, we propose diversifying GNN-based recommender systems by directly improving the embedding generation procedure. Particularly, we utilize the following three modules: submodular neighbor selection to find a subset of diverse neighbors to aggregate for each GNN node, layer attention to assign attention weights for each layer, and loss reweighting to focus on the learning of items belonging to long-tail categories. Blending the three modules into GNN, we present DGRec(Diversified GNN-based Recommender System) for diversified recommendation. Experiments on real-world datasets demonstrate that the proposed method can achieve the best diversity while keeping the accuracy comparable to state-of-the-art GNN-based recommender systems. ",
    "url": "https://arxiv.org/abs/2211.10486",
    "authors": [
      "Liangwei Yang",
      "Shengjie Wang",
      "Yunzhe Tao",
      "Jiankai Sun",
      "Xiaolong Liu",
      "Philip S. Yu",
      "Taiqing Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.10495",
    "title": "A DPU Solution for Container Overlay Networks",
    "abstract": "There is an increasing demand to incorporate hybrid environments as part of workflows across edge, cloud, and HPC systems. In a such converging environment of cloud and HPC, containers are starting to play a more prominent role, bringing their networking infrastructure along with them. However, the current body of work shows that container overlay networks, which are often used to connect containers across physical hosts, are ill-suited for the HPC environment. They tend to impose significant overhead and noise, resulting in degraded performance and disturbance to co-processes on the same host. This paper focuses on utilizing a novel class of hardware, Data Processing Unit, to offload the networking stack of overlay networks away from the host onto the DPU. We intend to show that such ancillary offload is possible and that it will result in decreased overhead on host nodes which in turn will improve the performance of running processes. ",
    "url": "https://arxiv.org/abs/2211.10495",
    "authors": [
      "Anton Njavro",
      "James Tau",
      "Taylor Groves",
      "Nicholas J. Wright",
      "Richard West"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.10511",
    "title": "Knowledge Graph Generation From Text",
    "abstract": "In this work we propose a novel end-to-end multi-stage Knowledge Graph (KG) generation system from textual inputs, separating the overall process into two stages. The graph nodes are generated first using pretrained language model, followed by a simple edge construction head, enabling efficient KG extraction from the text. For each stage we consider several architectural choices that can be used depending on the available training resources. We evaluated the model on a recent WebNLG 2020 Challenge dataset, matching the state-of-the-art performance on text-to-RDF generation task, as well as on New York Times (NYT) and a large-scale TekGen datasets, showing strong overall performance, outperforming the existing baselines. We believe that the proposed system can serve as a viable KG construction alternative to the existing linearization or sampling-based graph generation approaches. Our code can be found at https://github.com/IBM/Grapher ",
    "url": "https://arxiv.org/abs/2211.10511",
    "authors": [
      "Igor Melnyk",
      "Pierre Dognin",
      "Payel Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10517",
    "title": "Social Diversity Reduces the Complexity and Cost of Fostering Fairness",
    "abstract": "Institutions and investors are constantly faced with the challenge of appropriately distributing endowments. No budget is limitless and optimising overall spending without sacrificing positive outcomes has been approached and resolved using several heuristics. To date, prior works have failed to consider how to encourage fairness in a population where social diversity is ubiquitous, and in which investors can only partially observe the population. Herein, by incorporating social diversity in the Ultimatum game through heterogeneous graphs, we investigate the effects of several interference mechanisms which assume incomplete information and flexible standards of fairness. We quantify the role of diversity and show how it reduces the need for information gathering, allowing us to relax a strict, costly interference process. Furthermore, we find that the influence of certain individuals, expressed by different network centrality measures, can be exploited to further reduce spending if minimal fairness requirements are lowered. Our results indicate that diversity changes and opens up novel mechanisms available to institutions wishing to promote fairness. Overall, our analysis provides novel insights to guide institutional policies in socially diverse complex systems. ",
    "url": "https://arxiv.org/abs/2211.10517",
    "authors": [
      "Theodor Cimpeanu",
      "Alessandro Di Stefano",
      "Cedric Perret",
      "Anh Han"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2211.10527",
    "title": "PMNet: Robust Pathloss Map Prediction via Supervised Learning",
    "abstract": "Pathloss prediction is an essential component of wireless network planning. While ray-tracing based methods have been successfully used for many years, they require significant computational effort that may become prohibitive with the increased network densification and/or use of higher frequencies in 5G/B5G (beyond 5 G) systems. In this paper, we propose and evaluate a data-driven and model-free pathloss prediction method, dubbed PMNet. This method uses a supervised learning approach: training a neural network (NN) with a limited amount of ray tracing (or channel measurement) data and map data and then predicting the pathloss over location with no ray tracing data with a high level of accuracy. Our proposed pathloss map prediction-oriented NN architecture, which is empowered by state-of-the-art computer vision techniques, outperforms other architectures that have been previously proposed (e.g., UNet, RadioUNet) in terms of accuracy while showing generalization capability. Moreover, PMNet trained on a 4-fold smaller dataset surpasses the other baselines (trained on a 4-fold larger dataset), corroborating the potential of PMNet. ",
    "url": "https://arxiv.org/abs/2211.10527",
    "authors": [
      "Ju-Hyung Lee",
      "Omer Gokalp Serbetci",
      "Dheeraj Panneer Selvam",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.10530",
    "title": "Provable Defense against Backdoor Policies in Reinforcement Learning",
    "abstract": "We propose a provable defense mechanism against backdoor policies in reinforcement learning under subspace trigger assumption. A backdoor policy is a security threat where an adversary publishes a seemingly well-behaved policy which in fact allows hidden triggers. During deployment, the adversary can modify observed states in a particular way to trigger unexpected actions and harm the agent. We assume the agent does not have the resources to re-train a good policy. Instead, our defense mechanism sanitizes the backdoor policy by projecting observed states to a 'safe subspace', estimated from a small number of interactions with a clean (non-triggered) environment. Our sanitized policy achieves $\\epsilon$ approximate optimality in the presence of triggers, provided the number of clean interactions is $O\\left(\\frac{D}{(1-\\gamma)^4 \\epsilon^2}\\right)$ where $\\gamma$ is the discounting factor and $D$ is the dimension of state space. Empirically, we show that our sanitization defense performs well on two Atari game environments. ",
    "url": "https://arxiv.org/abs/2211.10530",
    "authors": [
      "Shubham Kumar Bharti",
      "Xuezhou Zhang",
      "Adish Singla",
      "Xiaojin Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10532",
    "title": "Semantic Encoder Guided Generative Adversarial Face Ultra-Resolution  Network",
    "abstract": "Face super-resolution is a domain-specific image super-resolution, which aims to generate High-Resolution (HR) face images from their Low-Resolution (LR) counterparts. In this paper, we propose a novel face super-resolution method, namely Semantic Encoder guided Generative Adversarial Face Ultra-Resolution Network (SEGA-FURN) to ultra-resolve an unaligned tiny LR face image to its HR counterpart with multiple ultra-upscaling factors (e.g., 4x and 8x). The proposed network is composed of a novel semantic encoder that has the ability to capture the embedded semantics to guide adversarial learning and a novel generator that uses a hierarchical architecture named Residual in Internal Dense Block (RIDB). Moreover, we propose a joint discriminator which discriminates both image data and embedded semantics. The joint discriminator learns the joint probability distribution of the image space and latent space. We also use a Relativistic average Least Squares loss (RaLS) as the adversarial loss to alleviate the gradient vanishing problem and enhance the stability of the training procedure. Extensive experiments on large face datasets have proved that the proposed method can achieve superior super-resolution results and significantly outperform other state-of-the-art methods in both qualitative and quantitative comparisons. ",
    "url": "https://arxiv.org/abs/2211.10532",
    "authors": [
      "Xiang Wang",
      "Yimin Yang",
      "Qixiang Pang",
      "Xiao Lu",
      "Yu Liu",
      "Shan Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.10546",
    "title": "Evaluating COVID-19 Sequence Data Using Nearest-Neighbors Based Network  Model",
    "abstract": "The SARS-CoV-2 coronavirus is the cause of the COVID-19 disease in humans. Like many coronaviruses, it can adapt to different hosts and evolve into different lineages. It is well-known that the major SARS-CoV-2 lineages are characterized by mutations that happen predominantly in the spike protein. Understanding the spike protein structure and how it can be perturbed is vital for understanding and determining if a lineage is of concern. These are crucial to identifying and controlling current outbreaks and preventing future pandemics. Machine learning (ML) methods are a viable solution to this effort, given the volume of available sequencing data, much of which is unaligned or even unassembled. However, such ML methods require fixed-length numerical feature vectors in Euclidean space to be applicable. Similarly, euclidean space is not considered the best choice when working with the classification and clustering tasks for biological sequences. For this purpose, we design a method that converts the protein (spike) sequences into the sequence similarity network (SSN). We can then use SSN as an input for the classical algorithms from the graph mining domain for the typical tasks such as classification and clustering to understand the data. We show that the proposed alignment-free method is able to outperform the current SOTA method in terms of clustering results. Similarly, we are able to achieve higher classification accuracy using well-known Node2Vec-based embedding compared to other baseline embedding approaches. ",
    "url": "https://arxiv.org/abs/2211.10546",
    "authors": [
      "Sarwan Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2211.10556",
    "title": "A Distanced Matching Game, Decremental APSP in Expanders, and Faster  Deterministic Algorithms for Graph Cut Problems",
    "abstract": "Expander graphs play a central role in graph theory and algorithms. With a number of powerful algorithmic tools developed around them, such as the Cut-Matching game, expander pruning, expander decomposition, and algorithms for decremental All-Pairs Shortest Paths (APSP) in expanders, to name just a few, the use of expanders in the design of graph algorithms has become ubiquitous. Specific applications of interest to us are fast deterministic algorithms for cut problems in static graphs, and algorithms for dynamic distance-based graph problems, such as APSP. Unfortunately, the use of expanders in these settings incurs a number of drawbacks. For example, the best currently known algorithm for decremental APSP in constant-degree expanders can only achieve a $(\\log n)^{O(1/\\epsilon^2)}$-approximation with $n^{1+O(\\epsilon)}$ total update time for any $\\epsilon$. All currently known algorithms for the Cut Player in the Cut-Matching game are either randomized, or provide rather weak guarantees. This, in turn, leads to somewhat weak algorithmic guarantees for several central cut problems: for example, the best current almost linear time deterministic algorithm for Sparsest Cut can only achieve approximation factor $(\\log n)^{\\omega(1)}$. Lastly, when relying on expanders in distance-based problems, such as dynamic APSP, via current methods, it seems inevitable that one has to settle for approximation factors that are at least $\\Omega(\\log n)$. In this paper we propose the use of well-connected graphs, and introduce a new algorithmic toolkit for such graphs that, in a sense, mirrors the above mentioned algorithmic tools for expanders. One of these new tools is the Distanced Matching game, an analogue of the Cut-Matching game for well-connected graphs. We demonstrate the power of these new tools by obtaining better results for several of the problems mentioned above. ",
    "url": "https://arxiv.org/abs/2211.10556",
    "authors": [
      "Julia Chuzhoy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.10558",
    "title": "Neural frames: A Tool for Studying the Tangent Bundles Underlying Image  Datasets and How Deep Learning Models Process Them",
    "abstract": "The assumption that many forms of high-dimensional data, such as images, actually live on low-dimensional manifolds, sometimes known as the manifold hypothesis, underlies much of our intuition for how and why deep learning works. Despite the central role that they play in our intuition, data manifolds are surprisingly hard to measure in the case of high-dimensional, sparsely sampled image datasets. This is particularly frustrating since the capability to measure data manifolds would provide a revealing window into the inner workings and dynamics of deep learning models. Motivated by this, we introduce neural frames, a novel and easy to use tool inspired by the notion of a frame from differential geometry. Neural frames can be used to explore the local neighborhoods of data manifolds as they pass through the hidden layers of neural networks even when one only has a single datapoint available. We present a mathematical framework for neural frames and explore some of their properties. We then use them to make a range of observations about how modern model architectures and training routines, such as heavy augmentation and adversarial training, affect the local behavior of a model. ",
    "url": "https://arxiv.org/abs/2211.10558",
    "authors": [
      "Henry Kvinge",
      "Grayson Jorgenson",
      "Davis Brown",
      "Charles Godfrey",
      "Tegan Emerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10563",
    "title": "Real-World Image Super Resolution via Unsupervised Bi-directional Cycle  Domain Transfer Learning based Generative Adversarial Network",
    "abstract": "Deep Convolutional Neural Networks (DCNNs) have exhibited impressive performance on image super-resolution tasks. However, these deep learning-based super-resolution methods perform poorly in real-world super-resolution tasks, where the paired high-resolution and low-resolution images are unavailable and the low-resolution images are degraded by complicated and unknown kernels. To break these limitations, we propose the Unsupervised Bi-directional Cycle Domain Transfer Learning-based Generative Adversarial Network (UBCDTL-GAN), which consists of an Unsupervised Bi-directional Cycle Domain Transfer Network (UBCDTN) and the Semantic Encoder guided Super Resolution Network (SESRN). First, the UBCDTN is able to produce an approximated real-like LR image through transferring the LR image from an artificially degraded domain to the real-world LR image domain. Second, the SESRN has the ability to super-resolve the approximated real-like LR image to a photo-realistic HR image. Extensive experiments on unpaired real-world image benchmark datasets demonstrate that the proposed method achieves superior performance compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2211.10563",
    "authors": [
      "Xiang Wang",
      "Yimin Yang",
      "Zhichang Guo",
      "Zhili Zhou",
      "Yu Liu",
      "Qixiang Pang",
      "Shan Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.10564",
    "title": "Gumbel-Softmax Selective Networks",
    "abstract": "ML models often operate within the context of a larger system that can adapt its response when the ML model is uncertain, such as falling back on safe defaults or a human in the loop. This commonly encountered operational context calls for principled techniques for training ML models with the option to abstain from predicting when uncertain. Selective neural networks are trained with an integrated option to abstain, allowing them to learn to recognize and optimize for the subset of the data distribution for which confident predictions can be made. However, optimizing selective networks is challenging due to the non-differentiability of the binary selection function (the discrete decision of whether to predict or abstain). This paper presents a general method for training selective networks that leverages the Gumbel-softmax reparameterization trick to enable selection within an end-to-end differentiable training framework. Experiments on public datasets demonstrate the potential of Gumbel-softmax selective networks for selective regression and classification. ",
    "url": "https://arxiv.org/abs/2211.10564",
    "authors": [
      "Mahmoud Salem",
      "Mohamed Osama Ahmed",
      "Frederick Tung",
      "Gabriel Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10579",
    "title": "Tired of Over-smoothing? Stress Graph Drawing Is All You Need!",
    "abstract": "In designing and applying graph neural networks, we often fall into some optimization pitfalls, the most deceptive of which is that we can only build a deep model by solving over-smoothing. The fundamental reason is that we do not understand how graph neural networks work. Stress graph drawing can offer a unique viewpoint to message iteration in the graph, such as the root of the over-smoothing problem lies in the inability of graph models to maintain an ideal distance between nodes. We further elucidate the trigger conditions of over-smoothing and propose Stress Graph Neural Networks. By introducing the attractive and repulsive message passing from stress iteration, we show how to build a deep model without preventing over-smoothing, how to use repulsive information, and how to optimize the current message-passing scheme to approximate the full stress message propagation. By performing different tasks on 23 datasets, we verified the effectiveness of our attractive and repulsive models and the derived relationship between stress iteration and graph neural networks. We believe that stress graph drawing will be a popular resource for understanding and designing graph neural networks. ",
    "url": "https://arxiv.org/abs/2211.10579",
    "authors": [
      "Xue Li",
      "Yuanzhi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10581",
    "title": "Sparse4D: Multi-view 3D Object Detection with Sparse Spatial-Temporal  Fusion",
    "abstract": "Bird-eye-view (BEV) based methods have made great progress recently in multi-view 3D detection task. Comparing with BEV based methods, sparse based methods lag behind in performance, but still have lots of non-negligible merits. To push sparse 3D detection further, in this work, we introduce a novel method, named Sparse4D, which does the iterative refinement of anchor boxes via sparsely sampling and fusing spatial-temporal features. (1) Sparse 4D Sampling: for each 3D anchor, we assign multiple 4D keypoints, which are then projected to multi-view/scale/timestamp image features to sample corresponding features; (2) Hierarchy Feature Fusion: we hierarchically fuse sampled features of different view/scale, different timestamp and different keypoints to generate high-quality instance feature. In this way, Sparse4D can efficiently and effectively achieve 3D detection without relying on dense view transformation nor global attention, and is more friendly to edge devices deployment. Furthermore, we introduce an instance-level depth reweight module to alleviate the ill-posed issue in 3D-to-2D projection. In experiment, our method outperforms all sparse based methods and most BEV based methods on detection task in the nuScenes dataset. ",
    "url": "https://arxiv.org/abs/2211.10581",
    "authors": [
      "Xuewu Lin",
      "Tianwei Lin",
      "Zixiang Pei",
      "Lichao Huang",
      "Zhizhong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10594",
    "title": "Autoregressive GNN-ODE GRU Model for Network Dynamics",
    "abstract": "Revealing the continuous dynamics on the networks is essential for understanding, predicting, and even controlling complex systems, but it is hard to learn and model the continuous network dynamics because of complex and unknown governing equations, high dimensions of complex systems, and unsatisfactory observations. Moreover, in real cases, observed time-series data are usually non-uniform and sparse, which also causes serious challenges. In this paper, we propose an Autoregressive GNN-ODE GRU Model (AGOG) to learn and capture the continuous network dynamics and realize predictions of node states at an arbitrary time in a data-driven manner. The GNN module is used to model complicated and nonlinear network dynamics. The hidden state of node states is specified by the ODE system, and the augmented ODE system is utilized to map the GNN into the continuous time domain. The hidden state is updated through GRUCell by observations. As prior knowledge, the true observations at the same timestamp are combined with the hidden states for the next prediction. We use the autoregressive model to make a one-step ahead prediction based on observation history. The prediction is achieved by solving an initial-value problem for ODE. To verify the performance of our model, we visualize the learned dynamics and test them in three tasks: interpolation reconstruction, extrapolation prediction, and regular sequences prediction. The results demonstrate that our model can capture the continuous dynamic process of complex systems accurately and make precise predictions of node states with minimal error. Our model can consistently outperform other baselines or achieve comparable performance. ",
    "url": "https://arxiv.org/abs/2211.10594",
    "authors": [
      "Bo Liang",
      "Lin Wang",
      "Xiaofan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10595",
    "title": "Explainable Artificial Intelligence and Causal Inference based ATM Fraud  Detection",
    "abstract": "Gaining the trust of customers and providing them empathy are very critical in the financial domain. Frequent occurrence of fraudulent activities affects these two factors. Hence, financial organizations and banks must take utmost care to mitigate them. Among them, ATM fraudulent transaction is a common problem faced by banks. There following are the critical challenges involved in fraud datasets: the dataset is highly imbalanced, the fraud pattern is changing, etc. Owing to the rarity of fraudulent activities, Fraud detection can be formulated as either a binary classification problem or One class classification (OCC). In this study, we handled these techniques on an ATM transactions dataset collected from India. In binary classification, we investigated the effectiveness of various over-sampling techniques, such as the Synthetic Minority Oversampling Technique (SMOTE) and its variants, Generative Adversarial Networks (GAN), to achieve oversampling. Further, we employed various machine learning techniques viz., Naive Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), Gradient Boosting Tree (GBT), Multi-layer perceptron (MLP). GBT outperformed the rest of the models by achieving 0.963 AUC, and DT stands second with 0.958 AUC. DT is the winner if the complexity and interpretability aspects are considered. Among all the oversampling approaches, SMOTE and its variants were observed to perform better. In OCC, IForest attained 0.959 CR, and OCSVM secured second place with 0.947 CR. Further, we incorporated explainable artificial intelligence (XAI) and causal inference (CI) in the fraud detection framework and studied it through various analyses. ",
    "url": "https://arxiv.org/abs/2211.10595",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "Abhay Anand Mane",
      "Laveti Ramesh Naidu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2211.10597",
    "title": "Adjacent Slice Feature Guided 2.5D Network for Pulmonary Nodule  Segmentation",
    "abstract": "More and more attention has been paid to the segmentation of pulmonary nodules. Among the current methods based on deep learning, 3D segmentation methods directly input 3D images, which takes up a lot of memory and brings huge computation. However, most of the 2D segmentation methods with less parameters and calculation have the problem of lacking spatial relations between slices, resulting in poor segmentation performance. In order to solve these problems, we propose an adjacent slice feature guided 2.5D network. In this paper, we design an adjacent slice feature fusion model to introduce information from adjacent slices. To further improve the model performance, we construct a multi-scale fusion module to capture more context information, in addition, we design an edge-constrained loss function to optimize the segmentation results in the edge region. Fully experiments show that our method performs better than other existing methods in pulmonary nodule segmentation task. ",
    "url": "https://arxiv.org/abs/2211.10597",
    "authors": [
      "Xinwei Xue",
      "Gaoyu Wang",
      "Long Ma",
      "Qi Jia",
      "Yi Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10603",
    "title": "Investigating the Security of EV Charging Mobile Applications As an  Attack Surface",
    "abstract": "The adoption rate of EVs has witnessed a significant increase in recent years driven by multiple factors, chief among which is the increased flexibility and ease of access to charging infrastructure. To improve user experience, increase system flexibility and commercialize the charging process, mobile applications have been incorporated into the EV charging ecosystem. EV charging mobile applications allow consumers to remotely trigger actions on charging stations and use functionalities such as start/stop charging sessions, pay for usage, and locate charging stations, to name a few. In this paper, we study the security posture of the EV charging ecosystem against remote attacks, which exploit the insecurity of the EV charging mobile applications as an attack surface. We leverage a combination of static and dynamic analysis techniques to analyze the security of widely used EV charging mobile applications. Our analysis of 31 widely used mobile applications and their interactions with various components such as the cloud management systems indicate the lack of user/vehicle verification and improper authorization for critical functions, which lead to remote (dis)charging session hijacking and Denial of Service (DoS) attacks against the EV charging station. Indeed, we discuss specific remote attack scenarios and their impact on the EV users. More importantly, our analysis results demonstrate the feasibility of leveraging existing vulnerabilities across various EV charging mobile applications to perform wide-scale coordinated remote charging/discharging attacks against the connected critical infrastructure (e.g., power grid), with significant undesired economical and operational implications. Finally, we propose counter measures to secure the infrastructure and impede adversaries from performing reconnaissance and launching remote attacks using compromised accounts. ",
    "url": "https://arxiv.org/abs/2211.10603",
    "authors": [
      "K. Sarieddine",
      "M. A. Sayed",
      "S. Torabi",
      "R. Atallah",
      "C. Assi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10624",
    "title": "A Unified Model for Video Understanding and Knowledge Embedding with  Heterogeneous Knowledge Graph Dataset",
    "abstract": "Video understanding is an important task in short video business platforms and it has a wide application in video recommendation and classification. Most of the existing video understanding works only focus on the information that appeared within the video content, including the video frames, audio and text. However, introducing common sense knowledge from the external Knowledge Graph (KG) dataset is essential for video understanding when referring to the content which is less relevant to the video. Owing to the lack of video knowledge graph dataset, the work which integrates video understanding and KG is rare. In this paper, we propose a heterogeneous dataset that contains the multi-modal video entity and fruitful common sense relations. This dataset also provides multiple novel video inference tasks like the Video-Relation-Tag (VRT) and Video-Relation-Video (VRV) tasks. Furthermore, based on this dataset, we propose an end-to-end model that jointly optimizes the video understanding objective with knowledge graph embedding, which can not only better inject factual knowledge into video understanding but also generate effective multi-modal entity embedding for KG. Comprehensive experiments indicate that combining video understanding embedding with factual knowledge benefits the content-based video retrieval performance. Moreover, it also helps the model generate better knowledge graph embedding which outperforms traditional KGE-based methods on VRT and VRV tasks with at least 42.36% and 17.73% improvement in HITS@10. ",
    "url": "https://arxiv.org/abs/2211.10624",
    "authors": [
      "Jiaxin Deng",
      "Dong Shen",
      "Haojie Pan",
      "Xiangyu Wu",
      "Ximan Liu",
      "Gaofeng Meng",
      "Fan Yang",
      "Size Li",
      "Ruiji Fu",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10627",
    "title": "Graph Augmentation Clustering Network",
    "abstract": "Existing graph clustering networks heavily rely on a predefined graph and may fail if the initial graph is of low quality. To tackle this issue, we propose a novel graph augmentation clustering network capable of adaptively enhancing the initial graph to achieve better clustering performance. Specifically, we first integrate the node attribute and topology structure information to learn the latent feature representation. Then, we explore the local geometric structure information on the embedding space to construct an adjacency graph and subsequently develop an adaptive graph augmentation architecture to fuse that graph with the initial one dynamically. Finally, we minimize the Jeffreys divergence between multiple derived distributions to conduct network training in an unsupervised fashion. Extensive experiments on six commonly used benchmark datasets demonstrate that the proposed method consistently outperforms several state-of-the-art approaches. In particular, our method improves the ARI by more than 9.39\\% over the best baseline on DBLP. The source codes and data have been submitted to the appendix. ",
    "url": "https://arxiv.org/abs/2211.10627",
    "authors": [
      "Zhihao Peng",
      "Hui Liu",
      "Yuheng Jia",
      "Junhui Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.10629",
    "title": "Unifying Label-inputted Graph Neural Networks with Deep Equilibrium  Models",
    "abstract": "For node classification, Graph Neural Networks (GNN) assign predefined labels to graph nodes according to node features propagated along the graph structure. Apart from the traditional end-to-end manner inherited from deep learning, many subsequent works input assigned labels into GNNs to improve their classification performance. Such label-inputted GNNs (LGNN) combine the advantages of learnable feature propagation and long-range label propagation, producing state-of-the-art performance on various benchmarks. However, the theoretical foundations of LGNNs are not well-established, and the combination is with seam because the long-range propagation is memory-consuming for optimization. To this end, this work interprets LGNNs with the theory of Implicit GNN (IGNN), which outputs a fixed state point of iterating its network infinite times and optimizes the infinite-range propagation with constant memory consumption. Besides, previous contributions to LGNNs inspire us to overcome the heavy computation in training IGNN by iterating the network only once but starting from historical states, which are randomly masked in forward-pass to implicitly guarantee the existence and uniqueness of the fixed point. Our improvements to IGNNs are network agnostic: for the first time, they are extended with complex networks and applied to large-scale graphs. Experiments on two synthetic and six real-world datasets verify the advantages of our method in terms of long-range dependencies capturing, label transitions modelling, accuracy, scalability, efficiency, and well-posedness. ",
    "url": "https://arxiv.org/abs/2211.10629",
    "authors": [
      "Yi Luo",
      "Guiduo Duan",
      "Guangchun Luo",
      "Aiguo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10636",
    "title": "Efficient Video Representation Learning via Masked Video Modeling with  Motion-centric Token Selection",
    "abstract": "Self-supervised Video Representation Learning (VRL) aims to learn transferrable representations from uncurated, unlabeled video streams that could be utilized for diverse downstream tasks. With recent advances in Masked Image Modeling (MIM), in which the model learns to predict randomly masked regions in the images given only the visible patches, MIM-based VRL methods have emerged and demonstrated their potential by significantly outperforming previous VRL methods. However, they require an excessive amount of computations due to the added temporal dimension. This is because existing MIM-based VRL methods overlook spatial and temporal inequality of information density among the patches in arriving videos by resorting to random masking strategies, thereby wasting computations on predicting uninformative tokens/frames. To tackle these limitations of Masked Video Modeling, we propose a new token selection method that masks our more important tokens according to the object's motions in an online manner, which we refer to as Motion-centric Token Selection. Further, we present a dynamic frame selection strategy that allows the model to focus on informative and causal frames with minimal redundancy. We validate our method over multiple benchmark and Ego4D datasets, showing that the pre-trained model using our proposed method significantly outperforms state-of-the-art VRL methods on downstream tasks, such as action recognition and object state change classification while largely reducing memory requirements during pre-training and fine-tuning. ",
    "url": "https://arxiv.org/abs/2211.10636",
    "authors": [
      "Sunil Hwang",
      "Jaehong Yoon",
      "Youngwan Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10641",
    "title": "Domain-Adaptive Self-Supervised Pre-Training for Face & Body Detection  in Drawings",
    "abstract": "Drawings are powerful means of pictorial abstraction and communication. Understanding diverse forms of drawings, including digital arts, cartoons, and comics, has been a major problem of interest for the computer vision and computer graphics communities. Although there are large amounts of digitized drawings from comic books and cartoons, they contain vast stylistic variations, which necessitate expensive manual labeling for training domain-specific recognizers. In this work, we show how self-supervised learning, based on a teacher-student network with a modified student network update design, can be used to build face and body detectors. Our setup allows exploiting large amounts of unlabeled data from the target domain when labels are provided for only a small subset of it. We further demonstrate that style transfer can be incorporated into our learning pipeline to bootstrap detectors using a vast amount of out-of-domain labeled images from natural images (i.e., images from the real world). Our combined architecture yields detectors with state-of-the-art (SOTA) and near-SOTA performance using minimal annotation effort. ",
    "url": "https://arxiv.org/abs/2211.10641",
    "authors": [
      "Bar\u0131\u015f Batuhan Topal",
      "Deniz Yuret",
      "Tevfik Metin Sezgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10642",
    "title": "On the Multidimensional Augmentation of Fingerprint Data for Indoor  Localization in A Large-Scale Building Complex Based on Multi-Output Gaussian  Process",
    "abstract": "Wi-Fi fingerprinting becomes a dominant solution for large-scale indoor localization due to its major advantage of not requiring new infrastructure and dedicated devices. The number and the distribution of Reference Points (RPs) for the measurement of localization fingerprints like RSSI during the offline phase, however, greatly affects the localization accuracy; for instance, the UJIIndoorLoc is known to have the issue of uneven spatial distribution of RPs over buildings and floors. Data augmentation has been proposed as a feasible solution to not only improve the smaller number and the uneven distribution of RPs in the existing fingerprint databases but also reduce the labor and time costs of constructing new fingerprint databases. In this paper, we propose the multidimensional augmentation of fingerprint data for indoor localization in a large-scale building complex based on Multi-Output Gaussian Process (MOGP) and systematically investigate the impact of augmentation ratio as well as MOGP kernel functions and models with their hyperparameters on the performance of indoor localization using the UJIIndoorLoc database and the state-of-the-art neural network indoor localization model based on a hierarchical RNN. The investigation based on experimental results suggests that we can generate synthetic RSSI fingerprint data up to ten times the original data -- i.e., the augmentation ratio of 10 -- through the proposed multidimensional MOGP-based data augmentation without significantly affecting the indoor localization performance compared to that of the original data alone, which extends the spatial coverage of the combined RPs and thereby could improve the localization performance at the locations that are not part of the test dataset. ",
    "url": "https://arxiv.org/abs/2211.10642",
    "authors": [
      "Zhe Tang",
      "Sihao Li",
      "Kyeong Soo Kim",
      "Jeremy Smith"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10643",
    "title": "Downscaled Representation Matters: Improving Image Rescaling with  Collaborative Downscaled Images",
    "abstract": "Deep networks have achieved great success in image rescaling (IR) task that seeks to learn the optimal downscaled representations, i.e., low-resolution (LR) images, to reconstruct the original high-resolution (HR) images. Compared with super-resolution methods that consider a fixed downscaling scheme, e.g., bicubic, IR often achieves significantly better reconstruction performance thanks to the learned downscaled representations. This highlights the importance of a good downscaled representation in image reconstruction tasks. Existing IR methods mainly learn the downscaled representation by jointly optimizing the downscaling and upscaling models. Unlike them, we seek to improve the downscaled representation through a different and more direct way: optimizing the downscaled image itself instead of the down-/upscaling models. Specifically, we propose a collaborative downscaling scheme that directly generates the collaborative LR examples by descending the gradient w.r.t. the reconstruction loss on them to benefit the IR process. Furthermore, since LR images are downscaled from the corresponding HR images, one can also improve the downscaled representation if we have a better representation in the HR domain. Inspired by this, we propose a Hierarchical Collaborative Downscaling (HCD) method that performs gradient descent in both HR and LR domains to improve the downscaled representations. Extensive experiments show that our HCD significantly improves the reconstruction performance both quantitatively and qualitatively. Moreover, we also highlight the flexibility of our HCD since it can generalize well across diverse IR models. ",
    "url": "https://arxiv.org/abs/2211.10643",
    "authors": [
      "Bingna Xu",
      "Yong Guo",
      "Luoqian Jiang",
      "Mianjie Yu",
      "Jian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10648",
    "title": "Anonymizing Periodical Releases of SRS Data by Fusing Differential  Privacy",
    "abstract": "Spontaneous reporting systems (SRS) have been developed to collect adverse event records that contain personal demographics and sensitive information like drug indications and adverse reactions. The release of SRS data may disclose the privacy of the data provider. Unlike other microdata, very few anonymyization methods have been proposed to protect individual privacy while publishing SRS data. MS(k, {\\theta}*)-bounding is the first privacy model for SRS data that considers multiple individual records, mutli-valued sensitive attributes, and rare events. PPMS(k, {\\theta}*)-bounding then is proposed for solving cross-release attacks caused by the follow-up cases in the periodical SRS releasing scenario. A recent trend of microdata anonymization combines the traditional syntactic model and differential privacy, fusing the advantages of both models to yield a better privacy protection method. This paper proposes the PPMS-DP(k, {\\theta}*, {\\epsilon}) framework, an enhancement of PPMS(k, {\\theta}*)-bounding that embraces differential privacy to improve privacy protection of periodically released SRS data. We propose two anonymization algorithms conforming to the PPMS-DP(k, {\\theta}*, {\\epsilon}) framework, PPMS-DPnum and PPMS-DPall. Experimental results on the FAERS datasets show that both PPMS-DPnum and PPMS-DPall provide significantly better privacy protection than PPMS-(k, {\\theta}*)-bounding without sacrificing data distortion and data utility. ",
    "url": "https://arxiv.org/abs/2211.10648",
    "authors": [
      "Yi-Yuang Wu",
      "Zhi-Xun Shen",
      "Wen-Yang Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10661",
    "title": "Phonemic Adversarial Attack against Audio Recognition in Real World",
    "abstract": "Recently, adversarial attacks for audio recognition have attracted much attention. However, most of the existing studies mainly rely on the coarse-grain audio features at the instance level to generate adversarial noises, which leads to expensive generation time costs and weak universal attacking ability. Motivated by the observations that all audio speech consists of fundamental phonemes, this paper proposes a phonemic adversarial tack (PAT) paradigm, which attacks the fine-grain audio features at the phoneme level commonly shared across audio instances, to generate phonemic adversarial noises, enjoying the more general attacking ability with fast generation speed. Specifically, for accelerating the generation, a phoneme density balanced sampling strategy is introduced to sample quantity less but phonemic features abundant audio instances as the training data via estimating the phoneme density, which substantially alleviates the heavy dependency on the large training dataset. Moreover, for promoting universal attacking ability, the phonemic noise is optimized in an asynchronous way with a sliding window, which enhances the phoneme diversity and thus well captures the critical fundamental phonemic patterns. By conducting extensive experiments, we comprehensively investigate the proposed PAT framework and demonstrate that it outperforms the SOTA baselines by large margins (i.e., at least 11X speed up and 78% attacking ability improvement). ",
    "url": "https://arxiv.org/abs/2211.10661",
    "authors": [
      "Jiakai Wang",
      "Zhendong Chen",
      "Zixin Yin",
      "Qinghong Yang",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.10670",
    "title": "Towards Adversarial Robustness of Deep Vision Algorithms",
    "abstract": "Deep learning methods have achieved great success in solving computer vision tasks, and they have been widely utilized in artificially intelligent systems for image processing, analysis, and understanding. However, deep neural networks have been shown to be vulnerable to adversarial perturbations in input data. The security issues of deep neural networks have thus come to the fore. It is imperative to study the adversarial robustness of deep vision algorithms comprehensively. This talk focuses on the adversarial robustness of image classification models and image denoisers. We will discuss the robustness of deep vision algorithms from three perspectives: 1) robustness evaluation (we propose the ObsAtk to evaluate the robustness of denoisers), 2) robustness improvement (HAT, TisODE, and CIFS are developed to robustify vision models), and 3) the connection between adversarial robustness and generalization capability to new domains (we find that adversarially robust denoisers can deal with unseen types of real-world noise). ",
    "url": "https://arxiv.org/abs/2211.10670",
    "authors": [
      "Hanshu Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10672",
    "title": "Leveraging Users' Social Network Embeddings for Fake News Detection on  Twitter",
    "abstract": "Social networks (SNs) are increasingly important sources of news for many people. The online connections made by users allows information to spread more easily than traditional news media (e.g., newspaper, television). However, they also make the spread of fake news easier than in traditional media, especially through the users' social network connections. In this paper, we focus on investigating if the SNs' users connection structure can aid fake news detection on Twitter. In particular, we propose to embed users based on their follower or friendship networks on the Twitter platform, so as to identify the groups that users form. Indeed, by applying unsupervised graph embedding methods on the graphs from the Twitter users' social network connections, we observe that users engaged with fake news are more tightly clustered together than users only engaged in factual news. Thus, we hypothesise that the embedded user's network can help detect fake news effectively. Through extensive experiments using a publicly available Twitter dataset, our results show that applying graph embedding methods on SNs, using the user connections as network information, can indeed classify fake news more effectively than most language-based approaches. Specifically, we observe a significant improvement over using only the textual information (i.e., TF.IDF or a BERT language model), as well as over models that deploy both advanced textual features (i.e., stance detection) and complex network features (e.g., users network, publishers cross citations). We conclude that the Twitter users' friendship and followers network information can significantly outperform language-based approaches, as well as the existing state-of-the-art fake news detection models that use a more sophisticated network structure, in classifying fake news on Twitter. ",
    "url": "https://arxiv.org/abs/2211.10672",
    "authors": [
      "Ting Su",
      "Craig Macdonald",
      "Iadh Ounis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.10685",
    "title": "Pairwise Instance Relation Augmentation for Long-tailed Multi-label Text  Classification",
    "abstract": "Multi-label text classification (MLTC) is one of the key tasks in natural language processing. It aims to assign multiple target labels to one document. Due to the uneven popularity of labels, the number of documents per label follows a long-tailed distribution in most cases. It is much more challenging to learn classifiers for data-scarce tail labels than for data-rich head labels. The main reason is that head labels usually have sufficient information, e.g., a large intra-class diversity, while tail labels do not. In response, we propose a Pairwise Instance Relation Augmentation Network (PIRAN) to augment tailed-label documents for balancing tail labels and head labels. PIRAN consists of a relation collector and an instance generator. The former aims to extract the document pairwise relations from head labels. Taking these relations as perturbations, the latter tries to generate new document instances in high-level feature space around the limited given tailed-label instances. Meanwhile, two regularizers (diversity and consistency) are designed to constrain the generation process. The consistency-regularizer encourages the variance of tail labels to be close to head labels and further balances the whole datasets. And diversity-regularizer makes sure the generated instances have diversity and avoids generating redundant instances. Extensive experimental results on three benchmark datasets demonstrate that PIRAN consistently outperforms the SOTA methods, and dramatically improves the performance of tail labels. ",
    "url": "https://arxiv.org/abs/2211.10685",
    "authors": [
      "Lin Xiao",
      "Pengyu Xu",
      "Liping Jing",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.10686",
    "title": "Spikeformer: A Novel Architecture for Training High-Performance  Low-Latency Spiking Neural Network",
    "abstract": "Spiking neural networks (SNNs) have made great progress on both performance and efficiency over the last few years,but their unique working pattern makes it hard to train a high-performance low-latency SNN.Thus the development of SNNs still lags behind traditional artificial neural networks (ANNs).To compensate this gap,many extraordinary works have been proposed.Nevertheless,these works are mainly based on the same kind of network structure (i.e.CNN) and their performance is worse than their ANN counterparts,which limits the applications of SNNs.To this end,we propose a novel Transformer-based SNN,termed \"Spikeformer\",which outperforms its ANN counterpart on both static dataset and neuromorphic dataset and may be an alternative architecture to CNN for training high-performance SNNs.First,to deal with the problem of \"data hungry\" and the unstable training period exhibited in the vanilla model,we design the Convolutional Tokenizer (CT) module,which improves the accuracy of the original model on DVS-Gesture by more than 16%.Besides,in order to better incorporate the attention mechanism inside Transformer and the spatio-temporal information inherent to SNN,we adopt spatio-temporal attention (STA) instead of spatial-wise or temporal-wise attention.With our proposed method,we achieve competitive or state-of-the-art (SOTA) SNN performance on DVS-CIFAR10,DVS-Gesture,and ImageNet datasets with the least simulation time steps (i.e.low latency).Remarkably,our Spikeformer outperforms other SNNs on ImageNet by a large margin (i.e.more than 5%) and even outperforms its ANN counterpart by 3.1% and 2.2% on DVS-Gesture and ImageNet respectively,indicating that Spikeformer is a promising architecture for training large-scale SNNs and may be more suitable for SNNs compared to CNN.We believe that this work shall keep the development of SNNs in step with ANNs as much as possible.Code will be available. ",
    "url": "https://arxiv.org/abs/2211.10686",
    "authors": [
      "Yudong Li",
      "Yunlin Lei",
      "Xu Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10688",
    "title": "ReInform: Selecting paths with reinforcement learning for contextualized  link prediction",
    "abstract": "We propose to use reinforcement learning to inform transformer-based contextualized link prediction models by providing paths that are most useful for predicting the correct answer. This is in contrast to previous approaches, that either used reinforcement learning (RL) to directly search for the answer, or based their prediction on limited or randomly selected context. Our experiments on WN18RR and FB15k-237 show that contextualized link prediction models consistently outperform RL-based answer search, and that additional improvements (of up to 13.5\\% MRR) can be gained by combining RL with a link prediction model. ",
    "url": "https://arxiv.org/abs/2211.10688",
    "authors": [
      "Marina Speranskaya",
      "Sameh Methias",
      "Benjamin Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10699",
    "title": "Wireless Connectivity of a Ground-and-Air Sensor Network",
    "abstract": "This paper shows that, when considering outdoor scenarios and wireless communications using the IEEE 802.11 protocol with dipole antennas, the ground reflection is a significant propagation mechanism. This way, the Two-Ray model for this environment allows predicting, with some accuracy, the received signal power. This study is relevant for the application in the communication between overflying Unmanned Aerial Vehicles (UAVs) and ground sensors. In the proposed Wireless Sensor Network (WSN) scenario, the UAVs must receive information from the environment, which is collected by sensors positioned on the ground, and need to maintain connectivity between them and the base station, in order to maintain the quality of service, while moving through the environment. ",
    "url": "https://arxiv.org/abs/2211.10699",
    "authors": [
      "Clara R. P. Baldansa",
      "Roberto C. G. Porto",
      "Bruno Jos\u00e9 Olivieri de Souza",
      "V\u00edtor G. Andrezo Carneiro",
      "Markus Endler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.10708",
    "title": "A Survey on Differential Privacy with Machine Learning and Future  Outlook",
    "abstract": "Nowadays, machine learning models and applications have become increasingly pervasive. With this rapid increase in the development and employment of machine learning models, a concern regarding privacy has risen. Thus, there is a legitimate need to protect the data from leaking and from any attacks. One of the strongest and most prevalent privacy models that can be used to protect machine learning models from any attacks and vulnerabilities is differential privacy (DP). DP is strict and rigid definition of privacy, where it can guarantee that an adversary is not capable to reliably predict if a specific participant is included in the dataset or not. It works by injecting a noise to the data whether to the inputs, the outputs, the ground truth labels, the objective functions, or even to the gradients to alleviate the privacy issue and protect the data. To this end, this survey paper presents different differentially private machine learning algorithms categorized into two main categories (traditional machine learning models vs. deep learning models). Moreover, future research directions for differential privacy with machine learning algorithms are outlined. ",
    "url": "https://arxiv.org/abs/2211.10708",
    "authors": [
      "Samah Baraheem",
      "Zhongmei Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10718",
    "title": "Upper and Lower Bounds on Bit-Error Rate for Convolutional Codes",
    "abstract": "In this paper, we provide a new approach to the analytical estimation of the bit-error rate (BER) for convolutional codes for Viterbi decoding in the binary symmetric channel (BSC). The expressions we obtained for lower and upper BER bounds are based on the active distances of the code and their distance spectrum. The estimates are derived for convolutional codes with the rate $R=\\frac{1}{2}$ but can be easily generalized for any convolutional code with rate $R=\\frac 1n$ and systematic encoder. The suggested approach is not computationally expensive for any crossover probability of BSC channel and convolutional code memory, and it allows to obtain precise estimates of BER. ",
    "url": "https://arxiv.org/abs/2211.10718",
    "authors": [
      "Anastasia Kurmukova",
      "Fedor Ivanov",
      "Victor Zyablov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2211.10724",
    "title": "Deep Smart Contract Intent Detection",
    "abstract": "Nowadays, security activities in smart contracts concentrate on vulnerability detection. Despite early success, we find that developers' intent to write smart contracts is a more noteworthy security concern because smart contracts with malicious intent have caused significant users' financial loss. Unfortunately, current approaches to identify the aforementioned malicious smart contracts rely on smart contract security audits, which entail huge manpower consumption and financial expenditure. To resolve this issue, we propose a novel deep learning-based approach, SmartIntentNN, to conduct automated smart contract intent detection. SmartIntentNN consists of three primary parts: a pre-trained sentence encoder to generate the contextual representations of smart contracts, a K-means clustering method to highlight intent-related representations, and a bidirectional LSTM-based (long-short term memory) multi-label classification network to predict the intents in smart contracts. To evaluate the performance of SmartIntentNN, we collect more than 40,000 real smart contracts and perform a series of comparison experiments with our selected baseline approaches. The experimental results demonstrate that SmartIntentNN outperforms all baselines by up to 0.8212 in terms of the f1-score metric. ",
    "url": "https://arxiv.org/abs/2211.10724",
    "authors": [
      "Youwei Huang",
      "Tao Zhang",
      "Sen Fang",
      "Youshuai Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10738",
    "title": "Relational Symmetry based Knowledge Graph Contrastive Learning",
    "abstract": "Knowledge graph embedding (KGE) aims to learn powerful representations to benefit various artificial intelligence applications, such as question answering and recommendations. Meanwhile, contrastive learning (CL), as an effective mechanism to enhance the discriminative capacity of the learned representations, has been leveraged in different fields, especially graph-based models. However, since the structures of knowledge graphs (KGs) are usually more complicated compared to homogeneous graphs, it is hard to construct appropriate contrastive sample pairs. In this paper, we find that the entities within a symmetrical structure are usually more similar and correlated. This key property can be utilized to construct contrastive positive pairs for contrastive learning. Following the ideas above, we propose a relational symmetrical structure based knowledge graph contrastive learning framework, termed KGE-SymCL, which leverages the symmetrical structure information in KGs to enhance the discriminative ability of KGE models. Concretely, a plug-and-play approach is designed by taking the entities in the relational symmetrical positions as the positive samples. Besides, a self-supervised alignment loss is used to pull together the constructed positive sample pairs for contrastive learning. Extensive experimental results on benchmark datasets have verified the good generalization and superiority of the proposed framework. ",
    "url": "https://arxiv.org/abs/2211.10738",
    "authors": [
      "Ke Liang",
      "Yue Liu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Wenxuan Tu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10743",
    "title": "Monitoring the edges of product networks using distances",
    "abstract": "Foucaud {\\it et al.} recently introduced and initiated the study of a new graph-theoretic concept in the area of network monitoring. Let $G$ be a graph with vertex set $V(G)$, $M$ a subset of $V(G)$, and $e$ be an edge in $E(G)$, and let $P(M, e)$ be the set of pairs $(x,y)$ such that $d_G(x, y)\\neq d_{G-e}(x, y)$ where $x\\in M$ and $y\\in V(G)$. $M$ is called a \\emph{distance-edge-monitoring set} if every edge $e$ of $G$ is monitored by some vertex of $M$, that is, the set $P(M, e)$ is nonempty. The {\\em distance-edge-monitoring number} of $G$, denoted by $\\operatorname{dem}(G)$, is defined as the smallest size of distance-edge-monitoring sets of $G$. For two graphs $G,H$ of order $m,n$, respectively, in this paper we prove that $\\max\\{m\\operatorname{dem}(H),n\\operatorname{dem}(G)\\} \\leq\\operatorname{dem}(G\\,\\Box \\,H) \\leq m\\operatorname{dem}(H)+n\\operatorname{dem}(G) -\\operatorname{dem}(G)\\operatorname{dem}(H)$, where $\\Box$ is the Cartesian product operation. Moreover, we characterize the graphs attaining the upper and lower bounds and show their applications on some known networks. We also obtain the distance-edge-monitoring numbers of join, corona, cluster, and some specific networks. ",
    "url": "https://arxiv.org/abs/2211.10743",
    "authors": [
      "Wen Li",
      "Ralf Klasing",
      "Yaping Mao",
      "Bo Ning"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Networking and Internet Architecture (cs.NI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2211.10752",
    "title": "Towards Robust Dataset Learning",
    "abstract": "Adversarial training has been actively studied in recent computer vision research to improve the robustness of models. However, due to the huge computational cost of generating adversarial samples, adversarial training methods are often slow. In this paper, we study the problem of learning a robust dataset such that any classifier naturally trained on the dataset is adversarially robust. Such a dataset benefits the downstream tasks as natural training is much faster than adversarial training, and demonstrates that the desired property of robustness is transferable between models and data. In this work, we propose a principled, tri-level optimization to formulate the robust dataset learning problem. We show that, under an abstraction model that characterizes robust vs. non-robust features, the proposed method provably learns a robust dataset. Extensive experiments on MNIST, CIFAR10, and TinyImageNet demostrate the effectiveness of our algorithm with different network initializations and architectures. ",
    "url": "https://arxiv.org/abs/2211.10752",
    "authors": [
      "Yihan Wu",
      "Xinda Li",
      "Florian Kerschbaum",
      "Heng Huang",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10763",
    "title": "PIDray: A Large-scale X-ray Benchmark for Real-World Prohibited Item  Detection",
    "abstract": "Automatic security inspection relying on computer vision technology is a challenging task in real-world scenarios due to many factors, such as intra-class variance, class imbalance, and occlusion. Most previous methods rarely touch the cases where the prohibited items are deliberately hidden in messy objects because of the scarcity of large-scale datasets, hindering their applications. To address this issue and facilitate related research, we present a large-scale dataset, named PIDray, which covers various cases in real-world scenarios for prohibited item detection, especially for deliberately hidden items. In specific, PIDray collects 124,486 X-ray images for $12$ categories of prohibited items, and each image is manually annotated with careful inspection, which makes it, to our best knowledge, to largest prohibited items detection dataset to date. Meanwhile, we propose a general divide-and-conquer pipeline to develop baseline algorithms on PIDray. Specifically, we adopt the tree-like structure to suppress the influence of the long-tailed issue in the PIDray dataset, where the first course-grained node is tasked with the binary classification to alleviate the influence of head category, while the subsequent fine-grained node is dedicated to the specific tasks of the tail categories. Based on this simple yet effective scheme, we offer strong task-specific baselines across object detection, instance segmentation, and multi-label classification tasks and verify the generalization ability on common datasets (e.g., COCO and PASCAL VOC). Extensive experiments on PIDray demonstrate that the proposed method performs favorably against current state-of-the-art methods, especially for deliberately hidden items. Our benchmark and codes will be released at https://github.com/lutao2021/PIDray. ",
    "url": "https://arxiv.org/abs/2211.10763",
    "authors": [
      "Libo Zhang",
      "Lutao Jiang",
      "Ruyi Ji",
      "Heng Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10782",
    "title": "Let Graph be the Go Board: Gradient-free Node Injection Attack for Graph  Neural Networks via Reinforcement Learning",
    "abstract": "Graph Neural Networks (GNNs) have drawn significant attentions over the years and been broadly applied to essential applications requiring solid robustness or vigorous security standards, such as product recommendation and user behavior modeling. Under these scenarios, exploiting GNN's vulnerabilities and further downgrading its performance become extremely incentive for adversaries. Previous attackers mainly focus on structural perturbations or node injections to the existing graphs, guided by gradients from the surrogate models. Although they deliver promising results, several limitations still exist. For the structural perturbation attack, to launch a proposed attack, adversaries need to manipulate the existing graph topology, which is impractical in most circumstances. Whereas for the node injection attack, though being more practical, current approaches require training surrogate models to simulate a white-box setting, which results in significant performance downgrade when the surrogate architecture diverges from the actual victim model. To bridge these gaps, in this paper, we study the problem of black-box node injection attack, without training a potentially misleading surrogate model. Specifically, we model the node injection attack as a Markov decision process and propose Gradient-free Graph Advantage Actor Critic, namely G2A2C, a reinforcement learning framework in the fashion of advantage actor critic. By directly querying the victim model, G2A2C learns to inject highly malicious nodes with extremely limited attacking budgets, while maintaining a similar node feature distribution. Through our comprehensive experiments over eight acknowledged benchmark datasets with different characteristics, we demonstrate the superior performance of our proposed G2A2C over the existing state-of-the-art attackers. Source code is publicly available at: https://github.com/jumxglhf/G2A2C}. ",
    "url": "https://arxiv.org/abs/2211.10782",
    "authors": [
      "Mingxuan Ju",
      "Yujie Fan",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10791",
    "title": "NIO: Lightweight neural operator-based architecture for video frame  interpolation",
    "abstract": "We present, NIO - Neural Interpolation Operator, a lightweight efficient neural operator-based architecture to perform video frame interpolation. Current deep learning based methods rely on local convolutions for feature learning and require a large amount of training on comprehensive datasets. Furthermore, transformer-based architectures are large and need dedicated GPUs for training. On the other hand, NIO, our neural operator-based approach learns the features in the frames by translating the image matrix into the Fourier space by using Fast Fourier Transform (FFT). The model performs global convolution, making it discretization invariant. We show that NIO can produce visually-smooth and accurate results and converges in fewer epochs than state-of-the-art approaches. To evaluate the visual quality of our interpolated frames, we calculate the structural similarity index (SSIM) and Peak Signal to Noise Ratio (PSNR) between the generated frame and the ground truth frame. We provide the quantitative performance of our model on Vimeo-90K dataset, DAVIS, UCF101 and DISFA+ dataset. ",
    "url": "https://arxiv.org/abs/2211.10791",
    "authors": [
      "Hrishikesh Viswanath",
      "Md Ashiqur Rahman",
      "Rashmi Bhaskara",
      "Aniket Bera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10793",
    "title": "BENK: The Beran Estimator with Neural Kernels for Estimating the  Heterogeneous Treatment Effect",
    "abstract": "A method for estimating the conditional average treatment effect under condition of censored time-to-event data called BENK (the Beran Estimator with Neural Kernels) is proposed. The main idea behind the method is to apply the Beran estimator for estimating the survival functions of controls and treatments. Instead of typical kernel functions in the Beran estimator, it is proposed to implement kernels in the form of neural networks of a specific form called the neural kernels. The conditional average treatment effect is estimated by using the survival functions as outcomes of the control and treatment neural networks which consists of a set of neural kernels with shared parameters. The neural kernels are more flexible and can accurately model a complex location structure of feature vectors. Various numerical simulation experiments illustrate BENK and compare it with the well-known T-learner, S-learner and X-learner for several types of the control and treatment outcome functions based on the Cox models, the random survival forest and the Nadaraya-Watson regression with Gaussian kernels. The code of proposed algorithms implementing BENK is available in https://github.com/Stasychbr/BENK. ",
    "url": "https://arxiv.org/abs/2211.10793",
    "authors": [
      "Stanislav R. Kirpichenko",
      "Lev V. Utkin",
      "Andrei V. Konstantinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.10794",
    "title": "NVDiff: Graph Generation through the Diffusion of Node Vectors",
    "abstract": "Learning to generate graphs is challenging as a graph is a set of pairwise connected, unordered nodes encoding complex combinatorial structures. Recently, several works have proposed graph generative models based on normalizing flows or score-based diffusion models. However, these models need to generate nodes and edges in parallel from the same process, whose dimensionality is unnecessarily high. We propose NVDiff, which takes the VGAE structure and uses a score-based generative model (SGM) as a flexible prior to sample node vectors. By modeling only node vectors in the latent space, NVDiff significantly reduces the dimension of the diffusion process and thus improves sampling speed. Built on the NVDiff framework, we introduce an attention-based score network capable of capturing both local and global contexts of graphs. Experiments indicate that NVDiff significantly reduces computations and can model much larger graphs than competing methods. At the same time, it achieves superior or competitive performances over various datasets compared to previous methods. ",
    "url": "https://arxiv.org/abs/2211.10794",
    "authors": [
      "Xiaohui Chen",
      "Yukun Li",
      "Aonan Zhang",
      "Li-ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10821",
    "title": "DeepGAR: Deep Graph Learning for Analogical Reasoning",
    "abstract": "Analogical reasoning is the process of discovering and mapping correspondences from a target subject to a base subject. As the most well-known computational method of analogical reasoning, Structure-Mapping Theory (SMT) abstracts both target and base subjects into relational graphs and forms the cognitive process of analogical reasoning by finding a corresponding subgraph (i.e., correspondence) in the target graph that is aligned with the base graph. However, incorporating deep learning for SMT is still under-explored due to several obstacles: 1) the combinatorial complexity of searching for the correspondence in the target graph; 2) the correspondence mining is restricted by various cognitive theory-driven constraints. To address both challenges, we propose a novel framework for Analogical Reasoning (DeepGAR) that identifies the correspondence between source and target domains by assuring cognitive theory-driven constraints. Specifically, we design a geometric constraint embedding space to induce subgraph relation from node embeddings for efficient subgraph search. Furthermore, we develop novel learning and optimization strategies that could end-to-end identify correspondences that are strictly consistent with constraints driven by the cognitive theory. Extensive experiments are conducted on synthetic and real-world datasets to demonstrate the effectiveness of the proposed DeepGAR over existing methods. ",
    "url": "https://arxiv.org/abs/2211.10821",
    "authors": [
      "Chen Ling",
      "Tanmoy Chowdhury",
      "Junji Jiang",
      "Junxiang Wang",
      "Xuchao Zhang",
      "Haifeng Chen",
      "Liang Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.10830",
    "title": "Discrete Lagrangian Neural Networks with Automatic Symmetry Discovery",
    "abstract": "By one of the most fundamental principles in physics, a dynamical system will exhibit those motions which extremise an action functional. This leads to the formation of the Euler-Lagrange equations, which serve as a model of how the system will behave in time. If the dynamics exhibit additional symmetries, then the motion fulfils additional conservation laws, such as conservation of energy (time invariance), momentum (translation invariance), or angular momentum (rotational invariance). To learn a system representation, one could learn the discrete Euler-Lagrange equations, or alternatively, learn the discrete Lagrangian function $\\mathcal{L}_d$ which defines them. Based on ideas from Lie group theory, in this work we introduce a framework to learn a discrete Lagrangian along with its symmetry group from discrete observations of motions and, therefore, identify conserved quantities. The learning process does not restrict the form of the Lagrangian, does not require velocity or momentum observations or predictions and incorporates a cost term which safeguards against unwanted solutions and against potential numerical issues in forward simulations. The learnt discrete quantities are related to their continuous analogues using variational backward error analysis and numerical results demonstrate the improvement such models can have both qualitatively and quantitatively even in the presence of noise. ",
    "url": "https://arxiv.org/abs/2211.10830",
    "authors": [
      "Yana Lishkova",
      "Paul Scherer",
      "Steffen Ridderbusch",
      "Mateja Jamnik",
      "Pietro Li\u00f2",
      "Sina Ober-Bl\u00f6baum",
      "Christian Offen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Symplectic Geometry (math.SG)"
    ]
  },
  {
    "id": "arXiv:2211.10831",
    "title": "Joint Embedding Predictive Architectures Focus on Slow Features",
    "abstract": "Many common methods for learning a world model for pixel-based environments use generative architectures trained with pixel-level reconstruction objectives. Recently proposed Joint Embedding Predictive Architectures (JEPA) offer a reconstruction-free alternative. In this work, we analyze performance of JEPA trained with VICReg and SimCLR objectives in the fully offline setting without access to rewards, and compare the results to the performance of the generative architecture. We test the methods in a simple environment with a moving dot with various background distractors, and probe learned representations for the dot's location. We find that JEPA methods perform on par or better than reconstruction when distractor noise changes every time step, but fail when the noise is fixed. Furthermore, we provide a theoretical explanation for the poor performance of JEPA-based methods with fixed noise, highlighting an important limitation. ",
    "url": "https://arxiv.org/abs/2211.10831",
    "authors": [
      "Vlad Sobal",
      "Jyothir S V",
      "Siddhartha Jalagam",
      "Nicolas Carion",
      "Kyunghyun Cho",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10832",
    "title": "NeuroSketch: Fast and Approximate Evaluation of Range Aggregate Queries  with Neural Networks",
    "abstract": "Range aggregate queries (RAQs) are an integral part of many real-world applications, where, often, fast and approximate answers for the queries are desired. Recent work has studied answering RAQs using machine learning (ML) models, where a model of the data is learned to answer the queries. However, there is no theoretical understanding of why and when the ML based approaches perform well. Furthermore, since the ML approaches model the data, they fail to capitalize on any query specific information to improve performance in practice. In this paper, we focus on modeling ``queries'' rather than data and train neural networks to learn the query answers. This change of focus allows us to theoretically study our ML approach to provide a distribution and query dependent error bound for neural networks when answering RAQs. We confirm our theoretical results by developing NeuroSketch, a neural network framework to answer RAQs in practice. Extensive experimental study on real-world, TPC-benchmark and synthetic datasets show that NeuroSketch answers RAQs multiple orders of magnitude faster than state-of-the-art and with better accuracy. ",
    "url": "https://arxiv.org/abs/2211.10832",
    "authors": [
      "Sepanta Zeighami",
      "Cyrus Shahabi",
      "Vatsal Sharan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2211.10841",
    "title": "SeDR: Segment Representation Learning for Long Documents Dense Retrieval",
    "abstract": "Recently, Dense Retrieval (DR) has become a promising solution to document retrieval, where document representations are used to perform effective and efficient semantic search. However, DR remains challenging on long documents, due to the quadratic complexity of its Transformer-based encoder and the finite capacity of a low-dimension embedding. Current DR models use suboptimal strategies such as truncating or splitting-and-pooling to long documents leading to poor utilization of whole document information. In this work, to tackle this problem, we propose Segment representation learning for long documents Dense Retrieval (SeDR). In SeDR, Segment-Interaction Transformer is proposed to encode long documents into document-aware and segment-sensitive representations, while it holds the complexity of splitting-and-pooling and outperforms other segment-interaction patterns on DR. Since GPU memory requirements for long document encoding causes insufficient negatives for DR training, Late-Cache Negative is further proposed to provide additional cache negatives for optimizing representation learning. Experiments on MS MARCO and TREC-DL datasets show that SeDR achieves superior performance among DR models, and confirm the effectiveness of SeDR on long document retrieval. ",
    "url": "https://arxiv.org/abs/2211.10841",
    "authors": [
      "Junying Chen",
      "Qingcai Chen",
      "Dongfang Li",
      "Yutao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.10843",
    "title": "Mask Off: Analytic-based Malware Detection By Transfer Learning and  Model Personalization",
    "abstract": "The vulnerability of smartphones to cyberattacks has been a severe concern to users arising from the integrity of installed applications (\\textit{apps}). Although applications are to provide legitimate and diversified on-the-go services, harmful and dangerous ones have also uncovered the feasible way to penetrate smartphones for malicious behaviors. Thorough application analysis is key to revealing malicious intent and providing more insights into the application behavior for security risk assessments. Such in-depth analysis motivates employing deep neural networks (DNNs) for a set of features and patterns extracted from applications to facilitate detecting potentially dangerous applications independently. This paper presents an Analytic-based deep neural network, Android Malware detection (ADAM), that employs a fine-grained set of features to train feature-specific DNNs to have consensus on the application labels when their ground truth is unknown. In addition, ADAM leverages the transfer learning technique to obtain its adjustability to new applications across smartphones for recycling the pre-trained model(s) and making them more adaptable by model personalization and federated learning techniques. This adjustability is also assisted by federated learning guards, which protect ADAM against poisoning attacks through model analysis. ADAM relies on a diverse dataset containing more than 153000 applications with over 41000 extracted features for DNNs training. The ADAM's feature-specific DNNs, on average, achieved more than 98% accuracy, resulting in an outstanding performance against data manipulation attacks. ",
    "url": "https://arxiv.org/abs/2211.10843",
    "authors": [
      "Amirmohammad Pasdar",
      "Young Choon Lee",
      "Seok-Hee Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10844",
    "title": "Learning to Generate Image Embeddings with User-level Differential  Privacy",
    "abstract": "Small on-device models have been successfully trained with user-level differential privacy (DP) for next word prediction and image classification tasks in the past. However, existing methods can fail when directly applied to learn embedding models using supervised training data with a large class space. To achieve user-level DP for large image-to-embedding feature extractors, we propose DP-FedEmb, a variant of federated learning algorithms with per-user sensitivity control and noise addition, to train from user-partitioned data centralized in the datacenter. DP-FedEmb combines virtual clients, partial aggregation, private local fine-tuning, and public pretraining to achieve strong privacy utility trade-offs. We apply DP-FedEmb to train image embedding models for faces, landmarks and natural species, and demonstrate its superior utility under same privacy budget on benchmark datasets DigiFace, EMNIST, GLD and iNaturalist. We further illustrate it is possible to achieve strong user-level DP guarantees of $\\epsilon<2$ while controlling the utility drop within 5%, when millions of users can participate in training. ",
    "url": "https://arxiv.org/abs/2211.10844",
    "authors": [
      "Zheng Xu",
      "Maxwell Collins",
      "Yuxiao Wang",
      "Liviu Panait",
      "Sewoong Oh",
      "Sean Augenstein",
      "Ting Liu",
      "Florian Schroff",
      "H. Brendan McMahan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10850",
    "title": "Context-Aware Data Augmentation for LIDAR 3D Object Detection",
    "abstract": "For 3D object detection, labeling lidar point cloud is difficult, so data augmentation is an important module to make full use of precious annotated data. As a widely used data augmentation method, GT-sample effectively improves detection performance by inserting groundtruths into the lidar frame during training. However, these samples are often placed in unreasonable areas, which misleads model to learn the wrong context information between targets and backgrounds. To address this problem, in this paper, we propose a context-aware data augmentation method (CA-aug) , which ensures the reasonable placement of inserted objects by calculating the \"Validspace\" of the lidar point cloud. CA-aug is lightweight and compatible with other augmentation methods. Compared with the GT-sample and the similar method in Lidar-aug(SOTA), it brings higher accuracy to the existing detectors. We also present an in-depth study of augmentation methods for the range-view-based(RV-based) models and find that CA-aug can fully exploit the potential of RV-based networks. The experiment on KITTI val split shows that CA-aug can improve the mAP of the test model by 8%. ",
    "url": "https://arxiv.org/abs/2211.10850",
    "authors": [
      "Xuzhong Hu",
      "Zaipeng Duan",
      "Jie Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10856",
    "title": "Diffeomorphic Information Neural Estimation",
    "abstract": "Mutual Information (MI) and Conditional Mutual Information (CMI) are multi-purpose tools from information theory that are able to naturally measure the statistical dependencies between random variables, thus they are usually of central interest in several statistical and machine learning tasks, such as conditional independence testing and representation learning. However, estimating CMI, or even MI, is infamously challenging due the intractable formulation. In this study, we introduce DINE (Diffeomorphic Information Neural Estimator)-a novel approach for estimating CMI of continuous random variables, inspired by the invariance of CMI over diffeomorphic maps. We show that the variables of interest can be replaced with appropriate surrogates that follow simpler distributions, allowing the CMI to be efficiently evaluated via analytical solutions. Additionally, we demonstrate the quality of the proposed estimator in comparison with state-of-the-arts in three important tasks, including estimating MI, CMI, as well as its application in conditional independence testing. The empirical evaluations show that DINE consistently outperforms competitors in all tasks and is able to adapt very well to complex and high-dimensional relationships. ",
    "url": "https://arxiv.org/abs/2211.10856",
    "authors": [
      "Bao Duong",
      "Thin Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.10866",
    "title": "Estimating Task Completion Times for Network Rollouts using Statistical  Models within Partitioning-based Regression Methods",
    "abstract": "This paper proposes a data and Machine Learning-based forecasting solution for the Telecommunications network-rollout planning problem. Milestone completion-time estimation is crucial to network-rollout planning; accurate estimates enable better crew utilisation and optimised cost of materials and logistics. Using historical data of milestone completion times, a model needs to incorporate domain knowledge, handle noise and yet be interpretable to project managers. This paper proposes partition-based regression models that incorporate data-driven statistical models within each partition, as a solution to the problem. Benchmarking experiments demonstrate that the proposed approach obtains competitive to better performance, at a small fraction of the model complexity of the best alternative approach based on Gradient Boosting. Experiments also demonstrate that the proposed approach is effective for both short and long-range forecasts. The proposed idea is applicable in any context requiring time-series regression with noisy and attributed data. ",
    "url": "https://arxiv.org/abs/2211.10866",
    "authors": [
      "Venkatachalam Natchiappan",
      "Shrihari Vasudevan",
      "Thalanayar Muthukumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.10872",
    "title": "MetaMax: Improved Open-Set Deep Neural Networks via Weibull Calibration",
    "abstract": "Open-set recognition refers to the problem in which classes that were not seen during training appear at inference time. This requires the ability to identify instances of novel classes while maintaining discriminative capability for closed-set classification. OpenMax was the first deep neural network-based approach to address open-set recognition by calibrating the predictive scores of a standard closed-set classification network. In this paper we present MetaMax, a more effective post-processing technique that improves upon contemporary methods by directly modeling class activation vectors. MetaMax removes the need for computing class mean activation vectors (MAVs) and distances between a query image and a class MAV as required in OpenMax. Experimental results show that MetaMax outperforms OpenMax and is comparable in performance to other state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2211.10872",
    "authors": [
      "Zongyao Lyu",
      "Nolan B. Gutierrez",
      "William J. Beksi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10882",
    "title": "On Multi-head Ensemble of Smoothed Classifiers for Certified Robustness",
    "abstract": "Randomized Smoothing (RS) is a promising technique for certified robustness, and recently in RS the ensemble of multiple deep neural networks (DNNs) has shown state-of-the-art performances. However, such an ensemble brings heavy computation burdens in both training and certification, and yet under-exploits individual DNNs and their mutual effects, as the communication between these classifiers is commonly ignored in optimization. In this work, starting from a single DNN, we augment the network with multiple heads, each of which pertains a classifier for the ensemble. A novel training strategy, namely Self-PAced Circular-TEaching (SPACTE), is proposed accordingly. SPACTE enables a circular communication flow among those augmented heads, i.e., each head teaches its neighbor with the self-paced learning using smoothed losses, which are specifically designed in relation to certified robustness. The deployed multi-head structure and the circular-teaching scheme of SPACTE jointly contribute to diversify and enhance the classifiers in augmented heads for ensemble, leading to even stronger certified robustness than ensembling multiple DNNs (effectiveness) at the cost of much less computational expenses (efficiency), verified by extensive experiments and discussions. ",
    "url": "https://arxiv.org/abs/2211.10882",
    "authors": [
      "Kun Fang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Tao Li",
      "Xiaolin Huang",
      "Jie Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10887",
    "title": "Differential Privacy from Locally Adjustable Graph Algorithms: $k$-Core  Decomposition, Low Out-Degree Ordering, and Densest Subgraphs",
    "abstract": "Differentially private algorithms allow large-scale data analytics while preserving user privacy. Designing such algorithms for graph data is gaining importance with the growth of large networks that model various (sensitive) relationships between individuals. While there exists a rich history of important literature in this space, to the best of our knowledge, no results formalize a relationship between certain parallel and distributed graph algorithms and differentially private graph analysis. In this paper, we define \\emph{locally adjustable} graph algorithms and show that algorithms of this type can be transformed into differentially private algorithms. Our formalization is motivated by a set of results that we present in the central and local models of differential privacy for a number of problems, including $k$-core decomposition, low out-degree ordering, and densest subgraphs. First, we design an $\\varepsilon$-edge differentially private (DP) algorithm that returns a subset of nodes that induce a subgraph of density at least $\\frac{D^*}{1+\\eta} - O\\left(\\text{poly}(\\log n)/\\varepsilon\\right),$ where $D^*$ is the density of the densest subgraph in the input graph (for any constant $\\eta > 0$). This algorithm achieves a two-fold improvement on the multiplicative approximation factor of the previously best-known private densest subgraph algorithms while maintaining a near-linear runtime. Then, we present an $\\varepsilon$-locally edge differentially private (LEDP) algorithm for $k$-core decompositions. Our LEDP algorithm provides approximates the core numbers (for any constant $\\eta > 0$) with $(2+\\eta)$ multiplicative and $O\\left(\\text{poly}\\left(\\log n\\right)/\\varepsilon\\right)$ additive error. This is the first differentially private algorithm that outputs private $k$-core decomposition statistics. ",
    "url": "https://arxiv.org/abs/2211.10887",
    "authors": [
      "Laxman Dhulipala",
      "Quanquan C. Liu",
      "Sofya Raskhodnikova",
      "Jessica Shi",
      "Julian Shun",
      "Shangdi Yu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.10892",
    "title": "Are Out-of-Distribution Detection Methods Reliable?",
    "abstract": "This paper establishes a novel evaluation framework for assessing the performance of out-of-distribution (OOD) detection in realistic settings. Our goal is to expose the shortcomings of existing OOD detection benchmarks and encourage a necessary research direction shift toward satisfying the requirements of real-world applications. We expand OOD detection research by introducing new OOD test datasets CIFAR-10-R, CIFAR-100-R, and MVTec-R, which allow researchers to benchmark OOD detection performance under realistic distribution shifts. We also introduce a generalizability score to measure a method's ability to generalize from standard OOD detection test datasets to a realistic setting. Contrary to existing OOD detection research, we demonstrate that further performance improvements on standard benchmark datasets do not increase the usability of such models in the real world. State-of-the-art (SOTA) methods tested on our realistic distributionally-shifted datasets drop in performance for up to 45%. This setting is critical for evaluating the reliability of OOD models before they are deployed in real-world environments. ",
    "url": "https://arxiv.org/abs/2211.10892",
    "authors": [
      "Vahid Reza Khazaie",
      "Anthony Wong",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10896",
    "title": "Spectral Adversarial Training for Robust Graph Neural Network",
    "abstract": "Recent studies demonstrate that Graph Neural Networks (GNNs) are vulnerable to slight but adversarially designed perturbations, known as adversarial examples. To address this issue, robust training methods against adversarial examples have received considerable attention in the literature. \\emph{Adversarial Training (AT)} is a successful approach to learning a robust model using adversarially perturbed training samples. Existing AT methods on GNNs typically construct adversarial perturbations in terms of graph structures or node features. However, they are less effective and fraught with challenges on graph data due to the discreteness of graph structure and the relationships between connected examples. In this work, we seek to address these challenges and propose Spectral Adversarial Training (SAT), a simple yet effective adversarial training approach for GNNs. SAT first adopts a low-rank approximation of the graph structure based on spectral decomposition, and then constructs adversarial perturbations in the spectral domain rather than directly manipulating the original graph structure. To investigate its effectiveness, we employ SAT on three widely used GNNs. Experimental results on four public graph datasets demonstrate that SAT significantly improves the robustness of GNNs against adversarial attacks without sacrificing classification accuracy and training efficiency. ",
    "url": "https://arxiv.org/abs/2211.10896",
    "authors": [
      "Jintang Li",
      "Jiaying Peng",
      "Liang Chen",
      "Zibin Zheng",
      "Tingting Liang",
      "Qing Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10904",
    "title": "Temporal Knowledge Graph Reasoning with Historical Contrastive Learning",
    "abstract": "Temporal knowledge graph, serving as an effective way to store and model dynamic relations, shows promising prospects in event forecasting. However, most temporal knowledge graph reasoning methods are highly dependent on the recurrence or periodicity of events, which brings challenges to inferring future events related to entities that lack historical interaction. In fact, the current moment is often the combined effect of a small part of historical information and those unobserved underlying factors. To this end, we propose a new event forecasting model called Contrastive Event Network (CENET), based on a novel training framework of historical contrastive learning. CENET learns both the historical and non-historical dependency to distinguish the most potential entities that can best match the given query. Simultaneously, it trains representations of queries to investigate whether the current moment depends more on historical or non-historical events by launching contrastive learning. The representations further help train a binary classifier whose output is a boolean mask to indicate related entities in the search space. During the inference process, CENET employs a mask-based strategy to generate the final results. We evaluate our proposed model on five benchmark graphs. The results demonstrate that CENET significantly outperforms all existing methods in most metrics, achieving at least $8.3\\%$ relative improvement of Hits@1 over previous state-of-the-art baselines on event-based datasets. ",
    "url": "https://arxiv.org/abs/2211.10904",
    "authors": [
      "Yi Xu",
      "Junjie Ou",
      "Hui Xu",
      "Luoyi Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10908",
    "title": "ESTAS: Effective and Stable Trojan Attacks in Self-supervised Encoders  with One Target Unlabelled Sample",
    "abstract": "Emerging self-supervised learning (SSL) has become a popular image representation encoding method to obviate the reliance on labeled data and learn rich representations from large-scale, ubiquitous unlabelled data. Then one can train a downstream classifier on top of the pre-trained SSL image encoder with few or no labeled downstream data. Although extensive works show that SSL has achieved remarkable and competitive performance on different downstream tasks, its security concerns, e.g, Trojan attacks in SSL encoders, are still not well-studied. In this work, we present a novel Trojan Attack method, denoted by ESTAS, that can enable an effective and stable attack in SSL encoders with only one target unlabeled sample. In particular, we propose consistent trigger poisoning and cascade optimization in ESTAS to improve attack efficacy and model accuracy, and eliminate the expensive target-class data sample extraction from large-scale disordered unlabelled data. Our substantial experiments on multiple datasets show that ESTAS stably achieves > 99% attacks success rate (ASR) with one target-class sample. Compared to prior works, ESTAS attains > 30% ASR increase and > 8.3% accuracy improvement on average. ",
    "url": "https://arxiv.org/abs/2211.10908",
    "authors": [
      "Jiaqi Xue",
      "Qian Lou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10922",
    "title": "Auto-Focus Contrastive Learning for Image Manipulation Detection",
    "abstract": "Generally, current image manipulation detection models are simply built on manipulation traces. However, we argue that those models achieve sub-optimal detection performance as it tends to: 1) distinguish the manipulation traces from a lot of noisy information within the entire image, and 2) ignore the trace relations among the pixels of each manipulated region and its surroundings. To overcome these limitations, we propose an Auto-Focus Contrastive Learning (AF-CL) network for image manipulation detection. It contains two main ideas, i.e., multi-scale view generation (MSVG) and trace relation modeling (TRM). Specifically, MSVG aims to generate a pair of views, each of which contains the manipulated region and its surroundings at a different scale, while TRM plays a role in modeling the trace relations among the pixels of each manipulated region and its surroundings for learning the discriminative representation. After learning the AF-CL network by minimizing the distance between the representations of corresponding views, the learned network is able to automatically focus on the manipulated region and its surroundings and sufficiently explore their trace relations for accurate manipulation detection. Extensive experiments demonstrate that, compared to the state-of-the-arts, AF-CL provides significant performance improvements, i.e., up to 2.5%, 7.5%, and 0.8% F1 score, on CAISA, NIST, and Coverage datasets, respectively. ",
    "url": "https://arxiv.org/abs/2211.10922",
    "authors": [
      "Wenyan Pan",
      "Zhili Zhou",
      "Guangcan Liu",
      "Teng Huang",
      "Hongyang Yan",
      "Q.M. Jonathan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10923",
    "title": "Traceable and Authenticable Image Tagging for Fake News Detection",
    "abstract": "To prevent fake news images from misleading the public, it is desirable not only to verify the authenticity of news images but also to trace the source of fake news, so as to provide a complete forensic chain for reliable fake news detection. To simultaneously achieve the goals of authenticity verification and source tracing, we propose a traceable and authenticable image tagging approach that is based on a design of Decoupled Invertible Neural Network (DINN). The designed DINN can simultaneously embed the dual-tags, \\textit{i.e.}, authenticable tag and traceable tag, into each news image before publishing, and then separately extract them for authenticity verification and source tracing. Moreover, to improve the accuracy of dual-tags extraction, we design a parallel Feature Aware Projection Model (FAPM) to help the DINN preserve essential tag information. In addition, we define a Distance Metric-Guided Module (DMGM) that learns asymmetric one-class representations to enable the dual-tags to achieve different robustness performances under malicious manipulations. Extensive experiments, on diverse datasets and unseen manipulations, demonstrate that the proposed tagging approach achieves excellent performance in the aspects of both authenticity verification and source tracing for reliable fake news detection and outperforms the prior works. ",
    "url": "https://arxiv.org/abs/2211.10923",
    "authors": [
      "Ruohan Meng",
      "Zhili Zhou",
      "Qi Cui",
      "Kwok-Yan Lam",
      "Alex Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10929",
    "title": "Towards Generalizable Graph Contrastive Learning: An Information Theory  Perspective",
    "abstract": "Graph contrastive learning (GCL) emerges as the most representative approach for graph representation learning, which leverages the principle of maximizing mutual information (InfoMax) to learn node representations applied in downstream tasks. To explore better generalization from GCL to downstream tasks, previous methods heuristically define data augmentation or pretext tasks. However, the generalization ability of GCL and its theoretical principle are still less reported. In this paper, we first propose a metric named GCL-GE for GCL generalization ability. Considering the intractability of the metric due to the agnostic downstream task, we theoretically prove a mutual information upper bound for it from an information-theoretic perspective. Guided by the bound, we design a GCL framework named InfoAdv with enhanced generalization ability, which jointly optimizes the generalization metric and InfoMax to strike the right balance between pretext task fitting and the generalization ability on downstream tasks. We empirically validate our theoretical findings on a number of representative benchmarks, and experimental results demonstrate that our model achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2211.10929",
    "authors": [
      "Yige Yuan",
      "Bingbing Xu",
      "Huawei Shen",
      "Qi Cao",
      "Keting Cen",
      "Wen Zheng",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10933",
    "title": "Invisible Backdoor Attack with Dynamic Triggers against Person  Re-identification",
    "abstract": "In recent years, person Re-identification (ReID) has rapidly progressed with wide real-world applications, but also poses significant risks of adversarial attacks. In this paper, we focus on the backdoor attack on deep ReID models. Existing backdoor attack methods follow an all-to-one/all attack scenario, where all the target classes in the test set have already been seen in the training set. However, ReID is a much more complex fine-grained open-set recognition problem, where the identities in the test set are not contained in the training set. Thus, previous backdoor attack methods for classification are not applicable for ReID. To ameliorate this issue, we propose a novel backdoor attack on deep ReID under a new all-to-unknown scenario, called Dynamic Triggers Invisible Backdoor Attack (DT-IBA). Instead of learning fixed triggers for the target classes from the training set, DT-IBA can dynamically generate new triggers for any unknown identities. Specifically, an identity hashing network is proposed to first extract target identity information from a reference image, which is then injected into the benign images by image steganography. We extensively validate the effectiveness and stealthiness of the proposed attack on benchmark datasets, and evaluate the effectiveness of several defense methods against our attack. ",
    "url": "https://arxiv.org/abs/2211.10933",
    "authors": [
      "Wenli Sun",
      "Xinyang Jiang",
      "Shuguang Dou",
      "Dongsheng Li",
      "Duoqian Miao",
      "Cheng Deng",
      "Cairong Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10938",
    "title": "AI-KD: Adversarial learning and Implicit regularization for  self-Knowledge Distillation",
    "abstract": "We present a novel adversarial penalized self-knowledge distillation method, named adversarial learning and implicit regularization for self-knowledge distillation (AI-KD), which regularizes the training procedure by adversarial learning and implicit distillations. Our model not only distills the deterministic and progressive knowledge which are from the pre-trained and previous epoch predictive probabilities but also transfers the knowledge of the deterministic predictive distributions using adversarial learning. The motivation is that the self-knowledge distillation methods regularize the predictive probabilities with soft targets, but the exact distributions may be hard to predict. Our method deploys a discriminator to distinguish the distributions between the pre-trained and student models while the student model is trained to fool the discriminator in the trained procedure. Thus, the student model not only can learn the pre-trained model's predictive probabilities but also align the distributions between the pre-trained and student models. We demonstrate the effectiveness of the proposed method with network architectures on multiple datasets and show the proposed method achieves better performance than state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2211.10938",
    "authors": [
      "Hyungmin Kim",
      "Sungho Suh",
      "Sunghyun Baek",
      "Daehwan Kim",
      "Daun Jeong",
      "Hansang Cho",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10943",
    "title": "Scalable Collaborative Learning via Representation Sharing",
    "abstract": "Privacy-preserving machine learning has become a key conundrum for multi-party artificial intelligence. Federated learning (FL) and Split Learning (SL) are two frameworks that enable collaborative learning while keeping the data private (on device). In FL, each data holder trains a model locally and releases it to a central server for aggregation. In SL, the clients must release individual cut-layer activations (smashed data) to the server and wait for its response (during both inference and back propagation). While relevant in several settings, both of these schemes have a high communication cost, rely on server-level computation algorithms and do not allow for tunable levels of collaboration. In this work, we present a novel approach for privacy-preserving machine learning, where the clients collaborate via online knowledge distillation using a contrastive loss (contrastive w.r.t. the labels). The goal is to ensure that the participants learn similar features on similar classes without sharing their input data. To do so, each client releases averaged last hidden layer activations of similar labels to a central server that only acts as a relay (i.e., is not involved in the training or aggregation of the models). Then, the clients download these last layer activations (feature representations) of the ensemble of users and distill their knowledge in their personal model using a contrastive objective. For cross-device applications (i.e., small local datasets and limited computational capacity), this approach increases the utility of the models compared to independent learning and other federated knowledge distillation (FD) schemes, is communication efficient and is scalable with the number of clients. We prove theoretically that our framework is well-posed, and we benchmark its performance against standard FD and FL on various datasets using different model architectures. ",
    "url": "https://arxiv.org/abs/2211.10943",
    "authors": [
      "Fr\u00e9d\u00e9ric Berdoz",
      "Abhishek Singh",
      "Martin Jaggi",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10944",
    "title": "Feature Weaken: Vicinal Data Augmentation for Classification",
    "abstract": "Deep learning usually relies on training large-scale data samples to achieve better performance. However, over-fitting based on training data always remains a problem. Scholars have proposed various strategies, such as feature dropping and feature mixing, to improve the generalization continuously. For the same purpose, we subversively propose a novel training method, Feature Weaken, which can be regarded as a data augmentation method. Feature Weaken constructs the vicinal data distribution with the same cosine similarity for model training by weakening features of the original samples. In especially, Feature Weaken changes the spatial distribution of samples, adjusts sample boundaries, and reduces the gradient optimization value of back-propagation. This work can not only improve the classification performance and generalization of the model, but also stabilize the model training and accelerate the model convergence. We conduct extensive experiments on classical deep convolution neural models with five common image classification datasets and the Bert model with four common text classification datasets. Compared with the classical models or the generalization improvement methods, such as Dropout, Mixup, Cutout, and CutMix, Feature Weaken shows good compatibility and performance. We also use adversarial samples to perform the robustness experiments, and the results show that Feature Weaken is effective in improving the robustness of the model. ",
    "url": "https://arxiv.org/abs/2211.10944",
    "authors": [
      "Songhao Jiang",
      "Yan Chu",
      "Tianxing Ma",
      "Tianning Zang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10946",
    "title": "Normalizing Flows for Human Pose Anomaly Detection",
    "abstract": "Video anomaly detection is an ill-posed problem because it relies on many parameters such as appearance, pose, camera angle, background, and more. We distill the problem to anomaly detection of human pose, thus reducing the risk of nuisance parameters such as appearance affecting the result. Focusing on pose alone also has the side benefit of reducing bias against distinct minority groups. Our model works directly on human pose graph sequences and is exceptionally lightweight ($\\sim1K$ parameters), capable of running on any machine able to run the pose estimation with negligible additional resources. We leverage the highly compact pose representation in a normalizing flows framework, which we extend to tackle the unique characteristics of spatio-temporal pose data and show its advantages in this use case. Our algorithm uses normalizing flows to learn a bijective mapping between the pose data distribution and a Gaussian distribution, using spatio-temporal graph convolution blocks. The algorithm is quite general and can handle training data of only normal examples, as well as a supervised dataset that consists of labeled normal and abnormal examples. We report state-of-the-art results on two anomaly detection benchmarks - the unsupervised ShanghaiTech dataset and the recent supervised UBnormal dataset. ",
    "url": "https://arxiv.org/abs/2211.10946",
    "authors": [
      "Or Hirschorn",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.10948",
    "title": "FedDCT: Federated Learning of Large Convolutional Neural Networks on  Resource Constrained Devices using Divide and Co-Training",
    "abstract": "We introduce FedDCT, a novel distributed learning paradigm that enables the usage of large, high-performance CNNs on resource-limited edge devices. As opposed to traditional FL approaches, which require each client to train the full-size neural network independently during each training round, the proposed FedDCT allows a cluster of several clients to collaboratively train a large deep learning model by dividing it into an ensemble of several small sub-models and train them on multiple devices in parallel while maintaining privacy. In this co-training process, clients from the same cluster can also learn from each other, further improving their ensemble performance. In the aggregation stage, the server takes a weighted average of all the ensemble models trained by all the clusters. FedDCT reduces the memory requirements and allows low-end devices to participate in FL. We empirically conduct extensive experiments on standardized datasets, including CIFAR-10, CIFAR-100, and two real-world medical datasets HAM10000 and VAIPE. Experimental results show that FedDCT outperforms a set of current SOTA FL methods with interesting convergence behaviors. Furthermore, compared to other existing approaches, FedDCT achieves higher accuracy and substantially reduces the number of communication rounds (with $4-8$ times fewer memory requirements) to achieve the desired accuracy on the testing dataset without incurring any extra training cost on the server side. ",
    "url": "https://arxiv.org/abs/2211.10948",
    "authors": [
      "Quan Nguyen",
      "Hieu H. Pham",
      "Kok-Seng Wong",
      "Phi Le Nguyen",
      "Truong Thao Nguyen",
      "Minh N. Do"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10960",
    "title": "CoCoNet: Coupled Contrastive Learning Network with Multi-level Feature  Ensemble for Multi-modality Image Fusion",
    "abstract": "Infrared and visible image fusion targets to provide an informative image by combining complementary information from different sensors. Existing learning-based fusion approaches attempt to construct various loss functions to preserve complementary features from both modalities, while neglecting to discover the inter-relationship between the two modalities, leading to redundant or even invalid information on the fusion results. To alleviate these issues, we propose a coupled contrastive learning network, dubbed CoCoNet, to realize infrared and visible image fusion in an end-to-end manner. Concretely, to simultaneously retain typical features from both modalities and remove unwanted information emerging on the fused result, we develop a coupled contrastive constraint in our loss function.In a fused imge, its foreground target/background detail part is pulled close to the infrared/visible source and pushed far away from the visible/infrared source in the representation space. We further exploit image characteristics to provide data-sensitive weights, which allows our loss function to build a more reliable relationship with source images. Furthermore, to learn rich hierarchical feature representation and comprehensively transfer features in the fusion process, a multi-level attention module is established. In addition, we also apply the proposed CoCoNet on medical image fusion of different types, e.g., magnetic resonance image and positron emission tomography image, magnetic resonance image and single photon emission computed tomography image. Extensive experiments demonstrate that our method achieves the state-of-the-art (SOTA) performance under both subjective and objective evaluation, especially in preserving prominent targets and recovering vital textural details. ",
    "url": "https://arxiv.org/abs/2211.10960",
    "authors": [
      "Jinyuan Liu",
      "Runjia Lin",
      "Guanyao Wu",
      "Risheng Liu",
      "Zhongxuan Luo",
      "Xin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10962",
    "title": "PG-Schema: Schemas for Property Graphs",
    "abstract": "Property graphs have reached a high level of maturity, witnessed by multiple robust graph database systems as well as the ongoing standardization effort aiming at a creating a new standard Graph Query Language (GQL). Yet, despite documented demand, schema support is limited in existing systems. It is anticipated that the second version of the GQL Standard will have an rich DDL. With is in mind, we propose PG-SCHEMAS, a simple yet powerful formalism for specifying property graph schemas, featuring flexible type definitions supporting multi-inheritance as well as an expressive constraint language based on recently proposed PG-KEYS. ",
    "url": "https://arxiv.org/abs/2211.10962",
    "authors": [
      "Angela Bonifati",
      "Stefania Dumbrava",
      "George Fletcher",
      "Jan Hidders",
      "Bei Li",
      "Leonid Libkin",
      "Wim Martens",
      "Filip Murlak",
      "Stefan Plantikow",
      "Ognjen Savkovi\u0107",
      "Juan Sequeda",
      "S\u0142awek Staworko",
      "Dominik Tomaszuk",
      "Hannes Voigt",
      "Domagoj Vrgo\u010d",
      "Mingxi Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2211.10967",
    "title": "Font Representation Learning via Paired-glyph Matching",
    "abstract": "Fonts can convey profound meanings of words in various forms of glyphs. Without typography knowledge, manually selecting an appropriate font or designing a new font is a tedious and painful task. To allow users to explore vast font styles and create new font styles, font retrieval and font style transfer methods have been proposed. These tasks increase the need for learning high-quality font representations. Therefore, we propose a novel font representation learning scheme to embed font styles into the latent space. For the discriminative representation of a font from others, we propose a paired-glyph matching-based font representation learning model that attracts the representations of glyphs in the same font to one another, but pushes away those of other fonts. Through evaluations on font retrieval with query glyphs on new fonts, we show our font representation learning scheme achieves better generalization performance than the existing font representation learning techniques. Finally on the downstream font style transfer and generation tasks, we confirm the benefits of transfer learning with the proposed method. The source code is available at https://github.com/junhocho/paired-glyph-matching. ",
    "url": "https://arxiv.org/abs/2211.10967",
    "authors": [
      "Junho Cho",
      "Kyuewang Lee",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10971",
    "title": "On Holistic Multi-Step Cyberattack Detection via a Graph-based  Correlation Approach",
    "abstract": "While digitization of distribution grids through information and communications technology brings numerous benefits, it also increases the grid's vulnerability to serious cyber attacks. Unlike conventional systems, attacks on many industrial control systems such as power grids often occur in multiple stages, with the attacker taking several steps at once to achieve its goal. Detection mechanisms with situational awareness are needed to detect orchestrated attack steps as part of a coherent attack campaign. To provide a foundation for detection and prevention of such attacks, this paper addresses the detection of multi-stage cyber attacks with the aid of a graph-based cyber intelligence database and alert correlation approach. Specifically, we propose an approach to detect multi-stage attacks by leveraging heterogeneous data to form a knowledge base and employ a model-based correlation approach on the generated alerts to identify multi-stage cyber attack sequences taking place in the network. We investigate the detection quality of the proposed approach by using a case study of a multi-stage cyber attack campaign in a future-orientated power grid pilot. ",
    "url": "https://arxiv.org/abs/2211.10971",
    "authors": [
      "\u00d6mer Sen",
      "Chijioke Eze",
      "Andreas Ulbig",
      "Antonello Monti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10973",
    "title": "FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News  Detection on Short Video Platforms",
    "abstract": "Short video platforms have become an important channel for news sharing, but also a new breeding ground for fake news. To mitigate this problem, research of fake news video detection has recently received a lot of attention. Existing works face two roadblocks: the scarcity of comprehensive and largescale datasets and insufficient utilization of multimodal information. Therefore, in this paper, we construct the largest Chinese short video dataset about fake news named FakeSV, which includes news content, user comments, and publisher profiles simultaneously. To understand the characteristics of fake news videos, we conduct exploratory analysis of FakeSV from different perspectives. Moreover, we provide a new multimodal detection model named SV-FEND, which exploits the cross-modal correlations to select the most informative features and utilizes the social context information for detection. Extensive experiments evaluate the superiority of the proposed method and provide detailed comparisons of different methods and modalities for future works. ",
    "url": "https://arxiv.org/abs/2211.10973",
    "authors": [
      "Peng Qi",
      "Yuyan Bu",
      "Juan Cao",
      "Wei Ji",
      "Ruihao Shui",
      "Junbin Xiao",
      "Danding Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.10990",
    "title": "Enhancing Intra-class Information Extraction for Heterophilous Graphs:  One Neural Architecture Search Approach",
    "abstract": "In recent years, Graph Neural Networks (GNNs) have been popular in graph representation learning which assumes the homophily property, i.e., the connected nodes have the same label or have similar features. However, they may fail to generalize into the heterophilous graphs which in the low/medium level of homophily. Existing methods tend to address this problem by enhancing the intra-class information extraction, i.e., either by designing better GNNs to improve the model effectiveness, or re-designing the graph structures to incorporate more potential intra-class nodes from distant hops. Despite the success, we observe two aspects that can be further improved: (a) enhancing the ego feature information extraction from node itself which is more reliable in extracting the intra-class information; (b) designing node-wise GNNs can better adapt to the nodes with different homophily ratios. In this paper, we propose a novel method IIE-GNN (Intra-class Information Enhanced Graph Neural Networks) to achieve two improvements. A unified framework is proposed based on the literature, in which the intra-class information from the node itself and neighbors can be extracted based on seven carefully designed blocks. With the help of neural architecture search (NAS), we propose a novel search space based on the framework, and then provide an architecture predictor to design GNNs for each node. We further conduct experiments to show that IIE-GNN can improve the model performance by designing node-wise GNNs to enhance intra-class information extraction. ",
    "url": "https://arxiv.org/abs/2211.10990",
    "authors": [
      "Lanning Wei",
      "Zhiqiang He",
      "Huan Zhao",
      "Quanming Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10991",
    "title": "Modeling Fine-grained Information via Knowledge-aware Hierarchical Graph  for Zero-shot Entity Retrieval",
    "abstract": "Zero-shot entity retrieval, aiming to link mentions to candidate entities under the zero-shot setting, is vital for many tasks in Natural Language Processing. Most existing methods represent mentions/entities via the sentence embeddings of corresponding context from the Pre-trained Language Model. However, we argue that such coarse-grained sentence embeddings can not fully model the mentions/entities, especially when the attention scores towards mentions/entities are relatively low. In this work, we propose GER, a \\textbf{G}raph enhanced \\textbf{E}ntity \\textbf{R}etrieval framework, to capture more fine-grained information as complementary to sentence embeddings. We extract the knowledge units from the corresponding context and then construct a mention/entity centralized graph. Hence, we can learn the fine-grained information about mention/entity by aggregating information from these knowledge units. To avoid the graph information bottleneck for the central mention/entity node, we construct a hierarchical graph and design a novel Hierarchical Graph Attention Network~(HGAN). Experimental results on popular benchmarks demonstrate that our proposed GER framework performs better than previous state-of-the-art models. The code has been available at https://github.com/wutaiqiang/GER-WSDM2023. ",
    "url": "https://arxiv.org/abs/2211.10991",
    "authors": [
      "Taiqiang Wu",
      "Xingyu Bai",
      "Weigang Guo",
      "Weijie Liu",
      "Siheng Li",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.10994",
    "title": "DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth  Completion",
    "abstract": "Unsupervised depth completion aims to recover dense depth from the sparse one without using the ground-truth annotation. Although depth measurement obtained from LiDAR is usually sparse, it contains valid and real distance information, i.e., scale-consistent absolute depth values. Meanwhile, scale-agnostic counterparts seek to estimate relative depth and have achieved impressive performance. To leverage both the inherent characteristics, we thus suggest to model scale-consistent depth upon unsupervised scale-agnostic frameworks. Specifically, we propose the decomposed scale-consistent learning (DSCL) strategy, which disintegrates the absolute depth into relative depth prediction and global scale estimation, contributing to individual learning benefits. But unfortunately, most existing unsupervised scale-agnostic frameworks heavily suffer from depth holes due to the extremely sparse depth input and weak supervised signal. To tackle this issue, we introduce the global depth guidance (GDG) module, which attentively propagates dense depth reference into the sparse target via novel dense-to-sparse attention. Extensive experiments show the superiority of our method on outdoor KITTI benchmark, ranking 1st and outperforming the best KBNet more than 12% in RMSE. In addition, our approach achieves state-of-the-art performance on indoor NYUv2 dataset. ",
    "url": "https://arxiv.org/abs/2211.10994",
    "authors": [
      "Zhiqiang Yan",
      "Kun Wang",
      "Xiang Li",
      "Zhenyu Zhang",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10995",
    "title": "Distinctive Fire and Smoke Detection with Self-Similar",
    "abstract": "Deep learning based object detection is demonstrating a preponderance in the practical artificial intelligence. However, there still are some objects that are difficult to be recognized such as fire and smoke because of their non-solid shapes. However, these objects have a mathematical fractal feature of self-similar that can relieve us from struggling with their various shapes. To this end, we propose to utilize the Hausdorff distance to evaluate the self-similarity and accordingly tailored a loss function to improve the detection accuracy of fire and smoke. Moreover, we proposed a general labeling criterion for these objects based on their geometrical features. Our experiments on commonly used baseline networks for object detection have verified that our method is valid and have improved the detecting accuracy by 2.23%. ",
    "url": "https://arxiv.org/abs/2211.10995",
    "authors": [
      "Zeyu Shangguan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10996",
    "title": "MINTIME: Multi-Identity Size-Invariant Video Deepfake Detection",
    "abstract": "In this paper, we introduce MINTIME, a video deepfake detection approach that captures spatial and temporal anomalies and handles instances of multiple people in the same video and variations in face sizes. Previous approaches disregard such information either by using simple a-posteriori aggregation schemes, i.e., average or max operation, or using only one identity for the inference, i.e., the largest one. On the contrary, the proposed approach builds on a Spatio-Temporal TimeSformer combined with a Convolutional Neural Network backbone to capture spatio-temporal anomalies from the face sequences of multiple identities depicted in a video. This is achieved through an Identity-aware Attention mechanism that attends to each face sequence independently based on a masking operation and facilitates video-level aggregation. In addition, two novel embeddings are employed: (i) the Temporal Coherent Positional Embedding that encodes each face sequence's temporal information and (ii) the Size Embedding that encodes the size of the faces as a ratio to the video frame size. These extensions allow our system to adapt particularly well in the wild by learning how to aggregate information of multiple identities, which is usually disregarded by other methods in the literature. It achieves state-of-the-art results on the ForgeryNet dataset with an improvement of up to 14% AUC in videos containing multiple people and demonstrates ample generalization capabilities in cross-forgery and cross-dataset settings. The code is publicly available at https://github.com/davide-coccomini/MINTIME-Multi-Identity-size-iNvariant-TIMEsformer-for-Video-Deepfake-Detection ",
    "url": "https://arxiv.org/abs/2211.10996",
    "authors": [
      "Davide Alessandro Coccomini",
      "Giorgos Kordopatis Zilos",
      "Giuseppe Amato",
      "Roberto Caldelli",
      "Fabrizio Falchi",
      "Symeon Papadopoulos",
      "Claudio Gennaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10999",
    "title": "LA-VocE: Low-SNR Audio-visual Speech Enhancement using Neural Vocoders",
    "abstract": "Audio-visual speech enhancement aims to extract clean speech from a noisy environment by leveraging not only the audio itself but also the target speaker's lip movements. This approach has been shown to yield improvements over audio-only speech enhancement, particularly for the removal of interfering speech. Despite recent advances in speech synthesis, most audio-visual approaches continue to use spectral mapping/masking to reproduce the clean audio, often resulting in visual backbones added to existing speech enhancement architectures. In this work, we propose LA-VocE, a new two-stage approach that predicts mel-spectrograms from noisy audio-visual speech via a transformer-based architecture, and then converts them into waveform audio using a neural vocoder (HiFi-GAN). We train and evaluate our framework on thousands of speakers and 11+ different languages, and study our model's ability to adapt to different levels of background noise and speech interference. Our experiments show that LA-VocE outperforms existing methods according to multiple metrics, particularly under very noisy scenarios. ",
    "url": "https://arxiv.org/abs/2211.10999",
    "authors": [
      "Rodrigo Mira",
      "Buye Xu",
      "Jacob Donley",
      "Anurag Kumar",
      "Stavros Petridis",
      "Vamsi Krishna Ithapu",
      "Maja Pantic"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.11001",
    "title": "F2SD: A dataset for end-to-end group detection algorithms",
    "abstract": "The lack of large-scale datasets has been impeding the advance of deep learning approaches to the problem of F-formation detection. Moreover, most research works on this problem rely on input sensor signals of object location and orientation rather than image signals. To address this, we develop a new, large-scale dataset of simulated images for F-formation detection, called F-formation Simulation Dataset (F2SD). F2SD contains nearly 60,000 images simulated from GTA-5, with bounding boxes and orientation information on images, making it useful for a wide variety of modelling approaches. It is also closer to practical scenarios, where three-dimensional location and orientation information are costly to record. It is challenging to construct such a large-scale simulated dataset while keeping it realistic. Furthermore, the available research utilizes conventional methods to detect groups. They do not detect groups directly from the image. In this work, we propose (1) a large-scale simulation dataset F2SD and a pipeline for F-formation simulation, (2) a first-ever end-to-end baseline model for the task, and experiments on our simulation dataset. ",
    "url": "https://arxiv.org/abs/2211.11001",
    "authors": [
      "Giang Hoang",
      "Tuan Nguyen Dinh",
      "Tung Cao Hoang",
      "Son Le Duy",
      "Keisuke Hihara",
      "Yumeka Utada",
      "Akihiko Torii",
      "Naoki Izumi",
      "Long Tran Quoc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11013",
    "title": "Machine Learning Methods for Anomaly Detection in Nuclear Power Plant  Power Transformers",
    "abstract": "Power transformers are an important component of a nuclear power plant (NPP). Currently, the NPP operates a lot of power transformers with extended service life, which exceeds the designated 25 years. Due to the extension of the service life, the task of monitoring the technical condition of power transformers becomes urgent. An important method for monitoring power transformers is Chromatographic Analysis of Dissolved Gas. It is based on the principle of controlling the concentration of gases dissolved in transformer oil. The appearance of almost any type of defect in equipment is accompanied by the formation of gases that dissolve in oil, and specific types of defects generate their gases in different quantities. At present, at NPPs, the monitoring systems for transformer equipment use predefined control limits for the concentration of dissolved gases in the oil. This study describes the stages of developing an algorithm to detect defects and faults in transformers automatically using machine learning and data analysis methods. Among machine learning models, we trained Logistic Regression, Decision Trees, Random Forest, Gradient Boosting, Neural Networks. The best of them were then combined into an ensemble (StackingClassifier) showing F1-score of 0.974 on a test sample. To develop mathematical models, we used data on the state of transformers, containing time series with values of gas concentrations (H2, CO, C2H4, C2H2). The datasets were labeled and contained four operating modes: normal mode, partial discharge, low energy discharge, low-temperature overheating. ",
    "url": "https://arxiv.org/abs/2211.11013",
    "authors": [
      "Iurii Katser",
      "Dmitriy Raspopov",
      "Vyacheslav Kozitsin",
      "Maxim Mezhov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.11030",
    "title": "Adversarial Cheap Talk",
    "abstract": "Adversarial attacks in reinforcement learning (RL) often assume highly-privileged access to the victim's parameters, environment, or data. Instead, this paper proposes a novel adversarial setting called a Cheap Talk MDP in which an Adversary can merely append deterministic messages to the Victim's observation, resulting in a minimal range of influence. The Adversary cannot occlude ground truth, influence underlying environment dynamics or reward signals, introduce non-stationarity, add stochasticity, see the Victim's actions, or access their parameters. Additionally, we present a simple meta-learning algorithm called Adversarial Cheap Talk (ACT) to train Adversaries in this setting. We demonstrate that an Adversary trained with ACT can still significantly influence the Victim's training and testing performance, despite the highly constrained setting. Affecting train-time performance reveals a new attack vector and provides insight into the success and failure modes of existing RL algorithms. More specifically, we show that an ACT Adversary is capable of harming performance by interfering with the learner's function approximation, or instead helping the Victim's performance by outputting useful features. Finally, we show that an ACT Adversary can manipulate messages during train-time to directly and arbitrarily control the Victim at test-time. ",
    "url": "https://arxiv.org/abs/2211.11030",
    "authors": [
      "Chris Lu",
      "Timon Willi",
      "Alistair Letcher",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.11035",
    "title": "Heterogenous Ensemble of Models for Molecular Property Prediction",
    "abstract": "Previous works have demonstrated the importance of considering different modalities on molecules, each of which provide a varied granularity of information for downstream property prediction tasks. Our method combines variants of the recent TransformerM architecture with Transformer, GNN, and ResNet backbone architectures. Models are trained on the 2D data, 3D data, and image modalities of molecular graphs. We ensemble these models with a HuberRegressor. The models are trained on 4 different train/validation splits of the original train + valid datasets. This yields a winning solution to the 2\\textsuperscript{nd} edition of the OGB Large-Scale Challenge (2022) on the PCQM4Mv2 molecular property prediction dataset. Our proposed method achieves a test-challenge MAE of $0.0723$ and a validation MAE of $0.07145$. Total inference time for our solution is less than 2 hours. We open-source our code at https://github.com/jfpuget/NVIDIA-PCQM4Mv2. ",
    "url": "https://arxiv.org/abs/2211.11035",
    "authors": [
      "Sajad Darabi",
      "Shayan Fazeli",
      "Jiwei Liu",
      "Alexandre Milesi",
      "Pawel Morkisz",
      "Jean-Fran\u00e7ois Puget",
      "Gilberto Titericz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.11039",
    "title": "Deep Composite Face Image Attacks: Generation, Vulnerability and  Detection",
    "abstract": "Face manipulation attacks have drawn the attention of biometric researchers because of their vulnerability to Face Recognition Systems (FRS). This paper proposes a novel scheme to generate Composite Face Image Attacks (CFIA) based on the Generative Adversarial Networks (GANs). Given the face images from contributory data subjects, the proposed CFIA method will independently generate the segmented facial attributes, then blend them using transparent masks to generate the CFIA samples. { The primary motivation for CFIA is to utilize deep learning to generate facial attribute-based composite attacks, which has been explored relatively less in the current literature.} We generate $14$ different combinations of facial attributes resulting in $14$ unique CFIA samples for each pair of contributory data subjects. Extensive experiments are carried out on our newly generated CFIA dataset consisting of 1000 unique identities with 2000 bona fide samples and 14000 CFIA samples, thus resulting in an overall 16000 face image samples. We perform a sequence of experiments to benchmark the vulnerability of CFIA to automatic FRS (based on both deep-learning and commercial-off-the-shelf (COTS). We introduced a new metric named Generalized Morphing Attack Potential (GMAP) to benchmark the vulnerability effectively. Additional experiments are performed to compute the perceptual quality of the generated CFIA samples. Finally, the CFIA detection performance is presented using three different Face Morphing Attack Detection (MAD) algorithms. The proposed CFIA method indicates good perceptual quality based on the obtained results. Further, { FRS is vulnerable to CFIA} (much higher than SOTA), making it difficult to detect by human observers and automatic detection algorithms. Lastly, we performed experiments to detect the CFIA samples using three different detection techniques automatically. ",
    "url": "https://arxiv.org/abs/2211.11039",
    "authors": [
      "Jag Mohan Singh",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11040",
    "title": "PointResNet: Residual Network for 3D Point Cloud Segmentation and  Classification",
    "abstract": "Point cloud segmentation and classification are some of the primary tasks in 3D computer vision with applications ranging from augmented reality to robotics. However, processing point clouds using deep learning-based algorithms is quite challenging due to the irregular point formats. Voxelization or 3D grid-based representation are different ways of applying deep neural networks to this problem. In this paper, we propose PointResNet, a residual block-based approach. Our model directly processes the 3D points, using a deep neural network for the segmentation and classification tasks. The main components of the architecture are: 1) residual blocks and 2) multi-layered perceptron (MLP). We show that it preserves profound features and structural information, which are useful for segmentation and classification tasks. The experimental evaluations demonstrate that the proposed model produces the best results for segmentation and comparable results for classification in comparison to the conventional baselines. ",
    "url": "https://arxiv.org/abs/2211.11040",
    "authors": [
      "Aadesh Desai",
      "Saagar Parikh",
      "Seema Kumari",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11052",
    "title": "Convexifying Transformers: Improving optimization and understanding of  transformer networks",
    "abstract": "Understanding the fundamental mechanism behind the success of transformer networks is still an open problem in the deep learning literature. Although their remarkable performance has been mostly attributed to the self-attention mechanism, the literature still lacks a solid analysis of these networks and interpretation of the functions learned by them. To this end, we study the training problem of attention/transformer networks and introduce a novel convex analytic approach to improve the understanding and optimization of these networks. Particularly, we first introduce a convex alternative to the self-attention mechanism and reformulate the regularized training problem of transformer networks with our alternative convex attention. Then, we cast the reformulation as a convex optimization problem that is interpretable and easier to optimize. Moreover, as a byproduct of our convex analysis, we reveal an implicit regularization mechanism, which promotes sparsity across tokens. Therefore, we not only improve the optimization of attention/transformer networks but also provide a solid theoretical understanding of the functions learned by them. We also demonstrate the effectiveness of our theory through several numerical experiments. ",
    "url": "https://arxiv.org/abs/2211.11052",
    "authors": [
      "Tolga Ergen",
      "Behnam Neyshabur",
      "Harsh Mehta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.11056",
    "title": "Safe Control Under Input Limits with Neural Control Barrier Functions",
    "abstract": "We propose new methods to synthesize control barrier function (CBF)-based safe controllers that avoid input saturation, which can cause safety violations. In particular, our method is created for high-dimensional, general nonlinear systems, for which such tools are scarce. We leverage techniques from machine learning, like neural networks and deep learning, to simplify this challenging problem in nonlinear control design. The method consists of a learner-critic architecture, in which the critic gives counterexamples of input saturation and the learner optimizes a neural CBF to eliminate those counterexamples. We provide empirical results on a 10D state, 4D input quadcopter-pendulum system. Our learned CBF avoids input saturation and maintains safety over nearly 100% of trials. ",
    "url": "https://arxiv.org/abs/2211.11056",
    "authors": [
      "Simin Liu",
      "Changliu Liu",
      "John Dolan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.11062",
    "title": "Patch-level Gaze Distribution Prediction for Gaze Following",
    "abstract": "Gaze following aims to predict where a person is looking in a scene, by predicting the target location, or indicating that the target is located outside the image. Recent works detect the gaze target by training a heatmap regression task with a pixel-wise mean-square error (MSE) loss, while formulating the in/out prediction task as a binary classification task. This training formulation puts a strict, pixel-level constraint in higher resolution on the single annotation available in training, and does not consider annotation variance and the correlation between the two subtasks. To address these issues, we introduce the patch distribution prediction (PDP) method. We replace the in/out prediction branch in previous models with the PDP branch, by predicting a patch-level gaze distribution that also considers the outside cases. Experiments show that our model regularizes the MSE loss by predicting better heatmap distributions on images with larger annotation variances, meanwhile bridging the gap between the target prediction and in/out prediction subtasks, showing a significant improvement in performance on both subtasks on public gaze following datasets. ",
    "url": "https://arxiv.org/abs/2211.11062",
    "authors": [
      "Qiaomu Miao",
      "Minh Hoai",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11066",
    "title": "Hybrid Transformer Based Feature Fusion for Self-Supervised Monocular  Depth Estimation",
    "abstract": "With an unprecedented increase in the number of agents and systems that aim to navigate the real world using visual cues and the rising impetus for 3D Vision Models, the importance of depth estimation is hard to understate. While supervised methods remain the gold standard in the domain, the copious amount of paired stereo data required to train such models makes them impractical. Most State of the Art (SOTA) works in the self-supervised and unsupervised domain employ a ResNet-based encoder architecture to predict disparity maps from a given input image which are eventually used alongside a camera pose estimator to predict depth without direct supervision. The fully convolutional nature of ResNets makes them susceptible to capturing per-pixel local information only, which is suboptimal for depth prediction. Our key insight for doing away with this bottleneck is to use Vision Transformers, which employ self-attention to capture the global contextual information present in an input image. Our model fuses per-pixel local information learned using two fully convolutional depth encoders with global contextual information learned by a transformer encoder at different scales. It does so using a mask-guided multi-stream convolution in the feature space to achieve state-of-the-art performance on most standard benchmarks. ",
    "url": "https://arxiv.org/abs/2211.11066",
    "authors": [
      "Snehal Singh Tomar",
      "Maitreya Suin",
      "A.N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11069",
    "title": "Learning Nonlinear Couplings in Network of Agents from a Single Sample  Trajectory",
    "abstract": "We consider a class of stochastic dynamical networks whose governing dynamics can be modeled using a coupling function. It is shown that the dynamics of such networks can generate geometrically ergodic trajectories under some reasonable assumptions. We show that a general class of coupling functions can be learned using only one sample trajectory from the network. This is practically plausible as in numerous applications it is desired to run an experiment only once but for a longer period of time, rather than repeating the same experiment multiple times from different initial conditions. Building upon ideas from the concentration inequalities for geometrically ergodic Markov chains, we formulate several results about the convergence of the empirical estimator to the true coupling function. Our theoretical findings are supported by extensive simulation results. ",
    "url": "https://arxiv.org/abs/2211.11069",
    "authors": [
      "Arash Amini",
      "Qiyu Sun",
      "Nader Motee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2211.11070",
    "title": "Who Tracks Who? An Surveillance Capitalist Examination of Commercial  Bluetooth Tracking Networks",
    "abstract": "Object and person tracking networks powered by Bluetooth and mobile devices have become increasingly popular for purposes of public safety and individual concerns. This essay examines popular commercial tracking networks and their campaigns from Apple, Samsung and Tile with reference to surveillance capitalism and digital privacy, discovering the hidden assets commodified through said networks, and their potential of turning users into unregulated digital labour while leaving individual privacy at risk. ",
    "url": "https://arxiv.org/abs/2211.11070",
    "authors": [
      "Hongrui Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.11074",
    "title": "Overfreezing Meets Overparameterization: A Double Descent Perspective on  Transfer Learning of Deep Neural Networks",
    "abstract": "We study the generalization behavior of transfer learning of deep neural networks (DNNs). We adopt the overparameterization perspective -- featuring interpolation of the training data (i.e., approximately zero train error) and the double descent phenomenon -- to explain the delicate effect of the transfer learning setting on generalization performance. We study how the generalization behavior of transfer learning is affected by the dataset size in the source and target tasks, the number of transferred layers that are kept frozen in the target DNN training, and the similarity between the source and target tasks. We show that the test error evolution during the target DNN training has a more significant double descent effect when the target training dataset is sufficiently large with some label noise. In addition, a larger source training dataset can delay the arrival to interpolation and double descent peak in the target DNN training. Moreover, we demonstrate that the number of frozen layers can determine whether the transfer learning is effectively underparameterized or overparameterized and, in turn, this may affect the relative success or failure of learning. Specifically, we show that too many frozen layers may make a transfer from a less related source task better or on par with a transfer from a more related source task; we call this case overfreezing. We establish our results using image classification experiments with the residual network (ResNet) and vision transformer (ViT) architectures. ",
    "url": "https://arxiv.org/abs/2211.11074",
    "authors": [
      "Yehuda Dar",
      "Lorenzo Luzi",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11077",
    "title": "A Unified Model for Tracking and Image-Video Detection Has More Power",
    "abstract": "Objection detection (OD) has been one of the most fundamental tasks in computer vision. Recent developments in deep learning have pushed the performance of image OD to new heights by learning-based, data-driven approaches. On the other hand, video OD remains less explored, mostly due to much more expensive data annotation needs. At the same time, multi-object tracking (MOT) which requires reasoning about track identities and spatio-temporal trajectories, shares similar spirits with video OD. However, most MOT datasets are class-specific (e.g., person-annotated only), which constrains a model's flexibility to perform tracking on other objects. We propose TrIVD (Tracking and Image-Video Detection), the first framework that unifies image OD, video OD, and MOT within one end-to-end model. To handle the discrepancies and semantic overlaps across datasets, TrIVD formulates detection/tracking as grounding and reasons about object categories via visual-text alignments. The unified formulation enables cross-dataset, multi-task training, and thus equips TrIVD with the ability to leverage frame-level features, video-level spatio-temporal relations, as well as track identity associations. With such joint training, we can now extend the knowledge from OD data, that comes with much richer object category annotations, to MOT and achieve zero-shot tracking capability. Experiments demonstrate that TrIVD achieves state-of-the-art performances across all image/video OD and MOT tasks. ",
    "url": "https://arxiv.org/abs/2211.11077",
    "authors": [
      "Peirong Liu",
      "Rui Wang",
      "Pengchuan Zhang",
      "Omid Poursaeed",
      "Yipin Zhou",
      "Xuefei Cao",
      "Sreya Dutta Roy",
      "Ashish Shah",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11082",
    "title": "DynIBaR: Neural Dynamic Image-Based Rendering",
    "abstract": "We address the problem of synthesizing novel views from a monocular video depicting a complex dynamic scene. State-of-the-art methods based on temporally varying Neural Radiance Fields (aka dynamic NeRFs) have shown impressive results on this task. However, for long videos with complex object motions and uncontrolled camera trajectories, these methods can produce blurry or inaccurate renderings, hampering their use in real-world applications. Instead of encoding the entire dynamic scene within the weights of an MLP, we present a new approach that addresses these limitations by adopting a volumetric image-based rendering framework that synthesizes new viewpoints by aggregating features from nearby views in a scene-motion-aware manner. Our system retains the advantages of prior methods in its ability to model complex scenes and view-dependent effects, but also enables synthesizing photo-realistic novel views from long videos featuring complex scene dynamics with unconstrained camera trajectories. We demonstrate significant improvements over state-of-the-art methods on dynamic scene datasets, and also apply our approach to in-the-wild videos with challenging camera and object motion, where prior methods fail to produce high-quality renderings. Our project webpage is at dynibar.github.io. ",
    "url": "https://arxiv.org/abs/2211.11082",
    "authors": [
      "Zhengqi Li",
      "Qianqian Wang",
      "Forrester Cole",
      "Richard Tucker",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11113",
    "title": "From Fake News to #FakeNews: Mining Direct and Indirect Relationships  among Hashtags for Fake News Detection",
    "abstract": "The COVID-19 pandemic has gained worldwide attention and allowed fake news, such as ``COVID-19 is the flu,'' to spread quickly and widely on social media. Combating this coronavirus infodemic demands effective methods to detect fake news. To this end, we propose a method to infer news credibility from hashtags involved in news dissemination on social media, motivated by the tight connection between hashtags and news credibility observed in our empirical analyses. We first introduce a new graph that captures all (direct and \\textit{indirect}) relationships among hashtags. Then, a language-independent semi-supervised algorithm is developed to predict fake news based on this constructed graph. This study first investigates the indirect relationship among hashtags; the proposed approach can be extended to any homogeneous graph to capture a comprehensive relationship among nodes. Language independence opens the proposed method to multilingual fake news detection. Experiments conducted on two real-world datasets demonstrate the effectiveness of our approach in identifying fake news, especially at an \\textit{early} stage of propagation. ",
    "url": "https://arxiv.org/abs/2211.11113",
    "authors": [
      "Xinyi Zhou",
      "Reza Zafarani",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.11116",
    "title": "Structure-Encoding Auxiliary Tasks for Improved Visual Representation in  Vision-and-Language Navigation",
    "abstract": "In Vision-and-Language Navigation (VLN), researchers typically take an image encoder pre-trained on ImageNet without fine-tuning on the environments that the agent will be trained or tested on. However, the distribution shift between the training images from ImageNet and the views in the navigation environments may render the ImageNet pre-trained image encoder suboptimal. Therefore, in this paper, we design a set of structure-encoding auxiliary tasks (SEA) that leverage the data in the navigation environments to pre-train and improve the image encoder. Specifically, we design and customize (1) 3D jigsaw, (2) traversability prediction, and (3) instance classification to pre-train the image encoder. Through rigorous ablations, our SEA pre-trained features are shown to better encode structural information of the scenes, which ImageNet pre-trained features fail to properly encode but is crucial for the target navigation task. The SEA pre-trained features can be easily plugged into existing VLN agents without any tuning. For example, on Test-Unseen environments, the VLN agents combined with our SEA pre-trained features achieve absolute success rate improvement of 12% for Speaker-Follower, 5% for Env-Dropout, and 4% for AuxRN. ",
    "url": "https://arxiv.org/abs/2211.11116",
    "authors": [
      "Chia-Wen Kuo",
      "Chih-Yao Ma",
      "Judy Hoffman",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11133",
    "title": "Towards Greener Solutions for Steering Angle Prediction",
    "abstract": "In this paper, we investigate the two most popular families of deep neural architectures (i.e., ResNets and Inception nets) for the autonomous driving task of steering angle prediction. This work provides preliminary evidence that Inception architectures can perform as well or better than ResNet architectures with less complexity for the autonomous driving task. Primary motivation includes support for further research in smaller, more efficient neural network architectures such that can not only accomplish complex tasks, such as steering angle predictions, but also produce less carbon emissions, or, more succinctly, neural networks that are more environmentally friendly. We look at various sizes of ResNet and InceptionNet models to compare results. Our derived models can achieve state-of-the-art results in terms of steering angle MSE. ",
    "url": "https://arxiv.org/abs/2211.11133",
    "authors": [
      "Jeremy C. Hagler",
      "David J. Lamb",
      "Qing Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11137",
    "title": "Long Range Constraints for Neural Texture Synthesis Using Sliced  Wasserstein Loss",
    "abstract": "In the past decade, exemplar-based texture synthesis algorithms have seen strong gains in performance by matching statistics of deep convolutional neural networks. However, these algorithms require regularization terms or user-added spatial tags to capture long range constraints in images. Having access to a user-added spatial tag for all situations is not always feasible, and regularization terms can be difficult to tune. It would be ideal to create an algorithm that does not have any of the aforementioned drawbacks. Thus, we propose a new set of statistics for exemplar based texture synthesis based on Sliced Wasserstein Loss and create a multi-scale algorithm to synthesize textures without a user-added spatial tag. Lastly, we study the ability of our proposed algorithm to capture long range constraints in images and compare our results to other exemplar-based neural texture synthesis algorithms. ",
    "url": "https://arxiv.org/abs/2211.11137",
    "authors": [
      "Liping Yin",
      "Albert Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11138",
    "title": "Diffusion-Based Scene Graph to Image Generation with Masked Contrastive  Pre-Training",
    "abstract": "Generating images from graph-structured inputs, such as scene graphs, is uniquely challenging due to the difficulty of aligning nodes and connections in graphs with objects and their relations in images. Most existing methods address this challenge by using scene layouts, which are image-like representations of scene graphs designed to capture the coarse structures of scene images. Because scene layouts are manually crafted, the alignment with images may not be fully optimized, causing suboptimal compliance between the generated images and the original scene graphs. To tackle this issue, we propose to learn scene graph embeddings by directly optimizing their alignment with images. Specifically, we pre-train an encoder to extract both global and local information from scene graphs that are predictive of the corresponding images, relying on two loss functions: masked autoencoding loss and contrastive loss. The former trains embeddings by reconstructing randomly masked image regions, while the latter trains embeddings to discriminate between compliant and non-compliant images according to the scene graph. Given these embeddings, we build a latent diffusion model to generate images from scene graphs. The resulting method, called SGDiff, allows for the semantic manipulation of generated images by modifying scene graph nodes and connections. On the Visual Genome and COCO-Stuff datasets, we demonstrate that SGDiff outperforms state-of-the-art methods, as measured by both the Inception Score and Fr\\'echet Inception Distance (FID) metrics. We will release our source code and trained models at https://github.com/YangLing0818/SGDiff. ",
    "url": "https://arxiv.org/abs/2211.11138",
    "authors": [
      "Ling Yang",
      "Zhilin Huang",
      "Yang Song",
      "Shenda Hong",
      "Guohao Li",
      "Wentao Zhang",
      "Bin Cui",
      "Bernard Ghanem",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11141",
    "title": "Attacking Shortest Paths by Cutting Edges",
    "abstract": "Identifying shortest paths between nodes in a network is a common graph analysis problem that is important for many applications involving routing of resources. An adversary that can manipulate the graph structure could alter traffic patterns to gain some benefit (e.g., make more money by directing traffic to a toll road). This paper presents the Force Path Cut problem, in which an adversary removes edges from a graph to make a particular path the shortest between its terminal nodes. We prove that this problem is APX-hard, but introduce PATHATTACK, a polynomial-time approximation algorithm that guarantees a solution within a logarithmic factor of the optimal value. In addition, we introduce the Force Edge Cut and Force Node Cut problems, in which the adversary targets a particular edge or node, respectively, rather than an entire path. We derive a nonconvex optimization formulation for these problems, and derive a heuristic algorithm that uses PATHATTACK as a subroutine. We demonstrate all of these algorithms on a diverse set of real and synthetic networks, illustrating the network types that benefit most from the proposed algorithms. ",
    "url": "https://arxiv.org/abs/2211.11141",
    "authors": [
      "Benjamin A. Miller",
      "Zohair Shafi",
      "Wheeler Ruml",
      "Yevgeniy Vorobeychik",
      "Tina Eliassi-Rad",
      "Scott Alfeld"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.11153",
    "title": "Unifying Vision-Language Representation Space with Single-tower  Transformer",
    "abstract": "Contrastive learning is a form of distance learning that aims to learn invariant features from two related representations. In this paper, we explore the bold hypothesis that an image and its caption can be simply regarded as two different views of the underlying mutual information, and train a model to learn a unified vision-language representation space that encodes both modalities at once in a modality-agnostic manner. We first identify difficulties in learning a generic one-tower model for vision-language pretraining (VLP), and propose OneR as a simple yet effective framework for our goal. We discover intriguing properties that distinguish OneR from the previous works that learn modality-specific representation spaces such as zero-shot object localization, text-guided visual reasoning and multi-modal retrieval, and present analyses to provide insights into this new form of multi-modal representation learning. Thorough evaluations demonstrate the potential of a unified modality-agnostic VLP framework. ",
    "url": "https://arxiv.org/abs/2211.11153",
    "authors": [
      "Jiho Jang",
      "Chaerin Kong",
      "Donghyeon Jeon",
      "Seonhoon Kim",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11159",
    "title": "Directed Acyclic Graph Factorization Machines for CTR Prediction via  Knowledge Distillation",
    "abstract": "With the growth of high-dimensional sparse data in web-scale recommender systems, the computational cost to learn high-order feature interaction in CTR prediction task largely increases, which limits the use of high-order interaction models in real industrial applications. Some recent knowledge distillation based methods transfer knowledge from complex teacher models to shallow student models for accelerating the online model inference. However, they suffer from the degradation of model accuracy in knowledge distillation process. It is challenging to balance the efficiency and effectiveness of the shallow student models. To address this problem, we propose a Directed Acyclic Graph Factorization Machine (KD-DAGFM) to learn the high-order feature interactions from existing complex interaction models for CTR prediction via Knowledge Distillation. The proposed lightweight student model DAGFM can learn arbitrary explicit feature interactions from teacher networks, which achieves approximately lossless performance and is proved by a dynamic programming algorithm. Besides, an improved general model KD-DAGFM+ is shown to be effective in distilling both explicit and implicit feature interactions from any complex teacher model. Extensive experiments are conducted on four real-world datasets, including a large-scale industrial dataset from WeChat platform with billions of feature dimensions. KD-DAGFM achieves the best performance with less than 21.5% FLOPs of the state-of-the-art method on both online and offline experiments, showing the superiority of DAGFM to deal with the industrial scale data in CTR prediction task. Our implementation code is available at: https://github.com/RUCAIBox/DAGFM. ",
    "url": "https://arxiv.org/abs/2211.11159",
    "authors": [
      "Zhen Tian",
      "Ting Bai",
      "Zibin Zhang",
      "Zhiyuan Xu",
      "Kangyi Lin",
      "Ji-Rong Wen",
      "Wayne Xin Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11172",
    "title": "HARL: Hierarchical Adaptive Reinforcement Learning Based Auto Scheduler  for Neural Networks",
    "abstract": "To efficiently perform inference with neural networks, the underlying tensor programs require sufficient tuning efforts before being deployed into production environments. Usually, enormous tensor program candidates need to be sufficiently explored to find the one with the best performance. This is necessary to make the neural network products meet the high demand of real-world applications such as natural language processing, auto-driving, etc. Auto-schedulers are being developed to avoid the need for human intervention. However, due to the gigantic search space and lack of intelligent search guidance, current auto-schedulers require hours to days of tuning time to find the best-performing tensor program for the entire neural network. In this paper, we propose HARL, a reinforcement learning (RL) based auto-scheduler specifically designed for efficient tensor program exploration. HARL uses a hierarchical RL architecture in which learning-based decisions are made at all different levels of search granularity. It also automatically adjusts exploration configurations in real-time for faster performance convergence. As a result, HARL improves the tensor operator performance by 22% and the search speed by 4.3x compared to the state-of-the-art auto-scheduler. Inference performance and search speed are also significantly improved on end-to-end neural networks. ",
    "url": "https://arxiv.org/abs/2211.11172",
    "authors": [
      "Zining Zhang",
      "Bingsheng He",
      "Zhenjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2211.11176",
    "title": "Spatiotemporal Modeling of Multivariate Signals With Graph Neural  Networks and Structured State Space Models",
    "abstract": "Multivariate signals are prevalent in various domains, such as healthcare, transportation systems, and space sciences. Modeling spatiotemporal dependencies in multivariate signals is challenging due to (1) long-range temporal dependencies and (2) complex spatial correlations between sensors. To address these challenges, we propose representing multivariate signals as graphs and introduce GraphS4mer, a general graph neural network (GNN) architecture that captures both spatial and temporal dependencies in multivariate signals. Specifically, (1) we leverage Structured State Spaces model (S4), a state-of-the-art sequence model, to capture long-term temporal dependencies and (2) we propose a graph structure learning layer in GraphS4mer to learn dynamically evolving graph structures in the data. We evaluate our proposed model on three distinct tasks and show that GraphS4mer consistently improves over existing models, including (1) seizure detection from electroencephalography signals, outperforming a previous GNN with self-supervised pretraining by 3.1 points in AUROC; (2) sleep staging from polysomnography signals, a 4.1 points improvement in macro-F1 score compared to existing sleep staging models; and (3) traffic forecasting, reducing MAE by 8.8% compared to existing GNNs and by 1.4% compared to Transformer-based models. ",
    "url": "https://arxiv.org/abs/2211.11176",
    "authors": [
      "Siyi Tang",
      "Jared A. Dunnmon",
      "Liangqiong Qu",
      "Khaled K. Saab",
      "Christopher Lee-Messer",
      "Daniel L. Rubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.11177",
    "title": "NeuMap: Neural Coordinate Mapping by Auto-Transdecoder for Camera  Localization",
    "abstract": "This paper presents an end-to-end neural mapping method for camera localization, encoding a whole scene into a grid of latent codes, with which a Transformer-based auto-decoder regresses 3D coordinates of query pixels. State-of-the-art camera localization methods require each scene to be stored as a 3D point cloud with per-point features, which takes several gigabytes of storage per scene. While compression is possible, the performance drops significantly at high compression rates. NeuMap achieves extremely high compression rates with minimal performance drop by using 1) learnable latent codes to store scene information and 2) a scene-agnostic Transformer-based auto-decoder to infer coordinates for a query pixel. The scene-agnostic network design also learns robust matching priors by training with large-scale data, and further allows us to just optimize the codes quickly for a new scene while fixing the network weights. Extensive evaluations with five benchmarks show that NeuMap outperforms all the other coordinate regression methods significantly and reaches similar performance as the feature matching methods while having a much smaller scene representation size. For example, NeuMap achieves 39.1% accuracy in Aachen night benchmark with only 6MB of data, while other compelling methods require 100MB or a few gigabytes and fail completely under high compression settings. The codes are available at https://github.com/Tangshitao/NeuMap. ",
    "url": "https://arxiv.org/abs/2211.11177",
    "authors": [
      "Shitao Tang",
      "Sicong Tang",
      "Andrea Tagliasacchi",
      "Ping Tan",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11178",
    "title": "Adaptive Finite-Time Model Estimation and Control for Manipulator Visual  Servoing using Sliding Mode Control and Neural Networks",
    "abstract": "The image-based visual servoing without models of system is challenging since it is hard to fetch an accurate estimation of hand-eye relationship via merely visual measurement. Whereas, the accuracy of estimated hand-eye relationship expressed in local linear format with Jacobian matrix is important to whole system's performance. In this article, we proposed a finite-time controller as well as a Jacobian matrix estimator in a combination of online and offline way. The local linear formulation is formulated first. Then, we use a combination of online and offline method to boost the estimation of the highly coupled and nonlinear hand-eye relationship with data collected via depth camera. A neural network (NN) is pre-trained to give a relative reasonable initial estimation of Jacobian matrix. Then, an online updating method is carried out to modify the offline trained NN for a more accurate estimation. Moreover, sliding mode control algorithm is introduced to realize a finite-time controller. Compared with previous methods, our algorithm possesses better convergence speed. The proposed estimator possesses excellent performance in the accuracy of initial estimation and powerful tracking capabilities for time-varying estimation for Jacobian matrix compared with other data-driven estimators. The proposed scheme acquires the combination of neural network and finite-time control effect which drives a faster convergence speed compared with the exponentially converge ones. Another main feature of our algorithm is that the state signals in system is proved to be semi-global practical finite-time stable. Several experiments are carried out to validate proposed algorithm's performance. ",
    "url": "https://arxiv.org/abs/2211.11178",
    "authors": [
      "Haibin Zeng",
      "Yueyong Lyu",
      "Jiaming Qi",
      "Shuangquan Zou",
      "Tanghao Qin",
      "Wenyu Qin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11181",
    "title": "A review of laser scanning for geological and geotechnical applications  in underground mining",
    "abstract": "Laser scanning can provide timely assessments of mine sites despite adverse challenges in the operational environment. Although there are several published articles on laser scanning, there is a need to review them in the context of underground mining applications. To this end, a holistic review of laser scanning is presented including progress in 3D scanning systems, data capture/processing techniques and primary applications in underground mines. Laser scanning technology has advanced significantly in terms of mobility and mapping, but there are constraints in coherent and consistent data collection at certain mines due to feature deficiency, dynamics, and environmental influences such as dust and water. Studies suggest that laser scanning has matured over the years for change detection, clearance measurements and structure mapping applications. However, there is scope for improvements in lithology identification, surface parameter measurements, logistic tracking and autonomous navigation. Laser scanning has the potential to provide real-time solutions but the lack of infrastructure in underground mines for data transfer, geodetic networking and processing capacity remain limiting factors. Nevertheless, laser scanners are becoming an integral part of mine automation thanks to their affordability, accuracy and mobility, which should support their widespread usage in years to come. ",
    "url": "https://arxiv.org/abs/2211.11181",
    "authors": [
      "Sarvesh Kumar Singh",
      "Bikram Pratap Banerjee",
      "Simit Raval"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11183",
    "title": "A Bayesian Causal Inference Approach for Assessing Fairness in Clinical  Decision-Making",
    "abstract": "Fairness in clinical decision-making is a critical element of health equity, but assessing fairness of clinical decisions from observational data is challenging. Recently, many fairness notions have been proposed to quantify fairness in decision-making, among which causality-based fairness notions have gained increasing attention due to its potential in adjusting for confounding and reasoning about bias. However, causal fairness notions remain under-explored in the context of clinical decision-making with large-scale healthcare data. In this work, we propose a Bayesian causal inference approach for assessing a causal fairness notion called principal fairness in clinical settings. We demonstrate our approach using both simulated data and electronic health records (EHR) data. ",
    "url": "https://arxiv.org/abs/2211.11183",
    "authors": [
      "Linying Zhang",
      "Lauren R. Richter",
      "Yixin Wang",
      "Anna Ostropolets",
      "Noemie Elhadad",
      "David M. Blei",
      "George Hripcsak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11186",
    "title": "DualApp: Tight Over-Approximation for Neural Network Robustness  Verification via Under-Approximation",
    "abstract": "The robustness of neural networks is fundamental to the hosting system's reliability and security. Formal verification has been proven to be effective in providing provable robustness guarantees. To improve the verification scalability, over-approximating the non-linear activation functions in neural networks by linear constraints is widely adopted, which transforms the verification problem into an efficiently solvable linear programming problem. As over-approximations inevitably introduce overestimation, many efforts have been dedicated to defining the tightest possible approximations. Recent studies have however showed that the existing so-called tightest approximations are superior to each other. In this paper we identify and report an crucial factor in defining tight approximations, namely the approximation domains of activation functions. We observe that existing approaches only rely on overestimated domains, while the corresponding tight approximation may not necessarily be tight on its actual domain. We propose a novel under-approximation-guided approach, called dual-approximation, to define tight over-approximations and two complementary under-approximation algorithms based on sampling and gradient descent. The overestimated domain guarantees the soundness while the underestimated one guides the tightness. We implement our approach into a tool called DualApp and extensively evaluate it on a comprehensive benchmark of 84 collected and trained neural networks with different architectures. The experimental results show that DualApp outperforms the state-of-the-art approximation-based approaches, with up to 71.22% improvement to the verification result. ",
    "url": "https://arxiv.org/abs/2211.11186",
    "authors": [
      "Yiting Wu",
      "Zhaodi Zhang",
      "Zhiyi Xue",
      "Si Liu",
      "Min Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11188",
    "title": "Simultaneous Multiple Object Detection and Pose Estimation using 3D  Model Infusion with Monocular Vision",
    "abstract": "Multiple object detection and pose estimation are vital computer vision tasks. The latter relates to the former as a downstream problem in applications such as robotics and autonomous driving. However, due to the high complexity of both tasks, existing methods generally treat them independently, which is sub-optimal. We propose simultaneous neural modeling of both using monocular vision and 3D model infusion. Our Simultaneous Multiple Object detection and Pose Estimation network (SMOPE-Net) is an end-to-end trainable multitasking network with a composite loss that also provides the advantages of anchor-free detections for efficient downstream pose estimation. To enable the annotation of training data for our learning objective, we develop a Twin-Space object labeling method and demonstrate its correctness analytically and empirically. Using the labeling method, we provide the KITTI-6DoF dataset with $\\sim7.5$K annotated frames. Extensive experiments on KITTI-6DoF and the popular LineMod datasets show a consistent performance gain with SMOPE-Net over existing pose estimation methods. Here are links to our proposed \\href{https://anonymous.4open.science/r/SMOPE-Net-D3DF}{SMOPE-Net}, \\href{https://anonymous.4open.science/r/LabelImg3D-6B16}{KITTI-6DoF dataset}, and \\href{https://anonymous.4open.science/r/LabelImg3D-6B16}{LabelImg3D labeling tool}. ",
    "url": "https://arxiv.org/abs/2211.11188",
    "authors": [
      "Congliang Li",
      "Shijie Sun",
      "Xiangyu Song",
      "Huansheng Song",
      "Naveed Akhtar",
      "Ajmal Saeed Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11189",
    "title": "Lemmas of Differential Privacy",
    "abstract": "We aim to collect buried lemmas that are useful for proofs. In particular, we try to provide self-contained proofs for those lemmas and categorise them according to their usage. ",
    "url": "https://arxiv.org/abs/2211.11189",
    "authors": [
      "Yiyang Huang",
      "Cl\u00e9ment L. Canonne"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.11190",
    "title": "Cross-Modal Contrastive Learning for Robust Reasoning in VQA",
    "abstract": "Multi-modal reasoning in visual question answering (VQA) has witnessed rapid progress recently. However, most reasoning models heavily rely on shortcuts learned from training data, which prevents their usage in challenging real-world scenarios. In this paper, we propose a simple but effective cross-modal contrastive learning strategy to get rid of the shortcut reasoning caused by imbalanced annotations and improve the overall performance. Different from existing contrastive learning with complex negative categories on coarse (Image, Question, Answer) triplet level, we leverage the correspondences between the language and image modalities to perform finer-grained cross-modal contrastive learning. We treat each Question-Answer (QA) pair as a whole, and differentiate between images that conform with it and those against it. To alleviate the issue of sampling bias, we further build connected graphs among images. For each positive pair, we regard the images from different graphs as negative samples and deduct the version of multi-positive contrastive learning. To our best knowledge, it is the first paper that reveals a general contrastive learning strategy without delicate hand-craft rules can contribute to robust VQA reasoning. Experiments on several mainstream VQA datasets demonstrate our superiority compared to the state of the arts. Code is available at \\url{https://github.com/qizhust/cmcl_vqa_pl}. ",
    "url": "https://arxiv.org/abs/2211.11190",
    "authors": [
      "Qi Zheng",
      "Chaoyue Wang",
      "Daqing Liu",
      "Dadong Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11191",
    "title": "Correlative Preference Transfer with Hierarchical Hypergraph Network for  Multi-Domain Recommendation",
    "abstract": "Advanced recommender systems usually involve multiple domains (scenarios or categories) for various marketing strategies, and users interact with them to satisfy their diverse demands. The goal of multi-domain recommendation is to improve the recommendation performance of all domains simultaneously. Conventional graph neural network based methods usually deal with each domain separately, or train a shared model for serving all domains. The former fails to leverage users' cross-domain behaviors, making the behavior sparseness issue a great obstacle. The latter learns shared user representation with respect to all domains, which neglects users' domain-specific preferences. These shortcomings greatly limit their performance in multi-domain recommendation. To tackle the limitations, an appropriate way is to learn from multi-domain user feedbacks and obtain separate user representations to characterize their domain-specific preferences. In this paper we propose $\\mathsf{H^3Trans}$, a hierarchical hypergraph network based correlative preference transfer framework for multi-domain recommendation. $\\mathsf{H^3Trans}$ represents multi-domain feedbacks into a unified graph to help preference transfer via taking full advantage of users' multi-domain behaviors. We incorporate two hyperedge-based modules, namely dynamic item transfer module (Hyper-I) and adaptive user aggregation module (Hyper-U). Hyper-I extracts correlative information from multi-domain user-item feedbacks for eliminating domain discrepancy of item representations. Hyper-U aggregates users' scattered preferences in multiple domains and further exploits the high-order (not only pair-wise) connections among them to learn user representations. Experimental results on both public datasets and large-scale production datasets verify the superiority of $\\mathsf{H^3Trans}$ for multi-domain recommendation. ",
    "url": "https://arxiv.org/abs/2211.11191",
    "authors": [
      "Zixuan Xu",
      "Penghui Wei",
      "Shaoguo Liu",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.11201",
    "title": "Uncertainty Reduction for 3D Point Cloud Self-Supervised Traversability  Estimation",
    "abstract": "Traversability estimation in off-road environments requires a robust perception system. Recently, approaches to learning a traversability estimation from past vehicle experiences in a self-supervised manner are arising as they can greatly reduce human labeling costs and labeling errors. Nonetheless, the learning setting from self-supervised traversability estimation suffers from congenital uncertainties that appear according to the scarcity of negative information. Negative data are rarely harvested as the system can be severely damaged while logging the data. To mitigate the uncertainty, we introduce a method to incorporate unlabeled data in order to leverage the uncertainty. First, we design a learning architecture that inputs query and support data. Second, unlabeled data are assigned based on the proximity in the metric space. Third, a new metric for uncertainty measures is introduced. We evaluated our approach on our own dataset, `Dtrail', which is composed of a wide variety of negative data. ",
    "url": "https://arxiv.org/abs/2211.11201",
    "authors": [
      "Jihwan Bae",
      "Junwon Seo",
      "Taekyung Kim",
      "Hae-gon Jeon",
      "Kiho Kwak",
      "Inwook Shim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11202",
    "title": "FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields",
    "abstract": "This paper presents the first significant work on directly predicting 3D face landmarks on neural radiance fields (NeRFs), without using intermediate representations such as 2D images, depth maps, or point clouds. Our 3D coarse-to-fine Face Landmarks NeRF (FLNeRF) model efficiently samples from the NeRF on the whole face with individual facial features for accurate landmarks. To mitigate the limited number of facial expressions in the available data, local and non-linear NeRF warp is applied at facial features in fine scale to simulate large emotions range, including exaggerated facial expressions (e.g., cheek blowing, wide opening mouth, eye blinking), for training FLNeRF. With such expression augmentation, our model can predict 3D landmarks not limited to the 20 discrete expressions given in the data. Robust 3D NeRF facial landmarks contribute to many downstream tasks. As an example, we modify MoFaNeRF to enable high-quality face editing and swapping using face landmarks on NeRF, allowing more direct control and wider range of complex expressions. Experiments show that the improved model using landmarks achieves comparable to better results. Github link: https://github.com/ZHANG1023/FLNeRF. ",
    "url": "https://arxiv.org/abs/2211.11202",
    "authors": [
      "Hao Zhang",
      "Tianyuan Dai",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.11208",
    "title": "Next3D: Generative Neural Texture Rasterization for 3D-Aware Head  Avatars",
    "abstract": "3D-aware generative adversarial networks (GANs) synthesize high-fidelity and multi-view-consistent facial images using only collections of single-view 2D imagery. Towards fine-grained control over facial attributes, recent efforts incorporate 3D Morphable Face Model (3DMM) to describe deformation in generative radiance fields either explicitly or implicitly. Explicit methods provide fine-grained expression control but cannot handle topological changes caused by hair and accessories, while implicit ones can model varied topologies but have limited generalization caused by the unconstrained deformation fields. We propose a novel 3D GAN framework for unsupervised learning of generative, high-quality and 3D-consistent facial avatars from unstructured 2D images. To achieve both deformation accuracy and topological flexibility, we propose a 3D representation called Generative Texture-Rasterized Tri-planes. The proposed representation learns Generative Neural Textures on top of parametric mesh templates and then projects them into three orthogonal-viewed feature planes through rasterization, forming a tri-plane feature representation for volume rendering. In this way, we combine both fine-grained expression control of mesh-guided explicit deformation and the flexibility of implicit volumetric representation. We further propose specific modules for modeling mouth interior which is not taken into account by 3DMM. Our method demonstrates state-of-the-art 3D-aware synthesis quality and animation ability through extensive experiments. Furthermore, serving as 3D prior, our animatable 3D representation boosts multiple applications including one-shot facial avatars and 3D-aware stylization. ",
    "url": "https://arxiv.org/abs/2211.11208",
    "authors": [
      "Jingxiang Sun",
      "Xuan Wang",
      "Lizhen Wang",
      "Xiaoyu Li",
      "Yong Zhang",
      "Hongwen Zhang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11209",
    "title": "A Novel Uncalibrated Visual Servoing Controller Baesd on Model-Free  Adaptive Control Method with Neural Network",
    "abstract": "Nowadays, with the continuous expansion of application scenarios of robotic arms, there are more and more scenarios where nonspecialist come into contact with robotic arms. However, in terms of robotic arm visual servoing, traditional Position-based Visual Servoing (PBVS) requires a lot of calibration work, which is challenging for the nonspecialist to cope with. To cope with this situation, Uncalibrated Image-Based Visual Servoing (UIBVS) frees people from tedious calibration work. This work applied a model-free adaptive control (MFAC) method which means that the parameters of controller are updated in real time, bringing better ability of suppression changes of system and environment. An artificial intelligent neural network is applied in designs of controller and estimator for hand-eye relationship. The neural network is updated with the knowledge of the system input and output information in MFAC method. Inspired by \"predictive model\" and \"receding-horizon\" in Model Predictive Control (MPC) method and introducing similar structures into our algorithm, we realizes the uncalibrated visual servoing for both stationary targets and moving trajectories. Simulated experiments with a robotic manipulator will be carried out to validate the proposed algorithm. ",
    "url": "https://arxiv.org/abs/2211.11209",
    "authors": [
      "Haibin Zeng",
      "Yueyong Lyu",
      "Jiaming Qi",
      "Shuangquan Zou",
      "Tanghao Qin",
      "Wenyu Qin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11210",
    "title": "Contrastive Masked Autoencoders for Self-Supervised Video Hashing",
    "abstract": "Self-Supervised Video Hashing (SSVH) models learn to generate short binary representations for videos without ground-truth supervision, facilitating large-scale video retrieval efficiency and attracting increasing research attention. The success of SSVH lies in the understanding of video content and the ability to capture the semantic relation among unlabeled videos. Typically, state-of-the-art SSVH methods consider these two points in a two-stage training pipeline, where they firstly train an auxiliary network by instance-wise mask-and-predict tasks and secondly train a hashing model to preserve the pseudo-neighborhood structure transferred from the auxiliary network. This consecutive training strategy is inflexible and also unnecessary. In this paper, we propose a simple yet effective one-stage SSVH method called ConMH, which incorporates video semantic information and video similarity relationship understanding in a single stage. To capture video semantic information for better hashing learning, we adopt an encoder-decoder structure to reconstruct the video from its temporal-masked frames. Particularly, we find that a higher masking ratio helps video understanding. Besides, we fully exploit the similarity relationship between videos by maximizing agreement between two augmented views of a video, which contributes to more discriminative and robust hash codes. Extensive experiments on three large-scale video datasets (\\ie, FCVID, ActivityNet and YFCC) indicate that ConMH achieves state-of-the-art results. Code is available at https://github.com/huangmozhi9527/ConMH. ",
    "url": "https://arxiv.org/abs/2211.11210",
    "authors": [
      "Yuting Wang",
      "Jinpeng Wang",
      "Bin Chen",
      "Ziyun Zeng",
      "Shutao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.11215",
    "title": "SegNeRF: 3D Part Segmentation with Neural Radiance Fields",
    "abstract": "Recent advances in Neural Radiance Fields (NeRF) boast impressive performances for generative tasks such as novel view synthesis and 3D reconstruction. Methods based on neural radiance fields are able to represent the 3D world implicitly by relying exclusively on posed images. Yet, they have seldom been explored in the realm of discriminative tasks such as 3D part segmentation.In this work, we attempt to bridge that gap by proposing SegNeRF: a neural field representation that integrates a semantic field along with the usual radiance field. SegNeRF inherits from previous works the ability to perform novel view synthesis and 3D reconstruction, and enables 3D part segmentation from a few images. Our extensive experiments on PartNet show that SegNeRF is capable of simultaneously predicting geometry, appearance, and semantic information from posed images, even for unseen objects. The predicted semantic fields allow SegNeRF to achieve an average mIoU of $\\textbf{30.30%}$ for 2D novel view segmentation, and $\\textbf{37.46%}$ for 3D part segmentation, boasting competitive performance against point-based methods by using only a few posed images. Additionally, SegNeRF is able to generate an explicit 3D model from a single image of an object taken in the wild, with its corresponding part segmentation. ",
    "url": "https://arxiv.org/abs/2211.11215",
    "authors": [
      "Jesus Zarzar",
      "Sara Rojas",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11220",
    "title": "STGlow: A Flow-based Generative Framework with Dual Graphormer for  Pedestrian Trajectory Prediction",
    "abstract": "Pedestrian trajectory prediction task is an essential component of intelligent systems, and its applications include but are not limited to autonomous driving, robot navigation, and anomaly detection of monitoring systems. Due to the diversity of motion behaviors and the complex social interactions among pedestrians, accurately forecasting the future trajectory of pedestrians is challenging. Existing approaches commonly adopt GANs or CVAEs to generate diverse trajectories. However, GAN-based methods do not directly model data in a latent space, which makes them fail to have full support over the underlying data distribution; CVAE-based methods optimize a lower bound on the log-likelihood of observations, causing the learned distribution to deviate from the underlying distribution. The above limitations make existing approaches often generate highly biased or unnatural trajectories.In this paper, we propose a novel generative flow based framework with dual graphormer for pedestrian trajectory prediction (STGlow). Different from previous approaches, our method can more accurately model the underlying data distribution by optimizing the exact log-likelihood of motion behaviors. Besides, our method has clear physical meanings to simulate the evolution of human motion behaviors, where the forward process of the flow gradually degrades the complex motion behavior into a simple behavior, while its reverse process represents the evolution of a simple behavior to the complex motion behavior. Further, we introduce a dual graphormer combining with the graph structure to more adequately model the temporal dependencies and the mutual spatial interactions. Experimental results on several benchmarks demonstrate that our method achieves much better performance compared to previous state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2211.11220",
    "authors": [
      "Rongqin Liang",
      "Yuanman Li",
      "Jiantao Zhou",
      "Xia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11236",
    "title": "Boosting the Transferability of Adversarial Attacks with Global Momentum  Initialization",
    "abstract": "Deep neural networks are vulnerable to adversarial examples, which attach human invisible perturbations to benign inputs. Simultaneously, adversarial examples exhibit transferability under different models, which makes practical black-box attacks feasible. However, existing methods are still incapable of achieving desired transfer attack performance. In this work, from the perspective of gradient optimization and consistency, we analyze and discover the gradient elimination phenomenon as well as the local momentum optimum dilemma. To tackle these issues, we propose Global Momentum Initialization (GI) to suppress gradient elimination and help search for the global optimum. Specifically, we perform gradient pre-convergence before the attack and carry out a global search during the pre-convergence stage. Our method can be easily combined with almost all existing transfer methods, and we improve the success rate of transfer attacks significantly by an average of 6.4% under various advanced defense mechanisms compared to state-of-the-art methods. Eventually, we achieve an attack success rate of 95.4%, fully illustrating the insecurity of existing defense mechanisms. ",
    "url": "https://arxiv.org/abs/2211.11236",
    "authors": [
      "Jiafeng Wang",
      "Zhaoyu Chen",
      "Kaixun Jiang",
      "Dingkang Yang",
      "Lingyi Hong",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.11238",
    "title": "RobustLoc: Robust Camera Pose Regression in Challenging Driving  Environments",
    "abstract": "Camera relocalization has various applications in autonomous driving. Previous camera pose regression models consider only ideal scenarios where there is little environmental perturbation. To deal with challenging driving environments that may have changing seasons, weather, illumination, and the presence of unstable objects, we propose RobustLoc, which derives its robustness against perturbations from neural differential equations. Our model uses a convolutional neural network to extract feature maps from multi-view images, a robust neural differential equation diffusion block module to diffuse information interactively, and a branched pose decoder with multi-layer training to estimate the vehicle poses. Experiments demonstrate that RobustLoc surpasses current state-of-the-art camera pose regression models and achieves robust performance in various environments. Our code is released at: https://github.com/sijieaaa/RobustLoc ",
    "url": "https://arxiv.org/abs/2211.11238",
    "authors": [
      "Sijie Wang",
      "Qiyu Kang",
      "Rui She",
      "Wee Peng Tay",
      "Andreas Hartmannsgruber",
      "Diego Navarro Navarro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11246",
    "title": "LSTM based models stability in the context of Sentiment Analysis for  social media",
    "abstract": "Deep learning techniques have proven their effectiveness for Sentiment Analysis (SA) related tasks. Recurrent neural networks (RNN), especially Long Short-Term Memory (LSTM) and Bidirectional LSTM, have become a reference for building accurate predictive models. However, the models complexity and the number of hyperparameters to configure raises several questions related to their stability. In this paper, we present various LSTM models and their key parameters, and we perform experiments to test the stability of these models in the context of Sentiment Analysis. ",
    "url": "https://arxiv.org/abs/2211.11246",
    "authors": [
      "Bousselham El Haddaoui",
      "Raddouane Chiheb",
      "Rdouan Faizi",
      "Abdellatif El Afia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.11255",
    "title": "Diffusion Denoising Process for Perceptron Bias in Out-of-distribution  Detection",
    "abstract": "Out-of-distribution (OOD) detection is an important task to ensure the reliability and safety of deep learning and the discriminator models outperform others for now. However, the feature extraction of the discriminator models must compress the data and lose certain information, leaving room for bad cases and malicious attacks. In this paper, we provide a new assumption that the discriminator models are more sensitive to some subareas of the input space and such perceptron bias causes bad cases and overconfidence areas. Under this assumption, we design new detection methods and indicator scores. For detection methods, we introduce diffusion models (DMs) into OOD detection. We find that the diffusion denoising process (DDP) of DMs also functions as a novel form of asymmetric interpolation, which is suitable to enhance the input and reduce the overconfidence areas. For indicator scores, we find that the features of the discriminator models of OOD inputs occur sharp changes under DDP and use the norm of this dynamic change as our indicator scores. Therefore, we develop a new framework to combine the discriminator and generation models to do OOD detection under our new assumption. The discriminator models provide proper detection spaces and the generation models reduce the overconfidence problem. According to our experiments on CIFAR10 and CIFAR100, our methods get competitive results with state-of-the-art methods. Our implementation is available at https://github.com/luping-liu/DiffOOD. ",
    "url": "https://arxiv.org/abs/2211.11255",
    "authors": [
      "Luping Liu",
      "Yi Ren",
      "Xize Cheng",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.11282",
    "title": "Task-Specific Data Augmentation and Inference Processing for VIPriors  Instance Segmentation Challenge",
    "abstract": "Instance segmentation is applied widely in image editing, image analysis and autonomous driving, etc. However, insufficient data is a common problem in practical applications. The Visual Inductive Priors(VIPriors) Instance Segmentation Challenge has focused on this problem. VIPriors for Data-Efficient Computer Vision Challenges ask competitors to train models from scratch in a data-deficient setting, but there are some visual inductive priors that can be used. In order to address the VIPriors instance segmentation problem, we designed a Task-Specific Data Augmentation(TS-DA) strategy and Inference Processing(TS-IP) strategy. The main purpose of task-specific data augmentation strategy is to tackle the data-deficient problem. And in order to make the most of visual inductive priors, we designed a task-specific inference processing strategy. We demonstrate the applicability of proposed method on VIPriors Instance Segmentation Challenge. The segmentation model applied is Hybrid Task Cascade based detector on the Swin-Base based CBNetV2 backbone. Experimental results demonstrate that proposed method can achieve a competitive result on the test set of 2022 VIPriors Instance Segmentation Challenge, with 0.531 AP@0.50:0.95. ",
    "url": "https://arxiv.org/abs/2211.11282",
    "authors": [
      "Bo Yan",
      "Xingran Zhao",
      "Yadong Li",
      "Hongbin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11292",
    "title": "Revealing intra-urban spatial structure through an exploratory analysis  by combining road network abstraction model and taxi trajectory data",
    "abstract": "The unprecedented urbanization in China has dramatically changed the urban spatial structure of cities. With the proliferation of individual-level geospatial big data, previous studies have widely used the network abstraction model to reveal the underlying urban spatial structure. However, the construction of network abstraction models primarily focuses on the topology of the road network without considering individual travel flows along with the road networks. Individual travel flows reflect the urban dynamics, which can further help understand the underlying spatial structure. This study therefore aims to reveal the intra-urban spatial structure by integrating the road network abstraction model and individual travel flows. To achieve this goal, we 1) quantify the spatial interaction relatedness of road segments based on the Word2Vec model using large volumes of taxi trip data, then 2) characterize the road abstraction network model according to the identified spatial interaction relatedness, and 3) implement a community detection algorithm to reveal sub-regions of a city. Our results reveal three levels of hierarchical spatial structures in the Wuhan metropolitan area. This study provides a data-driven approach to the investigation of urban spatial structure via identifying traffic interaction patterns on the road network, offering insights to urban planning practice and transportation management. ",
    "url": "https://arxiv.org/abs/2211.11292",
    "authors": [
      "Sheng Hu",
      "Song Gao",
      "Wei Luo",
      "Liang Wu",
      "Tianqi Li",
      "Yongyang Xu",
      "Ziwei Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2211.11300",
    "title": "Multi-Level Knowledge Distillation for Out-of-Distribution Detection in  Text",
    "abstract": "Self-supervised representation learning has proved to be a valuable component for out-of-distribution (OoD) detection with only the texts of in-distribution (ID) examples. These approaches either train a language model from scratch or fine-tune a pre-trained language model using ID examples, and then take perplexity as output by the language model as OoD scores. In this paper, we analyse the complementary characteristics of both OoD detection methods and propose a multi-level knowledge distillation approach to integrate their strengths, while mitigating their limitations. Specifically, we use a fine-tuned model as the teacher to teach a randomly initialized student model on the ID examples. Besides the prediction layer distillation, we present a similarity-based intermediate layer distillation method to facilitate the student's awareness of the information flow inside the teacher's layers. In this way, the derived student model gains the teacher's rich knowledge about the ID data manifold due to pre-training, while benefiting from seeing only ID examples during parameter learning, which promotes more distinguishable features for OoD detection. We conduct extensive experiments over multiple benchmark datasets, i.e., CLINC150, SST, 20 NewsGroups, and AG News; showing that the proposed method yields new state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2211.11300",
    "authors": [
      "Qianhui Wu",
      "Huiqiang Jiang",
      "Haonan Yin",
      "Borje F. Karlsson",
      "Chin-Yew Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.11306",
    "title": "A Computationally Efficient Robust Model Predictive Control Framework  for Ecological Adaptive Cruise Control Strategy of Electric Vehicles",
    "abstract": "The recent advancement in vehicular networking technology provides novel solutions for designing intelligent and sustainable vehicle motion controllers. This work addresses a car-following task, where the feedback linearisation method is combined with a robust model predictive control (RMPC) scheme to safely, optimally and efficiently control a connected electric vehicle. In particular, the nonlinear dynamics are linearised through a feedback linearisation method to maintain an efficient computational speed and to guarantee global optimality. At the same time, the inevitable model mismatch is dealt with by the RMPC design. The control objective of the RMPC is to optimise the electric energy efficiency of the ego vehicle with consideration of a bounded model mismatch disturbance subject to satisfaction of physical and safety constraints. Numerical results first verify the validity and robustness through a comparison between the proposed RMPC and a nominal MPC. Further investigation into the performance of the proposed method reveals a higher energy efficiency and passenger comfort level as compared to a recently proposed benchmark method using the space-domain modelling approach. ",
    "url": "https://arxiv.org/abs/2211.11306",
    "authors": [
      "Sheng Yu",
      "Xiao Pan",
      "Anastasis Georgiou",
      "Boli Chen",
      "Imad M. Jaimoukha",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.11308",
    "title": "Novel transfer learning schemes based on Siamese networks and synthetic  data",
    "abstract": "Transfer learning schemes based on deep networks which have been trained on huge image corpora offer state-of-the-art technologies in computer vision. Here, supervised and semi-supervised approaches constitute efficient technologies which work well with comparably small data sets. Yet, such applications are currently restricted to application domains where suitable deepnetwork models are readily available. In this contribution, we address an important application area in the domain of biotechnology, the automatic analysis of CHO-K1 suspension growth in microfluidic single-cell cultivation, where data characteristics are very dissimilar to existing domains and trained deep networks cannot easily be adapted by classical transfer learning. We propose a novel transfer learning scheme which expands a recently introduced Twin-VAE architecture, which is trained on realistic and synthetic data, and we modify its specialized training procedure to the transfer learning domain. In the specific domain, often only few to no labels exist and annotations are costly. We investigate a novel transfer learning strategy, which incorporates a simultaneous retraining on natural and synthetic data using an invariant shared representation as well as suitable target variables, while it learns to handle unseen data from a different microscopy tech nology. We show the superiority of the variation of our Twin-VAE architecture over the state-of-the-art transfer learning methodology in image processing as well as classical image processing technologies, which persists, even with strongly shortened training times and leads to satisfactory results in this domain. The source code is available at https://github.com/dstallmann/transfer_learning_twinvae, works cross-platform, is open-source and free (MIT licensed) software. We make the data sets available at https://pub.uni-bielefeld.de/record/2960030. ",
    "url": "https://arxiv.org/abs/2211.11308",
    "authors": [
      "Dominik Stallmann",
      "Philip Kenneweg",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.11312",
    "title": "Understanding the Vulnerability of Skeleton-based Human Activity  Recognition via Black-box Attack",
    "abstract": "Human Activity Recognition (HAR) has been employed in a wide range of applications, e.g. self-driving cars, where safety and lives are at stake. Recently, the robustness of existing skeleton-based HAR methods has been questioned due to their vulnerability to adversarial attacks, which causes concerns considering the scale of the implication. However, the proposed attacks require the full-knowledge of the attacked classifier, which is overly restrictive. In this paper, we show such threats indeed exist, even when the attacker only has access to the input/output of the model. To this end, we propose the very first black-box adversarial attack approach in skeleton-based HAR called BASAR. BASAR explores the interplay between the classification boundary and the natural motion manifold. To our best knowledge, this is the first time data manifold is introduced in adversarial attacks on time series. Via BASAR, we find on-manifold adversarial samples are extremely deceitful and rather common in skeletal motions, in contrast to the common belief that adversarial samples only exist off-manifold. Through exhaustive evaluation, we show that BASAR can deliver successful attacks across classifiers, datasets, and attack modes. By attack, BASAR helps identify the potential causes of the model vulnerability and provides insights on possible improvements. Finally, to mitigate the newly identified threat, we propose a new adversarial training approach by leveraging the sophisticated distributions of on/off-manifold adversarial samples, called mixed manifold-based adversarial training (MMAT). MMAT can successfully help defend against adversarial attacks without compromising classification accuracy. ",
    "url": "https://arxiv.org/abs/2211.11312",
    "authors": [
      "Yunfeng Diao",
      "He Wang",
      "Tianjia Shao",
      "Yong-Liang Yang",
      "Kun Zhou",
      "David Hogg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11317",
    "title": "DeSTSeg: Segmentation Guided Denoising Student-Teacher for Anomaly  Detection",
    "abstract": "Visual anomaly detection, an important problem in computer vision, is usually formulated as a one-class classification and segmentation task. The student-teacher (S-T) framework has proved to be effective in solving this challenge. However, previous works based on S-T only empirically applied constraints on normal data and fused multi-level information. In this study, we propose an improved model called DeSTSeg, which integrates a pre-trained teacher network, a denoising student encoder-decoder, and a segmentation network into one framework. First, to strengthen the constraints on anomalous data, we introduce a denoising procedure that allows the student network to learn more robust representations. From synthetically corrupted normal images, we train the student network to match the teacher network feature of the same images without corruption. Second, to fuse the multi-level S-T features adaptively, we train a segmentation network with rich supervision from synthetic anomaly masks, achieving a substantial performance improvement. Experiments on the industrial inspection benchmark dataset demonstrate that our method achieves state-of-the-art performance, 98.6% on image-level ROC, 75.8% on pixel-level average precision, and 76.4% on instance-level average precision. ",
    "url": "https://arxiv.org/abs/2211.11317",
    "authors": [
      "Xuan Zhang",
      "Shiyu Li",
      "Xi Li",
      "Ping Huang",
      "Jiulong Shan",
      "Ting Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11320",
    "title": "Recovering Fine Details for Neural Implicit Surface Reconstruction",
    "abstract": "Recent works on implicit neural representations have made significant strides. Learning implicit neural surfaces using volume rendering has gained popularity in multi-view reconstruction without 3D supervision. However, accurately recovering fine details is still challenging, due to the underlying ambiguity of geometry and appearance representation. In this paper, we present D-NeuS, a volume rendering-base neural implicit surface reconstruction method capable to recover fine geometry details, which extends NeuS by two additional loss functions targeting enhanced reconstruction quality. First, we encourage the rendered surface points from alpha compositing to have zero signed distance values, alleviating the geometry bias arising from transforming SDF to density for volume rendering. Second, we impose multi-view feature consistency on the surface points, derived by interpolating SDF zero-crossings from sampled points along rays. Extensive quantitative and qualitative results demonstrate that our method reconstructs high-accuracy surfaces with details, and outperforms the state of the art. ",
    "url": "https://arxiv.org/abs/2211.11320",
    "authors": [
      "Decai Chen",
      "Peng Zhang",
      "Ingo Feldmann",
      "Oliver Schreer",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11321",
    "title": "SPIN: Simulated Poisoning and Inversion Network for Federated  Learning-Based 6G Vehicular Networks",
    "abstract": "The applications concerning vehicular networks benefit from the vision of beyond 5G and 6G technologies such as ultra-dense network topologies, low latency, and high data rates. Vehicular networks have always faced data privacy preservation concerns, which lead to the advent of distributed learning techniques such as federated learning. Although federated learning has solved data privacy preservation issues to some extent, the technique is quite vulnerable to model inversion and model poisoning attacks. We assume that the design of defense mechanism and attacks are two sides of the same coin. Designing a method to reduce vulnerability requires the attack to be effective and challenging with real-world implications. In this work, we propose simulated poisoning and inversion network (SPIN) that leverages the optimization approach for reconstructing data from a differential model trained by a vehicular node and intercepted when transmitted to roadside unit (RSU). We then train a generative adversarial network (GAN) to improve the generation of data with each passing round and global update from the RSU, accordingly. Evaluation results show the qualitative and quantitative effectiveness of the proposed approach. The attack initiated by SPIN can reduce up to 22% accuracy on publicly available datasets while just using a single attacker. We assume that revealing the simulation of such attacks would help us find its defense mechanism in an effective manner. ",
    "url": "https://arxiv.org/abs/2211.11321",
    "authors": [
      "Sunder Ali Khowaja",
      "Parus Khuwaja",
      "Kapal Dev",
      "Angelos Antonopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.11323",
    "title": "A Generalized EigenGame with Extensions to Multiview Representation  Learning",
    "abstract": "Generalized Eigenvalue Problems (GEPs) encompass a range of interesting dimensionality reduction methods. Development of efficient stochastic approaches to these problems would allow them to scale to larger datasets. Canonical Correlation Analysis (CCA) is one example of a GEP for dimensionality reduction which has found extensive use in problems with two or more views of the data. Deep learning extensions of CCA require large mini-batch sizes, and therefore large memory consumption, in the stochastic setting to achieve good performance and this has limited its application in practice. Inspired by the Generalized Hebbian Algorithm, we develop an approach to solving stochastic GEPs in which all constraints are softly enforced by Lagrange multipliers. Then by considering the integral of this Lagrangian function, its pseudo-utility, and inspired by recent formulations of Principal Components Analysis and GEPs as games with differentiable utilities, we develop a game-theory inspired approach to solving GEPs. We show that our approaches share much of the theoretical grounding of the previous Hebbian and game theoretic approaches for the linear case but our method permits extension to general function approximators like neural networks for certain GEPs for dimensionality reduction including CCA which means our method can be used for deep multiview representation learning. We demonstrate the effectiveness of our method for solving GEPs in the stochastic setting using canonical multiview datasets and demonstrate state-of-the-art performance for optimizing Deep CCA. ",
    "url": "https://arxiv.org/abs/2211.11323",
    "authors": [
      "James Chapman",
      "Ana Lawry Aguila",
      "Lennie Wells"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.11324",
    "title": "Slow Motion Matters: A Slow Motion Enhanced Network for Weakly  Supervised Temporal Action Localization",
    "abstract": "Weakly supervised temporal action localization (WTAL) aims to localize actions in untrimmed videos with only weak supervision information (e.g. video-level labels). Most existing models handle all input videos with a fixed temporal scale. However, such models are not sensitive to actions whose pace of the movements is different from the ``normal\" speed, especially slow-motion action instances, which complete the movements with a much slower speed than their counterparts with a normal speed. Here arises the slow-motion blurred issue: It is hard to explore salient slow-motion information from videos at ``normal\" speed. In this paper, we propose a novel framework termed Slow Motion Enhanced Network (SMEN) to improve the ability of a WTAL network by compensating its sensitivity on slow-motion action segments. The proposed SMEN comprises a Mining module and a Localization module. The mining module generates mask to mine slow-motion-related features by utilizing the relationships between the normal motion and slow motion; while the localization module leverages the mined slow-motion features as complementary information to improve the temporal action localization results. Our proposed framework can be easily adapted by existing WTAL networks and enable them be more sensitive to slow-motion actions. Extensive experiments on three benchmarks are conducted, which demonstrate the high performance of our proposed framework. ",
    "url": "https://arxiv.org/abs/2211.11324",
    "authors": [
      "Weiqi Sun",
      "Rui Su",
      "Qian Yu",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11349",
    "title": "Data-Driven Offline Decision-Making via Invariant Representation  Learning",
    "abstract": "The goal in offline data-driven decision-making is synthesize decisions that optimize a black-box utility function, using a previously-collected static dataset, with no active interaction. These problems appear in many forms: offline reinforcement learning (RL), where we must produce actions that optimize the long-term reward, bandits from logged data, where the goal is to determine the correct arm, and offline model-based optimization (MBO) problems, where we must find the optimal design provided access to only a static dataset. A key challenge in all these settings is distributional shift: when we optimize with respect to the input into a model trained from offline data, it is easy to produce an out-of-distribution (OOD) input that appears erroneously good. In contrast to prior approaches that utilize pessimism or conservatism to tackle this problem, in this paper, we formulate offline data-driven decision-making as domain adaptation, where the goal is to make accurate predictions for the value of optimized decisions (\"target domain\"), when training only on the dataset (\"source domain\"). This perspective leads to invariant objective models (IOM), our approach for addressing distributional shift by enforcing invariance between the learned representations of the training dataset and optimized decisions. In IOM, if the optimized decisions are too different from the training dataset, the representation will be forced to lose much of the information that distinguishes good designs from bad ones, making all choices seem mediocre. Critically, when the optimizer is aware of this representational tradeoff, it should choose not to stray too far from the training distribution, leading to a natural trade-off between distributional shift and learning performance. ",
    "url": "https://arxiv.org/abs/2211.11349",
    "authors": [
      "Han Qi",
      "Yi Su",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11350",
    "title": "Rooms with Text: A Dataset for Overlaying Text Detection",
    "abstract": "In this paper, we introduce a new dataset of room interior pictures with overlaying and scene text, totalling to 4836 annotated images in 25 product categories. We provide details on the collection and annotation process of our dataset, and analyze its statistics. Furthermore, we propose a baseline method for overlaying text detection, that leverages the character region-aware text detection framework to guide the classification model. We validate our approach and show its efficiency in terms of binary classification metrics, reaching the final performance of 0.95 F1 score, with false positive and false negative rates of 0.02 and 0.06 correspondingly. ",
    "url": "https://arxiv.org/abs/2211.11350",
    "authors": [
      "Oleg Smirnov",
      "Aditya Tewari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11354",
    "title": "Object-level 3D Semantic Mapping using a Network of Smart Edge Sensors",
    "abstract": "Autonomous robots that interact with their environment require a detailed semantic scene model. For this, volumetric semantic maps are frequently used. The scene understanding can further be improved by including object-level information in the map. In this work, we extend a multi-view 3D semantic mapping system consisting of a network of distributed smart edge sensors with object-level information, to enable downstream tasks that need object-level input. Objects are represented in the map via their 3D mesh model or as an object-centric volumetric sub-map that can model arbitrary object geometry when no detailed 3D model is available. We propose a keypoint-based approach to estimate object poses via PnP and refinement via ICP alignment of the 3D object model with the observed point cloud segments. Object instances are tracked to integrate observations over time and to be robust against temporary occlusions. Our method is evaluated on the public Behave dataset where it shows pose estimation accuracy within a few centimeters and in real-world experiments with the sensor network in a challenging lab environment where multiple chairs and a table are tracked through the scene online, in real time even under high occlusions. ",
    "url": "https://arxiv.org/abs/2211.11354",
    "authors": [
      "Julian Hau",
      "Simon Bultmann",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11355",
    "title": "Blind Knowledge Distillation for Robust Image Classification",
    "abstract": "Optimizing neural networks with noisy labels is a challenging task, especially if the label set contains real-world noise. Networks tend to generalize to reasonable patterns in the early training stages and overfit to specific details of noisy samples in the latter ones. We introduce Blind Knowledge Distillation - a novel teacher-student approach for learning with noisy labels by masking the ground truth related teacher output to filter out potentially corrupted knowledge and to estimate the tipping point from generalizing to overfitting. Based on this, we enable the estimation of noise in the training data with Otsus algorithm. With this estimation, we train the network with a modified weighted cross-entropy loss function. We show in our experiments that Blind Knowledge Distillation detects overfitting effectively during training and improves the detection of clean and noisy labels on the recently published CIFAR-N dataset. Code is available at GitHub. ",
    "url": "https://arxiv.org/abs/2211.11355",
    "authors": [
      "Timo Kaiser",
      "Lukas Ehmann",
      "Christoph Reinders",
      "Bodo Rosenhahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11360",
    "title": "Extended Multilingual Protest News Detection -- Shared Task 1, CASE 2021  and 2022",
    "abstract": "We report results of the CASE 2022 Shared Task 1 on Multilingual Protest Event Detection. This task is a continuation of CASE 2021 that consists of four subtasks that are i) document classification, ii) sentence classification, iii) event sentence coreference identification, and iv) event extraction. The CASE 2022 extension consists of expanding the test data with more data in previously available languages, namely, English, Hindi, Portuguese, and Spanish, and adding new test data in Mandarin, Turkish, and Urdu for Sub-task 1, document classification. The training data from CASE 2021 in English, Portuguese and Spanish were utilized. Therefore, predicting document labels in Hindi, Mandarin, Turkish, and Urdu occurs in a zero-shot setting. The CASE 2022 workshop accepts reports on systems developed for predicting test data of CASE 2021 as well. We observe that the best systems submitted by CASE 2022 participants achieve between 79.71 and 84.06 F1-macro for new languages in a zero-shot setting. The winning approaches are mainly ensembling models and merging data in multiple languages. The best two submissions on CASE 2021 data outperform submissions from last year for Subtask 1 and Subtask 2 in all languages. Only the following scenarios were not outperformed by new submissions on CASE 2021: Subtask 3 Portuguese \\& Subtask 4 English. ",
    "url": "https://arxiv.org/abs/2211.11360",
    "authors": [
      "Ali H\u00fcrriyeto\u011flu",
      "Osman Mutlu",
      "F\u0131rat Duru\u015fan",
      "Onur Uca",
      "Alaeddin Sel\u00e7uk G\u00fcrel",
      "Benjamin Radford",
      "Yaoyao Dai",
      "Hansi Hettiarachchi",
      "Niklas Stoehr",
      "Tadashi Nomoto",
      "Milena Slavcheva",
      "Francielle Vargas",
      "Aaqib Javid",
      "Fatih Beyhan",
      "Erdem Y\u00f6r\u00fck"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11362",
    "title": "Crowdsensing-based Road Damage Detection Challenge (CRDDC-2022)",
    "abstract": "This paper summarizes the Crowdsensing-based Road Damage Detection Challenge (CRDDC), a Big Data Cup organized as a part of the IEEE International Conference on Big Data'2022. The Big Data Cup challenges involve a released dataset and a well-defined problem with clear evaluation metrics. The challenges run on a data competition platform that maintains a real-time online evaluation system for the participants. In the presented case, the data constitute 47,420 road images collected from India, Japan, the Czech Republic, Norway, the United States, and China to propose methods for automatically detecting road damages in these countries. More than 60 teams from 19 countries registered for this competition. The submitted solutions were evaluated using five leaderboards based on performance for unseen test images from the aforementioned six countries. This paper encapsulates the top 11 solutions proposed by these teams. The best-performing model utilizes ensemble learning based on YOLO and Faster-RCNN series models to yield an F1 score of 76% for test data combined from all 6 countries. The paper concludes with a comparison of current and past challenges and provides direction for the future. ",
    "url": "https://arxiv.org/abs/2211.11362",
    "authors": [
      "Deeksha Arya",
      "Hiroya Maeda",
      "Sanjay Kumar Ghosh",
      "Durga Toshniwal",
      "Hiroshi Omata",
      "Takehiro Kashiyama",
      "Yoshihide Sekimoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11378",
    "title": "Learning on tree architectures outperforms a convolutional feedforward  network",
    "abstract": "Advanced deep learning architectures consist of tens of fully connected and convolutional hidden layers, which are already extended to hundreds, and are far from their biological realization. Their implausible biological dynamics is based on changing a weight in a non-local manner, as the number of routes between an output unit and a weight is typically large, using the backpropagation technique. Here, offline and online CIFAR-10 database learning on 3-layer tree architectures, inspired by experimental-based dendritic tree adaptations, outperforms the achievable success rates of the 5-layer convolutional LeNet. Its highly pruning tree backpropagation procedure, where a single route connects an output unit and a weight, represents an efficient dendritic deep learning. ",
    "url": "https://arxiv.org/abs/2211.11378",
    "authors": [
      "Yuval Meir",
      "Itamar Ben-Noam",
      "Yarden Tzach",
      "Shiri Hodassman",
      "Ido Kanter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11381",
    "title": "LISA: Localized Image Stylization with Audio via Implicit Neural  Representation",
    "abstract": "We present a novel framework, Localized Image Stylization with Audio (LISA) which performs audio-driven localized image stylization. Sound often provides information about the specific context of the scene and is closely related to a certain part of the scene or object. However, existing image stylization works have focused on stylizing the entire image using an image or text input. Stylizing a particular part of the image based on audio input is natural but challenging. In this work, we propose a framework that a user provides an audio input to localize the sound source in the input image and another for locally stylizing the target object or scene. LISA first produces a delicate localization map with an audio-visual localization network by leveraging CLIP embedding space. We then utilize implicit neural representation (INR) along with the predicted localization map to stylize the target object or scene based on sound information. The proposed INR can manipulate the localized pixel values to be semantically consistent with the provided audio input. Through a series of experiments, we show that the proposed framework outperforms the other audio-guided stylization methods. Moreover, LISA constructs concise localization maps and naturally manipulates the target object or scene in accordance with the given audio input. ",
    "url": "https://arxiv.org/abs/2211.11381",
    "authors": [
      "Seung Hyun Lee",
      "Chanyoung Kim",
      "Wonmin Byeon",
      "Sang Ho Yoon",
      "Jinkyu Kim",
      "Sangpil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.11386",
    "title": "PS-Transformer: Learning Sparse Photometric Stereo Network using  Self-Attention Mechanism",
    "abstract": "Existing deep calibrated photometric stereo networks basically aggregate observations under different lights based on the pre-defined operations such as linear projection and max pooling. While they are effective with the dense capture, simple first-order operations often fail to capture the high-order interactions among observations under small number of different lights. To tackle this issue, this paper presents a deep sparse calibrated photometric stereo network named {\\it PS-Transformer} which leverages the learnable self-attention mechanism to properly capture the complex inter-image interactions. PS-Transformer builds upon the dual-branch design to explore both pixel-wise and image-wise features and individual feature is trained with the intermediate surface normal supervision to maximize geometric feasibility. A new synthetic dataset named CyclesPS+ is also presented with the comprehensive analysis to successfully train the photometric stereo networks. Extensive results on the publicly available benchmark datasets demonstrate that the surface normal prediction accuracy of the proposed method significantly outperforms other state-of-the-art algorithms with the same number of input images and is even comparable to that of dense algorithms which input 10$\\times$ larger number of images. ",
    "url": "https://arxiv.org/abs/2211.11386",
    "authors": [
      "Satoshi Ikehata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11396",
    "title": "A Curriculum-Training-Based Strategy for Distributing Collocation Points  during Physics-Informed Neural Network Training",
    "abstract": "Physics-informed Neural Networks (PINNs) often have, in their loss functions, terms based on physical equations and derivatives. In order to evaluate these terms, the output solution is sampled using a distribution of collocation points. However, density-based strategies, in which the number of collocation points over the domain increases throughout the training period, do not scale well to multiple spatial dimensions. To remedy this issue, we present here a curriculum-training-based method for lightweight collocation point distributions during network training. We apply this method to a PINN which recovers a full two-dimensional magnetohydrodynamic (MHD) solution from a partial sample taken from a baseline MHD simulation. We find that the curriculum collocation point strategy leads to a significant decrease in training time and simultaneously enhances the quality of the reconstructed solution. ",
    "url": "https://arxiv.org/abs/2211.11396",
    "authors": [
      "Marcus M\u00fcnzer",
      "Chris Bard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2211.11406",
    "title": "Structural Optimization of Factor Graphs for Symbol Detection via  Continuous Clustering and Machine Learning",
    "abstract": "We propose a novel method to optimize the structure of factor graphs for graph-based inference. As an example inference task, we consider symbol detection on linear inter-symbol interference channels. The factor graph framework has the potential to yield low-complexity symbol detectors. However, the sum-product algorithm on cyclic factor graphs is suboptimal and its performance is highly sensitive to the underlying graph. Therefore, we optimize the structure of the underlying factor graphs in an end-to-end manner using machine learning. For that purpose, we transform the structural optimization into a clustering problem of low-degree factor nodes that incorporates the known channel model into the optimization. Furthermore, we study the combination of this approach with neural belief propagation, yielding near-maximum a posteriori symbol detection performance for specific channels. ",
    "url": "https://arxiv.org/abs/2211.11406",
    "authors": [
      "Lukas Rapp",
      "Luca Schmid",
      "Andrej Rode",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.11407",
    "title": "RAILD: Towards Leveraging Relation Features for Inductive Link  Prediction In Knowledge Graphs",
    "abstract": "Due to the open world assumption, Knowledge Graphs (KGs) are never complete. In order to address this issue, various Link Prediction (LP) methods are proposed so far. Some of these methods are inductive LP models which are capable of learning representations for entities not seen during training. However, to the best of our knowledge, none of the existing inductive LP models focus on learning representations for unseen relations. In this work, a novel Relation Aware Inductive Link preDiction (RAILD) is proposed for KG completion which learns representations for both unseen entities and unseen relations. In addition to leveraging textual literals associated with both entities and relations by employing language models, RAILD also introduces a novel graph-based approach to generate features for relations. Experiments are conducted with different existing and newly created challenging benchmark datasets and the results indicate that RAILD leads to performance improvement over the state-of-the-art models. Moreover, since there are no existing inductive LP models which learn representations for unseen relations, we have created our own baselines and the results obtained with RAILD also outperform these baselines. ",
    "url": "https://arxiv.org/abs/2211.11407",
    "authors": [
      "Genet Asefa Gesese",
      "Harald Sack",
      "Mehwish Alam"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.11417",
    "title": "DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular  Automata",
    "abstract": "Current Dynamic Texture Synthesis (DyTS) models in the literature can synthesize realistic videos. However, these methods require a slow iterative optimization process to synthesize a single fixed-size short video, and they do not offer any post-training control over the synthesis process. We propose Dynamic Neural Cellular Automata (DyNCA), a framework for real-time and controllable dynamic texture synthesis. Our method is built upon the recently introduced NCA models, and can synthesize infinitely-long and arbitrary-size realistic texture videos in real-time. We quantitatively and qualitatively evaluate our model and show that our synthesized videos appear more realistic than the existing results. We improve the SOTA DyTS performance by $2\\sim 4$ orders of magnitude. Moreover, our model offers several real-time and interactive video controls including motion speed, motion direction, and an editing brush tool. ",
    "url": "https://arxiv.org/abs/2211.11417",
    "authors": [
      "Ehsan Pajouheshgar",
      "Yitao Xu",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11426",
    "title": "Revealing Hidden Context Bias in Segmentation and Object Detection  through Concept-specific Explanations",
    "abstract": "Applying traditional post-hoc attribution methods to segmentation or object detection predictors offers only limited insights, as the obtained feature attribution maps at input level typically resemble the models' predicted segmentation mask or bounding box. In this work, we address the need for more informative explanations for these predictors by proposing the post-hoc eXplainable Artificial Intelligence method L-CRP to generate explanations that automatically identify and visualize relevant concepts learned, recognized and used by the model during inference as well as precisely locate them in input space. Our method therefore goes beyond singular input-level attribution maps and, as an approach based on the recently published Concept Relevance Propagation technique, is efficiently applicable to state-of-the-art black-box architectures in segmentation and object detection, such as DeepLabV3+ and YOLOv6, among others. We verify the faithfulness of our proposed technique by quantitatively comparing different concept attribution methods, and discuss the effect on explanation complexity on popular datasets such as CityScapes, Pascal VOC and MS COCO 2017. The ability to precisely locate and communicate concepts is used to reveal and verify the use of background features, thereby highlighting possible biases of the model. ",
    "url": "https://arxiv.org/abs/2211.11426",
    "authors": [
      "Maximilian Dreyer",
      "Reduan Achtibat",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11434",
    "title": "Privacy in Practice: Private COVID-19 Detection in X-Ray Images",
    "abstract": "Machine learning (ML) can help fight the COVID-19 pandemic by enabling rapid screening of large volumes of chest X-ray images. To perform such data analysis while maintaining patient privacy, we create ML models that satisfy Differential Privacy (DP). Previous works exploring private COVID-19 ML models are in part based on small or skewed datasets, are lacking in their privacy guarantees, and do not investigate practical privacy. In this work, we therefore suggest several improvements to address these open gaps. We account for inherent class imbalances in the data and evaluate the utility-privacy trade-off more extensively and over stricter privacy budgets than in previous work. Our evaluation is supported by empirically estimating practical privacy leakage through actual attacks. Based on theory, the introduced DP should help limit and mitigate information leakage threats posed by black-box Membership Inference Attacks (MIAs). Our practical privacy analysis is the first to test this hypothesis on the COVID-19 detection task. In addition, we also re-examine the evaluation on the MNIST database. Our results indicate that based on the task-dependent threat from MIAs, DP does not always improve practical privacy, which we show on the COVID-19 task. The results further suggest that with increasing DP guarantees, empirical privacy leakage reaches an early plateau and DP therefore appears to have a limited impact on MIA defense. Our findings identify possibilities for better utility-privacy trade-offs, and we thus believe that empirical attack-specific privacy estimation can play a vital role in tuning for practical privacy. ",
    "url": "https://arxiv.org/abs/2211.11434",
    "authors": [
      "Lucas Lange",
      "Maja Schneider",
      "Erhard Rahm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11455",
    "title": "Backdoor Attacks on Multiagent Collaborative Systems",
    "abstract": "Backdoor attacks on reinforcement learning implant a backdoor in a victim agent's policy. Once the victim observes the trigger signal, it will switch to the abnormal mode and fail its task. Most of the attacks assume the adversary can arbitrarily modify the victim's observations, which may not be practical. One work proposes to let one adversary agent use its actions to affect its opponent in two-agent competitive games, so that the opponent quickly fails after observing certain trigger actions. However, in multiagent collaborative systems, agents may not always be able to observe others. When and how much the adversary agent can affect others are uncertain, and we want the adversary agent to trigger others for as few times as possible. To solve this problem, we first design a novel training framework to produce auxiliary rewards that measure the extent to which the other agents'observations being affected. Then we use the auxiliary rewards to train a trigger policy which enables the adversary agent to efficiently affect the others' observations. Given these affected observations, we further train the other agents to perform abnormally. Extensive experiments demonstrate that the proposed method enables the adversary agent to lure the others into the abnormal mode with only a few actions. ",
    "url": "https://arxiv.org/abs/2211.11455",
    "authors": [
      "Shuo Chen",
      "Yue Qiu",
      "Jie Zhang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2211.11475",
    "title": "Sensing-Assisted Communication in Vehicular Networks with Intelligent  Surface",
    "abstract": "The recent development of integrated sensing and communications (ISAC) technology offers new opportunities to meet high-throughput and low-latency communication as well as high-resolution localization requirements in vehicular networks. However, considering the limited transmit power of the road site units (RSUs) and the relatively small radar cross section (RCS) of vehicles with random reflection coefficients, the power of echo signals may be too weak to be utilized for effective target detection and tracking. Moreover, high-frequency signals usually suffer from large fading loss when penetrating vehicles, which seriously degrades the quality of communication services inside the vehicles. To handle this issue, we propose a novel sensing-assisted communication mechanism by employing an intelligent omni-surface (IOS) on the surface of vehicles to enhance both sensing and communication (S&C) performance. To this end, we first propose a two-stage ISAC protocol, including the joint S&C stage and the communication-only stage, to fulfill more efficient communication performance improvements benefited from sensing. The achievable communication rate maximization problem is formulated by jointly optimizing the transmit beamforming, the IOS phase shifts, and the duration of the joint S&C stage. However, solving this ISAC optimization problem is highly non-trivial since inaccurate estimation and measurement information renders the achievable rate lack of closed-form expression. To handle this issue, we first derive a closed-form expression of the achievable rate under uncertain location information, and then unveil a sufficient and necessary condition for the existence of the joint S&C stage to offer useful insights for practical system design. Moreover, two typical scenarios including interference-limited and noise-limited cases are analyzed. ",
    "url": "https://arxiv.org/abs/2211.11475",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Wen Chen",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.11478",
    "title": "Background-Mixed Augmentation for Weakly Supervised Change Detection",
    "abstract": "Change detection (CD) is to decouple object changes (i.e., object missing or appearing) from background changes (i.e., environment variations) like light and season variations in two images captured in the same scene over a long time span, presenting critical applications in disaster management, urban development, etc. In particular, the endless patterns of background changes require detectors to have a high generalization against unseen environment variations, making this task significantly challenging. Recent deep learning-based methods develop novel network architectures or optimization strategies with paired-training examples, which do not handle the generalization issue explicitly and require huge manual pixel-level annotation efforts. In this work, for the first attempt in the CD community, we study the generalization issue of CD from the perspective of data augmentation and develop a novel weakly supervised training algorithm that only needs image-level labels. Different from general augmentation techniques for classification, we propose the background-mixed augmentation that is specifically designed for change detection by augmenting examples under the guidance of a set of background changing images and letting deep CD models see diverse environment variations. Moreover, we propose the augmented & real data consistency loss that encourages the generalization increase significantly. Our method as a general framework can enhance a wide range of existing deep learning-based detectors. We conduct extensive experiments in two public datasets and enhance four state-of-the-art methods, demonstrating the advantages of ",
    "url": "https://arxiv.org/abs/2211.11478",
    "authors": [
      "Rui Huang",
      "Ruofei Wang",
      "Qing Guo",
      "Jieda Wei",
      "Yuxiang Zhang",
      "Wei Fan",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11482",
    "title": "Applications of statistical causal inference in software engineering",
    "abstract": "This paper reviews existing work in software engineering that applies statistical causal inference methods. These methods aim at estimating causal effects from observational data. The review covers 32 papers published between 2010 and 2022. Our results show that the application of statistical causal inference methods is relatively recent and that the corresponding research community remains relatively fragmented. ",
    "url": "https://arxiv.org/abs/2211.11482",
    "authors": [
      "Julien Siebert"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11501",
    "title": "DS-1000: A Natural and Reliable Benchmark for Data Science Code  Generation",
    "abstract": "We introduce DS-1000, a code generation benchmark with a thousand data science problems spanning seven Python libraries, such as NumPy and Pandas. Compared to prior works, DS-1000 incorporates three core features. First, our problems reflect diverse, realistic, and practical use cases since we collected them from StackOverflow. Second, our automatic evaluation is highly specific (reliable) -- across all Codex-002-predicted solutions that our evaluation accept, only 1.8% of them are incorrect; we achieve this with multi-criteria metrics, checking both functional correctness by running test cases and surface-form constraints by restricting API usages or keywords. Finally, we proactively defend against memorization by slightly modifying our problems to be different from the original StackOverflow source; consequently, models cannot answer them correctly by memorizing the solutions from pre-training. The current best public system (Codex-002) achieves 43.3% accuracy, leaving ample room for improvement. We release our benchmark at https://ds1000-code-gen.github.io. ",
    "url": "https://arxiv.org/abs/2211.11501",
    "authors": [
      "Yuhang Lai",
      "Chengxi Li",
      "Yiming Wang",
      "Tianyi Zhang",
      "Ruiqi Zhong",
      "Luke Zettlemoyer",
      "Scott Wen-tau Yih",
      "Daniel Fried",
      "Sida Wang",
      "Tao Yu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.11505",
    "title": "Local-to-Global Registration for Bundle-Adjusting Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) have achieved photorealistic novel views synthesis; however, the requirement of accurate camera poses limits its application. Despite analysis-by-synthesis extensions for jointly learning neural 3D representations and registering camera frames exist, they are susceptible to suboptimal solutions if poorly initialized. We propose L2G-NeRF, a Local-to-Global registration method for bundle-adjusting Neural Radiance Fields: first, a pixel-wise flexible alignment, followed by a frame-wise constrained parametric alignment. Pixel-wise local alignment is learned in an unsupervised way via a deep network which optimizes photometric reconstruction errors. Frame-wise global alignment is performed using differentiable parameter estimation solvers on the pixel-wise correspondences to find a global transformation. Experiments on synthetic and real-world data show that our method outperforms the current state-of-the-art in terms of high-fidelity reconstruction and resolving large camera pose misalignment. Our module is an easy-to-use plugin that can be applied to NeRF variants and other neural field applications. The Code and supplementary materials are available at https://rover-xingyu.github.io/L2G-NeRF/. ",
    "url": "https://arxiv.org/abs/2211.11505",
    "authors": [
      "Yue Chen",
      "Xingyu Chen",
      "Xuan Wang",
      "Qi Zhang",
      "Yu Guo",
      "Ying Shan",
      "Fei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11520",
    "title": "Demo Abstract: Real-Time Out-of-Distribution Detection on a Mobile Robot",
    "abstract": "In a cyber-physical system such as an autonomous vehicle (AV), machine learning (ML) models can be used to navigate and identify objects that may interfere with the vehicle's operation. However, ML models are unlikely to make accurate decisions when presented with data outside their training distribution. Out-of-distribution (OOD) detection can act as a safety monitor for ML models by identifying such samples at run time. However, in safety critical systems like AVs, OOD detection needs to satisfy real-time constraints in addition to functional requirements. In this demonstration, we use a mobile robot as a surrogate for an AV and use an OOD detector to identify potentially hazardous samples. The robot navigates a miniature town using image data and a YOLO object detection network. We show that our OOD detector is capable of identifying OOD images in real-time on an embedded platform concurrently performing object detection and lane following. We also show that it can be used to successfully stop the vehicle in the presence of unknown, novel samples. ",
    "url": "https://arxiv.org/abs/2211.11520",
    "authors": [
      "Michael Yuhas",
      "Arvind Easwaran"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11528",
    "title": "Machine Learning enabled models for YouTube Ranking Mechanism and Views  Prediction",
    "abstract": "With the continuous increase of internet usage in todays time, everyone is influenced by this source of the power of technology. Due to this, the rise of applications and games Is unstoppable. A major percentage of our population uses these applications for multiple purposes. These range from education, communication, news, entertainment, and many more. Out of this, the application that is making sure that the world stays in touch with each other and with current affairs is social media. Social media applications have seen a boom in the last 10 years with the introduction of smartphones and the internet being available at affordable prices. Applications like Twitch and Youtube are some of the best platforms for producing content and expressing their talent as well. It is the goal of every content creator to post the best and most reliable content so that they can gain recognition. It is important to know the methods of achieving popularity easily, which is what this paper proposes to bring to the spotlight. There should be certain parameters based on which the reach of content could be multiplied by a good factor. The proposed research work aims to identify and estimate the reach, popularity, and views of a YouTube video by using certain features using machine learning and AI techniques. A ranking system would also be used keeping the trending videos in consideration. This would eventually help the content creator know how authentic their content is and healthy competition to make better content before uploading the video on the platform will be ensured. ",
    "url": "https://arxiv.org/abs/2211.11528",
    "authors": [
      "Vandit Gupta",
      "Akshit Diwan",
      "Chaitanya Chadha",
      "Ashish Khanna",
      "Deepak Gupta"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11530",
    "title": "Open-Set Object Detection Using Classification-free Object Proposal and  Instance-level Contrastive Learning with Appendix",
    "abstract": "Detecting both known and unknown objects is a fundamental skill for robot manipulation in unstructured environments. Open-set object detection (OSOD) is a promising direction to handle the problem consisting of two subtasks: objects and background separation, and open-set object classification. In this paper, we present Openset RCNN to address the challenging OSOD. To disambiguate unknown objects and background in the first subtask, we propose to use classification-free region proposal network (CF-RPN) which estimates the objectness score of each region purely using cues from object's location and shape preventing overfitting to the training categories. To identify unknown objects in the second subtask, we propose to represent them using the complementary region of known categories in a latent space which is accomplished by a prototype learning network (PLN). PLN performs instance-level contrastive learning to encode proposals to a latent space and builds a compact region centering with a prototype for each known category. Further, we note that the detection performance of unknown objects can not be unbiasedly evaluated on the situation that commonly used object detection datasets are not fully annotated. Thus, a new benchmark is introduced by reorganizing GraspNet-1billion, a robotic grasp pose detection dataset with complete annotation. Extensive experiments demonstrate the merits of our method. We finally show that our Openset RCNN can endow the robot with an open-set perception ability to support robotic rearrangement tasks in cluttered environments. More details can be found in https://sites.google.com/view/openest-rcnn/ ",
    "url": "https://arxiv.org/abs/2211.11530",
    "authors": [
      "Zhongxiang Zhou",
      "Yifei Yang",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11534",
    "title": "How Fraudster Detection Contributes to Robust Recommendation",
    "abstract": "The adversarial robustness of recommendation systems under node injection attacks has received considerable research attention. Recently, a robust recommendation system GraphRfi was proposed, and it was shown that GraphRfi could successfully mitigate the effects of injected fake users in the system. Unfortunately, we demonstrate that GraphRfi is still vulnerable to attacks due to the supervised nature of its fraudster detection component. Specifically, we propose a new attack metaC against GraphRfi, and further analyze why GraphRfi fails under such an attack. Based on the insights we obtained from the vulnerability analysis, we build a new robust recommendation system PDR by re-designing the fraudster detection component. Comprehensive experiments show that our defense approach outperforms other benchmark methods under attacks. Overall, our research demonstrates an effective framework of integrating fraudster detection into recommendation to achieve adversarial robustness. ",
    "url": "https://arxiv.org/abs/2211.11534",
    "authors": [
      "Yuni Lai",
      "Kai Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11551",
    "title": "Evolutionary Strategies for the Design of Binary Linear Codes",
    "abstract": "The design of binary error-correcting codes is a challenging optimization problem with several applications in telecommunications and storage, which has also been addressed with metaheuristic techniques and evolutionary algorithms. Still, all these efforts focused on optimizing the minimum distance of unrestricted binary codes, i.e., with no constraints on their linearity, which is a desirable property for efficient implementations. In this paper, we present an Evolutionary Strategy (ES) algorithm that explores only the subset of linear codes of a fixed length and dimension. To that end, we represent the candidate solutions as binary matrices and devise variation operators that preserve their ranks. Our experiments show that up to length $n=14$, our ES always converges to an optimal solution with a full success rate, and the evolved codes are all inequivalent to the Best-Known Linear Code (BKLC) given by MAGMA. On the other hand, for larger lengths, both the success rate of the ES as well as the diversity of the evolved codes start to drop, with the extreme case of $(16,8,5)$ codes which all turn out to be equivalent to MAGMA's BKLC. ",
    "url": "https://arxiv.org/abs/2211.11551",
    "authors": [
      "Claude Carlet",
      "Luca Mariot",
      "Luca Manzoni",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2211.11554",
    "title": "Programming by Example and Text-to-Code Translation for Conversational  Code Generation",
    "abstract": "Dialogue systems is an increasingly popular task of natural language processing. However, the dialogue paths tend to be deterministic, restricted to the system rails, regardless of the given request or input text. Recent advances in program synthesis have led to systems which can synthesize programs from very general search spaces, e.g. Programming by Example, and to systems with very accessible interfaces for writing programs, e.g. text-to-code translation, but have not achieved both of these qualities in the same system. We propose Modular Programs for Text-guided Hierarchical Synthesis (MPaTHS), a method for integrating Programming by Example and text-to-code systems which offers an accessible natural language interface for synthesizing general programs. We present a program representation that allows our method to be applied to the problem of task-oriented dialogue. Finally, we demo MPaTHS using our program representation. ",
    "url": "https://arxiv.org/abs/2211.11554",
    "authors": [
      "Eli Whitehouse",
      "William Gerard",
      "Yauhen Klimovich",
      "Marc Franco-Salvador"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.11565",
    "title": "IEEE Big Data Cup 2022: Privacy Preserving Matching of Encrypted Images  with Deep Learning",
    "abstract": "Smart sensors, devices and systems deployed in smart cities have brought improved physical protections to their citizens. Enhanced crime prevention, and fire and life safety protection are achieved through these technologies that perform motion detection, threat and actors profiling, and real-time alerts. However, an important requirement in these increasingly prevalent deployments is the preservation of privacy and enforcement of protection of personal identifiable information. Thus, strong encryption and anonymization techniques should be applied to the collected data. In this IEEE Big Data Cup 2022 challenge, different masking, encoding and homomorphic encryption techniques were applied to the images to protect the privacy of their contents. Participants are required to develop detection solutions to perform privacy preserving matching of these images. In this paper, we describe our solution which is based on state-of-the-art deep convolutional neural networks and various data augmentation techniques. Our solution achieved 1st place at the IEEE Big Data Cup 2022: Privacy Preserving Matching of Encrypted Images Challenge. ",
    "url": "https://arxiv.org/abs/2211.11565",
    "authors": [
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.11571",
    "title": "SLLEN: Semantic-aware Low-light Image Enhancement Network",
    "abstract": "How to effectively explore semantic feature is vital for low-light image enhancement (LLE). Existing methods usually utilize the semantic feature that is only drawn from the semantic map produced by high-level semantic segmentation network (SSN). However, if the semantic map is not accurately estimated, it would affect the high-level semantic feature (HSF) extraction, which accordingly interferes with LLE. In this paper, we develop a simple yet effective two-branch semantic-aware LLE network (SLLEN) that neatly integrates the random intermediate embedding feature (IEF) (i.e., the information extracted from the intermediate layer of semantic segmentation network) together with the HSF into a unified framework for better LLE. Specifically, for one branch, we utilize an attention mechanism to integrate HSF into low-level feature. For the other branch, we extract IEF to guide the adjustment of low-level feature using nonlinear transformation manner. Finally, semantic-aware features obtained from two branches are fused and decoded for image enhancement. It is worth mentioning that IEF has some randomness compared to HSF despite their similarity on semantic characteristics, thus its introduction can allow network to learn more possibilities by leveraging the latent relationships between the low-level feature and semantic feature, just like the famous saying \"God rolls the dice\" in Physics Nobel Prize 2022. Comparisons between the proposed SLLEN and other state-of-the-art techniques demonstrate the superiority of SLLEN with respect to LLE quality over all the comparable alternatives. ",
    "url": "https://arxiv.org/abs/2211.11571",
    "authors": [
      "Mingye Ju",
      "Charles A. Guo",
      "Chuheng Chen",
      "Jinshan Pan",
      "Jinhui Tang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11572",
    "title": "Detect Only What You Specify : Object Detection with Linguistic Target",
    "abstract": "Object detection is a computer vision task of predicting a set of bounding boxes and category labels for each object of interest in a given image. The category is related to a linguistic symbol such as 'dog' or 'person' and there should be relationships among them. However the object detector only learns to classify the categories and does not treat them as the linguistic symbols. Multi-modal models often use the pre-trained object detector to extract object features from the image, but the models are separated from the detector and the extracted visual features does not change with their linguistic input. We rethink the object detection as a vision-and-language reasoning task. We then propose targeted detection task, where detection targets are given by a natural language and the goal of the task is to detect only all the target objects in a given image. There are no detection if the target is not given. Commonly used modern object detectors have many hand-designed components like anchor and it is difficult to fuse the textual inputs into the complex pipeline. We thus propose Language-Targeted Detector (LTD) for the targeted detection based on a recently proposed Transformer-based detector. LTD is a encoder-decoder architecture and our conditional decoder allows the model to reason about the encoded image with the textual input as the linguistic context. We evaluate detection performances of LTD on COCO object detection dataset and also show that our model improves the detection results with the textual input grounding to the visual object. ",
    "url": "https://arxiv.org/abs/2211.11572",
    "authors": [
      "Moyuru Yamada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11577",
    "title": "Data Privacy in Multi-Cloud: An Enhanced Data Fragmentation Framework",
    "abstract": "Data splitting preserves privacy by partitioning data into various fragments to be stored remotely and shared. It supports most data operations because data can be stored in clear as opposed to methods that rely on cryptography. However, majority of existing data splitting techniques do not consider data already in the multi-cloud. This leads to unnecessary use of resources to re-split data into fragments. This work proposes a data splitting framework that leverages on existing data in the multi-cloud. It improves data splitting mechanisms by reducing the number of splitting operations and resulting fragments. Therefore, decreasing the number of storage locations a data owner manages. Broadcasts queries locate third-party data fragments to avoid costly operations when splitting data. This work examines considerations for the use of third-party fragments and application to existing data splitting techniques. The proposed framework was also applied to an existing data splitting mechanism to complement its capabilities. ",
    "url": "https://arxiv.org/abs/2211.11577",
    "authors": [
      "Randolph Loh",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.11583",
    "title": "Recommending Related Products Using Graph Neural Networks in Directed  Graphs",
    "abstract": "Related product recommendation (RPR) is pivotal to the success of any e-commerce service. In this paper, we deal with the problem of recommending related products i.e., given a query product, we would like to suggest top-k products that have high likelihood to be bought together with it. Our problem implicitly assumes asymmetry i.e., for a phone, we would like to recommend a suitable phone case, but for a phone case, it may not be apt to recommend a phone because customers typically would purchase a phone case only while owning a phone. We also do not limit ourselves to complementary or substitute product recommendation. For example, for a specific night wear t-shirt, we can suggest similar t-shirts as well as track pants. So, the notion of relatedness is subjective to the query product and dependent on customer preferences. Further, various factors such as product price, availability lead to presence of selection bias in the historical purchase data, that needs to be controlled for while training related product recommendations model. These challenges are orthogonal to each other deeming our problem nontrivial. To address these, we propose DAEMON, a novel Graph Neural Network (GNN) based framework for related product recommendation, wherein the problem is formulated as a node recommendation task on a directed product graph. In order to capture product asymmetry, we employ an asymmetric loss function and learn dual embeddings for each product, by appropriately aggregating features from its neighborhood. DAEMON leverages multi-modal data sources such as catalog metadata, browse behavioral logs to mitigate selection bias and generate recommendations for cold-start products. Extensive offline experiments show that DAEMON outperforms state-of-the-art baselines by 30-160% in terms of HitRate and MRR for the node recommendation task. ",
    "url": "https://arxiv.org/abs/2211.11583",
    "authors": [
      "Srinivas Virinchi",
      "Anoop Saladi",
      "Abhirup Mondal"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11587",
    "title": "Timely Target Tracking in Cognitive Radar Networks",
    "abstract": "We consider a scenario where a fusion center must decide which updates to receive during each update period in a communication-limited cognitive radar network. When each radar node in the network only is able to obtain noisy state measurements for a subset of the targets, the fusion center may not receive updates on every target during each update period. The solution for the selection problem at the fusion center is not well suited for sequential learning frameworks. We derive an Age of Information-inspired track sensitive metric to inform node selection in such a network and compare it against less-informed techniques. ",
    "url": "https://arxiv.org/abs/2211.11587",
    "authors": [
      "William W. Howard",
      "Charles E. Thornton",
      "R. Michael Buehrer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.11589",
    "title": "Conjugate Product Graphs for Globally Optimal 2D-3D Shape Matching",
    "abstract": "We consider the problem of finding a continuous and non-rigid matching between a 2D contour and a 3D mesh. While such problems can be solved to global optimality by finding a shortest path in the product graph between both shapes, existing solutions heavily rely on unrealistic prior assumptions to avoid degenerate solutions (e.g. knowledge to which region of the 3D shape each point of the 2D contour is matched). To address this, we propose a novel 2D-3D shape matching formalism based on the conjugate product graph between the 2D contour and the 3D shape. Doing so allows us for the first time to consider higher-order costs, i.e. defined for edge chains, as opposed to costs defined for single edges. This offers substantially more flexibility, which we utilise to incorporate a local rigidity prior. By doing so, we effectively circumvent degenerate solutions and thereby obtain smoother and more realistic matchings, even when using only a one-dimensional feature descriptor. Overall, our method finds globally optimal and continuous 2D-3D matchings, has the same asymptotic complexity as previous solutions, produces state-of-the-art results for shape matching and is even capable of matching partial shapes. ",
    "url": "https://arxiv.org/abs/2211.11589",
    "authors": [
      "Paul Roetzer",
      "Zorah L\u00e4hner",
      "Florian Bernard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11596",
    "title": "Forecasting Unobserved Node States with spatio-temporal Graph Neural  Networks",
    "abstract": "Forecasting future states of sensors is key to solving tasks like weather prediction, route planning, and many others when dealing with networks of sensors. But complete spatial coverage of sensors is generally unavailable and would practically be infeasible due to limitations in budget and other resources during deployment and maintenance. Currently existing approaches using machine learning are limited to the spatial locations where data was observed, causing limitations to downstream tasks. Inspired by the recent surge of Graph Neural Networks for spatio-temporal data processing, we investigate whether these can also forecast the state of locations with no sensors available. For this purpose, we develop a framework, named Forecasting Unobserved Node States (FUNS), that allows forecasting the state at entirely unobserved locations based on spatio-temporal correlations and the graph inductive bias. FUNS serves as a blueprint for optimizing models only on observed data and demonstrates good generalization capabilities for predicting the state at entirely unobserved locations during the testing stage. Our framework can be combined with any spatio-temporal Graph Neural Network, that exploits spatio-temporal correlations with surrounding observed locations by using the network's graph structure. Our employed model builds on a previous model by also allowing us to exploit prior knowledge about locations of interest, e.g. the road type. Our empirical evaluation of both simulated and real-world datasets demonstrates that Graph Neural Networks are well-suited for this task. ",
    "url": "https://arxiv.org/abs/2211.11596",
    "authors": [
      "Andreas Roth",
      "Thomas Liebig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11608",
    "title": "Immersion and Invariance-based Coding for Privacy in Remote Anomaly  Detection",
    "abstract": "We present a framework for the design of coding mechanisms that allow remotely operating anomaly detectors in a privacy-preserving manner. We consider the following problem setup. A remote station seeks to identify anomalies based on system input-output signals transmitted over communication networks. However, it is not desired to disclose true data of the system operation as it can be used to infer private information. To prevent adversaries from eavesdropping on the network or at the remote station itself to access private data, we propose a privacy-preserving coding scheme to distort signals before transmission. As a next step, we design a new anomaly detector that runs on distorted signals and produces distorted diagnostics signals, and a decoding scheme that allows extracting true diagnostics data from distorted signals without error. The proposed scheme is built on the synergy of matrix encryption and system Immersion and Invariance (I&I) tools from control theory. The idea is to immerse the anomaly detector into a higher-dimensional system (the so-called target system). The dynamics of the target system is designed such that: the trajectories of the original anomaly detector are immersed/embedded in its trajectories, it works on randomly encoded input-output signals, and produces an encoded version of the original anomaly detector alarm signals, which are decoded to extract the original alarm at the user side. We show that the proposed privacy-preserving scheme provides the same anomaly detection performance as standard Kalman filter-based chi-squared anomaly detectors while revealing no information about system data. ",
    "url": "https://arxiv.org/abs/2211.11608",
    "authors": [
      "Haleh Hayati",
      "Nathan van de Wouw",
      "Carlos Murguia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.11610",
    "title": "Tensor4D : Efficient Neural 4D Decomposition for High-fidelity Dynamic  Reconstruction and Rendering",
    "abstract": "We present Tensor4D, an efficient yet effective approach to dynamic scene modeling. The key of our solution is an efficient 4D tensor decomposition method so that the dynamic scene can be directly represented as a 4D spatio-temporal tensor. To tackle the accompanying memory issue, we decompose the 4D tensor hierarchically by projecting it first into three time-aware volumes and then nine compact feature planes. In this way, spatial information over time can be simultaneously captured in a compact and memory-efficient manner. When applying Tensor4D for dynamic scene reconstruction and rendering, we further factorize the 4D fields to different scales in the sense that structural motions and dynamic detailed changes can be learned from coarse to fine. The effectiveness of our method is validated on both synthetic and real-world scenes. Extensive experiments show that our method is able to achieve high-quality dynamic reconstruction and rendering from sparse-view camera rigs or even a monocular camera. The code and dataset will be released at https://liuyebin.com/tensor4d/tensor4d.html. ",
    "url": "https://arxiv.org/abs/2211.11610",
    "authors": [
      "Ruizhi Shao",
      "Zerong Zheng",
      "Hanzhang Tu",
      "Boning Liu",
      "Hongwen Zhang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11612",
    "title": "Plug and Play Active Learning for Object Detection",
    "abstract": "Annotating data for supervised learning is expensive and tedious, and we want to do as little of it as possible. To make the most of a given \"annotation budget\" we can turn to active learning (AL) which aims to identify the most informative samples in a dataset for annotation. Active learning algorithms are typically uncertainty-based or diversity-based. Both have seen success in image classification, but fall short when it comes to object detection. We hypothesise that this is because: (1) it is difficult to quantify uncertainty for object detection as it consists of both localisation and classification, where some classes are harder to localise, and others are harder to classify; (2) it is difficult to measure similarities for diversity-based AL when images contain different numbers of objects. We propose a two-stage active learning algorithm Plug and Play Active Learning (PPAL) that overcomes these difficulties. It consists of (1) Difficulty Calibrated Uncertainty Sampling, in which we used a category-wise difficulty coefficient that takes both classification and localisation into account to re-weight object uncertainties for uncertainty-based sampling; (2) Category Conditioned Matching Similarity to compute the similarities of multi-instance images as ensembles of their instance similarities. PPAL is highly generalisable because it makes no change to model architectures or detector training pipelines. We benchmark PPAL on the MS-COCO and Pascal VOC datasets using different detector architectures and show that our method outperforms the prior state-of-the-art. Code is available at https://github.com/ChenhongyiYang/PPAL ",
    "url": "https://arxiv.org/abs/2211.11612",
    "authors": [
      "Chenhongyi Yang",
      "Lichao Huang",
      "Elliot J. Crowley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11616",
    "title": "Learning Heterogeneous Agent Cooperation via Multiagent League Training",
    "abstract": "Many multiagent systems in the real world include multiple types of agents with different abilities and functionality. Such heterogeneous multiagent systems have significant practical advantages. However, they also come with challenges compared with homogeneous systems for multiagent reinforcement learning, such as the non-stationary problem and the policy version iteration issue. This work proposes a general-purpose reinforcement learning algorithm named as Heterogeneous League Training (HLT) to address heterogeneous multiagent problems. HLT keeps track of a pool of policies that agents have explored during training, gathering a league of heterogeneous policies to facilitate future policy optimization. Moreover, a hyper-network is introduced to increase the diversity of agent behaviors when collaborating with teammates having different levels of cooperation skills. We use heterogeneous benchmark tasks to demonstrate that (1) HLT promotes the success rate in cooperative heterogeneous tasks; (2) HLT is an effective approach to solving the policy version iteration problem; (3) HLT provides a practical way to assess the difficulty of learning each role in a heterogeneous team. ",
    "url": "https://arxiv.org/abs/2211.11616",
    "authors": [
      "Qingxu Fu",
      "Xiaolin Ai",
      "Jianqiang Yi",
      "Tenghai Qiu",
      "Wanmai Yuan",
      "Zhiqiang Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11638",
    "title": "Normalizing Flow with Variational Latent Representation",
    "abstract": "Normalizing flow (NF) has gained popularity over traditional maximum likelihood based methods due to its strong capability to model complex data distributions. However, the standard approach, which maps the observed data to a normal distribution, has difficulty in handling data distributions with multiple relatively isolated modes. To overcome this issue, we propose a new framework based on variational latent representation to improve the practical performance of NF. The idea is to replace the standard normal latent variable with a more general latent representation, jointly learned via Variational Bayes. For example, by taking the latent representation as a discrete sequence, our framework can learn a Transformer model that generates the latent sequence and an NF model that generates continuous data distribution conditioned on the sequence. The resulting method is significantly more powerful than the standard normalization flow approach for generating data distributions with multiple modes. Extensive experiments have shown the advantages of NF with variational latent representation. ",
    "url": "https://arxiv.org/abs/2211.11638",
    "authors": [
      "Hanze Dong",
      "Shizhe Diao",
      "Weizhong Zhang",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.11646",
    "title": "NeRF-RPN: A general framework for object detection in NeRFs",
    "abstract": "This paper presents the first significant object detection framework, NeRF-RPN, which directly operates on NeRF. Given a pre-trained NeRF model, NeRF-RPN aims to detect all bounding boxes of objects in a scene. By exploiting a novel voxel representation that incorporates multi-scale 3D neural volumetric features, we demonstrate it is possible to regress the 3D bounding boxes of objects in NeRF directly without rendering the NeRF at any viewpoint. NeRF-RPN is a general framework and can be applied to detect objects without class labels. We experimented the NeRF-RPN with various backbone architectures, RPN head designs and loss functions. All of them can be trained in an end-to-end manner to estimate high quality 3D bounding boxes. To facilitate future research in object detection for NeRF, we built a new benchmark dataset which consists of both synthetic and real-world data with careful labeling and clean up. Please watch the \\href{https://youtu.be/M8_4Ih1CJjE}{video} for visualizing the 3D region proposals by our NeRF-RPN. Code and dataset will be made available. ",
    "url": "https://arxiv.org/abs/2211.11646",
    "authors": [
      "Benran Hu",
      "Junkai Huang",
      "Yichen Liu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11647",
    "title": "Benchmarking Edge Computing Devices for Grape Bunches and Trunks  Detection using Accelerated Object Detection Single Shot MultiBox Deep  Learning Models",
    "abstract": "Purpose: Visual perception enables robots to perceive the environment. Visual data is processed using computer vision algorithms that are usually time-expensive and require powerful devices to process the visual data in real-time, which is unfeasible for open-field robots with limited energy. This work benchmarks the performance of different heterogeneous platforms for object detection in real-time. This research benchmarks three architectures: embedded GPU -- Graphical Processing Units (such as NVIDIA Jetson Nano 2 GB and 4 GB, and NVIDIA Jetson TX2), TPU -- Tensor Processing Unit (such as Coral Dev Board TPU), and DPU -- Deep Learning Processor Unit (such as in AMD-Xilinx ZCU104 Development Board, and AMD-Xilinx Kria KV260 Starter Kit). Method: The authors used the RetinaNet ResNet-50 fine-tuned using the natural VineSet dataset. After the trained model was converted and compiled for target-specific hardware formats to improve the execution efficiency. Conclusions and Results: The platforms were assessed in terms of performance of the evaluation metrics and efficiency (time of inference). Graphical Processing Units (GPUs) were the slowest devices, running at 3 FPS to 5 FPS, and Field Programmable Gate Arrays (FPGAs) were the fastest devices, running at 14 FPS to 25 FPS. The efficiency of the Tensor Processing Unit (TPU) is irrelevant and similar to NVIDIA Jetson TX2. TPU and GPU are the most power-efficient, consuming about 5W. The performance differences, in the evaluation metrics, across devices are irrelevant and have an F1 of about 70 % and mean Average Precision (mAP) of about 60 %. ",
    "url": "https://arxiv.org/abs/2211.11647",
    "authors": [
      "Sandro Costa Magalh\u00e3es",
      "Filipe Neves Santos",
      "Pedro Machado",
      "Ant\u00f3nio Paulo Moreira",
      "Jorge Dias"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.11649",
    "title": "Implicit Training of Energy Model for Structure Prediction",
    "abstract": "Most deep learning research has focused on developing new model and training procedures. On the other hand the training objective has usually been restricted to combinations of standard losses. When the objective aligns well with the evaluation metric, this is not a major issue. However when dealing with complex structured outputs, the ideal objective can be hard to optimize and the efficacy of usual objectives as a proxy for the true objective can be questionable. In this work, we argue that the existing inference network based structure prediction methods ( Tu and Gimpel 2018; Tu, Pang, and Gimpel 2020) are indirectly learning to optimize a dynamic loss objective parameterized by the energy model. We then explore using implicit-gradient based technique to learn the corresponding dynamic objectives. Our experiments show that implicitly learning a dynamic loss landscape is an effective method for improving model performance in structure prediction. ",
    "url": "https://arxiv.org/abs/2211.11649",
    "authors": [
      "Shiv Shankar",
      "Vihari Piratla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11665",
    "title": "Representational dissimilarity metric spaces for stochastic neural  networks",
    "abstract": "Quantifying similarity between neural representations -- e.g. hidden layer activation vectors -- is a perennial problem in deep learning and neuroscience research. Existing methods compare deterministic responses (e.g. artificial networks that lack stochastic layers) or averaged responses (e.g., trial-averaged firing rates in biological data). However, these measures of deterministic representational similarity ignore the scale and geometric structure of noise, both of which play important roles in neural computation. To rectify this, we generalize previously proposed shape metrics (Williams et al. 2021) to quantify differences in stochastic representations. These new distances satisfy the triangle inequality, and thus can be used as a rigorous basis for many supervised and unsupervised analyses. Leveraging this novel framework, we find that the stochastic geometries of neurobiological representations of oriented visual gratings and naturalistic scenes respectively resemble untrained and trained deep network representations. Further, we are able to more accurately predict certain network attributes (e.g. training hyperparameters) from its position in stochastic (versus deterministic) shape space. ",
    "url": "https://arxiv.org/abs/2211.11665",
    "authors": [
      "Lyndon R. Duong",
      "Jingyang Zhou",
      "Josue Nassar",
      "Jules Berman",
      "Jeroen Olieslagers",
      "Alex H. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.11695",
    "title": "Disentangled Representation Learning",
    "abstract": "Disentangled Representation Learning (DRL) aims to learn a model capable of identifying and disentangling the underlying factors hidden in the observable data in representation form. The process of separating underlying factors of variation into variables with semantic meaning benefits in learning explainable representations of data, which imitates the meaningful understanding process of humans when observing an object or relation. As a general learning strategy, DRL has demonstrated its power in improving the model explainability, controlability, robustness, as well as generalization capacity in a wide range of scenarios such as computer vision, natural language processing, data mining etc. In this article, we comprehensively review DRL from various aspects including motivations, definitions, methodologies, evaluations, applications and model designs. We discuss works on DRL based on two well-recognized definitions, i.e., Intuitive Definition and Group Theory Definition. We further categorize the methodologies for DRL into four groups, i.e., Traditional Statistical Approaches, Variational Auto-encoder Based Approaches, Generative Adversarial Networks Based Approaches, Hierarchical Approaches and Other Approaches. We also analyze principles to design different DRL models that may benefit different tasks in practical applications. Finally, we point out challenges in DRL as well as potential research directions deserving future investigations. We believe this work may provide insights for promoting the DRL research in the community. ",
    "url": "https://arxiv.org/abs/2211.11695",
    "authors": [
      "Xin Wang",
      "Hong Chen",
      "Si'ao Tang",
      "Zihao Wu",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11699",
    "title": "Explaining Random Forests using Bipolar Argumentation and Markov  Networks (Technical Report)",
    "abstract": "Random forests are decision tree ensembles that can be used to solve a variety of machine learning problems. However, as the number of trees and their individual size can be large, their decision making process is often incomprehensible. In order to reason about the decision process, we propose representing it as an argumentation problem. We generalize sufficient and necessary argumentative explanations using a Markov network encoding, discuss the relevance of these explanations and establish relationships to families of abductive explanations from the literature. As the complexity of the explanation problems is high, we discuss a probabilistic approximation algorithm and present first experimental results. ",
    "url": "https://arxiv.org/abs/2211.11699",
    "authors": [
      "Nico Potyka",
      "Xiang Yin",
      "Francesca Toni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2211.11704",
    "title": "ESLAM: Efficient Dense SLAM System Based on Hybrid Representation of  Signed Distance Fields",
    "abstract": "We present ESLAM, an efficient implicit neural representation method for Simultaneous Localization and Mapping (SLAM). ESLAM reads RGB-D frames with unknown camera poses in a sequential manner and incrementally reconstructs the scene representation while estimating the current camera position in the scene. We incorporate the latest advances in Neural Radiance Fields (NeRF) into a SLAM system, resulting in an efficient and accurate dense visual SLAM method. Our scene representation consists of multi-scale axis-aligned perpendicular feature planes and shallow decoders that, for each point in the continuous space, decode the interpolated features into Truncated Signed Distance Field (TSDF) and RGB values. Our extensive experiments on two standard and recent datasets, Replica and ScanNet, show that ESLAM improves the accuracy of 3D reconstruction and camera localization of state-of-the-art dense visual SLAM methods by more than 50%, while it runs up to $\\times$10 faster and does not require any pre-training. ",
    "url": "https://arxiv.org/abs/2211.11704",
    "authors": [
      "Mohammad Mahdi Johari",
      "Camilla Carta",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11711",
    "title": "CLAWSAT: Towards Both Robust and Accurate Code Models",
    "abstract": "We integrate contrastive learning (CL) with adversarial learning to co-optimize the robustness and accuracy of code models. Different from existing works, we show that code obfuscation, a standard code transformation operation, provides novel means to generate complementary `views' of a code that enable us to achieve both robust and accurate code models. To the best of our knowledge, this is the first systematic study to explore and exploit the robustness and accuracy benefits of (multi-view) code obfuscations in code models. Specifically, we first adopt adversarial codes as robustness-promoting views in CL at the self-supervised pre-training phase. This yields improved robustness and transferability for downstream tasks. Next, at the supervised fine-tuning stage, we show that adversarial training with a proper temporally-staggered schedule of adversarial code generation can further improve robustness and accuracy of the pre-trained code model. Built on the above two modules, we develop CLAWSAT, a novel self-supervised learning (SSL) framework for code by integrating $\\underline{\\textrm{CL}}$ with $\\underline{\\textrm{a}}$dversarial vie$\\underline{\\textrm{w}}$s (CLAW) with $\\underline{\\textrm{s}}$taggered $\\underline{\\textrm{a}}$dversarial $\\underline{\\textrm{t}}$raining (SAT). On evaluating three downstream tasks across Python and Java, we show that CLAWSAT consistently yields the best robustness and accuracy ($\\textit{e.g.}$ 11$\\%$ in robustness and 6$\\%$ in accuracy on the code summarization task in Python). We additionally demonstrate the effectiveness of adversarial learning in CLAW by analyzing the characteristics of the loss landscape and interpretability of the pre-trained models. ",
    "url": "https://arxiv.org/abs/2211.11711",
    "authors": [
      "Jinghan Jia",
      "Shashank Srikant",
      "Tamara Mitrovska",
      "Chuang Gan",
      "Shiyu Chang",
      "Sijia Liu",
      "Una-May O'Reilly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.11724",
    "title": "Legal and Political Stance Detection of SCOTUS Language",
    "abstract": "We analyze publicly available US Supreme Court documents using automated stance detection. In the first phase of our work, we investigate the extent to which the Court's public-facing language is political. We propose and calculate two distinct ideology metrics of SCOTUS justices using oral argument transcripts. We then compare these language-based metrics to existing social scientific measures of the ideology of the Supreme Court and the public. Through this cross-disciplinary analysis, we find that justices who are more responsive to public opinion tend to express their ideology during oral arguments. This observation provides a new kind of evidence in favor of the attitudinal change hypothesis of Supreme Court justice behavior. As a natural extension of this political stance detection, we propose the more specialized task of legal stance detection with our new dataset SC-stance, which matches written opinions to legal questions. We find competitive performance on this dataset using language adapters trained on legal documents. ",
    "url": "https://arxiv.org/abs/2211.11724",
    "authors": [
      "Noah Bergam",
      "Emily Allaway",
      "Kathleen McKeown"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.11736",
    "title": "Robotic Skill Acquisition via Instruction Augmentation with  Vision-Language Models",
    "abstract": "In recent years, much progress has been made in learning robotic manipulation policies that follow natural language instructions. Such methods typically learn from corpora of robot-language data that was either collected with specific tasks in mind or expensively re-labelled by humans with rich language descriptions in hindsight. Recently, large-scale pretrained vision-language models (VLMs) like CLIP or ViLD have been applied to robotics for learning representations and scene descriptors. Can these pretrained models serve as automatic labelers for robot data, effectively importing Internet-scale knowledge into existing datasets to make them useful even for tasks that are not reflected in their ground truth annotations? To accomplish this, we introduce Data-driven Instruction Augmentation for Language-conditioned control (DIAL): we utilize semi-supervised language labels leveraging the semantic understanding of CLIP to propagate knowledge onto large datasets of unlabelled demonstration data and then train language-conditioned policies on the augmented datasets. This method enables cheaper acquisition of useful language descriptions compared to expensive human labels, allowing for more efficient label coverage of large-scale datasets. We apply DIAL to a challenging real-world robotic manipulation domain where 96.5% of the 80,000 demonstrations do not contain crowd-sourced language annotations. DIAL enables imitation learning policies to acquire new capabilities and generalize to 60 novel instructions unseen in the original dataset. ",
    "url": "https://arxiv.org/abs/2211.11736",
    "authors": [
      "Ted Xiao",
      "Harris Chan",
      "Pierre Sermanet",
      "Ayzaan Wahid",
      "Anthony Brohan",
      "Karol Hausman",
      "Sergey Levine",
      "Jonathan Tompson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11738",
    "title": "SPARF: Neural Radiance Fields from Sparse and Noisy Poses",
    "abstract": "Neural Radiance Field (NeRF) has recently emerged as a powerful representation to synthesize photorealistic novel views. While showing impressive performance, it relies on the availability of dense input views with highly accurate camera poses, thus limiting its application in real-world scenarios. In this work, we introduce Sparse Pose Adjusting Radiance Field (SPARF), to address the challenge of novel-view synthesis given only few wide-baseline input images (as low as 3) with noisy camera poses. Our approach exploits multi-view geometry constraints in order to jointly learn the NeRF and refine the camera poses. By relying on pixel matches extracted between the input views, our multi-view correspondence objective enforces the optimized scene and camera poses to converge to a global and geometrically accurate solution. Our depth consistency loss further encourages the reconstructed scene to be consistent from any viewpoint. Our approach sets a new state of the art in the sparse-view regime on multiple challenging datasets. ",
    "url": "https://arxiv.org/abs/2211.11738",
    "authors": [
      "Prune Truong",
      "Marie-Julie Rakotosaona",
      "Fabian Manhardt",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10442",
    "title": "Deep learning methods for drug response prediction in cancer:  predominant and emerging trends",
    "abstract": "Cancer claims millions of lives yearly worldwide. While many therapies have been made available in recent years, by in large cancer remains unsolved. Exploiting computational predictive models to study and treat cancer holds great promise in improving drug development and personalized design of treatment plans, ultimately suppressing tumors, alleviating suffering, and prolonging lives of patients. A wave of recent papers demonstrates promising results in predicting cancer response to drug treatments while utilizing deep learning methods. These papers investigate diverse data representations, neural network architectures, learning methodologies, and evaluations schemes. However, deciphering promising predominant and emerging trends is difficult due to the variety of explored methods and lack of standardized framework for comparing drug response prediction models. To obtain a comprehensive landscape of deep learning methods, we conducted an extensive search and analysis of deep learning models that predict the response to single drug treatments. A total of 60 deep learning-based models have been curated and summary plots were generated. Based on the analysis, observable patterns and prevalence of methods have been revealed. This review allows to better understand the current state of the field and identify major challenges and promising solution paths. ",
    "url": "https://arxiv.org/abs/2211.10442",
    "authors": [
      "Alexander Partin",
      "Thomas S. Brettin",
      "Yitan Zhu",
      "Oleksandr Narykov",
      "Austin Clyde",
      "Jamie Overbeek",
      "Rick L. Stevens"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10444",
    "title": "Neural Fields for Fast and Scalable Interpolation of Geophysical Ocean  Variables",
    "abstract": "Optimal Interpolation (OI) is a widely used, highly trusted algorithm for interpolation and reconstruction problems in geosciences. With the influx of more satellite missions, we have access to more and more observations and it is becoming more pertinent to take advantage of these observations in applications such as forecasting and reanalysis. With the increase in the volume of available data, scalability remains an issue for standard OI and it prevents many practitioners from effectively and efficiently taking advantage of these large sums of data to learn the model hyperparameters. In this work, we leverage recent advances in Neural Fields (NerFs) as an alternative to the OI framework where we show how they can be easily applied to standard reconstruction problems in physical oceanography. We illustrate the relevance of NerFs for gap-filling of sparse measurements of sea surface height (SSH) via satellite altimetry and demonstrate how NerFs are scalable with comparable results to the standard OI. We find that NerFs are a practical set of methods that can be readily applied to geoscience interpolation problems and we anticipate a wider adoption in the future. ",
    "url": "https://arxiv.org/abs/2211.10444",
    "authors": [
      "J. Emmanuel Johnson",
      "Redouane Lguensat",
      "Ronan Fablet",
      "Emmanuel Cosme",
      "Julien Le Sommer"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10475",
    "title": "Turning Silver into Gold: Domain Adaptation with Noisy Labels for  Wearable Cardio-Respiratory Fitness Prediction",
    "abstract": "Deep learning models have shown great promise in various healthcare applications. However, most models are developed and validated on small-scale datasets, as collecting high-quality (gold-standard) labels for health applications is often costly and time-consuming. As a result, these models may suffer from overfitting and not generalize well to unseen data. At the same time, an extensive amount of data with imprecise labels (silver-standard) is starting to be generally available, as collected from inexpensive wearables like accelerometers and electrocardiography sensors. These currently underutilized datasets and labels can be leveraged to produce more accurate clinical models. In this work, we propose UDAMA, a novel model with two key components: Unsupervised Domain Adaptation and Multi-discriminator Adversarial training, which leverage noisy data from source domain (the silver-standard dataset) to improve gold-standard modeling. We validate our framework on the challenging task of predicting lab-measured maximal oxygen consumption (VO$_{2}$max), the benchmark metric of cardio-respiratory fitness, using free-living wearable sensor data from two cohort studies as inputs. Our experiments show that the proposed framework achieves the best performance of corr = 0.665 $\\pm$ 0.04, paving the way for accurate fitness estimation at scale. ",
    "url": "https://arxiv.org/abs/2211.10475",
    "authors": [
      "Yu Wu",
      "Dimitris Spathis",
      "Hong Jia",
      "Ignacio Perez-Pozuelo",
      "Tomas I. Gonzales",
      "Soren Brage",
      "Nicholas Wareham",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10508",
    "title": "Distributionally Robust Survival Analysis: A Novel Fairness Loss Without  Demographics",
    "abstract": "We propose a general approach for training survival analysis models that minimizes a worst-case error across all subpopulations that are large enough (occurring with at least a user-specified minimum probability). This approach uses a training loss function that does not know any demographic information to treat as sensitive. Despite this, we demonstrate that our proposed approach often scores better on recently established fairness metrics (without a significant drop in prediction accuracy) compared to various baselines, including ones which directly use sensitive demographic information in their training loss. Our code is available at: https://github.com/discovershu/DRO_COX ",
    "url": "https://arxiv.org/abs/2211.10508",
    "authors": [
      "Shu Hu",
      "George H. Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10565",
    "title": "Filterbank Learning for Small-Footprint Keyword Spotting Robust to Noise",
    "abstract": "In the context of keyword spotting (KWS), the replacement of handcrafted speech features by learnable features has not yielded superior KWS performance. In this study, we demonstrate that filterbank learning outperforms handcrafted speech features for KWS whenever the number of filterbank channels is severely decreased. Reducing the number of channels might yield certain KWS performance drop, but also a substantial energy consumption reduction, which is key when deploying common always-on KWS on low-resource devices. Experimental results on a noisy version of the Google Speech Commands Dataset show that filterbank learning adapts to noise characteristics to provide a higher degree of robustness to noise, especially when dropout is integrated. Thus, switching from typically used 40-channel log-Mel features to 8-channel learned features leads to a relative KWS accuracy loss of only 3.5% while simultaneously achieving a 6.3x energy consumption reduction. ",
    "url": "https://arxiv.org/abs/2211.10565",
    "authors": [
      "Iv\u00e1n L\u00f3pez-Espejo",
      "Ram C. M. C. Shekar",
      "Zheng-Hua Tan",
      "Jesper Jensen",
      "John H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.10690",
    "title": "convoHER2: A Deep Neural Network for Multi-Stage Classification of HER2  Breast Cancer",
    "abstract": "Generally, human epidermal growth factor 2 (HER2) breast cancer is more aggressive than other kinds of breast cancer. Currently, HER2 breast cancer is detected using expensive medical tests are most expensive. Therefore, the aim of this study was to develop a computational model named convoHER2 for detecting HER2 breast cancer with image data using convolution neural network (CNN). Hematoxylin and eosin (H&E) and immunohistochemical (IHC) stained images has been used as raw data from the Bayesian information criterion (BIC) benchmark dataset. This dataset consists of 4873 images of H&E and IHC. Among all images of the dataset, 3896 and 977 images are applied to train and test the convoHER2 model, respectively. As all the images are in high resolution, we resize them so that we can feed them in our convoHER2 model. The cancerous samples images are classified into four classes based on the stage of the cancer (0+, 1+, 2+, 3+). The convoHER2 model is able to detect HER2 cancer and its grade with accuracy 85% and 88% using H&E images and IHC images, respectively. The outcomes of this study determined that the HER2 cancer detecting rates of the convoHER2 model are much enough to provide better diagnosis to the patient for recovering their HER2 breast cancer in future. ",
    "url": "https://arxiv.org/abs/2211.10690",
    "authors": [
      "M. F. Mridha",
      "Md. Kishor Morol",
      "Md. Asraf Ali",
      "Md Sakib Hossain Shovon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10748",
    "title": "Delay-aware Backpressure Routing Using Graph Neural Networks",
    "abstract": "We propose a throughput-optimal biased backpressure (BP) algorithm for routing, where the bias is learned through a graph neural network that seeks to minimize end-to-end delay. Classical BP routing provides a simple yet powerful distributed solution for resource allocation in wireless multi-hop networks but has poor delay performance. A low-cost approach to improve this delay performance is to favor shorter paths by incorporating pre-defined biases in the BP computation, such as a bias based on the shortest path (hop) distance to the destination. In this work, we improve upon the widely-used metric of hop distance (and its variants) for the shortest path bias by introducing a bias based on the link duty cycle, which we predict using a graph convolutional neural network. Numerical results show that our approach can improve the delay performance compared to classical BP and existing BP alternatives based on pre-defined bias while being adaptive to interference density. In terms of complexity, our distributed implementation only introduces a one-time overhead (linear in the number of devices in the network) compared to classical BP, and a constant overhead compared to the lowest-complexity existing bias-based BP algorithms. ",
    "url": "https://arxiv.org/abs/2211.10748",
    "authors": [
      "Zhongyuan Zhao",
      "Bojan Radojicic",
      "Gunjan Verma",
      "Ananthram Swami",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10790",
    "title": "Simple and Effective Augmentation Methods for CSI Based Indoor  Localization",
    "abstract": "Indoor localization is a challenging task. There is no robust and almost-universal approach, in contrast to outdoor environments where GPS is dominant. Recently, machine learning (ML) has emerged as the most promising approach for achieving accurate indoor localization, yet its main challenge is the requirement for large datasets to train the neural networks. The data collection procedure is costly and laborious as the procedure requires extensive measurements and labeling processes for different indoor environments. The situation can be improved by Data Augmentation (DA), which is a general framework to enlarge the datasets for ML, making ML systems more robust and increases their generalization capabilities. In this paper, we propose two simple yet surprisingly effective DA algorithms for channel state information (CSI) based indoor localization motivated by physical considerations. We show that the required number of measurements for a given accuracy requirement may be decreased by an order of magnitude. Specifically, we demonstrate the algorithms' effectiveness by experiments conducted with a measured indoor WiFi measurement dataset: as little as 10% of the original dataset size is enough to get the same performance of the original dataset. We also showed that, if we further augment the dataset with proposed techniques we get better test accuracy more than three-fold. ",
    "url": "https://arxiv.org/abs/2211.10790",
    "authors": [
      "Omer Gokalp Serbetci",
      "Ju-Hyung Lee",
      "Daoud Burghal",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10805",
    "title": "On the Pointwise Behavior of Recursive Partitioning and Its Implications  for Heterogeneous Causal Effect Estimation",
    "abstract": "Decision tree learning is increasingly being used for pointwise inference. Important applications include causal heterogenous treatment effects and dynamic policy decisions, as well as conditional quantile regression and design of experiments, where tree estimation and inference is conducted at specific values of the covariates. In this paper, we call into question the use of decision trees (trained by adaptive recursive partitioning) for such purposes by demonstrating that they can fail to achieve polynomial rates of convergence in uniform norm, even with pruning. Instead, the convergence may be poly-logarithmic or, in some important special cases, such as honest regression trees, fail completely. We show that random forests can remedy the situation, turning poor performing trees into nearly optimal procedures, at the cost of losing interpretability and introducing two additional tuning parameters. The two hallmarks of random forests, subsampling and the random feature selection mechanism, are seen to each distinctively contribute to achieving nearly optimal performance for the model class considered. ",
    "url": "https://arxiv.org/abs/2211.10805",
    "authors": [
      "Mattias D. Cattaneo",
      "Jason M. Klusowski",
      "Peter M. Tian"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2211.10965",
    "title": "Persistence of the Omicron variant of SARS-CoV-2 in Australia: The  impact of fluctuating social distancing",
    "abstract": "We modelled emergence and spread of the Omicron variant of SARS-CoV-2 in Australia between December 2021 and June 2022. This pandemic stage exhibited a diverse epidemiological profile with emergence of co-circulating sub-lineages of Omicron, further complicated by differences in social distancing behaviour which varied over time. Our study delineated distinct phases of the Omicron-associated pandemic stage, and retrospectively quantified the adoption of social distancing measures, fluctuating over different time periods in response to the observable incidence dynamics. We also modelled the corresponding disease burden, in terms of hospitalisations, intensive care unit occupancy, and mortality. Supported by good agreement between simulated and actual health data, our study revealed that the nonlinear dynamics observed in the daily incidence and disease burden were determined not only by introduction of sub-lineages of Omicron, but also by the fluctuating adoption of social distancing measures. Our high-resolution model can be used in design and evaluation of public health interventions during future crises. ",
    "url": "https://arxiv.org/abs/2211.10965",
    "authors": [
      "Sheryl L. Chang",
      "Quang Dang Nguyen",
      "Alexandra Martiniuk",
      "Vitali Sintchenko",
      "Tania C. Sorrell",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2211.11025",
    "title": "Self-supervised iRegNet for the Registration of Longitudinal Brain MRI  of Diffuse Glioma Patients",
    "abstract": "Reliable and accurate registration of patient-specific brain magnetic resonance imaging (MRI) scans containing pathologies is challenging due to tissue appearance changes. This paper describes our contribution to the Registration of the longitudinal brain MRI task of the Brain Tumor Sequence Registration Challenge 2022 (BraTS-Reg 2022). We developed an enhanced unsupervised learning-based method that extends the iRegNet. In particular, incorporating an unsupervised learning-based paradigm as well as several minor modifications to the network pipeline, allows the enhanced iRegNet method to achieve respectable results. Experimental findings show that the enhanced self-supervised model is able to improve the initial mean median registration absolute error (MAE) from 8.20 (7.62) mm to the lowest value of 3.51 (3.50) for the training set while achieving an MAE of 2.93 (1.63) mm for the validation set. Additional qualitative validation of this study was conducted through overlaying pre-post MRI pairs before and after the de-formable registration. The proposed method scored 5th place during the testing phase of the MICCAI BraTS-Reg 2022 challenge. The docker image to reproduce our BraTS-Reg submission results will be publicly available. ",
    "url": "https://arxiv.org/abs/2211.11025",
    "authors": [
      "Ramy A. Zeineldin",
      "Mohamed E. Karar",
      "Franziska Mathis-Ullrich",
      "Oliver Burgert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11043",
    "title": "Revealing Robust Oil and Gas Company Macro-Strategies using Deep  Multi-Agent Reinforcement Learning",
    "abstract": "The energy transition potentially poses an existential risk for major international oil companies (IOCs) if they fail to adapt to low-carbon business models. Projections of energy futures, however, are met with diverging assumptions on its scale and pace, causing disagreement among IOC decision-makers and their stakeholders over what the business model of an incumbent fossil fuel company should be. In this work, we used deep multi-agent reinforcement learning to solve an energy systems wargame wherein players simulate IOC decision-making, including hydrocarbon and low-carbon investments decisions, dividend policies, and capital structure measures, through an uncertain energy transition to explore critical and non-linear governance questions, from leveraged transitions to reserve replacements. Adversarial play facilitated by state-of-the-art algorithms revealed decision-making strategies robust to energy transition uncertainty and against multiple IOCs. In all games, robust strategies emerged in the form of low-carbon business models as a result of early transition-oriented movement. IOCs adopting such strategies outperformed business-as-usual and delayed transition strategies regardless of hydrocarbon demand projections. In addition to maximizing value, these strategies benefit greater society by contributing substantial amounts of capital necessary to accelerate the global low-carbon energy transition. Our findings point towards the need for lenders and investors to effectively mobilize transition-oriented finance and engage with IOCs to ensure responsible reallocation of capital towards low-carbon business models that would enable the emergence of fossil fuel incumbents as future low-carbon leaders. ",
    "url": "https://arxiv.org/abs/2211.11043",
    "authors": [
      "Dylan Radovic",
      "Lucas Kruitwagen",
      "Christian Schroeder de Witt",
      "Ben Caldecott",
      "Shane Tomlinson",
      "Mark Workman"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11058",
    "title": "Convolutional Filtering on Sampled Manifolds",
    "abstract": "The increasing availability of geometric data has motivated the need for information processing over non-Euclidean domains modeled as manifolds. The building block for information processing architectures with desirable theoretical properties such as invariance and stability is convolutional filtering. Manifold convolutional filters are defined from the manifold diffusion sequence, constructed by successive applications of the Laplace-Beltrami operator to manifold signals. However, the continuous manifold model can only be accessed by sampling discrete points and building an approximate graph model from the sampled manifold. Effective linear information processing on the manifold requires quantifying the error incurred when approximating manifold convolutions with graph convolutions. In this paper, we derive a non-asymptotic error bound for this approximation, showing that convolutional filtering on the sampled manifold converges to continuous manifold filtering. Our findings are further demonstrated empirically on a problem of navigation control. ",
    "url": "https://arxiv.org/abs/2211.11058",
    "authors": [
      "Zhiyang Wang",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11060",
    "title": "Simultaneously Learning Robust Audio Embeddings and balanced Hash codes  for Query-by-Example",
    "abstract": "Audio fingerprinting systems must efficiently and robustly identify query snippets in an extensive database. To this end, state-of-the-art systems use deep learning to generate compact audio fingerprints. These systems deploy indexing methods, which quantize fingerprints to hash codes in an unsupervised manner to expedite the search. However, these methods generate imbalanced hash codes, leading to their suboptimal performance. Therefore, we propose a self-supervised learning framework to compute fingerprints and balanced hash codes in an end-to-end manner to achieve both fast and accurate retrieval performance. We model hash codes as a balanced clustering process, which we regard as an instance of the optimal transport problem. Experimental results indicate that the proposed approach improves retrieval efficiency while preserving high accuracy, particularly at high distortion levels, compared to the competing methods. Moreover, our system is efficient and scalable in computational load and memory storage. ",
    "url": "https://arxiv.org/abs/2211.11060",
    "authors": [
      "Anup Singh",
      "Kris Demuynck",
      "Vipul Arora"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.11144",
    "title": "Coarse-Super-Resolution-Fine Network (CoSF-Net): A Unified End-to-End  Neural Network for 4D-MRI with Simultaneous Motion Estimation and  Super-Resolution",
    "abstract": "Four-dimensional magnetic resonance imaging (4D-MRI) is an emerging technique for tumor motion management in image-guided radiation therapy (IGRT). However, current 4D-MRI suffers from low spatial resolution and strong motion artifacts owing to the long acquisition time and patients' respiratory variations; these limitations, if not managed properly, can adversely affect treatment planning and delivery in IGRT. Herein, we developed a novel deep learning framework called the coarse-super-resolution-fine network (CoSF-Net) to achieve simultaneous motion estimation and super-resolution in a unified model. We designed CoSF-Net by fully excavating the inherent properties of 4D-MRI, with consideration of limited and imperfectly matched training datasets. We conducted extensive experiments on multiple real patient datasets to verify the feasibility and robustness of the developed network. Compared with existing networks and three state-of-the-art conventional algorithms, CoSF-Net not only accurately estimated the deformable vector fields between the respiratory phases of 4D-MRI but also simultaneously improved the spatial resolution of 4D-MRI with enhanced anatomic features, yielding 4D-MR images with high spatiotemporal resolution. ",
    "url": "https://arxiv.org/abs/2211.11144",
    "authors": [
      "Shaohua Zhi",
      "Yinghui Wang",
      "Haonan Xiao",
      "Ti Bai",
      "Hong Ge",
      "Bing Li",
      "Chenyang Liu",
      "Wen Li",
      "Tian Li",
      "Jing Cai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11222",
    "title": "Embedding a Differentiable Mel-cepstral Synthesis Filter to a Neural  Speech Synthesis System",
    "abstract": "This paper integrates a classic mel-cepstral synthesis filter into a modern neural speech synthesis system towards end-to-end controllable speech synthesis. Since the mel-cepstral synthesis filter is explicitly embedded in neural waveform models in the proposed system, both voice characteristics and the pitch of synthesized speech are highly controlled via a frequency warping parameter and fundamental frequency, respectively. We implement the mel-cepstral synthesis filter as a differentiable and GPU-friendly module to enable the acoustic and waveform models in the proposed system to be simultaneously optimized in an end-to-end manner. Experiments show that the proposed system improves speech quality from a baseline system maintaining controllability. The core PyTorch modules used in the experiments will be publicly available on GitHub. ",
    "url": "https://arxiv.org/abs/2211.11222",
    "authors": [
      "Takenori Yoshimura",
      "Shinji Takaki",
      "Kazuhiro Nakamura",
      "Keiichiro Oura",
      "Yukiya Hono",
      "Kei Hashimoto",
      "Yoshihiko Nankaku",
      "Keiichi Tokuda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.11275",
    "title": "VATLM: Visual-Audio-Text Pre-Training with Unified Masked Prediction for  Speech Representation Learning",
    "abstract": "Although speech is a simple and effective way for humans to communicate with the outside world, a more realistic speech interaction contains multimodal information, e.g., vision, text. How to design a unified framework to integrate different modal information and leverage different resources (e.g., visual-audio pairs, audio-text pairs, unlabeled speech, and unlabeled text) to facilitate speech representation learning was not well explored. In this paper, we propose a unified cross-modal representation learning framework VATLM (Visual-Audio-Text Language Model). The proposed VATLM employs a unified backbone network to model the modality-independent information and utilizes three simple modality-dependent modules to preprocess visual, speech, and text inputs. In order to integrate these three modalities into one shared semantic space, VATLM is optimized with a masked prediction task of unified tokens, given by our proposed unified tokenizer. We evaluate the pre-trained VATLM on audio-visual related downstream tasks, including audio-visual speech recognition (AVSR), visual speech recognition (VSR) tasks. Results show that the proposed VATLM outperforms previous the state-of-the-art models, such as audio-visual pre-trained AV-HuBERT model, and analysis also demonstrates that VATLM is capable of aligning different modalities into the same space. To facilitate future research, we release the code and pre-trained models at https://aka.ms/vatlm. ",
    "url": "https://arxiv.org/abs/2211.11275",
    "authors": [
      "Qiushi Zhu",
      "Long Zhou",
      "Ziqiang Zhang",
      "Shujie Liu",
      "Binxing Jiao",
      "Jie Zhang",
      "Lirong Dai",
      "Daxin Jiang",
      "Jinyu Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.11336",
    "title": "Orientation recognition and correction of Cardiac MRI with deep neural  network",
    "abstract": "In this paper, the problem of orientation correction in cardiac MRI images is investigated and a framework for orientation recognition via deep neural networks is proposed. For multi-modality MRI, we introduce a transfer learning strategy to transfer our proposed model from single modality to multi-modality. We embed the proposed network into the orientation correction command-line tool, which can implement orientation correction on 2D DICOM and 3D NIFTI images. Our source code, network models and tools are available at https://github.com/Jy-stdio/MSCMR_orient/ ",
    "url": "https://arxiv.org/abs/2211.11336",
    "authors": [
      "Jiyao Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11379",
    "title": "Modelling spatiotemporal turbulent dynamics with the convolutional  autoencoder echo state network",
    "abstract": "The spatiotemporal dynamics of turbulent flows is chaotic and difficult to predict. This makes the design of accurate and stable reduced-order models challenging. The overarching objective of this paper is to propose a nonlinear decomposition of the turbulent state for a reduced-order representation of the dynamics. We divide the turbulent flow into a spatial problem and a temporal problem. First, we compute the latent space, which is the manifold onto which the turbulent dynamics live (i.e., it is a numerical approximation of the turbulent attractor). The latent space is found by a series of nonlinear filtering operations, which are performed by a convolutional autoencoder (CAE). The CAE provides the decomposition in space. Second, we predict the time evolution of the turbulent state in the latent space, which is performed by an echo state network (ESN). The ESN provides the decomposition in time. Third, by assembling the CAE and the ESN, we obtain an autonomous dynamical system: the convolutional autoncoder echo state network (CAE-ESN). This is the reduced-order model of the turbulent flow. We test the CAE-ESN on a two-dimensional flow. We show that, after training, the CAE-ESN (i) finds a latent-space representation of the turbulent flow that has less than 1% of the degrees of freedom than the physical space; (ii) time-accurately and statistically predicts the flow in both quasiperiodic and turbulent regimes; (iii) is robust for different flow regimes (Reynolds numbers); and (iv) takes less than 1% of computational time to predict the turbulent flow than solving the governing equations. This work opens up new possibilities for nonlinear decompositions and reduced-order modelling of turbulent flows from data. ",
    "url": "https://arxiv.org/abs/2211.11379",
    "authors": [
      "Alberto Racca",
      "Nguyen Anh Khoa Doan",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2211.11403",
    "title": "Time-reversal equivariant neural network potential and Hamiltonian for  magnetic materials",
    "abstract": "This work presents Time-reversal Equivariant Neural Network (TENN) framework. With TENN, the time-reversal symmetry is considered in the equivariant neural network (ENN), which generalizes the ENN to consider physical quantities related to time-reversal symmetry such as spin and velocity of atoms. TENN-e3, as the time-reversal-extension of E(3) equivariant neural network, is developed to keep the Time-reversal E(3) equivariant with consideration of whether to include the spin-orbit effect for both collinear and non-collinear magnetic moments situations for magnetic material. TENN-e3 can construct spin neural network potential and the Hamiltonian of magnetic material from ab-initio calculations. Time-reversal-E(3)-equivariant convolutions for interactions of spinor and geometric tensors are employed in TENN-e3. Compared to the popular ENN, TENN-e3 can describe the complex spin-lattice coupling with high accuracy and keep time-reversal symmetry which is not preserved in the existing E(3)-equivariant model. Also, the Hamiltonian of magnetic material with time-reversal symmetry can be built with TENN-e3. TENN paves a new way to spin-lattice dynamics simulations over long-time scales and electronic structure calculations of large-scale magnetic materials. ",
    "url": "https://arxiv.org/abs/2211.11403",
    "authors": [
      "Hongyu Yu",
      "Yang Zhong",
      "Junyi Ji",
      "Xingao Gong",
      "Hongjun Xiang"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.11462",
    "title": "3D Detection and Characterisation of ALMA Sources through Deep Learning",
    "abstract": "We present a Deep-Learning (DL) pipeline developed for the detection and characterization of astronomical sources within simulated Atacama Large Millimeter/submillimeter Array (ALMA) data cubes. The pipeline is composed of six DL models: a Convolutional Autoencoder for source detection within the spatial domain of the integrated data cubes, a Recurrent Neural Network (RNN) for denoising and peak detection within the frequency domain, and four Residual Neural Networks (ResNets) for source characterization. The combination of spatial and frequency information improves completeness while decreasing spurious signal detection. To train and test the pipeline, we developed a simulation algorithm able to generate realistic ALMA observations, i.e. both sky model and dirty cubes. The algorithm simulates always a central source surrounded by fainter ones scattered within the cube. Some sources were spatially superimposed in order to test the pipeline deblending capabilities. The detection performances of the pipeline were compared to those of other methods and significant improvements in performances were achieved. Source morphologies are detected with subpixel accuracies obtaining mean residual errors of $10^{-3}$ pixel ($0.1$ mas) and $10^{-1}$ mJy/beam on positions and flux estimations, respectively. Projection angles and flux densities are also recovered within $10\\%$ of the true values for $80\\%$ and $73\\%$ of all sources in the test set, respectively. While our pipeline is fine-tuned for ALMA data, the technique is applicable to other interferometric observatories, as SKA, LOFAR, VLBI, and VLTI. ",
    "url": "https://arxiv.org/abs/2211.11462",
    "authors": [
      "Michele Delli Veneri",
      "Lukasz Tychoniec",
      "Fabrizia Guglielmetti",
      "Giuseppe Longo",
      "Eric Villard"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11567",
    "title": "Neural networks trained with SGD learn distributions of increasing  complexity",
    "abstract": "The ability of deep neural networks to generalise well even when they interpolate their training data has been explained using various \"simplicity biases\". These theories postulate that neural networks avoid overfitting by first learning simple functions, say a linear classifier, before learning more complex, non-linear functions. Meanwhile, data structure is also recognised as a key ingredient for good generalisation, yet its role in simplicity biases is not yet understood. Here, we show that neural networks trained using stochastic gradient descent initially classify their inputs using lower-order input statistics, like mean and covariance, and exploit higher-order statistics only later during training. We first demonstrate this distributional simplicity bias (DSB) in a solvable model of a neural network trained on synthetic data. We empirically demonstrate DSB in a range of deep convolutional networks and visual transformers trained on CIFAR10, and show that it even holds in networks pre-trained on ImageNet. We discuss the relation of DSB to other simplicity biases and consider its implications for the principle of Gaussian universality in learning. ",
    "url": "https://arxiv.org/abs/2211.11567",
    "authors": [
      "Maria Refinetti",
      "Alessandro Ingrosso",
      "Sebastian Goldt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11673",
    "title": "Asymptotically Normal Estimation of Local Latent Network Curvature",
    "abstract": "Network data, commonly used throughout the physical, social, and biological sciences, consist of nodes (individuals) and the edges (interactions) between them. One way to represent the complex, high-dimensional structure in network data is to embed the graph into a low-dimensional geometric space. Curvature of this space, in particular, provides insights about structure in the graph, such as the propensity to form triangles or present tree-like structure. ",
    "url": "https://arxiv.org/abs/2211.11673",
    "authors": [
      "Steven Wilkins-Reeves",
      "Tyler McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:1605.04711",
    "title": "Ternary Weight Networks",
    "abstract": " Comments: 5 pages, 3 fitures, conference ",
    "url": "https://arxiv.org/abs/1605.04711",
    "authors": [
      "Fengfu Li",
      "Bin Liu",
      "Xiaoxing Wang",
      "Bo Zhang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1907.05168",
    "title": "Graph product structure for non-minor-closed classes",
    "abstract": " Comments: v2 Cosmetic improvements and a corrected bound for (layered-)(tree)width in Theorems 2, 9, 11, and Corollaries 1, 3, 4, 6, 12. v3 Complete restructure. v4 Major revision, improved constants for 1-planar and d-map graphs. v5 Clarifications and corrections suggested by referee ",
    "url": "https://arxiv.org/abs/1907.05168",
    "authors": [
      "Vida Dujmovi\u0107",
      "Pat Morin",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2007.04281",
    "title": "Reconfigurable Intelligent Surfaces Empowered THz Communication in LEO  Satellite Networks",
    "abstract": " Comments: To appear in IEEE Access ",
    "url": "https://arxiv.org/abs/2007.04281",
    "authors": [
      "K\u00fcr\u015fat Tekb\u0131y\u0131k",
      "G\u00fcne\u015f Karabulut Kurt",
      "Ali R\u0131za Ekti",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2008.12566",
    "title": "A Framework for Improving Scholarly Neural Network Diagrams",
    "abstract": " Comments: 51 pages, 13 tables, 18 figures ",
    "url": "https://arxiv.org/abs/2008.12566",
    "authors": [
      "Guy Clarke Marshall",
      "Andr\u00e9 Freitas",
      "Caroline Jay"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2010.12190",
    "title": "Towards Robust Neural Networks via Orthogonal Diversity",
    "abstract": " Title: Towards Robust Neural Networks via Orthogonal Diversity ",
    "url": "https://arxiv.org/abs/2010.12190",
    "authors": [
      "Kun Fang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Tao Li",
      "Jia Cai",
      "Feipeng Cai",
      "Xiaolin Huang",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.07995",
    "title": "Detection of masses and architectural distortions in digital breast  tomosynthesis: a publicly available dataset of 5,060 patients and a deep  learning model",
    "abstract": " Title: Detection of masses and architectural distortions in digital breast  tomosynthesis: a publicly available dataset of 5,060 patients and a deep  learning model ",
    "url": "https://arxiv.org/abs/2011.07995",
    "authors": [
      "Mateusz Buda",
      "Ashirbani Saha",
      "Ruth Walsh",
      "Sujata Ghate",
      "Nianyi Li",
      "Albert \u015awi\u0119cicki",
      "Joseph Y. Lo",
      "Maciej A. Mazurowski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.11906",
    "title": "Development of a Vertex Finding Algorithm using Recurrent Neural Network",
    "abstract": " Comments: 16 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2101.11906",
    "authors": [
      "Kiichi Goto",
      "Taikan Suehara",
      "Tamaki Yoshioka",
      "Masakazu Kurata",
      "Hajime Nagahara",
      "Yuta Nakashima",
      "Noriko Takemura",
      "Masako Iwasaki"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2104.03813",
    "title": "Can Differential Privacy Practically Protect Collaborative Deep Learning  Inference for the Internet of Things?",
    "abstract": " Comments: Accepted in Wireless Networks ",
    "url": "https://arxiv.org/abs/2104.03813",
    "authors": [
      "Jihyeon Ryu",
      "Yifeng Zheng",
      "Yansong Gao",
      "Sharif Abuadbba",
      "Junyaup Kim",
      "Dongho Won",
      "Surya Nepal",
      "Hyoungshick Kim",
      "Cong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2105.01977",
    "title": "Limits and consistency of non-local and graph approximations to the  Eikonal equation",
    "abstract": " Title: Limits and consistency of non-local and graph approximations to the  Eikonal equation ",
    "url": "https://arxiv.org/abs/2105.01977",
    "authors": [
      "Jalal Fadili",
      "Nicolas Forcadel",
      "Thi Tuyen Nguyen",
      "Rita Zantout"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2105.11166",
    "title": "AirNet: Neural Network Transmission over the Air",
    "abstract": " Title: AirNet: Neural Network Transmission over the Air ",
    "url": "https://arxiv.org/abs/2105.11166",
    "authors": [
      "Mikolaj Jankowski",
      "Deniz Gunduz",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.03812",
    "title": "Neural Monge Map estimation and its applications",
    "abstract": " Title: Neural Monge Map estimation and its applications ",
    "url": "https://arxiv.org/abs/2106.03812",
    "authors": [
      "Jiaojiao Fan",
      "Shu Liu",
      "Shaojun Ma",
      "Haomin Zhou",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2106.15791",
    "title": "Distributionally Robust Learning with Stable Adversarial Training",
    "abstract": " Comments: Accepted by Transactions on Knowledge and Data Engineering. Extension of AAAI paper (arXiv:2006.04414v2). arXiv admin note: substantial text overlap with arXiv:2006.04414 ",
    "url": "https://arxiv.org/abs/2106.15791",
    "authors": [
      "Jiashuo Liu",
      "Zheyan Shen",
      "Peng Cui",
      "Linjun Zhou",
      "Kun Kuang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.01152",
    "title": "Maximizing and Satisficing in Multi-armed Bandits with Graph Information",
    "abstract": " Title: Maximizing and Satisficing in Multi-armed Bandits with Graph Information ",
    "url": "https://arxiv.org/abs/2108.01152",
    "authors": [
      "Parth K.Thaker",
      "Mohit Malu",
      "Nikhil Rao",
      "Gautam Dasarathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.02697",
    "title": "A tight local algorithm for the minimum dominating set problem in  outerplanar graphs",
    "abstract": " Comments: Accepted to DISC 2021 ",
    "url": "https://arxiv.org/abs/2108.02697",
    "authors": [
      "Marthe Bonamy",
      "Linda Cook",
      "Carla Groenland",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2111.10698",
    "title": "Towards Graph Self-Supervised Learning with Contrastive Adjusted Zooming",
    "abstract": " Title: Towards Graph Self-Supervised Learning with Contrastive Adjusted Zooming ",
    "url": "https://arxiv.org/abs/2111.10698",
    "authors": [
      "Yizhen Zheng",
      "Ming Jin",
      "Shirui Pan",
      "Yuan-Fang Li",
      "Hao Peng",
      "Ming Li",
      "Zhao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.11000",
    "title": "PRISM: A Hierarchical Intrusion Detection Architecture for Large-Scale  Cyber Networks",
    "abstract": " Title: PRISM: A Hierarchical Intrusion Detection Architecture for Large-Scale  Cyber Networks ",
    "url": "https://arxiv.org/abs/2111.11000",
    "authors": [
      "Yahya Javed",
      "Mosab A. Khayat",
      "Ali A. Elghariani",
      "Arif Ghafoor"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2111.12273",
    "title": "Sharpness-aware Quantization for Deep Neural Networks",
    "abstract": " Comments: Tech report ",
    "url": "https://arxiv.org/abs/2111.12273",
    "authors": [
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.02088",
    "title": "Deep Causal Reasoning for Recommendations",
    "abstract": " Title: Deep Causal Reasoning for Recommendations ",
    "url": "https://arxiv.org/abs/2201.02088",
    "authors": [
      "Yaochen Zhu",
      "Jing Yi",
      "Jiayi Xie",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2201.08066",
    "title": "NLP Methods in Host-based Intrusion Detection Systems: A Systematic  Review and Future Directions",
    "abstract": " Title: NLP Methods in Host-based Intrusion Detection Systems: A Systematic  Review and Future Directions ",
    "url": "https://arxiv.org/abs/2201.08066",
    "authors": [
      "Zarrin Tasnim Sworna",
      "Zahra Mousavi",
      "Muhammad Ali Babar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.11582",
    "title": "GUDN: A novel guide network with label reinforcement strategy for  extreme multi-label text classification",
    "abstract": " Comments: 12 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2201.11582",
    "authors": [
      "Qing Wang",
      "Jia Zhu",
      "Hongji Shu",
      "Kwame Omono Asamoah",
      "Jianyang Shi",
      "Cong Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.11808",
    "title": "LAP: An Attention-Based Module for Faithful Interpretation and Knowledge  Injection in Convolutional Neural Networks",
    "abstract": " Title: LAP: An Attention-Based Module for Faithful Interpretation and Knowledge  Injection in Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2201.11808",
    "authors": [
      "Rassa Ghavami Modegh",
      "Ahmad Salimi",
      "Alireza Dizaji",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12826",
    "title": "Optimizing Gradient-driven Criteria in Network Sparsity",
    "abstract": " Comments: 11 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2201.12826",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Mengzhao Chen",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04235",
    "title": "Towards Compositional Adversarial Robustness: Generalizing Adversarial  Training to Composite Semantic Perturbations",
    "abstract": " Title: Towards Compositional Adversarial Robustness: Generalizing Adversarial  Training to Composite Semantic Perturbations ",
    "url": "https://arxiv.org/abs/2202.04235",
    "authors": [
      "Lei Hsiung",
      "Yun-Yun Tsai",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04777",
    "title": "Exact Solutions of a Deep Linear Network",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2202.04777",
    "authors": [
      "Liu Ziyin",
      "Botao Li",
      "Xiangming Meng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06533",
    "title": "An Introduction to Neural Data Compression",
    "abstract": " Title: An Introduction to Neural Data Compression ",
    "url": "https://arxiv.org/abs/2202.06533",
    "authors": [
      "Yibo Yang",
      "Stephan Mandt",
      "Lucas Theis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.08235",
    "title": "Data Augmentation for Deep Graph Learning: A Survey",
    "abstract": " Comments: Accepted by SIGKDD Explorations Paper list: this https URL ",
    "url": "https://arxiv.org/abs/2202.08235",
    "authors": [
      "Kaize Ding",
      "Zhe Xu",
      "Hanghang Tong",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09115",
    "title": "Towards Simple and Accurate Human Pose Estimation with Stair Network",
    "abstract": " Comments: The paper has been accepted by IEEE Transactions on Emerging Topics in Computational Intelligence ",
    "url": "https://arxiv.org/abs/2202.09115",
    "authors": [
      "Chenru Jiang",
      "Kaizhu Huang",
      "Shufei Zhang",
      "Shufei Zhang",
      "Jimin Xiao",
      "Zhenxing Niu",
      "Amir Hussain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.12278",
    "title": "Learning Stochastic Dynamics with Statistics-Informed Neural Network",
    "abstract": " Title: Learning Stochastic Dynamics with Statistics-Informed Neural Network ",
    "url": "https://arxiv.org/abs/2202.12278",
    "authors": [
      "Yuanran Zhu",
      "Yu-Hang Tang",
      "Changho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2202.12938",
    "title": "Assessing the State of Self-Supervised Human Activity Recognition using  Wearables",
    "abstract": " Comments: updated ",
    "url": "https://arxiv.org/abs/2202.12938",
    "authors": [
      "Harish Haresamudram",
      "Irfan Essa",
      "Thomas Pl\u00f6tz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00949",
    "title": "GAP: Differentially Private Graph Neural Networks with Aggregation  Perturbation",
    "abstract": " Comments: Accepted at USENIX Security '23 ",
    "url": "https://arxiv.org/abs/2203.00949",
    "authors": [
      "Sina Sajadmanesh",
      "Ali Shahin Shamsabadi",
      "Aur\u00e9lien Bellet",
      "Daniel Gatica-Perez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.08921",
    "title": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-Resolution",
    "abstract": " Title: Hybrid Pixel-Unshuffled Network for Lightweight Image Super-Resolution ",
    "url": "https://arxiv.org/abs/2203.08921",
    "authors": [
      "Bin Sun",
      "Yulun Zhang",
      "Songyao Jiang",
      "Yun Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.00943",
    "title": "Efficient Convolutional Neural Networks on Raspberry Pi for Image  Classification",
    "abstract": " Title: Efficient Convolutional Neural Networks on Raspberry Pi for Image  Classification ",
    "url": "https://arxiv.org/abs/2204.00943",
    "authors": [
      "Rui-Yang Ju",
      "Ting-Yu Lin",
      "Jia-Hao Jian",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.01089",
    "title": "VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation",
    "abstract": " Title: VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation ",
    "url": "https://arxiv.org/abs/2204.01089",
    "authors": [
      "Lingyun Lu",
      "Bang Wang",
      "Zizhuo Zhang",
      "Shenghao Liu",
      "Han Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04440",
    "title": "Are Two Heads the Same as One? Identifying Disparate Treatment in Fair  Neural Networks",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2204.04440",
    "authors": [
      "Michael Lohaus",
      "Matth\u00e4us Kleindessner",
      "Krishnaram Kenthapadi",
      "Francesco Locatello",
      "Chris Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04853",
    "title": "Neural Lagrangian Schr\u00f6dinger Bridge",
    "abstract": " Title: Neural Lagrangian Schr\u00f6dinger Bridge ",
    "url": "https://arxiv.org/abs/2204.04853",
    "authors": [
      "Takeshi Koshizuka",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2204.05351",
    "title": "Graph Ordering Attention Networks",
    "abstract": " Comments: Accepted at AAAI 2023 ",
    "url": "https://arxiv.org/abs/2204.05351",
    "authors": [
      "Michail Chatzianastasis",
      "Johannes F. Lutzeyer",
      "George Dasoulas",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08319",
    "title": "Backward Reachability Analysis for Neural Feedback Loops",
    "abstract": " Comments: 8 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2204.08319",
    "authors": [
      "Nicholas Rober",
      "Michael Everett",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.09035",
    "title": "Massively Parallel Computation on Embedded Planar Graphs",
    "abstract": " Comments: To appear at SODA 2023 ",
    "url": "https://arxiv.org/abs/2204.09035",
    "authors": [
      "Jacob Holm",
      "Jakub T\u011btek"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.09093",
    "title": "Behind the Machine's Gaze: Neural Networks with Biologically-inspired  Constraints Exhibit Human-like Visual Attention",
    "abstract": " Comments: 31 pages, 14 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2204.09093",
    "authors": [
      "Leo Schwinn",
      "Doina Precup",
      "Bj\u00f6rn Eskofier",
      "Dario Zanca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.11695",
    "title": "Estimation of Reliable Proposal Quality for Temporal Action Detection",
    "abstract": " Comments: Accepted to ACM Multimedia 2022 ",
    "url": "https://arxiv.org/abs/2204.11695",
    "authors": [
      "Junshan Hu",
      "Chaoxu guo",
      "Liansheng Zhuang",
      "Biao Wang",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10498",
    "title": "Named Entity Linking with Entity Representation by Multiple Embeddings",
    "abstract": " Comments: 12 pages, 14 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2205.10498",
    "authors": [
      "Oleg Vasilyev",
      "Alex Dauenhauer",
      "Vedant Dharnidharka",
      "John Bohannon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11083",
    "title": "Deep Digging into the Generalization of Self-supervised Monocular Depth  Estimation",
    "abstract": " Comments: Accepted to AAAI 2023 ",
    "url": "https://arxiv.org/abs/2205.11083",
    "authors": [
      "Jinwoo Bae",
      "Sungho Moon",
      "Sunghoon Im"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12735",
    "title": "Inductive Learning of Complex Knowledge from Raw Data",
    "abstract": " Title: Inductive Learning of Complex Knowledge from Raw Data ",
    "url": "https://arxiv.org/abs/2205.12735",
    "authors": [
      "Daniel Cunnington",
      "Mark Law",
      "Jorge Lobo",
      "Alessandra Russo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01163",
    "title": "Invertible Neural Networks for Graph Prediction",
    "abstract": " Comments: Accepted at IEEE Journal on Selected Areas in Information Theory (JSAIT)---Special Issue Deep Learning for Inverse Problems ",
    "url": "https://arxiv.org/abs/2206.01163",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02095",
    "title": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "abstract": " Title: ARC -- Actor Residual Critic for Adversarial Imitation Learning ",
    "url": "https://arxiv.org/abs/2206.02095",
    "authors": [
      "Ankur Deka",
      "Changliu Liu",
      "Katia Sycara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.02916",
    "title": "Remember the Past: Distilling Datasets into Addressable Memories for  Neural Networks",
    "abstract": " Title: Remember the Past: Distilling Datasets into Addressable Memories for  Neural Networks ",
    "url": "https://arxiv.org/abs/2206.02916",
    "authors": [
      "Zhiwei Deng",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03314",
    "title": "Integrating Random Effects in Deep Neural Networks",
    "abstract": " Comments: 53 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2206.03314",
    "authors": [
      "Giora Simchoni",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04635",
    "title": "Optimal Design of Energy-Harvesting Hybrid VLC-RF Networks",
    "abstract": " Title: Optimal Design of Energy-Harvesting Hybrid VLC-RF Networks ",
    "url": "https://arxiv.org/abs/2206.04635",
    "authors": [
      "Amir Hossein Fahim Raouf",
      "Chethan Kumar Anjinappa",
      "Ismail Guvenc"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.04882",
    "title": "$\\mathsf{G^2Retro}$: Two-Step Graph Generative Models for Retrosynthesis  Prediction",
    "abstract": " Title: $\\mathsf{G^2Retro}$: Two-Step Graph Generative Models for Retrosynthesis  Prediction ",
    "url": "https://arxiv.org/abs/2206.04882",
    "authors": [
      "Ziqi Chen",
      "Oluwatosin R. Ayinde",
      "James R. Fuchs",
      "Huan Sun",
      "Xia Ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2206.10885",
    "title": "KiloNeuS: A Versatile Neural Implicit Surface Representation for  Real-Time Rendering",
    "abstract": " Comments: 9 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2206.10885",
    "authors": [
      "Stefano Esposito",
      "Daniele Baieri",
      "Stefan Zellmann",
      "Andr\u00e9 Hinkenjann",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11693",
    "title": "Learning Agile Skills via Adversarial Imitation of Rough Partial  Demonstrations",
    "abstract": " Title: Learning Agile Skills via Adversarial Imitation of Rough Partial  Demonstrations ",
    "url": "https://arxiv.org/abs/2206.11693",
    "authors": [
      "Chenhao Li",
      "Marin Vlastelica",
      "Sebastian Blaes",
      "Jonas Frey",
      "Felix Grimminger",
      "Georg Martius"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11828",
    "title": "On the Complexity of Problems on Tree-structured Graphs",
    "abstract": " Title: On the Complexity of Problems on Tree-structured Graphs ",
    "url": "https://arxiv.org/abs/2206.11828",
    "authors": [
      "Hans L. Bodlaender",
      "Carla Groenland",
      "Hugo Jacob",
      "Marcin Pilipczuk",
      "Michal Pilipczuk"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2206.14390",
    "title": "Diet Code Is Healthy: Simplifying Programs for Pre-trained Models of  Code",
    "abstract": " Comments: Accepted to be published in ESEC/FSE 2022 ",
    "url": "https://arxiv.org/abs/2206.14390",
    "authors": [
      "Zhaowei Zhang",
      "Hongyu Zhang",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.01127",
    "title": "DecisioNet: A Binary-Tree Structured Neural Network",
    "abstract": " Comments: The paper has been accepted to the ACCV2022 conference. A short summary video about the paper can be found at this https URL ",
    "url": "https://arxiv.org/abs/2207.01127",
    "authors": [
      "Noam Gottlieb",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05978",
    "title": "Enhanced Security and Privacy via Fragmented Federated Learning",
    "abstract": " Comments: IEEE Transactions on Neural Networks and Learning Systems (To Appear) ",
    "url": "https://arxiv.org/abs/2207.05978",
    "authors": [
      "Najeeb Moharram Jebreel",
      "Josep Domingo-Ferrer",
      "Alberto Blanco-Justicia",
      "David Sanchez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10862",
    "title": "Contrastive Self-Supervised Learning Leads to Higher Adversarial  Susceptibility",
    "abstract": " Comments: 8 pages, 3 figures, to appear at AAAI-2023 ",
    "url": "https://arxiv.org/abs/2207.10862",
    "authors": [
      "Rohit Gupta",
      "Naveed Akhtar",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00277",
    "title": "MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient  Neural Field Rendering on Mobile Architectures",
    "abstract": " Comments: Project page: this https URL, code: this https URL ",
    "url": "https://arxiv.org/abs/2208.00277",
    "authors": [
      "Zhiqin Chen",
      "Thomas Funkhouser",
      "Peter Hedman",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00800",
    "title": "GANDSE: Generative Adversarial Network based Design Space Exploration  for Neural Network Accelerator Design",
    "abstract": " Comments: Published in ACM Transactions on Design Automation of Electronic Systems ",
    "url": "https://arxiv.org/abs/2208.00800",
    "authors": [
      "Lang Feng",
      "Wenjian Liu",
      "Chuliang Guo",
      "Ke Tang",
      "Cheng Zhuo",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2208.01739",
    "title": "Reconstructing Sparse Multiplex Networks with Application to Covert  Networks",
    "abstract": " Title: Reconstructing Sparse Multiplex Networks with Application to Covert  Networks ",
    "url": "https://arxiv.org/abs/2208.01739",
    "authors": [
      "Jin-Zhu Yu",
      "Mincheng Wu",
      "Gisela Bichler",
      "Felipe Aros-Vera",
      "Jianxi Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06222",
    "title": "Scale-free and Task-agnostic Attack: Generating Photo-realistic  Adversarial Patterns with Patch Quilting Generator",
    "abstract": " Title: Scale-free and Task-agnostic Attack: Generating Photo-realistic  Adversarial Patterns with Patch Quilting Generator ",
    "url": "https://arxiv.org/abs/2208.06222",
    "authors": [
      "Xiangbo Gao",
      "Cheng Luo",
      "Qinliang Lin",
      "Weicheng Xie",
      "Minmin Liu",
      "Linlin Shen",
      "Keerthy Kusumam",
      "Siyang Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.08386",
    "title": "Neural Embeddings for Text",
    "abstract": " Comments: 27 pages, 18 figures, 19 tables, appendixes A-H ",
    "url": "https://arxiv.org/abs/2208.08386",
    "authors": [
      "Oleg Vasilyev",
      "John Bohannon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.09725",
    "title": "On Robustness in Nonconvex Optimization with Application to Defense  Planning",
    "abstract": " Title: On Robustness in Nonconvex Optimization with Application to Defense  Planning ",
    "url": "https://arxiv.org/abs/2208.09725",
    "authors": [
      "Johannes O. Royset"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11469",
    "title": "ProbGraph: High-Performance and High-Accuracy Graph Mining with  Probabilistic Set Representations",
    "abstract": " Comments: Best Paper Award at ACM/IEEE Supercomputing'22 (SC22) ",
    "url": "https://arxiv.org/abs/2208.11469",
    "authors": [
      "Maciej Besta",
      "Cesare Miglioli",
      "Paolo Sylos Labini",
      "Jakub T\u011btek",
      "Patrick Iff",
      "Raghavendra Kanakagiri",
      "Saleh Ashkboos",
      "Kacper Janda",
      "Michal Podstawski",
      "Grzegorz Kwasniewski",
      "Niels Gleinig",
      "Flavio Vella",
      "Onur Mutlu",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2209.04265",
    "title": "Routing Planning for Last-Mile Deliveries Using Mobile Parcel Lockers: A  Hybrid Q-Learning Network Approach",
    "abstract": " Comments: 76 pages, 18 figures. This paper has been submitted to Transportation Research Part E: Logistics and Transportation Review (Manuscript Number: TRE-D-22-01261) ",
    "url": "https://arxiv.org/abs/2209.04265",
    "authors": [
      "Yubin Liu",
      "Qiming Ye",
      "Jose Escribano-Macias",
      "Yuxiang Feng",
      "Eduardo Candela",
      "Panagiotis Angeloudis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.07778",
    "title": "Spatial-then-Temporal Self-Supervised Learning for Video Correspondence",
    "abstract": " Title: Spatial-then-Temporal Self-Supervised Learning for Video Correspondence ",
    "url": "https://arxiv.org/abs/2209.07778",
    "authors": [
      "Rui Li",
      "Dong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.09209",
    "title": "Discriminative Sampling of Proposals in Self-Supervised Transformers for  Weakly Supervised Object Localization",
    "abstract": " Title: Discriminative Sampling of Proposals in Self-Supervised Transformers for  Weakly Supervised Object Localization ",
    "url": "https://arxiv.org/abs/2209.09209",
    "authors": [
      "Shakeeb Murtaza",
      "Soufiane Belharbi",
      "Marco Pedersoli",
      "Aydin Sarraf",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.10585",
    "title": "Grape Cold Hardiness Prediction via Multi-Task Learning",
    "abstract": " Comments: 6 pages, 2 figures, accepted at IAAI-23 ",
    "url": "https://arxiv.org/abs/2209.10585",
    "authors": [
      "Aseem Saxena",
      "Paola Pesantez-Cabrera",
      "Rohan Ballapragada",
      "Kin-Ho Lam",
      "Markus Keller",
      "Alan Fern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14076",
    "title": "Backward Reachability Analysis of Neural Feedback Loops: Techniques for  Linear and Nonlinear Systems",
    "abstract": " Comments: 17 pages, 15 figures. Journal extension of arXiv:2204.08319 ",
    "url": "https://arxiv.org/abs/2209.14076",
    "authors": [
      "Nicholas Rober",
      "Sydney M. Katz",
      "Chelsea Sidrane",
      "Esen Yel",
      "Michael Everett",
      "Mykel J. Kochenderfer",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.15180",
    "title": "SCI: A spectrum concentrated implicit neural compression for biomedical  data",
    "abstract": " Comments: accepted to AAAI2023 ",
    "url": "https://arxiv.org/abs/2209.15180",
    "authors": [
      "Runzhao Yang",
      "Tingxiong Xiao",
      "Yuxiao Cheng",
      "Qianni Cao",
      "Jinyuan Qu",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00006",
    "title": "A graph neural network approach to automated model building in cryo-EM  maps",
    "abstract": " Title: A graph neural network approach to automated model building in cryo-EM  maps ",
    "url": "https://arxiv.org/abs/2210.00006",
    "authors": [
      "Kiarash Jamali",
      "Dari Kimanius",
      "Sjors H.W. Scheres"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2210.01257",
    "title": "Regularized linear convolutional networks inherit frequency sensitivity  from image statistics",
    "abstract": " Comments: Comments welcome! V2: Title updated to more precisely reflect our results, conjecture on non-commutative generalized H\\\"older upgraded to Lemma 4.11, and as a consequence restrictions on Theorem 4.9 removed, more datasets, more variable frequency statistics and more CNN architectures ",
    "url": "https://arxiv.org/abs/2210.01257",
    "authors": [
      "Charles Godfrey",
      "Elise Bishoff",
      "Myles Mckay",
      "Davis Brown",
      "Grayson Jorgenson",
      "Henry Kvinge",
      "Eleanor Byler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.02271",
    "title": "Extending Conformal Prediction to Hidden Markov Models with Exact  Validity via de Finetti's Theorem for Markov Chains",
    "abstract": " Title: Extending Conformal Prediction to Hidden Markov Models with Exact  Validity via de Finetti's Theorem for Markov Chains ",
    "url": "https://arxiv.org/abs/2210.02271",
    "authors": [
      "Buddhika Nettasinghe",
      "Samrat Chatterjee",
      "Ramakrishna Tipireddy",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.03274",
    "title": "TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts",
    "abstract": " Title: TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts ",
    "url": "https://arxiv.org/abs/2210.03274",
    "authors": [
      "Zhihao Wang",
      "Chuang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04872",
    "title": "Sequential Neural Score Estimation: Likelihood-Free Inference with  Conditional Score Based Diffusion Models",
    "abstract": " Title: Sequential Neural Score Estimation: Likelihood-Free Inference with  Conditional Score Based Diffusion Models ",
    "url": "https://arxiv.org/abs/2210.04872",
    "authors": [
      "Louis Sharrock",
      "Jack Simons",
      "Song Liu",
      "Mark Beaumont"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07321",
    "title": "Machine Generated Text: A Comprehensive Survey of Threat Models and  Detection Methods",
    "abstract": " Comments: Manuscript submitted to ACM Special Session on Trustworthy AI. 2022/11/19 - Updated references ",
    "url": "https://arxiv.org/abs/2210.07321",
    "authors": [
      "Evan Crothers",
      "Nathalie Japkowicz",
      "Herna Viktor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08398",
    "title": "SPIDR: SDF-based Neural Point Fields for Illumination and Deformation",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2210.08398",
    "authors": [
      "Ruofan Liang",
      "Jiahao Zhang",
      "Haoda Li",
      "Chen Yang",
      "Yushi Guan",
      "Nandita Vijaykumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.09049",
    "title": "SpanProto: A Two-stage Span-based Prototypical Network for Few-shot  Named Entity Recognition",
    "abstract": " Title: SpanProto: A Two-stage Span-based Prototypical Network for Few-shot  Named Entity Recognition ",
    "url": "https://arxiv.org/abs/2210.09049",
    "authors": [
      "Jianing Wang",
      "Chengcheng Han",
      "Chengyu Wang",
      "Chuanqi Tan",
      "Minghui Qiu",
      "Songfang Huang",
      "Jun Huang",
      "Ming Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.09884",
    "title": "Is Dogecoin a Viable Investment? Insights from Network and Bubble  Effects",
    "abstract": " Title: Is Dogecoin a Viable Investment? Insights from Network and Bubble  Effects ",
    "url": "https://arxiv.org/abs/2210.09884",
    "authors": [
      "Ruoxin Xiao",
      "Xinyu Ying",
      "Hengxu Li",
      "Kexin Liu"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.11060",
    "title": "Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots",
    "abstract": " Comments: 17 pages, 14 figures. Accepted by Findings of EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.11060",
    "authors": [
      "Haomin Fu",
      "Yeqin Zhang",
      "Haiyang Yu",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li",
      "Cam-Tu Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12689",
    "title": "Face Emotion Recognization Using Dataset Augmentation Based on Neural  Network",
    "abstract": " Comments: 5 pages, 8 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2210.12689",
    "authors": [
      "Mengyu Rao",
      "Ruyi Bao",
      "Liangshun Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14064",
    "title": "Learning Low Dimensional State Spaces with Overparameterized Recurrent  Neural Network",
    "abstract": " Comments: preprint, 9 pages, 2 figures plus supplementary ",
    "url": "https://arxiv.org/abs/2210.14064",
    "authors": [
      "Edo Cohen-Karlik",
      "Itamar Menuhin-Gruman",
      "Nadav Cohen",
      "Raja Giryes",
      "Amir Globerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14163",
    "title": "Multi-Granularity Cross-Modality Representation Learning for Named  Entity Recognition on Social Media",
    "abstract": " Comments: We have reconducted experiments of the paper, but found that there were fatal errors in our datasets leading to the wrong results and analyses. Therefore, we have to withdraw the paper to ensure the authenticity of science. We are very sorry ",
    "url": "https://arxiv.org/abs/2210.14163",
    "authors": [
      "Peipei Liu",
      "Gaosheng Wang",
      "Hong Li",
      "Jie Liu",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.00550",
    "title": "GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous  Graphs",
    "abstract": " Title: GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous  Graphs ",
    "url": "https://arxiv.org/abs/2211.00550",
    "authors": [
      "Marios Papachristou",
      "Rishab Goel",
      "Frank Portman",
      "Matthew Miller",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.01201",
    "title": "Human alignment of neural network representations",
    "abstract": " Title: Human alignment of neural network representations ",
    "url": "https://arxiv.org/abs/2211.01201",
    "authors": [
      "Lukas Muttenthaler",
      "Jonas Dippel",
      "Lorenz Linhardt",
      "Robert A. Vandermeulen",
      "Simon Kornblith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.01827",
    "title": "Demo: LE3D: A Privacy-preserving Lightweight Data Drift Detection  Framework",
    "abstract": " Comments: IEEE CCNC 2023, Las Vegas, USA ",
    "url": "https://arxiv.org/abs/2211.01827",
    "authors": [
      "Ioannis Mavromatis",
      "Aftab Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.03602",
    "title": "Retention Time Prediction for Chromatographic Enantioseparation by  Quantile Geometry-enhanced Graph Neural Network",
    "abstract": " Title: Retention Time Prediction for Chromatographic Enantioseparation by  Quantile Geometry-enhanced Graph Neural Network ",
    "url": "https://arxiv.org/abs/2211.03602",
    "authors": [
      "Hao Xu",
      "Jinglong Lin",
      "Dongxiao Zhang",
      "Fanyang Mo"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.04607",
    "title": "First principles physics-informed neural network for quantum  wavefunctions and eigenvalue surfaces",
    "abstract": " Title: First principles physics-informed neural network for quantum  wavefunctions and eigenvalue surfaces ",
    "url": "https://arxiv.org/abs/2211.04607",
    "authors": [
      "Marios Mattheakis",
      "Gabriel R. Schleder",
      "Daniel T. Larson",
      "Efthimios Kaxiras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.05364",
    "title": "Efficient Unsupervised Video Object Segmentation Network Based on Motion  Guidance",
    "abstract": " Comments: The 10th International Conference on Information Systems and Computing Technology ",
    "url": "https://arxiv.org/abs/2211.05364",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05410",
    "title": "Robust Smart Home Face Recognition under Starving Federated Data",
    "abstract": " Comments: 11 pages, 12 figures, 7 tables, accepted as a conference paper at IEEE UV 2022, Boston, USA ",
    "url": "https://arxiv.org/abs/2211.05410",
    "authors": [
      "Jaechul Roh",
      "Yajun Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.05554",
    "title": "Robust Federated Learning against both Data Heterogeneity and Poisoning  Attack via Aggregation Optimization",
    "abstract": " Title: Robust Federated Learning against both Data Heterogeneity and Poisoning  Attack via Aggregation Optimization ",
    "url": "https://arxiv.org/abs/2211.05554",
    "authors": [
      "Yueqi Xie",
      "Weizhong Zhang",
      "Renjie Pi",
      "Fangzhao Wu",
      "Qifeng Chen",
      "Xing Xie",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.05913",
    "title": "Twitter Spam and False Accounts Prevalence, Detection and  Characterization: A Survey",
    "abstract": " Comments: Submitted to First Monday ",
    "url": "https://arxiv.org/abs/2211.05913",
    "authors": [
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.06588",
    "title": "DEYO: DETR with YOLO for Step-by-Step Object Detection",
    "abstract": " Title: DEYO: DETR with YOLO for Step-by-Step Object Detection ",
    "url": "https://arxiv.org/abs/2211.06588",
    "authors": [
      "Haodong Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.07454",
    "title": "LGN-Net: Local-Global Normality Network for Video Anomaly Detection",
    "abstract": " Comments: Under Review in IEEE TCSVT ",
    "url": "https://arxiv.org/abs/2211.07454",
    "authors": [
      "Mengyang Zhao",
      "Xinhua Zeng",
      "Jing Liu",
      "Di Li",
      "Chengxin Pang",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.07587",
    "title": "Artificial neural networks for predicting the viscosity of  lead-containing glasses",
    "abstract": " Comments: 6 pages, 5 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2211.07587",
    "authors": [
      "Patrick dos Anjos",
      "Lucas A. Quaresma",
      "Marcelo L. P. Machado"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2211.07797",
    "title": "Energy Storage Price Arbitrage via Opportunity Value Function Prediction",
    "abstract": " Title: Energy Storage Price Arbitrage via Opportunity Value Function Prediction ",
    "url": "https://arxiv.org/abs/2211.07797",
    "authors": [
      "Ningkun Zheng",
      "Xiaoxiang Liu",
      "Bolun Xu",
      "Yuanyuan Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08398",
    "title": "Structured Knowledge Distillation Towards Efficient and Compact  Multi-View 3D Detection",
    "abstract": " Comments: Codes will be released if this paper is accepted ",
    "url": "https://arxiv.org/abs/2211.08398",
    "authors": [
      "Linfeng Zhang",
      "Yukang Shi",
      "Hung-Shuo Tai",
      "Zhipeng Zhang",
      "Yuan He",
      "Ke Wang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08512",
    "title": "N2V2 -- Fixing Noise2Void Checkerboard Artifacts with Modified Sampling  Strategies and a Tweaked Network Architecture",
    "abstract": " Comments: 16 pages, 7 figures, 5 page supplement, 4 supplementary figures, accepted at BIC workshop at ECCV 2022 ",
    "url": "https://arxiv.org/abs/2211.08512",
    "authors": [
      "Eva H\u00f6ck",
      "Tim-Oliver Buchholz",
      "Anselm Brachmann",
      "Florian Jug",
      "Alexander Freytag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08609",
    "title": "R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based  Trajectory Refinement",
    "abstract": " Title: R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based  Trajectory Refinement ",
    "url": "https://arxiv.org/abs/2211.08609",
    "authors": [
      "Sehwan Choi",
      "Jungho Kim",
      "Junyong Yun",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08657",
    "title": "Person Text-Image Matching via Text-Feature Interpretability Embedding  and External Attack Node Implantation",
    "abstract": " Title: Person Text-Image Matching via Text-Feature Interpretability Embedding  and External Attack Node Implantation ",
    "url": "https://arxiv.org/abs/2211.08657",
    "authors": [
      "Fan Li",
      "Hang Zhou",
      "Huafeng Li",
      "Yafei Zhang",
      "Zhengtao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.08761",
    "title": "Separable PINN: Mitigating the Curse of Dimensionality in  Physics-Informed Neural Networks",
    "abstract": " Comments: To appear in NeurIPS 2022 Workshop on The Symbiosis of Deep Learning and Differential Equations (DLDE) - II, 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2211.08761",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Hyunmo Yang",
      "Seok-Bae Yun",
      "Youngjoon Hong",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08892",
    "title": "Fast Graph Generation via Spectral Diffusion",
    "abstract": " Title: Fast Graph Generation via Spectral Diffusion ",
    "url": "https://arxiv.org/abs/2211.08892",
    "authors": [
      "Tianze Luo",
      "Zhanfeng Mo",
      "Sinno Jialin Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.09174",
    "title": "CASPR: Customer Activity Sequence-based Prediction and Representation",
    "abstract": " Comments: Presented at the Table Representation Learning Workshop, NeurIPS 2022, New Orleans. Authors listed in random order ",
    "url": "https://arxiv.org/abs/2211.09174",
    "authors": [
      "Pin-Jung Chen",
      "Sahil Bhatnagar",
      "Damian Konrad Kowalczyk",
      "Mayank Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.09510",
    "title": "Self-supervised Trajectory Representation Learning with Temporal  Regularities and Travel Semantics",
    "abstract": " Comments: Accepted by ICDE 2023 ",
    "url": "https://arxiv.org/abs/2211.09510",
    "authors": [
      "Jiawei Jiang",
      "Dayan Pan",
      "Houxing Ren",
      "Xiaohan Jiang",
      "Chao Li",
      "Jingyuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09591",
    "title": "Personal Privacy Protection Problems in the Digital Age",
    "abstract": " Comments: 9 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2211.09591",
    "authors": [
      "Zhiheng Yi",
      "Xiaoli Chen"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2211.09861",
    "title": "Self-Supervised Visual Representation Learning via Residual Momentum",
    "abstract": " Comments: 18 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2211.09861",
    "authors": [
      "Trung X. Pham",
      "Axi Niu",
      "Zhang Kang",
      "Sultan Rizky Madjid",
      "Ji Woo Hong",
      "Daehyeok Kim",
      "Joshua Tian Jin Tee",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10085",
    "title": "Identifying Unique Causal Network from Nonstationary Time Series",
    "abstract": " Comments: This manuscript are submitted so that other researchers can follow ",
    "url": "https://arxiv.org/abs/2211.10085",
    "authors": [
      "Mingyu Kang",
      "Duxin Chen",
      "Ning Meng",
      "Gang Yan",
      "Wenwu Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  }
]