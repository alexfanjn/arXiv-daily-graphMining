[
  {
    "id": "arXiv:2110.02375",
    "title": "Interpreting intermediate convolutional layers in unsupervised acoustic  word classification",
    "abstract": "Understanding how deep convolutional neural networks classify data has been subject to extensive research. This paper proposes a technique to visualize and interpret intermediate layers of unsupervised deep convolutional neural networks by averaging over individual feature maps in each convolutional layer and inferring underlying distributions of words with non-linear regression techniques. A GAN-based architecture (ciwGAN arXiv:2006.02951) that includes three convolutional networks (a Generator, a Discriminator, and a classifier) was trained on unlabeled sliced lexical items from TIMIT. The training results in a deep convolutional network that learns to classify words into discrete classes only from the requirement of the Generator to output informative data. The classifier network has no access to the training data -- only to the generated data -- which means lexical learning needs to emerge in a fully unsupervised manner. We propose a technique to visualize individual convolutional layers in the classifier that yields highly informative time-series data for each convolutional layer and apply it to unobserved test data. Using non-linear regression, we infer underlying distributions for each word which allows us to analyze both absolute values and shapes of individual words at different convolutional layers as well as perform hypothesis testing on their acoustic properties. The technique also allows us to tests individual phone contrasts and how they are represented at each layer. ",
    "url": "https://arxiv.org/abs/2110.02375",
    "authors": [
      "Ga\u0161per Begu\u0161",
      "Alan Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.02378",
    "title": "High-rate storage codes on triangle-free graphs",
    "abstract": "Consider an assignment of bits to the vertices of a connected graph $G(V,E)$ with the property that the value of each vertex is a function of the values of its neighbors. A collection of such assignments is called a {\\em storage code} of length $|V|$ on $G$. The storage code problem can be equivalently formulated as maximizing the probability of success in a {\\em guessing game} on graphs, or constructing {\\em index codes} of small rate. If $G$ contains many cliques, it is easy to construct codes of rate close to 1, so a natural problem is to construct high-rate codes on triangle-free graphs, where constructing codes of rate $>1/2$ is a nontrivial task, with few known results. In this work we construct infinite families of linear storage codes with high rate relying on coset graphs of binary linear codes. We also derive necessary conditions for such codes to have high rate, and even rate potentially close to one. We also address correction of multiple erasures in the codeword, deriving recovery guarantees based on expansion properties of the graph. Finally, we point out connections between linear storage codes and quantum CSS codes, a link to bootstrap percolation and contagion spread in graphs, and formulate a number of open problems. ",
    "url": "https://arxiv.org/abs/2110.02378",
    "authors": [
      "Alexander Barg",
      "Gilles Z\u00e9mor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2110.02543",
    "title": "A logical approach for temporal and multiplex networks analysis",
    "abstract": "Many systems generate data as a set of triplets (a, b, c): they may represent that user a called b at time c or that customer a purchased product b in store c. These datasets are traditionally studied as networks with an extra dimension (time or layer), for which the fields of temporal and multiplex networks have extended graph theory to account for the new dimension. However, such frameworks detach one variable from the others and allow to extend one same concept in many ways, making it hard to capture patterns across all dimensions and to identify the best definitions for a given dataset. This extended abstract overrides this vision and proposes a direct processing of the set of triplets. In particular, our work shows that a more general analysis is possible by partitioning the data and building categorical propositions that encode informative patterns. We show that several concepts from graph theory can be framed under this formalism and leverage such insights to extend the concepts to data triplets. Lastly, we propose an algorithm to list propositions satisfying specific constraints and apply it to a real world dataset. ",
    "url": "https://arxiv.org/abs/2110.02543",
    "authors": [
      "Esteban Bautista",
      "Matthieu Latapy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.02626",
    "title": "A multi-order smoothed particle hydrodynamics method for cardiac  electromechanics with the Purkinje network",
    "abstract": "In previous work, Zhang et al. (2021) \\cite{zhang2021integrative} developed an integrated smoothed particle hydrodynamics (SPH) method to simulate the principle aspects of cardiac function, including electrophysiology, passive and active mechanical response of the myocardium. As the inclusion of the Purkinje network in electrocardiology is recognized as fundamental to accurately describing the electrical activation in the right and left ventricles, in this paper, we present a multi-order SPH method to handle the electrical propagation through the Purkinje system and in the myocardium with monodomain/monodomain coupling strategy. We first propose an efficient algorithm for network generation on arbitrarily complex surface by exploiting level-set geometry representation and cell-linked list neighbor search algorithm. Then, a reduced-order SPH method is developed to solve the one-dimensional monodomain equation to characterize the fast electrical activation through the Purkinje network. Finally, a multi-order coupling paradigm is introduced to capture the coupled nature of potential propagation arising from the interaction between the network and the myocardium. A set of numerical examples are studied to assess the computational performance, accuracy and versatility of the proposed methods. In particular, numerical study performed in realistic left ventricle demonstrates that the present method features all the physiological issues that characterize a heartbeat simulation, including the initiation of the signal in the Purkinje network and the systolic and diastolic phases. As expected, the results underlie the importance of using physiologically realistic Purkinje network for modeling cardiac functions. ",
    "url": "https://arxiv.org/abs/2110.02626",
    "authors": [
      "Chi Zhang",
      "Hao Gao",
      "Xiangyu Hu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2110.02670",
    "title": "S-Extension Patch: A simple and efficient way to extend an object  detection model",
    "abstract": "While building convolutional network-based systems, the toll it takes to train the network is something that cannot be ignored. In cases where we need to append additional capabilities to the existing model, the attention immediately goes towards retraining techniques. In this paper, I show how to leverage knowledge about the dataset to append the class faster while maintaining the speed of inference as well as the accuracies; while reducing the amount of time and data required. The method can extend a class in the existing object detection model in 1/10th of the time compared to the other existing methods. S-Extension patch not only offers faster training but also speed and ease of adaptation, as it can be appended to any existing system, given it fulfills the similarity threshold condition. ",
    "url": "https://arxiv.org/abs/2110.02670",
    "authors": [
      "Dishant Parikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02700",
    "title": "Reversible adversarial examples against local visual perturbation",
    "abstract": "Recently, studies have indicated that adversarial attacks pose a threat to deep learning systems. However, when there are only adversarial examples, people cannot get the original images, so there is research on reversible adversarial attacks. However, the existing strategies are aimed at invisible adversarial perturbation, and do not consider the case of locally visible adversarial perturbation. In this article, we generate reversible adversarial examples for local visual adversarial perturbation, and use reversible data embedding technology to embed the information needed to restore the original image into the adversarial examples to generate examples that are both adversarial and reversible. Experiments on ImageNet dataset show that our method can restore the original image losslessly while ensuring the attack capability. ",
    "url": "https://arxiv.org/abs/2110.02700",
    "authors": [
      "Zhaoxia Yin",
      "Li Chen",
      "Shaowei Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.02708",
    "title": "Application of the interactive Leipzig Corpus Miner as a generic  research platform for the use in the social sciences",
    "abstract": "This article introduces to the interactive Leipzig Corpus Miner (iLCM) - a newly released, open-source software to perform automatic content analysis. Since the iLCM is based on the R-programming language, its generic text mining procedures provided via a user-friendly graphical user interface (GUI) can easily be extended using the integrated IDE RStudio-Server or numerous other interfaces in the tool. Furthermore, the iLCM offers various possibilities to use quantitative and qualitative research approaches in combination. Some of these possibilities will be presented in more detail in the following. ",
    "url": "https://arxiv.org/abs/2110.02708",
    "authors": [
      "Christian Kahmann",
      "Andreas Niekler",
      "Gregor Wiedemann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.02709",
    "title": "Subquadratic-time algorithm for the diameter and all eccentricities on  median graphs",
    "abstract": "On sparse graphs, Roditty and Williams [2013] proved that no $O(n^{2-\\varepsilon})$-time algorithm achieves an approximation factor smaller than $\\frac{3}{2}$ for the diameter problem unless SETH fails. In this article, we solve a longstanding question: can we use the structural properties of median graphs to break this global quadratic barrier? We propose the first combinatiorial algorithm computing exactly all eccentricities of a median graph in truly subquadratic time. Median graphs constitute the family of graphs which is the most studied in metric graph theory because their structure represent many other discrete and geometric concepts, such as CAT(0) cube complexes. Our result generalizes a recent one, stating that there is a linear-time algorithm for all eccentricities in median graphs with bounded dimension $d$, i.e. the dimension of the largest induced hypercube. This prerequisite on $d$ is not necessarily anymore to determine all eccentricities in subquadratic time. The execution time of our algorithm is $O(n^{1.6456}\\log^{O(1)} n)$. We provide also some satellite outcomes related to this general result. In particular, restricted to simplex graphs, this algorithm enumerate all eccentricities with a quasilinear running time. Moreover, an algorithm is proposed to compute exactly all reach centralities in time $O(2^{3d}n\\log^{O(1)}n)$. ",
    "url": "https://arxiv.org/abs/2110.02709",
    "authors": [
      "Pierre Berg\u00e9",
      "Guillaume Ducoffe",
      "Michel Habib"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2110.02753",
    "title": "Semi-relaxed Gromov Wasserstein divergence with applications on graphs",
    "abstract": "Comparing structured objects such as graphs is a fundamental operation involved in many learning tasks. To this end, the Gromov-Wasserstein (GW) distance, based on Optimal Transport (OT), has proven to be successful in handling the specific nature of the associated objects. More specifically, through the nodes connectivity relations, GW operates on graphs, seen as probability measures over specific spaces. At the core of OT is the idea of conservation of mass, which imposes a coupling between all the nodes from the two considered graphs. We argue in this paper that this property can be detrimental for tasks such as graph dictionary or partition learning, and we relax it by proposing a new semi-relaxed Gromov-Wasserstein divergence. Aside from immediate computational benefits, we discuss its properties, and show that it can lead to an efficient graph dictionary learning algorithm. We empirically demonstrate its relevance for complex tasks on graphs such as partitioning, clustering and completion. ",
    "url": "https://arxiv.org/abs/2110.02753",
    "authors": [
      "C\u00e9dric Vincent-Cuaz",
      "R\u00e9mi Flamary",
      "Marco Corneli",
      "Titouan Vayer",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02951",
    "title": "Video Autoencoder: self-supervised disentanglement of static 3D  structure and motion",
    "abstract": "A video autoencoder is proposed for learning disentan- gled representations of 3D structure and camera pose from videos in a self-supervised manner. Relying on temporal continuity in videos, our work assumes that the 3D scene structure in nearby video frames remains static. Given a sequence of video frames as input, the video autoencoder extracts a disentangled representation of the scene includ- ing: (i) a temporally-consistent deep voxel feature to represent the 3D structure and (ii) a 3D trajectory of camera pose for each frame. These two representations will then be re-entangled for rendering the input video frames. This video autoencoder can be trained directly using a pixel reconstruction loss, without any ground truth 3D or camera pose annotations. The disentangled representation can be applied to a range of tasks, including novel view synthesis, camera pose estimation, and video generation by motion following. We evaluate our method on several large- scale natural video datasets, and show generalization results on out-of-domain images. ",
    "url": "https://arxiv.org/abs/2110.02951",
    "authors": [
      "Zihang Lai",
      "Sifei Liu",
      "Alexei A. Efros",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02297",
    "title": "Robustness modularity in complex networks",
    "abstract": "A basic question in network community detection is how modular a given network is. This is usually addressed by evaluating the quality of partitions detected in the network. The Girvan-Newman (GN) modularity function is the standard way to make this assessment, but it has a number of drawbacks. Most importantly, it is not clearly interpretable, given that the measure can take relatively large values on partitions of random networks without communities. Here we propose a new measure based on the concept of robustness: modularity is the probability to find trivial partitions when the structure of the network is randomly perturbed. This concept can be implemented for any clustering algorithm capable of telling when a group structure is absent. Tests on artificial and real graphs reveal that robustness modularity can be used to assess and compare the strength of the community structure of different networks. We also introduce two other quality functions: modularity difference, a suitably normalized version of the GN modularity; information modularity, a measure of distance based on information compression. Both measures are strongly correlated with robustness modularity, and are promising options as well. ",
    "url": "https://arxiv.org/abs/2110.02297",
    "authors": [
      "Filipi N. Silva",
      "Aiiad Albeshri",
      "Vijey Thayananthan",
      "Wadee Alhalabi",
      "Santo Fortunato"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2110.02456",
    "title": "VC dimension of partially quantized neural networks in the  overparametrized regime",
    "abstract": "Vapnik-Chervonenkis (VC) theory has so far been unable to explain the small generalization error of overparametrized neural networks. Indeed, existing applications of VC theory to large networks obtain upper bounds on VC dimension that are proportional to the number of weights, and for a large class of networks, these upper bound are known to be tight. In this work, we focus on a class of partially quantized networks that we refer to as hyperplane arrangement neural networks (HANNs). Using a sample compression analysis, we show that HANNs can have VC dimension significantly smaller than the number of weights, while being highly expressive. In particular, empirical risk minimization over HANNs in the overparametrized regime achieves the minimax rate for classification with Lipschitz posterior class probability. We further demonstrate the expressivity of HANNs empirically. On a panel of 121 UCI datasets, overparametrized HANNs match the performance of state-of-the-art full-precision models. ",
    "url": "https://arxiv.org/abs/2110.02456",
    "authors": [
      "Yutong Wang",
      "Clayton D. Scott"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02743",
    "title": "Towards efficient end-to-end speech recognition with  biologically-inspired neural networks",
    "abstract": "Automatic speech recognition (ASR) is a capability which enables a program to process human speech into a written form. Recent developments in artificial intelligence (AI) have led to high-accuracy ASR systems based on deep neural networks, such as the recurrent neural network transducer (RNN-T). However, the core components and the performed operations of these approaches depart from the powerful biological counterpart, i.e., the human brain. On the other hand, the current developments in biologically-inspired ASR models, based on spiking neural networks (SNNs), lag behind in terms of accuracy and focus primarily on small scale applications. In this work, we revisit the incorporation of biologically-plausible models into deep learning and we substantially enhance their capabilities, by taking inspiration from the diverse neural and synaptic dynamics found in the brain. In particular, we introduce neural connectivity concepts emulating the axo-somatic and the axo-axonic synapses. Based on this, we propose novel deep learning units with enriched neuro-synaptic dynamics and integrate them into the RNN-T architecture. We demonstrate for the first time, that a biologically realistic implementation of a large-scale ASR model can yield competitive performance levels compared to the existing deep learning models. Specifically, we show that such an implementation bears several advantages, such as a reduced computational cost and a lower latency, which are critical for speech recognition applications. ",
    "url": "https://arxiv.org/abs/2110.02743",
    "authors": [
      "Thomas Bohnstingl",
      "Ayush Garg",
      "Stanis\u0142aw Wo\u017aniak",
      "George Saon",
      "Evangelos Eleftheriou",
      "Angeliki Pantazi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2110.02798",
    "title": "Dynamics of hot random hyperbolic graphs",
    "abstract": "We derive the most basic dynamical properties of random hyperbolic graphs (the distributions of contact and intercontact durations) in the hot regime (network temperature $T > 1$). We show that in the thermodynamic limit the contact distribution decays as a power law with exponent $2+T > 3$ for durations $t > T$, while for $t < T$ it exhibits exponential-like decays. This result holds irrespective of the expected degree distribution, as long as it has a finite $T^{\\text{th}}$ moment. Otherwise, the contact distribution depends on the expected degree distribution and we show that if the latter is a power law with exponent $\\gamma \\in (2, T+1]$, then the former decays as a power law with exponent $\\gamma+1 > 3$. On the other hand, the intercontact distribution exhibits power-law decays with exponent $2-T \\in (0, 1)$ for $T \\in (1,2)$, while for $T > 2$ it displays linear decays with a slope that depends on the observation interval. This result holds irrespective of the expected degree distribution as long as it has a finite $T^{\\text{th}}$ moment if $T \\in (1,2)$, or a finite second moment if $T > 2$. Otherwise, the intercontact distribution depends on the expected degree distribution and if the latter is a power law with exponent $\\gamma \\in (2, 3)$, then the former decays as a power law with exponent $3-\\gamma \\in (0,1)$. Thus, hot random hyperbolic graphs can give rise to contact and intercontact distributions that both decay as power laws. These power laws however are unrealistic for the case of the intercontact distribution, as their exponent is always less than one. These results suggest that hot random hyperbolic graphs are not adequate null models for real temporal networks, in stark contrast to cold random hyperbolic graphs ($T < 1$). Since the configuration model emerges at $T \\to \\infty$, these results also suggest that this is not an adequate null temporal network model either. ",
    "url": "https://arxiv.org/abs/2110.02798",
    "authors": [
      "Fragkiskos Papadopoulos",
      "Sofoclis Zambirinis"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2110.02836",
    "title": "Beyond quadratic speedups in quantum attacks on symmetric schemes",
    "abstract": "In this paper, we report the first quantum key-recovery attack on a symmetric block cipher design, using classical queries only, with a more than quadratic time speedup compared to the best classical attack. We study the 2XOR-Cascade construction of Ga\\v{z}i and Tessaro (EUROCRYPT~2012). It is a key length extension technique which provides an n-bit block cipher with 5n/2 bits of security out of an n-bit block cipher with 2n bits of key, with a security proof in the ideal model. We show that the offline-Simon algorithm of Bonnetain et al. (ASIACRYPT~2019) can be extended to, in particular, attack this construction in quantum time \\~O($2^n$), providing a 2.5 quantum speedup over the best classical attack. Regarding post-quantum security of symmetric ciphers, it is commonly assumed that doubling the key sizes is a sufficient precaution. This is because Grover's quantum search algorithm, and its derivatives, can only reach a quadratic speedup at most. Our attack shows that the structure of some symmetric constructions can be exploited to overcome this limit. In particular, the 2XOR-Cascade cannot be used to generically strengthen block ciphers against quantum adversaries, as it would offer only the same security as the block cipher itself. ",
    "url": "https://arxiv.org/abs/2110.02836",
    "authors": [
      "Xavier Bonnetain",
      "Andr\u00e9 Schrottenloher",
      "Ferdinand Sibleyras"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.02885",
    "title": "Bayesian neural network unit priors and generalized Weibull-tail  property",
    "abstract": "The connection between Bayesian neural networks and Gaussian processes gained a lot of attention in the last few years. Hidden units are proven to follow a Gaussian process limit when the layer width tends to infinity. Recent work has suggested that finite Bayesian neural networks may outperform their infinite counterparts because they adapt their internal representations flexibly. To establish solid ground for future research on finite-width neural networks, our goal is to study the prior induced on hidden units. Our main result is an accurate description of hidden units tails which shows that unit priors become heavier-tailed going deeper, thanks to the introduced notion of generalized Weibull-tail. This finding sheds light on the behavior of hidden units of finite Bayesian neural networks. ",
    "url": "https://arxiv.org/abs/2110.02885",
    "authors": [
      "Mariia Vladimirova",
      "Julyan Arbel",
      "St\u00e9phane Girard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02952",
    "title": "Hierarchical prosody modeling and control in non-autoregressive parallel  neural TTS",
    "abstract": "Neural text-to-speech (TTS) synthesis can generate speech that is indistinguishable from natural speech. However, the synthetic speech often represents the average prosodic style of the database instead of having more versatile prosodic variation. Moreover, many models lack the ability to control the output prosody, which does not allow for different styles for the same text input. In this work, we train a non-autoregressive parallel neural TTS model hierarchically conditioned on both coarse and fine-grained acoustic speech features to learn a latent prosody space with intuitive and meaningful dimensions. Experiments show that a non-autoregressive TTS model hierarchically conditioned on utterance-wise pitch, pitch range, duration, energy, and spectral tilt can effectively control each prosodic dimension, generate a wide variety of speaking styles, and provide word-wise emphasis control, while maintaining equal or better quality to the baseline model. ",
    "url": "https://arxiv.org/abs/2110.02952",
    "authors": [
      "Tuomo Raitio",
      "Jiangchuan Li",
      "Shreyas Seshadri"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:1710.06611",
    "title": "On community structure validation in real networks",
    "abstract": " Comments: The article is now published in Computational Statistics (with Open Access), see this https URL ",
    "url": "https://arxiv.org/abs/1710.06611",
    "authors": [
      "Mirko Signorelli",
      "Luisa Cutillo"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2003.03658",
    "title": "Securing LSB embedding against structural steganalysis",
    "abstract": " Comments: 23 pages, 6 figures. Section 3 added; revisions made to Section 6.3. Version accepted by Journal of Computer Security ",
    "url": "https://arxiv.org/abs/2003.03658",
    "authors": [
      "Brian A. Powell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2011.11734",
    "title": "Learnable Gabor modulated complex-valued networks for orientation  robustness",
    "abstract": " Comments: Submitted to Pattern Recognition ",
    "url": "https://arxiv.org/abs/2011.11734",
    "authors": [
      "Felix Richards",
      "Adeline Paiement",
      "Xianghua Xie",
      "Elisabeth Sola",
      "Pierre-Alain Duc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.03741",
    "title": "Stability of discrete-time feed-forward neural networks in NARX  configuration",
    "abstract": " Comments: Copyright 2021 by the authors. This work has been accepted to IFAC (19th IFAC Symposium on System Identification: learning models for decision and control) for publication under a Creative Commons Licence CC-BY-NC-ND. Published article: this https URL ",
    "url": "https://arxiv.org/abs/2012.03741",
    "authors": [
      "Fabio Bonassi",
      "Marcello Farina",
      "Riccardo Scattolini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2107.05747",
    "title": "SoftHebb: Bayesian inference in unsupervised Hebbian soft  winner-take-all networks",
    "abstract": " Title: SoftHebb: Bayesian inference in unsupervised Hebbian soft  winner-take-all networks ",
    "url": "https://arxiv.org/abs/2107.05747",
    "authors": [
      "Timoleon Moraitis",
      "Dmitry Toichkin",
      "Yansong Chua",
      "Qinghai Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2109.01451",
    "title": "Impact of GPU uncertainty on the training of predictive deep neural  networks",
    "abstract": " Comments: The results obtained in Chainer did not replicate with a different python library, pointing to a software bug rather than hardware cause. The title and discussion of the paper are therefore irrelevant to the real cause ",
    "url": "https://arxiv.org/abs/2109.01451",
    "authors": [
      "Maciej Pietrowski",
      "Andrzej Gajda",
      "Takuto Yamamoto",
      "Taisuke Kobayashi",
      "Lana Sinapayen",
      "Eiji Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2109.07826",
    "title": "Directed degree corrected mixed membership model and estimating  community memberships in directed networks",
    "abstract": " Title: Directed degree corrected mixed membership model and estimating  community memberships in directed networks ",
    "url": "https://arxiv.org/abs/2109.07826",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.11735",
    "title": "On the Robustness of \"Robust reversible data hiding scheme based on  two-layer embedding strategy\"",
    "abstract": " Title: On the Robustness of \"Robust reversible data hiding scheme based on  two-layer embedding strategy\" ",
    "url": "https://arxiv.org/abs/2109.11735",
    "authors": [
      "Wen Yin",
      "Longfei Ke",
      "Zhaoxia Yin",
      "Jin Tang",
      "Bin Luo"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2109.12827",
    "title": "Experimental symmetric private information retrieval with  measurement-device-independent quantum network",
    "abstract": " Title: Experimental symmetric private information retrieval with  measurement-device-independent quantum network ",
    "url": "https://arxiv.org/abs/2109.12827",
    "authors": [
      "Chao Wang",
      "Wen Yu Kon",
      "Hong Jie Ng",
      "Charles C.-W. Lim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.00993",
    "title": "On monoid graphs",
    "abstract": " Comments: 22 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2110.00993",
    "authors": [
      "Kolja Knauer",
      "Gil Puig i Surroca"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2110.01434",
    "title": "A curated, ontology-based, large-scale knowledge graph of artificial  intelligence tasks and benchmarks",
    "abstract": " Title: A curated, ontology-based, large-scale knowledge graph of artificial  intelligence tasks and benchmarks ",
    "url": "https://arxiv.org/abs/2110.01434",
    "authors": [
      "Kathrin Blagec",
      "Adriano Barbosa-Silva",
      "Simon Ott",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.02176",
    "title": "Machine learning attack on copy detection patterns: are 1x1 patterns  cloneable?",
    "abstract": " Title: Machine learning attack on copy detection patterns: are 1x1 patterns  cloneable? ",
    "url": "https://arxiv.org/abs/2110.02176",
    "authors": [
      "Roman Chaban",
      "Olga Taran",
      "Joakim Tutt",
      "Taras Holotyak",
      "Slavi Bonev",
      "Slava Voloshynovskiy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]