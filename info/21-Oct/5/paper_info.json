[
  {
    "id": "arXiv:2110.00587",
    "title": "Sentiment and structure in word co-occurrence networks on Twitter",
    "abstract": "We explore the relationship between context and happiness scores in political tweets using word co-occurrence networks, where nodes in the network are the words, and the weight of an edge is the number of tweets in the corpus for which the two connected words co-occur. In particular, we consider tweets with hashtags #imwithher and #crookedhillary, both relating to Hillary Clinton's presidential bid in 2016. We then analyze the network properties in conjunction with the word scores by comparing with null models to separate the effects of the network structure and the score distribution. Neutral words are found to be dominant and most words, regardless of polarity, tend to co-occur with neutral words. We do not observe any score homophily among positive and negative words. However, when we perform network backboning, community detection results in word groupings with meaningful narratives, and the happiness scores of the words in each group correspond to its respective theme. Thus, although we observe no clear relationship between happiness scores and co-occurrence at the node or edge level, a community-centric approach can isolate themes of competing sentiments in a corpus. ",
    "url": "https://arxiv.org/abs/2110.00587",
    "authors": [
      "Mikaela Irene Fudolig",
      "Thayer Alshaabi",
      "Michael V. Arnold",
      "Christopher M. Danforth",
      "Peter Sheridan Dodds"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2110.00601",
    "title": "Album: a framework for scientific data processing with software  solutions of heterogeneous tools",
    "abstract": "Album is a decentralized distribution platform for solutions to specific scientific problems. It works across platforms, tools, and data domains and is designed to address limitations in reproducibility of scientific data software solutions and workflows, particularly when interactivity is needed. `album` can be used to programmatically define how to interoperate between applications. It can ship versatile applications while tweaking them for a specific target audience or use case. An updated list of features and applications can be found on the documentation site. ",
    "url": "https://arxiv.org/abs/2110.00601",
    "authors": [
      "Jan Philipp Albrecht",
      "Deborah Schmidt",
      "Kyle Harrington"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2110.00652",
    "title": "Application of Social Network Analysis in Evaluating Risk and network  resilience of Closed-Loop-Supply-Chain",
    "abstract": "Closed Loop Supply Chain (CLSC) networks are an attractive topic in both industry and academic research due to their positive environmental effects and waste reduction. Performance evaluation of CLSC networks is challenging due to the variety of facility types and complex relationships among them. In this study, a framework based on Social Network Analysis (SNA) is proposed to evaluate the individual components of a network and identify the critical facilities whose disruptions can affect the entire network. The proposed SNA metrics are applied to a CLSC network case study based on real data and the results and their interpretation are presented. Practical recommendations and actionable guidelines are provided are provided based on the results to mitigate the identified risks and improve the flexibility and resilience of the network. The SNAinSCM R package is developed and shared on GitHub to facilitate the computation and visualization of the discussed metrics ",
    "url": "https://arxiv.org/abs/2110.00652",
    "authors": [
      "Sara Akbar Ghanadian",
      "Saeed Ghanbartehrani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2110.00683",
    "title": "Learning through atypical ''phase transitions'' in overparameterized  neural networks",
    "abstract": "Current deep neural networks are highly overparameterized (up to billions of connection weights) and nonlinear. Yet they can fit data almost perfectly through variants of gradient descent algorithms and achieve unexpected levels of prediction accuracy without overfitting. These are formidable results that escape the bias-variance predictions of statistical learning and pose conceptual challenges for non-convex optimization. In this paper, we use methods from statistical physics of disordered systems to analytically study the computational fallout of overparameterization in nonconvex neural network models. As the number of connection weights increases, we follow the changes of the geometrical structure of different minima of the error loss function and relate them to learning and generalisation performance. We find that there exist a gap between the SAT/UNSAT interpolation transition where solutions begin to exist and the point where algorithms start to find solutions, i.e. where accessible solutions appear. This second phase transition coincides with the discontinuous appearance of atypical solutions that are locally extremely entropic, i.e., flat regions of the weight space that are particularly solution-dense and have good generalization properties. Although exponentially rare compared to typical solutions (which are narrower and extremely difficult to sample), entropic solutions are accessible to the algorithms used in learning. We can characterize the generalization error of different solutions and optimize the Bayesian prediction, for data generated from a structurally different network. Numerical tests on observables suggested by the theory confirm that the scenario extends to realistic deep networks. ",
    "url": "https://arxiv.org/abs/2110.00683",
    "authors": [
      "Carlo Baldassi",
      "Clarissa Lauditi",
      "Enrico M. Malatesta",
      "Rosalba Pacelli",
      "Gabriele Perugini",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.00692",
    "title": "Decomposing a graph into subgraphs with small components",
    "abstract": "The component size of a graph is the maximum number of edges in any connected component of the graph. Given a graph $G$ and two integers $k$ and $c$, $(k,c)$-Decomposition is the problem of deciding whether $G$ admits an edge partition into $k$ subgraphs with component size at most $c$. We prove that for any fixed $k \\ge 2$ and $c \\ge 2$, $(k,c)$-Decomposition is NP-complete in bipartite graphs. Also, when both $k$ and $c$ are part of the input, $(k,c)$-Decomposition is NP-complete even in trees. Moreover, $(k,c)$-Decomposition in trees is W[1]-hard with parameter $k$, and is FPT with parameter $c$. In addition, we present approximation algorithms for decomposing a tree either into the minimum number of subgraphs with component size at most $c$, or into $k$ subgraphs minimizing the maximum component size. En route to these results, we also obtain a fixed-parameter algorithm for Bin Packing with the bin capacity as parameter. ",
    "url": "https://arxiv.org/abs/2110.00692",
    "authors": [
      "Rain Jiang",
      "Kai Jiang",
      "Minghui Jiang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2110.00917",
    "title": "Binary code optimization",
    "abstract": "This article shows that any type of binary data can be defined as a collection from codewords of variable length. This feature helps us to define an Injective and surjective function from the suggested codewords to the required codewords. Therefore, by replacing the new codewords, the binary data becomes another binary data regarding the intended goals. One of these goals is to reduce data size. It means that instead of the original codewords of each binary data, it replaced the Huffman codewords to reduce the data size. One of the features of this method is the result of positive compression for any type of binary data, that is, regardless of the size of the code table, the difference between the original data size and the data size after compression will be greater than or equal to zero. Another important and practical feature of this method is the use of symmetric codewords instead of the suggested codewords in order to create symmetry, reversibility and error resistance properties with two-way decoding. ",
    "url": "https://arxiv.org/abs/2110.00917",
    "authors": [
      "Parviz Gharehbagheri",
      "Sayeed Hamid Haji Sayeed Javadi",
      "Parvaneh Asghari",
      "Naser Gharehbagheri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.01186",
    "title": "The state-of-the-art in text-based automatic personality prediction",
    "abstract": "Personality detection is an old topic in psychology and Automatic Personality Prediction (or Perception) (APP) is the automated (computationally) forecasting of the personality on different types of human generated/exchanged contents (such as text, speech, image, video). The principal objective of this study is to offer a shallow (overall) review of natural language processing approaches on APP since 2010. With the advent of deep learning and following it transfer-learning and pre-trained model in NLP, APP research area has been a hot topic, so in this review, methods are categorized into three; pre-trained independent, pre-trained model based, multimodal approaches. Also, to achieve a comprehensive comparison, reported results are informed by datasets. ",
    "url": "https://arxiv.org/abs/2110.01186",
    "authors": [
      "Ali-Reza Feizi-Derakhshi",
      "Mohammad-Reza Feizi-Derakhshi",
      "Majid Ramezani",
      "Narjes Nikzad-Khasmakhi",
      "Meysam Asgari-Chenaghlu",
      "Taymaz Akan",
      "Mehrdad Ranjbar-Khadivi",
      "Elnaz Zafarni-Moattar",
      "Zoleikha Jahanbakhsh-Naghadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.01261",
    "title": "Scaling Graph-based Deep Learning models to larger networks",
    "abstract": "Graph Neural Networks (GNN) have shown a strong potential to be integrated into commercial products for network control and management. Early works using GNN have demonstrated an unprecedented capability to learn from different network characteristics that are fundamentally represented as graphs, such as the topology, the routing configuration, or the traffic that flows along a series of nodes in the network. In contrast to previous solutions based on Machine Learning (ML), GNN enables to produce accurate predictions even in other networks unseen during the training phase. Nowadays, GNN is a hot topic in the Machine Learning field and, as such, we are witnessing great efforts to leverage its potential in many different fields (e.g., chemistry, physics, social networks). In this context, the Graph Neural Networking challenge 2021 brings a practical limitation of existing GNN-based solutions for networking: the lack of generalization to larger networks. This paper approaches the scalability problem by presenting a GNN-based solution that can effectively scale to larger networks including higher link capacities and aggregated traffic on links. ",
    "url": "https://arxiv.org/abs/2110.01261",
    "authors": [
      "Miquel Ferriol-Galm\u00e9s",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Krzysztof Rusek",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.01322",
    "title": "What is understandable in Bayesian network explanations?",
    "abstract": "Explaining predictions from Bayesian networks, for example to physicians, is non-trivial. Various explanation methods for Bayesian network inference have appeared in literature, focusing on different aspects of the underlying reasoning. While there has been a lot of technical research, there is very little known about how well humans actually understand these explanations. In this paper, we present ongoing research in which four different explanation approaches were compared through a survey by asking a group of human participants to interpret the explanations. ",
    "url": "https://arxiv.org/abs/2110.01322",
    "authors": [
      "Raphaela Butz",
      "Ren\u00e9e Schulz",
      "Arjen Hommersom",
      "Marko van Eekelen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.01359",
    "title": "CENN: Conservative energy method based on neural network with subdomains  for solving heterogeneous problems involving complex geometries",
    "abstract": "We propose a conservative energy method based on a neural network with subdomains (CENN), where the admissible function satisfying the essential boundary condition without boundary penalty is constructed by the radial basis function, particular solution neural network, and general neural network. The loss term at the interfaces has the lower order derivative compared to the strong form PINN with subdomains. We apply the proposed method to some representative examples to demonstrate the ability of the proposed method to model strong discontinuity, singularity, complex boundary, non-linear, and heterogeneous PDE problems. The advantage of the method is the efficiency and accuracy compared to the strong form PINN. It is worth emphasizing that the method has a natural advantage in dealing with heterogeneous problems. ",
    "url": "https://arxiv.org/abs/2110.01359",
    "authors": [
      "Yizheng Wang",
      "Jia Sun",
      "Xiang Li",
      "Yinghua Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.01374",
    "title": "Hybrid quadrature moment method for accurate and stable representation  of non-Gaussian processes and their dynamics",
    "abstract": "Solving the population balance equation (PBE) for the dynamics of a dispersed phase coupled to a continuous fluid is expensive. Still, one can reduce the cost by representing the evolving particle density function in terms of its moments. In particular, quadrature-based moment methods (QBMMs) invert these moments with a quadrature rule, approximating the required statistics. QBMMs have been shown to accurately model sprays and soot with a relatively compact set of moments. However, significantly non-Gaussian processes such as bubble dynamics lead to numerical instabilities when extending their moment sets accordingly. We solve this problem by training a recurrent neural network (RNN) that adjusts the QBMM quadrature to evaluate unclosed moments with higher accuracy. The proposed method is tested on a simple model of bubbles oscillating in response to a temporally fluctuating pressure field. The approach decreases model-form error by a factor of 10 when compared to traditional QBMMs. It is both numerically stable and computationally efficient since it does not expand the baseline moment set. Additional quadrature points are also assessed, optimally placed and weighted according to an additional RNN. These points further decrease the error at low cost since the moment set is again unchanged. ",
    "url": "https://arxiv.org/abs/2110.01374",
    "authors": [
      "Alexis-Tzianni Charalampopoulos",
      "Spencer H. Bryngelson",
      "Tim Colonius",
      "Themistoklis P. Sapsis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2110.01384",
    "title": "Simulated annealing for optimization of graphs and sequences",
    "abstract": "Optimization of discrete structures aims at generating a new structure with the better property given an existing one, which is a fundamental problem in machine learning. Different from the continuous optimization, the realistic applications of discrete optimization (e.g., text generation) are very challenging due to the complex and long-range constraints, including both syntax and semantics, in discrete structures. In this work, we present SAGS, a novel Simulated Annealing framework for Graph and Sequence optimization. The key idea is to integrate powerful neural networks into metaheuristics (e.g., simulated annealing, SA) to restrict the search space in discrete optimization. We start by defining a sophisticated objective function, involving the property of interest and pre-defined constraints (e.g., grammar validity). SAGS searches from the discrete space towards this objective by performing a sequence of local edits, where deep generative neural networks propose the editing content and thus can control the quality of editing. We evaluate SAGS on paraphrase generation and molecule generation for sequence optimization and graph optimization, respectively. Extensive results show that our approach achieves state-of-the-art performance compared with existing paraphrase generation methods in terms of both automatic and human evaluations. Further, SAGS also significantly outperforms all the previous methods in molecule generation. ",
    "url": "https://arxiv.org/abs/2110.01384",
    "authors": [
      "Xianggen Liu",
      "Pengyong Li",
      "Fandong Meng",
      "Hao Zhou",
      "Huasong Zhong",
      "Jie Zhou",
      "Lili Mou",
      "Sen Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.01421",
    "title": "Unraveling the graph structure of tabular datasets through Bayesian and  spectral analysis",
    "abstract": "In the big-data age tabular datasets are being generated and analyzed everywhere. As a consequence, finding and understanding the relationships between the features of these datasets are of great relevance. Here, to encompass these relationships we propose a methodology that maps an entire tabular dataset or just an observation into a weighted directed graph using the Shapley additive explanations technique. With this graph of relationships, we show that the inference of the hierarchical modular structure obtained by the nested stochastic block model (nSBM) as well as the study of the spectral space of the magnetic Laplacian can help us identify the classes of features and unravel non-trivial relationships. As a case study, we analyzed a socioeconomic survey conducted with students in Brazil: the PeNSE survey. The spectral embedding of the columns suggested that questions related to physical activities form a separate group. The application of the nSBM approach, corroborated with that and allowed complementary findings about the modular structure: some groups of questions showed a high adherence with the divisions qualitatively defined by the designers of the survey. However, questions from the class \\textit{Safety} were partly grouped by our method in the class \\textit{Drugs}. Surprisingly, by inspecting these questions, we observed that they were related to both these topics, suggesting an alternative interpretation of these questions. Our method can provide guidance for tabular data analysis as well as the design of future surveys. ",
    "url": "https://arxiv.org/abs/2110.01421",
    "authors": [
      "Bruno Messias F. de Resende",
      "Eric K. Tokuda",
      "Luciano da Fontoura Costa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2110.01434",
    "title": "A curated, ontology-based, large-scale knowledge graph of artificial  intelligence tasks and benchmarks",
    "abstract": "Research in artificial intelligence (AI) is addressing a growing number of tasks through a rapidly growing number of models and methodologies. This makes it difficult to keep track of where novel AI methods are successfully -- or still unsuccessfully -- applied, how progress is measured, how different advances might synergize with each other, and how future research should be prioritized. To help address these issues, we created the Intelligence Task Ontology and Knowledge Graph (ITO), a comprehensive, richly structured and manually curated resource on artificial intelligence tasks, benchmark results and performance metrics. The current version of ITO contain 685,560 edges, 1,100 classes representing AI processes and 1,995 properties representing performance metrics. The goal of ITO is to enable precise and network-based analyses of the global landscape of AI tasks and capabilities. ITO is based on technologies that allow for easy integration and enrichment with external data, automated inference and continuous, collaborative expert curation of underlying ontological models. We make the ITO dataset and a collection of Jupyter notebooks utilising ITO openly available. ",
    "url": "https://arxiv.org/abs/2110.01434",
    "authors": [
      "Kathrin Blagec",
      "Simon Ott",
      "Adriano Barbosa da Silva",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.01444",
    "title": "Crashworthiness design of 3D lattice-structure filled thin-walled tubes  based on data mining",
    "abstract": "Lattice structures and thin-walled tubes are two types of energy-absorbers widely studied and applied in engineering practice. In this study, a new type of lattice-structure filled thin-walled tube (LFT) was proposed. In this new type of LFT, a BCC-Z lattice structure was filled into a square thin-walled tube. Then using data mining, a 3-D geometric design with five design variables was conducted on this new LFT. Using Latin Hypercubic sampling algorithm, 150 design cases were generated. Numerical models were then developed to simulate their crush behavior, and the simulation dataset was used for data mining. The results showed that (1) Filling the BBC-Z lattice structure into a thin-walled tube can significantly improve the energy absorption (EA) capacity of the structure. (2) The decision trees generated in the data mining process indicated that the rod diameter d of lattice structure is the key design variable that has most significant impact on EA, followed by m and n. (3) The design rules to build LFTs with high EA efficiency (SEA>=16 kJ/kg and CFE>=45%), high total EA (SEA>=16 kJ/kg and EA>=6 kJ), and lightweight (SEA>=16 kJ/kg and Mass<=0.45 kg) were obtained from decision trees. The ideal configurations of LFT corresponding to these three objectives are: d>2 mm, n>2 and m>3 for high EA efficiency; d>2 mm, n>2 and m>3 for high total EA; and d>2 mm, n>2, m<=4 and t<=1.7 mm for lightweight. ",
    "url": "https://arxiv.org/abs/2110.01444",
    "authors": [
      "Jiyuan Lv",
      "Zhonghao Bai",
      "Xianping Du",
      "Feng Zhu",
      "Clifford C. Chou",
      "Binhui Jiang",
      "Shiwei Xu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.01450",
    "title": "Extended dynamic mode decomposition with dictionary learning using  neural ordinary differential equations",
    "abstract": "Nonlinear phenomena can be analyzed via linear techniques using operator-theoretic approaches. Data-driven method called the extended dynamic mode decomposition (EDMD) and its variants, which approximate the Koopman operator associated with the nonlinear phenomena, have been rapidly developing by incorporating machine learning methods. Neural ordinary differential equations (NODEs), which are a neural network equipped with a continuum of layers, and have high parameter and memory efficiencies, have been proposed. In this paper, we propose an algorithm to perform EDMD using NODEs. NODEs are used to find a parameter-efficient dictionary which provides a good finite-dimensional approximation of the Koopman operator. We show the superiority of the parameter efficiency of the proposed method through numerical experiments. ",
    "url": "https://arxiv.org/abs/2110.01450",
    "authors": [
      "Hiroaki Terao",
      "Sho Shirasaka",
      "Hideyuki Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2110.01536",
    "title": "Universal approximation properties of shallow quadratic neural networks",
    "abstract": "In this paper we propose a new class of neural network functions which are linear combinations of compositions of activation functions with quadratic functions, replacing standard affine linear functions, often called neurons. We show the universality of this approximation and prove convergence rates results based on the theory of wavelets and statistical learning. We investigate the efficiency of our new approach numerically for simple test cases, by showing that it requires less numbers of neurons that standard affine linear neural networks. Similar observations are made when comparing deep (multi-layer) networks. ",
    "url": "https://arxiv.org/abs/2110.01536",
    "authors": [
      "Leon Frischauf",
      "Otmar Scherzer",
      "Cong Shi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.00920",
    "title": "Attention module improves both performance and interpretability of 4D  fMRI decoding neural network",
    "abstract": "Decoding brain cognitive states from neuroimaging signals is an important topic in neuroscience. In recent years, deep neural networks (DNNs) have been recruited for multiple brain state decoding and achieved good performance. However, the open question of how to interpret the DNN black box remains unanswered. Capitalizing on advances in machine learning, we integrated attention modules into brain decoders to facilitate an in-depth interpretation of DNN channels. A 4D convolution operation was also included to extract temporo-spatial interaction within the fMRI signal. The experiments showed that the proposed model obtains a very high accuracy (97.4%) and outperforms previous researches on the 7 different task benchmarks from the Human Connectome Project (HCP) dataset. The visualization analysis further illustrated the hierarchical emergence of task-specific masks with depth. Finally, the model was retrained to regress individual traits within the HCP and to classify viewing images from the BOLD5000 dataset, respectively. Transfer learning also achieves good performance. A further visualization analysis shows that, after transfer learning, low-level attention masks remained similar to the source domain, whereas high-level attention masks changed adaptively. In conclusion, the proposed 4D model with attention module performed well and facilitated interpretation of DNNs, which is helpful for subsequent research. ",
    "url": "https://arxiv.org/abs/2110.00920",
    "authors": [
      "Zhoufan Jiang",
      "Yanming Wang",
      "ChenWei Shi",
      "Yueyang Wu",
      "Rongjie Hu",
      "Shishuo Chen",
      "Sheng Hu",
      "Xiaoxiao Wang",
      "Bensheng Qiu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.00993",
    "title": "On monoid graphs",
    "abstract": "We investigate Cayley graphs of finite semigroups and monoids. First, we look at semigroup digraphs, i.e., directed Cayley graphs of semigroups, and give a Sabidussi-type characterization in the case of monoids. We then correct a proof of Zelinka from '81 that characterizes semigroup digraphs with outdegree $1$. Further, answering a question of Knauer and Knauer, we construct for every $k\\geq 2$ connected $k$-outregular non-semigroup digraphs. On the other hand, we show that every sink-free directed graph is a union of connected components of a monoid digraph. Second, we consider monoid graphs, i.e., underlying simple undirected graphs of Cayley graphs of monoids. We show that forests and threshold graphs form part of this family. Conversely, we construct the -- to our knowledge -- first graphs, that are not monoid graphs. We present non-monoid graphs that are planar, have arboricity $2$, and treewidth $3$ on the one hand, and non-monoid graphs of arbitrarily high connectivity on the other hand. Third, we study generated monoid trees, i.e., trees that are monoid graphs with respect to a generating set. We give necessary and sufficient conditions for a tree to be in this family, allowing us to find large classes of trees inside and outside the family. ",
    "url": "https://arxiv.org/abs/2110.00993",
    "authors": [
      "Kolja Knauer",
      "Gil Puig i Surroca"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2110.01096",
    "title": "Fast algorithm to identify cluster synchrony through fibration  symmetries in large information-processing networks",
    "abstract": "Recent studies revealed an important interplay between the detailed structure of fibration symmetric circuits and the functionality of biological and non-biological networks within which they have be identified. The presence of these circuits in complex networks are directed related to the phenomenon of cluster synchronization, which produces patterns of synchronized group of nodes. Here we present a fast, and memory efficient, algorithm to identify fibration symmetries over information-processing networks. This algorithm is specially suitable for large and sparse networks since it has runtime of complexity $O(M\\log N)$ and requires $O(M+N)$ of memory resources, where $N$ and $M$ are the number of nodes and edges in the network, respectively. We propose a modification on the so-called refinement paradigm to identify circuits symmetrical to information flow (i.e., fibers) by finding the coarsest refinement partition over the network. Finally, we show that the presented algorithm provides an optimal procedure for identifying fibers, overcoming the current approaches used in the literature. ",
    "url": "https://arxiv.org/abs/2110.01096",
    "authors": [
      "Higor S. Monteiro",
      "Ian Leifer",
      "Saulo D. S. Reis",
      "Jos\u00e9 S. Andrade, Jr.",
      "Hernan A. Makse"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:1909.05006",
    "title": "Boltzmann machine learning and regularization methods for inferring  evolutionary fields and couplings from a multiple sequence alignment",
    "abstract": " Comments: In this version (arXiv:1909.05006v3), the values of selective temperature for protein PF00153, $T_s$ in Table 5 and in the section 2.8, and folding free energy for PF00595 are corrected and shown in red. The version 2 (arXiv:1909.05006v2) was published in the IEEE/ACM Transactions on Computational Biology and Bioinformatics. The program is available from this https URL ",
    "url": "https://arxiv.org/abs/1909.05006",
    "authors": [
      "Sanzo Miyazawa"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2001.03124",
    "title": "Cops and robbers on $2K_2$-free graphs",
    "abstract": " Comments: 10 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2001.03124",
    "authors": [
      "J\u00e9r\u00e9mie Turcotte"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2002.10645",
    "title": "Multivariate time-series modeling with generative neural networks",
    "abstract": " Title: Multivariate time-series modeling with generative neural networks ",
    "url": "https://arxiv.org/abs/2002.10645",
    "authors": [
      "Marius Hofert",
      "Avinash Prasad",
      "Mu Zhu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.03151",
    "title": "Hidden Markov models as recurrent neural networks: an application to  Alzheimer's disease",
    "abstract": " Title: Hidden Markov models as recurrent neural networks: an application to  Alzheimer's disease ",
    "url": "https://arxiv.org/abs/2006.03151",
    "authors": [
      "Matt Baucum",
      "Anahita Khojandi",
      "Theodore Papamarkou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2009.13716",
    "title": "Grow-Push-Prune: aligning deep discriminants for effective structural  network compression",
    "abstract": " Title: Grow-Push-Prune: aligning deep discriminants for effective structural  network compression ",
    "url": "https://arxiv.org/abs/2009.13716",
    "authors": [
      "Qing Tian",
      "Tal Arbel",
      "James J. Clark"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.08855",
    "title": "Dissipativity, reciprocity and passive network synthesis: from Jan  Willems' seminal Dissipative Dynamical Systems papers to the present day",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2102.08855",
    "authors": [
      "Timothy H. Hughes",
      "Edward H. Branford"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2103.08294",
    "title": "3D-FFS: Faster 3D object detection with Focused Frustum Search in sensor  fusion based networks",
    "abstract": " Comments: Contains 6 pages and 2 figures. Manuscript accepted and presented in the IEEE International Conference on Intelligent Robots and Systems (IROS) 2021 ",
    "url": "https://arxiv.org/abs/2103.08294",
    "authors": [
      "Aniruddha Ganguly",
      "Tasin Ishmam",
      "Khandker Aftarul Islam",
      "Md Zahidur Rahman",
      "Md. Shamsuzzoha Bayzid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.14430",
    "title": "Combining distribution-based neural networks to predict weather forecast  probabilities",
    "abstract": " Comments: 21 pages, 14 figures, Github repository: this https URL, Submitted to Quarterly Journal of the Royal Meteorological Society ",
    "url": "https://arxiv.org/abs/2103.14430",
    "authors": [
      "Mariana Clare",
      "Omar Jamil",
      "Cyril Morcrette"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2103.16502",
    "title": "Intermittent non-pharmaceutical strategies to mitigate the COVID-19  epidemic in a network model of Italy via constrained optimization",
    "abstract": " Comments: Accepted by Control and Decision Conference 2021 ",
    "url": "https://arxiv.org/abs/2103.16502",
    "authors": [
      "Marco Coraggio",
      "Shihao Xie",
      "Francesco De Lellis",
      "Giovanni Russo",
      "Mario di Bernardo"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2103.17107",
    "title": "Facial expression and attributes recognition based on multi-task  learning of lightweight neural networks",
    "abstract": " Comments: 14 pages, 3 figures, accepted at IEEE SISY 2021 ",
    "url": "https://arxiv.org/abs/2103.17107",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.07671",
    "title": "Implementation of Sprouts: a graph drawing game",
    "abstract": " Comments: Appears in the Proceedings of the 29th International Symposium on Graph Drawing and Network Visualization (GD 2021) ",
    "url": "https://arxiv.org/abs/2108.07671",
    "authors": [
      "Tom\u00e1\u0161 \u010c\u00ed\u017eek",
      "Martin Balko"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2109.13076",
    "title": "Using neural networks to solve the 2D Poisson equation for electric  field computation in plasma fluid simulations",
    "abstract": " Comments: 25 pages, 22 figures; third author name typo corrected ",
    "url": "https://arxiv.org/abs/2109.13076",
    "authors": [
      "Lionel Cheng",
      "Ekhi Ajuria Illarramendi",
      "Guillaume Bogopolsky",
      "Michael Bauerheim",
      "Benedicte Cuenot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2109.14079",
    "title": "Robust recovery of bandlimited graph signals via randomized dynamical  sampling",
    "abstract": " Comments: corrected mistakes in plotting. arXiv admin note: text overlap with arXiv:1511.05118 by other authors ",
    "url": "https://arxiv.org/abs/2109.14079",
    "authors": [
      "Longxiu Huang",
      "Deanna Needell",
      "Sui Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ]
  }
]