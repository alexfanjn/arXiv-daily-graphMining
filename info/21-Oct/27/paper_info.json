[
  {
    "id": "arXiv:2110.13148",
    "title": "As if by magic: self-supervised training of deep despeckling networks  with MERLIN",
    "abstract": "Speckle fluctuations seriously limit the interpretability of synthetic aperture radar (SAR) images. Speckle reduction has thus been the subject of numerous works spanning at least four decades. Techniques based on deep neural networks have recently achieved a new level of performance in terms of SAR image restoration quality. Beyond the design of suitable network architectures or the selection of adequate loss functions, the construction of training sets is of uttermost importance. So far, most approaches have considered a supervised training strategy: the networks are trained to produce outputs as close as possible to speckle-free reference images. Speckle-free images are generally not available, which requires resorting to natural or optical images or the selection of stable areas in long time series to circumvent the lack of ground truth. Self-supervision, on the other hand, avoids the use of speckle-free images. We introduce a self-supervised strategy based on the separation of the real and imaginary parts of single-look complex SAR images, called MERLIN (coMplex sElf-supeRvised despeckLINg), and show that it offers a straightforward way to train all kinds of deep despeckling networks. Networks trained with MERLIN take into account the spatial correlations due to the SAR transfer function specific to a given sensor and imaging mode. By requiring only a single image, and possibly exploiting large archives, MERLIN opens the door to hassle-free as well as large-scale training of despeckling networks. The code of the trained models is made freely available at https://gitlab.telecom-paris.fr/RING/MERLIN. ",
    "url": "https://arxiv.org/abs/2110.13148",
    "authors": [
      "Emanuele Dalsasso",
      "Lo\u00efc Denis",
      "Florence Tupin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2110.13246",
    "title": "Adaptive maximum power point tracking using neural networks for a  photovoltaic systems according grid",
    "abstract": "Introduction. This article deals with the optimization of the energy conversion of a grid-connected photovoltaic system. The novelty is to develop an intelligent maximum power point tracking technique using artificial neural network algorithms. Purpose. Intelligent maximum power point tracking technique is developed in order to improve the photovoltaic system performances under the variations of the temperature and irradiation. Methods. This work is to calculate and follow the maximum power point for a photovoltaic system operating according to the artificial intelligence mechanism is and the latter is used an adaptive modified perturbation and observation maximum power point tracking algorithm based on function sign to generate an specify duty cycle applied to DC-DC converter, where we use the feed forward artificial neural network type trained by Levenberg-Marquardt backpropagation. Results. The photovoltaic system that we chose to simulate and apply this intelligent technique on it is a stand-alone photovoltaic system. According to the results obtained from simulation of the photovoltaic system using adaptive modified perturbation and observation artificial neural network the efficiency and the quality of the production of energy from photovoltaic is increased. Practical value. The proposed algorithm is validated by a dSPACE DS1104 for different operating conditions. All practice results confirm the effectiveness of our proposed algorithm. ",
    "url": "https://arxiv.org/abs/2110.13246",
    "authors": [
      "H. Sahraoui",
      "H. Mellah",
      "S. Drid",
      "L. Chrifi-Alaoui"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.13264",
    "title": "Memory visualization tool for training neural network",
    "abstract": "Software developed helps world a better place ranging from system software, open source, application software and so on. Software engineering does have neural network models applied to code suggestion, bug report summarizing and so on to demonstrate their effectiveness at a real SE task. Software and machine learning algorithms combine to make software give better solutions and understanding of environment. In software, there are both generalized applications which helps solve problems for entire world and also some specific applications which helps one particular community. To address the computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training time. Machine learning algorithms have a greater impact in the world but there is a considerable amount of memory utilization during the process. We propose a new tool for analysis of memory utilized for developing and training deep learning models. Our tool results in visual utilization of memory concurrently. Various parameters affecting the memory utilization are analysed while training. This tool helps in knowing better idea of processes or models which consumes more memory. ",
    "url": "https://arxiv.org/abs/2110.13264",
    "authors": [
      "Mahendran N"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.13297",
    "title": "Fast PDE-constrained optimization via self-supervised operator learning",
    "abstract": "Design and optimal control problems are among the fundamental, ubiquitous tasks we face in science and engineering. In both cases, we aim to represent and optimize an unknown (black-box) function that associates a performance/outcome to a set of controllable variables through an experiment. In cases where the experimental dynamics can be described by partial differential equations (PDEs), such problems can be mathematically translated into PDE-constrained optimization tasks, which quickly become intractable as the number of control variables and the cost of experiments increases. In this work we leverage physics-informed deep operator networks (DeepONets) -- a self-supervised framework for learning the solution operator of parametric PDEs -- to build fast and differentiable surrogates for rapidly solving PDE-constrained optimization problems, even in the absence of any paired input-output training data. The effectiveness of the proposed framework will be demonstrated across different applications involving continuous functions as control or design variables, including time-dependent optimal control of heat transfer, and drag minimization of obstacles in Stokes flow. In all cases, we observe that DeepONets can minimize high-dimensional cost functionals in a matter of seconds, yielding a significant speed up compared to traditional adjoint PDE solvers that are typically costly and limited to relatively low-dimensional control/design parametrizations. ",
    "url": "https://arxiv.org/abs/2110.13297",
    "authors": [
      "Sifan Wang",
      "Mohamed Aziz Bhouri",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2110.13418",
    "title": "Research on the inverse kinematics prediction of a soft actuator via BP  neural network",
    "abstract": "In this work we address the inverse kinetics problem of motion planning of the soft actuators driven by three chambers. Although the mathematical model describing inverse dynamics of this kind of actuator can been employed, this model is still a complex system. On the one hand, the differential equations are nonlinear, therefore, it is very difficult and time consuming to get the analytical solutions. Since the exact solutions of the mechanical model are not available, the elements of the Jacobian matrix cannot be calculated. On the other hand, material model is a complicated system with significant nonlinearity, non-stationarity, and uncertainty, making it challenging to develop an appropriate system model. To overcome these intrinsic problems, we propose a back-propagation (BP) neural network learning the inverse kinetics of the soft manipulator moving in three-dimensional space. After the training, the BP neural network model can represent the relation between the manipulator tip position and the pressures applied to the chambers. The proposed algorithm is very precise, and computationally efficient. The results show that a desired terminal position can be achieved with a degree of accuracy of 2.59% relative average error with respect to the total actuator length, demonstrate the ability of the model to realize inverse kinematic control. ",
    "url": "https://arxiv.org/abs/2110.13418",
    "authors": [
      "Huichen Ma",
      "Junjie Zhou",
      "Jian Zhang",
      "Lingyu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2110.13440",
    "title": "A deep learning driven pseudospectral PCE based FFT homogenization  algorithm for complex microstructures",
    "abstract": "This work is directed to uncertainty quantification of homogenized effective properties for composite materials with complex, three dimensional microstructure. The uncertainties arise in the material parameters of the single constituents as well as in the fiber volume fraction. They are taken into account by multivariate random variables. Uncertainty quantification is achieved by an efficient surrogate model based on pseudospectral polynomial chaos expansion and artificial neural networks. An artificial neural network is trained on synthetic binary voxelized unit cells of composite materials with uncertain three dimensional microstructures, uncertain linear elastic material parameters and different loading directions. The prediction goals of the artificial neural network are the corresponding effective components of the elasticity tensor, where the labels for training are generated via a fast Fourier transform based numerical homogenization method. The trained artificial neural network is then used as a deterministic solver for a pseudospectral polynomial chaos expansion based surrogate model to achieve the corresponding statistics of the effective properties. Three numerical examples deal with the comparison of the presented method to the literature as well as the application to different microstructures. It is shown, that the proposed method is able to predict central moments of interest while being magnitudes faster to evaluate than traditional approaches. ",
    "url": "https://arxiv.org/abs/2110.13440",
    "authors": [
      "Alexander Henkes",
      "Ismail Caylak",
      "Rolf Mahnken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13530",
    "title": "An extended physics informed neural network for preliminary analysis of  parametric optimal control problems",
    "abstract": "In this work we propose an extension of physics informed supervised learning strategies to parametric partial differential equations. Indeed, even if the latter are indisputably useful in many applications, they can be computationally expensive most of all in a real-time and many-query setting. Thus, our main goal is to provide a physics informed learning paradigm to simulate parametrized phenomena in a small amount of time. The physics information will be exploited in many ways, in the loss function (standard physics informed neural networks), as an augmented input (extra feature employment) and as a guideline to build an effective structure for the neural network (physics informed architecture). These three aspects, combined together, will lead to a faster training phase and to a more accurate parametric prediction. The methodology has been tested for several equations and also in an optimal control framework. ",
    "url": "https://arxiv.org/abs/2110.13530",
    "authors": [
      "Nicola Demo",
      "Maria Strazzullo",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.13571",
    "title": "Emotion recognition in talking-face videos using persistent entropy and  neural networks",
    "abstract": "The automatic recognition of a person's emotional state has become a very active research field that involves scientists specialized in different areas such as artificial intelligence, computer vision or psychology, among others. Our main objective in this work is to develop a novel approach, using persistent entropy and neural networks as main tools, to recognise and classify emotions from talking-face videos. Specifically, we combine audio-signal and image-sequence information to compute a topology signature(a 9-dimensional vector) for each video. We prove that small changes in the video produce small changes in the signature. These topological signatures are used to feed a neural network to distinguish between the following emotions: neutral, calm, happy, sad, angry, fearful, disgust, and surprised. The results reached are promising and competitive, beating the performance reached in other state-of-the-art works found in the literature. ",
    "url": "https://arxiv.org/abs/2110.13571",
    "authors": [
      "Eduardo Paluzo-Hidalgo",
      "Guillermo Aguirre-Carrazana",
      "Rocio Gonzalez-Diaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2110.13581",
    "title": "Gradient representations in ReLU networks as similarity functions",
    "abstract": "Feed-forward networks can be interpreted as mappings with linear decision surfaces at the level of the last layer. We investigate how the tangent space of the network can be exploited to refine the decision in case of ReLU (Rectified Linear Unit) activations. We show that a simple Riemannian metric parametrized on the parameters of the network forms a similarity function at least as good as the original network and we suggest a sparse metric to increase the similarity gap. ",
    "url": "https://arxiv.org/abs/2110.13581",
    "authors": [
      "D\u00e1niel R\u00e1cz",
      "B\u00e1lint Dar\u00f3czy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.13619",
    "title": "Vaccine skepticism detection by network embedding",
    "abstract": "We demonstrate the applicability of network embedding to vaccine skepticism, a controversial topic of long-past history. With the Covid-19 pandemic outbreak at the end of 2019, the topic is more important than ever. Only a year after the first international cases were registered, multiple vaccines were developed and passed clinical testing. Besides the challenges of development, testing, and logistics, another factor that might play a significant role in the fight against the pandemic are people who are hesitant to get vaccinated, or even state that they will refuse any vaccine offered to them. Two groups of people commonly referred to as a) pro-vaxxer, those who support vaccinating people b) vax-skeptic, those who question vaccine efficacy or the need for general vaccination against Covid-19. It is very difficult to tell exactly how many people share each of these views. It is even more difficult to understand all the reasoning why vax-skeptic opinions are getting more popular. In this work, our intention was to develop techniques that are able to efficiently differentiate between pro-vaxxer and vax-skeptic content. After multiple data preprocessing steps, we analyzed the tweet text as well as the structure of user interactions on Twitter. We deployed several node embedding and community detection models that scale well for graphs with millions of edges. ",
    "url": "https://arxiv.org/abs/2110.13619",
    "authors": [
      "Ferenc B\u00e9res",
      "Rita Csoma",
      "Tam\u00e1s Vilmos Michaletzky",
      "Andr\u00e1s A. Bencz\u00far"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13629",
    "title": "Bayesian Optimization and Deep Learning forsteering wheel angle  prediction",
    "abstract": "Automated driving systems (ADS) have undergone a significant improvement in the last years. ADS and more precisely self-driving cars technologies will change the way we perceive and know the world of transportation systems in terms of user experience, mode choices and business models. The emerging field of Deep Learning (DL) has been successfully applied for the development of innovative ADS solutions. However, the attempt to single out the best deep neural network architecture and tuning its hyperparameters are all expensive processes, both in terms of time and computational resources. In this work, Bayesian Optimization (BO) is used to optimize the hyperparameters of a Spatiotemporal-Long Short Term Memory (ST-LSTM) network with the aim to obtain an accurate model for the prediction of the steering angle in a ADS. BO was able to identify, within a limited number of trials, a model -- namely BOST-LSTM -- which resulted, on a public dataset, the most accurate when compared to classical end-to-end driving models. ",
    "url": "https://arxiv.org/abs/2110.13629",
    "authors": [
      "Alessandro Riboni",
      "Nicol\u00f2 Ghioldi",
      "Antonio Candelieri",
      "Matteo Borrotti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2110.13655",
    "title": "Bridging the gap to real-world for network intrusion detection systems  with data-centric approach",
    "abstract": "Most research using machine learning (ML) for network intrusion detection systems (NIDS) uses well-established datasets such as KDD-CUP99, NSL-KDD, UNSW-NB15, and CICIDS-2017. In this context, the possibilities of machine learning techniques are explored, aiming for metrics improvements compared to the published baselines (model-centric approach). However, those datasets present some limitations as aging that make it unfeasible to transpose those ML-based solutions to real-world applications. This paper presents a systematic data-centric approach to address the current limitations of NIDS research, specifically the datasets. This approach generates NIDS datasets composed of the most recent network traffic and attacks, with the labeling process integrated by design. ",
    "url": "https://arxiv.org/abs/2110.13655",
    "authors": [
      "Gustavo de Carvalho Bertoli",
      "Louren\u00e7o Alves Pereira Junior",
      "Filipe Alves Neto Verri",
      "Aldri Luiz dos Santos",
      "Osamu Saotome"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13708",
    "title": "TNTC: two-stream network with transformer-based complementarity for  gait-based emotion recognition",
    "abstract": "Recognizing the human emotion automatically from visual characteristics plays a vital role in many intelligent applications. Recently, gait-based emotion recognition, especially gait skeletons-based characteristic, has attracted much attention, while many available methods have been proposed gradually. The popular pipeline is to first extract affective features from joint skeletons, and then aggregate the skeleton joint and affective features as the feature vector for classifying the emotion. However, the aggregation procedure of these emerged methods might be rigid, resulting in insufficiently exploiting the complementary relationship between skeleton joint and affective features. Meanwhile, the long range dependencies in both spatial and temporal domains of the gait sequence are scarcely considered. To address these issues, we propose a novel two-stream network with transformer-based complementarity, termed as TNTC. Skeleton joint and affective features are encoded into two individual images as the inputs of two streams, respectively. A new transformer-based complementarity module (TCM) is proposed to bridge the complementarity between two streams hierarchically via capturing long range dependencies. Experimental results demonstrate TNTC outperforms state-of-the-art methods on the latest dataset in terms of accuracy. ",
    "url": "https://arxiv.org/abs/2110.13708",
    "authors": [
      "Chuanfei Hu",
      "Weijie Sheng",
      "Bo Dong",
      "Xinde Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.13710",
    "title": "DASentimental: Detecting depression, anxiety and stress in texts via  emotional recall, cognitive networks and machine learning",
    "abstract": "Most current affect scales and sentiment analysis on written text focus on quantifying valence (sentiment) -- the most primary dimension of emotion. However, emotions are broader and more complex than valence. Distinguishing negative emotions of similar valence could be important in contexts such as mental health. This project proposes a semi-supervised machine learning model (DASentimental) to extract depression, anxiety and stress from written text. First, we trained the model to spot how sequences of recalled emotion words by $N=200$ individuals correlated with their responses to the Depression Anxiety Stress Scale (DASS-21). Within the framework of cognitive network science, we model every list of recalled emotions as a walk over a networked mental representation of semantic memory, with emotions connected according to free associations in people's memory. Among several tested machine learning approaches, we find that a multilayer perceptron neural network trained on word sequences and semantic network distances can achieve state-of-art, cross-validated predictions for depression ($R = 0.7$), anxiety ($R = 0.44$) and stress ($R = 0.52$). Though limited by sample size, this first-of-its-kind approach enables quantitative explorations of key semantic dimensions behind DAS levels. We find that semantic distances between recalled emotions and the dyad \"sad-happy\" are crucial features for estimating depression levels but are less important for anxiety and stress. We also find that semantic distance of recalls from \"fear\" can boost the prediction of anxiety but it becomes redundant when the \"sad-happy\" dyad is considered. Adopting DASentimental as a semi-supervised learning tool to estimate DAS in text, we apply it to a dataset of 142 suicide notes. We conclude by discussing key directions for future research enabled by artificial intelligence detecting stress, anxiety and depression. ",
    "url": "https://arxiv.org/abs/2110.13710",
    "authors": [
      "Asra Fatima",
      "Li Ying",
      "Thomas Hills",
      "Massimo Stella"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2010.08262",
    "title": "Local plasticity rules can learn deep representations using  self-supervised contrastive predictions",
    "abstract": "Learning in the brain is poorly understood and learning rules that respect biological constraints, yet yield deep hierarchical representations, are still unknown. Here, we propose a learning rule that takes inspiration from neuroscience and recent advances in self-supervised deep learning. Learning minimizes a simple layer-specific loss function and does not need to back-propagate error signals within or between layers. Instead, weight updates follow a local, Hebbian, learning rule that only depends on pre- and post-synaptic neuronal activity, predictive dendritic input and widely broadcasted modulation factors which are identical for large groups of neurons. The learning rule applies contrastive predictive learning to a causal, biological setting using saccades (i.e. rapid shifts in gaze direction). We find that networks trained with this self-supervised and local rule build deep hierarchical representations of images, speech and video. ",
    "url": "https://arxiv.org/abs/2010.08262",
    "authors": [
      "Bernd Illing",
      "Jean Ventura",
      "Guillaume Bellec",
      "Wulfram Gerstner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13543",
    "title": "Collective decision-making under changing social environments among  agents adapted to sparse connectivity",
    "abstract": "Humans and other animals often follow the decisions made by others because these are indicative of the quality of possible choices, resulting in `social response rules': observed relationships between the probability that an agent will make a specific choice and the decisions other individuals have made. The form of social responses can be understood by considering the behaviour of rational agents that seek to maximise their expected utility using both social and private information. Previous derivations of social responses assume that agents observe all others within a group, but real interaction networks are often characterised by sparse connectivity. Here I analyse the observable behaviour of rational agents that attend to the decisions made by a subset of others in the group. This reveals an adaptive strategy in sparsely-connected networks based on highly-simplified social information: the difference in the observed number of agents choosing each option. Where agents employ this strategy, collective outcomes and decision-making efficacy are controlled by the social connectivity at the time of the decision, rather than that to which the agents are accustomed, providing an important caveat for sociality observed in the laboratory and suggesting a basis for the social dynamics of highly-connected online communities. ",
    "url": "https://arxiv.org/abs/2110.13543",
    "authors": [
      "Richard P. Mann"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2110.13732",
    "title": "Improving the efficacy of Deep Learning models for Heart Beat detection  on heterogeneous datasets",
    "abstract": "Deep Learning (DL) have greatly contributed to bioelectric signals processing, in particular to extract physiological markers. However, the efficacy and applicability of the results proposed in the literature is often constrained to the population represented by the data used to train the models. In this study, we investigate the issues related to applying a DL model on heterogeneous datasets. In particular, by focusing on heart beat detection from Electrocardiogram signals (ECG), we show that the performance of a model trained on data from healthy subjects decreases when applied to patients with cardiac conditions and to signals collected with different devices. We then evaluate the use of Transfer Learning (TL) to adapt the model to the different datasets. In particular, we show that the classification performance is improved, even with datasets with a small sample size. These results suggest that a greater effort should be made towards generalizability of DL models applied on bioelectric signals, in particular by retrieving more representative datasets. ",
    "url": "https://arxiv.org/abs/2110.13732",
    "authors": [
      "Andrea Bizzego",
      "Giulio Gabrieli",
      "Michelle Jin-Yee Neoh",
      "Gianluca Esposito"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13823",
    "title": "Real-time division-of-focal-plane polarization imaging system with  progressive networks",
    "abstract": "Division-of-focal-plane (DoFP) polarization imaging technical recently has been applied in many fields. However, the images captured by such sensors cannot be used directly because they suffer from instantaneous field-of-view errors and low resolution problem. This paper builds a fast DoFP demosaicing system with proposed progressive polarization demosaicing convolutional neural network (PPDN), which is specifically designed for edge-side GPU devices like Navidia Jetson TX2. The proposed network consists of two parts: reconstruction stage and refining stage. The former recovers four polarization channels from a single DoFP image. The latter fine-tune the four channels to obtain more accurate polarization information. PPDN can be implemented in another version: PPDN-L (large), for the platforms of high computing resources. Experiments show that PPDN can compete with the best existing methods with fewer parameters and faster inference speed and meet the real-time demands of imaging system. ",
    "url": "https://arxiv.org/abs/2110.13823",
    "authors": [
      "Rongyuan Wu",
      "Yongqiang Zhao",
      "Ning Li",
      "Seong G.Kong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2010.08262",
    "title": "Local plasticity rules can learn deep representations using  self-supervised contrastive predictions",
    "abstract": " Title: Local plasticity rules can learn deep representations using  self-supervised contrastive predictions ",
    "url": "https://arxiv.org/abs/2010.08262",
    "authors": [
      "Bernd Illing",
      "Jean Ventura",
      "Guillaume Bellec",
      "Wulfram Gerstner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.14622",
    "title": "Vertex nomination between graphs via spectral embedding and quadratic  programming",
    "abstract": " Title: Vertex nomination between graphs via spectral embedding and quadratic  programming ",
    "url": "https://arxiv.org/abs/2010.14622",
    "authors": [
      "Runbing Zheng",
      "Vince Lyzinski",
      "Carey E. Priebe",
      "Minh Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2012.01644",
    "title": "Capturing implicit hierarchical structure in 3D biomedical images with  self-supervised hyperbolic representations",
    "abstract": " Comments: To appear at NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2012.01644",
    "authors": [
      "Joy Hsu",
      "Jeffrey Gu",
      "Gong-Her Wu",
      "Wah Chiu",
      "Serena Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.08508",
    "title": "Attention over learned object embeddings enables complex visual  reasoning",
    "abstract": " Comments: 22 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2012.08508",
    "authors": [
      "David Ding",
      "Felix Hill",
      "Adam Santoro",
      "Malcolm Reynolds",
      "Matt Botvinick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.00651",
    "title": "Asymptotics of representation learning in finite Bayesian neural  networks",
    "abstract": " Comments: 13+28 pages, 4 figures; v3: extensive revision with improved exposition and new section on CNNs, accepted to NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2106.00651",
    "authors": [
      "Jacob A. Zavatone-Veth",
      "Abdulkadir Canatar",
      "Benjamin S. Ruben",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.02159",
    "title": "On the implementation of a robust and efficient finite element-based  parallel solver for the compressible Navier-Stokes equations",
    "abstract": " Title: On the implementation of a robust and efficient finite element-based  parallel solver for the compressible Navier-Stokes equations ",
    "url": "https://arxiv.org/abs/2106.02159",
    "authors": [
      "Jean-Luc Guermond",
      "Martin Kronbichler",
      "Matthias Maier",
      "Bojan Popov",
      "Ignacio Tomas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2107.01163",
    "title": "Unveiling the structure of wide flat minima in neural networks",
    "abstract": " Comments: 15 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2107.01163",
    "authors": [
      "Carlo Baldassi",
      "Clarissa Lauditi",
      "Enrico M. Malatesta",
      "Gabriele Perugini",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2107.04616",
    "title": "A deep convolutional neural network that is invariant to time rescaling",
    "abstract": " Title: A deep convolutional neural network that is invariant to time rescaling ",
    "url": "https://arxiv.org/abs/2107.04616",
    "authors": [
      "Brandon G. Jacques",
      "Zoran Tiganj",
      "Aakash Sarkar",
      "Marc W. Howard",
      "Per B. Sederberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.06721",
    "title": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "abstract": " Title: Linear block and convolutional MDS codes to required rate, distance and  type ",
    "url": "https://arxiv.org/abs/2109.06721",
    "authors": [
      "Ted Hurley"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2109.09710",
    "title": "Understanding neural networks with reproducing kernel Banach spaces",
    "abstract": " Title: Understanding neural networks with reproducing kernel Banach spaces ",
    "url": "https://arxiv.org/abs/2109.09710",
    "authors": [
      "Francesca Bartolucci",
      "Ernesto De Vito",
      "Lorenzo Rosasco",
      "Stefano Vigogna"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ]
  }
]