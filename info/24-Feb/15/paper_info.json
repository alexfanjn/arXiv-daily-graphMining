[
  {
    "id": "arXiv:2402.08698",
    "title": "AMEND: A Mixture of Experts Framework for Long-tailed Trajectory  Prediction",
    "abstract": "Accurate prediction of pedestrians' future motions is critical for intelligent driving systems. Developing models for this task requires rich datasets containing diverse sets of samples. However, the existing naturalistic trajectory prediction datasets are generally imbalanced in favor of simpler samples and lack challenging scenarios. Such a long-tail effect causes prediction models to underperform on the tail portion of the data distribution containing safety-critical scenarios. Previous methods tackle the long-tail problem using methods such as contrastive learning and class-conditioned hypernetworks. These approaches, however, are not modular and cannot be applied to many machine learning architectures. In this work, we propose a modular model-agnostic framework for trajectory prediction that leverages a specialized mixture of experts. In our approach, each expert is trained with a specialized skill with respect to a particular part of the data. To produce predictions, we utilise a router network that selects the best expert by generating relative confidence scores. We conduct experimentation on common pedestrian trajectory prediction datasets and show that besides achieving state-of-the-art performance, our method significantly performs better on long-tail scenarios. We further conduct ablation studies to highlight the contribution of different proposed components. ",
    "url": "https://arxiv.org/abs/2402.08698",
    "authors": [
      "Ray Coden Mercurius",
      "Ehsan Ahmadi",
      "Soheil Mohamad Alizadeh Shabestary",
      "Amir Rasouli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.08699",
    "title": "Unsupervised Evaluation of Code LLMs with Round-Trip Correctness",
    "abstract": "To evaluate code large language models (LLMs), research has relied on a few small manually curated benchmarks, such as HumanEval and MBPP, which represent a narrow part of the real-world software domains. In this work, we introduce round-trip correctness (RTC) as an alternative evaluation method. RTC allows Code LLM evaluation on a broader spectrum of real-world software domains without the need for costly human curation. RTC rests on the idea that we can ask a model to make a prediction (e.g., describe some code using natural language), feed that prediction back (e.g., synthesize code from the predicted description), and check if this round-trip leads to code that is semantically equivalent to the original input. We show how to employ RTC to evaluate code synthesis and editing. We find that RTC strongly correlates with model performance on existing narrow-domain code synthesis benchmarks while allowing us to expand to a much broader set of domains and tasks which was not previously possible without costly human annotations. ",
    "url": "https://arxiv.org/abs/2402.08699",
    "authors": [
      "Miltiadis Allamanis",
      "Sheena Panthaplackel",
      "Pengcheng Yin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08714",
    "title": "PRDP: Proximal Reward Difference Prediction for Large-Scale Reward  Finetuning of Diffusion Models",
    "abstract": "Reward finetuning has emerged as a promising approach to aligning foundation models with downstream objectives. Remarkable success has been achieved in the language domain by using reinforcement learning (RL) to maximize rewards that reflect human preference. However, in the vision domain, existing RL-based reward finetuning methods are limited by their instability in large-scale training, rendering them incapable of generalizing to complex, unseen prompts. In this paper, we propose Proximal Reward Difference Prediction (PRDP), enabling stable black-box reward finetuning for diffusion models for the first time on large-scale prompt datasets with over 100K prompts. Our key innovation is the Reward Difference Prediction (RDP) objective that has the same optimal solution as the RL objective while enjoying better training stability. Specifically, the RDP objective is a supervised regression objective that tasks the diffusion model with predicting the reward difference of generated image pairs from their denoising trajectories. We theoretically prove that the diffusion model that obtains perfect reward difference prediction is exactly the maximizer of the RL objective. We further develop an online algorithm with proximal updates to stably optimize the RDP objective. In experiments, we demonstrate that PRDP can match the reward maximization ability of well-established RL-based methods in small-scale training. Furthermore, through large-scale training on text prompts from the Human Preference Dataset v2 and the Pick-a-Pic v1 dataset, PRDP achieves superior generation quality on a diverse set of complex, unseen prompts whereas RL-based methods completely fail. ",
    "url": "https://arxiv.org/abs/2402.08714",
    "authors": [
      "Fei Deng",
      "Qifei Wang",
      "Wei Wei",
      "Matthias Grundmann",
      "Tingbo Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08749",
    "title": "Automated detection of motion artifacts in brain MR images using deep  learning and explainable artificial intelligence",
    "abstract": "Quality assessment, including inspecting the images for artifacts, is a critical step during MRI data acquisition to ensure data quality and downstream analysis or interpretation success. This study demonstrates a deep learning model to detect rigid motion in T1-weighted brain images. We leveraged a 2D CNN for three-class classification and tested it on publicly available retrospective and prospective datasets. Grad-CAM heatmaps enabled the identification of failure modes and provided an interpretation of the model's results. The model achieved average precision and recall metrics of 85% and 80% on six motion-simulated retrospective datasets. Additionally, the model's classifications on the prospective dataset showed a strong inverse correlation (-0.84) compared to average edge strength, an image quality metric indicative of motion. This model is part of the ArtifactID tool, aimed at inline automatic detection of Gibbs ringing, wrap-around, and motion artifacts. This tool automates part of the time-consuming QA process and augments expertise on-site, particularly relevant in low-resource settings where local MR knowledge is scarce. ",
    "url": "https://arxiv.org/abs/2402.08749",
    "authors": [
      "Marina Manso Jimeno",
      "Keerthi Sravan Ravi",
      "Maggie Fung",
      "John Thomas Vaughan, Jr.",
      "Sairam Geethanath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08750",
    "title": "Towards the Detection of AI-Synthesized Human Face Images",
    "abstract": "Over the past years, image generation and manipulation have achieved remarkable progress due to the rapid development of generative AI based on deep learning. Recent studies have devoted significant efforts to address the problem of face image manipulation caused by deepfake techniques. However, the problem of detecting purely synthesized face images has been explored to a lesser extent. In particular, the recent popular Diffusion Models (DMs) have shown remarkable success in image synthesis. Existing detectors struggle to generalize between synthesized images created by different generative models. In this work, a comprehensive benchmark including human face images produced by Generative Adversarial Networks (GANs) and a variety of DMs has been established to evaluate both the generalization ability and robustness of state-of-the-art detectors. Then, the forgery traces introduced by different generative models have been analyzed in the frequency domain to draw various insights. The paper further demonstrates that a detector trained with frequency representation can generalize well to other unseen generative models. ",
    "url": "https://arxiv.org/abs/2402.08750",
    "authors": [
      "Yuhang Lu",
      "Touradj Ebrahimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.08751",
    "title": "Nearest Neighbor Representations of Neural Circuits",
    "abstract": "Neural networks successfully capture the computational power of the human brain for many tasks. Similarly inspired by the brain architecture, Nearest Neighbor (NN) representations is a novel approach of computation. We establish a firmer correspondence between NN representations and neural networks. Although it was known how to represent a single neuron using NN representations, there were no results even for small depth neural networks. Specifically, for depth-2 threshold circuits, we provide explicit constructions for their NN representation with an explicit bound on the number of bits to represent it. Example functions include NN representations of convex polytopes (AND of threshold gates), IP2, OR of threshold gates, and linear or exact decision lists. ",
    "url": "https://arxiv.org/abs/2402.08751",
    "authors": [
      "Kordag Mehmet Kilic",
      "Jin Sima",
      "Jehoshua Bruck"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.08763",
    "title": "Enhancing Robustness of Indoor Robotic Navigation with Free-Space  Segmentation Models Against Adversarial Attacks",
    "abstract": "Endeavors in indoor robotic navigation rely on the accuracy of segmentation models to identify free space in RGB images. However, deep learning models are vulnerable to adversarial attacks, posing a significant challenge to their real-world deployment. In this study, we identify vulnerabilities within the hidden layers of neural networks and introduce a practical approach to reinforce traditional adversarial training. Our method incorporates a novel distance loss function, minimizing the gap between hidden layers in clean and adversarial images. Experiments demonstrate satisfactory performance in improving the model's robustness against adversarial perturbations. ",
    "url": "https://arxiv.org/abs/2402.08763",
    "authors": [
      "Qiyuan An",
      "Christos Sevastopoulos",
      "Fillia Makedon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08764",
    "title": "A Dataset for the Detection of Dehumanizing Language",
    "abstract": "Dehumanization is a mental process that enables the exclusion and ill treatment of a group of people. In this paper, we present two data sets of dehumanizing text, a large, automatically collected corpus and a smaller, manually annotated data set. Both data sets include a combination of political discourse and dialogue from movie subtitles. Our methods give us a broad and varied amount of dehumanization data to work with, enabling further exploratory analysis and automatic classification of dehumanization patterns. Both data sets will be publicly released. ",
    "url": "https://arxiv.org/abs/2402.08764",
    "authors": [
      "Paul Engelmann",
      "Peter Brunsgaard Trolle",
      "Christian Hardmeier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.08784",
    "title": "Preconditioners for the Stochastic Training of Implicit Neural  Representations",
    "abstract": "Implicit neural representations have emerged as a powerful technique for encoding complex continuous multidimensional signals as neural networks, enabling a wide range of applications in computer vision, robotics, and geometry. While Adam is commonly used for training due to its stochastic proficiency, it entails lengthy training durations. To address this, we explore alternative optimization techniques for accelerated training without sacrificing accuracy. Traditional second-order optimizers like L-BFGS are suboptimal in stochastic settings, making them unsuitable for large-scale data sets. Instead, we propose stochastic training using curvature-aware diagonal preconditioners, showcasing their effectiveness across various signal modalities such as images, shape reconstruction, and Neural Radiance Fields (NeRF). ",
    "url": "https://arxiv.org/abs/2402.08784",
    "authors": [
      "Shin-Fang Chng",
      "Hemanth Saratchandran",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08808",
    "title": "Depth Separation in Norm-Bounded Infinite-Width Neural Networks",
    "abstract": "We study depth separation in infinite-width neural networks, where complexity is controlled by the overall squared $\\ell_2$-norm of the weights (sum of squares of all weights in the network). Whereas previous depth separation results focused on separation in terms of width, such results do not give insight into whether depth determines if it is possible to learn a network that generalizes well even when the network width is unbounded. Here, we study separation in terms of the sample complexity required for learnability. Specifically, we show that there are functions that are learnable with sample complexity polynomial in the input dimension by norm-controlled depth-3 ReLU networks, yet are not learnable with sub-exponential sample complexity by norm-controlled depth-2 ReLU networks (with any value for the norm). We also show that a similar statement in the reverse direction is not possible: any function learnable with polynomial sample complexity by a norm-controlled depth-2 ReLU network with infinite width is also learnable with polynomial sample complexity by a norm-controlled depth-3 ReLU network. ",
    "url": "https://arxiv.org/abs/2402.08808",
    "authors": [
      "Suzanna Parkinson",
      "Greg Ongie",
      "Rebecca Willett",
      "Ohad Shamir",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.08823",
    "title": "RanDumb: A Simple Approach that Questions the Efficacy of Continual  Representation Learning",
    "abstract": "We propose RanDumb to examine the efficacy of continual representation learning. RanDumb embeds raw pixels using a fixed random transform which approximates an RBF-Kernel, initialized before seeing any data, and learns a simple linear classifier on top. We present a surprising and consistent finding: RanDumb significantly outperforms the continually learned representations using deep networks across numerous continual learning benchmarks, demonstrating the poor performance of representation learning in these scenarios. RanDumb stores no exemplars and performs a single pass over the data, processing one sample at a time. It complements GDumb, operating in a low-exemplar regime where GDumb has especially poor performance. We reach the same consistent conclusions when RanDumb is extended to scenarios with pretrained models replacing the random transform with pretrained feature extractor. Our investigation is both surprising and alarming as it questions our understanding of how to effectively design and train models that require efficient continual representation learning, and necessitates a principled reinvestigation of the widely explored problem formulation itself. Our code is available at https://github.com/drimpossible/RanDumb. ",
    "url": "https://arxiv.org/abs/2402.08823",
    "authors": [
      "Ameya Prabhu",
      "Shiven Sinha",
      "Ponnurangam Kumaraguru",
      "Philip H.S. Torr",
      "Ozan Sener",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08824",
    "title": "Disambiguated Node Classification with Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated significant success in learning from graph-structured data across various domains. Despite their great successful, one critical challenge is often overlooked by existing works, i.e., the learning of message propagation that can generalize effectively to underrepresented graph regions. These minority regions often exhibit irregular homophily/heterophily patterns and diverse neighborhood class distributions, resulting in ambiguity. In this work, we investigate the ambiguity problem within GNNs, its impact on representation learning, and the development of richer supervision signals to fight against this problem. We conduct a fine-grained evaluation of GNN, analyzing the existence of ambiguity in different graph regions and its relation with node positions. To disambiguate node embeddings, we propose a novel method, {\\method}, which exploits additional optimization guidance to enhance representation learning, particularly for nodes in ambiguous regions. {\\method} identifies ambiguous nodes based on temporal inconsistency of predictions and introduces a disambiguation regularization by employing contrastive learning in a topology-aware manner. {\\method} promotes discriminativity of node representations and can alleviating semantic mixing caused by message propagation, effectively addressing the ambiguity problem. Empirical results validate the efficiency of {\\method} and highlight its potential to improve GNN performance in underrepresented graph regions. ",
    "url": "https://arxiv.org/abs/2402.08824",
    "authors": [
      "Tianxiang Zhao",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.08825",
    "title": "Maximizing Throughput with Routing Interference Avoidance in  RIS-Assisted Relay Mesh Networks",
    "abstract": "In the modern landscape of wireless communications, multi-hop, high-bandwidth, indoor Terahertz (THz) wireless communications are gaining significant attention. These systems couple Reconfigurable Intelligent Surface (RIS) and relay devices within the emerging 6G network framework, offering promising solutions for creating cell-less, indoor, and on-demand mesh networks. RIS devices are especially attractive, constructed by an array of reflecting elements that can phase shifts, such that the reflecting signals can be focused, steered, and the power of the signal enhanced towards the destination. This paper presents an in-depth, analytical examination of how path allocation impacts interference within such networks. We develop the first model which analyzes interference based on the geometric parameters of beams (conic, cylindrical) as they interact with RIS, User Equipment (UE), and relay devices. We introduce a transmission scheduling heuristic designed to mitigate interference, alongside an efficient optimization method to maximize throughput. Our performance results elucidate the interference's effect on communication path quality and highlight effective path selection strategies with throughput maximization. ",
    "url": "https://arxiv.org/abs/2402.08825",
    "authors": [
      "Cao Vien Phung",
      "Andre Drummond",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.08826",
    "title": "Equilibria of Data Marketplaces with Privacy-Aware Sellers under  Endogenous Privacy Costs",
    "abstract": "We study a two-sided online data ecosystem comprised of an online platform, users on the platform, and downstream learners or data buyers. The learners can buy user data on the platform (to run a statistic or machine learning task). Potential users decide whether to join by looking at the trade-off between i) their benefit from joining the platform and interacting with other users and ii) the privacy costs they incur from sharing their data. First, we introduce a novel modeling element for two-sided data platforms: the privacy costs of the users are endogenous and depend on how much of their data is purchased by the downstream learners. Then, we characterize marketplace equilibria in certain simple settings. In particular, we provide a full characterization in two variants of our model that correspond to different utility functions for the users: i) when each user gets a constant benefit for participating in the platform and ii) when each user's benefit is linearly increasing in the number of other users that participate. In both variants, equilibria in our setting are significantly different from equilibria when privacy costs are exogenous and fixed, highlighting the importance of taking endogeneity in the privacy costs into account. Finally, we provide simulations and semi-synthetic experiments to extend our results to more general assumptions. We experiment with different distributions of users' privacy costs and different functional forms of the users' utilities for joining the platform. ",
    "url": "https://arxiv.org/abs/2402.08826",
    "authors": [
      "Diptangshu Sen",
      "Jingyan Wang",
      "Juba Ziani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2402.08830",
    "title": "Sequence graphs realizations and ambiguity in language models",
    "abstract": "Several popular language models represent local contexts in an input text as bags of words. Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in x, with edges representing the (ordered) co-occurrence of two words within a sliding window of size w. However, this compressed representation is not generally bijective, and may introduce some degree of ambiguity. Some sequence graphs may admit several realizations as a sequence, while others may not admit any realization. In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and computational point of view. We consider the existence and enumeration of realizations of a sequence graph under multiple settings: window size w, presence/absence of graph orientation, and presence/absence of weights (multiplicities). When w = 2, we provide polynomial time algorithms for realizability and enumeration in all cases except the undirected/weighted setting, where we show the #P-hardness of enumeration. For a window of size at least 3, we prove hardness of all variants, even when w is considered as a constant, with the notable exception of the undirected/unweighted case for which we propose an XP algorithms for both (realizability and enumeration) problems, tight due to a corresponding W[1]-hardness result. We conclude with an integer program formulation to solve the realizability problem, and with dynamic programming to solve the enumeration problem. This work leaves open the membership to NP for both problems, a non-trivial question due to the existence of minimum realizations having exponential size on the instance encoding. ",
    "url": "https://arxiv.org/abs/2402.08830",
    "authors": [
      "Sammy Khalife",
      "Yann Ponty",
      "Laurent Bulteau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.08845",
    "title": "Feature Attribution with Necessity and Sufficiency via Dual-stage  Perturbation Test for Causal Explanation",
    "abstract": "We investigate the problem of explainability in machine learning.To address this problem, Feature Attribution Methods (FAMs) measure the contribution of each feature through a perturbation test, where the difference in prediction is compared under different perturbations.However, such perturbation tests may not accurately distinguish the contributions of different features, when their change in prediction is the same after perturbation.In order to enhance the ability of FAMs to distinguish different features' contributions in this challenging setting, we propose to utilize the probability (PNS) that perturbing a feature is a necessary and sufficient cause for the prediction to change as a measure of feature importance.Our approach, Feature Attribution with Necessity and Sufficiency (FANS), computes the PNS via a perturbation test involving two stages (factual and interventional).In practice, to generate counterfactual samples, we use a resampling-based approach on the observed samples to approximate the required conditional distribution.Finally, we combine FANS and gradient-based optimization to extract the subset with the largest PNS.We demonstrate that FANS outperforms existing feature attribution methods on six benchmarks. ",
    "url": "https://arxiv.org/abs/2402.08845",
    "authors": [
      "Xuexin Chen",
      "Ruichu Cai",
      "Zhengting Huang",
      "Yuxuan Zhu",
      "Julien Horwood",
      "Zhifeng Hao",
      "Zijian Li",
      "Jose Miguel Hernandez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.08859",
    "title": "Large Language Model with Graph Convolution for Recommendation",
    "abstract": "In recent years, efforts have been made to use text information for better user profiling and item characterization in recommendations. However, text information can sometimes be of low quality, hindering its effectiveness for real-world applications. With knowledge and reasoning capabilities capsuled in Large Language Models (LLMs), utilizing LLMs emerges as a promising way for description improvement. However, existing ways of prompting LLMs with raw texts ignore structured knowledge of user-item interactions, which may lead to hallucination problems like inconsistent description generation. To this end, we propose a Graph-aware Convolutional LLM method to elicit LLMs to capture high-order relations in the user-item graph. To adapt text-based LLMs with structured graphs, We use the LLM as an aggregator in graph processing, allowing it to understand graph-based information step by step. Specifically, the LLM is required for description enhancement by exploring multi-hop neighbors layer by layer, thereby propagating information progressively in the graph. To enable LLMs to capture large-scale graph information, we break down the description task into smaller parts, which drastically reduces the context length of the token input with each step. Extensive experiments on three real-world datasets show that our method consistently outperforms state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2402.08859",
    "authors": [
      "Yingpeng Du",
      "Ziyan Wang",
      "Zhu Sun",
      "Haoyan Chua",
      "Hongzhi Liu",
      "Zhonghai Wu",
      "Yining Ma",
      "Jie Zhang",
      "Youchen Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08863",
    "title": "Multiscale graph neural networks with adaptive mesh refinement for  accelerating mesh-based simulations",
    "abstract": "Mesh-based Graph Neural Networks (GNNs) have recently shown capabilities to simulate complex multiphysics problems with accelerated performance times. However, mesh-based GNNs require a large number of message-passing (MP) steps and suffer from over-smoothing for problems involving very fine mesh. In this work, we develop a multiscale mesh-based GNN framework mimicking a conventional iterative multigrid solver, coupled with adaptive mesh refinement (AMR), to mitigate challenges with conventional mesh-based GNNs. We use the framework to accelerate phase field (PF) fracture problems involving coupled partial differential equations with a near-singular operator due to near-zero modulus inside the crack. We define the initial graph representation using all mesh resolution levels. We perform a series of downsampling steps using Transformer MP GNNs to reach the coarsest graph followed by upsampling steps to reach the original graph. We use skip connectors from the generated embedding during coarsening to prevent over-smoothing. We use Transfer Learning (TL) to significantly reduce the size of training datasets needed to simulate different crack configurations and loading conditions. The trained framework showed accelerated simulation times, while maintaining high accuracy for all cases compared to physics-based PF fracture model. Finally, this work provides a new approach to accelerate a variety of mesh-based engineering multiphysics problems ",
    "url": "https://arxiv.org/abs/2402.08863",
    "authors": [
      "Roberto Perera",
      "Vinamra Agrawal"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2402.08893",
    "title": "Inconsistency of evaluation metrics in link prediction",
    "abstract": "Link prediction is a paradigmatic and challenging problem in network science, which predicts missing links, future links and temporal links based on known topology. Along with the increasing number of link prediction algorithms, a critical yet previously ignored risk is that the evaluation metrics for algorithm performance are usually chosen at will. This paper implements extensive experiments on hundreds of real networks and 25 well-known algorithms, revealing statistically significant inconsistency of evaluation metrics, namely different metrics probably produce remarkably different rankings of algorithms. Therefore, we conclude that any single metric cannot comprehensively or credibly evaluate algorithm performance. Further analysis suggests the usage of at least two metrics: one is the area under the receiver operating characteristic curve (AUC), and the other is one of the following three candidates metrics, say the area under the precision-recall curve (AUPR), the area under the precision curve (AUC-Precision), and the normalized discounted cumulative gain (NDCG). In addition, as we have proved the essential equivalence of threshold-dependent metrics, if in a link prediction task, some specific thresholds are meaningful, we can consider any one threshold-dependent metric with those thresholds. This work completes a missing part in the landscape of link prediction, and provides a starting point toward a well-accepted criterion or standard to select proper evaluation metrics for link prediction. ",
    "url": "https://arxiv.org/abs/2402.08893",
    "authors": [
      "Yilin Bi",
      "Xinshan Jiao",
      "Yan-Li Lee",
      "Tao Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2402.08907",
    "title": "Tackling Negative Transfer on Graphs",
    "abstract": "Transfer learning aims to boost the learning on the target task leveraging knowledge learned from other relevant tasks. However, when the source and target are not closely related, the learning performance may be adversely affected, a phenomenon known as negative transfer. In this paper, we investigate the negative transfer in graph transfer learning, which is important yet underexplored. We reveal that, unlike image or text, negative transfer commonly occurs in graph-structured data, even when source and target graphs share semantic similarities. Specifically, we identify that structural differences significantly amplify the dissimilarities in the node embeddings across graphs. To mitigate this, we bring a new insight: for semantically similar graphs, although structural differences lead to significant distribution shift in node embeddings, their impact on subgraph embeddings could be marginal. Building on this insight, we introduce two effective yet elegant methods, Subgraph Pooling (SP) and Subgraph Pooling++ (SP++), that transfer subgraph-level knowledge across graphs. We theoretically analyze the role of SP in reducing graph discrepancy and conduct extensive experiments to evaluate its superiority under various settings. Our code and datasets are available at: https://github.com/Zehong-Wang/Subgraph-Pooling. ",
    "url": "https://arxiv.org/abs/2402.08907",
    "authors": [
      "Zehong Wang",
      "Zheyuan Zhang",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.08918",
    "title": "Graph Inference Acceleration by Learning MLPs on Graphs without  Supervision",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated effectiveness in various graph learning tasks, yet their reliance on message-passing constraints their deployment in latency-sensitive applications such as financial fraud detection. Recent works have explored distilling knowledge from GNNs to Multi-Layer Perceptrons (MLPs) to accelerate inference. However, this task-specific supervised distillation limits generalization to unseen nodes, which are prevalent in latency-sensitive applications. To this end, we present \\textbf{\\textsc{SimMLP}}, a \\textbf{\\textsc{Sim}}ple yet effective framework for learning \\textbf{\\textsc{MLP}}s on graphs without supervision, to enhance generalization. \\textsc{SimMLP} employs self-supervised alignment between GNNs and MLPs to capture the fine-grained and generalizable correlation between node features and graph structures, and proposes two strategies to alleviate the risk of trivial solutions. Theoretically, we comprehensively analyze \\textsc{SimMLP} to demonstrate its equivalence to GNNs in the optimal case and its generalization capability. Empirically, \\textsc{SimMLP} outperforms state-of-the-art baselines, especially in settings with unseen nodes. In particular, it obtains significant performance gains {\\bf (7$\\sim$26\\%)} over MLPs and inference acceleration over GNNs {\\bf (90$\\sim$126$\\times$)} on large-scale graph datasets. Our codes are available at: \\url{https://github.com/Zehong-Wang/SimMLP}. ",
    "url": "https://arxiv.org/abs/2402.08918",
    "authors": [
      "Zehong Wang",
      "Zheyuan Zhang",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.08956",
    "title": "Seagull: Privacy preserving network verification system",
    "abstract": "The current routing protocol used in the internet backbone is based on manual configuration, making it susceptible to errors. To mitigate these configuration-related issues, it becomes imperative to validate the accuracy and convergence of the algorithm, ensuring a seamless operation devoid of problems. However, the process of network verification faces challenges related to privacy and scalability. This paper addresses these challenges by introducing a novel approach: leveraging privacy-preserving computation, specifically multiparty computation (MPC), to verify the correctness of configurations in the internet backbone, governed by the BGP protocol. Not only does our proposed solution effectively address scalability concerns, but it also establishes a robust privacy framework. Through rigorous analysis, we demonstrate that our approach maintains privacy by not disclosing any information beyond the query result, thus providing a comprehensive and secure solution to the intricacies associated with routing protocol verification in large-scale networks. ",
    "url": "https://arxiv.org/abs/2402.08956",
    "authors": [
      "Jaber Daneshamooz",
      "Melody Yu",
      "Sucheer Maddury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.08961",
    "title": "HyCubE: Efficient Knowledge Hypergraph 3D Circular Convolutional  Embedding",
    "abstract": "Existing knowledge hypergraph embedding methods mainly focused on improving model performance, but their model structures are becoming more complex and redundant. Furthermore, due to the inherent complex semantic knowledge, the computation of knowledge hypergraph embedding models is often very expensive, leading to low efficiency. In this paper, we propose a feature interaction and extraction-enhanced 3D circular convolutional embedding model, HyCubE, which designs a novel 3D circular convolutional neural network and introduces the alternate mask stack strategy to achieve efficient n-ary knowledge hypergraph embedding. By adaptively adjusting the 3D circular convolution kernel size and uniformly embedding the entity position information, HyCubE improves the model performance with fewer parameters and reaches a better trade-off between model performance and efficiency. In addition, we use 1-N multilinear scoring based on the entity mask mechanism to further accelerate the model training efficiency. Finally, extensive experimental results on all datasets demonstrate that HyCubE consistently outperforms state-of-the-art baselines, with an average improvement of 4.08%-10.77% and a maximum improvement of 21.16% across all metrics. Commendably, HyCubE speeds up by an average of 7.55x and reduces memory usage by an average of 77.02% compared to the latest state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2402.08961",
    "authors": [
      "Zhao Li",
      "Xin Wang",
      "Jianxin Li",
      "Wenbin Guo",
      "Jun Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08963",
    "title": "DUEL: Duplicate Elimination on Active Memory for Self-Supervised  Class-Imbalanced Learning",
    "abstract": "Recent machine learning algorithms have been developed using well-curated datasets, which often require substantial cost and resources. On the other hand, the direct use of raw data often leads to overfitting towards frequently occurring class information. To address class imbalances cost-efficiently, we propose an active data filtering process during self-supervised pre-training in our novel framework, Duplicate Elimination (DUEL). This framework integrates an active memory inspired by human working memory and introduces distinctiveness information, which measures the diversity of the data in the memory, to optimize both the feature extractor and the memory. The DUEL policy, which replaces the most duplicated data with new samples, aims to enhance the distinctiveness information in the memory and thereby mitigate class imbalances. We validate the effectiveness of the DUEL framework in class-imbalanced environments, demonstrating its robustness and providing reliable results in downstream tasks. We also analyze the role of the DUEL policy in the training process through various metrics and visualizations. ",
    "url": "https://arxiv.org/abs/2402.08963",
    "authors": [
      "Won-Seok Choi",
      "Hyundo Lee",
      "Dong-Sig Han",
      "Junseok Park",
      "Heeyeon Koo",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08971",
    "title": "Structured Language Generation Model for Robust Structure Prediction",
    "abstract": "We propose Structured Language Generation Model (SLGM), a mixture of new loss function and inference method for better generalization of structured outputs. Previous studies on structure prediction (e.g. NER, RE) make use of explicit dataset information, which would boost performance, yet it might pose challenges to robust generalization in real-world situations. Instead, our model gives generalized format information about data indirectly. With format information, we could reduce sequence-to-sequence problem into classification problem via loss calibration and formatted decoding. Our experimental results showed SLGM successfully maintain performance without dataset information, and showed much less format errors. We also showed our model can work like adapters on individual dataset, with no additional training. ",
    "url": "https://arxiv.org/abs/2402.08971",
    "authors": [
      "Minho Lee",
      "Junghyun Min",
      "Woochul Lee",
      "Yeonsoo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.08975",
    "title": "Research and application of Transformer based anomaly detection model: A  literature review",
    "abstract": "Transformer, as one of the most advanced neural network models in Natural Language Processing (NLP), exhibits diverse applications in the field of anomaly detection. To inspire research on Transformer-based anomaly detection, this review offers a fresh perspective on the concept of anomaly detection. We explore the current challenges of anomaly detection and provide detailed insights into the operating principles of Transformer and its variants in anomaly detection tasks. Additionally, we delineate various application scenarios for Transformer-based anomaly detection models and discuss the datasets and evaluation metrics employed. Furthermore, this review highlights the key challenges in Transformer-based anomaly detection research and conducts a comprehensive analysis of future research trends in this domain. The review includes an extensive compilation of over 100 core references related to Transformer-based anomaly detection. To the best of our knowledge, this is the first comprehensive review that focuses on the research related to Transformer in the context of anomaly detection. We hope that this paper can provide detailed technical information to researchers interested in Transformer-based anomaly detection tasks. ",
    "url": "https://arxiv.org/abs/2402.08975",
    "authors": [
      "Mingrui Ma",
      "Lansheng Han",
      "Chunjie Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08976",
    "title": "Confidence-aware Fine-tuning of Sequential Recommendation Systems via  Conformal Prediction",
    "abstract": "In Sequential Recommendation Systems, Cross-Entropy (CE) loss is commonly used but fails to harness item confidence scores during training. Recognizing the critical role of confidence in aligning training objectives with evaluation metrics, we propose CPFT, a versatile framework that enhances recommendation confidence by integrating Conformal Prediction (CP)-based losses with CE loss during fine-tuning. CPFT dynamically generates a set of items with a high probability of containing the ground truth, enriching the training process by incorporating validation data without compromising its role in model selection. This innovative approach, coupled with CP-based losses, sharpens the focus on refining recommendation sets, thereby elevating the confidence in potential item predictions. By fine-tuning item confidence through CP-based losses, CPFT significantly enhances model performance, leading to more precise and trustworthy recommendations that increase user trust and satisfaction. Our extensive evaluation across five diverse datasets and four distinct sequential models confirms CPFT's substantial impact on improving recommendation quality through strategic confidence optimization. Access to the framework's code will be provided following the acceptance of the paper. ",
    "url": "https://arxiv.org/abs/2402.08976",
    "authors": [
      "Chen Wang",
      "Fangxin Wang",
      "Ruocheng Guo",
      "Yueqing Liang",
      "Kay Liu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.08982",
    "title": "MEL: Efficient Multi-Task Evolutionary Learning for High-Dimensional  Feature Selection",
    "abstract": "Feature selection is a crucial step in data mining to enhance model performance by reducing data dimensionality. However, the increasing dimensionality of collected data exacerbates the challenge known as the \"curse of dimensionality\", where computation grows exponentially with the number of dimensions. To tackle this issue, evolutionary computational (EC) approaches have gained popularity due to their simplicity and applicability. Unfortunately, the diverse designs of EC methods result in varying abilities to handle different data, often underutilizing and not sharing information effectively. In this paper, we propose a novel approach called PSO-based Multi-task Evolutionary Learning (MEL) that leverages multi-task learning to address these challenges. By incorporating information sharing between different feature selection tasks, MEL achieves enhanced learning ability and efficiency. We evaluate the effectiveness of MEL through extensive experiments on 22 high-dimensional datasets. Comparing against 24 EC approaches, our method exhibits strong competitiveness. Additionally, we have open-sourced our code on GitHub at https://github.com/wangxb96/MEL. ",
    "url": "https://arxiv.org/abs/2402.08982",
    "authors": [
      "Xubin Wang",
      "Haojiong Shangguan",
      "Fengyi Huang",
      "Shangrui Wu",
      "Weijia Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.08983",
    "title": "SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware  Decoding",
    "abstract": "As large language models (LLMs) become increasingly integrated into real-world applications such as code generation and chatbot assistance, extensive efforts have been made to align LLM behavior with human values, including safety. Jailbreak attacks, aiming to provoke unintended and unsafe behaviors from LLMs, remain a significant/leading LLM safety threat. In this paper, we aim to defend LLMs against jailbreak attacks by introducing SafeDecoding, a safety-aware decoding strategy for LLMs to generate helpful and harmless responses to user queries. Our insight in developing SafeDecoding is based on the observation that, even though probabilities of tokens representing harmful contents outweigh those representing harmless responses, safety disclaimers still appear among the top tokens after sorting tokens by probability in descending order. This allows us to mitigate jailbreak attacks by identifying safety disclaimers and amplifying their token probabilities, while simultaneously attenuating the probabilities of token sequences that are aligned with the objectives of jailbreak attacks. We perform extensive experiments on five LLMs using six state-of-the-art jailbreak attacks and four benchmark datasets. Our results show that SafeDecoding significantly reduces the attack success rate and harmfulness of jailbreak attacks without compromising the helpfulness of responses to benign user queries. SafeDecoding outperforms six defense methods. ",
    "url": "https://arxiv.org/abs/2402.08983",
    "authors": [
      "Zhangchen Xu",
      "Fengqing Jiang",
      "Luyao Niu",
      "Jinyuan Jia",
      "Bill Yuchen Lin",
      "Radha Poovendran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08986",
    "title": "Detecting Adversarial Spectrum Attacks via Distance to Decision Boundary  Statistics",
    "abstract": "Machine learning has been adopted for efficient cooperative spectrum sensing. However, it incurs an additional security risk due to attacks leveraging adversarial machine learning to create malicious spectrum sensing values to deceive the fusion center, called adversarial spectrum attacks. In this paper, we propose an efficient framework for detecting adversarial spectrum attacks. Our design leverages the concept of the distance to the decision boundary (DDB) observed at the fusion center and compares the training and testing DDB distributions to identify adversarial spectrum attacks. We create a computationally efficient way to compute the DDB for machine learning based spectrum sensing systems. Experimental results based on realistic spectrum data show that our method, under typical settings, achieves a high detection rate of up to 99\\% and maintains a low false alarm rate of less than 1\\%. In addition, our method to compute the DDB based on spectrum data achieves 54\\%--64\\% improvements in computational efficiency over existing distance calculation methods. The proposed DDB-based detection framework offers a practical and efficient solution for identifying malicious sensing values created by adversarial spectrum attacks. ",
    "url": "https://arxiv.org/abs/2402.08986",
    "authors": [
      "Wenwei Zhao",
      "Xiaowen Li",
      "Shangqing Zhao",
      "Jie Xu",
      "Yao Liu",
      "Zhuo Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.08994",
    "title": "CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic  Decoding",
    "abstract": "The study of decoding visual neural information faces challenges in generalizing single-subject decoding models to multiple subjects, due to individual differences. Moreover, the limited availability of data from a single subject has a constraining impact on model performance. Although prior multi-subject decoding methods have made significant progress, they still suffer from several limitations, including difficulty in extracting global neural response features, linear scaling of model parameters with the number of subjects, and inadequate characterization of the relationship between neural responses of different subjects to various stimuli. To overcome these limitations, we propose a CLIP-guided Multi-sUbject visual neural information SEmantic Decoding (CLIP-MUSED) method. Our method consists of a Transformer-based feature extractor to effectively model global neural representations. It also incorporates learnable subject-specific tokens that facilitates the aggregation of multi-subject data without a linear increase of parameters. Additionally, we employ representational similarity analysis (RSA) to guide token representation learning based on the topological relationship of visual stimuli in the representation space of CLIP, enabling full characterization of the relationship between neural responses of different subjects under different stimuli. Finally, token representations are used for multi-subject semantic decoding. Our proposed method outperforms single-subject decoding methods and achieves state-of-the-art performance among the existing multi-subject methods on two fMRI datasets. Visualization results provide insights into the effectiveness of our proposed method. Code is available at https://github.com/CLIP-MUSED/CLIP-MUSED. ",
    "url": "https://arxiv.org/abs/2402.08994",
    "authors": [
      "Qiongyi Zhou",
      "Changde Du",
      "Shengpei Wang",
      "Huiguang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.09011",
    "title": "Improved Deterministic Distributed Maximum Weight Independent Set  Approximation in Sparse Graphs",
    "abstract": "We design new deterministic CONGEST approximation algorithms for \\emph{maximum weight independent set (MWIS)} in \\emph{sparse graphs}. As our main results, we obtain new $\\Delta(1+\\epsilon)$-approximation algorithms as well as algorithms whose approximation ratio depend strictly on $\\alpha$, in graphs with maximum degree $\\Delta$ and arboricity $\\alpha$. For (deterministic) $\\Delta(1+\\epsilon)$-approximation, the current state-of-the-art is due to a recent breakthrough by Faour et al.\\ [SODA 2023] that showed an $O(\\log^{2} (\\Delta W)\\cdot \\log (1/\\epsilon)+\\log ^{*}n)$-round algorithm, where $W$ is the largest node-weight (this bound translates to $O(\\log^{2} n\\cdot\\log (1/\\epsilon))$ under the common assumption that $W=\\text{poly}(n)$). As for $\\alpha$-dependent approximations, a deterministic CONGEST $(8(1+\\epsilon)\\cdot\\alpha)$-approximation algorithm with runtime $O(\\log^{3} n\\cdot\\log (1/\\epsilon))$ can be derived by combining the aforementioned algorithm of Faour et al.\\ with a method presented by Kawarabayashi et al.\\ [DISC 2020]. ",
    "url": "https://arxiv.org/abs/2402.09011",
    "authors": [
      "Yuval Gil"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.09016",
    "title": "Pyramid Attention Network for Medical Image Registration",
    "abstract": "The advent of deep-learning-based registration networks has addressed the time-consuming challenge in traditional iterative methods.However, the potential of current registration networks for comprehensively capturing spatial relationships has not been fully explored, leading to inadequate performance in large-deformation image registration.The pure convolutional neural networks (CNNs) neglect feature enhancement, while current Transformer-based networks are susceptible to information redundancy.To alleviate these issues, we propose a pyramid attention network (PAN) for deformable medical image registration.Specifically, the proposed PAN incorporates a dual-stream pyramid encoder with channel-wise attention to boost the feature representation.Moreover, a multi-head local attention Transformer is introduced as decoder to analyze motion patterns and generate deformation fields.Extensive experiments on two public brain magnetic resonance imaging (MRI) datasets and one abdominal MRI dataset demonstrate that our method achieves favorable registration performance, while outperforming several CNN-based and Transformer-based registration networks.Our code is publicly available at https://github.com/JuliusWang-7/PAN. ",
    "url": "https://arxiv.org/abs/2402.09016",
    "authors": [
      "Zhuoyuan Wang",
      "Haiqiao Wang",
      "Yi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09022",
    "title": "Assessing AI-Based Code Assistants in Method Generation Tasks",
    "abstract": "AI-based code assistants are increasingly popular as a means to enhance productivity and improve code quality. This study compares four AI-based code assistants, GitHub Copilot, Tabnine, ChatGPT, and Google Bard, in method generation tasks, assessing their ability to produce accurate, correct, and efficient code. Results show that code assistants are useful, with complementary capabilities, although they rarely generate ready-to-use correct code. ",
    "url": "https://arxiv.org/abs/2402.09022",
    "authors": [
      "Vincenzo Corso",
      "Leonardo Mariani",
      "Daniela Micucci",
      "Oliviero Riganelli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.09023",
    "title": "Review-Incorporated Model-Agnostic Profile Injection Attacks on  Recommender Systems",
    "abstract": "Recent studies have shown that recommender systems (RSs) are highly vulnerable to data poisoning attacks. Understanding attack tactics helps improve the robustness of RSs. We intend to develop efficient attack methods that use limited resources to generate high-quality fake user profiles to achieve 1) transferability among black-box RSs 2) and imperceptibility among detectors. In order to achieve these goals, we introduce textual reviews of products to enhance the generation quality of the profiles. Specifically, we propose a novel attack framework named R-Trojan, which formulates the attack objectives as an optimization problem and adopts a tailored transformer-based generative adversarial network (GAN) to solve it so that high-quality attack profiles can be produced. Comprehensive experiments on real-world datasets demonstrate that R-Trojan greatly outperforms state-of-the-art attack methods on various victim RSs under black-box settings and show its good imperceptibility. ",
    "url": "https://arxiv.org/abs/2402.09023",
    "authors": [
      "Shiyi Yang",
      "Lina Yao",
      "Chen Wang",
      "Xiwei Xu",
      "Liming Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.09042",
    "title": "Joint Application Admission Control and Network Slicing in Virtual  Sensor Networks",
    "abstract": "We focus on the problem of managing a shared physical wireless sensor network where a single network infrastructure provider leases the physical resources of the networks to application providers to run/deploy specific applications/services. In this scenario, we solve jointly the problems of Application Admission Control (AAC), that is, whether to admit the application/service to the physical network, and wireless Sensor Network Slicing (SNS), that is, to allocate the required physical resources to the admitted applications in a transparent and effective way. We propose a mathematical programming framework to model the joint AAC-SNS problem which is then leveraged to design effective solution algorithms. The proposed framework is thoroughly evaluated on realistic wireless sensor networks infrastructures. ",
    "url": "https://arxiv.org/abs/2402.09042",
    "authors": [
      "Carmen Delgado",
      "Mar\u00eda Canales",
      "Jorge Ort\u00edn",
      "Jos\u00e9 Ram\u00f3n G\u00e1llego",
      "Alessandro Redondi",
      "Sonda Bousnina",
      "Matteo Cesana"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.09055",
    "title": "Comment-aided Video-Language Alignment via Contrastive Pre-training for  Short-form Video Humor Detection",
    "abstract": "The growing importance of multi-modal humor detection within affective computing correlates with the expanding influence of short-form video sharing on social media platforms. In this paper, we propose a novel two-branch hierarchical model for short-form video humor detection (SVHD), named Comment-aided Video-Language Alignment (CVLA) via data-augmented multi-modal contrastive pre-training. Notably, our CVLA not only operates on raw signals across various modal channels but also yields an appropriate multi-modal representation by aligning the video and language components within a consistent semantic space. The experimental results on two humor detection datasets, including DY11k and UR-FUNNY, demonstrate that CVLA dramatically outperforms state-of-the-art and several competitive baseline approaches. Our dataset, code and model release at https://github.com/yliu-cs/CVLA. ",
    "url": "https://arxiv.org/abs/2402.09055",
    "authors": [
      "Yang Liu",
      "Tongfei Shen",
      "Dong Zhang",
      "Qingying Sun",
      "Shoushan Li",
      "Guodong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.09062",
    "title": "Blind Deep-Learning-Based Image Watermarking Robust Against Geometric  Transformations",
    "abstract": "Digital watermarking enables protection against copyright infringement of images. Although existing methods embed watermarks imperceptibly and demonstrate robustness against attacks, they typically lack resilience against geometric transformations. Therefore, this paper proposes a new watermarking method that is robust against geometric attacks. The proposed method is based on the existing HiDDeN architecture that uses deep learning for watermark encoding and decoding. We add new noise layers to this architecture, namely for a differentiable JPEG estimation, rotation, rescaling, translation, shearing and mirroring. We demonstrate that our method outperforms the state of the art when it comes to geometric robustness. In conclusion, the proposed method can be used to protect images when viewed on consumers' devices. ",
    "url": "https://arxiv.org/abs/2402.09062",
    "authors": [
      "Hannes Mareen",
      "Lucas Antchougov",
      "Glenn Van Wallendael",
      "Peter Lambert"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09063",
    "title": "Soft Prompt Threats: Attacking Safety Alignment and Unlearning in  Open-Source LLMs through the Embedding Space",
    "abstract": "Current research in adversarial robustness of LLMs focuses on discrete input manipulations in the natural language space, which can be directly transferred to closed-source models. However, this approach neglects the steady progression of open-source models. As open-source models advance in capability, ensuring their safety also becomes increasingly imperative. Yet, attacks tailored to open-source LLMs that exploit full model access remain largely unexplored. We address this research gap and propose the embedding space attack, which directly attacks the continuous embedding representation of input tokens. We find that embedding space attacks circumvent model alignments and trigger harmful behaviors more efficiently than discrete attacks or model fine-tuning. Furthermore, we present a novel threat model in the context of unlearning and show that embedding space attacks can extract supposedly deleted information from unlearned LLMs across multiple datasets and models. Our findings highlight embedding space attacks as an important threat model in open-source LLMs. Trigger Warning: the appendix contains LLM-generated text with violence and harassment. ",
    "url": "https://arxiv.org/abs/2402.09063",
    "authors": [
      "Leo Schwinn",
      "David Dobre",
      "Sophie Xhonneux",
      "Gauthier Gidel",
      "Stephan Gunnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09066",
    "title": "Solid Waste Detection in Remote Sensing Images: A Survey",
    "abstract": "The detection and characterization of illegal solid waste disposal sites are essential for environmental protection, particularly for mitigating pollution and health hazards. Improperly managed landfills contaminate soil and groundwater via rainwater infiltration, posing threats to both animals and humans. Traditional landfill identification approaches, such as on-site inspections, are time-consuming and expensive. Remote sensing is a cost-effective solution for the identification and monitoring of solid waste disposal sites that enables broad coverage and repeated acquisitions over time. Earth Observation (EO) satellites, equipped with an array of sensors and imaging capabilities, have been providing high-resolution data for several decades. Researchers proposed specialized techniques that leverage remote sensing imagery to perform a range of tasks such as waste site detection, dumping site monitoring, and assessment of suitable locations for new landfills. This review aims to provide a detailed illustration of the most relevant proposals for the detection and monitoring of solid waste sites by describing and comparing the approaches, the implemented techniques, and the employed data. Furthermore, since the data sources are of the utmost importance for developing an effective solid waste detection model, a comprehensive overview of the satellites and publicly available data sets is presented. Finally, this paper identifies the open issues in the state-of-the-art and discusses the relevant research directions for reducing the costs and improving the effectiveness of novel solid waste detection methods. ",
    "url": "https://arxiv.org/abs/2402.09066",
    "authors": [
      "Piero Fraternali",
      "Luca Morandini",
      "Sergio Luis Herrera Gonz\u00e1lez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09071",
    "title": "Affine transformation estimation improves visual self-supervised  learning",
    "abstract": "The standard approach to modern self-supervised learning is to generate random views through data augmentations and minimise a loss computed from the representations of these views. This inherently encourages invariance to the transformations that comprise the data augmentation function. In this work, we show that adding a module to constrain the representations to be predictive of an affine transformation improves the performance and efficiency of the learning process. The module is agnostic to the base self-supervised model and manifests in the form of an additional loss term that encourages an aggregation of the encoder representations to be predictive of an affine transformation applied to the input images. We perform experiments in various modern self-supervised models and see a performance improvement in all cases. Further, we perform an ablation study on the components of the affine transformation to understand which of them is affecting performance the most, as well as on key architectural design decisions. ",
    "url": "https://arxiv.org/abs/2402.09071",
    "authors": [
      "David Torpey",
      "Richard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09077",
    "title": "DisGNet: A Distance Graph Neural Network for Forward Kinematics Learning  of Gough-Stewart Platform",
    "abstract": "In this paper, we propose a graph neural network, DisGNet, for learning the graph distance matrix to address the forward kinematics problem of the Gough-Stewart platform. DisGNet employs the k-FWL algorithm for message-passing, providing high expressiveness with a small parameter count, making it suitable for practical deployment. Additionally, we introduce the GPU-friendly Newton-Raphson method, an efficient parallelized optimization method executed on the GPU to refine DisGNet's output poses, achieving ultra-high-precision pose. This novel two-stage approach delivers ultra-high precision output while meeting real-time requirements. Our results indicate that on our dataset, DisGNet can achieves error accuracys below 1mm and 1deg at 79.8\\% and 98.2\\%, respectively. As executed on a GPU, our two-stage method can ensure the requirement for real-time computation. Codes are released at https://github.com/FLAMEZZ5201/DisGNet. ",
    "url": "https://arxiv.org/abs/2402.09077",
    "authors": [
      "Huizhi Zhu",
      "Wenxia Xu",
      "Jian Huang",
      "Jiaxin Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09082",
    "title": "Detection Latencies of Anomaly Detectors: An Overlooked Perspective ?",
    "abstract": "The ever-evolving landscape of attacks, coupled with the growing complexity of ICT systems, makes crafting anomaly-based intrusion detectors (ID) and error detectors (ED) a difficult task: they must accurately detect attacks, and they should promptly perform detections. Although improving and comparing the detection capability is the focus of most research works, the timeliness of the detection is less considered and often insufficiently evaluated or discussed. In this paper, we argue the relevance of measuring the temporal latency of attacks and errors, and we propose an evaluation approach for detectors to ensure a pragmatic trade-off between correct and in-time detection. Briefly, the approach relates the false positive rate with the temporal latency of attacks and errors, and this ultimately leads to guidelines for configuring a detector. We apply our approach by evaluating different ED and ID solutions in two industrial cases: i) an embedded railway on-board system that optimizes public mobility, and ii) an edge device for the Industrial Internet of Things. Our results show that considering latency in addition to traditional metrics like the false positive rate, precision, and coverage gives an additional fundamental perspective on the actual performance of the detector and should be considered when assessing and configuring anomaly detectors. ",
    "url": "https://arxiv.org/abs/2402.09082",
    "authors": [
      "Tommaso Puccetti",
      "Andrea Ceccarelli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09091",
    "title": "Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit  Clues",
    "abstract": "With the development of LLMs, the security threats of LLMs are getting more and more attention. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks primarily utilize scenario camouflage techniques. However their explicitly mention of malicious intent will be easily recognized and defended by LLMs. In this paper, we propose an indirect jailbreak attack approach, Puzzler, which can bypass the LLM's defense strategy and obtain malicious response by implicitly providing LLMs with some clues about the original malicious query. In addition, inspired by the wisdom of ''When unable to attack, defend'' from Sun Tzu's Art of War, we adopt a defensive stance to gather clues about the original malicious query through LLMs. Extensive experimental results show that Puzzler achieves a query success rate of 96.6% on closed-source LLMs, which is 57.9%-82.7% higher than baselines. Furthermore, when tested against the state-of-the-art jailbreak detection approaches, Puzzler proves to be more effective at evading detection compared to baselines. ",
    "url": "https://arxiv.org/abs/2402.09091",
    "authors": [
      "Zhiyuan Chang",
      "Mingyang Li",
      "Yi Liu",
      "Junjie Wang",
      "Qing Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.09092",
    "title": "Three Decades of Activations: A Comprehensive Survey of 400 Activation  Functions for Neural Networks",
    "abstract": "Neural networks have proven to be a highly effective tool for solving complex problems in many areas of life. Recently, their importance and practical usability have further been reinforced with the advent of deep learning. One of the important conditions for the success of neural networks is the choice of an appropriate activation function introducing non-linearity into the model. Many types of these functions have been proposed in the literature in the past, but there is no single comprehensive source containing their exhaustive overview. The absence of this overview, even in our experience, leads to redundancy and the unintentional rediscovery of already existing activation functions. To bridge this gap, our paper presents an extensive survey involving 400 activation functions, which is several times larger in scale than previous surveys. Our comprehensive compilation also references these surveys; however, its main goal is to provide the most comprehensive overview and systematization of previously published activation functions with links to their original sources. The secondary aim is to update the current understanding of this family of functions. ",
    "url": "https://arxiv.org/abs/2402.09092",
    "authors": [
      "Vladim\u00edr Kunc",
      "Ji\u0159\u00ed Kl\u00e9ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.09094",
    "title": "Unity is Strength: Enhancing Precision in Reentrancy Vulnerability  Detection of Smart Contract Analysis Tools",
    "abstract": "Reentrancy is one of the most notorious vulnerabilities in smart contracts, resulting in significant digital asset losses. However, many previous works indicate that current Reentrancy detection tools suffer from high false positive rates. Even worse, recent years have witnessed the emergence of new Reentrancy attack patterns fueled by intricate and diverse vulnerability exploit mechanisms. Unfortunately, current tools face a significant limitation in their capacity to adapt and detect these evolving Reentrancy patterns. Consequently, ensuring precise and highly extensible Reentrancy vulnerability detection remains critical challenges for existing tools. To address this issue, we propose a tool named ReEP, designed to reduce the false positives for Reentrancy vulnerability detection. Additionally, ReEP can integrate multiple tools, expanding its capacity for vulnerability detection. It evaluates results from existing tools to verify vulnerability likelihood and reduce false positives. ReEP also offers excellent extensibility, enabling the integration of different detection tools to enhance precision and cover different vulnerability attack patterns. We perform ReEP to eight existing state-of-the-art Reentrancy detection tools. The average precision of these eight tools increased from the original 0.5% to 73% without sacrificing recall. Furthermore, ReEP exhibits robust extensibility. By integrating multiple tools, the precision further improved to a maximum of 83.6%. These results demonstrate that ReEP effectively unites the strengths of existing works, enhances the precision of Reentrancy vulnerability detection tools. ",
    "url": "https://arxiv.org/abs/2402.09094",
    "authors": [
      "Zexu Wang",
      "Jiachi Chen",
      "Zibin Zheng",
      "Peilin Zheng",
      "Yu Zhang",
      "Weizhe Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.09109",
    "title": "Stochastic Spiking Attention: Accelerating Attention with Stochastic  Computing in Spiking Networks",
    "abstract": "Spiking Neural Networks (SNNs) have been recently integrated into Transformer architectures due to their potential to reduce computational demands and to improve power efficiency. Yet, the implementation of the attention mechanism using spiking signals on general-purpose computing platforms remains inefficient. In this paper, we propose a novel framework leveraging stochastic computing (SC) to effectively execute the dot-product attention for SNN-based Transformers. We demonstrate that our approach can achieve high classification accuracy ($83.53\\%$) on CIFAR-10 within 10 time steps, which is comparable to the performance of a baseline artificial neural network implementation ($83.66\\%$). We estimate that the proposed SC approach can lead to over $6.3\\times$ reduction in computing energy and $1.7\\times$ reduction in memory access costs for a digital CMOS-based ASIC design. We experimentally validate our stochastic attention block design through an FPGA implementation, which is shown to achieve $48\\times$ lower latency as compared to a GPU implementation, while consuming $15\\times$ less power. ",
    "url": "https://arxiv.org/abs/2402.09109",
    "authors": [
      "Zihang Song",
      "Prabodh Katti",
      "Osvaldo Simeone",
      "Bipin Rajendran"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.09115",
    "title": "Integrated Topology and Traffic Engineering for Reconfigurable  Datacenter Networks",
    "abstract": "The state-of-the-art topologies of datacenter networks are fixed, based on electrical switching technology, and by now, we understand their throughput and cost well. For the past years, researchers have been developing novel optical switching technologies that enable the emergence of reconfigurable datacenter networks (RDCNs) that support dynamic psychical topologies. The art of network design of dynamic topologies, i.e., 'Topology Engineering,' is still in its infancy. Different designs offer distinct advantages, such as faster switch reconfiguration times or demand-aware topologies, and to date, it is yet unclear what design maximizes the throughput. This paper aims to improve our analytical understanding and formally studies the throughput of reconfigurable networks by presenting a general and unifying model for dynamic networks and their topology and traffic engineering. We use our model to study demand-oblivious and demand-aware systems and prove new upper bounds for the throughput of a system as a function of its topology and traffic schedules. Next, we offer a novel system design that combines both demand-oblivious and demand-aware schedules, and we prove its throughput supremacy under a large family of demand matrices. We evaluate our design numerically for sparse and dense traffic and show that our approach can outperform other designs by up to 25% using common network parameters. ",
    "url": "https://arxiv.org/abs/2402.09115",
    "authors": [
      "Chen Griner",
      "Chen Avin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.09126",
    "title": "MPIrigen: MPI Code Generation through Domain-Specific Language Models",
    "abstract": "The imperative need to scale computation across numerous nodes highlights the significance of efficient parallel computing, particularly in the realm of Message Passing Interface (MPI) integration. The challenging parallel programming task of generating MPI-based parallel programs has remained unexplored. This study first investigates the performance of state-of-the-art language models in generating MPI-based parallel programs. Findings reveal that widely used models such as GPT-3.5 and PolyCoder (specialized multi-lingual code models) exhibit notable performance degradation, when generating MPI-based programs compared to general-purpose programs. In contrast, domain-specific models such as MonoCoder, which are pretrained on MPI-related programming languages of C and C++, outperform larger models. Subsequently, we introduce a dedicated downstream task of MPI-based program generation by fine-tuning MonoCoder on HPCorpusMPI. We call the resulting model as MPIrigen. We propose an innovative preprocessing for completion only after observing the whole code, thus enabling better completion with a wider context. Comparative analysis against GPT-3.5 zero-shot performance, using a novel HPC-oriented evaluation method, demonstrates that MPIrigen excels in generating accurate MPI functions up to 0.8 accuracy in location and function predictions, and with more than 0.9 accuracy for argument predictions. The success of this tailored solution underscores the importance of domain-specific fine-tuning in optimizing language models for parallel computing code generation, paving the way for a new generation of automatic parallelization tools. The sources of this work are available at our GitHub MPIrigen repository: https://github.com/Scientific-Computing-Lab-NRCN/MPI-rigen ",
    "url": "https://arxiv.org/abs/2402.09126",
    "authors": [
      "Nadav Schneider",
      "Niranjan Hasabnis",
      "Vy A. Vo",
      "Tal Kadosh",
      "Neva Krien",
      "Mihai Capot\u0103",
      "Abdul Wasay",
      "Guy Tamir",
      "Ted Willke",
      "Nesreen Ahmed",
      "Yuval Pinter",
      "Timothy Mattson",
      "Gal Oren"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.09132",
    "title": "Exploring the Adversarial Capabilities of Large Language Models",
    "abstract": "The proliferation of large language models (LLMs) has sparked widespread and general interest due to their strong language generation capabilities, offering great potential for both industry and research. While previous research delved into the security and privacy issues of LLMs, the extent to which these models can exhibit adversarial behavior remains largely unexplored. Addressing this gap, we investigate whether common publicly available LLMs have inherent capabilities to perturb text samples to fool safety measures, so-called adversarial examples resp.~attacks. More specifically, we investigate whether LLMs are inherently able to craft adversarial examples out of benign samples to fool existing safe rails. Our experiments, which focus on hate speech detection, reveal that LLMs succeed in finding adversarial perturbations, effectively undermining hate speech detection systems. Our findings carry significant implications for (semi-)autonomous systems relying on LLMs, highlighting potential challenges in their interaction with existing systems and safety measures. ",
    "url": "https://arxiv.org/abs/2402.09132",
    "authors": [
      "Lukas Struppek",
      "Minh Hieu Le",
      "Dominik Hintersdorf",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09136",
    "title": "DolphCoder: Echo-Locating Code Large Language Models with Diverse and  Multi-Objective Instruction Tuning",
    "abstract": "Code Large Language Models (Code LLMs) have demonstrated outstanding performance in code-related tasks. Several instruction tuning approaches have been proposed to boost the code generation performance of pre-trained Code LLMs. In this paper, we introduce a diverse instruction model (DolphCoder) with self-evaluating for code generation. It learns diverse instruction targets and combines a code evaluation objective to enhance its code generation ability. Our model achieves superior performance on the HumanEval and MBPP benchmarks, demonstrating new insights for future code instruction tuning work. Our key findings are: (1) Augmenting more diverse responses with distinct reasoning paths increases the code capability of LLMs. (2) Improving one's ability to evaluate the correctness of code solutions also enhances their ability to create it. ",
    "url": "https://arxiv.org/abs/2402.09136",
    "authors": [
      "Yejie Wang",
      "Keqing He",
      "Guanting Dong",
      "Pei Wang",
      "Weihao Zeng",
      "Muxi Diao",
      "Yutao Mou",
      "Mengdi Zhang",
      "Jingang Wang",
      "Xunliang Cai",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.09141",
    "title": "Advancing NLP Models with Strategic Text Augmentation: A Comprehensive  Study of Augmentation Methods and Curriculum Strategies",
    "abstract": "This study conducts a thorough evaluation of text augmentation techniques across a variety of datasets and natural language processing (NLP) tasks to address the lack of reliable, generalized evidence for these methods. It examines the effectiveness of these techniques in augmenting training sets to improve performance in tasks such as topic classification, sentiment analysis, and offensive language detection. The research emphasizes not only the augmentation methods, but also the strategic order in which real and augmented instances are introduced during training. A major contribution is the development and evaluation of Modified Cyclical Curriculum Learning (MCCL) for augmented datasets, which represents a novel approach in the field. Results show that specific augmentation methods, especially when integrated with MCCL, significantly outperform traditional training approaches in NLP model performance. These results underscore the need for careful selection of augmentation techniques and sequencing strategies to optimize the balance between speed and quality improvement in various NLP tasks. The study concludes that the use of augmentation methods, especially in conjunction with MCCL, leads to improved results in various classification tasks, providing a foundation for future advances in text augmentation strategies in NLP. ",
    "url": "https://arxiv.org/abs/2402.09141",
    "authors": [
      "Himmet Toprak Kesgin",
      "Mehmet Fatih Amasyali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.09142",
    "title": "When Representations Align: Universality in Representation Learning  Dynamics",
    "abstract": "Deep neural networks come in many sizes and architectures. The choice of architecture, in conjunction with the dataset and learning algorithm, is commonly understood to affect the learned neural representations. Yet, recent results have shown that different architectures learn representations with striking qualitative similarities. Here we derive an effective theory of representation learning under the assumption that the encoding map from input to hidden representation and the decoding map from representation to output are arbitrary smooth functions. This theory schematizes representation learning dynamics in the regime of complex, large architectures, where hidden representations are not strongly constrained by the parametrization. We show through experiments that the effective theory describes aspects of representation learning dynamics across a range of deep networks with different activation functions and architectures, and exhibits phenomena similar to the \"rich\" and \"lazy\" regime. While many network behaviors depend quantitatively on architecture, our findings point to certain behaviors that are widely conserved once models are sufficiently flexible. ",
    "url": "https://arxiv.org/abs/2402.09142",
    "authors": [
      "Loek van Rossem",
      "Andrew M. Saxe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2402.09146",
    "title": "ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural  Networks",
    "abstract": "In this paper, we present a novel framework for enhancing the performance of Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional layers and addressing the critical challenges associated with them. Traditional quanvolutional layers, although beneficial for feature extraction, have largely been static, offering limited adaptability. Unlike state-of-the-art, our research overcomes this limitation by enabling training within these layers, significantly increasing the flexibility and potential of QuNNs. However, the introduction of multiple trainable quanvolutional layers induces complexities in gradient-based optimization, primarily due to the difficulty in accessing gradients across these layers. To resolve this, we propose a novel architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging the concept of residual learning, which facilitates the flow of gradients by adding skip connections between layers. By inserting residual blocks between quanvolutional layers, we ensure enhanced gradient access throughout the network, leading to improved training performance. Moreover, we provide empirical evidence on the strategic placement of these residual blocks within QuNNs. Through extensive experimentation, we identify an efficient configuration of residual blocks, which enables gradients across all the layers in the network that eventually results in efficient training. Our findings suggest that the precise location of residual blocks plays a crucial role in maximizing the performance gains in QuNNs. Our results mark a substantial step forward in the evolution of quantum deep learning, offering new avenues for both theoretical development and practical quantum computing applications. ",
    "url": "https://arxiv.org/abs/2402.09146",
    "authors": [
      "Muhammad Kashif",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2402.09151",
    "title": "Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for  Chinese Mental Health Text Analysis",
    "abstract": "In the current environment, psychological issues are prevalent and widespread, with social media serving as a key outlet for individuals to share their feelings. This results in the generation of vast quantities of data daily, where negative emotions have the potential to precipitate crisis situations. There is a recognized need for models capable of efficient analysis. While pre-trained language models have demonstrated their effectiveness broadly, there's a noticeable gap in pre-trained models tailored for specialized domains like psychology. To address this, we have collected a huge dataset from Chinese social media platforms and enriched it with publicly available datasets to create a comprehensive database encompassing 3.36 million text entries. To enhance the model's applicability to psychological text analysis, we integrated psychological lexicons into the pre-training masking mechanism. Building on an existing Chinese language model, we performed adaptive training to develop a model specialized for the psychological domain. We assessed our model's effectiveness across four public benchmarks, where it not only surpassed the performance of standard pre-trained models but also showed a inclination for making psychologically relevant predictions. Due to concerns regarding data privacy, the dataset will not be made publicly available. However, we have made the pre-trained models and codes publicly accessible to the community via: https://github.com/zwzzzQAQ/Chinese-MentalBERT. ",
    "url": "https://arxiv.org/abs/2402.09151",
    "authors": [
      "Wei Zhai",
      "Hongzhi Qi",
      "Qing Zhao",
      "Jianqiang Li",
      "Ziqi Wang",
      "Han Wang",
      "Bing Xiang Yang",
      "Guanghui Fu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09154",
    "title": "Attacking Large Language Models with Projected Gradient Descent",
    "abstract": "Current LLM alignment methods are readily broken through specifically crafted adversarial prompts. While crafting adversarial prompts using discrete optimization is highly effective, such attacks typically use more than 100,000 LLM calls. This high computational cost makes them unsuitable for, e.g., quantitative analyses and adversarial training. To remedy this, we revisit Projected Gradient Descent (PGD) on the continuously relaxed input prompt. Although previous attempts with ordinary gradient-based attacks largely failed, we show that carefully controlling the error introduced by the continuous relaxation tremendously boosts their efficacy. Our PGD for LLMs is up to one order of magnitude faster than state-of-the-art discrete optimization to achieve the same devastating attack results. ",
    "url": "https://arxiv.org/abs/2402.09154",
    "authors": [
      "Simon Geisler",
      "Tom Wollschl\u00e4ger",
      "M. H. I. Abdalla",
      "Johannes Gasteiger",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09158",
    "title": "Wireless Crowd Detection for Smart Overtourism Mitigation",
    "abstract": "Overtourism occurs when the number of tourists exceeds the carrying capacity of a destination, leading to negative impacts on the environment, culture, and quality of life for residents. By monitoring overtourism, destination managers can identify areas of concern and implement measures to mitigate the negative impacts of tourism while promoting smarter tourism practices. This can help ensure that tourism benefits both visitors and residents while preserving the natural and cultural resources that make these destinations so appealing. This chapter describes a low-cost approach to monitoring overtourism based on mobile devices' wireless activity. A flexible architecture was designed for a smart tourism toolkit to be used by Small and Medium-sized Enterprises (SMEs) in crowding management solutions, to build better tourism services, improve efficiency and sustainability, and reduce the overwhelming feeling of pressure in critical hotspots. The crowding sensors count the number of surrounding mobile devices, by detecting trace elements of wireless technologies, mitigating the effect of MAC address randomization. They run detection programs for several technologies, and fingerprinting analysis results are only stored locally in an anonymized database, without infringing privacy rights. After that edge computing, sensors communicate the crowding information to a cloud server, by using a variety of uplink techniques to mitigate local connectivity limitations, something that has been often disregarded in alternative approaches. Field validation of sensors has been performed on Iscte's campus. Preliminary results show that these sensors can be deployed in multiple scenarios and provide a diversity of spatio-temporal crowding data that can scaffold tourism overcrowding management strategies. ",
    "url": "https://arxiv.org/abs/2402.09158",
    "authors": [
      "Tom\u00e1s Mestre Santos",
      "Rui Neto Marinheiro",
      "Fernando Brito e Abreu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.09165",
    "title": "Unifying Invariance and Spuriousity for Graph Out-of-Distribution via  Probability of Necessity and Sufficiency",
    "abstract": "Graph Out-of-Distribution (OOD), requiring that models trained on biased data generalize to the unseen test data, has a massive of real-world applications. One of the most mainstream methods is to extract the invariant subgraph by aligning the original and augmented data with the help of environment augmentation. However, these solutions might lead to the loss or redundancy of semantic subgraph and further result in suboptimal generalization. To address this challenge, we propose a unified framework to exploit the Probability of Necessity and Sufficiency to extract the Invariant Substructure (PNSIS). Beyond that, this framework further leverages the spurious subgraph to boost the generalization performance in an ensemble manner to enhance the robustness on the noise data. Specificially, we first consider the data generation process for graph data. Under mild conditions, we show that the invariant subgraph can be extracted by minimizing an upper bound, which is built on the theoretical advance of probability of necessity and sufficiency. To further bridge the theory and algorithm, we devise the PNSIS model, which involves an invariant subgraph extractor for invariant graph learning as well invariant and spurious subgraph classifiers for generalization enhancement. Experimental results demonstrate that our \\textbf{PNSIS} model outperforms the state-of-the-art techniques on graph OOD on several benchmarks, highlighting the effectiveness in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2402.09165",
    "authors": [
      "Xuexin Chen",
      "Ruichu Cai",
      "Kaitao Zheng",
      "Zhifan Jiang",
      "Zhengting Huang",
      "Zhifeng Hao",
      "Zijian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09167",
    "title": "Evolving Restricted Boltzmann Machine-Kohonen Network for Online  Clustering",
    "abstract": "A novel online clustering algorithm is presented where an Evolving Restricted Boltzmann Machine (ERBM) is embedded with a Kohonen Network called ERBM-KNet. The proposed ERBM-KNet efficiently handles streaming data in a single-pass mode using the ERBM, employing a bias-variance strategy for neuron growing and pruning, as well as online clustering based on a cluster update strategy for cluster prediction and cluster center update using KNet. Initially, ERBM evolves its architecture while processing unlabeled image data, effectively disentangling the data distribution in the latent space. Subsequently, the KNet utilizes the feature extracted from ERBM to predict the number of clusters and updates the cluster centers. By overcoming the common challenges associated with clustering algorithms, such as prior initialization of the number of clusters and subpar clustering accuracy, the proposed ERBM-KNet offers significant improvements. Extensive experimental evaluations on four benchmarks and one industry dataset demonstrate the superiority of ERBM-KNet compared to state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2402.09167",
    "authors": [
      "J. Senthilnath",
      "Adithya Bhattiprolu",
      "Ankur Singh",
      "Bangjian Zhou",
      "Min Wu",
      "J\u00f3n Atli Benediktsson",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09177",
    "title": "Leveraging the Context through Multi-Round Interactions for Jailbreaking  Attacks",
    "abstract": "Large Language Models (LLMs) are susceptible to Jailbreaking attacks, which aim to extract harmful information by subtly modifying the attack query. As defense mechanisms evolve, directly obtaining harmful information becomes increasingly challenging for Jailbreaking attacks. In this work, inspired by human practices of indirect context to elicit harmful information, we focus on a new attack form called Contextual Interaction Attack. The idea relies on the autoregressive nature of the generation process in LLMs. We contend that the prior context--the information preceding the attack query--plays a pivotal role in enabling potent Jailbreaking attacks. Specifically, we propose an approach that leverages preliminary question-answer pairs to interact with the LLM. By doing so, we guide the responses of the model toward revealing the 'desired' harmful information. We conduct experiments on four different LLMs and demonstrate the efficacy of this attack, which is black-box and can also transfer across LLMs. We believe this can lead to further developments and understanding of the context vector in LLMs. ",
    "url": "https://arxiv.org/abs/2402.09177",
    "authors": [
      "Yixin Cheng",
      "Markos Georgopoulos",
      "Volkan Cevher",
      "Grigorios G. Chrysos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.09199",
    "title": "Ten Words Only Still Help: Improving Black-Box AI-Generated Text  Detection via Proxy-Guided Efficient Re-Sampling",
    "abstract": "With the rapidly increasing application of large language models (LLMs), their abuse has caused many undesirable societal problems such as fake news, academic dishonesty, and information pollution. This makes AI-generated text (AIGT) detection of great importance. Among existing methods, white-box methods are generally superior to black-box methods in terms of performance and generalizability, but they require access to LLMs' internal states and are not applicable to black-box settings. In this paper, we propose to estimate word generation probabilities as pseudo white-box features via multiple re-sampling to help improve AIGT detection under the black-box setting. Specifically, we design POGER, a proxy-guided efficient re-sampling method, which selects a small subset of representative words (e.g., 10 words) for performing multiple re-sampling in black-box AIGT detection. Experiments on datasets containing texts from humans and seven LLMs show that POGER outperforms all baselines in macro F1 under black-box, partial white-box, and out-of-distribution settings and maintains lower re-sampling costs than its existing counterparts. ",
    "url": "https://arxiv.org/abs/2402.09199",
    "authors": [
      "Yuhui Shi",
      "Qiang Sheng",
      "Juan Cao",
      "Hao Mi",
      "Beizhe Hu",
      "Danding Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09200",
    "title": "Discovering Command and Control (C2) Channels on Tor and Public Networks  Using Reinforcement Learning",
    "abstract": "Command and control (C2) channels are an essential component of many types of cyber attacks, as they enable attackers to remotely control their malware-infected machines and execute harmful actions, such as propagating malicious code across networks, exfiltrating confidential data, or initiating distributed denial of service (DDoS) attacks. Identifying these C2 channels is therefore crucial in helping to mitigate and prevent cyber attacks. However, identifying C2 channels typically involves a manual process, requiring deep knowledge and expertise in cyber operations. In this paper, we propose a reinforcement learning (RL) based approach to automatically emulate C2 attack campaigns using both the normal (public) and the Tor networks. In addition, payload size and network firewalls are configured to simulate real-world attack scenarios. Results on a typical network configuration show that the RL agent can automatically discover resilient C2 attack paths utilizing both Tor-based and conventional communication channels, while also bypassing network firewalls. ",
    "url": "https://arxiv.org/abs/2402.09200",
    "authors": [
      "Cheng Wang",
      "Christopher Redino",
      "Abdul Rahman",
      "Ryan Clark",
      "Daniel Radke",
      "Tyler Cody",
      "Dhruv Nandakumar",
      "Edward Bowen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.09213",
    "title": "Identification of cohesive subgroups in a university hall of residence  during the COVID-19 pandemic using a social network analysis approach",
    "abstract": "The aims: (i) analyze connectivity between subgroups of university students, (ii) assess which bridges of relational contacts are essential for connecting or disconnecting subgroups and (iii) to explore the similarities between the attributes of the subgroup nodes in relation to the pandemic context. During the COVID-19 pandemic, young university students have experienced significant changes in their relationships, especially in the halls of residence. Previous research has shown the importance of relationship structure in contagion processes. However, there is a lack of studies in the university setting, where students live closely together. The case study methodology was applied to carry out a descriptive study. The participation consisted of 43 university students living in the same hall of residence. Social network analysis has been applied for data analysis. Factions and Girvan Newman algorithms have been applied to detect the existing cohesive subgroups. The UCINET tool was used for the calculation of the SNA measure. A visualization of the global network will be carried out using Gephi software. After applying the Girvan-Newman and Factions, in both cases it was found that the best division into subgroups was the one that divided the network into 4 subgroups. There is high degree of cohesion within the subgroups and a low cohesion between them. The relationship between subgroup membership and gender was significant. The degree of COVID-19 infection is related to the degree of clustering between the students. College students form subgroups in their residence. Social network analysis facilitates an understanding of structural behavior during the pandemic. The study provides evidence on the importance of gender, race and the building where they live in creating network structures that favor, or not, contagion during a pandemic. ",
    "url": "https://arxiv.org/abs/2402.09213",
    "authors": [
      "Pilar Marqu\u00e9s-S\u00e1nchez",
      "Arrate Pinto-Carral",
      "Tania Fern\u00e1ndez-Villa",
      "Ana V\u00e1zquez-Casares",
      "Cristina Li\u00e9bana-Presa",
      "Jos\u00e9 Alberto Ben\u00edtez-Andrades"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2402.09219",
    "title": "A case study of university student networks and the COVID-19 pandemic  using a social network analysis approach in halls of residence",
    "abstract": "The COVID-19 pandemic has meant that young university students have had to adapt their learning and have a reduced relational context. Adversity contexts build models of human behaviour based on relationships. However, there is a lack of studies that analyse the behaviour of university students based on their social structure in the context of a pandemic. This information could be useful in making decisions on how to plan collective responses to adversities. The Social Network Analysis (SNA) method has been chosen to address this structural perspective. The aim of our research is to describe the structural behaviour of students in university residences during the COVID-19 pandemic with a more in-depth analysis of student leaders. A descriptive cross-sectional study was carried out at one Spanish Public University, Le\\'on, from 23th October 2020 to 20th November 2020. The participation was of 93 students, from four halls of residence. The data were collected from a database created specifically at the university to \"track\" contacts in the COVID-19 pandemic, SiVeUle. We applied the SNA for the analysis of the data. The leadership on the university residence was measured using centrality measures. The top leaders were analyzed using the Egonetwork and an assessment of the key players. Students with higher social reputations experience higher levels of pandemic contagion in relation to COVID-19 infection. The results were statistically significant between the centrality in the network and the results of the COVID-19 infection. The most leading students showed a high degree of Betweenness, and three students had the key player structure in the network. Networking behaviour of university students in halls of residence could be related to contagion in the COVID-19 pandemic. ",
    "url": "https://arxiv.org/abs/2402.09219",
    "authors": [
      "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
      "Tania Fern\u00e1ndez-Villa",
      "Carmen Benavides",
      "Andrea Gayubo-Serrenes",
      "Vicente Mart\u00edn",
      "Pilar Marqu\u00e9s-S\u00e1nchez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2402.09226",
    "title": "Directional Convergence Near Small Initializations and Saddles in  Two-Homogeneous Neural Networks",
    "abstract": "This paper examines gradient flow dynamics of two-homogeneous neural networks for small initializations, where all weights are initialized near the origin. For both square and logistic losses, it is shown that for sufficiently small initializations, the gradient flow dynamics spend sufficient time in the neighborhood of the origin to allow the weights of the neural network to approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of a neural correlation function that quantifies the correlation between the output of the neural network and corresponding labels in the training data set. For square loss, it has been observed that neural networks undergo saddle-to-saddle dynamics when initialized close to the origin. Motivated by this, this paper also shows a similar directional convergence among weights of small magnitude in the neighborhood of certain saddle points. ",
    "url": "https://arxiv.org/abs/2402.09226",
    "authors": [
      "Akshay Kumar",
      "Jarvis Haupt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.09230",
    "title": "Context Composing for Full Line Code Completion",
    "abstract": "Code Completion is one of the most used Integrated Development Environment (IDE) features, which affects the everyday life of a software developer. Modern code completion approaches moved from the composition of several static analysis-based contributors to pipelines that involve neural networks. This change allows the proposal of longer code suggestions while maintaining the relatively short time spent on generation itself. At JetBrains, we put a lot of effort into perfecting the code completion workflow so it can be both helpful and non-distracting for a programmer. We managed to ship the Full Line Code Completion feature to PyCharm Pro IDE and proved its usefulness in A/B testing on hundreds of real Python users. The paper describes our approach to context composing for the Transformer model that is a core of the feature's implementation. In addition to that, we share our next steps to improve the feature and emphasize the importance of several research aspects in the area. ",
    "url": "https://arxiv.org/abs/2402.09230",
    "authors": [
      "Anton Semenkin",
      "Yaroslav Sokolov",
      "Evgeniia Vu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09234",
    "title": "Multi-Hierarchical Surrogate Learning for Structural Dynamics of  Automotive Crashworthiness Using Graph Convolutional Neural Networks",
    "abstract": "Crash simulations play an essential role in improving vehicle safety, design optimization, and injury risk estimation. Unfortunately, numerical solutions of such problems using state-of-the-art high-fidelity models require significant computational effort. Conventional data-driven surrogate modeling approaches create low-dimensional embeddings for evolving the dynamics in order to circumvent this computational effort. Most approaches directly operate on high-resolution data obtained from numerical discretization, which is both costly and complicated for mapping the flow of information over large spatial distances. Furthermore, working with a fixed resolution prevents the adaptation of surrogate models to environments with variable computing capacities, different visualization resolutions, and different accuracy requirements. We thus propose a multi-hierarchical framework for structurally creating a series of surrogate models for a kart frame, which is a good proxy for industrial-relevant crash simulations, at different levels of resolution. For multiscale phenomena, macroscale features are captured on a coarse surrogate, whereas microscale effects are resolved by finer ones. The learned behavior of the individual surrogates is passed from coarse to finer levels through transfer learning. In detail, we perform a mesh simplification on the kart model to obtain multi-resolution representations of it. We then train a graph-convolutional neural network-based surrogate that learns parameter-dependent low-dimensional latent dynamics on the coarsest representation. Subsequently, another, similarly structured surrogate is trained on the residual of the first surrogate using a finer resolution. This step can be repeated multiple times. By doing so, we construct multiple surrogates for the same system with varying hardware requirements and increasing accuracy. ",
    "url": "https://arxiv.org/abs/2402.09234",
    "authors": [
      "Jonas Kneifl",
      "J\u00f6rg Fehr",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2402.09236",
    "title": "Learning Interpretable Concepts: Unifying Causal Representation Learning  and Foundation Models",
    "abstract": "To build intelligent machine learning systems, there are two broad approaches. One approach is to build inherently interpretable models, as endeavored by the growing field of causal representation learning. The other approach is to build highly-performant foundation models and then invest efforts into understanding how they work. In this work, we relate these two approaches and study how to learn human-interpretable concepts from data. Weaving together ideas from both fields, we formally define a notion of concepts and show that they can be provably recovered from diverse data. Experiments on synthetic data and large language models show the utility of our unified approach. ",
    "url": "https://arxiv.org/abs/2402.09236",
    "authors": [
      "Goutham Rajendran",
      "Simon Buchholz",
      "Bryon Aragam",
      "Bernhard Sch\u00f6lkopf",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.09239",
    "title": "Robust Training of Temporal GNNs using Nearest Neighbours based Hard  Negatives",
    "abstract": "Temporal graph neural networks Tgnn have exhibited state-of-art performance in future-link prediction tasks. Training of these TGNNs is enumerated by uniform random sampling based unsupervised loss. During training, in the context of a positive example, the loss is computed over uninformative negatives, which introduces redundancy and sub-optimal performance. In this paper, we propose modified unsupervised learning of Tgnn, by replacing the uniform negative sampling with importance-based negative sampling. We theoretically motivate and define the dynamically computed distribution for a sampling of negative examples. Finally, using empirical evaluations over three real-world datasets, we show that Tgnn trained using loss based on proposed negative sampling provides consistent superior performance. ",
    "url": "https://arxiv.org/abs/2402.09239",
    "authors": [
      "Shubham Gupta",
      "Srikanta Bedathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.09241",
    "title": "Efficient One-stage Video Object Detection by Exploiting Temporal  Consistency",
    "abstract": "Recently, one-stage detectors have achieved competitive accuracy and faster speed compared with traditional two-stage detectors on image data. However, in the field of video object detection (VOD), most existing VOD methods are still based on two-stage detectors. Moreover, directly adapting existing VOD methods to one-stage detectors introduces unaffordable computational costs. In this paper, we first analyse the computational bottlenecks of using one-stage detectors for VOD. Based on the analysis, we present a simple yet efficient framework to address the computational bottlenecks and achieve efficient one-stage VOD by exploiting the temporal consistency in video frames. Specifically, our method consists of a location-prior network to filter out background regions and a size-prior network to skip unnecessary computations on low-level feature maps for specific frames. We test our method on various modern one-stage detectors and conduct extensive experiments on the ImageNet VID dataset. Excellent experimental results demonstrate the superior effectiveness, efficiency, and compatibility of our method. The code is available at https://github.com/guanxiongsun/vfe.pytorch. ",
    "url": "https://arxiv.org/abs/2402.09241",
    "authors": [
      "Guanxiong Sun",
      "Yang Hua",
      "Guosheng Hu",
      "Neil Robertson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09242",
    "title": "Synthesizing Knowledge-enhanced Features for Real-world Zero-shot Food  Detection",
    "abstract": "Food computing brings various perspectives to computer vision like vision-based food analysis for nutrition and health. As a fundamental task in food computing, food detection needs Zero-Shot Detection (ZSD) on novel unseen food objects to support real-world scenarios, such as intelligent kitchens and smart restaurants. Therefore, we first benchmark the task of Zero-Shot Food Detection (ZSFD) by introducing FOWA dataset with rich attribute annotations. Unlike ZSD, fine-grained problems in ZSFD like inter-class similarity make synthesized features inseparable. The complexity of food semantic attributes further makes it more difficult for current ZSD methods to distinguish various food categories. To address these problems, we propose a novel framework ZSFDet to tackle fine-grained problems by exploiting the interaction between complex attributes. Specifically, we model the correlation between food categories and attributes in ZSFDet by multi-source graphs to provide prior knowledge for distinguishing fine-grained features. Within ZSFDet, Knowledge-Enhanced Feature Synthesizer (KEFS) learns knowledge representation from multiple sources (e.g., ingredients correlation from knowledge graph) via the multi-source graph fusion. Conditioned on the fusion of semantic knowledge representation, the region feature diffusion model in KEFS can generate fine-grained features for training the effective zero-shot detector. Extensive evaluations demonstrate the superior performance of our method ZSFDet on FOWA and the widely-used food dataset UECFOOD-256, with significant improvements by 1.8% and 3.7% ZSD mAP compared with the strong baseline RRFS. Further experiments on PASCAL VOC and MS COCO prove that enhancement of the semantic knowledge can also improve the performance on general ZSD. Code and dataset are available at https://github.com/LanceZPF/KEFS. ",
    "url": "https://arxiv.org/abs/2402.09242",
    "authors": [
      "Pengfei Zhou",
      "Weiqing Min",
      "Jiajun Song",
      "Yang Zhang",
      "Shuqiang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09264",
    "title": "UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers",
    "abstract": "Traditional machine learning techniques are prone to generating inaccurate predictions when confronted with shifts in the distribution of data between the training and testing phases. This vulnerability can lead to severe consequences, especially in applications such as mobile healthcare. Uncertainty estimation has the potential to mitigate this issue by assessing the reliability of a model's output. However, existing uncertainty estimation techniques often require substantial computational resources and memory, making them impractical for implementation on microcontrollers (MCUs). This limitation hinders the feasibility of many important on-device wearable event detection (WED) applications, such as heart attack detection. In this paper, we present UR2M, a novel Uncertainty and Resource-aware event detection framework for MCUs. Specifically, we (i) develop an uncertainty-aware WED based on evidential theory for accurate event detection and reliable uncertainty estimation; (ii) introduce a cascade ML framework to achieve efficient model inference via early exits, by sharing shallower model layers among different event models; (iii) optimize the deployment of the model and MCU library for system efficiency. We conducted extensive experiments and compared UR2M to traditional uncertainty baselines using three wearable datasets. Our results demonstrate that UR2M achieves up to 864% faster inference speed, 857% energy-saving for uncertainty estimation, 55% memory saving on two popular MCUs, and a 22% improvement in uncertainty quantification performance. UR2M can be deployed on a wide range of MCUs, significantly expanding real-time and reliable WED applications. ",
    "url": "https://arxiv.org/abs/2402.09264",
    "authors": [
      "Hong Jia",
      "Young D. Kwon",
      "Dong Ma",
      "Nhat Pham",
      "Lorena Qendro",
      "Tam Vu",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.09272",
    "title": "Insights and caveats from mining local and global temporal motifs in  cryptocurrency transaction networks",
    "abstract": "Distributed ledger technologies have opened up a wealth of fine-grained transaction data from cryptocurrencies like Bitcoin and Ethereum. This allows research into problems like anomaly detection, anti-money laundering, pattern mining and activity clustering (where data from traditional currencies is rarely available). The formalism of temporal networks offers a natural way of representing this data and offers access to a wealth of metrics and models. However, the large scale of the data presents a challenge using standard graph analysis techniques. We use temporal motifs to analyse two Bitcoin datasets and one NFT dataset, using sequences of three transactions and up to three users. We show that the commonly used technique of simply counting temporal motifs over all users and all time can give misleading conclusions. Here we also study the motifs contributed by each user and discover that the motif distribution is heavy-tailed and that the key players have diverse motif signatures. We study the motifs that occur in different time periods and find events and anomalous activity that cannot be seen just by a count on the whole dataset. Studying motif completion time reveals dynamics driven by human behaviour as well as algorithmic behaviour. ",
    "url": "https://arxiv.org/abs/2402.09272",
    "authors": [
      "Naomi A. Arnold",
      "Peijie Zhong",
      "Cheick Tidiane Ba",
      "Ben Steer",
      "Raul Mondragon",
      "Felix Cuadrado",
      "Renaud Lambiotte",
      "Richard G. Clegg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.09275",
    "title": "The socialisation of the adolescent who carries out team sports: a  transversal study of centrality with a social network analysis",
    "abstract": "Objectives: This study analyzed adolescent physical activity, its link to overweight, and the social network structure in group sports participants, focusing on centrality measures. Setting: Conducted in 11 classrooms across 5 schools in Ponferrada, Spain. Participants: Included 235 adolescents (49.4% female), categorized as normal weight or overweight. Methods: The Physical Activity Questionnaire for Adolescents (PAQ-A) assessed physical activity levels. Social network analysis evaluated centrality in varying contact degrees. Results: 30.2% were overweight. Males scored higher in PAQ-A and were more likely to engage in group sports. No significant correlation was found between physical activity and weight in the total sample. However, overweight females reported higher exercise levels. Centrality analysis showed gender differences; women in group sports had lower centrality, whereas men had higher. Conclusions: The study highlights the importance of gender and social network centrality in designing future strategies, considering peer interaction intensity ",
    "url": "https://arxiv.org/abs/2402.09275",
    "authors": [
      "Pilar Marqu\u00e9s-S\u00e1nchez",
      "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
      "Mar\u00eda Dolores Calvo S\u00e1nchez",
      "Natalia Arias"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2402.09299",
    "title": "Trained Without My Consent: Detecting Code Inclusion In Language Models  Trained on Code",
    "abstract": "Code auditing ensures that the developed code adheres to standards, regulations, and copyright protection by verifying that it does not contain code from protected sources. The recent advent of Large Language Models (LLMs) as coding assistants in the software development process poses new challenges for code auditing. The dataset for training these models is mainly collected from publicly available sources. This raises the issue of intellectual property infringement as developers' codes are already included in the dataset. Therefore, auditing code developed using LLMs is challenging, as it is difficult to reliably assert if an LLM used during development has been trained on specific copyrighted codes, given that we do not have access to the training datasets of these models. Given the non-disclosure of the training datasets, traditional approaches such as code clone detection are insufficient for asserting copyright infringement. To address this challenge, we propose a new approach, TraWiC; a model-agnostic and interpretable method based on membership inference for detecting code inclusion in an LLM's training dataset. We extract syntactic and semantic identifiers unique to each program to train a classifier for detecting code inclusion. In our experiments, we observe that TraWiC is capable of detecting 83.87% of codes that were used to train an LLM. In comparison, the prevalent clone detection tool NiCad is only capable of detecting 47.64%. In addition to its remarkable performance, TraWiC has low resource overhead in contrast to pair-wise clone detection that is conducted during the auditing process of tools like CodeWhisperer reference tracker, across thousands of code snippets. ",
    "url": "https://arxiv.org/abs/2402.09299",
    "authors": [
      "Vahid Majdinasab",
      "Amin Nikanjam",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09303",
    "title": "Immediate generalisation in humans but a generalisation lag in deep  neural networks$\\unicode{x2014}$evidence for representational divergence?",
    "abstract": "Recent research has seen many behavioral comparisons between humans and deep neural networks (DNNs) in the domain of image classification. Often, comparison studies focus on the end-result of the learning process by measuring and comparing the similarities in the representations of object categories once they have been formed. However, the process of how these representations emerge$\\unicode{x2014}$that is, the behavioral changes and intermediate stages observed during the acquisition$\\unicode{x2014}$is less often directly and empirically compared. Here we report a detailed investigation of how transferable representations are acquired in human observers and various classic and state-of-the-art DNNs. We develop a constrained supervised learning environment in which we align learning-relevant parameters such as starting point, input modality, available input data and the feedback provided. Across the whole learning process we evaluate and compare how well learned representations can be generalized to previously unseen test data. Our findings indicate that in terms of absolute classification performance DNNs demonstrate a level of data efficiency comparable to$\\unicode{x2014}$and sometimes even exceeding that$\\unicode{x2014}$of human learners, challenging some prevailing assumptions in the field. However, comparisons across the entire learning process reveal significant representational differences: while DNNs' learning is characterized by a pronounced generalisation lag, humans appear to immediately acquire generalizable representations without a preliminary phase of learning training set-specific information that is only later transferred to novel data. ",
    "url": "https://arxiv.org/abs/2402.09303",
    "authors": [
      "Lukas S. Huber",
      "Fred W. Mast",
      "Felix A. Wichmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2402.09305",
    "title": "Embracing the black box: Heading towards foundation models for causal  discovery from time series data",
    "abstract": "Causal discovery from time series data encompasses many existing solutions, including those based on deep learning techniques. However, these methods typically do not endorse one of the most prevalent paradigms in deep learning: End-to-end learning. To address this gap, we explore what we call Causal Pretraining. A methodology that aims to learn a direct mapping from multivariate time series to the underlying causal graphs in a supervised manner. Our empirical findings suggest that causal discovery in a supervised manner is possible, assuming that the training and test time series samples share most of their dynamics. More importantly, we found evidence that the performance of Causal Pretraining can increase with data and model size, even if the additional data do not share the same dynamics. Further, we provide examples where causal discovery for real-world data with causally pretrained neural networks is possible within limits. We argue that this hints at the possibility of a foundation model for causal discovery. ",
    "url": "https://arxiv.org/abs/2402.09305",
    "authors": [
      "Gideon Stein",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.09315",
    "title": "Few-Shot Object Detection with Sparse Context Transformers",
    "abstract": "Few-shot detection is a major task in pattern recognition which seeks to localize objects using models trained with few labeled data. One of the mainstream few-shot methods is transfer learning which consists in pretraining a detection model in a source domain prior to its fine-tuning in a target domain. However, it is challenging for fine-tuned models to effectively identify new classes in the target domain, particularly when the underlying labeled training data are scarce. In this paper, we devise a novel sparse context transformer (SCT) that effectively leverages object knowledge in the source domain, and automatically learns a sparse context from only few training images in the target domain. As a result, it combines different relevant clues in order to enhance the discrimination power of the learned detectors and reduce class confusion. We evaluate the proposed method on two challenging few-shot object detection benchmarks, and empirical results show that the proposed method obtains competitive performance compared to the related state-of-the-art. ",
    "url": "https://arxiv.org/abs/2402.09315",
    "authors": [
      "Jie Mei",
      "Mingyuan Jiu",
      "Hichem Sahbi",
      "Xiaoheng Jiang",
      "Mingliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09316",
    "title": "Only My Model On My Data: A Privacy Preserving Approach Protecting one  Model and Deceiving Unauthorized Black-Box Models",
    "abstract": "Deep neural networks are extensively applied to real-world tasks, such as face recognition and medical image classification, where privacy and data protection are critical. Image data, if not protected, can be exploited to infer personal or contextual information. Existing privacy preservation methods, like encryption, generate perturbed images that are unrecognizable to even humans. Adversarial attack approaches prohibit automated inference even for authorized stakeholders, limiting practical incentives for commercial and widespread adaptation. This pioneering study tackles an unexplored practical privacy preservation use case by generating human-perceivable images that maintain accurate inference by an authorized model while evading other unauthorized black-box models of similar or dissimilar objectives, and addresses the previous research gaps. The datasets employed are ImageNet, for image classification, Celeba-HQ dataset, for identity classification, and AffectNet, for emotion classification. Our results show that the generated images can successfully maintain the accuracy of a protected model and degrade the average accuracy of the unauthorized black-box models to 11.97%, 6.63%, and 55.51% on ImageNet, Celeba-HQ, and AffectNet datasets, respectively. ",
    "url": "https://arxiv.org/abs/2402.09316",
    "authors": [
      "Weiheng Chai",
      "Brian Testa",
      "Huantao Ren",
      "Asif Salekin",
      "Senem Velipasalar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09325",
    "title": "PC-NeRF: Parent-Child Neural Radiance Fields Using Sparse LiDAR Frames  in Autonomous Driving Environments",
    "abstract": "Large-scale 3D scene reconstruction and novel view synthesis are vital for autonomous vehicles, especially utilizing temporally sparse LiDAR frames. However, conventional explicit representations remain a significant bottleneck towards representing the reconstructed and synthetic scenes at unlimited resolution. Although the recently developed neural radiance fields (NeRF) have shown compelling results in implicit representations, the problem of large-scale 3D scene reconstruction and novel view synthesis using sparse LiDAR frames remains unexplored. To bridge this gap, we propose a 3D scene reconstruction and novel view synthesis framework called parent-child neural radiance field (PC-NeRF). Based on its two modules, parent NeRF and child NeRF, the framework implements hierarchical spatial partitioning and multi-level scene representation, including scene, segment, and point levels. The multi-level scene representation enhances the efficient utilization of sparse LiDAR point cloud data and enables the rapid acquisition of an approximate volumetric scene representation. With extensive experiments, PC-NeRF is proven to achieve high-precision novel LiDAR view synthesis and 3D reconstruction in large-scale scenes. Moreover, PC-NeRF can effectively handle situations with sparse LiDAR frames and demonstrate high deployment efficiency with limited training epochs. Our approach implementation and the pre-trained models are available at https://github.com/biter0088/pc-nerf. ",
    "url": "https://arxiv.org/abs/2402.09325",
    "authors": [
      "Xiuzhong Hu",
      "Guangming Xiong",
      "Zheng Zang",
      "Peng Jia",
      "Yuxuan Han",
      "Junyi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.09329",
    "title": "YOLOv8-AM: YOLOv8 with Attention Mechanisms for Pediatric Wrist Fracture  Detection",
    "abstract": "Wrist trauma and even fractures occur frequently in daily life, particularly among children who account for a significant proportion of fracture cases. Before performing surgery, surgeons often request patients to undergo X-ray imaging first and prepare for it based on the analysis of the radiologist. With the development of neural networks, You Only Look Once (YOLO) series models have been widely used in fracture detection as computer-assisted diagnosis (CAD). In 2023, Ultralytics presented the latest version of the YOLO models, which has been employed for detecting fractures across various parts of the body. Attention mechanism is one of the hottest methods to improve the model performance. This research work proposes YOLOv8-AM, which incorporates the attention mechanism into the original YOLOv8 architecture. Specifically, we respectively employ four attention modules, Convolutional Block Attention Module (CBAM), Global Attention Mechanism (GAM), Efficient Channel Attention (ECA), and Shuffle Attention (SA), to design the improved models and train them on GRAZPEDWRI-DX dataset. Experimental results demonstrate that the mean Average Precision at IoU 50 (mAP 50) of the YOLOv8-AM model based on ResBlock + CBAM (ResCBAM) increased from 63.6% to 65.8%, which achieves the state-of-the-art (SOTA) performance. Conversely, YOLOv8-AM model incorporating GAM obtains the mAP 50 value of 64.2%, which is not a satisfactory enhancement. Therefore, we combine ResBlock and GAM, introducing ResGAM to design another new YOLOv8-AM model, whose mAP 50 value is increased to 65.0%. ",
    "url": "https://arxiv.org/abs/2402.09329",
    "authors": [
      "Chun-Tse Chien",
      "Rui-Yang Ju",
      "Kuang-Yi Chou",
      "Chien-Sheng Lin",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09367",
    "title": "Prediction of Activated Sludge Settling Characteristics from Microscopy  Images with Deep Convolutional Neural Networks and Transfer Learning",
    "abstract": "Microbial communities play a key role in biological wastewater treatment processes. Activated sludge settling characteristics, for example, are affected by microbial community composition, varying by changes in operating conditions and influent characteristics of wastewater treatment plants (WWTPs). Timely assessment and prediction of changes in microbial composition leading to settling problems, such as filamentous bulking (FB), can prevent operational challenges, reductions in treatment efficiency, and adverse environmental impacts. This study presents an innovative computer vision-based approach to assess activated sludge-settling characteristics based on the morphological properties of flocs and filaments in microscopy images. Implementing the transfer learning of deep convolutional neural network (CNN) models, this approach aims to overcome the limitations of existing quantitative image analysis techniques. The offline microscopy image dataset was collected over two years, with weekly sampling at a full-scale industrial WWTP in Belgium. Multiple data augmentation techniques were employed to enhance the generalizability of the CNN models. Various CNN architectures, including Inception v3, ResNet18, ResNet152, ConvNeXt-nano, and ConvNeXt-S, were tested to evaluate their performance in predicting sludge settling characteristics. The sludge volume index was used as the final prediction variable, but the method can easily be adjusted to predict any other settling metric of choice. The results showed that the suggested CNN-based approach provides less labour-intensive, objective, and consistent assessments, while transfer learning notably minimises the training phase, resulting in a generalizable system that can be employed in real-time applications. ",
    "url": "https://arxiv.org/abs/2402.09367",
    "authors": [
      "Sina Borzooei",
      "Leonardo Scabini",
      "Gisele Miranda",
      "Saba Daneshgar",
      "Lukas Deblieck",
      "Piet De Langhe",
      "Odemir Bruno",
      "Bernard De Baets",
      "Ingmar Nopens",
      "Elena Torfs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2402.09381",
    "title": "GraSSRep: Graph-Based Self-Supervised Learning for Repeat Detection in  Metagenomic Assembly",
    "abstract": "Repetitive DNA (repeats) poses significant challenges for accurate and efficient genome assembly and sequence alignment. This is particularly true for metagenomic data, where genome dynamics such as horizontal gene transfer, gene duplication, and gene loss/gain complicate accurate genome assembly from metagenomic communities. Detecting repeats is a crucial first step in overcoming these challenges. To address this issue, we propose GraSSRep, a novel approach that leverages the assembly graph's structure through graph neural networks (GNNs) within a self-supervised learning framework to classify DNA sequences into repetitive and non-repetitive categories. Specifically, we frame this problem as a node classification task within a metagenomic assembly graph. In a self-supervised fashion, we rely on a high-precision (but low-recall) heuristic to generate pseudo-labels for a small proportion of the nodes. We then use those pseudo-labels to train a GNN embedding and a random forest classifier to propagate the labels to the remaining nodes. In this way, GraSSRep combines sequencing features with pre-defined and learned graph features to achieve state-of-the-art performance in repeat detection. We evaluate our method using simulated and synthetic metagenomic datasets. The results on the simulated data highlight our GraSSRep's robustness to repeat attributes, demonstrating its effectiveness in handling the complexity of repeated sequences. Additionally, our experiments with synthetic metagenomic datasets reveal that incorporating the graph structure and the GNN enhances our detection performance. Finally, in comparative analyses, GraSSRep outperforms existing repeat detection tools with respect to precision and recall. ",
    "url": "https://arxiv.org/abs/2402.09381",
    "authors": [
      "Ali Azizpour",
      "Advait Balaji",
      "Todd J. Treangen",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09390",
    "title": "HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context  Learning in Factuality Evaluation",
    "abstract": "With the widespread adoption of large language models (LLMs) in numerous applications, the challenge of factuality and the propensity for hallucinations raises significant concerns. To address this issue, particularly in retrieval-augmented in-context learning, we introduce the hierarchical graph of thoughts (HGOT), a structured, multi-layered graph approach designed to enhance the retrieval of pertinent passages during in-context learning. The framework utilizes the emergent planning capabilities of LLMs, employing the divide-and-conquer strategy to break down complex queries into manageable sub-queries. It refines self-consistency majority voting for answer selection, which incorporates the recently proposed citation recall and precision metrics to assess the quality of thoughts, linking an answer's credibility intrinsically to the thought's quality. This methodology introduces a weighted system in majority voting, prioritizing answers based on the citation quality of their thoughts. Additionally, we propose a scoring mechanism for evaluating retrieved passages, considering factors such as citation frequency and quality, self-consistency confidence, and the retrieval module's ranking. Experiments reveal that HGOT outperforms other retrieval-augmented in-context learning methods, including Demonstrate-Search-Predict (DSP), ReAct, Self-Ask, and Retrieve-then-Read on different datasets by as much as $7\\%$, demonstrating its efficacy in enhancing the factuality of LLMs. ",
    "url": "https://arxiv.org/abs/2402.09390",
    "authors": [
      "Yihao Fang",
      "Stephen W. Thomas",
      "Xiaodan Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.09403",
    "title": "Auditing Private Prediction",
    "abstract": "Differential privacy (DP) offers a theoretical upper bound on the potential privacy leakage of analgorithm, while empirical auditing establishes a practical lower bound. Auditing techniques exist forDP training algorithms. However machine learning can also be made private at inference. We propose thefirst framework for auditing private prediction where we instantiate adversaries with varying poisoningand query capabilities. This enables us to study the privacy leakage of four private prediction algorithms:PATE [Papernot et al., 2016], CaPC [Choquette-Choo et al., 2020], PromptPATE [Duan et al., 2023],and Private-kNN [Zhu et al., 2020]. To conduct our audit, we introduce novel techniques to empiricallyevaluate privacy leakage in terms of Renyi DP. Our experiments show that (i) the privacy analysis ofprivate prediction can be improved, (ii) algorithms which are easier to poison lead to much higher privacyleakage, and (iii) the privacy leakage is significantly lower for adversaries without query control than thosewith full control. ",
    "url": "https://arxiv.org/abs/2402.09403",
    "authors": [
      "Karan Chadha",
      "Matthew Jagielski",
      "Nicolas Papernot",
      "Christopher Choquette-Choo",
      "Milad Nasr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.08697",
    "title": "Weakly Supervised Detection of Pheochromocytomas and Paragangliomas in  CT",
    "abstract": "Pheochromocytomas and Paragangliomas (PPGLs) are rare adrenal and extra-adrenal tumors which have the potential to metastasize. For the management of patients with PPGLs, CT is the preferred modality of choice for precise localization and estimation of their progression. However, due to the myriad variations in size, morphology, and appearance of the tumors in different anatomical regions, radiologists are posed with the challenge of accurate detection of PPGLs. Since clinicians also need to routinely measure their size and track their changes over time across patient visits, manual demarcation of PPGLs is quite a time-consuming and cumbersome process. To ameliorate the manual effort spent for this task, we propose an automated method to detect PPGLs in CT studies via a proxy segmentation task. As only weak annotations for PPGLs in the form of prospectively marked 2D bounding boxes on an axial slice were available, we extended these 2D boxes into weak 3D annotations and trained a 3D full-resolution nnUNet model to directly segment PPGLs. We evaluated our approach on a dataset consisting of chest-abdomen-pelvis CTs of 255 patients with confirmed PPGLs. We obtained a precision of 70% and sensitivity of 64.1% with our proposed approach when tested on 53 CT studies. Our findings highlight the promising nature of detecting PPGLs via segmentation, and furthers the state-of-the-art in this exciting yet challenging area of rare cancer management. ",
    "url": "https://arxiv.org/abs/2402.08697",
    "authors": [
      "David C. Oluigboa",
      "Bikash Santra",
      "Tejas Sudharshan Mathai",
      "Pritam Mukherjee",
      "Jianfei Liu",
      "Abhishek Jha",
      "Mayank Patel",
      "Karel Pacak",
      "Ronald M. Summers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08726",
    "title": "Trained quantum neural networks are Gaussian processes",
    "abstract": "We study quantum neural networks made by parametric one-qubit gates and fixed two-qubit gates in the limit of infinite width, where the generated function is the expectation value of the sum of single-qubit observables over all the qubits. First, we prove that the probability distribution of the function generated by the untrained network with randomly initialized parameters converges in distribution to a Gaussian process whenever each measured qubit is correlated only with few other measured qubits. Then, we analytically characterize the training of the network via gradient descent with square loss on supervised learning problems. We prove that, as long as the network is not affected by barren plateaus, the trained network can perfectly fit the training set and that the probability distribution of the function generated after training still converges in distribution to a Gaussian process. Finally, we consider the statistical noise of the measurement at the output of the network and prove that a polynomial number of measurements is sufficient for all the previous results to hold and that the network can always be trained in polynomial time. ",
    "url": "https://arxiv.org/abs/2402.08726",
    "authors": [
      "Filippo Girardi",
      "Giacomo De Palma"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2402.08752",
    "title": "Edge coloring lattice graphs",
    "abstract": "We develop the theory of the edge coloring of infinite lattice graphs, proving a necessary and sufficient condition for a proper edge coloring of a patch of a lattice graph to induce a proper edge coloring of the entire lattice graph by translation. This condition forms the cornerstone of a method that finds nearly minimal or minimal edge colorings of infinite lattice graphs. In case a nearly minimal edge coloring is requested, the running time is $O(\\mu^2 D^4)$, where $\\mu$ is the number of edges in one cell (or `basis graph') of the lattice graph and $D$ is the maximum distance between two cells so that there is an edge from within one cell to the other. In case a minimal edge coloring is requested, we lack an upper bound on the running time, which we find need not pose a limitation in practice; we use the method to minimal edge color the meshes of all $k$-uniform tilings of the plane for $k\\leq 6$, while utilizing modest computational resources. We find that all these lattice graphs are Vizing class~I. Relating edge colorings to quantum circuits, our work finds direct application by offering minimal-depth quantum circuits in the areas of quantum simulation, quantum optimization, and quantum state verification. ",
    "url": "https://arxiv.org/abs/2402.08752",
    "authors": [
      "Joris Kattem\u00f6lle"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.08768",
    "title": "Adversarially Robust Feature Learning for Breast Cancer Diagnosis",
    "abstract": "Adversarial data can lead to malfunction of deep learning applications. It is essential to develop deep learning models that are robust to adversarial data while accurate on standard, clean data. In this study, we proposed a novel adversarially robust feature learning (ARFL) method for a real-world application of breast cancer diagnosis. ARFL facilitates adversarial training using both standard data and adversarial data, where a feature correlation measure is incorporated as an objective function to encourage learning of robust features and restrain spurious features. To show the effects of ARFL in breast cancer diagnosis, we built and evaluated diagnosis models using two independent clinically collected breast imaging datasets, comprising a total of 9,548 mammogram images. We performed extensive experiments showing that our method outperformed several state-of-the-art methods and that our method can enhance safer breast cancer diagnosis against adversarial attacks in clinical settings. ",
    "url": "https://arxiv.org/abs/2402.08768",
    "authors": [
      "Degan Hao",
      "Dooman Arefan",
      "Margarita Zuley",
      "Wendie Berg",
      "Shandong Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08777",
    "title": "DNABERT-S: Learning Species-Aware DNA Embedding with Genome Foundation  Models",
    "abstract": "Effective DNA embedding remains crucial in genomic analysis, particularly in scenarios lacking labeled data for model fine-tuning, despite the significant advancements in genome foundation models. A prime example is metagenomics binning, a critical process in microbiome research that aims to group DNA sequences by their species from a complex mixture of DNA sequences derived from potentially thousands of distinct, often uncharacterized species. To fill the lack of effective DNA embedding models, we introduce DNABERT-S, a genome foundation model that specializes in creating species-aware DNA embeddings. To encourage effective embeddings to error-prone long-read DNA sequences, we introduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes the hidden representations of DNA sequences at randomly selected layers and trains the model to recognize and differentiate these mixed proportions at the output layer. We further enhance it with the proposed Curriculum Contrastive Learning (C$^2$LR) strategy. Empirical results on 18 diverse datasets showed DNABERT-S's remarkable performance. It outperforms the top baseline's performance in 10-shot species classification with just a 2-shot training while doubling the Adjusted Rand Index (ARI) in species clustering and substantially increasing the number of correctly identified species in metagenomics binning. The code, data, and pre-trained model are publicly available at https://github.com/Zhihan1996/DNABERT_S. ",
    "url": "https://arxiv.org/abs/2402.08777",
    "authors": [
      "Zhihan Zhou",
      "Winmin Wu",
      "Harrison Ho",
      "Jiayi Wang",
      "Lizhen Shi",
      "Ramana V Davuluri",
      "Zhong Wang",
      "Han Liu"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.08779",
    "title": "Strategic Contract Negotiation in Financial Networks",
    "abstract": "How can firms optimally negotiate bilateral contracts with each other in a financial network? Every firm seeks to maximize the utility it gains from its portfolio of contracts. We focus on mean-variance utilities, where each firm has its own beliefs about the expected returns of the contracts and the covariances between them (Markowitz, J. Finance 7(11), 1952). Instead of revealing these beliefs, a firm may adopt a different negotiating position, seeking better contract terms. We formulate a contract negotiation process by which such strategic behavior leads to a network of contracts. In our formulation, any subset of firms can be strategic. The negotiating positions of these firms can form Nash equilibria, where each firm's position is optimal given the others' positions. We give a polynomial-time algorithm to find the Nash equilibria, if they exist, and certify their nonexistence otherwise. We explore the implications of such equilibria on several model networks. These illustrate that firms' utilities can be sensitive to their negotiating position. We then propose trade deadlines as a mechanism to reduce the need for strategic behavior. At the deadline, each firm can unilaterally cancel some or all of its contracts, for a penalty. In our model networks, we show that trade deadlines can reduce the loss of utility from being honest. We empirically verify our insights using data on international trade between 46 large economies. ",
    "url": "https://arxiv.org/abs/2402.08779",
    "authors": [
      "Akhil Jalan",
      "Deepayan Chakrabarti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2402.08904",
    "title": "Sound Field Reconstruction Using a Compact Acoustics-informed Neural  Network",
    "abstract": "Sound field reconstruction (SFR) augments the information of a sound field captured by a microphone array. Conventional SFR methods using basis function decomposition are straightforward and computationally efficient, but may require more microphones than needed to measure the sound field. Recent studies show that pure data-driven and learning-based methods are promising in some SFR tasks, but they are usually computationally heavy and may fail to reconstruct a physically valid sound field. This paper proposes a compact acoustics-informed neural network (AINN) method for SFR, whereby the Helmholtz equation is exploited to regularize the neural network. As opposed to pure data-driven approaches that solely rely on measured sound pressures, the integration of the Helmholtz equation improves robustness of the neural network against variations during the measurement processes and prompts the generation of physically valid reconstructions. The AINN is designed to be compact, and is able to predict not only the sound pressures but also sound pressure gradients within a spatial region of interest based on measured sound pressures along the boundary. Numerical experiments with acoustic transfer functions measured in different environments demonstrate the superiority of the AINN method over the traditional cylinder harmonic decomposition and the singular value decomposition methods. ",
    "url": "https://arxiv.org/abs/2402.08904",
    "authors": [
      "Fei Ma",
      "Sipei Zhao",
      "Ian S. Burnett"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.08991",
    "title": "Towards Robust Model-Based Reinforcement Learning Against Adversarial  Corruption",
    "abstract": "This study tackles the challenges of adversarial corruption in model-based reinforcement learning (RL), where the transition dynamics can be corrupted by an adversary. Existing studies on corruption-robust RL mostly focus on the setting of model-free RL, where robust least-square regression is often employed for value function estimation. However, these techniques cannot be directly applied to model-based RL. In this paper, we focus on model-based RL and take the maximum likelihood estimation (MLE) approach to learn transition model. Our work encompasses both online and offline settings. In the online setting, we introduce an algorithm called corruption-robust optimistic MLE (CR-OMLE), which leverages total-variation (TV)-based information ratios as uncertainty weights for MLE. We prove that CR-OMLE achieves a regret of $\\tilde{\\mathcal{O}}(\\sqrt{T} + C)$, where $C$ denotes the cumulative corruption level after $T$ episodes. We also prove a lower bound to show that the additive dependence on $C$ is optimal. We extend our weighting technique to the offline setting, and propose an algorithm named corruption-robust pessimistic MLE (CR-PMLE). Under a uniform coverage condition, CR-PMLE exhibits suboptimality worsened by $\\mathcal{O}(C/n)$, nearly matching the lower bound. To the best of our knowledge, this is the first work on corruption-robust model-based RL algorithms with provable guarantees. ",
    "url": "https://arxiv.org/abs/2402.08991",
    "authors": [
      "Chenlu Ye",
      "Jiafan He",
      "Quanquan Gu",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09018",
    "title": "Neural Operators Meet Energy-based Theory: Operator Learning for  Hamiltonian and Dissipative PDEs",
    "abstract": "The operator learning has received significant attention in recent years, with the aim of learning a mapping between function spaces. Prior works have proposed deep neural networks (DNNs) for learning such a mapping, enabling the learning of solution operators of partial differential equations (PDEs). However, these works still struggle to learn dynamics that obeys the laws of physics. This paper proposes Energy-consistent Neural Operators (ENOs), a general framework for learning solution operators of PDEs that follows the energy conservation or dissipation law from observed solution trajectories. We introduce a novel penalty function inspired by the energy-based theory of physics for training, in which the energy functional is modeled by another DNN, allowing one to bias the outputs of the DNN-based solution operators to ensure energetic consistency without explicit PDEs. Experiments on multiple physical systems show that ENO outperforms existing DNN models in predicting solutions from data, especially in super-resolution settings. ",
    "url": "https://arxiv.org/abs/2402.09018",
    "authors": [
      "Yusuke Tanaka",
      "Takaharu Yaguchi",
      "Tomoharu Iwata",
      "Naonori Ueda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09076",
    "title": "Preserving system activity while controlling epidemic spreading in  adaptive temporal networks",
    "abstract": "Human behaviour strongly influences the spread of infectious diseases: understanding the interplay between epidemic dynamics and adaptive behaviours is essential to improve response strategies to epidemics, with the goal of containing the epidemic while preserving a sufficient level of operativeness in the population. Through activity-driven temporal networks, we formulate a general framework which models a wide range of adaptive behaviours and mitigation strategies, observed in real populations. We analytically derive the conditions for a widespread diffusion of epidemics in the presence of arbitrary adaptive behaviours, highlighting the crucial role of correlations between agents behaviour in the infected and in the susceptible state. We focus on the effects of sick-leave, comparing the effectiveness of different strategies in reducing the impact of the epidemic and preserving the system operativeness. We show the critical relevance of heterogeneity in individual behavior: in homogeneous networks, all sick-leave strategies are equivalent and poorly effective, while in heterogeneous networks, strategies targeting the most vulnerable nodes are able to effectively mitigate the epidemic, also avoiding a deterioration in system activity and maintaining a low level of absenteeism. Interestingly, with targeted strategies both the minimum of population activity and the maximum of absenteeism anticipate the infection peak, which is effectively flattened and delayed, so that full operativeness is almost restored when the infection peak arrives. We also provide realistic estimates of the model parameters for influenza-like illness, thereby suggesting strategies for managing epidemics and absenteeism in realistic populations. ",
    "url": "https://arxiv.org/abs/2402.09076",
    "authors": [
      "Marco Mancastroppa",
      "Alessandro Vezzani",
      "Vittoria Colizza",
      "Raffaella Burioni"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2402.09108",
    "title": "Web 3.0 and Quantum Security: Long-Distance Free-Space QSDC for Global  Web 3.0 Networks",
    "abstract": "With the advent of Web 3.0, the swift advancement of technology confronts an imminent threat from quantum computing. Security protocols safeguarding the integrity of Web 2.0 and Web 3.0 are growing more susceptible to both quantum attacks and sophisticated classical threats. The article introduces long-distance free-space quantum secure direct communication (LF QSDC) as a method to safeguard against security breaches in both quantum and classical contexts. Differing from techniques like quantum key distribution (QKD), LF QSDC surpasses constraints by facilitating encrypted data transmission sans key exchanges, thus diminishing the inherent weaknesses of key-based systems. The distinctiveness of this attribute, coupled with its quantum mechanics base, protects against quantum computer assaults and advanced non-quantum dangers, harmonizing seamlessly with the untrustworthy tenets of the Web 3.0 age. The focus of our study is the incorporation of LF QSDC into network infrastructures, highlighting its efficacy for extended-range communication via memory DL04 protocol, quantum-aware low-density parity check (LDPC), and pointing, acquisition, and tracking (PAT) technologies. Utilizing this method not only bolsters the security of worldwide Web 3.0 networks but also guarantees their endurance in a time when quantum and sophisticated classical threats exist simultaneously. Consequently, LF QSDC stands out as a robust security solution, well-suited for Web 3.0 systems amidst the constantly evolving digital environment. ",
    "url": "https://arxiv.org/abs/2402.09108",
    "authors": [
      "Yew Kee Wong",
      "Yifan Zhou",
      "Xinlin Zhou",
      "Yan Shing Liang",
      "Zi Yan Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.09131",
    "title": "General penny graphs are at most 43/18-dense",
    "abstract": "We prove that among $n$ points in the plane in general position, the shortest distance occurs at most $43n/18$ times, improving upon the upper bound of $17n/7$ obtained by T\\'oth in 1997. ",
    "url": "https://arxiv.org/abs/2402.09131",
    "authors": [
      "Arsenii Sagdeev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Metric Geometry (math.MG)"
    ]
  },
  {
    "id": "arXiv:2402.09137",
    "title": "Semi-Supervised Diffusion Model for Brain Age Prediction",
    "abstract": "Brain age prediction models have succeeded in predicting clinical outcomes in neurodegenerative diseases, but can struggle with tasks involving faster progressing diseases and low quality data. To enhance their performance, we employ a semi-supervised diffusion model, obtaining a 0.83(p<0.01) correlation between chronological and predicted age on low quality T1w MR images. This was competitive with state-of-the-art non-generative methods. Furthermore, the predictions produced by our model were significantly associated with survival length (r=0.24, p<0.05) in Amyotrophic Lateral Sclerosis. Thus, our approach demonstrates the value of diffusion-based architectures for the task of brain age prediction. ",
    "url": "https://arxiv.org/abs/2402.09137",
    "authors": [
      "Ayodeji Ijishakin",
      "Sophie Martin",
      "Florence Townend",
      "Federica Agosta",
      "Edoardo Gioele Spinelli",
      "Silvia Basaia",
      "Paride Schito",
      "Yuri Falzone",
      "Massimo Filippi",
      "James Cole",
      "Andrea Malaspina"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09155",
    "title": "Joint and Robust Beamforming Framework for Integrated Sensing and  Communication Systems",
    "abstract": "Integrated sensing and communication (ISAC) is widely recognized as a fundamental enabler for future wireless communications. In this paper, we present a joint communication and radar beamforming framework for maximizing a sum spectral efficiency (SE) while guaranteeing desired radar performance with imperfect channel state information (CSI) in multi-user and multi-target ISAC systems. To this end, we adopt either a radar transmit beam mean square error (MSE) or receive signal-to-clutter-plus-noise ratio (SCNR) as a radar performance constraint of a sum SE maximization problem. To resolve inherent challenges such as non-convexity and imperfect CSI, we reformulate the problems and identify first-order optimality conditions for the joint radar and communication beamformer. Turning the condition to a nonlinear eigenvalue problem with eigenvector dependency (NEPv), we develop an alternating method which finds the joint beamformer through power iteration and a Lagrangian multiplier through binary search. The proposed framework encompasses both the radar metrics and is robust to channel estimation error with low complexity. Simulations validate the proposed methods. In particular, we observe that the MSE and SCNR constraints exhibit complementary performance depending on the operating environment, which manifests the importance of the proposed comprehensive and robust optimization framework. ",
    "url": "https://arxiv.org/abs/2402.09155",
    "authors": [
      "Jinseok Choi",
      "Jeonghun Park",
      "Namyoon Lee",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.09156",
    "title": "Crop and Couple: cardiac image segmentation using interlinked specialist  networks",
    "abstract": "Diagnosis of cardiovascular disease using automated methods often relies on the critical task of cardiac image segmentation. We propose a novel strategy that performs segmentation using specialist networks that focus on a single anatomy (left ventricle, right ventricle, or myocardium). Given an input long-axis cardiac MR image, our method performs a ternary segmentation in the first stage to identify these anatomical regions, followed by cropping the original image to focus subsequent processing on the anatomical regions. The specialist networks are coupled through an attention mechanism that performs cross-attention to interlink features from different anatomies, serving as a soft relative shape prior. Central to our approach is an additive attention block (E-2A block), which is used throughout our architecture thanks to its efficiency. ",
    "url": "https://arxiv.org/abs/2402.09156",
    "authors": [
      "Abbas Khan",
      "Muhammad Asad",
      "Martin Benning",
      "Caroline Roney",
      "Gregory Slabaugh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09330",
    "title": "3D-based RNA function prediction tools in rnaglib",
    "abstract": "Understanding the connection between complex structural features of RNA and biological function is a fundamental challenge in evolutionary studies and in RNA design. However, building datasets of RNA 3D structures and making appropriate modeling choices remains time-consuming and lacks standardization. In this chapter, we describe the use of rnaglib, to train supervised and unsupervised machine learning-based function prediction models on datasets of RNA 3D structures. ",
    "url": "https://arxiv.org/abs/2402.09330",
    "authors": [
      "Carlos Oliver",
      "Vincent Mallet",
      "J\u00e9r\u00f4me Waldisp\u00fchl"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09338",
    "title": "Neural Networks asymptotic behaviours suitable for the resolution of  inverse problems",
    "abstract": "In this paper, we perform a study on the effectiveness of Neural Network (NN) techniques for deconvolution inverse problems. We consider NN's asymptotic limits, corresponding to Gaussian Processes (GPs), where parameter non-linearities are lost. Using these resulting GPs, we address the deconvolution inverse problem in the case of a quantum harmonic oscillator simulated through Monte Carlo techniques on a lattice. A scenario with a known analytical solution. Our findings indicate that solving the deconvolution inverse problem with a fully connected NN yields less performing results than those obtained using the GPs derived from NN's asymptotic limits. Furthermore, we observe the trained NN's accuracy approaching that of GPs with increasing layer width. Notably, one of these GPs defies interpretation as a probabilistic model, offering a novel perspective compared to established methods in the literature. Additionally, the NNs, in their asymptotic limit, provide cost-effective analytical solutions. ",
    "url": "https://arxiv.org/abs/2402.09338",
    "authors": [
      "Luigi Del Debbio",
      "Manuel Naviglio",
      "Francesco Tarantelli"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)",
      "High Energy Physics - Lattice (hep-lat)",
      "High Energy Physics - Theory (hep-th)"
    ]
  },
  {
    "id": "arXiv:2402.09359",
    "title": "Pruning Sparse Tensor Neural Networks Enables Deep Learning for 3D  Ultrasound Localization Microscopy",
    "abstract": "Ultrasound Localization Microscopy (ULM) is a non-invasive technique that allows for the imaging of micro-vessels in vivo, at depth and with a resolution on the order of ten microns. ULM is based on the sub-resolution localization of individual microbubbles injected in the bloodstream. Mapping the whole angioarchitecture requires the accumulation of microbubbles trajectories from thousands of frames, typically acquired over a few minutes. ULM acquisition times can be reduced by increasing the microbubble concentration, but requires more advanced algorithms to detect them individually. Several deep learning approaches have been proposed for this task, but they remain limited to 2D imaging, in part due to the associated large memory requirements. Herein, we propose to use sparse tensor neural networks to reduce memory usage in 2D and to improve the scaling of the memory requirement for the extension of deep learning architecture to 3D. We study several approaches to efficiently convert ultrasound data into a sparse format and study the impact of the associated loss of information. When applied in 2D, the sparse formulation reduces the memory requirements by a factor 2 at the cost of a small reduction of performance when compared against dense networks. In 3D, the proposed approach reduces memory requirements by two order of magnitude while largely outperforming conventional ULM in high concentration settings. We show that Sparse Tensor Neural Networks in 3D ULM allow for the same benefits as dense deep learning based method in 2D ULM i.e. the use of higher concentration in silico and reduced acquisition time. ",
    "url": "https://arxiv.org/abs/2402.09359",
    "authors": [
      "Brice Rauby",
      "Paul Xing",
      "Jonathan Por\u00e9e",
      "Maxime Gasse",
      "Jean Provost"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09387",
    "title": "Active Disruption Avoidance and Trajectory Design for Tokamak Ramp-downs  with Neural Differential Equations and Reinforcement Learning",
    "abstract": "The tokamak offers a promising path to fusion energy, but plasma disruptions pose a major economic risk, motivating considerable advances in disruption avoidance. This work develops a reinforcement learning approach to this problem by training a policy to safely ramp-down the plasma current while avoiding limits on a number of quantities correlated with disruptions. The policy training environment is a hybrid physics and machine learning model trained on simulations of the SPARC primary reference discharge (PRD) ramp-down, an upcoming burning plasma scenario which we use as a testbed. To address physics uncertainty and model inaccuracies, the simulation environment is massively parallelized on GPU with randomized physics parameters during policy training. The trained policy is then successfully transferred to a higher fidelity simulator where it successfully ramps down the plasma while avoiding user-specified disruptive limits. We also address the crucial issue of safety criticality by demonstrating that a constraint-conditioned policy can be used as a trajectory design assistant to design a library of feed-forward trajectories to handle different physics conditions and user settings. As a library of trajectories is more interpretable and verifiable offline, we argue such an approach is a promising path for leveraging the capabilities of reinforcement learning in the safety-critical context of burning plasma tokamaks. Finally, we demonstrate how the training environment can be a useful platform for other feed-forward optimization approaches by using an evolutionary algorithm to perform optimization of feed-forward trajectories that are robust to physics uncertainty ",
    "url": "https://arxiv.org/abs/2402.09387",
    "authors": [
      "Allen M. Wang",
      "Oswin So",
      "Charles Dawson",
      "Darren T. Garnier",
      "Cristina Rea",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.11935",
    "title": "Provably Efficient Representation Selection in Low-rank Markov Decision  Processes: From Online to Offline RL",
    "abstract": " Comments: 32 pages, 2 figures, 7 tables, In UAI 2023 ",
    "url": "https://arxiv.org/abs/2106.11935",
    "authors": [
      "Weitong Zhang",
      "Jiafan He",
      "Dongruo Zhou",
      "Amy Zhang",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.14465",
    "title": "Unbiased Statistical Estimation and Valid Confidence Intervals Under  Differential Privacy",
    "abstract": " Title: Unbiased Statistical Estimation and Valid Confidence Intervals Under  Differential Privacy ",
    "url": "https://arxiv.org/abs/2110.14465",
    "authors": [
      "Christian Covington",
      "Xi He",
      "James Honaker",
      "Gautam Kamath"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2203.00187",
    "title": "Robots Autonomously Detecting People: A Multimodal Deep Contrastive  Learning Method Robust to Intraclass Variations",
    "abstract": " Title: Robots Autonomously Detecting People: A Multimodal Deep Contrastive  Learning Method Robust to Intraclass Variations ",
    "url": "https://arxiv.org/abs/2203.00187",
    "authors": [
      "Angus Fung",
      "Beno Benhabib",
      "Goldie Nejat"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11921",
    "title": "Compression-aware Training of Neural Networks using Frank-Wolfe",
    "abstract": " Comments: 8 pages, 5 pages references, 14 pages appendix, 8 figures, and 11 tables ",
    "url": "https://arxiv.org/abs/2205.11921",
    "authors": [
      "Max Zimmer",
      "Christoph Spiegel",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.14905",
    "title": "Variance Covariance Regularization Enforces Pairwise Independence in  Self-Supervised Representations",
    "abstract": " Title: Variance Covariance Regularization Enforces Pairwise Independence in  Self-Supervised Representations ",
    "url": "https://arxiv.org/abs/2209.14905",
    "authors": [
      "Gr\u00e9goire Mialon",
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09974",
    "title": "Theoretical Guarantees for Permutation-Equivariant Quantum Neural  Networks",
    "abstract": " Comments: 15+21 pages, 5 + 5 figures. Prior generalization bounds replaced with more general theorem. Comments added about hardness of simulation and narrow gorges ",
    "url": "https://arxiv.org/abs/2210.09974",
    "authors": [
      "Louis Schatzki",
      "Martin Larocca",
      "Quynh T. Nguyen",
      "Frederic Sauvage",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.00214",
    "title": "Test-Time Mixup Augmentation for Data and Class-Specific Uncertainty  Estimation in Deep Learning Image Classification",
    "abstract": " Title: Test-Time Mixup Augmentation for Data and Class-Specific Uncertainty  Estimation in Deep Learning Image Classification ",
    "url": "https://arxiv.org/abs/2212.00214",
    "authors": [
      "Hansang Lee",
      "Haeil Lee",
      "Helen Hong",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10809",
    "title": "Causal Explanations for Sequential Decision-Making in Multi-Agent  Systems",
    "abstract": " Comments: Accepted in 23rd International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2024 ",
    "url": "https://arxiv.org/abs/2302.10809",
    "authors": [
      "Balint Gyevnar",
      "Cheng Wang",
      "Christopher G. Lucas",
      "Shay B. Cohen",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.02186",
    "title": "Causal Deep Learning",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2212.00911 ",
    "url": "https://arxiv.org/abs/2303.02186",
    "authors": [
      "Jeroen Berrevoets",
      "Krzysztof Kacprzyk",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05739",
    "title": "LEDetection: A Simple Framework for Semi-Supervised Few-Shot Object  Detection",
    "abstract": " Comments: AISTATS 2024. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.05739",
    "authors": [
      "Phi Vu Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18484",
    "title": "Neural Fourier Transform: A General Approach to Equivariant  Representation Learning",
    "abstract": " Title: Neural Fourier Transform: A General Approach to Equivariant  Representation Learning ",
    "url": "https://arxiv.org/abs/2305.18484",
    "authors": [
      "Masanori Koyama",
      "Kenji Fukumizu",
      "Kohei Hayashi",
      "Takeru Miyato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02775",
    "title": "Input-gradient space particle inference for neural network ensembles",
    "abstract": " Comments: Published at ICLR 2024 (spotlight presentation) ",
    "url": "https://arxiv.org/abs/2306.02775",
    "authors": [
      "Trung Trinh",
      "Markus Heinonen",
      "Luigi Acerbi",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.04828",
    "title": "Fast and Effective GNN Training with Linearized Random Spanning Trees",
    "abstract": " Title: Fast and Effective GNN Training with Linearized Random Spanning Trees ",
    "url": "https://arxiv.org/abs/2306.04828",
    "authors": [
      "Francesco Bonchi",
      "Claudio Gentile",
      "Francesco Paolo Nerini",
      "Andr\u00e9 Panisson",
      "Fabio Vitale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10816",
    "title": "$\\texttt{causalAssembly}$: Generating Realistic Production Data for  Benchmarking Causal Discovery",
    "abstract": " Title: $\\texttt{causalAssembly}$: Generating Realistic Production Data for  Benchmarking Causal Discovery ",
    "url": "https://arxiv.org/abs/2306.10816",
    "authors": [
      "Konstantin G\u00f6bler",
      "Tobias Windisch",
      "Mathias Drton",
      "Tim Pychynski",
      "Steffen Sonntag",
      "Martin Roth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.14291",
    "title": "Hyp-OW: Exploiting Hierarchical Structure Learning with Hyperbolic  Distance Enhances Open World Object Detection",
    "abstract": " Comments: Accepted at AAAI 2024 || keywords: Open World Object Detection, Hyperbolic Distance, Unknown Detection, Deformable Transformers, Hierarchical Representation Learning ",
    "url": "https://arxiv.org/abs/2306.14291",
    "authors": [
      "Thang Doan",
      "Xin Li",
      "Sima Behpour",
      "Wenbin He",
      "Liang Gou",
      "Liu Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.05432",
    "title": "Self-Supervised Learning with Lie Symmetries for Partial Differential  Equations",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.05432",
    "authors": [
      "Gr\u00e9goire Mialon",
      "Quentin Garrido",
      "Hannah Lawrence",
      "Danyal Rehman",
      "Yann LeCun",
      "Bobak T. Kiani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.06556",
    "title": "Metal Oxide-based Gas Sensor Array for the VOCs Analysis in Complex  Mixtures using Machine Learning",
    "abstract": " Title: Metal Oxide-based Gas Sensor Array for the VOCs Analysis in Complex  Mixtures using Machine Learning ",
    "url": "https://arxiv.org/abs/2307.06556",
    "authors": [
      "Shivam Singh",
      "Sajana S",
      "Poornima",
      "Gajje Sreelekha",
      "Chandranath Adak",
      "Rajendra P. Shukla",
      "Vinayak Kamble"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16036",
    "title": "Multichannel Voice Trigger Detection Based on  Transform-average-concatenate",
    "abstract": " Comments: Accepted at HSCMA 2024 ",
    "url": "https://arxiv.org/abs/2309.16036",
    "authors": [
      "Takuya Higuchi",
      "Avamarie Brueggeman",
      "Masood Delfarah",
      "Stephen Shum"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.16597",
    "title": "Transfer Learning for Bayesian Optimization on Heterogeneous Search  Spaces",
    "abstract": " Title: Transfer Learning for Bayesian Optimization on Heterogeneous Search  Spaces ",
    "url": "https://arxiv.org/abs/2309.16597",
    "authors": [
      "Zhou Fan",
      "Xinran Han",
      "Zi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00076",
    "title": "Robustness of AI-Image Detectors: Fundamental Limits and Practical  Attacks",
    "abstract": " Title: Robustness of AI-Image Detectors: Fundamental Limits and Practical  Attacks ",
    "url": "https://arxiv.org/abs/2310.00076",
    "authors": [
      "Mehrdad Saberi",
      "Vinu Sankar Sadasivan",
      "Keivan Rezaei",
      "Aounon Kumar",
      "Atoosa Chegini",
      "Wenxiao Wang",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08739",
    "title": "Voyager: MTD-Based Aggregation Protocol for Mitigating Poisoning Attacks  on DFL",
    "abstract": " Title: Voyager: MTD-Based Aggregation Protocol for Mitigating Poisoning Attacks  on DFL ",
    "url": "https://arxiv.org/abs/2310.08739",
    "authors": [
      "Chao Feng",
      "Alberto Huertas Celdran",
      "Michael Vuong",
      "Gerome Bovet",
      "Burkhard Stiller"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.08748",
    "title": "Evolutionary Dynamic Optimization and Machine Learning",
    "abstract": " Comments: This is a preprint of the following chapter: Abdennour Boulesnane, Evolutionary Dynamic Optimization and Machine Learning, published in Advanced Machine Learning with Evolutionary and Metaheuristic Techniques, Computational Intelligence Methods and Applications, edited by J. Valadi et al. (eds.),2024, Springer Nature ",
    "url": "https://arxiv.org/abs/2310.08748",
    "authors": [
      "Abdennour Boulesnane"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08881",
    "title": "Online Resource Sharing via Dynamic Max-Min Fairness: Efficiency,  Robustness and Non-Stationarity",
    "abstract": " Title: Online Resource Sharing via Dynamic Max-Min Fairness: Efficiency,  Robustness and Non-Stationarity ",
    "url": "https://arxiv.org/abs/2310.08881",
    "authors": [
      "Giannis Fikioris",
      "Siddhartha Banerjee",
      "\u00c9va Tardos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2310.12294",
    "title": "Open-Set Multivariate Time-Series Anomaly Detection",
    "abstract": " Comments: 12 pages, 7 tables, 2 figures ",
    "url": "https://arxiv.org/abs/2310.12294",
    "authors": [
      "Thomas Lai",
      "Thi Kieu Khanh Ho",
      "Narges Armanfard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15450",
    "title": "General Identifiability and Achievability for Causal Representation  Learning",
    "abstract": " Comments: Accepted to AISTATS 2024 (oral presentation). Also appeared at CRL Workshop @ NeurIPS 2023 (oral presentation) titled as \"Score-based Causal Representation Learning: Nonparametric Identifiability\" ",
    "url": "https://arxiv.org/abs/2310.15450",
    "authors": [
      "Burak Var\u0131c\u0131",
      "Emre Acart\u00fcrk",
      "Karthikeyan Shanmugam",
      "Ali Tajer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.17534",
    "title": "SoK: Pitfalls in Evaluating Black-Box Attacks",
    "abstract": " Comments: Accepted at SaTML 2024 ",
    "url": "https://arxiv.org/abs/2310.17534",
    "authors": [
      "Fnu Suya",
      "Anshuman Suri",
      "Tingwei Zhang",
      "Jingtao Hong",
      "Yuan Tian",
      "David Evans"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.02357",
    "title": "Contrastive Deep Nonnegative Matrix Factorization for Community  Detection",
    "abstract": " Comments: In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2024. Source Code available at: this https URL ",
    "url": "https://arxiv.org/abs/2311.02357",
    "authors": [
      "Yuecheng Li",
      "Jialong Chen",
      "Chuan Chen",
      "Lei Yang",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.07454",
    "title": "Discrete Nonparametric Causal Discovery Under Latent Class Confounding",
    "abstract": " Title: Discrete Nonparametric Causal Discovery Under Latent Class Confounding ",
    "url": "https://arxiv.org/abs/2311.07454",
    "authors": [
      "Bijan Mazaheri",
      "Spencer Gordon",
      "Yuval Rabani",
      "Leonard Schulman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2311.15674",
    "title": "MOT-DETR: 3D Single Shot Detection and Tracking with Transformers to  build 3D representations for Agro-Food Robots",
    "abstract": " Title: MOT-DETR: 3D Single Shot Detection and Tracking with Transformers to  build 3D representations for Agro-Food Robots ",
    "url": "https://arxiv.org/abs/2311.15674",
    "authors": [
      "David Rapado-Rincon",
      "Henk Nap",
      "Katarina Smolenova",
      "Eldert J. van Henten",
      "Gert Kootstra"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.16856",
    "title": "Attentional Graph Neural Networks for Robust Massive Network  Localization",
    "abstract": " Title: Attentional Graph Neural Networks for Robust Massive Network  Localization ",
    "url": "https://arxiv.org/abs/2311.16856",
    "authors": [
      "Wenzhong Yan",
      "Juntao Wang",
      "Feng Yin",
      "Yang Tian",
      "Abdelhak M. Zoubir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.07540",
    "title": "diff History for Neural Language Agents",
    "abstract": " Title: diff History for Neural Language Agents ",
    "url": "https://arxiv.org/abs/2312.07540",
    "authors": [
      "Ulyana Piterbarg",
      "Lerrel Pinto",
      "Rob Fergus"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14440",
    "title": "Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks",
    "abstract": " Comments: preprint version ",
    "url": "https://arxiv.org/abs/2312.14440",
    "authors": [
      "Haz Sameen Shahgir",
      "Xianghao Kong",
      "Greg Ver Steeg",
      "Yue Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.17528",
    "title": "Characterizing the Role of Complex Power in Small-Signal Synchronization  Stability of Multi-Converter Power Systems",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2312.17528",
    "authors": [
      "Fuyilong Ma",
      "Huanhai Xin",
      "Zhiyi Li",
      "Linbin Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.00608",
    "title": "Bringing Back the Context: Camera Trap Species Identification as Link  Prediction on Multimodal Knowledge Graphs",
    "abstract": " Comments: 13 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2401.00608",
    "authors": [
      "Vardaan Pahuja",
      "Weidi Luo",
      "Yu Gu",
      "Cheng-Hao Tu",
      "Hong-You Chen",
      "Tanya Berger-Wolf",
      "Charles Stewart",
      "Song Gao",
      "Wei-Lun Chao",
      "Yu Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.05845",
    "title": "Graph Reconstruction via MIS Queries",
    "abstract": " Comments: Lower bound for deterministic query algorithms added in this version ",
    "url": "https://arxiv.org/abs/2401.05845",
    "authors": [
      "Christian Konrad",
      "Conor O'Sullivan",
      "Victor Traistaru"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2401.06072",
    "title": "Chain of History: Learning and Forecasting with LLMs for Temporal  Knowledge Graph Completion",
    "abstract": " Comments: 15 pages; typos corrected, references added ",
    "url": "https://arxiv.org/abs/2401.06072",
    "authors": [
      "Ruilin Luo",
      "Tianle Gu",
      "Haoling Li",
      "Junzhe Li",
      "Zicheng Lin",
      "Jiayi Li",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.13839",
    "title": "Edge-coloring sparse graphs with $\u0394$ colors in quasilinear time",
    "abstract": " Title: Edge-coloring sparse graphs with $\u0394$ colors in quasilinear time ",
    "url": "https://arxiv.org/abs/2401.13839",
    "authors": [
      "Lukasz Kowalik"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2401.15857",
    "title": "Leadership Dynamics in Social Multiplex Networks with Mono and  Bi-directional Interactions",
    "abstract": " Comments: This submission has not been submitted to any conference or journal. There are serious technical problems in the submission which is being revised and the replacement is a going to be completely different from the previous versions. In addition, there are new contributors who are not ok for the previous versions to be shown ",
    "url": "https://arxiv.org/abs/2401.15857",
    "authors": [
      "Amirreza Talebi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.01207",
    "title": "Efficient Causal Graph Discovery Using Large Language Models",
    "abstract": " Title: Efficient Causal Graph Discovery Using Large Language Models ",
    "url": "https://arxiv.org/abs/2402.01207",
    "authors": [
      "Thomas Jiralerspong",
      "Xiaoyin Chen",
      "Yash More",
      "Vedant Shah",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.01677",
    "title": "Embedding Ontologies via Incorporating Extensional and Intensional  Knowledge",
    "abstract": " Comments: Submitting to IJCAI2024; 9 pages and 3 figures ",
    "url": "https://arxiv.org/abs/2402.01677",
    "authors": [
      "Keyu Wang",
      "Guilin Qi",
      "Jiaoyan Chen",
      "Tianxing Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.04362",
    "title": "Neural Networks Learn Statistics of Increasing Complexity",
    "abstract": " Title: Neural Networks Learn Statistics of Increasing Complexity ",
    "url": "https://arxiv.org/abs/2402.04362",
    "authors": [
      "Nora Belrose",
      "Quintin Pope",
      "Lucia Quirke",
      "Alex Mallen",
      "Xiaoli Fern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06187",
    "title": "Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask  Representation via Temporal Action-Driven Contrastive Loss",
    "abstract": " Title: Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask  Representation via Temporal Action-Driven Contrastive Loss ",
    "url": "https://arxiv.org/abs/2402.06187",
    "authors": [
      "Ruijie Zheng",
      "Yongyuan Liang",
      "Xiyao Wang",
      "Shuang Ma",
      "Hal Daum\u00e9 III",
      "Huazhe Xu",
      "John Langford",
      "Praveen Palanisamy",
      "Kalyan Shankar Basu",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.08309",
    "title": "Prompted Contextual Vectors for Spear-Phishing Detection",
    "abstract": " Title: Prompted Contextual Vectors for Spear-Phishing Detection ",
    "url": "https://arxiv.org/abs/2402.08309",
    "authors": [
      "Daniel Nahmias",
      "Gal Engelberg",
      "Dan Klein",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.08431",
    "title": "Generating Java Methods: An Empirical Assessment of Four AI-Based Code  Assistants",
    "abstract": " Title: Generating Java Methods: An Empirical Assessment of Four AI-Based Code  Assistants ",
    "url": "https://arxiv.org/abs/2402.08431",
    "authors": [
      "Vincenzo Corso",
      "Leonardo Mariani",
      "Daniela Micucci",
      "Oliviero Riganelli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.08571",
    "title": "Glass Segmentation with Multi Scales and Primary Prediction Guiding",
    "abstract": " Comments: under review ",
    "url": "https://arxiv.org/abs/2402.08571",
    "authors": [
      "Zhiyu Xu",
      "Qingliang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]