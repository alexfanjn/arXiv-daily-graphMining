[
  {
    "id": "arXiv:2402.14029",
    "title": "Partial Search in a Frozen Network is Enough to Find a Strong Lottery  Ticket",
    "abstract": "Randomly initialized dense networks contain subnetworks that achieve high accuracy without weight learning -- strong lottery tickets (SLTs). Recently, Gadhikar et al. (2023) demonstrated theoretically and experimentally that SLTs can also be found within a randomly pruned source network, thus reducing the SLT search space. However, this limits the search to SLTs that are even sparser than the source, leading to worse accuracy due to unintentionally high sparsity. This paper proposes a method that reduces the SLT search space by an arbitrary ratio that is independent of the desired SLT sparsity. A random subset of the initial weights is excluded from the search space by freezing it -- i.e., by either permanently pruning them or locking them as a fixed part of the SLT. Indeed, the SLT existence in such a reduced search space is theoretically guaranteed by our subset-sum approximation with randomly frozen variables. In addition to reducing search space, the random freezing pattern can also be exploited to reduce model size in inference. Furthermore, experimental results show that the proposed method finds SLTs with better accuracy and model size trade-off than the SLTs obtained from dense or randomly pruned source networks. In particular, the SLT found in a frozen graph neural network achieves higher accuracy than its weight trained counterpart while reducing model size by $40.3\\times$. ",
    "url": "https://arxiv.org/abs/2402.14029",
    "authors": [
      "Hikari Otsuka",
      "Daiki Chijiwa",
      "\u00c1ngel L\u00f3pez Garc\u00eda-Arias",
      "Yasuyuki Okoshi",
      "Kazushi Kawamura",
      "Thiem Van Chu",
      "Daichi Fujiki",
      "Susumu Takeuchi",
      "Masato Motomura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14033",
    "title": "VN Network: Embedding Newly Emerging Entities with Virtual Neighbors",
    "abstract": "Embedding entities and relations into continuous vector spaces has attracted a surge of interest in recent years. Most embedding methods assume that all test entities are available during training, which makes it time-consuming to retrain embeddings for newly emerging entities. To address this issue, recent works apply the graph neural network on the existing neighbors of the unseen entities. In this paper, we propose a novel framework, namely Virtual Neighbor (VN) network, to address three key challenges. Firstly, to reduce the neighbor sparsity problem, we introduce the concept of the virtual neighbors inferred by rules. And we assign soft labels to these neighbors by solving a rule-constrained problem, rather than simply regarding them as unquestionably true. Secondly, many existing methods only use one-hop or two-hop neighbors for aggregation and ignore the distant information that may be helpful. Instead, we identify both logic and symmetric path rules to capture complex patterns. Finally, instead of one-time injection of rules, we employ an iterative learning scheme between the embedding method and virtual neighbor prediction to capture the interactions within. Experimental results on two knowledge graph completion tasks demonstrate that our VN network significantly outperforms state-of-the-art baselines. Furthermore, results on Subject/Object-R show that our proposed VN network is highly robust to the neighbor sparsity problem. ",
    "url": "https://arxiv.org/abs/2402.14033",
    "authors": [
      "Yongquan He",
      "Zihan Wang",
      "Peng Zhang",
      "Zhaopeng Tu",
      "Zhaochun Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14034",
    "title": "AgentScope: A Flexible yet Robust Multi-Agent Platform",
    "abstract": "With the rapid advancement of Large Language Models (LLMs), significant progress has been made in multi-agent applications. However, the complexities in coordinating agents' cooperation and LLMs' erratic performance pose notable challenges in developing robust and efficient multi-agent applications. To tackle these challenges, we propose AgentScope, a developer-centric multi-agent platform with message exchange as its core communication mechanism. Together with abundant syntactic tools, built-in resources, and user-friendly interactions, our communication mechanism significantly reduces the barriers to both development and understanding. Towards robust and flexible multi-agent application, AgentScope provides both built-in and customizable fault tolerance mechanisms while it is also armed with system-level supports for multi-modal data generation, storage and transmission. Additionally, we design an actor-based distribution framework, enabling easy conversion between local and distributed deployments and automatic parallel optimization without extra effort. With these features, AgentScope empowers developers to build applications that fully realize the potential of intelligent agents. We have released AgentScope at https://github.com/modelscope/agentscope, and hope AgentScope invites wider participation and innovation in this fast-moving field. ",
    "url": "https://arxiv.org/abs/2402.14034",
    "authors": [
      "Dawei Gao",
      "Zitao Li",
      "Weirui Kuang",
      "Xuchen Pan",
      "Daoyuan Chen",
      "Zhijian Ma",
      "Bingchen Qian",
      "Liuyi Yao",
      "Lin Zhu",
      "Chen Cheng",
      "Hongzhu Shi",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14037",
    "title": "An Effective Networks Intrusion Detection Approach Based on Hybrid  Harris Hawks and Multi-Layer Perceptron",
    "abstract": "This paper proposes an Intrusion Detection System (IDS) employing the Harris Hawks Optimization algorithm (HHO) to optimize Multilayer Perceptron learning by optimizing bias and weight parameters. HHO-MLP aims to select optimal parameters in its learning process to minimize intrusion detection errors in networks. HHO-MLP has been implemented using EvoloPy NN framework, an open-source Python tool specialized for training MLPs using evolutionary algorithms. For purposes of comparing the HHO model against other evolutionary methodologies currently available, specificity and sensitivity measures, accuracy measures, and mse and rmse measures have been calculated using KDD datasets. Experiments have demonstrated the HHO MLP method is effective at identifying malicious patterns. HHO-MLP has been tested against evolutionary algorithms like Butterfly Optimization Algorithm (BOA), Grasshopper Optimization Algorithms (GOA), and Black Widow Optimizations (BOW), with validation by Random Forest (RF), XG-Boost. HHO-MLP showed superior performance by attaining top scores with accuracy rate of 93.17%, sensitivity level of 89.25%, and specificity percentage of 95.41%. ",
    "url": "https://arxiv.org/abs/2402.14037",
    "authors": [
      "Moutaz Alazab",
      "Ruba Abu Khurma",
      "Pedro A. Castillo",
      "Bilal Abu-Salih",
      "Alejandro Martin",
      "David Camacho"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14039",
    "title": "Specialty detection in the context of telemedicine in a highly  imbalanced multi-class distribution",
    "abstract": "The Covid-19 pandemic has led to an increase in the awareness of and demand for telemedicine services, resulting in a need for automating the process and relying on machine learning (ML) to reduce the operational load. This research proposes a specialty detection classifier based on a machine learning model to automate the process of detecting the correct specialty for each question and routing it to the correct doctor. The study focuses on handling multiclass and highly imbalanced datasets for Arabic medical questions, comparing some oversampling techniques, developing a Deep Neural Network (DNN) model for specialty detection, and exploring the hidden business areas that rely on specialty detection such as customizing and personalizing the consultation flow for different specialties. The proposed module is deployed in both synchronous and asynchronous medical consultations to provide more real-time classification, minimize the doctor effort in addressing the correct specialty, and give the system more flexibility in customizing the medical consultation flow. The evaluation and assessment are based on accuracy, precision, recall, and F1-score. The experimental results suggest that combining multiple techniques, such as SMOTE and reweighing with keyword identification, is necessary to achieve improved performance in detecting rare classes in imbalanced multiclass datasets. By using these techniques, specialty detection models can more accurately detect rare classes in real-world scenarios where imbalanced data is common. ",
    "url": "https://arxiv.org/abs/2402.14039",
    "authors": [
      "Alaa Alomari",
      "Hossam Faris",
      "Pedro A. Castillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14041",
    "title": "E2USD: Efficient-yet-effective Unsupervised State Detection for  Multivariate Time Series",
    "abstract": "We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead. Our code is available at https://github.com/AI4CTS/E2Usd. ",
    "url": "https://arxiv.org/abs/2402.14041",
    "authors": [
      "Zhichen Lai",
      "Huan Li",
      "Dalin Zhang",
      "Yan Zhao",
      "Weizhu Qian",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2402.14048",
    "title": "PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial  Optimization",
    "abstract": "Reinforcement learning-based methods for constructing solutions to combinatorial optimization problems are rapidly approaching the performance of human-designed algorithms. To further narrow the gap, learning-based approaches must efficiently explore the solution space during the search process. Recent approaches artificially increase exploration by enforcing diverse solution generation through handcrafted rules, however, these rules can impair solution quality and are difficult to design for more complex problems. In this paper, we introduce PolyNet, an approach for improving exploration of the solution space by learning complementary solution strategies. In contrast to other works, PolyNet uses only a single-decoder and a training schema that does not enforce diverse solution generation through handcrafted rules. We evaluate PolyNet on four combinatorial optimization problems and observe that the implicit diversity mechanism allows PolyNet to find better solutions than approaches the explicitly enforce diverse solution generation. ",
    "url": "https://arxiv.org/abs/2402.14048",
    "authors": [
      "Andr\u00e9 Hottung",
      "Mridul Mahajan",
      "Kevin Tierney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14049",
    "title": "Generative Adversarial Models for Extreme Downscaling of Climate  Datasets",
    "abstract": "Addressing the challenges of climate change requires accurate and high-resolution mapping of climate and weather variables. However, many existing climate datasets, such as the gridded outputs of the state-of-the-art numerical climate models (e.g., general circulation models), are only available at very coarse spatial resolutions due to the model complexity and extremely high computational demand. Deep-learning-based methods, particularly generative adversarial networks (GANs) and their variants, have proved effective for refining natural images, and have shown great promise in improving scientific datasets. In this paper, we describe a conditional GAN-based geospatial downscaling method for extreme downscaling of gridded climate datasets. Compared to most existing methods, the method can generate high-resolution accurate climate datasets from very low-resolution inputs. More importantly, the method explicitly considers the uncertainty inherent to the downscaling process that tends to be ignored in existing methods. Given an input, the method can produce a multitude of plausible high-resolution samples instead of one single deterministic result. These samples allow for an empirical exploration and inferences of model uncertainty and robustness. With a case study of gridded climate datasets (wind velocity and solar irradiance), we demonstrate the performances of the framework in downscaling tasks with very high scaling factors (up to $64\\times$) and highlight the advantages of the framework with a comprehensive comparison with commonly used downscaling methods, including area-to-point (ATP) kriging, deep image prior (DIP), enhanced deep super-resolution network (EDSR), enhanced super-resolution generative adversarial networks (ESRGAN), and physics-informed resolution-enhancing GAN (PhIRE GAN). ",
    "url": "https://arxiv.org/abs/2402.14049",
    "authors": [
      "Guiye Li",
      "Guofeng Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2402.14080",
    "title": "Efficient Normalized Conformal Prediction and Uncertainty Quantification  for Anti-Cancer Drug Sensitivity Prediction with Deep Regression Forests",
    "abstract": "Deep learning models are being adopted and applied on various critical decision-making tasks, yet they are trained to provide point predictions without providing degrees of confidence. The trustworthiness of deep learning models can be increased if paired with uncertainty estimations. Conformal Prediction has emerged as a promising method to pair machine learning models with prediction intervals, allowing for a view of the model's uncertainty. However, popular uncertainty estimation methods for conformal prediction fail to provide heteroskedastic intervals that are equally accurate for all samples. In this paper, we propose a method to estimate the uncertainty of each sample by calculating the variance obtained from a Deep Regression Forest. We show that the deep regression forest variance improves the efficiency and coverage of normalized inductive conformal prediction on a drug response prediction task. ",
    "url": "https://arxiv.org/abs/2402.14080",
    "authors": [
      "Daniel Nolte",
      "Souparno Ghosh",
      "Ranadip Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14081",
    "title": "Robust Learning of Noisy Time Series Collections Using Stochastic  Process Models with Motion Codes",
    "abstract": "While time series classification and forecasting problems have been extensively studied, the cases of noisy time series data with arbitrary time sequence lengths have remained challenging. Each time series instance can be thought of as a sample realization of a noisy dynamical model, which is characterized by a continuous stochastic process. For many applications, the data are mixed and consist of several types of noisy time series sequences modeled by multiple stochastic processes, making the forecasting and classification tasks even more challenging. Instead of regressing data naively and individually to each time series type, we take a latent variable model approach using a mixtured Gaussian processes with learned spectral kernels. More specifically, we auto-assign each type of noisy time series data a signature vector called its motion code. Then, conditioned on each assigned motion code, we infer a sparse approximation of the corresponding time series using the concept of the most informative timestamps. Our unmixing classification approach involves maximizing the likelihood across all the mixed noisy time series sequences of varying lengths. This stochastic approach allows us to learn not only within a single type of noisy time series data but also across many underlying stochastic processes, giving us a way to learn multiple dynamical models in an integrated and robust manner. The different learned latent stochastic models allow us to generate specific sub-type forecasting. We provide several quantitative comparisons demonstrating the performance of our approach. ",
    "url": "https://arxiv.org/abs/2402.14081",
    "authors": [
      "Chandrajit Bajaj",
      "Minh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14090",
    "title": "Social Environment Design",
    "abstract": "Artificial Intelligence (AI) holds promise as a technology that can be used to improve government and economic policy-making. This paper proposes a new research agenda towards this end by introducing Social Environment Design, a general framework for the use of AI for automated policy-making that connects with the Reinforcement Learning, EconCS, and Computational Social Choice communities. The framework seeks to capture general economic environments, includes voting on policy objectives, and gives a direction for the systematic analysis of government and economic policy through AI simulation. We highlight key open problems for future research in AI-based policy-making. By solving these challenges, we hope to achieve various social welfare objectives, thereby promoting more ethical and responsible decision making. ",
    "url": "https://arxiv.org/abs/2402.14090",
    "authors": [
      "Edwin Zhang",
      "Sadie Zhao",
      "Tonghan Wang",
      "Safwan Hossain",
      "Henry Gasztowtt",
      "Stephan Zheng",
      "David C. Parkes",
      "Milind Tambe",
      "Yiling Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "General Economics (econ.GN)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14096",
    "title": "EyeTrans: Merging Human and Machine Attention for Neural Code  Summarization",
    "abstract": "Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention, that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention with machine attention in the Transformer architecture, and (3) we conduct comprehensive experiments on two code summarization tasks to demonstrate the effectiveness of incorporating human attention into Transformers. Integrating human attention leads to an improvement of up to 29.91% in Functional Summarization and up to 6.39% in General Code Summarization performance, demonstrating the substantial benefits of this combination. We further explore performance in terms of robustness and efficiency by creating challenging summarization scenarios in which EyeTrans exhibits interesting properties. We also visualize the attention map to depict the simplifying effect of machine attention in the Transformer by incorporating human attention. This work has the potential to propel AI research in software engineering by introducing more human-centered approaches and data. ",
    "url": "https://arxiv.org/abs/2402.14096",
    "authors": [
      "Yifan Zhang",
      "Jiliang Li",
      "Zachary Karas",
      "Aakash Bansal",
      "Toby Jia-Jun Li",
      "Collin McMillan",
      "Kevin Leach",
      "Yu Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.14114",
    "title": "Multi-organ Self-supervised Contrastive Learning for Breast Lesion  Segmentation",
    "abstract": "Self-supervised learning has proven to be an effective way to learn representations in domains where annotated labels are scarce, such as medical imaging. A widely adopted framework for this purpose is contrastive learning and it has been applied to different scenarios. This paper seeks to advance our understanding of the contrastive learning framework by exploring a novel perspective: employing multi-organ datasets for pre-training models tailored to specific organ-related target tasks. More specifically, our target task is breast tumour segmentation in ultrasound images. The pre-training datasets include ultrasound images from other organs, such as the lungs and heart, and large datasets of natural images. Our results show that conventional contrastive learning pre-training improves performance compared to supervised baseline approaches. Furthermore, our pre-trained models achieve comparable performance when fine-tuned with only half of the available labelled data. Our findings also show the advantages of pre-training on diverse organ data for improving performance in the downstream task. ",
    "url": "https://arxiv.org/abs/2402.14114",
    "authors": [
      "Hugo Figueiras",
      "Helena Aidos",
      "Nuno Cruz Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14124",
    "title": "Fake Resume Attacks: Data Poisoning on Online Job Platforms",
    "abstract": "While recent studies have exposed various vulnerabilities incurred from data poisoning attacks in many web services, little is known about the vulnerability on online professional job platforms (e.g., LinkedIn and Indeed). In this work, first time, we demonstrate the critical vulnerabilities found in the common Human Resources (HR) task of matching job seekers and companies on online job platforms. Capitalizing on the unrestricted format and contents of job seekers' resumes and easy creation of accounts on job platforms, we demonstrate three attack scenarios: (1) company promotion attack to increase the likelihood of target companies being recommended, (2) company demotion attack to decrease the likelihood of target companies being recommended, and (3) user promotion attack to increase the likelihood of certain users being matched to certain companies. To this end, we develop an end-to-end \"fake resume\" generation framework, titled FRANCIS, that induces systematic prediction errors via data poisoning. Our empirical evaluation on real-world datasets reveals that data poisoning attacks can markedly skew the results of matchmaking between job seekers and companies, regardless of underlying models, with vulnerability amplified in proportion to poisoning intensity. These findings suggest that the outputs of various services from job platforms can be potentially hacked by malicious users. ",
    "url": "https://arxiv.org/abs/2402.14124",
    "authors": [
      "Michiharu Yamashita",
      "Thanh Tran",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.14129",
    "title": "Combining Language and Graph Models for Semi-structured Information  Extraction on the Web",
    "abstract": "Relation extraction is an efficient way of mining the extraordinary wealth of human knowledge on the Web. Existing methods rely on domain-specific training data or produce noisy outputs. We focus here on extracting targeted relations from semi-structured web pages given only a short description of the relation. We present GraphScholarBERT, an open-domain information extraction method based on a joint graph and language model structure. GraphScholarBERT can generalize to previously unseen domains without additional data or training and produces only clean extraction results matched to the search keyword. Experiments show that GraphScholarBERT can improve extraction F1 scores by as much as 34.8\\% compared to previous work in a zero-shot domain and zero-shot website setting. ",
    "url": "https://arxiv.org/abs/2402.14129",
    "authors": [
      "Zhi Hong",
      "Kyle Chard",
      "Ian Foster"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14144",
    "title": "Extending identifiability results from isolated networks to embedded  networks",
    "abstract": "This paper deals with the design of Excitation and Measurement Patterns (EMPs) for the identification of dynamical networks, when the objective is to identify only a subnetwork embedded in a larger network. Recent results have shown how to construct EMPs that guarantee identifiability for a range of networks with specific graph topologies, such as trees, loops, or Directed Acyclic Graphs (DAGs). However, an EMP that is valid for the identification of a subnetwork taken in isolation may no longer be valid when that subnetwork is embedded in a larger network. Our main contribution is to exhibit conditions under which it does remain valid, and to propose ways to enhance such EMP when these conditions are not satisfied. ",
    "url": "https://arxiv.org/abs/2402.14144",
    "authors": [
      "Eduardo Mapurunga",
      "Michel Gevers",
      "Alexandre S. Bazanella"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.14151",
    "title": "BIRCO: A Benchmark of Information Retrieval Tasks with Complex  Objectives",
    "abstract": "We present the Benchmark of Information Retrieval (IR) tasks with Complex Objectives (BIRCO). BIRCO evaluates the ability of IR systems to retrieve documents given multi-faceted user objectives. The benchmark's complexity and compact size make it suitable for evaluating large language model (LLM)-based information retrieval systems. We present a modular framework for investigating factors that may influence LLM performance on retrieval tasks, and identify a simple baseline model which matches or outperforms existing approaches and more complex alternatives. No approach achieves satisfactory performance on all benchmark tasks, suggesting that stronger models and new retrieval protocols are necessary to address complex user needs. ",
    "url": "https://arxiv.org/abs/2402.14151",
    "authors": [
      "Xiaoyue Wang",
      "Jianyou Wang",
      "Weili Cao",
      "Kaicheng Wang",
      "Ramamohan Paturi",
      "Leon Bergen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14154",
    "title": "MM-Soc: Benchmarking Multimodal Large Language Models in Social Media  Platforms",
    "abstract": "Social media platforms are hubs for multimodal information exchange, encompassing text, images, and videos, making it challenging for machines to comprehend the information or emotions associated with interactions in online spaces. Multimodal Large Language Models (MLLMs) have emerged as a promising solution to address these challenges, yet struggle with accurately interpreting human emotions and complex contents like misinformation. This paper introduces MM-Soc, a comprehensive benchmark designed to evaluate MLLMs' understanding of multimodal social media content. MM-Soc compiles prominent multimodal datasets and incorporates a novel large-scale YouTube tagging dataset, targeting a range of tasks from misinformation detection, hate speech detection, and social context generation. Through our exhaustive evaluation on ten size-variants of four open-source MLLMs, we have identified significant performance disparities, highlighting the need for advancements in models' social understanding capabilities. Our analysis reveals that, in a zero-shot setting, various types of MLLMs generally exhibit difficulties in handling social media tasks. However, MLLMs demonstrate performance improvements post fine-tuning, suggesting potential pathways for improvement. ",
    "url": "https://arxiv.org/abs/2402.14154",
    "authors": [
      "Yiqiao Jin",
      "Minje Choi",
      "Gaurav Verma",
      "Jindong Wang",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.14172",
    "title": "Open Source Software Field Research: Spanning Social and Practice  Networks for Re-Entering the Field",
    "abstract": "Sociotechnical research increasingly includes the social sub-networks that emerge from large-scale sociotechnical infrastructure, including the infrastructure for building open source software. This paper addresses these numerous sub-networks as advantageous for researchers. It provides a methodological synthesis focusing on how researchers can best span adjacent social sub-networks during engaged field research. Specifically, we describe practices and artifacts that aid movement from one social subsystem within a more extensive technical infrastructure to another. To surface the importance of spanning sub-networks, we incorporate a discussion of social capital and the role of technical infrastructure in its development for sociotechnical researchers. We then characterize a five-step process for spanning social sub-networks during engaged field research: commitment, context mapping, jargon competence, returning value, and bridging. We then present our experience studying corporate open source software projects and the role of that experience in accelerating our work in open source scientific software research as described through the lens of bridging social capital. Based on our analysis, we offer recommendations for engaging in fieldwork in adjacent social sub-networks that share a technical context and discussion of how the relationship between social and technically acquired social capital is a missing but critical methodological dimension for research on large-scale sociotechnical research. ",
    "url": "https://arxiv.org/abs/2402.14172",
    "authors": [
      "Sean P. Goggins",
      "Kevin Lumbard",
      "Matt Germonprez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.14182",
    "title": "Do Machines and Humans Focus on Similar Code? Exploring Explainability  of Large Language Models in Code Summarization",
    "abstract": "Recent language models have demonstrated proficiency in summarizing source code. However, as in many other domains of machine learning, language models of code lack sufficient explainability. Informally, we lack a formulaic or intuitive understanding of what and how models learn from code. Explainability of language models can be partially provided if, as the models learn to produce higher-quality code summaries, they also align in deeming the same code parts important as those identified by human programmers. In this paper, we report negative results from our investigation of explainability of language models in code summarization through the lens of human comprehension. We measure human focus on code using eye-tracking metrics such as fixation counts and duration in code summarization tasks. To approximate language model focus, we employ a state-of-the-art model-agnostic, black-box, perturbation-based approach, SHAP (SHapley Additive exPlanations), to identify which code tokens influence that generation of summaries. Using these settings, we find no statistically significant relationship between language models' focus and human programmers' attention. Furthermore, alignment between model and human foci in this setting does not seem to dictate the quality of the LLM-generated summaries. Our study highlights an inability to align human focus with SHAP-based model focus measures. This result calls for future investigation of multiple open questions for explainable language models for code summarization and software engineering tasks in general, including the training mechanisms of language models for code, whether there is an alignment between human and model attention on code, whether human attention can improve the development of language models, and what other model focus measures are appropriate for improving explainability. ",
    "url": "https://arxiv.org/abs/2402.14182",
    "authors": [
      "Jiliang Li",
      "Yifan Zhang",
      "Zachary Karas",
      "Collin McMillan",
      "Kevin Leach",
      "Yu Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14194",
    "title": "BeTAIL: Behavior Transformer Adversarial Imitation Learning from Human  Racing Gameplay",
    "abstract": "Imitation learning learns a policy from demonstrations without requiring hand-designed reward functions. In many robotic tasks, such as autonomous racing, imitated policies must model complex environment dynamics and human decision-making. Sequence modeling is highly effective in capturing intricate patterns of motion sequences but struggles to adapt to new environments or distribution shifts that are common in real-world robotics tasks. In contrast, Adversarial Imitation Learning (AIL) can mitigate this effect, but struggles with sample inefficiency and handling complex motion patterns. Thus, we propose BeTAIL: Behavior Transformer Adversarial Imitation Learning, which combines a Behavior Transformer (BeT) policy from human demonstrations with online AIL. BeTAIL adds an AIL residual policy to the BeT policy to model the sequential decision-making process of human experts and correct for out-of-distribution states or shifts in environment dynamics. We test BeTAIL on three challenges with expert-level demonstrations of real human gameplay in Gran Turismo Sport. Our proposed residual BeTAIL reduces environment interactions and improves racing performance and stability, even when the BeT is pretrained on different tracks than downstream learning. Videos and code available at: https://sites.google.com/berkeley.edu/BeTAIL/home. ",
    "url": "https://arxiv.org/abs/2402.14194",
    "authors": [
      "Catherine Weaver",
      "Chen Tang",
      "Ce Hao",
      "Kenta Kawamoto",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.14196",
    "title": "Mip-Grid: Anti-aliased Grid Representations for Neural Radiance Fields",
    "abstract": "Despite the remarkable achievements of neural radiance fields (NeRF) in representing 3D scenes and generating novel view images, the aliasing issue, rendering \"jaggies\" or \"blurry\" images at varying camera distances, remains unresolved in most existing approaches. The recently proposed mip-NeRF has addressed this challenge by rendering conical frustums instead of rays. However, it relies on MLP architecture to represent the radiance fields, missing out on the fast training speed offered by the latest grid-based methods. In this work, we present mip-Grid, a novel approach that integrates anti-aliasing techniques into grid-based representations for radiance fields, mitigating the aliasing artifacts while enjoying fast training time. The proposed method generates multi-scale grids by applying simple convolution operations over a shared grid representation and uses the scale-aware coordinate to retrieve features at different scales from the generated multi-scale grids. To test the effectiveness, we integrated the proposed method into the two recent representative grid-based methods, TensoRF and K-Planes. Experimental results demonstrate that mip-Grid greatly improves the rendering performance of both methods and even outperforms mip-NeRF on multi-scale datasets while achieving significantly faster training time. For code and demo videos, please see https://stnamjef.github.io/mipgrid.github.io/. ",
    "url": "https://arxiv.org/abs/2402.14196",
    "authors": [
      "Seungtae Nam",
      "Daniel Rho",
      "Jong Hwan Ko",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2402.14202",
    "title": "Comparing Graph Transformers via Positional Encodings",
    "abstract": "The distinguishing power of graph transformers is closely tied to the choice of positional encoding: features used to augment the base transformer with information about the graph. There are two primary types of positional encoding: absolute positional encodings (APEs) and relative positional encodings (RPEs). APEs assign features to each node and are given as input to the transformer. RPEs instead assign a feature to each pair of nodes, e.g., graph distance, and are used to augment the attention block. A priori, it is unclear which method is better for maximizing the power of the resulting graph transformer. In this paper, we aim to understand the relationship between these different types of positional encodings. Interestingly, we show that graph transformers using APEs and RPEs are equivalent in terms of distinguishing power. In particular, we demonstrate how to interchange APEs and RPEs while maintaining their distinguishing power in terms of graph transformers. Based on our theoretical results, we provide a study on several APEs and RPEs (including the resistance distance and the recently introduced stable and expressive positional encoding (SPE)) and compare their distinguishing power in terms of transformers. We believe our work will help navigate the huge number of choices of positional encoding and will provide guidance on the future design of positional encodings for graph transformers. ",
    "url": "https://arxiv.org/abs/2402.14202",
    "authors": [
      "Mitchell Black",
      "Zhengchao Wan",
      "Gal Mishne",
      "Amir Nayyeri",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14205",
    "title": "Compression Robust Synthetic Speech Detection Using Patched Spectrogram  Transformer",
    "abstract": "Many deep learning synthetic speech generation tools are readily available. The use of synthetic speech has caused financial fraud, impersonation of people, and misinformation to spread. For this reason forensic methods that can detect synthetic speech have been proposed. Existing methods often overfit on one dataset and their performance reduces substantially in practical scenarios such as detecting synthetic speech shared on social platforms. In this paper we propose, Patched Spectrogram Synthetic Speech Detection Transformer (PS3DT), a synthetic speech detector that converts a time domain speech signal to a mel-spectrogram and processes it in patches using a transformer neural network. We evaluate the detection performance of PS3DT on ASVspoof2019 dataset. Our experiments show that PS3DT performs well on ASVspoof2019 dataset compared to other approaches using spectrogram for synthetic speech detection. We also investigate generalization performance of PS3DT on In-the-Wild dataset. PS3DT generalizes well than several existing methods on detecting synthetic speech from an out-of-distribution dataset. We also evaluate robustness of PS3DT to detect telephone quality synthetic speech and synthetic speech shared on social platforms (compressed speech). PS3DT is robust to compression and can detect telephone quality synthetic speech better than several existing methods. ",
    "url": "https://arxiv.org/abs/2402.14205",
    "authors": [
      "Amit Kumar Singh Yadav",
      "Ziyue Xiang",
      "Kratika Bhagtani",
      "Paolo Bestagini",
      "Stefano Tubaro",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.14208",
    "title": "Content Conditional Debiasing for Fair Text Embedding",
    "abstract": "Mitigating biases in machine learning models has gained increasing attention in Natural Language Processing (NLP). Yet, only a few studies focus on fair text embeddings, which are crucial yet challenging for real-world applications. In this paper, we propose a novel method for learning fair text embeddings. We achieve fairness while maintaining utility trade-off by ensuring conditional independence between sensitive attributes and text embeddings conditioned on the content. Specifically, we enforce that embeddings of texts with different sensitive attributes but identical content maintain the same distance toward the embedding of their corresponding neutral text. Furthermore, we address the issue of lacking proper training data by using Large Language Models (LLMs) to augment texts into different sensitive groups. Our extensive evaluations demonstrate that our approach effectively improves fairness while preserving the utility of embeddings, representing a pioneering effort in achieving conditional independence for fair text embeddings. ",
    "url": "https://arxiv.org/abs/2402.14208",
    "authors": [
      "Wenlong Deng",
      "Blair Chen",
      "Xiaoxiao Li",
      "Christos Thrampoulidis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14227",
    "title": "Quaternion recurrent neural network with real-time recurrent learning  and maximum correntropy criterion",
    "abstract": "We develop a robust quaternion recurrent neural network (QRNN) for real-time processing of 3D and 4D data with outliers. This is achieved by combining the real-time recurrent learning (RTRL) algorithm and the maximum correntropy criterion (MCC) as a loss function. While both the mean square error and maximum correntropy criterion are viable cost functions, it is shown that the non-quadratic maximum correntropy loss function is less sensitive to outliers, making it suitable for applications with multidimensional noisy or uncertain data. Both algorithms are derived based on the novel generalised HR (GHR) calculus, which allows for the differentiation of real functions of quaternion variables and offers the product and chain rules, thus enabling elegant and compact derivations. Simulation results in the context of motion prediction of chest internal markers for lung cancer radiotherapy, which includes regular and irregular breathing sequences, support the analysis. ",
    "url": "https://arxiv.org/abs/2402.14227",
    "authors": [
      "Pauline Bourigault",
      "Dongpo Xu",
      "Danilo P. Mandic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14241",
    "title": "A Self-supervised Pressure Map human keypoint Detection Approch:  Optimizing Generalization and Computational Efficiency Across Datasets",
    "abstract": "In environments where RGB images are inadequate, pressure maps is a viable alternative, garnering scholarly attention. This study introduces a novel self-supervised pressure map keypoint detection (SPMKD) method, addressing the current gap in specialized designs for human keypoint extraction from pressure maps. Central to our contribution is the Encoder-Fuser-Decoder (EFD) model, which is a robust framework that integrates a lightweight encoder for precise human keypoint detection, a fuser for efficient gradient propagation, and a decoder that transforms human keypoints into reconstructed pressure maps. This structure is further enhanced by the Classification-to-Regression Weight Transfer (CRWT) method, which fine-tunes accuracy through initial classification task training. This innovation not only enhances human keypoint generalization without manual annotations but also showcases remarkable efficiency and generalization, evidenced by a reduction to only $5.96\\%$ in FLOPs and $1.11\\%$ in parameter count compared to the baseline methods. ",
    "url": "https://arxiv.org/abs/2402.14241",
    "authors": [
      "Chengzhang Yu",
      "Xianjun Yang",
      "Wenxia Bao",
      "Shaonan Wang",
      "Zhiming Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14279",
    "title": "Mitigating the Linguistic Gap with Phonemic Representations for Robust  Multilingual Language Understanding",
    "abstract": "Approaches to improving multilingual language understanding often require multiple languages during the training phase, rely on complicated training techniques, and -- importantly -- struggle with significant performance gaps between high-resource and low-resource languages. We hypothesize that the performance gaps between languages are affected by linguistic gaps between those languages and provide a novel solution for robust multilingual language modeling by employing phonemic representations (specifically, using phonemes as input tokens to LMs rather than subwords). We present quantitative evidence from three cross-lingual tasks that demonstrate the effectiveness of phonemic representation, which is further justified by a theoretical analysis of the cross-lingual performance gap. ",
    "url": "https://arxiv.org/abs/2402.14279",
    "authors": [
      "Haeji Jung",
      "Changdae Oh",
      "Jooeon Kang",
      "Jimin Sohn",
      "Kyungwoo Song",
      "Jinkyu Kim",
      "David R. Mortensen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14292",
    "title": "Saharaline: A Collective Social Support Intervention for Teachers in  Low-Income Indian Schools",
    "abstract": "This paper presents Saharaline, an intervention designed to provide collective social support for teachers in low-income schools. Implemented as a WhatsApp-based helpline, Saharaline enables teachers to reach out for personalized, long-term assistance with a wide range of problems and stressors, including pedagogical, emotional, and technological challenges. Depending on the support needed, teachers' requests are routed to appropriate domain experts -- staff employed by educational non-profit organizations who understand teachers' on-the-ground realities -- who offer localized and contextualized assistance. Via a three-month exploratory deployment with 28 teachers in India, we show how Saharaline's design enabled a collective of diverse education experts to craft and deliver localized solutions that teachers could incorporate into their practice. We conclude by reflecting on the efficacy of our intervention in low-resource work contexts and provide recommendations to enhance collective social support interventions similar to Saharaline. ",
    "url": "https://arxiv.org/abs/2402.14292",
    "authors": [
      "Rama Adithya Varanasi",
      "Aditya Vashistha",
      "Nicola Dell"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.14293",
    "title": "Leveraging Large Language Models for Concept Graph Recovery and Question  Answering in NLP Education",
    "abstract": "In the domain of Natural Language Processing (NLP), Large Language Models (LLMs) have demonstrated promise in text-generation tasks. However, their educational applications, particularly for domain-specific queries, remain underexplored. This study investigates LLMs' capabilities in educational scenarios, focusing on concept graph recovery and question-answering (QA). We assess LLMs' zero-shot performance in creating domain-specific concept graphs and introduce TutorQA, a new expert-verified NLP-focused benchmark for scientific graph reasoning and QA. TutorQA consists of five tasks with 500 QA pairs. To tackle TutorQA queries, we present CGLLM, a pipeline integrating concept graphs with LLMs for answering diverse questions. Our results indicate that LLMs' zero-shot concept graph recovery is competitive with supervised methods, showing an average 3% F1 score improvement. In TutorQA tasks, LLMs achieve up to 26% F1 score enhancement. Moreover, human evaluation and analysis show that CGLLM generates answers with more fine-grained concepts. ",
    "url": "https://arxiv.org/abs/2402.14293",
    "authors": [
      "Rui Yang",
      "Boming Yang",
      "Sixun Ouyang",
      "Tianwei She",
      "Aosong Feng",
      "Yuang Jiang",
      "Freddy Lecue",
      "Jinghui Lu",
      "Irene Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14296",
    "title": "Mitigating Biases of Large Language Models in Stance Detection with  Calibration",
    "abstract": "Large language models (LLMs) have achieved remarkable progress in many natural language processing tasks. However, our experiment reveals that, in stance detection tasks, LLMs may generate biased stances due to spurious sentiment-stance correlation and preference towards certain individuals and topics, thus harming their performance. Therefore, in this paper, we propose to Mitigate Biases of LLMs in stance detection with Calibration (MB-Cal). In which, a novel gated calibration network is devised to mitigate the biases on the stance reasoning results from LLMs. Further, to make the calibration more accurate and generalizable, we construct counterfactual augmented data to rectify stance biases. Experimental results on in-target and zero-shot stance detection tasks show that the proposed MB-Cal can effectively mitigate biases of LLMs, achieving state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2402.14296",
    "authors": [
      "Ang Li",
      "Jingqian Zhao",
      "Bin Liang",
      "Lin Gui",
      "Hui Wang",
      "Xi Zeng",
      "Kam-Fai Wong",
      "Ruifeng Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14308",
    "title": "Ground-Fusion: A Low-cost Ground SLAM System Robust to Corner Cases",
    "abstract": "We introduce Ground-Fusion, a low-cost sensor fusion simultaneous localization and mapping (SLAM) system for ground vehicles. Our system features efficient initialization, effective sensor anomaly detection and handling, real-time dense color mapping, and robust localization in diverse environments. We tightly integrate RGB-D images, inertial measurements, wheel odometer and GNSS signals within a factor graph to achieve accurate and reliable localization both indoors and outdoors. To ensure successful initialization, we propose an efficient strategy that comprises three different methods: stationary, visual, and dynamic, tailored to handle diverse cases. Furthermore, we develop mechanisms to detect sensor anomalies and degradation, handling them adeptly to maintain system accuracy. Our experimental results on both public and self-collected datasets demonstrate that Ground-Fusion outperforms existing low-cost SLAM systems in corner cases. We release the code and datasets at https://github.com/SJTU-ViSYS/Ground-Fusion. ",
    "url": "https://arxiv.org/abs/2402.14308",
    "authors": [
      "Jie Yin",
      "Ang Li",
      "Wei Xi",
      "Wenxian Yu",
      "Danping Zou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.14309",
    "title": "YOLO-TLA: An Efficient and Lightweight Small Object Detection Model  based on YOLOv5",
    "abstract": "Object detection, a crucial aspect of computer vision, has seen significant advancements in accuracy and robustness. Despite these advancements, practical applications still face notable challenges, primarily the inaccurate detection or missed detection of small objects. In this paper, we propose YOLO-TLA, an advanced object detection model building on YOLOv5. We first introduce an additional detection layer for small objects in the neck network pyramid architecture, thereby producing a feature map of a larger scale to discern finer features of small objects. Further, we integrate the C3CrossCovn module into the backbone network. This module uses sliding window feature extraction, which effectively minimizes both computational demand and the number of parameters, rendering the model more compact. Additionally, we have incorporated a global attention mechanism into the backbone network. This mechanism combines the channel information with global information to create a weighted feature map. This feature map is tailored to highlight the attributes of the object of interest, while effectively ignoring irrelevant details. In comparison to the baseline YOLOv5s model, our newly developed YOLO-TLA model has shown considerable improvements on the MS COCO validation dataset, with increases of 4.6% in mAP@0.5 and 4% in mAP@0.5:0.95, all while keeping the model size compact at 9.49M parameters. Further extending these improvements to the YOLOv5m model, the enhanced version exhibited a 1.7% and 1.9% increase in mAP@0.5 and mAP@0.5:0.95, respectively, with a total of 27.53M parameters. These results validate the YOLO-TLA model's efficient and effective performance in small object detection, achieving high accuracy with fewer parameters and computational demands. ",
    "url": "https://arxiv.org/abs/2402.14309",
    "authors": [
      "Peng Gao",
      "Chun-Lin Ji",
      "Tao Yu",
      "Ru-Yue Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14323",
    "title": "REPOFUSE: Repository-Level Code Completion with Fused Dual Context",
    "abstract": "The success of language models in code assistance has spurred the proposal of repository-level code completion as a means to enhance prediction accuracy, utilizing the context from the entire codebase. However, this amplified context can inadvertently increase inference latency, potentially undermining the developer experience and deterring tool adoption-a challenge we termed the Context-Latency Conundrum. This paper introduces RepoGenix, a pioneering solution designed to enhance repository-level code completion without the latency trade-off. RepoGenix uniquely fuses two types of contexts: the analogy context, rooted in code analogies, and the rationale context, which encompasses in-depth semantic relationships. We propose a novel rank truncated generation (RTG) technique that efficiently condenses these contexts into prompts with restricted size. This enables RepoGenix to deliver precise code completions while maintaining inference efficiency. Through testing with the CrossCodeEval suite, RepoGenix has demonstrated a significant leap over existing models, achieving a 40.90% to 59.75% increase in exact match (EM) accuracy for code completions and a 26.8% enhancement in inference speed. Beyond experimental validation, RepoGenix has been integrated into the workflow of a large enterprise, where it actively supports various coding tasks. ",
    "url": "https://arxiv.org/abs/2402.14323",
    "authors": [
      "Ming Liang",
      "Xiaoheng Xie",
      "Gehao Zhang",
      "Xunjin Zheng",
      "Peng Di",
      "wei jiang",
      "Hongwei Chen",
      "Chengpeng Wang",
      "Gang Fan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14344",
    "title": "Cluster-then-Match: Efficient Management of Human-Centric, Cell-Less 6G  Networks",
    "abstract": "In 5G and beyond (5GB) networks, the notion of cell tends to blur, as a set of points-of-access (PoAs) using different technologies often cover overlapping areas. In this context, high-quality decisions are needed about (i) which PoA to use when serving an end user and (ii) how to manage PoAs, e.g., how to set their power levels. To address this challenge, we present Cluster-then-Match (CtM), an efficient algorithm making joint decisions about user assignment and PoA management. Following the human-centric networking paradigm, such decisions account not only for the performance of the network, but also for the level of electromagnetic field exposure to which human bodies incur and energy consumption. Our performance evaluation shows how CtM can match the performance of state-of-the-art network management schemes, while reducing electromagnetic emissions and energy consumption by over 80%. ",
    "url": "https://arxiv.org/abs/2402.14344",
    "authors": [
      "Emma Chiaramello",
      "Carla Fabiana Chiasserini",
      "Francesco Malandrino",
      "Alessandro Nordio",
      "Marta Parazzini",
      "Alvaro Valcarce"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.14353",
    "title": "Exploring Emerging Trends in 5G Malicious Traffic Analysis and  Incremental Learning Intrusion Detection Strategies",
    "abstract": "The popularity of 5G networks poses a huge challenge for malicious traffic detection technology. The reason for this is that as the use of 5G technology increases, so does the risk of malicious traffic activity on 5G networks. Malicious traffic activity in 5G networks not only has the potential to disrupt communication services, but also to compromise sensitive data. This can have serious consequences for individuals and organizations. In this paper, we first provide an in-depth study of 5G technology and 5G security. Next we analyze and discuss the latest malicious traffic detection under AI and their applicability to 5G networks, and compare the various traffic detection aspects addressed by SOTA. The SOTA in 5G traffic detection is also analyzed. Next, we propose seven criteria for traffic monitoring datasets to confirm their suitability for future traffic detection studies. Finally, we present three major issues that need to be addressed for traffic detection in 5G environment. The concept of incremental learning techniques is proposed and applied in the experiments, and the experimental results prove to be able to solve the three problems to some extent. ",
    "url": "https://arxiv.org/abs/2402.14353",
    "authors": [
      "Zihao Wang",
      "Kar Wai Fok",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.14354",
    "title": "GAM-Depth: Self-Supervised Indoor Depth Estimation Leveraging a  Gradient-Aware Mask and Semantic Constraints",
    "abstract": "Self-supervised depth estimation has evolved into an image reconstruction task that minimizes a photometric loss. While recent methods have made strides in indoor depth estimation, they often produce inconsistent depth estimation in textureless areas and unsatisfactory depth discrepancies at object boundaries. To address these issues, in this work, we propose GAM-Depth, developed upon two novel components: gradient-aware mask and semantic constraints. The gradient-aware mask enables adaptive and robust supervision for both key areas and textureless regions by allocating weights based on gradient magnitudes.The incorporation of semantic constraints for indoor self-supervised depth estimation improves depth discrepancies at object boundaries, leveraging a co-optimization network and proxy semantic labels derived from a pretrained segmentation model. Experimental studies on three indoor datasets, including NYUv2, ScanNet, and InteriorNet, show that GAM-Depth outperforms existing methods and achieves state-of-the-art performance, signifying a meaningful step forward in indoor depth estimation. Our code will be available at https://github.com/AnqiCheng1234/GAM-Depth. ",
    "url": "https://arxiv.org/abs/2402.14354",
    "authors": [
      "Anqi Cheng",
      "Zhiyuan Yang",
      "Haiyue Zhu",
      "Kezhi Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14367",
    "title": "Representation Learning for Frequent Subgraph Mining",
    "abstract": "Identifying frequent subgraphs, also called network motifs, is crucial in analyzing and predicting properties of real-world networks. However, finding large commonly-occurring motifs remains a challenging problem not only due to its NP-hard subroutine of subgraph counting, but also the exponential growth of the number of possible subgraphs patterns. Here we present Subgraph Pattern Miner (SPMiner), a novel neural approach for approximately finding frequent subgraphs in a large target graph. SPMiner combines graph neural networks, order embedding space, and an efficient search strategy to identify network subgraph patterns that appear most frequently in the target graph. SPMiner first decomposes the target graph into many overlapping subgraphs and then encodes each subgraph into an order embedding space. SPMiner then uses a monotonic walk in the order embedding space to identify frequent motifs. Compared to existing approaches and possible neural alternatives, SPMiner is more accurate, faster, and more scalable. For 5- and 6-node motifs, we show that SPMiner can almost perfectly identify the most frequent motifs while being 100x faster than exact enumeration methods. In addition, SPMiner can also reliably identify frequent 10-node motifs, which is well beyond the size limit of exact enumeration approaches. And last, we show that SPMiner can find large up to 20 node motifs with 10-100x higher frequency than those found by current approximate methods. ",
    "url": "https://arxiv.org/abs/2402.14367",
    "authors": [
      "Rex Ying",
      "Tianyu Fu",
      "Andrew Wang",
      "Jiaxuan You",
      "Yu Wang",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.14380",
    "title": "RadarMOSEVE: A Spatial-Temporal Transformer Network for Radar-Only  Moving Object Segmentation and Ego-Velocity Estimation",
    "abstract": "Moving object segmentation (MOS) and Ego velocity estimation (EVE) are vital capabilities for mobile systems to achieve full autonomy. Several approaches have attempted to achieve MOSEVE using a LiDAR sensor. However, LiDAR sensors are typically expensive and susceptible to adverse weather conditions. Instead, millimeter-wave radar (MWR) has gained popularity in robotics and autonomous driving for real applications due to its cost-effectiveness and resilience to bad weather. Nonetheless, publicly available MOSEVE datasets and approaches using radar data are limited. Some existing methods adopt point convolutional networks from LiDAR-based approaches, ignoring the specific artifacts and the valuable radial velocity information of radar measurements, leading to suboptimal performance. In this paper, we propose a novel transformer network that effectively addresses the sparsity and noise issues and leverages the radial velocity measurements of radar points using our devised radar self- and cross-attention mechanisms. Based on that, our method achieves accurate EVE of the robot and performs MOS using only radar data simultaneously. To thoroughly evaluate the MOSEVE performance of our method, we annotated the radar points in the public View-of-Delft (VoD) dataset and additionally constructed a new radar dataset in various environments. The experimental results demonstrate the superiority of our approach over existing state-of-the-art methods. The code is available at https://github.com/ORCA-Uboat/RadarMOSEVE. ",
    "url": "https://arxiv.org/abs/2402.14380",
    "authors": [
      "Changsong Pang",
      "Xieyuanli Chen",
      "Yimin Liu",
      "Huimin Lu",
      "Yuwei Cheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.14382",
    "title": "Enhancing Temporal Knowledge Graph Forecasting with Large Language  Models via Chain-of-History Reasoning",
    "abstract": "Temporal Knowledge Graph (TKG) forecasting aims to predict future facts based on given histories. Most recent graph-based models excel at capturing structural information within TKGs but lack semantic comprehension abilities. Nowadays, with the surge of LLMs, the LLM-based TKG prediction model has emerged. However, the existing LLM-based model exhibits three shortcomings: (1) It only focuses on the first-order history for prediction while ignoring high-order historical information, resulting in the provided information for LLMs being extremely limited. (2) LLMs struggle with optimal reasoning performance under heavy historical information loads. (3) For TKG prediction, the temporal reasoning capability of LLM alone is limited. To address the first two challenges, we propose Chain-of-History (CoH) reasoning which explores high-order histories step-by-step, achieving effective utilization of high-order historical information for LLMs on TKG prediction. To address the third issue, we design CoH as a paly-and-plug module to enhance the performance of graph-based models for TKG prediction. Extensive experiments on three datasets and backbones demonstrate the effectiveness of CoH. ",
    "url": "https://arxiv.org/abs/2402.14382",
    "authors": [
      "Yuwei Xia",
      "Ding Wang",
      "Qiang Liu",
      "Liang Wang",
      "Shu Wu",
      "Xiaoyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14384",
    "title": "Generative Adversarial Network with Soft-Dynamic Time Warping and  Parallel Reconstruction for Energy Time Series Anomaly Detection",
    "abstract": "In this paper, we employ a 1D deep convolutional generative adversarial network (DCGAN) for sequential anomaly detection in energy time series data. Anomaly detection involves gradient descent to reconstruct energy sub-sequences, identifying the noise vector that closely generates them through the generator network. Soft-DTW is used as a differentiable alternative for the reconstruction loss and is found to be superior to Euclidean distance. Combining reconstruction loss and the latent space's prior probability distribution serves as the anomaly score. Our novel method accelerates detection by parallel computation of reconstruction of multiple points and shows promise in identifying anomalous energy consumption in buildings, as evidenced by performing experiments on hourly energy time series from 15 buildings. ",
    "url": "https://arxiv.org/abs/2402.14384",
    "authors": [
      "Hardik Prabhu",
      "Jayaraman Valadi",
      "Pandarasamy Arjunan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14391",
    "title": "MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction  Prediction via Microenvironment-Aware Protein Embedding",
    "abstract": "Protein-Protein Interactions (PPIs) are fundamental in various biological processes and play a key role in life activities. The growing demand and cost of experimental PPI assays require computational methods for efficient PPI prediction. While existing methods rely heavily on protein sequence for PPI prediction, it is the protein structure that is the key to determine the interactions. To take both protein modalities into account, we define the microenvironment of an amino acid residue by its sequence and structural contexts, which describe the surrounding chemical properties and geometric features. In addition, microenvironments defined in previous work are largely based on experimentally assayed physicochemical properties, for which the \"vocabulary\" is usually extremely small. This makes it difficult to cover the diversity and complexity of microenvironments. In this paper, we propose Microenvironment-Aware Protein Embedding for PPI prediction (MPAE-PPI), which encodes microenvironments into chemically meaningful discrete codes via a sufficiently large microenvironment \"vocabulary\" (i.e., codebook). Moreover, we propose a novel pre-training strategy, namely Masked Codebook Modeling (MCM), to capture the dependencies between different microenvironments by randomly masking the codebook and reconstructing the input. With the learned microenvironment codebook, we can reuse it as an off-the-shelf tool to efficiently and effectively encode proteins of different sizes and functions for large-scale PPI prediction. Extensive experiments show that MAPE-PPI can scale to PPI prediction with millions of PPIs with superior trade-offs between effectiveness and computational efficiency than the state-of-the-art competitors. ",
    "url": "https://arxiv.org/abs/2402.14391",
    "authors": [
      "Lirong Wu",
      "Yijun Tian",
      "Yufei Huang",
      "Siyuan Li",
      "Haitao Lin",
      "Nitesh V Chawla",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2402.14392",
    "title": "Reading Relevant Feature from Global Representation Memory for Visual  Object Tracking",
    "abstract": "Reference features from a template or historical frames are crucial for visual object tracking. Prior works utilize all features from a fixed template or memory for visual object tracking. However, due to the dynamic nature of videos, the required reference historical information for different search regions at different time steps is also inconsistent. Therefore, using all features in the template and memory can lead to redundancy and impair tracking performance. To alleviate this issue, we propose a novel tracking paradigm, consisting of a relevance attention mechanism and a global representation memory, which can adaptively assist the search region in selecting the most relevant historical information from reference features. Specifically, the proposed relevance attention mechanism in this work differs from previous approaches in that it can dynamically choose and build the optimal global representation memory for the current frame by accessing cross-frame information globally. Moreover, it can flexibly read the relevant historical information from the constructed memory to reduce redundancy and counteract the negative effects of harmful information. Extensive experiments validate the effectiveness of the proposed method, achieving competitive performance on five challenging datasets with 71 FPS. ",
    "url": "https://arxiv.org/abs/2402.14392",
    "authors": [
      "Xinyu Zhou",
      "Pinxue Guo",
      "Lingyi Hong",
      "Jinglun Li",
      "Wei Zhang",
      "Weifeng Ge",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14393",
    "title": "Graph Parsing Networks",
    "abstract": "Graph pooling compresses graph information into a compact representation. State-of-the-art graph pooling methods follow a hierarchical approach, which reduces the graph size step-by-step. These methods must balance memory efficiency with preserving node information, depending on whether they use node dropping or node clustering. Additionally, fixed pooling ratios or numbers of pooling layers are predefined for all graphs, which prevents personalized pooling structures from being captured for each individual graph. In this work, inspired by bottom-up grammar induction, we propose an efficient graph parsing algorithm to infer the pooling structure, which then drives graph pooling. The resulting Graph Parsing Network (GPN) adaptively learns personalized pooling structure for each individual graph. GPN benefits from the discrete assignments generated by the graph parsing algorithm, allowing good memory efficiency while preserving node information intact. Experimental results on standard benchmarks demonstrate that GPN outperforms state-of-the-art graph pooling methods in graph classification tasks while being able to achieve competitive performance in node classification tasks. We also conduct a graph reconstruction task to show GPN's ability to preserve node information and measure both memory and time efficiency through relevant tests. ",
    "url": "https://arxiv.org/abs/2402.14393",
    "authors": [
      "Yunchong Song",
      "Siyuan Huang",
      "Xinbing Wang",
      "Chenghu Zhou",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14400",
    "title": "Modeling 3D Infant Kinetics Using Adaptive Graph Convolutional Networks",
    "abstract": "Reliable methods for the neurodevelopmental assessment of infants are essential for early detection of medical issues that may need prompt interventions. Spontaneous motor activity, or `kinetics', is shown to provide a powerful surrogate measure of upcoming neurodevelopment. However, its assessment is by and large qualitative and subjective, focusing on visually identified, age-specific gestures. Here, we follow an alternative approach, predicting infants' neurodevelopmental maturation based on data-driven evaluation of individual motor patterns. We utilize 3D video recordings of infants processed with pose-estimation to extract spatio-temporal series of anatomical landmarks, and apply adaptive graph convolutional networks to predict the actual age. We show that our data-driven approach achieves improvement over traditional machine learning baselines based on manually engineered features. ",
    "url": "https://arxiv.org/abs/2402.14400",
    "authors": [
      "Daniel Holmberg",
      "Manu Airaksinen",
      "Viviana Marchi",
      "Andrea Guzzetta",
      "Anna Kivi",
      "Leena Haataja",
      "Sampsa Vanhatalo",
      "Teemu Roos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.14404",
    "title": "On the Tip of the Tongue: Analyzing Conceptual Representation in Large  Language Models with Reverse-Dictionary Probe",
    "abstract": "Probing and enhancing large language models' reasoning capacity remains a crucial open question. Here we re-purpose the reverse dictionary task as a case study to probe LLMs' capacity for conceptual inference. We use in-context learning to guide the models to generate the term for an object concept implied in a linguistic description. Models robustly achieve high accuracy in this task, and their representation space encodes information about object categories and fine-grained features. Further experiments suggest that the conceptual inference ability as probed by the reverse-dictionary task predicts model's general reasoning performance across multiple benchmarks, despite similar syntactic generalization behaviors across models. Explorative analyses suggest that prompting LLMs with description$\\Rightarrow$word examples may induce generalization beyond surface-level differences in task construals and facilitate models on broader commonsense reasoning problems. ",
    "url": "https://arxiv.org/abs/2402.14404",
    "authors": [
      "Ningyu Xu",
      "Qi Zhang",
      "Menghan Zhang",
      "Peng Qian",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14410",
    "title": "Human-machine social systems",
    "abstract": "From fake accounts on social media and generative-AI bots such as ChatGPT to high-frequency trading algorithms on financial markets and self-driving vehicles on the streets, robots, bots, and algorithms are proliferating and permeating our communication channels, social interactions, economic transactions, and transportation arteries. Networks of multiple interdependent and interacting humans and autonomous machines constitute complex adaptive social systems where the collective outcomes cannot be simply deduced from either human or machine behavior alone. Under this paradigm, we review recent experimental, theoretical, and observational research from across a range of disciplines - robotics, human-computer interaction, web science, complexity science, computational social science, finance, economics, political science, social psychology, and sociology. We identify general dynamics and patterns in situations of competition, coordination, cooperation, contagion, and collective decision-making, and contextualize them in four prominent existing human-machine communities: high-frequency trading markets, the social media platform formerly known as Twitter, the open-collaboration encyclopedia Wikipedia, and the news aggregation and discussion community Reddit. We conclude with suggestions for the research, design, and governance of human-machine social systems, which are necessary to reduce misinformation, prevent financial crashes, improve road safety, overcome labor market disruptions, and enable a better human future. ",
    "url": "https://arxiv.org/abs/2402.14410",
    "authors": [
      "Milena Tsvetkova",
      "Taha Yasseri",
      "Niccolo Pescetelli",
      "Tobias Werner"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2402.14424",
    "title": "Automating Psychological Hypothesis Generation with AI: Large Language  Models Meet Causal Graph",
    "abstract": "Leveraging the synergy between causal knowledge graphs and a large language model (LLM), our study introduces a groundbreaking approach for computational hypothesis generation in psychology. We analyzed 43,312 psychology articles using a LLM to extract causal relation pairs. This analysis produced a specialized causal graph for psychology. Applying link prediction algorithms, we generated 130 potential psychological hypotheses focusing on `well-being', then compared them against research ideas conceived by doctoral scholars and those produced solely by the LLM. Interestingly, our combined approach of a LLM and causal graphs mirrored the expert-level insights in terms of novelty, clearly surpassing the LLM-only hypotheses (t(59) = 3.34, p=0.007 and t(59) = 4.32, p<0.001, respectively). This alignment was further corroborated using deep semantic analysis. Our results show that combining LLM with machine learning techniques such as causal knowledge graphs can revolutionize automated discovery in psychology, extracting novel insights from the extensive literature. This work stands at the crossroads of psychology and artificial intelligence, championing a new enriched paradigm for data-driven hypothesis generation in psychological research. ",
    "url": "https://arxiv.org/abs/2402.14424",
    "authors": [
      "Song Tong",
      "Kai Mao",
      "Zhen Huang",
      "Yukun Zhao",
      "Kaiping Peng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.14428",
    "title": "KoCoSa: Korean Context-aware Sarcasm Detection Dataset",
    "abstract": "Sarcasm is a way of verbal irony where someone says the opposite of what they mean, often to ridicule a person, situation, or idea. It is often difficult to detect sarcasm in the dialogue since detecting sarcasm should reflect the context (i.e., dialogue history). In this paper, we introduce a new dataset for the Korean dialogue sarcasm detection task, KoCoSa (Korean Context-aware Sarcasm Detection Dataset), which consists of 12.8K daily Korean dialogues and the labels for this task on the last response. To build the dataset, we propose an efficient sarcasm detection dataset generation pipeline: 1) generating new sarcastic dialogues from source dialogues with large language models, 2) automatic and manual filtering of abnormal and toxic dialogues, and 3) human annotation for the sarcasm detection task. We also provide a simple but effective baseline for the Korean sarcasm detection task trained on our dataset. Experimental results on the dataset show that our baseline system outperforms strong baselines like large language models, such as GPT-3.5, in the Korean sarcasm detection task. We show that the sarcasm detection task relies deeply on the existence of sufficient context. We will release the dataset at https://anonymous.4open.science/r/KoCoSa-2372. ",
    "url": "https://arxiv.org/abs/2402.14428",
    "authors": [
      "Yumin Kim",
      "Heejae Suh",
      "Mingi Kim",
      "Dongyeon Won",
      "Hwanhee Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14430",
    "title": "Robust Training of Federated Models with Extremely Label Deficiency",
    "abstract": "Federated semi-supervised learning (FSSL) has emerged as a powerful paradigm for collaboratively training machine learning models using distributed data with label deficiency. Advanced FSSL methods predominantly focus on training a single model on each client. However, this approach could lead to a discrepancy between the objective functions of labeled and unlabeled data, resulting in gradient conflicts. To alleviate gradient conflict, we propose a novel twin-model paradigm, called Twin-sight, designed to enhance mutual guidance by providing insights from different perspectives of labeled and unlabeled data. In particular, Twin-sight concurrently trains a supervised model with a supervised objective function while training an unsupervised model using an unsupervised objective function. To enhance the synergy between these two models, Twin-sight introduces a neighbourhood-preserving constraint, which encourages the preservation of the neighbourhood relationship among data features extracted by both models. Our comprehensive experiments on four benchmark datasets provide substantial evidence that Twin-sight can significantly outperform state-of-the-art methods across various experimental settings, demonstrating the efficacy of the proposed Twin-sight. ",
    "url": "https://arxiv.org/abs/2402.14430",
    "authors": [
      "Yonggang Zhang",
      "Zhiqin Yang",
      "Xinmei Tian",
      "Nannan Wang",
      "Tongliang Liu",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14454",
    "title": "CCPA: Long-term Person Re-Identification via Contrastive Clothing and  Pose Augmentation",
    "abstract": "Long-term Person Re-Identification (LRe-ID) aims at matching an individual across cameras after a long period of time, presenting variations in clothing, pose, and viewpoint. In this work, we propose CCPA: Contrastive Clothing and Pose Augmentation framework for LRe-ID. Beyond appearance, CCPA captures body shape information which is cloth-invariant using a Relation Graph Attention Network. Training a robust LRe-ID model requires a wide range of clothing variations and expensive cloth labeling, which is lacked in current LRe-ID datasets. To address this, we perform clothing and pose transfer across identities to generate images of more clothing variations and of different persons wearing similar clothing. The augmented batch of images serve as inputs to our proposed Fine-grained Contrastive Losses, which not only supervise the Re-ID model to learn discriminative person embeddings under long-term scenarios but also ensure in-distribution data generation. Results on LRe-ID datasets demonstrate the effectiveness of our CCPA framework. ",
    "url": "https://arxiv.org/abs/2402.14454",
    "authors": [
      "Vuong D. Nguyen",
      "Shishir K. Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14461",
    "title": "S^2Former-OR: Single-Stage Bimodal Transformer for Scene Graph  Generation in OR",
    "abstract": "Scene graph generation (SGG) of surgical procedures is crucial in enhancing holistically cognitive intelligence in the operating room (OR). However, previous works have primarily relied on the multi-stage learning that generates semantic scene graphs dependent on intermediate processes with pose estimation and object detection, which may compromise model efficiency and efficacy, also impose extra annotation burden. In this study, we introduce a novel single-stage bimodal transformer framework for SGG in the OR, termed S^2Former-OR, aimed to complementally leverage multi-view 2D scenes and 3D point clouds for SGG in an end-to-end manner. Concretely, our model embraces a View-Sync Transfusion scheme to encourage multi-view visual information interaction. Concurrently, a Geometry-Visual Cohesion operation is designed to integrate the synergic 2D semantic features into 3D point cloud features. Moreover, based on the augmented feature, we propose a novel relation-sensitive transformer decoder that embeds dynamic entity-pair queries and relational trait priors, which enables the direct prediction of entity-pair relations for graph generation without intermediate steps. Extensive experiments have validated the superior SGG performance and lower computational cost of S^2Former-OR on 4D-OR benchmark, compared with current OR-SGG methods, e.g., 3% Precision increase and 24.2M reduction in model parameters. We further compared our method with generic single-stage SGG methods with broader metrics for a comprehensive evaluation, with consistently better performance achieved. The code will be made available. ",
    "url": "https://arxiv.org/abs/2402.14461",
    "authors": [
      "Jialun Pei",
      "Diandian Guo",
      "Jingyang Zhang",
      "Manxi Lin",
      "Yueming Jin",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14464",
    "title": "NeRF-Det++: Incorporating Semantic Cues and Perspective-aware Depth  Supervision for Indoor Multi-View 3D Detection",
    "abstract": "NeRF-Det has achieved impressive performance in indoor multi-view 3D detection by innovatively utilizing NeRF to enhance representation learning. Despite its notable performance, we uncover three decisive shortcomings in its current design, including semantic ambiguity, inappropriate sampling, and insufficient utilization of depth supervision. To combat the aforementioned problems, we present three corresponding solutions: 1) Semantic Enhancement. We project the freely available 3D segmentation annotations onto the 2D plane and leverage the corresponding 2D semantic maps as the supervision signal, significantly enhancing the semantic awareness of multi-view detectors. 2) Perspective-aware Sampling. Instead of employing the uniform sampling strategy, we put forward the perspective-aware sampling policy that samples densely near the camera while sparsely in the distance, more effectively collecting the valuable geometric clues. 3)Ordinal Residual Depth Supervision. As opposed to directly regressing the depth values that are difficult to optimize, we divide the depth range of each scene into a fixed number of ordinal bins and reformulate the depth prediction as the combination of the classification of depth bins as well as the regression of the residual depth values, thereby benefiting the depth learning process. The resulting algorithm, NeRF-Det++, has exhibited appealing performance in the ScanNetV2 and ARKITScenes datasets. Notably, in ScanNetV2, NeRF-Det++ outperforms the competitive NeRF-Det by +1.9% in mAP@0.25 and +3.5% in mAP@0.50$. The code will be publicly at https://github.com/mrsempress/NeRF-Detplusplus. ",
    "url": "https://arxiv.org/abs/2402.14464",
    "authors": [
      "Chenxi Huang",
      "Yuenan Hou",
      "Weicai Ye",
      "Di Huang",
      "Xiaoshui Huang",
      "Binbin Lin",
      "Deng Cai",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14471",
    "title": "BUGFIX: towards a common language and framework for the AutomaticProgram  Repair community",
    "abstract": "Techniques of Automatic Program Repair (APR) have the potential of thoroughly facilitating the task of producing quality software. After a promising start, however, progress in making APR practical has been hindered by the lack of a common framework to support the multiplicity of APR ideas and tools, and of target programming languages and environments. In this position paper we outline a general framework to enable the APR community to benefit from each other\\'s advances, in particular through a standard language for describing bugs and their fixes. Such a common framework (which is also applicable to work on fault seeding) could be a tremendous benefit to researchers and developers of Interactive Development Environments (IDEs) who are working to make APR an effective part of the practical experience of software developers. ",
    "url": "https://arxiv.org/abs/2402.14471",
    "authors": [
      "Bertrand Meyer",
      "Viktoryia Kananchuk",
      "Li Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.14475",
    "title": "DynGMA: a robust approach for learning stochastic differential equations  from data",
    "abstract": "Learning unknown stochastic differential equations (SDEs) from observed data is a significant and challenging task with applications in various fields. Current approaches often use neural networks to represent drift and diffusion functions, and construct likelihood-based loss by approximating the transition density to train these networks. However, these methods often rely on one-step stochastic numerical schemes, necessitating data with sufficiently high time resolution. In this paper, we introduce novel approximations to the transition density of the parameterized SDE: a Gaussian density approximation inspired by the random perturbation theory of dynamical systems, and its extension, the dynamical Gaussian mixture approximation (DynGMA). Benefiting from the robust density approximation, our method exhibits superior accuracy compared to baseline methods in learning the fully unknown drift and diffusion functions and computing the invariant distribution from trajectory data. And it is capable of handling trajectory data with low time resolution and variable, even uncontrollable, time step sizes, such as data generated from Gillespie's stochastic simulations. We then conduct several experiments across various scenarios to verify the advantages and robustness of the proposed method. ",
    "url": "https://arxiv.org/abs/2402.14475",
    "authors": [
      "Aiqing Zhu",
      "Qianxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2402.14481",
    "title": "Towards Automated Causal Discovery: a case study on 5G telecommunication  data",
    "abstract": "We introduce the concept of Automated Causal Discovery (AutoCD), defined as any system that aims to fully automate the application of causal discovery and causal reasoning methods. AutoCD's goal is to deliver all causal information that an expert human analyst would and answer a user's causal queries. We describe the architecture of such a platform, and illustrate its performance on synthetic data sets. As a case study, we apply it on temporal telecommunication data. The system is general and can be applied to a plethora of causal discovery problems. ",
    "url": "https://arxiv.org/abs/2402.14481",
    "authors": [
      "Konstantina Biza",
      "Antonios Ntroumpogiannis",
      "Sofia Triantafillou",
      "Ioannis Tsamardinos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.14484",
    "title": "Is ChatGPT the Future of Causal Text Mining? A Comprehensive Evaluation  and Analysis",
    "abstract": "Causality is fundamental in human cognition and has drawn attention in diverse research fields. With growing volumes of textual data, discerning causalities within text data is crucial, and causal text mining plays a pivotal role in extracting meaningful patterns. This study conducts comprehensive evaluations of ChatGPT's causal text mining capabilities. Firstly, we introduce a benchmark that extends beyond general English datasets, including domain-specific and non-English datasets. We also provide an evaluation framework to ensure fair comparisons between ChatGPT and previous approaches. Finally, our analysis outlines the limitations and future challenges in employing ChatGPT for causal text mining. Specifically, our analysis reveals that ChatGPT serves as a good starting point for various datasets. However, when equipped with a sufficient amount of training data, previous models still surpass ChatGPT's performance. Additionally, ChatGPT suffers from the tendency to falsely recognize non-causal sequences as causal sequences. These issues become even more pronounced with advanced versions of the model, such as GPT-4. In addition, we highlight the constraints of ChatGPT in handling complex causality types, including both intra/inter-sentential and implicit causality. The model also faces challenges with effectively leveraging in-context learning and domain adaptation. Our code is available on \\url{https://github.com/retarfi/gemcausal} ",
    "url": "https://arxiv.org/abs/2402.14484",
    "authors": [
      "Takehiro Takayanagi",
      "Masahiro Suzuki",
      "Ryotaro Kobayashi",
      "Hiroki Sakaji",
      "Kiyoshi Izumi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14492",
    "title": "INSTRAUG: Automatic Instruction Augmentation for Multimodal Instruction  Fine-tuning",
    "abstract": "Fine-tuning large language models (LLMs) on multi-task instruction-following data has been proven to be a powerful learning paradigm for improving their zero-shot capabilities on new tasks. Recent works about high-quality instruction-following data generation and selection require amounts of human labor to conceive model-understandable instructions for the given tasks and carefully filter the LLM-generated data. In this work, we introduce an automatic instruction augmentation method named INSTRAUG in multimodal tasks. It starts from a handful of basic and straightforward meta instructions but can expand an instruction-following dataset by 30 times. Results on two popular multimodal instructionfollowing benchmarks MULTIINSTRUCT and InstructBLIP show that INSTRAUG can significantly improve the alignment of multimodal large language models (MLLMs) across 12 multimodal tasks, which is even equivalent to the benefits of scaling up training data multiple times. ",
    "url": "https://arxiv.org/abs/2402.14492",
    "authors": [
      "Wei Han",
      "Hui Chen",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14523",
    "title": "Daisy-TTS: Simulating Wider Spectrum of Emotions via Prosody Embedding  Decomposition",
    "abstract": "We often verbally express emotions in a multifaceted manner, they may vary in their intensities and may be expressed not just as a single but as a mixture of emotions. This wide spectrum of emotions is well-studied in the structural model of emotions, which represents variety of emotions as derivative products of primary emotions with varying degrees of intensity. In this paper, we propose an emotional text-to-speech design to simulate a wider spectrum of emotions grounded on the structural model. Our proposed design, Daisy-TTS, incorporates a prosody encoder to learn emotionally-separable prosody embedding as a proxy for emotion. This emotion representation allows the model to simulate: (1) Primary emotions, as learned from the training samples, (2) Secondary emotions, as a mixture of primary emotions, (3) Intensity-level, by scaling the emotion embedding, and (4) Emotions polarity, by negating the emotion embedding. Through a series of perceptual evaluations, Daisy-TTS demonstrated overall higher emotional speech naturalness and emotion perceiveability compared to the baseline. ",
    "url": "https://arxiv.org/abs/2402.14523",
    "authors": [
      "Rendi Chevi",
      "Alham Fikri Aji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.14532",
    "title": "A Framework for Variational Inference of Lightweight Bayesian Neural  Networks with Heteroscedastic Uncertainties",
    "abstract": "Obtaining heteroscedastic predictive uncertainties from a Bayesian Neural Network (BNN) is vital to many applications. Often, heteroscedastic aleatoric uncertainties are learned as outputs of the BNN in addition to the predictive means, however doing so may necessitate adding more learnable parameters to the network. In this work, we demonstrate that both the heteroscedastic aleatoric and epistemic variance can be embedded into the variances of learned BNN parameters, improving predictive performance for lightweight networks. By complementing this approach with a moment propagation approach to inference, we introduce a relatively simple framework for sampling-free variational inference suitable for lightweight BNNs. ",
    "url": "https://arxiv.org/abs/2402.14532",
    "authors": [
      "David J. Schodt",
      "Ryan Brown",
      "Michael Merritt",
      "Samuel Park",
      "Delsin Menolascino",
      "Mark A. Peot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14536",
    "title": "Domain Generalization via Causal Adjustment for Cross-Domain Sentiment  Analysis",
    "abstract": "Domain adaption has been widely adapted for cross-domain sentiment analysis to transfer knowledge from the source domain to the target domain. Whereas, most methods are proposed under the assumption that the target (test) domain is known, making them fail to generalize well on unknown test data that is not always available in practice. In this paper, we focus on the problem of domain generalization for cross-domain sentiment analysis. Specifically, we propose a backdoor adjustment-based causal model to disentangle the domain-specific and domain-invariant representations that play essential roles in tackling domain shift. First, we rethink the cross-domain sentiment analysis task in a causal view to model the causal-and-effect relationships among different variables. Then, to learn an invariant feature representation, we remove the effect of domain confounders (e.g., domain knowledge) using the backdoor adjustment. A series of experiments over many homologous and diverse datasets show the great performance and robustness of our model by comparing it with the state-of-the-art domain generalization baselines. ",
    "url": "https://arxiv.org/abs/2402.14536",
    "authors": [
      "Siyin Wang",
      "Jie Zhou",
      "Qin Chen",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14539",
    "title": "Transforming Norm-based To Graph-based Spatial Representation for  Spatio-Temporal Epidemiological Models",
    "abstract": "Pandemics, with their profound societal and economic impacts, pose significant threats to global health, mortality rates, economic stability, and political landscapes. In response to the persistent challenges posed by emerging and reemerging pandemics, numerous studies have employed spatio-temporal models to enhance our understanding and management of these complex phenomena. These spatio-temporal models can be roughly divided into two main spatial categories: norm-based and graph-based trade-offering between accuracy, computational burden, and representational feasibility. In this study, we explore the ability to transform from norm-based to graph-based spatial representation for these models. We introduce a novel framework for this task together with twelve possible implementations using a wide range of heuristic optimization approaches. Our findings show that by leveraging agent-based simulations and heuristic algorithms for the graph node's location and population's spatial walk dynamics approximation one can use graph-based spatial representation without losing much of the model's accuracy and expressiveness. For three real-world cases, the best-performing algorithmic configuration archives 94\\% accuracy presence, on average. Moreover, an analysis of synthetic cases shows the proposed framework is relatively robust, as fluctuation in both spatial and temporal dynamics is not badly reflected by the framework's performance. ",
    "url": "https://arxiv.org/abs/2402.14539",
    "authors": [
      "Teddy Lazebnik"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.14544",
    "title": "{A New Hope}: Contextual Privacy Policies for Mobile Applications and An  Approach Toward Automated Generation",
    "abstract": "Privacy policies have emerged as the predominant approach to conveying privacy notices to mobile application users. In an effort to enhance both readability and user engagement, the concept of contextual privacy policies (CPPs) has been proposed by researchers. The aim of CPPs is to fragment privacy policies into concise snippets, displaying them only within the corresponding contexts within the application's graphical user interfaces (GUIs). In this paper, we first formulate CPP in mobile application scenario, and then present a novel multimodal framework, named SeePrivacy, specifically designed to automatically generate CPPs for mobile applications. This method uniquely integrates vision-based GUI understanding with privacy policy analysis, achieving 0.88 precision and 0.90 recall to detect contexts, as well as 0.98 precision and 0.96 recall in extracting corresponding policy segments. A human evaluation shows that 77% of the extracted privacy policy segments were perceived as well-aligned with the detected contexts. These findings suggest that SeePrivacy could serve as a significant tool for bolstering user interaction with, and understanding of, privacy policies. Furthermore, our solution has the potential to make privacy notices more accessible and inclusive, thus appealing to a broader demographic. A demonstration of our work can be accessed at https://cpp4app.github.io/SeePrivacy/ ",
    "url": "https://arxiv.org/abs/2402.14544",
    "authors": [
      "Shidong Pan",
      "Zhen Tao",
      "Thong Hoang",
      "Dawen Zhang",
      "Tianshi Li",
      "Zhenchang Xing",
      "Sherry Xu",
      "Mark Staples",
      "Thierry Rakotoarivelo",
      "David Lo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.14566",
    "title": "Self-supervised Visualisation of Medical Image Datasets",
    "abstract": "Self-supervised learning methods based on data augmentations, such as SimCLR, BYOL, or DINO, allow obtaining semantically meaningful representations of image datasets and are widely used prior to supervised fine-tuning. A recent self-supervised learning method, $t$-SimCNE, uses contrastive learning to directly train a 2D representation suitable for visualisation. When applied to natural image datasets, $t$-SimCNE yields 2D visualisations with semantically meaningful clusters. In this work, we used $t$-SimCNE to visualise medical image datasets, including examples from dermatology, histology, and blood microscopy. We found that increasing the set of data augmentations to include arbitrary rotations improved the results in terms of class separability, compared to data augmentations used for natural images. Our 2D representations show medically relevant structures and can be used to aid data exploration and annotation, improving on common approaches for data visualisation. ",
    "url": "https://arxiv.org/abs/2402.14566",
    "authors": [
      "Ifeoma Veronica Nwabufo",
      "Jan Niklas B\u00f6hm",
      "Philipp Berens",
      "Dmitry Kobak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14567",
    "title": "CesASMe and Staticdeps: static detection of memory-carried dependencies  for code analyzers",
    "abstract": "A variety of code analyzers, such as IACA, uiCA, llvm-mca or Ithemal, strive to statically predict the throughput of a computation kernel. Each analyzer is based on its own simplified CPU model reasoning at the scale of a basic block. Facing this diversity, evaluating their strengths and weaknesses is important to guide both their usage and their enhancement. We present CesASMe, a fully-tooled solution to evaluate code analyzers on C-level benchmarks composed of a benchmark derivation procedure that feeds an evaluation harness. We conclude that memory-carried data dependencies are a major source of imprecision for these tools. We tackle this issue with staticdeps, a static analyzer extracting memory-carried data dependencies, including across loop iterations, from an assembly basic block. We integrate its output to uiCA, a state-of-the-art code analyzer, to evaluate staticdeps' impact on a code analyzer's precision through CesASMe. ",
    "url": "https://arxiv.org/abs/2402.14567",
    "authors": [
      "Th\u00e9ophile Bastian",
      "Hugo Pompougnac",
      "Alban Dutilleul",
      "Fabrice Rastello"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2402.14568",
    "title": "LLM-DA: Data Augmentation via Large Language Models for Few-Shot Named  Entity Recognition",
    "abstract": "Despite the impressive capabilities of large language models (LLMs), their performance on information extraction tasks is still not entirely satisfactory. However, their remarkable rewriting capabilities and extensive world knowledge offer valuable insights to improve these tasks. In this paper, we propose $LLM-DA$, a novel data augmentation technique based on LLMs for the few-shot NER task. To overcome the limitations of existing data augmentation methods that compromise semantic integrity and address the uncertainty inherent in LLM-generated text, we leverage the distinctive characteristics of the NER task by augmenting the original data at both the contextual and entity levels. Our approach involves employing 14 contextual rewriting strategies, designing entity replacements of the same type, and incorporating noise injection to enhance robustness. Extensive experiments demonstrate the effectiveness of our approach in enhancing NER model performance with limited data. Furthermore, additional analyses provide further evidence supporting the assertion that the quality of the data we generate surpasses that of other existing methods. ",
    "url": "https://arxiv.org/abs/2402.14568",
    "authors": [
      "Junjie Ye",
      "Nuo Xu",
      "Yikun Wang",
      "Jie Zhou",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14599",
    "title": "Enhancing SCADA Security: Developing a Host-Based Intrusion Detection  System to Safeguard Against Cyberattacks",
    "abstract": "With the increasing reliance of smart grids on correctly functioning SCADA systems and their vulnerability to cyberattacks, there is a pressing need for effective security measures. SCADA systems are prone to cyberattacks, posing risks to critical infrastructure. As there is a lack of host-based intrusion detection systems specifically designed for the stable nature of SCADA systems, the objective of this work is to propose a host-based intrusion detection system tailored for SCADA systems in smart grids. The proposed system utilizes USB device identification, flagging, and process memory scanning to monitor and detect anomalies in SCADA systems, providing enhanced security measures. Evaluation in three different scenarios demonstrates the tool's effectiveness in detecting and disabling malware. The proposed approach effectively identifies potential threats and enhances the security of SCADA systems in smart grids, providing a promising solution to protect against cyberattacks. ",
    "url": "https://arxiv.org/abs/2402.14599",
    "authors": [
      "Omer Sen",
      "Tarek Hassan",
      "Andreas Ulbig",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.14609",
    "title": "Federated Complex Qeury Answering",
    "abstract": "Complex logical query answering is a challenging task in knowledge graphs (KGs) that has been widely studied. The ability to perform complex logical reasoning is essential and supports various graph reasoning-based downstream tasks, such as search engines. Recent approaches are proposed to represent KG entities and logical queries into embedding vectors and find answers to logical queries from the KGs. However, existing proposed methods mainly focus on querying a single KG and cannot be applied to multiple graphs. In addition, directly sharing KGs with sensitive information may incur privacy risks, making it impractical to share and construct an aggregated KG for reasoning to retrieve query answers. Thus, it remains unknown how to answer queries on multi-source KGs. An entity can be involved in various knowledge graphs and reasoning on multiple KGs and answering complex queries on multi-source KGs is important in discovering knowledge cross graphs. Fortunately, federated learning is utilized in knowledge graphs to collaboratively learn representations with privacy preserved. Federated knowledge graph embeddings enrich the relations in knowledge graphs to improve the representation quality. However, these methods only focus on one-hop relations and cannot perform complex reasoning tasks. In this paper, we apply federated learning to complex query-answering tasks to reason over multi-source knowledge graphs while preserving privacy. We propose a Federated Complex Query Answering framework (FedCQA), to reason over multi-source KGs avoiding sensitive raw data transmission to protect privacy. We conduct extensive experiments on three real-world datasets and evaluate retrieval performance on various types of complex queries. ",
    "url": "https://arxiv.org/abs/2402.14609",
    "authors": [
      "Qi Hu",
      "Weifeng Jiang",
      "Haoran Li",
      "Zihao Wang",
      "Jiaxin Bai",
      "Qianren Mao",
      "Yangqiu Song",
      "Lixin Fan",
      "Jianxin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2402.14610",
    "title": "Toward Scalable Docker-Based Emulations of Blockchain Networks for  Research and Development",
    "abstract": "Blockchain, like any other complex technology, needs a strong testing methodology to support its evolution in both research and development contexts. Setting up meaningful tests for permissionless blockchain technology is a notoriously complex task for several reasons: software is complex, large number of nodes are involved, network is non ideal, etc. Developers usually adopt small virtual laboratories or costly real devnets, based on real software. Researchers usually prefer simulations of a large number of nodes, based on simplified models. In this paper, we aim to obtain the advantages of both approaches, i.e., performing large, realistic, inexpensive, and flexible experiments, using real blockchain software within a virtual environment. To do that, we tackle the challenge of running large blockchain networks in a single physical machine, leveraging Linux and Docker. We analyze a number of problems that arise when large blockchain networks are emulated and we provide technical solutions for all of them. Finally, we describe two experiences of emulating fairly large blockchain networks on a single machine, adopting both research oriented and production oriented software, and involving up to more than 3000 containers. ",
    "url": "https://arxiv.org/abs/2402.14610",
    "authors": [
      "Diego Pennino",
      "Maurizio Pizzonia"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2402.14611",
    "title": "Overcoming Dimensional Collapse in Self-supervised Contrastive Learning  for Medical Image Segmentation",
    "abstract": "Self-supervised learning (SSL) approaches have achieved great success when the amount of labeled data is limited. Within SSL, models learn robust feature representations by solving pretext tasks. One such pretext task is contrastive learning, which involves forming pairs of similar and dissimilar input samples, guiding the model to distinguish between them. In this work, we investigate the application of contrastive learning to the domain of medical image analysis. Our findings reveal that MoCo v2, a state-of-the-art contrastive learning method, encounters dimensional collapse when applied to medical images. This is attributed to the high degree of inter-image similarity shared between the medical images. To address this, we propose two key contributions: local feature learning and feature decorrelation. Local feature learning improves the ability of the model to focus on the local regions of the image, while feature decorrelation removes the linear dependence among the features. Our experimental findings demonstrate that our contributions significantly enhance the model's performance in the downstream task of medical segmentation, both in the linear evaluation and full fine-tuning settings. This work illustrates the importance of effectively adapting SSL techniques to the characteristics of medical imaging tasks. ",
    "url": "https://arxiv.org/abs/2402.14611",
    "authors": [
      "Jamshid Hassanpour",
      "Vinkle Srivastav",
      "Didier Mutter",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14623",
    "title": "RoboScript: Code Generation for Free-Form Manipulation Tasks across Real  and Simulation",
    "abstract": "Rapid progress in high-level task planning and code generation for open-world robot manipulation has been witnessed in Embodied AI. However, previous studies put much effort into general common sense reasoning and task planning capabilities of large-scale language or multi-modal models, relatively little effort on ensuring the deployability of generated code on real robots, and other fundamental components of autonomous robot systems including robot perception, motion planning, and control. To bridge this ``ideal-to-real'' gap, this paper presents \\textbf{RobotScript}, a platform for 1) a deployable robot manipulation pipeline powered by code generation; and 2) a code generation benchmark for robot manipulation tasks in free-form natural language. The RobotScript platform addresses this gap by emphasizing the unified interface with both simulation and real robots, based on abstraction from the Robot Operating System (ROS), ensuring syntax compliance and simulation validation with Gazebo. We demonstrate the adaptability of our code generation framework across multiple robot embodiments, including the Franka and UR5 robot arms, and multiple grippers. Additionally, our benchmark assesses reasoning abilities for physical space and constraints, highlighting the differences between GPT-3.5, GPT-4, and Gemini in handling complex physical interactions. Finally, we present a thorough evaluation on the whole system, exploring how each module in the pipeline: code generation, perception, motion planning, and even object geometric properties, impact the overall performance of the system. ",
    "url": "https://arxiv.org/abs/2402.14623",
    "authors": [
      "Junting Chen",
      "Yao Mu",
      "Qiaojun Yu",
      "Tianming Wei",
      "Silang Wu",
      "Zhecheng Yuan",
      "Zhixuan Liang",
      "Chao Yang",
      "Kaipeng Zhang",
      "Wenqi Shao",
      "Yu Qiao",
      "Huazhe Xu",
      "Mingyu Ding",
      "Ping Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14625",
    "title": "Putting the Count Back Into Accountability: An Audit of Social Media  Transparency Disclosures, Focusing on Sexual Exploitation of Minors",
    "abstract": "This paper explores a lightweight, quantitative audit methodology for transparency disclosures called scrappy audits. It amounts to little more than treating redundant and repeated disclosures as opportunities for validating quantities. The paper applies two concrete audits to social media disclosures about content moderation. The first compares legally mandated reports about the sexual exploitation of minors as disclosed by social media and the national clearinghouse receiving them. The second compares historical quantities included in platforms' CSV files across two subsequent disclosures of the data. Despite their simplicity, these scrappy audits are nonetheless effective. Out of 16 surveyed social media platforms, 11 make transparency disclosures about content moderation and 8 meet the prerequisites of one audit. Yet only 4~platforms pass their audits. The paper continues probing the limits of transparency data by presenting a data-driven overview of the online sexual exploitation of minors. Accordingly, the analysis is particularly careful to identify threats to validity as well as potentially helpful, but unavailable statistics. Likewise, it identifies major shortcomings of widely used technologies for the automated detection of images and videos depicting sexual abuse of minors. Overall, the data shows an alarming growth in such material over the last decade. However, there also are strong indicators that current statistics, which treat all such material the same, are large and unhelpful overcounts. Notably, many technical violations of the law, e.g., teenagers sexting, are not necessarily grounded in actual harm to minors but still reported as such. ",
    "url": "https://arxiv.org/abs/2402.14625",
    "authors": [
      "Robert Grimm"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.14646",
    "title": "CoLoRA: Continuous low-rank adaptation for reduced implicit neural  modeling of parameterized partial differential equations",
    "abstract": "This work introduces reduced models based on Continuous Low Rank Adaptation (CoLoRA) that pre-train neural networks for a given partial differential equation and then continuously adapt low-rank weights in time to rapidly predict the evolution of solution fields at new physics parameters and new initial conditions. The adaptation can be either purely data-driven or via an equation-driven variational approach that provides Galerkin-optimal approximations. Because CoLoRA approximates solution fields locally in time, the rank of the weights can be kept small, which means that only few training trajectories are required offline so that CoLoRA is well suited for data-scarce regimes. Predictions with CoLoRA are orders of magnitude faster than with classical methods and their accuracy and parameter efficiency is higher compared to other neural network approaches. ",
    "url": "https://arxiv.org/abs/2402.14646",
    "authors": [
      "Jules Berman",
      "Benjamin Peherstorfer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14648",
    "title": "Rethinking Invariance Regularization in Adversarial Training to Improve  Robustness-Accuracy Trade-off",
    "abstract": "Although adversarial training has been the state-of-the-art approach to defend against adversarial examples (AEs), they suffer from a robustness-accuracy trade-off. In this work, we revisit representation-based invariance regularization to learn discriminative yet adversarially invariant representations, aiming to mitigate this trade-off. We empirically identify two key issues hindering invariance regularization: (1) a \"gradient conflict\" between invariance loss and classification objectives, indicating the existence of \"collapsing solutions,\" and (2) the mixture distribution problem arising from diverged distributions of clean and adversarial inputs. To address these issues, we propose Asymmetrically Representation-regularized Adversarial Training (AR-AT), which incorporates a stop-gradient operation and a pre-dictor in the invariance loss to avoid \"collapsing solutions,\" inspired by a recent non-contrastive self-supervised learning approach, and a split-BatchNorm (BN) structure to resolve the mixture distribution problem. Our method significantly improves the robustness-accuracy trade-off by learning adversarially invariant representations without sacrificing discriminative power. Furthermore, we discuss the relevance of our findings to knowledge-distillation-based defense methods, contributing to a deeper understanding of their relative successes. ",
    "url": "https://arxiv.org/abs/2402.14648",
    "authors": [
      "Futa Waseda",
      "Isao Echizen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14652",
    "title": "Cleaner Pretraining Corpus Curation with Neural Web Scraping",
    "abstract": "The web contains large-scale, diverse, and abundant information to satisfy the information-seeking needs of humans. Through meticulous data collection, preprocessing, and curation, webpages can be used as a fundamental data resource for language model pretraining. However, when confronted with the progressively revolutionized and intricate nature of webpages, rule-based/feature-based web scrapers are becoming increasingly inadequate. This paper presents a simple, fast, and effective Neural web Scraper (NeuScraper) to help extract primary and clean text contents from webpages. Experimental results show that NeuScraper surpasses the baseline scrapers by achieving more than a 20% improvement, demonstrating its potential in extracting higher-quality data to facilitate the language model pretraining. All of the code is available at https://github.com/OpenMatch/NeuScraper. ",
    "url": "https://arxiv.org/abs/2402.14652",
    "authors": [
      "Zhipeng Xu",
      "Zhenghao Liu",
      "Yukun Yan",
      "Zhiyuan Liu",
      "Chenyan Xiong",
      "Ge Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14658",
    "title": "OpenCodeInterpreter: Integrating Code Generation with Execution and  Refinement",
    "abstract": "The introduction of large language models has significantly advanced code generation. However, open-source models often lack the execution capabilities and iterative refinement of advanced systems like the GPT-4 Code Interpreter. To address this, we introduce OpenCodeInterpreter, a family of open-source code systems designed for generating, executing, and iteratively refining code. Supported by Code-Feedback, a dataset featuring 68K multi-turn interactions, OpenCodeInterpreter integrates execution and human feedback for dynamic code refinement. Our comprehensive evaluation of OpenCodeInterpreter across key benchmarks such as HumanEval, MBPP, and their enhanced versions from EvalPlus reveals its exceptional performance. Notably, OpenCodeInterpreter-33B achieves an accuracy of 83.2 (76.4) on the average (and plus versions) of HumanEval and MBPP, closely rivaling GPT-4's 84.2 (76.2) and further elevates to 91.6 (84.6) with synthesized human feedback from GPT-4. OpenCodeInterpreter brings the gap between open-source code generation models and proprietary systems like GPT-4 Code Interpreter. ",
    "url": "https://arxiv.org/abs/2402.14658",
    "authors": [
      "Tianyu Zheng",
      "Ge Zhang",
      "Tianhao Shen",
      "Xueling Liu",
      "Bill Yuchen Lin",
      "Jie Fu",
      "Wenhu Chen",
      "Xiang Yue"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14665",
    "title": "Quadruplet Loss For Improving the Robustness to Face Morphing Attacks",
    "abstract": "Recent advancements in deep learning have revolutionized technology and security measures, necessitating robust identification methods. Biometric approaches, leveraging personalized characteristics, offer a promising solution. However, Face Recognition Systems are vulnerable to sophisticated attacks, notably face morphing techniques, enabling the creation of fraudulent documents. In this study, we introduce a novel quadruplet loss function for increasing the robustness of face recognition systems against morphing attacks. Our approach involves specific sampling of face image quadruplets, combined with face morphs, for network training. Experimental results demonstrate the efficiency of our strategy in improving the robustness of face recognition networks against morphing attacks. ",
    "url": "https://arxiv.org/abs/2402.14665",
    "authors": [
      "Iurii Medvedev",
      "Nuno Gon\u00e7alves"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14666",
    "title": "Stability of P2P Networks Under Greedy Peering (Full Version)",
    "abstract": "Major cryptocurrency networks have relied on random peering choice rules for making connections in their peer-to-peer networks. Generally, these choices have good properties, particularly for open, permissionless networks. Random peering choices however do not take into account that some actors may choose to optimize who they connect to such that they are quicker to hear about information being propagated in the network. In this paper, we explore the dynamics of such greedy strategies. We study a model in which nodes select peers with the objective of minimizing their average distance to a designated subset of nodes in the network, and consider the impact of several factors including the peer selection process, degree constraints, and the size of the designated subset. The latter is particularly interesting in the context of blockchain networks as generally only a subset of nodes are the propagation source for content. We first analyze an idealized version of the game where each node has full knowledge of the current network and aims to select the $d$ best connections, and prove the existence of equilibria under various model assumptions. Since in reality nodes only have local knowledge based on their peers' behavior, we also study a greedy protocol which runs in rounds, with each node replacing its worst-performing edge with a new random edge. We exactly characterize stability properties of networks that evolve with this peering rule and derive regimes where stability is possible and even inevitable. We also run extensive simulations with this peering rule examining both how the network evolves and how different network parameters affect the stability properties of the network. Our findings generally show that the only stable networks that arise from greedy peering choices are low-diameter and result in disparate performance for nodes in the network. ",
    "url": "https://arxiv.org/abs/2402.14666",
    "authors": [
      "Lucianna Kiffer",
      "Rajmohan Rajaraman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.14672",
    "title": "Middleware for LLMs: Tools Are Instrumental for Language Agents in  Complex Environments",
    "abstract": "The applications of large language models (LLMs) have expanded well beyond the confines of text processing, signaling a new era where LLMs are envisioned as generalist language agents capable of operating within complex real-world environments. These environments are often highly expansive, making it impossible for the LLM to process them within its short-term memory. Motivated by recent research on extending the capabilities of LLMs with tools, this paper investigates the intriguing potential of tools to augment LLMs in handling such complexity. To this end, we design customized tools to aid in the proactive exploration within these massive environments. Such tools can serve as a middleware layer shielding the LLM from environmental complexity. In two representative complex environments -- knowledge bases (KBs) and databases -- we demonstrate the significant potential of augmenting language agents with tools in complex environments. Notably, equipped with these tools, GPT-4 achieves 2.8X the performance of the best baseline in tasks requiring access to database content and 2.2X in KB tasks. Our findings illuminate the path for advancing language agents in complex real-world applications. ",
    "url": "https://arxiv.org/abs/2402.14672",
    "authors": [
      "Yu Gu",
      "Yiheng Shu",
      "Hao Yu",
      "Xiao Liu",
      "Yuxiao Dong",
      "Jie Tang",
      "Jayanth Srinivasa",
      "Hugo Latapie",
      "Yu Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14704",
    "title": "An LLM-Enhanced Adversarial Editing System for Lexical Simplification",
    "abstract": "Lexical Simplification (LS) aims to simplify text at the lexical level. Existing methods rely heavily on annotated data, making it challenging to apply in low-resource scenarios. In this paper, we propose a novel LS method without parallel corpora. This method employs an Adversarial Editing System with guidance from a confusion loss and an invariance loss to predict lexical edits in the original sentences. Meanwhile, we introduce an innovative LLM-enhanced loss to enable the distillation of knowledge from Large Language Models (LLMs) into a small-size LS system. From that, complex words within sentences are masked and a Difficulty-aware Filling module is crafted to replace masked positions with simpler words. At last, extensive experimental results and analyses on three benchmark LS datasets demonstrate the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2402.14704",
    "authors": [
      "Keren Tan",
      "Kangyang Luo",
      "Yunshi Lan",
      "Zheng Yuan",
      "Jinlong Shu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14708",
    "title": "CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph  Neural Networks",
    "abstract": "Credit card fraud poses a significant threat to the economy. While Graph Neural Network (GNN)-based fraud detection methods perform well, they often overlook the causal effect of a node's local structure on predictions. This paper introduces a novel method for credit card fraud detection, the \\textbf{\\underline{Ca}}usal \\textbf{\\underline{T}}emporal \\textbf{\\underline{G}}raph \\textbf{\\underline{N}}eural \\textbf{N}etwork (CaT-GNN), which leverages causal invariant learning to reveal inherent correlations within transaction data. By decomposing the problem into discovery and intervention phases, CaT-GNN identifies causal nodes within the transaction graph and applies a causal mixup strategy to enhance the model's robustness and interpretability. CaT-GNN consists of two key components: Causal-Inspector and Causal-Intervener. The Causal-Inspector utilizes attention weights in the temporal attention mechanism to identify causal and environment nodes without introducing additional parameters. Subsequently, the Causal-Intervener performs a causal mixup enhancement on environment nodes based on the set of nodes. Evaluated on three datasets, including a private financial dataset and two public datasets, CaT-GNN demonstrates superior performance over existing state-of-the-art methods. Our findings highlight the potential of integrating causal reasoning with graph neural networks to improve fraud detection capabilities in financial transactions. ",
    "url": "https://arxiv.org/abs/2402.14708",
    "authors": [
      "Yifan Duan",
      "Guibin Zhang",
      "Shilong Wang",
      "Xiaojiang Peng",
      "Wang Ziqi",
      "Junyuan Mao",
      "Hao Wu",
      "Xinke Jiang",
      "Kun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2402.14720",
    "title": "A Transformer Model for Boundary Detection in Continuous Sign Language",
    "abstract": "Sign Language Recognition (SLR) has garnered significant attention from researchers in recent years, particularly the intricate domain of Continuous Sign Language Recognition (CSLR), which presents heightened complexity compared to Isolated Sign Language Recognition (ISLR). One of the prominent challenges in CSLR pertains to accurately detecting the boundaries of isolated signs within a continuous video stream. Additionally, the reliance on handcrafted features in existing models poses a challenge to achieving optimal accuracy. To surmount these challenges, we propose a novel approach utilizing a Transformer-based model. Unlike traditional models, our approach focuses on enhancing accuracy while eliminating the need for handcrafted features. The Transformer model is employed for both ISLR and CSLR. The training process involves using isolated sign videos, where hand keypoint features extracted from the input video are enriched using the Transformer model. Subsequently, these enriched features are forwarded to the final classification layer. The trained model, coupled with a post-processing method, is then applied to detect isolated sign boundaries within continuous sign videos. The evaluation of our model is conducted on two distinct datasets, including both continuous signs and their corresponding isolated signs, demonstrates promising results. ",
    "url": "https://arxiv.org/abs/2402.14720",
    "authors": [
      "Razieh Rastgoo",
      "Kourosh Kiani",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14726",
    "title": "Incorporating Expert Rules into Neural Networks in the Framework of  Concept-Based Learning",
    "abstract": "A problem of incorporating the expert rules into machine learning models for extending the concept-based learning is formulated in the paper. It is proposed how to combine logical rules and neural networks predicting the concept probabilities. The first idea behind the combination is to form constraints for a joint probability distribution over all combinations of concept values to satisfy the expert rules. The second idea is to represent a feasible set of probability distributions in the form of a convex polytope and to use its vertices or faces. We provide several approaches for solving the stated problem and for training neural networks which guarantee that the output probabilities of concepts would not violate the expert rules. The solution of the problem can be viewed as a way for combining the inductive and deductive learning. Expert rules are used in a broader sense when any logical function that connects concepts and class labels or just concepts with each other can be regarded as a rule. This feature significantly expands the class of the proposed results. Numerical examples illustrate the approaches. The code of proposed algorithms is publicly available. ",
    "url": "https://arxiv.org/abs/2402.14726",
    "authors": [
      "Andrei V. Konstantinov",
      "Lev V. Utkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14730",
    "title": "Clifford-Steerable Convolutional Neural Networks",
    "abstract": "We present Clifford-Steerable Convolutional Neural Networks (CS-CNNs), a novel class of $\\mathrm{E}(p, q)$-equivariant CNNs. CS-CNNs process multivector fields on pseudo-Euclidean spaces $\\mathbb{R}^{p,q}$. They cover, for instance, $\\mathrm{E}(3)$-equivariance on $\\mathbb{R}^3$ and Poincar\\'e-equivariance on Minkowski spacetime $\\mathbb{R}^{1,3}$. Our approach is based on an implicit parametrization of $\\mathrm{O}(p,q)$-steerable kernels via Clifford group equivariant neural networks. We significantly and consistently outperform baseline methods on fluid dynamics as well as relativistic electrodynamics forecasting tasks. ",
    "url": "https://arxiv.org/abs/2402.14730",
    "authors": [
      "Maksim Zhdanov",
      "David Ruhe",
      "Maurice Weiler",
      "Ana Lucic",
      "Johannes Brandstetter",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14735",
    "title": "How Transformers Learn Causal Structure with Gradient Descent",
    "abstract": "The incredible success of transformers on sequence modeling tasks can be largely attributed to the self-attention mechanism, which allows information to be transferred between different parts of a sequence. Self-attention allows transformers to encode causal structure which makes them particularly suitable for sequence modeling. However, the process by which transformers learn such causal structure via gradient-based training algorithms remains poorly understood. To better understand this process, we introduce an in-context learning task that requires learning latent causal structure. We prove that gradient descent on a simplified two-layer transformer learns to solve this task by encoding the latent causal graph in the first attention layer. The key insight of our proof is that the gradient of the attention matrix encodes the mutual information between tokens. As a consequence of the data processing inequality, the largest entries of this gradient correspond to edges in the latent causal graph. As a special case, when the sequences are generated from in-context Markov chains, we prove that transformers learn an induction head (Olsson et al., 2022). We confirm our theoretical findings by showing that transformers trained on our in-context learning task are able to recover a wide variety of causal structures. ",
    "url": "https://arxiv.org/abs/2402.14735",
    "authors": [
      "Eshaan Nichani",
      "Alex Damian",
      "Jason D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14766",
    "title": "Environment Semantic Communication: Enabling Distributed Sensing Aided  Networks",
    "abstract": "Millimeter-wave (mmWave) and terahertz (THz) communication systems require large antenna arrays and use narrow directive beams to ensure sufficient receive signal power. However, selecting the optimal beams for these large antenna arrays incurs a significant beam training overhead, making it challenging to support applications involving high mobility. In recent years, machine learning (ML) solutions have shown promising results in reducing the beam training overhead by utilizing various sensing modalities such as GPS position and RGB images. However, the existing approaches are mainly limited to scenarios with only a single object of interest present in the wireless environment and focus only on co-located sensing, where all the sensors are installed at the communication terminal. This brings key challenges such as the limited sensing coverage compared to the coverage of the communication system and the difficulty in handling non-line-of-sight scenarios. To overcome these limitations, our paper proposes the deployment of multiple distributed sensing nodes, each equipped with an RGB camera. These nodes focus on extracting environmental semantics from the captured RGB images. The semantic data, rather than the raw images, are then transmitted to the basestation. This strategy significantly alleviates the overhead associated with the data storage and transmission of the raw images. Furthermore, semantic communication enhances the system's adaptability and responsiveness to dynamic environments, allowing for prioritization and transmission of contextually relevant information. Experimental results on the DeepSense 6G dataset demonstrate the effectiveness of the proposed solution in reducing the sensing data transmission overhead while accurately predicting the optimal beams in realistic communication environments. ",
    "url": "https://arxiv.org/abs/2402.14766",
    "authors": [
      "Shoaib Imran",
      "Gouranga Charan",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.14781",
    "title": "Rao-Blackwellising Bayesian Causal Inference",
    "abstract": "Bayesian causal inference, i.e., inferring a posterior over causal models for the use in downstream causal reasoning tasks, poses a hard computational inference problem that is little explored in literature. In this work, we combine techniques from order-based MCMC structure learning with recent advances in gradient-based graph learning into an effective Bayesian causal inference framework. Specifically, we decompose the problem of inferring the causal structure into (i) inferring a topological order over variables and (ii) inferring the parent sets for each variable. When limiting the number of parents per variable, we can exactly marginalise over the parent sets in polynomial time. We further use Gaussian processes to model the unknown causal mechanisms, which also allows their exact marginalisation. This introduces a Rao-Blackwellization scheme, where all components are eliminated from the model, except for the causal order, for which we learn a distribution via gradient-based optimisation. The combination of Rao-Blackwellization with our sequential inference procedure for causal orders yields state-of-the-art on linear and non-linear additive noise benchmarks with scale-free and Erdos-Renyi graph structures. ",
    "url": "https://arxiv.org/abs/2402.14781",
    "authors": [
      "Christian Toth",
      "Christian Knoll",
      "Franz Pernkopf",
      "Robert Peharz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14789",
    "title": "Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised  Learning",
    "abstract": "Self-supervised learning excels in learning representations from large amounts of unlabeled data, demonstrating success across multiple data modalities. Yet, extending self-supervised learning to new modalities is non-trivial because the specifics of existing methods are tailored to each domain, such as domain-specific augmentations which reflect the invariances in the target task. While masked modeling is promising as a domain-agnostic framework for self-supervised learning because it does not rely on input augmentations, its mask sampling procedure remains domain-specific. We present Self-guided Masked Autoencoders (SMA), a fully domain-agnostic masked modeling method. SMA trains an attention based model using a masked modeling objective, by learning masks to sample without any domain-specific assumptions. We evaluate SMA on three self-supervised learning benchmarks in protein biology, chemical property prediction, and particle physics. We find SMA is capable of learning representations without domain-specific knowledge and achieves state-of-the-art performance on these three benchmarks. ",
    "url": "https://arxiv.org/abs/2402.14789",
    "authors": [
      "Johnathan Xie",
      "Yoonho Lee",
      "Annie S. Chen",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14801",
    "title": "Mochi: Fast \\& Exact Collision Detection",
    "abstract": "Collision Detection (CD) has several applications across the domains such as robotics, visual graphics, and fluid mechanics. Finding exact collisions between the objects in the scene is quite computationally intensive. To quickly filter the object pairs that do not result in a collision, bounding boxes are built on the objects, indexed using a Bounding Volume Hierarchy(BVH), and tested for intersection before performing the expensive object-object intersection tests. In state-of-the-art CD libraries, accelerators such as GPUs are used to accelerate BVH traversal by building specialized data structures. The recent addition of ray tracing architecture to GPU hardware is designed to do the same but in the context of implementing a Ray Tracing algorithm to render a graphical scene in real-time. We present Mochi, a fast and exact collision detection engine that accelerates both the broad and narrow phases by taking advantage of the capabilities of Ray Tracing cores. We introduce multiple new reductions to perform generic CD to support three types of objects for CD: simple spherical particles, objects describable by mathematical equations, and complex objects composed of a triangle mesh. By implementing our reductions, Mochi achieves several orders of magnitude speedups on synthetic datasets and 5x-28x speedups on real-world triangle mesh datasets. We further evaluate our reductions thoroughly and provide several architectural insights on the ray tracing cores that are otherwise unknown due to their proprietorship. ",
    "url": "https://arxiv.org/abs/2402.14801",
    "authors": [
      "Durga Keerthi Mandarapu",
      "Nicholas James",
      "Milind Kulkarni"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2402.14802",
    "title": "Link Prediction under Heterophily: A Physics-Inspired Graph Neural  Network Approach",
    "abstract": "In the past years, Graph Neural Networks (GNNs) have become the `de facto' standard in various deep learning domains, thanks to their flexibility in modeling real-world phenomena represented as graphs. However, the message-passing mechanism of GNNs faces challenges in learnability and expressivity, hindering high performance on heterophilic graphs, where adjacent nodes frequently have different labels. Most existing solutions addressing these challenges are primarily confined to specific benchmarks focused on node classification tasks. This narrow focus restricts the potential impact that link prediction under heterophily could offer in several applications, including recommender systems. For example, in social networks, two users may be connected for some latent reason, making it challenging to predict such connections in advance. Physics-Inspired GNNs such as GRAFF provided a significant contribution to enhance node classification performance under heterophily, thanks to the adoption of physics biases in the message-passing. Drawing inspiration from these findings, we advocate that the methodology employed by GRAFF can improve link prediction performance as well. To further explore this hypothesis, we introduce GRAFF-LP, an extension of GRAFF to link prediction. We evaluate its efficacy within a recent collection of heterophilic graphs, establishing a new benchmark for link prediction under heterophily. Our approach surpasses previous methods, in most of the datasets, showcasing a strong flexibility in different contexts, and achieving relative AUROC improvements of up to 26.7%. ",
    "url": "https://arxiv.org/abs/2402.14802",
    "authors": [
      "Andrea Giuseppe Di Francesco",
      "Francesco Caso",
      "Maria Sofia Bucarelli",
      "Fabrizio Silvestri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.14022",
    "title": "Statistical validation of a deep learning algorithm for dental anomaly  detection in intraoral radiographs using paired data",
    "abstract": "This article describes the clinical validation study setup, statistical analysis and results for a deep learning algorithm which detects dental anomalies in intraoral radiographic images, more specifically caries, apical lesions, root canal treatment defects, marginal defects at crown restorations, periodontal bone loss and calculus. The study compares the detection performance of dentists using the deep learning algorithm to the prior performance of these dentists evaluating the images without algorithmic assistance. Calculating the marginal profit and loss of performance from the annotated paired image data allows for a quantification of the hypothesized change in sensitivity and specificity. The statistical significance of these results is extensively proven using both McNemar's test and the binomial hypothesis test. The average sensitivity increases from $60.7\\%$ to $85.9\\%$, while the average specificity slightly decreases from $94.5\\%$ to $92.7\\%$. We prove that the increase of the area under the localization ROC curve (AUC) is significant (from $0.60$ to $0.86$ on average), while the average AUC is bounded by the $95\\%$ confidence intervals ${[}0.54, 0.65{]}$ and ${[}0.82, 0.90{]}$. When using the deep learning algorithm for diagnostic guidance, the dentist can be $95\\%$ confident that the average true population sensitivity is bounded by the range $79.6\\%$ to $91.9\\%$. The proposed paired data setup and statistical analysis can be used as a blueprint to thoroughly test the effect of a modality change, like a deep learning based detection and/or segmentation, on radiographic images. ",
    "url": "https://arxiv.org/abs/2402.14022",
    "authors": [
      "Pieter Van Leemput",
      "Johannes Keustermans",
      "Wouter Mollemans"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2402.14102",
    "title": "Learning dynamic representations of the functional connectome in  neurobiological networks",
    "abstract": "The static synaptic connectivity of neuronal circuits stands in direct contrast to the dynamics of their function. As in changing community interactions, different neurons can participate actively in various combinations to effect behaviors at different times. We introduce an unsupervised approach to learn the dynamic affinities between neurons in live, behaving animals, and to reveal which communities form among neurons at different times. The inference occurs in two major steps. First, pairwise non-linear affinities between neuronal traces from brain-wide calcium activity are organized by non-negative tensor factorization (NTF). Each factor specifies which groups of neurons are most likely interacting for an inferred interval in time, and for which animals. Finally, a generative model that allows for weighted community detection is applied to the functional motifs produced by NTF to reveal a dynamic functional connectome. Since time codes the different experimental variables (e.g., application of chemical stimuli), this provides an atlas of neural motifs active during separate stages of an experiment (e.g., stimulus application or spontaneous behaviors). Results from our analysis are experimentally validated, confirming that our method is able to robustly predict causal interactions between neurons to generate behavior. Code is available at https://github.com/dyballa/dynamic-connectomes. ",
    "url": "https://arxiv.org/abs/2402.14102",
    "authors": [
      "Luciano Dyballa",
      "Samuel Lang",
      "Alexandra Haslund-Gourley",
      "Eviatar Yemini",
      "Steven W. Zucker"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.14145",
    "title": "Multiply Robust Estimation for Local Distribution Shifts with Multiple  Domains",
    "abstract": "Distribution shifts are ubiquitous in real-world machine learning applications, posing a challenge to the generalization of models trained on one data distribution to another. We focus on scenarios where data distributions vary across multiple segments of the entire population and only make local assumptions about the differences between training and test (deployment) distributions within each segment. We propose a two-stage multiply robust estimation method to improve model performance on each individual segment for tabular data analysis. The method involves fitting a linear combination of the based models, learned using clusters of training data from multiple segments, followed by a refinement step for each segment. Our method is designed to be implemented with commonly used off-the-shelf machine learning models. We establish theoretical guarantees on the generalization bound of the method on the test risk. With extensive experiments on synthetic and real datasets, we demonstrate that the proposed method substantially improves over existing alternatives in prediction accuracy and robustness on both regression and classification tasks. We also assess its effectiveness on a user city prediction dataset from a large technology company. ",
    "url": "https://arxiv.org/abs/2402.14145",
    "authors": [
      "Steven Wilkins-Reeves",
      "Xu Chen",
      "Qi Ma",
      "Christine Agarwal",
      "Aude Hofleitner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.14148",
    "title": "Neural Networks and Friction: Slide, Hold, Learn",
    "abstract": "In this study, it is demonstrated that Recurrent Neural Networks (RNNs), specifically those utilizing Gated Recurrent Unit (GRU) architecture, possess the capability to learn the complex dynamics of rate-and-state friction laws from synthetic data. The data employed for training the network is generated through the application of traditional rate-and-state friction equations coupled with the aging law for state evolution. A novel aspect of our approach is the formulation of a loss function that explicitly accounts for initial conditions, the direct effect, and the evolution of state variables during training. It is found that the RNN, with its GRU architecture, effectively learns to predict changes in the friction coefficient resulting from velocity jumps, thereby showcasing the potential of machine learning models in understanding and simulating the physics of frictional processes. ",
    "url": "https://arxiv.org/abs/2402.14148",
    "authors": [
      "Joaquin Garcia-Suarez"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14264",
    "title": "Structure-agnostic Optimality of Doubly Robust Learning for Treatment  Effect Estimation",
    "abstract": "Average treatment effect estimation is the most central problem in causal inference with application to numerous disciplines. While many estimation strategies have been proposed in the literature, recently also incorporating generic machine learning estimators, the statistical optimality of these methods has still remained an open area of investigation. In this paper, we adopt the recently introduced structure-agnostic framework of statistical lower bounds, which poses no structural properties on the nuisance functions other than access to black-box estimators that attain small errors; which is particularly appealing when one is only willing to consider estimation strategies that use non-parametric regression and classification oracles as a black-box sub-process. Within this framework, we prove the statistical optimality of the celebrated and widely used doubly robust estimators for both the Average Treatment Effect (ATE) and the Average Treatment Effect on the Treated (ATTE), as well as weighted variants of the former, which arise in policy evaluation. ",
    "url": "https://arxiv.org/abs/2402.14264",
    "authors": [
      "Jikai Jin",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.14349",
    "title": "Uncertainty-driven and Adversarial Calibration Learning for Epicardial  Adipose Tissue Segmentation",
    "abstract": "Epicardial adipose tissue (EAT) is a type of visceral fat that can secrete large amounts of adipokines to affect the myocardium and coronary arteries. EAT volume and density can be used as independent risk markers measurement of volume by noninvasive magnetic resonance images is the best method of assessing EAT. However, segmenting EAT is challenging due to the low contrast between EAT and pericardial effusion and the presence of motion artifacts. we propose a novel feature latent space multilevel supervision network (SPDNet) with uncertainty-driven and adversarial calibration learning to enhance segmentation for more accurate EAT volume estimation. The network first addresses the blurring of EAT edges due to the medical images in the open medical environments with low quality or out-of-distribution by modeling the uncertainty as a Gaussian distribution in the feature latent space, which using its Bayesian estimation as a regularization constraint to optimize SwinUNETR. Second, an adversarial training strategy is introduced to calibrate the segmentation feature map and consider the multi-scale feature differences between the uncertainty-guided predictive segmentation and the ground truth segmentation, synthesizing the multi-scale adversarial loss directly improves the ability to discriminate the similarity between organizations. Experiments on both the cardiac public MRI dataset (ACDC) and the real-world clinical cohort EAT dataset show that the proposed network outperforms mainstream models, validating that uncertainty-driven and adversarial calibration learning can be used to provide additional information for modeling multi-scale ambiguities. ",
    "url": "https://arxiv.org/abs/2402.14349",
    "authors": [
      "Kai Zhao",
      "Zhiming Liu",
      "Jiaqi Liu",
      "Jingbiao Zhou",
      "Bihong Liao",
      "Huifang Tang",
      "Qiuyu Wang",
      "Chunquan Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14515",
    "title": "Spectral invariance and maximality properties of the frequency spectrum  of quantum neural networks",
    "abstract": "Quantum Neural Networks (QNNs) are a popular approach in Quantum Machine Learning due to their close connection to Variational Quantum Circuits, making them a promising candidate for practical applications on Noisy Intermediate-Scale Quantum (NISQ) devices. A QNN can be expressed as a finite Fourier series, where the set of frequencies is called the frequency spectrum. We analyse this frequency spectrum and prove, for a large class of models, various maximality results. Furthermore, we prove that under some mild conditions there exists a bijection between classes of models with the same area $A = RL$ that preserves the frequency spectrum, where $R$ denotes the number of qubits and $L$ the number of layers, which we consequently call spectral invariance under area-preserving transformations. With this we explain the symmetry in $R$ and $L$ in the results often observed in the literature and show that the maximal frequency spectrum depends only on the area $A = RL$ and not on the individual values of $R$ and $L$. Moreover, we extend existing results and specify the maximum possible frequency spectrum of a QNN with arbitrarily many layers as a function of the spectrum of its generators. If the generators of the QNN can be further decomposed into 2-dimensional sub-generators, then this specification follows from elementary number-theoretical considerations. In the case of arbitrary dimensional generators, we extend existing results based on the so-called Golomb ruler and introduce a second novel approach based on a variation of the turnpike problem, which we call the relaxed turnpike problem. ",
    "url": "https://arxiv.org/abs/2402.14515",
    "authors": [
      "Patrick Holzer",
      "Ivica Turkalj"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.14692",
    "title": "PeriodGrad: Towards Pitch-Controllable Neural Vocoder Based on a  Diffusion Probabilistic Model",
    "abstract": "This paper presents a neural vocoder based on a denoising diffusion probabilistic model (DDPM) incorporating explicit periodic signals as auxiliary conditioning signals. Recently, DDPM-based neural vocoders have gained prominence as non-autoregressive models that can generate high-quality waveforms. The neural vocoders based on DDPM have the advantage of training with a simple time-domain loss. In practical applications, such as singing voice synthesis, there is a demand for neural vocoders to generate high-fidelity speech waveforms with flexible pitch control. However, conventional DDPM-based neural vocoders struggle to generate speech waveforms under such conditions. Our proposed model aims to accurately capture the periodic structure of speech waveforms by incorporating explicit periodic signals. Experimental results show that our model improves sound quality and provides better pitch control than conventional DDPM-based neural vocoders. ",
    "url": "https://arxiv.org/abs/2402.14692",
    "authors": [
      "Yukiya Hono",
      "Kei Hashimoto",
      "Yoshihiko Nankaku",
      "Keiichi Tokuda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.14741",
    "title": "Zero-Shot Pediatric Tuberculosis Detection in Chest X-Rays using  Self-Supervised Learning",
    "abstract": "Tuberculosis (TB) remains a significant global health challenge, with pediatric cases posing a major concern. The World Health Organization (WHO) advocates for chest X-rays (CXRs) for TB screening. However, visual interpretation by radiologists can be subjective, time-consuming and prone to error, especially in pediatric TB. Artificial intelligence (AI)-driven computer-aided detection (CAD) tools, especially those utilizing deep learning, show promise in enhancing lung disease detection. However, challenges include data scarcity and lack of generalizability. In this context, we propose a novel self-supervised paradigm leveraging Vision Transformers (ViT) for improved TB detection in CXR, enabling zero-shot pediatric TB detection. We demonstrate improvements in TB detection performance ($\\sim$12.7% and $\\sim$13.4% top AUC/AUPR gains in adults and children, respectively) when conducting self-supervised pre-training when compared to fully-supervised (i.e., non pre-trained) ViT models, achieving top performances of 0.959 AUC and 0.962 AUPR in adult TB detection, and 0.697 AUC and 0.607 AUPR in zero-shot pediatric TB detection. As a result, this work demonstrates that self-supervised learning on adult CXRs effectively extends to challenging downstream tasks such as pediatric TB detection, where data are scarce. ",
    "url": "https://arxiv.org/abs/2402.14741",
    "authors": [
      "Daniel Capell\u00e1n-Mart\u00edn",
      "Abhijeet Parida",
      "Juan J. G\u00f3mez-Valverde",
      "Ramon Sanchez-Jacob",
      "Pooneh Roshanitabrizi",
      "Marius G. Linguraru",
      "Mar\u00eda J. Ledesma-Carbayo",
      "Syed M. Anwar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14777",
    "title": "Causal Imputation for Counterfactual SCMs: Bridging Graphs and Latent  Factor Models",
    "abstract": "We consider the task of causal imputation, where we aim to predict the outcomes of some set of actions across a wide range of possible contexts. As a running example, we consider predicting how different drugs affect cells from different cell types. We study the index-only setting, where the actions and contexts are categorical variables with a finite number of possible values. Even in this simple setting, a practical challenge arises, since often only a small subset of possible action-context pairs have been studied. Thus, models must extrapolate to novel action-context pairs, which can be framed as a form of matrix completion with rows indexed by actions, columns indexed by contexts, and matrix entries corresponding to outcomes. We introduce a novel SCM-based model class, where the outcome is expressed as a counterfactual, actions are expressed as interventions on an instrumental variable, and contexts are defined based on the initial state of the system. We show that, under a linearity assumption, this setup induces a latent factor model over the matrix of outcomes, with an additional fixed effect term. To perform causal prediction based on this model class, we introduce simple extension to the Synthetic Interventions estimator (Agarwal et al., 2020). We evaluate several matrix completion approaches on the PRISM drug repurposing dataset, showing that our method outperforms all other considered matrix completion approaches. ",
    "url": "https://arxiv.org/abs/2402.14777",
    "authors": [
      "Alvaro Ribot",
      "Chandler Squires",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2003.03546",
    "title": "Adversarial Machine Learning: Bayesian Perspectives",
    "abstract": " Title: Adversarial Machine Learning: Bayesian Perspectives ",
    "url": "https://arxiv.org/abs/2003.03546",
    "authors": [
      "David Rios Insua",
      "Roi Naveiro",
      "Victor Gallego",
      "Jason Poulos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.06919",
    "title": "AQD: Towards Accurate Fully-Quantized Object Detection",
    "abstract": " Comments: CVPR 2021 Oral ",
    "url": "https://arxiv.org/abs/2007.06919",
    "authors": [
      "Peng Chen",
      "Jing Liu",
      "Bohan Zhuang",
      "Mingkui Tan",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.08021",
    "title": "StreaMulT: Streaming Multimodal Transformer for Heterogeneous and  Arbitrary Long Sequential Data",
    "abstract": " Comments: 11 pages, 6 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2110.08021",
    "authors": [
      "Victor Pellegrain",
      "Myriam Tami",
      "Michel Batteux",
      "C\u00e9line Hudelot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2202.07082",
    "title": "Graph Neural Networks for Graphs with Heterophily: A Survey",
    "abstract": " Comments: 22 pages ",
    "url": "https://arxiv.org/abs/2202.07082",
    "authors": [
      "Xin Zheng",
      "Yi Wang",
      "Yixin Liu",
      "Ming Li",
      "Miao Zhang",
      "Di Jin",
      "Philip S. Yu",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.05396",
    "title": "A Survey on Fairness for Machine Learning on Graphs",
    "abstract": " Comments: 25 pages ",
    "url": "https://arxiv.org/abs/2205.05396",
    "authors": [
      "Charlotte Laclau",
      "Christine Largeron",
      "Manvi Choudhary"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09023",
    "title": "Ratio convergence rates for Euclidean first-passage percolation:  Applications to the graph infinity Laplacian",
    "abstract": " Title: Ratio convergence rates for Euclidean first-passage percolation:  Applications to the graph infinity Laplacian ",
    "url": "https://arxiv.org/abs/2210.09023",
    "authors": [
      "Leon Bungert",
      "Jeff Calder",
      "Tim Roith"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.15996",
    "title": "Towards Generalized Few-Shot Open-Set Object Detection",
    "abstract": " Title: Towards Generalized Few-Shot Open-Set Object Detection ",
    "url": "https://arxiv.org/abs/2210.15996",
    "authors": [
      "Binyi Su",
      "Hua Zhang",
      "Jingzhi Li",
      "Zhong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.12906",
    "title": "Generative Invertible Quantum Neural Networks",
    "abstract": " Comments: 18 pages, 7 figures Changes in v2: Add references 49-51, provided gitlab link to code repository Changes in v3: Incorporate rebuttal from this https URL ",
    "url": "https://arxiv.org/abs/2302.12906",
    "authors": [
      "Armand Rousselot",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2303.02536",
    "title": "Finding Alignments Between Interpretable Causal Variables and  Distributed Neural Representations",
    "abstract": " Title: Finding Alignments Between Interpretable Causal Variables and  Distributed Neural Representations ",
    "url": "https://arxiv.org/abs/2303.02536",
    "authors": [
      "Atticus Geiger",
      "Zhengxuan Wu",
      "Christopher Potts",
      "Thomas Icard",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.04040",
    "title": "Uncertainty Quantification of Spatiotemporal Travel Demand with  Probabilistic Graph Neural Networks",
    "abstract": " Title: Uncertainty Quantification of Spatiotemporal Travel Demand with  Probabilistic Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2303.04040",
    "authors": [
      "Qingyi Wang",
      "Shenhao Wang",
      "Dingyi Zhuang",
      "Haris Koutsopoulos",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.10976",
    "title": "Attention Disturbance and Dual-Path Constraint Network for Occluded  Person Re-identification",
    "abstract": " Comments: AAAI2024 ",
    "url": "https://arxiv.org/abs/2303.10976",
    "authors": [
      "Jiaer Xia",
      "Lei Tan",
      "Pingyang Dai",
      "Mingbo Zhao",
      "Yongjian Wu",
      "Liujuan Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.13672",
    "title": "Neural Level Set Topology Optimization Using Unfitted Finite Elements",
    "abstract": " Comments: 16 pages + refs, 10 figs ",
    "url": "https://arxiv.org/abs/2303.13672",
    "authors": [
      "Connor N. Mallon",
      "Aaron W. Thornton",
      "Matthew R. Hill",
      "Santiago Badia"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2304.10031",
    "title": "Architectures of Topological Deep Learning: A Survey of Message-Passing  Topological Neural Networks",
    "abstract": " Title: Architectures of Topological Deep Learning: A Survey of Message-Passing  Topological Neural Networks ",
    "url": "https://arxiv.org/abs/2304.10031",
    "authors": [
      "Mathilde Papillon",
      "Sophia Sanborn",
      "Mustafa Hajij",
      "Nina Miolane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11625",
    "title": "Meaningful Causal Aggregation and Paradoxical Confounding",
    "abstract": " Comments: CLeaR 2024 ",
    "url": "https://arxiv.org/abs/2304.11625",
    "authors": [
      "Yuchen Zhu",
      "Kailash Budhathoki",
      "Jonas Kuebler",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.12033",
    "title": "A Spatial Calibration Method for Robust Cooperative Perception",
    "abstract": " Title: A Spatial Calibration Method for Robust Cooperative Perception ",
    "url": "https://arxiv.org/abs/2304.12033",
    "authors": [
      "Zhiying Song",
      "Tenghui Xie",
      "Hailiang Zhang",
      "Jiaxin Liu",
      "Fuxi Wen",
      "Jun Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.01938",
    "title": "Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text  Documents via Semantic-Oriented Hierarchical Graphs",
    "abstract": " Comments: Accepted by COLING 2024 ",
    "url": "https://arxiv.org/abs/2305.01938",
    "authors": [
      "Fengbin Zhu",
      "Chao Wang",
      "Fuli Feng",
      "Zifeng Ren",
      "Moxin Li",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13168",
    "title": "LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities  and Future Opportunities",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2305.13168",
    "authors": [
      "Yuqi Zhu",
      "Xiaohan Wang",
      "Jing Chen",
      "Shuofei Qiao",
      "Yixin Ou",
      "Yunzhi Yao",
      "Shumin Deng",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16202",
    "title": "DP-SGD Without Clipping: The Lipschitz Neural Network Way",
    "abstract": " Comments: 46 pages, published at International Conferences on Learning Representations (ICLR), 2024 ",
    "url": "https://arxiv.org/abs/2305.16202",
    "authors": [
      "Louis Bethune",
      "Thomas Massena",
      "Thibaut Boissin",
      "Yannick Prudent",
      "Corentin Friedrich",
      "Franck Mamalet",
      "Aurelien Bellet",
      "Mathieu Serrurier",
      "David Vigouroux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.05587",
    "title": "MC-NN: An End-to-End Multi-Channel Neural Network Approach for  Predicting Influenza A Virus Hosts and Antigenic Types",
    "abstract": " Comments: Accepted version submitted to the SN Computer Science; Published in the SN Computer Science 2023; V2: minor updates were made to the Results section; V3: minor updates regarding data description; V4: correct the time stamps mentioned in the legends of Figures 1 and 2 ",
    "url": "https://arxiv.org/abs/2306.05587",
    "authors": [
      "Yanhua Xu",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.06268",
    "title": "Attention-stacked Generative Adversarial Network (AS-GAN)-empowered  Sensor Data Augmentation for Online Monitoring of Manufacturing System",
    "abstract": " Title: Attention-stacked Generative Adversarial Network (AS-GAN)-empowered  Sensor Data Augmentation for Online Monitoring of Manufacturing System ",
    "url": "https://arxiv.org/abs/2306.06268",
    "authors": [
      "Yuxuan Li",
      "Chenang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.09222",
    "title": "Stochastic Re-weighted Gradient Descent via Distributionally Robust  Optimization",
    "abstract": " Title: Stochastic Re-weighted Gradient Descent via Distributionally Robust  Optimization ",
    "url": "https://arxiv.org/abs/2306.09222",
    "authors": [
      "Ramnath Kumar",
      "Kushal Majmundar",
      "Dheeraj Nagaraj",
      "Arun Sai Suggala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09312",
    "title": "Multi-Modal Discussion Transformer: Integrating Text, Images and Graph  Transformers to Detect Hate Speech on Social Media",
    "abstract": " Comments: Accepted to AAAI 2024 (AI for Social Impact Track) ",
    "url": "https://arxiv.org/abs/2307.09312",
    "authors": [
      "Liam Hebert",
      "Gaurav Sahu",
      "Yuxuan Guo",
      "Nanda Kishore Sreenivas",
      "Lukasz Golab",
      "Robin Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.01574",
    "title": "Another Hamiltonian Cycle in Bipartite Pfaffian Graphs",
    "abstract": " Comments: Adds analysis of Thomason's lollipop method ",
    "url": "https://arxiv.org/abs/2308.01574",
    "authors": [
      "Andreas Bj\u00f6rklund",
      "Petteri Kaski",
      "Jesper Nederlof"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.08241",
    "title": "TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for  Time Series",
    "abstract": " Title: TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for  Time Series ",
    "url": "https://arxiv.org/abs/2308.08241",
    "authors": [
      "Chenxi Sun",
      "Hongyan Li",
      "Yaliang Li",
      "Shenda Hong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10561",
    "title": "Spatial Transform Decoupling for Oriented Object Detection",
    "abstract": " Comments: Accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2308.10561",
    "authors": [
      "Hongtian Yu",
      "Yunjie Tian",
      "Qixiang Ye",
      "Yunfan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.15246",
    "title": "A Classification-Guided Approach for Adversarial Attacks against Neural  Machine Translation",
    "abstract": " Title: A Classification-Guided Approach for Adversarial Attacks against Neural  Machine Translation ",
    "url": "https://arxiv.org/abs/2308.15246",
    "authors": [
      "Sahar Sadrizadeh",
      "Ljiljana Dolamic",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.01669",
    "title": "Donkii: Can Annotation Error Detection Methods Find Errors in  Instruction-Tuning Datasets?",
    "abstract": " Comments: Camera ready version for LAW-XVIII ",
    "url": "https://arxiv.org/abs/2309.01669",
    "authors": [
      "Leon Weber-Genzel",
      "Robert Litschko",
      "Ekaterina Artemova",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.03882",
    "title": "Large Language Models Are Not Robust Multiple Choice Selectors",
    "abstract": " Comments: ICLR 2024 Spotlight ",
    "url": "https://arxiv.org/abs/2309.03882",
    "authors": [
      "Chujie Zheng",
      "Hao Zhou",
      "Fandong Meng",
      "Jie Zhou",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08469",
    "title": "Silver Retriever: Advancing Neural Passage Retrieval for Polish Question  Answering",
    "abstract": " Title: Silver Retriever: Advancing Neural Passage Retrieval for Polish Question  Answering ",
    "url": "https://arxiv.org/abs/2309.08469",
    "authors": [
      "Piotr Rybak",
      "Maciej Ogrodniczuk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.03032",
    "title": "Graph-enhanced Optimizers for Structure-aware Recommendation Embedding  Evolution",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2310.03032",
    "authors": [
      "Cong Xu",
      "Jun Wang",
      "Jianyong Wang",
      "Wei Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03774",
    "title": "Differential Game Strategies for Social Networks with Self-Interested  Individuals",
    "abstract": " Comments: Affiliation and Acknowledgment Correction to previous versions of \"Differential Game Strategies for Social Networks with Self-Interested Individuals,\" arXiv:2310.03774. Corrections were made by the author. arXiv admin note: substantial text overlap with arXiv:2310.03095 ",
    "url": "https://arxiv.org/abs/2310.03774",
    "authors": [
      "Hossein B. Jond"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.03900",
    "title": "A Game Approach to Multi-dimensional Opinion Dynamics in Social Networks  with Stubborn Strategist Agents",
    "abstract": " Comments: Affiliation and Acknowledgment Correction to previous versions of \"A Game Approach to Multi-dimensional Opinion Dynamics in Social Networks with Stubborn Strategist Agents,\" arXiv:2310.03900. Corrections correspond to the first author ",
    "url": "https://arxiv.org/abs/2310.03900",
    "authors": [
      "Hossein B. Jond",
      "Aykut Y\u0131ld\u0131z"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.05130",
    "title": "Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text  via Conditional Probability Curvature",
    "abstract": " Comments: ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.05130",
    "authors": [
      "Guangsheng Bao",
      "Yanbin Zhao",
      "Zhiyang Teng",
      "Linyi Yang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.10642",
    "title": "Real-time Photorealistic Dynamic Scene Representation and Rendering with  4D Gaussian Splatting",
    "abstract": " Comments: ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.10642",
    "authors": [
      "Zeyu Yang",
      "Hongye Yang",
      "Zijie Pan",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16022",
    "title": "A Robust Measure on FDFAs Following Duo-Normalized Acceptance",
    "abstract": " Title: A Robust Measure on FDFAs Following Duo-Normalized Acceptance ",
    "url": "https://arxiv.org/abs/2310.16022",
    "authors": [
      "Dana Fisman",
      "Emmanuel Goldberg",
      "Oded Zimerman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2310.19253",
    "title": "Flow-based Distributionally Robust Optimization",
    "abstract": " Comments: IEEE Journal on Selected Areas in Information Theory (JSAIT). Accepted. 2024 ",
    "url": "https://arxiv.org/abs/2310.19253",
    "authors": [
      "Chen Xu",
      "Jonghyeok Lee",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19608",
    "title": "On Feynman--Kac training of partial Bayesian neural networks",
    "abstract": " Comments: In AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2310.19608",
    "authors": [
      "Zheng Zhao",
      "Sebastian Mair",
      "Thomas B. Sch\u00f6n",
      "Jens Sj\u00f6lund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.04131",
    "title": "Interpreting Shared Circuits for Ordered Sequence Prediction in a Large  Language Model",
    "abstract": " Title: Interpreting Shared Circuits for Ordered Sequence Prediction in a Large  Language Model ",
    "url": "https://arxiv.org/abs/2311.04131",
    "authors": [
      "Michael Lan",
      "Fazl Barez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.06973",
    "title": "Analytical Verification of Performance of Deep Neural Network Based  Time-Synchronized Distribution System State Estimation",
    "abstract": " Comments: 8 pages, in Journal of Modern Power Systems and Clean Energy, 2023 ",
    "url": "https://arxiv.org/abs/2311.06973",
    "authors": [
      "Behrouz Azimian",
      "Shiva Moshtagh",
      "Anamitra Pal",
      "Shanshan Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.08369",
    "title": "How You Prompt Matters! Even Task-Oriented Constraints in Instructions  Affect LLM-Generated Text Detection",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2311.08369",
    "authors": [
      "Ryuto Koike",
      "Masahiro Kaneko",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00824",
    "title": "Variational Self-Supervised Contrastive Learning Using Beta Divergence  For Face Understanding",
    "abstract": " Title: Variational Self-Supervised Contrastive Learning Using Beta Divergence  For Face Understanding ",
    "url": "https://arxiv.org/abs/2312.00824",
    "authors": [
      "Mehmet Can Yavuz",
      "Berrin Yanikoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05928",
    "title": "AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer",
    "abstract": " Comments: Accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2312.05928",
    "authors": [
      "Joonwoo Kwon",
      "Sooyoung Kim",
      "Yuewei Lin",
      "Shinjae Yoo",
      "Jiook Cha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08656",
    "title": "MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural  Networks Training",
    "abstract": " Comments: ASPLOS 2024 accepted publication ",
    "url": "https://arxiv.org/abs/2312.08656",
    "authors": [
      "Hongwu Peng",
      "Xi Xie",
      "Kaustubh Shivdikar",
      "MD Amit Hasan",
      "Jiahui Zhao",
      "Shaoyi Huang",
      "Omer Khan",
      "David Kaeli",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.15198",
    "title": "Do LLM Agents Exhibit Social Behavior?",
    "abstract": " Title: Do LLM Agents Exhibit Social Behavior? ",
    "url": "https://arxiv.org/abs/2312.15198",
    "authors": [
      "Yan Leng",
      "Yuan Yuan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2312.15591",
    "title": "Privacy-Preserving Neural Graph Databases",
    "abstract": " Title: Privacy-Preserving Neural Graph Databases ",
    "url": "https://arxiv.org/abs/2312.15591",
    "authors": [
      "Qi Hu",
      "Haoran Li",
      "Jiaxin Bai",
      "Zihao Wang",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.03374",
    "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and  Semantic Reward",
    "abstract": " Title: LLM-Powered Code Vulnerability Repair with Reinforcement Learning and  Semantic Reward ",
    "url": "https://arxiv.org/abs/2401.03374",
    "authors": [
      "Nafis Tanveer Islam",
      "Joseph Khoury",
      "Andrew Seong",
      "Mohammad Bahrami Karkevandi",
      "Gonzalo De La Torre Parra",
      "Elias Bou-Harb",
      "Peyman Najafirad"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.06362",
    "title": "Attention, Distillation, and Tabularization: Towards Practical Neural  Network-Based Prefetching",
    "abstract": " Title: Attention, Distillation, and Tabularization: Towards Practical Neural  Network-Based Prefetching ",
    "url": "https://arxiv.org/abs/2401.06362",
    "authors": [
      "Pengmiao Zhang",
      "Neelesh Gupta",
      "Rajgopal Kannan",
      "Viktor K. Prasanna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2401.06855",
    "title": "Fine-grained Hallucination Detection and Editing for Language Models",
    "abstract": " Comments: Our code, data, and demo are available at this https URL Expanded human annotations adding a new LM, as well as included more baselines for comparison ",
    "url": "https://arxiv.org/abs/2401.06855",
    "authors": [
      "Abhika Mishra",
      "Akari Asai",
      "Vidhisha Balachandran",
      "Yizhong Wang",
      "Graham Neubig",
      "Yulia Tsvetkov",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.08190",
    "title": "MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible  Pipeline",
    "abstract": " Title: MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible  Pipeline ",
    "url": "https://arxiv.org/abs/2401.08190",
    "authors": [
      "Minpeng Liao",
      "Wei Luo",
      "Chengxi Li",
      "Jing Wu",
      "Kai Fan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.16637",
    "title": "IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code  Completion",
    "abstract": " Comments: Accepted for the 32nd ACM Symposium on the Foundations of Software Engineering (FSE 2024) ",
    "url": "https://arxiv.org/abs/2401.16637",
    "authors": [
      "Bolun Li",
      "Zhihong Sun",
      "Tao Huang",
      "Hongyu Zhang",
      "Yao Wan",
      "Ge Li",
      "Zhi Jin",
      "Chen Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.17010",
    "title": "Finetuning Large Language Models for Vulnerability Detection",
    "abstract": " Title: Finetuning Large Language Models for Vulnerability Detection ",
    "url": "https://arxiv.org/abs/2401.17010",
    "authors": [
      "Alexey Shestov",
      "Rodion Levichev",
      "Ravil Mussabayev",
      "Anton Cheshkov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.17270",
    "title": "YOLO-World: Real-Time Open-Vocabulary Object Detection",
    "abstract": " Comments: Work still in progress. Code & models are available at: this https URL ",
    "url": "https://arxiv.org/abs/2401.17270",
    "authors": [
      "Tianheng Cheng",
      "Lin Song",
      "Yixiao Ge",
      "Wenyu Liu",
      "Xinggang Wang",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.03686",
    "title": "Are Machines Better at Complex Reasoning? Unveiling Human-Machine  Inference Gaps in Entailment Verification",
    "abstract": " Title: Are Machines Better at Complex Reasoning? Unveiling Human-Machine  Inference Gaps in Entailment Verification ",
    "url": "https://arxiv.org/abs/2402.03686",
    "authors": [
      "Soumya Sanyal",
      "Tianyi Xiao",
      "Jiacheng Liu",
      "Wenya Wang",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05391",
    "title": "Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey",
    "abstract": " Comments: Ongoing work; 41 pages (Main Text), 55 pages (Total), 11 Tables, 13 Figures, 617 citations; Paper list is available at this https URL ",
    "url": "https://arxiv.org/abs/2402.05391",
    "authors": [
      "Zhuo Chen",
      "Yichi Zhang",
      "Yin Fang",
      "Yuxia Geng",
      "Lingbing Guo",
      "Xiang Chen",
      "Qian Li",
      "Wen Zhang",
      "Jiaoyan Chen",
      "Yushan Zhu",
      "Jiaqi Li",
      "Xiaoze Liu",
      "Jeff Z. Pan",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.05644",
    "title": "FuncGrasp: Learning Object-Centric Neural Grasp Functions from Single  Annotated Example Object",
    "abstract": " Comments: Accepted to ICRA 2024 ",
    "url": "https://arxiv.org/abs/2402.05644",
    "authors": [
      "Hanzhi Chen",
      "Binbin Xu",
      "Stefan Leutenegger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08441",
    "title": "Latent space configuration for improved generalization in supervised  autoencoder neural networks",
    "abstract": " Comments: 19 pages,18 figures, 2 tables, 15 equations ",
    "url": "https://arxiv.org/abs/2402.08441",
    "authors": [
      "Nikita Gabdullin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.09664",
    "title": "CodeMind: A Framework to Challenge Large Language Models for Code  Reasoning",
    "abstract": " Title: CodeMind: A Framework to Challenge Large Language Models for Code  Reasoning ",
    "url": "https://arxiv.org/abs/2402.09664",
    "authors": [
      "Changshu Liu",
      "Shizhuo Dylan Zhang",
      "Reyhaneh Jabbarvand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.10002",
    "title": "MM-Point: Multi-View Information-Enhanced Multi-Modal Self-Supervised 3D  Point Cloud Understanding",
    "abstract": " Comments: Accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2402.10002",
    "authors": [
      "Hai-Tao Yu",
      "Mofei Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.10059",
    "title": "Partial synchrony for free? New bounds for Byzantine agreement via a  generic transformation across network models",
    "abstract": " Title: Partial synchrony for free? New bounds for Byzantine agreement via a  generic transformation across network models ",
    "url": "https://arxiv.org/abs/2402.10059",
    "authors": [
      "Pierre Civit",
      "Muhammad Ayaz Dzulfikar",
      "Seth Gilbert",
      "Rachid Guerraoui",
      "Jovan Komatovic",
      "Manuel Vidigueira",
      "Igor Zablotchi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.11753",
    "title": "ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs",
    "abstract": " Title: ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs ",
    "url": "https://arxiv.org/abs/2402.11753",
    "authors": [
      "Fengqing Jiang",
      "Zhangchen Xu",
      "Luyao Niu",
      "Zhen Xiang",
      "Bhaskar Ramasubramanian",
      "Bo Li",
      "Radha Poovendran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.11773",
    "title": "Dynamic Multi-Network Mining of Tensor Time Series",
    "abstract": " Comments: Accepted by WWW 2024 ",
    "url": "https://arxiv.org/abs/2402.11773",
    "authors": [
      "Kohei Obata",
      "Koki Kawabata",
      "Yasuko Matsubara",
      "Yasushi Sakurai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.13352",
    "title": "KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers",
    "abstract": " Title: KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers ",
    "url": "https://arxiv.org/abs/2402.13352",
    "authors": [
      "Boran Apak",
      "Medina Bandic",
      "Aritra Sarkar",
      "Sebastian Feld"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13528",
    "title": "Infrastructure Ombudsman: Mining Future Failure Concerns from Structural  Disaster Response",
    "abstract": " Title: Infrastructure Ombudsman: Mining Future Failure Concerns from Structural  Disaster Response ",
    "url": "https://arxiv.org/abs/2402.13528",
    "authors": [
      "Md Towhidul Absar Chowdhury",
      "Soumyajit Datta",
      "Naveen Sharma",
      "Ashiqur R. KhudaBukhsh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.13545",
    "title": "A Two-Stage Dual-Path Framework for Text Tampering Detection and  Recognition",
    "abstract": " Title: A Two-Stage Dual-Path Framework for Text Tampering Detection and  Recognition ",
    "url": "https://arxiv.org/abs/2402.13545",
    "authors": [
      "Guandong Li",
      "Xian Yang",
      "Wenpin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13605",
    "title": "KorNAT: LLM Alignment Benchmark for Korean Social Values and Common  Knowledge",
    "abstract": " Comments: 35 pages, 7 figures, 16 tables ",
    "url": "https://arxiv.org/abs/2402.13605",
    "authors": [
      "Jiyoung Lee",
      "Minwoo Kim",
      "Seungho Kim",
      "Junghwan Kim",
      "Seunghyun Won",
      "Hwaran Lee",
      "Edward Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13651",
    "title": "Robustness of Deep Neural Networks for Micro-Doppler Radar  Classification",
    "abstract": " Title: Robustness of Deep Neural Networks for Micro-Doppler Radar  Classification ",
    "url": "https://arxiv.org/abs/2402.13651",
    "authors": [
      "Mikolaj Czerkawski",
      "Carmine Clemente",
      "Craig Michie",
      "Christos Tachtatzis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.13711",
    "title": "DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based  Graph Continual Learning",
    "abstract": " Comments: Accepted at ACM TheWebConf 2024 (WWW 2024) ",
    "url": "https://arxiv.org/abs/2402.13711",
    "authors": [
      "Seungyoon Choi",
      "Wonjoong Kim",
      "Sungwon Kim",
      "Yeonjun In",
      "Sein Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13948",
    "title": "Improved Syndrome-based Neural Decoder for Linear Block Codes",
    "abstract": " Comments: 6 pages, 7 figures. To be published in Proc. IEEE Global Communications Conference (GLOBECOM 2023), Kuala Lumpur, Malaysia, December 4-8, 2023. \\{copyright} 2023 IEEE ",
    "url": "https://arxiv.org/abs/2402.13948",
    "authors": [
      "Gast\u00f3n De Boni Rovella",
      "Meryem Benammar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  }
]