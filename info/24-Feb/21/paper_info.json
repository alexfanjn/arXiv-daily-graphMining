[
  {
    "id": "arXiv:2402.12390",
    "title": "A Semantic Social Network Analysis Tool for Sensitivity Analysis and  What-If Scenario Testing in Alcohol Consumption Studies",
    "abstract": "Social Network Analysis (SNA) is a set of techniques developed in the field of social and behavioral sciences research, in order to characterize and study the social relationships that are established among a set of individuals. When building a social network for performing an SNA analysis, an initial process of data gathering is achieved in order to extract the characteristics of the individuals and their relationships. This is usually done by completing a questionnaire containing different types of questions that will be later used to obtain the SNA measures needed to perform the study. There are, then, a great number of different possible network generating questions and also many possibilities for mapping the responses to the corresponding characteristics and relationships. Many variations may be introduced into these questions (the way they are posed, the weights given to each of the responses, etc.) that may have an effect on the resulting networks. All these different variations are difficult to achieve manually, because the process is time-consuming and error prone. The tool described in this paper uses semantic knowledge representation techniques in order to facilitate this kind of sensitivity studies. The base of the tool is a conceptual structure, called \"ontology\" that is able to represent the different concepts and their definitions. The tool is compared to other similar ones, and the advantages of the approach are highlighted, giving some particular examples from an ongoing SNA study about alcohol consumption habits in adolescents. ",
    "url": "https://arxiv.org/abs/2402.12390",
    "authors": [
      "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
      "Alejandro Rodr\u00edguez-Gonz\u00e1lez",
      "Carmen Benavides",
      "Leticia S\u00e1nchez-Valde\u00f3n",
      "Isa\u00edas Garc\u00eda"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12411",
    "title": "Deep Structural Knowledge Exploitation and Synergy for Estimating Node  Importance Value on Heterogeneous Information Networks",
    "abstract": "Node importance estimation problem has been studied conventionally with homogeneous network topology analysis. To deal with network heterogeneity, a few recent methods employ graph neural models to automatically learn diverse sources of information. However, the major concern revolves around that their full adaptive learning process may lead to insufficient information exploration, thereby formulating the problem as the isolated node value prediction with underperformance and less interpretability. In this work, we propose a novel learning framework: SKES. Different from previous automatic learning designs, SKES exploits heterogeneous structural knowledge to enrich the informativeness of node representations. Based on a sufficiently uninformative reference, SKES estimates the importance value for any input node, by quantifying its disparity against the reference. This establishes an interpretable node importance computation paradigm. Furthermore, SKES dives deep into the understanding that \"nodes with similar characteristics are prone to have similar importance values\" whilst guaranteeing that such informativeness disparity between any different nodes is orderly reflected by the embedding distance of their associated latent features. Extensive experiments on three widely-evaluated benchmarks demonstrate the performance superiority of SKES over several recent competing methods. ",
    "url": "https://arxiv.org/abs/2402.12411",
    "authors": [
      "Yankai Chen",
      "Yixiang Fang",
      "Qiongyan Wang",
      "Xin Cao",
      "Irwin King"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12418",
    "title": "Beyond Uniform Scaling: Exploring Depth Heterogeneity in Neural  Architectures",
    "abstract": "Conventional scaling of neural networks typically involves designing a base network and growing different dimensions like width, depth, etc. of the same by some predefined scaling factors. We introduce an automated scaling approach leveraging second-order loss landscape information. Our method is flexible towards skip connections a mainstay in modern vision transformers. Our training-aware method jointly scales and trains transformers without additional training iterations. Motivated by the hypothesis that not all neurons need uniform depth complexity, our approach embraces depth heterogeneity. Extensive evaluations on DeiT-S with ImageNet100 show a 2.5% accuracy gain and 10% parameter efficiency improvement over conventional scaling. Scaled networks demonstrate superior performance upon training small scale datasets from scratch. We introduce the first intact scaling mechanism for vision transformers, a step towards efficient model scaling. ",
    "url": "https://arxiv.org/abs/2402.12418",
    "authors": [
      "Akash Guna R.T",
      "Arnav Chavan",
      "Deepak Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.12426",
    "title": "Attacks on Node Attributes in Graph Neural Networks",
    "abstract": "Graphs are commonly used to model complex networks prevalent in modern social media and literacy applications. Our research investigates the vulnerability of these graphs through the application of feature based adversarial attacks, focusing on both decision-time attacks and poisoning attacks. In contrast to state-of-the-art models like Net Attack and Meta Attack, which target node attributes and graph structure, our study specifically targets node attributes. For our analysis, we utilized the text dataset Hellaswag and graph datasets Cora and CiteSeer, providing a diverse basis for evaluation. Our findings indicate that decision-time attacks using Projected Gradient Descent (PGD) are more potent compared to poisoning attacks that employ Mean Node Embeddings and Graph Contrastive Learning strategies. This provides insights for graph data security, pinpointing where graph-based models are most vulnerable and thereby informing the development of stronger defense mechanisms against such attacks. ",
    "url": "https://arxiv.org/abs/2402.12426",
    "authors": [
      "Ying Xu",
      "Michael Lanier",
      "Anindya Sarkar",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12475",
    "title": "Diffeomorphism Neural Operator for various domains and parameters of  partial differential equations",
    "abstract": "Many science and engineering applications demand partial differential equations (PDE) evaluations that are traditionally computed with resource-intensive numerical solvers. Neural operator models provide an efficient alternative by learning the governing physical laws directly from data in a class of PDEs with different parameters, but constrained in a fixed boundary (domain). Many applications, such as design and manufacturing, would benefit from neural operators with flexible domains when studied at scale. Here we present a diffeomorphism neural operator learning framework towards developing domain-flexible models for physical systems with various and complex domains. Specifically, a neural operator trained in a shared domain mapped from various domains of fields by diffeomorphism is proposed, which transformed the problem of learning function mappings in varying domains (spaces) into the problem of learning operators on a shared diffeomorphic domain. Meanwhile, an index is provided to evaluate the generalization of diffeomorphism neural operators in different domains by the domain diffeomorphism similarity. Experiments on statics scenarios (Darcy flow, mechanics) and dynamic scenarios (pipe flow, airfoil flow) demonstrate the advantages of our approach for neural operator learning under various domains, where harmonic and volume parameterization are used as the diffeomorphism for 2D and 3D domains. Our diffeomorphism neural operator approach enables strong learning capability and robust generalization across varying domains and parameters. ",
    "url": "https://arxiv.org/abs/2402.12475",
    "authors": [
      "Zhiwei Zhao",
      "Changqing Liu",
      "Yingguang Li",
      "Zhibin Chen",
      "Xu Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12479",
    "title": "In deep reinforcement learning, a pruned network is a good network",
    "abstract": "Recent work has shown that deep reinforcement learning agents have difficulty in effectively using their network parameters. We leverage prior insights into the advantages of sparse training techniques and demonstrate that gradual magnitude pruning enables agents to maximize parameter effectiveness. This results in networks that yield dramatic performance improvements over traditional networks and exhibit a type of \"scaling law\", using only a small fraction of the full network parameters. ",
    "url": "https://arxiv.org/abs/2402.12479",
    "authors": [
      "Johan Obando-Ceron",
      "Aaron Courville",
      "Pablo Samuel Castro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12498",
    "title": "Feudal Networks for Visual Navigation",
    "abstract": "Visual navigation follows the intuition that humans can navigate without detailed maps. A common approach is interactive exploration while building a topological graph with images at nodes that can be used for planning. Recent variations learn from passive videos and can navigate using complex social and semantic cues. However, a significant number of training videos are needed, large graphs are utilized, and scenes are not unseen since odometry is utilized. We introduce a new approach to visual navigation using feudal learning, which employs a hierarchical structure consisting of a worker agent, a mid-level manager, and a high-level manager. Key to the feudal learning paradigm, agents at each level see a different aspect of the task and operate at different spatial and temporal scales. Two unique modules are developed in this framework. For the high- level manager, we learn a memory proxy map in a self supervised manner to record prior observations in a learned latent space and avoid the use of graphs and odometry. For the mid-level manager, we develop a waypoint network that outputs intermediate subgoals imitating human waypoint selection during local navigation. This waypoint network is pre-trained using a new, small set of teleoperation videos that we make publicly available, with training environments different from testing environments. The resulting feudal navigation network achieves near SOTA performance, while providing a novel no-RL, no-graph, no-odometry, no-metric map approach to the image goal navigation task. ",
    "url": "https://arxiv.org/abs/2402.12498",
    "authors": [
      "Faith Johnson",
      "Bryan Bo Cao",
      "Kristin Dana",
      "Shubham Jain",
      "Ashwin Ashok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.12503",
    "title": "PARCv2: Physics-aware Recurrent Convolutional Neural Networks for  Spatiotemporal Dynamics Modeling",
    "abstract": "Modeling unsteady, fast transient, and advection-dominated physics problems is a pressing challenge for physics-aware deep learning (PADL). The physics of complex systems is governed by large systems of partial differential equations (PDEs) and ancillary constitutive models with nonlinear structures, as well as evolving state fields exhibiting sharp gradients and rapidly deforming material interfaces. Here, we investigate an inductive bias approach that is versatile and generalizable to model generic nonlinear field evolution problems. Our study focuses on the recent physics-aware recurrent convolutions (PARC), which incorporates a differentiator-integrator architecture that inductively models the spatiotemporal dynamics of generic physical systems. We extend the capabilities of PARC to simulate unsteady, transient, and advection-dominant systems. The extended model, referred to as PARCv2, is equipped with differential operators to model advection-reaction-diffusion equations, as well as a hybrid integral solver for stable, long-time predictions. PARCv2 is tested on both standard benchmark problems in fluid dynamics, namely Burgers and Navier-Stokes equations, and then applied to more complex shock-induced reaction problems in energetic materials. We evaluate the behavior of PARCv2 in comparison to other physics-informed and learning bias models and demonstrate its potential to model unsteady and advection-dominant dynamics regimes. ",
    "url": "https://arxiv.org/abs/2402.12503",
    "authors": [
      "Phong C.H. Nguyen",
      "Xinlun Cheng",
      "Shahab Arfaza",
      "Pradeep Seshadri",
      "Yen T. Nguyen",
      "Munho Kim",
      "Sanghun Choi",
      "H.S. Udaykumar",
      "Stephen Baek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12518",
    "title": "Gaussian Process Neural Additive Models",
    "abstract": "Deep neural networks have revolutionized many fields, but their black-box nature also occasionally prevents their wider adoption in fields such as healthcare and finance, where interpretable and explainable models are required. The recent development of Neural Additive Models (NAMs) is a significant step in the direction of interpretable deep learning for tabular datasets. In this paper, we propose a new subclass of NAMs that use a single-layer neural network construction of the Gaussian process via random Fourier features, which we call Gaussian Process Neural Additive Models (GP-NAM). GP-NAMs have the advantage of a convex objective function and number of trainable parameters that grows linearly with feature dimensionality. It suffers no loss in performance compared to deeper NAM approaches because GPs are well-suited for learning complex non-parametric univariate functions. We demonstrate the performance of GP-NAM on several tabular datasets, showing that it achieves comparable or better performance in both classification and regression tasks with a large reduction in the number of parameters. ",
    "url": "https://arxiv.org/abs/2402.12518",
    "authors": [
      "Wei Zhang",
      "Brian Barr",
      "John Paisley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12519",
    "title": "System Identification of Neural Systems: Going Beyond Images to  Modelling Dynamics",
    "abstract": "Vast literature has compared the recordings of biological neurons in the brain to deep neural networks. The ultimate goal is to interpret deep networks or to better understand and encode biological neural systems. Recently, there has been a debate on whether system identification is possible and how much it can tell us about the brain computation. System identification recognizes whether one model is more valid to represent the brain computation over another. Nonetheless, previous work did not consider the time aspect and how video and dynamics (e.g., motion) modelling in deep networks relate to these biological neural systems within a large-scale comparison. Towards this end, we propose a system identification study focused on comparing single image vs. video understanding models with respect to the visual cortex recordings. Our study encompasses two sets of experiments; a real environment setup and a simulated environment setup. The study also encompasses more than 30 models and, unlike prior works, we focus on convolutional vs. transformer-based, single vs. two-stream, and fully vs. self-supervised video understanding models. The goal is to capture a greater variety of architectures that model dynamics. As such, this signifies the first large-scale study of video understanding models from a neuroscience perspective. Our results in the simulated experiments, show that system identification can be attained to a certain level in differentiating image vs. video understanding models. Moreover, we provide key insights on how video understanding models predict visual cortex responses; showing video understanding better than image understanding models, convolutional models are better in the early-mid regions than transformer based except for multiscale transformers that are still good in predicting these regions, and that two-stream models are better than single stream. ",
    "url": "https://arxiv.org/abs/2402.12519",
    "authors": [
      "Mai Gamal",
      "Mohamed Rashad",
      "Eman Ehab",
      "Seif Eldawlatly",
      "Mennatullah Siam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12526",
    "title": "Optimize Energy Consumption of Wireless Sensor Networks by using  modified Ant Colony Optimization ACO",
    "abstract": "Routing represents a pivotal concern in the context of Wireless Sensor Networks (WSN) owing to its divergence from traditional network routing paradigms. The inherent dynamism of the WSN environment, coupled with the scarcity of available resources, engenders considerable challenges for industry and academia alike in devising efficient routing strategies. Addressing these challenges, a viable recourse lies in applying heuristic search methodologies to ascertain the most optimal path in WSNs. Ant Colony Optimization (ACO) is a well-established heuristic algorithm that has demonstrated notable advancements in routing contexts. This paper introduces a modify routing protocols based on Ant colony optimization. In these protocols, we incorporate the inverse of the distance between nodes and their neighbours in the probability equations of ACO along with considering pheromone levels and residual energy. These formulation modifications facilitate the selection of the most suitable candidate for the subsequent hop, effectively minimizing the average energy consumption across all nodes in each iteration. Furthermore, in this protocol, we iteratively fine-tune ACO's parameter values based on the outcomes of several experimental trials. The experimental analysis is conducted through a diverse set of network topologies, and the results are subjected to comparison against well-established ACO algorithm and routing protocols. The efficacy of the proposed protocol is assessed based on various performance metrics, encompassing throughput, energy consumption, network lifetime, energy consumption, the extent of data transferred over the network, and the length of paths traversed by packets. These metrics collectively provide a comprehensive evaluation of the performance attainments of the routing protocols. ",
    "url": "https://arxiv.org/abs/2402.12526",
    "authors": [
      "Yasameen Sajid Razooqi",
      "Muntasir Al-Asfoor",
      "Mohammed Hamzah Abed"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.12536",
    "title": "Designing High-Performing Networks for Multi-Scale Computer Vision",
    "abstract": "Since the emergence of deep learning, the computer vision field has flourished with models improving at a rapid pace on more and more complex tasks. We distinguish three main ways to improve a computer vision model: (1) improving the data aspect by for example training on a large, more diverse dataset, (2) improving the training aspect by for example designing a better optimizer, and (3) improving the network architecture (or network for short). In this thesis, we chose to improve the latter, i.e. improving the network designs of computer vision models. More specifically, we investigate new network designs for multi-scale computer vision tasks, which are tasks requiring to make predictions about concepts at different scales. The goal of these new network designs is to outperform existing baseline designs from the literature. Specific care is taken to make sure the comparisons are fair, by guaranteeing that the different network designs were trained and evaluated with the same settings. Code is publicly available at https://github.com/CedricPicron/DetSeg. ",
    "url": "https://arxiv.org/abs/2402.12536",
    "authors": [
      "C\u00e9dric Picron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12538",
    "title": "A Machine Learning Ensemble Model for the Detection of Cyberbullying",
    "abstract": "The pervasive use of social media platforms, such as Facebook, Instagram, and X, has significantly amplified our electronic interconnectedness. Moreover, these platforms are now easily accessible from any location at any given time. However, the increased popularity of social media has also led to cyberbullying.It is imperative to address the need for finding, monitoring, and mitigating cyberbullying posts on social media platforms. Motivated by this necessity, we present this paper to contribute to developing an automated system for detecting binary labels of aggressive tweets.Our study has demonstrated remarkable performance compared to previous experiments on the same dataset. We employed the stacking ensemble machine learning method, utilizing four various feature extraction techniques to optimize performance within the stacking ensemble learning framework. Combining five machine learning algorithms,Decision Trees, Random Forest, Linear Support Vector Classification, Logistic Regression, and K-Nearest Neighbors into an ensemble method, we achieved superior results compared to traditional machine learning classifier models. The stacking classifier achieved a high accuracy rate of 94.00%, outperforming traditional machine learning models and surpassing the results of prior experiments that utilized the same dataset. The outcomes of our experiments showcased an accuracy rate of 0.94% in detection tweets as aggressive or non-aggressive. ",
    "url": "https://arxiv.org/abs/2402.12538",
    "authors": [
      "Abulkarim Faraj Alqahtani",
      "Mohammad Ilyas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12560",
    "title": "CausalGym: Benchmarking causal interpretability methods on linguistic  tasks",
    "abstract": "Language models (LMs) have proven to be powerful tools for psycholinguistic research, but most prior work has focused on purely behavioural measures (e.g., surprisal comparisons). At the same time, research in model interpretability has begun to illuminate the abstract causal mechanisms shaping LM behavior. To help bring these strands of research closer together, we introduce CausalGym. We adapt and expand the SyntaxGym suite of tasks to benchmark the ability of interpretability methods to causally affect model behaviour. To illustrate how CausalGym can be used, we study the pythia models (14M--6.9B) and assess the causal efficacy of a wide range of interpretability methods, including linear probing and distributed alignment search (DAS). We find that DAS outperforms the other methods, and so we use it to study the learning trajectory of two difficult linguistic phenomena in pythia-1b: negative polarity item licensing and filler--gap dependencies. Our analysis shows that the mechanism implementing both of these tasks is learned in discrete stages, not gradually. ",
    "url": "https://arxiv.org/abs/2402.12560",
    "authors": [
      "Aryaman Arora",
      "Dan Jurafsky",
      "Christopher Potts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12572",
    "title": "FairProof : Confidential and Certifiable Fairness for Neural Networks",
    "abstract": "Machine learning models are increasingly used in societal applications, yet legal and privacy concerns demand that they very often be kept confidential. Consequently, there is a growing distrust about the fairness properties of these models in the minds of consumers, who are often at the receiving end of model predictions. To this end, we propose FairProof - a system that uses Zero-Knowledge Proofs (a cryptographic primitive) to publicly verify the fairness of a model, while maintaining confidentiality. We also propose a fairness certification algorithm for fully-connected neural networks which is befitting to ZKPs and is used in this system. We implement FairProof in Gnark and demonstrate empirically that our system is practically feasible. ",
    "url": "https://arxiv.org/abs/2402.12572",
    "authors": [
      "Chhavi Yadav",
      "Amrita Roy Chowdhury",
      "Dan Boneh",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12620",
    "title": "Are Large Language Models (LLMs) Good Social Predictors?",
    "abstract": "The prediction has served as a crucial scientific method in modern social studies. With the recent advancement of Large Language Models (LLMs), efforts have been made to leverage LLMs to predict the human features in social life, such as presidential voting. These works suggest that LLMs are capable of generating human-like responses. However, we find that the promising performance achieved by previous studies is because of the existence of input shortcut features to the response. In fact, by removing these shortcuts, the performance is reduced dramatically. To further revisit the ability of LLMs, we introduce a novel social prediction task, Soc-PRF Prediction, which utilizes general features as input and simulates real-world social study settings. With the comprehensive investigations on various LLMs, we reveal that LLMs cannot work as expected on social prediction when given general input features without shortcuts. We further investigate possible reasons for this phenomenon that suggest potential ways to enhance LLMs for social prediction. ",
    "url": "https://arxiv.org/abs/2402.12620",
    "authors": [
      "Kaiqi Yang",
      "Hang Li",
      "Hongzhi Wen",
      "Tai-Quan Peng",
      "Jiliang Tang",
      "Hui Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.12624",
    "title": "Efficient Parameter Mining and Freezing for Continual Object Detection",
    "abstract": "Continual Object Detection is essential for enabling intelligent agents to interact proactively with humans in real-world settings. While parameter-isolation strategies have been extensively explored in the context of continual learning for classification, they have yet to be fully harnessed for incremental object detection scenarios. Drawing inspiration from prior research that focused on mining individual neuron responses and integrating insights from recent developments in neural pruning, we proposed efficient ways to identify which layers are the most important for a network to maintain the performance of a detector across sequential updates. The presented findings highlight the substantial advantages of layer-level parameter isolation in facilitating incremental learning within object detection models, offering promising avenues for future research and application in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2402.12624",
    "authors": [
      "Angelo G. Menezes",
      "Augusto J. Peterlevitz",
      "Mateus A. Chinelatto",
      "Andr\u00e9 C. P. L. F. de Carvalho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12626",
    "title": "Indiscriminate Data Poisoning Attacks on Pre-trained Feature Extractors",
    "abstract": "Machine learning models have achieved great success in supervised learning tasks for end-to-end training, which requires a large amount of labeled data that is not always feasible. Recently, many practitioners have shifted to self-supervised learning methods that utilize cheap unlabeled data to learn a general feature extractor via pre-training, which can be further applied to personalized downstream tasks by simply training an additional linear layer with limited labeled data. However, such a process may also raise concerns regarding data poisoning attacks. For instance, indiscriminate data poisoning attacks, which aim to decrease model utility by injecting a small number of poisoned data into the training set, pose a security risk to machine learning models, but have only been studied for end-to-end supervised learning. In this paper, we extend the exploration of the threat of indiscriminate attacks on downstream tasks that apply pre-trained feature extractors. Specifically, we propose two types of attacks: (1) the input space attacks, where we modify existing attacks to directly craft poisoned data in the input space. However, due to the difficulty of optimization under constraints, we further propose (2) the feature targeted attacks, where we mitigate the challenge with three stages, firstly acquiring target parameters for the linear head; secondly finding poisoned features by treating the learned feature representations as a dataset; and thirdly inverting the poisoned features back to the input space. Our experiments examine such attacks in popular downstream tasks of fine-tuning on the same dataset and transfer learning that considers domain adaptation. Empirical results reveal that transfer learning is more vulnerable to our attacks. Additionally, input space attacks are a strong threat if no countermeasures are posed, but are otherwise weaker than feature targeted attacks. ",
    "url": "https://arxiv.org/abs/2402.12626",
    "authors": [
      "Yiwei Lu",
      "Matthew Y.R. Yang",
      "Gautam Kamath",
      "Yaoliang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12641",
    "title": "YOLO-Ant: A Lightweight Detector via Depthwise Separable Convolutional  and Large Kernel Design for Antenna Interference Source Detection",
    "abstract": "In the era of 5G communication, removing interference sources that affect communication is a resource-intensive task. The rapid development of computer vision has enabled unmanned aerial vehicles to perform various high-altitude detection tasks. Because the field of object detection for antenna interference sources has not been fully explored, this industry lacks dedicated learning samples and detection models for this specific task. In this article, an antenna dataset is created to address important antenna interference source detection issues and serves as the basis for subsequent research. We introduce YOLO-Ant, a lightweight CNN and transformer hybrid detector specifically designed for antenna interference source detection. Specifically, we initially formulated a lightweight design for the network depth and width, ensuring that subsequent investigations were conducted within a lightweight framework. Then, we propose a DSLK-Block module based on depthwise separable convolution and large convolution kernels to enhance the network's feature extraction ability, effectively improving small object detection. To address challenges such as complex backgrounds and large interclass differences in antenna detection, we construct DSLKVit-Block, a powerful feature extraction module that combines DSLK-Block and transformer structures. Considering both its lightweight design and accuracy, our method not only achieves optimal performance on the antenna dataset but also yields competitive results on public datasets. ",
    "url": "https://arxiv.org/abs/2402.12641",
    "authors": [
      "Xiaoyu Tang",
      "Xingming Chen",
      "Jintao Cheng",
      "Jin Wu",
      "Rui Fan",
      "Chengxi Zhang",
      "Zebo Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12642",
    "title": "Rampo: A CEGAR-based Integration of Binary Code Analysis and System  Falsification for Cyber-Kinetic Vulnerability Detection",
    "abstract": "This paper presents a novel tool, named Rampo, that can perform binary code analysis to identify cyber kinetic vulnerabilities in CPS. The tool takes as input a Signal Temporal Logic (STL) formula that describes the kinetic effect, i.e., the behavior of the physical system, that one wants to avoid. The tool then searches the possible cyber trajectories in the binary code that may lead to such physical behavior. This search integrates binary code analysis tools and hybrid systems falsification tools using a Counter-Example Guided Abstraction Refinement (CEGAR) approach. Rampo starts by analyzing the binary code to extract symbolic constraints that represent the different paths in the code. These symbolic constraints are then passed to a Satisfiability Modulo Theories (SMT) solver to extract the range of control signals that can be produced by each path in the code. The next step is to search over possible physical trajectories using a hybrid systems falsification tool that adheres to the behavior of the cyber paths and yet leads to violations of the STL formula. Since the number of cyber paths that need to be explored increases exponentially with the length of physical trajectories, we iteratively perform refinement of the cyber path constraints based on the previous falsification result and traverse the abstract path tree obtained from the control program to explore the search space of the system. To illustrate the practical utility of binary code analysis in identifying cyber kinetic vulnerabilities, we present case studies from diverse CPS domains, showcasing how they can be discovered in their control programs. Our tool could compute the same number of vulnerabilities while leading to a speedup that ranges from 3x to 98x. ",
    "url": "https://arxiv.org/abs/2402.12642",
    "authors": [
      "Kohei Tsujio",
      "Mohammad Abdullah Al Faruque",
      "Yasser Shoukry"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.12646",
    "title": "Training Artificial Neural Networks by Coordinate Search Algorithm",
    "abstract": "Training Artificial Neural Networks poses a challenging and critical problem in machine learning. Despite the effectiveness of gradient-based learning methods, such as Stochastic Gradient Descent (SGD), in training neural networks, they do have several limitations. For instance, they require differentiable activation functions, and cannot optimize a model based on several independent non-differentiable loss functions simultaneously; for example, the F1-score, which is used during testing, can be used during training when a gradient-free optimization algorithm is utilized. Furthermore, the training in any DNN can be possible with a small size of the training dataset. To address these concerns, we propose an efficient version of the gradient-free Coordinate Search (CS) algorithm, an instance of General Pattern Search methods, for training neural networks. The proposed algorithm can be used with non-differentiable activation functions and tailored to multi-objective/multi-loss problems. Finding the optimal values for weights of ANNs is a large-scale optimization problem. Therefore instead of finding the optimal value for each variable, which is the common technique in classical CS, we accelerate optimization and convergence by bundling the weights. In fact, this strategy is a form of dimension reduction for optimization problems. Based on the experimental results, the proposed method, in some cases, outperforms the gradient-based approach, particularly, in situations with insufficient labeled training data. The performance plots demonstrate a high convergence rate, highlighting the capability of our suggested method to find a reasonable solution with fewer function calls. As of now, the only practical and efficient way of training ANNs with hundreds of thousands of weights is gradient-based algorithms such as SGD or Adam. In this paper we introduce an alternative method for training ANN. ",
    "url": "https://arxiv.org/abs/2402.12646",
    "authors": [
      "Ehsan Rokhsatyazdi",
      "Shahryar Rahnamayan",
      "Sevil Zanjani Miyandoab",
      "Azam Asilian Bidgoli",
      "H.R. Tizhoosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12655",
    "title": "Ego Group Partition: A Novel Framework for Improving Ego Experiments in  Social Networks",
    "abstract": "Estimating the average treatment effect in social networks is challenging due to individuals influencing each other. One approach to address interference is ego cluster experiments, where each cluster consists of a central individual (ego) and its peers (alters). Clusters are randomized, and only the effects on egos are measured. In this work, we propose an improved framework for ego cluster experiments called ego group partition (EGP), which directly generates two groups and an ego sub-population instead of ego clusters. Under specific model assumptions, we propose two ego group partition algorithms. Compared to the original ego clustering algorithm, our algorithms produce more egos, yield smaller biases, and support parallel computation. The performance of our algorithms is validated through simulation and real-world case studies. ",
    "url": "https://arxiv.org/abs/2402.12655",
    "authors": [
      "Lu Deng",
      "JingJing Zhang",
      "Yong Wang",
      "Chuan Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2402.12664",
    "title": "Discriminant Distance-Aware Representation on Deterministic Uncertainty  Quantification Methods",
    "abstract": "Uncertainty estimation is a crucial aspect of deploying dependable deep learning models in safety-critical systems. In this study, we introduce a novel and efficient method for deterministic uncertainty estimation called Discriminant Distance-Awareness Representation (DDAR). Our approach involves constructing a DNN model that incorporates a set of prototypes in its latent representations, enabling us to analyze valuable feature information from the input data. By leveraging a distinction maximization layer over optimal trainable prototypes, DDAR can learn a discriminant distance-awareness representation. We demonstrate that DDAR overcomes feature collapse by relaxing the Lipschitz constraint that hinders the practicality of deterministic uncertainty methods (DUMs) architectures. Our experiments show that DDAR is a flexible and architecture-agnostic method that can be easily integrated as a pluggable layer with distance-sensitive metrics, outperforming state-of-the-art uncertainty estimation methods on multiple benchmark problems. ",
    "url": "https://arxiv.org/abs/2402.12664",
    "authors": [
      "Jiaxin Zhang",
      "Kamalika Das",
      "Sricharan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12673",
    "title": "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via  Non-dominated Policies",
    "abstract": "In light of the burgeoning success of reinforcement learning (RL) in diverse real-world applications, considerable focus has been directed towards ensuring RL policies are robust to adversarial attacks during test time. Current approaches largely revolve around solving a minimax problem to prepare for potential worst-case scenarios. While effective against strong attacks, these methods often compromise performance in the absence of attacks or the presence of only weak attacks. To address this, we study policy robustness under the well-accepted state-adversarial attack model, extending our focus beyond only worst-case attacks. We first formalize this task at test time as a regret minimization problem and establish its intrinsic hardness in achieving sublinear regret when the baseline policy is from a general continuous policy class, $\\Pi$. This finding prompts us to \\textit{refine} the baseline policy class $\\Pi$ prior to test time, aiming for efficient adaptation within a finite policy class $\\Tilde{\\Pi}$, which can resort to an adversarial bandit subroutine. In light of the importance of a small, finite $\\Tilde{\\Pi}$, we propose a novel training-time algorithm to iteratively discover \\textit{non-dominated policies}, forming a near-optimal and minimal $\\Tilde{\\Pi}$, thereby ensuring both robustness and test-time efficiency. Empirical validation on the Mujoco corroborates the superiority of our approach in terms of natural and robust performance, as well as adaptability to various attack scenarios. ",
    "url": "https://arxiv.org/abs/2402.12673",
    "authors": [
      "Xiangyu Liu",
      "Chenghao Deng",
      "Yanchao Sun",
      "Yongyuan Liang",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12675",
    "title": "Visual Reasoning in Object-Centric Deep Neural Networks: A Comparative  Cognition Approach",
    "abstract": "Achieving visual reasoning is a long-term goal of artificial intelligence. In the last decade, several studies have applied deep neural networks (DNNs) to the task of learning visual relations from images, with modest results in terms of generalization of the relations learned. However, in recent years, object-centric representation learning has been put forward as a way to achieve visual reasoning within the deep learning framework. Object-centric models attempt to model input scenes as compositions of objects and relations between them. To this end, these models use several kinds of attention mechanisms to segregate the individual objects in a scene from the background and from other objects. In this work we tested relation learning and generalization in several object-centric models, as well as a ResNet-50 baseline. In contrast to previous research, which has focused heavily in the same-different task in order to asses relational reasoning in DNNs, we use a set of tasks -- with varying degrees of difficulty -- derived from the comparative cognition literature. Our results show that object-centric models are able to segregate the different objects in a scene, even in many out-of-distribution cases. In our simpler tasks, this improves their capacity to learn and generalize visual relations in comparison to the ResNet-50 baseline. However, object-centric models still struggle in our more difficult tasks and conditions. We conclude that abstract visual reasoning remains an open challenge for DNNs, including object-centric models. ",
    "url": "https://arxiv.org/abs/2402.12675",
    "authors": [
      "Guillermo Puebla",
      "Jeffrey S. Bowers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12683",
    "title": "TorchCP: A Library for Conformal Prediction based on PyTorch",
    "abstract": "TorchCP is a Python toolbox for conformal prediction research on deep learning models. It contains various implementations for posthoc and training methods for classification and regression tasks (including multi-dimension output). TorchCP is built on PyTorch (Paszke et al., 2019) and leverages the advantages of matrix computation to provide concise and efficient inference implementations. The code is licensed under the LGPL license and is open-sourced at $\\href{https://github.com/ml-stat-Sustech/TorchCP}{\\text{this https URL}}$. ",
    "url": "https://arxiv.org/abs/2402.12683",
    "authors": [
      "Hongxin Wei",
      "Jianguo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2402.12688",
    "title": "Robust-Wide: Robust Watermarking against Instruction-driven Image  Editing",
    "abstract": "Instruction-driven image editing allows users to quickly edit an image according to text instructions in a forward pass. Nevertheless, malicious users can easily exploit this technique to create fake images, which could cause a crisis of trust and harm the rights of the original image owners. Watermarking is a common solution to trace such malicious behavior. Unfortunately, instruction-driven image editing can significantly change the watermarked image at the semantic level, making it less robust and effective. We propose Robust-Wide, the first robust watermarking methodology against instruction-driven image editing. Specifically, we adopt the widely-used encoder-decoder framework for watermark embedding and extraction. To achieve robustness against semantic distortions, we introduce a novel Partial Instruction-driven Denoising Sampling Guidance (PIDSG) module, which consists of a large variety of instruction injections and substantial modifications of images at different semantic levels. With PIDSG, the encoder tends to embed the watermark into more robust and semantic-aware areas, which remains in existence even after severe image editing. Experiments demonstrate that Robust-Wide can effectively extract the watermark from the edited image with a low bit error rate of nearly 2.6% for 64-bit watermark messages. Meanwhile, it only induces a neglectable influence on the visual quality and editability of the original images. Moreover, Robust-Wide holds general robustness against different sampling configurations and other image editing methods such as ControlNet-InstructPix2Pix, MagicBrush, Inpainting and DDIM Inversion. ",
    "url": "https://arxiv.org/abs/2402.12688",
    "authors": [
      "Runyi Hu",
      "Jie Zhang",
      "Tianwei Zhang",
      "Jiwei Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12716",
    "title": "Off-Path TCP Hijacking in Wi-Fi Networks: A Packet-Size Side Channel  Attack",
    "abstract": "In this paper, we unveil a fundamental side channel in Wi-Fi networks, specifically the observable frame size, which can be exploited by attackers to conduct TCP hijacking attacks. Despite the various security mechanisms (e.g., WEP and WPA2/WPA3) implemented to safeguard Wi-Fi networks, our study reveals that an off path attacker can still extract sufficient information from the frame size side channel to hijack the victim's TCP connection. Our side channel attack is based on two significant findings: (i) response packets (e.g., ACK and RST) generated by TCP receivers vary in size, and (ii) the encrypted frames containing these response packets have consistent and distinguishable sizes. By observing the size of the victim's encrypted frames, the attacker can detect and hijack the victim's TCP connections. We validate the effectiveness of this side channel attack through two case studies, i.e., SSH DoS and web traffic manipulation. Furthermore, we conduct extensive measurements to evaluate the impact of our attack on real-world Wi-Fi networks. We test 30 popular wireless routers from 9 well-known vendors, and none of these routers can protect victims from our attack. Also, we implement our attack in 80 real-world Wi-Fi networks and successfully hijack the victim's TCP connections in 69 (86%) evaluated Wi-Fi networks. We have responsibly disclosed the vulnerability to the Wi-Fi Alliance and proposed several mitigation strategies to address this issue. ",
    "url": "https://arxiv.org/abs/2402.12716",
    "authors": [
      "Ziqiang Wang",
      "Xuewei Feng",
      "Qi Li",
      "Kun Sun",
      "Yuxiang Yang",
      "Mengyuan Li",
      "Ke Xu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12720",
    "title": "Revisiting the Information Capacity of Neural Network Watermarks: Upper  Bound Estimation and Beyond",
    "abstract": "To trace the copyright of deep neural networks, an owner can embed its identity information into its model as a watermark. The capacity of the watermark quantify the maximal volume of information that can be verified from the watermarked model. Current studies on capacity focus on the ownership verification accuracy under ordinary removal attacks and fail to capture the relationship between robustness and fidelity. This paper studies the capacity of deep neural network watermarks from an information theoretical perspective. We propose a new definition of deep neural network watermark capacity analogous to channel capacity, analyze its properties, and design an algorithm that yields a tight estimation of its upper bound under adversarial overwriting. We also propose a universal non-invasive method to secure the transmission of the identity message beyond capacity by multiple rounds of ownership verification. Our observations provide evidence for neural network owners and defenders that are curious about the tradeoff between the integrity of their ownership and the performance degradation of their products. ",
    "url": "https://arxiv.org/abs/2402.12720",
    "authors": [
      "Fangqi Li",
      "Haodong Zhao",
      "Wei Du",
      "Shilin Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12721",
    "title": "PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for  Recognizing Low-Quality Images",
    "abstract": "A standard practice in developing image recognition models is to train a model on a specific image resolution and then deploy it. However, in real-world inference, models often encounter images different from the training sets in resolution and/or subject to natural variations such as weather changes, noise types and compression artifacts. While traditional solutions involve training multiple models for different resolutions or input variations, these methods are computationally expensive and thus do not scale in practice. To this end, we propose a novel neural network model, parallel-structured and all-component Fourier neural operator (PAC-FNO), that addresses the problem. Unlike conventional feed-forward neural networks, PAC-FNO operates in the frequency domain, allowing it to handle images of varying resolutions within a single model. We also propose a two-stage algorithm for training PAC-FNO with a minimal modification to the original, downstream model. Moreover, the proposed PAC-FNO is ready to work with existing image recognition models. Extensively evaluating methods with seven image recognition benchmarks, we show that the proposed PAC-FNO improves the performance of existing baseline models on images with various resolutions by up to 77.1% and various types of natural variations in the images at inference. ",
    "url": "https://arxiv.org/abs/2402.12721",
    "authors": [
      "Jinsung Jeon",
      "Hyundong Jin",
      "Jonghyun Choi",
      "Sanghyun Hong",
      "Dongeun Lee",
      "Kookjin Lee",
      "Noseong Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12729",
    "title": "Scalable and reliable deep transfer learning for intelligent fault  detection via multi-scale neural processes embedded with knowledge",
    "abstract": "Deep transfer learning (DTL) is a fundamental method in the field of Intelligent Fault Detection (IFD). It aims to mitigate the degradation of method performance that arises from the discrepancies in data distribution between training set (source domain) and testing set (target domain). Considering the fact that fault data collection is challenging and certain faults are scarce, DTL-based methods face the limitation of available observable data, which reduces the detection performance of the methods in the target domain. Furthermore, DTL-based methods lack comprehensive uncertainty analysis that is essential for building reliable IFD systems. To address the aforementioned problems, this paper proposes a novel DTL-based method known as Neural Processes-based deep transfer learning with graph convolution network (GTNP). Feature-based transfer strategy of GTNP bridges the data distribution discrepancies of source domain and target domain in high-dimensional space. Both the joint modeling based on global and local latent variables and sparse sampling strategy reduce the demand of observable data in the target domain. The multi-scale uncertainty analysis is obtained by using the distribution characteristics of global and local latent variables. Global analysis of uncertainty enables GTNP to provide quantitative values that reflect the complexity of methods and the difficulty of tasks. Local analysis of uncertainty allows GTNP to model uncertainty (confidence of the fault detection result) at each sample affected by noise and bias. The validation of the proposed method is conducted across 3 IFD tasks, consistently showing the superior detection performance of GTNP compared to the other DTL-based methods. ",
    "url": "https://arxiv.org/abs/2402.12729",
    "authors": [
      "Zhongzhi Li",
      "Jingqi Tu",
      "Jiacheng Zhu",
      "Jianliang Ai",
      "Yiqun Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12733",
    "title": "BMLP: Behavior-aware MLP for Heterogeneous Sequential Recommendation",
    "abstract": "In real recommendation scenarios, users often have different types of behaviors, such as clicking and buying. Existing research methods show that it is possible to capture the heterogeneous interests of users through different types of behaviors. However, most multi-behavior approaches have limitations in learning the relationship between different behaviors. In this paper, we propose a novel multilayer perceptron (MLP)-based heterogeneous sequential recommendation method, namely behavior-aware multilayer perceptron (BMLP). Specifically, it has two main modules, including a heterogeneous interest perception (HIP) module, which models behaviors at multiple granularities through behavior types and transition relationships, and a purchase intent perception (PIP) module, which adaptively fuses subsequences of auxiliary behaviors to capture users' purchase intent. Compared with mainstream sequence models, MLP is competitive in terms of accuracy and has unique advantages in simplicity and efficiency. Extensive experiments show that BMLP achieves significant improvement over state-of-the-art algorithms on four public datasets. In addition, its pure MLP architecture leads to a linear time complexity. ",
    "url": "https://arxiv.org/abs/2402.12733",
    "authors": [
      "Weixin Li",
      "Yuhao Wu",
      "Yang Liu",
      "Weike Pan",
      "Zhong Ming"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12754",
    "title": "Fingerprint Presentation Attack Detector Using Global-Local Model",
    "abstract": "The vulnerability of automated fingerprint recognition systems (AFRSs) to presentation attacks (PAs) promotes the vigorous development of PA detection (PAD) technology. However, PAD methods have been limited by information loss and poor generalization ability, resulting in new PA materials and fingerprint sensors. This paper thus proposes a global-local model-based PAD (RTK-PAD) method to overcome those limitations to some extent. The proposed method consists of three modules, called: 1) the global module; 2) the local module; and 3) the rethinking module. By adopting the cut-out-based global module, a global spoofness score predicted from nonlocal features of the entire fingerprint images can be achieved. While by using the texture in-painting-based local module, a local spoofness score predicted from fingerprint patches is obtained. The two modules are not independent but connected through our proposed rethinking module by localizing two discriminative patches for the local module based on the global spoofness score. Finally, the fusion spoofness score by averaging the global and local spoofness scores is used for PAD. Our experimental results evaluated on LivDet 2017 show that the proposed RTK-PAD can achieve an average classification error (ACE) of 2.28% and a true detection rate (TDR) of 91.19% when the false detection rate (FDR) equals 1.0%, which significantly outperformed the state-of-the-art methods by $\\sim$10% in terms of TDR (91.19% versus 80.74%). ",
    "url": "https://arxiv.org/abs/2402.12754",
    "authors": [
      "Haozhe Liu",
      "Wentian Zhang",
      "Feng Liu",
      "Haoqian Wu",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12759",
    "title": "Towards Fair Allocation in Social Commerce Platforms",
    "abstract": "Social commerce platforms are emerging businesses where producers sell products through re-sellers who advertise the products to other customers in their social network. Due to the increasing popularity of this business model, thousands of small producers and re-sellers are starting to depend on these platforms for their livelihood; thus, it is important to provide fair earning opportunities to them. The enormous product space in such platforms prohibits manual search, and motivates the need for recommendation algorithms to effectively allocate product exposure and, consequently, earning opportunities. In this work, we focus on the fairness of such allocations in social commerce platforms and formulate the problem of assigning products to re-sellers as a fair division problem with indivisible items under two-sided cardinality constraints, wherein each product must be given to at least a certain number of re-sellers and each re-seller must get a certain number of products. Our work systematically explores various well-studied benchmarks of fairness -- including Nash social welfare, envy-freeness up to one item (EF1), and equitability up to one item (EQ1) -- from both theoretical and experimental perspectives. We find that the existential and computational guarantees of these concepts known from the unconstrained setting do not extend to our constrained model. To address this limitation, we develop a mixed-integer linear program and other scalable heuristics that provide near-optimal approximation of Nash social welfare in simulated and real social commerce datasets. Overall, our work takes the first step towards achieving provable fairness alongside reasonable revenue guarantees on social commerce platforms. ",
    "url": "https://arxiv.org/abs/2402.12759",
    "authors": [
      "Anjali Gupta",
      "Shreyans J. Nagori",
      "Abhijnan Chakraborty",
      "Rohit Vaish",
      "Sayan Ranu",
      "Prajit Prashant Nadkarni",
      "Narendra Varma Dasararaju",
      "Muthusamy Chelliah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.12761",
    "title": "FGAD: Self-boosted Knowledge Distillation for An Effective Federated  Graph Anomaly Detection Framework",
    "abstract": "Graph anomaly detection (GAD) aims to identify anomalous graphs that significantly deviate from other ones, which has raised growing attention due to the broad existence and complexity of graph-structured data in many real-world scenarios. However, existing GAD methods usually execute with centralized training, which may lead to privacy leakage risk in some sensitive cases, thereby impeding collaboration among organizations seeking to collectively develop robust GAD models. Although federated learning offers a promising solution, the prevalent non-IID problems and high communication costs present significant challenges, particularly pronounced in collaborations with graph data distributed among different participants. To tackle these challenges, we propose an effective federated graph anomaly detection framework (FGAD). We first introduce an anomaly generator to perturb the normal graphs to be anomalous, and train a powerful anomaly detector by distinguishing generated anomalous graphs from normal ones. Then, we leverage a student model to distill knowledge from the trained anomaly detector (teacher model), which aims to maintain the personality of local models and alleviate the adverse impact of non-IID problems. Moreover, we design an effective collaborative learning mechanism that facilitates the personalization preservation of local models and significantly reduces communication costs among clients. Empirical results of the GAD tasks on non-IID graphs compared with state-of-the-art baselines demonstrate the superiority and efficiency of the proposed FGAD method. ",
    "url": "https://arxiv.org/abs/2402.12761",
    "authors": [
      "Jinyu Cai",
      "Yunhe Zhang",
      "Zhoumin Lu",
      "Wenzhong Guo",
      "See-kiong Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12765",
    "title": "GOOD: Towards Domain Generalized Orientated Object Detection",
    "abstract": "Oriented object detection has been rapidly developed in the past few years, but most of these methods assume the training and testing images are under the same statistical distribution, which is far from reality. In this paper, we propose the task of domain generalized oriented object detection, which intends to explore the generalization of oriented object detectors on arbitrary unseen target domains. Learning domain generalized oriented object detectors is particularly challenging, as the cross-domain style variation not only negatively impacts the content representation, but also leads to unreliable orientation predictions. To address these challenges, we propose a generalized oriented object detector (GOOD). After style hallucination by the emerging contrastive language-image pre-training (CLIP), it consists of two key components, namely, rotation-aware content consistency learning (RAC) and style consistency learning (SEC). The proposed RAC allows the oriented object detector to learn stable orientation representation from style-diversified samples. The proposed SEC further stabilizes the generalization ability of content representation from different image styles. Extensive experiments on multiple cross-domain settings show the state-of-the-art performance of GOOD. Source code will be publicly available. ",
    "url": "https://arxiv.org/abs/2402.12765",
    "authors": [
      "Qi Bi",
      "Beichen Zhou",
      "Jingjun Yi",
      "Wei Ji",
      "Haolan Zhan",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12774",
    "title": "Interpreting Conversational Dense Retrieval by Rewriting-Enhanced  Inversion of Session Embedding",
    "abstract": "Conversational dense retrieval has shown to be effective in conversational search. However, a major limitation of conversational dense retrieval is their lack of interpretability, hindering intuitive understanding of model behaviors for targeted improvements. This paper presents CONVINV, a simple yet effective approach to shed light on interpretable conversational dense retrieval models. CONVINV transforms opaque conversational session embeddings into explicitly interpretable text while faithfully maintaining their original retrieval performance as much as possible. Such transformation is achieved by training a recently proposed Vec2Text model based on the ad-hoc query encoder, leveraging the fact that the session and query embeddings share the same space in existing conversational dense retrieval. To further enhance interpretability, we propose to incorporate external interpretable query rewrites into the transformation process. Extensive evaluations on three conversational search benchmarks demonstrate that CONVINV can yield more interpretable text and faithfully preserve original retrieval performance than baselines. Our work connects opaque session embeddings with transparent query rewriting, paving the way toward trustworthy conversational search. ",
    "url": "https://arxiv.org/abs/2402.12774",
    "authors": [
      "Yiruo Cheng",
      "Kelong Mao",
      "Zhicheng Dou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.12777",
    "title": "Application of Quantum Extreme Learning Machines for QoS Prediction of  Elevators' Software in an Industrial Context",
    "abstract": "Quantum Extreme Learning Machine (QELM) is an emerging technique that utilizes quantum dynamics and an easy-training strategy to solve problems such as classification and regression efficiently. Although QELM has many potential benefits, its real-world applications remain limited. To this end, we present QELM's industrial application in the context of elevators, by proposing an approach called QUELL. In QUELL, we use QELM for the waiting time prediction related to the scheduling software of elevators, with applications for software regression testing, elevator digital twins, and real-time performance prediction. The scheduling software has been implemented by our industrial partner Orona, a globally recognized leader in elevator technology. We demonstrate that QUELL can efficiently predict waiting times, with prediction quality significantly better than that of classical ML models employed in a state-of-the-practice approach. Moreover, we show that the prediction quality of QUELL does not degrade when using fewer features. Based on our industrial application, we further provide insights into using QELM in other applications in Orona, and discuss how QELM could be applied to other industrial applications. ",
    "url": "https://arxiv.org/abs/2402.12777",
    "authors": [
      "Xinyi Wang",
      "Shaukat Ali",
      "Aitor Arrieta",
      "Paolo Arcaini",
      "Maite Arratibel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.12782",
    "title": "Advancing GenAI Assisted Programming--A Comparative Study on Prompt  Efficiency and Code Quality Between GPT-4 and GLM-4",
    "abstract": "This study aims to explore the best practices for utilizing GenAI as a programming tool, through a comparative analysis between GPT-4 and GLM-4. By evaluating prompting strategies at different levels of complexity, we identify that simplest and straightforward prompting strategy yields best code generation results. Additionally, adding a CoT-like preliminary confirmation step would further increase the success rate. Our results reveal that while GPT-4 marginally outperforms GLM-4, the difference is minimal for average users. In our simplified evaluation model, we see a remarkable 30 to 100-fold increase in code generation efficiency over traditional coding norms. Our GenAI Coding Workshop highlights the effectiveness and accessibility of the prompting methodology developed in this study. We observe that GenAI-assisted coding would trigger a paradigm shift in programming landscape, which necessitates developers to take on new roles revolving around supervising and guiding GenAI, and to focus more on setting high-level objectives and engaging more towards innovation. ",
    "url": "https://arxiv.org/abs/2402.12782",
    "authors": [
      "Angus Yang",
      "Zehan Li",
      "Jie Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12792",
    "title": "OccFlowNet: Towards Self-supervised Occupancy Estimation via  Differentiable Rendering and Occupancy Flow",
    "abstract": "Semantic occupancy has recently gained significant traction as a prominent 3D scene representation. However, most existing methods rely on large and costly datasets with fine-grained 3D voxel labels for training, which limits their practicality and scalability, increasing the need for self-monitored learning in this domain. In this work, we present a novel approach to occupancy estimation inspired by neural radiance field (NeRF) using only 2D labels, which are considerably easier to acquire. In particular, we employ differentiable volumetric rendering to predict depth and semantic maps and train a 3D network based on 2D supervision only. To enhance geometric accuracy and increase the supervisory signal, we introduce temporal rendering of adjacent time steps. Additionally, we introduce occupancy flow as a mechanism to handle dynamic objects in the scene and ensure their temporal consistency. Through extensive experimentation we demonstrate that 2D supervision only is sufficient to achieve state-of-the-art performance compared to methods using 3D labels, while outperforming concurrent 2D approaches. When combining 2D supervision with 3D labels, temporal rendering and occupancy flow we outperform all previous occupancy estimation models significantly. We conclude that the proposed rendering supervision and occupancy flow advances occupancy estimation and further bridges the gap towards self-supervised learning in this domain. ",
    "url": "https://arxiv.org/abs/2402.12792",
    "authors": [
      "Simon Boeder",
      "Fabian Gigengack",
      "Benjamin Risse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12797",
    "title": "A Geometric Algorithm for Tubular Shape Reconstruction from Skeletal  Representation",
    "abstract": "We introduce a novel approach for the reconstruction of tubular shapes from skeletal representations. Our method processes all skeletal points as a whole, eliminating the need for splitting input structure into multiple segments. We represent the tubular shape as a truncated signed distance function (TSDF) in a voxel hashing manner, in which the signed distance between a voxel center and the object is computed through a simple geometric algorithm. Our method does not involve any surface sampling scheme or solving large matrix equations, and therefore is a faster and more elegant solution for tubular shape reconstruction compared to other approaches. Experiments demonstrate the efficiency and effectiveness of the proposed method. Code is avaliable at https://github.com/wlsdzyzl/Dragon. ",
    "url": "https://arxiv.org/abs/2402.12797",
    "authors": [
      "Guoqing Zhang",
      "Songzi Cat",
      "Juzi Cat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2402.12804",
    "title": "Modular Assurance of Complex Systems Using Contract-Based Design  Principles",
    "abstract": "A growing number of safety-critical industries agree that building confidence in complex systems can be achieved through evidence and structured argumentation framed in assurance cases. Nevertheless, assurance cases can easily become too rigorous and difficult to develop and maintain when applied to complex systems. Therefore, we propose to use contract-based development (CBD), a method to manage complexity originally developed in computer science, to simplify assurance cases by modularizing them. This paper will not only summarize relevant previous work such as constructing consistent modular assurance cases using CBD, but more importantly also propose a novel approach to integrate CBD with the argumentation in assurance case modules. This approach will allow interdisciplinary subject-matter and domain experts to build assurance cases together without even knowing about CBD. This helps subject matter experts outside of computer science to reap benefits from CBD and helps with interdisciplinary co-development of assurance cases that cover all the required fields. This paper motivates four rules of thumb aimed to help practitioners developing high-quality modular assurance cases. It also explains how modularization of assurance is an enabler for multi-concern assurance that accounts for the inter-dependency of different concerns such as safety, security and performance. ",
    "url": "https://arxiv.org/abs/2402.12804",
    "authors": [
      "Dag McGeorge",
      "Jon Arne Glomsrud"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.12810",
    "title": "PIP-Net: Pedestrian Intention Prediction in the Wild",
    "abstract": "Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to enhancement in the model's contextual perception. Depending on the traffic scenario and road environment, the model excels in predicting pedestrian crossing intentions up to 4 seconds in advance which is a breakthrough in current research studies in pedestrian intention prediction. Finally, for the first time, we present the Urban-PIP dataset, a customised pedestrian intention prediction dataset, with multi-camera annotations in real-world automated driving scenarios. ",
    "url": "https://arxiv.org/abs/2402.12810",
    "authors": [
      "Mohsen Azarmi",
      "Mahdi Rezaei",
      "He Wang",
      "Sebastien Glaser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.12813",
    "title": "Scaling Laws Behind Code Understanding Model",
    "abstract": "The scaling law is becoming a fundamental law in many machine learning areas. That is, test error falls off with the power law when increasing training data, model size, and computing resource. However, whether this law is suitable for the task of code understanding is not well studied, and most current language models for code understanding are about 100M parameters, which are relatively \"small\" compared to large language models. In this paper, we conduct extensive experiments to investigate the scaling law for the code understanding task by varying training data, model size, and computing resource. We validate that the test error of code understanding models falls off with the power law when using larger models, indicating that the scaling law is suitable for the code understanding task. Besides, we apply different scales of models to two downstream code understanding tasks, and find that the performance increases with larger scale of models. Finally, we train a large-scale code understanding model named CoLSBERT with 1.5B parameters on a large dataset using more computing resource, which outperforms previous work by a large margin. We will release our code and the CoLSBERT model when our paper is published. ",
    "url": "https://arxiv.org/abs/2402.12813",
    "authors": [
      "Jiayi Lin",
      "Hande Dong",
      "Yutao Xie",
      "Lei Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.12844",
    "title": "ICON: Improving Inter-Report Consistency of Radiology Report Generation  via Lesion-aware Mix-up Augmentation",
    "abstract": "Previous research on radiology report generation has made significant progress in terms of increasing the clinical accuracy of generated reports. In this paper, we emphasize another crucial quality that it should possess, i.e., inter-report consistency, which refers to the capability of generating consistent reports for semantically equivalent radiographs. This quality is even of greater significance than the overall report accuracy in terms of ensuring the system's credibility, as a system prone to providing conflicting results would severely erode users' trust. Regrettably, existing approaches struggle to maintain inter-report consistency, exhibiting biases towards common patterns and susceptibility to lesion variants. To address this issue, we propose ICON, which improves the inter-report consistency of radiology report generation. Aiming at enhancing the system's ability to capture the similarities in semantically equivalent lesions, our approach involves first extracting lesions from input images and examining their characteristics. Then, we introduce a lesion-aware mix-up augmentation technique to ensure that the representations of the semantically equivalent lesions align with the same attributes, by linearly interpolating them during the training phase. Extensive experiments on three publicly available chest X-ray datasets verify the effectiveness of our approach, both in terms of improving the consistency and accuracy of the generated reports. ",
    "url": "https://arxiv.org/abs/2402.12844",
    "authors": [
      "Wenjun Hou",
      "Yi Cheng",
      "Kaishuai Xu",
      "Yan Hu",
      "Wenjie Li",
      "Jiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.12854",
    "title": "Differentiable Mapper For Topological Optimization Of Data  Representation",
    "abstract": "Unsupervised data representation and visualization using tools from topology is an active and growing field of Topological Data Analysis (TDA) and data science. Its most prominent line of work is based on the so-called Mapper graph, which is a combinatorial graph whose topological structures (connected components, branches, loops) are in correspondence with those of the data itself. While highly generic and applicable, its use has been hampered so far by the manual tuning of its many parameters-among these, a crucial one is the so-called filter: it is a continuous function whose variations on the data set are the main ingredient for both building the Mapper representation and assessing the presence and sizes of its topological structures. However, while a few parameter tuning methods have already been investigated for the other Mapper parameters (i.e., resolution, gain, clustering), there is currently no method for tuning the filter itself. In this work, we build on a recently proposed optimization framework incorporating topology to provide the first filter optimization scheme for Mapper graphs. In order to achieve this, we propose a relaxed and more general version of the Mapper graph, whose convergence properties are investigated. Finally, we demonstrate the usefulness of our approach by optimizing Mapper graph representations on several datasets, and showcasing the superiority of the optimized representation over arbitrary ones. ",
    "url": "https://arxiv.org/abs/2402.12854",
    "authors": [
      "Ziyad Oulhaj",
      "Mathieu Carri\u00e8re",
      "Bertrand Michel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2402.12861",
    "title": "Bounding Reconstruction Attack Success of Adversaries Without Data  Priors",
    "abstract": "Reconstruction attacks on machine learning (ML) models pose a strong risk of leakage of sensitive data. In specific contexts, an adversary can (almost) perfectly reconstruct training data samples from a trained model using the model's gradients. When training ML models with differential privacy (DP), formal upper bounds on the success of such reconstruction attacks can be provided. So far, these bounds have been formulated under worst-case assumptions that might not hold high realistic practicality. In this work, we provide formal upper bounds on reconstruction success under realistic adversarial settings against ML models trained with DP and support these bounds with empirical results. With this, we show that in realistic scenarios, (a) the expected reconstruction success can be bounded appropriately in different contexts and by different metrics, which (b) allows for a more educated choice of a privacy parameter. ",
    "url": "https://arxiv.org/abs/2402.12861",
    "authors": [
      "Alexander Ziller",
      "Anneliese Riess",
      "Kristian Schwethelm",
      "Tamara T. Mueller",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12862",
    "title": "Handling Ambiguity in Emotion: From Out-of-Domain Detection to  Distribution Estimation",
    "abstract": "The subjective perception of emotion leads to inconsistent labels from human annotators. Typically, utterances lacking majority-agreed labels are excluded when training an emotion classifier, which cause problems when encountering ambiguous emotional expressions during testing. This paper investigates three methods to handle ambiguous emotion. First, we show that incorporating utterances without majority-agreed labels as an additional class in the classifier reduces the classification performance of the other emotion classes. Then, we propose detecting utterances with ambiguous emotions as out-of-domain samples by quantifying the uncertainty in emotion classification using evidential deep learning. This approach retains the classification accuracy while effectively detects ambiguous emotion expressions. Furthermore, to obtain fine-grained distinctions among ambiguous emotions, we propose representing emotion as a distribution instead of a single class label. The task is thus re-framed from classification to distribution estimation where every individual annotation is taken into account, not just the majority opinion. The evidential uncertainty measure is extended to quantify the uncertainty in emotion distribution estimation. Experimental results on the IEMOCAP and CREMA-D datasets demonstrate the superior capability of the proposed method in terms of majority class prediction, emotion distribution estimation, and uncertainty estimation. ",
    "url": "https://arxiv.org/abs/2402.12862",
    "authors": [
      "Wen Wu",
      "Bo Li",
      "Chao Zhang",
      "Chung-Cheng Chiu",
      "Qiujia Li",
      "Junwen Bai",
      "Tara N. Sainath",
      "Philip C. Woodland"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.12864",
    "title": "A Novel Protocol Using Captive Portals for FIDO2 Network Authentication",
    "abstract": "FIDO2 authentication is starting to be applied in numerous web authentication services, aiming to replace passwords and their known vulnerabilities. However, this new authentication method has not been integrated yet with network authentication systems. In this paper, we introduce FIDO2CAP: FIDO2 Captive-portal Authentication Protocol. Our proposal describes a novel protocol for captive-portal network authentication using FIDO2 authenticators, as security keys and passkeys. For validating our proposal, we have developed a prototype of FIDO2CAP authentication in a mock scenario. Using this prototype, we performed an usability experiment with 15 real users. This work makes the first systematic approach for adapting network authentication to the new authentication paradigm relying on FIDO2 authentication. ",
    "url": "https://arxiv.org/abs/2402.12864",
    "authors": [
      "Marti\u00f1o Rivera-Dourado",
      "Marcos Gestal",
      "Alejandro Pazos",
      "Jose V\u00e1zquez-Naya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.12880",
    "title": "Autism Detection in Speech - A Survey",
    "abstract": "There has been a range of studies of how autism is displayed in voice, speech, and language. We analyse studies from the biomedical, as well as the psychological domain, but also from the NLP domain in order to find linguistic, prosodic and acoustic cues that could indicate autism. Our survey looks at all three domains. We define autism and which comorbidities might influence the correct detection of the disorder. We especially look at observations such as verbal and semantic fluency, prosodic features, but also disfluencies and speaking rate. We also show word-based approaches and describe machine learning and transformer-based approaches both on the audio data as well as the transcripts. Lastly, we conclude, while there already is a lot of research, female patients seem to be severely under-researched. Also, most NLP research focuses on traditional machine learning methods instead of transformers which could be beneficial in this context. Additionally, we were unable to find research combining both features from audio and transcripts. ",
    "url": "https://arxiv.org/abs/2402.12880",
    "authors": [
      "Nadine Probol",
      "Margot Mieskes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.12886",
    "title": "Real-time High-resolution View Synthesis of Complex Scenes with Explicit  3D Visibility Reasoning",
    "abstract": "Rendering photo-realistic novel-view images of complex scenes has been a long-standing challenge in computer graphics. In recent years, great research progress has been made on enhancing rendering quality and accelerating rendering speed in the realm of view synthesis. However, when rendering complex dynamic scenes with sparse views, the rendering quality remains limited due to occlusion problems. Besides, for rendering high-resolution images on dynamic scenes, the rendering speed is still far from real-time. In this work, we propose a generalizable view synthesis method that can render high-resolution novel-view images of complex static and dynamic scenes in real-time from sparse views. To address the occlusion problems arising from the sparsity of input views and the complexity of captured scenes, we introduce an explicit 3D visibility reasoning approach that can efficiently estimate the visibility of sampled 3D points to the input views. The proposed visibility reasoning approach is fully differentiable and can gracefully fit inside the volume rendering pipeline, allowing us to train our networks with only multi-view images as supervision while refining geometry and texture simultaneously. Besides, each module in our pipeline is carefully designed to bypass the time-consuming MLP querying process and enhance the rendering quality of high-resolution images, enabling us to render high-resolution novel-view images in real-time.Experimental results show that our method outperforms previous view synthesis methods in both rendering quality and speed, particularly when dealing with complex dynamic scenes with sparse views. ",
    "url": "https://arxiv.org/abs/2402.12886",
    "authors": [
      "Tiansong Zhou",
      "Yebin Liu",
      "Xuangeng Chu",
      "Chengkun Cao",
      "Changyin Zhou",
      "Fei Yu",
      "Yu Li"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2402.12887",
    "title": "The practice of qualitative parameterisation in the development of  Bayesian networks",
    "abstract": "The typical phases of Bayesian network (BN) structured development include specification of purpose and scope, structure development, parameterisation and validation. Structure development is typically focused on qualitative issues and parameterisation quantitative issues, however there are qualitative and quantitative issues that arise in both phases. A common step that occurs after the initial structure has been developed is to perform a rough parameterisation that only captures and illustrates the intended qualitative behaviour of the model. This is done prior to a more rigorous parameterisation, ensuring that the structure is fit for purpose, as well as supporting later development and validation. In our collective experience and in discussions with other modellers, this step is an important part of the development process, but is under-reported in the literature. Since the practice focuses on qualitative issues, despite being quantitative in nature, we call this step qualitative parameterisation and provide an outline of its role in the BN development process. ",
    "url": "https://arxiv.org/abs/2402.12887",
    "authors": [
      "Steven Mascaro",
      "Owen Woodberry",
      "Yue Wu",
      "Ann E. Nicholson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12889",
    "title": "BFT-DSN: A Byzantine Fault Tolerant Decentralized Storage Network",
    "abstract": "With the rapid development of blockchain and its applications, the amount of data stored on decentralized storage networks (DSNs) has grown exponentially. DSNs bring together affordable storage resources from around the world to provide robust, decentralized storage services for tens of thousands of decentralized applications (dApps). However, existing DSNs do not offer verifiability when implementing erasure coding for redundant storage, making them vulnerable to Byzantine encoders. Additionally, there is a lack of Byzantine fault-tolerant consensus for optimal resilience in DSNs. This paper introduces BFT-DSN, a Byzantine fault-tolerant decentralized storage network designed to address these challenges. BFT-DSN combines storage-weighted BFT consensus with erasure coding and incorporates homomorphic fingerprints and weighted threshold signatures for decentralized verification. The implementation of BFT-DSN demonstrates its comparable performance in terms of storage cost and latency as well as superior performance in Byzantine resilience when compared to existing industrial decentralized storage networks. ",
    "url": "https://arxiv.org/abs/2402.12889",
    "authors": [
      "Hechuan Guo",
      "Minghui Xu",
      "Jiahao Zhang",
      "Chunchi Liu",
      "Rajiv Ranjan",
      "Dongxiao Yu",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12890",
    "title": "More Discriminative Sentence Embeddings via Semantic Graph Smoothing",
    "abstract": "This paper explores an empirical approach to learn more discriminantive sentence representations in an unsupervised fashion. Leveraging semantic graph smoothing, we enhance sentence embeddings obtained from pretrained models to improve results for the text clustering and classification tasks. Our method, validated on eight benchmarks, demonstrates consistent improvements, showcasing the potential of semantic graph smoothing in improving sentence embeddings for the supervised and unsupervised document categorization tasks. ",
    "url": "https://arxiv.org/abs/2402.12890",
    "authors": [
      "Chakib Fettal",
      "Lazhar Labiod",
      "Mohamed Nadif"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12913",
    "title": "OPDAI at SemEval-2024 Task 6: Small LLMs can Accelerate Hallucination  Detection with Weakly Supervised Data",
    "abstract": "This paper mainly describes a unified system for hallucination detection of LLMs, which wins the second prize in the model-agnostic track of the SemEval-2024 Task 6, and also achieves considerable results in the model-aware track. This task aims to detect hallucination with LLMs for three different text-generation tasks without labeled training data. We utilize prompt engineering and few-shot learning to verify the performance of different LLMs on the validation data. Then we select the LLMs with better performance to generate high-quality weakly supervised training data, which not only satisfies the consistency of different LLMs, but also satisfies the consistency of the optimal LLM with different sampling parameters. Furthermore, we finetune different LLMs by using the constructed training data, and finding that a relatively small LLM can achieve a competitive level of performance in hallucination detection, when compared to the large LLMs and the prompt-based approaches using GPT-4. ",
    "url": "https://arxiv.org/abs/2402.12913",
    "authors": [
      "Chengcheng Wei",
      "Ze Chen",
      "Songtan Fang",
      "Jiarong He",
      "Max Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.12914",
    "title": "Large Language Model-based Human-Agent Collaboration for Complex Task  Solving",
    "abstract": "In recent developments within the research community, the integration of Large Language Models (LLMs) in creating fully autonomous agents has garnered significant interest. Despite this, LLM-based agents frequently demonstrate notable shortcomings in adjusting to dynamic environments and fully grasping human needs. In this work, we introduce the problem of LLM-based human-agent collaboration for complex task-solving, exploring their synergistic potential. In addition, we propose a Reinforcement Learning-based Human-Agent Collaboration method, ReHAC. This approach includes a policy model designed to determine the most opportune stages for human intervention within the task-solving process. We construct a human-agent collaboration dataset to train this policy model in an offline reinforcement learning environment. Our validation tests confirm the model's effectiveness. The results demonstrate that the synergistic efforts of humans and LLM-based agents significantly improve performance in complex tasks, primarily through well-planned, limited human intervention. Datasets and code are available at: https://github.com/XueyangFeng/ReHAC. ",
    "url": "https://arxiv.org/abs/2402.12914",
    "authors": [
      "Xueyang Feng",
      "Zhi-Yuan Chen",
      "Yujia Qin",
      "Yankai Lin",
      "Xu Chen",
      "Zhiyuan Liu",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.12923",
    "title": "Advancements in Point Cloud-Based 3D Defect Detection and Classification  for Industrial Systems: A Comprehensive Survey",
    "abstract": "In recent years, 3D point clouds (PCs) have gained significant attention due to their diverse applications across various fields such as computer vision (CV), condition monitoring, virtual reality, robotics, autonomous driving etc. Deep learning (DL) has proven effective in leveraging 3D PCs to address various challenges previously encountered in 2D vision. However, the application of deep neural networks (DNN) to process 3D PCs presents its own set of challenges. To address these challenges, numerous methods have been proposed. This paper provides an in-depth review of recent advancements in DL-based condition monitoring (CM) using 3D PCs, with a specific focus on defect shape classification and segmentation within industrial applications for operational and maintenance purposes. Recognizing the crucial role of these aspects in industrial maintenance, the paper provides insightful observations that offer perspectives on the strengths and limitations of the reviewed DL-based PC processing methods. This synthesis of knowledge aims to contribute to the understanding and enhancement of CM processes, particularly within the framework of remaining useful life (RUL), in industrial systems. ",
    "url": "https://arxiv.org/abs/2402.12923",
    "authors": [
      "Anju Rani",
      "Daniel Ortiz-Arroyo",
      "Petar Durdevic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12927",
    "title": "CLIPping the Deception: Adapting Vision-Language Models for Universal  Deepfake Detection",
    "abstract": "The recent advancements in Generative Adversarial Networks (GANs) and the emergence of Diffusion models have significantly streamlined the production of highly realistic and widely accessible synthetic content. As a result, there is a pressing need for effective general purpose detection mechanisms to mitigate the potential risks posed by deepfakes. In this paper, we explore the effectiveness of pre-trained vision-language models (VLMs) when paired with recent adaptation methods for universal deepfake detection. Following previous studies in this domain, we employ only a single dataset (ProGAN) in order to adapt CLIP for deepfake detection. However, in contrast to prior research, which rely solely on the visual part of CLIP while ignoring its textual component, our analysis reveals that retaining the text part is crucial. Consequently, the simple and lightweight Prompt Tuning based adaptation strategy that we employ outperforms the previous SOTA approach by 5.01% mAP and 6.61% accuracy while utilizing less than one third of the training data (200k images as compared to 720k). To assess the real-world applicability of our proposed models, we conduct a comprehensive evaluation across various scenarios. This involves rigorous testing on images sourced from 21 distinct datasets, including those generated by GANs-based, Diffusion-based and Commercial tools. ",
    "url": "https://arxiv.org/abs/2402.12927",
    "authors": [
      "Sohail Ahmed Khan",
      "Duc-Tien Dang-Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12936",
    "title": "Measuring Impacts of Poisoning on Model Parameters and Neuron  Activations: A Case Study of Poisoning CodeBERT",
    "abstract": "Large language models (LLMs) have revolutionized software development practices, yet concerns about their safety have arisen, particularly regarding hidden backdoors, aka trojans. Backdoor attacks involve the insertion of triggers into training data, allowing attackers to manipulate the behavior of the model maliciously. In this paper, we focus on analyzing the model parameters to detect potential backdoor signals in code models. Specifically, we examine attention weights and biases, activation values, and context embeddings of the clean and poisoned CodeBERT models. Our results suggest noticeable patterns in activation values and context embeddings of poisoned samples for the poisoned CodeBERT model; however, attention weights and biases do not show any significant differences. This work contributes to ongoing efforts in white-box detection of backdoor signals in LLMs of code through the analysis of parameters and activations. ",
    "url": "https://arxiv.org/abs/2402.12936",
    "authors": [
      "Aftab Hussain",
      "Md Rafiqul Islam Rabin",
      "Navid Ayoobi",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.12937",
    "title": "GRAPHGINI: Fostering Individual and Group Fairness in Graph Neural  Networks",
    "abstract": "We address the growing apprehension that GNNs, in the absence of fairness constraints, might produce biased decisions that disproportionately affect underprivileged groups or individuals. Departing from previous work, we introduce for the first time a method for incorporating the Gini coefficient as a measure of fairness to be used within the GNN framework. Our proposal, GRAPHGINI, works with the two different goals of individual and group fairness in a single system, while maintaining high prediction accuracy. GRAPHGINI enforces individual fairness through learnable attention scores that help in aggregating more information through similar nodes. A heuristic-based maximum Nash social welfare constraint ensures the maximum possible group fairness. Both the individual fairness constraint and the group fairness constraint are stated in terms of a differentiable approximation of the Gini coefficient. This approximation is a contribution that is likely to be of interest even beyond the scope of the problem studied in this paper. Unlike other state-of-the-art, GRAPHGINI automatically balances all three optimization objectives (utility, individual, and group fairness) of the GNN and is free from any manual tuning of weight parameters. Extensive experimentation on real-world datasets showcases the efficacy of GRAPHGINI in making significant improvements in individual fairness compared to all currently available state-of-the-art methods while maintaining utility and group equality. ",
    "url": "https://arxiv.org/abs/2402.12937",
    "authors": [
      "Anuj Kumar Sirohi",
      "Anjali Gupta",
      "Sayan Ranu",
      "Sandeep Kumar",
      "Amitabha Bagchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.12946",
    "title": "Cell Graph Transformer for Nuclei Classification",
    "abstract": "Nuclei classification is a critical step in computer-aided diagnosis with histopathology images. In the past, various methods have employed graph neural networks (GNN) to analyze cell graphs that model inter-cell relationships by considering nuclei as vertices. However, they are limited by the GNN mechanism that only passes messages among local nodes via fixed edges. To address the issue, we develop a cell graph transformer (CGT) that treats nodes and edges as input tokens to enable learnable adjacency and information exchange among all nodes. Nevertheless, training the transformer with a cell graph presents another challenge. Poorly initialized features can lead to noisy self-attention scores and inferior convergence, particularly when processing the cell graphs with numerous connections. Thus, we further propose a novel topology-aware pretraining method that leverages a graph convolutional network (GCN) to learn a feature extractor. The pre-trained features may suppress unreasonable correlations and hence ease the finetuning of CGT. Experimental results suggest that the proposed cell graph transformer with topology-aware pretraining significantly improves the nuclei classification results, and achieves the state-of-the-art performance. Code and models are available at https://github.com/lhaof/CGT ",
    "url": "https://arxiv.org/abs/2402.12946",
    "authors": [
      "Wei Lou",
      "Guanbin Li",
      "Xiang Wan",
      "Haofeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12950",
    "title": "QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems",
    "abstract": "Quantum Neural Network (QNN) combines the Deep Learning (DL) principle with the fundamental theory of quantum mechanics to achieve machine learning tasks with quantum acceleration. Recently, QNN systems have been found to manifest robustness issues similar to classical DL systems. There is an urgent need for ways to test their correctness and security. However, QNN systems differ significantly from traditional quantum software and classical DL systems, posing critical challenges for QNN testing. These challenges include the inapplicability of traditional quantum software testing methods, the dependence of quantum test sample generation on perturbation operators, and the absence of effective information in quantum neurons. In this paper, we propose QuanTest, a quantum entanglement-guided adversarial testing framework to uncover potential erroneous behaviors in QNN systems. We design a quantum entanglement adequacy criterion to quantify the entanglement acquired by the input quantum states from the QNN system, along with two similarity metrics to measure the proximity of generated quantum adversarial examples to the original inputs. Subsequently, QuanTest formulates the problem of generating test inputs that maximize the quantum entanglement sufficiency and capture incorrect behaviors of the QNN system as a joint optimization problem and solves it in a gradient-based manner to generate quantum adversarial examples. Experimental results demonstrate that QuanTest possesses the capability to capture erroneous behaviors in QNN systems (generating 67.48%-96.05% more test samples than the random noise under the same perturbation size constraints). The entanglement-guided approach proves effective in adversarial testing, generating more adversarial examples (maximum increase reached 21.32%). ",
    "url": "https://arxiv.org/abs/2402.12950",
    "authors": [
      "Jinjing Shi",
      "Zimeng Xiao",
      "Heyuan Shi",
      "Yu Jiang",
      "Xuelong Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12954",
    "title": "Conditional Logical Message Passing Transformer for Complex Query  Answering",
    "abstract": "Complex Query Answering (CQA) over Knowledge Graphs (KGs) is a challenging task. Given that KGs are usually incomplete, neural models are proposed to solve CQA by performing multi-hop logical reasoning. However, most of them cannot perform well on both one-hop and multi-hop queries simultaneously. Recent work proposes a logical message passing mechanism based on the pre-trained neural link predictors. While effective on both one-hop and multi-hop queries, it ignores the difference between the constant and variable nodes in a query graph. In addition, during the node embedding update stage, this mechanism cannot dynamically measure the importance of different messages, and whether it can capture the implicit logical dependencies related to a node and received messages remains unclear. In this paper, we propose Conditional Logical Message Passing Transformer (CLMPT), which considers the difference between constants and variables in the case of using pre-trained neural link predictors and performs message passing conditionally on the node type. We empirically verified that this approach can reduce computational costs without affecting performance. Furthermore, CLMPT uses the transformer to aggregate received messages and update the corresponding node embedding. Through the self-attention mechanism, CLMPT can assign adaptive weights to elements in an input set consisting of received messages and the corresponding node and explicitly model logical dependencies between various elements. Experimental results show that CLMPT is a new state-of-the-art neural CQA model. ",
    "url": "https://arxiv.org/abs/2402.12954",
    "authors": [
      "Chongzhi Zhang",
      "Zhiping Peng",
      "Junhao Zheng",
      "Qianli Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2402.12959",
    "title": "Prompt Stealing Attacks Against Large Language Models",
    "abstract": "The increasing reliance on large language models (LLMs) such as ChatGPT in various fields emphasizes the importance of ``prompt engineering,'' a technology to improve the quality of model outputs. With companies investing significantly in expert prompt engineers and educational resources rising to meet market demand, designing high-quality prompts has become an intriguing challenge. In this paper, we propose a novel attack against LLMs, named prompt stealing attacks. Our proposed prompt stealing attack aims to steal these well-designed prompts based on the generated answers. The prompt stealing attack contains two primary modules: the parameter extractor and the prompt reconstruction. The goal of the parameter extractor is to figure out the properties of the original prompts. We first observe that most prompts fall into one of three categories: direct prompt, role-based prompt, and in-context prompt. Our parameter extractor first tries to distinguish the type of prompts based on the generated answers. Then, it can further predict which role or how many contexts are used based on the types of prompts. Following the parameter extractor, the prompt reconstructor can be used to reconstruct the original prompts based on the generated answers and the extracted features. The final goal of the prompt reconstructor is to generate the reversed prompts, which are similar to the original prompts. Our experimental results show the remarkable performance of our proposed attacks. Our proposed attacks add a new dimension to the study of prompt engineering and call for more attention to the security issues on LLMs. ",
    "url": "https://arxiv.org/abs/2402.12959",
    "authors": [
      "Zeyang Sha",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.12967",
    "title": "Quantifying Privacy via Information Density",
    "abstract": "We examine the relationship between privacy metrics that utilize information density to measure information leakage between a private and a disclosed random variable. Firstly, we prove that bounding the information density from above or below in turn implies a lower or upper bound on the information density, respectively. Using this result, we establish new relationships between local information privacy, asymmetric local information privacy, pointwise maximal leakage and local differential privacy. We further provide applications of these relations to privacy mechanism design. Furthermore, we provide statements showing the equivalence between a lower bound on information density and risk-averse adversaries. More specifically, we prove an equivalence between a guessing framework and a cost-function framework that result in the desired lower bound on the information density. ",
    "url": "https://arxiv.org/abs/2402.12967",
    "authors": [
      "Leonhard Grosse",
      "Sara Saeidian",
      "Parastoo Sadeghi",
      "Tobias J. Oechtering",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12984",
    "title": "Can GNN be Good Adapter for LLMs?",
    "abstract": "Recently, large language models (LLMs) have demonstrated superior capabilities in understanding and zero-shot learning on textual data, promising significant advances for many text-related domains. In the graph domain, various real-world scenarios also involve textual data, where tasks and node features can be described by text. These text-attributed graphs (TAGs) have broad applications in social media, recommendation systems, etc. Thus, this paper explores how to utilize LLMs to model TAGs. Previous methods for TAG modeling are based on million-scale LMs. When scaled up to billion-scale LLMs, they face huge challenges in computational costs. Additionally, they also ignore the zero-shot inference capabilities of LLMs. Therefore, we propose GraphAdapter, which uses a graph neural network (GNN) as an efficient adapter in collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN adapter introduces only a few trainable parameters and can be trained with low computation costs. The entire framework is trained using auto-regression on node text (next token prediction). Once trained, GraphAdapter can be seamlessly fine-tuned with task-specific prompts for various downstream tasks. Through extensive experiments across multiple real-world TAGs, GraphAdapter based on Llama 2 gains an average improvement of approximately 5\\% in terms of node classification. Furthermore, GraphAdapter can also adapt to other language models, including RoBERTa, GPT-2. The promising results demonstrate that GNNs can serve as effective adapters for LLMs in TAG modeling. ",
    "url": "https://arxiv.org/abs/2402.12984",
    "authors": [
      "Xuanwen Huang",
      "Kaiqiao Han",
      "Yang Yang",
      "Dezheng Bao",
      "Quanjin Tao",
      "Ziwei Chai",
      "Qi Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12987",
    "title": "Towards Robust Graph Incremental Learning on Evolving Graphs",
    "abstract": "Incremental learning is a machine learning approach that involves training a model on a sequence of tasks, rather than all tasks at once. This ability to learn incrementally from a stream of tasks is crucial for many real-world applications. However, incremental learning is a challenging problem on graph-structured data, as many graph-related problems involve prediction tasks for each individual node, known as Node-wise Graph Incremental Learning (NGIL). This introduces non-independent and non-identically distributed characteristics in the sample data generation process, making it difficult to maintain the performance of the model as new tasks are added. In this paper, we focus on the inductive NGIL problem, which accounts for the evolution of graph structure (structural shift) induced by emerging tasks. We provide a formal formulation and analysis of the problem, and propose a novel regularization-based technique called Structural-Shift-Risk-Mitigation (SSRM) to mitigate the impact of the structural shift on catastrophic forgetting of the inductive NGIL problem. We show that the structural shift can lead to a shift in the input distribution for the existing tasks, and further lead to an increased risk of catastrophic forgetting. Through comprehensive empirical studies with several benchmark datasets, we demonstrate that our proposed method, Structural-Shift-Risk-Mitigation (SSRM), is flexible and easy to adapt to improve the performance of state-of-the-art GNN incremental learning frameworks in the inductive setting. ",
    "url": "https://arxiv.org/abs/2402.12987",
    "authors": [
      "Junwei Su",
      "Difan Zou",
      "Zijun Zhang",
      "Chuan Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12991",
    "title": "TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box  Identification",
    "abstract": "Large Language Model (LLM) services and models often come with legal rules on who can use them and how they must use them. Assessing the compliance of the released LLMs is crucial, as these rules protect the interests of the LLM contributor and prevent misuse. In this context, we describe the novel problem of Black-box Identity Verification (BBIV). The goal is to determine whether a third-party application uses a certain LLM through its chat function. We propose a method called Targeted Random Adversarial Prompt (TRAP) that identifies the specific LLM in use. We repurpose adversarial suffixes, originally proposed for jailbreaking, to get a pre-defined answer from the target LLM, while other models give random answers. TRAP detects the target LLMs with over 95% true positive rate at under 0.2% false positive rate even after a single interaction. TRAP remains effective even if the LLM has minor changes that do not significantly alter the original function. ",
    "url": "https://arxiv.org/abs/2402.12991",
    "authors": [
      "Martin Gubri",
      "Dennis Ulmer",
      "Hwaran Lee",
      "Sangdoo Yun",
      "Seong Joon Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12993",
    "title": "An Autonomous Large Language Model Agent for Chemical Literature Data  Mining",
    "abstract": "Chemical synthesis, which is crucial for advancing material synthesis and drug discovery, impacts various sectors including environmental science and healthcare. The rise of technology in chemistry has generated extensive chemical data, challenging researchers to discern patterns and refine synthesis processes. Artificial intelligence (AI) helps by analyzing data to optimize synthesis and increase yields. However, AI faces challenges in processing literature data due to the unstructured format and diverse writing style of chemical literature. To overcome these difficulties, we introduce an end-to-end AI agent framework capable of high-fidelity extraction from extensive chemical literature. This AI agent employs large language models (LLMs) for prompt generation and iterative optimization. It functions as a chemistry assistant, automating data collection and analysis, thereby saving manpower and enhancing performance. Our framework's efficacy is evaluated using accuracy, recall, and F1 score of reaction condition data, and we compared our method with human experts in terms of content correctness and time efficiency. The proposed approach marks a significant advancement in automating chemical literature extraction and demonstrates the potential for AI to revolutionize data management and utilization in chemistry. ",
    "url": "https://arxiv.org/abs/2402.12993",
    "authors": [
      "Kexin Chen",
      "Hanqun Cao",
      "Junyou Li",
      "Yuyang Du",
      "Menghao Guo",
      "Xin Zeng",
      "Lanqing Li",
      "Jiezhong Qiu",
      "Pheng Ann Heng",
      "Guangyong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2402.12994",
    "title": "Distributionally Robust Graph-based Recommendation System",
    "abstract": "With the capacity to capture high-order collaborative signals, Graph Neural Networks (GNNs) have emerged as powerful methods in Recommender Systems (RS). However, their efficacy often hinges on the assumption that training and testing data share the same distribution (a.k.a. IID assumption), and exhibits significant declines under distribution shifts. Distribution shifts commonly arises in RS, often attributed to the dynamic nature of user preferences or ubiquitous biases during data collection in RS. Despite its significance, researches on GNN-based recommendation against distribution shift are still sparse. To bridge this gap, we propose Distributionally Robust GNN (DR-GNN) that incorporates Distributional Robust Optimization (DRO) into the GNN-based recommendation. DR-GNN addresses two core challenges: 1) To enable DRO to cater to graph data intertwined with GNN, we reinterpret GNN as a graph smoothing regularizer, thereby facilitating the nuanced application of DRO; 2) Given the typically sparse nature of recommendation data, which might impede robust optimization, we introduce slight perturbations in the training distribution to expand its support. Notably, while DR-GNN involves complex optimization, it can be implemented easily and efficiently. Our extensive experiments validate the effectiveness of DR-GNN against three typical distribution shifts. The code is available at https://github.com/WANGBohaO-jpg/DR-GNN . ",
    "url": "https://arxiv.org/abs/2402.12994",
    "authors": [
      "Bohao Wang",
      "Jiawei Chen",
      "Changdong Li",
      "Sheng Zhou",
      "Qihao Shi",
      "Yang Gao",
      "Yan Feng",
      "Chun Chen",
      "Can Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.13013",
    "title": "Code Needs Comments: Enhancing Code LLMs with Comment Augmentation",
    "abstract": "The programming skill is one crucial ability for Large Language Models (LLMs), necessitating a deep understanding of programming languages (PLs) and their correlation with natural languages (NLs). We examine the impact of pre-training data on code-focused LLMs' performance by assessing the comment density as a measure of PL-NL alignment. Given the scarcity of code-comment aligned data in pre-training corpora, we introduce a novel data augmentation method that generates comments for existing code, coupled with a data filtering strategy that filters out code data poorly correlated with natural language. We conducted experiments on three code-focused LLMs and observed consistent improvements in performance on two widely-used programming skill benchmarks. Notably, the model trained on the augmented data outperformed both the model used for generating comments and the model further trained on the data without augmentation. ",
    "url": "https://arxiv.org/abs/2402.13013",
    "authors": [
      "Demin Song",
      "Honglin Guo",
      "Yunhua Zhou",
      "Shuhao Xing",
      "Yudong Wang",
      "Zifan Song",
      "Wenwei Zhang",
      "Qipeng Guo",
      "Hang Yan",
      "Xipeng Qiu",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13022",
    "title": "SoMeLVLM: A Large Vision Language Model for Social Media Processing",
    "abstract": "The growth of social media, characterized by its multimodal nature, has led to the emergence of diverse phenomena and challenges, which calls for an effective approach to uniformly solve automated tasks. The powerful Large Vision Language Models make it possible to handle a variety of tasks simultaneously, but even with carefully designed prompting methods, the general domain models often fall short in aligning with the unique speaking style and context of social media tasks. In this paper, we introduce a Large Vision Language Model for Social Media Processing (SoMeLVLM), which is a cognitive framework equipped with five key capabilities including knowledge & comprehension, application, analysis, evaluation, and creation. SoMeLVLM is designed to understand and generate realistic social media behavior. We have developed a 654k multimodal social media instruction-tuning dataset to support our cognitive framework and fine-tune our model. Our experiments demonstrate that SoMeLVLM achieves state-of-the-art performance in multiple social media tasks. Further analysis shows its significant advantages over baselines in terms of cognitive abilities. ",
    "url": "https://arxiv.org/abs/2402.13022",
    "authors": [
      "Xinnong Zhang",
      "Haoyu Kuang",
      "Xinyi Mou",
      "Hanjia Lyu",
      "Kun Wu",
      "Siming Chen",
      "Jiebo Luo",
      "Xuanjing Huang",
      "Zhongyu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.13028",
    "title": "Heterogeneous Graph Reasoning for Fact Checking over Texts and Tables",
    "abstract": "Fact checking aims to predict claim veracity by reasoning over multiple evidence pieces. It usually involves evidence retrieval and veracity reasoning. In this paper, we focus on the latter, reasoning over unstructured text and structured table information. Previous works have primarily relied on fine-tuning pretrained language models or training homogeneous-graph-based models. Despite their effectiveness, we argue that they fail to explore the rich semantic information underlying the evidence with different structures. To address this, we propose a novel word-level Heterogeneous-graph-based model for Fact Checking over unstructured and structured information, namely HeterFC. Our approach leverages a heterogeneous evidence graph, with words as nodes and thoughtfully designed edges representing different evidence properties. We perform information propagation via a relational graph neural network, facilitating interactions between claims and evidence. An attention-based method is utilized to integrate information, combined with a language model for generating predictions. We introduce a multitask loss function to account for potential inaccuracies in evidence retrieval. Comprehensive experiments on the large fact checking dataset FEVEROUS demonstrate the effectiveness of HeterFC. Code will be released at: https://github.com/Deno-V/HeterFC. ",
    "url": "https://arxiv.org/abs/2402.13028",
    "authors": [
      "Haisong Gong",
      "Weizhi Xu",
      "Shu wu",
      "Qiang Liu",
      "Liang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13033",
    "title": "Enhancing Real-World Complex Network Representations with Hyperedge  Augmentation",
    "abstract": "Graph augmentation methods play a crucial role in improving the performance and enhancing generalisation capabilities in Graph Neural Networks (GNNs). Existing graph augmentation methods mainly perturb the graph structures and are usually limited to pairwise node relations. These methods cannot fully address the complexities of real-world large-scale networks that often involve higher-order node relations beyond only being pairwise. Meanwhile, real-world graph datasets are predominantly modelled as simple graphs, due to the scarcity of data that can be used to form higher-order edges. Therefore, reconfiguring the higher-order edges as an integration into graph augmentation strategies lights up a promising research path to address the aforementioned issues. In this paper, we present Hyperedge Augmentation (HyperAug), a novel graph augmentation method that constructs virtual hyperedges directly form the raw data, and produces auxiliary node features by extracting from the virtual hyperedge information, which are used for enhancing GNN performances on downstream tasks. We design three diverse virtual hyperedge construction strategies to accompany the augmentation scheme: (1) via graph statistics, (2) from multiple data perspectives, and (3) utilising multi-modality. Furthermore, to facilitate HyperAug evaluation, we provide 23 novel real-world graph datasets across various domains including social media, biology, and e-commerce. Our empirical study shows that HyperAug consistently and significantly outperforms GNN baselines and other graph augmentation methods, across a variety of application contexts, which clearly indicates that it can effectively incorporate higher-order node relations into graph augmentation methods for real-world complex networks. ",
    "url": "https://arxiv.org/abs/2402.13033",
    "authors": [
      "Xiangyu Zhao",
      "Zehui Li",
      "Mingzhu Shen",
      "Guy-Bart Stan",
      "Pietro Li\u00f2",
      "Yiren Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.13038",
    "title": "N-MPC for Deep Neural Network-Based Collision Avoidance exploiting Depth  Images",
    "abstract": "This paper introduces a Nonlinear Model Predictive Control (N-MPC) framework exploiting a Deep Neural Network for processing onboard-captured depth images for collision avoidance in trajectory-tracking tasks with UAVs. The network is trained on simulated depth images to output a collision score for queried 3D points within the sensor field of view. Then, this network is translated into an algebraic symbolic equation and included in the N-MPC, explicitly constraining predicted positions to be collision-free throughout the receding horizon. The N-MPC achieves real time control of a UAV with a control frequency of 100Hz. The proposed framework is validated through statistical analysis of the collision classifier network, as well as Gazebo simulations and real experiments to assess the resulting capabilities of the N-MPC to effectively avoid collisions in cluttered environments. The associated code is released open-source along with the training images. ",
    "url": "https://arxiv.org/abs/2402.13038",
    "authors": [
      "Martin Jacquet",
      "Kostas Alexis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.13045",
    "title": "A Recurrent Neural Network Enhanced Unscented Kalman Filter for Human  Motion Prediction",
    "abstract": "This paper presents a deep learning enhanced adaptive unscented Kalman filter (UKF) for predicting human arm motion in the context of manufacturing. Unlike previous network-based methods that solely rely on captured human motion data, which is represented as bone vectors in this paper, we incorporate a human arm dynamic model into the motion prediction algorithm and use the UKF to iteratively forecast human arm motions. Specifically, a Lagrangian-mechanics-based physical model is employed to correlate arm motions with associated muscle forces. Then a Recurrent Neural Network (RNN) is integrated into the framework to predict future muscle forces, which are transferred back to future arm motions based on the dynamic model. Given the absence of measurement data for future human motions that can be input into the UKF to update the state, we integrate another RNN to directly predict human future motions and treat the prediction as surrogate measurement data fed into the UKF. A noteworthy aspect of this study involves the quantification of uncertainties associated with both the data-driven and physical models in one unified framework. These quantified uncertainties are used to dynamically adapt the measurement and process noises of the UKF over time. This adaption, driven by the uncertainties of the RNN models, addresses inaccuracies stemming from the data-driven model and mitigates discrepancies between the assumed and true physical models, ultimately enhancing the accuracy and robustness of our predictions. Compared to the traditional RNN-based prediction, our method demonstrates improved accuracy and robustness in extensive experimental validations of various types of human motions. ",
    "url": "https://arxiv.org/abs/2402.13045",
    "authors": [
      "Wansong Liu",
      "Sibo Tian",
      "Boyi Hu",
      "Xiao Liang",
      "Minghui Zheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.13058",
    "title": "Random Graph Set and Evidence Pattern Reasoning Model",
    "abstract": "Evidence theory is widely used in decision-making and reasoning systems. In previous research, Transferable Belief Model (TBM) is a commonly used evidential decision making model, but TBM is a non-preference model. In order to better fit the decision making goals, the Evidence Pattern Reasoning Model (EPRM) is proposed. By defining pattern operators and decision making operators, corresponding preferences can be set for different tasks. Random Permutation Set (RPS) expands order information for evidence theory. It is hard for RPS to characterize the complex relationship between samples such as cycling, paralleling relationships. Therefore, Random Graph Set (RGS) were proposed to model complex relationships and represent more event types. In order to illustrate the significance of RGS and EPRM, an experiment of aircraft velocity ranking was designed and 10,000 cases were simulated. The implementation of EPRM called Conflict Resolution Decision optimized 18.17\\% of the cases compared to Mean Velocity Decision, effectively improving the aircraft velocity ranking. EPRM provides a unified solution for evidence-based decision making. ",
    "url": "https://arxiv.org/abs/2402.13058",
    "authors": [
      "Tianxiang Zhan",
      "Zhen Li",
      "Yong Deng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13065",
    "title": "Scalable Pattern Matching in Computation Graphs",
    "abstract": "Graph rewriting is a popular tool for the optimisation and modification of graph expressions in domains such as compilers, machine learning and quantum computing. The underlying data structures are often port graphs - graphs with labels at edge endpoints. These port labels greatly simplify pattern matching. A pre-requisite for graph rewriting is the ability to find subgraphs of the input that match known graph identities: the pattern matching problem. We propose a new solution to pattern matching in port graphs. Its novelty lies in the use of a pre-computed data structure that makes the pattern matching runtime complexity independent of the number of patterns. The runtime is bound by the maximum width $w$ and depth $d$ of the patterns, as well as the input graph size $|G|$ as $O(|G| \\cdot c^w / w^{1/2} \\cdot d)$ with $c = 6.75$. This offers a significant advantage over existing solutions for use cases where patterns have low width and the set of patterns is large and fixed ahead of time. In the context of quantum circuits, pattern width can be limited to qubit number. Quantum superoptimisers may use thousands of rewrite rules on circuits with less than 5 qubits, making them an ideal use case. We provide benchmarks showing that our algorithm offers a 20x speedup over current implementations on a dataset of 10'000 real world patterns describing quantum circuits. ",
    "url": "https://arxiv.org/abs/2402.13065",
    "authors": [
      "Luca Mondada",
      "Pablo Andr\u00e9s-Mart\u00ednez"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2402.13077",
    "title": "Mechanistic Neural Networks for Scientific Machine Learning",
    "abstract": "This paper presents Mechanistic Neural Networks, a neural network design for machine learning applications in the sciences. It incorporates a new Mechanistic Block in standard architectures to explicitly learn governing differential equations as representations, revealing the underlying dynamics of data and enhancing interpretability and efficiency in data modeling. Central to our approach is a novel Relaxed Linear Programming Solver (NeuRLP) inspired by a technique that reduces solving linear ODEs to solving linear programs. This integrates well with neural networks and surpasses the limitations of traditional ODE solvers enabling scalable GPU parallel processing. Overall, Mechanistic Neural Networks demonstrate their versatility for scientific machine learning applications, adeptly managing tasks from equation discovery to dynamic systems modeling. We prove their comprehensive capabilities in analyzing and interpreting complex scientific data across various applications, showing significant performance against specialized state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2402.13077",
    "authors": [
      "Adeel Pervez",
      "Francesco Locatello",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.13081",
    "title": "IT Intrusion Detection Using Statistical Learning and Testbed  Measurements",
    "abstract": "We study automated intrusion detection in an IT infrastructure, specifically the problem of identifying the start of an attack, the type of attack, and the sequence of actions an attacker takes, based on continuous measurements from the infrastructure. We apply statistical learning methods, including Hidden Markov Model (HMM), Long Short-Term Memory (LSTM), and Random Forest Classifier (RFC) to map sequences of observations to sequences of predicted attack actions. In contrast to most related research, we have abundant data to train the models and evaluate their predictive power. The data comes from traces we generate on an in-house testbed where we run attacks against an emulated IT infrastructure. Central to our work is a machine-learning pipeline that maps measurements from a high-dimensional observation space to a space of low dimensionality or to a small set of observation symbols. Investigating intrusions in offline as well as online scenarios, we find that both HMM and LSTM can be effective in predicting attack start time, attack type, and attack actions. If sufficient training data is available, LSTM achieves higher prediction accuracy than HMM. HMM, on the other hand, requires less computational resources and less training data for effective prediction. Also, we find that the methods we study benefit from data produced by traditional intrusion detection systems like SNORT. ",
    "url": "https://arxiv.org/abs/2402.13081",
    "authors": [
      "Xiaoxuan Wang",
      "Rolf Stadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.13092",
    "title": "Contractivity of neural ODEs: an eigenvalue optimization problem",
    "abstract": "We propose a novel methodology to solve a key eigenvalue optimization problem which arises in the contractivity analysis of neural ODEs. When looking at contractivity properties of a one layer weight-tied neural ODE $\\dot{u}(t)=\\sigma(Au(t)+b)$ (with $u,b \\in {\\mathbb R}^n$, $A$ is a given $n \\times n$ matrix, $\\sigma : {\\mathbb R} \\to {\\mathbb R}^+$ denotes an activation function and for a vector $z \\in {\\mathbb R}^n$, $\\sigma(z) \\in {\\mathbb R}^n$ has to be interpreted entry-wise), we are led to study the logarithmic norm of a set of products of type $D A$, where $D$ is a diagonal matrix such that ${\\mathrm{diag}}(D) \\in \\sigma'({\\mathbb R}^n)$. Specifically, given a real number $c$ (usually $c=0$), the problem consists in finding the largest positive interval $\\chi\\subseteq \\mathbb [0,\\infty)$ such that the logarithmic norm $\\mu(DA) \\le c$ for all diagonal matrices $D$ with $D_{ii}\\in \\chi$. We propose a two-level nested methodology: an inner level where, for a given $\\chi$, we compute an optimizer $D^\\star(\\chi)$ by a gradient system approach, and an outer level where we tune $\\chi$ so that the value $c$ is reached by $\\mu(D^\\star(\\chi)A)$. We extend the proposed two-level approach to the general multilayer, and possibly time-dependent, case $\\dot{u}(t) = \\sigma( A_k(t) \\ldots \\sigma ( A_{1}(t) u(t) + b_{1}(t) ) \\ldots + b_{k}(t) )$ and we propose several numerical examples to illustrate its behaviour, including its stabilizing performance on a one-layer neural ODE applied to the classification of the MNIST handwritten digits dataset. ",
    "url": "https://arxiv.org/abs/2402.13092",
    "authors": [
      "Nicola Guglielmi",
      "Arturo De Marinis",
      "Anton Savastianov",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.13096",
    "title": "A Lightweight Machine Learning Approach for Delay-Aware Cell-Switching  in 6G HAPS Networks",
    "abstract": "This study investigates the integration of a high altitude platform station (HAPS), a non-terrestrial network (NTN) node, into the cell-switching paradigm for energy saving. By doing so, the sustainability and ubiquitous connectivity targets can be achieved. Besides, a delay-aware approach is also adopted, where the delay profiles of users are respected in such a way that we attempt to meet the latency requirements of users with a best-effort strategy. To this end, a novel, simple, and lightweight Q-learning algorithm is designed to address the cell-switching optimization problem. During the simulation campaigns, different interference scenarios and delay situations between base stations are examined in terms of energy consumption and quality-of-service (QoS), and the results confirm the efficacy of the proposed Q-learning algorithm. ",
    "url": "https://arxiv.org/abs/2402.13096",
    "authors": [
      "G\u00f6rkem Berkay Ko\u00e7",
      "Berk \u00c7ilo\u011flu",
      "Metin Ozturk",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.13101",
    "title": "A Microstructure-based Graph Neural Network for Accelerating Multiscale  Simulations",
    "abstract": "Simulating the mechanical response of advanced materials can be done more accurately using concurrent multiscale models than with single-scale simulations. However, the computational costs stand in the way of the practical application of this approach. The costs originate from microscale Finite Element (FE) models that must be solved at every macroscopic integration point. A plethora of surrogate modeling strategies attempt to alleviate this cost by learning to predict macroscopic stresses from macroscopic strains, completely replacing the microscale models. In this work, we introduce an alternative surrogate modeling strategy that allows for keeping the multiscale nature of the problem, allowing it to be used interchangeably with an FE solver for any time step. Our surrogate provides all microscopic quantities, which are then homogenized to obtain macroscopic quantities of interest. We achieve this for an elasto-plastic material by predicting full-field microscopic strains using a graph neural network (GNN) while retaining the microscopic constitutive material model to obtain the stresses. This hybrid data-physics graph-based approach avoids the high dimensionality originating from predicting full-field responses while allowing non-locality to arise. By training the GNN on a variety of meshes, it learns to generalize to unseen meshes, allowing a single model to be used for a range of microstructures. The embedded microscopic constitutive model in the GNN implicitly tracks history-dependent variables and leads to improved accuracy. We demonstrate for several challenging scenarios that the surrogate can predict complex macroscopic stress-strain paths. As the computation time of our method scales favorably with the number of elements in the microstructure compared to the FE method, our method can significantly accelerate FE2 simulations. ",
    "url": "https://arxiv.org/abs/2402.13101",
    "authors": [
      "J. Storm",
      "I. B. C. M. Rocha",
      "F. P. van der Meer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.13132",
    "title": "Electric Field Evaluation of Reconfigurable Intelligent Surface in  Wireless Networks",
    "abstract": "Reconfigurable intelligent surface (RIS) used as infrastructure in wireless networks has been a trend, thanks to its low cost and high flexibility. Working in many ways including reflective mirrors and phase-shifted surfaces, RIS is able to enhance the coverage in communications and provide more degrees of freedom for sensing. However, the key issue lies in how to place RIS in accordance with the regulations for electromagnetic field (EMF) exposure, which requires refined evaluations. In this paper, we first investigate the regulations in terms of E-field. Then, relevant deployment characteristics are evaluated jointly: the minimum distance from the base station (BS) to the RIS, and the minimum height of the RIS are given for a given BS power limit and as function of the number of RIS elements. The ray-tracing simulations verify the correctness of our analysis. Besides, different frequency ranges (FRs) and radiation patterns of RIS elements are investigated. The results show that the EMF exposure risk is negligible when RIS works in the reflective-only (RO) mode. However, when it works in the beamforming (BO) mode, its placement should be well specified based on our analytical framework to comply with the regulations of E-field limit in general public scenarios. Finally, we provide an E-field measurement methodology and low-cost solutions in terms of general wireless networks and 5G standalone networks, which pave the way for real-world evaluation in future work. ",
    "url": "https://arxiv.org/abs/2402.13132",
    "authors": [
      "Zhuangzhuang Cui",
      "Franco Minucci",
      "Rizqi Hersyandika",
      "Rodney Martinez Alonso",
      "Andrea P. Guevara",
      "Hazem Sallouha",
      "Sofie Pollin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.13144",
    "title": "Neural Network Diffusion",
    "abstract": "Diffusion models have achieved remarkable success in image and video generation. In this work, we demonstrate that diffusion models can also \\textit{generate high-performing neural network parameters}. Our approach is simple, utilizing an autoencoder and a standard latent diffusion model. The autoencoder extracts latent representations of a subset of the trained network parameters. A diffusion model is then trained to synthesize these latent parameter representations from random noise. It then generates new representations that are passed through the autoencoder's decoder, whose outputs are ready to use as new subsets of network parameters. Across various architectures and datasets, our diffusion process consistently generates models of comparable or improved performance over trained networks, with minimal additional cost. Notably, we empirically find that the generated models perform differently with the trained networks. Our results encourage more exploration on the versatile use of diffusion models. ",
    "url": "https://arxiv.org/abs/2402.13144",
    "authors": [
      "Kai Wang",
      "Zhaopan Xu",
      "Yukun Zhou",
      "Zelin Zang",
      "Trevor Darrell",
      "Zhuang Liu",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13148",
    "title": "Defending Jailbreak Prompts via In-Context Adversarial Game",
    "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities across diverse applications. However, concerns regarding their security, particularly the vulnerability to jailbreak attacks, persist. Drawing inspiration from adversarial training in deep learning and LLM agent learning processes, we introduce the In-Context Adversarial Game (ICAG) for defending against jailbreaks without the need for fine-tuning. ICAG leverages agent learning to conduct an adversarial game, aiming to dynamically extend knowledge to defend against jailbreaks. Unlike traditional methods that rely on static datasets, ICAG employs an iterative process to enhance both the defense and attack agents. This continuous improvement process strengthens defenses against newly generated jailbreak prompts. Our empirical studies affirm ICAG's efficacy, where LLMs safeguarded by ICAG exhibit significantly reduced jailbreak success rates across various attack scenarios. Moreover, ICAG demonstrates remarkable transferability to other LLMs, indicating its potential as a versatile defense mechanism. ",
    "url": "https://arxiv.org/abs/2402.13148",
    "authors": [
      "Yujun Zhou",
      "Yufei Han",
      "Haomin Zhuang",
      "Taicheng Guo",
      "Kehan Guo",
      "Zhenwen Liang",
      "Hongyan Bao",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.13153",
    "title": "Clustered Planarity Variants for Level Graphs",
    "abstract": "We consider variants of the clustered planarity problem for level-planar drawings. So far, only convex clusters have been studied in this setting. We introduce two new variants that both insist on a level-planar drawing of the input graph but relax the requirements on the shape of the clusters. In unrestricted Clustered Level Planarity (uCLP) we only require that they are bounded by simple closed curves that enclose exactly the vertices of the cluster and cross each edge of the graph at most once. The problem y-monotone Clustered Level Planarity (y-CLP) requires that additionally it must be possible to augment each cluster with edges that do not cross the cluster boundaries so that it becomes connected while the graph remains level-planar, thereby mimicking a classic characterization of clustered planarity in the level-planar setting. We give a polynomial-time algorithm for uCLP if the input graph is biconnected and has a single source. By contrast, we show that y-CLP is hard under the same restrictions and it remains NP-hard even if the number of levels is bounded by a constant and there is only a single non-trivial cluster. ",
    "url": "https://arxiv.org/abs/2402.13153",
    "authors": [
      "Simon D. Fink",
      "Matthias Pfretzschner",
      "Ignaz Rutter",
      "Marie Diana Sieper"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.13159",
    "title": "Barking dogs: A Fr\u00e9chet distance variant for detour detection",
    "abstract": "Imagine you are a dog behind a fence $Q$ and a hiker is passing by at constant speed along the hiking path $P$. In order to fulfil your duties as a watchdog, you desire to bark as long as possible at the human. However, your barks can only be heard in a fixed radius $\\rho$ and, as a dog, you have bounded speed $s$. Can you optimize your route along the fence $Q$ in order to maximize the barking time with radius $\\rho$, assuming you can run backwards and forward at speed at most $s$? We define the barking distance from a polyline $P$ on $n$ vertices to a polyline $Q$ on $m$ vertices as the time that the hiker stays in your barking radius if you run optimally along $Q$. This asymmetric similarity measure between two curves can be used to detect outliers in $Q$ compared to $P$ that other established measures like the Fr\\'echet distance and Dynamic Time Warping fail to capture at times. We consider this measure in three different settings. In the discrete setting, the traversals of $P$ and $Q$ are both discrete. For this case we show that the barking distance from $P$ to $Q$ can be computed in $O(nm\\log s)$ time. In the semi-discrete setting, the traversal of $Q$ is continuous while the one of $P$ is again discrete. Here, we show how to compute the barking distance in time $O(nm\\log (nm))$. Finally, in the continuous setting in which both traversals are continuous, we show that the problem can be solved in polynomial time. For all the settings we show that, assuming SETH, no truly subquadratic algorithm can exist. ",
    "url": "https://arxiv.org/abs/2402.13159",
    "authors": [
      "Ivor van der Hoog",
      "Fabian Klute",
      "Irene Parada",
      "Patrick Schnider"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2402.13183",
    "title": "Robust Model Predictive Control for nonlinear discrete-time systems  using iterative time-varying constraint tightening",
    "abstract": "Robust Model Predictive Control (MPC) for nonlinear systems is a problem that poses significant challenges as highlighted by the diversity of approaches proposed in the last decades. Often compromises with respect to computational load, conservatism, generality, or implementation complexity have to be made, and finding an approach that provides the right balance is still a challenge to the research community. This work provides a contribution by proposing a novel shrinking-horizon robust MPC formulation for nonlinear discrete-time systems. By explicitly accounting for how disturbances and linearization errors are propagated through the nonlinear dynamics, a constraint tightening-based formulation is obtained, with guarantees of robust constraint satisfaction. The proposed controller relies on iteratively solving a Nonlinear Program (NLP) to simultaneously optimize system operation and the required constraint tightening. Numerical experiments show the effectiveness of the proposed controller with three different choices of NLP solvers as well as significantly improved computational speed, better scalability, and generally reduced conservatism when compared to an existing technique from the literature. ",
    "url": "https://arxiv.org/abs/2402.13183",
    "authors": [
      "Daniel D. Leister",
      "Justin P. Koeln"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.13204",
    "title": "SONATA: Self-adaptive Evolutionary Framework for Hardware-aware Neural  Architecture Search",
    "abstract": "Recent advancements in Artificial Intelligence (AI), driven by Neural Networks (NN), demand innovative neural architecture designs, particularly within the constrained environments of Internet of Things (IoT) systems, to balance performance and efficiency. HW-aware Neural Architecture Search (HW-aware NAS) emerges as an attractive strategy to automate the design of NN using multi-objective optimization approaches, such as evolutionary algorithms. However, the intricate relationship between NN design parameters and HW-aware NAS optimization objectives remains an underexplored research area, overlooking opportunities to effectively leverage this knowledge to guide the search process accordingly. Furthermore, the large amount of evaluation data produced during the search holds untapped potential for refining the optimization strategy and improving the approximation of the Pareto front. Addressing these issues, we propose SONATA, a self-adaptive evolutionary algorithm for HW-aware NAS. Our method leverages adaptive evolutionary operators guided by the learned importance of NN design parameters. Specifically, through tree-based surrogate models and a Reinforcement Learning agent, we aspire to gather knowledge on 'How' and 'When' to evolve NN architectures. Comprehensive evaluations across various NAS search spaces and hardware devices on the ImageNet-1k dataset have shown the merit of SONATA with up to 0.25% improvement in accuracy and up to 2.42x gains in latency and energy. Our SONATA has seen up to sim$93.6% Pareto dominance over the native NSGA-II, further stipulating the importance of self-adaptive evolution operators in HW-aware NAS. ",
    "url": "https://arxiv.org/abs/2402.13204",
    "authors": [
      "Halima Bouzidi",
      "Smail Niar",
      "Hamza Ouarnoughi",
      "El-Ghazali Talbi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13221",
    "title": "CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset  for Advancing Graph Machine Learning",
    "abstract": "Advances in graph machine learning (ML) have been driven by applications in chemistry as graphs have remained the most expressive representations of molecules. While early graph ML methods focused primarily on small organic molecules, recently, the scope of graph ML has expanded to include inorganic materials. Modelling the periodicity and symmetry of inorganic crystalline materials poses unique challenges, which existing graph ML methods are unable to address. Moving to inorganic nanomaterials increases complexity as the scale of number of nodes within each graph can be broad ($10$ to $10^5$). The bulk of existing graph ML focuses on characterising molecules and materials by predicting target properties with graphs as input. However, the most exciting applications of graph ML will be in their generative capabilities, which is currently not at par with other domains such as images or text. We invite the graph ML community to address these open challenges by presenting two new chemically-informed large-scale inorganic (CHILI) nanomaterials datasets: A medium-scale dataset (with overall >6M nodes, >49M edges) of mono-metallic oxide nanomaterials generated from 12 selected crystal types (CHILI-3K) and a large-scale dataset (with overall >183M nodes, >1.2B edges) of nanomaterials generated from experimentally determined crystal structures (CHILI-100K). We define 11 property prediction tasks and 6 structure prediction tasks, which are of special interest for nanomaterial research. We benchmark the performance of a wide array of baseline methods and use these benchmarking results to highlight areas which need future work. To the best of our knowledge, CHILI-3K and CHILI-100K are the first open-source nanomaterial datasets of this scale -- both on the individual graph level and of the dataset as a whole -- and the only nanomaterials datasets with high structural and elemental diversity. ",
    "url": "https://arxiv.org/abs/2402.13221",
    "authors": [
      "Ulrik Friis-Jensen",
      "Frederik L. Johansen",
      "Andy S. Anker",
      "Erik B. Dam",
      "Kirsten M. \u00d8. Jensen",
      "Raghavendra Selvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.13222",
    "title": "RoCode: A Dataset for Measuring Code Intelligence from Problem  Definitions in Romanian",
    "abstract": "Recently, large language models (LLMs) have become increasingly powerful and have become capable of solving a plethora of tasks through proper instructions in natural language. However, the vast majority of testing suites assume that the instructions are written in English, the de facto prompting language. Code intelligence and problem solving still remain a difficult task, even for the most advanced LLMs. Currently, there are no datasets to measure the generalization power for code-generation models in a language other than English. In this work, we present RoCode, a competitive programming dataset, consisting of 2,642 problems written in Romanian, 11k solutions in C, C++ and Python and comprehensive testing suites for each problem. The purpose of RoCode is to provide a benchmark for evaluating the code intelligence of language models trained on Romanian / multilingual text as well as a fine-tuning set for pretrained Romanian models. Through our results and review of related works, we argue for the need to develop code models for languages other than English. ",
    "url": "https://arxiv.org/abs/2402.13222",
    "authors": [
      "Adrian Cosma",
      "Bogdan Iordache",
      "Paolo Rosso"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13225",
    "title": "AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale  Clinical Tool Learning",
    "abstract": "Clinical calculators play a vital role in healthcare by offering accurate evidence-based predictions for various purposes such as prognosis. Nevertheless, their widespread utilization is frequently hindered by usability challenges, poor dissemination, and restricted functionality. Augmenting large language models with extensive collections of clinical calculators presents an opportunity to overcome these obstacles and improve workflow efficiency, but the scalability of the manual curation process poses a significant challenge. In response, we introduce AgentMD, a novel language agent capable of curating and applying clinical calculators across various clinical contexts. Using the published literature, AgentMD has automatically curated a collection of 2,164 diverse clinical calculators with executable functions and structured documentation, collectively named RiskCalcs. Manual evaluations show that RiskCalcs tools achieve an accuracy of over 80% on three quality metrics. At inference time, AgentMD can automatically select and apply the relevant RiskCalcs tools given any patient description. On the newly established RiskQA benchmark, AgentMD significantly outperforms chain-of-thought prompting with GPT-4 (87.7% vs. 40.9% in accuracy). Additionally, we also applied AgentMD to real-world clinical notes for analyzing both population-level and risk-level patient characteristics. In summary, our study illustrates the utility of language agents augmented with clinical calculators for healthcare analytics and patient care. ",
    "url": "https://arxiv.org/abs/2402.13225",
    "authors": [
      "Qiao Jin",
      "Zhizheng Wang",
      "Yifan Yang",
      "Qingqing Zhu",
      "Donald Wright",
      "Thomas Huang",
      "W John Wilbur",
      "Zhe He",
      "Andrew Taylor",
      "Qingyu Chen",
      "Zhiyong Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13241",
    "title": "Federated Causal Discovery from Heterogeneous Data",
    "abstract": "Conventional causal discovery methods rely on centralized data, which is inconsistent with the decentralized nature of data in many real-world situations. This discrepancy has motivated the development of federated causal discovery (FCD) approaches. However, existing FCD methods may be limited by their potentially restrictive assumptions of identifiable functional causal models or homogeneous data distributions, narrowing their applicability in diverse scenarios. In this paper, we propose a novel FCD method attempting to accommodate arbitrary causal models and heterogeneous data. We first utilize a surrogate variable corresponding to the client index to account for the data heterogeneity across different clients. We then develop a federated conditional independence test (FCIT) for causal skeleton discovery and establish a federated independent change principle (FICP) to determine causal directions. These approaches involve constructing summary statistics as a proxy of the raw data to protect data privacy. Owing to the nonparametric properties, FCIT and FICP make no assumption about particular functional forms, thereby facilitating the handling of arbitrary causal models. We conduct extensive experiments on synthetic and real datasets to show the efficacy of our method. The code is available at \\url{https://github.com/lokali/FedCDH.git}. ",
    "url": "https://arxiv.org/abs/2402.13241",
    "authors": [
      "Loka Li",
      "Ignavier Ng",
      "Gongxu Luo",
      "Biwei Huang",
      "Guangyi Chen",
      "Tongliang Liu",
      "Bin Gu",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13252",
    "title": "Improving Robustness for Joint Optimization of Camera Poses and  Decomposed Low-Rank Tensorial Radiance Fields",
    "abstract": "In this paper, we propose an algorithm that allows joint refinement of camera pose and scene geometry represented by decomposed low-rank tensor, using only 2D images as supervision. First, we conduct a pilot study based on a 1D signal and relate our findings to 3D scenarios, where the naive joint pose optimization on voxel-based NeRFs can easily lead to sub-optimal solutions. Moreover, based on the analysis of the frequency spectrum, we propose to apply convolutional Gaussian filters on 2D and 3D radiance fields for a coarse-to-fine training schedule that enables joint camera pose optimization. Leveraging the decomposition property in decomposed low-rank tensor, our method achieves an equivalent effect to brute-force 3D convolution with only incurring little computational overhead. To further improve the robustness and stability of joint optimization, we also propose techniques of smoothed 2D supervision, randomly scaled kernel parameters, and edge-guided loss mask. Extensive quantitative and qualitative evaluations demonstrate that our proposed framework achieves superior performance in novel view synthesis as well as rapid convergence for optimization. ",
    "url": "https://arxiv.org/abs/2402.13252",
    "authors": [
      "Bo-Yu Cheng",
      "Wei-Chen Chiu",
      "Yu-Lun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.10649",
    "title": "Hermite Neural Network Simulation for Solving the 2D Schrodinger  Equation",
    "abstract": "The Schrodinger equation is a mathematical equation describing the wave function's behavior in a quantum-mechanical system. It is a partial differential equation that provides valuable insights into the fundamental principles of quantum mechanics. In this paper, the aim was to solve the Schrodinger equation with sufficient accuracy by using a mixture of neural networks with the collocation method base Hermite functions. Initially, the Hermite functions roots were employed as collocation points, enhancing the efficiency of the solution. The Schrodinger equation is defined in an infinite domain, the use of Hermite functions as activation functions resulted in excellent precision. Finally, the proposed method was simulated using MATLAB's Simulink tool. The results were then compared with those obtained using Physics-informed neural networks and the presented method. ",
    "url": "https://arxiv.org/abs/2402.10649",
    "authors": [
      "Kourosh Parand",
      "Aida Pakniyat"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2402.12397",
    "title": "Multi-class Temporal Logic Neural Networks",
    "abstract": "Time-series data can represent the behaviors of autonomous systems, such as drones and self-driving cars. The problem of binary and multi-class classification has received a lot of attention in this field. Neural networks represent a popular approach to classifying data; However, they lack interpretability, which poses a significant challenge in extracting meaningful information from them. Signal Temporal Logic (STL) is a formalism to describe the properties of timed behaviors. We propose a method that combines all of the above: neural networks that represent STL specifications for multi-class classification of time-series data. We offer two key contributions: 1) We introduce a notion of margin for multi-class classification, and 2) we introduce the use of STL-based attributes for enhancing the interpretability of the results. We evaluate our method on two datasets and compare with state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2402.12397",
    "authors": [
      "Danyang Li",
      "Roberto Tron"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12435",
    "title": "Emulating the interstellar medium chemistry with neural operators",
    "abstract": "Galaxy formation and evolution critically depend on understanding the complex photo-chemical processes that govern the evolution and thermodynamics of the InterStellar Medium (ISM). Computationally, solving chemistry is among the most heavy tasks in cosmological and astrophysical simulations. The evolution of such non-equilibrium photo-chemical network relies on implicit, precise, computationally costly, ordinary differential equations (ODE) solvers. Here, we aim at substituting such procedural solvers with fast, pre-trained, emulators based on neural operators. We emulate a non-equilibrium chemical network up to H$_2$ formation (9 species, 52 reactions) by adopting the DeepONet formalism, i.e. by splitting the ODE solver operator that maps the initial conditions and time evolution into a tensor product of two neural networks. We use $\\texttt{KROME}$ to generate a training set spanning $-2\\leq \\log(n/\\mathrm{cm}^{-3}) \\leq 3.5$, $\\log(20) \\leq\\log(T/\\mathrm{K}) \\leq 5.5$, $-6 \\leq \\log(n_i/n) < 0$, and by adopting an incident radiation field $\\textbf{F}$ sampled in 10 energy bins with a continuity prior. We separately train the solver for $T$ and each $n_i$ for $\\simeq 4.34\\,\\rm GPUhrs$. Compared with the reference solutions obtained by $\\texttt{KROME}$ for single zone models, the typical precision obtained is of order $10^{-2}$, i.e. the $10 \\times$ better with a training that is $40 \\times$ less costly with respect to previous emulators which however considered only a fixed $\\mathbf{F}$. The present model achieves a speed-up of a factor of $128 \\times$ with respect to stiff ODE solvers. Our neural emulator represents a significant leap forward in the modeling of ISM chemistry, offering a good balance of precision, versatility, and computational efficiency. ",
    "url": "https://arxiv.org/abs/2402.12435",
    "authors": [
      "Lorenzo Branca",
      "Andrea Pallottini"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12565",
    "title": "A Simple Detection and Identification Scheme For Reconfigurable  Intelligent Surfaces",
    "abstract": "Reconfigurable intelligent surface (RIS)-empowered communication is one of the promising physical layer enabling technologies for the sixth generation (6G) wireless networks due to their unprecedented capabilities in shaping the wireless communication environment. RISs are modeled as passive objects that can not transmit or receive wireless signals. While the passiveness of these surfaces is a key advantage in terms of power consumption and implementation complexity, it limits their capability to interact with the other active components in the network. Specifically, unlike conventional base stations (BSs), which actively identify themselves to user equipment (UEs) by periodically sending pilot signals, RISs need to be detected from the UE side. This paper proposes a novel RIS identification (RIS- ID) scheme, enabling UEs to detect and uniquely identify RISs in their surrounding environment. Furthermore, to assess the proposed RIS-ID scheme, we propose two performance metrics: the false and miss detection probabilities. These probabilities are analytically derived and verified through computer simulations, revealing the effectiveness of the proposed RIS-ID scheme under different operating scenarios. ",
    "url": "https://arxiv.org/abs/2402.12565",
    "authors": [
      "Aymen Khaleel",
      "Recep Vural",
      "Mehmet Cagri Ilter",
      "Majid Gerami",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.12589",
    "title": "On The Fourier Coefficients of High-Dimensional Random Geometric Graphs",
    "abstract": "The random geometric graph $\\mathsf{RGG}(n,\\mathbb{S}^{d-1}, p)$ is formed by sampling $n$ i.i.d. vectors $\\{V_i\\}_{i = 1}^n$ uniformly on $\\mathbb{S}^{d-1}$ and placing an edge between pairs of vertices $i$ and $j$ for which $\\langle V_i,V_j\\rangle \\ge \\tau^p_d,$ where $\\tau^p_d$ is such that the expected density is $p.$ We study the low-degree Fourier coefficients of the distribution $\\mathsf{RGG}(n,\\mathbb{S}^{d-1}, p)$ and its Gaussian analogue. Our main conceptual contribution is a novel two-step strategy for bounding Fourier coefficients which we believe is more widely applicable to studying latent space distributions. First, we localize the dependence among edges to few fragile edges. Second, we partition the space of latent vector configurations $(\\mathsf{RGG}(n,\\mathbb{S}^{d-1}, p))^{\\otimes n}$ based on the set of fragile edges and on each subset of configurations, we define a noise operator acting independently on edges not incident (in an appropriate sense) to fragile edges. We apply the resulting bounds to: 1) Settle the low-degree polynomial complexity of distinguishing spherical and Gaussian random geometric graphs from Erdos-Renyi both in the case of observing a complete set of edges and in the non-adaptively chosen mask $\\mathcal{M}$ model recently introduced by [MVW24]; 2) Exhibit a statistical-computational gap for distinguishing $\\mathsf{RGG}$ and the planted coloring model [KVWX23] in a regime when $\\mathsf{RGG}$ is distinguishable from Erdos-Renyi; 3) Reprove known bounds on the second eigenvalue of random geometric graphs. ",
    "url": "https://arxiv.org/abs/2402.12589",
    "authors": [
      "Kiril Bangachev",
      "Guy Bresler"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2402.12595",
    "title": "Truncated Polynomial Expansion-Based Detection in Massive MIMO: A  Model-Driven Deep Learning Approach",
    "abstract": "In this paper, we propose a deep learning (DL)-based approach for efficiently computing the inverse of Hermitian matrices using truncated polynomial expansion (TPE). Our model-driven approach involves optimizing the coefficients of the TPE during an offline training procedure for a given number of TPE terms. We apply this method to signal detection in uplink massive multiple-input multiple-output (MIMO) systems, where the matrix inverse operation required by linear detectors, such as zero-forcing (ZF) and minimum mean square error (MMSE), is approximated using TPE. Our simulation results demonstrate that the proposed learned TPE-based method outperforms the conventional TPE method with optimal coefficients in terms of asymptotic convergence speed and reduces the computational complexity of the online detection stage, albeit at the expense of the offline training stage. However, the limited number of trainable parameters leads to a swift offline training process. ",
    "url": "https://arxiv.org/abs/2402.12595",
    "authors": [
      "Kazem Izadinasab",
      "Ahmed Wagdy Shaban",
      "Oussama Damen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12701",
    "title": "wmh_seg: Transformer based U-Net for Robust and Automatic White Matter  Hyperintensity Segmentation across 1.5T, 3T and 7T",
    "abstract": "White matter hyperintensity (WMH) remains the top imaging biomarker for neurodegenerative diseases. Robust and accurate segmentation of WMH holds paramount significance for neuroimaging studies. The growing shift from 3T to 7T MRI necessitates robust tools for harmonized segmentation across field strengths and artifacts. Recent deep learning models exhibit promise in WMH segmentation but still face challenges, including diverse training data representation and limited analysis of MRI artifacts' impact. To address these, we introduce wmh_seg, a novel deep learning model leveraging a transformer-based encoder from SegFormer. wmh_seg is trained on an unmatched dataset, including 1.5T, 3T, and 7T FLAIR images from various sources, alongside with artificially added MR artifacts. Our approach bridges gaps in training diversity and artifact analysis. Our model demonstrated stable performance across magnetic field strengths, scanner manufacturers, and common MR imaging artifacts. Despite the unique inhomogeneity artifacts on ultra-high field MR images, our model still offers robust and stable segmentation on 7T FLAIR images. Our model, to date, is the first that offers quality white matter lesion segmentation on 7T FLAIR images. ",
    "url": "https://arxiv.org/abs/2402.12701",
    "authors": [
      "Jinghang Li",
      "Tales Santini",
      "Yuanzhe Huang",
      "Joseph M. Mettenburg",
      "Tamer S. Ibrahima",
      "Howard J. Aizensteina",
      "Minjie Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12704",
    "title": "Quantum Embedding with Transformer for High-dimensional Data",
    "abstract": "Quantum embedding with transformers is a novel and promising architecture for quantum machine learning to deliver exceptional capability on near-term devices or simulators. The research incorporated a vision transformer (ViT) to advance quantum significantly embedding ability and results for a single qubit classifier with around 3 percent in the median F1 score on the BirdCLEF-2021, a challenging high-dimensional dataset. The study showcases and analyzes empirical evidence that our transformer-based architecture is a highly versatile and practical approach to modern quantum machine learning problems. ",
    "url": "https://arxiv.org/abs/2402.12704",
    "authors": [
      "Hao-Yuan Chen",
      "Yen-Jui Chang",
      "Shih-Wei Liao",
      "Ching-Ray Chang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12710",
    "title": "Integrating Active Learning in Causal Inference with Interference: A  Novel Approach in Online Experiments",
    "abstract": "In the domain of causal inference research, the prevalent potential outcomes framework, notably the Rubin Causal Model (RCM), often overlooks individual interference and assumes independent treatment effects. This assumption, however, is frequently misaligned with the intricate realities of real-world scenarios, where interference is not merely a possibility but a common occurrence. Our research endeavors to address this discrepancy by focusing on the estimation of direct and spillover treatment effects under two assumptions: (1) network-based interference, where treatments on neighbors within connected networks affect one's outcomes, and (2) non-random treatment assignments influenced by confounders. To improve the efficiency of estimating potentially complex effects functions, we introduce an novel active learning approach: Active Learning in Causal Inference with Interference (ACI). This approach uses Gaussian process to flexibly model the direct and spillover treatment effects as a function of a continuous measure of neighbors' treatment assignment. The ACI framework sequentially identifies the experimental settings that demand further data. It further optimizes the treatment assignments under the network interference structure using genetic algorithms to achieve efficient learning outcome. By applying our method to simulation data and a Tencent game dataset, we demonstrate its feasibility in achieving accurate effects estimations with reduced data requirements. This ACI approach marks a significant advancement in the realm of data efficiency for causal inference, offering a robust and efficient alternative to traditional methodologies, particularly in scenarios characterized by complex interference patterns. ",
    "url": "https://arxiv.org/abs/2402.12710",
    "authors": [
      "Hongtao Zhu",
      "Sizhe Zhang",
      "Yang Su",
      "Zhenyu Zhao",
      "Nan Chen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.12746",
    "title": "Plugin Speech Enhancement: A Universal Speech Enhancement Framework  Inspired by Dynamic Neural Network",
    "abstract": "The expectation to deploy a universal neural network for speech enhancement, with the aim of improving noise robustness across diverse speech processing tasks, faces challenges due to the existing lack of awareness within static speech enhancement frameworks regarding the expected speech in downstream modules. These limitations impede the effectiveness of static speech enhancement approaches in achieving optimal performance for a range of speech processing tasks, thereby challenging the notion of universal applicability. The fundamental issue in achieving universal speech enhancement lies in effectively informing the speech enhancement module about the features of downstream modules. In this study, we present a novel weighting prediction approach, which explicitly learns the task relationships from downstream training information to address the core challenge of universal speech enhancement. We found the role of deciding whether to employ data augmentation techniques as crucial downstream training information. This decision significantly impacts the expected speech and the performance of the speech enhancement module. Moreover, we introduce a novel speech enhancement network, the Plugin Speech Enhancement (Plugin-SE). The Plugin-SE is a dynamic neural network that includes the speech enhancement module, gate module, and weight prediction module. Experimental results demonstrate that the proposed Plugin-SE approach is competitive or superior to other joint training methods across various downstream tasks. ",
    "url": "https://arxiv.org/abs/2402.12746",
    "authors": [
      "Yanan Chen",
      "Zihao Cui",
      "Yingying Gao",
      "Junlan Feng",
      "Chao Deng",
      "Shilei Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.12971",
    "title": "How Temporal Unrolling Supports Neural Physics Simulators",
    "abstract": "Unrolling training trajectories over time strongly influences the inference accuracy of neural network-augmented physics simulators. We analyze these effects by studying three variants of training neural networks on discrete ground truth trajectories. In addition to commonly used one-step setups and fully differentiable unrolling, we include a third, less widely used variant: unrolling without temporal gradients. Comparing networks trained with these three modalities makes it possible to disentangle the two dominant effects of unrolling, training distribution shift and long-term gradients. We present a detailed study across physical systems, network sizes, network architectures, training setups, and test scenarios. It provides an empirical basis for our main findings: A non-differentiable but unrolled training setup supported by a numerical solver can yield 4.5-fold improvements over a fully differentiable prediction setup that does not utilize this solver. We also quantify a difference in the accuracy of models trained in a fully differentiable setup compared to their non-differentiable counterparts. While differentiable setups perform best, the accuracy of unrolling without temporal gradients comes comparatively close. Furthermore, we empirically show that these behaviors are invariant to changes in the underlying physical system, the network architecture and size, and the numerical scheme. These results motivate integrating non-differentiable numerical simulators into training setups even if full differentiability is unavailable. We also observe that the convergence rate of common neural architectures is low compared to numerical algorithms. This encourages the use of hybrid approaches combining neural and numerical algorithms to utilize the benefits of both. ",
    "url": "https://arxiv.org/abs/2402.12971",
    "authors": [
      "Bjoern List",
      "Li-Wei Chen",
      "Kartik Bali",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13001",
    "title": "A unifying primary framework for quantum graph neural networks from  quantum graph states",
    "abstract": "Graph states are used to represent mathematical graphs as quantum states on quantum computers. They can be formulated through stabilizer codes or directly quantum gates and quantum states. In this paper we show that a quantum graph neural network model can be understood and realized based on graph states. We show that they can be used either as a parameterized quantum circuits to represent neural networks or as an underlying structure to construct graph neural networks on quantum computers. ",
    "url": "https://arxiv.org/abs/2402.13001",
    "authors": [
      "Ammar Daskin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13005",
    "title": "SzCORE: A Seizure Community Open-source Research Evaluation framework  for the validation of EEG-based automated seizure detection algorithms",
    "abstract": "The need for high-quality automated seizure detection algorithms based on electroencephalography (EEG) becomes ever more pressing with the increasing use of ambulatory and long-term EEG monitoring. Heterogeneity in validation methods of these algorithms influences the reported results and makes comprehensive evaluation and comparison challenging. This heterogeneity concerns in particular the choice of datasets, evaluation methodologies, and performance metrics. In this paper, we propose a unified framework designed to establish standardization in the validation of EEG-based seizure detection algorithms. Based on existing guidelines and recommendations, the framework introduces a set of recommendations and standards related to datasets, file formats, EEG data input content, seizure annotation input and output, cross-validation strategies, and performance metrics. We also propose the 10-20 seizure detection benchmark, a machine-learning benchmark based on public datasets converted to a standardized format. This benchmark defines the machine-learning task as well as reporting metrics. We illustrate the use of the benchmark by evaluating a set of existing seizure detection algorithms. The SzCORE (Seizure Community Open-source Research Evaluation) framework and benchmark are made publicly available along with an open-source software library to facilitate research use, while enabling rigorous evaluation of the clinical significance of the algorithms, fostering a collective effort to more optimally detect seizures to improve the lives of people with epilepsy. ",
    "url": "https://arxiv.org/abs/2402.13005",
    "authors": [
      "Jonathan Dan",
      "Una Pale",
      "Alireza Amirshahi",
      "William Cappelletti",
      "Thorir Mar Ingolfsson",
      "Xiaying Wang",
      "Andrea Cossettini",
      "Adriano Bernini",
      "Luca Benini",
      "S\u00e1ndor Beniczky",
      "David Atienza",
      "Philippe Ryvlin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13011",
    "title": "An evolutionary game with reputation-based imitation-mutation dynamics",
    "abstract": "Reputation plays a crucial role in social interactions by affecting the fitness of individuals during an evolutionary process. Previous works have extensively studied the result of imitation dynamics without focusing on potential irrational choices in strategy updates. We now fill this gap and explore the consequence of such kind of randomness, or one may interpret it as an autonomous thinking. In particular, we study how this extended dynamics alters the evolution of cooperation when individual reputation is directly linked to collected payoff, hence providing a general fitness function. For a broadly valid conclusion, our spatial populations cover different types of interaction topologies, including lattices, small-world and scale-free graphs. By means of intensive simulations we can detect substantial increase in cooperation level that shows a reasonable stability in the presence of a notable strategy mutation. ",
    "url": "https://arxiv.org/abs/2402.13011",
    "authors": [
      "Kehuan Feng",
      "Songlin Han",
      "Minyu Feng",
      "Attila Szolnoki"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Science and Game Theory (cs.GT)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2402.13106",
    "title": "On Generalization Bounds for Deep Compound Gaussian Neural Networks",
    "abstract": "Algorithm unfolding or unrolling is the technique of constructing a deep neural network (DNN) from an iterative algorithm. Unrolled DNNs often provide better interpretability and superior empirical performance over standard DNNs in signal estimation tasks. An important theoretical question, which has only recently received attention, is the development of generalization error bounds for unrolled DNNs. These bounds deliver theoretical and practical insights into the performance of a DNN on empirical datasets that are distinct from, but sampled from, the probability density generating the DNN training data. In this paper, we develop novel generalization error bounds for a class of unrolled DNNs that are informed by a compound Gaussian prior. These compound Gaussian networks have been shown to outperform comparative standard and unfolded deep neural networks in compressive sensing and tomographic imaging problems. The generalization error bound is formulated by bounding the Rademacher complexity of the class of compound Gaussian network estimates with Dudley's integral. Under realistic conditions, we show that, at worst, the generalization error scales $\\mathcal{O}(n\\sqrt{\\ln(n)})$ in the signal dimension and $\\mathcal{O}(($Network Size$)^{3/2})$ in network size. ",
    "url": "https://arxiv.org/abs/2402.13106",
    "authors": [
      "Carter Lyons",
      "Raghu G. Raj",
      "Margaret Cheney"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.13136",
    "title": "Relaxing Trust Assumptions on Quantum Key Distribution Networks",
    "abstract": "Quantum security over long distances with un- trusted relays is largely unfounded and is still an open ques- tion for active research. Nevertheless, quantum networks based on trusted relays are being built across the globe. However, standard QKD network architecture implores a complete trust requirement on QKD relays, which is too demanding and limits the use cases for QKD networks. In this work, we explore the possibility to securely relay a secret in a QKD network by relaxing the trust assumptions (if not completely) on the relay. We characterize QKD relays with different trust levels, namely, Full Access Trust (FAT), Partial Access Trust (PAT), and No Access Trust (NAT). As the name suggests, each level defines the degree with which a relay is required to be trusted with the secret provided by the key management system for end- to-end communication. We then review and propose multiple constructions of the QKD key management system based on the different trust levels. Main contribution of the paper is realized by evaluating key management systems with no access trust level. In principle, we review key management with centralized topology and propose a new decentralized key management system. These different topologies provide various advantages based on the QKD network requirements, allowing an operational flexibility in the architecture. We believe this work presents a new perspective to the open problem of providing a confiding and a practical solution for future long range secure communications ",
    "url": "https://arxiv.org/abs/2402.13136",
    "authors": [
      "Nilesh Vyas",
      "Paulo Mendes"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.13199",
    "title": "Target Speech Extraction with Pre-trained Self-supervised Learning  Models",
    "abstract": "Pre-trained self-supervised learning (SSL) models have achieved remarkable success in various speech tasks. However, their potential in target speech extraction (TSE) has not been fully exploited. TSE aims to extract the speech of a target speaker in a mixture guided by enrollment utterances. We exploit pre-trained SSL models for two purposes within a TSE framework, i.e., to process the input mixture and to derive speaker embeddings from the enrollment. In this paper, we focus on how to effectively use SSL models for TSE. We first introduce a novel TSE downstream task following the SUPERB principles. This simple experiment shows the potential of SSL models for TSE, but extraction performance remains far behind the state-of-the-art. We then extend a powerful TSE architecture by incorporating two SSL-based modules: an Adaptive Input Enhancer (AIE) and a speaker encoder. Specifically, the proposed AIE utilizes intermediate representations from the CNN encoder by adjusting the time resolution of CNN encoder and transformer blocks through progressive upsampling, capturing both fine-grained and hierarchical features. Our method outperforms current TSE systems achieving a SI-SDR improvement of 14.0 dB on LibriMix. Moreover, we can further improve performance by 0.7 dB by fine-tuning the whole model including the SSL model parameters. ",
    "url": "https://arxiv.org/abs/2402.13199",
    "authors": [
      "Junyi Peng",
      "Marc Delcroix",
      "Tsubasa Ochiai",
      "Oldrich Plchot",
      "Shoko Araki",
      "Jan Cernocky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.13200",
    "title": "Probing Self-supervised Learning Models with Target Speech Extraction",
    "abstract": "Large-scale pre-trained self-supervised learning (SSL) models have shown remarkable advancements in speech-related tasks. However, the utilization of these models in complex multi-talker scenarios, such as extracting a target speaker in a mixture, is yet to be fully evaluated. In this paper, we introduce target speech extraction (TSE) as a novel downstream task to evaluate the feature extraction capabilities of pre-trained SSL models. TSE uniquely requires both speaker identification and speech separation, distinguishing it from other tasks in the Speech processing Universal PERformance Benchmark (SUPERB) evaluation. Specifically, we propose a TSE downstream model composed of two lightweight task-oriented modules based on the same frozen SSL model. One module functions as a speaker encoder to obtain target speaker information from an enrollment speech, while the other estimates the target speaker's mask to extract its speech from the mixture. Experimental results on the Libri2mix datasets reveal the relevance of the TSE downstream task to probe SSL models, as its performance cannot be simply deduced from other related tasks such as speaker verification and separation. ",
    "url": "https://arxiv.org/abs/2402.13200",
    "authors": [
      "Junyi Peng",
      "Marc Delcroix",
      "Tsubasa Ochiai",
      "Oldrich Plchot",
      "Takanori Ashihara",
      "Shoko Araki",
      "Jan Cernocky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2007.11643",
    "title": "Space-Efficient Graph Kernelizations",
    "abstract": " Title: Space-Efficient Graph Kernelizations ",
    "url": "https://arxiv.org/abs/2007.11643",
    "authors": [
      "Frank Kammer",
      "Andrej Sajenko"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2106.03907",
    "title": "Deep Proxy Causal Learning and its Application to Confounded Bandit  Policy Evaluation",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2010.07154 ",
    "url": "https://arxiv.org/abs/2106.03907",
    "authors": [
      "Liyuan Xu",
      "Heishiro Kanagawa",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.01601",
    "title": "Is RobustBench/AutoAttack a suitable Benchmark for Adversarial  Robustness?",
    "abstract": " Comments: AAAI-22 AdvML Workshop ",
    "url": "https://arxiv.org/abs/2112.01601",
    "authors": [
      "Peter Lorenz",
      "Dominik Strassel",
      "Margret Keuper",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.11720",
    "title": "Simplicial Convolutional Filters",
    "abstract": " Comments: 16 pages, 13 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2201.11720",
    "authors": [
      "Maosheng Yang",
      "Elvin Isufi",
      "Michael T. Schaub",
      "Geert Leus"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2205.10309",
    "title": "A Fully Implicit Method for Robust Frictional Contact Handling in  Elastic Rods",
    "abstract": " Comments: Extreme Mechanics Letters (EML 2023). First two authors have equal contribution. A video summarizing this work is available on YouTube: this https URL ",
    "url": "https://arxiv.org/abs/2205.10309",
    "authors": [
      "Dezhong Tong",
      "Andrew Choi",
      "Jungseock Joo",
      "M. Khalid Jawed"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2206.02911",
    "title": "Inverse Boundary Value and Optimal Control Problems on Graphs: A Neural  and Numerical Synthesis",
    "abstract": " Title: Inverse Boundary Value and Optimal Control Problems on Graphs: A Neural  and Numerical Synthesis ",
    "url": "https://arxiv.org/abs/2206.02911",
    "authors": [
      "Mehdi Garrousian",
      "Amirhossein Nouranizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.08061",
    "title": "Optimal Computation in Leaderless and Multi-Leader Disconnected  Anonymous Dynamic Networks",
    "abstract": " Comments: 37 pages, 1 figure. arXiv admin note: substantial text overlap with arXiv:2204.02128 ",
    "url": "https://arxiv.org/abs/2207.08061",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.14016",
    "title": "Cascades towards noise-induced transitions on networks revealed using  information flows",
    "abstract": " Comments: Should contain color ",
    "url": "https://arxiv.org/abs/2207.14016",
    "authors": [
      "Casper van Elteren",
      "Rick Quax",
      "Peter Sloot"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2209.05550",
    "title": "Mathematical Framework for Online Social Media Auditing",
    "abstract": " Title: Mathematical Framework for Online Social Media Auditing ",
    "url": "https://arxiv.org/abs/2209.05550",
    "authors": [
      "Wasim Huleihel",
      "Yehonathan Refael"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.08854",
    "title": "Graph Filters for Signal Processing and Machine Learning on Graphs",
    "abstract": " Title: Graph Filters for Signal Processing and Machine Learning on Graphs ",
    "url": "https://arxiv.org/abs/2211.08854",
    "authors": [
      "Elvin Isufi",
      "Fernando Gama",
      "David I. Shuman",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14221",
    "title": "Learning Large Causal Structures from Inverse Covariance Matrix via  Sparse Matrix Decomposition",
    "abstract": " Title: Learning Large Causal Structures from Inverse Covariance Matrix via  Sparse Matrix Decomposition ",
    "url": "https://arxiv.org/abs/2211.14221",
    "authors": [
      "Shuyu Dong",
      "Kento Uemura",
      "Akito Fujii",
      "Shuang Chang",
      "Yusuke Koyanagi",
      "Koji Maruhashi",
      "Mich\u00e8le Sebag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2212.06776",
    "title": "Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial  Detection",
    "abstract": " Comments: accepted at VISAPP23 ",
    "url": "https://arxiv.org/abs/2212.06776",
    "authors": [
      "Peter Lorenz",
      "Margret Keuper",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.10049",
    "title": "OBMO: One Bounding Box Multiple Objects for Monocular 3D Object  Detection",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2212.10049",
    "authors": [
      "Chenxi Huang",
      "Tong He",
      "Haidong Ren",
      "Wenxiao Wang",
      "Binbin Lin",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01968",
    "title": "Learning Neural Force Manifolds for Sim2Real Robotic Symmetrical Paper  Folding",
    "abstract": " Comments: IEEE Transactions on Automation Science and Engineering (T-ASE 2024). First two authors have equal contribution. Supplementary video is available on YouTube: this https URL ",
    "url": "https://arxiv.org/abs/2301.01968",
    "authors": [
      "Andrew Choi",
      "Dezhong Tong",
      "Demetri Terzopoulos",
      "Jungseock Joo",
      "M. Khalid Jawed"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.02181",
    "title": "Model Stitching and Visualization How GAN Generators can Invert Networks  in Real-Time",
    "abstract": " Title: Model Stitching and Visualization How GAN Generators can Invert Networks  in Real-Time ",
    "url": "https://arxiv.org/abs/2302.02181",
    "authors": [
      "Rudolf Herdt",
      "Maximilian Schmidt",
      "Daniel Otero Baguer",
      "Jean Le'Clerc Arrastia",
      "Peter Maass"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.09444",
    "title": "mBEST: Realtime Deformable Linear Object Detection Through Minimal  Bending Energy Skeleton Pixel Traversals",
    "abstract": " Comments: IEEE Robotics and Automation Letters (RA-L 2023). YouTube video: this https URL ",
    "url": "https://arxiv.org/abs/2302.09444",
    "authors": [
      "Andrew Choi",
      "Dezhong Tong",
      "Brian Park",
      "Demetri Terzopoulos",
      "Jungseock Joo",
      "Mohammad Khalid Jawed"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05789",
    "title": "AnoMalNet: Outlier Detection based Malaria Cell Image Classification  Method Leveraging Deep Autoencoder",
    "abstract": " Comments: Accepted and Published at International Journal of Reconfigurable and Embedded Systems (IJRES) ",
    "url": "https://arxiv.org/abs/2303.05789",
    "authors": [
      "Aminul Huq",
      "Md Tanzim Reza",
      "Shahriar Hossain",
      "Shakib Mahmud Dipto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.02688",
    "title": "Going Further: Flatness at the Rescue of Early Stopping for Adversarial  Example Transferability",
    "abstract": " Comments: Version 2: originally submitted in April 2023 and revised in February 2024 ",
    "url": "https://arxiv.org/abs/2304.02688",
    "authors": [
      "Martin Gubri",
      "Maxime Cordy",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.05218",
    "title": "Improving Neural Radiance Fields with Depth-aware Optimization for Novel  View Synthesis",
    "abstract": " Title: Improving Neural Radiance Fields with Depth-aware Optimization for Novel  View Synthesis ",
    "url": "https://arxiv.org/abs/2304.05218",
    "authors": [
      "Shu Chen",
      "Junyao Li",
      "Yang Zhang",
      "Beiji Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.06857",
    "title": "Enhancing Self-Supervised Learning for Remote Sensing with Elevation  Data: A Case Study with Scarce And High Level Semantic Labels",
    "abstract": " Title: Enhancing Self-Supervised Learning for Remote Sensing with Elevation  Data: A Case Study with Scarce And High Level Semantic Labels ",
    "url": "https://arxiv.org/abs/2304.06857",
    "authors": [
      "Omar A. Casta\u00f1o-Idarraga",
      "Raul Ramos-Poll\u00e1n",
      "Freddie Kalaitzis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11671",
    "title": "Battery Capacity Knee-Onset Identification and Early Prediction Using  Degradation Curvature",
    "abstract": " Title: Battery Capacity Knee-Onset Identification and Early Prediction Using  Degradation Curvature ",
    "url": "https://arxiv.org/abs/2304.11671",
    "authors": [
      "Huang Zhang",
      "Faisal Altaf",
      "Torsten Wik"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.03582",
    "title": "A multimodal dynamical variational autoencoder for audiovisual speech  representation learning",
    "abstract": " Comments: 14 figures, this https URL ",
    "url": "https://arxiv.org/abs/2305.03582",
    "authors": [
      "Samir Sadok",
      "Simon Leglaive",
      "Laurent Girin",
      "Xavier Alameda-Pineda",
      "Renaud S\u00e9guier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.05013",
    "title": "Beyond Diagonal Reconfigurable Intelligent Surfaces Utilizing Graph  Theory: Modeling, Architecture Design, and Optimization",
    "abstract": " Comments: Accepted by IEEE for publication ",
    "url": "https://arxiv.org/abs/2305.05013",
    "authors": [
      "Matteo Nerini",
      "Shanpu Shen",
      "Hongyu Li",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.09181",
    "title": "(Rectified Version) Push-LSVRG-UP: Distributed Stochastic Optimization  over Unbalanced Directed Networks with Uncoordinated Triggered Probabilities",
    "abstract": " Comments: 16 pages, 30 figures ",
    "url": "https://arxiv.org/abs/2305.09181",
    "authors": [
      "Jinhui Hu",
      "Guo Chen",
      "Huaqing Li",
      "Zixiang Shen",
      "Weidong Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.12990",
    "title": "Sentence Representations via Gaussian Embedding",
    "abstract": " Comments: Accepted to EACL 2024 (Main) ",
    "url": "https://arxiv.org/abs/2305.12990",
    "authors": [
      "Shohei Yoda",
      "Hayato Tsukagoshi",
      "Ryohei Sasano",
      "Koichi Takeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17342",
    "title": "Rethinking Adversarial Policies: A Generalized Attack Formulation and  Provable Defense in RL",
    "abstract": " Comments: International Conference on Learning Representations (ICLR) 2024 ",
    "url": "https://arxiv.org/abs/2305.17342",
    "authors": [
      "Xiangyu Liu",
      "Souradip Chakraborty",
      "Yanchao Sun",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19971",
    "title": "Federated Learning in the Presence of Adversarial Client Unavailability",
    "abstract": " Title: Federated Learning in the Presence of Adversarial Client Unavailability ",
    "url": "https://arxiv.org/abs/2305.19971",
    "authors": [
      "Lili Su",
      "Ming Xiang",
      "Jiaming Xu",
      "Pengkun Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2306.04802",
    "title": "A Review on Knowledge Graphs for Healthcare: Resources, Applications,  and Promises",
    "abstract": " Title: A Review on Knowledge Graphs for Healthcare: Resources, Applications,  and Promises ",
    "url": "https://arxiv.org/abs/2306.04802",
    "authors": [
      "Hejie Cui",
      "Jiaying Lu",
      "Shiyu Wang",
      "Ran Xu",
      "Wenjing Ma",
      "Shaojun Yu",
      "Yue Yu",
      "Xuan Kan",
      "Chen Ling",
      "Tianfan Fu",
      "Liang Zhao",
      "Joyce Ho",
      "Fei Wang",
      "Carl Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.05108",
    "title": "Hybrid Graph: A Unified Graph Representation with Datasets and  Benchmarks for Complex Graphs",
    "abstract": " Comments: 16 pages, 5 figures, 11 tables ",
    "url": "https://arxiv.org/abs/2306.05108",
    "authors": [
      "Zehui Li",
      "Xiangyu Zhao",
      "Mingzhu Shen",
      "Guy-Bart Stan",
      "Pietro Li\u00f2",
      "Yiren Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.06945",
    "title": "Underwater Acoustic Target Recognition based on Smoothness-inducing  Regularization and Spectrogram-based Data Augmentation",
    "abstract": " Title: Underwater Acoustic Target Recognition based on Smoothness-inducing  Regularization and Spectrogram-based Data Augmentation ",
    "url": "https://arxiv.org/abs/2306.06945",
    "authors": [
      "Ji Xu",
      "Yuan Xie",
      "Wenchao Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13891",
    "title": "Estimating the Causal Effect of Early ArXiving on Paper Acceptance",
    "abstract": " Comments: Published at CLeaR 2024 ",
    "url": "https://arxiv.org/abs/2306.13891",
    "authors": [
      "Yanai Elazar",
      "Jiayao Zhang",
      "David Wadden",
      "Bo Zhang",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.12449",
    "title": "DyPP: Dynamic Parameter Prediction to Accelerate Convergence of  Variational Quantum Algorithms",
    "abstract": " Title: DyPP: Dynamic Parameter Prediction to Accelerate Convergence of  Variational Quantum Algorithms ",
    "url": "https://arxiv.org/abs/2307.12449",
    "authors": [
      "Satwik Kundu",
      "Debarshi Kundu",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12497",
    "title": "Embedding Integer Lattices as Ideals into Polynomial Rings",
    "abstract": " Title: Embedding Integer Lattices as Ideals into Polynomial Rings ",
    "url": "https://arxiv.org/abs/2307.12497",
    "authors": [
      "Yihang Cheng",
      "Yansong Feng",
      "Yanbin Pan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.09842",
    "title": "Enumerating Safe Regions in Deep Neural Networks with Provable  Probabilistic Guarantees",
    "abstract": " Comments: Accepted at the 38th Annual AAAI Conference on Artificial Intelligence 2024 ",
    "url": "https://arxiv.org/abs/2308.09842",
    "authors": [
      "Luca Marzari",
      "Davide Corsi",
      "Enrico Marchesini",
      "Alessandro Farinelli",
      "Ferdinando Cicalese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.11978",
    "title": "Will More Expressive Graph Neural Networks do Better on Generative  Tasks?",
    "abstract": " Comments: 2nd Learning on Graphs Conference (LoG 2023). 26 pages, 5 figures, 11 tables ",
    "url": "https://arxiv.org/abs/2308.11978",
    "authors": [
      "Xiandong Zou",
      "Xiangyu Zhao",
      "Pietro Li\u00f2",
      "Yiren Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.14714",
    "title": "A Stochastic Surveillance Stackelberg Game: Co-Optimizing Defense  Placement and Patrol Strategy",
    "abstract": " Comments: 9 pages, 1 figure, submitted as a technical note to the IEEE Transactions on Automatic Control. Replaced to fix inaccuracies ",
    "url": "https://arxiv.org/abs/2308.14714",
    "authors": [
      "Yohan John",
      "Gilberto Diaz-Garcia",
      "Xiaoming Duan",
      "Jason R. Marden",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.15949",
    "title": "Latency-aware Unified Dynamic Networks for Efficient Image Recognition",
    "abstract": " Title: Latency-aware Unified Dynamic Networks for Efficient Image Recognition ",
    "url": "https://arxiv.org/abs/2308.15949",
    "authors": [
      "Yizeng Han",
      "Zeyu Liu",
      "Zhihang Yuan",
      "Yifan Pu",
      "Chaofei Wang",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.04761",
    "title": "A Comprehensive Survey on Deep Learning Techniques in Educational Data  Mining",
    "abstract": " Comments: 19 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2309.04761",
    "authors": [
      "Yuanguo Lin",
      "Hong Chen",
      "Wei Xia",
      "Fan Lin",
      "Zongyue Wang",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.11134",
    "title": "GNSS/Multi-Sensor Fusion Using Continuous-Time Factor Graph Optimization  for Robust Localization",
    "abstract": " Comments: Submitted to IEEE Transactions on Robotics (2024-02-19) ",
    "url": "https://arxiv.org/abs/2309.11134",
    "authors": [
      "Haoming Zhang",
      "Chih-Chun Chen",
      "Heike Vallery",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.13506",
    "title": "Evaluating the Usability of Differential Privacy Tools with Data  Practitioners",
    "abstract": " Comments: 19 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2309.13506",
    "authors": [
      "Ivoline C. Ngong",
      "Brad Stenger",
      "Joseph P. Near",
      "Yuanyuan Feng"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.03755",
    "title": "Physics Informed Neural Network Code for 2D Transient Problems  (PINN-2DT) Compatible with Google Colab",
    "abstract": " Comments: 21 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2310.03755",
    "authors": [
      "Pawe\u0142 Maczuga",
      "Maciej Sikora",
      "Maciej Skocze\u0144",
      "Przemys\u0142aw Ro\u017cnawski",
      "Filip T\u0142uszcz",
      "Marcin Szubert",
      "Marcin \u0141o\u015b",
      "Witold Dzwinel",
      "Keshav Pingali",
      "Maciej Paszy\u0144ski"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.04918",
    "title": "SWAP: Sparse Entropic Wasserstein Regression for Robust Network Pruning",
    "abstract": " Comments: Published as a conference paper at ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.04918",
    "authors": [
      "Lei You",
      "Hei Victor Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05105",
    "title": "How Graph Neural Networks Learn: Lessons from Training Dynamics",
    "abstract": " Comments: ongoing work ",
    "url": "https://arxiv.org/abs/2310.05105",
    "authors": [
      "Chenxiao Yang",
      "Qitian Wu",
      "David Wipf",
      "Ruoyu Sun",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05668",
    "title": "LARA: A Light and Anti-overfitting Retraining Approach for Unsupervised  Anomaly Detection",
    "abstract": " Comments: Accepted by ACM Web Conference 2024 (WWW 24) ",
    "url": "https://arxiv.org/abs/2310.05668",
    "authors": [
      "Feiyi Chen",
      "Zhen Qin",
      "Yingying Zhang",
      "Shuiguang Deng",
      "Yi Xiao",
      "Guansong Pang",
      "Qingsong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08513",
    "title": "How connectivity structure shapes rich and lazy learning in neural  circuits",
    "abstract": " Comments: Published at ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.08513",
    "authors": [
      "Yuhan Helena Liu",
      "Aristide Baratin",
      "Jonathan Cornford",
      "Stefan Mihalas",
      "Eric Shea-Brown",
      "Guillaume Lajoie"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.09234",
    "title": "ClickPrompt: CTR Models are Strong Prompt Generators for Adapting  Language Models to CTR Prediction",
    "abstract": " Comments: Accepted by WWW 2024 ",
    "url": "https://arxiv.org/abs/2310.09234",
    "authors": [
      "Jianghao Lin",
      "Bo Chen",
      "Hangyu Wang",
      "Yunjia Xi",
      "Yanru Qu",
      "Xinyi Dai",
      "Kangning Zhang",
      "Ruiming Tang",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15627",
    "title": "Contextual Directed Acyclic Graphs",
    "abstract": " Comments: To appear in the Proceedings of the 27th International Conference on Artificial Intelligence and Statistics ",
    "url": "https://arxiv.org/abs/2310.15627",
    "authors": [
      "Ryan Thompson",
      "Edwin V. Bonilla",
      "Robert Kohn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18212",
    "title": "Robustness of Algorithms for Causal Structure Learning to Hyperparameter  Choice",
    "abstract": " Comments: To appear in the 3rd Conference on Causal Learning and Reasoning (CLeaR 2024) ",
    "url": "https://arxiv.org/abs/2310.18212",
    "authors": [
      "Damian Machlanski",
      "Spyridon Samothrakis",
      "Paul Clarke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.19192",
    "title": "Emergence of Grid-like Representations by Training Recurrent Networks  with Conformal Normalization",
    "abstract": " Title: Emergence of Grid-like Representations by Training Recurrent Networks  with Conformal Normalization ",
    "url": "https://arxiv.org/abs/2310.19192",
    "authors": [
      "Dehong Xu",
      "Ruiqi Gao",
      "Wen-Hao Zhang",
      "Xue-Xin Wei",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19906",
    "title": "Interpretable Prototype-based Graph Information Bottleneck",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.19906",
    "authors": [
      "Sangwoo Seo",
      "Sungwon Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20187",
    "title": "Self-Supervised Pre-Training for Precipitation Post-Processor",
    "abstract": " Comments: 7 pages, 3 figures, 1 table, accepted to NeurIPS 2023 Workshop on Tackling Climate Change with Machine Learning at [this http URL](this https URL) ",
    "url": "https://arxiv.org/abs/2310.20187",
    "authors": [
      "Sojung An",
      "Junha Lee",
      "Jiyeon Jang",
      "Inchae Na",
      "Wooyeon Park",
      "Sujeong You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20522",
    "title": "Tight bounds on adjacency labels for monotone graph classes",
    "abstract": " Comments: New result added (monotone small classes have bounded degeneracy - thus an implicit representation). 22 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2310.20522",
    "authors": [
      "\u00c9douard Bonnet",
      "Julien Duron",
      "John Sylvester",
      "Viktor Zamaraev",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.09538",
    "title": "Reducing Privacy Risks in Online Self-Disclosures with Language Models",
    "abstract": " Comments: LLMs, Privacy, HCI ",
    "url": "https://arxiv.org/abs/2311.09538",
    "authors": [
      "Yao Dou",
      "Isadora Krsek",
      "Tarek Naous",
      "Anubha Kabra",
      "Sauvik Das",
      "Alan Ritter",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.16476",
    "title": "LANS: A Layout-Aware Neural Solver for Plane Geometry Problem",
    "abstract": " Title: LANS: A Layout-Aware Neural Solver for Plane Geometry Problem ",
    "url": "https://arxiv.org/abs/2311.16476",
    "authors": [
      "Zhong-Zhi Li",
      "Ming-Liang Zhang",
      "Fei Yin",
      "Cheng-Lin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06658",
    "title": "Mean estimation in the add-remove model of differential privacy",
    "abstract": " Title: Mean estimation in the add-remove model of differential privacy ",
    "url": "https://arxiv.org/abs/2312.06658",
    "authors": [
      "Alex Kulesza",
      "Ananda Theertha Suresh",
      "Yuyan Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.06717",
    "title": "Privacy Issues in Large Language Models: A Survey",
    "abstract": " Comments: February 2023 Update ",
    "url": "https://arxiv.org/abs/2312.06717",
    "authors": [
      "Seth Neel",
      "Peter Chang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08223",
    "title": "Patch-wise Graph Contrastive Learning for Image Translation",
    "abstract": " Comments: AAAI 2024 ",
    "url": "https://arxiv.org/abs/2312.08223",
    "authors": [
      "Chanyong Jung",
      "Gihyun Kwon",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.09007",
    "title": "LLMind: Orchestrating AI and IoT with LLM for Complex Task Execution",
    "abstract": " Title: LLMind: Orchestrating AI and IoT with LLM for Complex Task Execution ",
    "url": "https://arxiv.org/abs/2312.09007",
    "authors": [
      "Hongwei Cui",
      "Yuyang Du",
      "Qun Yang",
      "Yulin Shao",
      "Soung Chang Liew"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04620",
    "title": "Agent Alignment in Evolving Social Norms",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2401.04620",
    "authors": [
      "Shimin Li",
      "Tianxiang Sun",
      "Qinyuan Cheng",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.07128",
    "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex  Tabular Reasoning on Electronic Health Records",
    "abstract": " Comments: Work in Progress ",
    "url": "https://arxiv.org/abs/2401.07128",
    "authors": [
      "Wenqi Shi",
      "Ran Xu",
      "Yuchen Zhuang",
      "Yue Yu",
      "Jieyu Zhang",
      "Hang Wu",
      "Yuanda Zhu",
      "Joyce Ho",
      "Carl Yang",
      "May D. Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.13227",
    "title": "LPNL: Scalable Link Prediction with Large Language Models",
    "abstract": " Title: LPNL: Scalable Link Prediction with Large Language Models ",
    "url": "https://arxiv.org/abs/2401.13227",
    "authors": [
      "Baolong Bi",
      "Shenghua Liu",
      "Yiwei Wang",
      "Lingrui Mei",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.14606",
    "title": "Challenging Low Homophily in Social Recommendation",
    "abstract": " Comments: This paper has been accepted by The Web Conference (WWW) 2024 ",
    "url": "https://arxiv.org/abs/2401.14606",
    "authors": [
      "Wei Jiang",
      "Xinyi Gao",
      "Guandong Xu",
      "Tong Chen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.01697",
    "title": "APT-Pipe: A Prompt-Tuning Tool for Social Data Annotation using ChatGPT",
    "abstract": " Comments: Accepted by WWW 2024; Camera-ready version ",
    "url": "https://arxiv.org/abs/2402.01697",
    "authors": [
      "Yiming Zhu",
      "Zhizhuo Yin",
      "Gareth Tyson",
      "Ehsan-Ul Haq",
      "Lik-Hang Lee",
      "Pan Hui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.03190",
    "title": "Unified Hallucination Detection for Multimodal Large Language Models",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2402.03190",
    "authors": [
      "Xiang Chen",
      "Chenxi Wang",
      "Yida Xue",
      "Ningyu Zhang",
      "Xiaoyan Yang",
      "Qiang Li",
      "Yue Shen",
      "Lei Liang",
      "Jinjie Gu",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.03843",
    "title": "A new method for optical steel rope non-destructive damage detection",
    "abstract": " Title: A new method for optical steel rope non-destructive damage detection ",
    "url": "https://arxiv.org/abs/2402.03843",
    "authors": [
      "Yunqing Bao",
      "Bin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05388",
    "title": "Form-From: A Design Space of Social Media Systems",
    "abstract": " Title: Form-From: A Design Space of Social Media Systems ",
    "url": "https://arxiv.org/abs/2402.05388",
    "authors": [
      "Amy X. Zhang",
      "Michael S. Bernstein",
      "David R. Karger",
      "Mark S. Ackerman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.05937",
    "title": "InstaGen: Enhancing Object Detection by Training on Synthetic Dataset",
    "abstract": " Comments: Tech report ",
    "url": "https://arxiv.org/abs/2402.05937",
    "authors": [
      "Chengjian Feng",
      "Yujie Zhong",
      "Zequn Jie",
      "Weidi Xie",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07140",
    "title": "Graph Descriptive Order Improves Reasoning with Large Language Model",
    "abstract": " Title: Graph Descriptive Order Improves Reasoning with Large Language Model ",
    "url": "https://arxiv.org/abs/2402.07140",
    "authors": [
      "Yuyao Ge",
      "Shenghua Liu",
      "Wenjie Feng",
      "Lingrui Mei",
      "Lizhe Chen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07197",
    "title": "GraphTranslator: Aligning Graph Model to Large Language Model for  Open-ended Tasks",
    "abstract": " Title: GraphTranslator: Aligning Graph Model to Large Language Model for  Open-ended Tasks ",
    "url": "https://arxiv.org/abs/2402.07197",
    "authors": [
      "Mengmei Zhang",
      "Mingwei Sun",
      "Peng Wang",
      "Shen Fan",
      "Yanhu Mo",
      "Xiaoxiao Xu",
      "Hong Liu",
      "Cheng Yang",
      "Chuan Shi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.10011",
    "title": "Clifford Group Equivariant Simplicial Message Passing Networks",
    "abstract": " Title: Clifford Group Equivariant Simplicial Message Passing Networks ",
    "url": "https://arxiv.org/abs/2402.10011",
    "authors": [
      "Cong Liu",
      "David Ruhe",
      "Floor Eijkelboom",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.10184",
    "title": "Rethinking Information Structures in RLHF: Reward Generalization from a  Graph Theory Perspective",
    "abstract": " Title: Rethinking Information Structures in RLHF: Reward Generalization from a  Graph Theory Perspective ",
    "url": "https://arxiv.org/abs/2402.10184",
    "authors": [
      "Tianyi Qiu",
      "Fanzhi Zeng",
      "Jiaming Ji",
      "Dong Yan",
      "Kaile Wang",
      "Jiayi Zhou",
      "Han Yang",
      "Josef Dai",
      "Xuehai Pan",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.10307",
    "title": "A New Radio to Overcome Critical Link Budgets",
    "abstract": " Comments: The paper is not correct. The paper calculates the beamforming gain of transmit beamforming for N antennas as N, but it should be N^2 ",
    "url": "https://arxiv.org/abs/2402.10307",
    "authors": [
      "Ralf R. M\u00fcller"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.10964",
    "title": "Optimal feature rescaling in machine learning based on neural networks",
    "abstract": " Comments: 6 pages ",
    "url": "https://arxiv.org/abs/2402.10964",
    "authors": [
      "Federico Maria Vitr\u00f2",
      "Marco Leonesio",
      "Lorenzo Fagiano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.11222",
    "title": "Treewidth versus clique number. IV. Tree-independence number of graphs  excluding an induced star",
    "abstract": " Comments: 26 pages ",
    "url": "https://arxiv.org/abs/2402.11222",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Matja\u017e Krnc",
      "O-joung Kwon",
      "Martin Milani\u010d",
      "Andrea Munaro",
      "Kenny \u0160torgel",
      "Sebastian Wiederrecht"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.11401",
    "title": "GraphKD: Exploring Knowledge Distillation Towards Document Object  Detection with Structured Graph Creation",
    "abstract": " Title: GraphKD: Exploring Knowledge Distillation Towards Document Object  Detection with Structured Graph Creation ",
    "url": "https://arxiv.org/abs/2402.11401",
    "authors": [
      "Ayan Banerjee",
      "Sanket Biswas",
      "Josep Llad\u00f3s",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11454",
    "title": "Addressing Internally-Disconnected Communities in Leiden and Louvain  Community Detection Algorithms",
    "abstract": " Comments: 18 pages, 11 figures, 1 table. arXiv admin note: text overlap with arXiv:2312.13936 ",
    "url": "https://arxiv.org/abs/2402.11454",
    "authors": [
      "Subhajit Sahu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.11821",
    "title": "Microstructures and Accuracy of Graph Recall by Large Language Models",
    "abstract": " Comments: 16 pages, 7 tables, 5 figures ",
    "url": "https://arxiv.org/abs/2402.11821",
    "authors": [
      "Yanbang Wang",
      "Hejie Cui",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.11853",
    "title": "Beyond Voice Assistants: Exploring Advantages and Risks of an In-Car  Social Robot in Real Driving Scenarios",
    "abstract": " Comments: Submitted to ACM Transactions on Computer-Human Interaction ",
    "url": "https://arxiv.org/abs/2402.11853",
    "authors": [
      "Yuanchao Li",
      "Lachlan Urquhart",
      "Nihan Karatas",
      "Shun Shao",
      "Hiroshi Ishiguro",
      "Xun Shen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.11922",
    "title": "A Generative Pre-Training Framework for Spatio-Temporal Graph Transfer  Learning",
    "abstract": " Title: A Generative Pre-Training Framework for Spatio-Temporal Graph Transfer  Learning ",
    "url": "https://arxiv.org/abs/2402.11922",
    "authors": [
      "Yuan Yuan",
      "Chenyang Shao",
      "Jingtao Ding",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11940",
    "title": "AICAttack: Adversarial Image Captioning Attack with Attention-Based  Optimization",
    "abstract": " Title: AICAttack: Adversarial Image Captioning Attack with Attention-Based  Optimization ",
    "url": "https://arxiv.org/abs/2402.11940",
    "authors": [
      "Jiyao Li",
      "Mingze Ni",
      "Yifei Dong",
      "Tianqing Zhu",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12161",
    "title": "Endowing Pre-trained Graph Models with Provable Fairness",
    "abstract": " Comments: Accepted by WWW 2024 ",
    "url": "https://arxiv.org/abs/2402.12161",
    "authors": [
      "Zhongjian Zhang",
      "Mengmei Zhang",
      "Yue Yu",
      "Cheng Yang",
      "Jiawei Liu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.12188",
    "title": "Structure of activity in multiregion recurrent neural networks",
    "abstract": " Comments: 18 pages, 10 figures; updated author info ",
    "url": "https://arxiv.org/abs/2402.12188",
    "authors": [
      "David G. Clark",
      "Manuel Beiran"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.12208",
    "title": "Language-Codec: Reducing the Gaps Between Discrete Codec Representation  and Speech Language Models",
    "abstract": " Title: Language-Codec: Reducing the Gaps Between Discrete Codec Representation  and Speech Language Models ",
    "url": "https://arxiv.org/abs/2402.12208",
    "authors": [
      "Shengpeng Ji",
      "Minghui Fang",
      "Ziyue Jiang",
      "Rongjie Huang",
      "Jialung Zuo",
      "Shulei Wang",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  }
]