[
  {
    "id": "arXiv:2402.13264",
    "title": "KGroot: Enhancing Root Cause Analysis through Knowledge Graphs and Graph  Convolutional Neural Networks",
    "abstract": "Fault localization is challenging in online micro-service due to the wide variety of monitoring data volume, types, events and complex interdependencies in service and components. Faults events in services are propagative and can trigger a cascade of alerts in a short period of time. In the industry, fault localization is typically conducted manually by experienced personnel. This reliance on experience is unreliable and lacks automation. Different modules present information barriers during manual localization, making it difficult to quickly align during urgent faults. This inefficiency lags stability assurance to minimize fault detection and repair time. Though actionable methods aimed to automatic the process, the accuracy and efficiency are less than satisfactory. The precision of fault localization results is of paramount importance as it underpins engineers trust in the diagnostic conclusions, which are derived from multiple perspectives and offer comprehensive insights. Therefore, a more reliable method is required to automatically identify the associative relationships among fault events and propagation path. To achieve this, KGroot uses event knowledge and the correlation between events to perform root cause reasoning by integrating knowledge graphs and GCNs for RCA. FEKG is built based on historical data, an online graph is constructed in real-time when a failure event occurs, and the similarity between each knowledge graph and online graph is compared using GCNs to pinpoint the fault type through a ranking strategy. Comprehensive experiments demonstrate KGroot can locate the root cause with accuracy of 93.5% top 3 potential causes in second-level. This performance matches the level of real-time fault diagnosis in the industrial environment and significantly surpasses state-of-the-art baselines in RCA in terms of effectiveness and efficiency. ",
    "url": "https://arxiv.org/abs/2402.13264",
    "authors": [
      "Tingting Wang",
      "Guilin Qi",
      "Tianxing Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13277",
    "title": "MLSTL-WSN: Machine Learning-based Intrusion Detection using SMOTETomek  in WSNs",
    "abstract": "Wireless Sensor Networks (WSNs) play a pivotal role as infrastructures, encompassing both stationary and mobile sensors. These sensors self-organize and establish multi-hop connections for communication, collectively sensing, gathering, processing, and transmitting data about their surroundings. Despite their significance, WSNs face rapid and detrimental attacks that can disrupt functionality. Existing intrusion detection methods for WSNs encounter challenges such as low detection rates, computational overhead, and false alarms. These issues stem from sensor node resource constraints, data redundancy, and high correlation within the network. To address these challenges, we propose an innovative intrusion detection approach that integrates Machine Learning (ML) techniques with the Synthetic Minority Oversampling Technique Tomek Link (SMOTE-TomekLink) algorithm. This blend synthesizes minority instances and eliminates Tomek links, resulting in a balanced dataset that significantly enhances detection accuracy in WSNs. Additionally, we incorporate feature scaling through standardization to render input features consistent and scalable, facilitating more precise training and detection. To counteract imbalanced WSN datasets, we employ the SMOTE-Tomek resampling technique, mitigating overfitting and underfitting issues. Our comprehensive evaluation, using the WSN Dataset (WSN-DS) containing 374,661 records, identifies the optimal model for intrusion detection in WSNs. The standout outcome of our research is the remarkable performance of our model. In binary, it achieves an accuracy rate of 99.78% and in multiclass, it attains an exceptional accuracy rate of 99.92%. These findings underscore the efficiency and superiority of our proposal in the context of WSN intrusion detection, showcasing its effectiveness in detecting and mitigating intrusions in WSNs. ",
    "url": "https://arxiv.org/abs/2402.13277",
    "authors": [
      "Md. Alamin Talukder",
      "Selina Sharmin",
      "Md Ashraf Uddin",
      "Md Manowarul Islam",
      "Sunil Aryal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13281",
    "title": "Fight Hardware with Hardware: System-wide Detection and Mitigation of  Side-Channel Attacks using Performance Counters",
    "abstract": "We present a kernel-level infrastructure that allows system-wide detection of malicious applications attempting to exploit cache-based side-channel attacks to break the process confinement enforced by standard operating systems. This infrastructure relies on hardware performance counters to collect information at runtime from all applications running on the machine. High-level detection metrics are derived from these measurements to maximize the likelihood of promptly detecting a malicious application. Our experimental assessment shows that we can catch a large family of side-channel attacks with a significantly reduced overhead. We also discuss countermeasures that can be enacted once a process is suspected of carrying out a side-channel attack to increase the overall tradeoff between the system's security level and the delivered performance under non-suspected process executions. ",
    "url": "https://arxiv.org/abs/2402.13281",
    "authors": [
      "Stefano Carn\u00e0",
      "Serena Ferracci",
      "Francesco Quaglia",
      "Alessandro Pellegrini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2402.13296",
    "title": "Evolutionary Reinforcement Learning: A Systematic Review and Future  Directions",
    "abstract": "In response to the limitations of reinforcement learning and evolutionary algorithms (EAs) in complex problem-solving, Evolutionary Reinforcement Learning (EvoRL) has emerged as a synergistic solution. EvoRL integrates EAs and reinforcement learning, presenting a promising avenue for training intelligent agents. This systematic review firstly navigates through the technological background of EvoRL, examining the symbiotic relationship between EAs and reinforcement learning algorithms. We then delve into the challenges faced by both EAs and reinforcement learning, exploring their interplay and impact on the efficacy of EvoRL. Furthermore, the review underscores the need for addressing open issues related to scalability, adaptability, sample efficiency, adversarial robustness, ethic and fairness within the current landscape of EvoRL. Finally, we propose future directions for EvoRL, emphasizing research avenues that strive to enhance self-adaptation and self-improvement, generalization, interpretability, explainability, and so on. Serving as a comprehensive resource for researchers and practitioners, this systematic review provides insights into the current state of EvoRL and offers a guide for advancing its capabilities in the ever-evolving landscape of artificial intelligence. ",
    "url": "https://arxiv.org/abs/2402.13296",
    "authors": [
      "Yuanguo Lin",
      "Fan Lin",
      "Guorong Cai",
      "Hong Chen",
      "Lixin Zou",
      "Pengcheng Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.13331",
    "title": "Enhanced Hallucination Detection in Neural Machine Translation through  Simple Detector Aggregation",
    "abstract": "Hallucinated translations pose significant threats and safety concerns when it comes to the practical deployment of machine translation systems. Previous research works have identified that detectors exhibit complementary performance different detectors excel at detecting different types of hallucinations. In this paper, we propose to address the limitations of individual detectors by combining them and introducing a straightforward method for aggregating multiple detectors. Our results demonstrate the efficacy of our aggregated detector, providing a promising step towards evermore reliable machine translation systems. ",
    "url": "https://arxiv.org/abs/2402.13331",
    "authors": [
      "Anas Himmi",
      "Guillaume Staerman",
      "Marine Picot",
      "Pierre Colombo",
      "Nuno M. Guerreiro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13332",
    "title": "Double machine learning for causal hybrid modeling -- applications in  the Earth sciences",
    "abstract": "Hybrid modeling integrates machine learning with scientific knowledge with the goal of enhancing interpretability, generalization, and adherence to natural laws. Nevertheless, equifinality and regularization biases pose challenges in hybrid modeling to achieve these purposes. This paper introduces a novel approach to estimating hybrid models via a causal inference framework, specifically employing Double Machine Learning (DML) to estimate causal effects. We showcase its use for the Earth sciences on two problems related to carbon dioxide fluxes. In the $Q_{10}$ model, we demonstrate that DML-based hybrid modeling is superior in estimating causal parameters over end-to-end deep neural network (DNN) approaches, proving efficiency, robustness to bias from regularization methods, and circumventing equifinality. Our approach, applied to carbon flux partitioning, exhibits flexibility in accommodating heterogeneous causal effects. The study emphasizes the necessity of explicitly defining causal graphs and relationships, advocating for this as a general best practice. We encourage the continued exploration of causality in hybrid models for more interpretable and trustworthy results in knowledge-guided machine learning. ",
    "url": "https://arxiv.org/abs/2402.13332",
    "authors": [
      "Kai-Hendrik Cohrs",
      "Gherardo Varando",
      "Nuno Carvalhais",
      "Markus Reichstein",
      "Gustau Camps-Valls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.13410",
    "title": "Bayesian Neural Networks with Domain Knowledge Priors",
    "abstract": "Bayesian neural networks (BNNs) have recently gained popularity due to their ability to quantify model uncertainty. However, specifying a prior for BNNs that captures relevant domain knowledge is often extremely challenging. In this work, we propose a framework for integrating general forms of domain knowledge (i.e., any knowledge that can be represented by a loss function) into a BNN prior through variational inference, while enabling computationally efficient posterior inference and sampling. Specifically, our approach results in a prior over neural network weights that assigns high probability mass to models that better align with our domain knowledge, leading to posterior samples that also exhibit this behavior. We show that BNNs using our proposed domain knowledge priors outperform those with standard priors (e.g., isotropic Gaussian, Gaussian process), successfully incorporating diverse types of prior information such as fairness, physics rules, and healthcare knowledge and achieving better predictive performance. We also present techniques for transferring the learned priors across different model architectures, demonstrating their broad utility across various settings. ",
    "url": "https://arxiv.org/abs/2402.13410",
    "authors": [
      "Dylan Sam",
      "Rattana Pukdee",
      "Daniel P. Jeong",
      "Yewon Byun",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.13415",
    "title": "Structure Guided Prompt: Instructing Large Language Model in Multi-Step  Reasoning by Exploring Graph Structure of the Text",
    "abstract": "Although Large Language Models (LLMs) excel at addressing straightforward reasoning tasks, they frequently struggle with difficulties when confronted by more complex multi-step reasoning due to a range of factors. Firstly, natural language often encompasses complex relationships among entities, making it challenging to maintain a clear reasoning chain over longer spans. Secondly, the abundance of linguistic diversity means that the same entities and relationships can be expressed using different terminologies and structures, complicating the task of identifying and establishing connections between multiple pieces of information. Graphs provide an effective solution to represent data rich in relational information and capture long-term dependencies among entities. To harness the potential of graphs, our paper introduces Structure Guided Prompt, an innovative three-stage task-agnostic prompting framework designed to improve the multi-step reasoning capabilities of LLMs in a zero-shot setting. This framework explicitly converts unstructured text into a graph via LLMs and instructs them to navigate this graph using task-specific strategies to formulate responses. By effectively organizing information and guiding navigation, it enables LLMs to provide more accurate and context-aware responses. Our experiments show that this framework significantly enhances the reasoning capabilities of LLMs, enabling them to excel in a broader spectrum of natural language scenarios. ",
    "url": "https://arxiv.org/abs/2402.13415",
    "authors": [
      "Kewei Cheng",
      "Nesreen K. Ahmed",
      "Theodore Willke",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13427",
    "title": "Quantitative causality, causality-guided scientific discovery, and  causal machine learning",
    "abstract": "It has been said, arguably, that causality analysis should pave a promising way to interpretable deep learning and generalization. Incorporation of causality into artificial intelligence (AI) algorithms, however, is challenged with its vagueness, non-quantitiveness, computational inefficiency, etc. During the past 18 years, these challenges have been essentially resolved, with the establishment of a rigorous formalism of causality analysis initially motivated from atmospheric predictability. This not only opens a new field in the atmosphere-ocean science, namely, information flow, but also has led to scientific discoveries in other disciplines, such as quantum mechanics, neuroscience, financial economics, etc., through various applications. This note provides a brief review of the decade-long effort, including a list of major theoretical results, a sketch of the causal deep learning framework, and some representative real-world applications in geoscience pertaining to this journal, such as those on the anthropogenic cause of global warming, the decadal prediction of El Ni\\~no Modoki, the forecasting of an extreme drought in China, among others. ",
    "url": "https://arxiv.org/abs/2402.13427",
    "authors": [
      "X. San Liang",
      "Dake Chen",
      "Renhe Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2402.13430",
    "title": "LinkSAGE: Optimizing Job Matching Using Graph Neural Networks",
    "abstract": "We present LinkSAGE, an innovative framework that integrates Graph Neural Networks (GNNs) into large-scale personalized job matching systems, designed to address the complex dynamics of LinkedIns extensive professional network. Our approach capitalizes on a novel job marketplace graph, the largest and most intricate of its kind in industry, with billions of nodes and edges. This graph is not merely extensive but also richly detailed, encompassing member and job nodes along with key attributes, thus creating an expansive and interwoven network. A key innovation in LinkSAGE is its training and serving methodology, which effectively combines inductive graph learning on a heterogeneous, evolving graph with an encoder-decoder GNN model. This methodology decouples the training of the GNN model from that of existing Deep Neural Nets (DNN) models, eliminating the need for frequent GNN retraining while maintaining up-to-date graph signals in near realtime, allowing for the effective integration of GNN insights through transfer learning. The subsequent nearline inference system serves the GNN encoder within a real-world setting, significantly reducing online latency and obviating the need for costly real-time GNN infrastructure. Validated across multiple online A/B tests in diverse product scenarios, LinkSAGE demonstrates marked improvements in member engagement, relevance matching, and member retention, confirming its generalizability and practical impact. ",
    "url": "https://arxiv.org/abs/2402.13430",
    "authors": [
      "Ping Liu",
      "Haichao Wei",
      "Xiaochen Hou",
      "Jianqiang Shen",
      "Shihai He",
      "Kay Qianqi Shen",
      "Zhujun Chen",
      "Fedor Borisyuk",
      "Daniel Hewlett",
      "Liang Wu",
      "Srikant Veeraraghavan",
      "Alex Tsun",
      "Chengming Jiang",
      "Wenjing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.13441",
    "title": "PaCKD: Pattern-Clustered Knowledge Distillation for Compressing Memory  Access Prediction Models",
    "abstract": "Deep neural networks (DNNs) have proven to be effective models for accurate Memory Access Prediction (MAP), a critical task in mitigating memory latency through data prefetching. However, existing DNN-based MAP models suffer from the challenges such as significant physical storage space and poor inference latency, primarily due to their large number of parameters. These limitations render them impractical for deployment in real-world scenarios. In this paper, we propose PaCKD, a Pattern-Clustered Knowledge Distillation approach to compress MAP models while maintaining the prediction performance. The PaCKD approach encompasses three steps: clustering memory access sequences into distinct partitions involving similar patterns, training large pattern-specific teacher models for memory access prediction for each partition, and training a single lightweight student model by distilling the knowledge from the trained pattern-specific teachers. We evaluate our approach on LSTM, MLP-Mixer, and ResNet models, as they exhibit diverse structures and are widely used for image classification tasks in order to test their effectiveness in four widely used graph applications. Compared to the teacher models with 5.406M parameters and an F1-score of 0.4626, our student models achieve a 552$\\times$ model size compression while maintaining an F1-score of 0.4538 (with a 1.92% performance drop). Our approach yields an 8.70% higher result compared to student models trained with standard knowledge distillation and an 8.88% higher result compared to student models trained without any form of knowledge distillation. ",
    "url": "https://arxiv.org/abs/2402.13441",
    "authors": [
      "Neelesh Gupta",
      "Pengmiao Zhang",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2402.13442",
    "title": "CoFRIDA: Self-Supervised Fine-Tuning for Human-Robot Co-Painting",
    "abstract": "Prior robot painting and drawing work, such as FRIDA, has focused on decreasing the sim-to-real gap and expanding input modalities for users, but the interaction with these systems generally exists only in the input stages. To support interactive, human-robot collaborative painting, we introduce the Collaborative FRIDA (CoFRIDA) robot painting framework, which can co-paint by modifying and engaging with content already painted by a human collaborator. To improve text-image alignment, FRIDA's major weakness, our system uses pre-trained text-to-image models; however, pre-trained models in the context of real-world co-painting do not perform well because they (1) do not understand the constraints and abilities of the robot and (2) cannot perform co-painting without making unrealistic edits to the canvas and overwriting content. We propose a self-supervised fine-tuning procedure that can tackle both issues, allowing the use of pre-trained state-of-the-art text-image alignment models with robots to enable co-painting in the physical world. Our open-source approach, CoFRIDA, creates paintings and drawings that match the input text prompt more clearly than FRIDA, both from a blank canvas and one with human created work. More generally, our fine-tuning procedure successfully encodes the robot's constraints and abilities into a foundation model, showcasing promising results as an effective method for reducing sim-to-real gaps. ",
    "url": "https://arxiv.org/abs/2402.13442",
    "authors": [
      "Peter Schaldenbrand",
      "Gaurav Parmar",
      "Jun-Yan Zhu",
      "James McCann",
      "Jean Oh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.13444",
    "title": "The Effectiveness of Graph Contrastive Learning on Mathematical  Information Retrieval",
    "abstract": "This paper details an empirical investigation into using Graph Contrastive Learning (GCL) to generate mathematical equation representations, a critical aspect of Mathematical Information Retrieval (MIR). Our findings reveal that this simple approach consistently exceeds the performance of the current leading formula retrieval model, TangentCFT. To support ongoing research and development in this field, we have made our source code accessible to the public at https://github.com/WangPeiSyuan/GCL-Formula-Retrieval/. ",
    "url": "https://arxiv.org/abs/2402.13444",
    "authors": [
      "Pei-Syuan Wang",
      "Hung-Hsuan Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.13457",
    "title": "LLM Jailbreak Attack versus Defense Techniques -- A Comprehensive Study",
    "abstract": "Large Language Models (LLMS) have increasingly become central to generating content with potential societal impacts. Notably, these models have demonstrated capabilities for generating content that could be deemed harmful. To mitigate these risks, researchers have adopted safety training techniques to align model outputs with societal values to curb the generation of malicious content. However, the phenomenon of \"jailbreaking\", where carefully crafted prompts elicit harmful responses from models, persists as a significant challenge. This research conducts a comprehensive analysis of existing studies on jailbreaking LLMs and their defense techniques. We meticulously investigate nine attack techniques and seven defense techniques applied across three distinct language models: Vicuna, LLama, and GPT-3.5 Turbo. We aim to evaluate the effectiveness of these attack and defense techniques. Our findings reveal that existing white-box attacks underperform compared to universal techniques and that including special tokens in the input significantly affects the likelihood of successful attacks. This research highlights the need to concentrate on the security facets of LLMs. Additionally, we contribute to the field by releasing our datasets and testing framework, aiming to foster further research into LLM security. We believe these contributions will facilitate the exploration of security measures within this domain. ",
    "url": "https://arxiv.org/abs/2402.13457",
    "authors": [
      "Zihao Xu",
      "Yi Liu",
      "Gelei Deng",
      "Yuekang Li",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13462",
    "title": "Potential and Challenges of Model Editing for Social Debiasing",
    "abstract": "Large language models (LLMs) trained on vast corpora suffer from inevitable stereotype biases. Mitigating these biases with fine-tuning could be both costly and data-hungry. Model editing methods, which focus on modifying LLMs in a post-hoc manner, are of great potential to address debiasing. However, it lacks a comprehensive study that facilitates both internal and external model editing methods, supports various bias types, as well as understands the pros and cons of applying editing methods to stereotypical debiasing. To mitigate this gap, we carefully formulate social debiasing into an editing problem and benchmark seven existing model editing algorithms on stereotypical debiasing, i.e., debias editing. Our findings in three scenarios reveal both the potential and challenges of debias editing: (1) Existing model editing methods can effectively preserve knowledge and mitigate biases, while the generalization of debias effect from edited sentences to semantically equivalent sentences is limited.(2) Sequential editing highlights the robustness of SERAC (Mitchell et al. 2022b), while internal editing methods degenerate with the number of edits. (3) Model editing algorithms achieve generalization towards unseen biases both within the same type and from different types. In light of these findings, we further propose two simple but effective methods to improve debias editing, and experimentally show the effectiveness of the proposed methods. ",
    "url": "https://arxiv.org/abs/2402.13462",
    "authors": [
      "Jianhao Yan",
      "Futing Wang",
      "Yafu Li",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13465",
    "title": "Unsupervised learning based object detection using Contrastive Learning",
    "abstract": "Training image-based object detectors presents formidable challenges, as it entails not only the complexities of object detection but also the added intricacies of precisely localizing objects within potentially diverse and noisy environments. However, the collection of imagery itself can often be straightforward; for instance, cameras mounted in vehicles can effortlessly capture vast amounts of data in various real-world scenarios. In light of this, we introduce a groundbreaking method for training single-stage object detectors through unsupervised/self-supervised learning. Our state-of-the-art approach has the potential to revolutionize the labeling process, substantially reducing the time and cost associated with manual annotation. Furthermore, it paves the way for previously unattainable research opportunities, particularly for large, diverse, and challenging datasets lacking extensive labels. In contrast to prevalent unsupervised learning methods that primarily target classification tasks, our approach takes on the unique challenge of object detection. We pioneer the concept of intra-image contrastive learning alongside inter-image counterparts, enabling the acquisition of crucial location information essential for object detection. The method adeptly learns and represents this location information, yielding informative heatmaps. Our results showcase an outstanding accuracy of \\textbf{89.2\\%}, marking a significant breakthrough of approximately \\textbf{15x} over random initialization in the realm of unsupervised object detection within the field of computer vision. ",
    "url": "https://arxiv.org/abs/2402.13465",
    "authors": [
      "Chandan Kumar",
      "Jansel Herrera-Gerena",
      "John Just",
      "Matthew Darr",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13482",
    "title": "Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks",
    "abstract": "Despite large successes of recent language models on diverse tasks, they suffer from severe performance degeneration in low-resource settings with limited training data available. Many existing works tackle this problem by generating synthetic data from the training data and then training models on them, recently using Large Language Models (LLMs). However, in low-resource settings, the amount of seed data samples to use for data augmentation is very small, which makes generated samples suboptimal and less diverse. To tackle this challenge, we propose a novel method that augments training data by incorporating a wealth of examples from other datasets, along with the given training data. Specifically, we first retrieve the relevant instances from other datasets, such as their input-output pairs or contexts, based on their similarities with the given seed data, and then prompt LLMs to generate new samples with the contextual information within and across the original and retrieved samples. This approach can ensure that the generated data is not only relevant but also more diverse than what could be achieved using the limited seed data alone. We validate our proposed Retrieval-Augmented Data Augmentation (RADA) framework on multiple datasets under low-resource settings of training and test-time data augmentation scenarios, on which it outperforms existing LLM-powered data augmentation baselines. ",
    "url": "https://arxiv.org/abs/2402.13482",
    "authors": [
      "Minju Seo",
      "Jinheon Baek",
      "James Thorne",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13487",
    "title": "Stealthy Adversarial Attacks on Stochastic Multi-Armed Bandits",
    "abstract": "Adversarial attacks against stochastic multi-armed bandit (MAB) algorithms have been extensively studied in the literature. In this work, we focus on reward poisoning attacks and find most existing attacks can be easily detected by our proposed detection method based on the test of homogeneity, due to their aggressive nature in reward manipulations. This motivates us to study the notion of stealthy attack against stochastic MABs and investigate the resulting attackability. Our analysis shows that against two popularly employed MAB algorithms, UCB1 and $\\epsilon$-greedy, the success of a stealthy attack depends on the environmental conditions and the realized reward of the arm pulled in the first round. We also analyze the situation for general MAB algorithms equipped with our attack detection method and find that it is possible to have a stealthy attack that almost always succeeds. This brings new insights into the security risks of MAB algorithms. ",
    "url": "https://arxiv.org/abs/2402.13487",
    "authors": [
      "Zhiwei Wang",
      "Huazheng Wang",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.13492",
    "title": "Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval  Augmentation to Language Models",
    "abstract": "While large language models (LMs) demonstrate remarkable performance, they encounter challenges in providing accurate responses when queried for information beyond their pre-trained memorization. Although augmenting them with relevant external information can mitigate these issues, failure to consider the necessity of retrieval may adversely affect overall performance. Previous research has primarily focused on examining how entities influence retrieval models and knowledge recall in LMs, leaving other aspects relatively unexplored. In this work, our goal is to offer a more detailed, fact-centric analysis by exploring the effects of combinations of entities and relations. To facilitate this, we construct a new question answering (QA) dataset called WiTQA (Wikipedia Triple Question Answers). This dataset includes questions about entities and relations of various popularity levels, each accompanied by a supporting passage. Our extensive experiments with diverse LMs and retrievers reveal when retrieval does not consistently enhance LMs from the viewpoints of fact-centric popularity.Confirming earlier findings, we observe that larger LMs excel in recalling popular facts. However, they notably encounter difficulty with infrequent entity-relation pairs compared to retrievers. Interestingly, they can effectively retain popular relations of less common entities. We demonstrate the efficacy of our finer-grained metric and insights through an adaptive retrieval system that selectively employs retrieval and recall based on the frequencies of entities and relations in the question. ",
    "url": "https://arxiv.org/abs/2402.13492",
    "authors": [
      "Seiji Maekawa",
      "Hayate Iso",
      "Sairam Gurajada",
      "Nikita Bhutani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13495",
    "title": "Can One Embedding Fit All? A Multi-Interest Learning Paradigm Towards  Improving User Interest Diversity Fairness",
    "abstract": "Recommender systems (RSs) have gained widespread applications across various domains owing to the superior ability to capture users' interests. However, the complexity and nuanced nature of users' interests, which span a wide range of diversity, pose a significant challenge in delivering fair recommendations. In practice, user preferences vary significantly; some users show a clear preference toward certain item categories, while others have a broad interest in diverse ones. Even though it is expected that all users should receive high-quality recommendations, the effectiveness of RSs in catering to this disparate interest diversity remains under-explored. In this work, we investigate whether users with varied levels of interest diversity are treated fairly. Our empirical experiments reveal an inherent disparity: users with broader interests often receive lower-quality recommendations. To mitigate this, we propose a multi-interest framework that uses multiple (virtual) interest embeddings rather than single ones to represent users. Specifically, the framework consists of stacked multi-interest representation layers, which include an interest embedding generator that derives virtual interests from shared parameters, and a center embedding aggregator that facilitates multi-hop aggregation. Experiments demonstrate the effectiveness of the framework in achieving better trade-off between fairness and utility across various datasets and backbones. ",
    "url": "https://arxiv.org/abs/2402.13495",
    "authors": [
      "Yuying Zhao",
      "Minghua Xu",
      "Huiyuan Chen",
      "Yuzhong Chen",
      "Yiwei Cai",
      "Rashidul Islam",
      "Yu Wang",
      "Tyler Derr"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.13496",
    "title": "HetTree: Heterogeneous Tree Graph Neural Network",
    "abstract": "The recent past has seen an increasing interest in Heterogeneous Graph Neural Networks (HGNNs) since many real-world graphs are heterogeneous in nature, from citation graphs to email graphs. However, existing methods ignore a tree hierarchy among metapaths, which is naturally constituted by different node types and relation types. In this paper, we present HetTree, a novel heterogeneous tree graph neural network that models both the graph structure and heterogeneous aspects in a scalable and effective manner. Specifically, HetTree builds a semantic tree data structure to capture the hierarchy among metapaths. Existing tree encoding techniques aggregate children nodes by weighting the contribution of children nodes based on similarity to the parent node. However, we find that this tree encoding fails to capture the entire parent-children hierarchy by only considering the parent node. Hence, HetTree uses a novel subtree attention mechanism to emphasize metapaths that are more helpful in encoding parent-children relationships. Moreover, instead of separating feature learning from label learning or treating features and labels equally by projecting them to the same latent space, HetTree proposes to match them carefully based on corresponding metapaths, which provides more accurate and richer information between node features and labels. Our evaluation of HetTree on a variety of real-world datasets demonstrates that it outperforms all existing baselines on open benchmarks and efficiently scales to large real-world graphs with millions of nodes and edges. ",
    "url": "https://arxiv.org/abs/2402.13496",
    "authors": [
      "Mingyu Guan",
      "Jack W. Stokes",
      "Qinlong Luo",
      "Fuchen Liu",
      "Purvanshi Mehta",
      "Elnaz Nouri",
      "Taesoo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.13510",
    "title": "SealD-NeRF: Interactive Pixel-Level Editing for Dynamic Scenes by Neural  Radiance Fields",
    "abstract": "The widespread adoption of implicit neural representations, especially Neural Radiance Fields (NeRF), highlights a growing need for editing capabilities in implicit 3D models, essential for tasks like scene post-processing and 3D content creation. Despite previous efforts in NeRF editing, challenges remain due to limitations in editing flexibility and quality. The key issue is developing a neural representation that supports local edits for real-time updates. Current NeRF editing methods, offering pixel-level adjustments or detailed geometry and color modifications, are mostly limited to static scenes. This paper introduces SealD-NeRF, an extension of Seal-3D for pixel-level editing in dynamic settings, specifically targeting the D-NeRF network. It allows for consistent edits across sequences by mapping editing actions to a specific timeframe, freezing the deformation network responsible for dynamic scene representation, and using a teacher-student approach to integrate changes. ",
    "url": "https://arxiv.org/abs/2402.13510",
    "authors": [
      "Zhentao Huang",
      "Yukun Shi",
      "Neil Bruce",
      "Minglun Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13517",
    "title": "Round Trip Translation Defence against Large Language Model Jailbreaking  Attacks",
    "abstract": "Large language models (LLMs) are susceptible to social-engineered attacks that are human-interpretable but require a high level of comprehension for LLMs to counteract. Existing defensive measures can only mitigate less than half of these attacks at most. To address this issue, we propose the Round Trip Translation (RTT) method, the first algorithm specifically designed to defend against social-engineered attacks on LLMs. RTT paraphrases the adversarial prompt and generalizes the idea conveyed, making it easier for LLMs to detect induced harmful behavior. This method is versatile, lightweight, and transferrable to different LLMs. Our defense successfully mitigated over 70% of Prompt Automatic Iterative Refinement (PAIR) attacks, which is currently the most effective defense to the best of our knowledge. We are also the first to attempt mitigating the MathsAttack and reduced its attack success rate by almost 40%. Our code is publicly available at https://github.com/Cancanxxx/Round_Trip_Translation_Defence ",
    "url": "https://arxiv.org/abs/2402.13517",
    "authors": [
      "Canaan Yung",
      "Hadi Mohaghegh Dolatabadi",
      "Sarah Erfani",
      "Christopher Leckie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13518",
    "title": "RITFIS: Robust input testing framework for LLMs-based intelligent  software",
    "abstract": "The dependence of Natural Language Processing (NLP) intelligent software on Large Language Models (LLMs) is increasingly prominent, underscoring the necessity for robustness testing. Current testing methods focus solely on the robustness of LLM-based software to prompts. Given the complexity and diversity of real-world inputs, studying the robustness of LLMbased software in handling comprehensive inputs (including prompts and examples) is crucial for a thorough understanding of its performance. To this end, this paper introduces RITFIS, a Robust Input Testing Framework for LLM-based Intelligent Software. To our knowledge, RITFIS is the first framework designed to assess the robustness of LLM-based intelligent software against natural language inputs. This framework, based on given threat models and prompts, primarily defines the testing process as a combinatorial optimization problem. Successful test cases are determined by a goal function, creating a transformation space for the original examples through perturbation means, and employing a series of search methods to filter cases that meet both the testing objectives and language constraints. RITFIS, with its modular design, offers a comprehensive method for evaluating the robustness of LLMbased intelligent software. RITFIS adapts 17 automated testing methods, originally designed for Deep Neural Network (DNN)-based intelligent software, to the LLM-based software testing scenario. It demonstrates the effectiveness of RITFIS in evaluating LLM-based intelligent software through empirical validation. However, existing methods generally have limitations, especially when dealing with lengthy texts and structurally complex threat models. Therefore, we conducted a comprehensive analysis based on five metrics and provided insightful testing method optimization strategies, benefiting both researchers and everyday users. ",
    "url": "https://arxiv.org/abs/2402.13518",
    "authors": [
      "Mingxuan Xiao",
      "Yan Xiao",
      "Hai Dong",
      "Shunhui Ji",
      "Pengcheng Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13521",
    "title": "Test-Driven Development for Code Generation",
    "abstract": "Large language models (LLMs) like GPT4, have shown proficiency in generating code snippets from problem statements. Traditionally software development by humans followed a similar methodology of writing code from problem statements or requirements. However, in the past, there have been several studies that have shown the value of test-driven development (TDD) where humans write tests based on problem statements before the code for the functionality is written. In the context of LLM-based code generation, one obvious benefit of TDD is that the developer then knows for sure if the generated code has passed all the given tests or not. Therefore, in this paper, we want to empirically evaluate the hypothesis: giving the problem statements and tests as input to GPT4 is better than just giving the problem statement as input. To test our hypothesis, we build a framework TGen. In our experiments on the MBPP, HumanEval and CodeChef datasets, we consistently find that including tests solves more programming problems than not including them. Thus we show that TDD is a better development model than just using a problem statement when using GPT4 for code generation tasks. ",
    "url": "https://arxiv.org/abs/2402.13521",
    "authors": [
      "Noble Saji Mathews",
      "Meiyappan Nagappan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13525",
    "title": "MatchNAS: Optimizing Edge AI in Sparse-Label Data Contexts via  Automating Deep Neural Network Porting for Mobile Deployment",
    "abstract": "Recent years have seen the explosion of edge intelligence with powerful Deep Neural Networks (DNNs). One popular scheme is training DNNs on powerful cloud servers and subsequently porting them to mobile devices after being lightweight. Conventional approaches manually specialized DNNs for various edge platforms and retrain them with real-world data. However, as the number of platforms increases, these approaches become labour-intensive and computationally prohibitive. Additionally, real-world data tends to be sparse-label, further increasing the difficulty of lightweight models. In this paper, we propose MatchNAS, a novel scheme for porting DNNs to mobile devices. Specifically, we simultaneously optimise a large network family using both labelled and unlabelled data and then automatically search for tailored networks for different hardware platforms. MatchNAS acts as an intermediary that bridges the gap between cloud-based DNNs and edge-based DNNs. ",
    "url": "https://arxiv.org/abs/2402.13525",
    "authors": [
      "Hongtao Huang",
      "Xiaojun Chang",
      "Wen Hu",
      "Lina Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.13528",
    "title": "Infrastructure Ombudsman: Mining Future Failure Concerns from Structural  Disaster Response",
    "abstract": "Current research concentrates on studying discussions on social media related to structural failures to improve disaster response strategies. However, detecting social web posts discussing concerns about anticipatory failures is under-explored. If such concerns are channeled to the appropriate authorities, it can aid in the prevention and mitigation of potential infrastructural failures. In this paper, we develop an infrastructure ombudsman -- that automatically detects specific infrastructure concerns. Our work considers several recent structural failures in the US. We present a first-of-its-kind dataset of 2,662 social web instances for this novel task mined from Reddit and YouTube. ",
    "url": "https://arxiv.org/abs/2402.13528",
    "authors": [
      "Md Towhidul Absar Chowdhury",
      "Soumyajit Datta",
      "Naveen Sharma",
      "Ashiqur R. KhudaBukhsh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.13529",
    "title": "Multitier Service Migration Framework Based on Mobility Prediction in  Mobile Edge Computing",
    "abstract": "Mobile edge computing (MEC) pushes computing resources to the edge of the network and distributes them at the edge of the mobile network. Offloading computing tasks to the edge instead of the cloud can reduce computing latency and backhaul load simultaneously. However, new challenges incurred by user mobility and limited coverage of MEC server service arise. Services should be dynamically migrated between multiple MEC servers to maintain service performance due to user movement. Tackling this problem is nontrivial because it is arduous to predict user movement, and service migration will generate service interruptions and redundant network traffic. Service interruption time must be minimized, and redundant network traffic should be reduced to ensure service quality. In this paper, the container lives migration technology based on prediction is studied, and an online prediction method based on map data that does not rely on prior knowledge such as user trajectories is proposed to address this challenge in terms of mobility prediction accuracy. ",
    "url": "https://arxiv.org/abs/2402.13529",
    "authors": [
      "Run Yang",
      "Hui He",
      "Weizhe Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.13532",
    "title": "Backdoor Attacks on Dense Passage Retrievers for Disseminating  Misinformation",
    "abstract": "Dense retrievers and retrieval-augmented language models have been widely used in various NLP applications. Despite being designed to deliver reliable and secure outcomes, the vulnerability of retrievers to potential attacks remains unclear, raising concerns about their security. In this paper, we introduce a novel scenario where the attackers aim to covertly disseminate targeted misinformation, such as hate speech or advertisement, through a retrieval system. To achieve this, we propose a perilous backdoor attack triggered by grammar errors in dense passage retrieval. Our approach ensures that attacked models can function normally for standard queries but are manipulated to return passages specified by the attacker when users unintentionally make grammatical mistakes in their queries. Extensive experiments demonstrate the effectiveness and stealthiness of our proposed attack method. When a user query is error-free, our model consistently retrieves accurate information while effectively filtering out misinformation from the top-k results. However, when a query contains grammar errors, our system shows a significantly higher success rate in fetching the targeted content. ",
    "url": "https://arxiv.org/abs/2402.13532",
    "authors": [
      "Quanyu Long",
      "Yue Deng",
      "LeiLei Gan",
      "Wenya Wang",
      "Sinno Jialin Pan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13534",
    "title": "An Effective Incorporating Heterogeneous Knowledge Curriculum Learning  for Sequence Labeling",
    "abstract": "Sequence labeling models often benefit from incorporating external knowledge. However, this practice introduces data heterogeneity and complicates the model with additional modules, leading to increased expenses for training a high-performing model. To address this challenge, we propose a two-stage curriculum learning (TCL) framework specifically designed for sequence labeling tasks. The TCL framework enhances training by gradually introducing data instances from easy to hard, aiming to improve both performance and training speed. Furthermore, we explore different metrics for assessing the difficulty levels of sequence labeling tasks. Through extensive experimentation on six Chinese word segmentation (CWS) and Part-of-speech tagging (POS) datasets, we demonstrate the effectiveness of our model in enhancing the performance of sequence labeling models. Additionally, our analysis indicates that TCL accelerates training and alleviates the slow training problem associated with complex models. ",
    "url": "https://arxiv.org/abs/2402.13534",
    "authors": [
      "Xuemei Tang",
      "Qi Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13545",
    "title": "A Two-Stage Dual-Path Framework for Text Tampering Detection and  Recognition",
    "abstract": "Document tamper detection has always been an important aspect of tamper detection. Before the advent of deep learning, document tamper detection was difficult. We have made some explorations in the field of text tamper detection based on deep learning. Our Ps tamper detection method includes three steps: feature assistance, audit point positioning, and tamper recognition. It involves hierarchical filtering and graded output (tampered/suspected tampered/untampered). By combining artificial tamper data features, we simulate and augment data samples in various scenarios (cropping with noise addition/replacement, single character/space replacement, smearing/splicing, brightness/contrast adjustment, etc.). The auxiliary features include exif/binary stream keyword retrieval/noise, which are used for branch detection based on the results. Audit point positioning uses detection frameworks and controls thresholds for high and low density detection. Tamper recognition employs a dual-path dual-stream recognition network, with RGB and ELA stream feature extraction. After dimensionality reduction through self-correlation percentile pooling, the fused output is processed through vlad, yielding an accuracy of 0.804, recall of 0.659, and precision of 0.913. ",
    "url": "https://arxiv.org/abs/2402.13545",
    "authors": [
      "Guandong Li",
      "Xian Yang",
      "Wenpin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13551",
    "title": "Graph Representation of Narrative Context: Coherence Dependency via  Retrospective Questions",
    "abstract": "This work introduces a novel and practical paradigm for narrative comprehension, stemming from the observation that individual passages within narratives are often cohesively related than being isolated. We therefore propose to formulate a graph upon narratives dubbed NARCO that depicts a task-agnostic coherence dependency of the entire context. Especially, edges in NARCO encompass retrospective free-form questions between two context snippets reflecting high-level coherent relations, inspired by the cognitive perception of humans who constantly reinstate relevant events from prior context. Importantly, our graph is instantiated through our designed two-stage LLM prompting, thereby without reliance on human annotations. We present three unique studies on its practical utility, examining the edge efficacy via recap identification, local context augmentation via plot retrieval, and broader applications exemplified by long document QA. Experiments suggest that our approaches leveraging NARCO yield performance boost across all three tasks. ",
    "url": "https://arxiv.org/abs/2402.13551",
    "authors": [
      "Liyan Xu",
      "Jiangnan Li",
      "Mo Yu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13556",
    "title": "Inductive Graph Alignment Prompt: Bridging the Gap between Graph  Pre-training and Inductive Fine-tuning From Spectral Perspective",
    "abstract": "The \"Graph pre-training and fine-tuning\" paradigm has significantly improved Graph Neural Networks(GNNs) by capturing general knowledge without manual annotations for downstream tasks. However, due to the immense gap of data and tasks between the pre-training and fine-tuning stages, the model performance is still limited. Inspired by prompt fine-tuning in Natural Language Processing(NLP), many endeavors have been made to bridge the gap in graph domain. But existing methods simply reformulate the form of fine-tuning tasks to the pre-training ones. With the premise that the pre-training graphs are compatible with the fine-tuning ones, these methods typically operate in transductive setting. In order to generalize graph pre-training to inductive scenario where the fine-tuning graphs might significantly differ from pre-training ones, we propose a novel graph prompt based method called Inductive Graph Alignment Prompt(IGAP). Firstly, we unify the mainstream graph pre-training frameworks and analyze the essence of graph pre-training from graph spectral theory. Then we identify the two sources of the data gap in inductive setting: (i) graph signal gap and (ii) graph structure gap. Based on the insight of graph pre-training, we propose to bridge the graph signal gap and the graph structure gap with learnable prompts in the spectral space. A theoretical analysis ensures the effectiveness of our method. At last, we conduct extensive experiments among nodes classification and graph classification tasks under the transductive, semi-inductive and inductive settings. The results demonstrate that our proposed method can successfully bridge the data gap under different settings. ",
    "url": "https://arxiv.org/abs/2402.13556",
    "authors": [
      "Yuchen Yan",
      "Peiyan Zhang",
      "Zheng Fang",
      "Qingqing Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13578",
    "title": "TransGOP: Transformer-Based Gaze Object Prediction",
    "abstract": "Gaze object prediction aims to predict the location and category of the object that is watched by a human. Previous gaze object prediction works use CNN-based object detectors to predict the object's location. However, we find that Transformer-based object detectors can predict more accurate object location for dense objects in retail scenarios. Moreover, the long-distance modeling capability of the Transformer can help to build relationships between the human head and the gaze object, which is important for the GOP task. To this end, this paper introduces Transformer into the fields of gaze object prediction and proposes an end-to-end Transformer-based gaze object prediction method named TransGOP. Specifically, TransGOP uses an off-the-shelf Transformer-based object detector to detect the location of objects and designs a Transformer-based gaze autoencoder in the gaze regressor to establish long-distance gaze relationships. Moreover, to improve gaze heatmap regression, we propose an object-to-gaze cross-attention mechanism to let the queries of the gaze autoencoder learn the global-memory position knowledge from the object detector. Finally, to make the whole framework end-to-end trained, we propose a Gaze Box loss to jointly optimize the object detector and gaze regressor by enhancing the gaze heatmap energy in the box of the gaze object. Extensive experiments on the GOO-Synth and GOO-Real datasets demonstrate that our TransGOP achieves state-of-the-art performance on all tracks, i.e., object detection, gaze estimation, and gaze object prediction. Our code will be available at https://github.com/chenxi-Guo/TransGOP.git. ",
    "url": "https://arxiv.org/abs/2402.13578",
    "authors": [
      "Binglu Wang",
      "Chenxi Guo",
      "Yang Jin",
      "Haisheng Xia",
      "Nian Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13579",
    "title": "Learning Pixel-wise Continuous Depth Representation via Clustering for  Depth Completion",
    "abstract": "Depth completion is a long-standing challenge in computer vision, where classification-based methods have made tremendous progress in recent years. However, most existing classification-based methods rely on pre-defined pixel-shared and discrete depth values as depth categories. This representation fails to capture the continuous depth values that conform to the real depth distribution, leading to depth smearing in boundary regions. To address this issue, we revisit depth completion from the clustering perspective and propose a novel clustering-based framework called CluDe which focuses on learning the pixel-wise and continuous depth representation. The key idea of CluDe is to iteratively update the pixel-shared and discrete depth representation to its corresponding pixel-wise and continuous counterpart, driven by the real depth distribution. Specifically, CluDe first utilizes depth value clustering to learn a set of depth centers as the depth representation. While these depth centers are pixel-shared and discrete, they are more in line with the real depth distribution compared to pre-defined depth categories. Then, CluDe estimates offsets for these depth centers, enabling their dynamic adjustment along the depth axis of the depth distribution to generate the pixel-wise and continuous depth representation. Extensive experiments demonstrate that CluDe successfully reduces depth smearing around object boundaries by utilizing pixel-wise and continuous depth representation. Furthermore, CluDe achieves state-of-the-art performance on the VOID datasets and outperforms classification-based methods on the KITTI dataset. ",
    "url": "https://arxiv.org/abs/2402.13579",
    "authors": [
      "Chen Shenglun",
      "Zhang Hong",
      "Ma XinZhu",
      "Wang Zhihui",
      "Li Haojie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13593",
    "title": "Knowledge Graph Enhanced Large Language Model Editing",
    "abstract": "Large language models (LLMs) are pivotal in advancing natural language processing (NLP) tasks, yet their efficacy is hampered by inaccuracies and outdated knowledge. Model editing emerges as a promising solution to address these challenges. However, existing editing methods struggle to track and incorporate changes in knowledge associated with edits, which limits the generalization ability of postedit LLMs in processing edited knowledge. To tackle these problems, we propose a novel model editing method that leverages knowledge graphs for enhancing LLM editing, namely GLAME. Specifically, we first utilize a knowledge graph augmentation module to uncover associated knowledge that has changed due to editing, obtaining its internal representations within LLMs. This approach allows knowledge alterations within LLMs to be reflected through an external graph structure. Subsequently, we design a graph-based knowledge edit module to integrate structured knowledge into the model editing. This ensures that the updated parameters reflect not only the modifications of the edited knowledge but also the changes in other associated knowledge resulting from the editing process. Comprehensive experiments conducted on GPT-J and GPT-2 XL demonstrate that GLAME significantly improves the generalization capabilities of post-edit LLMs in employing edited knowledge. ",
    "url": "https://arxiv.org/abs/2402.13593",
    "authors": [
      "Mengqi Zhang",
      "Xiaotian Ye",
      "Qiang Liu",
      "Pengjie Ren",
      "Shu Wu",
      "Zhumin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13605",
    "title": "KorNAT: LLM Alignment Benchmark for Korean Social Values and Common  Knowledge",
    "abstract": "For Large Language Models (LLMs) to be effectively deployed in a specific country, they must possess an understanding of the nation's culture and basic knowledge. To this end, we introduce National Alignment, which measures an alignment between an LLM and a targeted country from two aspects: social value alignment and common knowledge alignment. Social value alignment evaluates how well the model understands nation-specific social values, while common knowledge alignment examines how well the model captures basic knowledge related to the nation. We constructed KorNAT, the first benchmark that measures national alignment with South Korea. For the social value dataset, we obtained ground truth labels from a large-scale survey involving 6,174 unique Korean participants. For the common knowledge dataset, we constructed samples based on Korean textbooks and GED reference materials. KorNAT contains 4K and 6K multiple-choice questions for social value and common knowledge, respectively. Our dataset creation process is meticulously designed and based on statistical sampling theory and was refined through multiple rounds of human review. The experiment results of seven LLMs reveal that only a few models met our reference score, indicating a potential for further enhancement. KorNAT has received government approval after passing an assessment conducted by a government-affiliated organization dedicated to evaluating dataset quality. Samples and detailed evaluation protocols of our dataset can be found in \\url{https://selectstar.ai/ko/papers-national-alignment#} ",
    "url": "https://arxiv.org/abs/2402.13605",
    "authors": [
      "Jiyoung Lee",
      "Minwoo Kim",
      "Seungho Kim",
      "Junghwan Kim",
      "Seunghyun Won",
      "Hwaran Lee",
      "Edward Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13609",
    "title": "VOOM: Robust Visual Object Odometry and Mapping using Hierarchical  Landmarks",
    "abstract": "In recent years, object-oriented simultaneous localization and mapping (SLAM) has attracted increasing attention due to its ability to provide high-level semantic information while maintaining computational efficiency. Some researchers have attempted to enhance localization accuracy by integrating the modeled object residuals into bundle adjustment. However, few have demonstrated better results than feature-based visual SLAM systems, as the generic coarse object models, such as cuboids or ellipsoids, are less accurate than feature points. In this paper, we propose a Visual Object Odometry and Mapping framework VOOM using high-level objects and low-level points as the hierarchical landmarks in a coarse-to-fine manner instead of directly using object residuals in bundle adjustment. Firstly, we introduce an improved observation model and a novel data association method for dual quadrics, employed to represent physical objects. It facilitates the creation of a 3D map that closely reflects reality. Next, we use object information to enhance the data association of feature points and consequently update the map. In the visual object odometry backend, the updated map is employed to further optimize the camera pose and the objects. Meanwhile, local bundle adjustment is performed utilizing the objects and points-based covisibility graphs in our visual object mapping process. Experiments show that VOOM outperforms both object-oriented SLAM and feature points SLAM systems such as ORB-SLAM2 in terms of localization. The implementation of our method is available at https://github.com/yutongwangBIT/VOOM.git. ",
    "url": "https://arxiv.org/abs/2402.13609",
    "authors": [
      "Yutong Wang",
      "Chaoyang Jiang",
      "Xieyuanli Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13613",
    "title": "Overview of the VLSP 2023 -- ComOM Shared Task: A Data Challenge for  Comparative Opinion Mining from Vietnamese Product Reviews",
    "abstract": "This paper presents a comprehensive overview of the Comparative Opinion Mining from Vietnamese Product Reviews shared task (ComOM), held as part of the 10$^{th}$ International Workshop on Vietnamese Language and Speech Processing (VLSP 2023). The primary objective of this shared task is to advance the field of natural language processing by developing techniques that proficiently extract comparative opinions from Vietnamese product reviews. Participants are challenged to propose models that adeptly extract a comparative \"quintuple\" from a comparative sentence, encompassing Subject, Object, Aspect, Predicate, and Comparison Type Label. We construct a human-annotated dataset comprising $120$ documents, encompassing $7427$ non-comparative sentences and $2468$ comparisons within $1798$ sentences. Participating models undergo evaluation and ranking based on the Exact match macro-averaged quintuple F1 score. ",
    "url": "https://arxiv.org/abs/2402.13613",
    "authors": [
      "Hoang-Quynh Le",
      "Duy-Cat Can",
      "Khanh-Vinh Nguyen",
      "Mai-Vu Tran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13623",
    "title": "FLAME: Self-Supervised Low-Resource Taxonomy Expansion using Large  Language Models",
    "abstract": "Taxonomies represent an arborescence hierarchical structure that establishes relationships among entities to convey knowledge within a specific domain. Each edge in the taxonomy signifies a hypernym-hyponym relationship. Taxonomies find utility in various real-world applications, such as e-commerce search engines and recommendation systems. Consequently, there arises a necessity to enhance these taxonomies over time. However, manually curating taxonomies with neoteric data presents challenges due to limitations in available human resources and the exponential growth of data. Therefore, it becomes imperative to develop automatic taxonomy expansion methods. Traditional supervised taxonomy expansion approaches encounter difficulties stemming from limited resources, primarily due to the small size of existing taxonomies. This scarcity of training data often leads to overfitting. In this paper, we propose FLAME, a novel approach for taxonomy expansion in low-resource environments by harnessing the capabilities of large language models that are trained on extensive real-world knowledge. LLMs help compensate for the scarcity of domain-specific knowledge. Specifically, FLAME leverages prompting in few-shot settings to extract the inherent knowledge within the LLMs, ascertaining the hypernym entities within the taxonomy. Furthermore, it employs reinforcement learning to fine-tune the large language models, resulting in more accurate predictions. Experiments on three real-world benchmark datasets demonstrate the effectiveness of FLAME in real-world scenarios, achieving a remarkable improvement of 18.5% in accuracy and 12.3% in Wu & Palmer metric over eight baselines. Furthermore, we elucidate the strengths and weaknesses of FLAME through an extensive case study, error analysis and ablation studies on the benchmarks. ",
    "url": "https://arxiv.org/abs/2402.13623",
    "authors": [
      "Sahil Mishra",
      "Ujjwal Sudev",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.13630",
    "title": "UniGraph: Learning a Cross-Domain Graph Foundation Model From Natural  Language",
    "abstract": "Foundation models like ChatGPT and GPT-4 have revolutionized artificial intelligence, exhibiting remarkable abilities to generalize across a wide array of tasks and applications beyond their initial training objectives. However, when this concept is applied to graph learning, a stark contrast emerges. Graph learning has predominantly focused on single-graph models, tailored to specific tasks or datasets, lacking the ability to transfer learned knowledge to different domains. This limitation stems from the inherent complexity and diversity of graph structures, along with the different feature and label spaces specific to graph data. In this paper, we present our UniGraph framework, designed to train a graph foundation model capable of generalizing to unseen graphs and tasks across diverse domains. Unlike single-graph models that use pre-computed node features of varying dimensions as input, our approach leverages Text-Attributed Graphs (TAGs) for unifying node representations. We propose a cascaded architecture of Language Models (LMs) and Graph Neural Networks (GNNs) as backbone networks with a self-supervised training objective based on Masked Graph Modeling (MGM). We introduce graph instruction tuning using Large Language Models (LLMs) to enable zero-shot prediction ability. Our comprehensive experiments across various graph learning tasks and domains demonstrate the model's effectiveness in self-supervised representation learning on unseen graphs, few-shot in-context transfer, and zero-shot transfer, even surpassing or matching the performance of GNNs that have undergone supervised training on target datasets. ",
    "url": "https://arxiv.org/abs/2402.13630",
    "authors": [
      "Yufei He",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13631",
    "title": "Delving into Dark Regions for Robust Shadow Detection",
    "abstract": "Shadow detection is a challenging task as it requires a comprehensive understanding of shadow characteristics and global/local illumination conditions. We observe from our experiment that state-of-the-art deep methods tend to have higher error rates in differentiating shadow pixels from non-shadow pixels in dark regions (ie, regions with low-intensity values). Our key insight to this problem is that existing methods typically learn discriminative shadow features from the whole image globally, covering the full range of intensity values, and may not learn the subtle differences between shadow and non-shadow pixels in dark regions. Hence, if we can design a model to focus on a narrower range of low-intensity regions, it may be able to learn better discriminative features for shadow detection. Inspired by this insight, we propose a novel shadow detection approach that first learns global contextual cues over the entire image and then zooms into the dark regions to learn local shadow representations. To this end, we formulate an effective dark-region recommendation (DRR) module to recommend regions of low-intensity values, and a novel dark-aware shadow analysis (DASA) module to learn dark-aware shadow features from the recommended dark regions. Extensive experiments show that the proposed method outperforms the state-of-the-art methods on three popular shadow detection datasets. Code is available at https://github.com/guanhuankang/ShadowDetection2021.git. ",
    "url": "https://arxiv.org/abs/2402.13631",
    "authors": [
      "Huankang Guan",
      "Ke Xu",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13651",
    "title": "Robustness of Deep Neural Networks for Micro-Doppler Radar  Classification",
    "abstract": "With the great capabilities of deep classifiers for radar data processing come the risks of learning dataset-specific features that do not generalize well. In this work, the robustness of two deep convolutional architectures, trained and tested on the same data, is evaluated. When standard training practice is followed, both classifiers exhibit sensitivity to subtle temporal shifts of the input representation, an augmentation that carries minimal semantic content. Furthermore, the models are extremely susceptible to adversarial examples. Both small temporal shifts and adversarial examples are a result of a model overfitting on features that do not generalize well. As a remedy, it is shown that training on adversarial examples and temporally augmented samples can reduce this effect and lead to models that generalise better. Finally, models operating on cadence-velocity diagram representation rather than Doppler-time are demonstrated to be naturally more immune to adversarial examples. ",
    "url": "https://arxiv.org/abs/2402.13651",
    "authors": [
      "Mikolaj Czerkawski",
      "Carmine Clemente",
      "Craig MichieCraig Michie",
      "Christos Tachtatzis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.13671",
    "title": "KInIT at SemEval-2024 Task 8: Fine-tuned LLMs for Multilingual  Machine-Generated Text Detection",
    "abstract": "SemEval-2024 Task 8 is focused on multigenerator, multidomain, and multilingual black-box machine-generated text detection. Such a detection is important for preventing a potential misuse of large language models (LLMs), the newest of which are very capable in generating multilingual human-like texts. We have coped with this task in multiple ways, utilizing language identification and parameter-efficient fine-tuning of smaller LLMs for text classification. We have further used the per-language classification-threshold calibration to uniquely combine fine-tuned models predictions with statistical detection metrics to improve generalization of the system detection performance. Our submitted method achieved competitive results, ranking at the fourth place, just under 1 percentage point behind the winner. ",
    "url": "https://arxiv.org/abs/2402.13671",
    "authors": [
      "Michal Spiegel",
      "Dominik Macko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13693",
    "title": "CMNER: A Chinese Multimodal NER Dataset based on Social Media",
    "abstract": "Multimodal Named Entity Recognition (MNER) is a pivotal task designed to extract named entities from text with the support of pertinent images. Nonetheless, a notable paucity of data for Chinese MNER has considerably impeded the progress of this natural language processing task within the Chinese domain. Consequently, in this study, we compile a Chinese Multimodal NER dataset (CMNER) utilizing data sourced from Weibo, China's largest social media platform. Our dataset encompasses 5,000 Weibo posts paired with 18,326 corresponding images. The entities are classified into four distinct categories: person, location, organization, and miscellaneous. We perform baseline experiments on CMNER, and the outcomes underscore the effectiveness of incorporating images for NER. Furthermore, we conduct cross-lingual experiments on the publicly available English MNER dataset (Twitter2015), and the results substantiate our hypothesis that Chinese and English multimodal NER data can mutually enhance the performance of the NER model. ",
    "url": "https://arxiv.org/abs/2402.13693",
    "authors": [
      "Yuanze Ji",
      "Bobo Li",
      "Jun Zhou",
      "Fei Li",
      "Chong Teng",
      "Donghong Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13700",
    "title": "On the Conflict of Robustness and Learning in Collaborative Machine  Learning",
    "abstract": "Collaborative Machine Learning (CML) allows participants to jointly train a machine learning model while keeping their training data private. In scenarios where privacy is a strong requirement, such as health-related applications, safety is also a primary concern. This means that privacy-preserving CML processes must produce models that output correct and reliable decisions \\emph{even in the presence of potentially untrusted participants}. In response to this issue, researchers propose to use \\textit{robust aggregators} that rely on metrics which help filter out malicious contributions that could compromise the training process. In this work, we formalize the landscape of robust aggregators in the literature. Our formalization allows us to show that existing robust aggregators cannot fulfill their goal: either they use distance-based metrics that cannot accurately identify targeted malicious updates; or propose methods whose success is in direct conflict with the ability of CML participants to learn from others and therefore cannot eliminate the risk of manipulation without preventing learning. ",
    "url": "https://arxiv.org/abs/2402.13700",
    "authors": [
      "Mathilde Raynal",
      "Carmela Troncoso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.13711",
    "title": "DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based  Graph Continual Learning",
    "abstract": "We investigate the replay buffer in rehearsal-based approaches for graph continual learning (GCL) methods. Existing rehearsal-based GCL methods select the most representative nodes for each class and store them in a replay buffer for later use in training subsequent tasks. However, we discovered that considering only the class representativeness of each replayed node makes the replayed nodes to be concentrated around the center of each class, incurring a potential risk of overfitting to nodes residing in those regions, which aggravates catastrophic forgetting. Moreover, as the rehearsal-based approach heavily relies on a few replayed nodes to retain knowledge obtained from previous tasks, involving the replayed nodes that have irrelevant neighbors in the model training may have a significant detrimental impact on model performance. In this paper, we propose a GCL model named DSLR, specifically, we devise a coverage-based diversity (CD) approach to consider both the class representativeness and the diversity within each class of the replayed nodes. Moreover, we adopt graph structure learning (GSL) to ensure that the replayed nodes are connected to truly informative neighbors. Extensive experimental results demonstrate the effectiveness and efficiency of DSLR. ",
    "url": "https://arxiv.org/abs/2402.13711",
    "authors": [
      "Seungyoon Choi",
      "Wonjoong Kim",
      "Sungwon Kim",
      "Yeonjun In",
      "Sein Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13723",
    "title": "The Effect of Batch Size on Contrastive Self-Supervised Speech  Representation Learning",
    "abstract": "Foundation models in speech are often trained using many GPUs, which implicitly leads to large effective batch sizes. In this paper we study the effect of batch size on pre-training, both in terms of statistics that can be monitored during training, and in the effect on the performance of a downstream fine-tuning task. By using batch sizes varying from 87.5 seconds to 80 minutes of speech we show that, for a fixed amount of iterations, larger batch sizes result in better pre-trained models. However, there is lower limit for stability, and an upper limit for effectiveness. We then show that the quality of the pre-trained model depends mainly on the amount of speech data seen during training, i.e., on the product of batch size and number of iterations. All results are produced with an independent implementation of the wav2vec 2.0 architecture, which to a large extent reproduces the results of the original work (arXiv:2006.11477). Our extensions can help researchers choose effective operating conditions when studying self-supervised learning in speech, and hints towards benchmarking self-supervision with a fixed amount of seen data. Code and model checkpoints are available at https://github.com/nikvaessen/w2v2-batch-size. ",
    "url": "https://arxiv.org/abs/2402.13723",
    "authors": [
      "Nik Vaessen",
      "David A. van Leeuwen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.13725",
    "title": "Sparse and Structured Hopfield Networks",
    "abstract": "Modern Hopfield networks have enjoyed recent interest due to their connection to attention in transformers. Our paper provides a unified framework for sparse Hopfield networks by establishing a link with Fenchel-Young losses. The result is a new family of Hopfield-Fenchel-Young energies whose update rules are end-to-end differentiable sparse transformations. We reveal a connection between loss margins, sparsity, and exact memory retrieval. We further extend this framework to structured Hopfield networks via the SparseMAP transformation, which can retrieve pattern associations instead of a single pattern. Experiments on multiple instance learning and text rationalization demonstrate the usefulness of our approach. ",
    "url": "https://arxiv.org/abs/2402.13725",
    "authors": [
      "Saul Santos",
      "Vlad Niculae",
      "Daniel McNamee",
      "Andre F. T. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13728",
    "title": "Average gradient outer product as a mechanism for deep neural collapse",
    "abstract": "Deep Neural Collapse (DNC) refers to the surprisingly rigid structure of the data representations in the final layers of Deep Neural Networks (DNNs). Though the phenomenon has been measured in a wide variety of settings, its emergence is only partially understood. In this work, we provide substantial evidence that DNC formation occurs primarily through deep feature learning with the average gradient outer product (AGOP). This takes a step further compared to efforts that explain neural collapse via feature-agnostic approaches, such as the unconstrained features model. We proceed by providing evidence that the right singular vectors and values of the weights are responsible for the majority of within-class variability collapse in DNNs. As shown in recent work, this singular structure is highly correlated with that of the AGOP. We then establish experimentally and theoretically that AGOP induces neural collapse in a randomly initialized neural network. In particular, we demonstrate that Deep Recursive Feature Machines, a method originally introduced as an abstraction for AGOP feature learning in convolutional neural networks, exhibits DNC. ",
    "url": "https://arxiv.org/abs/2402.13728",
    "authors": [
      "Daniel Beaglehole",
      "Peter S\u00faken\u00edk",
      "Marco Mondelli",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.13729",
    "title": "Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet  Representation",
    "abstract": "Generating high-quality videos that synthesize desired realistic content is a challenging task due to their intricate high-dimensionality and complexity of videos. Several recent diffusion-based methods have shown comparable performance by compressing videos to a lower-dimensional latent space, using traditional video autoencoder architecture. However, such method that employ standard frame-wise 2D and 3D convolution fail to fully exploit the spatio-temporal nature of videos. To address this issue, we propose a novel hybrid video diffusion model, called HVDM, which can capture spatio-temporal dependencies more effectively. The HVDM is trained by a hybrid video autoencoder which extracts a disentangled representation of the video including: (i) a global context information captured by a 2D projected latent (ii) a local volume information captured by 3D convolutions with wavelet decomposition (iii) a frequency information for improving the video reconstruction. Based on this disentangled representation, our hybrid autoencoder provide a more comprehensive video latent enriching the generated videos with fine structures and details. Experiments on video generation benchamarks (UCF101, SkyTimelapse, and TaiChi) demonstrate that the proposed approach achieves state-of-the-art video generation quality, showing a wide range of video applications (e.g., long video generation, image-to-video, and video dynamics control). ",
    "url": "https://arxiv.org/abs/2402.13729",
    "authors": [
      "Kihong Kim",
      "Haneol Lee",
      "Jihye Park",
      "Seyeon Kim",
      "Kwanghee Lee",
      "Seungryong Kim",
      "Jaejun Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13731",
    "title": "The Da Vinci Code of Large Pre-trained Language Models: Deciphering  Degenerate Knowledge Neurons",
    "abstract": "This study explores the mechanism of factual knowledge storage in pre-trained language models (PLMs). Previous research suggests that factual knowledge is stored within multi-layer perceptron weights, and some storage units exhibit degeneracy, referred to as Degenerate Knowledge Neurons (DKNs). This paper provides a comprehensive definition of DKNs that covers both structural and functional aspects, pioneering the study of structures in PLMs' factual knowledge storage units. Based on this, we introduce the Neurological Topology Clustering method, which allows the formation of DKNs in any numbers and structures, leading to a more accurate DKN acquisition. Furthermore, we introduce the Neuro-Degeneracy Analytic Analysis Framework, which uniquely integrates model robustness, evolvability, and complexity for a holistic assessment of PLMs. Within this framework, our execution of 34 experiments across 2 PLMs, 4 datasets, and 6 settings highlights the critical role of DKNs. The code will be available soon. ",
    "url": "https://arxiv.org/abs/2402.13731",
    "authors": [
      "Yuheng Chen",
      "Pengfei Cao",
      "Yubo Chen",
      "Yining Wang",
      "Shengping Liu",
      "Kang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13744",
    "title": "Reasoning Algorithmically in Graph Neural Networks",
    "abstract": "The development of artificial intelligence systems with advanced reasoning capabilities represents a persistent and long-standing research question. Traditionally, the primary strategy to address this challenge involved the adoption of symbolic approaches, where knowledge was explicitly represented by means of symbols and explicitly programmed rules. However, with the advent of machine learning, there has been a paradigm shift towards systems that can autonomously learn from data, requiring minimal human guidance. In light of this shift, in latest years, there has been increasing interest and efforts at endowing neural networks with the ability to reason, bridging the gap between data-driven learning and logical reasoning. Within this context, Neural Algorithmic Reasoning (NAR) stands out as a promising research field, aiming to integrate the structured and rule-based reasoning of algorithms with the adaptive learning capabilities of neural networks, typically by tasking neural models to mimic classical algorithms. In this dissertation, we provide theoretical and practical contributions to this area of research. We explore the connections between neural networks and tropical algebra, deriving powerful architectures that are aligned with algorithm execution. Furthermore, we discuss and show the ability of such neural reasoners to learn and manipulate complex algorithmic and combinatorial optimization concepts, such as the principle of strong duality. Finally, in our empirical efforts, we validate the real-world utility of NAR networks across different practical scenarios. This includes tasks as diverse as planning problems, large-scale edge classification tasks and the learning of polynomial-time approximate algorithms for NP-hard combinatorial problems. Through this exploration, we aim to showcase the potential integrating algorithmic reasoning in machine learning models. ",
    "url": "https://arxiv.org/abs/2402.13744",
    "authors": [
      "Danilo Numeroso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13746",
    "title": "A Unified Knowledge Graph to Permit Interoperability of Heterogeneous  Digital Evidence",
    "abstract": "The modern digital world is highly heterogeneous, encompassing a wide variety of communications, devices, and services. This interconnectedness generates, synchronises, stores, and presents digital information in multidimensional, complex formats, often fragmented across multiple sources. When linked to misuse, this digital information becomes vital digital evidence. Integrating and harmonising these diverse formats into a unified system is crucial for comprehensively understanding evidence and its relationships. However, existing approaches to date have faced challenges limiting investigators' ability to query heterogeneous evidence across large datasets. This paper presents a novel approach in the form of a modern unified data graph. The proposed approach aims to seamlessly integrate, harmonise, and unify evidence data, enabling cross-platform interoperability, efficient data queries, and improved digital investigation performance. To demonstrate its efficacy, a case study is conducted, highlighting the benefits of the proposed approach and showcasing its effectiveness in enabling the interoperability required for advanced analytics in digital investigations. ",
    "url": "https://arxiv.org/abs/2402.13746",
    "authors": [
      "Ali Alshumrani",
      "Nathan Clarke",
      "Bogdan Ghita"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.13750",
    "title": "Breaking the Barrier: Utilizing Large Language Models for Industrial  Recommendation Systems through an Inferential Knowledge Graph",
    "abstract": "Recommendation systems are widely used in e-commerce websites and online platforms to address information overload. However, existing systems primarily rely on historical data and user feedback, making it difficult to capture user intent transitions. Recently, Knowledge Base (KB)-based models are proposed to incorporate expert knowledge, but it struggle to adapt to new items and the evolving e-commerce environment. To address these challenges, we propose a novel Large Language Model based Complementary Knowledge Enhanced Recommendation System (LLM-KERec). It introduces an entity extractor that extracts unified concept terms from item and user information. To provide cost-effective and reliable prior knowledge, entity pairs are generated based on entity popularity and specific strategies. The large language model determines complementary relationships in each entity pair, constructing a complementary knowledge graph. Furthermore, a new complementary recall module and an Entity-Entity-Item (E-E-I) weight decision model refine the scoring of the ranking model using real complementary exposure-click samples. Extensive experiments conducted on three industry datasets demonstrate the significant performance improvement of our model compared to existing approaches. Additionally, detailed analysis shows that LLM-KERec enhances users' enthusiasm for consumption by recommending complementary items. In summary, LLM-KERec addresses the limitations of traditional recommendation systems by incorporating complementary knowledge and utilizing a large language model to capture user intent transitions, adapt to new items, and enhance recommendation efficiency in the evolving e-commerce landscape. ",
    "url": "https://arxiv.org/abs/2402.13750",
    "authors": [
      "Qian Zhao",
      "Hao Qian",
      "Ziqi Liu",
      "Gong-Duo Zhang",
      "Lihong Gu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13755",
    "title": "Adaptive Massively Parallel Coloring in Sparse Graphs",
    "abstract": "Classic symmetry-breaking problems on graphs have gained a lot of attention in models of modern parallel computation. The Adaptive Massively Parallel Computation (AMPC) is a model that captures central challenges in data center computations. Chang et al. [PODC'2019] gave an extremely fast, constant time, algorithm for the $(\\Delta + 1)$-coloring problem, where $\\Delta$ is the maximum degree of an input graph of $n$ nodes. The algorithm works in the most restrictive low-space setting, where each machine has $n^{\\delta}$ local space for a constant $0 < \\delta < 1$. In this work, we study the vertex-coloring problem in sparse graphs parameterized by their arboricity $\\alpha$, a standard measure for sparsity. We give deterministic algorithms that in constant, or almost constant, time give $\\text{poly}(\\alpha)$ and $O(\\alpha)$-colorings, where $\\alpha$ can be arbitrarily smaller than $\\Delta$. A strong and standard approach to compute arboricity-dependent colorings is through the Nash-Williams forest decomposition, which gives rise to an (acyclic) orientation of the edges such that each node has a small outdegree. Our main technical contribution is giving efficient deterministic algorithms to compute these orientations and showing how to leverage them to find colorings in low-space AMPC. A key technical challenge is that the color of a node may depend on almost all of the other nodes in the graph and these dependencies cannot be stored on a single machine. Nevertheless, our novel and careful exploration technique yields the orientation, and the arboricity-dependent coloring, with a sublinear number of adaptive queries per node. ",
    "url": "https://arxiv.org/abs/2402.13755",
    "authors": [
      "Rustam Latypov",
      "Yannic Maus",
      "Shreyas Pai",
      "Jara Uitto"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.13756",
    "title": "High-throughput Visual Nano-drone to Nano-drone Relative Localization  using Onboard Fully Convolutional Networks",
    "abstract": "Relative drone-to-drone localization is a fundamental building block for any swarm operations. We address this task in the context of miniaturized nano-drones, i.e., 10cm in diameter, which show an ever-growing interest due to novel use cases enabled by their reduced form factor. The price for their versatility comes with limited onboard resources, i.e., sensors, processing units, and memory, which limits the complexity of the onboard algorithms. A traditional solution to overcome these limitations is represented by lightweight deep learning models directly deployed aboard nano-drones. This work tackles the challenging relative pose estimation between nano-drones using only a gray-scale low-resolution camera and an ultra-low-power System-on-Chip (SoC) hosted onboard. We present a vertically integrated system based on a novel vision-based fully convolutional neural network (FCNN), which runs at 39Hz within 101mW onboard a Crazyflie nano-drone extended with the GWT GAP8 SoC. We compare our FCNN against three State-of-the-Art (SoA) systems. Considering the best-performing SoA approach, our model results in an R-squared improvement from 32 to 47% on the horizontal image coordinate and from 18 to 55% on the vertical image coordinate, on a real-world dataset of 30k images. Finally, our in-field tests show a reduction of the average tracking error of 37% compared to a previous SoA work and an endurance performance up to the entire battery lifetime of 4 minutes. ",
    "url": "https://arxiv.org/abs/2402.13756",
    "authors": [
      "Luca Crupi",
      "Alessandro Giusti",
      "Daniele Palossi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.13769",
    "title": "General Debiasing for Graph-based Collaborative Filtering via  Adversarial Graph Dropout",
    "abstract": "Graph neural networks (GNNs) have shown impressive performance in recommender systems, particularly in collaborative filtering (CF). The key lies in aggregating neighborhood information on a user-item interaction graph to enhance user/item representations. However, we have discovered that this aggregation mechanism comes with a drawback, which amplifies biases present in the interaction graph. For instance, a user's interactions with items can be driven by both unbiased true interest and various biased factors like item popularity or exposure. However, the current aggregation approach combines all information, both biased and unbiased, leading to biased representation learning. Consequently, graph-based recommenders can learn distorted views of users/items, hindering the modeling of their true preferences and generalizations. To address this issue, we introduce a novel framework called Adversarial Graph Dropout (AdvDrop). It differentiates between unbiased and biased interactions, enabling unbiased representation learning. For each user/item, AdvDrop employs adversarial learning to split the neighborhood into two views: one with bias-mitigated interactions and the other with bias-aware interactions. After view-specific aggregation, AdvDrop ensures that the bias-mitigated and bias-aware representations remain invariant, shielding them from the influence of bias. We validate AdvDrop's effectiveness on five public datasets that cover both general and specific biases, demonstrating significant improvements. Furthermore, our method exhibits meaningful separation of subgraphs and achieves unbiased representations for graph-based CF models, as revealed by in-depth analysis. Our code is publicly available at https://github.com/Arthurma71/AdvDrop. ",
    "url": "https://arxiv.org/abs/2402.13769",
    "authors": [
      "An Zhang",
      "Wenchang Ma",
      "Pengbo Wei",
      "Leheng Sheng",
      "Xiang Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.13779",
    "title": "Contextual Molecule Representation Learning from Chemical Reaction  Knowledge",
    "abstract": "In recent years, self-supervised learning has emerged as a powerful tool to harness abundant unlabelled data for representation learning and has been broadly adopted in diverse areas. However, when applied to molecular representation learning (MRL), prevailing techniques such as masked sub-unit reconstruction often fall short, due to the high degree of freedom in the possible combinations of atoms within molecules, which brings insurmountable complexity to the masking-reconstruction paradigm. To tackle this challenge, we introduce REMO, a self-supervised learning framework that takes advantage of well-defined atom-combination rules in common chemistry. Specifically, REMO pre-trains graph/Transformer encoders on 1.7 million known chemical reactions in the literature. We propose two pre-training objectives: Masked Reaction Centre Reconstruction (MRCR) and Reaction Centre Identification (RCI). REMO offers a novel solution to MRL by exploiting the underlying shared patterns in chemical reactions as \\textit{context} for pre-training, which effectively infers meaningful representations of common chemistry knowledge. Such contextual representations can then be utilized to support diverse downstream molecular tasks with minimum finetuning, such as affinity prediction and drug-drug interaction prediction. Extensive experimental results on MoleculeACE, ACNet, drug-drug interaction (DDI), and reaction type classification show that across all tested downstream tasks, REMO outperforms the standard baseline of single-molecule masked modeling used in current MRL. Remarkably, REMO is the pioneering deep learning model surpassing fingerprint-based methods in activity cliff benchmarks. ",
    "url": "https://arxiv.org/abs/2402.13779",
    "authors": [
      "Han Tang",
      "Shikun Feng",
      "Bicheng Lin",
      "Yuyan Ni",
      "JIngjing Liu",
      "Wei-Ying Ma",
      "Yanyan Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2402.13787",
    "title": "Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks",
    "abstract": "In this paper, we investigate the conditions under which link analysis algorithms prevent minority groups from reaching high ranking slots. We find that the most common link-based algorithms using centrality metrics, such as PageRank and HITS, can reproduce and even amplify bias against minority groups in networks. Yet, their behavior differs: one one hand, we empirically show that PageRank mirrors the degree distribution for most of the ranking positions and it can equalize representation of minorities among the top ranked nodes; on the other hand, we find that HITS amplifies pre-existing bias in homophilic networks through a novel theoretical analysis, supported by empirical results. We find the root cause of bias amplification in HITS to be the level of homophily present in the network, modeled through an evolving network model with two communities. We illustrate our theoretical analysis on both synthetic and real datasets and we present directions for future work. ",
    "url": "https://arxiv.org/abs/2402.13787",
    "authors": [
      "Ana-Andreea Stoica",
      "Nelly Litvak",
      "Augustin Chaintreau"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.13796",
    "title": "Scalable Methods for Brick Kiln Detection and Compliance Monitoring from  Satellite Imagery: A Deployment Case Study in India",
    "abstract": "Air pollution kills 7 million people annually. Brick manufacturing industry is the second largest consumer of coal contributing to 8%-14% of air pollution in Indo-Gangetic plain (highly populated tract of land in the Indian subcontinent). As brick kilns are an unorganized sector and present in large numbers, detecting policy violations such as distance from habitat is non-trivial. Air quality and other domain experts rely on manual human annotation to maintain brick kiln inventory. Previous work used computer vision based machine learning methods to detect brick kilns from satellite imagery but they are limited to certain geographies and labeling the data is laborious. In this paper, we propose a framework to deploy a scalable brick kiln detection system for large countries such as India and identify 7477 new brick kilns from 28 districts in 5 states in the Indo-Gangetic plain. We then showcase efficient ways to check policy violations such as high spatial density of kilns and abnormal increase over time in a region. We show that 90% of brick kilns in Delhi-NCR violate a density-based policy. Our framework can be directly adopted by the governments across the world to automate the policy regulations around brick kilns. ",
    "url": "https://arxiv.org/abs/2402.13796",
    "authors": [
      "Rishabh Mondal",
      "Zeel B Patel",
      "Vannsh Jani",
      "Nipun Batra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13812",
    "title": "Voice-Driven Mortality Prediction in Hospitalized Heart Failure  Patients: A Machine Learning Approach Enhanced with Diagnostic Biomarkers",
    "abstract": "Addressing heart failure (HF) as a prevalent global health concern poses difficulties in implementing innovative approaches for enhanced patient care. Predicting mortality rates in HF patients, in particular, is difficult yet critical, necessitating individualized care, proactive management, and enabling educated decision-making to enhance outcomes. Recently, the significance of voice biomarkers coupled with Machine Learning (ML) has surged, demonstrating remarkable efficacy, particularly in predicting heart failure. The synergy of voice analysis and ML algorithms provides a non-invasive and easily accessible means to evaluate patients' health. However, there is a lack of voice biomarkers for predicting mortality rates among heart failure patients with standardized speech protocols. Here, we demonstrate a powerful and effective ML model for predicting mortality rates in hospitalized HF patients through the utilization of voice biomarkers. By seamlessly integrating voice biomarkers into routine patient monitoring, this strategy has the potential to improve patient outcomes, optimize resource allocation, and advance patient-centered HF management. In this study, a Machine Learning system, specifically a logistic regression model, is trained to predict patients' 5-year mortality rates using their speech as input. The model performs admirably and consistently, as demonstrated by cross-validation and statistical approaches (p-value < 0.001). Furthermore, integrating NT-proBNP, a diagnostic biomarker in HF, improves the model's predictive accuracy substantially. ",
    "url": "https://arxiv.org/abs/2402.13812",
    "authors": [
      "Nihat Ahmadli",
      "Mehmet Ali Sarsil",
      "Berk Mizrak",
      "Kurtulus Karauzum",
      "Ata Shaker",
      "Erol Tulumen",
      "Didar Mirzamidinov",
      "Dilek Ural",
      "Onur Ergen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.13815",
    "title": "An Empirical Study on Oculus Virtual Reality Applications: Security and  Privacy Perspectives",
    "abstract": "Although Virtual Reality (VR) has accelerated its prevalent adoption in emerging metaverse applications, it is not a fundamentally new technology. On one hand, most VR operating systems (OS) are based on off-the-shelf mobile OS. As a result, VR apps also inherit privacy and security deficiencies from conventional mobile apps. On the other hand, in contrast to conventional mobile apps, VR apps can achieve immersive experience via diverse VR devices, such as head-mounted displays, body sensors, and controllers though achieving this requires the extensive collection of privacy-sensitive human biometrics. Moreover, VR apps have been typically implemented by 3D gaming engines (e.g., Unity), which also contain intrinsic security vulnerabilities. Inappropriate use of these technologies may incur privacy leaks and security vulnerabilities although these issues have not received significant attention compared to the proliferation of diverse VR apps. In this paper, we develop a security and privacy assessment tool, namely the VR-SP detector for VR apps. The VR-SP detector has integrated program static analysis tools and privacy-policy analysis methods. Using the VR-SP detector, we conduct a comprehensive empirical study on 500 popular VR apps. We obtain the original apps from the popular Oculus and SideQuest app stores and extract APK files via the Meta Oculus Quest 2 device. We evaluate security vulnerabilities and privacy data leaks of these VR apps by VR app analysis, taint analysis, and privacy-policy analysis. We find that a number of security vulnerabilities and privacy leaks widely exist in VR apps. Moreover, our results also reveal conflicting representations in the privacy policies of these apps and inconsistencies of the actual data collection with the privacy-policy statements of the apps. Based on these findings, we make suggestions for the future development of VR apps. ",
    "url": "https://arxiv.org/abs/2402.13815",
    "authors": [
      "Hanyang Guo",
      "Hong-Ning Dai",
      "Xiapu Luo",
      "Zibin Zheng",
      "Gengyang Xu",
      "Fengliang He"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.13820",
    "title": "FLD: Fourier Latent Dynamics for Structured Motion Representation and  Learning",
    "abstract": "Motion trajectories offer reliable references for physics-based motion learning but suffer from sparsity, particularly in regions that lack sufficient data coverage. To address this challenge, we introduce a self-supervised, structured representation and generation method that extracts spatial-temporal relationships in periodic or quasi-periodic motions. The motion dynamics in a continuously parameterized latent space enable our method to enhance the interpolation and generalization capabilities of motion learning algorithms. The motion learning controller, informed by the motion parameterization, operates online tracking of a wide range of motions, including targets unseen during training. With a fallback mechanism, the controller dynamically adapts its tracking strategy and automatically resorts to safe action execution when a potentially risky target is proposed. By leveraging the identified spatial-temporal structure, our work opens new possibilities for future advancements in general motion representation and learning algorithms. ",
    "url": "https://arxiv.org/abs/2402.13820",
    "authors": [
      "Chenhao Li",
      "Elijah Stanger-Jones",
      "Steve Heim",
      "Sangbae Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.13841",
    "title": "Equilibria, Efficiency, and Inequality in Network Formation for Hiring  and Opportunity",
    "abstract": "Professional networks -- the social networks among people in a given line of work -- can serve as a conduit for job prospects and other opportunities. Here we propose a model for the formation of such networks and the transfer of opportunities within them. In our theoretical model, individuals strategically connect with others to maximize the probability that they receive opportunities from them. We explore how professional networks balance connectivity, where connections facilitate opportunity transfers to those who did not get them from outside sources, and congestion, where some individuals receive too many opportunities from their connections and waste some of them. We show that strategic individuals are over-connected at equilibrium relative to a social optimum, leading to a price of anarchy for which we derive nearly tight asymptotic bounds. We also show that, at equilibrium, individuals form connections to those who provide similar benefit to them as they provide to others. Thus, our model provides a microfoundation in professional networking contexts for the fundamental sociological principle of homophily, that \"similarity breeds connection,\" which in our setting is realized as a form of status homophily based on alignment in individual benefit. We further explore how, even if individuals are a priori equally likely to receive opportunities from outside sources, equilibria can be unequal, and we provide nearly tight bounds on how unequal they can be. Finally, we explore the ability for online platforms to intervene to improve social welfare and show that natural heuristics may result in adverse effects at equilibrium. Our simple model allows for a surprisingly rich analysis of coordination problems in professional networks and suggests many directions for further exploration. ",
    "url": "https://arxiv.org/abs/2402.13841",
    "authors": [
      "Cynthia Dwork",
      "Chris Hays",
      "Jon Kleinberg",
      "Manish Raghavan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.13845",
    "title": "Multi-Agent Online Graph Exploration on Cycles and Tadpole Graphs",
    "abstract": "We study the problem of multi-agent online graph exploration, in which a team of k agents has to explore a given graph, starting and ending on the same node. The graph is initially unknown. Whenever a node is visited by an agent, its neighborhood and adjacent edges are revealed. The agents share a global view of the explored parts of the graph. The cost of the exploration has to be minimized, where cost either describes the time needed for the entire exploration (time model), or the length of the longest path traversed by any agent (energy model). We investigate graph exploration on cycles and tadpole graphs for 2-4 agents, providing optimal results on the competitive ratio in the energy model (1-competitive with two agents on cycles and three agents on tadpole graphs), and for tadpole graphs in the time model (1.5-competitive with four agents). We also show competitive upper bounds of 2 for the exploration of tadpole graphs with three agents, and 2.5 for the exploration of tadpole graphs with two agents in the time model. ",
    "url": "https://arxiv.org/abs/2402.13845",
    "authors": [
      "Erik van den Akker",
      "Kevin Buchin",
      "Klaus-Tycho Foerster"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.13851",
    "title": "VL-Trojan: Multimodal Instruction Backdoor Attacks against  Autoregressive Visual Language Models",
    "abstract": "Autoregressive Visual Language Models (VLMs) showcase impressive few-shot learning capabilities in a multimodal context. Recently, multimodal instruction tuning has been proposed to further enhance instruction-following abilities. However, we uncover the potential threat posed by backdoor attacks on autoregressive VLMs during instruction tuning. Adversaries can implant a backdoor by injecting poisoned samples with triggers embedded in instructions or images, enabling malicious manipulation of the victim model's predictions with predefined triggers. Nevertheless, the frozen visual encoder in autoregressive VLMs imposes constraints on the learning of conventional image triggers. Additionally, adversaries may encounter restrictions in accessing the parameters and architectures of the victim model. To address these challenges, we propose a multimodal instruction backdoor attack, namely VL-Trojan. Our approach facilitates image trigger learning through an isolating and clustering strategy and enhance black-box-attack efficacy via an iterative character-level text trigger generation method. Our attack successfully induces target outputs during inference, significantly surpassing baselines (+62.52\\%) in ASR. Moreover, it demonstrates robustness across various model scales and few-shot in-context reasoning scenarios. ",
    "url": "https://arxiv.org/abs/2402.13851",
    "authors": [
      "Jiawei Liang",
      "Siyuan Liang",
      "Man Luo",
      "Aishan Liu",
      "Dongchen Han",
      "Ee-Chien Chang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13852",
    "title": "Neural Control System for Continuous Glucose Monitoring and Maintenance",
    "abstract": "Precise glucose level management is pivotal for individuals with diabetes, averting severe complications. In this work, we introduce a novel neural control system for continuous glucose monitoring and maintenance, utilizing differential predictive control. Our system, guided by a sophisticated neural policy and differentiable modeling, dynamically adjusts insulin delivery in real-time, enhancing glucose optimization. This end-to-end approach maximizes efficiency, ensuring personalized care and improved health outcomes, as affirmed by empirical findings. ",
    "url": "https://arxiv.org/abs/2402.13852",
    "authors": [
      "Azmine Toushik Wasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.13861",
    "title": "Improving Efficiency of Iso-Surface Extraction on Implicit Neural  Representations Using Uncertainty Propagation",
    "abstract": "Implicit Neural representations (INRs) are widely used for scientific data reduction and visualization by modeling the function that maps a spatial location to a data value. Without any prior knowledge about the spatial distribution of values, we are forced to sample densely from INRs to perform visualization tasks like iso-surface extraction which can be very computationally expensive. Recently, range analysis has shown promising results in improving the efficiency of geometric queries, such as ray casting and hierarchical mesh extraction, on INRs for 3D geometries by using arithmetic rules to bound the output range of the network within a spatial region. However, the analysis bounds are often too conservative for complex scientific data. In this paper, we present an improved technique for range analysis by revisiting the arithmetic rules and analyzing the probability distribution of the network output within a spatial region. We model this distribution efficiently as a Gaussian distribution by applying the central limit theorem. Excluding low probability values, we are able to tighten the output bounds, resulting in a more accurate estimation of the value range, and hence more accurate identification of iso-surface cells and more efficient iso-surface extraction on INRs. Our approach demonstrates superior performance in terms of the iso-surface extraction time on four datasets compared to the original range analysis method and can also be generalized to other geometric query tasks. ",
    "url": "https://arxiv.org/abs/2402.13861",
    "authors": [
      "Haoyu Li",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13918",
    "title": "BenchCloudVision: A Benchmark Analysis of Deep Learning Approaches for  Cloud Detection and Segmentation in Remote Sensing Imagery",
    "abstract": "Satellites equipped with optical sensors capture high-resolution imagery, providing valuable insights into various environmental phenomena. In recent years, there has been a surge of research focused on addressing some challenges in remote sensing, ranging from water detection in diverse landscapes to the segmentation of mountainous and terrains. Ongoing investigations goals to enhance the precision and efficiency of satellite imagery analysis. Especially, there is a growing emphasis on developing methodologies for accurate water body detection, snow and clouds, important for environmental monitoring, resource management, and disaster response. Within this context, this paper focus on the cloud segmentation from remote sensing imagery. Accurate remote sensing data analysis can be challenging due to the presence of clouds in optical sensor-based applications. The quality of resulting products such as applications and research is directly impacted by cloud detection, which plays a key role in the remote sensing data processing pipeline. This paper examines seven cutting-edge semantic segmentation and detection algorithms applied to clouds identification, conducting a benchmark analysis to evaluate their architectural approaches and identify the most performing ones. To increase the model's adaptability, critical elements including the type of imagery and the amount of spectral bands used during training are analyzed. Additionally, this research tries to produce machine learning algorithms that can perform cloud segmentation using only a few spectral bands, including RGB and RGBN-IR combinations. The model's flexibility for a variety of applications and user scenarios is assessed by using imagery from Sentinel-2 and Landsat-8 as datasets. This benchmark can be reproduced using the material from this github link: \\url{https://github.com/toelt-llc/cloud\\_segmentation\\_comparative}. ",
    "url": "https://arxiv.org/abs/2402.13918",
    "authors": [
      "Loddo Fabio",
      "Dario Piga",
      "Michelucci Umberto",
      "El Ghazouali Safouane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.13920",
    "title": "Practical algorithms for Hierarchical overlap graphs",
    "abstract": "Genome assembly is a prominent problem studied in bioinformatics, which computes the source string using a set of its overlapping substrings. Classically, genome assembly uses assembly graphs built using this set of substrings to compute the source string efficiently, having a tradeoff between scalability and avoiding information loss. The scalable de Bruijn graphs come at the price of losing crucial overlap information. The complete overlap information is stored in overlap graphs using quadratic space. Hierarchical overlap graphs [IPL20] (HOG) overcome these limitations, avoiding information loss despite using linear space. After a series of suboptimal improvements, Khan and Park et al. simultaneously presented two optimal algorithms [CPM2021], where only the former was seemingly practical. We empirically analyze all the practical algorithms for computing HOG, where the optimal algorithm [CPM2021] outperforms the previous algorithms as expected, though at the expense of extra memory. However, it uses non-intuitive approach and non-trivial data structures. We present arguably the most intuitive algorithm, using only elementary arrays, which is also optimal. Our algorithm empirically proves even better for both time and memory over all the algorithms, highlighting its significance in both theory and practice. We further explore the applications of hierarchical overlap graphs to solve various forms of suffix-prefix queries on a set of strings. Loukides et al. [CPM2023] recently presented state-of-the-art algorithms for these queries. However, these algorithms require complex black-box data structures and are seemingly impractical. Our algorithms, despite failing to match the state-of-the-art algorithms theoretically, answer different queries ranging from 0.01-100 milliseconds for a data set having around a billion characters. ",
    "url": "https://arxiv.org/abs/2402.13920",
    "authors": [
      "Saumya Talera",
      "Parth Bansal",
      "Shabnam Khan",
      "Shahbaz Khan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.13921",
    "title": "Robust recovery for stochastic block models, simplified and generalized",
    "abstract": "We study the problem of $\\textit{robust community recovery}$: efficiently recovering communities in sparse stochastic block models in the presence of adversarial corruptions. In the absence of adversarial corruptions, there are efficient algorithms when the $\\textit{signal-to-noise ratio}$ exceeds the $\\textit{Kesten--Stigum (KS) threshold}$, widely believed to be the computational threshold for this problem. The question we study is: does the computational threshold for robust community recovery also lie at the KS threshold? We answer this question affirmatively, providing an algorithm for robust community recovery for arbitrary stochastic block models on any constant number of communities, generalizing the work of Ding, d'Orsi, Nasser & Steurer on an efficient algorithm above the KS threshold in the case of $2$-community block models. There are three main ingredients to our work: (i) The Bethe Hessian of the graph is defined as $H_G(t) \\triangleq (D_G-I)t^2 - A_Gt + I$ where $D_G$ is the diagonal matrix of degrees and $A_G$ is the adjacency matrix. Empirical work suggested that the Bethe Hessian for the stochastic block model has outlier eigenvectors corresponding to the communities right above the Kesten-Stigum threshold. We formally confirm the existence of outlier eigenvalues for the Bethe Hessian, by explicitly constructing outlier eigenvectors from the community vectors. (ii) We develop an algorithm for a variant of robust PCA on sparse matrices. Specifically, an algorithm to partially recover top eigenspaces from adversarially corrupted sparse matrices under mild delocalization constraints. (iii) A rounding algorithm to turn vector assignments of vertices into a community assignment, inspired by the algorithm of Charikar \\& Wirth \\cite{CW04} for $2$XOR. ",
    "url": "https://arxiv.org/abs/2402.13921",
    "authors": [
      "Sidhanth Mohanty",
      "Prasad Raghavendra",
      "David X. Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2402.13926",
    "title": "Large Language Models are Vulnerable to Bait-and-Switch Attacks for  Generating Harmful Content",
    "abstract": "The risks derived from large language models (LLMs) generating deceptive and damaging content have been the subject of considerable research, but even safe generations can lead to problematic downstream impacts. In our study, we shift the focus to how even safe text coming from LLMs can be easily turned into potentially dangerous content through Bait-and-Switch attacks. In such attacks, the user first prompts LLMs with safe questions and then employs a simple find-and-replace post-hoc technique to manipulate the outputs into harmful narratives. The alarming efficacy of this approach in generating toxic content highlights a significant challenge in developing reliable safety guardrails for LLMs. In particular, we stress that focusing on the safety of the verbatim LLM outputs is insufficient and that we also need to consider post-hoc transformations. ",
    "url": "https://arxiv.org/abs/2402.13926",
    "authors": [
      "Federico Bianchi",
      "James Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13929",
    "title": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation",
    "abstract": "We propose a diffusion distillation method that achieves new state-of-the-art in one-step/few-step 1024px text-to-image generation based on SDXL. Our method combines progressive and adversarial distillation to achieve a balance between quality and mode coverage. In this paper, we discuss the theoretical analysis, discriminator design, model formulation, and training techniques. We open-source our distilled SDXL-Lightning models both as LoRA and full UNet weights. ",
    "url": "https://arxiv.org/abs/2402.13929",
    "authors": [
      "Shanchuan Lin",
      "Anran Wang",
      "Xiao Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13948",
    "title": "Improved Syndrome-based Neural Decoder for Linear Block Codes",
    "abstract": "In this work, we investigate the problem of neural-based error correction decoding, and more specifically, the new so-called syndrome-based decoding technique introduced to tackle scalability in the training phase for larger code sizes. We improve on previous works in terms of allowing full decoding of the message rather than codewords, allowing thus the application to non-systematic codes, and proving that the single-message training property is still viable. The suggested system is implemented and tested on polar codes of sizes (64,32) and (128,64), and a BCH of size (63,51), leading to a significant improvement in both Bit Error Rate (BER) and Frame Error Rate (FER), with gains between 0.3dB and 1dB for the implemented codes in the high Signal-to-Noise Ratio (SNR) regime. ",
    "url": "https://arxiv.org/abs/2402.13948",
    "authors": [
      "Gast\u00f3n De Boni Rovella",
      "Meryem Benammar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.13954",
    "title": "Measuring Social Biases in Masked Language Models by Proxy of Prediction  Quality",
    "abstract": "Social and political scientists often aim to discover and measure distinct biases from text data representations (embeddings). Innovative transformer-based language models produce contextually-aware token embeddings and have achieved state-of-the-art performance for a variety of natural language tasks, but have been shown to encode unwanted biases for downstream applications. In this paper, we evaluate the social biases encoded by transformers trained with the masked language modeling objective using proposed proxy functions within an iterative masking experiment to measure the quality of transformer models' predictions, and assess the preference of MLMs towards disadvantaged and advantaged groups. We compare bias estimations with those produced by other evaluation methods using two benchmark datasets, finding relatively high religious and disability biases across considered MLMs and low gender bias in one dataset relative to the other. Our measures outperform others in their agreement with human annotators. We extend on previous work by evaluating social biases introduced after re-training an MLM under the masked language modeling objective (w.r.t. the model's pre-trained base), and find that proposed measures produce more accurate estimations of relative preference for biased sentences between transformers than others based on our methods. ",
    "url": "https://arxiv.org/abs/2402.13954",
    "authors": [
      "Rahul Zalkikar",
      "Kanchan Chandra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13955",
    "title": "BEE-NET: A deep neural network to identify in-the-wild Bodily Expression  of Emotions",
    "abstract": "In this study, we investigate how environmental factors, specifically the scenes and objects involved, can affect the expression of emotions through body language. To this end, we introduce a novel multi-stream deep convolutional neural network named BEE-NET. We also propose a new late fusion strategy that incorporates meta-information on places and objects as prior knowledge in the learning process. Our proposed probabilistic pooling model leverages this information to generate a joint probability distribution of both available and anticipated non-available contextual information in latent space. Importantly, our fusion strategy is differentiable, allowing for end-to-end training and capturing of hidden associations among data points without requiring further post-processing or regularisation. To evaluate our deep model, we use the Body Language Database (BoLD), which is currently the largest available database for the Automatic Identification of the in-the-wild Bodily Expression of Emotions (AIBEE). Our experimental results demonstrate that our proposed approach surpasses the current state-of-the-art in AIBEE by a margin of 2.07%, achieving an Emotional Recognition Score of 66.33%. ",
    "url": "https://arxiv.org/abs/2402.13955",
    "authors": [
      "Mohammad Mahdi Dehshibi",
      "David Masip"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13959",
    "title": "Retention Induced Biases in a Recommendation System with Heterogeneous  Users",
    "abstract": "I examine a conceptual model of a recommendation system (RS) with user inflow and churn dynamics. When inflow and churn balance out, the user distribution reaches a steady state. Changing the recommendation algorithm alters the steady state and creates a transition period. During this period, the RS behaves differently from its new steady state. In particular, A/B experiment metrics obtained in transition periods are biased indicators of the RS's long term performance. Scholars and practitioners, however, often conduct A/B tests shortly after introducing new algorithms to validate their effectiveness. This A/B experiment paradigm, widely regarded as the gold standard for assessing RS improvements, may consequently yield false conclusions. I also briefly discuss the data bias caused by the user retention dynamics. ",
    "url": "https://arxiv.org/abs/2402.13959",
    "authors": [
      "Shichao Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.13973",
    "title": "Linear-Time Graph Neural Networks for Scalable Recommendations",
    "abstract": "In an era of information explosion, recommender systems are vital tools to deliver personalized recommendations for users. The key of recommender systems is to forecast users' future behaviors based on previous user-item interactions. Due to their strong expressive power of capturing high-order connectivities in user-item interaction data, recent years have witnessed a rising interest in leveraging Graph Neural Networks (GNNs) to boost the prediction performance of recommender systems. Nonetheless, classic Matrix Factorization (MF) and Deep Neural Network (DNN) approaches still play an important role in real-world large-scale recommender systems due to their scalability advantages. Despite the existence of GNN-acceleration solutions, it remains an open question whether GNN-based recommender systems can scale as efficiently as classic MF and DNN methods. In this paper, we propose a Linear-Time Graph Neural Network (LTGNN) to scale up GNN-based recommender systems to achieve comparable scalability as classic MF approaches while maintaining GNNs' powerful expressiveness for superior prediction accuracy. Extensive experiments and ablation studies are presented to validate the effectiveness and scalability of the proposed algorithm. Our implementation based on PyTorch is available. ",
    "url": "https://arxiv.org/abs/2402.13973",
    "authors": [
      "Jiahao Zhang",
      "Rui Xue",
      "Wenqi Fan",
      "Xin Xu",
      "Qing Li",
      "Jian Pei",
      "Xiaorui Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13984",
    "title": "Stability-Aware Training of Neural Network Interatomic Potentials with  Differentiable Boltzmann Estimators",
    "abstract": "Neural network interatomic potentials (NNIPs) are an attractive alternative to ab-initio methods for molecular dynamics (MD) simulations. However, they can produce unstable simulations which sample unphysical states, limiting their usefulness for modeling phenomena occurring over longer timescales. To address these challenges, we present Stability-Aware Boltzmann Estimator (StABlE) Training, a multi-modal training procedure which combines conventional supervised training from quantum-mechanical energies and forces with reference system observables, to produce stable and accurate NNIPs. StABlE Training iteratively runs MD simulations to seek out unstable regions, and corrects the instabilities via supervision with a reference observable. The training procedure is enabled by the Boltzmann Estimator, which allows efficient computation of gradients required to train neural networks to system observables, and can detect both global and local instabilities. We demonstrate our methodology across organic molecules, tetrapeptides, and condensed phase systems, along with using three modern NNIP architectures. In all three cases, StABlE-trained models achieve significant improvements in simulation stability and recovery of structural and dynamic observables. In some cases, StABlE-trained models outperform conventional models trained on datasets 50 times larger. As a general framework applicable across NNIP architectures and systems, StABlE Training is a powerful tool for training stable and accurate NNIPs, particularly in the absence of large reference datasets. ",
    "url": "https://arxiv.org/abs/2402.13984",
    "authors": [
      "Sanjeev Raja",
      "Ishan Amin",
      "Fabian Pedregosa",
      "Aditi S. Krishnapriyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2402.13987",
    "title": "A Simple and Yet Fairly Effective Defense for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have emerged as the dominant approach for machine learning on graph-structured data. However, concerns have arisen regarding the vulnerability of GNNs to small adversarial perturbations. Existing defense methods against such perturbations suffer from high time complexity and can negatively impact the model's performance on clean graphs. To address these challenges, this paper introduces NoisyGNNs, a novel defense method that incorporates noise into the underlying model's architecture. We establish a theoretical connection between noise injection and the enhancement of GNN robustness, highlighting the effectiveness of our approach. We further conduct extensive empirical evaluations on the node classification task to validate our theoretical findings, focusing on two popular GNNs: the GCN and GIN. The results demonstrate that NoisyGNN achieves superior or comparable defense performance to existing methods while minimizing added time complexity. The NoisyGNN approach is model-agnostic, allowing it to be integrated with different GNN architectures. Successful combinations of our NoisyGNN approach with existing defense techniques demonstrate even further improved adversarial defense results. Our code is publicly available at: https://github.com/Sennadir/NoisyGNN. ",
    "url": "https://arxiv.org/abs/2402.13987",
    "authors": [
      "Sofiane Ennadir",
      "Yassine Abbahaddou",
      "Johannes F. Lutzeyer",
      "Michalis Vazirgiannis",
      "Henrik Bostr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14009",
    "title": "Geometry-Informed Neural Networks",
    "abstract": "We introduce the concept of geometry-informed neural networks (GINNs), which encompass (i) learning under geometric constraints, (ii) neural fields as a suitable representation, and (iii) generating diverse solutions to under-determined systems often encountered in geometric tasks. Notably, the GINN formulation does not require training data, and as such can be considered generative modeling driven purely by constraints. We add an explicit diversity loss to mitigate mode collapse. We consider several constraints, in particular, the connectedness of components which we convert to a differentiable loss through Morse theory. Experimentally, we demonstrate the efficacy of the GINN learning paradigm across a range of two and three-dimensional scenarios with increasing levels of complexity. ",
    "url": "https://arxiv.org/abs/2402.14009",
    "authors": [
      "Arturs Berzins",
      "Andreas Radler",
      "Sebastian Sanokowski",
      "Sepp Hochreiter",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14016",
    "title": "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on  Zero-shot LLM Assessment",
    "abstract": "Large Language Models (LLMs) are powerful zero-shot assessors and are increasingly used in real-world situations such as for written exams or benchmarking systems. Despite this, no existing work has analyzed the vulnerability of judge-LLMs against adversaries attempting to manipulate outputs. This work presents the first study on the adversarial robustness of assessment LLMs, where we search for short universal phrases that when appended to texts can deceive LLMs to provide high assessment scores. Experiments on SummEval and TopicalChat demonstrate that both LLM-scoring and pairwise LLM-comparative assessment are vulnerable to simple concatenation attacks, where in particular LLM-scoring is very susceptible and can yield maximum assessment scores irrespective of the input text quality. Interestingly, such attacks are transferable and phrases learned on smaller open-source LLMs can be applied to larger closed-source models, such as GPT3.5. This highlights the pervasive nature of the adversarial vulnerabilities across different judge-LLM sizes, families and methods. Our findings raise significant concerns on the reliability of LLMs-as-a-judge methods, and underscore the importance of addressing vulnerabilities in LLM assessment methods before deployment in high-stakes real-world scenarios. ",
    "url": "https://arxiv.org/abs/2402.14016",
    "authors": [
      "Vyas Raina",
      "Adian Liusie",
      "Mark Gales"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13259",
    "title": "Fast Discrete-Event Simulation of Markovian Queueing Networks through  Euler Approximation",
    "abstract": "The efficient management of large-scale queueing networks is critical for a variety of sectors, including healthcare, logistics, and customer service, where system performance has profound implications for operational effectiveness and cost management. To address this key challenge, our paper introduces simulation techniques tailored for complex, large-scale Markovian queueing networks. We develop two simulation schemes based on Euler approximation, namely the backward and forward schemes. These schemes can accommodate time-varying dynamics and are optimized for efficient implementation using vectorization. Assuming a feedforward queueing network structure, we establish that the two schemes provide stochastic upper and lower bounds for the system state, while the approximation error remains bounded over the simulation horizon. With the recommended choice of time step, we show that our approximation schemes exhibit diminishing asymptotic relative error as the system scales up, while maintaining much lower computational complexity compared to traditional discrete-event simulation and achieving speedups up to tens of thousands times. This study highlights the substantial potential of Euler approximation in simulating large-scale discrete systems. ",
    "url": "https://arxiv.org/abs/2402.13259",
    "authors": [
      "L.Jeff Hong",
      "Yingda Song",
      "Tan Wang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2402.13270",
    "title": "Global Tropical Cyclone Intensity Forecasting with Multi-modal  Multi-scale Causal Autoregressive Model",
    "abstract": "Accurate forecasting of Tropical cyclone (TC) intensity is crucial for formulating disaster risk reduction strategies. Current methods predominantly rely on limited spatiotemporal information from ERA5 data and neglect the causal relationships between these physical variables, failing to fully capture the spatial and temporal patterns required for intensity forecasting. To address this issue, we propose a Multi-modal multi-Scale Causal AutoRegressive model (MSCAR), which is the first model that combines causal relationships with large-scale multi-modal data for global TC intensity autoregressive forecasting. Furthermore, given the current absence of a TC dataset that offers a wide range of spatial variables, we present the Satellite and ERA5-based Tropical Cyclone Dataset (SETCD), which stands as the longest and most comprehensive global dataset related to TCs. Experiments on the dataset show that MSCAR outperforms the state-of-the-art methods, achieving maximum reductions in global and regional forecast errors of 9.52% and 6.74%, respectively. The code and dataset are publicly available at https://anonymous.4open.science/r/MSCAR. ",
    "url": "https://arxiv.org/abs/2402.13270",
    "authors": [
      "Xinyu Wang",
      "Kang Chen",
      "Lei Liu",
      "Tao Han",
      "Bin Li",
      "Lei Bai"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2402.13276",
    "title": "When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate  Speech into Large Language Models for Depression Detection",
    "abstract": "Depression is a critical concern in global mental health, prompting extensive research into AI-based detection methods. Among various AI technologies, Large Language Models (LLMs) stand out for their versatility in mental healthcare applications. However, their primary limitation arises from their exclusive dependence on textual input, which constrains their overall capabilities. Furthermore, the utilization of LLMs in identifying and analyzing depressive states is still relatively untapped. In this paper, we present an innovative approach to integrating acoustic speech information into the LLMs framework for multimodal depression detection. We investigate an efficient method for depression detection by integrating speech signals into LLMs utilizing Acoustic Landmarks. By incorporating acoustic landmarks, which are specific to the pronunciation of spoken words, our method adds critical dimensions to text transcripts. This integration also provides insights into the unique speech patterns of individuals, revealing the potential mental states of individuals. Evaluations of the proposed approach on the DAIC-WOZ dataset reveal state-of-the-art results when compared with existing Audio-Text baselines. In addition, this approach is not only valuable for the detection of depression but also represents a new perspective in enhancing the ability of LLMs to comprehend and process speech signals. ",
    "url": "https://arxiv.org/abs/2402.13276",
    "authors": [
      "Xiangyu Zhang",
      "Hexin Liu",
      "Kaishuai Xu",
      "Qiquan Zhang",
      "Daijiao Liu",
      "Beena Ahmed",
      "Julien Epps"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.13352",
    "title": "KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers",
    "abstract": "Quantum algorithms, represented as quantum circuits, can be used as benchmarks for assessing the performance of quantum systems. Existing datasets, widely utilized in the field, suffer from limitations in size and versatility, leading researchers to employ randomly generated circuits. Random circuits are, however, not representative benchmarks as they lack the inherent properties of real quantum algorithms for which the quantum systems are manufactured. This shortage of `useful' quantum benchmarks poses a challenge to advancing the development and comparison of quantum compilers and hardware. This research aims to enhance the existing quantum circuit datasets by generating what we refer to as `realistic-looking' circuits by employing the Transformer machine learning architecture. For this purpose, we introduce KetGPT, a tool that generates synthetic circuits in OpenQASM language, whose structure is based on quantum circuits derived from existing quantum algorithms and follows the typical patterns of human-written algorithm-based code (e.g., order of gates and qubits). Our three-fold verification process, involving manual inspection and Qiskit framework execution, transformer-based classification, and structural analysis, demonstrates the efficacy of KetGPT in producing large amounts of additional circuits that closely align with algorithm-based structures. Beyond benchmarking, we envision KetGPT contributing substantially to AI-driven quantum compilers and systems. ",
    "url": "https://arxiv.org/abs/2402.13352",
    "authors": [
      "Boran Apak",
      "Medina Bandic",
      "Aritra Sarkar",
      "Sebastian Feld"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13629",
    "title": "Adversarial Purification and Fine-tuning for Robust UDC Image  Restoration",
    "abstract": "This study delves into the enhancement of Under-Display Camera (UDC) image restoration models, focusing on their robustness against adversarial attacks. Despite its innovative approach to seamless display integration, UDC technology faces unique image degradation challenges exacerbated by the susceptibility to adversarial perturbations. Our research initially conducts an in-depth robustness evaluation of deep-learning-based UDC image restoration models by employing several white-box and black-box attacking methods. This evaluation is pivotal in understanding the vulnerabilities of current UDC image restoration techniques. Following the assessment, we introduce a defense framework integrating adversarial purification with subsequent fine-tuning processes. First, our approach employs diffusion-based adversarial purification, effectively neutralizing adversarial perturbations. Then, we apply the fine-tuning methodologies to refine the image restoration models further, ensuring that the quality and fidelity of the restored images are maintained. The effectiveness of our proposed approach is validated through extensive experiments, showing marked improvements in resilience against typical adversarial attacks. ",
    "url": "https://arxiv.org/abs/2402.13629",
    "authors": [
      "Zhenbo Song",
      "Zhenyuan Zhang",
      "Kaihao Zhang",
      "Wenhan Luo",
      "Zhaoxin Fan",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.13673",
    "title": "Computing Transiting Exoplanet Parameters with 1D Convolutional Neural  Networks",
    "abstract": "The transit method allows the detection and characterization of planetary systems by analyzing stellar light curves. Convolutional neural networks appear to offer a viable solution for automating these analyses. In this research, two 1D convolutional neural network models, which work with simulated light curves in which transit-like signals were injected, are presented. One model operates on complete light curves and estimates the orbital period, and the other one operates on phase-folded light curves and estimates the semimajor axis of the orbit and the square of the planet-to-star radius ratio. Both models were tested on real data from TESS light curves with confirmed planets to ensure that they are able to work with real data. The results obtained show that 1D CNNs are able to characterize transiting exoplanets from their host star's detrended light curve and, furthermore, reducing both the required time and computational costs compared with the current detection and characterization algorithms. ",
    "url": "https://arxiv.org/abs/2402.13673",
    "authors": [
      "Santiago Iglesias \u00c1lvarez",
      "Enrique D\u00edez Alonso",
      "Mar\u00eda Luisa S\u00e1nchez Rodr\u00edguez",
      "Javier Rodr\u00edguez Rodr\u00edguez",
      "Sa\u00fal P\u00e9rez Fern\u00e1ndez",
      "Francisco Javier de Cos Juez"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13937",
    "title": "Verifying message-passing neural networks via topology-based bounds  tightening",
    "abstract": "Since graph neural networks (GNNs) are often vulnerable to attack, we need to know when we can trust them. We develop a computationally effective approach towards providing robust certificates for message-passing neural networks (MPNNs) using a Rectified Linear Unit (ReLU) activation function. Because our work builds on mixed-integer optimization, it encodes a wide variety of subproblems, for example it admits (i) both adding and removing edges, (ii) both global and local budgets, and (iii) both topological perturbations and feature modifications. Our key technology, topology-based bounds tightening, uses graph structure to tighten bounds. We also experiment with aggressive bounds tightening to dynamically change the optimization constraints by tightening variable bounds. To demonstrate the effectiveness of these strategies, we implement an extension to the open-source branch-and-cut solver SCIP. We test on both node and graph classification problems and consider topological attacks that both add and remove edges. ",
    "url": "https://arxiv.org/abs/2402.13937",
    "authors": [
      "Christopher Hojny",
      "Shiqiang Zhang",
      "Juan S. Campos",
      "Ruth Misener"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13945",
    "title": "Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty  in Scientific Machine Learning",
    "abstract": "This paper investigates the use of probabilistic neural networks (PNNs) to model aleatoric uncertainty, which refers to the inherent variability in the input-output relationships of a system, often characterized by unequal variance or heteroscedasticity. Unlike traditional neural networks that produce deterministic outputs, PNNs generate probability distributions for the target variable, allowing the determination of both predicted means and intervals in regression scenarios. Contributions of this paper include the development of a probabilistic distance metric to optimize PNN architecture, and the deployment of PNNs in controlled data sets as well as a practical material science case involving fiber-reinforced composites. The findings confirm that PNNs effectively model aleatoric uncertainty, proving to be more appropriate than the commonly employed Gaussian process regression for this purpose. Specifically, in a real-world scientific machine learning context, PNNs yield remarkably accurate output mean estimates with R-squared scores approaching 0.97, and their predicted intervals exhibit a high correlation coefficient of nearly 0.80, closely matching observed data intervals. Hence, this research contributes to the ongoing exploration of leveraging the sophisticated representational capacity of neural networks to delineate complex input-output relationships in scientific problems. ",
    "url": "https://arxiv.org/abs/2402.13945",
    "authors": [
      "Farhad Pourkamali-Anaraki",
      "Jamal F. Husseini",
      "Scott E. Stapleton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1804.05105",
    "title": "Recognizing Visibility Graphs of Polygons with Holes and  Internal-External Visibility Graphs of Polygons",
    "abstract": " Title: Recognizing Visibility Graphs of Polygons with Holes and  Internal-External Visibility Graphs of Polygons ",
    "url": "https://arxiv.org/abs/1804.05105",
    "authors": [
      "Hossein Boomari",
      "Mojtaba Ostovari",
      "Alireza Zarei"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2203.02002",
    "title": "Discord in the voter model for complex networks",
    "abstract": " Title: Discord in the voter model for complex networks ",
    "url": "https://arxiv.org/abs/2203.02002",
    "authors": [
      "Antoine Vendeville",
      "Shi Zhou",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.07424",
    "title": "Trustworthy Graph Neural Networks: Aspects, Methods and Trends",
    "abstract": " Comments: 42 pages, 7 tables, 4 figures, double columns, accepted by Proceedings of the IEEE ",
    "url": "https://arxiv.org/abs/2205.07424",
    "authors": [
      "He Zhang",
      "Bang Wu",
      "Xingliang Yuan",
      "Shirui Pan",
      "Hanghang Tong",
      "Jian Pei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.00655",
    "title": "Self-supervised Representation Learning on Electronic Health Records  with Graph Kernel Infomax",
    "abstract": " Comments: Accepted to ACM Transactions on Computing for Healthcare (HEALTH) ",
    "url": "https://arxiv.org/abs/2209.00655",
    "authors": [
      "Hao-Ren Yao",
      "Nairen Cao",
      "Katina Russell",
      "Der-Chen Chang",
      "Ophir Frieder",
      "Jeremy Fineman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2209.09841",
    "title": "Exploring Inconsistent Knowledge Distillation for Object Detection with  Data Augmentation",
    "abstract": " Comments: ACMMM 2023 Oral ",
    "url": "https://arxiv.org/abs/2209.09841",
    "authors": [
      "Jiawei Liang",
      "Siyuan Liang",
      "Aishan Liu",
      "Ke Ma",
      "Jingzhi Li",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05988",
    "title": "CLEEGN: A Convolutional Neural Network for Plug-and-Play Automatic EEG  Reconstruction",
    "abstract": " Title: CLEEGN: A Convolutional Neural Network for Plug-and-Play Automatic EEG  Reconstruction ",
    "url": "https://arxiv.org/abs/2210.05988",
    "authors": [
      "Pin-Hua Lai",
      "Bo-Shan Wang",
      "Wei-Chun Yang",
      "Hsiang-Chieh Tsou",
      "Chun-Shu Wei"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2211.09771",
    "title": "Boosting Object Representation Learning via Motion and Object Continuity",
    "abstract": " Comments: 8 pages main text, 32 tables, 21 Figures ",
    "url": "https://arxiv.org/abs/2211.09771",
    "authors": [
      "Quentin Delfosse",
      "Wolfgang Stammer",
      "Thomas Rothenbacher",
      "Dwarak Vittal",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06717",
    "title": "The Subgraph Isomorphism Problem for Port Graphs and Quantum Circuits",
    "abstract": " Comments: The main bound of thm 1 is asymptotically very close to previous work, significantly reducing the novelty and motivation for this work. A new approach to this problem is presented in 2402.13065 ",
    "url": "https://arxiv.org/abs/2302.06717",
    "authors": [
      "Luca Mondada",
      "Pablo Andr\u00e9s-Mart\u00ednez"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2302.09852",
    "title": "Unsupervised Layer-wise Score Aggregation for Textual OOD Detection",
    "abstract": " Title: Unsupervised Layer-wise Score Aggregation for Textual OOD Detection ",
    "url": "https://arxiv.org/abs/2302.09852",
    "authors": [
      "Maxime Darrin",
      "Guillaume Staerman",
      "Eduardo Dadalto C\u00e2mara Gomes",
      "Jackie CK Cheung",
      "Pablo Piantanida",
      "Pierre Colombo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.01580",
    "title": "Untargeted Near-collision Attacks on Biometrics: Real-world Bounds and  Theoretical Limits",
    "abstract": " Comments: Correction of typos ",
    "url": "https://arxiv.org/abs/2304.01580",
    "authors": [
      "Axel Durbet",
      "Paul-Marie Grollemund",
      "Kevin Thiry-Atighehchi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03443",
    "title": "Learning Multi-Pursuit Evasion for Safe Targeted Navigation of Drones",
    "abstract": " Comments: Accepted by IEEE Transactions on Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2304.03443",
    "authors": [
      "Jiaping Xiao",
      "Mir Feroskhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11643",
    "title": "Privacy Computing Meets Metaverse: Necessity, Taxonomy and Challenges",
    "abstract": " Comments: In Ad Hoc Networks (2024) ",
    "url": "https://arxiv.org/abs/2304.11643",
    "authors": [
      "Chuan Chen",
      "Yuecheng Li",
      "Zhenpeng Wu",
      "Chengyuan Mai",
      "Youming Liu",
      "Yanming Hu",
      "Zibin Zheng",
      "Jiawen Kang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2304.11783",
    "title": "Rip Current Detection in Nearshore Areas through UAV Video Analysis with  Almost Local-Isometric Embedding Techniques on Sphere",
    "abstract": " Comments: 10 pages, 9 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2304.11783",
    "authors": [
      "Anchen Sun",
      "Kaiqi Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.13269",
    "title": "Chain-of-Knowledge: Grounding Large Language Models via Dynamic  Knowledge Adapting over Heterogeneous Sources",
    "abstract": " Comments: Accepted by ICLR 2024 ",
    "url": "https://arxiv.org/abs/2305.13269",
    "authors": [
      "Xingxuan Li",
      "Ruochen Zhao",
      "Yew Ken Chia",
      "Bosheng Ding",
      "Shafiq Joty",
      "Soujanya Poria",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13718",
    "title": "LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large  Language Models",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2305.13718",
    "authors": [
      "Fangkai Jiao",
      "Zhiyang Teng",
      "Bosheng Ding",
      "Zhengyuan Liu",
      "Nancy F. Chen",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17212",
    "title": "Rotational Equilibrium: How Weight Decay Balances Learning Across Neural  Networks",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2305.17212",
    "authors": [
      "Atli Kosson",
      "Bettina Messmer",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05037",
    "title": "Normalization-Equivariant Neural Networks with Application to Image  Denoising",
    "abstract": " Title: Normalization-Equivariant Neural Networks with Application to Image  Denoising ",
    "url": "https://arxiv.org/abs/2306.05037",
    "authors": [
      "S\u00e9bastien Herbreteau",
      "Emmanuel Moebel",
      "Charles Kervrann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06088",
    "title": "SENS: Part-Aware Sketch-based Implicit Neural Shape Modeling",
    "abstract": " Comments: 25 pages, 24 figures ",
    "url": "https://arxiv.org/abs/2306.06088",
    "authors": [
      "Alexandre Binninger",
      "Amir Hertz",
      "Olga Sorkine-Hornung",
      "Daniel Cohen-Or",
      "Raja Giryes"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10447",
    "title": "Globally Interpretable Graph Learning via Distribution Matching",
    "abstract": " Comments: 8 page, 3 figures, 5 tables. Accepted by the ACM Web Conference 2024 ",
    "url": "https://arxiv.org/abs/2306.10447",
    "authors": [
      "Yi Nian",
      "Yurui Chang",
      "Wei Jin",
      "Lu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.12584",
    "title": "Hierarchical Neural Simulation-Based Inference Over Event Ensembles",
    "abstract": " Comments: 15+2 pages, 7 figures; v2, version published in TMLR ",
    "url": "https://arxiv.org/abs/2306.12584",
    "authors": [
      "Lukas Heinrich",
      "Siddharth Mishra-Sharma",
      "Chris Pollard",
      "Philipp Windischhofer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2306.16869",
    "title": "NeuralFuse: Learning to Recover the Accuracy of Access-Limited Neural  Network Inference in Low-Voltage Regimes",
    "abstract": " Title: NeuralFuse: Learning to Recover the Accuracy of Access-Limited Neural  Network Inference in Low-Voltage Regimes ",
    "url": "https://arxiv.org/abs/2306.16869",
    "authors": [
      "Hao-Lun Sun",
      "Lei Hsiung",
      "Nandhini Chandramoorthy",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15981",
    "title": "GaitASMS: Gait Recognition by Adaptive Structured Spatial Representation  and Multi-Scale Temporal Aggregation",
    "abstract": " Title: GaitASMS: Gait Recognition by Adaptive Structured Spatial Representation  and Multi-Scale Temporal Aggregation ",
    "url": "https://arxiv.org/abs/2307.15981",
    "authors": [
      "Yan Sun",
      "Hu Long",
      "Xueling Feng",
      "Mark Nixon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.16797",
    "title": "Shepherding control and herdability in complex multiagent systems",
    "abstract": " Title: Shepherding control and herdability in complex multiagent systems ",
    "url": "https://arxiv.org/abs/2307.16797",
    "authors": [
      "Andrea Lama",
      "Mario di Bernardo"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.14456",
    "title": "Speech Self-Supervised Representations Benchmarking: a Case for Larger  Probing Heads",
    "abstract": " Comments: 18 Pages ",
    "url": "https://arxiv.org/abs/2308.14456",
    "authors": [
      "Salah Zaiem",
      "Youcef Kemiche",
      "Titouan Parcollet",
      "Slim Essid",
      "Mirco Ravanelli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.15478",
    "title": "An Adaptive Tangent Feature Perspective of Neural Networks",
    "abstract": " Comments: 14 pages, 3 figures. Appeared at the First Conference on Parsimony and Learning (CPAL 2024) ",
    "url": "https://arxiv.org/abs/2308.15478",
    "authors": [
      "Daniel LeJeune",
      "Sina Alemohammad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.16800",
    "title": "Rank Collapse Causes Over-Smoothing and Over-Correlation in Graph Neural  Networks",
    "abstract": " Comments: Published at LoG 2023 ",
    "url": "https://arxiv.org/abs/2308.16800",
    "authors": [
      "Andreas Roth",
      "Thomas Liebig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07524",
    "title": "A Multi-scale Generalized Shrinkage Threshold Network for Image Blind  Deblurring in Remote Sensing",
    "abstract": " Comments: 16 pages,Accepted to IEEE Transactions on Geoscience and Remote Sensing,2024 ",
    "url": "https://arxiv.org/abs/2309.07524",
    "authors": [
      "Yujie Feng",
      "Yin Yang",
      "Xiaohong Fan",
      "Zhengpeng Zhang",
      "Jianping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.10462",
    "title": "Adaptive Neural Ranking Framework: Toward Maximized Business Goal for  Cascade Ranking Systems",
    "abstract": " Comments: 12 pages, Accepted by www2024 ",
    "url": "https://arxiv.org/abs/2310.10462",
    "authors": [
      "Yunli Wang",
      "Zhiqiang Wang",
      "Jian Yang",
      "Shiyang Wen",
      "Dongying Kong",
      "Han Li",
      "Kun Gai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.14691",
    "title": "Identifiability of total effects from abstractions of time series causal  graphs",
    "abstract": " Title: Identifiability of total effects from abstractions of time series causal  graphs ",
    "url": "https://arxiv.org/abs/2310.14691",
    "authors": [
      "Charles K. Assaad",
      "Emilie Devijver",
      "Eric Gaussier",
      "Gregor G\u00f6ssler",
      "Anouar Meynaoui"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18948",
    "title": "Probabilistic Feature Augmentation for AIS-Based Multi-Path Long-Term  Vessel Trajectory Forecasting",
    "abstract": " Title: Probabilistic Feature Augmentation for AIS-Based Multi-Path Long-Term  Vessel Trajectory Forecasting ",
    "url": "https://arxiv.org/abs/2310.18948",
    "authors": [
      "Gabriel Spadon",
      "Jay Kumar",
      "Derek Eden",
      "Josh van Berkel",
      "Tom Foster",
      "Matthew Smith",
      "Sarah Vela",
      "Romina Gehrmann",
      "Amilcar Soares",
      "Ronan Fablet",
      "Stan Matwin",
      "Ronald Pelot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2311.06973",
    "title": "Analytical Verification of Deep Neural Network Performance for  Time-Synchronized Distribution System State Estimation",
    "abstract": " Comments: 8 pages, in Journal of Modern Power Systems and Clean Energy, 2023 ",
    "url": "https://arxiv.org/abs/2311.06973",
    "authors": [
      "Behrouz Azimian",
      "Shiva Moshtagh",
      "Anamitra Pal",
      "Shanshan Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.07215",
    "title": "Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2311.07215",
    "authors": [
      "Seungjun Moon",
      "Yongho Song",
      "Hyungjoo Chae",
      "Dongjin Kang",
      "Taeyoon Kwon",
      "Kai Tzu-iunn Ong",
      "Seung-won Hwang",
      "Jinyoung Yeo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.11343",
    "title": "A Generative Model for Accelerated Inverse Modelling Using a Novel  Embedding for Continuous Variables",
    "abstract": " Comments: 9 pages, 8 figures, NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2311.11343",
    "authors": [
      "S\u00e9bastien Bompas",
      "Stefan Sandfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2311.14024",
    "title": "Creating and Leveraging a Synthetic Dataset of Cloud Optical Thickness  Measures for Cloud Detection in MSI",
    "abstract": " Comments: Published in the journal Remote Sensing (2024). Code, data and models available at this https URL ",
    "url": "https://arxiv.org/abs/2311.14024",
    "authors": [
      "Aleksis Pirinen",
      "Nosheen Abid",
      "Nuria Agues Paszkowsky",
      "Thomas Ohlson Timoudas",
      "Ronald Scheirer",
      "Chiara Ceccobello",
      "Gy\u00f6rgy Kov\u00e1cs",
      "Anders Persson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.04404",
    "title": "On the Impact of Multi-dimensional Local Differential Privacy on  Fairness",
    "abstract": " Title: On the Impact of Multi-dimensional Local Differential Privacy on  Fairness ",
    "url": "https://arxiv.org/abs/2312.04404",
    "authors": [
      "Karima Makhlouf",
      "Heber H. Arcolezi",
      "Sami Zhioua",
      "Ghassen Ben Brahim",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.06125",
    "title": "Pre-Evolved Model for Complex Multi-objective Optimization Problems",
    "abstract": " Comments: 9 pages, 2 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2312.06125",
    "authors": [
      "Haokai Hong",
      "Min Jiang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.07250",
    "title": "Neural Machine Translation of Clinical Text: An Empirical Investigation  into Multilingual Pre-Trained Language Models and Transfer-Learning",
    "abstract": " Comments: Accepted by Frontiers in Digital Health - Health Informatics ",
    "url": "https://arxiv.org/abs/2312.07250",
    "authors": [
      "Lifeng Han",
      "Serge Gladkoff",
      "Gleb Erofeev",
      "Irina Sorokina",
      "Betty Galiano",
      "Goran Nenadic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.07266",
    "title": "ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for  Open-Vocabulary Object Detection",
    "abstract": " Comments: Accepted in AAAI24. Code: this https URL Project page: this https URL ",
    "url": "https://arxiv.org/abs/2312.07266",
    "authors": [
      "Joonhyun Jeong",
      "Geondo Park",
      "Jayeon Yoo",
      "Hyungsik Jung",
      "Heesu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.11529",
    "title": "Efficient and Scalable Graph Generation through Iterative Local  Expansion",
    "abstract": " Title: Efficient and Scalable Graph Generation through Iterative Local  Expansion ",
    "url": "https://arxiv.org/abs/2312.11529",
    "authors": [
      "Andreas Bergmeister",
      "Karolis Martinkus",
      "Nathana\u00ebl Perraudin",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.02686",
    "title": "Beyond Fidelity: Explaining Vulnerability Localization of Learning-based  Detectors",
    "abstract": " Comments: Accepted by Tosem ",
    "url": "https://arxiv.org/abs/2401.02686",
    "authors": [
      "Baijun Cheng",
      "Shengming Zhao",
      "Kailong Wang",
      "Meizhen Wang",
      "Guangdong Bai",
      "Ruitao Feng",
      "Yao Guo",
      "Lei Ma",
      "Haoyu Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.02737",
    "title": "The Vulnerability Is in the Details: Locating Fine-grained Information  of Vulnerable Code Identified by Graph-based Detectors",
    "abstract": " Title: The Vulnerability Is in the Details: Locating Fine-grained Information  of Vulnerable Code Identified by Graph-based Detectors ",
    "url": "https://arxiv.org/abs/2401.02737",
    "authors": [
      "Baijun Cheng",
      "Kailong Wang",
      "Cuiyun Gao",
      "Xiapu Luo",
      "Yulei Sui",
      "Li Li",
      "Yao Guo",
      "Xiangqun Chen",
      "Haoyu Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.04829",
    "title": "GNNShap: Fast and Accurate GNN Explanations using Shapley Values",
    "abstract": " Title: GNNShap: Fast and Accurate GNN Explanations using Shapley Values ",
    "url": "https://arxiv.org/abs/2401.04829",
    "authors": [
      "Selahattin Akkas",
      "Ariful Azad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.06432",
    "title": "Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation  Models",
    "abstract": " Title: Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation  Models ",
    "url": "https://arxiv.org/abs/2401.06432",
    "authors": [
      "Yae Jee Cho",
      "Luyang Liu",
      "Zheng Xu",
      "Aldi Fahrezi",
      "Gauri Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2401.17499",
    "title": "AdvGPS: Adversarial GPS for Multi-Agent Perception Attack",
    "abstract": " Comments: Accepted by the 2024 IEEE International Conference on Robotics and Automation (ICRA) ",
    "url": "https://arxiv.org/abs/2401.17499",
    "authors": [
      "Jinlong Li",
      "Baolu Li",
      "Xinyu Liu",
      "Jianwu Fang",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.17580",
    "title": "Graph Contrastive Learning with Cohesive Subgraph Awareness",
    "abstract": " Title: Graph Contrastive Learning with Cohesive Subgraph Awareness ",
    "url": "https://arxiv.org/abs/2401.17580",
    "authors": [
      "Yucheng Wu",
      "Leye Wang",
      "Xiao Han",
      "Han-Jia Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02695",
    "title": "Exploiting Class Probabilities for Black-box Sentence-level Attacks",
    "abstract": " Comments: EACL 2024 Findings ",
    "url": "https://arxiv.org/abs/2402.02695",
    "authors": [
      "Raha Moraffah",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.04032",
    "title": "HEAM : Hashed Embedding Acceleration using Processing-In-Memory",
    "abstract": " Comments: 10 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2402.04032",
    "authors": [
      "Youngsuk Kim",
      "Hyuk-Jae Lee",
      "Chae Eun Rhee"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07687",
    "title": "Privacy-Preserving Gaze Data Streaming in Immersive Interactive Virtual  Reality: Robustness and User Experience",
    "abstract": " Comments: To appear in IEEE Transactions on Visualization and Computer Graphics ",
    "url": "https://arxiv.org/abs/2402.07687",
    "authors": [
      "Ethan Wilson",
      "Azim Ibragimov",
      "Michael J. Proulx",
      "Sai Deep Tetali",
      "Kevin Butler",
      "Eakta Jain"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.08653",
    "title": "SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds",
    "abstract": " Title: SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds ",
    "url": "https://arxiv.org/abs/2402.08653",
    "authors": [
      "Wuxinlin Cheng",
      "Chenhui Deng",
      "Ali Aghdaei",
      "Zhiru Zhang",
      "Zhuo Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.10097",
    "title": "Adaptive Federated Learning in Heterogeneous Wireless Networks with  Independent Sampling",
    "abstract": " Comments: 6 pages, 5 figures, accepted for publication in IEEE International Conference on Communications (ICC) ",
    "url": "https://arxiv.org/abs/2402.10097",
    "authors": [
      "Jiaxiang Geng",
      "Yanzhao Hou",
      "Xiaofeng Tao",
      "Juncheng Wang",
      "Bing Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.10853",
    "title": "Discovering and exploring cases of educational source code plagiarism  with Dolos",
    "abstract": " Comments: 20 pages, 5 figures; minor corrections, reference added for section 2 ",
    "url": "https://arxiv.org/abs/2402.10853",
    "authors": [
      "Rien Maertens",
      "Maarten Van Neyghem",
      "Maxiem Geldhof",
      "Charlotte Van Petegem",
      "Niko Strijbol",
      "Peter Dawyndt",
      "Bart Mesuere"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.11942",
    "title": "The effect of Leaky ReLUs on the training and generalization of  overparameterized networks",
    "abstract": " Title: The effect of Leaky ReLUs on the training and generalization of  overparameterized networks ",
    "url": "https://arxiv.org/abs/2402.11942",
    "authors": [
      "Yinglong Guo",
      "Shaohan Li",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12062",
    "title": "Causal Equal Protection as Algorithmic Fairness",
    "abstract": " Comments: 18 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2402.12062",
    "authors": [
      "Marcello Di Bello",
      "Nicol\u00f2 Cangiotti",
      "Michele Loi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12503",
    "title": "PARCv2: Physics-aware Recurrent Convolutional Neural Networks for  Spatiotemporal Dynamics Modeling",
    "abstract": " Title: PARCv2: Physics-aware Recurrent Convolutional Neural Networks for  Spatiotemporal Dynamics Modeling ",
    "url": "https://arxiv.org/abs/2402.12503",
    "authors": [
      "Phong C.H. Nguyen",
      "Xinlun Cheng",
      "Shahab Azarfar",
      "Pradeep Seshadri",
      "Yen T. Nguyen",
      "Munho Kim",
      "Sanghun Choi",
      "H.S. Udaykumar",
      "Stephen Baek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12688",
    "title": "Robust-Wide: Robust Watermarking against Instruction-driven Image  Editing",
    "abstract": " Title: Robust-Wide: Robust Watermarking against Instruction-driven Image  Editing ",
    "url": "https://arxiv.org/abs/2402.12688",
    "authors": [
      "Runyi Hu",
      "Jie Zhang",
      "Ting Xu",
      "Tianwei Zhang",
      "Jiwei Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.12994",
    "title": "Distributionally Robust Graph-based Recommendation System",
    "abstract": " Comments: Accepted by WWW2024 ",
    "url": "https://arxiv.org/abs/2402.12994",
    "authors": [
      "Bohao Wang",
      "Jiawei Chen",
      "Changdong Li",
      "Sheng Zhou",
      "Qihao Shi",
      "Yang Gao",
      "Yan Feng",
      "Chun Chen",
      "Can Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.13001",
    "title": "A unifying primary framework for quantum graph neural networks from  quantum graph states",
    "abstract": " Comments: short version 6 pages, a few important typos are corrected ",
    "url": "https://arxiv.org/abs/2402.13001",
    "authors": [
      "Ammar Daskin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13092",
    "title": "Contractivity of neural ODEs: an eigenvalue optimization problem",
    "abstract": " Comments: 23 pages, 5 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2402.13092",
    "authors": [
      "Nicola Guglielmi",
      "Arturo De Marinis",
      "Anton Savostianov",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.13221",
    "title": "CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset  for Advancing Graph Machine Learning",
    "abstract": " Comments: 16 pages, 15 figures, 8 tables. Dataset is available at this https URL ",
    "url": "https://arxiv.org/abs/2402.13221",
    "authors": [
      "Ulrik Friis-Jensen",
      "Frederik L. Johansen",
      "Andy S. Anker",
      "Erik B. Dam",
      "Kirsten M. \u00d8. Jensen",
      "Raghavendra Selvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  }
]