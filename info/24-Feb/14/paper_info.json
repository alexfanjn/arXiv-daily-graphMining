[
  {
    "id": "arXiv:2402.07909",
    "title": "Prompt4Vis: Prompting Large Language Models with Example Mining and  Schema Filtering for Tabular Data Visualization",
    "abstract": "Data visualization (DV) systems are increasingly recognized for their profound capability to uncover insights from vast datasets, gaining attention across both industry and academia. Crafting data queries is an essential process within certain declarative visualization languages (DVLs, e.g., Vega-Lite, EChart.). The evolution of natural language processing (NLP) technologies has streamlined the use of natural language interfaces to visualize tabular data, offering a more accessible and intuitive user experience. However, current methods for converting natural language questions into data visualization queries, such as Seq2Vis, ncNet, and RGVisNet, despite utilizing complex neural network architectures, still fall short of expectations and have great room for improvement. Large language models (LLMs) such as ChatGPT and GPT-4, have established new benchmarks in a variety of NLP tasks, fundamentally altering the landscape of the field. Inspired by these advancements, we introduce a novel framework, Prompt4Vis, leveraging LLMs and in-context learning to enhance the performance of generating data visualization from natural language. Prompt4Vis comprises two key components: (1) a multi-objective example mining module, designed to find out the truly effective examples that strengthen the LLM's in-context learning capabilities for text-to-vis; (2) a schema filtering module, which is proposed to simplify the schema of the database. Extensive experiments through 5-fold cross-validation on the NVBench dataset demonstrate the superiority of Prompt4Vis, which notably surpasses the state-of-the-art (SOTA) RGVisNet by approximately 35.9% and 71.3% on dev and test sets, respectively. To the best of our knowledge, Prompt4Vis is the first work that introduces in-context learning into the text-to-vis for generating data visualization queries. ",
    "url": "https://arxiv.org/abs/2402.07909",
    "authors": [
      "Shuaimin Li",
      "Xuanang Chen",
      "Yuanfeng Song",
      "Yunze Song",
      "Chen Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2402.07950",
    "title": "Sentinels of the Stream: Unleashing Large Language Models for Dynamic  Packet Classification in Software Defined Networks -- Position Paper",
    "abstract": "With the release of OpenAI's ChatGPT, the field of large language models (LLM) saw an increase of academic interest in GPT based chat assistants. In the next few months multiple accesible large language models were released that included Meta's LLama models and Mistral AI's Mistral and Mixtral MoE models. These models are available openly for a wide array of purposes with a wide spectrum of licenses. These LLMs have found their use in a different number of fields like code development, SQL generation etc. In this work we propose our plan to explore the applicability of large language model in the domain of network security. We plan to create Sentinel, a LLM, to analyse network packet contents and pass a judgment on it's threat level. This work is a preliminary report that will lay our plan for our future endeavors. ",
    "url": "https://arxiv.org/abs/2402.07950",
    "authors": [
      "Shariq Murtuza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.07956",
    "title": "Educational data mining and learning analytics: An updated survey",
    "abstract": "This survey is an updated and improved version of the previous one published in 2013 in this journal with the title data mining in education. It reviews in a comprehensible and very general way how Educational Data Mining and Learning Analytics have been applied over educational data. In the last decade, this research area has evolved enormously and a wide range of related terms are now used in the bibliography such as Academic Analytics, Institutional Analytics, Teaching Analytics, Data-Driven Education, Data-Driven Decision-Making in Education, Big Data in Education, and Educational Data Science. This paper provides the current state of the art by reviewing the main publications, the key milestones, the knowledge discovery cycle, the main educational environments, the specific tools, the free available datasets, the most used methods, the main objectives, and the future trends in this research area. ",
    "url": "https://arxiv.org/abs/2402.07956",
    "authors": [
      "C. Romero",
      "S. Ventura"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07999",
    "title": "NetInfoF Framework: Measuring and Exploiting Network Usable Information",
    "abstract": "Given a node-attributed graph, and a graph task (link prediction or node classification), can we tell if a graph neural network (GNN) will perform well? More specifically, do the graph structure and the node features carry enough usable information for the task? Our goals are (1) to develop a fast tool to measure how much information is in the graph structure and in the node features, and (2) to exploit the information to solve the task, if there is enough. We propose NetInfoF, a framework including NetInfoF_Probe and NetInfoF_Act, for the measurement and the exploitation of network usable information (NUI), respectively. Given a graph data, NetInfoF_Probe measures NUI without any model training, and NetInfoF_Act solves link prediction and node classification, while two modules share the same backbone. In summary, NetInfoF has following notable advantages: (a) General, handling both link prediction and node classification; (b) Principled, with theoretical guarantee and closed-form solution; (c) Effective, thanks to the proposed adjustment to node similarity; (d) Scalable, scaling linearly with the input size. In our carefully designed synthetic datasets, NetInfoF correctly identifies the ground truth of NUI and is the only method being robust to all graph scenarios. Applied on real-world datasets, NetInfoF wins in 11 out of 12 times on link prediction compared to general GNN baselines. ",
    "url": "https://arxiv.org/abs/2402.07999",
    "authors": [
      "Meng-Chieh Lee",
      "Haiyang Yu",
      "Jian Zhang",
      "Vassilis N. Ioannidis",
      "Xiang Song",
      "Soji Adeshina",
      "Da Zheng",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.08022",
    "title": "Leveraging Digital Cousins for Ensemble Q-Learning in Large-Scale  Wireless Networks",
    "abstract": "Optimizing large-scale wireless networks, including optimal resource management, power allocation, and throughput maximization, is inherently challenging due to their non-observable system dynamics and heterogeneous and complex nature. Herein, a novel ensemble Q-learning algorithm that addresses the performance and complexity challenges of the traditional Q-learning algorithm for optimizing wireless networks is presented. Ensemble learning with synthetic Markov Decision Processes is tailored to wireless networks via new models for approximating large state-space observable wireless networks. In particular, digital cousins are proposed as an extension of the traditional digital twin concept wherein multiple Q-learning algorithms on multiple synthetic Markovian environments are run in parallel and their outputs are fused into a single Q-function. Convergence analyses of key statistics and Q-functions and derivations of upper bounds on the estimation bias and variance are provided. Numerical results across a variety of real-world wireless networks show that the proposed algorithm can achieve up to 50% less average policy error with up to 40% less runtime complexity than the state-of-the-art reinforcement learning algorithms. It is also shown that theoretical results properly predict trends in the experimental results. ",
    "url": "https://arxiv.org/abs/2402.08022",
    "authors": [
      "Talha Bozkus",
      "Urbashi Mitra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.08023",
    "title": "UGMAE: A Unified Framework for Graph Masked Autoencoders",
    "abstract": "Generative self-supervised learning on graphs, particularly graph masked autoencoders, has emerged as a popular learning paradigm and demonstrated its efficacy in handling non-Euclidean data. However, several remaining issues limit the capability of existing methods: 1) the disregard of uneven node significance in masking, 2) the underutilization of holistic graph information, 3) the ignorance of semantic knowledge in the representation space due to the exclusive use of reconstruction loss in the output space, and 4) the unstable reconstructions caused by the large volume of masked contents. In light of this, we propose UGMAE, a unified framework for graph masked autoencoders to address these issues from the perspectives of adaptivity, integrity, complementarity, and consistency. Specifically, we first develop an adaptive feature mask generator to account for the unique significance of nodes and sample informative masks (adaptivity). We then design a ranking-based structure reconstruction objective joint with feature reconstruction to capture holistic graph information and emphasize the topological proximity between neighbors (integrity). After that, we present a bootstrapping-based similarity module to encode the high-level semantic knowledge in the representation space, complementary to the low-level reconstruction in the output space (complementarity). Finally, we build a consistency assurance module to provide reconstruction objectives with extra stabilized consistency targets (consistency). Extensive experiments demonstrate that UGMAE outperforms both contrastive and generative state-of-the-art baselines on several tasks across multiple datasets. ",
    "url": "https://arxiv.org/abs/2402.08023",
    "authors": [
      "Yijun Tian",
      "Chuxu Zhang",
      "Ziyi Kou",
      "Zheyuan Liu",
      "Xiangliang Zhang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08035",
    "title": "Multiple Random Masking Autoencoder Ensembles for Robust Multimodal  Semi-supervised Learning",
    "abstract": "There is an increasing number of real-world problems in computer vision and machine learning requiring to take into consideration multiple interpretation layers (modalities or views) of the world and learn how they relate to each other. For example, in the case of Earth Observations from satellite data, it is important to be able to predict one observation layer (e.g. vegetation index) from other layers (e.g. water vapor, snow cover, temperature etc), in order to best understand how the Earth System functions and also be able to reliably predict information for one layer when the data is missing (e.g. due to measurement failure or error). ",
    "url": "https://arxiv.org/abs/2402.08035",
    "authors": [
      "Alexandru-Raul Todoran",
      "Marius Leordeanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08063",
    "title": "Locality Sensitive Hashing for Network Traffic Fingerprinting",
    "abstract": "The advent of the Internet of Things (IoT) has brought forth additional intricacies and difficulties to computer networks. These gadgets are particularly susceptible to cyber-attacks because of their simplistic design. Therefore, it is crucial to recognise these devices inside a network for the purpose of network administration and to identify any harmful actions. Network traffic fingerprinting is a crucial technique for identifying devices and detecting anomalies. Currently, the predominant methods for this depend heavily on machine learning (ML). Nevertheless, machine learning (ML) methods need the selection of features, adjustment of hyperparameters, and retraining of models to attain optimal outcomes and provide resilience to concept drifts detected in a network. In this research, we suggest using locality-sensitive hashing (LSH) for network traffic fingerprinting as a solution to these difficulties. Our study focuses on examining several design options for the Nilsimsa LSH function. We then use this function to create unique fingerprints for network data, which may be used to identify devices. We also compared it with ML-based traffic fingerprinting and observed that our method increases the accuracy of state-of-the-art by 12% achieving around 94% accuracy in identifying devices in a network. ",
    "url": "https://arxiv.org/abs/2402.08063",
    "authors": [
      "Nowfel Mashnoor",
      "Jay Thom",
      "Abdur Rouf",
      "Shamik Sengupta",
      "Batyr Charyyev"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08064",
    "title": "Beyond LLMs: Advancing the Landscape of Complex Reasoning",
    "abstract": "Since the advent of Large Language Models a few years ago, they have often been considered the de facto solution for many AI problems. However, in addition to the many deficiencies of LLMs that prevent them from broad industry adoption, such as reliability, cost, and speed, there is a whole class of common real world problems that Large Language Models perform poorly on, namely, constraint satisfaction and optimization problems. These problems are ubiquitous and current solutions are highly specialized and expensive to implement. At Elemental Cognition, we developed our EC AI platform which takes a neuro-symbolic approach to solving constraint satisfaction and optimization problems. The platform employs, at its core, a precise and high performance logical reasoning engine, and leverages LLMs for knowledge acquisition and user interaction. This platform supports developers in specifying application logic in natural and concise language while generating application user interfaces to interact with users effectively. We evaluated LLMs against systems built on the EC AI platform in three domains and found the EC AI systems to significantly outperform LLMs on constructing valid and optimal solutions, on validating proposed solutions, and on repairing invalid solutions. ",
    "url": "https://arxiv.org/abs/2402.08064",
    "authors": [
      "Jennifer Chu-Carroll",
      "Andrew Beck",
      "Greg Burnham",
      "David OS Melville",
      "David Nachman",
      "A. Erdem \u00d6zcan",
      "David Ferrucci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.08070",
    "title": "Multi-Attribute Vision Transformers are Efficient and Robust Learners",
    "abstract": "Since their inception, Vision Transformers (ViTs) have emerged as a compelling alternative to Convolutional Neural Networks (CNNs) across a wide spectrum of tasks. ViTs exhibit notable characteristics, including global attention, resilience against occlusions, and adaptability to distribution shifts. One underexplored aspect of ViTs is their potential for multi-attribute learning, referring to their ability to simultaneously grasp multiple attribute-related tasks. In this paper, we delve into the multi-attribute learning capability of ViTs, presenting a straightforward yet effective strategy for training various attributes through a single ViT network as distinct tasks. We assess the resilience of multi-attribute ViTs against adversarial attacks and compare their performance against ViTs designed for single attributes. Moreover, we further evaluate the robustness of multi-attribute ViTs against a recent transformer based attack called Patch-Fool. Our empirical findings on the CelebA dataset provide validation for our assertion. ",
    "url": "https://arxiv.org/abs/2402.08070",
    "authors": [
      "Hanan Gani",
      "Nada Saadi",
      "Noor Hussein",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08073",
    "title": "Grounding Data Science Code Generation with Input-Output Specifications",
    "abstract": "Large language models (LLMs) have recently demonstrated a remarkable ability to generate code from natural language (NL) prompts. However, in the real world, NL is often too ambiguous to capture the true intent behind programming problems, requiring additional input-output (I/O) specifications. Unfortunately, LLMs can have difficulty aligning their outputs with both the NL prompt and the I/O specification. In this paper, we give a way to mitigate this issue in the context of data science programming, where tasks require explicit I/O specifications for clarity. Specifically, we propose GIFT4Code, a novel approach for the instruction fine-tuning of LLMs with respect to I/O specifications. Our method leverages synthetic data produced by the LLM itself and utilizes execution-derived feedback as a key learning signal. This feedback, in the form of program I/O specifications, is provided to the LLM to facilitate instruction fine-tuning. We evaluated our approach on two challenging data science benchmarks, Arcade and DS-1000. The results demonstrate a significant improvement in the LLM's ability to generate code that is not only executable but also accurately aligned with user specifications, substantially improving the quality of code generation for complex data science tasks. ",
    "url": "https://arxiv.org/abs/2402.08073",
    "authors": [
      "Yeming Wen",
      "Pengcheng Yin",
      "Kensen Shi",
      "Henryk Michalewski",
      "Swarat Chaudhuri",
      "Alex Polozov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.08079",
    "title": "ReNeLiB: Real-time Neural Listening Behavior Generation for Socially  Interactive Agents",
    "abstract": "Flexible and natural nonverbal reactions to human behavior remain a challenge for socially interactive agents (SIAs) that are predominantly animated using hand-crafted rules. While recently proposed machine learning based approaches to conversational behavior generation are a promising way to address this challenge, they have not yet been employed in SIAs. The primary reason for this is the lack of a software toolkit integrating such approaches with SIA frameworks that conforms to the challenging real-time requirements of human-agent interaction scenarios. In our work, we for the first time present such a toolkit consisting of three main components: (1) real-time feature extraction capturing multi-modal social cues from the user; (2) behavior generation based on a recent state-of-the-art neural network approach; (3) visualization of the generated behavior supporting both FLAME-based and Apple ARKit-based interactive agents. We comprehensively evaluate the real-time performance of the whole framework and its components. In addition, we introduce pre-trained behavioral generation models derived from psychotherapy sessions for domain-specific listening behaviors. Our software toolkit, pivotal for deploying and assessing SIAs' listening behavior in real-time, is publicly available. Resources, including code, behavioural multi-modal features extracted from therapeutic interactions, are hosted at \\url{https://daksitha.github.io/ReNeLib} ",
    "url": "https://arxiv.org/abs/2402.08079",
    "authors": [
      "Daksitha Withanage Don",
      "Philipp M\u00fcller",
      "Fabrizio Nunnari",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.08085",
    "title": "Message Detouring: A Simple Yet Effective Cycle Representation for  Expressive Graph Learning",
    "abstract": "Graph learning is crucial in the fields of bioinformatics, social networks, and chemicals. Although high-order graphlets, such as cycles, are critical to achieving an informative graph representation for node classification, edge prediction, and graph recognition, modeling high-order topological characteristics poses significant computational challenges, restricting its widespread applications in machine learning. To address this limitation, we introduce the concept of \\textit{message detouring} to hierarchically characterize cycle representation throughout the entire graph, which capitalizes on the contrast between the shortest and longest pathways within a range of local topologies associated with each graph node. The topological feature representations derived from our message detouring landscape demonstrate comparable expressive power to high-order \\textit{Weisfeiler-Lehman} (WL) tests but much less computational demands. In addition to the integration with graph kernel and message passing neural networks, we present a novel message detouring neural network, which uses Transformer backbone to integrate cycle representations across nodes and edges. Aside from theoretical results, experimental results on expressiveness, graph classification, and node classification show message detouring can significantly outperform current counterpart approaches on various benchmark datasets. ",
    "url": "https://arxiv.org/abs/2402.08085",
    "authors": [
      "Ziquan Wei",
      "Tingting Dan",
      "Guorong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2402.08088",
    "title": "Out-of-Distribution Detection and Data Drift Monitoring using  Statistical Process Control",
    "abstract": "Background: Machine learning (ML) methods often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices in clinical settings, where data drift may cause unexpected performance that jeopardizes patient safety. Method: We propose a ML-enabled Statistical Process Control (SPC) framework for out-of-distribution (OOD) detection and drift monitoring. SPC is advantageous as it visually and statistically highlights deviations from the expected distribution. To demonstrate the utility of the proposed framework for monitoring data drift in radiological images, we investigated different design choices, including methods for extracting feature representations, drift quantification, and SPC parameter selection. Results: We demonstrate the effectiveness of our framework for two tasks: 1) differentiating axial vs. non-axial computed tomography (CT) images and 2) separating chest x-ray (CXR) from other modalities. For both tasks, we achieved high accuracy in detecting OOD inputs, with 0.913 in CT and 0.995 in CXR, and sensitivity of 0.980 in CT and 0.984 in CXR. Our framework was also adept at monitoring data streams and identifying the time a drift occurred. In a simulation with 100 daily CXR cases, we detected a drift in OOD input percentage from 0-1% to 3-5% within two days, maintaining a low false-positive rate. Through additional experimental results, we demonstrate the framework's data-agnostic nature and independence from the underlying model's structure. Conclusion: We propose a framework for OOD detection and drift monitoring that is agnostic to data, modality, and model. The framework is customizable and can be adapted for specific applications. ",
    "url": "https://arxiv.org/abs/2402.08088",
    "authors": [
      "Ghada Zamzmi",
      "Kesavan Venkatesh",
      "Brandon Nelson",
      "Smriti Prathapan",
      "Paul H. Yi",
      "Berkman Sahiner",
      "Jana G. Delfino"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.08090",
    "title": "Learning Neural Contracting Dynamics: Extended Linearization and Global  Guarantees",
    "abstract": "Global stability and robustness guarantees in learned dynamical systems are essential to ensure well-behavedness of the systems in the face of uncertainty. We present Extended Linearized Contracting Dynamics (ELCD), the first neural network-based dynamical system with global contractivity guarantees in arbitrary metrics. The key feature of ELCD is a parametrization of the extended linearization of the nonlinear vector field. In its most basic form, ELCD is guaranteed to be (i) globally exponentially stable, (ii) equilibrium contracting, and (iii) globally contracting with respect to some metric. To allow for contraction with respect to more general metrics in the data space, we train diffeomorphisms between the data space and a latent space and enforce contractivity in the latent space, which ensures global contractivity in the data space. We demonstrate the performance of ELCD on the $2$D, $4$D, and $8$D LASA datasets. ",
    "url": "https://arxiv.org/abs/2402.08090",
    "authors": [
      "Sean Jaffe",
      "Alexander Davydov",
      "Deniz Lapsekili",
      "Ambuj singh",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.08105",
    "title": "Learning Cartesian Product Graphs with Laplacian Constraints",
    "abstract": "Graph Laplacian learning, also known as network topology inference, is a problem of great interest to multiple communities. In Gaussian graphical models (GM), graph learning amounts to endowing covariance selection with the Laplacian structure. In graph signal processing (GSP), it is essential to infer the unobserved graph from the outputs of a filtering system. In this paper, we study the problem of learning Cartesian product graphs under Laplacian constraints. The Cartesian graph product is a natural way for modeling higher-order conditional dependencies and is also the key for generalizing GSP to multi-way tensors. We establish statistical consistency for the penalized maximum likelihood estimation (MLE) of a Cartesian product Laplacian, and propose an efficient algorithm to solve the problem. We also extend our method for efficient joint graph learning and imputation in the presence of structural missing values. Experiments on synthetic and real-world datasets demonstrate that our method is superior to previous GSP and GM methods. ",
    "url": "https://arxiv.org/abs/2402.08105",
    "authors": [
      "Changhao Shi",
      "Gal Mishne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.08122",
    "title": "Unmasking honey adulteration : a breakthrough in quality assurance  through cutting-edge convolutional neural network analysis of thermal images",
    "abstract": "Honey, a natural product generated from organic sources, is widely recognized for its revered reputation. Nevertheless, honey is susceptible to adulteration, a situation that has substantial consequences for both the well-being of the general population and the financial well-being of a country. Conventional approaches for detecting honey adulteration are often associated with extensive time requirements and restricted sensitivity. This paper presents a novel approach to address the aforementioned issue by employing Convolutional Neural Networks (CNNs) for the classification of honey samples based on thermal images. The use of thermal imaging technique offers a significant advantage in detecting adulterants, as it can reveal differences in temperature in honey samples caused by variations in sugar composition, moisture levels, and other substances used for adulteration. To establish a meticulous approach to categorizing honey, a thorough dataset comprising thermal images of authentic and tainted honey samples was collected. Several state-of-the-art Convolutional Neural Network (CNN) models were trained and optimized using the dataset that was gathered. Within this set of models, there exist pre-trained models such as InceptionV3, Xception, VGG19, and ResNet that have exhibited exceptional performance, achieving classification accuracies ranging from 88% to 98%. Furthermore, we have implemented a more streamlined and less complex convolutional neural network (CNN) model, outperforming comparable models with an outstanding accuracy rate of 99%. This simplification offers not only the sole advantage of the model, but it also concurrently offers a more efficient solution in terms of resources and time. This approach offers a viable way to implement quality control measures in the honey business, so guaranteeing the genuineness and safety of this valuable organic commodity. ",
    "url": "https://arxiv.org/abs/2402.08122",
    "authors": [
      "Ilias Boulbarj",
      "Bouklouze Abdelaziz",
      "Yousra El Alami",
      "Douzi Samira",
      "Douzi Hassan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08125",
    "title": "Customizable Perturbation Synthesis for Robust SLAM Benchmarking",
    "abstract": "Robustness is a crucial factor for the successful deployment of robots in unstructured environments, particularly in the domain of Simultaneous Localization and Mapping (SLAM). Simulation-based benchmarks have emerged as a highly scalable approach for robustness evaluation compared to real-world data collection. However, crafting a challenging and controllable noisy world with diverse perturbations remains relatively under-explored. To this end, we propose a novel, customizable pipeline for noisy data synthesis, aimed at assessing the resilience of multi-modal SLAM models against various perturbations. This pipeline incorporates customizable hardware setups, software components, and perturbed environments. In particular, we introduce comprehensive perturbation taxonomy along with a perturbation composition toolbox, allowing the transformation of clean simulations into challenging noisy environments. Utilizing the pipeline, we instantiate the Robust-SLAM benchmark, which includes diverse perturbation types, to evaluate the risk tolerance of existing advanced multi-modal SLAM models. Our extensive analysis uncovers the susceptibilities of existing SLAM models to real-world disturbance, despite their demonstrated accuracy in standard benchmarks. Our perturbation synthesis toolbox, SLAM robustness evaluation pipeline, and Robust-SLAM benchmark will be made publicly available at https://github.com/Xiaohao-Xu/SLAM-under-Perturbation/. ",
    "url": "https://arxiv.org/abs/2402.08125",
    "authors": [
      "Xiaohao Xu",
      "Tianyi Zhang",
      "Sibo Wang",
      "Xiang Li",
      "Yongqi Chen",
      "Ye Li",
      "Bhiksha Raj",
      "Matthew Johnson-Roberson",
      "Xiaonan Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.08127",
    "title": "Efficient Contextual Bandits with Uninformed Feedback Graphs",
    "abstract": "Bandits with feedback graphs are powerful online learning models that interpolate between the full information and classic bandit problems, capturing many real-life applications. A recent work by Zhang et al. (2023) studies the contextual version of this problem and proposes an efficient and optimal algorithm via a reduction to online regression. However, their algorithm crucially relies on seeing the feedback graph before making each decision, while in many applications, the feedback graph is uninformed, meaning that it is either only revealed after the learner makes her decision or even never fully revealed at all. This work develops the first contextual algorithm for such uninformed settings, via an efficient reduction to online regression over both the losses and the graphs. Importantly, we show that it is critical to learn the graphs using log loss instead of squared loss to obtain favorable regret guarantees. We also demonstrate the empirical effectiveness of our algorithm on a bidding application using both synthetic and real-world data. ",
    "url": "https://arxiv.org/abs/2402.08127",
    "authors": [
      "Mengxiao Zhang",
      "Yuheng Zhang",
      "Haipeng Luo",
      "Paul Mineiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08135",
    "title": "A scalable, synergy-first backbone decomposition of higher-order  structures in complex systems",
    "abstract": "Since its introduction in 2011, the partial information decomposition (PID) has triggered an explosion of interest in the field of multivariate information theory and the study of emergent, higher-order (\"synergistic\") interactions in complex systems. Despite its power, however, the PID has a number of limitations that restrict its general applicability: it scales poorly with system size and the standard approach to decomposition hinges on a definition of \"redundancy\", leaving synergy only vaguely defined as \"that information not redundant.\" Other heuristic measures, such as the O-information, have been introduced, although these measures typically only provided a summary statistic of redundancy/synergy dominance, rather than direct insight into the synergy itself. To address this issue, we present an alternative decomposition that is synergy-first, scales much more gracefully than the PID, and has a straightforward interpretation. Our approach defines synergy as that information in a set that would be lost following the minimally invasive perturbation on any single element. By generalizing this idea to sets of elements, we construct a totally ordered \"backbone\" of partial synergy atoms that sweeps systems scales. Our approach starts with entropy, but can be generalized to the Kullback-Leibler divergence, and by extension, to the total correlation and the single-target mutual information. Finally, we show that this approach can be used to decompose higher-order interactions beyond just information theory: we demonstrate this by showing how synergistic combinations of pairwise edges in a complex network supports signal communicability and global integration. We conclude by discussing how this perspective on synergistic structure (information-based or otherwise) can deepen our understanding of part-whole relationships in complex systems. ",
    "url": "https://arxiv.org/abs/2402.08135",
    "authors": [
      "Thomas F. Varley"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Other Statistics (stat.OT)"
    ]
  },
  {
    "id": "arXiv:2402.08155",
    "title": "CMA-R:Causal Mediation Analysis for Explaining Rumour Detection",
    "abstract": "We apply causal mediation analysis to explain the decision-making process of neural models for rumour detection on Twitter. Interventions at the input and network level reveal the causal impacts of tweets and words in the model output. We find that our approach CMA-R -- Causal Mediation Analysis for Rumour detection -- identifies salient tweets that explain model predictions and show strong agreement with human judgements for critical tweets determining the truthfulness of stories. CMA-R can further highlight causally impactful words in the salient tweets, providing another layer of interpretability and transparency into these blackbox rumour detection systems. Code is available at: https://github.com/ltian678/cma-r. ",
    "url": "https://arxiv.org/abs/2402.08155",
    "authors": [
      "Lin Tian",
      "Xiuzhen Zhang",
      "Jey Han Lau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08170",
    "title": "LLaGA: Large Language and Graph Assistant",
    "abstract": "Graph Neural Networks (GNNs) have empowered the advance in graph-structured data analysis. Recently, the rise of Large Language Models (LLMs) like GPT-4 has heralded a new era in deep learning. However, their application to graph data poses distinct challenges due to the inherent difficulty of translating graph structures to language. To this end, we introduce the \\textbf{L}arge \\textbf{L}anguage \\textbf{a}nd \\textbf{G}raph \\textbf{A}ssistant (\\textbf{LLaGA}), an innovative model that effectively integrates LLM capabilities to handle the complexities of graph-structured data. LLaGA retains the general-purpose nature of LLMs while adapting graph data into a format compatible with LLM input. LLaGA achieves this by reorganizing graph nodes to structure-aware sequences and then mapping these into the token embedding space through a versatile projector. LLaGA excels in versatility, generalizability and interpretability, allowing it to perform consistently well across different datasets and tasks, extend its ability to unseen datasets or tasks, and provide explanations for graphs. Our extensive experiments across popular graph benchmarks show that LLaGA delivers outstanding performance across four datasets and three tasks using one single model, surpassing state-of-the-art graph models in both supervised and zero-shot scenarios. Our code is available at \\url{https://github.com/ChenRunjin/LLaGA} ",
    "url": "https://arxiv.org/abs/2402.08170",
    "authors": [
      "Runjin Chen",
      "Tong Zhao",
      "Ajay Jaiswal",
      "Neil Shah",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08174",
    "title": "Hierarchical Position Embedding of Graphs with Landmarks and Clustering  for Link Prediction",
    "abstract": "Learning positional information of nodes in a graph is important for link prediction tasks. We propose a representation of positional information using representative nodes called landmarks. A small number of nodes with high degree centrality are selected as landmarks, which serve as reference points for the nodes' positions. We justify this selection strategy for well-known random graph models and derive closed-form bounds on the average path lengths involving landmarks. In a model for power-law graphs, we prove that landmarks provide asymptotically exact information on inter-node distances. We apply theoretical insights to practical networks and propose Hierarchical Position embedding with Landmarks and Clustering (HPLC). HPLC combines landmark selection and graph clustering, where the graph is partitioned into densely connected clusters in which nodes with the highest degree are selected as landmarks. HPLC leverages the positional information of nodes based on landmarks at various levels of hierarchy such as nodes' distances to landmarks, inter-landmark distances and hierarchical grouping of clusters. Experiments show that HPLC achieves state-of-the-art performances of link prediction on various datasets in terms of HIT@K, MRR, and AUC. The code is available at \\url{https://github.com/kmswin1/HPLC}. ",
    "url": "https://arxiv.org/abs/2402.08174",
    "authors": [
      "Minsang Kim",
      "Seungjun Baek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08180",
    "title": "Online Structured Prediction with Fenchel--Young Losses and Improved  Surrogate Regret for Online Multiclass Classification with Logistic Loss",
    "abstract": "This paper studies online structured prediction with full-information feedback. For online multiclass classification, van der Hoeven (2020) has obtained surrogate regret bounds independent of the time horizon, or \\emph{finite}, by introducing an elegant \\emph{exploit-the-surrogate-gap} framework. However, this framework has been limited to multiclass classification primarily because it relies on a classification-specific procedure for converting estimated scores to outputs. We extend the exploit-the-surrogate-gap framework to online structured prediction with \\emph{Fenchel--Young losses}, a large family of surrogate losses including the logistic loss for multiclass classification, obtaining finite surrogate regret bounds in various structured prediction problems. To this end, we propose and analyze \\emph{randomized decoding}, which converts estimated scores to general structured outputs. Moreover, by applying our decoding to online multiclass classification with the logistic loss, we obtain a surrogate regret bound of $O(B^2)$, where $B$ is the $\\ell_2$-diameter of the domain. This bound is tight up to logarithmic factors and improves the previous bound of $O(dB^2)$ due to van der Hoeven (2020) by a factor of $d$, the number of classes. ",
    "url": "https://arxiv.org/abs/2402.08180",
    "authors": [
      "Shinsaku Sakaue",
      "Han Bao",
      "Taira Tsuchiya",
      "Taihei Oki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08183",
    "title": "Pixel Sentence Representation Learning",
    "abstract": "Pretrained language models are long known to be subpar in capturing sentence and document-level semantics. Though heavily investigated, transferring perturbation-based methods from unsupervised visual representation learning to NLP remains an unsolved problem. This is largely due to the discreteness of subword units brought by tokenization of language models, limiting small perturbations of inputs to form semantics-preserved positive pairs. In this work, we conceptualize the learning of sentence-level textual semantics as a visual representation learning process. Drawing from cognitive and linguistic sciences, we introduce an unsupervised visual sentence representation learning framework, employing visually-grounded text perturbation methods like typos and word order shuffling, resonating with human cognitive patterns, and enabling perturbation to texts to be perceived as continuous. Our approach is further bolstered by large-scale unsupervised topical alignment training and natural language inference supervision, achieving comparable performance in semantic textual similarity (STS) to existing state-of-the-art NLP methods. Additionally, we unveil our method's inherent zero-shot cross-lingual transferability and a unique leapfrogging pattern across languages during iterative training. To our knowledge, this is the first representation learning method devoid of traditional language models for understanding sentence and document semantics, marking a stride closer to human-like textual comprehension. Our code is available at https://github.com/gowitheflow-1998/Pixel-Linguist ",
    "url": "https://arxiv.org/abs/2402.08183",
    "authors": [
      "Chenghao Xiao",
      "Zhuoxu Huang",
      "Danlu Chen",
      "G Thomas Hudson",
      "Yizhi Li",
      "Haoran Duan",
      "Chenghua Lin",
      "Jie Fu",
      "Jungong Han",
      "Noura Al Moubayed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08184",
    "title": "Enabling Multi-Agent Transfer Reinforcement Learning via Scenario  Independent Representation",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) algorithms are widely adopted in tackling complex tasks that require collaboration and competition among agents in dynamic Multi-Agent Systems (MAS). However, learning such tasks from scratch is arduous and may not always be feasible, particularly for MASs with a large number of interactive agents due to the extensive sample complexity. Therefore, reusing knowledge gained from past experiences or other agents could efficiently accelerate the learning process and upscale MARL algorithms. In this study, we introduce a novel framework that enables transfer learning for MARL through unifying various state spaces into fixed-size inputs that allow one unified deep-learning policy viable in different scenarios within a MAS. We evaluated our approach in a range of scenarios within the StarCraft Multi-Agent Challenge (SMAC) environment, and the findings show significant enhancements in multi-agent learning performance using maneuvering skills learned from other scenarios compared to agents learning from scratch. Furthermore, we adopted Curriculum Transfer Learning (CTL), enabling our deep learning policy to progressively acquire knowledge and skills across pre-designed homogeneous learning scenarios organized by difficulty levels. This process promotes inter- and intra-agent knowledge transfer, leading to high multi-agent learning performance in more complicated heterogeneous scenarios. ",
    "url": "https://arxiv.org/abs/2402.08184",
    "authors": [
      "Ayesha Siddika Nipu",
      "Siming Liu",
      "Anthony Harris"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08185",
    "title": "Advancing Data-driven Weather Forecasting: Time-Sliding Data  Augmentation of ERA5",
    "abstract": "Modern deep learning techniques, which mimic traditional numerical weather prediction (NWP) models and are derived from global atmospheric reanalysis data, have caused a significant revolution within a few years. In this new paradigm, our research introduces a novel strategy that deviates from the common dependence on high-resolution data, which is often constrained by computational resources, and instead utilizes low-resolution data (2.5 degrees) for global weather prediction and climate data analysis. Our main focus is evaluating data-driven weather prediction (DDWP) frameworks, specifically addressing sample size adequacy, structural improvements to the model, and the ability of climate data to represent current climatic trends. By using the Adaptive Fourier Neural Operator (AFNO) model via FourCastNet and a proposed time-sliding method to inflate the dataset of the ECMWF Reanalysis v5 (ERA5), this paper improves on conventional approaches by adding more variables and a novel approach to data augmentation and processing. Our findings reveal that despite the lower resolution, the proposed approach demonstrates considerable accuracy in predicting atmospheric conditions, effectively rivaling higher-resolution models. Furthermore, the study confirms the model's proficiency in reflecting current climate trends and its potential in predicting future climatic events, underscoring its utility in climate change strategies. This research marks a pivotal step in the realm of meteorological forecasting, showcasing the feasibility of lower-resolution data in producing reliable predictions and opening avenues for more accessible and inclusive climate modeling. The insights gleaned from this study not only contribute to the advancement of climate science but also lay the groundwork for future innovations in the field. ",
    "url": "https://arxiv.org/abs/2402.08185",
    "authors": [
      "Minjong Cheon",
      "Daehyun Kang",
      "Yo-Hwan Choi",
      "Seon-Yu Kang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2402.08187",
    "title": "Learning time-dependent PDE via graph neural networks and deep operator  network for robust accuracy on irregular grids",
    "abstract": "Scientific computing using deep learning has seen significant advancements in recent years. There has been growing interest in models that learn the operator from the parameters of a partial differential equation (PDE) to the corresponding solutions. Deep Operator Network (DeepONet) and Fourier Neural operator, among other models, have been designed with structures suitable for handling functions as inputs and outputs, enabling real-time predictions as surrogate models for solution operators. There has also been significant progress in the research on surrogate models based on graph neural networks (GNNs), specifically targeting the dynamics in time-dependent PDEs. In this paper, we propose GraphDeepONet, an autoregressive model based on GNNs, to effectively adapt DeepONet, which is well-known for successful operator learning. GraphDeepONet exhibits robust accuracy in predicting solutions compared to existing GNN-based PDE solver models. It maintains consistent performance even on irregular grids, leveraging the advantages inherited from DeepONet and enabling predictions on arbitrary grids. Additionally, unlike traditional DeepONet and its variants, GraphDeepONet enables time extrapolation for time-dependent PDE solutions. We also provide theoretical analysis of the universal approximation capability of GraphDeepONet in approximating continuous operators across arbitrary time intervals. ",
    "url": "https://arxiv.org/abs/2402.08187",
    "authors": [
      "Sung Woong Cho",
      "Jae Yong Lee",
      "Hyung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.08217",
    "title": "Springboard, Roadblock or \"Crutch\"?: How Transgender Users Leverage  Voice Changers for Gender Presentation in Social Virtual Reality",
    "abstract": "Social virtual reality (VR) serves as a vital platform for transgender individuals to explore their identities through avatars and foster personal connections within online communities. However, it presents a challenge: the disconnect between avatar embodiment and voice representation, often leading to misgendering and harassment. Prior research acknowledges this issue but overlooks the potential solution of voice changers. We interviewed 13 transgender and gender-nonconforming users of social VR platforms, focusing on their experiences with and without voice changers. We found that using a voice changer not only reduces voice-related harassment, but also allows them to experience gender euphoria through both hearing their modified voice and the reactions of others to their modified voice, motivating them to pursue voice training and medication to achieve desired voices. Furthermore, we identified the technical barriers to current voice changer technology and potential improvements to alleviate the problems that transgender and gender-nonconforming users face. ",
    "url": "https://arxiv.org/abs/2402.08217",
    "authors": [
      "Kassie Povinelli",
      "Yuhang Zhao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.08221",
    "title": "MetaTra: Meta-Learning for Generalized Trajectory Prediction in Unseen  Domain",
    "abstract": "Trajectory prediction has garnered widespread attention in different fields, such as autonomous driving and robotic navigation. However, due to the significant variations in trajectory patterns across different scenarios, models trained in known environments often falter in unseen ones. To learn a generalized model that can directly handle unseen domains without requiring any model updating, we propose a novel meta-learning-based trajectory prediction method called MetaTra. This approach incorporates a Dual Trajectory Transformer (Dual-TT), which enables a thorough exploration of the individual intention and the interactions within group motion patterns in diverse scenarios. Building on this, we propose a meta-learning framework to simulate the generalization process between source and target domains. Furthermore, to enhance the stability of our prediction outcomes, we propose a Serial and Parallel Training (SPT) strategy along with a feature augmentation method named MetaMix. Experimental results on several real-world datasets confirm that MetaTra not only surpasses other state-of-the-art methods but also exhibits plug-and-play capabilities, particularly in the realm of domain generalization. ",
    "url": "https://arxiv.org/abs/2402.08221",
    "authors": [
      "Xiaohe Li",
      "Feilong Huang",
      "Zide Fan",
      "Fangli Mou",
      "Yingyan Hou",
      "Chen Qian",
      "Lijie Wen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08225",
    "title": "Improving Black-box Robustness with In-Context Rewriting",
    "abstract": "Machine learning models often excel on in-distribution (ID) data but struggle with unseen out-of-distribution (OOD) inputs. Most techniques for improving OOD robustness are not applicable to settings where the model is effectively a black box, such as when the weights are frozen, retraining is costly, or the model is leveraged via an API. Test-time augmentation (TTA) is a simple post-hoc technique for improving robustness that sidesteps black-box constraints by aggregating predictions across multiple augmentations of the test input. TTA has seen limited use in NLP due to the challenge of generating effective natural language augmentations. In this work, we propose LLM-TTA, which uses LLM-generated augmentations as TTA's augmentation function. LLM-TTA outperforms conventional augmentation functions across sentiment, toxicity, and news classification tasks for BERT and T5 models, with BERT's OOD robustness improving by an average of 4.30 percentage points without regressing average ID performance. We explore selectively augmenting inputs based on prediction entropy to reduce the rate of expensive LLM augmentations, allowing us to maintain performance gains while reducing the average number of generated augmentations by 57.76%. LLM-TTA is agnostic to the task model architecture, does not require OOD labels, and is effective across low and high-resource settings. We share our data, models, and code for reproducibility. ",
    "url": "https://arxiv.org/abs/2402.08225",
    "authors": [
      "Kyle O'Brien",
      "Nathan Ng",
      "Isha Puri",
      "Jorge Mendez",
      "Hamid Palangi",
      "Yoon Kim",
      "Marzyeh Ghassemi",
      "Thomas Hartvigsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08229",
    "title": "Causal Discovery under Off-Target Interventions",
    "abstract": "Causal graph discovery is a significant problem with applications across various disciplines. However, with observational data alone, the underlying causal graph can only be recovered up to its Markov equivalence class, and further assumptions or interventions are necessary to narrow down the true graph. This work addresses the causal discovery problem under the setting of stochastic interventions with the natural goal of minimizing the number of interventions performed. We propose the following stochastic intervention model which subsumes existing adaptive noiseless interventions in the literature while capturing scenarios such as fat-hand interventions and CRISPR gene knockouts: any intervention attempt results in an actual intervention on a random subset of vertices, drawn from a distribution dependent on attempted action. Under this model, we study the two fundamental problems in causal discovery of verification and search and provide approximation algorithms with polylogarithmic competitive ratios and provide some preliminary experimental results. ",
    "url": "https://arxiv.org/abs/2402.08229",
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.08231",
    "title": "Asynchronous Distributed Coordinated Hybrid Precoding in Multi-cell  mmWave Wireless Networks",
    "abstract": "Asynchronous distributed hybrid beamformers (ADBF) are conceived for minimizing the total transmit power subject to signal-to-interference-plus-noise ratio (SINR) constraints at the users. Our design requires only limited information exchange between the base stations (BSs) of the mmWave multi-cell coordinated (MCC) networks considered. To begin with, a semidefinite relaxation (SDR)-based fully-digital (FD) beamformer is designed for a centralized MCC system. Subsequently, a Bayesian learning (BL) technique is harnessed for decomposing the FD beamformer into its analog and baseband components and construct a hybrid transmit precoder (TPC). However, the centralized TPC design requires global channel state information (CSI), hence it results in a high signaling overhead. An alternating direction based method of multipliers (ADMM) technique is developed for a synchronous distributed beamformer (SDBF) design, which relies only on limited information exchange among the BSs, thus reducing the signaling overheads required by the centralized TPC design procedure. However, the SDBF design is challenging, since it requires the updates from the BSs to be strictly synchronized. As a remedy, an ADBF framework is developed that mitigates the inter-cell interference (ICI) and also control the asynchrony in the system. Furthermore, the above ADBF framework is also extended to the robust ADBF (R-ADBF) algorithm that incorporates the CSI uncertainty into the design procedure for minimizing the the worst-case transmit power. Our simulation results illustrate both the enhanced performance and the improved convergence properties of the ADMM-based ADBF and R-ADBF schemes. ",
    "url": "https://arxiv.org/abs/2402.08231",
    "authors": [
      "Meesam Jafri",
      "Suraj Srivastava",
      "Sunil Kumar",
      "Aditya K. Jagannatham",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.08236",
    "title": "BERT4FCA: A Method for Bipartite Link Prediction using Formal Concept  Analysis and BERT",
    "abstract": "We propose BERT4FCA, a novel method for link prediction in bipartite networks, using formal concept analysis (FCA) and BERT. Link prediction in bipartite networks is an important task that can solve various practical problems like friend recommendation in social networks and co-authorship prediction in author-paper networks. Recent research has found that in bipartite networks, maximal bi-cliques provide important information for link prediction, and they can be extracted by FCA. Some FCA-based bipartite link prediction methods have achieved good performance. However, we figured out that their performance could be further improved because these methods did not fully capture the rich information of the extracted maximal bi-cliques. To address this limitation, we propose an approach using BERT, which can learn more information from the maximal bi-cliques extracted by FCA and use them to make link prediction. We conduct experiments on three real-world bipartite networks and demonstrate that our method outperforms previous FCA-based methods, and some classic methods such as matrix-factorization and node2vec. ",
    "url": "https://arxiv.org/abs/2402.08236",
    "authors": [
      "Siqi Peng",
      "Hongyuan Yang",
      "Akihiro Yamamoto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08241",
    "title": "Causal Learning for Trustworthy Recommender Systems: A Survey",
    "abstract": "Recommender Systems (RS) have significantly advanced online content discovery and personalized decision-making. However, emerging vulnerabilities in RS have catalyzed a paradigm shift towards Trustworthy RS (TRS). Despite numerous progress on TRS, most of them focus on data correlations while overlooking the fundamental causal nature in recommendation. This drawback hinders TRS from identifying the cause in addressing trustworthiness issues, leading to limited fairness, robustness, and explainability. To bridge this gap, causal learning emerges as a class of promising methods to augment TRS. These methods, grounded in reliable causality, excel in mitigating various biases and noises while offering insightful explanations for TRS. However, there lacks a timely survey in this vibrant area. This paper creates an overview of TRS from the perspective of causal learning. We begin by presenting the advantages and common procedures of Causality-oriented TRS (CTRS). Then, we identify potential trustworthiness challenges at each stage and link them to viable causal solutions, followed by a classification of CTRS methods. Finally, we discuss several future directions for advancing this field. ",
    "url": "https://arxiv.org/abs/2402.08241",
    "authors": [
      "Jin Li",
      "Shoujin Wang",
      "Qi Zhang",
      "Longbing Cao",
      "Fang Chen",
      "Xiuzhen Zhang",
      "Dietmar Jannach",
      "Charu C. Aggarwal"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.08244",
    "title": "APALU: A Trainable, Adaptive Activation Function for Deep Learning  Networks",
    "abstract": "Activation function is a pivotal component of deep learning, facilitating the extraction of intricate data patterns. While classical activation functions like ReLU and its variants are extensively utilized, their static nature and simplicity, despite being advantageous, often limit their effectiveness in specialized tasks. The trainable activation functions also struggle sometimes to adapt to the unique characteristics of the data. Addressing these limitations, we introduce a novel trainable activation function, adaptive piecewise approximated activation linear unit (APALU), to enhance the learning performance of deep learning across a broad range of tasks. It presents a unique set of features that enable it to maintain stability and efficiency in the learning process while adapting to complex data representations. Experiments reveal significant improvements over widely used activation functions for different tasks. In image classification, APALU increases MobileNet and GoogleNet accuracy by 0.37% and 0.04%, respectively, on the CIFAR10 dataset. In anomaly detection, it improves the average area under the curve of One-CLASS Deep SVDD by 0.8% on the MNIST dataset, 1.81% and 1.11% improvements with DifferNet, and knowledge distillation, respectively, on the MVTech dataset. Notably, APALU achieves 100% accuracy on a sign language recognition task with a limited dataset. For regression tasks, APALU enhances the performance of deep neural networks and recurrent neural networks on different datasets. These improvements highlight the robustness and adaptability of APALU across diverse deep-learning applications. ",
    "url": "https://arxiv.org/abs/2402.08244",
    "authors": [
      "Barathi Subramanian",
      "Rathinaraja Jeyaraj",
      "Rakhmonov Akhrorjon Akhmadjon Ugli",
      "Jeonghong Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.08251",
    "title": "Object Detection in Thermal Images Using Deep Learning for Unmanned  Aerial Vehicles",
    "abstract": "This work presents a neural network model capable of recognizing small and tiny objects in thermal images collected by unmanned aerial vehicles. Our model consists of three parts, the backbone, the neck, and the prediction head. The backbone is developed based on the structure of YOLOv5 combined with the use of a transformer encoder at the end. The neck includes a BI-FPN block combined with the use of a sliding window and a transformer to increase the information fed into the prediction head. The prediction head carries out the detection by evaluating feature maps with the Sigmoid function. The use of transformers with attention and sliding windows increases recognition accuracy while keeping the model at a reasonable number of parameters and computation requirements for embedded systems. Experiments conducted on public dataset VEDAI and our collected datasets show that our model has a higher accuracy than state-of-the-art methods such as ResNet, Faster RCNN, ComNet, ViT, YOLOv5, SMPNet, and DPNetV3. Experiments on the embedded computer Jetson AGX show that our model achieves a real-time computation speed with a stability rate of over 90%. ",
    "url": "https://arxiv.org/abs/2402.08251",
    "authors": [
      "Minh Dang Tu",
      "Kieu Trang Le",
      "Manh Duong Phung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08269",
    "title": "Geometry-induced Implicit Regularization in Deep ReLU Neural Networks",
    "abstract": "It is well known that neural networks with many more parameters than training examples do not overfit. Implicit regularization phenomena, which are still not well understood, occur during optimization and 'good' networks are favored. Thus the number of parameters is not an adequate measure of complexity if we do not consider all possible networks but only the 'good' ones. To better understand which networks are favored during optimization, we study the geometry of the output set as parameters vary. When the inputs are fixed, we prove that the dimension of this set changes and that the local dimension, called batch functional dimension, is almost surely determined by the activation patterns in the hidden layers. We prove that the batch functional dimension is invariant to the symmetries of the network parameterization: neuron permutations and positive rescalings. Empirically, we establish that the batch functional dimension decreases during optimization. As a consequence, optimization leads to parameters with low batch functional dimensions. We call this phenomenon geometry-induced implicit regularization.The batch functional dimension depends on both the network parameters and inputs. To understand the impact of the inputs, we study, for fixed parameters, the largest attainable batch functional dimension when the inputs vary. We prove that this quantity, called computable full functional dimension, is also invariant to the symmetries of the network's parameterization, and is determined by the achievable activation patterns. We also provide a sampling theorem, showing a fast convergence of the estimation of the computable full functional dimension for a random input of increasing size. Empirically we find that the computable full functional dimension remains close to the number of parameters, which is related to the notion of local identifiability. This differs from the observed values for the batch functional dimension computed on training inputs and test inputs. The latter are influenced by geometry-induced implicit regularization. ",
    "url": "https://arxiv.org/abs/2402.08269",
    "authors": [
      "Joachim Bona-Pellissier",
      "Fran \u00e7ois Malgouyres",
      "Fran \u00e7ois Bachoc"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2402.08277",
    "title": "Towards Faithful and Robust LLM Specialists for Evidence-Based  Question-Answering",
    "abstract": "Advances towards more faithful and traceable answers of Large Language Models (LLMs) are crucial for various research and practical endeavors. One avenue in reaching this goal is basing the answers on reliable sources. However, this Evidence-Based QA has proven to work insufficiently with LLMs in terms of citing the correct sources (source quality) and truthfully representing the information within sources (answer attributability). In this work, we systematically investigate how to robustly fine-tune LLMs for better source quality and answer attributability. Specifically, we introduce a data generation pipeline with automated data quality filters, which can synthesize diversified high-quality training and testing data at scale. We further introduce four test sets to benchmark the robustness of fine-tuned specialist models. Extensive evaluation shows that fine-tuning on synthetic data improves performance on both in- and out-of-distribution. %Evidence-Based QA cases. Furthermore, we show that data quality, which can be drastically improved by proposed quality filters, matters more than quantity in improving Evidence-Based QA. ",
    "url": "https://arxiv.org/abs/2402.08277",
    "authors": [
      "Tobias Schimanski",
      "Jingwei Ni",
      "Mathias Kraus",
      "Elliott Ash",
      "Markus Leippold"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08280",
    "title": "Pix2Code: Learning to Compose Neural Visual Concepts as Programs",
    "abstract": "The challenge in learning abstract concepts from images in an unsupervised fashion lies in the required integration of visual perception and generalizable relational reasoning. Moreover, the unsupervised nature of this task makes it necessary for human users to be able to understand a model's learnt concepts and potentially revise false behaviours. To tackle both the generalizability and interpretability constraints of visual concept learning, we propose Pix2Code, a framework that extends program synthesis to visual relational reasoning by utilizing the abilities of both explicit, compositional symbolic and implicit neural representations. This is achieved by retrieving object representations from images and synthesizing relational concepts as lambda-calculus programs. We evaluate the diverse properties of Pix2Code on the challenging reasoning domains, Kandinsky Patterns and CURI, thereby testing its ability to identify compositional visual concepts that generalize to novel data and concept configurations. Particularly, in stark contrast to neural approaches, we show that Pix2Code's representations remain human interpretable and can be easily revised for improved performance. ",
    "url": "https://arxiv.org/abs/2402.08280",
    "authors": [
      "Antonia W\u00fcst",
      "Wolfgang Stammer",
      "Quentin Delfosse",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08286",
    "title": "MetaVRadar: Measuring Metaverse Virtual Reality Network Activity",
    "abstract": "The \"metaverse\", wherein users can enter virtual worlds to work, study, play, shop, socialize, and entertain, is fast becoming a reality, attracting billions of dollars in investment from companies such as Meta, Microsoft, and Clipo Labs. Further, virtual reality (VR) headsets from entities like Oculus, HTC, and Microsoft are rapidly maturing to provide fully immersive experiences to metaverse users. However, little is known about the network dynamics of metaverse VR applications in terms of service domains, flow counts, traffic rates and volumes, content location and latency, etc., which are needed to make telecommunications network infrastructure \"metaverse ready\". This paper is an empirical measurement study of metaverse VR network behavior aimed at helping telecommunications network operators better provision and manage the network to ensure good user experience. Using illustrative hour-long network traces of metaverse sessions on the Oculus VR headset, we first develop a categorization of user activity into distinct states ranging from login home to streetwalking and event attendance to asset trading, and undertake a detailed analysis of network traffic per state, identifying unique service domains, protocols, flow profiles, and volumetric patterns, thereby highlighting the vastly more complex nature of a metaverse session compared to streaming video or gaming. Armed with the network behavioral profiles, our second contribution develops a real-time method MetaVRadar to detect metaverse session and classify the user activity state leveraging formalized flow signatures and volumetric attributes. Our third contribution practically implements MetaVRadar, evaluates its accuracy in our lab environment, and demonstrates its usability in a large university network so operators can better monitor and plan resources to support requisite metaverse user experience. ",
    "url": "https://arxiv.org/abs/2402.08286",
    "authors": [
      "Minzhao Lyu",
      "Rahul Dev Tripathi",
      "Vijay Sivaraman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.08290",
    "title": "The Effect of Data Poisoning on Counterfactual Explanations",
    "abstract": "Counterfactual explanations provide a popular method for analyzing the predictions of black-box systems, and they can offer the opportunity for computational recourse by suggesting actionable changes on how to change the input to obtain a different (i.e. more favorable) system output. However, recent work highlighted their vulnerability to different types of manipulations. This work studies the vulnerability of counterfactual explanations to data poisoning. We formalize data poisoning in the context of counterfactual explanations for increasing the cost of recourse on three different levels: locally for a single instance, or a sub-group of instances, or globally for all instances. We demonstrate that state-of-the-art counterfactual generation methods \\& toolboxes are vulnerable to such data poisoning. ",
    "url": "https://arxiv.org/abs/2402.08290",
    "authors": [
      "Andr\u00e9 Artelt",
      "Shubham Sharma",
      "Freddy Lecu\u00e9",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08296",
    "title": "Multi-Level GNN Preconditioner for Solving Large Scale Problems",
    "abstract": "Large-scale numerical simulations often come at the expense of daunting computations. High-Performance Computing has enhanced the process, but adapting legacy codes to leverage parallel GPU computations remains challenging. Meanwhile, Machine Learning models can harness GPU computations effectively but often struggle with generalization and accuracy. Graph Neural Networks (GNNs), in particular, are great for learning from unstructured data like meshes but are often limited to small-scale problems. Moreover, the capabilities of the trained model usually restrict the accuracy of the data-driven solution. To benefit from both worlds, this paper introduces a novel preconditioner integrating a GNN model within a multi-level Domain Decomposition framework. The proposed GNN-based preconditioner is used to enhance the efficiency of a Krylov method, resulting in a hybrid solver that can converge with any desired level of accuracy. The efficiency of the Krylov method greatly benefits from the GNN preconditioner, which is adaptable to meshes of any size and shape, is executed on GPUs, and features a multi-level approach to enforce the scalability of the entire process. Several experiments are conducted to validate the numerical behavior of the hybrid solver, and an in-depth analysis of its performance is proposed to assess its competitiveness against a C++ legacy solver. ",
    "url": "https://arxiv.org/abs/2402.08296",
    "authors": [
      "Matthieu Nastorg",
      "Jean-Marc Gratien",
      "Thibault Faney",
      "Michele Alessandro Bucci",
      "Guillaume Charpiat",
      "Marc Schoenauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.08299",
    "title": "Zero Trust Score-based Network-level Access Control in Enterprise  Networks",
    "abstract": "Zero Trust security has recently gained attention in enterprise network security. One of its key ideas is making network-level access decisions based on trust scores. However, score-based access control in the enterprise domain still lacks essential elements in our understanding, and in this paper, we contribute with respect to three crucial aspects. First, we provide a comprehensive list of 29 trust attributes that can be used to calculate a trust score. By introducing a novel mathematical approach, we demonstrate how to quantify these attributes. Second, we describe a dynamic risk-based method to calculate the trust threshold the trust score must meet for permitted access. Third, we introduce a novel trust algorithm based on Subjective Logic that incorporates the first two contributions and offers fine-grained decision possibilities. We discuss how this algorithm shows a higher expressiveness compared to a lightweight additive trust algorithm. Performance-wise, a prototype of the Subjective Logic-based approach showed similar calculation times for making an access decision as the additive approach. In addition, the dynamic threshold calculation showed only 7% increased decision-making times compared to a static threshold. ",
    "url": "https://arxiv.org/abs/2402.08299",
    "authors": [
      "Leonard Bradatsch",
      "Oleksandr Miroshkin",
      "Natasa Trkulja",
      "Frank Kargl"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.08309",
    "title": "Prompted Contextual Vectors for Spear-Phishing Detection",
    "abstract": "Spear-phishing attacks present a significant security challenge, with large language models (LLMs) escalating the threat by generating convincing emails and facilitating target reconnaissance. To address this, we propose a detection approach based on a novel document vectorization method that utilizes an ensemble of LLMs to create representation vectors. By prompting LLMs to reason and respond to human-crafted questions, we quantify the presence of common persuasion principles in the email's content, producing prompted contextual document vectors for a downstream supervised machine learning model. We evaluate our method using a unique dataset generated by a proprietary system that automates target reconnaissance and spear-phishing email creation. Our method achieves a 91% F1 score in identifying LLM-generated spear-phishing emails, with the training set comprising only traditional phishing and benign emails. Key contributions include an innovative document vectorization method utilizing LLM reasoning, a publicly available dataset of high-quality spear-phishing emails, and the demonstrated effectiveness of our method in detecting such emails. This methodology can be utilized for various document classification tasks, particularly in adversarial problem domains. ",
    "url": "https://arxiv.org/abs/2402.08309",
    "authors": [
      "Daniel Nahmias",
      "Gal Engelberg",
      "Dan Klein",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.08313",
    "title": "Approximating Families of Sharp Solutions to Fisher's Equation with  Physics-Informed Neural Networks",
    "abstract": "This paper employs physics-informed neural networks (PINNs) to solve Fisher's equation, a fundamental representation of a reaction-diffusion system with both simplicity and significance. The focus lies specifically in investigating Fisher's equation under conditions of large reaction rate coefficients, wherein solutions manifest as traveling waves, posing a challenge for numerical methods due to the occurring steepness of the wave front. To address optimization challenges associated with the standard PINN approach, a residual weighting scheme is introduced. This scheme is designed to enhance the tracking of propagating wave fronts by considering the reaction term in the reaction-diffusion equation. Furthermore, a specific network architecture is studied which is tailored for solutions in the form of traveling waves. Lastly, the capacity of PINNs to approximate an entire family of solutions is assessed by incorporating the reaction rate coefficient as an additional input to the network architecture. This modification enables the approximation of the solution across a broad and continuous range of reaction rate coefficients, thus solving a class of reaction-diffusion systems using a single PINN instance. ",
    "url": "https://arxiv.org/abs/2402.08313",
    "authors": [
      "Franz M. Rohrhofer",
      "Stefan Posch",
      "Clemens G\u00f6\u00dfnitzer",
      "Bernhard C. Geiger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08318",
    "title": "Explicit References to Social Values in Fairy Tales: A Comparison  between Three European Cultures",
    "abstract": "The study of social values in fairy tales opens the possibility to learn about the communication of values across space and time. We propose to study the communication of values in fairy tales from Portugal, Italy and Germany using a technique called word embedding with a compass to quantify vocabulary differences and commonalities. We study how these three national traditions of fairy tales differ in their explicit references to values. To do this, we specify a list of value-charged tokens, consider their word stems and analyse the distance between these in a bespoke pre-trained Word2Vec model. We triangulate and critically discuss the validity of the resulting hypotheses emerging from this quantitative model. Our claim is that this is a reusable and reproducible method for the study of the values explicitly referenced in historical corpora. Finally, our preliminary findings hint at a shared cultural understanding and the expression of values such as Benevolence, Conformity, and Universalism across European societies, suggesting the existence of a pan-European cultural memory. ",
    "url": "https://arxiv.org/abs/2402.08318",
    "authors": [
      "Alba Morollon Diaz-Faes",
      "Carla Sofia Ribeiro Murteira",
      "Martin Ruskov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.08321",
    "title": "Exploration by Optimization with Hybrid Regularizers: Logarithmic Regret  with Adversarial Robustness in Partial Monitoring",
    "abstract": "Partial monitoring is a generic framework of online decision-making problems with limited observations. To make decisions from such limited observations, it is necessary to find an appropriate distribution for exploration. Recently, a powerful approach for this purpose, exploration by optimization (ExO), was proposed, which achieves the optimal bounds in adversarial environments with follow-the-regularized-leader for a wide range of online decision-making problems. However, a naive application of ExO in stochastic environments significantly degrades regret bounds. To resolve this problem in locally observable games, we first establish a novel framework and analysis for ExO with a hybrid regularizer. This development allows us to significantly improve the existing regret bounds of best-of-both-worlds (BOBW) algorithms, which achieves nearly optimal bounds both in stochastic and adversarial environments. In particular, we derive a stochastic regret bound of $O(\\sum_{a \\neq a^*} k^2 m^2 \\log T / \\Delta_a)$, where $k$, $m$, and $T$ are the numbers of actions, observations and rounds, $a^*$ is an optimal action, and $\\Delta_a$ is the suboptimality gap for action $a$. This bound is roughly $\\Theta(k^2 \\log T)$ times smaller than existing BOBW bounds. In addition, for globally observable games, we provide a new BOBW algorithm with the first $O(\\log T)$ stochastic bound. ",
    "url": "https://arxiv.org/abs/2402.08321",
    "authors": [
      "Taira Tsuchiya",
      "Shinji Ito",
      "Junya Honda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.08349",
    "title": "Evaluating the Data Model Robustness of Text-to-SQL Systems Based on  Real User Queries",
    "abstract": "Text-to-SQL systems (also known as NL-to-SQL systems) have become an increasingly popular solution for bridging the gap between user capabilities and SQL-based data access. These systems translate user requests in natural language to valid SQL statements for a specific database. Recent Text-to-SQL systems have benefited from the rapid improvement of transformer-based language models. However, while Text-to-SQL systems that incorporate such models continuously reach new high scores on -- often synthetic -- benchmark datasets, a systematic exploration of their robustness towards different data models in a real-world, realistic scenario is notably missing. This paper provides the first in-depth evaluation of the data model robustness of Text-to-SQL systems in practice based on a multi-year international project focused on Text-to-SQL interfaces. Our evaluation is based on a real-world deployment of FootballDB, a system that was deployed over a 9 month period in the context of the FIFA World Cup 2022, during which about 6K natural language questions were asked and executed. All of our data is based on real user questions that were asked live to the system. We manually labeled and translated a subset of these questions for three different data models. For each data model, we explore the performance of representative Text-to-SQL systems and language models. We further quantify the impact of training data size, pre-, and post-processing steps as well as language model inference time. Our comprehensive evaluation sheds light on the design choices of real-world Text-to-SQL systems and their impact on moving from research prototypes to real deployments. Last, we provide a new benchmark dataset to the community, which is the first to enable the evaluation of different data models for the same dataset and is substantially more challenging than most previous datasets in terms of query complexity. ",
    "url": "https://arxiv.org/abs/2402.08349",
    "authors": [
      "Jonathan F\u00fcrst",
      "Catherine Kosten",
      "Farhard Nooralahzadeh",
      "Yi Zhang",
      "Kurt Stockinger"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.08367",
    "title": "RBF-PINN: Non-Fourier Positional Embedding in Physics-Informed Neural  Networks",
    "abstract": "While many recent Physics-Informed Neural Networks (PINNs) variants have had considerable success in solving Partial Differential Equations, the empirical benefits of feature mapping drawn from the broader Neural Representations research have been largely overlooked. We highlight the limitations of widely used Fourier-based feature mapping in certain situations and suggest the use of the conditionally positive definite Radial Basis Function. The empirical findings demonstrate the effectiveness of our approach across a variety of forward and inverse problem cases. Our method can be seamlessly integrated into coordinate-based input neural networks and contribute to the wider field of PINNs research. ",
    "url": "https://arxiv.org/abs/2402.08367",
    "authors": [
      "Chengxi Zeng",
      "Tilo Burghardt",
      "Alberto M Gambaruto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08384",
    "title": "Selective Learning: Towards Robust Calibration with Dynamic  Regularization",
    "abstract": "Miscalibration in deep learning refers to there is a discrepancy between the predicted confidence and performance. This problem usually arises due to the overfitting problem, which is characterized by learning everything presented in the training set, resulting in overconfident predictions during testing. Existing methods typically address overfitting and mitigate the miscalibration by adding a maximum-entropy regularizer to the objective function. The objective can be understood as seeking a model that fits the ground-truth labels by increasing the confidence while also maximizing the entropy of predicted probabilities by decreasing the confidence. However, previous methods lack clear guidance on confidence adjustment, leading to conflicting objectives (increasing but also decreasing confidence). Therefore, we introduce a method called Dynamic Regularization (DReg), which aims to learn what should be learned during training thereby circumventing the confidence adjusting trade-off. At a high level, DReg aims to obtain a more reliable model capable of acknowledging what it knows and does not know. Specifically, DReg effectively fits the labels for in-distribution samples (samples that should be learned) while applying regularization dynamically to samples beyond model capabilities (e.g., outliers), thereby obtaining a robust calibrated model especially on the samples beyond model capabilities. Both theoretical and empirical analyses sufficiently demonstrate the superiority of DReg compared with previous methods. ",
    "url": "https://arxiv.org/abs/2402.08384",
    "authors": [
      "Zongbo Han",
      "Yifeng Yang",
      "Changqing Zhang",
      "Linjun Zhang",
      "Joey Tianyi Zhou",
      "Qinghua Hu",
      "Huaxiu Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08393",
    "title": "NfgTransformer: Equivariant Representation Learning for Normal-form  Games",
    "abstract": "Normal-form games (NFGs) are the fundamental model of strategic interaction. We study their representation using neural networks. We describe the inherent equivariance of NFGs -- any permutation of strategies describes an equivalent game -- as well as the challenges this poses for representation learning. We then propose the NfgTransformer architecture that leverages this equivariance, leading to state-of-the-art performance in a range of game-theoretic tasks including equilibrium-solving, deviation gain estimation and ranking, with a common approach to NFG representation. We show that the resulting model is interpretable and versatile, paving the way towards deep learning systems capable of game-theoretic reasoning when interacting with humans and with each other. ",
    "url": "https://arxiv.org/abs/2402.08393",
    "authors": [
      "Siqi Liu",
      "Luke Marris",
      "Georgios Piliouras",
      "Ian Gemp",
      "Nicolas Heess"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2402.08401",
    "title": "LOSS-GAT: Label Propagation and One-Class Semi-Supervised Graph  Attention Network for Fake News Detection",
    "abstract": "In the era of widespread social networks, the rapid dissemination of fake news has emerged as a significant threat, inflicting detrimental consequences across various dimensions of people's lives. Machine learning and deep learning approaches have been extensively employed for identifying fake news. However, a significant challenge in identifying fake news is the limited availability of labeled news datasets. Therefore, the One-Class Learning (OCL) approach, utilizing only a small set of labeled data from the interest class, can be a suitable approach to address this challenge. On the other hand, representing data as a graph enables access to diverse content and structural information, and label propagation methods on graphs can be effective in predicting node labels. In this paper, we adopt a graph-based model for data representation and introduce a semi-supervised and one-class approach for fake news detection, called LOSS-GAT. Initially, we employ a two-step label propagation algorithm, utilizing Graph Neural Networks (GNNs) as an initial classifier to categorize news into two groups: interest (fake) and non-interest (real). Subsequently, we enhance the graph structure using structural augmentation techniques. Ultimately, we predict the final labels for all unlabeled data using a GNN that induces randomness within the local neighborhood of nodes through the aggregation function. We evaluate our proposed method on five common datasets and compare the results against a set of baseline models, including both OCL and binary labeled models. The results demonstrate that LOSS-GAT achieves a notable improvement, surpassing 10%, with the advantage of utilizing only a limited set of labeled fake news. Noteworthy, LOSS-GAT even outperforms binary labeled models. ",
    "url": "https://arxiv.org/abs/2402.08401",
    "authors": [
      "Batool Lakzaei",
      "Mostafa Haghir Chehreghani",
      "Alireza Bagheri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.08416",
    "title": "Pandora: Jailbreak GPTs by Retrieval Augmented Generation Poisoning",
    "abstract": "Large Language Models~(LLMs) have gained immense popularity and are being increasingly applied in various domains. Consequently, ensuring the security of these models is of paramount importance. Jailbreak attacks, which manipulate LLMs to generate malicious content, are recognized as a significant vulnerability. While existing research has predominantly focused on direct jailbreak attacks on LLMs, there has been limited exploration of indirect methods. The integration of various plugins into LLMs, notably Retrieval Augmented Generation~(RAG), which enables LLMs to incorporate external knowledge bases into their response generation such as GPTs, introduces new avenues for indirect jailbreak attacks. To fill this gap, we investigate indirect jailbreak attacks on LLMs, particularly GPTs, introducing a novel attack vector named Retrieval Augmented Generation Poisoning. This method, Pandora, exploits the synergy between LLMs and RAG through prompt manipulation to generate unexpected responses. Pandora uses maliciously crafted content to influence the RAG process, effectively initiating jailbreak attacks. Our preliminary tests show that Pandora successfully conducts jailbreak attacks in four different scenarios, achieving higher success rates than direct attacks, with 64.3\\% for GPT-3.5 and 34.8\\% for GPT-4. ",
    "url": "https://arxiv.org/abs/2402.08416",
    "authors": [
      "Gelei Deng",
      "Yi Liu",
      "Kailong Wang",
      "Yuekang Li",
      "Tianwei Zhang",
      "Yang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.08423",
    "title": "Vehicle Behavior Prediction by Episodic-Memory Implanted NDT",
    "abstract": "In autonomous driving, predicting the behavior (turning left, stopping, etc.) of target vehicles is crucial for the self-driving vehicle to make safe decisions and avoid accidents. Existing deep learning-based methods have shown excellent and accurate performance, but the black-box nature makes it untrustworthy to apply them in practical use. In this work, we explore the interpretability of behavior prediction of target vehicles by an Episodic Memory implanted Neural Decision Tree (abbrev. eMem-NDT). The structure of eMem-NDT is constructed by hierarchically clustering the text embedding of vehicle behavior descriptions. eMem-NDT is a neural-backed part of a pre-trained deep learning model by changing the soft-max layer of the deep model to eMem-NDT, for grouping and aligning the memory prototypes of the historical vehicle behavior features in training data on a neural decision tree. Each leaf node of eMem-NDT is modeled by a neural network for aligning the behavior memory prototypes. By eMem-NDT, we infer each instance in behavior prediction of vehicles by bottom-up Memory Prototype Matching (MPM) (searching the appropriate leaf node and the links to the root node) and top-down Leaf Link Aggregation (LLA) (obtaining the probability of future behaviors of vehicles for certain instances). We validate eMem-NDT on BLVD and LOKI datasets, and the results show that our model can obtain a superior performance to other methods with clear explainability. The code is available at https://github.com/JWFangit/eMem-NDT. ",
    "url": "https://arxiv.org/abs/2402.08423",
    "authors": [
      "Peining Shen",
      "Jianwu Fang",
      "Hongkai Yu",
      "Jianru Xue"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08424",
    "title": "Conditional Neural Expert Processes for Learning from Demonstration",
    "abstract": "Learning from Demonstration (LfD) is a widely used technique for skill acquisition in robotics. However, demonstrations of the same skill may exhibit significant variances, or learning systems may attempt to acquire different means of the same skill simultaneously, making it challenging to encode these motions into movement primitives. To address these challenges, we propose an LfD framework, namely the Conditional Neural Expert Processes (CNEP), that learns to assign demonstrations from different modes to distinct expert networks utilizing the inherent information within the latent space to match experts with the encoded representations. CNEP does not require supervision on which mode the trajectories belong to. Provided experiments on artificially generated datasets demonstrate the efficacy of CNEP. Furthermore, we compare the performance of CNEP with another LfD framework, namely Conditional Neural Movement Primitives (CNMP), on a range of tasks, including experiments on a real robot. The results reveal enhanced modeling performance for movement primitives, leading to the synthesis of trajectories that more accurately reflect those demonstrated by experts, particularly when the model inputs include intersection points from various trajectories. Additionally, CNEP offers improved interpretability and faster convergence by promoting expert specialization. Furthermore, we show that the CNEP model accomplishes obstacle avoidance tasks with a real manipulator when provided with novel start and destination points, in contrast to the CNMP model, which leads to collisions with the obstacle. ",
    "url": "https://arxiv.org/abs/2402.08424",
    "authors": [
      "Yigit Yildirim",
      "Emre Ugur"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08426",
    "title": "Frequency-aware Graph Signal Processing for Collaborative Filtering",
    "abstract": "Graph Signal Processing (GSP) based recommendation algorithms have recently attracted lots of attention due to its high efficiency. However, these methods failed to consider the importance of various interactions that reflect unique user/item characteristics and failed to utilize user and item high-order neighborhood information to model user preference, thus leading to sub-optimal performance. To address the above issues, we propose a frequency-aware graph signal processing method (FaGSP) for collaborative filtering. Firstly, we design a Cascaded Filter Module, consisting of an ideal high-pass filter and an ideal low-pass filter that work in a successive manner, to capture both unique and common user/item characteristics to more accurately model user preference. Then, we devise a Parallel Filter Module, consisting of two low-pass filters that can easily capture the hierarchy of neighborhood, to fully utilize high-order neighborhood information of users/items for more accurate user preference modeling. Finally, we combine these two modules via a linear model to further improve recommendation accuracy. Extensive experiments on six public datasets demonstrate the superiority of our method from the perspectives of prediction accuracy and training efficiency compared with state-of-the-art GCN-based recommendation methods and GSP-based recommendation methods. ",
    "url": "https://arxiv.org/abs/2402.08426",
    "authors": [
      "Jiafeng Xia",
      "Dongsheng Li",
      "Hansu Gu",
      "Tun Lu",
      "Peng Zhang",
      "Li Shang",
      "Ning Gu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08427",
    "title": "Leveraging Self-Supervised Instance Contrastive Learning for Radar  Object Detection",
    "abstract": "In recent years, driven by the need for safer and more autonomous transport systems, the automotive industry has shifted toward integrating a growing number of Advanced Driver Assistance Systems (ADAS). Among the array of sensors employed for object recognition tasks, radar sensors have emerged as a formidable contender due to their abilities in adverse weather conditions or low-light scenarios and their robustness in maintaining consistent performance across diverse environments. However, the small size of radar datasets and the complexity of the labelling of those data limit the performance of radar object detectors. Driven by the promising results of self-supervised learning in computer vision, this paper presents RiCL, an instance contrastive learning framework to pre-train radar object detectors. We propose to exploit the detection from the radar and the temporal information to pre-train the radar object detection model in a self-supervised way using contrastive learning. We aim to pre-train an object detector's backbone, head and neck to learn with fewer data. Experiments on the CARRADA and the RADDet datasets show the effectiveness of our approach in learning generic representations of objects in range-Doppler maps. Notably, our pre-training strategy allows us to use only 20% of the labelled data to reach a similar mAP@0.5 than a supervised approach using the whole training set. ",
    "url": "https://arxiv.org/abs/2402.08427",
    "authors": [
      "Colin Decourt",
      "Rufin VanRullen",
      "Didier Salle",
      "Thomas Oberlin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08431",
    "title": "Generating Java Methods: An Empirical Assessment of Four AI-Based Code  Assistants",
    "abstract": "AI-based code assistants are promising tools that can facilitate and speed up code development. They exploit machine learning algorithms and natural language processing to interact with developers, suggesting code snippets (e.g., method implementations) that can be incorporated into projects. Recent studies empirically investigated the effectiveness of code assistants using simple exemplary problems (e.g., the re-implementation of well-known algorithms), which fail to capture the spectrum and nature of the tasks actually faced by developers. In this paper, we expand the knowledge in the area by comparatively assessing four popular AI-based code assistants, namely GitHub Copilot, Tabnine, ChatGPT, and Google Bard, with a dataset of 100 methods that we constructed from real-life open-source Java projects, considering a variety of cases for complexity and dependency from contextual elements. Results show that Copilot is often more accurate than other techniques, yet none of the assistants is completely subsumed by the rest of the approaches. Interestingly, the effectiveness of these solutions dramatically decreases when dealing with dependencies outside the boundaries of single classes. ",
    "url": "https://arxiv.org/abs/2402.08431",
    "authors": [
      "Vincenzo Corso",
      "Leonardo Mariani",
      "Daniela Micucci",
      "Oliviero Riganelli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.08441",
    "title": "Latent space configuration for improved generalization in supervised  autoencoder neural networks",
    "abstract": "Autoencoders (AE) are simple yet powerful class of neural networks that compress data by projecting input into low-dimensional latent space (LS). Whereas LS is formed according to the loss function minimization during training, its properties and topology are not controlled directly. In this paper we focus on AE LS properties and propose two methods for obtaining LS with desired topology, called LS configuration. The proposed methods include loss configuration using a geometric loss term that acts directly in LS, and encoder configuration. We show that the former allows to reliably obtain LS with desired configuration by defining the positions and shapes of LS clusters for supervised AE (SAE). Knowing LS configuration allows to define similarity measure in LS to predict labels or estimate similarity for multiple inputs without using decoders or classifiers. We also show that this leads to more stable and interpretable training. We show that SAE trained for clothes texture classification using the proposed method generalizes well to unseen data from LIP, Market1501, and WildTrack datasets without fine-tuning, and even allows to evaluate similarity for unseen classes. We further illustrate the advantages of pre-configured LS similarity estimation with cross-dataset searches and text-based search using a text query without language models. ",
    "url": "https://arxiv.org/abs/2402.08441",
    "authors": [
      "Nikita Gabdullin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08443",
    "title": "Energy-aware Dynamic Resource Allocation in Virtual Sensor Networks",
    "abstract": "Sensor network virtualization enables the possibility of sharing common physical resources to multiple stakeholder applications. This paper focuses on addressing the dynamic adaptation of already assigned virtual sensor network resources to respond to time varying application demands. We propose an optimization framework that dynamically allocate applications into sensor nodes while accounting for the characteristics and limitations of the wireless sensor environment. It takes also into account the additional energy consumption related to activating new nodes and/or moving already active applications. Different objective functions related to the available energy in the nodes are analyzed. The proposed framework is evaluated by simulation considering realistic parameters from actual sensor nodes and deployed applications to assess the efficiency of the proposals. ",
    "url": "https://arxiv.org/abs/2402.08443",
    "authors": [
      "Carmen Delgado",
      "Mar\u00eda Canales",
      "Jorge Ort\u00edn",
      "Jos\u00e9 Ram\u00f3n G\u00e1llego",
      "Alessandro Redondi",
      "Sonda Bousnina",
      "Matteo Cesana"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.08450",
    "title": "Subgraphormer: Unifying Subgraph GNNs and Graph Transformers via Graph  Products",
    "abstract": "In the realm of Graph Neural Networks (GNNs), two exciting research directions have recently emerged: Subgraph GNNs and Graph Transformers. In this paper, we propose an architecture that integrates both approaches, dubbed Subgraphormer, which combines the enhanced expressive power, message-passing mechanisms, and aggregation schemes from Subgraph GNNs with attention and positional encodings, arguably the most important components in Graph Transformers. Our method is based on an intriguing new connection we reveal between Subgraph GNNs and product graphs, suggesting that Subgraph GNNs can be formulated as Message Passing Neural Networks (MPNNs) operating on a product of the graph with itself. We use this formulation to design our architecture: first, we devise an attention mechanism based on the connectivity of the product graph. Following this, we propose a novel and efficient positional encoding scheme for Subgraph GNNs, which we derive as a positional encoding for the product graph. Our experimental results demonstrate significant performance improvements over both Subgraph GNNs and Graph Transformers on a wide range of datasets. ",
    "url": "https://arxiv.org/abs/2402.08450",
    "authors": [
      "Guy Bar-Shalom",
      "Beatrice Bevilacqua",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08462",
    "title": "Indicators for characterising online hate speech and its automatic  detection",
    "abstract": "We examined four case studies in the context of hate speech on Twitter in Italian from 2019 to 2020, aiming at comparing the classification of the 3,600 tweets made by expert pedagogists with the automatic classification made by machine learning algorithms. Pedagogists used a novel classification scheme based on seven indicators that characterize hate. These indicators are: the content is public, it affects a target group, it contains hate speech in explicit verbal form, it will not redeem, it has intention to harm, it can have a possible violent response, it incites hatred and violence. The case studies refer to Jews, Muslims, Roma, and immigrants target groups. We find that not all the types of hateful content are equally detectable by the machine learning algorithms that we considered. In particular, algorithms perform better in identifying tweets that incite hatred and violence, and those that can have possible violent response. ",
    "url": "https://arxiv.org/abs/2402.08462",
    "authors": [
      "Erica Forzinetti",
      "Marco L. Della Vedova",
      "Stefano Pasta",
      "Milena Santerini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.08468",
    "title": "ROSpace: Intrusion Detection Dataset for a ROS2-Based Cyber-Physical  System",
    "abstract": "Most of the intrusion detection datasets to research machine learning-based intrusion detection systems (IDSs) are devoted to cyber-only systems, and they typically collect data from one architectural layer. Additionally, often the attacks are generated in dedicated attack sessions, without reproducing the realistic alternation and overlap of normal and attack actions. We present a dataset for intrusion detection by performing penetration testing on an embedded cyber-physical system built over Robot Operating System 2 (ROS2). Features are monitored from three architectural layers: the Linux operating system, the network, and the ROS2 services. The dataset is structured as a time series and describes the expected behavior of the system and its response to ROS2-specific attacks: it repeatedly alternates periods of attack-free operation with periods when a specific attack is being performed. Noteworthy, this allows measuring the time to detect an attacker and the number of malicious activities performed before detection. Also, it allows training an intrusion detector to minimize both, by taking advantage of the numerous alternating periods of normal and attack operations. ",
    "url": "https://arxiv.org/abs/2402.08468",
    "authors": [
      "Tommaso Puccetti",
      "Simone Nardi",
      "Cosimo Cinquilli",
      "Tommaso Zoppi",
      "Andrea Ceccarelli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08470",
    "title": "Parallel-friendly Spatio-Temporal Graph Learning for Photovoltaic  Degradation Analysis at Scale",
    "abstract": "We propose a novel Spatio-Temporal Graph Neural Network empowered trend analysis approach (ST-GTrend) to perform fleet-level performance degradation analysis for Photovoltaic (PV) power networks. PV power stations have become an integral component to the global sustainable energy production landscape. Accurately estimating the performance of PV systems is critical to their feasibility as a power generation technology and as a financial asset. One of the most challenging problems in assessing the Levelized Cost of Energy (LCOE) of a PV system is to understand and estimate the long-term Performance Loss Rate (PLR) for large fleets of PV inverters. ST-GTrend integrates spatio-temporal coherence and graph attention to separate PLR as a long-term \"aging\" trend from multiple fluctuation terms in the PV input data. To cope with diverse degradation patterns in timeseries, ST-GTrend adopts a paralleled graph autoencoder array to extract aging and fluctuation terms simultaneously. ST-GTrend imposes flatness and smoothness regularization to ensure the disentanglement between aging and fluctuation. To scale the analysis to large PV systems, we also introduce Para-GTrend, a parallel algorithm to accelerate the training and inference of ST-GTrend. We have evaluated ST-GTrend on three large-scale PV datasets, spanning a time period of 10 years. Our results show that ST-GTrend reduces Mean Absolute Percent Error (MAPE) and Euclidean Distances by 34.74% and 33.66% compared to the SOTA methods. Our results demonstrate that Para-GTrend can speed up ST-GTrend by up to 7.92 times. We further verify the generality and effectiveness of ST-GTrend for trend analysis using financial and economic datasets. ",
    "url": "https://arxiv.org/abs/2402.08470",
    "authors": [
      "Yangxin Fan",
      "Raymond Wieser",
      "Laura Bruckman",
      "Roger French",
      "Yinghui Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.08480",
    "title": "Revealing Decurve Flows for Generalized Graph Propagation",
    "abstract": "This study addresses the limitations of the traditional analysis of message-passing, central to graph learning, by defining {\\em \\textbf{generalized propagation}} with directed and weighted graphs. The significance manifest in two ways. \\textbf{Firstly}, we propose {\\em Generalized Propagation Neural Networks} (\\textbf{GPNNs}), a framework that unifies most propagation-based graph neural networks. By generating directed-weighted propagation graphs with adjacency function and connectivity function, GPNNs offer enhanced insights into attention mechanisms across various graph models. We delve into the trade-offs within the design space with empirical experiments and emphasize the crucial role of the adjacency function for model expressivity via theoretical analysis. \\textbf{Secondly}, we propose the {\\em Continuous Unified Ricci Curvature} (\\textbf{CURC}), an extension of celebrated {\\em Ollivier-Ricci Curvature} for directed and weighted graphs. Theoretically, we demonstrate that CURC possesses continuity, scale invariance, and a lower bound connection with the Dirichlet isoperimetric constant validating bottleneck analysis for GPNNs. We include a preliminary exploration of learned propagation patterns in datasets, a first in the field. We observe an intriguing ``{\\em \\textbf{decurve flow}}'' - a curvature reduction during training for models with learnable propagation, revealing the evolution of propagation over time and a deeper connection to over-smoothing and bottleneck trade-off. ",
    "url": "https://arxiv.org/abs/2402.08480",
    "authors": [
      "Chen Lin",
      "Liheng Ma",
      "Yiyang Chen",
      "Wanli Ouyang",
      "Michael M. Bronstein",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ]
  },
  {
    "id": "arXiv:2402.08529",
    "title": "Approximately Piecewise E(3) Equivariant Point Networks",
    "abstract": "Integrating a notion of symmetry into point cloud neural networks is a provably effective way to improve their generalization capability. Of particular interest are $E(3)$ equivariant point cloud networks where Euclidean transformations applied to the inputs are preserved in the outputs. Recent efforts aim to extend networks that are $E(3)$ equivariant, to accommodate inputs made of multiple parts, each of which exhibits local $E(3)$ symmetry. In practical settings, however, the partitioning into individually transforming regions is unknown a priori. Errors in the partition prediction would unavoidably map to errors in respecting the true input symmetry. Past works have proposed different ways to predict the partition, which may exhibit uncontrolled errors in their ability to maintain equivariance to the actual partition. To this end, we introduce APEN: a general framework for constructing approximate piecewise-$E(3)$ equivariant point networks. Our primary insight is that functions that are equivariant with respect to a finer partition will also maintain equivariance in relation to the true partition. Leveraging this observation, we propose a design where the equivariance approximation error at each layers can be bounded solely in terms of (i) uncertainty quantification of the partition prediction, and (ii) bounds on the probability of failing to suggest a proper subpartition of the ground truth one. We demonstrate the effectiveness of APEN using two data types exemplifying part-based symmetry: (i) real-world scans of room scenes containing multiple furniture-type objects; and, (ii) human motions, characterized by articulated parts exhibiting rigid movement. Our empirical results demonstrate the advantage of integrating piecewise $E(3)$ symmetry into network design, showing a distinct improvement in generalization compared to prior works for both classification and segmentation tasks. ",
    "url": "https://arxiv.org/abs/2402.08529",
    "authors": [
      "Matan Atzmon",
      "Jiahui Huang",
      "Francis Williams",
      "Or Litany"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08530",
    "title": "A Distributional Analogue to the Successor Representation",
    "abstract": "This paper contributes a new approach for distributional reinforcement learning which elucidates a clean separation of transition structure and reward in the learning process. Analogous to how the successor representation (SR) describes the expected consequences of behaving according to a given policy, our distributional successor measure (SM) describes the distributional consequences of this behaviour. We formulate the distributional SM as a distribution over distributions and provide theory connecting it with distributional and model-based reinforcement learning. Moreover, we propose an algorithm that learns the distributional SM from data by minimizing a two-level maximum mean discrepancy. Key to our method are a number of algorithmic techniques that are independently valuable for learning generative models of state. As an illustration of the usefulness of the distributional SM, we show that it enables zero-shot risk-sensitive policy evaluation in a way that was not previously possible. ",
    "url": "https://arxiv.org/abs/2402.08530",
    "authors": [
      "Harley Wiltzer",
      "Jesse Farebrother",
      "Arthur Gretton",
      "Yunhao Tang",
      "Andr\u00e9 Barreto",
      "Will Dabney",
      "Marc G. Bellemare",
      "Mark Rowland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.08558",
    "title": "Exploring diversity perceptions in a community through a Q&A chatbot",
    "abstract": "While diversity has become a debated issue in design, very little research exists on positive use-cases for diversity beyond scholarly criticism. The current work addresses this gap through the case of a diversity-aware chatbot, exploring what benefits a diversity-aware chatbot could bring to people and how do people interpret diversity when being presented with it. In this paper, we motivate a Q&A chatbot as a technology probe and deploy it in two student communities within a study. During the study, we collected contextual data on people's expectations and perceptions when presented with diversity during the study. Our key findings show that people seek out others with shared niche interests, or their search is driven by exploration and inspiration when presented with diversity. Although interacting with chatbots is limited, participants found the engagement novel and interesting to motivate future research. ",
    "url": "https://arxiv.org/abs/2402.08558",
    "authors": [
      "Peter Kun",
      "Amalia De G\u00f6tzen",
      "Miriam Bidoglia",
      "Niels J\u00f8rgen Gommesen",
      "George Gaskell"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.08571",
    "title": "Glass Segmentation with Multi Scales and Primary Prediction Guiding",
    "abstract": "Glass-like objects can be seen everywhere in our daily life which are very hard for existing methods to segment them. The properties of transparencies pose great challenges of detecting them from the chaotic background and the vague separation boundaries further impede the acquisition of their exact contours. Moving machines which ignore glasses have great risks of crashing into transparent barriers or difficulties in analysing objects reflected in the mirror, thus it is of substantial significance to accurately locate glass-like objects and completely figure out their contours. In this paper, inspired by the scale integration strategy and the refinement method, we proposed a brand-new network, named as MGNet, which consists of a Fine-Rescaling and Merging module (FRM) to improve the ability to extract spatially relationship and a Primary Prediction Guiding module (PPG) to better mine the leftover semantics from the fused features. Moreover, we supervise the model with a novel loss function with the uncertainty-aware loss to produce high-confidence segmentation maps. Unlike the existing glass segmentation models that must be trained on different settings with respect to varied datasets, our model are trained under consistent settings and has achieved superior performance on three popular public datasets. Code is available at ",
    "url": "https://arxiv.org/abs/2402.08571",
    "authors": [
      "Zhiyu Xu",
      "Qingliang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08577",
    "title": "Test-Time Backdoor Attacks on Multimodal Large Language Models",
    "abstract": "Backdoor attacks are commonly executed by contaminating training data, such that a trigger can activate predetermined harmful effects during the test phase. In this work, we present AnyDoor, a test-time backdoor attack against multimodal large language models (MLLMs), which involves injecting the backdoor into the textual modality using adversarial test images (sharing the same universal perturbation), without requiring access to or modification of the training data. AnyDoor employs similar techniques used in universal adversarial attacks, but distinguishes itself by its ability to decouple the timing of setup and activation of harmful effects. In our experiments, we validate the effectiveness of AnyDoor against popular MLLMs such as LLaVA-1.5, MiniGPT-4, InstructBLIP, and BLIP-2, as well as provide comprehensive ablation studies. Notably, because the backdoor is injected by a universal perturbation, AnyDoor can dynamically change its backdoor trigger prompts/harmful effects, exposing a new challenge for defending against backdoor attacks. Our project page is available at https://sail-sg.github.io/AnyDoor/. ",
    "url": "https://arxiv.org/abs/2402.08577",
    "authors": [
      "Dong Lu",
      "Tianyu Pang",
      "Chao Du",
      "Qian Liu",
      "Xianjun Yang",
      "Min Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.08578",
    "title": "FedLPS: Heterogeneous Federated Learning for Multiple Tasks with Local  Parameter Sharing",
    "abstract": "Federated Learning (FL) has emerged as a promising solution in Edge Computing (EC) environments to process the proliferation of data generated by edge devices. By collaboratively optimizing the global machine learning models on distributed edge devices, FL circumvents the need for transmitting raw data and enhances user privacy. Despite practical successes, FL still confronts significant challenges including constrained edge device resources, multiple tasks deployment, and data heterogeneity. However, existing studies focus on mitigating the FL training costs of each single task whereas neglecting the resource consumption across multiple tasks in heterogeneous FL scenarios. In this paper, we propose Heterogeneous Federated Learning with Local Parameter Sharing (FedLPS) to fill this gap. FedLPS leverages principles from transfer learning to facilitate the deployment of multiple tasks on a single device by dividing the local model into a shareable encoder and task-specific encoders. To further reduce resource consumption, a channel-wise model pruning algorithm that shrinks the footprint of local models while accounting for both data and system heterogeneity is employed in FedLPS. Additionally, a novel heterogeneous model aggregation algorithm is proposed to aggregate the heterogeneous predictors in FedLPS. We implemented the proposed FedLPS on a real FL platform and compared it with state-of-the-art (SOTA) FL frameworks. The experimental results on five popular datasets and two modern DNN models illustrate that the proposed FedLPS significantly outperforms the SOTA FL frameworks by up to 4.88% and reduces the computational resource consumption by 21.3%. Our code is available at:https://github.com/jyzgh/FedLPS. ",
    "url": "https://arxiv.org/abs/2402.08578",
    "authors": [
      "Yongzhe Jia",
      "Xuyun Zhang",
      "Amin Beheshti",
      "Wanchun Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.08583",
    "title": "Mixture of Link Predictors",
    "abstract": "Link prediction, which aims to forecast unseen connections in graphs, is a fundamental task in graph machine learning. Heuristic methods, leveraging a range of different pairwise measures such as common neighbors and shortest paths, often rival the performance of vanilla Graph Neural Networks (GNNs). Therefore, recent advancements in GNNs for link prediction (GNN4LP) have primarily focused on integrating one or a few types of pairwise information. In this work, we reveal that different node pairs within the same dataset necessitate varied pairwise information for accurate prediction and models that only apply the same pairwise information uniformly could achieve suboptimal performance. As a result, we propose a simple mixture of experts model Link-MoE for link prediction. Link-MoE utilizes various GNNs as experts and strategically selects the appropriate expert for each node pair based on various types of pairwise information. Experimental results across diverse real-world datasets demonstrate substantial performance improvement from Link-MoE. Notably, Link-MoE achieves a relative improvement of 18.82\\% on the MRR metric for the Pubmed dataset and 10.8\\% on the Hits@100 metric for the ogbl-ppa dataset, compared to the best baselines. ",
    "url": "https://arxiv.org/abs/2402.08583",
    "authors": [
      "Li Ma",
      "Haoyu Han",
      "Juanhui Li",
      "Harry Shomer",
      "Hui Liu",
      "Xiaofeng Gao",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08586",
    "title": "Faster Repeated Evasion Attacks in Tree Ensembles",
    "abstract": "Tree ensembles are one of the most widely used model classes. However, these models are susceptible to adversarial examples, i.e., slightly perturbed examples that elicit a misprediction. There has been significant research on designing approaches to construct such examples for tree ensembles. But this is a computationally challenging problem that often must be solved a large number of times (e.g., for all examples in a training set). This is compounded by the fact that current approaches attempt to find such examples from scratch. In contrast, we exploit the fact that multiple similar problems are being solved. Specifically, our approach exploits the insight that adversarial examples for tree ensembles tend to perturb a consistent but relatively small set of features. We show that we can quickly identify this set of features and use this knowledge to speedup constructing adversarial examples. ",
    "url": "https://arxiv.org/abs/2402.08586",
    "authors": [
      "Lorenzo Cascioli",
      "Laurens Devos",
      "Ond\u0159ej Ku\u017eelka",
      "Jesse Davis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08593",
    "title": "Graph Feature Preprocessor: Real-time Extraction of Subgraph-based  Features from Transaction Graphs",
    "abstract": "In this paper, we present \"Graph Feature Preprocessor\", a software library for detecting typical money laundering and fraud patterns in financial transaction graphs in real time. These patterns are used to produce a rich set of transaction features for downstream machine learning training and inference tasks such as money laundering detection. We show that our enriched transaction features dramatically improve the prediction accuracy of gradient-boosting-based machine learning models. Our library exploits multicore parallelism, maintains a dynamic in-memory graph, and efficiently mines subgraph patterns in the incoming transaction stream, which enables it to be operated in a streaming manner. We evaluate our library using highly-imbalanced synthetic anti-money laundering (AML) and real-life Ethereum phishing datasets. In these datasets, the proportion of illicit transactions is very small, which makes the learning process challenging. Our solution, which combines our Graph Feature Preprocessor and gradient-boosting-based machine learning models, is able to detect these illicit transactions with higher minority-class F1 scores than standard graph neural networks. In addition, the end-to-end throughput rate of our solution executed on a multicore CPU outperforms the graph neural network baselines executed on a powerful V100 GPU. Overall, the combination of high accuracy, a high throughput rate, and low latency of our solution demonstrates the practical value of our library in real-world applications. Graph Feature Preprocessor has been integrated into IBM mainframe software products, namely \"IBM Cloud Pak for Data on Z\" and \"AI Toolkit for IBM Z and LinuxONE\". ",
    "url": "https://arxiv.org/abs/2402.08593",
    "authors": [
      "Jovan Blanu\u0161a",
      "Maximo Cravero Baraja",
      "Andreea Anghel",
      "Luc von Niederh\u00e4usern",
      "Erik Altman",
      "Haris Pozidis",
      "Kubilay Atasu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08595",
    "title": "Homomorphism Counts for Graph Neural Networks: All About That Basis",
    "abstract": "Graph neural networks are architectures for learning invariant functions over graphs. A large body of work has investigated the properties of graph neural networks and identified several limitations, particularly pertaining to their expressive power. Their inability to count certain patterns (e.g., cycles) in a graph lies at the heart of such limitations, since many functions to be learned rely on the ability of counting such patterns. Two prominent paradigms aim to address this limitation by enriching the graph features with subgraph or homomorphism pattern counts. In this work, we show that both of these approaches are sub-optimal in a certain sense and argue for a more fine-grained approach, which incorporates the homomorphism counts of all structures in the \"basis\" of the target pattern. This yields strictly more expressive architectures without incurring any additional overhead in terms of computational complexity compared to existing approaches. We prove a series of theoretical results on node-level and graph-level motif parameters and empirically validate them on standard benchmark datasets. ",
    "url": "https://arxiv.org/abs/2402.08595",
    "authors": [
      "Emily Jin",
      "Michael Bronstein",
      "Ismail Ilkan Ceylan",
      "Matthias Lanzinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08607",
    "title": "A robust second-order low-rank BUG integrator based on the midpoint rule",
    "abstract": "Dynamical low-rank approximation has become a valuable tool to perform an on-the-fly model order reduction for prohibitively large matrix differential equations. A core ingredient is the construction of integrators that are robust to the presence of small singular values and the resulting large time derivatives of the orthogonal factors in the low-rank matrix representation. Recently, the robust basis-update & Galerkin (BUG) class of integrators has been introduced. These methods require no steps that evolve the solution backward in time, often have favourable structure-preserving properties, and allow for parallel time-updates of the low-rank factors. The BUG framework is flexible enough to allow for adaptations to these and further requirements. However, the BUG methods presented so far have only first-order robust error bounds. This work proposes a second-order BUG integrator for dynamical low-rank approximation based on the midpoint rule. The integrator first performs a half-step with a first-order BUG integrator, followed by a Galerkin update with a suitably augmented basis. We prove a robust second-order error bound which in addition shows an improved dependence on the normal component of the vector field. These rigorous results are illustrated and complemented by a number of numerical experiments. ",
    "url": "https://arxiv.org/abs/2402.08607",
    "authors": [
      "Gianluca Ceruti",
      "Lukas Einkemmer",
      "Jonas Kusch",
      "Christian Lubich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.08640",
    "title": "Forecasting high-impact research topics via machine learning on evolving  knowledge graphs",
    "abstract": "The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to predict the impact of new ideas will be a crucial component of future artificial muses that can inspire new impactful and interesting scientific ideas. ",
    "url": "https://arxiv.org/abs/2402.08640",
    "authors": [
      "Xuemei Gu",
      "Mario Krenn"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08648",
    "title": "Generating Universal Adversarial Perturbations for Quantum Classifiers",
    "abstract": "Quantum Machine Learning (QML) has emerged as a promising field of research, aiming to leverage the capabilities of quantum computing to enhance existing machine learning methodologies. Recent studies have revealed that, like their classical counterparts, QML models based on Parametrized Quantum Circuits (PQCs) are also vulnerable to adversarial attacks. Moreover, the existence of Universal Adversarial Perturbations (UAPs) in the quantum domain has been demonstrated theoretically in the context of quantum classifiers. In this work, we introduce QuGAP: a novel framework for generating UAPs for quantum classifiers. We conceptualize the notion of additive UAPs for PQC-based classifiers and theoretically demonstrate their existence. We then utilize generative models (QuGAP-A) to craft additive UAPs and experimentally show that quantum classifiers are susceptible to such attacks. Moreover, we formulate a new method for generating unitary UAPs (QuGAP-U) using quantum generative models and a novel loss function based on fidelity constraints. We evaluate the performance of the proposed framework and show that our method achieves state-of-the-art misclassification rates, while maintaining high fidelity between legitimate and adversarial samples. ",
    "url": "https://arxiv.org/abs/2402.08648",
    "authors": [
      "Gautham Anil",
      "Vishnu Vinod",
      "Apurva Narayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08653",
    "title": "SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds",
    "abstract": "Modern graph neural networks (GNNs) can be sensitive to changes in the input graph structure and node features, potentially resulting in unpredictable behavior and degraded performance. In this work, we introduce a spectral framework known as SAGMAN for examining the stability of GNNs. This framework assesses the distance distortions that arise from the nonlinear mappings of GNNs between the input and output manifolds: when two nearby nodes on the input manifold are mapped (through a GNN model) to two distant ones on the output manifold, it implies a large distance distortion and thus a poor GNN stability. We propose a distance-preserving graph dimension reduction (GDR) approach that utilizes spectral graph embedding and probabilistic graphical models (PGMs) to create low-dimensional input/output graph-based manifolds for meaningful stability analysis. Our empirical evaluations show that SAGMAN effectively assesses the stability of each node when subjected to various edge or feature perturbations, offering a scalable approach for evaluating the stability of GNNs, extending to applications within recommendation systems. Furthermore, we illustrate its utility in downstream tasks, notably in enhancing GNN stability and facilitating adversarial targeted attacks. ",
    "url": "https://arxiv.org/abs/2402.08653",
    "authors": [
      "Wuxinlin Cheng",
      "Chenhui Deng",
      "Ali Aghdaei",
      "Zhiru Zhang",
      "Zhuo Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.08655",
    "title": "Assessing the Privacy Risk of Cross-Platform Identity Linkage using Eye  Movement Biometrics",
    "abstract": "The recent emergence of ubiquitous, multi-platform eye tracking has raised user privacy concerns over re-identification across platforms, where a person is re-identified across multiple eye tracking-enabled platforms using personally identifying information that is implicitly expressed through their eye movement. We present an empirical investigation quantifying a modern eye movement biometric model's ability to link subject identities across three different eye tracking devices using eye movement signals from each device. We show that a state-of-the art eye movement biometrics model demonstrates above-chance levels of biometric performance (34.99% equal error rate, 15% rank-1 identification rate) when linking user identities across one pair of devices, but not for the other. Considering these findings, we also discuss the impact that eye tracking signal quality has on the model's ability to meaningfully associate a subject's identity between two substantially different eye tracking devices. Our investigation advances a fundamental understanding of the privacy risks for identity linkage across platforms by employing both quantitative and qualitative measures of biometric performance, including a visualization of the model's ability to distinguish genuine and imposter authentication attempts across platforms. ",
    "url": "https://arxiv.org/abs/2402.08655",
    "authors": [
      "Samantha Aziz",
      "Oleg Komogortsev"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.08674",
    "title": "Human Curriculum Effects Emerge with In-Context Learning in Neural  Networks",
    "abstract": "Human learning is sensitive to rule-like structure and the curriculum of examples used for training. In tasks governed by succinct rules, learning is more robust when related examples are blocked across trials, but in the absence of such rules, interleaving is more effective. To date, no neural model has simultaneously captured these seemingly contradictory effects. Here we show that this same tradeoff spontaneously emerges with \"in-context learning\" (ICL) both in neural networks trained with metalearning and in large language models (LLMs). ICL is the ability to learn new tasks \"in context\" - without weight changes - via an inner-loop algorithm implemented in activation dynamics. Experiments with pretrained LLMs and metalearning transformers show that ICL exhibits the blocking advantage demonstrated in humans on a task involving rule-like structure, and conversely, that concurrent in-weight learning reproduces the interleaving advantage observed in humans on tasks lacking such structure. ",
    "url": "https://arxiv.org/abs/2402.08674",
    "authors": [
      "Jacob Russin",
      "Ellie Pavlick",
      "Michael J. Frank"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2402.08678",
    "title": "Graph Mamba: Towards Learning on Graphs with State Space Models",
    "abstract": "Graph Neural Networks (GNNs) have shown promising potential in graph representation learning. The majority of GNNs define a local message-passing mechanism, propagating information over the graph by stacking multiple layers. These methods, however, are known to suffer from two major limitations: over-squashing and poor capturing of long-range dependencies. Recently, Graph Transformers (GTs) emerged as a powerful alternative to Message-Passing Neural Networks (MPNNs). GTs, however, have quadratic computational cost, lack inductive biases on graph structures, and rely on complex Positional/Structural Encodings (SE/PE). In this paper, we show that while Transformers, complex message-passing, and SE/PE are sufficient for good performance in practice, neither is necessary. Motivated by the recent success of State Space Models (SSMs), such as Mamba, we present Graph Mamba Networks (GMNs), a general framework for a new class of GNNs based on selective SSMs. We discuss and categorize the new challenges when adopting SSMs to graph-structured data, and present four required and one optional steps to design GMNs, where we choose (1) Neighborhood Tokenization, (2) Token Ordering, (3) Architecture of Bidirectional Selective SSM Encoder, (4) Local Encoding, and dispensable (5) PE and SE. We further provide theoretical justification for the power of GMNs. Experiments demonstrate that despite much less computational cost, GMNs attain an outstanding performance in long-range, small-scale, large-scale, and heterophilic benchmark datasets. ",
    "url": "https://arxiv.org/abs/2402.08678",
    "authors": [
      "Ali Behrouz",
      "Farnoosh Hashemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07948",
    "title": "evolSOM: an R Package for evolutionary conservation analysis with SOMs",
    "abstract": "Motivation: Unraveling the connection between genes and traits is crucial for solving many biological puzzles. Genes provide instructions for building cellular machinery, directing the processes that sustain life. RNA molecules and proteins, derived from these genetic instructions, play crucial roles in shaping cell structures, influencing reactions, and guiding behavior. This fundamental biological principle links genetic makeup to observable traits, but integrating and extracting meaningful relationships from this complex, multimodal data presents a significant challenge. Results: We introduce evolSOM, a novel R package that utilizes Self-Organizing Maps (SOMs) to explore and visualize the conservation of biological variables, easing the integration of phenotypic and genotypic attributes. By constructing species-specific or condition-specific SOMs that capture non-redundant patterns, evolSOM allows the analysis of displacement of biological variables between species or conditions. Variables displaced together suggest membership in the same regulatory network, and the nature of the displacement may hold biological significance. The package automatically calculates and graphically presents these displacements, enabling efficient comparison and revealing conserved and displaced variables. The package facilitates the integration of diverse phenotypic data types, enabling the exploration of potential gene drivers underlying observed phenotypic changes. Its user-friendly interface and visualization capabilities enhance the accessibility of complex network analyses. Illustratively, we employed evolSOM to study the displacement of genes and phenotypic traits, successfully identifying potential drivers of phenotypic differentiation in grass leaves. Availability: The package is open-source and is available at https://github.com/sanprochetto/evolSOM. ",
    "url": "https://arxiv.org/abs/2402.07948",
    "authors": [
      "Santiago Prochetto",
      "Renata Reinheimer",
      "Georgina Stegmayer"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2402.07975",
    "title": "Computational complexity of isometric tensor network states",
    "abstract": "We determine the computational power of isometric tensor network states (isoTNS), a variational ansatz originally developed to numerically find and compute properties of gapped ground states and topological states in two dimensions. By mapping 2D isoTNS to 1+1D unitary quantum circuits, we find that computing local expectation values in isoTNS is $\\textsf{BQP}$-complete. We then introduce injective isoTNS, which are those isoTNS that are the unique ground states of frustration-free Hamiltonians, and which are characterized by an injectivity parameter $\\delta\\in(0,1/D]$, where $D$ is the bond dimension of the isoTNS. We show that injectivity necessarily adds depolarizing noise to the circuit at a rate $\\eta=\\delta^2D^2$. We show that weakly injective isoTNS (small $\\delta$) are still $\\textsf{BQP}$-complete, but that there exists an efficient classical algorithm to compute local expectation values in strongly injective isoTNS ($\\eta\\geq0.41$). Sampling from isoTNS corresponds to monitored quantum dynamics and we exhibit a family of isoTNS that undergo a phase transition from a hard regime to an easy phase where the monitored circuit can be sampled efficiently. Our results can be used to design provable algorithms to contract isoTNS. Our mapping between ground states of certain frustration-free Hamiltonians to open circuit dynamics in one dimension fewer may be of independent interest. ",
    "url": "https://arxiv.org/abs/2402.07975",
    "authors": [
      "Daniel Malz",
      "Rahul Trivedi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2402.08098",
    "title": "Automated Classification of Body MRI Sequence Type Using Convolutional  Neural Networks",
    "abstract": "Multi-parametric MRI of the body is routinely acquired for the identification of abnormalities and diagnosis of diseases. However, a standard naming convention for the MRI protocols and associated sequences does not exist due to wide variations in imaging practice at institutions and myriad MRI scanners from various manufacturers being used for imaging. The intensity distributions of MRI sequences differ widely as a result, and there also exists information conflicts related to the sequence type in the DICOM headers. At present, clinician oversight is necessary to ensure that the correct sequence is being read and used for diagnosis. This poses a challenge when specific series need to be considered for building a cohort for a large clinical study or for developing AI algorithms. In order to reduce clinician oversight and ensure the validity of the DICOM headers, we propose an automated method to classify the 3D MRI sequence acquired at the levels of the chest, abdomen, and pelvis. In our pilot work, our 3D DenseNet-121 model achieved an F1 score of 99.5% at differentiating 5 common MRI sequences obtained by three Siemens scanners (Aera, Verio, Biograph mMR). To the best of our knowledge, we are the first to develop an automated method for the 3D classification of MRI sequences in the chest, abdomen, and pelvis, and our work has outperformed the previous state-of-the-art MRI series classifiers. ",
    "url": "https://arxiv.org/abs/2402.08098",
    "authors": [
      "Kimberly Helm",
      "Tejas Sudharshan Mathai",
      "Boah Kim",
      "Pritam Mukherjee",
      "Jianfei Liu",
      "Ronald M. Summers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08198",
    "title": "PSC-CPI: Multi-Scale Protein Sequence-Structure Contrasting for  Efficient and Generalizable Compound-Protein Interaction Prediction",
    "abstract": "Compound-Protein Interaction (CPI) prediction aims to predict the pattern and strength of compound-protein interactions for rational drug discovery. Existing deep learning-based methods utilize only the single modality of protein sequences or structures and lack the co-modeling of the joint distribution of the two modalities, which may lead to significant performance drops in complex real-world scenarios due to various factors, e.g., modality missing and domain shifting. More importantly, these methods only model protein sequences and structures at a single fixed scale, neglecting more fine-grained multi-scale information, such as those embedded in key protein fragments. In this paper, we propose a novel multi-scale Protein Sequence-structure Contrasting framework for CPI prediction (PSC-CPI), which captures the dependencies between protein sequences and structures through both intra-modality and cross-modality contrasting. We further apply length-variable protein augmentation to allow contrasting to be performed at different scales, from the amino acid level to the sequence level. Finally, in order to more fairly evaluate the model generalizability, we split the test data into four settings based on whether compounds and proteins have been observed during the training stage. Extensive experiments have shown that PSC-CPI generalizes well in all four settings, particularly in the more challenging ``Unseen-Both\" setting, where neither compounds nor proteins have been observed during training. Furthermore, even when encountering a situation of modality missing, i.e., inference with only single-modality protein data, PSC-CPI still exhibits comparable or even better performance than previous approaches. ",
    "url": "https://arxiv.org/abs/2402.08198",
    "authors": [
      "Lirong Wu",
      "Yufei Huang",
      "Cheng Tan",
      "Zhangyang Gao",
      "Bozhen Hu",
      "Haitao Lin",
      "Zicheng Liu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08220",
    "title": "Computing Threshold Circuits with Void Reactions in Step Chemical  Reaction Networks",
    "abstract": "We introduce a new model of \\emph{step} Chemical Reaction Networks (step CRNs), motivated by the step-wise addition of materials in standard lab procedures. Step CRNs have ordered reactants that transform into products via reaction rules over a series of steps. We study an important subset of weak reaction rules, \\emph{void} rules, in which chemical species may only be deleted but never changed. We demonstrate the capabilities of these simple limited systems to simulate threshold circuits and compute functions using various configurations of rule sizes and step constructions, and prove that without steps, void rules are incapable of these computations, which further motivates the step model. Additionally, we prove the coNP-completeness of verifying if a given step CRN computes a function, holding even for $O(1)$ step systems. ",
    "url": "https://arxiv.org/abs/2402.08220",
    "authors": [
      "Rachel Anderson",
      "Alberto Avila",
      "Bin Fu",
      "Timothy Gomez",
      "Elise Grizzell",
      "Aiden Massie",
      "Gourab Mukhopadhyay",
      "Adrian Salinas",
      "Robert Schweller",
      "Evan Tomai",
      "Tim Wylie"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2402.08223",
    "title": "The Limits of Price Discrimination Under Privacy Constraints",
    "abstract": "We consider a producer's problem of selling a product to a continuum of privacy-conscious consumers, where the producer can implement third-degree price discrimination, offering different prices to different market segments. In the absence of privacy constraints, Bergemann, Brooks, and Morris [2015] characterize the set of all possible consumer-producer utilities, showing that it is a triangle. We consider a privacy mechanism that provides a degree of protection by probabilistically masking each market segment, and we establish that the resultant set of all consumer-producer utilities forms a convex polygon, characterized explicitly as a linear mapping of a certain high-dimensional convex polytope into $\\mathbb{R}^2$. This characterization enables us to investigate the impact of the privacy mechanism on both producer and consumer utilities. In particular, we establish that the privacy constraint always hurts the producer by reducing both the maximum and minimum utility achievable. From the consumer's perspective, although the privacy mechanism ensures an increase in the minimum utility compared to the non-private scenario, interestingly, it may reduce the maximum utility. Finally, we demonstrate that increasing the privacy level does not necessarily intensify these effects. For instance, the maximum utility for the producer or the minimum utility for the consumer may exhibit nonmonotonic behavior in response to an increase of the privacy level. ",
    "url": "https://arxiv.org/abs/2402.08223",
    "authors": [
      "Alireza Fallah",
      "Michael I. Jordan",
      "Ali Makhdoumi",
      "Azarakhsh Malekian"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2402.08312",
    "title": "Channel-Combination Algorithms for Robust Distant Voice Activity and  Overlapped Speech Detection",
    "abstract": "Voice Activity Detection (VAD) and Overlapped Speech Detection (OSD) are key pre-processing tasks for speaker diarization. In the meeting context, it is often easier to capture speech with a distant device. This consideration however leads to severe performance degradation. We study a unified supervised learning framework to solve distant multi-microphone joint VAD and OSD (VAD+OSD). This paper investigates various multi-channel VAD+OSD front-ends that weight and combine incoming channels. We propose three algorithms based on the Self-Attention Channel Combinator (SACC), previously proposed in the literature. Experiments conducted on the AMI meeting corpus exhibit that channel combination approaches bring significant VAD+OSD improvements in the distant speech scenario. Specifically, we explore the use of learned complex combination weights and demonstrate the benefits of such an approach in terms of explainability. Channel combination-based VAD+OSD systems are evaluated on the final back-end task, i.e. speaker diarization, and show significant improvements. Finally, since multi-channel systems are trained given a fixed array configuration, they may fail in generalizing to other array set-ups, e.g. mismatched number of microphones. A channel-number invariant loss is proposed to learn a unique feature representation regardless of the number of available microphones. The evaluation conducted on mismatched array configurations highlights the robustness of this training strategy. ",
    "url": "https://arxiv.org/abs/2402.08312",
    "authors": [
      "Th\u00e9o Mariotte",
      "Anthony Larcher",
      "Silvio Montr\u00e9sor",
      "Jean-Hugh Thomas"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.08399",
    "title": "Deep Learning-based Real-time Smartphone Pose Detection for  Ultra-wideband Tagless Gate",
    "abstract": "As commercial interest in proximity services increased, the development of various wireless localization techniques was promoted. In line with this trend, Ultra-wideband (UWB) is emerging as a promising solution that can realize proximity services thanks to centimeter-level localization accuracy. In addition, since the actual location of the mobile device (MD) on the human body, called pose, affects the localization accuracy, poses are also important to provide accurate proximity services, especially for the UWB tagless gate (UTG). In this paper, a real-time pose detector, termed D3, is proposed to estimate the pose of MD when users pass through UTG. D3 is based on line-of-sight (LOS) and non-LOS (NLOS) classification using UWB channel impulse response and utilizes the inertial measurement unit embedded in the smartphone to estimate the pose. D3 is implemented on Samsung Galaxy Note20 Ultra (i.e., SMN986B) and Qorvo UWB board to show the feasibility and applicability. D3 achieved an LOS/NLOS classification accuracy of 0.984, and ultimately detected four different poses of MD with an accuracy of 0.961 in real-time. ",
    "url": "https://arxiv.org/abs/2402.08399",
    "authors": [
      "Junyoung Choi",
      "Sagnik Bhattacharya"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.08412",
    "title": "Interacting Particle Systems on Networks: joint inference of the network  and the interaction kernel",
    "abstract": "Modeling multi-agent systems on networks is a fundamental challenge in a wide variety of disciplines. We jointly infer the weight matrix of the network and the interaction kernel, which determine respectively which agents interact with which others and the rules of such interactions from data consisting of multiple trajectories. The estimator we propose leads naturally to a non-convex optimization problem, and we investigate two approaches for its solution: one is based on the alternating least squares (ALS) algorithm; another is based on a new algorithm named operator regression with alternating least squares (ORALS). Both algorithms are scalable to large ensembles of data trajectories. We establish coercivity conditions guaranteeing identifiability and well-posedness. The ALS algorithm appears statistically efficient and robust even in the small data regime but lacks performance and convergence guarantees. The ORALS estimator is consistent and asymptotically normal under a coercivity condition. We conduct several numerical experiments ranging from Kuramoto particle systems on networks to opinion dynamics in leader-follower models. ",
    "url": "https://arxiv.org/abs/2402.08412",
    "authors": [
      "Quanjun Lang",
      "Xiong Wang",
      "Fei Lu",
      "Mauro Maggioni"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2402.08508",
    "title": "A PAC-Bayesian Link Between Generalisation and Flat Minima",
    "abstract": "Modern machine learning usually involves predictors in the overparametrised setting (number of trained parameters greater than dataset size), and their training yield not only good performances on training data, but also good generalisation capacity. This phenomenon challenges many theoretical results, and remains an open problem. To reach a better understanding, we provide novel generalisation bounds involving gradient terms. To do so, we combine the PAC-Bayes toolbox with Poincar\\'e and Log-Sobolev inequalities, avoiding an explicit dependency on dimension of the predictor space. Our results highlight the positive influence of \\emph{flat minima} (being minima with a neighbourhood nearly minimising the learning problem as well) on generalisation performances, involving directly the benefits of the optimisation phase. ",
    "url": "https://arxiv.org/abs/2402.08508",
    "authors": [
      "Maxime Haddouche",
      "Paul Viallard",
      "Umut Simsekli",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08592",
    "title": "Convolutional Neural Networks Towards Facial Skin Lesions Detection",
    "abstract": "Facial analysis has emerged as a prominent area of research with diverse applications, including cosmetic surgery programs, the beauty industry, photography, and entertainment. Manipulating patient images often necessitates professional image processing software. This study contributes by providing a model that facilitates the detection of blemishes and skin lesions on facial images through a convolutional neural network and machine learning approach. The proposed method offers advantages such as simple architecture, speed and suitability for image processing while avoiding the complexities associated with traditional methods. The model comprises four main steps: area selection, scanning the chosen region, lesion diagnosis, and marking the identified lesion. Raw data for this research were collected from a reputable clinic in Tehran specializing in skincare and beauty services. The dataset includes administrative information, clinical data, and facial and profile images. A total of 2300 patient images were extracted from this raw data. A software tool was developed to crop and label lesions, with input from two treatment experts. In the lesion preparation phase, the selected area was standardized to 50 * 50 pixels. Subsequently, a convolutional neural network model was employed for lesion labeling. The classification model demonstrated high accuracy, with a measure of 0.98 for healthy skin and 0.97 for lesioned skin specificity. Internal validation involved performance indicators and cross-validation, while external validation compared the model's performance indicators with those of the transfer learning method using the Vgg16 deep network model. Compared to existing studies, the results of this research showcase the efficacy and desirability of the proposed model and methodology. ",
    "url": "https://arxiv.org/abs/2402.08592",
    "authors": [
      "Reza Sarshar",
      "Mohammad Heydari",
      "Elham Akhondzadeh Noughabi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08616",
    "title": "Adjustment Identification Distance: A gadjid for Causal Structure  Learning",
    "abstract": "Evaluating graphs learned by causal discovery algorithms is difficult: The number of edges that differ between two graphs does not reflect how the graphs differ with respect to the identifying formulas they suggest for causal effects. We introduce a framework for developing causal distances between graphs which includes the structural intervention distance for directed acyclic graphs as a special case. We use this framework to develop improved adjustment-based distances as well as extensions to completed partially directed acyclic graphs and causal orders. We develop polynomial-time reachability algorithms to compute the distances efficiently. In our package gadjid (open source at https://github.com/CausalDisco/gadjid), we provide implementations of our distances; they are orders of magnitude faster than the structural intervention distance and thereby provide a success metric for causal discovery that scales to graph sizes that were previously prohibitive. ",
    "url": "https://arxiv.org/abs/2402.08616",
    "authors": [
      "Leonard Henckel",
      "Theo W\u00fcrtzen",
      "Sebastian Weichwald"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:1807.11110",
    "title": "ROPNN: Detection of ROP Payloads Using Deep Neural Networks",
    "abstract": " Title: ROPNN: Detection of ROP Payloads Using Deep Neural Networks ",
    "url": "https://arxiv.org/abs/1807.11110",
    "authors": [
      "Xusheng Li",
      "Zhisheng Hu",
      "Haizhou Wang",
      "Yiwei Fu",
      "Ping Chen",
      "Minghui Zhu",
      "Peng Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2002.03339",
    "title": "Input Validation for Neural Networks via Runtime Local Robustness  Verification",
    "abstract": " Title: Input Validation for Neural Networks via Runtime Local Robustness  Verification ",
    "url": "https://arxiv.org/abs/2002.03339",
    "authors": [
      "Jiangchao Liu",
      "Liqian Chen",
      "Antoine Mine",
      "Ji Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.04567",
    "title": "Robust and Dexterous Dual-arm Tele-Cooperation using Adaptable Impedance  Control",
    "abstract": " Title: Robust and Dexterous Dual-arm Tele-Cooperation using Adaptable Impedance  Control ",
    "url": "https://arxiv.org/abs/2108.04567",
    "authors": [
      "Keyhan Kouhkiloui Babarahmati",
      "Mohammadreza Kasaei",
      "Carlo Tiseo",
      "Michael Mistry",
      "Sethu Vijayakumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2112.08217",
    "title": "Probabilistic Forecasting with Generative Networks via Scoring Rule  Minimization",
    "abstract": " Title: Probabilistic Forecasting with Generative Networks via Scoring Rule  Minimization ",
    "url": "https://arxiv.org/abs/2112.08217",
    "authors": [
      "Lorenzo Pacchiardi",
      "Rilwan Adewoyin",
      "Peter Dueben",
      "Ritabrata Dutta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10677",
    "title": "List homomorphisms by deleting edges and vertices: tight complexity  bounds for bounded-treewidth graphs",
    "abstract": " Title: List homomorphisms by deleting edges and vertices: tight complexity  bounds for bounded-treewidth graphs ",
    "url": "https://arxiv.org/abs/2210.10677",
    "authors": [
      "Bar\u0131\u015f Can Esmer",
      "Jacob Focke",
      "D\u00e1niel Marx",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.03180",
    "title": "Subset verification and search algorithms for causal DAGs",
    "abstract": " Comments: Accepted into AISTATS 2023 (this https URL) ",
    "url": "https://arxiv.org/abs/2301.03180",
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.05352",
    "title": "Concentration in Gossip Opinion Dynamics over Random Graphs",
    "abstract": " Title: Concentration in Gossip Opinion Dynamics over Random Graphs ",
    "url": "https://arxiv.org/abs/2301.05352",
    "authors": [
      "Yu Xing",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.11223",
    "title": "Monocular Cyclist Detection with Convolutional Neural Networks",
    "abstract": " Comments: 9 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2303.11223",
    "authors": [
      "Charles Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.11793",
    "title": "Bridging Optimal Transport and Jacobian Regularization by Optimal  Trajectory for Enhanced Adversarial Defense",
    "abstract": " Title: Bridging Optimal Transport and Jacobian Regularization by Optimal  Trajectory for Enhanced Adversarial Defense ",
    "url": "https://arxiv.org/abs/2303.11793",
    "authors": [
      "Binh M. Le",
      "Shahroz Tariq",
      "Simon S. Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.08242",
    "title": "The Deep Latent Position Topic Model for Clustering and Representation  of Networks with Textual Edges",
    "abstract": " Comments: 29 pages including the appendix, 13 figures, 6 tables, journal paper ",
    "url": "https://arxiv.org/abs/2304.08242",
    "authors": [
      "R\u00e9mi Boutin",
      "Pierre Latouche",
      "Charles Bouveyron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.12138",
    "title": "LMs: Understanding Code Syntax and Semantics for Code Analysis",
    "abstract": " Title: LMs: Understanding Code Syntax and Semantics for Code Analysis ",
    "url": "https://arxiv.org/abs/2305.12138",
    "authors": [
      "Wei Ma",
      "Shangqing Liu",
      "Zhihao Lin",
      "Wenhan Wang",
      "Qiang Hu",
      "Ye Liu",
      "Cen Zhang",
      "Liming Nie",
      "Li Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12179",
    "title": "Commodity-specific triads in the Dutch inter-industry production network",
    "abstract": " Comments: 20 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2305.12179",
    "authors": [
      "Marzio Di Vece",
      "Frank P. Pijpers",
      "Diego Garlaschelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Theory (cs.IT)",
      "General Economics (econ.GN)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.18797",
    "title": "Learning Weakly Supervised Audio-Visual Violence Detection in Hyperbolic  Space",
    "abstract": " Comments: 11 pages, 12 figures, typos are fixed ",
    "url": "https://arxiv.org/abs/2305.18797",
    "authors": [
      "Xiaogang Peng",
      "Hao Wen",
      "Yikai Luo",
      "Xiao Zhou",
      "Keyang Yu",
      "Ping Yang",
      "Zizhao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06064",
    "title": "Neural Algorithmic Reasoning for Combinatorial Optimisation",
    "abstract": " Title: Neural Algorithmic Reasoning for Combinatorial Optimisation ",
    "url": "https://arxiv.org/abs/2306.06064",
    "authors": [
      "Dobrik Georgiev",
      "Danilo Numeroso",
      "Davide Bacciu",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06123",
    "title": "Adversarial attacks and defenses in explainable artificial intelligence:  A survey",
    "abstract": " Comments: Accepted by Information Fusion ",
    "url": "https://arxiv.org/abs/2306.06123",
    "authors": [
      "Hubert Baniecki",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.12510",
    "title": "Comparative Analysis of Segment Anything Model and U-Net for Breast  Tumor Detection in Ultrasound and Mammography Images",
    "abstract": " Title: Comparative Analysis of Segment Anything Model and U-Net for Breast  Tumor Detection in Ultrasound and Mammography Images ",
    "url": "https://arxiv.org/abs/2306.12510",
    "authors": [
      "Mohsen Ahmadi",
      "Masoumeh Farhadi Nia",
      "Sara Asgarian",
      "Kasra Danesh",
      "Elyas Irankhah",
      "Ahmad Gholizadeh Lonbar",
      "Abbas Sharifi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.06299",
    "title": "Towards a Certified Proof Checker for Deep Neural Network Verification",
    "abstract": " Comments: This is a preprint version of the paper that appeared at LOPSTR 2023 ",
    "url": "https://arxiv.org/abs/2307.06299",
    "authors": [
      "Remi Desmartin",
      "Omri Isac",
      "Grant Passmore",
      "Kathrin Stark",
      "Guy Katz",
      "Ekaterina Komendantskaya"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2307.06887",
    "title": "Provable Multi-Task Representation Learning by Two-Layer ReLU Neural  Networks",
    "abstract": " Title: Provable Multi-Task Representation Learning by Two-Layer ReLU Neural  Networks ",
    "url": "https://arxiv.org/abs/2307.06887",
    "authors": [
      "Liam Collins",
      "Hamed Hassani",
      "Mahdi Soltanolkotabi",
      "Aryan Mokhtari",
      "Sanjay Shakkottai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08433",
    "title": "From random-walks to graph-sprints: a low-latency node embedding  framework on continuous-time dynamic graphs",
    "abstract": " Comments: 9 pages, 5 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2307.08433",
    "authors": [
      "Ahmad Naser Eddin",
      "Jacopo Bono",
      "David Apar\u00edcio",
      "Hugo Ferreira",
      "Jo\u00e3o Ascens\u00e3o",
      "Pedro Ribeiro",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01037",
    "title": "A Fast Monte Carlo algorithm for evaluating matrix functions with  application in complex networks",
    "abstract": " Comments: Submitted to the Journal of Scientific Computing ",
    "url": "https://arxiv.org/abs/2308.01037",
    "authors": [
      "Nicolas L. Guidotti",
      "Juan A. Acebr\u00f3n",
      "Jos\u00e9 Monteiro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.08426",
    "title": "Differentiable Robust Model Predictive Control",
    "abstract": " Title: Differentiable Robust Model Predictive Control ",
    "url": "https://arxiv.org/abs/2308.08426",
    "authors": [
      "Alex Oshin",
      "Hassan Almubarak",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.00851",
    "title": "Drift Analysis with Fitness Levels for Elitist Evolutionary Algorithms",
    "abstract": " Title: Drift Analysis with Fitness Levels for Elitist Evolutionary Algorithms ",
    "url": "https://arxiv.org/abs/2309.00851",
    "authors": [
      "Jun He",
      "Yuren Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.07138",
    "title": "Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders",
    "abstract": " Comments: 17 pages, 8 figures, submitted for review ",
    "url": "https://arxiv.org/abs/2309.07138",
    "authors": [
      "Matthew B. Webster",
      "Joonnyong Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04918",
    "title": "SWAP: Sparse Entropic Wasserstein Regression for Robust Network Pruning",
    "abstract": " Comments: Published as a conference paper at ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.04918",
    "authors": [
      "Lei You",
      "Hei Victor Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.11009",
    "title": "LPFormer: An Adaptive Graph Transformer for Link Prediction",
    "abstract": " Title: LPFormer: An Adaptive Graph Transformer for Link Prediction ",
    "url": "https://arxiv.org/abs/2310.11009",
    "authors": [
      "Harry Shomer",
      "Yao Ma",
      "Haitao Mao",
      "Juanhui Li",
      "Bo Wu",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.13576",
    "title": "Tree Search in DAG Space with Model-based Reinforcement Learning for  Causal Discovery",
    "abstract": " Title: Tree Search in DAG Space with Model-based Reinforcement Learning for  Causal Discovery ",
    "url": "https://arxiv.org/abs/2310.13576",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15903",
    "title": "Neural Collapse in Multi-label Learning with Pick-all-label Loss",
    "abstract": " Title: Neural Collapse in Multi-label Learning with Pick-all-label Loss ",
    "url": "https://arxiv.org/abs/2310.15903",
    "authors": [
      "Pengyu Li",
      "Yutong Wang",
      "Xiao Li",
      "Qing Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17816",
    "title": "Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around  Exposure-Outcome Pairs",
    "abstract": " Title: Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around  Exposure-Outcome Pairs ",
    "url": "https://arxiv.org/abs/2310.17816",
    "authors": [
      "Jacqueline Maasch",
      "Weishen Pan",
      "Shantanu Gupta",
      "Volodymyr Kuleshov",
      "Kyra Gan",
      "Fei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.19791",
    "title": "LILO: Learning Interpretable Libraries by Compressing and Documenting  Code",
    "abstract": " Comments: Accepted to ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.19791",
    "authors": [
      "Gabriel Grand",
      "Lionel Wong",
      "Matthew Bowers",
      "Theo X. Olausson",
      "Muxin Liu",
      "Joshua B. Tenenbaum",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2311.03415",
    "title": "PowerFlowNet: Power Flow Approximation Using Message Passing Graph  Neural Networks",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2311.03415",
    "authors": [
      "Nan Lin",
      "Stavros Orfanoudakis",
      "Nathan Ordonez Cardenas",
      "Juan S. Giraldo",
      "Pedro P. Vergara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.09593",
    "title": "Multi-Step Dialogue Workflow Action Prediction",
    "abstract": " Title: Multi-Step Dialogue Workflow Action Prediction ",
    "url": "https://arxiv.org/abs/2311.09593",
    "authors": [
      "Ramya Ramakrishnan",
      "Ethan R. Elenberg",
      "Hashan Narangodage",
      "Ryan McDonald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09904",
    "title": "Capacitated Network Bargaining Games: Stability and Structure",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2311.09904",
    "authors": [
      "Laura Sanit\u00e0",
      "Lucy Verberk"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2311.15024",
    "title": "A Comparative Study of Watering Hole Attack Detection Using Supervised  Neural Network",
    "abstract": " Title: A Comparative Study of Watering Hole Attack Detection Using Supervised  Neural Network ",
    "url": "https://arxiv.org/abs/2311.15024",
    "authors": [
      "Mst. Nishita Aktar",
      "Sornali Akter",
      "Md. Nusaim Islam Saad",
      "Jakir Hosen Jisun",
      "Kh. Mustafizur Rahman",
      "Md. Nazmus Sakib"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.01046",
    "title": "Bagged Regularized $k$-Distances for Anomaly Detection",
    "abstract": " Title: Bagged Regularized $k$-Distances for Anomaly Detection ",
    "url": "https://arxiv.org/abs/2312.01046",
    "authors": [
      "Yuchao Cai",
      "Yuheng Ma",
      "Hanfang Yang",
      "Hanyuan Hang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2312.06441",
    "title": "Revisiting Graph-Based Fraud Detection in Sight of Heterophily and  Spectrum",
    "abstract": " Title: Revisiting Graph-Based Fraud Detection in Sight of Heterophily and  Spectrum ",
    "url": "https://arxiv.org/abs/2312.06441",
    "authors": [
      "Fan Xu",
      "Nan Wang",
      "Hao Wu",
      "Xuezhi Wen",
      "Xibin Zhao",
      "Hai Wan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.09533",
    "title": "Adversarial Robustness on Image Classification with $k$-means",
    "abstract": " Comments: 6 pages, 3 figures, 2 equations, 1 algorithm ",
    "url": "https://arxiv.org/abs/2312.09533",
    "authors": [
      "Rollin Omari",
      "Junae Kim",
      "Paul Montague"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2401.01269",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "abstract": " Comments: This project report was presented as a part of the course CS858 at the University of Waterloo under the supervision of Prof. Yousra Aafer ",
    "url": "https://arxiv.org/abs/2401.01269",
    "authors": [
      "Noble Saji Mathews",
      "Yelizaveta Brus",
      "Yousra Aafer",
      "Meiyappan Nagappan",
      "Shane McIntosh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.04632",
    "title": "Hypercomplex neural network in time series forecasting of stock data",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2401.04632",
    "authors": [
      "Rados\u0142aw Kycia",
      "Agnieszka Niemczynowicz"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.06366",
    "title": "Network Anatomy and Real-Time Measurement of Nvidia GeForce NOW Cloud  Gaming",
    "abstract": " Comments: This paper is accepted at Passive and Active Measurement (PAM) conference Mar 2024 ",
    "url": "https://arxiv.org/abs/2401.06366",
    "authors": [
      "Minzhao Lyu",
      "Sharat Chandra Madanapalli",
      "Arun Vishwanath",
      "Vijay Sivaraman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2401.06713",
    "title": "Picasso: Memory-Efficient Graph Coloring Using Palettes With  Applications in Quantum Computing",
    "abstract": " Comments: Accepted by IPDPS 2024 ",
    "url": "https://arxiv.org/abs/2401.06713",
    "authors": [
      "S M Ferdous",
      "Reece Neff",
      "Bo Peng",
      "Salman Shuvo",
      "Marco Minutoli",
      "Sayak Mukherjee",
      "Karol Kowalski",
      "Michela Becchi",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2401.09002",
    "title": "AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on  Large Language Models",
    "abstract": " Title: AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on  Large Language Models ",
    "url": "https://arxiv.org/abs/2401.09002",
    "authors": [
      "Dong shu",
      "Mingyu Jin",
      "Suiyuan Zhu",
      "Beichen Wang",
      "Zihao Zhou",
      "Chong Zhang",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.00746",
    "title": "Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model",
    "abstract": " Title: Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model ",
    "url": "https://arxiv.org/abs/2402.00746",
    "authors": [
      "Mingyu Jin",
      "Qinkai Yu",
      "Chong Zhang",
      "Dong Shu",
      "Suiyuan Zhu",
      "Mengnan Du",
      "Yongfeng Zhang",
      "Yanda Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.02316",
    "title": "Your Diffusion Model is Secretly a Certifiably Robust Classifier",
    "abstract": " Title: Your Diffusion Model is Secretly a Certifiably Robust Classifier ",
    "url": "https://arxiv.org/abs/2402.02316",
    "authors": [
      "Huanran Chen",
      "Yinpeng Dong",
      "Shitong Shao",
      "Zhongkai Hao",
      "Xiao Yang",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.04020",
    "title": "Examining Rail Transportation Route of Crude Oil in the United States  Using Crowdsourced Social Media Data",
    "abstract": " Title: Examining Rail Transportation Route of Crude Oil in the United States  Using Crowdsourced Social Media Data ",
    "url": "https://arxiv.org/abs/2402.04020",
    "authors": [
      "Yuandong Liu",
      "Majbah Uddin",
      "Shih-Miao Chin",
      "Ho-Ling Hwang",
      "Jiaoli Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.04390",
    "title": "Densely Multiplied Physics Informed Neural Networks",
    "abstract": " Comments: 15 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2402.04390",
    "authors": [
      "Feilong Jiang",
      "Xiaonan Hou",
      "Min Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05643",
    "title": "Improving Token-Based World Models with Parallel Observation Prediction",
    "abstract": " Title: Improving Token-Based World Models with Parallel Observation Prediction ",
    "url": "https://arxiv.org/abs/2402.05643",
    "authors": [
      "Lior Cohen",
      "Kaixin Wang",
      "Bingyi Kang",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05872",
    "title": "You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for  Semantic and Property Prediction",
    "abstract": " Title: You've Got to Feel It To Believe It: Multi-Modal Bayesian Inference for  Semantic and Property Prediction ",
    "url": "https://arxiv.org/abs/2402.05872",
    "authors": [
      "Parker Ewen",
      "Hao Chen",
      "Yuzhen Chen",
      "Anran Li",
      "Anup Bagali",
      "Gitesh Gunjal",
      "Ram Vasudevan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.06260",
    "title": "Vertex-minor universal graphs for generating entangled quantum  subsystems",
    "abstract": " Title: Vertex-minor universal graphs for generating entangled quantum  subsystems ",
    "url": "https://arxiv.org/abs/2402.06260",
    "authors": [
      "Maxime Cautr\u00e8s",
      "Nathan Claudet",
      "Mehdi Mhalla",
      "Simon Perdrix",
      "Valentin Savin",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.06281",
    "title": "On Optimal Resource Allocation in Virtual Sensor Networks",
    "abstract": " Comments: Journal Version: 41 pages, 14 figures, 41 references ",
    "url": "https://arxiv.org/abs/2402.06281",
    "authors": [
      "Carmen Delgado",
      "Jos\u00e9 Ram\u00f3n G\u00e1llego",
      "Mar\u00eda Canales",
      "Jorge Ort\u00edn",
      "Sonda Bousnina",
      "Matteo Cesana"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.06846",
    "title": "System-level Analysis of Adversarial Attacks and Defenses on  Intelligence in O-RAN based Cellular Networks",
    "abstract": " Comments: his paper has been accepted for publication in ACM WiSec 2024 ",
    "url": "https://arxiv.org/abs/2402.06846",
    "authors": [
      "Azuka Chiejina",
      "Brian Kim",
      "Kaushik Chowhdury",
      "Vijay K. Shah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.06864",
    "title": "Discriminative Adversarial Unlearning",
    "abstract": " Comments: 13 pages including references, 2 tables, 2 figures and 1 algorithm ",
    "url": "https://arxiv.org/abs/2402.06864",
    "authors": [
      "Rohan Sharma",
      "Shijie Zhou",
      "Kaiyi Ji",
      "Changyou Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07197",
    "title": "GraphTranslator: Aligning Graph Model to Large Language Model for  Open-ended Tasks",
    "abstract": " Title: GraphTranslator: Aligning Graph Model to Large Language Model for  Open-ended Tasks ",
    "url": "https://arxiv.org/abs/2402.07197",
    "authors": [
      "Mengmei Zhang",
      "Mingwei Sun",
      "Peng Wang",
      "Shen Fan",
      "Yanhu Mo",
      "Xiaoxiao Xu",
      "Hong Liu",
      "Cheng Yang",
      "Chuan Shi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07357",
    "title": "Regression Trees for Fast and Adaptive Prediction Intervals",
    "abstract": " Title: Regression Trees for Fast and Adaptive Prediction Intervals ",
    "url": "https://arxiv.org/abs/2402.07357",
    "authors": [
      "Luben M. C. Cabezas",
      "Mateus P. Otto",
      "Rafael Izbicki",
      "Rafael B. Stern"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07480",
    "title": "Topological safeguard for evasion attack interpreting the neural  networks' behavior",
    "abstract": " Title: Topological safeguard for evasion attack interpreting the neural  networks' behavior ",
    "url": "https://arxiv.org/abs/2402.07480",
    "authors": [
      "Xabier Echeberria-Barrio",
      "Amaia Gil-Lerchundi",
      "I\u00f1igo Mendialdua",
      "Raul Orduna-Urrutia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07735",
    "title": "Graph Structure Inference with BAM: Introducing the Bilinear Attention  Mechanism",
    "abstract": " Title: Graph Structure Inference with BAM: Introducing the Bilinear Attention  Mechanism ",
    "url": "https://arxiv.org/abs/2402.07735",
    "authors": [
      "Philipp Froehlich",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07787",
    "title": "Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment  Analysis",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2402.07787",
    "authors": [
      "Xiaowei Zhao",
      "Yong Zhou",
      "Xiujuan Xu",
      "Yu Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  }
]