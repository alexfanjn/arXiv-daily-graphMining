[
  {
    "id": "arXiv:2402.14825",
    "title": "Deepfake Detection and the Impact of Limited Computing Capabilities",
    "abstract": "The rapid development of technologies and artificial intelligence makes deepfakes an increasingly sophisticated and challenging-to-identify technique. To ensure the accuracy of information and control misinformation and mass manipulation, it is of paramount importance to discover and develop artificial intelligence models that enable the generic detection of forged videos. This work aims to address the detection of deepfakes across various existing datasets in a scenario with limited computing resources. The goal is to analyze the applicability of different deep learning techniques under these restrictions and explore possible approaches to enhance their efficiency. ",
    "url": "https://arxiv.org/abs/2402.14825",
    "authors": [
      "Paloma Cantero-Arjona",
      "Alfonso S\u00e1nchez-Maci\u00e1n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.14834",
    "title": "MSynFD: Multi-hop Syntax aware Fake News Detection",
    "abstract": "The proliferation of social media platforms has fueled the rapid dissemination of fake news, posing threats to our real-life society. Existing methods use multimodal data or contextual information to enhance the detection of fake news by analyzing news content and/or its social context. However, these methods often overlook essential textual news content (articles) and heavily rely on sequential modeling and global attention to extract semantic information. These existing methods fail to handle the complex, subtle twists in news articles, such as syntax-semantics mismatches and prior biases, leading to lower performance and potential failure when modalities or social context are missing. To bridge these significant gaps, we propose a novel multi-hop syntax aware fake news detection (MSynFD) method, which incorporates complementary syntax information to deal with subtle twists in fake news. Specifically, we introduce a syntactical dependency graph and design a multi-hop subgraph aggregation mechanism to capture multi-hop syntax. It extends the effect of word perception, leading to effective noise filtering and adjacent relation enhancement. Subsequently, a sequential relative position-aware Transformer is designed to capture the sequential information, together with an elaborate keyword debiasing module to mitigate the prior bias. Extensive experimental results on two public benchmark datasets verify the effectiveness and superior performance of our proposed MSynFD over state-of-the-art detection models. ",
    "url": "https://arxiv.org/abs/2402.14834",
    "authors": [
      "Liang Xiao",
      "Qi Zhang",
      "Chongyang Shi",
      "Shoujin Wang",
      "Usman Naseem",
      "Liang Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.14836",
    "title": "Stealthy Attack on Large Language Model based Recommendation",
    "abstract": "Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of recommender systems (RS). However, while these systems have flourished, their susceptibility to security threats has been largely overlooked. In this work, we reveal that the introduction of LLMs into recommendation models presents new security vulnerabilities due to their emphasis on the textual content of items. We demonstrate that attackers can significantly boost an item's exposure by merely altering its textual content during the testing phase, without requiring direct interference with the model's training process. Additionally, the attack is notably stealthy, as it does not affect the overall recommendation performance and the modifications to the text are subtle, making it difficult for users and platforms to detect. Our comprehensive experiments across four mainstream LLM-based recommendation models demonstrate the superior efficacy and stealthiness of our approach. Our work unveils a significant security gap in LLM-based recommendation systems and paves the way for future research on protecting these systems. ",
    "url": "https://arxiv.org/abs/2402.14836",
    "authors": [
      "Jinghao Zhang",
      "Yuting Liu",
      "Qiang Liu",
      "Shu Wu",
      "Guibing Guo",
      "Liang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.14861",
    "title": "CloudNine: Analyzing Meteorological Observation Impact on Weather  Prediction Using Explainable Graph Neural Networks",
    "abstract": "The impact of meteorological observations on weather forecasting varies with sensor type, location, time, and other environmental factors. Thus, quantitative analysis of observation impacts is crucial for effective and efficient development of weather forecasting systems. However, the existing impact analysis methods are difficult to be widely applied due to their high dependencies on specific forecasting systems. Also, they cannot provide observation impacts at multiple spatio-temporal scales, only global impacts of observation types. To address these issues, we present a novel system called ``CloudNine,'' which allows analysis of individual observations' impacts on specific predictions based on explainable graph neural networks (XGNNs). Combining an XGNN-based atmospheric state estimation model with a numerical weather prediction model, we provide a web application to search for observations in the 3D space of the Earth system and to visualize the impact of individual observations on predictions in specific spatial regions and time periods. ",
    "url": "https://arxiv.org/abs/2402.14861",
    "authors": [
      "Hyeon-Ju Jeon",
      "Jeon-Ho Kang",
      "In-Hyuk Kwon",
      "O-Joun Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2402.14881",
    "title": "A Study on the Vulnerability of Test Questions against ChatGPT-based  Cheating",
    "abstract": "ChatGPT is a chatbot that can answer text prompts fairly accurately, even performing very well on postgraduate-level questions. Many educators have found that their take-home or remote tests and exams are vulnerable to ChatGPT-based cheating because students may directly use answers provided by tools like ChatGPT. In this paper, we try to provide an answer to an important question: how well ChatGPT can answer test questions and how we can detect whether the questions of a test can be answered correctly by ChatGPT. We generated ChatGPT's responses to the MedMCQA dataset, which contains over 10,000 medical school entrance exam questions. We analyzed the responses and uncovered certain types of questions ChatGPT answers more inaccurately than others. In addition, we have created a basic natural language processing model to single out the most vulnerable questions to ChatGPT in a collection of questions or a sample exam. Our tool can be used by test-makers to avoid ChatGPT-vulnerable test questions. ",
    "url": "https://arxiv.org/abs/2402.14881",
    "authors": [
      "Shanker Ram",
      "Chen Qian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.14888",
    "title": "Efficient data selection employing Semantic Similarity-based Graph  Structures for model training",
    "abstract": "Recent developments in natural language processing (NLP) have highlighted the need for substantial amounts of data for models to capture textual information accurately. This raises concerns regarding the computational resources and time required for training such models. This paper introduces Semantics for data SAliency in Model performance Estimation (SeSaME). It is an efficient data sampling mechanism solely based on textual information without passing the data through a compute-heavy model or other intensive pre-processing transformations. The application of this approach is demonstrated in the use case of low-resource automated speech recognition (ASR) models, which excessively rely on text-to-speech (TTS) calls when using augmented data. SeSaME learns to categorize new incoming data points into speech recognition difficulty buckets by employing semantic similarity-based graph structures and discrete ASR information from homophilous neighbourhoods through message passing. The results indicate reliable projections of ASR performance, with a 93% accuracy increase when using the proposed method compared to random predictions, bringing non-trivial information on the impact of textual representations in speech models. Furthermore, a series of experiments show both the benefits and challenges of using the ASR information on incoming data to fine-tune the model. We report a 7% drop in validation loss compared to random sampling, 7% WER drop with non-local aggregation when evaluating against a highly difficult dataset, and 1.8% WER drop with local aggregation and high semantic similarity between datasets. ",
    "url": "https://arxiv.org/abs/2402.14888",
    "authors": [
      "Roxana Petcu",
      "Subhadeep Maji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14895",
    "title": "Data Augmentation is Dead, Long Live Data Augmentation",
    "abstract": "Textual data augmentation (DA) is a prolific field of study where novel techniques to create artificial data are regularly proposed, and that has demonstrated great efficiency on small data settings, at least for text classification tasks. In this paper, we challenge those results, showing that classical data augmentation is simply a way of performing better fine-tuning, and that spending more time fine-tuning before applying data augmentation negates its effect. This is a significant contribution as it answers several questions that were left open in recent years, namely~: which DA technique performs best (all of them as long as they generate data close enough to the training set as to not impair training) and why did DA show positive results (facilitates training of network). We furthermore show that zero and few-shot data generation via conversational agents such as ChatGPT or LLama2 can increase performances, concluding that this form of data augmentation does still work, even if classical methods do not. ",
    "url": "https://arxiv.org/abs/2402.14895",
    "authors": [
      "Fr\u00e9d\u00e9ric Piedboeuf",
      "Philippe Langlais"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14899",
    "title": "Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning  Meets Adversarial Images",
    "abstract": "Recently, Multimodal LLMs (MLLMs) have shown a great ability to understand images. However, like traditional vision models, they are still vulnerable to adversarial images. Meanwhile, Chain-of-Thought (CoT) reasoning has been widely explored on MLLMs, which not only improves model's performance, but also enhances model's explainability by giving intermediate reasoning steps. Nevertheless, there is still a lack of study regarding MLLMs' adversarial robustness with CoT and an understanding of what the rationale looks like when MLLMs infer wrong answers with adversarial images. Our research evaluates the adversarial robustness of MLLMs when employing CoT reasoning, finding that CoT marginally improves adversarial robustness against existing attack methods. Moreover, we introduce a novel stop-reasoning attack technique that effectively bypasses the CoT-induced robustness enhancements. Finally, we demonstrate the alterations in CoT reasoning when MLLMs confront adversarial images, shedding light on their reasoning process under adversarial attacks. ",
    "url": "https://arxiv.org/abs/2402.14899",
    "authors": [
      "Zefeng Wang",
      "Zhen Han",
      "Shuo Chen",
      "Fan Xue",
      "Zifeng Ding",
      "Xun Xiao",
      "Volker Tresp",
      "Philip Torr",
      "Jindong Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14937",
    "title": "SoK: Analyzing Adversarial Examples: A Framework to Study Adversary  Knowledge",
    "abstract": "Adversarial examples are malicious inputs to machine learning models that trigger a misclassification. This type of attack has been studied for close to a decade, and we find that there is a lack of study and formalization of adversary knowledge when mounting attacks. This has yielded a complex space of attack research with hard-to-compare threat models and attacks. We focus on the image classification domain and provide a theoretical framework to study adversary knowledge inspired by work in order theory. We present an adversarial example game, inspired by cryptographic games, to standardize attacks. We survey recent attacks in the image classification domain and classify their adversary's knowledge in our framework. From this systematization, we compile results that both confirm existing beliefs about adversary knowledge, such as the potency of information about the attacked model as well as allow us to derive new conclusions on the difficulty associated with the white-box and transferable threat models, for example, that transferable attacks might not be as difficult as previously thought. ",
    "url": "https://arxiv.org/abs/2402.14937",
    "authors": [
      "Lucas Fenaux",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.14956",
    "title": "Robust mass lumping and outlier removal strategies in isogeometric  analysis",
    "abstract": "Mass lumping techniques are commonly employed in explicit time integration schemes for problems in structural dynamics and both avoid solving costly linear systems with the consistent mass matrix and increase the critical time step. In isogeometric analysis, the critical time step is constrained by so-called \"outlier\" frequencies, representing the inaccurate high frequency part of the spectrum. Removing or dampening these high frequencies is paramount for fast explicit solution techniques. In this work, we propose robust mass lumping and outlier removal techniques for nontrivial geometries, including multipatch and trimmed geometries. Our lumping strategies provably do not deteriorate (and often improve) the CFL condition of the original problem and are combined with deflation techniques to remove persistent outlier frequencies. Numerical experiments reveal the advantages of the method, especially for simulations covering large time spans where they may halve the number of iterations with little or no effect on the numerical solution. ",
    "url": "https://arxiv.org/abs/2402.14956",
    "authors": [
      "Yannis Voet",
      "Espen Sande",
      "Annalisa Buffa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.14957",
    "title": "The Common Stability Mechanism behind most Self-Supervised Learning  Approaches",
    "abstract": "Last couple of years have witnessed a tremendous progress in self-supervised learning (SSL), the success of which can be attributed to the introduction of useful inductive biases in the learning process to learn meaningful visual representations while avoiding collapse. These inductive biases and constraints manifest themselves in the form of different optimization formulations in the SSL techniques, e.g. by utilizing negative examples in a contrastive formulation, or exponential moving average and predictor in BYOL and SimSiam. In this paper, we provide a framework to explain the stability mechanism of these different SSL techniques: i) we discuss the working mechanism of contrastive techniques like SimCLR, non-contrastive techniques like BYOL, SWAV, SimSiam, Barlow Twins, and DINO; ii) we provide an argument that despite different formulations these methods implicitly optimize a similar objective function, i.e. minimizing the magnitude of the expected representation over all data samples, or the mean of the data distribution, while maximizing the magnitude of the expected representation of individual samples over different data augmentations; iii) we provide mathematical and empirical evidence to support our framework. We formulate different hypotheses and test them using the Imagenet100 dataset. ",
    "url": "https://arxiv.org/abs/2402.14957",
    "authors": [
      "Abhishek Jha",
      "Matthew B. Blaschko",
      "Yuki M. Asano",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14968",
    "title": "Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment",
    "abstract": "Despite the general capabilities of Large Language Models (LLMs) like GPT-4 and Llama-2, these models still request fine-tuning or adaptation with customized data when it comes to meeting the specific business demands and intricacies of tailored use cases. However, this process inevitably introduces new safety threats, particularly against the Fine-tuning based Jailbreak Attack (FJAttack), where incorporating just a few harmful examples into the fine-tuning dataset can significantly compromise the model safety. Though potential defenses have been proposed by incorporating safety examples into the fine-tuning dataset to reduce the safety issues, such approaches require incorporating a substantial amount of safety examples, making it inefficient. To effectively defend against the FJAttack with limited safety examples, we propose a Backdoor Enhanced Safety Alignment method inspired by an analogy with the concept of backdoor attacks. In particular, we construct prefixed safety examples by integrating a secret prompt, acting as a \"backdoor trigger\", that is prefixed to safety examples. Our comprehensive experiments demonstrate that through the Backdoor Enhanced Safety Alignment with adding as few as 11 prefixed safety examples, the maliciously fine-tuned LLMs will achieve similar safety performance as the original aligned models. Furthermore, we also explore the effectiveness of our method in a more practical setting where the fine-tuning data consists of both FJAttack examples and the fine-tuning task data. Our method shows great efficacy in defending against FJAttack without harming the performance of fine-tuning tasks. ",
    "url": "https://arxiv.org/abs/2402.14968",
    "authors": [
      "Jiongxiao Wang",
      "Jiazhao Li",
      "Yiquan Li",
      "Xiangyu Qi",
      "Muhao Chen",
      "Junjie Hu",
      "Yixuan Li",
      "Bo Li",
      "Chaowei Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14970",
    "title": "What comes after optical-bypass network? A study on  optical-computing-enabled network",
    "abstract": "A new architectural paradigm, named, optical-computing-enabled network, is proposed as a potential evolution of the currently used optical-bypass framework. The main idea is to leverage the optical computing capabilities performed on transitional lightpaths at intermediate nodes and such proposal reverses the conventional wisdom in optical-bypass network, that is, separating in-transit lightpaths in avoidance of unwanted interference. In optical-computing-enabled network, the optical nodes are therefore upgraded from conventional functions of add-drop and cross-connect to include optical computing / processing capabilities. This is enabled by exploiting the superposition of in-transit lightpaths for computing purposes to achieve greater capacity efficiency. While traditional network design and planning algorithms have been well-developed for optical-bypass framework in which the routing and resource allocation is dedicated to each optical channel (lightpath), more complicated problems arise in optical-computing-enabled architecture as a consequence of intricate interaction between optical channels and hence resulting into the establishment of the so-called integrated / computed lightpaths. This necessitates for a different framework of network design and planning to maximize the impact of optical computing opportunities. In highlighting this critical point, a detailed case study exploiting the optical aggregation operation to re-design the optical core network is investigated in this paper. Numerical results obtained from extensive simulations on the COST239 network are presented to quantify the efficacy of optical-computing-enabled approach versus the conventional optical-bypass-enabled one. ",
    "url": "https://arxiv.org/abs/2402.14970",
    "authors": [
      "Dao Thanh Hai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.14977",
    "title": "Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models",
    "abstract": "Foundation model has become the backbone of the AI ecosystem. In particular, a foundation model can be used as a general-purpose feature extractor to build various downstream classifiers. However, foundation models are vulnerable to backdoor attacks and a backdoored foundation model is a single-point-of-failure of the AI ecosystem, e.g., multiple downstream classifiers inherit the backdoor vulnerabilities simultaneously. In this work, we propose Mudjacking, the first method to patch foundation models to remove backdoors. Specifically, given a misclassified trigger-embedded input detected after a backdoored foundation model is deployed, Mudjacking adjusts the parameters of the foundation model to remove the backdoor. We formulate patching a foundation model as an optimization problem and propose a gradient descent based method to solve it. We evaluate Mudjacking on both vision and language foundation models, eleven benchmark datasets, five existing backdoor attacks, and thirteen adaptive backdoor attacks. Our results show that Mudjacking can remove backdoor from a foundation model while maintaining its utility. ",
    "url": "https://arxiv.org/abs/2402.14977",
    "authors": [
      "Hongbin Liu",
      "Michael K. Reiter",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14979",
    "title": "Optimizing Language Models for Human Preferences is a Causal Inference  Problem",
    "abstract": "As large language models (LLMs) see greater use in academic and commercial settings, there is increasing interest in methods that allow language models to generate texts aligned with human preferences. In this paper, we present an initial exploration of language model optimization for human preferences from direct outcome datasets, where each sample consists of a text and an associated numerical outcome measuring the reader's response. We first propose that language model optimization should be viewed as a causal problem to ensure that the model correctly learns the relationship between the text and the outcome. We formalize this causal language optimization problem, and we develop a method--causal preference optimization (CPO)--that solves an unbiased surrogate objective for the problem. We further extend CPO with doubly robust CPO (DR-CPO), which reduces the variance of the surrogate objective while retaining provably strong guarantees on bias. Finally, we empirically demonstrate the effectiveness of (DR-)CPO in optimizing state-of-the-art LLMs for human preferences on direct outcome data, and we validate the robustness of DR-CPO under difficult confounding conditions. ",
    "url": "https://arxiv.org/abs/2402.14979",
    "authors": [
      "Victoria Lin",
      "Eli Ben-Michael",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.14989",
    "title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular  Time Series Data",
    "abstract": "Irregular sampling intervals and missing values in real-world time series data present challenges for conventional methods that assume consistent intervals and complete data. Neural Ordinary Differential Equations (Neural ODEs) offer an alternative approach, utilizing neural networks combined with ODE solvers to learn continuous latent representations through parameterized vector fields. Neural Stochastic Differential Equations (Neural SDEs) extend Neural ODEs by incorporating a diffusion term, although this addition is not trivial, particularly when addressing irregular intervals and missing values. Consequently, careful design of drift and diffusion functions is crucial for maintaining stability and enhancing performance, while incautious choices can result in adverse properties such as the absence of strong solutions, stochastic destabilization, or unstable Euler discretizations, significantly affecting Neural SDEs' performance. In this study, we propose three stable classes of Neural SDEs: Langevin-type SDE, Linear Noise SDE, and Geometric SDE. Then, we rigorously demonstrate their robustness in maintaining excellent performance under distribution shift, while effectively preventing overfitting. To assess the effectiveness of our approach, we conduct extensive experiments on four benchmark datasets for interpolation, forecasting, and classification tasks, and analyze the robustness of our methods with 30 public datasets under different missing rates. Our results demonstrate the efficacy of the proposed method in handling real-world irregular time series data. ",
    "url": "https://arxiv.org/abs/2402.14989",
    "authors": [
      "YongKyung Oh",
      "Dongyoung Lim",
      "Sungil Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15008",
    "title": "Radiation Surveys in Active Nuclear Facilities with Heterogeneous  Collaborative Mobile Robots",
    "abstract": "Nuclear facilities must routinely survey their infrastructure for radiation contamination. Generally, this is done by trained professionals, wearing personal protective equipment (PPE) that swipe potentially contaminated surfaces and test the wipes under detectors. This approach leaves personnel vulnerable to radiation exposure and is not comprehensive. Robots address these inadequacies, offering a cost-effective solution with negligible downtime. We present a Robot Radiation Survey System (RRSS): a heterogeneous robot team to perform comprehensive alpha/beta/gamma radiation surveys. The RRSS system members, core capabilities, and comprehensive survey plan are addresses in this paper. ",
    "url": "https://arxiv.org/abs/2402.15008",
    "authors": [
      "Mitchell Pryor",
      "Alex Navarro",
      "Janak Panthi",
      "Kevin Torres",
      "Mary Tebben",
      "Daniel Meza",
      "Caleb Horan",
      "Alex Macris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.15018",
    "title": "Unintended Impacts of LLM Alignment on Global Representation",
    "abstract": "Before being deployed for user-facing applications, developers align Large Language Models (LLMs) to user preferences through a variety of procedures, such as Reinforcement Learning From Human Feedback (RLHF) and Direct Preference Optimization (DPO). Current evaluations of these procedures focus on benchmarks of instruction following, reasoning, and truthfulness. However, human preferences are not universal, and aligning to specific preference sets may have unintended effects. We explore how alignment impacts performance along three axes of global representation: English dialects, multilingualism, and opinions from and about countries worldwide. Our results show that current alignment procedures create disparities between English dialects and global opinions. We find alignment improves capabilities in several languages. We conclude by discussing design decisions that led to these unintended impacts and recommendations for more equitable preference tuning. ",
    "url": "https://arxiv.org/abs/2402.15018",
    "authors": [
      "Michael J. Ryan",
      "William Held",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15044",
    "title": "Fiducial Focus Augmentation for Facial Landmark Detection",
    "abstract": "Deep learning methods have led to significant improvements in the performance on the facial landmark detection (FLD) task. However, detecting landmarks in challenging settings, such as head pose changes, exaggerated expressions, or uneven illumination, continue to remain a challenge due to high variability and insufficient samples. This inadequacy can be attributed to the model's inability to effectively acquire appropriate facial structure information from the input images. To address this, we propose a novel image augmentation technique specifically designed for the FLD task to enhance the model's understanding of facial structures. To effectively utilize the newly proposed augmentation technique, we employ a Siamese architecture-based training mechanism with a Deep Canonical Correlation Analysis (DCCA)-based loss to achieve collective learning of high-level feature representations from two different views of the input images. Furthermore, we employ a Transformer + CNN-based network with a custom hourglass module as the robust backbone for the Siamese framework. Extensive experiments show that our approach outperforms multiple state-of-the-art approaches across various benchmark datasets. ",
    "url": "https://arxiv.org/abs/2402.15044",
    "authors": [
      "Purbayan Kar",
      "Vishal Chudasama",
      "Naoyuki Onoe",
      "Pankaj Wasnik",
      "Vineeth Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15059",
    "title": "ColBERT-XM: A Modular Multi-Vector Representation Model for Zero-Shot  Multilingual Information Retrieval",
    "abstract": "State-of-the-art neural retrievers predominantly focus on high-resource languages like English, which impedes their adoption in retrieval scenarios involving other languages. Current approaches circumvent the lack of high-quality labeled data in non-English languages by leveraging multilingual pretrained language models capable of cross-lingual transfer. However, these models require substantial task-specific fine-tuning across multiple languages, often perform poorly in languages with minimal representation in the pretraining corpus, and struggle to incorporate new languages after the pretraining phase. In this work, we present a novel modular dense retrieval model that learns from the rich data of a single high-resource language and effectively zero-shot transfers to a wide array of languages, thereby eliminating the need for language-specific labeled data. Our model, ColBERT-XM, demonstrates competitive performance against existing state-of-the-art multilingual retrievers trained on more extensive datasets in various languages. Further analysis reveals that our modular approach is highly data-efficient, effectively adapts to out-of-distribution data, and significantly reduces energy consumption and carbon emissions. By demonstrating its proficiency in zero-shot scenarios, ColBERT-XM marks a shift towards more sustainable and inclusive retrieval systems, enabling effective information accessibility in numerous languages. We publicly release our code and models for the community. ",
    "url": "https://arxiv.org/abs/2402.15059",
    "authors": [
      "Antoine Louis",
      "Vageesh Saxena",
      "Gijs van Dijck",
      "Gerasimos Spanakis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.15075",
    "title": "Stacking Factorizing Partitioned Expressions in Hybrid Bayesian Network  Models",
    "abstract": "Hybrid Bayesian networks (HBN) contain complex conditional probabilistic distributions (CPD) specified as partitioned expressions over discrete and continuous variables. The size of these CPDs grows exponentially with the number of parent nodes when using discrete inference, resulting in significant inefficiency. Normally, an effective way to reduce the CPD size is to use a binary factorization (BF) algorithm to decompose the statistical or arithmetic functions in the CPD by factorizing the number of connected parent nodes to sets of size two. However, the BF algorithm was not designed to handle partitioned expressions. Hence, we propose a new algorithm called stacking factorization (SF) to decompose the partitioned expressions. The SF algorithm creates intermediate nodes to incrementally reconstruct the densities in the original partitioned expression, allowing no more than two continuous parent nodes to be connected to each child node in the resulting HBN. SF can be either used independently or combined with the BF algorithm. We show that the SF+BF algorithm significantly reduces the CPD size and contributes to lowering the tree-width of a model, thus improving efficiency. ",
    "url": "https://arxiv.org/abs/2402.15075",
    "authors": [
      "Peng Lin",
      "Martin Neil",
      "Norman Fenton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15105",
    "title": "A First Look at GPT Apps: Landscape and Vulnerability",
    "abstract": "With the advancement of Large Language Models (LLMs), increasingly sophisticated and powerful GPTs are entering the market. Despite their popularity, the LLM ecosystem still remains unexplored. Additionally, LLMs' susceptibility to attacks raises concerns over safety and plagiarism. Thus, in this work, we conduct a pioneering exploration of GPT stores, aiming to study vulnerabilities and plagiarism within GPT applications. To begin with, we conduct, to our knowledge, the first large-scale monitoring and analysis of two stores, an unofficial GPTStore.AI, and an official OpenAI GPT Store. Then, we propose a TriLevel GPT Reversing (T-GR) strategy for extracting GPT internals. To complete these two tasks efficiently, we develop two automated tools: one for web scraping and another designed for programmatically interacting with GPTs. Our findings reveal a significant enthusiasm among users and developers for GPT interaction and creation, as evidenced by the rapid increase in GPTs and their creators. However, we also uncover a widespread failure to protect GPT internals, with nearly 90% of system prompts easily accessible, leading to considerable plagiarism and duplication among GPTs. ",
    "url": "https://arxiv.org/abs/2402.15105",
    "authors": [
      "Zejun Zhang",
      "Li Zhang",
      "Xin Yuan",
      "Anlan Zhang",
      "Mengwei Xu",
      "Feng Qian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.15106",
    "title": "Sampling-based Distributed Training with Message Passing Neural Network",
    "abstract": "In this study, we introduce a domain-decomposition-based distributed training and inference approach for message-passing neural networks (MPNN). Our objective is to address the challenge of scaling edge-based graph neural networks as the number of nodes increases. Through our distributed training approach, coupled with Nystr\\\"om-approximation sampling techniques, we present a scalable graph neural network, referred to as DS-MPNN (D and S standing for distributed and sampled, respectively), capable of scaling up to $O(10^5)$ nodes. We validate our sampling and distributed training approach on two cases: (a) a Darcy flow dataset and (b) steady RANS simulations of 2-D airfoils, providing comparisons with both single-GPU implementation and node-based graph convolution networks (GCNs). The DS-MPNN model demonstrates comparable accuracy to single-GPU implementation, can accommodate a significantly larger number of nodes compared to the single-GPU variant (S-MPNN), and significantly outperforms the node-based GCN. ",
    "url": "https://arxiv.org/abs/2402.15106",
    "authors": [
      "Priyesh Kakka",
      "Sheel Nidhan",
      "Rishikesh Ranade",
      "Jonathan F. MacArt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2402.15113",
    "title": "MSPipe: Efficient Temporal GNN Training via Staleness-aware Pipeline",
    "abstract": "Memory-based Temporal Graph Neural Networks (MTGNNs) are a class of temporal graph neural networks that utilize a node memory module to capture and retain long-term temporal dependencies, leading to superior performance compared to memory-less counterparts. However, the iterative reading and updating process of the memory module in MTGNNs to obtain up-to-date information needs to follow the temporal dependencies. This introduces significant overhead and limits training throughput. Existing optimizations for static GNNs are not directly applicable to MTGNNs due to differences in training paradigm, model architecture, and the absence of a memory module. Moreover, they do not effectively address the challenges posed by temporal dependencies, making them ineffective for MTGNN training. In this paper, we propose MSPipe, a general and efficient framework for MTGNNs that maximizes training throughput while maintaining model accuracy. Our design addresses the unique challenges associated with fetching and updating node memory states in MTGNNs by integrating staleness into the memory module. However, simply introducing a predefined staleness bound in the memory module to break temporal dependencies may lead to suboptimal performance and lack of generalizability across different models and datasets. To solve this, we introduce an online pipeline scheduling algorithm in MSPipe that strategically breaks temporal dependencies with minimal staleness and delays memory fetching to obtain fresher memory states. Moreover, we design a staleness mitigation mechanism to enhance training convergence and model accuracy. We provide convergence analysis and prove that MSPipe maintains the same convergence rate as vanilla sample-based GNN training. Experimental results show that MSPipe achieves up to 2.45x speed-up without sacrificing accuracy, making it a promising solution for efficient MTGNN training. ",
    "url": "https://arxiv.org/abs/2402.15113",
    "authors": [
      "Guangming Sheng",
      "Junwei Su",
      "Chao Huang",
      "Chuan Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.15134",
    "title": "Deep Coupling Network For Multivariate Time Series Forecasting",
    "abstract": "Multivariate time series (MTS) forecasting is crucial in many real-world applications. To achieve accurate MTS forecasting, it is essential to simultaneously consider both intra- and inter-series relationships among time series data. However, previous work has typically modeled intra- and inter-series relationships separately and has disregarded multi-order interactions present within and between time series data, which can seriously degrade forecasting accuracy. In this paper, we reexamine intra- and inter-series relationships from the perspective of mutual information and accordingly construct a comprehensive relationship learning mechanism tailored to simultaneously capture the intricate multi-order intra- and inter-series couplings. Based on the mechanism, we propose a novel deep coupling network for MTS forecasting, named DeepCN, which consists of a coupling mechanism dedicated to explicitly exploring the multi-order intra- and inter-series relationships among time series data concurrently, a coupled variable representation module aimed at encoding diverse variable patterns, and an inference module facilitating predictions through one forward step. Extensive experiments conducted on seven real-world datasets demonstrate that our proposed DeepCN achieves superior performance compared with the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2402.15134",
    "authors": [
      "Kun Yi",
      "Qi Zhang",
      "Hui He",
      "Kaize Shi",
      "Liang Hu",
      "Ning An",
      "Zhendong Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15140",
    "title": "A Relation-Interactive Approach for Message Passing in Hyper-relational  Knowledge Graphs",
    "abstract": "Hyper-relational knowledge graphs (KGs) contain additional key-value pairs, providing more information about the relations. In many scenarios, the same relation can have distinct key-value pairs, making the original triple fact more recognizable and specific. Prior studies on hyper-relational KGs have established a solid standard method for hyper-relational graph encoding. In this work, we propose a message-passing-based graph encoder with global relation structure awareness ability, which we call ReSaE. Compared to the prior state-of-the-art approach, ReSaE emphasizes the interaction of relations during message passing process and optimizes the readout structure for link prediction tasks. Overall, ReSaE gives a encoding solution for hyper-relational KGs and ensures stronger performance on downstream link prediction tasks. Our experiments demonstrate that ReSaE achieves state-of-the-art performance on multiple link prediction benchmarks. Furthermore, we also analyze the influence of different model structures on model performance. ",
    "url": "https://arxiv.org/abs/2402.15140",
    "authors": [
      "Yonglin Jing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15141",
    "title": "A note on the adjoint method for neural ordinary differential equation  network",
    "abstract": "Perturbation and operator adjoint method are used to give the right adjoint form rigourously. From the derivation, we can have following results: 1) The loss gradient is not an ODE, it is an integral and we shows the reason; 2) The traditional adjoint form is not equivalent with the back propagation results. 3) The adjoint operator analysis shows that if and only if the discrete adjoint has the same scheme with the discrete neural ODE, the adjoint form would give the same results as BP does. ",
    "url": "https://arxiv.org/abs/2402.15141",
    "authors": [
      "Pipi Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15143",
    "title": "PUAD: Frustratingly Simple Method for Robust Anomaly Detection",
    "abstract": "Developing an accurate and fast anomaly detection model is an important task in real-time computer vision applications. There has been much research to develop a single model that detects either structural or logical anomalies, which are inherently distinct. The majority of the existing approaches implicitly assume that the anomaly can be represented by identifying the anomalous location. However, we argue that logical anomalies, such as the wrong number of objects, can not be well-represented by the spatial feature maps and require an alternative approach. In addition, we focused on the possibility of detecting logical anomalies by using an out-of-distribution detection approach on the feature space, which aggregates the spatial information of the feature map. As a demonstration, we propose a method that incorporates a simple out-of-distribution detection method on the feature space against state-of-the-art reconstruction-based approaches. Despite the simplicity of our proposal, our method PUAD (Picturable and Unpicturable Anomaly Detection) achieves state-of-the-art performance on the MVTec LOCO AD dataset. ",
    "url": "https://arxiv.org/abs/2402.15143",
    "authors": [
      "Shota Sugawara",
      "Ryuji Imamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15152",
    "title": "On the Duality Between Sharpness-Aware Minimization and Adversarial  Training",
    "abstract": "Adversarial Training (AT), which adversarially perturb the input samples during training, has been acknowledged as one of the most effective defenses against adversarial attacks, yet suffers from a fundamental tradeoff that inevitably decreases clean accuracy. Instead of perturbing the samples, Sharpness-Aware Minimization (SAM) perturbs the model weights during training to find a more flat loss landscape and improve generalization. However, as SAM is designed for better clean accuracy, its effectiveness in enhancing adversarial robustness remains unexplored. In this work, considering the duality between SAM and AT, we investigate the adversarial robustness derived from SAM. Intriguingly, we find that using SAM alone can improve adversarial robustness. To understand this unexpected property of SAM, we first provide empirical and theoretical insights into how SAM can implicitly learn more robust features, and conduct comprehensive experiments to show that SAM can improve adversarial robustness notably without sacrificing any clean accuracy, shedding light on the potential of SAM to be a substitute for AT when accuracy comes at a higher priority. Code is available at https://github.com/weizeming/SAM_AT. ",
    "url": "https://arxiv.org/abs/2402.15152",
    "authors": [
      "Yihao Zhang",
      "Hangzhou He",
      "Jingyu Zhu",
      "Huanran Chen",
      "Yifei Wang",
      "Zeming Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.15163",
    "title": "Studying the Impact of Stochasticity on the Evaluation of Deep Neural  Networks for Forest-Fire Prediction",
    "abstract": "This paper presents the first systematic study of the evaluation of Deep Neural Networks (DNNs) for discrete dynamical systems under stochastic assumptions, with a focus on wildfire prediction. We develop a framework to study the impact of stochasticity on two classes of evaluation metrics: classification-based metrics, which assess fidelity to observed ground truth (GT), and proper scoring rules, which test fidelity-to-statistic. Our findings reveal that evaluating for fidelity-to-statistic is a reliable alternative in highly stochastic scenarios. We extend our analysis to real-world wildfire data, highlighting limitations in traditional wildfire prediction evaluation methods, and suggest interpretable stochasticity-compatible alternatives. ",
    "url": "https://arxiv.org/abs/2402.15163",
    "authors": [
      "Harshit Kumar",
      "Biswadeep Chakraborty",
      "Beomseok Kang",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15164",
    "title": "EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning  Based Recommender Systems",
    "abstract": "Reinforcement Learning (RL)-Based Recommender Systems (RSs) are increasingly recognized for their ability to improve long-term user engagement. Yet, the field grapples with challenges such as the absence of accessible frameworks, inconsistent evaluation standards, and the complexity of replicating prior work. Addressing these obstacles, we present EasyRL4Rec, a user-friendly and efficient library tailored for RL-based RSs. EasyRL4Rec features lightweight, diverse RL environments built on five widely-used public datasets, and is equipped with comprehensive core modules that offer rich options to ease the development of models. It establishes consistent evaluation criteria with a focus on long-term impacts and introduces customized solutions for state modeling and action representation tailored to recommender systems. Additionally, we share valuable insights gained from extensive experiments with current methods. EasyRL4Rec aims to facilitate the model development and experimental process in the domain of RL-based RSs. The library is openly accessible at https://github.com/chongminggao/EasyRL4Rec. ",
    "url": "https://arxiv.org/abs/2402.15164",
    "authors": [
      "Yuanqing Yu",
      "Chongming Gao",
      "Jiawei Chen",
      "Heng Tang",
      "Yuefeng Sun",
      "Qian Chen",
      "Weizhi Ma",
      "Min Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15166",
    "title": "Convergence Analysis of Split Federated Learning on Heterogeneous Data",
    "abstract": "Split federated learning (SFL) is a recent distributed approach for collaborative model training among multiple clients. In SFL, a global model is typically split into two parts, where clients train one part in a parallel federated manner, and a main server trains the other. Despite the recent research on SFL algorithm development, the convergence analysis of SFL is missing in the literature, and this paper aims to fill this gap. The analysis of SFL can be more challenging than that of federated learning (FL), due to the potential dual-paced updates at the clients and the main server. We provide convergence analysis of SFL for strongly convex and general convex objectives on heterogeneous data. The convergence rates are $O(1/T)$ and $O(1/\\sqrt[3]{T})$, respectively, where $T$ denotes the total number of rounds for SFL training. We further extend the analysis to non-convex objectives and where some clients may be unavailable during training. Numerical experiments validate our theoretical results and show that SFL outperforms FL and split learning (SL) when data is highly heterogeneous across a large number of clients. ",
    "url": "https://arxiv.org/abs/2402.15166",
    "authors": [
      "Pengchao Han",
      "Chao Huang",
      "Geng Tian",
      "Ming Tang",
      "Xin Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15179",
    "title": "Advancing Parameter Efficiency in Fine-tuning via Representation Editing",
    "abstract": "Parameter Efficient Fine-Tuning (PEFT) has gained significant attention for its ability to achieve competitive results while updating only a small subset of trainable parameters. Despite the promising performance of current PEFT methods, they present challenges in hyperparameter selection, such as determining the rank of LoRA or Adapter, or specifying the length of soft prompts. In addressing these challenges, we propose a novel approach to fine-tuning neural models, termed Representation EDiting (RED), which scales and biases the representation produced at each layer. RED substantially reduces the number of trainable parameters by a factor of $25,700$ compared to full parameter fine-tuning, and by a factor of $32$ compared to LoRA. Remarkably, RED achieves comparable or superior results to full parameter fine-tuning and other PEFT methods. Extensive experiments were conducted across models of varying architectures and scales, including RoBERTa, GPT-2, T5, and Llama-2, and the results demonstrate the efficiency and efficacy of RED, positioning it as a promising PEFT approach for large neural models. ",
    "url": "https://arxiv.org/abs/2402.15179",
    "authors": [
      "Muling Wu",
      "Wenhao Liu",
      "Xiaohua Wang",
      "Tianlong Li",
      "Changze Lv",
      "Zixuan Ling",
      "Jianhao Zhu",
      "Cenyuan Zhang",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.15180",
    "title": "Break the Breakout: Reinventing LM Defense Against Jailbreak Attacks  with Self-Refinement",
    "abstract": "Caution: This paper includes offensive words that could potentially cause unpleasantness. Language models (LMs) are vulnerable to exploitation for adversarial misuse. Training LMs for safety alignment is extensive and makes it hard to respond to fast-developing attacks immediately, such as jailbreaks. We propose self-refine with formatting that achieves outstanding safety even in non-safety-aligned LMs and evaluate our method alongside several defense baselines, demonstrating that it is the safest training-free method against jailbreak attacks. Additionally, we proposed a formatting method that improves the efficiency of the self-refine process while reducing attack success rates in fewer iterations. We've also observed that non-safety-aligned LMs outperform safety-aligned LMs in safety tasks by giving more helpful and safe responses. In conclusion, our findings can achieve less safety risk with fewer computational costs, allowing non-safety LM to be easily utilized in real-world service. ",
    "url": "https://arxiv.org/abs/2402.15180",
    "authors": [
      "Heegyu Kim",
      "Sehyun Yuk",
      "Hyunsouk Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.15183",
    "title": "GraphEdit: Large Language Models for Graph Structure Learning",
    "abstract": "Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks (GNNs) have emerged as promising GSL solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing GSL methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of LLMs through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy connections but also identifies node-wise dependencies from a global perspective, providing a comprehensive understanding of the graph structure. We conduct extensive experiments on multiple benchmark datasets to demonstrate the effectiveness and robustness of GraphEdit across various settings. We have made our model implementation available at: https://github.com/HKUDS/GraphEdit. ",
    "url": "https://arxiv.org/abs/2402.15183",
    "authors": [
      "Zirui Guo",
      "Lianghao Xia",
      "Yanhua Yu",
      "Yuling Wang",
      "Zixuan Yang",
      "Wei Wei",
      "Liang Pang",
      "Tat-Seng Chua",
      "Chao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15218",
    "title": "BSPA: Exploring Black-box Stealthy Prompt Attacks against Image  Generators",
    "abstract": "Extremely large image generators offer significant transformative potential across diverse sectors. It allows users to design specific prompts to generate realistic images through some black-box APIs. However, some studies reveal that image generators are notably susceptible to attacks and generate Not Suitable For Work (NSFW) contents by manually designed toxin texts, especially imperceptible to human observers. We urgently need a multitude of universal and transferable prompts to improve the safety of image generators, especially black-box-released APIs. Nevertheless, they are constrained by labor-intensive design processes and heavily reliant on the quality of the given instructions. To achieve this, we introduce a black-box stealthy prompt attack (BSPA) that adopts a retriever to simulate attacks from API users. It can effectively harness filter scores to tune the retrieval space of sensitive words for matching the input prompts, thereby crafting stealthy prompts tailored for image generators. Significantly, this approach is model-agnostic and requires no internal access to the model's features, ensuring its applicability to a wide range of image generators. Building on BSPA, we have constructed an automated prompt tool and a comprehensive prompt attack dataset (NSFWeval). Extensive experiments demonstrate that BSPA effectively explores the security vulnerabilities in a variety of state-of-the-art available black-box models, including Stable Diffusion XL, Midjourney, and DALL-E 2/3. Furthermore, we develop a resilient text filter and offer targeted recommendations to ensure the security of image generators against prompt attacks in the future. ",
    "url": "https://arxiv.org/abs/2402.15218",
    "authors": [
      "Yu Tian",
      "Xiao Yang",
      "Yinpeng Dong",
      "Heming Yang",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.15264",
    "title": "DEEM: Dynamic Experienced Expert Modeling for Stance Detection",
    "abstract": "Recent work has made a preliminary attempt to use large language models (LLMs) to solve the stance detection task, showing promising results. However, considering that stance detection usually requires detailed background knowledge, the vanilla reasoning method may neglect the domain knowledge to make a professional and accurate analysis. Thus, there is still room for improvement of LLMs reasoning, especially in leveraging the generation capability of LLMs to simulate specific experts (i.e., multi-agents) to detect the stance. In this paper, different from existing multi-agent works that require detailed descriptions and use fixed experts, we propose a Dynamic Experienced Expert Modeling (DEEM) method which can leverage the generated experienced experts and let LLMs reason in a semi-parametric way, making the experts more generalizable and reliable. Experimental results demonstrate that DEEM consistently achieves the best results on three standard benchmarks, outperforms methods with self-consistency reasoning, and reduces the bias of LLMs. ",
    "url": "https://arxiv.org/abs/2402.15264",
    "authors": [
      "Xiaolong Wang",
      "Yile Wang",
      "Sijie Cheng",
      "Peng Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.15267",
    "title": "Adversarial Robustness of Deep Learning-based Malware Detectors via  (De)Randomized Smoothing",
    "abstract": "Deep learning-based malware detectors have been shown to be susceptible to adversarial malware examples, i.e. malware examples that have been deliberately manipulated in order to avoid detection. In light of the vulnerability of deep learning detectors to subtle input file modifications, we propose a practical defense against adversarial malware examples inspired by (de)randomized smoothing. In this work, we reduce the chances of sampling adversarial content injected by malware authors by selecting correlated subsets of bytes, rather than using Gaussian noise to randomize inputs like in the Computer Vision (CV) domain. During training, our ablation-based smoothing scheme trains a base classifier to make classifications on a subset of contiguous bytes or chunk of bytes. At test time, a large number of chunks are then classified by a base classifier and the consensus among these classifications is then reported as the final prediction. We propose two strategies to determine the location of the chunks used for classification: (1) randomly selecting the locations of the chunks and (2) selecting contiguous adjacent chunks. To showcase the effectiveness of our approach, we have trained two classifiers with our chunk-based ablation schemes on the BODMAS dataset. Our findings reveal that the chunk-based smoothing classifiers exhibit greater resilience against adversarial malware examples generated with state-of-the-are evasion attacks, outperforming a non-smoothed classifier and a randomized smoothing-based classifier by a great margin. ",
    "url": "https://arxiv.org/abs/2402.15267",
    "authors": [
      "Daniel Gibert",
      "Giulio Zizzo",
      "Quan Le",
      "Jordi Planes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15270",
    "title": "Smoothed Graph Contrastive Learning via Seamless Proximity Integration",
    "abstract": "Graph contrastive learning (GCL) aligns node representations by classifying node pairs into positives and negatives using a selection process that typically relies on establishing correspondences within two augmented graphs. The conventional GCL approaches incorporate negative samples uniformly in the contrastive loss, resulting in the equal treatment negative nodes, regardless of their proximity to the true positive. In this paper, we present a Smoothed Graph Contrastive Learning model (SGCL), which leverages the geometric structure of augmented graphs to inject proximity information associated with positive/negative pairs in the contrastive loss, thus significantly regularizing the learning process. The proposed SGCL adjusts the penalties associated with node pairs in the contrastive loss by incorporating three distinct smoothing techniques that result in proximity aware positives and negatives. To enhance scalability for large-scale graphs, the proposed framework incorporates a graph batch-generating strategy that partitions the given graphs into multiple subgraphs, facilitating efficient training in separate batches. Through extensive experimentation in the unsupervised setting on various benchmarks, particularly those of large scale, we demonstrate the superiority of our proposed framework against recent baselines. ",
    "url": "https://arxiv.org/abs/2402.15270",
    "authors": [
      "Maysam Behmanesh",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15272",
    "title": "EMIFF: Enhanced Multi-scale Image Feature Fusion for  Vehicle-Infrastructure Cooperative 3D Object Detection",
    "abstract": "In autonomous driving, cooperative perception makes use of multi-view cameras from both vehicles and infrastructure, providing a global vantage point with rich semantic context of road conditions beyond a single vehicle viewpoint. Currently, two major challenges persist in vehicle-infrastructure cooperative 3D (VIC3D) object detection: $1)$ inherent pose errors when fusing multi-view images, caused by time asynchrony across cameras; $2)$ information loss in transmission process resulted from limited communication bandwidth. To address these issues, we propose a novel camera-based 3D detection framework for VIC3D task, Enhanced Multi-scale Image Feature Fusion (EMIFF). To fully exploit holistic perspectives from both vehicles and infrastructure, we propose Multi-scale Cross Attention (MCA) and Camera-aware Channel Masking (CCM) modules to enhance infrastructure and vehicle features at scale, spatial, and channel levels to correct the pose error introduced by camera asynchrony. We also introduce a Feature Compression (FC) module with channel and spatial compression blocks for transmission efficiency. Experiments show that EMIFF achieves SOTA on DAIR-V2X-C datasets, significantly outperforming previous early-fusion and late-fusion methods with comparable transmission costs. ",
    "url": "https://arxiv.org/abs/2402.15272",
    "authors": [
      "Zhe Wang",
      "Siqi Fan",
      "Xiaoliang Huo",
      "Tongda Xu",
      "Yan Wang",
      "Jingjing Liu",
      "Yilun Chen",
      "Ya-Qin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15273",
    "title": "Optimized Deployment of Deep Neural Networks for Visual Pose Estimation  on Nano-drones",
    "abstract": "Miniaturized autonomous unmanned aerial vehicles (UAVs) are gaining popularity due to their small size, enabling new tasks such as indoor navigation or people monitoring. Nonetheless, their size and simple electronics pose severe challenges in implementing advanced onboard intelligence. This work proposes a new automatic optimization pipeline for visual pose estimation tasks using Deep Neural Networks (DNNs). The pipeline leverages two different Neural Architecture Search (NAS) algorithms to pursue a vast complexity-driven exploration in the DNNs' architectural space. The obtained networks are then deployed on an off-the-shelf nano-drone equipped with a parallel ultra-low power System-on-Chip leveraging a set of novel software kernels for the efficient fused execution of critical DNN layer sequences. Our results improve the state-of-the-art reducing inference latency by up to 3.22x at iso-error. ",
    "url": "https://arxiv.org/abs/2402.15273",
    "authors": [
      "Matteo Risso",
      "Francesco Daghero",
      "Beatrice Alessandra Motetti",
      "Daniele Jahier Pagliari",
      "Enrico Macii",
      "Massimo Poncino",
      "Alessio Burrello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15281",
    "title": "Neural Implicit Swept Volume Models for Fast Collision Detection",
    "abstract": "Collision detection is one of the most time-consuming operations during motion planning. Thus, there is an increasing interest in exploring machine learning techniques to speed up collision detection and sampling-based motion planning. A recent line of research focuses on utilizing neural signed distance functions of either the robot geometry or the swept volume of the robot motion. Building on this, we present a novel neural implicit swept volume model that is the first to continuously represent arbitrary motions parameterized by their start and goal configurations. This allows to quickly compute signed distances for any point in the task space to the robot motion. Further, we present an algorithm combining the speed of the deep learning-based signed distance computations with the strong accuracy guarantees of geometric collision checkers. We validate our approach in simulated and real-world robotic experiments, and demonstrate that it is able to speed up a commercial bin picking application. ",
    "url": "https://arxiv.org/abs/2402.15281",
    "authors": [
      "Dominik Joho",
      "Jonas Schwinn",
      "Kirill Safronov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15290",
    "title": "Linear Dynamics-embedded Neural Network for Long-Sequence Modeling",
    "abstract": "The trade-off between performance and computational efficiency in long-sequence modeling becomes a bottleneck for existing models. Inspired by the continuous state space models (SSMs) with multi-input and multi-output in control theory, we propose a new neural network called Linear Dynamics-embedded Neural Network (LDNN). SSMs' continuous, discrete, and convolutional properties enable LDNN to have few parameters, flexible inference, and efficient training in long-sequence tasks. Two efficient strategies, diagonalization and $'\\text{Disentanglement then Fast Fourier Transform (FFT)}'$, are developed to reduce the time complexity of convolution from $O(LNH\\max\\{L, N\\})$ to $O(LN\\max \\{H, \\log L\\})$. We further improve LDNN through bidirectional noncausal and multi-head settings to accommodate a broader range of applications. Extensive experiments on the Long Range Arena (LRA) demonstrate the effectiveness and state-of-the-art performance of LDNN. ",
    "url": "https://arxiv.org/abs/2402.15290",
    "authors": [
      "Tongyi Liang",
      "Han-Xiong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15301",
    "title": "Causal Graph Discovery with Retrieval-Augmented Generation based Large  Language Models",
    "abstract": "Causal graph recovery is essential in the field of causal inference. Traditional methods are typically knowledge-based or statistical estimation-based, which are limited by data collection biases and individuals' knowledge about factors affecting the relations between variables of interests. The advance of large language models (LLMs) provides opportunities to address these problems. We propose a novel method that utilizes the extensive knowledge contained within a large corpus of scientific literature to deduce causal relationships in general causal graph recovery tasks. This method leverages Retrieval Augmented-Generation (RAG) based LLMs to systematically analyze and extract pertinent information from a comprehensive collection of research papers. Our method first retrieves relevant text chunks from the aggregated literature. Then, the LLM is tasked with identifying and labelling potential associations between factors. Finally, we give a method to aggregate the associational relationships to build a causal graph. We demonstrate our method is able to construct high quality causal graphs on the well-known SACHS dataset solely from literature. ",
    "url": "https://arxiv.org/abs/2402.15301",
    "authors": [
      "Yuzhe Zhang",
      "Yipeng Zhang",
      "Yidong Gan",
      "Lina Yao",
      "Chen Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.15315",
    "title": "On Minimal Depth in Neural Networks",
    "abstract": "A characterization of the representability of neural networks is relevant to comprehend their success in artificial intelligence. This study investigate two topics on ReLU neural network expressivity and their connection with a conjecture related to the minimum depth required for representing any continuous piecewise linear function (CPWL). The topics are the minimal depth representation of the sum and max operations, as well as the exploration of polytope neural networks. For the sum operation, we establish a sufficient condition on the minimal depth of the operands to find the minimal depth of the operation. In contrast, regarding the max operation, a comprehensive set of examples is presented, demonstrating that no sufficient conditions, depending solely on the depth of the operands, would imply a minimal depth for the operation. The study also examine the minimal depth relationship between convex CPWL functions. On polytope neural networks, we investigate several fundamental properties, deriving results equivalent to those of ReLU networks, such as depth inclusions and depth computation from vertices. Notably, we compute the minimal depth of simplices, which is strictly related to the minimal depth conjecture in ReLU networks. ",
    "url": "https://arxiv.org/abs/2402.15315",
    "authors": [
      "Juan L. Valerdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.15324",
    "title": "Shapley Value Based Multi-Agent Reinforcement Learning: Theory, Method  and Its Application to Energy Network",
    "abstract": "Multi-agent reinforcement learning is an area of rapid advancement in artificial intelligence and machine learning. One of the important questions to be answered is how to conduct credit assignment in a multi-agent system. There have been many schemes designed to conduct credit assignment by multi-agent reinforcement learning algorithms. Although these credit assignment schemes have been proved useful in improving the performance of multi-agent reinforcement learning, most of them are designed heuristically without a rigorous theoretic basis and therefore infeasible to understand how agents cooperate. In this thesis, we aim at investigating the foundation of credit assignment in multi-agent reinforcement learning via cooperative game theory. We first extend a game model called convex game and a payoff distribution scheme called Shapley value in cooperative game theory to Markov decision process, named as Markov convex game and Markov Shapley value respectively. We represent a global reward game as a Markov convex game under the grand coalition. As a result, Markov Shapley value can be reasonably used as a credit assignment scheme in the global reward game. Markov Shapley value possesses the following virtues: (i) efficiency; (ii) identifiability of dummy agents; (iii) reflecting the contribution and (iv) symmetry, which form the fair credit assignment. Based on Markov Shapley value, we propose three multi-agent reinforcement learning algorithms called SHAQ, SQDDPG and SMFPPO. Furthermore, we extend Markov convex game to partial observability to deal with the partially observable problems, named as partially observable Markov convex game. In application, we evaluate SQDDPG and SMFPPO on the real-world problem in energy networks. ",
    "url": "https://arxiv.org/abs/2402.15324",
    "authors": [
      "Jianhong Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15331",
    "title": "A Blockchain-Enabled Framework of UAV Coordination for Post-Disaster  Networks",
    "abstract": "Emergency communication is critical but challenging after natural disasters when ground infrastructure is devastated. Unmanned aerial vehicles (UAVs) offer enormous potential for agile relief coordination in these scenarios. However, effectively leveraging UAV fleets poses additional challenges around security, privacy, and efficient collaboration across response agencies. This paper presents a robust blockchain-enabled framework to address these challenges by integrating a consortium blockchain model, smart contracts, and cryptographic techniques to securely coordinate UAV fleets for disaster response. Specifically, we make two key contributions: a consortium blockchain architecture for secure and private multi-agency coordination; and an optimized consensus protocol balancing efficiency and fault tolerance using a delegated proof of stake practical byzantine fault tolerance (DPoS-PBFT). Comprehensive simulations showcase the framework's ability to enhance transparency, automation, scalability, and cyber-attack resilience for UAV coordination in post-disaster networks. ",
    "url": "https://arxiv.org/abs/2402.15331",
    "authors": [
      "Sana Hafeez",
      "Runze Cheng",
      "Lina Mohjazi",
      "Muhammad Ali Imran",
      "Yao Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.15363",
    "title": "Follow the Footprints: Self-supervised Traversability Estimation for  Off-road Vehicle Navigation based on Geometric and Visual Cues",
    "abstract": "In this study, we address the off-road traversability estimation problem, that predicts areas where a robot can navigate in off-road environments. An off-road environment is an unstructured environment comprising a combination of traversable and non-traversable spaces, which presents a challenge for estimating traversability. This study highlights three primary factors that affect a robot's traversability in an off-road environment: surface slope, semantic information, and robot platform. We present two strategies for estimating traversability, using a guide filter network (GFN) and footprint supervision module (FSM). The first strategy involves building a novel GFN using a newly designed guide filter layer. The GFN interprets the surface and semantic information from the input data and integrates them to extract features optimized for traversability estimation. The second strategy involves developing an FSM, which is a self-supervision module that utilizes the path traversed by the robot in pre-driving, also known as a footprint. This enables the prediction of traversability that reflects the characteristics of the robot platform. Based on these two strategies, the proposed method overcomes the limitations of existing methods, which require laborious human supervision and lack scalability. Extensive experiments in diverse conditions, including automobiles and unmanned ground vehicles, herbfields, woodlands, and farmlands, demonstrate that the proposed method is compatible for various robot platforms and adaptable to a range of terrains. Code is available at https://github.com/yurimjeon1892/FtFoot. ",
    "url": "https://arxiv.org/abs/2402.15363",
    "authors": [
      "Yurim Jeon",
      "E In Son",
      "Seung-Woo Seo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.15368",
    "title": "Safe Task Planning for Language-Instructed Multi-Robot Systems using  Conformal Prediction",
    "abstract": "This paper addresses task planning problems for language-instructed robot teams. Tasks are expressed in natural language (NL), requiring the robots to apply their capabilities (e.g., mobility, manipulation, and sensing) at various locations and semantic objects. Several recent works have addressed similar planning problems by leveraging pre-trained Large Language Models (LLMs) to design effective multi-robot plans. However, these approaches lack mission performance and safety guarantees. To address this challenge, we introduce a new decentralized LLM-based planner that is capable of achieving high mission success rates. This is accomplished by leveraging conformal prediction (CP), a distribution-free uncertainty quantification tool in black-box models. CP allows the proposed multi-robot planner to reason about its inherent uncertainty in a decentralized fashion, enabling robots to make individual decisions when they are sufficiently certain and seek help otherwise. We show, both theoretically and empirically, that the proposed planner can achieve user-specified task success rates while minimizing the overall number of help requests. We demonstrate the performance of our approach on multi-robot home service applications. We also show through comparative experiments, that our method outperforms recent centralized and decentralized multi-robot LLM-based planners in terms of in terms of its ability to design correct plans. The advantage of our algorithm over baselines becomes more pronounced with increasing mission complexity and robot team size. ",
    "url": "https://arxiv.org/abs/2402.15368",
    "authors": [
      "Jun Wang",
      "Guocheng He",
      "Yiannis Kantaros"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15374",
    "title": "Outlier detection by ensembling uncertainty with negative objectness",
    "abstract": "Outlier detection is an essential capability in safety-critical applications of supervised visual recognition. Most of the existing methods deliver best results by encouraging standard closed-set models to produce low-confidence predictions in negative training data. However, that approach conflates prediction uncertainty with recognition of the negative class. We therefore reconsider direct prediction of K+1 logits that correspond to K groundtruth classes and one outlier class. This setup allows us to formulate a novel anomaly score as an ensemble of in-distribution uncertainty and the posterior of the outlier class which we term negative objectness. Now outliers can be independently detected due to i) high prediction uncertainty or ii) similarity with negative data. We embed our method into a dense prediction architecture with mask-level recognition over K+2 classes. The training procedure encourages the novel K+2-th class to learn negative objectness at pasted negative instances. Our models outperform the current state-of-the art on standard benchmarks for image-wide and pixel-level outlier detection with and without training on real negative data. ",
    "url": "https://arxiv.org/abs/2402.15374",
    "authors": [
      "Anja Deli\u0107",
      "Matej Grci\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15398",
    "title": "TransFlower: An Explainable Transformer-Based Model with Flow-to-Flow  Attention for Commuting Flow Prediction",
    "abstract": "Understanding the link between urban planning and commuting flows is crucial for guiding urban development and policymaking. This research, bridging computer science and urban studies, addresses the challenge of integrating these fields with their distinct focuses. Traditional urban studies methods, like the gravity and radiation models, often underperform in complex scenarios due to their limited handling of multiple variables and reliance on overly simplistic and unrealistic assumptions, such as spatial isotropy. While deep learning models offer improved accuracy, their black-box nature poses a trade-off between performance and explainability -- both vital for analyzing complex societal phenomena like commuting flows. To address this, we introduce TransFlower, an explainable, transformer-based model employing flow-to-flow attention to predict urban commuting patterns. It features a geospatial encoder with an anisotropy-aware relative location encoder for nuanced flow representation. Following this, the transformer-based flow predictor enhances this by leveraging attention mechanisms to efficiently capture flow interactions. Our model outperforms existing methods by up to 30.8% Common Part of Commuters, offering insights into mobility dynamics crucial for urban planning and policy decisions. ",
    "url": "https://arxiv.org/abs/2402.15398",
    "authors": [
      "Yan Luo",
      "Zhuoyue Wan",
      "Yuzhong Chen",
      "Gengchen Mai",
      "Fu-lai Chung",
      "Kent Larson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.15399",
    "title": "Distributionally Robust Off-Dynamics Reinforcement Learning: Provable  Efficiency with Linear Function Approximation",
    "abstract": "We study off-dynamics Reinforcement Learning (RL), where the policy is trained on a source domain and deployed to a distinct target domain. We aim to solve this problem via online distributionally robust Markov decision processes (DRMDPs), where the learning algorithm actively interacts with the source domain while seeking the optimal performance under the worst possible dynamics that is within an uncertainty set of the source domain's transition kernel. We provide the first study on online DRMDPs with function approximation for off-dynamics RL. We find that DRMDPs' dual formulation can induce nonlinearity, even when the nominal transition kernel is linear, leading to error propagation. By designing a $d$-rectangular uncertainty set using the total variation distance, we remove this additional nonlinearity and bypass the error propagation. We then introduce DR-LSVI-UCB, the first provably efficient online DRMDP algorithm for off-dynamics RL with function approximation, and establish a polynomial suboptimality bound that is independent of the state and action space sizes. Our work makes the first step towards a deeper understanding of the provable efficiency of online DRMDPs with linear function approximation. Finally, we substantiate the performance and robustness of DR-LSVI-UCB through different numerical experiments. ",
    "url": "https://arxiv.org/abs/2402.15399",
    "authors": [
      "Zhishuai Liu",
      "Pan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15400",
    "title": "Faithful Temporal Question Answering over Heterogeneous Sources",
    "abstract": "Temporal question answering (QA) involves time constraints, with phrases such as \"... in 2019\" or \"... before COVID\". In the former, time is an explicit condition, in the latter it is implicit. State-of-the-art methods have limitations along three dimensions. First, with neural inference, time constraints are merely soft-matched, giving room to invalid or inexplicable answers. Second, questions with implicit time are poorly supported. Third, answers come from a single source: either a knowledge base (KB) or a text corpus. We propose a temporal QA system that addresses these shortcomings. First, it enforces temporal constraints for faithful answering with tangible evidence. Second, it properly handles implicit questions. Third, it operates over heterogeneous sources, covering KB, text and web tables in a unified manner. The method has three stages: (i) understanding the question and its temporal conditions, (ii) retrieving evidence from all sources, and (iii) faithfully answering the question. As implicit questions are sparse in prior benchmarks, we introduce a principled method for generating diverse questions. Experiments show superior performance over a suite of baselines. ",
    "url": "https://arxiv.org/abs/2402.15400",
    "authors": [
      "Zhen Jia",
      "Philipp Christmann",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.15404",
    "title": "United We Pretrain, Divided We Fail! Representation Learning for Time  Series by Pretraining on 75 Datasets at Once",
    "abstract": "In natural language processing and vision, pretraining is utilized to learn effective representations. Unfortunately, the success of pretraining does not easily carry over to time series due to potential mismatch between sources and target. Actually, common belief is that multi-dataset pretraining does not work for time series! Au contraire, we introduce a new self-supervised contrastive pretraining approach to learn one encoding from many unlabeled and diverse time series datasets, so that the single learned representation can then be reused in several target domains for, say, classification. Specifically, we propose the XD-MixUp interpolation method and the Soft Interpolation Contextual Contrasting (SICC) loss. Empirically, this outperforms both supervised training and other self-supervised pretraining methods when finetuning on low-data regimes. This disproves the common belief: We can actually learn from multiple time series datasets, even from 75 at once. ",
    "url": "https://arxiv.org/abs/2402.15404",
    "authors": [
      "Maurice Kraus",
      "Felix Divo",
      "David Steinmann",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15406",
    "title": "Conformalized-DeepONet: A Distribution-Free Framework for Uncertainty  Quantification in Deep Operator Networks",
    "abstract": "In this paper, we adopt conformal prediction, a distribution-free uncertainty quantification (UQ) framework, to obtain confidence prediction intervals with coverage guarantees for Deep Operator Network (DeepONet) regression. Initially, we enhance the uncertainty quantification frameworks (B-DeepONet and Prob-DeepONet) previously proposed by the authors by using split conformal prediction. By combining conformal prediction with our Prob- and B-DeepONets, we effectively quantify uncertainty by generating rigorous confidence intervals for DeepONet prediction. Additionally, we design a novel Quantile-DeepONet that allows for a more natural use of split conformal prediction. We refer to this distribution-free effective uncertainty quantification framework as split conformal Quantile-DeepONet regression. Finally, we demonstrate the effectiveness of the proposed methods using various ordinary, partial differential equation numerical examples, and multi-fidelity learning. ",
    "url": "https://arxiv.org/abs/2402.15406",
    "authors": [
      "Christian Moya",
      "Amirhossein Mollaali",
      "Zecheng Zhang",
      "Lu Lu",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.15413",
    "title": "G-RepsNet: A Fast and General Construction of Equivariant Networks for  Arbitrary Matrix Groups",
    "abstract": "Group equivariance is a strong inductive bias useful in a wide range of deep learning tasks. However, constructing efficient equivariant networks for general groups and domains is difficult. Recent work by Finzi et al. (2021) directly solves the equivariance constraint for arbitrary matrix groups to obtain equivariant MLPs (EMLPs). But this method does not scale well and scaling is crucial in deep learning. Here, we introduce Group Representation Networks (G-RepsNets), a lightweight equivariant network for arbitrary matrix groups with features represented using tensor polynomials. The key intuition for our design is that using tensor representations in the hidden layers of a neural network along with simple inexpensive tensor operations can lead to expressive universal equivariant networks. We find G-RepsNet to be competitive to EMLP on several tasks with group symmetries such as O(5), O(1, 3), and O(3) with scalars, vectors, and second-order tensors as data types. On image classification tasks, we find that G-RepsNet using second-order representations is competitive and often even outperforms sophisticated state-of-the-art equivariant models such as GCNNs (Cohen & Welling, 2016a) and E(2)-CNNs (Weiler & Cesa, 2019). To further illustrate the generality of our approach, we show that G-RepsNet is competitive to G-FNO (Helwig et al., 2023) and EGNN (Satorras et al., 2021) on N-body predictions and solving PDEs, respectively, while being efficient. ",
    "url": "https://arxiv.org/abs/2402.15413",
    "authors": [
      "Sourya Basu",
      "Suhas Lohit",
      "Matthew Brand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15429",
    "title": "ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion  Models against Stochastic Perturbation",
    "abstract": "Text-to-Image (T2I) Diffusion Models (DMs) have shown impressive abilities in generating high-quality images based on simple text descriptions. However, as is common with many Deep Learning (DL) models, DMs are subject to a lack of robustness. While there are attempts to evaluate the robustness of T2I DMs as a binary or worst-case problem, they cannot answer how robust in general the model is whenever an adversarial example (AE) can be found. In this study, we first introduce a probabilistic notion of T2I DMs' robustness; and then establish an efficient framework, ProTIP, to evaluate it with statistical guarantees. The main challenges stem from: i) the high computational cost of the generation process; and ii) determining if a perturbed input is an AE involves comparing two output distributions, which is fundamentally harder compared to other DL tasks like classification where an AE is identified upon misprediction of labels. To tackle the challenges, we employ sequential analysis with efficacy and futility early stopping rules in the statistical testing for identifying AEs, and adaptive concentration inequalities to dynamically determine the \"just-right\" number of stochastic perturbations whenever the verification target is met. Empirical experiments validate the effectiveness and efficiency of ProTIP over common T2I DMs. Finally, we demonstrate an application of ProTIP to rank commonly used defence methods. ",
    "url": "https://arxiv.org/abs/2402.15429",
    "authors": [
      "Yi Zhang",
      "Yun Tang",
      "Wenjie Ruan",
      "Xiaowei Huang",
      "Siddartha Khastgir",
      "Paul Jennings",
      "Xingyu Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15430",
    "title": "Hierarchical Invariance for Robust and Interpretable Vision Tasks at  Larger Scales",
    "abstract": "Developing robust and interpretable vision systems is a crucial step towards trustworthy artificial intelligence. In this regard, a promising paradigm considers embedding task-required invariant structures, e.g., geometric invariance, in the fundamental image representation. However, such invariant representations typically exhibit limited discriminability, limiting their applications in larger-scale trustworthy vision tasks. For this open problem, we conduct a systematic investigation of hierarchical invariance, exploring this topic from theoretical, practical, and application perspectives. At the theoretical level, we show how to construct over-complete invariants with a Convolutional Neural Networks (CNN)-like hierarchical architecture yet in a fully interpretable manner. The general blueprint, specific definitions, invariant properties, and numerical implementations are provided. At the practical level, we discuss how to customize this theoretical framework into a given task. With the over-completeness, discriminative features w.r.t. the task can be adaptively formed in a Neural Architecture Search (NAS)-like manner. We demonstrate the above arguments with accuracy, invariance, and efficiency results on texture, digit, and parasite classification experiments. Furthermore, at the application level, our representations are explored in real-world forensics tasks on adversarial perturbations and Artificial Intelligence Generated Content (AIGC). Such applications reveal that the proposed strategy not only realizes the theoretically promised invariance, but also exhibits competitive discriminability even in the era of deep learning. For robust and interpretable vision tasks at larger scales, hierarchical invariant representation can be considered as an effective alternative to traditional CNN and invariants. ",
    "url": "https://arxiv.org/abs/2402.15430",
    "authors": [
      "Shuren Qi",
      "Yushu Zhang",
      "Chao Wang",
      "Zhihua Xia",
      "Jian Weng",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15434",
    "title": "Decoding the Pulse of Community during Disasters: Resilience Analysis  Based on Fluctuations in Latent Lifestyle Signatures within Human Visitation  Networks",
    "abstract": "Examining the impact of disasters on life activities of populations is critical for understanding community resilience dynamics, yet it remains insufficiently studied in the existing literature. In this study, we leveraged data from more than 1.2 million anonymized human mobility communications across 30 parishes in Louisiana to construct a temporal network that tracks visitation to places from which we characterized human lifestyle signatures before, during, and after Hurricane Ida in 2021. Utilizing the motif model, we distilled complex human lifestyles into identifiable patterns and clustered them into classes: commute, healthcare, dining out, and youth-oriented lifestyle. We defined two metrics to evaluate disruption and recovery fluctuations in lifestyle patterns during the perturbation period compared to the steady period: 1) frequency (daily number of motifs), and 2) proximity (daily average distance of motifs). The results indicate significant dynamics in lifestyle patterns due to the hurricane, with essential facilities (e.g., healthcare) demonstrating a swift recovery. The study underscores the heterogeneity of locations visited and the necessity of integrating both essential and non-essential facilities into disaster response initiatives. Furthermore, our study reveals sustained changes in lifestyle patterns, highlighting the long-term impact of the hurricane on daily life. These insights demonstrate the significance of examining lifestyle signatures and their fluctuations in evaluating disaster resilience patterns for affected communities. The outcomes of this study are poised to aid emergency managers and public officials to more effectively evaluate and monitor disaster impacts and recovery based on changes in lifestyle patterns in the community. ",
    "url": "https://arxiv.org/abs/2402.15434",
    "authors": [
      "Junwei Ma",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2402.15444",
    "title": "Unleashing the Power of Imbalanced Modality Information for Multi-modal  Knowledge Graph Completion",
    "abstract": "Multi-modal knowledge graph completion (MMKGC) aims to predict the missing triples in the multi-modal knowledge graphs by incorporating structural, visual, and textual information of entities into the discriminant models. The information from different modalities will work together to measure the triple plausibility. Existing MMKGC methods overlook the imbalance problem of modality information among entities, resulting in inadequate modal fusion and inefficient utilization of the raw modality information. To address the mentioned problems, we propose Adaptive Multi-modal Fusion and Modality Adversarial Training (AdaMF-MAT) to unleash the power of imbalanced modality information for MMKGC. AdaMF-MAT achieves multi-modal fusion with adaptive modality weights and further generates adversarial samples by modality-adversarial training to enhance the imbalanced modality information. Our approach is a co-design of the MMKGC model and training strategy which can outperform 19 recent MMKGC methods and achieve new state-of-the-art results on three public MMKGC benchmarks. Our code and data have been released at https://github.com/zjukg/AdaMF-MAT. ",
    "url": "https://arxiv.org/abs/2402.15444",
    "authors": [
      "Yichi Zhang",
      "Zhuo Chen",
      "Lei Liang",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.15464",
    "title": "CLIPPER+: A Fast Maximal Clique Algorithm for Robust Global Registration",
    "abstract": "We present CLIPPER+, an algorithm for finding maximal cliques in unweighted graphs for outlier-robust global registration. The registration problem can be formulated as a graph and solved by finding its maximum clique. This formulation leads to extreme robustness to outliers; however, finding the maximum clique is an NP-hard problem, and therefore approximation is required in practice for large-size problems. The performance of an approximation algorithm is evaluated by its computational complexity (the lower the runtime, the better) and solution accuracy (how close the solution is to the maximum clique). Accordingly, the main contribution of CLIPPER+ is outperforming the state-of-the-art in accuracy while maintaining a relatively low runtime. CLIPPER+ builds on prior work (CLIPPER [1] and PMC [2]) and prunes the graph by removing vertices that have a small core number and cannot be a part of the maximum clique. This will result in a smaller graph, on which the maximum clique can be estimated considerably faster. We evaluate the performance of CLIPPER+ on standard graph benchmarks, as well as synthetic and real-world point cloud registration problems. These evaluations demonstrate that CLIPPER+ has the highest accuracy and can register point clouds in scenarios where over $99\\%$ of associations are outliers. Our code and evaluation benchmarks are released at https://github.com/ariarobotics/clipperp. ",
    "url": "https://arxiv.org/abs/2402.15464",
    "authors": [
      "Kaveh Fathian",
      "Tyler Summers"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.15469",
    "title": "Benchmarking the Robustness of Panoptic Segmentation for Automated  Driving",
    "abstract": "Precise situational awareness is required for the safe decision-making of assisted and automated driving (AAD) functions. Panoptic segmentation is a promising perception technique to identify and categorise objects, impending hazards, and driveable space at a pixel level. While segmentation quality is generally associated with the quality of the camera data, a comprehensive understanding and modelling of this relationship are paramount for AAD system designers. Motivated by such a need, this work proposes a unifying pipeline to assess the robustness of panoptic segmentation models for AAD, correlating it with traditional image quality. The first step of the proposed pipeline involves generating degraded camera data that reflects real-world noise factors. To this end, 19 noise factors have been identified and implemented with 3 severity levels. Of these factors, this work proposes novel models for unfavourable light and snow. After applying the degradation models, three state-of-the-art CNN- and vision transformers (ViT)-based panoptic segmentation networks are used to analyse their robustness. The variations of the segmentation performance are then correlated to 8 selected image quality metrics. This research reveals that: 1) certain specific noise factors produce the highest impact on panoptic segmentation, i.e. droplets on lens and Gaussian noise; 2) the ViT-based panoptic segmentation backbones show better robustness to the considered noise factors; 3) some image quality metrics (i.e. LPIPS and CW-SSIM) correlate strongly with panoptic segmentation performance and therefore they can be used as predictive metrics for network performance. ",
    "url": "https://arxiv.org/abs/2402.15469",
    "authors": [
      "Yiting Wang",
      "Haonan Zhao",
      "Daniel Gummadi",
      "Mehrdad Dianati",
      "Kurt Debattista",
      "Valentina Donzella"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.15470",
    "title": "Some results involving the $A_\u03b1$-eigenvalues for graphs and line  graphs",
    "abstract": "Let $G$ be a simple graph with adjacency matrix $A(G)$, signless Laplacian matrix $Q(G)$, degree diagonal matrix $D(G)$ and let $l(G)$ be the line graph of $G$. In 2017, Nikiforov defined the $A_\\alpha$-matrix of $G$, $A_\\alpha(G)$, as a linear convex combination of $A(G)$ and $D(G)$, the following way, $A_\\alpha(G):=\\alpha A(G)+(1-\\alpha)D(G),$ where $\\alpha\\in[0,1]$. In this paper, we present some bounds for the eigenvalues of $A_\\alpha(G)$ and for the largest and smallest eigenvalues of $A_\\alpha(l(G))$. Extremal graphs attaining some of these bounds are characterized. ",
    "url": "https://arxiv.org/abs/2402.15470",
    "authors": [
      "Joao Domingos Gomes da Silva Junior",
      "Carla Silva Oliveira",
      "Liliana Manuela Gaspar C. da Costa"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.15480",
    "title": "Retinotopic Mapping Enhances the Robustness of Convolutional Neural  Networks",
    "abstract": "Foveated vision, a trait shared by many animals, including humans, has not been fully utilized in machine learning applications, despite its significant contributions to biological visual function. This study investigates whether retinotopic mapping, a critical component of foveated vision, can enhance image categorization and localization performance when integrated into deep convolutional neural networks (CNNs). Retinotopic mapping was integrated into the inputs of standard off-the-shelf convolutional neural networks (CNNs), which were then retrained on the ImageNet task. As expected, the logarithmic-polar mapping improved the network's ability to handle arbitrary image zooms and rotations, particularly for isolated objects. Surprisingly, the retinotopically mapped network achieved comparable performance in classification. Furthermore, the network demonstrated improved classification localization when the foveated center of the transform was shifted. This replicates a crucial ability of the human visual system that is absent in typical convolutional neural networks (CNNs). These findings suggest that retinotopic mapping may be fundamental to significant preattentive visual processes. ",
    "url": "https://arxiv.org/abs/2402.15480",
    "authors": [
      "Jean-Nicolas J\u00e9r\u00e9mie",
      "Emmanuel Dauc\u00e9",
      "Laurent U Perrinet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2402.15481",
    "title": "Prejudice and Caprice: A Statistical Framework for Measuring Social  Discrimination in Large Language Models",
    "abstract": "The growing integration of large language models (LLMs) into social operations amplifies their impact on decisions in crucial areas such as economics, law, education, and healthcare, raising public concerns about these models' discrimination-related safety and reliability. However, prior discrimination measuring frameworks solely assess the average discriminatory behavior of LLMs, often proving inadequate due to the overlook of an additional discrimination-leading factor, i.e., the LLMs' prediction variation across diverse contexts. In this work, we present the Prejudice-Caprice Framework (PCF) that comprehensively measures discrimination in LLMs by considering both their consistently biased preference and preference variation across diverse contexts. Specifically, we mathematically dissect the aggregated contextualized discrimination risk of LLMs into prejudice risk, originating from LLMs' persistent prejudice, and caprice risk, stemming from their generation inconsistency. In addition, we utilize a data-mining approach to gather preference-detecting probes from sentence skeletons, devoid of attribute indications, to approximate LLMs' applied contexts. While initially intended for assessing discrimination in LLMs, our proposed PCF facilitates the comprehensive and flexible measurement of any inductive biases, including knowledge alongside prejudice, across various modality models. We apply our discrimination-measuring framework to 12 common LLMs, yielding intriguing findings: i) modern LLMs demonstrate significant pro-male stereotypes, ii) LLMs' exhibited discrimination correlates with several social and economic factors, iii) prejudice risk dominates the overall discrimination risk and follows a normal distribution, and iv) caprice risk contributes minimally to the overall risk but follows a fat-tailed distribution, suggesting that it is wild risk requiring enhanced surveillance. ",
    "url": "https://arxiv.org/abs/2402.15481",
    "authors": [
      "Yiran Liu",
      "Ke Yang",
      "Zehan Qi",
      "Xiao Liu",
      "Yang Yu",
      "Chengxiang Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.15485",
    "title": "Graph Partitioning With Limited Moves",
    "abstract": "In many real world networks, there already exists a (not necessarily optimal) $k$-partitioning of the network. Oftentimes, one aims to find a $k$-partitioning with a smaller cut value for such networks by moving only a few nodes across partitions. The number of nodes that can be moved across partitions is often a constraint forced by budgetary limitations. Motivated by such real-world applications, we introduce and study the $r$-move $k$-partitioning~problem, a natural variant of the Multiway cut problem. Given a graph, a set of $k$ terminals and an initial partitioning of the graph, the $r$-move $k$-partitioning~problem aims to find a $k$-partitioning with the minimum-weighted cut among all the $k$-partitionings that can be obtained by moving at most $r$ non-terminal nodes to partitions different from their initial ones. Our main result is a polynomial time $3(r+1)$ approximation algorithm for this problem. We further show that this problem is $W[1]$-hard, and give an FPTAS for when $r$ is a small constant. ",
    "url": "https://arxiv.org/abs/2402.15485",
    "authors": [
      "Majid Behbahani",
      "Mina Dalirrooyfard",
      "Elaheh Fata",
      "Yuriy Nevmyvaka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.15487",
    "title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for  Robotic Manipulation",
    "abstract": "Robots need to explore their surroundings to adapt to and tackle tasks in unknown environments. Prior work has proposed building scene graphs of the environment but typically assumes that the environment is static, omitting regions that require active interactions. This severely limits their ability to handle more complex tasks in household and office environments: before setting up a table, robots must explore drawers and cabinets to locate all utensils and condiments. In this work, we introduce the novel task of interactive scene exploration, wherein robots autonomously explore environments and produce an action-conditioned scene graph (ACSG) that captures the structure of the underlying environment. The ACSG accounts for both low-level information, such as geometry and semantics, and high-level information, such as the action-conditioned relationships between different entities in the scene. To this end, we present the Robotic Exploration (RoboEXP) system, which incorporates the Large Multimodal Model (LMM) and an explicit memory design to enhance our system's capabilities. The robot reasons about what and how to explore an object, accumulating new information through the interaction process and incrementally constructing the ACSG. We apply our system across various real-world settings in a zero-shot manner, demonstrating its effectiveness in exploring and modeling environments it has never seen before. Leveraging the constructed ACSG, we illustrate the effectiveness and efficiency of our RoboEXP system in facilitating a wide range of real-world manipulation tasks involving rigid, articulated objects, nested objects like Matryoshka dolls, and deformable objects like cloth. ",
    "url": "https://arxiv.org/abs/2402.15487",
    "authors": [
      "Hanxiao Jiang",
      "Binghao Huang",
      "Ruihai Wu",
      "Zhuoran Li",
      "Shubham Garg",
      "Hooshang Nayyeri",
      "Shenlong Wang",
      "Yunzhu Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15492",
    "title": "Mechanics-Informed Autoencoder Enables Automated Detection and  Localization of Unforeseen Structural Damage",
    "abstract": "Structural health monitoring (SHM) is vital for ensuring the safety and longevity of structures like buildings and bridges. As the volume and scale of structures and the impact of their failure continue to grow, there is a dire need for SHM techniques that are scalable, inexpensive, operate passively without human intervention, and customized for each mechanical structure without the need for complex baseline models. We present a novel \"deploy-and-forget\" approach for automated detection and localization of damages in structures. It is based on a synergistic combination of fully passive measurements from inexpensive sensors and a mechanics-informed autoencoder. Once deployed, our solution continuously learns and adapts a bespoke baseline model for each structure, learning from its undamaged state's response characteristics. After learning from just 3 hours of data, it can autonomously detect and localize different types of unforeseen damage. Results from numerical simulations and experiments indicate that incorporating the mechanical characteristics into the variational autoencoder allows for up to 35\\% earlier detection and localization of damage over a standard autoencoder. Our approach holds substantial promise for a significant reduction in human intervention and inspection costs and enables proactive and preventive maintenance strategies, thus extending the lifespan, reliability, and sustainability of civil infrastructures. ",
    "url": "https://arxiv.org/abs/2402.15492",
    "authors": [
      "Xuyang Li",
      "Hamed Bolandi",
      "Mahdi Masmoudi",
      "Talal Salem",
      "Nizar Lajnef",
      "Vishnu Naresh Boddeti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.15494",
    "title": "On the Complexity of Community-aware Network Sparsification",
    "abstract": "Network sparsification is the task of reducing the number of edges of a given graph while preserving some crucial graph property. In community-aware network sparsification, the preserved property concerns the subgraphs that are induced by the communities of the graph which are given as vertex subsets. This is formalized in the $\\Pi$-Network Sparsification problem: given an edge-weighted graph $G$, a collection $Z$ of $c$ subsets of $V(G)$ (communities), and two numbers $\\ell, b$, the question is whether there exists a spanning subgraph $G'$ of $G$ with at most $\\ell$ edges of total weight at most $b$ such that $G'[C]$ fulfills $\\Pi$ for each community $C$. Here, we consider two graph properties $\\Pi$: the connectivity property (Connectivity NWS) and the property of having a spanning star (Stars NWS). Since both problems are NP-hard, we study their parameterized and fine-grained complexity. We provide a tight $2^{\\Omega(n^2+c)} poly(n+|Z|)$-time running time lower bound based on the ETH for both problems, where $n$ is the number of vertices in $G$. The lower bound holds even in the restricted case when all communities have size at most 4, $G$ is a clique, and every edge has unit weight. For the connectivity property, the unit weight case with $G$ being a clique is the well-studied problem of computing a hypergraph support with a minimum number of edges. We then study the complexity of both problems parameterized by the feedback edge number $t$ of the solution graph $G'$. For Stars NWS, we present an XP-algorithm for $t$. This answers an open question by Korach and Stern [Disc. Appl. Math. '08] who asked for the existence of polynomial-time algorithms for $t=0$. In contrast, we show for Connectivity NWS that known polynomial-time algorithms for $t=0$ [Korach and Stern, Math. Program. '03; Klemz et al., SWAT '14] cannot be extended by showing that Connectivity NWS is NP-hard for $t=1$. ",
    "url": "https://arxiv.org/abs/2402.15494",
    "authors": [
      "Emanuel Herrendorf",
      "Christian Komusiewicz",
      "Nils Morawietz",
      "Frank Sommer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.14877",
    "title": "Machine-learning prediction of tipping and collapse of the Atlantic  Meridional Overturning Circulation",
    "abstract": "Recent research on the Atlantic Meridional Overturning Circulation (AMOC) raised concern about its potential collapse through a tipping point due to the climate-change caused increase in the freshwater input into the North Atlantic. The predicted time window of collapse is centered about the middle of the century and the earliest possible start is approximately two years from now. More generally, anticipating a tipping point at which the system transitions from one stable steady state to another is relevant to a broad range of fields. We develop a machine-learning approach to predicting tipping in noisy dynamical systems with a time-varying parameter and test it on a number of systems including the AMOC, ecological networks, an electrical power system, and a climate model. For the AMOC, our prediction based on simulated fingerprint data and real data of the sea surface temperature places the time window of a potential collapse between the years 2040 and 2065. ",
    "url": "https://arxiv.org/abs/2402.14877",
    "authors": [
      "Shirin Panahi",
      "Ling-Wei Kong",
      "Mohammadamin Moradi",
      "Zheng-Meng Zhai",
      "Bryan Glaz",
      "Mulugeta Haile",
      "Ying-Cheng Lai"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Popular Physics (physics.pop-ph)"
    ]
  },
  {
    "id": "arXiv:2402.14892",
    "title": "Novelty Detection on Radio Astronomy Data using Signatures",
    "abstract": "We introduce SigNova, a new semi-supervised framework for detecting anomalies in streamed data. While our initial examples focus on detecting radio-frequency interference (RFI) in digitized signals within the field of radio astronomy, it is important to note that SigNova's applicability extends to any type of streamed data. The framework comprises three primary components. Firstly, we use the signature transform to extract a canonical collection of summary statistics from observational sequences. This allows us to represent variable-length visibility samples as finite-dimensional feature vectors. Secondly, each feature vector is assigned a novelty score, calculated as the Mahalanobis distance to its nearest neighbor in an RFI-free training set. By thresholding these scores we identify observation ranges that deviate from the expected behavior of RFI-free visibility samples without relying on stringent distributional assumptions. Thirdly, we integrate this anomaly detector with Pysegments, a segmentation algorithm, to localize consecutive observations contaminated with RFI, if any. This approach provides a compelling alternative to classical windowing techniques commonly used for RFI detection. Importantly, the complexity of our algorithm depends on the RFI pattern rather than on the size of the observation window. We demonstrate how SigNova improves the detection of various types of RFI (e.g., broadband and narrowband) in time-frequency visibility data. We validate our framework on the Murchison Widefield Array (MWA) telescope and simulated data and the Hydrogen Epoch of Reionization Array (HERA). ",
    "url": "https://arxiv.org/abs/2402.14892",
    "authors": [
      "Paola Arrubarrena",
      "Maud Lemercier",
      "Bojan Nikolic",
      "Terry Lyons",
      "Thomas Cass"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14959",
    "title": "A Causal Framework to Evaluate Racial Bias in Law Enforcement Systems",
    "abstract": "We are interested in developing a data-driven method to evaluate race-induced biases in law enforcement systems. While the recent works have addressed this question in the context of police-civilian interactions using police stop data, they have two key limitations. First, bias can only be properly quantified if true criminality is accounted for in addition to race, but it is absent in prior works. Second, law enforcement systems are multi-stage and hence it is important to isolate the true source of bias within the \"causal chain of interactions\" rather than simply focusing on the end outcome; this can help guide reforms. In this work, we address these challenges by presenting a multi-stage causal framework incorporating criminality. We provide a theoretical characterization and an associated data-driven method to evaluate (a) the presence of any form of racial bias, and (b) if so, the primary source of such a bias in terms of race and criminality. Our framework identifies three canonical scenarios with distinct characteristics: in settings like (1) airport security, the primary source of observed bias against a race is likely to be bias in law enforcement against innocents of that race; (2) AI-empowered policing, the primary source of observed bias against a race is likely to be bias in law enforcement against criminals of that race; and (3) police-civilian interaction, the primary source of observed bias against a race could be bias in law enforcement against that race or bias from the general public in reporting against the other race. Through an extensive empirical study using police-civilian interaction data and 911 call data, we find an instance of such a counter-intuitive phenomenon: in New Orleans, the observed bias is against the majority race and the likely reason for it is the over-reporting (via 911 calls) of incidents involving the minority race by the general public. ",
    "url": "https://arxiv.org/abs/2402.14959",
    "authors": [
      "Fotini Christia",
      "Jessy Xinyi Han",
      "Andrew Miller",
      "Devavrat Shah",
      "S. Craig Watkins",
      "Christopher Winship"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.15034",
    "title": "Rectilinear Crossing Number of Graphs Excluding Single-Crossing Graphs  as Minors",
    "abstract": "The crossing number of a graph $G$ is the minimum number of crossings in a drawing of $G$ in the plane. A rectilinear drawing of a graph $G$ represents vertices of $G$ by a set of points in the plane and represents each edge of $G$ by a straight-line segment connecting its two endpoints. The rectilinear crossing number of $G$ is the minimum number of crossings in a rectilinear drawing of $G$. By the crossing lemma, the crossing number of an $n$-vertex graph $G$ can be $O(n)$ only if $|E(G)|\\in O(n)$. Graphs of bounded genus and bounded degree (B\\\"{o}r\\\"{o}czky, Pach and T\\'{o}th, 2006) and in fact all bounded degree proper minor-closed families (Wood and Telle, 2007) have been shown to admit linear crossing number, with tight $\\Theta(\\Delta n)$ bound shown by Dujmovi\\'c, Kawarabayashi, Mohar and Wood, 2008. Much less is known about rectilinear crossing number. It is not bounded by any function of the crossing number. We prove that graphs that exclude a single-crossing graph as a minor have the rectilinear crossing number $O(\\Delta n)$. This dependence on $n$ and $\\Delta$ is best possible. A single-crossing graph is a graph whose crossing number is at most one. Thus the result applies to $K_5$-minor-free graphs, for example. It also applies to bounded treewidth graphs, since each family of bounded treewidth graphs excludes some fixed planar graph as a minor. Prior to our work, the only bounded degree minor-closed families known to have linear rectilinear crossing number were bounded degree graphs of bounded treewidth (Wood and Telle, 2007), as well as, bounded degree $K_{3,3}$-minor-free graphs (Dujmovi\\'c, Kawarabayashi, Mohar and Wood, 2008). In the case of bounded treewidth graphs, our $O(\\Delta n)$ result is again tight and improves on the previous best known bound of $O(\\Delta^2 n)$ by Wood and Telle, 2007 (obtained for convex geometric drawings). ",
    "url": "https://arxiv.org/abs/2402.15034",
    "authors": [
      "Vida Dujmovi\u0107",
      "Camille La Rose"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2402.15214",
    "title": "ChildAugment: Data Augmentation Methods for Zero-Resource Children's  Speaker Verification",
    "abstract": "The accuracy of modern automatic speaker verification (ASV) systems, when trained exclusively on adult data, drops substantially when applied to children's speech. The scarcity of children's speech corpora hinders fine-tuning ASV systems for children's speech. Hence, there is a timely need to explore more effective ways of reusing adults' speech data. One promising approach is to align vocal-tract parameters between adults and children through children-specific data augmentation, referred here to as ChildAugment. Specifically, we modify the formant frequencies and formant bandwidths of adult speech to emulate children's speech. The modified spectra are used to train ECAPA-TDNN (emphasized channel attention, propagation, and aggregation in time-delay neural network) recognizer for children. We compare ChildAugment against various state-of-the-art data augmentation techniques for children's ASV. We also extensively compare different scoring methods, including cosine scoring, PLDA (probabilistic linear discriminant analysis), and NPLDA (neural PLDA). We also propose a low-complexity weighted cosine score for extremely low-resource children ASV. Our findings on the CSLU kids corpus indicate that ChildAugment holds promise as a simple, acoustics-motivated approach, for improving state-of-the-art deep learning based ASV for children. We achieve up to 12.45% (boys) and 11.96% (girls) relative improvement over the baseline. ",
    "url": "https://arxiv.org/abs/2402.15214",
    "authors": [
      "Vishwanath Pratap Singh",
      "Md Sahidullah",
      "Tomi Kinnunen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.15246",
    "title": "Artificial Bee Colony optimization of Deep Convolutional Neural Networks  in the context of Biomedical Imaging",
    "abstract": "Most efforts in Computer Vision focus on natural images or artwork, which differ significantly both in size and contents from the kind of data biomedical image processing deals with. Thus, Transfer Learning models often prove themselves suboptimal for these tasks, even after manual finetuning. The development of architectures from scratch is oftentimes unfeasible due to the vastness of the hyperparameter space and a shortage of time, computational resources and Deep Learning experts in most biomedical research laboratories. An alternative to manually defining the models is the use of Neuroevolution, which employs metaheuristic techniques to optimize Deep Learning architectures. However, many algorithms proposed in the neuroevolutive literature are either too unreliable or limited to a small, predefined region of the hyperparameter space. To overcome these shortcomings, we propose the Chimera Algorithm, a novel, hybrid neuroevolutive algorithm that integrates the Artificial Bee Colony Algorithm with Evolutionary Computation tools to generate models from scratch, as well as to refine a given previous architecture to better fit the task at hand. The Chimera Algorithm has been validated with two datasets of natural and medical images, producing models that surpassed the performance of those coming from Transfer Learning. ",
    "url": "https://arxiv.org/abs/2402.15246",
    "authors": [
      "Adri Gomez Martin",
      "Carlos Fernandez del Cerro",
      "Monica Abella Garcia",
      "Manuel Desco Menendez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.15335",
    "title": "Low-Rank Representations Meets Deep Unfolding: A Generalized and  Interpretable Network for Hyperspectral Anomaly Detection",
    "abstract": "Current hyperspectral anomaly detection (HAD) benchmark datasets suffer from low resolution, simple background, and small size of the detection data. These factors also limit the performance of the well-known low-rank representation (LRR) models in terms of robustness on the separation of background and target features and the reliance on manual parameter selection. To this end, we build a new set of HAD benchmark datasets for improving the robustness of the HAD algorithm in complex scenarios, AIR-HAD for short. Accordingly, we propose a generalized and interpretable HAD network by deeply unfolding a dictionary-learnable LLR model, named LRR-Net$^+$, which is capable of spectrally decoupling the background structure and object properties in a more generalized fashion and eliminating the bias introduced by vital interference targets concurrently. In addition, LRR-Net$^+$ integrates the solution process of the Alternating Direction Method of Multipliers (ADMM) optimizer with the deep network, guiding its search process and imparting a level of interpretability to parameter optimization. Additionally, the integration of physical models with DL techniques eliminates the need for manual parameter tuning. The manually tuned parameters are seamlessly transformed into trainable parameters for deep neural networks, facilitating a more efficient and automated optimization process. Extensive experiments conducted on the AIR-HAD dataset show the superiority of our LRR-Net$^+$ in terms of detection performance and generalization ability, compared to top-performing rivals. Furthermore, the compilable codes and our AIR-HAD benchmark datasets in this paper will be made available freely and openly at \\url{https://sites.google.com/view/danfeng-hong}. ",
    "url": "https://arxiv.org/abs/2402.15335",
    "authors": [
      "Chenyu Li",
      "Bing Zhang",
      "Danfeng Hong",
      "Jing Yao",
      "Jocelyn Chanussot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1905.00517",
    "title": "From Abstractions to Grounded Languages for Robust Coordination of Task  Planning Robots",
    "abstract": " Comments: A short version of this paper appears as an extended abstract at AAMAS 2023 ",
    "url": "https://arxiv.org/abs/1905.00517",
    "authors": [
      "Yu Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.08620",
    "title": "Adversarial Examples Detection with Bayesian Neural Network",
    "abstract": " Title: Adversarial Examples Detection with Bayesian Neural Network ",
    "url": "https://arxiv.org/abs/2105.08620",
    "authors": [
      "Yao Li",
      "Tongyi Tang",
      "Cho-Jui Hsieh",
      "Thomas C. M. Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.06257",
    "title": "Causal Discovery from Conditionally Stationary Time Series",
    "abstract": " Title: Causal Discovery from Conditionally Stationary Time Series ",
    "url": "https://arxiv.org/abs/2110.06257",
    "authors": [
      "Carles Balsells-Rodas",
      "Ruibo Tu",
      "Hedvig Kjellstrom",
      "Yingzhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.13847",
    "title": "Cluster Algebras: Network Science and Machine Learning",
    "abstract": " Comments: 38 pages, 27 figures ",
    "url": "https://arxiv.org/abs/2203.13847",
    "authors": [
      "Pierre-Philippe Dechant",
      "Yang-Hui He",
      "Elli Heyes",
      "Edward Hirst"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Algebraic Geometry (math.AG)"
    ]
  },
  {
    "id": "arXiv:2204.13704",
    "title": "Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction  in Low Dimensions",
    "abstract": " Title: Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction  in Low Dimensions ",
    "url": "https://arxiv.org/abs/2204.13704",
    "authors": [
      "Wenjie Zheng",
      "Wenxue Wang",
      "Shu Zhao",
      "Fulan Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.07924",
    "title": "GNNInterpreter: A Probabilistic Generative Model-Level Explanation for  Graph Neural Networks",
    "abstract": " Title: GNNInterpreter: A Probabilistic Generative Model-Level Explanation for  Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2209.07924",
    "authors": [
      "Xiaoqi Wang",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11924",
    "title": "Interventional Causal Representation Learning",
    "abstract": " Title: Interventional Causal Representation Learning ",
    "url": "https://arxiv.org/abs/2209.11924",
    "authors": [
      "Kartik Ahuja",
      "Divyat Mahajan",
      "Yixin Wang",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14568",
    "title": "BeGin: Extensive Benchmark Scenarios and An Easy-to-use Framework for  Graph Continual Learning",
    "abstract": " Title: BeGin: Extensive Benchmark Scenarios and An Easy-to-use Framework for  Graph Continual Learning ",
    "url": "https://arxiv.org/abs/2211.14568",
    "authors": [
      "Jihoon Ko",
      "Shinhwan Kang",
      "Taehyung Kwon",
      "Heechan Moon",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09400",
    "title": "Medical Knowledge Graph QA for Drug-Drug Interaction Prediction based on  Multi-hop Machine Reading Comprehension",
    "abstract": " Title: Medical Knowledge Graph QA for Drug-Drug Interaction Prediction based on  Multi-hop Machine Reading Comprehension ",
    "url": "https://arxiv.org/abs/2212.09400",
    "authors": [
      "Peng Gao",
      "Feng Gao",
      "Jian-Cheng Ni",
      "Yu Wang",
      "Fei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.12292",
    "title": "Zero-shot causal learning",
    "abstract": " Title: Zero-shot causal learning ",
    "url": "https://arxiv.org/abs/2301.12292",
    "authors": [
      "Hamed Nilforoshan",
      "Michael Moor",
      "Yusuf Roohani",
      "Yining Chen",
      "Anja \u0160urina",
      "Michihiro Yasunaga",
      "Sara Oblak",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.00288",
    "title": "CoderEval: A Benchmark of Pragmatic Code Generation with Generative  Pre-trained Models",
    "abstract": " Title: CoderEval: A Benchmark of Pragmatic Code Generation with Generative  Pre-trained Models ",
    "url": "https://arxiv.org/abs/2302.00288",
    "authors": [
      "Hao Yu",
      "Bo Shen",
      "Dezhi Ran",
      "Jiaxin Zhang",
      "Qi Zhang",
      "Yuchi Ma",
      "Guangtai Liang",
      "Ying Li",
      "Qianxiang Wang",
      "Tao Xie"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.00834",
    "title": "Sharp Lower Bounds on Interpolation by Deep ReLU Neural Networks at  Irregularly Spaced Data",
    "abstract": " Title: Sharp Lower Bounds on Interpolation by Deep ReLU Neural Networks at  Irregularly Spaced Data ",
    "url": "https://arxiv.org/abs/2302.00834",
    "authors": [
      "Jonathan W. Siegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05279",
    "title": "Can large language models build causal graphs?",
    "abstract": " Comments: Peer reviewed and accepted for presentation at the Causal Machine Learning for Real-World Impact Workshop (CML4Impact) at NeuRIPs2022 Fixed author list ",
    "url": "https://arxiv.org/abs/2303.05279",
    "authors": [
      "Stephanie Long",
      "Tibor Schuster",
      "Alexandre Pich\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.15103",
    "title": "Contrastive Learning Is Spectral Clustering On Similarity Graph",
    "abstract": " Comments: ICLR 2024; We express our gratitude to the anonymous reviewers for their valuable feedback ",
    "url": "https://arxiv.org/abs/2303.15103",
    "authors": [
      "Zhiquan Tan",
      "Yifan Zhang",
      "Jingqin Yang",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16749",
    "title": "Improving Code Generation by Training with Natural Language Feedback",
    "abstract": " Comments: Published in (and superceded by) TMLR: this https URL ",
    "url": "https://arxiv.org/abs/2303.16749",
    "authors": [
      "Angelica Chen",
      "J\u00e9r\u00e9my Scheurer",
      "Tomasz Korbak",
      "Jon Ander Campos",
      "Jun Shern Chan",
      "Samuel R. Bowman",
      "Kyunghyun Cho",
      "Ethan Perez"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.05949",
    "title": "CMOS + stochastic nanomagnets: heterogeneous computers for probabilistic  inference and learning",
    "abstract": " Title: CMOS + stochastic nanomagnets: heterogeneous computers for probabilistic  inference and learning ",
    "url": "https://arxiv.org/abs/2304.05949",
    "authors": [
      "Nihal Sanjay Singh",
      "Keito Kobayashi",
      "Qixuan Cao",
      "Kemal Selcuk",
      "Tianrui Hu",
      "Shaila Niazi",
      "Navid Anjum Aadit",
      "Shun Kanai",
      "Hideo Ohno",
      "Shunsuke Fukami",
      "Kerem Y. Camsari"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.03237",
    "title": "Out-of-Domain Intent Detection Considering Multi-Turn Dialogue Contexts",
    "abstract": " Comments: COLING2024 Long Paper ",
    "url": "https://arxiv.org/abs/2305.03237",
    "authors": [
      "Hao Lang",
      "Yinhe Zheng",
      "Binyuan Hui",
      "Fei Huang",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.05448",
    "title": "Robust Implicit Regularization via Weight Normalization",
    "abstract": " Title: Robust Implicit Regularization via Weight Normalization ",
    "url": "https://arxiv.org/abs/2305.05448",
    "authors": [
      "Hung-Hsu Chou",
      "Holger Rauhut",
      "Rachel Ward"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.14828",
    "title": "Towards Few-shot Entity Recognition in Document Images: A Graph Neural  Network Approach Robust to Image Manipulation",
    "abstract": " Title: Towards Few-shot Entity Recognition in Document Images: A Graph Neural  Network Approach Robust to Image Manipulation ",
    "url": "https://arxiv.org/abs/2305.14828",
    "authors": [
      "Prashant Krishnan",
      "Zilong Wang",
      "Yangkun Wang",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15060",
    "title": "Who Wrote this Code? Watermarking for Code Generation",
    "abstract": " Title: Who Wrote this Code? Watermarking for Code Generation ",
    "url": "https://arxiv.org/abs/2305.15060",
    "authors": [
      "Taehyun Lee",
      "Seokhee Hong",
      "Jaewoo Ahn",
      "Ilgee Hong",
      "Hwaran Lee",
      "Sangdoo Yun",
      "Jamin Shin",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17443",
    "title": "Resilience in Platoons of Cooperative Heterogeneous Vehicles:  Self-organization Strategies and Provably-correct Design",
    "abstract": " Title: Resilience in Platoons of Cooperative Heterogeneous Vehicles:  Self-organization Strategies and Provably-correct Design ",
    "url": "https://arxiv.org/abs/2305.17443",
    "authors": [
      "Di Liu",
      "Sebastian Mair",
      "Kang Yang",
      "Simone Baldi",
      "Paolo Frasca",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.17510",
    "title": "A Hybrid Quantum-Classical Approach based on the Hadamard Transform for  the Convolutional Layer",
    "abstract": " Comments: To be presented at International Conference on Machine Learning (ICML), 2023 ",
    "url": "https://arxiv.org/abs/2305.17510",
    "authors": [
      "Hongyi Pan",
      "Xin Zhu",
      "Salih Atici",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.02117",
    "title": "Oversmoothing: A Nightmare for Graph Contrastive Learning?",
    "abstract": " Comments: Technical report; Code available at this https URL ",
    "url": "https://arxiv.org/abs/2306.02117",
    "authors": [
      "Jintang Li",
      "Wangbin Sun",
      "Ruofan Wu",
      "Yuchang Zhu",
      "Liang Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.04366",
    "title": "Enhancing Worker Recruitment in Collaborative Mobile Crowdsourcing: A  Graph Neural Network Trust Evaluation Approach",
    "abstract": " Title: Enhancing Worker Recruitment in Collaborative Mobile Crowdsourcing: A  Graph Neural Network Trust Evaluation Approach ",
    "url": "https://arxiv.org/abs/2306.04366",
    "authors": [
      "Zhongwei Zhan",
      "Yingjie Wang",
      "Peiyong Duan",
      "Akshita Maradapu Vera Venkata Sai",
      "Zhaowei Liu",
      "Chaocan Xiang",
      "Xiangrong Tong",
      "Weilong Wang",
      "Zhipeng Cai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.09541",
    "title": "Validating AI-Generated Code with Live Programming",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2306.09541",
    "authors": [
      "Kasra Ferdowsi",
      "Ruanqianqian Huang",
      "Michael B. James",
      "Nadia Polikarpova",
      "Sorin Lerner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2306.11828",
    "title": "Near-Optimal Dynamic Rounding of Fractional Matchings in Bipartite  Graphs",
    "abstract": " Comments: Full version of STOC 2024 paper ",
    "url": "https://arxiv.org/abs/2306.11828",
    "authors": [
      "Sayan Bhattacharya",
      "Peter Kiss",
      "Aaron Sidford",
      "David Wajc"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.13292",
    "title": "Variance-Covariance Regularization Improves Representation Learning",
    "abstract": " Comments: 165 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2306.13292",
    "authors": [
      "Jiachen Zhu",
      "Katrina Evtimova",
      "Yubei Chen",
      "Ravid Shwartz-Ziv",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08672",
    "title": "FedDefender: Backdoor Attack Defense in Federated Learning",
    "abstract": " Comments: Published in SE4SafeML 2023 (co-located with FSE 2023). See this https URL ",
    "url": "https://arxiv.org/abs/2307.08672",
    "authors": [
      "Waris Gill",
      "Ali Anwar",
      "Muhammad Ali Gulzar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11565",
    "title": "Adversarial Feature Map Pruning for Backdoor",
    "abstract": " Comments: Accepted to ICLR 2024 ",
    "url": "https://arxiv.org/abs/2307.11565",
    "authors": [
      "Dong Huang",
      "Qingwen Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.11792",
    "title": "Quantum Convolutional Neural Networks with Interaction Layers for  Classification of Classical Data",
    "abstract": " Comments: 31 pages, 13 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2307.11792",
    "authors": [
      "Jishnu Mahmud",
      "Raisa Mashtura",
      "Shaikh Anowarul Fattah",
      "Mohammad Saquib"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01054",
    "title": "Simulation-based inference using surjective sequential neural likelihood  estimation",
    "abstract": " Title: Simulation-based inference using surjective sequential neural likelihood  estimation ",
    "url": "https://arxiv.org/abs/2308.01054",
    "authors": [
      "Simon Dirmeier",
      "Carlo Albert",
      "Fernando Perez-Cruz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2308.06338",
    "title": "Size Lowerbounds for Deep Operator Networks",
    "abstract": " Comments: 25 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2308.06338",
    "authors": [
      "Anirbit Mukherjee",
      "Amartya Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.08784",
    "title": "CodeCoT: Tackling Code Syntax Errors in CoT Reasoning for Code  Generation",
    "abstract": " Comments: Title changed ",
    "url": "https://arxiv.org/abs/2308.08784",
    "authors": [
      "Dong Huang",
      "Qingwen Bu",
      "Yuhao Qing",
      "Heming Cui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10001",
    "title": "AltNeRF: Learning Robust Neural Radiance Field via Alternating  Depth-Pose Optimization",
    "abstract": " Comments: Accepted by AAAI-24 ",
    "url": "https://arxiv.org/abs/2308.10001",
    "authors": [
      "Kun Wang",
      "Zhiqiang Yan",
      "Huang Tian",
      "Zhenyu Zhang",
      "Xiang Li",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10779",
    "title": "Spear and Shield: Adversarial Attacks and Defense Methods for  Model-Based Link Prediction on Continuous-Time Dynamic Graphs",
    "abstract": " Comments: Published at AAAI 2024 ",
    "url": "https://arxiv.org/abs/2308.10779",
    "authors": [
      "Dongjin Lee",
      "Juho Lee",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.12215",
    "title": "The Challenges of Machine Learning for Trust and Safety: A Case Study on  Misinformation Detection",
    "abstract": " Title: The Challenges of Machine Learning for Trust and Safety: A Case Study on  Misinformation Detection ",
    "url": "https://arxiv.org/abs/2308.12215",
    "authors": [
      "Madelyne Xiao",
      "Jonathan Mayer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.08849",
    "title": "Learning a Stable Dynamic System with a Lyapunov Energy Function for  Demonstratives Using Neural Networks",
    "abstract": " Title: Learning a Stable Dynamic System with a Lyapunov Energy Function for  Demonstratives Using Neural Networks ",
    "url": "https://arxiv.org/abs/2309.08849",
    "authors": [
      "Yu Zhang",
      "Yongxiang Zou",
      "Haoyu Zhang",
      "Xiuze Xia",
      "Long Cheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09814",
    "title": "Convolutional Deep Kernel Machines",
    "abstract": " Comments: ICLR 2024 Camera Ready Version ",
    "url": "https://arxiv.org/abs/2309.09814",
    "authors": [
      "Edward Milsom",
      "Ben Anson",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02861",
    "title": "Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly  Detection",
    "abstract": " Title: Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2310.02861",
    "authors": [
      "Xiangyu Dong",
      "Xingyi Zhang",
      "Sibo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05668",
    "title": "LARA: A Light and Anti-overfitting Retraining Approach for Unsupervised  Time Series Anomaly Detection",
    "abstract": " Comments: Accepted by ACM Web Conference 2024 (WWW 24) ",
    "url": "https://arxiv.org/abs/2310.05668",
    "authors": [
      "Feiyi Chen",
      "Zhen Qin",
      "Yingying Zhang",
      "Shuiguang Deng",
      "Yi Xiao",
      "Guansong Pang",
      "Qingsong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00888",
    "title": "A robust shape model for blood vessels analysis",
    "abstract": " Title: A robust shape model for blood vessels analysis ",
    "url": "https://arxiv.org/abs/2311.00888",
    "authors": [
      "Pau Romero",
      "Abel Pedr\u00f3s",
      "Rafael Sebastian",
      "Miguel Lozano",
      "Ignacio Garc\u00eda-Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2311.07215",
    "title": "Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2311.07215",
    "authors": [
      "Seungjun Moon",
      "Hyungjoo Chae",
      "Yongho Song",
      "Taeyoon Kwon",
      "Dongjin Kang",
      "Kai Tzu-iunn Ong",
      "Seung-won Hwang",
      "Jinyoung Yeo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.08045",
    "title": "Adversarial Preference Optimization",
    "abstract": " Comments: In process ",
    "url": "https://arxiv.org/abs/2311.08045",
    "authors": [
      "Pengyu Cheng",
      "Yifan Yang",
      "Jian Li",
      "Yong Dai",
      "Tianhao Hu",
      "Peixin Cao",
      "Nan Du"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10788",
    "title": "Efficient Temporally-Aware DeepFake Detection using H.264 Motion Vectors",
    "abstract": " Title: Efficient Temporally-Aware DeepFake Detection using H.264 Motion Vectors ",
    "url": "https://arxiv.org/abs/2311.10788",
    "authors": [
      "Peter Gr\u00f6nquist",
      "Yufan Ren",
      "Qingyi He",
      "Alessio Verardo",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12943",
    "title": "InteRACT: Transformer Models for Human Intent Prediction Conditioned on  Robot Actions",
    "abstract": " Title: InteRACT: Transformer Models for Human Intent Prediction Conditioned on  Robot Actions ",
    "url": "https://arxiv.org/abs/2311.12943",
    "authors": [
      "Kushal Kedia",
      "Atiksh Bhardwaj",
      "Prithwish Dan",
      "Sanjiban Choudhury"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.17852",
    "title": "A Computing-in-Memory-based One-Class Hyperdimensional Computing Model  for Outlier Detection",
    "abstract": " Title: A Computing-in-Memory-based One-Class Hyperdimensional Computing Model  for Outlier Detection ",
    "url": "https://arxiv.org/abs/2311.17852",
    "authors": [
      "Ruixuan Wang",
      "Sabrina Hassan Moon",
      "Xiaobo Sharon Hu",
      "Xun Jiao",
      "Dayane Reis"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2312.10743",
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language  Models",
    "abstract": " Comments: submited to TOIS ",
    "url": "https://arxiv.org/abs/2312.10743",
    "authors": [
      "Zichuan Fu",
      "Xiangyang Li",
      "Chuhan Wu",
      "Yichao Wang",
      "Kuicai Dong",
      "Xiangyu Zhao",
      "Mengchen Zhao",
      "Huifeng Guo",
      "Ruiming Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2401.02602",
    "title": "Neural Causal Abstractions",
    "abstract": " Comments: 48 total pages, 20 figures, short version accepted to AAAI-24 ",
    "url": "https://arxiv.org/abs/2401.02602",
    "authors": [
      "Kevin Xia",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.03855",
    "title": "PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLM",
    "abstract": " Title: PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLM ",
    "url": "https://arxiv.org/abs/2401.03855",
    "authors": [
      "Ankit Yadav",
      "Mayank Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04829",
    "title": "GNNShap: Scalable and Accurate GNN Explanation using Shapley Values",
    "abstract": " Title: GNNShap: Scalable and Accurate GNN Explanation using Shapley Values ",
    "url": "https://arxiv.org/abs/2401.04829",
    "authors": [
      "Selahattin Akkas",
      "Ariful Azad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.17791",
    "title": "Graph Transformers without Positional Encodings",
    "abstract": " Comments: Independent Research ",
    "url": "https://arxiv.org/abs/2401.17791",
    "authors": [
      "Ayush Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01596",
    "title": "Immersive Video Compression using Implicit Neural Representations",
    "abstract": " Title: Immersive Video Compression using Implicit Neural Representations ",
    "url": "https://arxiv.org/abs/2402.01596",
    "authors": [
      "Ho Man Kwan",
      "Fan Zhang",
      "Andrew Gower",
      "David Bull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02389",
    "title": "KICGPT: Large Language Model with Knowledge in Context for Knowledge  Graph Completion",
    "abstract": " Comments: Accepted to EMNLP 2023 Findings ",
    "url": "https://arxiv.org/abs/2402.02389",
    "authors": [
      "Yanbin Wei",
      "Qiushi Huang",
      "James T. Kwok",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.03910",
    "title": "Understanding Trends, Patterns, and Dynamics in Global Acquisitions: A  Network Perspective",
    "abstract": " Title: Understanding Trends, Patterns, and Dynamics in Global Acquisitions: A  Network Perspective ",
    "url": "https://arxiv.org/abs/2402.03910",
    "authors": [
      "Ghazal Kalhor",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.05980",
    "title": "Do Large Code Models Understand Programming Concepts? A Black-box  Approach",
    "abstract": " Title: Do Large Code Models Understand Programming Concepts? A Black-box  Approach ",
    "url": "https://arxiv.org/abs/2402.05980",
    "authors": [
      "Ashish Hooda",
      "Mihai Christodorescu",
      "Miltiadis Allamanis",
      "Aaron Wilson",
      "Kassem Fawaz",
      "Somesh Jha"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.10877",
    "title": "Robust agents learn causal world models",
    "abstract": " Comments: ICLR 2024 (oral) ",
    "url": "https://arxiv.org/abs/2402.10877",
    "authors": [
      "Jonathan Richens",
      "Tom Everitt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11621",
    "title": "Decoding News Narratives: A Critical Analysis of Large Language Models  in Framing Bias Detection",
    "abstract": " Title: Decoding News Narratives: A Critical Analysis of Large Language Models  in Framing Bias Detection ",
    "url": "https://arxiv.org/abs/2402.11621",
    "authors": [
      "Valeria Pastorino",
      "Jasivan A. Sivakumar",
      "Nafise Sadat Moosavi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.11641",
    "title": "Towards Versatile Graph Learning Approach: from the Perspective of Large  Language Models",
    "abstract": " Title: Towards Versatile Graph Learning Approach: from the Perspective of Large  Language Models ",
    "url": "https://arxiv.org/abs/2402.11641",
    "authors": [
      "Lanning Wei",
      "Jun Gao",
      "Huan Zhao",
      "Quanming Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12269",
    "title": "End-to-end Supervised Prediction of Arbitrary-size Graphs with  Partially-Masked Fused Gromov-Wasserstein Matching",
    "abstract": " Comments: 17 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2402.12269",
    "authors": [
      "Paul Krzakala",
      "Junjie Yang",
      "R\u00e9mi Flamary",
      "Florence d'Alch\u00e9-Buc",
      "Charlotte Laclau",
      "Matthieu Labeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12777",
    "title": "Application of Quantum Extreme Learning Machines for QoS Prediction of  Elevators' Software in an Industrial Context",
    "abstract": " Title: Application of Quantum Extreme Learning Machines for QoS Prediction of  Elevators' Software in an Industrial Context ",
    "url": "https://arxiv.org/abs/2402.12777",
    "authors": [
      "Xinyi Wang",
      "Shaukat Ali",
      "Aitor Arrieta",
      "Paolo Arcaini",
      "Maite Arratibel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.13005",
    "title": "SzCORE: A Seizure Community Open-source Research Evaluation framework  for the validation of EEG-based automated seizure detection algorithms",
    "abstract": " Title: SzCORE: A Seizure Community Open-source Research Evaluation framework  for the validation of EEG-based automated seizure detection algorithms ",
    "url": "https://arxiv.org/abs/2402.13005",
    "authors": [
      "Jonathan Dan",
      "Una Pale",
      "Alireza Amirshahi",
      "William Cappelletti",
      "Thorir Mar Ingolfsson",
      "Xiaying Wang",
      "Andrea Cossettini",
      "Adriano Bernini",
      "Luca Benini",
      "S\u00e1ndor Beniczky",
      "David Atienza",
      "Philippe Ryvlin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13027",
    "title": "Solving the decision-making differential equations from eye fixation  data in Unity software by using Hermite Long-Short-Term Memory neural network",
    "abstract": " Title: Solving the decision-making differential equations from eye fixation  data in Unity software by using Hermite Long-Short-Term Memory neural network ",
    "url": "https://arxiv.org/abs/2402.13027",
    "authors": [
      "Kourosh Parand",
      "Saeed Setayeshi",
      "Mir Mohsen Pedram",
      "Ali Yoonesi",
      "Aida Pakniyat"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.13277",
    "title": "MLSTL-WSN: Machine Learning-based Intrusion Detection using SMOTETomek  in WSNs",
    "abstract": " Comments: International Journal of Information Security, Springer Journal - Q1, Scopus, ISI, SCIE, IF: 3.2 - Accepted on Jan 17, 2024 ",
    "url": "https://arxiv.org/abs/2402.13277",
    "authors": [
      "Md. Alamin Talukder",
      "Selina Sharmin",
      "Md Ashraf Uddin",
      "Md Manowarul Islam",
      "Sunil Aryal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13352",
    "title": "KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers",
    "abstract": " Title: KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers ",
    "url": "https://arxiv.org/abs/2402.13352",
    "authors": [
      "Boran Apak",
      "Medina Bandic",
      "Aritra Sarkar",
      "Sebastian Feld"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13711",
    "title": "DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based  Graph Continual Learning",
    "abstract": " Comments: Accepted at ACM TheWebConf 2024 (WWW 2024) ",
    "url": "https://arxiv.org/abs/2402.13711",
    "authors": [
      "Seungyoon Choi",
      "Wonjoong Kim",
      "Sungwon Kim",
      "Yeonjun In",
      "Sein Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.13787",
    "title": "Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks",
    "abstract": " Comments: Accepted for publication in Proceedings of The Web Conference, 2024 ",
    "url": "https://arxiv.org/abs/2402.13787",
    "authors": [
      "Ana-Andreea Stoica",
      "Nelly Litvak",
      "Augustin Chaintreau"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.14096",
    "title": "EyeTrans: Merging Human and Machine Attention for Neural Code  Summarization",
    "abstract": " Title: EyeTrans: Merging Human and Machine Attention for Neural Code  Summarization ",
    "url": "https://arxiv.org/abs/2402.14096",
    "authors": [
      "Yifan Zhang",
      "Jiliang Li",
      "Zachary Karas",
      "Aakash Bansal",
      "Toby Jia-Jun Li",
      "Collin McMillan",
      "Kevin Leach",
      "Yu Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.14148",
    "title": "Neural Networks and Friction: Slide, Hold, Learn",
    "abstract": " Comments: 10 paged, 10 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2402.14148",
    "authors": [
      "Joaquin Garcia-Suarez"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14208",
    "title": "Content Conditional Debiasing for Fair Text Embedding",
    "abstract": " Title: Content Conditional Debiasing for Fair Text Embedding ",
    "url": "https://arxiv.org/abs/2402.14208",
    "authors": [
      "Wenlong Deng",
      "Blair Chen",
      "Xiaoxiao Li",
      "Christos Thrampoulidis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14323",
    "title": "REPOFUSE: Repository-Level Code Completion with Fused Dual Context",
    "abstract": " Title: REPOFUSE: Repository-Level Code Completion with Fused Dual Context ",
    "url": "https://arxiv.org/abs/2402.14323",
    "authors": [
      "Ming Liang",
      "Xiaoheng Xie",
      "Gehao Zhang",
      "Xunjin Zheng",
      "Peng Di",
      "wei jiang",
      "Hongwei Chen",
      "Chengpeng Wang",
      "Gang Fan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14349",
    "title": "Uncertainty-driven and Adversarial Calibration Learning for Epicardial  Adipose Tissue Segmentation",
    "abstract": " Comments: 13 pages,7 figuers ",
    "url": "https://arxiv.org/abs/2402.14349",
    "authors": [
      "Kai Zhao",
      "Zhiming Liu",
      "Jiaqi Liu",
      "Jingbiao Zhou",
      "Bihong Liao",
      "Huifang Tang",
      "Qiuyu Wang",
      "Chunquan Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.14392",
    "title": "Reading Relevant Feature from Global Representation Memory for Visual  Object Tracking",
    "abstract": " Comments: 9pages,5 figures, accepted py the Thirty-seventh Conference on Neural Information Processing Systems(Neurips 2023) ",
    "url": "https://arxiv.org/abs/2402.14392",
    "authors": [
      "Xinyu Zhou",
      "Pinxue Guo",
      "Lingyi Hong",
      "Jinglun Li",
      "Wei Zhang",
      "Weifeng Ge",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14484",
    "title": "Is ChatGPT the Future of Causal Text Mining? A Comprehensive Evaluation  and Analysis",
    "abstract": " Title: Is ChatGPT the Future of Causal Text Mining? A Comprehensive Evaluation  and Analysis ",
    "url": "https://arxiv.org/abs/2402.14484",
    "authors": [
      "Takehiro Takayanagi",
      "Masahiro Suzuki",
      "Ryotaro Kobayashi",
      "Hiroki Sakaji",
      "Kiyoshi Izumi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14704",
    "title": "An LLM-Enhanced Adversarial Editing System for Lexical Simplification",
    "abstract": " Comments: Accepted by COLING 2024 main conference ",
    "url": "https://arxiv.org/abs/2402.14704",
    "authors": [
      "Keren Tan",
      "Kangyang Luo",
      "Yunshi Lan",
      "Zheng Yuan",
      "Jinlong Shu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  }
]