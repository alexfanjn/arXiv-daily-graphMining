[
  {
    "id": "arXiv:2402.00002",
    "title": "Raptor Encoding for Low-Latency Concurrent Multi-PDU Session  Transmission with Security Consideration in B5G Edge Network",
    "abstract": "In B5G edge networks, end-to-end low-latency and high-reliability transmissions between edge computing nodes and terminal devices are essential. This paper investigates the queue-aware coding scheduling transmission of randomly arriving data packets, taking into account potential eavesdroppers in edge networks. To address these concerns, we introduce SCLER, a Protocol Data Units (PDU) Raptor-encoded multi-path transmission method that overcomes the challenges of a larger attack surface in Concurrent Multipath Transfer (CMT), excessive delay due to asymmetric delay\\&bandwidth, and lack of interaction among PDU session bearers. We propose a secure and reliable transmission scheme based on Raptor encoding and distribution that incorporates a queue length-aware encoding strategy. This strategy is modeled using Constrained Markov Decision Process (CMDP), and we solve the constraint optimization problem of optimal decision-making based on a threshold strategy. Numerical results indicate that SCLER effectively reduces data leakage risks while achieving the optimal balance between delay and reliability, thereby ensuring data security. Importantly, the proposed system is compatible with current mobile networks and demonstrates practical applicability. ",
    "url": "https://arxiv.org/abs/2402.00002",
    "authors": [
      "Zhongfu Guo",
      "Xinsheng Ji",
      "Wei You",
      "Mingyan Xu",
      "Yu Zhao",
      "Zhimo Cheng",
      "Deqiang Zhou"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.00009",
    "title": "Markovian embedding of nonlocal equations using spectral representation",
    "abstract": "Nonlocal evolutionary equations containing memory terms model a variety of non-Markovian processes. We present a Markovian embedding procedure for a class of nonlocal equations by utilising the spectral representation of the nonlinear memory kernel. This allows us to transform the nonlocal system to a local-in-time system in an abstract extended space. We demonstrate our embedding procedure and its efficacy for two different physical models, namely the (i) 1D walking droplet and (ii) the 1D single-phase Stefan problem. ",
    "url": "https://arxiv.org/abs/2402.00009",
    "authors": [
      "Divya Jaganathan",
      "Rahil N. Valani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2402.00013",
    "title": "No More Trade-Offs. GPT and Fully Informative Privacy Policies",
    "abstract": "The paper reports the results of an experiment aimed at testing to what extent ChatGPT 3.5 and 4 is able to answer questions regarding privacy policies designed in the new format that we propose. In a world of human-only interpreters, there was a trade-off between comprehensiveness and comprehensibility of privacy policies, leading to the actual policies not containing enough information for users to learn anything meaningful. Having shown that GPT performs relatively well with the new format, we provide experimental evidence supporting our policy suggestion, namely that the law should require fully comprehensive privacy policies, even if this means they become less concise. ",
    "url": "https://arxiv.org/abs/2402.00013",
    "authors": [
      "Przemys\u0142aw Pa\u0142ka",
      "Marco Lippi",
      "Francesca Lagioia",
      "R\u016bta Liepi\u0146a",
      "Giovanni Sartor"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.00028",
    "title": "Neural Rendering and Its Hardware Acceleration: A Review",
    "abstract": "Neural rendering is a new image and video generation method based on deep learning. It combines the deep learning model with the physical knowledge of computer graphics, to obtain a controllable and realistic scene model, and realize the control of scene attributes such as lighting, camera parameters, posture and so on. On the one hand, neural rendering can not only make full use of the advantages of deep learning to accelerate the traditional forward rendering process, but also provide new solutions for specific tasks such as inverse rendering and 3D reconstruction. On the other hand, the design of innovative hardware structures that adapt to the neural rendering pipeline breaks through the parallel computing and power consumption bottleneck of existing graphics processors, which is expected to provide important support for future key areas such as virtual and augmented reality, film and television creation and digital entertainment, artificial intelligence and the metaverse. In this paper, we review the technical connotation, main challenges, and research progress of neural rendering. On this basis, we analyze the common requirements of neural rendering pipeline for hardware acceleration and the characteristics of the current hardware acceleration architecture, and then discuss the design challenges of neural rendering processor architecture. Finally, the future development trend of neural rendering processor architecture is prospected. ",
    "url": "https://arxiv.org/abs/2402.00028",
    "authors": [
      "Xinkai Yan",
      "Jieting Xu",
      "Yuchi Huo",
      "Hujun Bao"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.00031",
    "title": "An Integrated Framework for Team Formation and Winner Prediction in the  FIRST Robotics Competition: Model, Algorithm, and Analysis",
    "abstract": "This research work aims to develop an analytical approach for optimizing team formation and predicting team performance in a competitive environment based on data on the competitors' skills prior to the team formation. There are several approaches in scientific literature to optimize and predict a team's performance. However, most studies employ fine-grained skill statistics of the individual members or constraints such as teams with a set group of members. Currently, no research tackles the highly constrained domain of the FIRST Robotics Competition. This research effort aims to fill this gap by providing an analytical method for optimizing and predicting team performance in a competitive environment while allowing these constraints and only using metrics on previous team performance, not on each individual member's performance. We apply our method to the drafting process of the FIRST Robotics competition, a domain in which the skills change year-over-year, team members change throughout the season, each match only has a superficial set of statistics, and alliance formation is key to competitive success. First, we develop a method that could extrapolate individual members' performance based on overall team performance. An alliance optimization algorithm is developed to optimize team formation and a deep neural network model is trained to predict the winning team, both using highly post-processed real-world data. Our method is able to successfully extract individual members' metrics from overall team statistics, form competitive teams, and predict the winning team with 84.08% accuracy. ",
    "url": "https://arxiv.org/abs/2402.00031",
    "authors": [
      "Federico Galbiati",
      "Ranier X. Gran",
      "Brendan D. Jacques",
      "Sullivan J. Mulhern",
      "Chun-Kit Ngan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.00034",
    "title": "Why does Prediction Accuracy Decrease over Time? Uncertain Positive  Learning for Cloud Failure Prediction",
    "abstract": "With the rapid growth of cloud computing, a variety of software services have been deployed in the cloud. To ensure the reliability of cloud services, prior studies focus on failure instance (disk, node, and switch, etc.) prediction. Once the output of prediction is positive, mitigation actions are taken to rapidly resolve the underlying failure. According to our real-world practice in Microsoft Azure, we find that the prediction accuracy may decrease by about 9% after retraining the models. Considering that the mitigation actions may result in uncertain positive instances since they cannot be verified after mitigation, which may introduce more noise while updating the prediction model. To the best of our knowledge, we are the first to identify this Uncertain Positive Learning (UPLearning) issue in the real-world cloud failure prediction scenario. To tackle this problem, we design an Uncertain Positive Learning Risk Estimator (Uptake) approach. Using two real-world datasets of disk failure prediction and conducting node prediction experiments in Microsoft Azure, which is a top-tier cloud provider that serves millions of users, we demonstrate Uptake can significantly improve the failure prediction accuracy by 5% on average. ",
    "url": "https://arxiv.org/abs/2402.00034",
    "authors": [
      "Haozhe Li",
      "Minghua Ma",
      "Yudong Liu",
      "Pu Zhao",
      "Lingling Zheng",
      "Ze Li",
      "Yingnong Dang",
      "Murali Chintalapati",
      "Saravan Rajmohan",
      "Qingwei Lin",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00035",
    "title": "Robustness Assessment of a Runway Object Classifier for Safe Aircraft  Taxiing",
    "abstract": "As deep neural networks (DNNs) are becoming the prominent solution for many computational problems, the aviation industry seeks to explore their potential in alleviating pilot workload and in improving operational safety. However, the use of DNNs in this type of safety-critical applications requires a thorough certification process. This need can be addressed through formal verification, which provides rigorous assurances -- e.g.,~by proving the absence of certain mispredictions. In this case-study paper, we demonstrate this process using an image-classifier DNN currently under development at Airbus and intended for use during the aircraft taxiing phase. We use formal methods to assess this DNN's robustness to three common image perturbation types: noise, brightness and contrast, and some of their combinations. This process entails multiple invocations of the underlying verifier, which might be computationally expensive; and we therefore propose a method that leverages the monotonicity of these robustness properties, as well as the results of past verification queries, in order to reduce the overall number of verification queries required by nearly 60%. Our results provide an indication of the level of robustness achieved by the DNN classifier under study, and indicate that it is considerably more vulnerable to noise than to brightness or contrast perturbations. ",
    "url": "https://arxiv.org/abs/2402.00035",
    "authors": [
      "Yizhak Elboher",
      "Raya Elsaleh",
      "Omri Isac",
      "M\u00e9lanie Ducoffe",
      "Audrey Galametz",
      "Guillaume Pov\u00e9da",
      "Ryma Boumazouza",
      "No\u00e9mie Cohen",
      "Guy Katz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2402.00036",
    "title": "Kronecker Product Feature Fusion for Convolutional Neural Network in  Remote Sensing Scene Classification",
    "abstract": "Remote Sensing Scene Classification is a challenging and valuable research topic, in which Convolutional Neural Network (CNN) has played a crucial role. CNN can extract hierarchical convolutional features from remote sensing imagery, and Feature Fusion of different layers can enhance CNN's performance. Two successful Feature Fusion methods, Add and Concat, are employed in certain state-of-the-art CNN algorithms. In this paper, we propose a novel Feature Fusion algorithm, which unifies the aforementioned methods using the Kronecker Product (KPFF), and we discuss the Backpropagation procedure associated with this algorithm. To validate the efficacy of the proposed method, a series of experiments are designed and conducted. The results demonstrate its effectiveness of enhancing CNN's accuracy in Remote sensing scene classification. ",
    "url": "https://arxiv.org/abs/2402.00036",
    "authors": [
      "Yinzhu Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00040",
    "title": "Solving High-dimensional Parametric Elliptic Equation Using Tensor  Neural Network",
    "abstract": "In this paper, we introduce a tensor neural network based machine learning method for solving the elliptic partial differential equations with random coefficients in a bounded physical domain. With the help of tensor product structure, we can transform the high-dimensional integrations of tensor neural network functions to one-dimensional integrations which can be computed with the classical quadrature schemes with high accuracy. The complexity of its calculation can be reduced from the exponential scale to a polynomial scale. The corresponding machine learning method is designed for solving high-dimensional parametric elliptic equations. Some numerical examples are provided to validate the accuracy and efficiency of the proposed algorithms. ",
    "url": "https://arxiv.org/abs/2402.00040",
    "authors": [
      "Hongtao Chen",
      "Rui Fu",
      "Yifan Wang",
      "Hehu Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.00043",
    "title": "Interactive and Intelligent Root Cause Analysis in Manufacturing with  Causal Bayesian Networks and Knowledge Graphs",
    "abstract": "Root Cause Analysis (RCA) in the manufacturing of electric vehicles is the process of identifying fault causes. Traditionally, the RCA is conducted manually, relying on process expert knowledge. Meanwhile, sensor networks collect significant amounts of data in the manufacturing process. Using this data for RCA makes it more efficient. However, purely data-driven methods like Causal Bayesian Networks have problems scaling to large-scale, real-world manufacturing processes due to the vast amount of potential cause-effect relationships (CERs). Furthermore, purely data-driven methods have the potential to leave out already known CERs or to learn spurious CERs. The paper contributes by proposing an interactive and intelligent RCA tool that combines expert knowledge of an electric vehicle manufacturing process and a data-driven machine learning method. It uses reasoning over a large-scale Knowledge Graph of the manufacturing process while learning a Causal Bayesian Network. In addition, an Interactive User Interface enables a process expert to give feedback to the root cause graph by adding and removing information to the Knowledge Graph. The interactive and intelligent RCA tool reduces the learning time of the Causal Bayesian Network while decreasing the number of spurious CERs. Thus, the interactive and intelligent RCA tool closes the feedback loop between expert and machine learning method. ",
    "url": "https://arxiv.org/abs/2402.00043",
    "authors": [
      "Christoph Wehner",
      "Maximilian Kertel",
      "Judith Wewerka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00048",
    "title": "IICONGRAPH: improved Iconographic and Iconological Statements in  Knowledge Graphs",
    "abstract": "Iconography and iconology are fundamental domains when it comes to understanding artifacts of cultural heritage. Iconography deals with the study and interpretation of visual elements depicted in artifacts and their symbolism, while iconology delves deeper, exploring the underlying cultural and historical meanings. Despite the advances in representing cultural heritage with Linked Open Data (LOD), recent studies show persistent gaps in the representation of iconographic and iconological statements in current knowledge graphs (KGs). To address them, this paper presents IICONGRAPH, a KG that was created by refining and extending the iconographic and iconological statements of ArCo (the Italian KG of cultural heritage) and Wikidata. The development of IICONGRAPH was also driven by a series of requirements emerging from research case studies that were unattainable in the non-reengineered versions of the KGs. The evaluation results demonstrate that IICONGRAPH not only outperforms ArCo and Wikidata through domain-specific assessments from the literature but also serves as a robust platform for addressing the formulated research questions. IICONGRAPH is released and documented in accordance with the FAIR principles to guarantee the resource's reusability. The algorithms used to create it and assess the research questions have also been made available to ensure transparency and reproducibility. While future work focuses on ingesting more data into the KG, and on implementing it as a backbone of LLM-based question answering systems, the current version of IICONGRAPH still emerges as a valuable asset, contributing to the evolving landscape of cultural heritage representation within Knowledge Graphs, the Semantic Web, and beyond. ",
    "url": "https://arxiv.org/abs/2402.00048",
    "authors": [
      "Bruno Sartini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00051",
    "title": "Design and Implementation of Hardware Accelerators for Neural Processing  Applications",
    "abstract": "Primary motivation for this work was the need to implement hardware accelerators for a newly proposed ANN structure called Auto Resonance Network (ARN) for robotic motion planning. ARN is an approximating feed-forward hierarchical and explainable network. It can be used in various AI applications but the application base was small. Therefore, the objective of the research was twofold: to develop a new application using ARN and to implement a hardware accelerator for ARN. As per the suggestions given by the Doctoral Committee, an image recognition system using ARN has been implemented. An accuracy of around 94% was achieved with only 2 layers of ARN. The network also required a small training data set of about 500 images. Publicly available MNIST dataset was used for this experiment. All the coding was done in Python. Massive parallelism seen in ANNs presents several challenges to CPU design. For a given functionality, e.g., multiplication, several copies of serial modules can be realized within the same area as a parallel module. Advantage of using serial modules compared to parallel modules under area constraints has been discussed. One of the module often useful in ANNs is a multi-operand addition. One problem in its implementation is that the estimation of carry bits when the number of operands changes. A theorem to calculate exact number of carry bits required for a multi-operand addition has been presented in the thesis which alleviates this problem. The main advantage of the modular approach to multi-operand addition is the possibility of pipelined addition with low reconfiguration overhead. This results in overall increase in throughput for large number of additions, typically seen in several DNN configurations. ",
    "url": "https://arxiv.org/abs/2402.00051",
    "authors": [
      "Shilpa Mayannavar",
      "Uday Wali"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.00053",
    "title": "Are We Wasting Time? A Fast, Accurate Performance Evaluation Framework  for Knowledge Graph Link Predictors",
    "abstract": "The standard evaluation protocol for measuring the quality of Knowledge Graph Completion methods - the task of inferring new links to be added to a graph - typically involves a step which ranks every entity of a Knowledge Graph to assess their fit as a head or tail of a candidate link to be added. In Knowledge Graphs on a larger scale, this task rapidly becomes prohibitively heavy. Previous approaches mitigate this problem by using random sampling of entities to assess the quality of links predicted or suggested by a method. However, we show that this approach has serious limitations since the ranking metrics produced do not properly reflect true outcomes. In this paper, we present a thorough analysis of these effects along with the following findings. First, we empirically find and theoretically motivate why sampling uniformly at random vastly overestimates the ranking performance of a method. We show that this can be attributed to the effect of easy versus hard negative candidates. Second, we propose a framework that uses relational recommenders to guide the selection of candidates for evaluation. We provide both theoretical and empirical justification of our methodology, and find that simple and fast methods can work extremely well, and that they match advanced neural approaches. Even when a large portion of true candidates for a property are missed, the estimation barely deteriorates. With our proposed framework, we can reduce the time and computation needed similar to random sampling strategies while vastly improving the estimation; on ogbl-wikikg2, we show that accurate estimations of the full, filtered ranking can be obtained in 20 seconds instead of 30 minutes. We conclude that considerable computational effort can be saved by effective preprocessing and sampling methods and still reliably predict performance accurately of the true performance for the entire ranking procedure. ",
    "url": "https://arxiv.org/abs/2402.00053",
    "authors": [
      "Filip Cornell",
      "Yifei Jin",
      "Jussi Karlgren",
      "Sarunas Girdzijauskas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00080",
    "title": "Arithmetic Average Density Fusion -- Part IV: Distributed Heterogeneous  Fusion of RFS and LRFS Filters via Variational Approximation",
    "abstract": "This paper, the fourth part of a series of papers on the arithmetic average (AA) density fusion approach and its application for target tracking, addresses the intricate challenge of distributed heterogeneous multisensor multitarget tracking, where each inter-connected sensor operates a probability hypothesis density (PHD) filter, a multiple Bernoulli (MB) filter or a labeled MB (LMB) filter and they cooperate with each other via information fusion. Earlier papers in this series have proven that the proper AA fusion of these filters is all exactly built on averaging their respective unlabeled/labeled PHDs. Based on this finding, two PHD-AA fusion approaches are proposed via variational minimization of the upper bound of the Kullback-Leibler divergence between the local and multi-filter averaged PHDs subject to cardinality consensus based on the Gaussian mixture implementation, enabling heterogeneous filter cooperation. One focuses solely on fitting the weights of the local Gaussian components (L-GCs), while the other simultaneously fits all the parameters of the L-GCs at each sensor, both seeking average consensus on the unlabeled PHD, irrespective of the specific posterior form of the local filters. For the distributed peer-to-peer communication, both the classic consensus and flooding paradigms have been investigated. Simulations have demonstrated the effectiveness and flexibility of the proposed approaches in both homogeneous and heterogeneous scenarios. ",
    "url": "https://arxiv.org/abs/2402.00080",
    "authors": [
      "Tiancheng Li",
      "Haozhe Liang",
      "Guchong Li",
      "Jes\u00fas Garc\u00eda Herrero",
      "Quan Pan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.00086",
    "title": "Retrosynthesis prediction enhanced by in-silico reaction data  augmentation",
    "abstract": "Recent advances in machine learning (ML) have expedited retrosynthesis research by assisting chemists to design experiments more efficiently. However, all ML-based methods consume substantial amounts of paired training data (i.e., chemical reaction: product-reactant(s) pair), which is costly to obtain. Moreover, companies view reaction data as a valuable asset and restrict the accessibility to researchers. These issues prevent the creation of more powerful retrosynthesis models due to their data-driven nature. As a response, we exploit easy-to-access unpaired data (i.e., one component of product-reactant(s) pair) for generating in-silico paired data to facilitate model training. Specifically, we present RetroWISE, a self-boosting framework that employs a base model inferred from real paired data to perform in-silico reaction generation and augmentation using unpaired data, ultimately leading to a superior model. On three benchmark datasets, RetroWISE achieves the best overall performance against state-of-the-art models (e.g., +8.6% top-1 accuracy on the USPTO-50K test dataset). Moreover, it consistently improves the prediction accuracy of rare transformations. These results show that Retro- WISE overcomes the training bottleneck by in-silico reactions, thereby paving the way toward more effective ML-based retrosynthesis models. ",
    "url": "https://arxiv.org/abs/2402.00086",
    "authors": [
      "Xu Zhang",
      "Yiming Mo",
      "Wenguan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00094",
    "title": "Deep Neural Networks: A Formulation Via Non-Archimedean Analysis",
    "abstract": "We introduce a new class of deep neural networks (DNNs) with multilayered tree-like architectures. The architectures are codified using numbers from the ring of integers of non-Archimdean local fields. These rings have a natural hierarchical organization as infinite rooted trees. Natural morphisms on these rings allow us to construct finite multilayered architectures. The new DNNs are robust universal approximators of real-valued functions defined on the mentioned rings. We also show that the DNNs are robust universal approximators of real-valued square-integrable functions defined in the unit interval. ",
    "url": "https://arxiv.org/abs/2402.00094",
    "authors": [
      "W. A. Z\u00fa\u00f1iga-Galindo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00126",
    "title": "Common Sense Reasoning for Deep Fake Detection",
    "abstract": "State-of-the-art approaches rely on image-based features extracted via neural networks for the deepfake detection binary classification. While these approaches trained in the supervised sense extract likely fake features, they may fall short in representing unnatural `non-physical' semantic facial attributes -- blurry hairlines, double eyebrows, rigid eye pupils, or unnatural skin shading. However, such facial attributes are generally easily perceived by humans via common sense reasoning. Furthermore, image-based feature extraction methods that provide visual explanation via saliency maps can be hard to be interpreted by humans. To address these challenges, we propose the use of common sense reasoning to model deepfake detection, and extend it to the Deepfake Detection VQA (DD-VQA) task with the aim to model human intuition in explaining the reason behind labeling an image as either real or fake. To this end, we introduce a new dataset that provides answers to the questions related to the authenticity of an image, along with its corresponding explanations. We also propose a Vision and Language Transformer-based framework for the DD-VQA task, incorporating text and image aware feature alignment formulations. Finally, we evaluate our method on both the performance of deepfake detection and the quality of the generated explanations. We hope that this task inspires researchers to explore new avenues for enhancing language-based interpretability and cross-modality applications in the realm of deepfake detection. ",
    "url": "https://arxiv.org/abs/2402.00126",
    "authors": [
      "Yue Zhang",
      "Ben Colman",
      "Ali Shahriyari",
      "Gaurav Bharaj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.00128",
    "title": "Real-time Traffic Object Detection for Autonomous Driving",
    "abstract": "With recent advances in computer vision, it appears that autonomous driving will be part of modern society sooner rather than later. However, there are still a significant number of concerns to address. Although modern computer vision techniques demonstrate superior performance, they tend to prioritize accuracy over efficiency, which is a crucial aspect of real-time applications. Large object detection models typically require higher computational power, which is achieved by using more sophisticated onboard hardware. For autonomous driving, these requirements translate to increased fuel costs and, ultimately, a reduction in mileage. Further, despite their computational demands, the existing object detectors are far from being real-time. In this research, we assess the robustness of our previously proposed, highly efficient pedestrian detector LSFM on well-established autonomous driving benchmarks, including diverse weather conditions and nighttime scenes. Moreover, we extend our LSFM model for general object detection to achieve real-time object detection in traffic scenes. We evaluate its performance, low latency, and generalizability on traffic object detection datasets. Furthermore, we discuss the inadequacy of the current key performance indicator employed by object detection systems in the context of autonomous driving and propose a more suitable alternative that incorporates real-time requirements. ",
    "url": "https://arxiv.org/abs/2402.00128",
    "authors": [
      "Abdul Hannan Khan",
      "Syed Tahseen Raza Rizvi",
      "Andreas Dengel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00153",
    "title": "Fully Data-Driven Model for Increasing Sampling Rate Frequency of  Seismic Data using Super-Resolution Generative Adversarial Networks",
    "abstract": "High-quality data is one of the key requirements for any engineering application. In earthquake engineering practice, accurate data is pivotal in predicting the response of structure or damage detection process in an Structural Health Monitoring (SHM) application with less uncertainty. However, obtaining high-resolution data is fraught with challenges, such as significant costs, extensive data channels, and substantial storage requirements. To address these challenges, this study employs super-resolution generative adversarial networks (SRGANs) to improve the resolution of time-history data such as the data obtained by a sensor network in an SHM application, marking the first application of SRGANs in earthquake engineering domain. The time-series data are transformed into RGB values, converting raw data into images. SRGANs are then utilized to upscale these low-resolution images, thereby enhancing the overall sensor resolution. This methodology not only offers potential reductions in data storage requirements but also simplifies the sensor network, which could result in lower installation and maintenance costs. The proposed SRGAN method is rigorously evaluated using real seismic data, and its performance is compared with traditional enhancement techniques. The findings of this study pave the way for cost-effective and efficient improvements in the resolution of sensors used in SHM systems, with promising implications for the safety and sustainability of infrastructures worldwide. ",
    "url": "https://arxiv.org/abs/2402.00153",
    "authors": [
      "Navid Gholizadeh",
      "Javad Katebi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2402.00160",
    "title": "Multimodal Clinical Pseudo-notes for Emergency Department Prediction  Tasks using Multiple Embedding Model for EHR (MEME)",
    "abstract": "In this work, we introduce Multiple Embedding Model for EHR (MEME), an approach that views Electronic Health Records (EHR) as multimodal data. This approach incorporates \"pseudo-notes\", textual representations of tabular EHR concepts such as diagnoses and medications, and allows us to effectively employ Large Language Models (LLMs) for EHR representation. This framework also adopts a multimodal approach, embedding each EHR modality separately. We demonstrate the effectiveness of MEME by applying it to several tasks within the Emergency Department across multiple hospital systems. Our findings show that MEME surpasses the performance of both single modality embedding methods and traditional machine learning approaches. However, we also observe notable limitations in generalizability across hospital institutions for all tested models. ",
    "url": "https://arxiv.org/abs/2402.00160",
    "authors": [
      "Simon A. Lee",
      "Sujay Jain",
      "Alex Chen",
      "Arabdha Biswas",
      "Jennifer Fang",
      "Akos Rudas",
      "Jeffrey N. Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.00163",
    "title": "Improving Object Detection Quality in Football Through Super-Resolution  Techniques",
    "abstract": "This study explores the potential of super-resolution techniques in enhancing object detection accuracy in football. Given the sport's fast-paced nature and the critical importance of precise object (e.g. ball, player) tracking for both analysis and broadcasting, super-resolution could offer significant improvements. We investigate how advanced image processing through super-resolution impacts the accuracy and reliability of object detection algorithms in processing football match footage. Our methodology involved applying state-of-the-art super-resolution techniques to a diverse set of football match videos from SoccerNet, followed by object detection using Faster R-CNN. The performance of these algorithms, both with and without super-resolution enhancement, was rigorously evaluated in terms of detection accuracy. The results indicate a marked improvement in object detection accuracy when super-resolution preprocessing is applied. The improvement of object detection through the integration of super-resolution techniques yields significant benefits, especially for low-resolution scenarios, with a notable 12\\% increase in mean Average Precision (mAP) at an IoU (Intersection over Union) range of 0.50:0.95 for 320x240 size images when increasing the resolution fourfold using RLFN. As the dimensions increase, the magnitude of improvement becomes more subdued; however, a discernible improvement in the quality of detection is consistently evident. Additionally, we discuss the implications of these findings for real-time sports analytics, player tracking, and the overall viewing experience. The study contributes to the growing field of sports technology by demonstrating the practical benefits and limitations of integrating super-resolution techniques in football analytics and broadcasting. ",
    "url": "https://arxiv.org/abs/2402.00163",
    "authors": [
      "Karolina Seweryn",
      "Gabriel Ch\u0119\u0107",
      "Szymon \u0141ukasik",
      "Anna Wr\u00f3blewska"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00188",
    "title": "The Graph Pencil Method: Mapping Subgraph Densities to Stochastic Block  Models",
    "abstract": "In this work, we describe a method that determines an exact map from a finite set of subgraph densities to the parameters of a stochastic block model (SBM) matching these densities. Given a number $K$ of blocks, the subgraph densities of a finite number of stars and bistars uniquely determines a single element of the class of all degree-separated stochastic block models with $K$ blocks. Our method makes it possible to translate estimates of these subgraph densities into model parameters, and hence to use subgraph densities directly for inference. The computational overhead is negligible; computing the translation map is polynomial in $K$, but independent of the graph size once the subgraph densities are given. ",
    "url": "https://arxiv.org/abs/2402.00188",
    "authors": [
      "Lee M Gunderson",
      "Gecia Bravo-Hermsdorff",
      "Peter Orbanz"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2402.00236",
    "title": "Positional Encoding Helps Recurrent Neural Networks Handle a Large  Vocabulary",
    "abstract": "This study discusses the effects of positional encoding on recurrent neural networks (RNNs) utilizing synthetic benchmarks. Positional encoding \"time-stamps\" data points in time series and complements the capabilities of Transformer neural networks, which lack an inherent mechanism for representing the data order. By contrast, RNNs can encode the temporal information of data points on their own, rendering their use of positional encoding seemingly \"redundant\". Nonetheless, empirical investigations reveal the effectiveness of positional encoding even when coupled with RNNs, specifically for handling a large vocabulary that yields diverse observations. These findings pave the way for a new line of research on RNNs, concerning the combination of input-driven and autonomous time representation. Additionally, biological implications of the computational/simulational results are discussed, in the light of the affinity between the sinusoidal implementation of positional encoding and neural oscillations in biological brains. ",
    "url": "https://arxiv.org/abs/2402.00236",
    "authors": [
      "Takashi Morita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.00240",
    "title": "Spectral Norm of Convolutional Layers with Circular and Zero Paddings",
    "abstract": "This paper leverages the use of \\emph{Gram iteration} an efficient, deterministic, and differentiable method for computing spectral norm with an upper bound guarantee. Designed for circular convolutional layers, we generalize the use of the Gram iteration to zero padding convolutional layers and prove its quadratic convergence. We also provide theorems for bridging the gap between circular and zero padding convolution's spectral norm. We design a \\emph{spectral rescaling} that can be used as a competitive $1$-Lipschitz layer that enhances network robustness. Demonstrated through experiments, our method outperforms state-of-the-art techniques in precision, computational cost, and scalability. The code of experiments is available at https://github.com/blaisedelattre/lip4conv. ",
    "url": "https://arxiv.org/abs/2402.00240",
    "authors": [
      "Blaise Delattre",
      "Quentin Barth\u00e9lemy",
      "Alexandre Allauzen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00243",
    "title": "Capacity Constraint Analysis Using Object Detection for Smart  Manufacturing",
    "abstract": "The increasing popularity of Deep Learning (DL) based Object Detection (OD) methods and their real-world applications have opened new venues in smart manufacturing. Traditional industries struck by capacity constraints after Coronavirus Disease (COVID-19) require non-invasive methods for in-depth operations' analysis to optimize and increase their revenue. In this study, we have initially developed a Convolutional Neural Network (CNN) based OD model to tackle this issue. This model is trained to accurately identify the presence of chairs and individuals on the production floor. The identified objects are then passed to the CNN based tracker, which tracks them throughout their life cycle in the workstation. The extracted meta-data is further processed through a novel framework for the capacity constraint analysis. We identified that the Station C is only 70.6% productive through 6 months. Additionally, the time spent at each station is recorded and aggregated for each object. This data proves helpful in conducting annual audits and effectively managing labor and material over time. ",
    "url": "https://arxiv.org/abs/2402.00243",
    "authors": [
      "Hafiz Mughees Ahmad",
      "Afshin Rahimi",
      "Khizer Hayat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00261",
    "title": "Understanding Neural Network Systems for Image Analysis using Vector  Spaces and Inverse Maps",
    "abstract": "There is strong interest in developing mathematical methods that can be used to understand complex neural networks used in image analysis. In this paper, we introduce techniques from Linear Algebra to model neural network layers as maps between signal spaces. First, we demonstrate how signal spaces can be used to visualize weight spaces and convolutional layer kernels. We also demonstrate how residual vector spaces can be used to further visualize information lost at each layer. Second, we introduce the concept of invertible networks and an algorithm for computing input images that yield specific outputs. We demonstrate our approach on two invertible networks and ResNet18. ",
    "url": "https://arxiv.org/abs/2402.00261",
    "authors": [
      "Rebecca Pattichis",
      "Marios S. Pattichis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00292",
    "title": "Effective Bug Detection in Graph Database Engines: An LLM-based Approach",
    "abstract": "Graph database engines play a pivotal role in efficiently storing and managing graph data across various domains, including bioinformatics, knowledge graphs, and recommender systems. Ensuring data accuracy within graph database engines is paramount, as inaccuracies can yield unreliable analytical outcomes. Current bug-detection approaches are confined to specific graph query languages, limiting their applicabilities when handling graph database engines that use various graph query languages across various domains. Moreover, they require extensive prior knowledge to generate queries for detecting bugs. To address these challenges, we introduces DGDB, a novel paradigm harnessing large language models(LLM), such as ChatGPT, for comprehensive bug detection in graph database engines. DGDB leverages ChatGPT to generate high-quality queries for different graph query languages. It subsequently employs differential testing to identify bugs in graph database engines. We applied this paradigm to graph database engines using the Gremlin query language and those using the Cypher query language, generating approximately 4,000 queries each. In the latest versions of Neo4j, Agensgraph, and JanusGraph databases, we detected 2, 5, and 3 wrong-result bugs, respectively. ",
    "url": "https://arxiv.org/abs/2402.00292",
    "authors": [
      "Jiayi Wu",
      "Zhengyu Wu",
      "Ronghua Li",
      "Hongchao Qin",
      "Guoren Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2402.00296",
    "title": "High-Level, Collaborative Task Planning Grammar and Execution for  Heterogeneous Agents",
    "abstract": "We propose a new multi-agent task grammar to encode collaborative tasks for a team of heterogeneous agents that can have overlapping capabilities. The grammar allows users to specify the relationship between agents and parts of the task without providing explicit assignments or constraints on the number of agents required. We develop a method to automatically find a team of agents and synthesize correct-by-construction control with synchronization policies to satisfy the task. We demonstrate the scalability of our approach through simulation and compare our method to existing task grammars that encode multi-agent tasks. ",
    "url": "https://arxiv.org/abs/2402.00296",
    "authors": [
      "Amy Fang",
      "Hadas Kress-Gazit"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.00300",
    "title": "Self-supervised learning of video representations from a child's  perspective",
    "abstract": "Children learn powerful internal models of the world around them from a few years of egocentric visual experience. Can such internal models be learned from a child's visual experience with highly generic learning algorithms or do they require strong inductive biases? Recent advances in collecting large-scale, longitudinal, developmentally realistic video datasets and generic self-supervised learning (SSL) algorithms are allowing us to begin to tackle this nature vs. nurture question. However, existing work typically focuses on image-based SSL algorithms and visual capabilities that can be learned from static images (e.g. object recognition), thus ignoring temporal aspects of the world. To close this gap, here we train self-supervised video models on longitudinal, egocentric headcam recordings collected from a child over a two year period in their early development (6-31 months). The resulting models are highly effective at facilitating the learning of action concepts from a small number of labeled examples; they have favorable data size scaling properties; and they display emergent video interpolation capabilities. Video models also learn more robust object representations than image-based models trained with the exact same data. These results suggest that important temporal aspects of a child's internal model of the world may be learnable from their visual experience using highly generic learning algorithms and without strong inductive biases. ",
    "url": "https://arxiv.org/abs/2402.00300",
    "authors": [
      "A. Emin Orhan",
      "Wentao Wang",
      "Alex N. Wang",
      "Mengye Ren",
      "Brenden M. Lake"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2402.00304",
    "title": "Invariance-powered Trustworthy Defense via Remove Then Restore",
    "abstract": "Adversarial attacks pose a challenge to the deployment of deep neural networks (DNNs), while previous defense models overlook the generalization to various attacks. Inspired by targeted therapies for cancer, we view adversarial samples as local lesions of natural benign samples, because a key finding is that salient attack in an adversarial sample dominates the attacking process, while trivial attack unexpectedly provides trustworthy evidence for obtaining generalizable robustness. Based on this finding, a Pixel Surgery and Semantic Regeneration (PSSR) model following the targeted therapy mechanism is developed, which has three merits: 1) To remove the salient attack, a score-based Pixel Surgery module is proposed, which retains the trivial attack as a kind of invariance information. 2) To restore the discriminative content, a Semantic Regeneration module based on a conditional alignment extrapolator is proposed, which achieves pixel and semantic consistency. 3) To further harmonize robustness and accuracy, an intractable problem, a self-augmentation regularizer with adversarial R-drop is designed. Experiments on numerous benchmarks show the superiority of PSSR. ",
    "url": "https://arxiv.org/abs/2402.00304",
    "authors": [
      "Xiaowei Fu",
      "Yuhang Zhou",
      "Lina Ma",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00306",
    "title": "An Accurate and Low-Parameter Machine Learning Architecture for Next  Location Prediction",
    "abstract": "Next location prediction is a discipline that involves predicting a users next location. Its applications include resource allocation, quality of service, energy efficiency, and traffic management. This paper proposes an energy-efficient, small, and low parameter machine learning (ML) architecture for accurate next location prediction, deployable on modest base stations and edge devices. To accomplish this we ran a hundred hyperparameter experiments on the full human mobility patterns of an entire city, to determine an exact ML architecture that reached a plateau of accuracy with the least amount of model parameters. We successfully achieved a reduction in the number of model parameters within published ML architectures from 202 million down to 2 million. This reduced the total size of the model parameters from 791 MB down to 8 MB. Additionally, this decreased the training time by a factor of four, the amount of graphics processing unit (GPU) memory needed for training by a factor of twenty, and the overall accuracy was increased from 80.16% to 82.54%. This improvement allows for modest base stations and edge devices which do not have a large amount of memory or storage, to deploy and utilize the proposed ML architecture for next location prediction. ",
    "url": "https://arxiv.org/abs/2402.00306",
    "authors": [
      "Calvin Jary",
      "Nafiseh Kahani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00319",
    "title": "SCO-VIST: Social Interaction Commonsense Knowledge-based Visual  Storytelling",
    "abstract": "Visual storytelling aims to automatically generate a coherent story based on a given image sequence. Unlike tasks like image captioning, visual stories should contain factual descriptions, worldviews, and human social commonsense to put disjointed elements together to form a coherent and engaging human-writeable story. However, most models mainly focus on applying factual information and using taxonomic/lexical external knowledge when attempting to create stories. This paper introduces SCO-VIST, a framework representing the image sequence as a graph with objects and relations that includes human action motivation and its social interaction commonsense knowledge. SCO-VIST then takes this graph representing plot points and creates bridges between plot points with semantic and occurrence-based edge weights. This weighted story graph produces the storyline in a sequence of events using Floyd-Warshall's algorithm. Our proposed framework produces stories superior across multiple metrics in terms of visual grounding, coherence, diversity, and humanness, per both automatic and human evaluations. ",
    "url": "https://arxiv.org/abs/2402.00319",
    "authors": [
      "Eileen Wang",
      "Soyeon Caren Han",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00325",
    "title": "How digital twins provide new opportunities for managing change in  complex projects",
    "abstract": "Digital twins provide opportunities for the development of new techniques for managing change in complex projects, such as infrastructure, new energy and resource projects. Managing change is an important element of a systems approach to infrastructure, and for ensuring the systems integration and handover to asset owners, yet it is often done poorly, becoming a source of errors that lead projects to be over budget and schedule. We set out to articulate the opportunities provided by the digital twin for advanced methodologies for managing change in complex projects, through an under-pinning state of the art review of the existing technical literature and a small pilot to identify the characteristics of future data-driven solutions. This identifies the need to integrate work on identifying systems interfaces, change propagation and visualisation, and the potential to significantly extend the limitations of existing solutions by using developments in the digital twin, such as linked data, semantic enrichment, network analyses and machine learning. ",
    "url": "https://arxiv.org/abs/2402.00325",
    "authors": [
      "Jennifer Whyte",
      "Ranjith Soman",
      "Rafael Sacks",
      "Neda Mohammadi",
      "Nader Naderpajouh",
      "Wei-Ting Hong",
      "Ghang Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.00326",
    "title": "PirateNets: Physics-informed Deep Learning with Residual Adaptive  Networks",
    "abstract": "While physics-informed neural networks (PINNs) have become a popular deep learning framework for tackling forward and inverse problems governed by partial differential equations (PDEs), their performance is known to degrade when larger and deeper neural network architectures are employed. Our study identifies that the root of this counter-intuitive behavior lies in the use of multi-layer perceptron (MLP) architectures with non-suitable initialization schemes, which result in poor trainablity for the network derivatives, and ultimately lead to an unstable minimization of the PDE residual loss. To address this, we introduce Physics-informed Residual Adaptive Networks (PirateNets), a novel architecture that is designed to facilitate stable and efficient training of deep PINN models. PirateNets leverage a novel adaptive residual connection, which allows the networks to be initialized as shallow networks that progressively deepen during training. We also show that the proposed initialization scheme allows us to encode appropriate inductive biases corresponding to a given PDE system into the network architecture. We provide comprehensive empirical evidence showing that PirateNets are easier to optimize and can gain accuracy from considerably increased depth, ultimately achieving state-of-the-art results across various benchmarks. All code and data accompanying this manuscript will be made publicly available at \\url{https://github.com/PredictiveIntelligenceLab/jaxpi}. ",
    "url": "https://arxiv.org/abs/2402.00326",
    "authors": [
      "Sifan Wang",
      "Bowen Li",
      "Yuhan Chen",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.00332",
    "title": "Comparing Spectral Bias and Robustness For Two-Layer Neural Networks:  SGD vs Adaptive Random Fourier Features",
    "abstract": "We present experimental results highlighting two key differences resulting from the choice of training algorithm for two-layer neural networks. The spectral bias of neural networks is well known, while the spectral bias dependence on the choice of training algorithm is less studied. Our experiments demonstrate that an adaptive random Fourier features algorithm (ARFF) can yield a spectral bias closer to zero compared to the stochastic gradient descent optimizer (SGD). Additionally, we train two identically structured classifiers, employing SGD and ARFF, to the same accuracy levels and empirically assess their robustness against adversarial noise attacks. ",
    "url": "https://arxiv.org/abs/2402.00332",
    "authors": [
      "Aku Kammonen",
      "Lisi Liang",
      "Anamika Pandey",
      "Ra\u00fal Tempone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.00340",
    "title": "Can you Remove the Downstream Model for Speaker Recognition with  Self-Supervised Speech Features?",
    "abstract": "Self-supervised features are typically used in place of filter-banks in speaker verification models. However, these models were originally designed to ingest filter-banks as inputs, and thus, training them on top of self-supervised features assumes that both feature types require the same amount of learning for the task. In this work, we observe that pre-trained self-supervised speech features inherently include information required for downstream speaker verification task, and therefore, we can simplify the downstream model without sacrificing performance. To this end, we revisit the design of the downstream model for speaker verification using self-supervised features. We show that we can simplify the model to use 97.51% fewer parameters while achieving a 29.93% average improvement in performance on SUPERB. Consequently, we show that the simplified downstream model is more data efficient compared to baseline--it achieves better performance with only 60% of the training data. ",
    "url": "https://arxiv.org/abs/2402.00340",
    "authors": [
      "Zakaria Aldeneh",
      "Takuya Higuchi",
      "Jee-weon Jung",
      "Skyler Seto",
      "Tatiana Likhomanenko",
      "Stephen Shum",
      "Ahmed Hussen Abdelaziz",
      "Shinji Watanabe",
      "Barry-John Theobald"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.00342",
    "title": "Survey of Privacy Threats and Countermeasures in Federated Learning",
    "abstract": "Federated learning is widely considered to be as a privacy-aware learning method because no training data is exchanged directly between clients. Nevertheless, there are threats to privacy in federated learning, and privacy countermeasures have been studied. However, we note that common and unique privacy threats among typical types of federated learning have not been categorized and described in a comprehensive and specific way. In this paper, we describe privacy threats and countermeasures for the typical types of federated learning; horizontal federated learning, vertical federated learning, and transfer federated learning. ",
    "url": "https://arxiv.org/abs/2402.00342",
    "authors": [
      "Masahiro Hayashitani",
      "Junki Mori",
      "Isamu Teranishi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.00345",
    "title": "IndiVec: An Exploration of Leveraging Large Language Models for Media  Bias Detection with Fine-Grained Bias Indicators",
    "abstract": "This study focuses on media bias detection, crucial in today's era of influential social media platforms shaping individual attitudes and opinions. In contrast to prior work that primarily relies on training specific models tailored to particular datasets, resulting in limited adaptability and subpar performance on out-of-domain data, we introduce a general bias detection framework, IndiVec, built upon large language models. IndiVec begins by constructing a fine-grained media bias database, leveraging the robust instruction-following capabilities of large language models and vector database techniques. When confronted with new input for bias detection, our framework automatically selects the most relevant indicator from the vector database and employs majority voting to determine the input's bias label. IndiVec excels compared to previous methods due to its adaptability (demonstrating consistent performance across diverse datasets from various sources) and explainability (providing explicit top-k indicators to interpret bias predictions). Experimental results on four political bias datasets highlight IndiVec's significant superiority over baselines. Furthermore, additional experiments and analysis provide profound insights into the framework's effectiveness. ",
    "url": "https://arxiv.org/abs/2402.00345",
    "authors": [
      "Luyang Lin",
      "Lingzhi Wang",
      "Xiaoyan Zhao",
      "Jing Li",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.00366",
    "title": "Legged Robot State Estimation With Invariant Extended Kalman Filter  Using Neural Measurement Network",
    "abstract": "This paper introduces a novel proprioceptive state estimator for legged robots that combines model-based filters and deep neural networks. Recent studies have shown that neural networks such as multi-layer perceptron or recurrent neural networks can estimate the robot states, including contact probability and linear velocity. Inspired by this, we develop a state estimation framework that integrates a neural measurement network (NMN) with an invariant extended Kalman filter. We show that our framework improves estimation performance in various terrains. Existing studies that combine model-based filters and learning-based approaches typically use real-world data. However, our approach relies solely on simulation data, as it allows us to easily obtain extensive data. This difference leads to a gap between the learning and the inference domain, commonly referred to as a sim-to-real gap. We address this challenge by adapting existing learning techniques and regularization. To validate our proposed method, we conduct experiments using a quadruped robot on four types of terrain: \\textit{flat}, \\textit{debris}, \\textit{soft}, and \\textit{slippery}. We observe that our approach significantly reduces position drift compared to the existing model-based state estimator. ",
    "url": "https://arxiv.org/abs/2402.00366",
    "authors": [
      "Donghoon Youm",
      "Hyunsik Oh",
      "Suyoung Choi",
      "Hyeongjun Kim",
      "Jemin Hwangbo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00371",
    "title": "What Does the Bot Say? Opportunities and Risks of Large Language Models  in Social Media Bot Detection",
    "abstract": "Social media bot detection has always been an arms race between advancements in machine learning bot detectors and adversarial bot strategies to evade detection. In this work, we bring the arms race to the next level by investigating the opportunities and risks of state-of-the-art large language models (LLMs) in social bot detection. To investigate the opportunities, we design novel LLM-based bot detectors by proposing a mixture-of-heterogeneous-experts framework to divide and conquer diverse user information modalities. To illuminate the risks, we explore the possibility of LLM-guided manipulation of user textual and structured information to evade detection. Extensive experiments with three LLMs on two datasets demonstrate that instruction tuning on merely 1,000 annotated examples produces specialized LLMs that outperform state-of-the-art baselines by up to 9.1% on both datasets, while LLM-guided manipulation strategies could significantly bring down the performance of existing bot detectors by up to 29.6% and harm the calibration and reliability of bot detection systems. ",
    "url": "https://arxiv.org/abs/2402.00371",
    "authors": [
      "Shangbin Feng",
      "Herun Wan",
      "Ningnan Wang",
      "Zhaoxuan Tan",
      "Minnan Luo",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.00381",
    "title": "A Joint Communication and Computation Framework for Digital Twin over  Wireless Networks",
    "abstract": "In this paper, the problem of low-latency communication and computation resource allocation for digital twin (DT) over wireless networks is investigated. In the considered model, multiple physical devices in the physical network (PN) needs to frequently offload the computation task related data to the digital network twin (DNT), which is generated and controlled by the central server. Due to limited energy budget of the physical devices, both computation accuracy and wireless transmission power must be considered during the DT procedure. This joint communication and computation problem is formulated as an optimization problem whose goal is to minimize the overall transmission delay of the system under total PN energy and DNT model accuracy constraints. To solve this problem, an alternating algorithm with iteratively solving device scheduling, power control, and data offloading subproblems. For the device scheduling subproblem, the optimal solution is obtained in closed form through the dual method. For the special case with one physical device, the optimal number of transmission times is reveled. Based on the theoretical findings, the original problem is transformed into a simplified problem and the optimal device scheduling can be found. Numerical results verify that the proposed algorithm can reduce the transmission delay of the system by up to 51.2\\% compared to the conventional schemes. ",
    "url": "https://arxiv.org/abs/2402.00381",
    "authors": [
      "Zhaohui Yang",
      "Mingzhe Chen",
      "Yuchen Liu",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.00384",
    "title": "Adaptive FRIT-based Recursive Robust Controller Design Using Forgetting  Factors",
    "abstract": "Adaptive FRIT (A-FRIT) with exponential forgetting (EF) has been proposed for time-varying systems to improve the data dependence of FRIT, which is a direct data-driven tuning method. However, the EF-based method is not a reliable controller because it can cause significant degradation of the control performance and instability unless the persistent excitation (PE) condition is satisfied. To solve this problem, we propose a new A-FRIT method based on directional forgetting (DF) and exponential resetting that can forget old data without instability regardless of the PE condition. To confirm the effectiveness of the proposed method, we applied it to artificial muscle control with strong asymmetric hysteresis characteristics and evaluated its robust performance against load changes during the experiment. The experimental results show that the proposed method based on DF achieves high control performance and is robust against changes in the characteristics and/or target trajectory. The proposed method is also practical because it does not require system identification, model structure, or prior experimentation. ",
    "url": "https://arxiv.org/abs/2402.00384",
    "authors": [
      "Satoshi Tsuruhara",
      "Kazuhisa Ito"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.00393",
    "title": "Loss Function Considering Dead Zone for Neural Networks",
    "abstract": "It is important to reveal the inverse dynamics of manipulators to improve control performance of model-based control. Neural networks (NNs) are promising techniques to represent complicated inverse dynamics while they require a large amount of motion data. However, motion data in dead zones of actuators is not suitable for training models decreasing the number of useful training data. In this study, based on the fact that the manipulator joint does not work irrespective of input torque in dead zones, we propose a new loss function that considers only errors of joints not in dead zones. The proposed method enables to increase in the amount of motion data available for training and the accuracy of the inverse dynamics computation. Experiments on actual equipment using a three-degree-of-freedom (DOF) manipulator showed higher accuracy than conventional methods. We also confirmed and discussed the behavior of the model of the proposed method in dead zones. ",
    "url": "https://arxiv.org/abs/2402.00393",
    "authors": [
      "Koki Inami",
      "Koki Yamane",
      "Sho Sakaino"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00395",
    "title": "ONE-SA: Enabling Nonlinear Operations in Systolic Arrays for Efficient  and Flexible Neural Network Inference",
    "abstract": "The computation and memory-intensive nature of DNNs limits their use in many mobile and embedded contexts. Application-specific integrated circuit (ASIC) hardware accelerators employ matrix multiplication units (such as the systolic arrays) and dedicated nonlinear function units to speed up DNN computations. A close examination of these ASIC accelerators reveals that the designs are often specialized and lack versatility across different networks, especially when the networks have different types of computation. In this paper, we introduce a novel systolic array architecture, which is capable of executing nonlinear functions. By encompassing both inherent linear and newly enabled nonlinear functions within the systolic arrays, the proposed architecture facilitates versatile network inferences, substantially enhancing computational power and energy efficiency. Experimental results show that employing this systolic array enables seamless execution of entire DNNs, incurring only a negligible loss in the network inference accuracy. Furthermore, assessment and evaluation with FPGAs reveal that integrating nonlinear computation capacity into a systolic array does not introduce extra notable (less than 1.5%) block memory memories (BRAMs), look-up-tables (LUTs), or digital signal processors (DSPs) but a mere 13.3% - 24.1% more flip flops (FFs). In comparison to existing methodologies, executing the networks with the proposed systolic array, which enables the flexibility of different network models, yields up to 25.73x, 5.21x, and 1.54x computational efficiency when compared to general-purpose CPUs, GPUs, and SoCs respectively, while achieving comparable (83.4% - 135.8%) performance with the conventional accelerators which are designed for specific neural network models. ",
    "url": "https://arxiv.org/abs/2402.00395",
    "authors": [
      "Ruiqi Sun",
      "Yinchen Ni",
      "Xin He",
      "Jie Zhao",
      "An Zou"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.00398",
    "title": "Reconfigurable Intelligent Computational Surfaces for MEC-Assisted  Autonomous Driving Networks",
    "abstract": "In this paper, we focus on improving autonomous driving safety via task offloading from cellular vehicles (CVs), using vehicle-to-infrastructure (V2I) links, to an multi-access edge computing (MEC) server. Considering that the frequencies used for V2I links can be reused for vehicle-to-vehicle (V2V) communications to improve spectrum utilization, the receiver of each V2I link may suffer from severe interference, causing outages in the task offloading process. To tackle this issue, we propose the deployment of a reconfigurable intelligent computational surface (RICS) to enable, not only V2I reflective links, but also interference cancellation at the V2V links exploiting the computational capability of its metamaterials. We devise a joint optimization formulation for the task offloading ratio between the CVs and the MEC server, the spectrum sharing strategy between V2V and V2I communications, as well as the RICS reflection and refraction matrices, with the objective to maximize a safety-based autonomous driving task. Due to the non-convexity of the problem and the coupling among its free variables, we transform it into a more tractable equivalent form, which is then decomposed into three sub-problems and solved via an alternate approximation method. Our simulation results demonstrate the effectiveness of the proposed RICS optimization in improving the safety in autonomous driving networks. ",
    "url": "https://arxiv.org/abs/2402.00398",
    "authors": [
      "Bo Yang",
      "Xueyao Zhang",
      "Zhiwen Yu",
      "Xuelin Cao",
      "Chongwen Huang",
      "George C. Alexandropoulos",
      "Yan Zhang",
      "Merouane Debbah",
      "Chau Yuen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.00404",
    "title": "Improving Critical Node Detection Using Neural Network-based  Initialization in a Genetic Algorithm",
    "abstract": "The Critical Node Problem (CNP) is concerned with identifying the critical nodes in a complex network. These nodes play a significant role in maintaining the connectivity of the network, and removing them can negatively impact network performance. CNP has been studied extensively due to its numerous real-world applications. Among the different versions of CNP, CNP-1a has gained the most popularity. The primary objective of CNP-1a is to minimize the pair-wise connectivity in the remaining network after deleting a limited number of nodes from a network. Due to the NP-hard nature of CNP-1a, many heuristic/metaheuristic algorithms have been proposed to solve this problem. However, most existing algorithms start with a random initialization, leading to a high cost of obtaining an optimal solution. To improve the efficiency of solving CNP-1a, a knowledge-guided genetic algorithm named K2GA has been proposed. Unlike the standard genetic algorithm framework, K2GA has two main components: a pretrained neural network to obtain prior knowledge on possible critical nodes, and a hybrid genetic algorithm with local search for finding an optimal set of critical nodes based on the knowledge given by the trained neural network. The local search process utilizes a cut node-based greedy strategy. The effectiveness of the proposed knowledgeguided genetic algorithm is verified by experiments on 26 realworld instances of complex networks. Experimental results show that K2GA outperforms the state-of-the-art algorithms regarding the best, median, and average objective values, and improves the best upper bounds on the best objective values for eight realworld instances. ",
    "url": "https://arxiv.org/abs/2402.00404",
    "authors": [
      "Chanjuan Liu",
      "Shike Ge",
      "Zhihan Chen",
      "Wenbin Pei",
      "Enqiang Zhu",
      "Yi Mei",
      "Hisao Ishibuchi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.00412",
    "title": "Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated  Student Essay Detection",
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in text generation tasks. However, the utilization of these models carries inherent risks, including but not limited to plagiarism, the dissemination of fake news, and issues in educational exercises. Although several detectors have been proposed to address these concerns, their effectiveness against adversarial perturbations, specifically in the context of student essay writing, remains largely unexplored. This paper aims to bridge this gap by constructing AIG-ASAP, an AI-generated student essay dataset, employing a range of text perturbation methods that are expected to generate high-quality essays while evading detection. Through empirical experiments, we assess the performance of current AIGC detectors on the AIG-ASAP dataset. The results reveal that the existing detectors can be easily circumvented using straightforward automatic adversarial attacks. Specifically, we explore word substitution and sentence substitution perturbation methods that effectively evade detection while maintaining the quality of the generated essays. This highlights the urgent need for more accurate and robust methods to detect AI-generated student essays in the education domain. ",
    "url": "https://arxiv.org/abs/2402.00412",
    "authors": [
      "Xinlin Peng",
      "Ying Zhou",
      "Ben He",
      "Le Sun",
      "Yingfei Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00418",
    "title": "Short: Benchmarking transferable adversarial attacks",
    "abstract": "The robustness of deep learning models against adversarial attacks remains a pivotal concern. This study presents, for the first time, an exhaustive review of the transferability aspect of adversarial attacks. It systematically categorizes and critically evaluates various methodologies developed to augment the transferability of adversarial attacks. This study encompasses a spectrum of techniques, including Generative Structure, Semantic Similarity, Gradient Editing, Target Modification, and Ensemble Approach. Concurrently, this paper introduces a benchmark framework \\textit{TAA-Bench}, integrating ten leading methodologies for adversarial attack transferability, thereby providing a standardized and systematic platform for comparative analysis across diverse model architectures. Through comprehensive scrutiny, we delineate the efficacy and constraints of each method, shedding light on their underlying operational principles and practical utility. This review endeavors to be a quintessential resource for both scholars and practitioners in the field, charting the complex terrain of adversarial transferability and setting a foundation for future explorations in this vital sector. The associated codebase is accessible at: https://github.com/KxPlaug/TAA-Bench ",
    "url": "https://arxiv.org/abs/2402.00418",
    "authors": [
      "Zhibo Jin",
      "Jiayu Zhang",
      "Zhiyu Zhu",
      "Huaming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00422",
    "title": "Lightweight Pixel Difference Networks for Efficient Visual  Representation Learning",
    "abstract": "Recently, there have been tremendous efforts in developing lightweight Deep Neural Networks (DNNs) with satisfactory accuracy, which can enable the ubiquitous deployment of DNNs in edge devices. The core challenge of developing compact and efficient DNNs lies in how to balance the competing goals of achieving high accuracy and high efficiency. In this paper we propose two novel types of convolutions, dubbed \\emph{Pixel Difference Convolution (PDC) and Binary PDC (Bi-PDC)} which enjoy the following benefits: capturing higher-order local differential information, computationally efficient, and able to be integrated with existing DNNs. With PDC and Bi-PDC, we further present two lightweight deep networks named \\emph{Pixel Difference Networks (PiDiNet)} and \\emph{Binary PiDiNet (Bi-PiDiNet)} respectively to learn highly efficient yet more accurate representations for visual tasks including edge detection and object recognition. Extensive experiments on popular datasets (BSDS500, ImageNet, LFW, YTF, \\emph{etc.}) show that PiDiNet and Bi-PiDiNet achieve the best accuracy-efficiency trade-off. For edge detection, PiDiNet is the first network that can be trained without ImageNet, and can achieve the human-level performance on BSDS500 at 100 FPS and with $<$1M parameters. For object recognition, among existing Binary DNNs, Bi-PiDiNet achieves the best accuracy and a nearly $2\\times$ reduction of computational cost on ResNet18. Code available at \\href{https://github.com/hellozhuo/pidinet}{https://github.com/hellozhuo/pidinet}. ",
    "url": "https://arxiv.org/abs/2402.00422",
    "authors": [
      "Zhuo Su",
      "Jiehua Zhang",
      "Longguang Wang",
      "Hua Zhang",
      "Zhen Liu",
      "Matti Pietik\u00e4inen",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00435",
    "title": "A practical existence theorem for reduced order models based on  convolutional autoencoders",
    "abstract": "In recent years, deep learning has gained increasing popularity in the fields of Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM), providing domain practitioners with new powerful data-driven techniques such as Physics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator Networks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context, deep autoencoders based on Convolutional Neural Networks (CNNs) have proven extremely effective, outperforming established techniques, such as the reduced basis method, when dealing with complex nonlinear problems. However, despite the empirical success of CNN-based autoencoders, there are only a few theoretical results supporting these architectures, usually stated in the form of universal approximation theorems. In particular, although the existing literature provides users with guidelines for designing convolutional autoencoders, the subsequent challenge of learning the latent features has been barely investigated. Furthermore, many practical questions remain unanswered, e.g., the number of snapshots needed for convergence or the neural network training strategy. In this work, using recent techniques from sparse high-dimensional function approximation, we fill some of these gaps by providing a new practical existence theorem for CNN-based autoencoders when the parameter-to-solution map is holomorphic. This regularity assumption arises in many relevant classes of parametric PDEs, such as the parametric diffusion equation, for which we discuss an explicit application of our general theory. ",
    "url": "https://arxiv.org/abs/2402.00435",
    "authors": [
      "Nicola Rares Franco",
      "Simone Brugiapaglia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00447",
    "title": "A Survey of Data-Efficient Graph Learning",
    "abstract": "Graph-structured data, prevalent in domains ranging from social networks to biochemical analysis, serve as the foundation for diverse real-world systems. While graph neural networks demonstrate proficiency in modeling this type of data, their success is often reliant on significant amounts of labeled data, posing a challenge in practical scenarios with limited annotation resources. To tackle this problem, tremendous efforts have been devoted to enhancing graph machine learning performance under low-resource settings by exploring various approaches to minimal supervision. In this paper, we introduce a novel concept of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the first survey that summarizes the current progress of DEGL. We initiate by highlighting the challenges inherent in training models with large labeled data, paving the way for our exploration into DEGL. Next, we systematically review recent advances on this topic from several key aspects, including self-supervised graph learning, semi-supervised graph learning, and few-shot graph learning. Also, we state promising directions for future research, contributing to the evolution of graph machine learning. ",
    "url": "https://arxiv.org/abs/2402.00447",
    "authors": [
      "Wei Ju",
      "Siyu Yi",
      "Yifan Wang",
      "Qingqing Long",
      "Junyu Luo",
      "Zhiping Xiao",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.00448",
    "title": "Dual-Student Knowledge Distillation Networks for Unsupervised Anomaly  Detection",
    "abstract": "Due to the data imbalance and the diversity of defects, student-teacher networks (S-T) are favored in unsupervised anomaly detection, which explores the discrepancy in feature representation derived from the knowledge distillation process to recognize anomalies. However, vanilla S-T network is not stable. Employing identical structures to construct the S-T network may weaken the representative discrepancy on anomalies. But using different structures can increase the likelihood of divergent performance on normal data. To address this problem, we propose a novel dual-student knowledge distillation (DSKD) architecture. Different from other S-T networks, we use two student networks a single pre-trained teacher network, where the students have the same scale but inverted structures. This framework can enhance the distillation effect to improve the consistency in recognition of normal data, and simultaneously introduce diversity for anomaly representation. To explore high-dimensional semantic information to capture anomaly clues, we employ two strategies. First, a pyramid matching mode is used to perform knowledge distillation on multi-scale feature maps in the intermediate layers of networks. Second, an interaction is facilitated between the two student networks through a deep feature embedding module, which is inspired by real-world group discussions. In terms of classification, we obtain pixel-wise anomaly segmentation maps by measuring the discrepancy between the output feature maps of the teacher and student networks, from which an anomaly score is computed for sample-wise determination. We evaluate DSKD on three benchmark datasets and probe the effects of internal modules through ablation experiments. The results demonstrate that DSKD can achieve exceptional performance on small models like ResNet18 and effectively improve vanilla S-T networks. ",
    "url": "https://arxiv.org/abs/2402.00448",
    "authors": [
      "Liyi Yao",
      "Shaobing Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00449",
    "title": "Efficient Training Spiking Neural Networks with Parallel Spiking Unit",
    "abstract": "Efficient parallel computing has become a pivotal element in advancing artificial intelligence. Yet, the deployment of Spiking Neural Networks (SNNs) in this domain is hampered by their inherent sequential computational dependency. This constraint arises from the need for each time step's processing to rely on the preceding step's outcomes, significantly impeding the adaptability of SNN models to massively parallel computing environments. Addressing this challenge, our paper introduces the innovative Parallel Spiking Unit (PSU) and its two derivatives, the Input-aware PSU (IPSU) and Reset-aware PSU (RPSU). These variants skillfully decouple the leaky integration and firing mechanisms in spiking neurons while probabilistically managing the reset process. By preserving the fundamental computational attributes of the spiking neuron model, our approach enables the concurrent computation of all membrane potential instances within the SNN, facilitating parallel spike output generation and substantially enhancing computational efficiency. Comprehensive testing across various datasets, including static and sequential images, Dynamic Vision Sensor (DVS) data, and speech datasets, demonstrates that the PSU and its variants not only significantly boost performance and simulation speed but also augment the energy efficiency of SNNs through enhanced sparsity in neural activity. These advancements underscore the potential of our method in revolutionizing SNN deployment for high-performance parallel computing applications. ",
    "url": "https://arxiv.org/abs/2402.00449",
    "authors": [
      "Yang Li",
      "Yinqian Sun",
      "Xiang He",
      "Yiting Dong",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.00496",
    "title": "Optimization of a Line Detection Algorithm for Autonomous Vehicles on a  RISC-V with Accelerator",
    "abstract": "In recent years, autonomous vehicles have attracted the attention of many research groups, both in academia and business, including researchers from leading companies such as Google, Uber and Tesla. This type of vehicles are equipped with systems that are subject to very strict requirements, essentially aimed at performing safe operations -- both for potential passengers and pedestrians -- as well as carrying out the processing needed for decision making in real time. In many instances, general-purpose processors alone cannot ensure that these safety, reliability and real-time requirements are met, so it is common to implement heterogeneous systems by including accelerators. This paper explores the acceleration of a line detection application in the autonomous car environment using a heterogeneous system consisting of a general-purpose RISC-V core and a domain-specific accelerator. In particular, the application is analyzed to identify the most computationally intensive parts of the code and it is adapted accordingly for more efficient processing. Furthermore, the code is executed on the aforementioned hardware platform to verify that the execution effectively meets the existing requirements in autonomous vehicles, experiencing a 3.7x speedup with respect to running without accelerator. ",
    "url": "https://arxiv.org/abs/2402.00496",
    "authors": [
      "Mar\u00eda Jos\u00e9 Belda",
      "Katzalin Olcoz",
      "Fernando Castro",
      "Francisco Tirado"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2402.00519",
    "title": "Towards Summarizing Code Snippets Using Pre-Trained Transformers",
    "abstract": "When comprehending code, a helping hand may come from the natural language comments documenting it that, unfortunately, are not always there. To support developers in such a scenario, several techniques have been presented to automatically generate natural language summaries for a given code. Most recent approaches exploit deep learning (DL) to automatically document classes or functions, while little effort has been devoted to more fine-grained documentation (e.g., documenting code snippets or even a single statement). Such a design choice is dictated by the availability of training data: For example, in the case of Java, it is easy to create datasets composed of pairs <Method, Javadoc> that can be fed to DL models to teach them how to summarize a method. Such a comment-to-code linking is instead non-trivial when it comes to inner comments documenting a few statements. In this work, we take all the steps needed to train a DL model to document code snippets. First, we manually built a dataset featuring 6.6k comments that have been (i) classified based on their type (e.g., code summary, TODO), and (ii) linked to the code statements they document. Second, we used such a dataset to train a multi-task DL model, taking as input a comment and being able to (i) classify whether it represents a \"code summary\" or not and (ii) link it to the code statements it documents. Our model identifies code summaries with 84% accuracy and is able to link them to the documented lines of code with recall and precision higher than 80%. Third, we run this model on 10k projects, identifying and linking code summaries to the documented code. This unlocked the possibility of building a large-scale dataset of documented code snippets that have then been used to train a new DL model able to document code snippets. A comparison with state-of-the-art baselines shows the superiority of the proposed approach. ",
    "url": "https://arxiv.org/abs/2402.00519",
    "authors": [
      "Antonio Mastropaolo",
      "Matteo Ciniselli",
      "Luca Pascarella",
      "Rosalia Tufano",
      "Emad Aghajani",
      "Gabriele Bavota"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.00531",
    "title": "Preconditioning for Physics-Informed Neural Networks",
    "abstract": "Physics-informed neural networks (PINNs) have shown promise in solving various partial differential equations (PDEs). However, training pathologies have negatively affected the convergence and prediction accuracy of PINNs, which further limits their practical applications. In this paper, we propose to use condition number as a metric to diagnose and mitigate the pathologies in PINNs. Inspired by classical numerical analysis, where the condition number measures sensitivity and stability, we highlight its pivotal role in the training dynamics of PINNs. We prove theorems to reveal how condition number is related to both the error control and convergence of PINNs. Subsequently, we present an algorithm that leverages preconditioning to improve the condition number. Evaluations of 18 PDE problems showcase the superior performance of our method. Significantly, in 7 of these problems, our method reduces errors by an order of magnitude. These empirical findings verify the critical role of the condition number in PINNs' training. ",
    "url": "https://arxiv.org/abs/2402.00531",
    "authors": [
      "Songming Liu",
      "Chang Su",
      "Jiachen Yao",
      "Zhongkai Hao",
      "Hang Su",
      "Youjia Wu",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.00534",
    "title": "A Manifold Representation of the Key in Vision Transformers",
    "abstract": "Vision Transformers implement multi-head self-attention (MSA) via stacking multiple attention blocks. The query, key, and value are often intertwined and generated within those blocks via a single, shared linear transformation. This paper explores the concept of disentangling the key from the query and value, and adopting a manifold representation for the key. Our experiments reveal that decoupling and endowing the key with a manifold structure can enhance the model performance. Specifically, ViT-B exhibits a 0.87% increase in top-1 accuracy, while Swin-T sees a boost of 0.52% in top-1 accuracy on the ImageNet-1K dataset, with eight charts in the manifold key. Our approach also yields positive results in object detection and instance segmentation tasks on the COCO dataset. Through detailed ablation studies, we establish that these performance gains are not merely due to the simplicity of adding more parameters and computations. Future research may investigate strategies for cutting the budget of such representations and aim for further performance improvements based on our findings. ",
    "url": "https://arxiv.org/abs/2402.00534",
    "authors": [
      "Li Meng",
      "Morten Goodwin",
      "Anis Yazidi",
      "Paal Engelstad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00537",
    "title": "Robust Path Planning via Learning from Demonstrations for Robotic  Catheters in Deformable Environments",
    "abstract": "Navigation through tortuous and deformable vessels using catheters with limited steering capability underscores the need for reliable path planning. State-of-the-art path planners do not fully account for the deformable nature of the environment. This work proposes a robust path planner via a learning from demonstrations method, named Curriculum Generative Adversarial Imitation Learning (C-GAIL). This path planning framework takes into account the interaction between steerable catheters and vessel walls and the deformable property of vessels. In-silico comparative experiments show that the proposed network achieves smaller targeting errors, and a higher success rate, compared to a state-of-the-art approach based on GAIL. The in-vitro validation experiments demonstrate that the path generated by the proposed C-GAIL path planner aligns better with the actual steering capability of the pneumatic artificial muscle-driven catheter utilized in this study. Therefore, the proposed approach can provide enhanced support to the user in navigating the catheter towards the target with greater precision, in contrast to the conventional centerline-following technique. The targeting and tracking errors are 1.26$\\pm$0.55mm and 5.18$\\pm$3.48mm, respectively. The proposed path planning framework exhibits superior performance in managing uncertainty associated with vessel deformation, thereby resulting in lower tracking errors. ",
    "url": "https://arxiv.org/abs/2402.00537",
    "authors": [
      "Zhen Li",
      "Chiara Lambranzi",
      "Di Wu",
      "Alice Segato",
      "Federico De Marco",
      "Emmanuel Vander Poorten",
      "Jenny Dankelman",
      "Elena De Momi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.00541",
    "title": "Masked Conditional Diffusion Model for Enhancing Deepfake Detection",
    "abstract": "Recent studies on deepfake detection have achieved promising results when training and testing faces are from the same dataset. However, their results severely degrade when confronted with forged samples that the model has not yet seen during training. In this paper, deepfake data to help detect deepfakes. this paper present we put a new insight into diffusion model-based data augmentation, and propose a Masked Conditional Diffusion Model (MCDM) for enhancing deepfake detection. It generates a variety of forged faces from a masked pristine one, encouraging the deepfake detection model to learn generic and robust representations without overfitting to special artifacts. Extensive experiments demonstrate that forgery images generated with our method are of high quality and helpful to improve the performance of deepfake detection models. ",
    "url": "https://arxiv.org/abs/2402.00541",
    "authors": [
      "Tiewen Chen",
      "Shanmin Yang",
      "Shu Hu",
      "Zhenghan Fang",
      "Ying Fu",
      "Xi Wu",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00564",
    "title": "A Single Graph Convolution Is All You Need: Efficient Grayscale Image  Classification",
    "abstract": "Image classifiers often rely on convolutional neural networks (CNN) for their tasks, which are inherently more heavyweight than multilayer perceptrons (MLPs), which can be problematic in real-time applications. Additionally, many image classification models work on both RGB and grayscale datasets. Classifiers that operate solely on grayscale images are much less common. Grayscale image classification has diverse applications, including but not limited to medical image classification and synthetic aperture radar (SAR) automatic target recognition (ATR). Thus, we present a novel grayscale (single channel) image classification approach using a vectorized view of images. We exploit the lightweightness of MLPs by viewing images as a vector and reducing our problem setting to the grayscale image classification setting. We find that using a single graph convolutional layer batch-wise increases accuracy and reduces variance in the performance of our model. Moreover, we develop a customized accelerator on FPGA for the proposed model with several optimizations to improve its performance. Our experimental results on benchmark grayscale image datasets demonstrate the effectiveness of the proposed model, achieving vastly lower latency (up to 16$\\times$ less) and competitive or leading performance compared to other state-of-the-art image classification models on various domain-specific grayscale image classification datasets. ",
    "url": "https://arxiv.org/abs/2402.00564",
    "authors": [
      "Jacob Fein-Ashley",
      "Tian Ye",
      "Sachini Wickramasinghe",
      "Bingyi Zhang",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00576",
    "title": "Tropical Decision Boundaries for Neural Networks Are Robust Against  Adversarial Attacks",
    "abstract": "We introduce a simple, easy to implement, and computationally efficient tropical convolutional neural network architecture that is robust against adversarial attacks. We exploit the tropical nature of piece-wise linear neural networks by embedding the data in the tropical projective torus in a single hidden layer which can be added to any model. We study the geometry of its decision boundary theoretically and show its robustness against adversarial attacks on image datasets using computational experiments. ",
    "url": "https://arxiv.org/abs/2402.00576",
    "authors": [
      "Kurt Pasque",
      "Christopher Teska",
      "Ruriko Yoshida",
      "Keiji Miura",
      "Jefferson Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.00588",
    "title": "BrainSLAM: SLAM on Neural Population Activity Data",
    "abstract": "Simultaneous localisation and mapping (SLAM) algorithms are commonly used in robotic systems for learning maps of novel environments. Brains also appear to learn maps, but the mechanisms are not known and it is unclear how to infer these maps from neural activity data. We present BrainSLAM; a method for performing SLAM using only population activity (local field potential, LFP) data simultaneously recorded from three brain regions in rats: hippocampus, prefrontal cortex, and parietal cortex. This system uses a convolutional neural network (CNN) to decode velocity and familiarity information from wavelet scalograms of neural local field potential data recorded from rats as they navigate a 2D maze. The CNN's output drives a RatSLAM-inspired architecture, powering an attractor network which performs path integration plus a separate system which performs `loop closure' (detecting previously visited locations and correcting map aliasing errors). Together, these three components can construct faithful representations of the environment while simultaneously tracking the animal's location. This is the first demonstration of inference of a spatial map from brain recordings. Our findings expand SLAM to a new modality, enabling a new method of mapping environments and facilitating a better understanding of the role of cognitive maps in navigation and decision making. ",
    "url": "https://arxiv.org/abs/2402.00588",
    "authors": [
      "Kipp Freud",
      "Nathan Lepora",
      "Matt W. Jones",
      "Cian O'Donnell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2402.00626",
    "title": "Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks",
    "abstract": "Recently, significant progress has been made on Large Vision-Language Models (LVLMs); a new class of VL models that make use of large pre-trained language models. Yet, their vulnerability to Typographic attacks, which involve superimposing misleading text onto an image remain unstudied. Furthermore, prior work typographic attacks rely on sampling a random misleading class from a predefined set of classes. However, the random chosen class might not be the most effective attack. To address these issues, we first introduce a novel benchmark uniquely designed to test LVLMs vulnerability to typographic attacks. Furthermore, we introduce a new and more effective typographic attack: Self-Generated typographic attacks. Indeed, our method, given an image, make use of the strong language capabilities of models like GPT-4V by simply prompting them to recommend a typographic attack. Using our novel benchmark, we uncover that typographic attacks represent a significant threat against LVLM(s). Furthermore, we uncover that typographic attacks recommended by GPT-4V using our new method are not only more effective against GPT-4V itself compared to prior work attacks, but also against a host of less capable yet popular open source models like LLaVA, InstructBLIP, and MiniGPT4. ",
    "url": "https://arxiv.org/abs/2402.00626",
    "authors": [
      "Maan Qraitem",
      "Nazia Tasnim",
      "Kate Saenko",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00631",
    "title": "SeFi-IDE: Semantic-Fidelity Identity Embedding for Personalized  Diffusion-Based Generation",
    "abstract": "Advanced diffusion-based Text-to-Image (T2I) models, such as the Stable Diffusion Model, have made significant progress in generating diverse and high-quality images using text prompts alone. However, T2I models are unable to accurately map identities (IDs) when non-famous users require personalized image generation. The main problem is that existing T2I models do not learn the ID-image alignments of new users. The previous methods either failed to accurately fit the face region or lost the interactive generative ability with other existing concepts in T2I models (i.e., unable to generate other concepts described in given prompts such as scenes, actions, and facial attributes). In this paper, we focus on accurate and semantic-fidelity ID embedding into the Stable Diffusion Model for personalized generation. We address this challenge from two perspectives: face-wise region fitting, and semantic-fidelity token optimization. Specifically, we first visualize the attention overfit problem, and propose a face-wise attention loss to fit the face region instead of the whole target image. This key trick significantly enhances the ID accuracy and interactive generative ability with other existing concepts. Then, we optimize one ID representation as multiple per-stage tokens where each token contains two disentangled features. This expansion of the textual conditioning space enhances semantic-fidelity control. Extensive experiments validate that our results exhibit superior ID accuracy and manipulation ability compared to previous methods. ",
    "url": "https://arxiv.org/abs/2402.00631",
    "authors": [
      "Yang Li",
      "Songlin Yang",
      "Wei Wang",
      "Jing Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00638",
    "title": "Random Forest-Based Prediction of Stroke Outcome",
    "abstract": "We research into the clinical, biochemical and neuroimaging factors associated with the outcome of stroke patients to generate a predictive model using machine learning techniques for prediction of mortality and morbidity 3 months after admission. The dataset consisted of patients with ischemic stroke (IS) and non-traumatic intracerebral hemorrhage (ICH) admitted to Stroke Unit of a European Tertiary Hospital prospectively registered. We identified the main variables for machine learning Random Forest (RF), generating a predictive model that can estimate patient mortality/morbidity. In conclusion, machine learning algorithms RF can be effectively used in stroke patients for long-term outcome prediction of mortality and morbidity. ",
    "url": "https://arxiv.org/abs/2402.00638",
    "authors": [
      "Carlos Fernandez-Lozano",
      "Pablo Hervella",
      "Virginia Mato-Abad",
      "Manuel Rodriguez-Yanez",
      "Sonia Suarez-Garaboa",
      "Iria Lopez-Dequidt",
      "Ana Estany-Gestal",
      "Tomas Sobrino",
      "Francisco Campos",
      "Jose Castillo",
      "Santiago Rodriguez-Yanez",
      "Ramon Iglesias-Rey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00657",
    "title": "Pre-training by Predicting Program Dependencies for Vulnerability  Analysis Tasks",
    "abstract": "Vulnerability analysis is crucial for software security. This work focuses on using pre-training techniques to enhance the understanding of vulnerable code and boost vulnerability analysis. The code understanding ability of a pre-trained model is highly related to its pre-training objectives. The semantic structure, e.g., control and data dependencies, of code is important for vulnerability analysis. However, existing pre-training objectives either ignore such structure or focus on learning to use it. The feasibility and benefits of learning the knowledge of analyzing semantic structure have not been investigated. To this end, this work proposes two novel pre-training objectives, namely Control Dependency Prediction (CDP) and Data Dependency Prediction (DDP), which aim to predict the statement-level control dependencies and token-level data dependencies, respectively, in a code snippet only based on its source code. During pre-training, CDP and DDP can guide the model to learn the knowledge required for analyzing fine-grained dependencies in code. After pre-training, the pre-trained model can boost the understanding of vulnerable code during fine-tuning and can directly be used to perform dependence analysis for both partial and complete functions. To demonstrate the benefits of our pre-training objectives, we pre-train a Transformer model named PDBERT with CDP and DDP, fine-tune it on three vulnerability analysis tasks, i.e., vulnerability detection, vulnerability classification, and vulnerability assessment, and also evaluate it on program dependence analysis. Experimental results show that PDBERT benefits from CDP and DDP, leading to state-of-the-art performance on the three downstream tasks. Also, PDBERT achieves F1-scores of over 99% and 94% for predicting control and data dependencies, respectively, in partial and complete functions. ",
    "url": "https://arxiv.org/abs/2402.00657",
    "authors": [
      "Zhongxin Liu",
      "Zhijie Tang",
      "Junwei Zhang",
      "Xin Xia",
      "Xiaohu Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.00663",
    "title": "Transferring human emotions to robot motions using Neural Policy Style  Transfer",
    "abstract": "Neural Style Transfer (NST) was originally proposed to use feature extraction capabilities of Neural Networks as a way to perform Style Transfer with images. Pre-trained image classification architectures were selected for feature extraction, leading to new images showing the same content as the original but with a different style. In robotics, Style Transfer can be employed to transfer human motion styles to robot motions. The challenge lies in the lack of pre-trained classification architectures for robot motions that could be used for feature extraction. Neural Policy Style Transfer TD3 (NPST3) is proposed for the transfer of human motion styles to robot motions. This framework allows the same robot motion to be executed in different human-centered motion styles, such as in an angry, happy, calm, or sad fashion. The Twin Delayed Deep Deterministic Policy Gradient (TD3) network is introduced for the generation of control policies. An autoencoder network is in charge of feature extraction for the Style Transfer step. The Style Transfer step can be performed both offline and online: offline for the autonomous executions of human-style robot motions, and online for adapting at runtime the style of e.g., a teleoperated robot. The framework is tested using two different robotic platforms: a robotic manipulator designed for telemanipulation tasks, and a humanoid robot designed for social interaction. The proposed approach was evaluated for both platforms, performing a total of 147 questionnaires asking human subjects to recognize the human motion style transferred to the robot motion for a predefined set of actions. ",
    "url": "https://arxiv.org/abs/2402.00663",
    "authors": [
      "Raul Fernandez-Fernandez",
      "Bartek \u0141ukawski",
      "Juan G. Victores",
      "Claudio Pacchierotti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.00672",
    "title": "Exploring Homogeneous and Heterogeneous Consistent Label Associations  for Unsupervised Visible-Infrared Person ReID",
    "abstract": "Unsupervised visible-infrared person re-identification (USL-VI-ReID) aims to retrieve pedestrian images of the same identity from different modalities without annotations. While prior work focuses on establishing cross-modality pseudo-label associations to bridge the modality-gap, they ignore maintaining the instance-level homogeneous and heterogeneous consistency in pseudo-label space, resulting in coarse associations. In response, we introduce a Modality-Unified Label Transfer (MULT) module that simultaneously accounts for both homogeneous and heterogeneous fine-grained instance-level structures, yielding high-quality cross-modality label associations. It models both homogeneous and heterogeneous affinities, leveraging them to define the inconsistency for the pseudo-labels and then minimize it, leading to pseudo-labels that maintain alignment across modalities and consistency within intra-modality structures. Additionally, a straightforward plug-and-play Online Cross-memory Label Refinement (OCLR) module is proposed to further mitigate the impact of noisy pseudo-labels while simultaneously aligning different modalities, coupled with a Modality-Invariant Representation Learning (MIRL) framework. Experiments demonstrate that our proposed method outperforms existing USL-VI-ReID methods, highlighting the superiority of our MULT in comparison to other cross-modality association methods. The code will be available. ",
    "url": "https://arxiv.org/abs/2402.00672",
    "authors": [
      "Lingfeng He",
      "De Cheng",
      "Nannan Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00676",
    "title": "Deep Robot Sketching: An application of Deep Q-Learning Networks for  human-like sketching",
    "abstract": "The current success of Reinforcement Learning algorithms for its performance in complex environments has inspired many recent theoretical approaches to cognitive science. Artistic environments are studied within the cognitive science community as rich, natural, multi-sensory, multi-cultural environments. In this work, we propose the introduction of Reinforcement Learning for improving the control of artistic robot applications. Deep Q-learning Neural Networks (DQN) is one of the most successful algorithms for the implementation of Reinforcement Learning in robotics. DQN methods generate complex control policies for the execution of complex robot applications in a wide set of environments. Current art painting robot applications use simple control laws that limits the adaptability of the frameworks to a set of simple environments. In this work, the introduction of DQN within an art painting robot application is proposed. The goal is to study how the introduction of a complex control policy impacts the performance of a basic art painting robot application. The main expected contribution of this work is to serve as a first baseline for future works introducing DQN methods for complex art painting robot frameworks. Experiments consist of real world executions of human drawn sketches using the DQN generated policy and TEO, the humanoid robot. Results are compared in terms of similarity and obtained reward with respect to the reference inputs ",
    "url": "https://arxiv.org/abs/2402.00676",
    "authors": [
      "Raul Fernandez-Fernandez",
      "Juan G. Victores",
      "Carlos Balaguer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.00677",
    "title": "Neural Policy Style Transfer",
    "abstract": "Style Transfer has been proposed in a number of fields: fine arts, natural language processing, and fixed trajectories. We scale this concept up to control policies within a Deep Reinforcement Learning infrastructure. Each network is trained to maximize the expected reward, which typically encodes the goal of an action, and can be described as the content. The expressive power of deep neural networks enables encoding a secondary task, which can be described as the style. The Neural Policy Style Transfer (NPST) algorithm is proposed to transfer the style of one policy to another, while maintaining the content of the latter. Different policies are defined via Deep Q-Network architectures. These models are trained using demonstrations through Inverse Reinforcement Learning. Two different sets of user demonstrations are performed, one for content and other for style. Different styles are encoded as defined by user demonstrations. The generated policy is the result of feeding a content policy and a style policy to the NPST algorithm. Experiments are performed in a catch-ball game inspired by the Deep Reinforcement Learning classical Atari games; and a real-world painting scenario with a full-sized humanoid robot, based on previous works of the authors. The implementation of three different Q-Network architectures (Shallow, Deep and Deep Recurrent Q-Network) to encode the policies within the NPST framework is proposed and the results obtained in the experiments with each of these architectures compared. ",
    "url": "https://arxiv.org/abs/2402.00677",
    "authors": [
      "Raul Fernandez-Fernandez",
      "Juan G. Victores",
      "Jennifer J. Gago",
      "David Estevez",
      "Carlos Balaguer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.00683",
    "title": "WayFASTER: a Self-Supervised Traversability Prediction for Increased  Navigation Awareness",
    "abstract": "Accurate and robust navigation in unstructured environments requires fusing data from multiple sensors. Such fusion ensures that the robot is better aware of its surroundings, including areas of the environment that are not immediately visible, but were visible at a different time. To solve this problem, we propose a method for traversability prediction in challenging outdoor environments using a sequence of RGB and depth images fused with pose estimations. Our method, termed WayFASTER (Waypoints-Free Autonomous System for Traversability with Enhanced Robustness), uses experience data recorded from a receding horizon estimator to train a self-supervised neural network for traversability prediction, eliminating the need for heuristics. Our experiments demonstrate that our method excels at avoiding geometric obstacles, and correctly detects that traversable terrains, such as tall grass, can be navigable. By using a sequence of images, WayFASTER significantly enhances the robot's awareness of its surroundings, enabling it to predict the traversability of terrains that are not immediately visible. This enhanced awareness contributes to better navigation performance in environments where such predictive capabilities are essential. ",
    "url": "https://arxiv.org/abs/2402.00683",
    "authors": [
      "Mateus Valverde Gasparino",
      "Arun Narenthiran Sivakumar",
      "Girish Chowdhary"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.00689",
    "title": "Ocassionally Secure: A Comparative Analysis of Code Generation  Assistants",
    "abstract": "$ $Large Language Models (LLMs) are being increasingly utilized in various applications, with code generations being a notable example. While previous research has shown that LLMs have the capability to generate both secure and insecure code, the literature does not take into account what factors help generate secure and effective code. Therefore in this paper we focus on identifying and understanding the conditions and contexts in which LLMs can be effectively and safely deployed in real-world scenarios to generate quality code. We conducted a comparative analysis of four advanced LLMs--GPT-3.5 and GPT-4 using ChatGPT and Bard and Gemini from Google--using 9 separate tasks to assess each model's code generation capabilities. We contextualized our study to represent the typical use cases of a real-life developer employing LLMs for everyday tasks as work. Additionally, we place an emphasis on security awareness which is represented through the use of two distinct versions of our developer persona. In total, we collected 61 code outputs and analyzed them across several aspects: functionality, security, performance, complexity, and reliability. These insights are crucial for understanding the models' capabilities and limitations, guiding future development and practical applications in the field of automated code generation. ",
    "url": "https://arxiv.org/abs/2402.00689",
    "authors": [
      "Ran Elgedawy",
      "John Sadik",
      "Senjuti Dutta",
      "Anuj Gautam",
      "Konstantinos Georgiou",
      "Farzin Gholamrezae",
      "Fujiao Ji",
      "Kyungchan Lim",
      "Qian Liu",
      "Scott Ruoti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00692",
    "title": "A Framework for Building Point Cloud Cleaning, Plane Detection and  Semantic Segmentation",
    "abstract": "This paper presents a framework to address the challenges involved in building point cloud cleaning, plane detection, and semantic segmentation, with the ultimate goal of enhancing building modeling. We focus in the cleaning stage on removing outliers from the acquired point cloud data by employing an adaptive threshold technique based on z-score measure. Following the cleaning process, we perform plane detection using the robust RANSAC paradigm. The goal is to carry out multiple plane segmentations, and to classify segments into distinct categories, such as floors, ceilings, and walls. The resulting segments can generate accurate and detailed point clouds representing the building's architectural elements. Moreover, we address the problem of semantic segmentation, which plays a vital role in the identification and classification of different components within the building, such as walls, windows, doors, roofs, and objects. Inspired by the PointNet architecture, we propose a deep learning architecture for efficient semantic segmentation in buildings. The results demonstrate the effectiveness of the proposed framework in handling building modeling tasks, paving the way for improved accuracy and efficiency in the field of building modelization. ",
    "url": "https://arxiv.org/abs/2402.00692",
    "authors": [
      "Ilyass Abouelaziz",
      "Youssef Mourchid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00695",
    "title": "Approximating Optimal Morphing Attacks using Template Inversion",
    "abstract": "Recent works have demonstrated the feasibility of inverting face recognition systems, enabling to recover convincing face images using only their embeddings. We leverage such template inversion models to develop a novel type ofdeep morphing attack based on inverting a theoretical optimal morph embedding, which is obtained as an average of the face embeddings of source images. We experiment with two variants of this approach: the first one exploits a fully self-contained embedding-to-image inversion model, while the second leverages the synthesis network of a pretrained StyleGAN network for increased morph realism. We generate morphing attacks from several source datasets and study the effectiveness of those attacks against several face recognition networks. We showcase that our method can compete with and regularly beat the previous state of the art for deep-learning based morph generation in terms of effectiveness, both in white-box and black-box attack scenarios, and is additionally much faster to run. We hope this might facilitate the development of large scale deep morph datasets for training detection models. ",
    "url": "https://arxiv.org/abs/2402.00695",
    "authors": [
      "Laurent Colbois",
      "Hatef Otroshi Shahreza",
      "S\u00e9bastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00712",
    "title": "ChaosBench: A Multi-Channel, Physics-Based Benchmark for  Subseasonal-to-Seasonal Climate Prediction",
    "abstract": "Accurate prediction of climate in the subseasonal-to-seasonal scale is crucial for disaster readiness, reduced economic risk, and improved policy-making amidst climate change. Yet, S2S prediction remains challenging due to the chaotic nature of the system. At present, existing benchmarks for weather and climate applications, tend to (1) have shorter forecasting range of up-to 14 days, (2) do not include a wide range of operational baseline forecasts, and (3) lack physics-based constraints for explainability. Thus, we propose ChaosBench, a large-scale, multi-channel, physics-based benchmark for S2S prediction. ChaosBench has over 460K frames of real-world observations and simulations, each with 60 variable-channels and spanning for up-to 45 years. We also propose several physics-based, in addition to vision-based metrics, that enables for a more physically-consistent model. Furthermore, we include a diverse set of physics-based forecasts from 4 national weather agencies as baselines to our data-driven counterpart. We establish two tasks that vary in complexity: full and sparse dynamics prediction. Our benchmark is one of the first to perform large-scale evaluation on existing models including PanguWeather, FourCastNetV2, GraphCast, and ClimaX, and finds methods originally developed for weather-scale applications fails on S2S task. We release our benchmark code and datasets at https://leap-stc.github.io/ChaosBench. ",
    "url": "https://arxiv.org/abs/2402.00712",
    "authors": [
      "Juan Nathaniel",
      "Yongquan Qu",
      "Tung Nguyen",
      "Sungduk Yu",
      "Julius Busecke",
      "Aditya Grover",
      "Pierre Gentine"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.00722",
    "title": "Neural Style Transfer with Twin-Delayed DDPG for Shared Control of  Robotic Manipulators",
    "abstract": "Neural Style Transfer (NST) refers to a class of algorithms able to manipulate an element, most often images, to adopt the appearance or style of another one. Each element is defined as a combination of Content and Style: the Content can be conceptually defined as the what and the Style as the how of said element. In this context, we propose a custom NST framework for transferring a set of styles to the motion of a robotic manipulator, e.g., the same robotic task can be carried out in an angry, happy, calm, or sad way. An autoencoder architecture extracts and defines the Content and the Style of the target robot motions. A Twin Delayed Deep Deterministic Policy Gradient (TD3) network generates the robot control policy using the loss defined by the autoencoder. The proposed Neural Policy Style Transfer TD3 (NPST3) alters the robot motion by introducing the trained style. Such an approach can be implemented either offline, for carrying out autonomous robot motions in dynamic environments, or online, for adapting at runtime the style of a teleoperated robot. The considered styles can be learned online from human demonstrations. We carried out an evaluation with human subjects enrolling 73 volunteers, asking them to recognize the style behind some representative robotic motions. Results show a good recognition rate, proving that it is possible to convey different styles to a robot using this approach. ",
    "url": "https://arxiv.org/abs/2402.00722",
    "authors": [
      "Raul Fernandez-Fernandez",
      "Marco Aggravi",
      "Paolo Robuffo Giordano",
      "Juan G. Victores",
      "Claudio Pacchierotti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.00740",
    "title": "DRSM: efficient neural 4d decomposition for dynamic reconstruction in  stationary monocular cameras",
    "abstract": "With the popularity of monocular videos generated by video sharing and live broadcasting applications, reconstructing and editing dynamic scenes in stationary monocular cameras has become a special but anticipated technology. In contrast to scene reconstructions that exploit multi-view observations, the problem of modeling a dynamic scene from a single view is significantly more under-constrained and ill-posed. Inspired by recent progress in neural rendering, we present a novel framework to tackle 4D decomposition problem for dynamic scenes in monocular cameras. Our framework utilizes decomposed static and dynamic feature planes to represent 4D scenes and emphasizes the learning of dynamic regions through dense ray casting. Inadequate 3D clues from a single-view and occlusion are also particular challenges in scene reconstruction. To overcome these difficulties, we propose deep supervised optimization and ray casting strategies. With experiments on various videos, our method generates higher-fidelity results than existing methods for single-view dynamic scene representation. ",
    "url": "https://arxiv.org/abs/2402.00740",
    "authors": [
      "Weixing Xie",
      "Xiao Dong",
      "Yong Yang",
      "Qiqin Lin",
      "Jingze Chen",
      "Junfeng Yao",
      "Xiaohu Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00746",
    "title": "Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model",
    "abstract": "Artificial intelligence (AI) in healthcare has significantly advanced intelligent medical treatment. However, traditional intelligent healthcare is limited by static data and unified standards, preventing full integration with individual situations and other challenges. Hence, a more professional and detailed intelligent healthcare method is needed for development. To this end, we propose an innovative framework named Heath-LLM, which combines large-scale feature extraction and medical knowledge trade-off scoring. Compared to traditional health management methods, our approach has three main advantages. First, our method integrates health reports into a large model to provide detailed task information. Second, professional medical expertise is used to adjust the weighted scores of health characteristics. Third, we use a semi-automated feature extraction framework to enhance the analytical power of language models and incorporate expert insights to improve the accuracy of disease prediction. We have conducted disease prediction experiments on a large number of health reports to assess the effectiveness of Health-LLM. The results of the experiments indicate that the proposed method surpasses traditional methods and has the potential to revolutionize disease prediction and personalized health management. The code is available at https://github.com/jmyissb/HealthLLM. ",
    "url": "https://arxiv.org/abs/2402.00746",
    "authors": [
      "Mingyu Jin",
      "Qinkai Yu",
      "Chong Zhang",
      "Dong Shu",
      "Suiyuan Zhu",
      "Mengnan Du",
      "Yongfeng Zhang",
      "Yanda Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.00761",
    "title": "Control-Theoretic Techniques for Online Adaptation of Deep Neural  Networks in Dynamical Systems",
    "abstract": "Deep neural networks (DNNs), trained with gradient-based optimization and backpropagation, are currently the primary tool in modern artificial intelligence, machine learning, and data science. In many applications, DNNs are trained offline, through supervised learning or reinforcement learning, and deployed online for inference. However, training DNNs with standard backpropagation and gradient-based optimization gives no intrinsic performance guarantees or bounds on the DNN, which is essential for applications such as controls. Additionally, many offline-training and online-inference problems, such as sim2real transfer of reinforcement learning policies, experience domain shift from the training distribution to the real-world distribution. To address these stability and transfer learning issues, we propose using techniques from control theory to update DNN parameters online. We formulate the fully-connected feedforward DNN as a continuous-time dynamical system, and we propose novel last-layer update laws that guarantee desirable error convergence under various conditions on the time derivative of the DNN input vector. We further show that training the DNN under spectral normalization controls the upper bound of the error trajectories of the online DNN predictions, which is desirable when numerically differentiated quantities or noisy state measurements are input to the DNN. The proposed online DNN adaptation laws are validated in simulation to learn the dynamics of the Van der Pol system under domain shift, where parameters are varied in inference from the training dataset. The simulations demonstrate the effectiveness of using control-theoretic techniques to derive performance improvements and guarantees in DNN-based learning systems. ",
    "url": "https://arxiv.org/abs/2402.00761",
    "authors": [
      "Jacob G. Elkins",
      "Farbod Fahimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.00774",
    "title": "Mesh motion in fluid-structure interaction with deep operator networks",
    "abstract": "A mesh motion model based on deep operator networks is presented. The model is trained on and evaluated against a biharmonic mesh motion model on a fluid-structure interaction benchmark problem and further evaluated in a setting where biharmonic mesh motion fails. The performance of the proposed mesh motion model is comparable to the biharmonic mesh motion on the test problems. ",
    "url": "https://arxiv.org/abs/2402.00774",
    "authors": [
      "Ottar Hellan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00787",
    "title": "Learning and Calibrating Heterogeneous Bounded Rational Market Behaviour  with Multi-Agent Reinforcement Learning",
    "abstract": "Agent-based models (ABMs) have shown promise for modelling various real world phenomena incompatible with traditional equilibrium analysis. However, a critical concern is the manual definition of behavioural rules in ABMs. Recent developments in multi-agent reinforcement learning (MARL) offer a way to address this issue from an optimisation perspective, where agents strive to maximise their utility, eliminating the need for manual rule specification. This learning-focused approach aligns with established economic and financial models through the use of rational utility-maximising agents. However, this representation departs from the fundamental motivation for ABMs: that realistic dynamics emerging from bounded rationality and agent heterogeneity can be modelled. To resolve this apparent disparity between the two approaches, we propose a novel technique for representing heterogeneous processing-constrained agents within a MARL framework. The proposed approach treats agents as constrained optimisers with varying degrees of strategic skills, permitting departure from strict utility maximisation. Behaviour is learnt through repeated simulations with policy gradients to adjust action likelihoods. To allow efficient computation, we use parameterised shared policy learning with distributions of agent skill levels. Shared policy learning avoids the need for agents to learn individual policies yet still enables a spectrum of bounded rational behaviours. We validate our model's effectiveness using real-world data on a range of canonical $n$-agent settings, demonstrating significantly improved predictive capability. ",
    "url": "https://arxiv.org/abs/2402.00787",
    "authors": [
      "Benjamin Patrick Evans",
      "Sumitra Ganesh"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2402.00789",
    "title": "Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective  State Spaces",
    "abstract": "Attention mechanisms have been widely used to capture long-range dependencies among nodes in Graph Transformers. Bottlenecked by the quadratic computational cost, attention mechanisms fail to scale in large graphs. Recent improvements in computational efficiency are mainly achieved by attention sparsification with random or heuristic-based graph subsampling, which falls short in data-dependent context reasoning. State space models (SSMs), such as Mamba, have gained prominence for their effectiveness and efficiency in modeling long-range dependencies in sequential data. However, adapting SSMs to non-sequential graph data presents a notable challenge. In this work, we introduce Graph-Mamba, the first attempt to enhance long-range context modeling in graph networks by integrating a Mamba block with the input-dependent node selection mechanism. Specifically, we formulate graph-centric node prioritization and permutation strategies to enhance context-aware reasoning, leading to a substantial improvement in predictive performance. Extensive experiments on ten benchmark datasets demonstrate that Graph-Mamba outperforms state-of-the-art methods in long-range graph prediction tasks, with a fraction of the computational cost in both FLOPs and GPU memory consumption. The code and models are publicly available at https://github.com/bowang-lab/Graph-Mamba. ",
    "url": "https://arxiv.org/abs/2402.00789",
    "authors": [
      "Chloe Wang",
      "Oleksii Tsepa",
      "Jun Ma",
      "Bo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00793",
    "title": "Distinguishing the Indistinguishable: Human Expertise in Algorithmic  Prediction",
    "abstract": "We introduce a novel framework for incorporating human expertise into algorithmic predictions. Our approach focuses on the use of human judgment to distinguish inputs which `look the same' to any feasible predictive algorithm. We argue that this framing clarifies the problem of human/AI collaboration in prediction tasks, as experts often have access to information -- particularly subjective information -- which is not encoded in the algorithm's training data. We use this insight to develop a set of principled algorithms for selectively incorporating human feedback only when it improves the performance of any feasible predictor. We find empirically that although algorithms often outperform their human counterparts on average, human judgment can significantly improve algorithmic predictions on specific instances (which can be identified ex-ante). In an X-ray classification task, we find that this subset constitutes nearly 30% of the patient population. Our approach provides a natural way of uncovering this heterogeneity and thus enabling effective human-AI collaboration. ",
    "url": "https://arxiv.org/abs/2402.00793",
    "authors": [
      "Rohan Alur",
      "Manish Raghavan",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.00795",
    "title": "LLMs learn governing principles of dynamical systems, revealing an  in-context neural scaling law",
    "abstract": "Pretrained large language models (LLMs) are surprisingly effective at performing zero-shot tasks, including time-series forecasting. However, understanding the mechanisms behind such capabilities remains highly challenging due to the complexity of the models. In this paper, we study LLMs' ability to extrapolate the behavior of dynamical systems whose evolution is governed by principles of physical interest. Our results show that LLaMA 2, a language model trained primarily on texts, achieves accurate predictions of dynamical system time series without fine-tuning or prompt engineering. Moreover, the accuracy of the learned physical rules increases with the length of the input context window, revealing an in-context version of neural scaling law. Along the way, we present a flexible and efficient algorithm for extracting probability density functions of multi-digit numbers directly from LLMs. ",
    "url": "https://arxiv.org/abs/2402.00795",
    "authors": [
      "Toni J.B. Liu",
      "Nicolas Boull\u00e9",
      "Rapha\u00ebl Sarfati",
      "Christopher J. Earls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00822",
    "title": "WiOpen: A Robust Wi-Fi-based Open-set Gesture Recognition Framework",
    "abstract": "Recent years have witnessed a growing interest in Wi-Fi-based gesture recognition. However, existing works have predominantly focused on closed-set paradigms, where all testing gestures are predefined during training. This poses a significant challenge in real-world applications, as unseen gestures might be misclassified as known classes during testing. To address this issue, we propose WiOpen, a robust Wi-Fi-based Open-Set Gesture Recognition (OSGR) framework. Implementing OSGR requires addressing challenges caused by the unique uncertainty in Wi-Fi sensing. This uncertainty, resulting from noise and domains, leads to widely scattered and irregular data distributions in collected Wi-Fi sensing data. Consequently, data ambiguity between classes and challenges in defining appropriate decision boundaries to identify unknowns arise. To tackle these challenges, WiOpen adopts a two-fold approach to eliminate uncertainty and define precise decision boundaries. Initially, it addresses uncertainty induced by noise during data preprocessing by utilizing the CSI ratio. Next, it designs the OSGR network based on an uncertainty quantification method. Throughout the learning process, this network effectively mitigates uncertainty stemming from domains. Ultimately, the network leverages relationships among samples' neighbors to dynamically define open-set decision boundaries, successfully realizing OSGR. Comprehensive experiments on publicly accessible datasets confirm WiOpen's effectiveness. Notably, WiOpen also demonstrates superiority in cross-domain tasks when compared to state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2402.00822",
    "authors": [
      "Xiang Zhang",
      "Jingyang Huang",
      "Huan Yan",
      "Peng Zhao",
      "Guohang Zhuang",
      "Zhi Liu",
      "Bin Liu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00825",
    "title": "Resolution invariant deep operator network for PDEs with complex  geometries",
    "abstract": "Neural operators (NO) are discretization invariant deep learning methods with functional output and can approximate any continuous operator. NO have demonstrated the superiority of solving partial differential equations (PDEs) over other deep learning methods. However, the spatial domain of its input function needs to be identical to its output, which limits its applicability. For instance, the widely used Fourier neural operator (FNO) fails to approximate the operator that maps the boundary condition to the PDE solution. To address this issue, we propose a novel framework called resolution-invariant deep operator (RDO) that decouples the spatial domain of the input and output. RDO is motivated by the Deep operator network (DeepONet) and it does not require retraining the network when the input/output is changed compared with DeepONet. RDO takes functional input and its output is also functional so that it keeps the resolution invariant property of NO. It can also resolve PDEs with complex geometries whereas NO fail. Various numerical experiments demonstrate the advantage of our method over DeepONet and FNO. ",
    "url": "https://arxiv.org/abs/2402.00825",
    "authors": [
      "Jianguo Huang",
      "Yue Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00831",
    "title": "A YANG-aided Unified Strategy for Black Hole Detection for Backbone  Networks",
    "abstract": "Despite the crucial importance of addressing Black Hole failures in Internet backbone networks, effective detection strategies in backbone networks are lacking. This is largely because previous research has been centered on Mobile Ad-hoc Networks (MANETs), which operate under entirely different dynamics, protocols, and topologies, making their findings not directly transferable to backbone networks. Furthermore, detecting Black Hole failures in backbone networks is particularly challenging. It requires a comprehensive range of network data due to the wide variety of conditions that need to be considered, making data collection and analysis far from straightforward. Addressing this gap, our study introduces a novel approach for Black Hole detection in backbone networks using specialized Yet Another Next Generation (YANG) data models with Black Hole-sensitive Metric Matrix (BHMM) analysis. This paper details our method of selecting and analyzing four YANG models relevant to Black Hole detection in ISP networks, focusing on routing protocols and ISP-specific configurations. Our BHMM approach derived from these models demonstrates a 10% improvement in detection accuracy and a 13% increase in packet delivery rate, highlighting the efficiency of our approach. Additionally, we evaluate the Machine Learning approach leveraged with BHMM analysis in two different network settings, a commercial ISP network, and a scientific research-only network topology. This evaluation also demonstrates the practical applicability of our method, yielding significantly improved prediction outcomes in both environments. ",
    "url": "https://arxiv.org/abs/2402.00831",
    "authors": [
      "Elif Ak",
      "Kiymet Kaya",
      "Eren Ozaltun",
      "Sule Gunduz Oguducu",
      "Berk Canberk"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00839",
    "title": "X-CBA: Explainability Aided CatBoosted Anomal-E for Intrusion Detection  System",
    "abstract": "The effectiveness of Intrusion Detection Systems (IDS) is critical in an era where cyber threats are becoming increasingly complex. Machine learning (ML) and deep learning (DL) models provide an efficient and accurate solution for identifying attacks and anomalies in computer networks. However, using ML and DL models in IDS has led to a trust deficit due to their non-transparent decision-making. This transparency gap in IDS research is significant, affecting confidence and accountability. To address, this paper introduces a novel Explainable IDS approach, called X-CBA, that leverages the structural advantages of Graph Neural Networks (GNNs) to effectively process network traffic data, while also adapting a new Explainable AI (XAI) methodology. Unlike most GNN-based IDS that depend on labeled network traffic and node features, thereby overlooking critical packet-level information, our approach leverages a broader range of traffic data through network flows, including edge attributes, to improve detection capabilities and adapt to novel threats. Through empirical testing, we establish that our approach not only achieves high accuracy with 99.47% in threat detection but also advances the field by providing clear, actionable explanations of its analytical outcomes. This research also aims to bridge the current gap and facilitate the broader integration of ML/DL technologies in cybersecurity defenses by offering a local and global explainability solution that is both precise and interpretable. ",
    "url": "https://arxiv.org/abs/2402.00839",
    "authors": [
      "Kiymet Kaya",
      "Elif Ak",
      "Sumeyye Bas",
      "Berk Canberk",
      "Sule Gunduz Oguducu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.00849",
    "title": "Score-based Causal Representation Learning: Linear and General  Transformations",
    "abstract": "This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the \\emph{identifiability} and \\emph{achievability} aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between \\emph{score functions} (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a \\emph{score-based class of algorithms} that ensures both identifiability and achievability. First, the paper focuses on \\emph{linear} transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on \\emph{general} transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does \\emph{not} need to know which pair of interventional environments have the same node intervened. ",
    "url": "https://arxiv.org/abs/2402.00849",
    "authors": [
      "Burak Var\u0131c\u0131",
      "Emre Acart\u00fcrk",
      "Karthikeyan Shanmugam",
      "Abhishek Kumar",
      "Ali Tajer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.00851",
    "title": "Data Augmentation Scheme for Raman Spectra with Highly Correlated  Annotations",
    "abstract": "In biotechnology Raman Spectroscopy is rapidly gaining popularity as a process analytical technology (PAT) that measures cell densities, substrate- and product concentrations. As it records vibrational modes of molecules it provides that information non-invasively in a single spectrum. Typically, partial least squares (PLS) is the model of choice to infer information about variables of interest from the spectra. However, biological processes are known for their complexity where convolutional neural networks (CNN) present a powerful alternative. They can handle non-Gaussian noise and account for beam misalignment, pixel malfunctions or the presence of additional substances. However, they require a lot of data during model training, and they pick up non-linear dependencies in the process variables. In this work, we exploit the additive nature of spectra in order to generate additional data points from a given dataset that have statistically independent labels so that a network trained on such data exhibits low correlations between the model predictions. We show that training a CNN on these generated data points improves the performance on datasets where the annotations do not bear the same correlation as the dataset that was used for model training. This data augmentation technique enables us to reuse spectra as training data for new contexts that exhibit different correlations. The additional data allows for building a better and more robust model. This is of interest in scenarios where large amounts of historical data are available but are currently not used for model training. We demonstrate the capabilities of the proposed method using synthetic spectra of Ralstonia eutropha batch cultivations to monitor substrate, biomass and polyhydroxyalkanoate (PHA) biopolymer concentrations during of the experiments. ",
    "url": "https://arxiv.org/abs/2402.00851",
    "authors": [
      "Christoph Lange",
      "Isabel Thiele",
      "Lara Santolin",
      "Sebastian L. Riedel",
      "Maxim Borisyak",
      "Peter Neubauer",
      "M. Nicolas Cruz Bournazou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2402.00861",
    "title": "Evaluating Large Language Models for Generalization and Robustness via  Data Compression",
    "abstract": "Existing methods for evaluating large language models face challenges such as data contamination, sensitivity to prompts, and the high cost of benchmark creation. To address this, we propose a lossless data compression based evaluation approach that tests how models' predictive abilities generalize after their training cutoff. Specifically, we collect comprehensive test data spanning 83 months from 2017 to 2023 and split the data into training and testing periods according to models' training data cutoff. We measure: 1) the compression performance on the testing period as a measure of generalization on unseen data; and 2) the performance gap between the training and testing period as a measure of robustness. Our experiments test 14 representative large language models with various sizes on sources including Wikipedia, news articles, code, arXiv papers, and multi-modal data. We find that the compression rate of many models reduces significantly after their cutoff date, but models such as Mistral and Llama-2 demonstrate a good balance between performance and robustness. Results also suggest that models struggle to generalize on news and code data, but work especially well on arXiv papers. We also find the context size and tokenization implementation have a big impact of on the overall compression performance. ",
    "url": "https://arxiv.org/abs/2402.00861",
    "authors": [
      "Yucheng Li",
      "Yunhao Guo",
      "Frank Guerin",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00864",
    "title": "ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields",
    "abstract": "We introduce ViCA-NeRF, the first view-consistency-aware method for 3D editing with text instructions. In addition to the implicit neural radiance field (NeRF) modeling, our key insight is to exploit two sources of regularization that explicitly propagate the editing information across different views, thus ensuring multi-view consistency. For geometric regularization, we leverage the depth information derived from NeRF to establish image correspondences between different views. For learned regularization, we align the latent codes in the 2D diffusion model between edited and unedited images, enabling us to edit key views and propagate the update throughout the entire scene. Incorporating these two strategies, our ViCA-NeRF operates in two stages. In the initial stage, we blend edits from different views to create a preliminary 3D edit. This is followed by a second stage of NeRF training, dedicated to further refining the scene's appearance. Experimental results demonstrate that ViCA-NeRF provides more flexible, efficient (3 times faster) editing with higher levels of consistency and details, compared with the state of the art. Our code is publicly available. ",
    "url": "https://arxiv.org/abs/2402.00864",
    "authors": [
      "Jiahua Dong",
      "Yu-Xiong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00865",
    "title": "Towards Optimal Feature-Shaping Methods for Out-of-Distribution  Detection",
    "abstract": "Feature shaping refers to a family of methods that exhibit state-of-the-art performance for out-of-distribution (OOD) detection. These approaches manipulate the feature representation, typically from the penultimate layer of a pre-trained deep learning model, so as to better differentiate between in-distribution (ID) and OOD samples. However, existing feature-shaping methods usually employ rules manually designed for specific model architectures and OOD datasets, which consequently limit their generalization ability. To address this gap, we first formulate an abstract optimization framework for studying feature-shaping methods. We then propose a concrete reduction of the framework with a simple piecewise constant shaping function and show that existing feature-shaping methods approximate the optimal solution to the concrete optimization problem. Further, assuming that OOD data is inaccessible, we propose a formulation that yields a closed-form solution for the piecewise constant shaping function, utilizing solely the ID data. Through extensive experiments, we show that the feature-shaping function optimized by our method improves the generalization ability of OOD detection across a large variety of datasets and model architectures. ",
    "url": "https://arxiv.org/abs/2402.00865",
    "authors": [
      "Qinyu Zhao",
      "Ming Xu",
      "Kartik Gupta",
      "Akshay Asthana",
      "Liang Zheng",
      "Stephen Gould"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00014",
    "title": "Hybrid quantum cycle generative adversarial network for small molecule  generation",
    "abstract": "The contemporary drug design process demands considerable time and resources to develop each new compound entering the market. Generating small molecules is a pivotal aspect of drug discovery, essential for developing innovative pharmaceuticals. Uniqueness, validity, diversity, druglikeliness, synthesizability, and solubility molecular pharmacokinetic properties, however, are yet to be maximized. This work introduces several new generative adversarial network models based on engineering integration of parametrized quantum circuits into known molecular generative adversarial networks. The introduced machine learning models incorporate a new multi-parameter reward function grounded in reinforcement learning principles. Through extensive experimentation on benchmark drug design datasets, QM9 and PC9, the introduced models are shown to outperform scores achieved previously. Most prominently, the new scores indicate an increase of up to 30% in the druglikeness quantitative estimation. The new hybrid quantum machine learning algorithms, as well as the achieved scores of pharmacokinetic properties, contribute to the development of fast and accurate drug discovery processes. ",
    "url": "https://arxiv.org/abs/2402.00014",
    "authors": [
      "Matvei Anoshin",
      "Asel Sagingalieva",
      "Christopher Mansell",
      "Vishal Shete",
      "Markus Pflitsch",
      "Alexey Melnikov"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2402.00024",
    "title": "Comparative Analysis of LLaMA and ChatGPT Embeddings for Molecule  Embedding",
    "abstract": "Purpose: Large Language Models (LLMs) like ChatGPT and LLaMA are increasingly recognized for their potential in the field of cheminformatics, particularly in interpreting Simplified Molecular Input Line Entry System (SMILES), a standard method for representing chemical structures. These LLMs can decode SMILES strings into vector representations, providing a novel approach to understanding chemical graphs. Methods: We investigate the performance of ChatGPT and LLaMA in embedding SMILES strings. Our evaluation focuses on two key applications: molecular property (MP) prediction and drug-drug interaction (DDI) prediction, both essential in drug development and healthcare. Results: We find that SMILES embeddings generated using LLaMA outperform those from ChatGPT in both MP and DDI prediction tasks. Notably, LLaMA-based SMILES embeddings show results comparable to existing methods in both prediction tasks. Conclusion: The application of LLMs in cheminformatics, particularly in utilizing SMILES embeddings, shows significant promise for advancing drug development. This includes improving the prediction of chemical properties and facilitating the drug discovery process. GitHub: https://github.com/sshaghayeghs/LLaMA-VS-ChatGPT ",
    "url": "https://arxiv.org/abs/2402.00024",
    "authors": [
      "Shaghayegh Sadeghi",
      "Alan Bui",
      "Ali Forooghi",
      "Jianguo Lu",
      "Alioune Ngom"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00038",
    "title": "Detecting Brain Tumors through Multimodal Neural Networks",
    "abstract": "Tumors can manifest in various forms and in different areas of the human body. Brain tumors are specifically hard to diagnose and treat because of the complexity of the organ in which they develop. Detecting them in time can lower the chances of death and facilitate the therapy process for patients. The use of Artificial Intelligence (AI) and, more specifically, deep learning, has the potential to significantly reduce costs in terms of time and resources for the discovery and identification of tumors from images obtained through imaging techniques. This research work aims to assess the performance of a multimodal model for the classification of Magnetic Resonance Imaging (MRI) scans processed as grayscale images. The results are promising, and in line with similar works, as the model reaches an accuracy of around 98\\%. We also highlight the need for explainability and transparency to ensure human control and safety. ",
    "url": "https://arxiv.org/abs/2402.00038",
    "authors": [
      "Antonio Curci",
      "Andrea Esposito"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2402.00175",
    "title": "Weakly-Supervised Detection of Bone Lesions in CT",
    "abstract": "The skeletal region is one of the common sites of metastatic spread of cancer in the breast and prostate. CT is routinely used to measure the size of lesions in the bones. However, they can be difficult to spot due to the wide variations in their sizes, shapes, and appearances. Precise localization of such lesions would enable reliable tracking of interval changes (growth, shrinkage, or unchanged status). To that end, an automated technique to detect bone lesions is highly desirable. In this pilot work, we developed a pipeline to detect bone lesions (lytic, blastic, and mixed) in CT volumes via a proxy segmentation task. First, we used the bone lesions that were prospectively marked by radiologists in a few 2D slices of CT volumes and converted them into weak 3D segmentation masks. Then, we trained a 3D full-resolution nnUNet model using these weak 3D annotations to segment the lesions and thereby detected them. Our automated method detected bone lesions in CT with a precision of 96.7% and recall of 47.3% despite the use of incomplete and partial training data. To the best of our knowledge, we are the first to attempt the direct detection of bone lesions in CT via a proxy segmentation task. ",
    "url": "https://arxiv.org/abs/2402.00175",
    "authors": [
      "Tao Sheng",
      "Tejas Sudharshan Mathai",
      "Alexander Shieh",
      "Ronald M. Summers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00176",
    "title": "Adversarial Quantum Machine Learning: An Information-Theoretic  Generalization Analysis",
    "abstract": "In a manner analogous to their classical counterparts, quantum classifiers are vulnerable to adversarial attacks that perturb their inputs. A promising countermeasure is to train the quantum classifier by adopting an attack-aware, or adversarial, loss function. This paper studies the generalization properties of quantum classifiers that are adversarially trained against bounded-norm white-box attacks. Specifically, a quantum adversary maximizes the classifier's loss by transforming an input state $\\rho(x)$ into a state $\\lambda$ that is $\\epsilon$-close to the original state $\\rho(x)$ in $p$-Schatten distance. Under suitable assumptions on the quantum embedding $\\rho(x)$, we derive novel information-theoretic upper bounds on the generalization error of adversarially trained quantum classifiers for $p = 1$ and $p = \\infty$. The derived upper bounds consist of two terms: the first is an exponential function of the 2-R\\'enyi mutual information between classical data and quantum embedding, while the second term scales linearly with the adversarial perturbation size $\\epsilon$. Both terms are shown to decrease as $1/\\sqrt{T}$ over the training set size $T$ . An extension is also considered in which the adversary assumed during training has different parameters $p$ and $\\epsilon$ as compared to the adversary affecting the test inputs. Finally, we validate our theoretical findings with numerical experiments for a synthetic setting. ",
    "url": "https://arxiv.org/abs/2402.00176",
    "authors": [
      "Petros Georgiou",
      "Sharu Theresa Jose",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00222",
    "title": "Uncover the nature of overlapping community in cities",
    "abstract": "Urban spaces, though often perceived as discrete communities, are shared by various functional and social groups. Our study introduces a graph-based physics-aware deep learning framework, illuminating the intricate overlapping nature inherent in urban communities. Through analysis of individual mobile phone positioning data at Twin Cities metro area (TCMA) in Minnesota, USA, our findings reveal that 95.7 % of urban functional complexity stems from the overlapping structure of communities during weekdays. Significantly, our research not only quantifies these overlaps but also reveals their compelling correlations with income and racial indicators, unraveling the complex segregation patterns in U.S. cities. As the first to elucidate the overlapping nature of urban communities, this work offers a unique geospatial perspective on looking at urban structures, highlighting the nuanced interplay of socioeconomic dynamics within cities. ",
    "url": "https://arxiv.org/abs/2402.00222",
    "authors": [
      "Peng Luo",
      "Di Zhu"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00288",
    "title": "Frame-Wise Breath Detection with Self-Training: An Exploration of  Enhancing Breath Naturalness in Text-to-Speech",
    "abstract": "Developing Text-to-Speech (TTS) systems that can synthesize natural breath is essential for human-like voice agents but requires extensive manual annotation of breath positions in training data. To this end, we propose a self-training method for training a breath detection model that can automatically detect breath positions in speech. Our method trains the model using a large speech corpus and involves: 1) annotation of limited breath sounds utilizing a rule-based approach, and 2) iterative augmentation of these annotations through pseudo-labeling based on the model's predictions. Our detection model employs Conformer blocks with down-/up-sampling layers, enabling accurate frame-wise breath detection. We investigate its effectiveness in multi-speaker TTS using text transcripts with detected breath marks. The results indicate that using our proposed model for breath detection and breath mark insertion synthesizes breath-contained speech more naturally than a baseline model. ",
    "url": "https://arxiv.org/abs/2402.00288",
    "authors": [
      "Dong Yang",
      "Tomoki Koriyama",
      "Yuki Saito"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.00299",
    "title": "Attention-based Dynamic Multilayer Graph Neural Networks for Loan  Default Prediction",
    "abstract": "Whereas traditional credit scoring tends to employ only individual borrower- or loan-level predictors, it has been acknowledged for some time that connections between borrowers may result in default risk propagating over a network. In this paper, we present a model for credit risk assessment leveraging a dynamic multilayer network built from a Graph Neural Network and a Recurrent Neural Network, each layer reflecting a different source of network connection. We test our methodology in a behavioural credit scoring context using a dataset provided by U.S. mortgage financier Freddie Mac, in which different types of connections arise from the geographical location of the borrower and their choice of mortgage provider. The proposed model considers both types of connections and the evolution of these connections over time. We enhance the model by using a custom attention mechanism that weights the different time snapshots according to their importance. After testing multiple configurations, a model with GAT, LSTM, and the attention mechanism provides the best results. Empirical results demonstrate that, when it comes to predicting probability of default for the borrowers, our proposed model brings both better results and novel insights for the analysis of the importance of connections and timestamps, compared to traditional methods. ",
    "url": "https://arxiv.org/abs/2402.00299",
    "authors": [
      "Sahab Zandi",
      "Kamesh Korangi",
      "Mar\u00eda \u00d3skarsd\u00f3ttir",
      "Christophe Mues",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00570",
    "title": "CADICA: a new dataset for coronary artery disease detection by using  invasive coronary angiography",
    "abstract": "Coronary artery disease (CAD) remains the leading cause of death globally and invasive coronary angiography (ICA) is considered the gold standard of anatomical imaging evaluation when CAD is suspected. However, risk evaluation based on ICA has several limitations, such as visual assessment of stenosis severity, which has significant interobserver variability. This motivates to development of a lesion classification system that can support specialists in their clinical procedures. Although deep learning classification methods are well-developed in other areas of medical imaging, ICA image classification is still at an early stage. One of the most important reasons is the lack of available and high-quality open-access datasets. In this paper, we reported a new annotated ICA images dataset, CADICA, to provide the research community with a comprehensive and rigorous dataset of coronary angiography consisting of a set of acquired patient videos and associated disease-related metadata. This dataset can be used by clinicians to train their skills in angiographic assessment of CAD severity and by computer scientists to create computer-aided diagnostic systems to help in such assessment. In addition, baseline classification methods are proposed and analyzed, validating the functionality of CADICA and giving the scientific community a starting point to improve CAD detection. ",
    "url": "https://arxiv.org/abs/2402.00570",
    "authors": [
      "Ariadna Jim\u00e9nez-Partinen",
      "Miguel A. Molina-Cabello",
      "Karl Thurnhofer-Hemsi",
      "Esteban J. Palomo",
      "Jorge Rodr\u00edguez-Capit\u00e1n",
      "Ana I. Molina-Ramos",
      "Manuel Jim\u00e9nez-Navarro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00623",
    "title": "Bayesian Causal Inference with Gaussian Process Networks",
    "abstract": "Causal discovery and inference from observational data is an essential problem in statistics posing both modeling and computational challenges. These are typically addressed by imposing strict assumptions on the joint distribution such as linearity. We consider the problem of the Bayesian estimation of the effects of hypothetical interventions in the Gaussian Process Network (GPN) model, a flexible causal framework which allows describing the causal relationships nonparametrically. We detail how to perform causal inference on GPNs by simulating the effect of an intervention across the whole network and propagating the effect of the intervention on downstream variables. We further derive a simpler computational approximation by estimating the intervention distribution as a function of local variables only, modeling the conditional distributions via additive Gaussian processes. We extend both frameworks beyond the case of a known causal graph, incorporating uncertainty about the causal structure via Markov chain Monte Carlo methods. Simulation studies show that our approach is able to identify the effects of hypothetical interventions with non-Gaussian, non-linear observational data and accurately reflect the posterior uncertainty of the causal estimates. Finally we compare the results of our GPN-based causal inference approach to existing methods on a dataset of $A.~thaliana$ gene expressions. ",
    "url": "https://arxiv.org/abs/2402.00623",
    "authors": [
      "Enrico Giudice",
      "Jack Kuipers",
      "Giusi Moffa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00653",
    "title": "Coherent Feed Forward Quantum Neural Network",
    "abstract": "Quantum machine learning, focusing on quantum neural networks (QNNs), remains a vastly uncharted field of study. Current QNN models primarily employ variational circuits on an ansatz or a quantum feature map, often requiring multiple entanglement layers. This methodology not only increases the computational cost of the circuit beyond what is practical on near-term quantum devices but also misleadingly labels these models as neural networks, given their divergence from the structure of a typical feed-forward neural network (FFNN). Moreover, the circuit depth and qubit needs of these models scale poorly with the number of data features, resulting in an efficiency challenge for real-world machine-learning tasks. We introduce a bona fide QNN model, which seamlessly aligns with the versatility of a traditional FFNN in terms of its adaptable intermediate layers and nodes, absent from intermediate measurements such that our entire model is coherent. This model stands out with its reduced circuit depth and number of requisite C-NOT gates to outperform prevailing QNN models. Furthermore, the qubit count in our model remains unaffected by the data's feature quantity. We test our proposed model on various benchmarking datasets such as the diagnostic breast cancer (Wisconsin) and credit card fraud detection datasets. We compare the outcomes of our model with the existing QNN methods to showcase the advantageous efficacy of our approach, even with a reduced requirement on quantum resources. Our model paves the way for application of quantum neural networks to real relevant machine learning problems. ",
    "url": "https://arxiv.org/abs/2402.00653",
    "authors": [
      "Utkarsh Singh",
      "Aaron Z. Goldberg",
      "Khabat Heshami"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00772",
    "title": "Neural Risk Limiting Dispatch in Power Networks: Formulation and  Generalization Guarantees",
    "abstract": "Risk limiting dispatch (RLD) has been proposed as an approach that effectively trades off economic costs with operational risks for power dispatch under uncertainty. However, how to solve the RLD problem with provably near-optimal performance still remains an open problem. This paper presents a learning-based solution to this challenge. We first design a data-driven formulation for the RLD problem, which aims to construct a decision rule that directly maps day-ahead observable information to cost-effective dispatch decisions for the future delivery interval. Unlike most existing works that follow a predict-then-optimize paradigm, this end-to-end rule bypasses the additional suboptimality introduced by separately handling prediction and optimization. We then propose neural RLD, a novel solution method to the data-driven formulation. This method leverages an L2-regularized neural network to learn the decision rule, thereby transforming the data-driven formulation into a neural network training task that can be efficiently completed by stochastic gradient descent. A theoretical performance guarantee is further established to bound the suboptimality of our method, which implies that its suboptimality approaches to zero with high probability as more samples are utilized. Simulation tests across various systems demonstrate our method's superior performance in convergence, suboptimality, and computational efficiency compared with benchmarks. ",
    "url": "https://arxiv.org/abs/2402.00772",
    "authors": [
      "Ge Chen",
      "Junjie Qin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2001.04086",
    "title": "GridMask Data Augmentation",
    "abstract": " Title: GridMask Data Augmentation ",
    "url": "https://arxiv.org/abs/2001.04086",
    "authors": [
      "Pengguang Chen",
      "Shu Liu",
      "Hengshuang Zhao",
      "Xingquan Wang",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.04828",
    "title": "Asymptotically Optimal Procedures for Sequential Joint Detection and  Estimation",
    "abstract": " Comments: 30 pages, 3 figures, 1 table, 8 pages supplementing material. Accepted for publication in Signal Processing ",
    "url": "https://arxiv.org/abs/2105.04828",
    "authors": [
      "Dominik Reinhard",
      "Michael Fau\u00df",
      "Abdelhak M. Zoubir"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2107.08020",
    "title": "Online Graph Topology Learning from Matrix-valued Time Series",
    "abstract": " Title: Online Graph Topology Learning from Matrix-valued Time Series ",
    "url": "https://arxiv.org/abs/2107.08020",
    "authors": [
      "Yiye Jiang",
      "J\u00e9r\u00e9mie Bigot",
      "Sofian Maabout"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.04567",
    "title": "Robust and Dexterous Dual-arm Tele-Cooperation using Adaptable Impedance  Control",
    "abstract": " Title: Robust and Dexterous Dual-arm Tele-Cooperation using Adaptable Impedance  Control ",
    "url": "https://arxiv.org/abs/2108.04567",
    "authors": [
      "Keyhan Kouhkiloui Babarahmati",
      "Mohammadreza Kasaei",
      "Carlo Tiseo",
      "Michael Mistry",
      "Sethu Vijayakumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.12782",
    "title": "SketchNE: Embedding Billion-Scale Networks Accurately in One Hour",
    "abstract": " Title: SketchNE: Embedding Billion-Scale Networks Accurately in One Hour ",
    "url": "https://arxiv.org/abs/2110.12782",
    "authors": [
      "Yuyang Xie",
      "Yuxiao Dong",
      "Jiezhong Qiu",
      "Wenjian Yu",
      "Xu Feng",
      "Jie Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2201.05149",
    "title": "The curse of overparametrization in adversarial training: Precise  analysis of robust generalization for random features regression",
    "abstract": " Comments: 86 pages (main file: 25 pages and supplementary: 61 pages). To appear in the Annals of Statistics ",
    "url": "https://arxiv.org/abs/2201.05149",
    "authors": [
      "Hamed Hassani",
      "Adel Javanmard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.13140",
    "title": "Polynomial kernels for edge modification problems towards block and  strictly chordal graphs",
    "abstract": " Title: Polynomial kernels for edge modification problems towards block and  strictly chordal graphs ",
    "url": "https://arxiv.org/abs/2201.13140",
    "authors": [
      "Ma\u00ebl Dumas",
      "Anthony Perez",
      "Mathis Rocton",
      "Ioan Todinca"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2205.14461",
    "title": "Collaborative likelihood-ratio estimation over graphs",
    "abstract": " Title: Collaborative likelihood-ratio estimation over graphs ",
    "url": "https://arxiv.org/abs/2205.14461",
    "authors": [
      "Alejandro de la Concha",
      "Nicolas Vayatis",
      "Argyris Kalogeratos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12644",
    "title": "FORESEE: Prediction with Expansion-Compression Unscented Transform for  Online Policy Optimization",
    "abstract": " Title: FORESEE: Prediction with Expansion-Compression Unscented Transform for  Online Policy Optimization ",
    "url": "https://arxiv.org/abs/2209.12644",
    "authors": [
      "Hardik Parwana",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.11133",
    "title": "Enhancing Accuracy and Robustness of Steering Angle Prediction with  Attention Mechanism",
    "abstract": " Title: Enhancing Accuracy and Robustness of Steering Angle Prediction with  Attention Mechanism ",
    "url": "https://arxiv.org/abs/2211.11133",
    "authors": [
      "Swetha Nadella",
      "Pramiti Barua",
      "Jeremy C. Hagler",
      "David J. Lamb",
      "Qing Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.03182",
    "title": "Structure-Informed Shadow Removal Networks",
    "abstract": " Comments: IEEE TIP ",
    "url": "https://arxiv.org/abs/2301.03182",
    "authors": [
      "Yuhao Liu",
      "Qing Guo",
      "Lan Fu",
      "Zhanghan Ke",
      "Ke Xu",
      "Wei Feng",
      "Ivor W. Tsang",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.09624",
    "title": "Breaking the Communication-Privacy-Accuracy Tradeoff with  $f$-Differential Privacy",
    "abstract": " Title: Breaking the Communication-Privacy-Accuracy Tradeoff with  $f$-Differential Privacy ",
    "url": "https://arxiv.org/abs/2302.09624",
    "authors": [
      "Richeng Jin",
      "Zhonggen Su",
      "Caijun Zhong",
      "Zhaoyang Zhang",
      "Tony Quek",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09117",
    "title": "Cross-Modal Causal Intervention for Medical Report Generation",
    "abstract": " Title: Cross-Modal Causal Intervention for Medical Report Generation ",
    "url": "https://arxiv.org/abs/2303.09117",
    "authors": [
      "Weixing Chen",
      "Yang Liu",
      "Ce Wang",
      "Jiarui Zhu",
      "Shen Zhao",
      "Guanbin Li",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.01710",
    "title": "Stars Are All You Need: A Distantly Supervised Pyramid Network for  Unified Sentiment Analysis",
    "abstract": " Comments: 15 pages, 3 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2305.01710",
    "authors": [
      "Wenchang Li",
      "Yixing Chen",
      "Shuang Zheng",
      "Lei Wang",
      "John P. Lalor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14163",
    "title": "Leveraging Open Information Extraction for More Robust Domain Transfer  of Event Trigger Detection",
    "abstract": " Comments: Accepted at EACL 2024 Findings ",
    "url": "https://arxiv.org/abs/2305.14163",
    "authors": [
      "David Duki\u0107",
      "Kiril Gashteovski",
      "Goran Glava\u0161",
      "Jan \u0160najder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16590",
    "title": "Seeding with Differentially Private Network Information",
    "abstract": " Comments: Preliminary version in AAMAS 2023: this https URL -- Code and data: this https URL ",
    "url": "https://arxiv.org/abs/2305.16590",
    "authors": [
      "M. Amin Rahimian",
      "Fang-Yi Yu",
      "Carlos Hurtado"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Complexity (cs.CC)",
      "Multiagent Systems (cs.MA)",
      "Probability (math.PR)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.18460",
    "title": "Minimum Width of Leaky-ReLU Neural Networks for Uniform Universal  Approximation",
    "abstract": " Comments: Include errata of the previous versions ",
    "url": "https://arxiv.org/abs/2305.18460",
    "authors": [
      "Li'ang Li",
      "Yifei Duan",
      "Guanghua Ji",
      "Yongqiang Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.04072",
    "title": "Exploring Simple, High Quality Out-of-Distribution Detection with L2  Normalization",
    "abstract": " Title: Exploring Simple, High Quality Out-of-Distribution Detection with L2  Normalization ",
    "url": "https://arxiv.org/abs/2306.04072",
    "authors": [
      "Jarrod Haas",
      "William Yolland",
      "Bernhard Rabus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.04817",
    "title": "SiBBlInGS: Similarity-driven Building-Block Inference using Graphs  across States",
    "abstract": " Title: SiBBlInGS: Similarity-driven Building-Block Inference using Graphs  across States ",
    "url": "https://arxiv.org/abs/2306.04817",
    "authors": [
      "Noga Mudrik",
      "Gal Mishne",
      "Adam S. Charles"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05587",
    "title": "MC-NN: An End-to-End Multi-Channel Neural Network Approach for  Predicting Influenza A Virus Hosts and Antigenic Types",
    "abstract": " Comments: Accepted version submitted to the SN Computer Science; Published in the SN Computer Science 2023; V1: minor updates were made to the Results section; V2: minor updates regarding data description ",
    "url": "https://arxiv.org/abs/2306.05587",
    "authors": [
      "Yanhua Xu",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.13042",
    "title": "Analysing Mechanisms for Virtual Channel Management in Low-Diameter  networks",
    "abstract": " Title: Analysing Mechanisms for Virtual Channel Management in Low-Diameter  networks ",
    "url": "https://arxiv.org/abs/2306.13042",
    "authors": [
      "Alejandro Cano",
      "Crist\u00f3bal Camarero",
      "Carmen Mart\u00ednez",
      "Ram\u00f3n Beivide"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.16958",
    "title": "Identifiability of Direct Effects from Summary Causal Graphs",
    "abstract": " Title: Identifiability of Direct Effects from Summary Causal Graphs ",
    "url": "https://arxiv.org/abs/2306.16958",
    "authors": [
      "Simon Ferreira",
      "Charles K. Assaad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.04308",
    "title": "Towards Cross-Table Masked Pretraining for Web Data Mining",
    "abstract": " Comments: Accepted to WWW 2024 ",
    "url": "https://arxiv.org/abs/2307.04308",
    "authors": [
      "Chao Ye",
      "Guoshan Lu",
      "Haobo Wang",
      "Liyao Li",
      "Sai Wu",
      "Gang Chen",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12233",
    "title": "Adaptive Consensus-based Reference Generation for the Regulation of  Open-Channel Networks",
    "abstract": " Comments: 14 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2307.12233",
    "authors": [
      "Marco Fabris",
      "Marco D. Bellinazzi",
      "Andrea Furlanetto",
      "Angelo Cenedese"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.13149",
    "title": "Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions",
    "abstract": " Title: Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions ",
    "url": "https://arxiv.org/abs/2307.13149",
    "authors": [
      "Bahador Bahmani",
      "Hyoung Suk Suh",
      "WaiChing Sun"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.00206",
    "title": "Synthetic Skull CT Generation with Generative Adversarial Networks to  Train Deep Learning Models for Clinical Transcranial Ultrasound",
    "abstract": " Comments: The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2308.00206",
    "authors": [
      "Kasra Naftchi-Ardebili",
      "Karanpartap Singh",
      "Reza Pourabolghasem",
      "Pejman Ghanouni",
      "Gerald R. Popelka",
      "Kim Butts Pauly"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06377",
    "title": "CATS v2: Hybrid encoders for robust medical segmentation",
    "abstract": " Title: CATS v2: Hybrid encoders for robust medical segmentation ",
    "url": "https://arxiv.org/abs/2308.06377",
    "authors": [
      "Hao Li",
      "Han Liu",
      "Dewei Hu",
      "Xing Yao",
      "Jiacheng Wang",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12063",
    "title": "Learning the Plasticity: Plasticity-Driven Learning Framework in Spiking  Neural Networks",
    "abstract": " Title: Learning the Plasticity: Plasticity-Driven Learning Framework in Spiking  Neural Networks ",
    "url": "https://arxiv.org/abs/2308.12063",
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Yiting Dong",
      "Yang Li",
      "Feifei Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.12950",
    "title": "Code Llama: Open Foundation Models for Code",
    "abstract": " Title: Code Llama: Open Foundation Models for Code ",
    "url": "https://arxiv.org/abs/2308.12950",
    "authors": [
      "Baptiste Rozi\u00e8re",
      "Jonas Gehring",
      "Fabian Gloeckle",
      "Sten Sootla",
      "Itai Gat",
      "Xiaoqing Ellen Tan",
      "Yossi Adi",
      "Jingyu Liu",
      "Romain Sauvestre",
      "Tal Remez",
      "J\u00e9r\u00e9my Rapin",
      "Artyom Kozhevnikov",
      "Ivan Evtimov",
      "Joanna Bitton",
      "Manish Bhatt",
      "Cristian Canton Ferrer",
      "Aaron Grattafiori",
      "Wenhan Xiong",
      "Alexandre D\u00e9fossez",
      "Jade Copet",
      "Faisal Azhar",
      "Hugo Touvron",
      "Louis Martin",
      "Nicolas Usunier",
      "Thomas Scialom",
      "Gabriel Synnaeve"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.13223",
    "title": "Causal Reasoning: Charting a Revolutionary Course for Next-Generation  AI-Native Wireless Networks",
    "abstract": " Title: Causal Reasoning: Charting a Revolutionary Course for Next-Generation  AI-Native Wireless Networks ",
    "url": "https://arxiv.org/abs/2309.13223",
    "authors": [
      "Christo Kurisummoottil Thomas",
      "Christina Chaccour",
      "Walid Saad",
      "Merouane Debbah",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14976",
    "title": "MoCaE: Mixture of Calibrated Experts Significantly Improves Object  Detection",
    "abstract": " Title: MoCaE: Mixture of Calibrated Experts Significantly Improves Object  Detection ",
    "url": "https://arxiv.org/abs/2309.14976",
    "authors": [
      "Kemal Oksuz",
      "Selim Kuzucu",
      "Tom Joy",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.13167",
    "title": "Visualizing Causality in Mixed Reality for Manual Task Learning: An  Exploratory Study",
    "abstract": " Title: Visualizing Causality in Mixed Reality for Manual Task Learning: An  Exploratory Study ",
    "url": "https://arxiv.org/abs/2310.13167",
    "authors": [
      "Rahul Jain",
      "Jingyu Shi",
      "Andrew Benton",
      "Moiz Rasheed",
      "Hyungjun Doh",
      "Subramanian Chidambaram",
      "Karthik Ramani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.20008",
    "title": "Evolutionary Tabletop Game Design: A Case Study in the Risk Game",
    "abstract": " Comments: Published in the 22nd Brazilian Symposium on Games and Digital Entertainment (SBGames 2023) ",
    "url": "https://arxiv.org/abs/2310.20008",
    "authors": [
      "Lana Bertoldo Rossato",
      "Leonardo Boaventura Bombardelli",
      "Anderson Rocha Tavares"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.03076",
    "title": "SugarViT -- Multi-objective Regression of UAV Images with Vision  Transformers and Deep Label Distribution Learning Demonstrated on Disease  Severity Prediction in Sugar Beet",
    "abstract": " Comments: submitted to Computers and Electronics in Agriculture ",
    "url": "https://arxiv.org/abs/2311.03076",
    "authors": [
      "Maurice G\u00fcnder",
      "Facundo Ram\u00f3n Ispizua Yamati",
      "Abel Andree Barreto Alc\u00e1ntara",
      "Anne-Katrin Mahlein",
      "Rafet Sifa",
      "Christian Bauckhage"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.05739",
    "title": "Adaptive Compression-Aware Split Learning and Inference for Enhanced  Network Efficiency",
    "abstract": " Title: Adaptive Compression-Aware Split Learning and Inference for Enhanced  Network Efficiency ",
    "url": "https://arxiv.org/abs/2311.05739",
    "authors": [
      "Akrit Mudvari",
      "Antero Vainio",
      "Iason Ofeidis",
      "Sasu Tarkoma",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.18826",
    "title": "Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal  Inference",
    "abstract": " Title: Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal  Inference ",
    "url": "https://arxiv.org/abs/2311.18826",
    "authors": [
      "Kaiwen Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.01804",
    "title": "Minimizing Maximum Dissatisfaction in the Allocation of Indivisible  Items under a Common Preference Graph",
    "abstract": " Comments: 26 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2312.01804",
    "authors": [
      "Nina Chiarelli",
      "Cl\u00e9ment Dallard",
      "Andreas Darmann",
      "Stefan Lendl",
      "Martin Milani\u010d",
      "Peter Mur\u0161i\u010d",
      "Ulrich Pferschy"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2312.06643",
    "title": "Gaze Detection and Analysis for Initiating Joint Activity in Industrial  Human-Robot Collaboration",
    "abstract": " Comments: First draft for a paper submitted to Frontiers in Robotics and AI ",
    "url": "https://arxiv.org/abs/2312.06643",
    "authors": [
      "Pooja Prajod",
      "Matteo Lavit Nicora",
      "Marta Mondellini",
      "Giovanni Tauro",
      "Rocco Vertechy",
      "Matteo Malosio",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2312.15488",
    "title": "The Zeta ($\u03b6$) Notation for Complex Asymptotes",
    "abstract": " Title: The Zeta ($\u03b6$) Notation for Complex Asymptotes ",
    "url": "https://arxiv.org/abs/2312.15488",
    "authors": [
      "Anurag Dutta",
      "K. Lakshmanan",
      "John Harshith",
      "A. Ramamoorthy",
      "C. Pradeep",
      "Pijush Kanti Kumar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2312.16815",
    "title": "Emergence and Causality in Complex Systems: A Survey on Causal Emergence  and Related Quantitative Studies",
    "abstract": " Comments: 57 pages, 17 figures, 1 table ",
    "url": "https://arxiv.org/abs/2312.16815",
    "authors": [
      "Bing Yuan",
      "Zhang Jiang",
      "Aobo Lyu",
      "Jiayun Wu",
      "Zhipeng Wang",
      "Mingzhe Yang",
      "Kaiwei Liu",
      "Muyun Mou",
      "Peng Cui"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2401.02814",
    "title": "Object-Centric Instruction Augmentation for Robotic Manipulation",
    "abstract": " Comments: accepted to ICRA2024 ",
    "url": "https://arxiv.org/abs/2401.02814",
    "authors": [
      "Junjie Wen",
      "Yichen Zhu",
      "Minjie Zhu",
      "Jinming Li",
      "Zhiyuan Xu",
      "Zhengping Che",
      "Chaomin Shen",
      "Yaxin Peng",
      "Dong Liu",
      "Feifei Feng",
      "Jian Tang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.03661",
    "title": "GrainGNN: A dynamic graph neural network for predicting 3D grain  microstructure",
    "abstract": " Title: GrainGNN: A dynamic graph neural network for predicting 3D grain  microstructure ",
    "url": "https://arxiv.org/abs/2401.03661",
    "authors": [
      "Yigong Qin",
      "Stephen DeWitt",
      "Balasubramaniam Radhakrishnan",
      "George Biros"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2401.04964",
    "title": "Self-supervised speech representation and contextual text embedding for  match-mismatch classification with EEG recording",
    "abstract": " Comments: 2 pages, 2 figures, accepted by ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2401.04964",
    "authors": [
      "Bo Wang",
      "Xiran Xu",
      "Zechen Zhang",
      "Haolin Zhu",
      "YuJie Yan",
      "Xihong Wu",
      "Jing Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2401.05580",
    "title": "Enhancing Blood Flow Assessment in Diffuse Correlation Spectroscopy: A  Transfer Learning Approach with Noise Robustness Analysis",
    "abstract": " Comments: Not ready for submission. Need further changes ",
    "url": "https://arxiv.org/abs/2401.05580",
    "authors": [
      "Xi Chen",
      "Xingda Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.08224",
    "title": "Privacy Preserving Adaptive Experiment Design",
    "abstract": " Comments: Update an algorithm and the title of our paper ",
    "url": "https://arxiv.org/abs/2401.08224",
    "authors": [
      "Jiachun Li",
      "Kaining Shi",
      "David Simchi-Levi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.08426",
    "title": "GD doesn't make the cut: Three ways that non-differentiability affects  neural network training",
    "abstract": " Title: GD doesn't make the cut: Three ways that non-differentiability affects  neural network training ",
    "url": "https://arxiv.org/abs/2401.08426",
    "authors": [
      "Siddharth Krishna Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.09769",
    "title": "Learning from Graphs with Heterophily: Progress and Future",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2401.09769",
    "authors": [
      "Chenghua Gong",
      "Yao Cheng",
      "Xiang Li",
      "Caihua Shan",
      "Siqiang Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.09923",
    "title": "MAMBA: Multi-level Aggregation via Memory Bank for Video Object  Detection",
    "abstract": " Comments: update code url this https URL ",
    "url": "https://arxiv.org/abs/2401.09923",
    "authors": [
      "Guanxiong Sun",
      "Yang Hua",
      "Guosheng Hu",
      "Neil Robertson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.10306",
    "title": "Physics-constrained convolutional neural networks for inverse problems  in spatiotemporal partial differential equations",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2306.04600, arXiv:2306.10990 ",
    "url": "https://arxiv.org/abs/2401.10306",
    "authors": [
      "Daniel Kelshaw",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.13744",
    "title": "Conformal Prediction Sets Improve Human Decision Making",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2401.13744",
    "authors": [
      "Jesse C. Cresswell",
      "Yi Sui",
      "Bhargava Kumar",
      "No\u00ebl Vouitsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.15140",
    "title": "Link Prediction Accuracy on Real-World Networks Under Non-Uniform  Missing Edge Patterns",
    "abstract": " Comments: Submitted to IEEE Transaction on Network Science and Engineering ",
    "url": "https://arxiv.org/abs/2401.15140",
    "authors": [
      "Xie He",
      "Amir Ghasemian",
      "Eun Lee",
      "Alice Schwarze",
      "Aaron Clauset",
      "Peter J. Mucha"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.15583",
    "title": "SCTransNet: Spatial-channel Cross Transformer Network for Infrared Small  Target Detection",
    "abstract": " Title: SCTransNet: Spatial-channel Cross Transformer Network for Infrared Small  Target Detection ",
    "url": "https://arxiv.org/abs/2401.15583",
    "authors": [
      "Shuai Yuan",
      "Hanlin Qin",
      "Xiang Yan",
      "Naveed AKhtar",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.15857",
    "title": "Leadership Dynamics in Social Multiplex Networks with Mono and  Bi-directional Interactions",
    "abstract": " Title: Leadership Dynamics in Social Multiplex Networks with Mono and  Bi-directional Interactions ",
    "url": "https://arxiv.org/abs/2401.15857",
    "authors": [
      "Amirreza Talebi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.15940",
    "title": "Knowledge-Aware Code Generation with Large Language Models",
    "abstract": " Comments: Accepted in ICPC 2024 ",
    "url": "https://arxiv.org/abs/2401.15940",
    "authors": [
      "Tao Huang",
      "Zhihong Sun",
      "Zhi Jin",
      "Ge Li",
      "Chen Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.16637",
    "title": "IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code  Completion",
    "abstract": " Comments: Accepted for the 32nd ACM Symposium on the Foundations of Software Engineering (FSE 2024) ",
    "url": "https://arxiv.org/abs/2401.16637",
    "authors": [
      "Bolun Li",
      "Zhihong Sun",
      "Tao Huang",
      "Hongyu Zhang",
      "Yao Wan",
      "Ge Li",
      "Zhi Jin",
      "Chen Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.16719",
    "title": "OptiState: State Estimation of Legged Robots using Gated Networks with  Transformer-based Vision and Kalman Filtering",
    "abstract": " Comments: Accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA), May 13-17, in Yokohama, Japan. 7 pages, 5 figures, 1 table ",
    "url": "https://arxiv.org/abs/2401.16719",
    "authors": [
      "Alexander Schperberg",
      "Yusuke Tanaka",
      "Saviz Mowlavi",
      "Feng Xu",
      "Bharathan Balaji",
      "Dennis Hong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.17814",
    "title": "Detection of Critical Events in Renewable Energy Production Time Series",
    "abstract": " Title: Detection of Critical Events in Renewable Energy Production Time Series ",
    "url": "https://arxiv.org/abs/2401.17814",
    "authors": [
      "Laurens P. Stoop",
      "Erik Duijm",
      "Ad J. Feelders",
      "Machteld van den Broek"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.17910",
    "title": "Controllable Dense Captioner with Multimodal Embedding Bridging",
    "abstract": " Comments: this https URL ",
    "url": "https://arxiv.org/abs/2401.17910",
    "authors": [
      "Yuzhong Zhao",
      "Yue Liu",
      "Zonghao Guo",
      "Weijia Wu",
      "Chen Gong",
      "Fang Wan",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]