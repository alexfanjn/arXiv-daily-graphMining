[
  {
    "id": "arXiv:2402.16855",
    "title": "MB-RACS: Measurement-Bounds-based Rate-Adaptive Image Compressed Sensing  Network",
    "abstract": "Conventional compressed sensing (CS) algorithms typically apply a uniform sampling rate to different image blocks. A more strategic approach could be to allocate the number of measurements adaptively, based on each image block's complexity. In this paper, we propose a Measurement-Bounds-based Rate-Adaptive Image Compressed Sensing Network (MB-RACS) framework, which aims to adaptively determine the sampling rate for each image block in accordance with traditional measurement bounds theory. Moreover, since in real-world scenarios statistical information about the original image cannot be directly obtained, we suggest a multi-stage rate-adaptive sampling strategy. This strategy sequentially adjusts the sampling ratio allocation based on the information gathered from previous samplings. We formulate the multi-stage rate-adaptive sampling as a convex optimization problem and address it using a combination of Newton's method and binary search techniques. Additionally, we enhance our decoding process by incorporating skip connections between successive iterations to facilitate a richer transmission of feature information across iterations. Our experiments demonstrate that the proposed MB-RACS method surpasses current leading methods, with experimental evidence also underscoring the effectiveness of each module within our proposed framework. ",
    "url": "https://arxiv.org/abs/2402.16855",
    "authors": [
      "Yujun Huang",
      "Bin Chen",
      "Naiqi Li",
      "Baoyi An",
      "Shu-Tao Xia",
      "Yaowei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.16861",
    "title": "Self-Tuning Network Control Architectures with Joint Sensor and Actuator  Selection",
    "abstract": "We formulate a mathematical framework for designing a self-tuning network control architecture, and propose a computationally-feasible greedy algorithm for online architecture optimization. In this setting, the locations of active sensors and actuators in the network, as well as the feedback control policy are jointly adapted using all available information about the network states and dynamics to optimize a performance criterion. We show that the case with full-state feedback can be solved with dynamic programming, and in the linear-quadratic setting, the optimal cost functions and policies are piecewise quadratic and piecewise linear, respectively. Our framework is extended for joint sensor and actuator selection for dynamic output feedback control with both control performance and architecture costs. For large networks where exhaustive architecture search is prohibitive, we describe a greedy heuristic for actuator selection and propose a greedy swapping algorithm for joint sensor and actuator selection. Via numerical experiments, we demonstrate a dramatic performance improvement of greedy self-tuning architectures over fixed architectures. Our general formulation provides an extremely rich and challenging problem space with opportunities to apply a wide variety of approximation methods from stochastic control, system identification, reinforcement learning, and static architecture design for practical model-based control. ",
    "url": "https://arxiv.org/abs/2402.16861",
    "authors": [
      "Karthik Ganapathy",
      "Iman Shames",
      "Mathias Hudoba de Badyn",
      "Tyler Summers"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.16864",
    "title": "Joint Resource Allocation and Trajectory Design for Resilient Multi-UAV  Communication Networks",
    "abstract": "In contrast to terrestrial wireless networks, dynamic Unmanned Aerial Vehicle (UAV) networks are susceptible to unexpected link failures arising from UAV breakdowns or the depletion of its batteries. Drastic user rate fluctuations and sum rate drops can occur due to the unexpected UAV link failures. Previous research has focused primarily on re-establishing these links to maintain service continuity, while neglecting overall system performance, including sum rate and user rate fluctuations. This letter proposes a resilient UAV network design utilizing the modern portfolio theory (MPT), which jointly optimizes the bandwidth allocation, UAV-user association, and UAV trajectories to enhance the overall service stability. Specifically, the design incorporates a novel utility function based on MPT to achieve a better balance between the sum rate and user rate fluctuations. To solve the joint optimization problem, we propose an iterative algorithm based on alternating optimization (AO) and successive convex approximation (SCA). Simulation results show that our scheme outperforms the other two baselines in terms of sum rate and user rate fluctuations. Furthermore, the resilience requirement in terms of sum rate, user rate fluctuations and user fairness can be achieved by flexibly tuning weight factor in our proposed algorithm. ",
    "url": "https://arxiv.org/abs/2402.16864",
    "authors": [
      "Linghui Ge",
      "Xiao Liang",
      "Hua Zhang",
      "Peihao Dong",
      "Jianxin Liao",
      "Jingyu Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.16870",
    "title": "Pioneering Deterministic Scheduling and Network Structure Optimization  for Time-Critical Computing Tasks in Industrial IoT",
    "abstract": "The Industrial Internet of Things (IIoT) has become a critical technology to accelerate the process of digital and intelligent transformation of industries. As the cooperative relationship between smart devices in IIoT becomes more complex, getting deterministic responses of IIoT periodic time-critical computing tasks becomes a crucial and nontrivial problem. However, few current works in cloud/edge/fog computing focus on this problem. This paper is a pioneer to explore the deterministic scheduling and network structural optimization problems for IIoT periodic time-critical computing tasks. We first formulate the two problems and derive theorems to help quickly identify computation and network resource sharing conflicts. Based on this, we propose a deterministic scheduling algorithm, \\textit{IIoTBroker}, which realizes deterministic response for each IIoT task by optimizing the fine-grained computation and network resources allocations, and a network optimization algorithm, \\textit{IIoTDeployer}, providing a cost-effective structural upgrade solution for existing IIoT networks. Our methods are illustrated to be cost-friendly, scalable, and deterministic response guaranteed with low computation cost from our simulation results. ",
    "url": "https://arxiv.org/abs/2402.16870",
    "authors": [
      "Yujiao Hu",
      "Yining Zhu",
      "Huayu Zhang",
      "Yan Pan",
      "Qingmin Jia",
      "Renchao Xie",
      "Gang Yang",
      "F. Richard Yu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.16878",
    "title": "EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math  Languages",
    "abstract": "Formal mathematics is the discipline of translating mathematics into a programming language in which any statement can be unequivocally checked by a computer. Mathematicians and computer scientists have spent decades of painstaking formalization efforts developing languages such as Coq, HOL, and Lean. Machine learning research has converged on these formal math corpora and given rise to an assortment of methodologies to aid in interactive and automated theorem proving. However, these papers have primarily focused on one method, for one proof task, in one language. This paper introduces EvoGPT-f: a novel evolutionary framework for the first systematic quantitative analysis of the differential machine learnability of five formal math corpora (Lean 3, Lean 4, Coq, HOL 4, HOL Light) using four tokenization methods (character, word-level, Byte Pair Encoding and StarCoder tokenizer). This paper does not put to rest the question of the \"best\" or \"easiest\" language to learn. Rather, this framework and preliminary findings begin to illuminate the differential machine learnability of these languages, offering a foundation to forge more systematic quantitative and qualitative comparative research across communities. ",
    "url": "https://arxiv.org/abs/2402.16878",
    "authors": [
      "Johnathan Mercer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.16886",
    "title": "Using text embedding models and vector databases as text classifiers  with the example of medical data",
    "abstract": "The advent of Large Language Models (LLMs) is promising and has found application in numerous fields, but as it often is with the medical field, the bar is typically quite high [5]. In tandem with LLMs, vector embedding models and vector databases provide a robust way of expressing numerous modes of data that are easily digestible by typical machine learning models. Along with the ease of adding information, knowledge, and data to these vector databases, they provide a compelling reason to apply them in numerous fields where the task of retrieving information is typically done by humans. Researchers at Google have developed a clear alternative model, Med-PaLM [6] specifically designed to match a clinician's level of accuracy when it comes to medical knowledge. When training classifiers, and developing models, it is imperative to maintain factuality and reduce bias [4]. Here, we explore the use of vector databases and embedding models as a means of encoding, and classifying text with the example and application in the field of medicine. We show the robustness of these tools depends heavily on the sparsity of the data presented, and even with low amounts of data in the vector database itself, the vector database does a good job at classifying data [9]. Using various LLMs to generate the medical data, we also understand the limitations of the medical knowledge of these models and encourage further expert medical review of our testing data. By using vector databases to classify a clinician's notes on a patient presented with a certain ailment, we understand the limitations of such methods, but also the promise of their prospective use and with continued testing and experimentation, hope to explore a unique use case of vector databases and embedding models. ",
    "url": "https://arxiv.org/abs/2402.16886",
    "authors": [
      "Rishabh Goel"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.16887",
    "title": "Artificial Intelligence for Complex Network: Potential, Methodology and  Application",
    "abstract": "Complex networks pervade various real-world systems, from the natural environment to human societies. The essence of these networks is in their ability to transition and evolve from microscopic disorder-where network topology and node dynamics intertwine-to a macroscopic order characterized by certain collective behaviors. Over the past two decades, complex network science has significantly enhanced our understanding of the statistical mechanics, structures, and dynamics underlying real-world networks. Despite these advancements, there remain considerable challenges in exploring more realistic systems and enhancing practical applications. The emergence of artificial intelligence (AI) technologies, coupled with the abundance of diverse real-world network data, has heralded a new era in complex network science research. This survey aims to systematically address the potential advantages of AI in overcoming the lingering challenges of complex network research. It endeavors to summarize the pivotal research problems and provide an exhaustive review of the corresponding methodologies and applications. Through this comprehensive survey-the first of its kind on AI for complex networks-we expect to provide valuable insights that will drive further research and advancement in this interdisciplinary field. ",
    "url": "https://arxiv.org/abs/2402.16887",
    "authors": [
      "Jingtao Ding",
      "Chang Liu",
      "Yu Zheng",
      "Yunke Zhang",
      "Zihan Yu",
      "Ruikun Li",
      "Hongyi Chen",
      "Jinghua Piao",
      "Huandong Wang",
      "Jiazhen Liu",
      "Yong Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2402.16893",
    "title": "The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented  Generation (RAG)",
    "abstract": "Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could potentially reshape the inherent behaviors of LLM generation, posing new privacy issues that are currently under-explored. In this work, we conduct extensive empirical studies with novel attack methods, which demonstrate the vulnerability of RAG systems on leaking the private retrieval database. Despite the new risk brought by RAG on the retrieval data, we further reveal that RAG can mitigate the leakage of the LLMs' training data. Overall, we provide new insights in this paper for privacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG systems builders. Our code is available at https://github.com/phycholosogy/RAG-privacy. ",
    "url": "https://arxiv.org/abs/2402.16893",
    "authors": [
      "Shenglai Zeng",
      "Jiankun Zhang",
      "Pengfei He",
      "Yue Xing",
      "Yiding Liu",
      "Han Xu",
      "Jie Ren",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Yi Chang",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.16896",
    "title": "On Trojan Signatures in Large Language Models of Code",
    "abstract": "Trojan signatures, as described by Fields et al. (2021), are noticeable differences in the distribution of the trojaned class parameters (weights) and the non-trojaned class parameters of the trojaned model, that can be used to detect the trojaned model. Fields et al. (2021) found trojan signatures in computer vision classification tasks with image models, such as, Resnet, WideResnet, Densenet, and VGG. In this paper, we investigate such signatures in the classifier layer parameters of large language models of source code. Our results suggest that trojan signatures could not generalize to LLMs of code. We found that trojaned code models are stubborn, even when the models were poisoned under more explicit settings (finetuned with pre-trained weights frozen). We analyzed nine trojaned models for two binary classification tasks: clone and defect detection. To the best of our knowledge, this is the first work to examine weight-based trojan signature revelation techniques for large-language models of code and furthermore to demonstrate that detecting trojans only from the weights in such models is a hard problem. ",
    "url": "https://arxiv.org/abs/2402.16896",
    "authors": [
      "Aftab Hussain",
      "Md Rafiqul Islam Rabin",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.16899",
    "title": "A prior Estimates for Deep Residual Network in Continuous-time  Reinforcement Learning",
    "abstract": "Deep reinforcement learning excels in numerous large-scale practical applications. However, existing performance analyses ignores the unique characteristics of continuous-time control problems, is unable to directly estimate the generalization error of the Bellman optimal loss and require a boundedness assumption. Our work focuses on continuous-time control problems and proposes a method that is applicable to all such problems where the transition function satisfies semi-group and Lipschitz properties. Under this method, we can directly analyze the \\emph{a priori} generalization error of the Bellman optimal loss. The core of this method lies in two transformations of the loss function. To complete the transformation, we propose a decomposition method for the maximum operator. Additionally, this analysis method does not require a boundedness assumption. Finally, we obtain an \\emph{a priori} generalization error without the curse of dimensionality. ",
    "url": "https://arxiv.org/abs/2402.16899",
    "authors": [
      "Shuyu Yin",
      "Qixuan Zhou",
      "Fei Wen",
      "Tao Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.16903",
    "title": "A novel data generation scheme for surrogate modelling with deep  operator networks",
    "abstract": "Operator-based neural network architectures such as DeepONets have emerged as a promising tool for the surrogate modeling of physical systems. In general, towards operator surrogate modeling, the training data is generated by solving the PDEs using techniques such as Finite Element Method (FEM). The computationally intensive nature of data generation is one of the biggest bottleneck in deploying these surrogate models for practical applications. In this study, we propose a novel methodology to alleviate the computational burden associated with training data generation for DeepONets. Unlike existing literature, the proposed framework for data generation does not use any partial differential equation integration strategy, thereby significantly reducing the computational cost associated with generating training dataset for DeepONet. In the proposed strategy, first, the output field is generated randomly, satisfying the boundary conditions using Gaussian Process Regression (GPR). From the output field, the input source field can be calculated easily using finite difference techniques. The proposed methodology can be extended to other operator learning methods, making the approach widely applicable. To validate the proposed approach, we employ the heat equations as the model problem and develop the surrogate model for numerous boundary value problems. ",
    "url": "https://arxiv.org/abs/2402.16903",
    "authors": [
      "Shivam Choubey",
      "Birupaksha Pal",
      "Manish Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.16909",
    "title": "Impact of Physical Activity on Quality of Life During Pregnancy: A  Causal ML Approach",
    "abstract": "The concept of Quality of Life (QoL) refers to a holistic measurement of an individual's well-being, incorporating psychological and social aspects. Pregnant women, especially those with obesity and stress, often experience lower QoL. Physical activity (PA) has shown the potential to enhance the QoL. However, pregnant women who are overweight and obese rarely meet the recommended level of PA. Studies have investigated the relationship between PA and QoL during pregnancy using correlation-based approaches. These methods aim to discover spurious correlations between variables rather than causal relationships. Besides, the existing methods mainly rely on physical activity parameters and neglect the use of different factors such as maternal (medical) history and context data, leading to biased estimates. Furthermore, the estimations lack an understanding of mediators and counterfactual scenarios that might affect them. In this paper, we investigate the causal relationship between being physically active (treatment variable) and the QoL (outcome) during pregnancy and postpartum. To estimate the causal effect, we develop a Causal Machine Learning method, integrating causal discovery and causal inference components. The data for our investigation is derived from a long-term wearable-based health monitoring study focusing on overweight and obese pregnant women. The machine learning (meta-learner) estimation technique is used to estimate the causal effect. Our result shows that performing adequate physical activity during pregnancy and postpartum improves the QoL by units of 7.3 and 3.4 on average in physical health and psychological domains, respectively. In the final step, four refutation analysis techniques are employed to validate our estimation. ",
    "url": "https://arxiv.org/abs/2402.16909",
    "authors": [
      "Kianoosh Kazemi",
      "Iina Ryht\u00e4",
      "Iman Azimi",
      "Hannakaisa Niela-Vilen",
      "Anna Axelin",
      "Amir M. Rahmani",
      "Pasi Liljeberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.16910",
    "title": "NeSy is alive and well: A LLM-driven symbolic approach for better code  comment data generation and classification",
    "abstract": "We present a neuro-symbolic (NeSy) workflow combining a symbolic-based learning technique with a large language model (LLM) agent to generate synthetic data for code comment classification in the C programming language. We also show how generating controlled synthetic data using this workflow fixes some of the notable weaknesses of LLM-based generation and increases the performance of classical machine learning models on the code comment classification task. Our best model, a Neural Network, achieves a Macro-F1 score of 91.412% with an increase of 1.033% after data augmentation. ",
    "url": "https://arxiv.org/abs/2402.16910",
    "authors": [
      "Hanna Abi Akl"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.16912",
    "title": "An Adversarial Robustness Benchmark for Enterprise Network Intrusion  Detection",
    "abstract": "As cyber-attacks become more sophisticated, improving the robustness of Machine Learning (ML) models must be a priority for enterprises of all sizes. To reliably compare the robustness of different ML models for cyber-attack detection in enterprise computer networks, they must be evaluated in standardized conditions. This work presents a methodical adversarial robustness benchmark of multiple decision tree ensembles with constrained adversarial examples generated from standard datasets. The robustness of regularly and adversarially trained RF, XGB, LGBM, and EBM models was evaluated on the original CICIDS2017 dataset, a corrected version of it designated as NewCICIDS, and the HIKARI dataset, which contains more recent network traffic. NewCICIDS led to models with a better performance, especially XGB and EBM, but RF and LGBM were less robust against the more recent cyber-attacks of HIKARI. Overall, the robustness of the models to adversarial cyber-attack examples was improved without their generalization to regular traffic being affected, enabling a reliable detection of suspicious activity without costly increases of false alarms. ",
    "url": "https://arxiv.org/abs/2402.16912",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Miguel Silva",
      "Eva Maia",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.16915",
    "title": "More Than Routing: Joint GPS and Route Modeling for Refine Trajectory  Representation Learning",
    "abstract": "Trajectory representation learning plays a pivotal role in supporting various downstream tasks. Traditional methods in order to filter the noise in GPS trajectories tend to focus on routing-based methods used to simplify the trajectories. However, this approach ignores the motion details contained in the GPS data, limiting the representation capability of trajectory representation learning. To fill this gap, we propose a novel representation learning framework that Joint GPS and Route Modelling based on self-supervised technology, namely JGRM. We consider GPS trajectory and route as the two modes of a single movement observation and fuse information through inter-modal information interaction. Specifically, we develop two encoders, each tailored to capture representations of route and GPS trajectories respectively. The representations from the two modalities are fed into a shared transformer for inter-modal information interaction. Eventually, we design three self-supervised tasks to train the model. We validate the effectiveness of the proposed method on two real datasets based on extensive experiments. The experimental results demonstrate that JGRM outperforms existing methods in both road segment representation and trajectory representation tasks. Our source code is available at Anonymous Github. ",
    "url": "https://arxiv.org/abs/2402.16915",
    "authors": [
      "Zhipeng Ma",
      "Zheyan Tu",
      "Xinhai Chen",
      "Yan Zhang",
      "Deguo Xia",
      "Guyue Zhou",
      "Yilun Chen",
      "Yu Zheng",
      "Jiangtao Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.16919",
    "title": "Personalized Federated Instruction Tuning via Neural Architecture Search",
    "abstract": "Federated Instruction Tuning (FIT) has shown the ability to achieve collaborative model instruction tuning among massive data owners without sharing private data. However, it still faces two key challenges, i.e., data and resource heterogeneity. Due to the varying data distribution and preferences among data owners, FIT cannot adapt to the personalized data of individual owners. Moreover, clients with superior computational abilities are constrained since they need to maintain the same fine-tuning architecture as the weaker clients. To address these issues, we propose a novel Personalized Federated Instruction Tuning (PerFIT) framework based on architecture search. Specifically, PerFIT allows each client to search for a personalized architecture by expanding the trainable parameter space of the global model followed by pruning the parameters to the original state. This procedure allows personalized instruction fine-tuning within expanded parameter spaces, concurrently preserving the same number of trainable parameters. Furthermore, to release the abilities of heterogeneous computational resources and enhance the performance of personalization on local data, we exploit personalized parameter-wise aggregation. The evaluation with multiple LLMs non-IID scenarios demonstrates that compared to the state-of-the-art FIT methods, our approach can achieve up to a 23% decrease in perplexity. ",
    "url": "https://arxiv.org/abs/2402.16919",
    "authors": [
      "Pengyu Zhang",
      "Yingbo Zhou",
      "Ming Hu",
      "Junxian Feng",
      "Jiawen Weng",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.16925",
    "title": "Minimize Control Inputs for Strong Structural Controllability Using  Reinforcement Learning with Graph Neural Network",
    "abstract": "Strong structural controllability (SSC) guarantees networked system with linear-invariant dynamics controllable for all numerical realizations of parameters. Current research has established algebraic and graph-theoretic conditions of SSC for zero/nonzero or zero/nonzero/arbitrary structure. One relevant practical problem is how to fully control the system with the minimal number of input signals and identify which nodes must be imposed signals. Previous work shows that this optimization problem is NP-hard and it is difficult to find the solution. To solve this problem, we formulate the graph coloring process as a Markov decision process (MDP) according to the graph-theoretical condition of SSC for both zero/nonzero and zero/nonzero/arbitrary structure. We use Actor-critic method with Directed graph neural network which represents the color information of graph to optimize MDP. Our method is validated in a social influence network with real data and different complex network models. We find that the number of input nodes is determined by the average degree of the network and the input nodes tend to select nodes with low in-degree and avoid high-degree nodes. ",
    "url": "https://arxiv.org/abs/2402.16925",
    "authors": [
      "Mengbang Zou",
      "Weisi Guo",
      "Bailu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.16926",
    "title": "On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing  Problem",
    "abstract": "We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem. ",
    "url": "https://arxiv.org/abs/2402.16926",
    "authors": [
      "Georg Pichler",
      "Marco Romanelli",
      "Divya Prakash Manivannan",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.16928",
    "title": "CLAP: Learning Transferable Binary Code Representations with Natural  Language Supervision",
    "abstract": "Binary code representation learning has shown significant performance in binary analysis tasks. But existing solutions often have poor transferability, particularly in few-shot and zero-shot scenarios where few or no training samples are available for the tasks. To address this problem, we present CLAP (Contrastive Language-Assembly Pre-training), which employs natural language supervision to learn better representations of binary code (i.e., assembly code) and get better transferability. At the core, our approach boosts superior transfer learning capabilities by effectively aligning binary code with their semantics explanations (in natural language), resulting a model able to generate better embeddings for binary code. To enable this alignment training, we then propose an efficient dataset engine that could automatically generate a large and diverse dataset comprising of binary code and corresponding natural language explanations. We have generated 195 million pairs of binary code and explanations and trained a prototype of CLAP. The evaluations of CLAP across various downstream tasks in binary analysis all demonstrate exceptional performance. Notably, without any task-specific training, CLAP is often competitive with a fully supervised baseline, showing excellent transferability. We release our pre-trained model and code at https://github.com/Hustcw/CLAP. ",
    "url": "https://arxiv.org/abs/2402.16928",
    "authors": [
      "Hao Wang",
      "Zeyu Gao",
      "Chao Zhang",
      "Zihan Sha",
      "Mingyang Sun",
      "Yuchen Zhou",
      "Wenyu Zhu",
      "Wenju Sun",
      "Han Qiu",
      "Xi Xiao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.16982",
    "title": "Synthesizing Tight Privacy and Accuracy Bounds via Weighted Model  Counting",
    "abstract": "Programmatically generating tight differential privacy (DP) bounds is a hard problem. Two core challenges are (1) finding expressive, compact, and efficient encodings of the distributions of DP algorithms, and (2) state space explosion stemming from the multiple quantifiers and relational properties of the DP definition. We address the first challenge by developing a method for tight privacy and accuracy bound synthesis using weighted model counting on binary decision diagrams, a state of the art technique from the artificial intelligence and automated reasoning communities for exactly computing probability distributions. We address the second challenge by developing a framework for leveraging inherent symmetries in DP algorithms. Our solution benefits from ongoing research in probabilistic programming languages, allowing us to succinctly and expressively represent different DP algorithms with approachable language syntax that can be used by non-experts. We provide a detailed case study of our solution on the binary randomized response algorithm. We also evaluate an implementation of our solution using the Dice probabilistic programming language for the randomized response and truncated geometric above threshold algorithms. We compare to prior work on exact DP verification using Markov chain probabilistic model checking. Very few existing works consider mechanized analysis of accuracy guarantees for DP algorithms. We additionally provide a detailed analysis using our technique for finding tight accuracy bounds for DP algorithms. ",
    "url": "https://arxiv.org/abs/2402.16982",
    "authors": [
      "Lisa Oakley",
      "Steven Holtzen",
      "Alina Oprea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.16990",
    "title": "inGRASS: Incremental Graph Spectral Sparsification via  Low-Resistance-Diameter Decomposition",
    "abstract": "This work presents inGRASS, a novel algorithm designed for incremental spectral sparsification of large undirected graphs. The proposed inGRASS algorithm is highly scalable and parallel-friendly, having a nearly-linear time complexity for the setup phase and the ability to update the spectral sparsifier in $O(\\log N)$ time for each incremental change made to the original graph with $N$ nodes. A key component in the setup phase of inGRASS is a multilevel resistance embedding framework introduced for efficiently identifying spectrally-critical edges and effectively detecting redundant ones, which is achieved by decomposing the initial sparsifier into many node clusters with bounded effective-resistance diameters leveraging a low-resistance-diameter decomposition (LRD) scheme. The update phase of inGRASS exploits low-dimensional node embedding vectors for efficiently estimating the importance and uniqueness of each newly added edge. As demonstrated through extensive experiments, inGRASS achieves up to over $200 \\times$ speedups while retaining comparable solution quality in incremental spectral sparsification of graphs obtained from various datasets, such as circuit simulations, finite element analysis, and social networks. ",
    "url": "https://arxiv.org/abs/2402.16990",
    "authors": [
      "Ali Aghdaei",
      "Zhuo Feng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17014",
    "title": "Z-AGI Labs at ClimateActivism 2024: Stance and Hate Event Detection on  Social Media",
    "abstract": "In the digital realm, rich data serves as a crucial source of insights into the complexities of social, political, and economic landscapes. Addressing the growing need for high-quality information on events and the imperative to combat hate speech, this research led to the establishment of the Shared Task on Climate Activism Stance and Hate Event Detection at CASE 2024. Focused on climate activists contending with hate speech on social media, our study contributes to hate speech identification from tweets. Analyzing three sub-tasks - Hate Speech Detection (Sub-task A), Targets of Hate Speech Identification (Sub-task B), and Stance Detection (Sub-task C) - Team Z-AGI Labs evaluated various models, including LSTM, Xgboost, and LGBM based on Tf-Idf. Results unveiled intriguing variations, with Catboost excelling in Subtask-B (F1: 0.5604) and Subtask-C (F1: 0.7081), while LGBM emerged as the top-performing model for Subtask-A (F1: 0.8684). This research provides valuable insights into the suitability of classical machine learning models for climate hate speech and stance detection, aiding informed model selection for robust mechanisms. ",
    "url": "https://arxiv.org/abs/2402.17014",
    "authors": [
      "Nikhil Narayan",
      "Mrutyunjay Biswal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.17015",
    "title": "Tree-Verifiable Graph Grammars",
    "abstract": "Hyperedge-Replacement grammars (HR) have been introduced by Courcelle in order to extend the notion of context-free sets from words and trees to graphs of bounded tree-width. While for words and trees the syntactic restrictions that guarantee that the associated languages of words resp. trees are regular - and hence, MSO-definable - are known, the situation is far more complicated for graphs. Here, Courcelle proposed the notion of regular graph grammars, a syntactic restriction of HR grammars that guarantees the definability of the associated languages of graphs in Counting Monadic Second Order Logic (CMSO). However, these grammars are not complete in the sense that not every CMSO-definable set of graphs of bounded tree-width can be generated by a regular graph grammar. In this paper, we introduce a new syntactic restriction of HR grammars, called tree-verifiable graph grammars, and a new notion of bounded tree-width, called embeddable bounded tree-width, where the later restricts the trees of a tree-decomposition to be a subgraph of the analyzed graph. The main property of tree-verifiable graph grammars is that their associated languages are CMSO-definable and that the have bounded embeddable tree-width. We show further that they strictly generalize the regular graph grammars of Courcelle. Finally, we establish a completeness result, showing that every language of graphs that is CMSO-definable and of bounded embeddable tree-width can be generated by a tree-verifiable graph grammar. ",
    "url": "https://arxiv.org/abs/2402.17015",
    "authors": [
      "Mark Chimes",
      "Radu Iosif",
      "Florian Zuleger"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2402.17018",
    "title": "A Curious Case of Remarkable Resilience to Gradient Attacks via Fully  Convolutional and Differentiable Front End with a Skip Connection",
    "abstract": "We tested front-end enhanced neural models where a frozen classifier was prepended by a differentiable and fully convolutional model with a skip connection. By training them using a small learning rate for about one epoch, we obtained models that retained the accuracy of the backbone classifier while being unusually resistant to gradient attacks including APGD and FAB-T attacks from the AutoAttack package, which we attributed to gradient masking. The gradient masking phenomenon is not new, but the degree of masking was quite remarkable for fully differentiable models that did not have gradient-shattering components such as JPEG compression or components that are expected to cause diminishing gradients. Though black box attacks can be partially effective against gradient masking, they are easily defeated by combining models into randomized ensembles. We estimate that such ensembles achieve near-SOTA AutoAttack accuracy on CIFAR10, CIFAR100, and ImageNet despite having virtually zero accuracy under adaptive attacks. Adversarial training of the backbone classifier can further increase resistance of the front-end enhanced model to gradient attacks. On CIFAR10, the respective randomized ensemble achieved 90.8$\\pm 2.5$% (99% CI) accuracy under AutoAttack while having only 18.2$\\pm 3.6$% accuracy under the adaptive attack. We do not establish SOTA in adversarial robustness. Instead, we make methodological contributions and further supports the thesis that adaptive attacks designed with the complete knowledge of model architecture are crucial in demonstrating model robustness and that even the so-called white-box gradient attacks can have limited applicability. Although gradient attacks can be complemented with black-box attack such as the SQUARE attack or the zero-order PGD, black-box attacks can be weak against randomized ensembles, e.g., when ensemble models mask gradients. ",
    "url": "https://arxiv.org/abs/2402.17018",
    "authors": [
      "Leonid Boytsov",
      "Ameya Joshi",
      "Filipe Condessa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17019",
    "title": "Leveraging Large Language Models for Learning Complex Legal Concepts  through Storytelling",
    "abstract": "Making legal knowledge accessible to non-experts is crucial for enhancing general legal literacy and encouraging civic participation in democracy. However, legal documents are often challenging to understand for people without legal backgrounds. In this paper, we present a novel application of large language models (LLMs) in legal education to help non-experts learn intricate legal concepts through storytelling, an effective pedagogical tool in conveying complex and abstract concepts. We also introduce a new dataset LegalStories, which consists of 295 complex legal doctrines, each accompanied by a story and a set of multiple-choice questions generated by LLMs. To construct the dataset, we experiment with various LLMs to generate legal stories explaining these concepts. Furthermore, we use an expert-in-the-loop method to iteratively design multiple-choice questions. Then, we evaluate the effectiveness of storytelling with LLMs through an RCT experiment with legal novices on 10 samples from the dataset. We find that LLM-generated stories enhance comprehension of legal concepts and interest in law among non-native speakers compared to only definitions. Moreover, stories consistently help participants relate legal concepts to their lives. Finally, we find that learning with stories shows a higher retention rate for non-native speakers in the follow-up assessment. Our work has strong implications for using LLMs in promoting teaching and learning in the legal field and beyond. ",
    "url": "https://arxiv.org/abs/2402.17019",
    "authors": [
      "Hang Jiang",
      "Xiajie Zhang",
      "Robert Mahari",
      "Daniel Kessler",
      "Eric Ma",
      "Tal August",
      "Irene Li",
      "Alex 'Sandy' Pentland",
      "Yoon Kim",
      "Jad Kabbara",
      "Deb Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.17020",
    "title": "Deep Learning Algorithms Used in Intrusion Detection Systems -- A Review",
    "abstract": "The increase in network attacks has necessitated the development of robust and efficient intrusion detection systems (IDS) capable of identifying malicious activities in real-time. In the last five years, deep learning algorithms have emerged as powerful tools in this domain, offering enhanced detection capabilities compared to traditional methods. This review paper studies recent advancements in the application of deep learning techniques, including Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Deep Belief Networks (DBN), Deep Neural Networks (DNN), Long Short-Term Memory (LSTM), autoencoders (AE), Multi-Layer Perceptrons (MLP), Self-Normalizing Networks (SNN) and hybrid models, within network intrusion detection systems. we delve into the unique architectures, training models, and classification methodologies tailored for network traffic analysis and anomaly detection. Furthermore, we analyze the strengths and limitations of each deep learning approach in terms of detection accuracy, computational efficiency, scalability, and adaptability to evolving threats. Additionally, this paper highlights prominent datasets and benchmarking frameworks commonly utilized for evaluating the performance of deep learning-based IDS. This review will provide researchers and industry practitioners with valuable insights into the state-of-the-art deep learning algorithms for enhancing the security framework of network environments through intrusion detection. ",
    "url": "https://arxiv.org/abs/2402.17020",
    "authors": [
      "Richard Kimanzi",
      "Peter Kimanga",
      "Dedan Cherori",
      "Patrick K. Gikunda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.17029",
    "title": "Offline Writer Identification Using Convolutional Neural Network  Activation Features",
    "abstract": "Convolutional neural networks (CNNs) have recently become the state-of-the-art tool for large-scale image classification. In this work we propose the use of activation features from CNNs as local descriptors for writer identification. A global descriptor is then formed by means of GMM supervector encoding, which is further improved by normalization with the KL-Kernel. We evaluate our method on two publicly available datasets: the ICDAR 2013 benchmark database and the CVL dataset. While we perform comparably to the state of the art on CVL, our proposed method yields about 0.21 absolute improvement in terms of mAP on the challenging bilingual ICDAR dataset. ",
    "url": "https://arxiv.org/abs/2402.17029",
    "authors": [
      "Vincent Christlein",
      "David Bernecker",
      "Andreas Maier",
      "Elli Angelopoulou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17073",
    "title": "One-Shot Graph Representation Learning Using Hyperdimensional Computing",
    "abstract": "We present a novel, simple, fast, and efficient approach for semi-supervised learning on graphs. The proposed approach takes advantage of hyper-dimensional computing which encodes data samples using random projections into a high dimensional space (HD space for short). Specifically, we propose a Hyper-dimensional Graph Learning (HDGL) algorithm that leverages the injectivity property of the node representations of a family of graph neural networks. HDGL maps node features to the HD space and then uses HD operators such as bundling and binding to aggregate information from the local neighborhood of each node. Results of experiments with widely used benchmark data sets show that HDGL achieves predictive performance that is competitive with the state-of-the-art deep learning methods, without the need for computationally expensive training. ",
    "url": "https://arxiv.org/abs/2402.17073",
    "authors": [
      "Abhishek Dalvi",
      "Vasant Honavar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.17091",
    "title": "Structural Teacher-Student Normality Learning for Multi-Class Anomaly  Detection and Localization",
    "abstract": "Visual anomaly detection is a challenging open-set task aimed at identifying unknown anomalous patterns while modeling normal data. The knowledge distillation paradigm has shown remarkable performance in one-class anomaly detection by leveraging teacher-student network feature comparisons. However, extending this paradigm to multi-class anomaly detection introduces novel scalability challenges. In this study, we address the significant performance degradation observed in previous teacher-student models when applied to multi-class anomaly detection, which we identify as resulting from cross-class interference. To tackle this issue, we introduce a novel approach known as Structural Teacher-Student Normality Learning (SNL): (1) We propose spatial-channel distillation and intra-&inter-affinity distillation techniques to measure structural distance between the teacher and student networks. (2) We introduce a central residual aggregation module (CRAM) to encapsulate the normal representation space of the student network. We evaluate our proposed approach on two anomaly detection datasets, MVTecAD and VisA. Our method surpasses the state-of-the-art distillation-based algorithms by a significant margin of 3.9% and 1.5% on MVTecAD and 1.2% and 2.5% on VisA in the multi-class anomaly detection and localization tasks, respectively. Furthermore, our algorithm outperforms the current state-of-the-art unified models on both MVTecAD and VisA. ",
    "url": "https://arxiv.org/abs/2402.17091",
    "authors": [
      "Hanqiu Deng",
      "Xingyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17092",
    "title": "A Pioneering Study and An Innovative Information Theory-based Approach  to Enhance The Transparency in Phishing Detection",
    "abstract": "Phishing attacks have become a serious and challenging issue for detection, explanation, and defense. Despite more than a decade of research on phishing, encompassing both technical and non-technical remedies, phishing continues to be a serious problem. Nowadays, AI-based phishing detection stands out as one of the most effective solutions for defending against phishing attacks by providing vulnerability (i.e., phishing or benign) predictions for the data. However, it lacks explainability in terms of providing comprehensive interpretations for the predictions, such as identifying the specific information that causes the data to be classified as phishing. To this end, we propose an innovative deep learning-based approach for email (the most common phishing way) phishing attack localization. Our method can not only predict the vulnerability of the email data but also automatically figure out and highlight the most important and phishing-relevant information (i.e., sentences) in each phishing email. The selected information indicates useful explanations for the vulnerability of the phishing email data. The rigorous experiments on seven real-world email datasets show the effectiveness and advancement of our proposed method in providing comprehensive explanations (by successfully figuring out the most important and phishing-relevant information in phishing emails) for the vulnerability of corresponding phishing data with higher performances from nearly (1% to 3%) and (1% to 4%) in two main Label-Accuracy and Cognitive-True-Positive measures, respectively, compared to the state-of-the-art potential baselines. ",
    "url": "https://arxiv.org/abs/2402.17092",
    "authors": [
      "Van Nguyen",
      "Tingmin Wu",
      "Xingliang Yuan",
      "Marthie Grobler",
      "Surya Nepal",
      "Carsten Rudolph"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.17098",
    "title": "In Defense and Revival of Bayesian Filtering for Thermal Infrared Object  Tracking",
    "abstract": "Deep learning-based methods monopolize the latest research in the field of thermal infrared (TIR) object tracking. However, relying solely on deep learning models to obtain better tracking results requires carefully selecting feature information that is beneficial to representing the target object and designing a reasonable template update strategy, which undoubtedly increases the difficulty of model design. Thus, recent TIR tracking methods face many challenges in complex scenarios. This paper introduces a novel Deep Bayesian Filtering (DBF) method to enhance TIR tracking in these challenging situations. DBF is distinctive in its dual-model structure: the system and observation models. The system model leverages motion data to estimate the potential positions of the target object based on two-dimensional Brownian motion, thus generating a prior probability. Following this, the observation model comes into play upon capturing the TIR image. It serves as a classifier and employs infrared information to ascertain the likelihood of these estimated positions, creating a likelihood probability. According to the guidance of the two models, the position of the target object can be determined, and the template can be dynamically updated. Experimental analysis across several benchmark datasets reveals that DBF achieves competitive performance, surpassing most existing TIR tracking methods in complex scenarios. ",
    "url": "https://arxiv.org/abs/2402.17098",
    "authors": [
      "Peng Gao",
      "Shi-Min Li",
      "Feng Gao",
      "Fei Wang",
      "Ru-Yue Yuan",
      "Hamido Fujita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17104",
    "title": "Adversarial Perturbations of Physical Signals",
    "abstract": "We investigate the vulnerability of computer-vision-based signal classifiers to adversarial perturbations of their inputs, where the signals and perturbations are subject to physical constraints. We consider a scenario in which a source and interferer emit signals that propagate as waves to a detector, which attempts to classify the source by analyzing the spectrogram of the signal it receives using a pre-trained neural network. By solving PDE-constrained optimization problems, we construct interfering signals that cause the detector to misclassify the source even though the perturbations to the spectrogram of the received signal are nearly imperceptible. Though such problems can have millions of decision variables, we introduce methods to solve them efficiently. Our experiments demonstrate that one can compute effective and physically realizable adversarial perturbations for a variety of machine learning models under various physical conditions. ",
    "url": "https://arxiv.org/abs/2402.17104",
    "authors": [
      "Robert L. Bassett",
      "Austin Van Dellen",
      "Anthony P. Austin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.17127",
    "title": "Experimental Study: Enhancing Voice Spoofing Detection Models with  wav2vec 2.0",
    "abstract": "Conventional spoofing detection systems have heavily relied on the use of handcrafted features derived from speech data. However, a notable shift has recently emerged towards the direct utilization of raw speech waveforms, as demonstrated by methods like SincNet filters. This shift underscores the demand for more sophisticated audio sample features. Moreover, the success of deep learning models, particularly those utilizing large pretrained wav2vec 2.0 as a featurization front-end, highlights the importance of refined feature encoders. In response, this research assessed the representational capability of wav2vec 2.0 as an audio feature extractor, modifying the size of its pretrained Transformer layers through two key adjustments: (1) selecting a subset of layers starting from the leftmost one and (2) fine-tuning a portion of the selected layers from the rightmost one. We complemented this analysis with five spoofing detection back-end models, with a primary focus on AASIST, enabling us to pinpoint the optimal configuration for the selection and fine-tuning process. In contrast to conventional handcrafted features, our investigation identified several spoofing detection systems that achieve state-of-the-art performance in the ASVspoof 2019 LA dataset. This comprehensive exploration offers valuable insights into feature selection strategies, advancing the field of spoofing detection. ",
    "url": "https://arxiv.org/abs/2402.17127",
    "authors": [
      "Taein Kang",
      "Soyul Han",
      "Sunmook Choi",
      "Jaejin Seo",
      "Sanghyeok Chung",
      "Seungeun Lee",
      "Seungsang Oh",
      "Il-Youp Kwak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.17128",
    "title": "OSCaR: Object State Captioning and State Change Representation",
    "abstract": "The capability of intelligent models to extrapolate and comprehend changes in object states is a crucial yet demanding aspect of AI research, particularly through the lens of human interaction in real-world settings. This task involves describing complex visual environments, identifying active objects, and interpreting their changes as conveyed through language. Traditional methods, which isolate object captioning and state change detection, offer a limited view of dynamic environments. Moreover, relying on a small set of symbolic words to represent changes has restricted the expressiveness of language. To address these challenges, in this paper, we introduce the Object State Captioning and State Change Representation (OSCaR) dataset and benchmark. OSCaR consists of 14,084 annotated video segments with nearly 1,000 unique objects from various egocentric video collections. It sets a new testbed for evaluating multimodal large language models (MLLMs). Our experiments demonstrate that while MLLMs show some skill, they lack a full understanding of object state changes. The benchmark includes a fine-tuned model that, despite initial capabilities, requires significant improvements in accuracy and generalization ability for effective understanding of these changes. Our code and dataset are available at https://github.com/nguyennm1024/OSCaR. ",
    "url": "https://arxiv.org/abs/2402.17128",
    "authors": [
      "Nguyen Nguyen",
      "Jing Bi",
      "Ali Vosoughi",
      "Yapeng Tian",
      "Pooyan Fazli",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17157",
    "title": "Generative Learning for Forecasting the Dynamics of Complex Systems",
    "abstract": "We introduce generative models for accelerating simulations of complex systems through learning and evolving their effective dynamics. In the proposed Generative Learning of Effective Dynamics (G-LED), instances of high dimensional data are down sampled to a lower dimensional manifold that is evolved through an auto-regressive attention mechanism. In turn, Bayesian diffusion models, that map this low-dimensional manifold onto its corresponding high-dimensional space, capture the statistics of the system dynamics. We demonstrate the capabilities and drawbacks of G-LED in simulations of several benchmark systems, including the Kuramoto-Sivashinsky (KS) equation, two-dimensional high Reynolds number flow over a backward-facing step, and simulations of three-dimensional turbulent channel flow. The results demonstrate that generative learning offers new frontiers for the accurate forecasting of the statistical properties of complex systems at a reduced computational cost. ",
    "url": "https://arxiv.org/abs/2402.17157",
    "authors": [
      "Han Gao",
      "Sebastian Kaltenbach",
      "Petros Koumoutsakos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.17172",
    "title": "Lane2Seq: Towards Unified Lane Detection via Sequence Generation",
    "abstract": "In this paper, we present a novel sequence generation-based framework for lane detection, called Lane2Seq. It unifies various lane detection formats by casting lane detection as a sequence generation task. This is different from previous lane detection methods, which depend on well-designed task-specific head networks and corresponding loss functions. Lane2Seq only adopts a plain transformer-based encoder-decoder architecture with a simple cross-entropy loss. Additionally, we propose a new multi-format model tuning based on reinforcement learning to incorporate the task-specific knowledge into Lane2Seq. Experimental results demonstrate that such a simple sequence generation paradigm not only unifies lane detection but also achieves competitive performance on benchmarks. For example, Lane2Seq gets 97.95\\% and 97.42\\% F1 score on Tusimple and LLAMAS datasets, establishing a new state-of-the-art result for two benchmarks. ",
    "url": "https://arxiv.org/abs/2402.17172",
    "authors": [
      "Kunyang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17178",
    "title": "NeuralSI: Neural Design of Semantic Interaction for Interactive Deep  Learning",
    "abstract": "An increasing number of studies have utilized interactive deep learning as the analytic model of visual analytics systems for complex sensemaking tasks. In these systems, traditional interactive dimensionality reduction (DR) models are commonly utilized to build a bi-directional bridge between high-dimensional deep learning representations and low-dimensional visualizations. While these systems better capture analysts' intents in the context of human-in-the-loop interactive deep learning, traditional DR cannot support several desired properties for visual analytics, including out-of-sample extensions, stability, and real-time inference. To avoid this issue, we propose the neural design framework of semantic interaction for interactive deep learning. In our framework, we replace the traditional DR with a neural projection network and append it to the deep learning model as the task-specific output layer. Therefore, the analytic model (deep learning) and visualization method (interactive DR) form one integrated end-to-end trainable deep neural network. In order to understand the performance of the neural design in comparison to the state-of-the-art, we systematically performed two complementary studies, a human-centered qualitative case study and an algorithm-centered simulation-based quantitative experiment. The results of these studies indicate that the neural design can give semantic interaction systems substantial advantages while still keeping comparable inference ability compared to the state-of-the-art model. ",
    "url": "https://arxiv.org/abs/2402.17178",
    "authors": [
      "Yali Bian",
      "Rebecca Faust",
      "Chris North"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.17191",
    "title": "AI-Driven Anonymization: Protecting Personal Data Privacy While  Leveraging Machine Learning",
    "abstract": "The development of artificial intelligence has significantly transformed people's lives. However, it has also posed a significant threat to privacy and security, with numerous instances of personal information being exposed online and reports of criminal attacks and theft. Consequently, the need to achieve intelligent protection of personal information through machine learning algorithms has become a paramount concern. Artificial intelligence leverages advanced algorithms and technologies to effectively encrypt and anonymize personal data, enabling valuable data analysis and utilization while safeguarding privacy. This paper focuses on personal data privacy protection and the promotion of anonymity as its core research objectives. It achieves personal data privacy protection and detection through the use of machine learning's differential privacy protection algorithm. The paper also addresses existing challenges in machine learning related to privacy and personal data protection, offers improvement suggestions, and analyzes factors impacting datasets to enable timely personal data privacy detection and protection. ",
    "url": "https://arxiv.org/abs/2402.17191",
    "authors": [
      "Le Yang",
      "Miao Tian",
      "Duan Xin",
      "Qishuo Cheng",
      "Jiajian Zheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17205",
    "title": "Measuring Vision-Language STEM Skills of Neural Models",
    "abstract": "We introduce a new challenge to test the STEM skills of neural models. The problems in the real world often require solutions, combining knowledge from STEM (science, technology, engineering, and math). Unlike existing datasets, our dataset requires the understanding of multimodal vision-language information of STEM. Our dataset features one of the largest and most comprehensive datasets for the challenge. It includes 448 skills and 1,073,146 questions spanning all STEM subjects. Compared to existing datasets that often focus on examining expert-level ability, our dataset includes fundamental skills and questions designed based on the K-12 curriculum. We also add state-of-the-art foundation models such as CLIP and GPT-3.5-Turbo to our benchmark. Results show that the recent model advances only help master a very limited number of lower grade-level skills (2.5% in the third grade) in our dataset. In fact, these models are still well below (averaging 54.7%) the performance of elementary students, not to mention near expert-level performance. To understand and increase the performance on our dataset, we teach the models on a training split of our dataset. Even though we observe improved performance, the model performance remains relatively low compared to average elementary students. To solve STEM problems, we will need novel algorithmic innovations from the community. ",
    "url": "https://arxiv.org/abs/2402.17205",
    "authors": [
      "Jianhao Shen",
      "Ye Yuan",
      "Srbuhi Mirzoyan",
      "Ming Zhang",
      "Chenguang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17206",
    "title": "Scalable Identification of Minimum Undesignable RNA Motifs on Loop-Pair  Graphs",
    "abstract": "Motivation: RNA design aims to find at least one sequence that folds with the highest probability into a designated target structure, but some structures are undesignable in the sense that no sequence folds into them. Identifying undesignable structures is useful in delineating and understanding the limit of RNA designability, but has received little attention until recently. In addition, existing methods on undesignability are not scalable and not interpretable. Results: We introduce a novel graph representation and a new general algorithmic framework to efficiently identify undesignable motifs in a secondary structure. The proposed algorithm enumerates minimal motifs based on the loop-pair graph representation of a structure and establishes the undesignability of a motif by proposing rival substructure(s). Our work can also identify unique minimum undesignable motifs across different structures. Our implemented algorithms successfully identify 26 unique minimum undesignable motifs among 18 undesignable puzzles from the benchmark Eterna100. Additionally, our algorithm is so efficient that it scales to natural structures of 16S and 23S Ribosomal RNAs (about 1,500 and 3,000 nucleotides, resp.), and finds all of those structures in the widely used ArchiveII database to be undesignable, with 73 unique minimum undesignable motifs, under the standard Turner energy model in ViennaRNA. ",
    "url": "https://arxiv.org/abs/2402.17206",
    "authors": [
      "Tianshuo Zhou",
      "Wei Yu Tang",
      "David H. Mathews",
      "Liang Huang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.17207",
    "title": "Deployment Prior Injection for Run-time Calibratable Object Detection",
    "abstract": "With a strong alignment between the training and test distributions, object relation as a context prior facilitates object detection. Yet, it turns into a harmful but inevitable training set bias upon test distributions that shift differently across space and time. Nevertheless, the existing detectors cannot incorporate deployment context prior during the test phase without parameter update. Such kind of capability requires the model to explicitly learn disentangled representations with respect to context prior. To achieve this, we introduce an additional graph input to the detector, where the graph represents the deployment context prior, and its edge values represent object relations. Then, the detector behavior is trained to bound to the graph with a modified training objective. As a result, during the test phase, any suitable deployment context prior can be injected into the detector via graph edits, hence calibrating, or \"re-biasing\" the detector towards the given prior at run-time without parameter update. Even if the deployment prior is unknown, the detector can self-calibrate using deployment prior approximated using its own predictions. Comprehensive experimental results on the COCO dataset, as well as cross-dataset testing on the Objects365 dataset, demonstrate the effectiveness of the run-time calibratable detector. ",
    "url": "https://arxiv.org/abs/2402.17207",
    "authors": [
      "Mo Zhou",
      "Yiding Yang",
      "Haoxiang Li",
      "Vishal M. Patel",
      "Gang Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17210",
    "title": "Purified and Unified Steganographic Network",
    "abstract": "Steganography is the art of hiding secret data into the cover media for covert communication. In recent years, more and more deep neural network (DNN)-based steganographic schemes are proposed to train steganographic networks for secret embedding and recovery, which are shown to be promising. Compared with the handcrafted steganographic tools, steganographic networks tend to be large in size. It raises concerns on how to imperceptibly and effectively transmit these networks to the sender and receiver to facilitate the covert communication. To address this issue, we propose in this paper a Purified and Unified Steganographic Network (PUSNet). It performs an ordinary machine learning task in a purified network, which could be triggered into steganographic networks for secret embedding or recovery using different keys. We formulate the construction of the PUSNet into a sparse weight filling problem to flexibly switch between the purified and steganographic networks. We further instantiate our PUSNet as an image denoising network with two steganographic networks concealed for secret image embedding and recovery. Comprehensive experiments demonstrate that our PUSNet achieves good performance on secret image embedding, secret image recovery, and image denoising in a single architecture. It is also shown to be capable of imperceptibly carrying the steganographic networks in a purified network. Code is available at \\url{https://github.com/albblgb/PUSNet} ",
    "url": "https://arxiv.org/abs/2402.17210",
    "authors": [
      "Guobiao Li",
      "Sheng Li",
      "Zicong Luo",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17223",
    "title": "Time-Restricted Double-Spending Attack on PoW-based Blockchains",
    "abstract": "Numerous blockchain applications are designed with tasks that naturally have finite durations, and hence, a double-spending attack (DSA) on such blockchain applications leans towards being conducted within a finite timeframe, specifically before the completion of their tasks. Furthermore, existing research suggests that practical attackers typically favor executing a DSA within a finite timeframe due to their limited computational resources. These observations serve as the impetus for this paper to investigate a time-restricted DSA (TR-DSA) model on Proof-of-Work based blockchains. In this TR-DSA model, an attacker only mines its branch within a finite timeframe, and the TR-DSA is considered unsuccessful if the attacker's branch fails to surpass the honest miners' branch when the honest miners' branch has grown by a specific number of blocks. First, we developed a general closed-form expression for the success probability of a TR-DSA. This developed probability not only can assist in evaluating the risk of a DSA on blockchain applications with timely tasks, but also can enable practical attackers with limited computational resources to assess the feasibility and expected reward of launching a TR-DSA. In addition, we provide rigorous proof that the success probability of a TR-DSA is no greater than that of a time-unrestricted DSA where the attacker indefinitely mines its branch. This result implies that blockchain applications with timely tasks are less vulnerable to DSAs than blockchain applications that provide attackers with an unlimited timeframe for their attacks. Furthermore, we show that the success probability of a TR-DSA is always smaller than one even though the attacker controls more than half of the hash rate in the network. This result alerts attackers that there is still a risk of failure in launching a TR-DSA even if they amass a majority of the hash rate in the network. ",
    "url": "https://arxiv.org/abs/2402.17223",
    "authors": [
      "Yiming Jiang",
      "Jiangfan Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.17229",
    "title": "Preserving Fairness Generalization in Deepfake Detection",
    "abstract": "Although effective deepfake detection models have been developed in recent years, recent studies have revealed that these models can result in unfair performance disparities among demographic groups, such as race and gender. This can lead to particular groups facing unfair targeting or exclusion from detection, potentially allowing misclassified deepfakes to manipulate public opinion and undermine trust in the model. The existing method for addressing this problem is providing a fair loss function. It shows good fairness performance for intra-domain evaluation but does not maintain fairness for cross-domain testing. This highlights the significance of fairness generalization in the fight against deepfakes. In this work, we propose the first method to address the fairness generalization problem in deepfake detection by simultaneously considering features, loss, and optimization aspects. Our method employs disentanglement learning to extract demographic and domain-agnostic forgery features, fusing them to encourage fair learning across a flattened loss landscape. Extensive experiments on prominent deepfake datasets demonstrate our method's effectiveness, surpassing state-of-the-art approaches in preserving fairness during cross-domain deepfake detection. The code is available at https://github.com/Purdue-M2/Fairness-Generalization ",
    "url": "https://arxiv.org/abs/2402.17229",
    "authors": [
      "Li Lin",
      "Xinan He",
      "Yan Ju",
      "Xin Wang",
      "Feng Ding",
      "Shu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17232",
    "title": "Two-scale Neural Networks for Partial Differential Equations with Small  Parameters",
    "abstract": "We propose a two-scale neural network method for solving partial differential equations (PDEs) with small parameters using physics-informed neural networks (PINNs). We directly incorporate the small parameters into the architecture of neural networks. The proposed method enables solving PDEs with small parameters in a simple fashion, without adding Fourier features or other computationally taxing searches of truncation parameters. Various numerical examples demonstrate reasonable accuracy in capturing features of large derivatives in the solutions caused by small parameters. ",
    "url": "https://arxiv.org/abs/2402.17232",
    "authors": [
      "Qiao Zhuang",
      "Chris Ziyi Yao",
      "Zhongqiang Zhang",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2402.17233",
    "title": "Hybrid Square Neural ODE Causal Modeling",
    "abstract": "Hybrid models combine mechanistic ODE-based dynamics with flexible and expressive neural network components. Such models have grown rapidly in popularity, especially in scientific domains where such ODE-based modeling offers important interpretability and validated causal grounding (e.g., for counterfactual reasoning). The incorporation of mechanistic models also provides inductive bias in standard blackbox modeling approaches, critical when learning from small datasets or partially observed, complex systems. Unfortunately, as hybrid models become more flexible, the causal grounding provided by the mechanistic model can quickly be lost. We address this problem by leveraging another common source of domain knowledge: ranking of treatment effects for a set of interventions, even if the precise treatment effect is unknown. We encode this information in a causal loss that we combine with the standard predictive loss to arrive at a hybrid loss that biases our learning towards causally valid hybrid models. We demonstrate our ability to achieve a win-win -- state-of-the-art predictive performance and causal validity -- in the challenging task of modeling glucose dynamics during exercise. ",
    "url": "https://arxiv.org/abs/2402.17233",
    "authors": [
      "Bob Junyi Zou",
      "Matthew E. Levine",
      "Dessi P. Zaharieva",
      "Ramesh Johari",
      "Emily B. Fox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.17236",
    "title": "A Review of Data Mining in Personalized Education: Current Trends and  Future Prospects",
    "abstract": "Personalized education, tailored to individual student needs, leverages educational technology and artificial intelligence (AI) in the digital age to enhance learning effectiveness. The integration of AI in educational platforms provides insights into academic performance, learning preferences, and behaviors, optimizing the personal learning process. Driven by data mining techniques, it not only benefits students but also provides educators and institutions with tools to craft customized learning experiences. To offer a comprehensive review of recent advancements in personalized educational data mining, this paper focuses on four primary scenarios: educational recommendation, cognitive diagnosis, knowledge tracing, and learning analysis. This paper presents a structured taxonomy for each area, compiles commonly used datasets, and identifies future research directions, emphasizing the role of data mining in enhancing personalized education and paving the way for future exploration and innovation. ",
    "url": "https://arxiv.org/abs/2402.17236",
    "authors": [
      "Zhang Xiong",
      "Haoxuan Li",
      "Zhuang Liu",
      "Zhuofan Chen",
      "Hao Zhou",
      "Wenge Rong",
      "Yuanxin Ouyang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17242",
    "title": "Scalable Community Search with Accuracy Guarantee on Attributed Graphs",
    "abstract": "Given an attributed graph $G$ and a query node $q$, \\underline{C}ommunity \\underline{S}earch over \\underline{A}ttributed \\underline{G}raphs (CS-AG) aims to find a structure- and attribute-cohesive subgraph from $G$ that contains $q$. Although CS-AG has been widely studied, they still face three challenges. (1) Exact methods based on graph traversal are time-consuming, especially for large graphs. Some tailored indices can improve efficiency, but introduce nonnegligible storage and maintenance overhead. (2) Approximate methods with a loose approximation ratio only provide a coarse-grained evaluation of a community's quality, rather than a reliable evaluation with an accuracy guarantee in runtime. (3) Attribute cohesiveness metrics often ignores the important correlation with the query node $q$. We formally define our CS-AG problem atop a $q$-centric attribute cohesiveness metric considering both textual and numerical attributes, for $k$-core model on homogeneous graphs. We show the problem is NP-hard. To solve it, we first propose an exact baseline with three pruning strategies. Then, we propose an index-free sampling-estimation-based method to quickly return an approximate community with an accuracy guarantee, in the form of a confidence interval. Once a good result satisfying a user-desired error bound is reached, we terminate it early. We extend it to heterogeneous graphs, $k$-truss model, and size-bounded CS. Comprehensive experimental studies on ten real-world datasets show its superiority, e.g., at least 1.54$\\times$ (41.1$\\times$ on average) faster in response time and a reliable relative error (within a user-specific error bound) of attribute cohesiveness is achieved. ",
    "url": "https://arxiv.org/abs/2402.17242",
    "authors": [
      "Yuxiang Wang",
      "Shuzhan Ye",
      "Xiaoliang Xu",
      "Yuxia Geng",
      "Zhenghe Zhao",
      "Xiangyu Ke",
      "Tianxing Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2402.17249",
    "title": "Deep Learning-Based Speech and Vision Synthesis to Improve Phishing  Attack Detection through a Multi-layer Adaptive Framework",
    "abstract": "The ever-evolving ways attacker continues to im prove their phishing techniques to bypass existing state-of-the-art phishing detection methods pose a mountain of challenges to researchers in both industry and academia research due to the inability of current approaches to detect complex phishing attack. Thus, current anti-phishing methods remain vulnerable to complex phishing because of the increasingly sophistication tactics adopted by attacker coupled with the rate at which new tactics are being developed to evade detection. In this research, we proposed an adaptable framework that combines Deep learning and Randon Forest to read images, synthesize speech from deep-fake videos, and natural language processing at various predictions layered to significantly increase the performance of machine learning models for phishing attack detection. ",
    "url": "https://arxiv.org/abs/2402.17249",
    "authors": [
      "Tosin Ige",
      "Christopher Kiekintveld",
      "Aritran Piplai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17256",
    "title": "Beyond the Known: Investigating LLMs Performance on Out-of-Domain Intent  Detection",
    "abstract": "Out-of-domain (OOD) intent detection aims to examine whether the user's query falls outside the predefined domain of the system, which is crucial for the proper functioning of task-oriented dialogue (TOD) systems. Previous methods address it by fine-tuning discriminative models. Recently, some studies have been exploring the application of large language models (LLMs) represented by ChatGPT to various downstream tasks, but it is still unclear for their ability on OOD detection task.This paper conducts a comprehensive evaluation of LLMs under various experimental settings, and then outline the strengths and weaknesses of LLMs. We find that LLMs exhibit strong zero-shot and few-shot capabilities, but is still at a disadvantage compared to models fine-tuned with full resource. More deeply, through a series of additional analysis experiments, we discuss and summarize the challenges faced by LLMs and provide guidance for future work including injecting domain knowledge, strengthening knowledge transfer from IND(In-domain) to OOD, and understanding long instructions. ",
    "url": "https://arxiv.org/abs/2402.17256",
    "authors": [
      "Pei Wang",
      "Keqing He",
      "Yejie Wang",
      "Xiaoshuai Song",
      "Yutao Mou",
      "Jingang Wang",
      "Yunsen Xian",
      "Xunliang Cai",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.17257",
    "title": "RIME: Robust Preference-based Reinforcement Learning with Noisy  Preferences",
    "abstract": "Preference-based Reinforcement Learning (PbRL) avoids the need for reward engineering by harnessing human preferences as the reward signal. However, current PbRL algorithms over-reliance on high-quality feedback from domain experts, which results in a lack of robustness. In this paper, we present RIME, a robust PbRL algorithm for effective reward learning from noisy preferences. Our method incorporates a sample selection-based discriminator to dynamically filter denoised preferences for robust training. To mitigate the accumulated error caused by incorrect selection, we propose to warm start the reward model, which additionally bridges the performance gap during transition from pre-training to online training in PbRL. Our experiments on robotic manipulation and locomotion tasks demonstrate that RIME significantly enhances the robustness of the current state-of-the-art PbRL method. Ablation studies further demonstrate that the warm start is crucial for both robustness and feedback-efficiency in limited-feedback cases. ",
    "url": "https://arxiv.org/abs/2402.17257",
    "authors": [
      "Jie Cheng",
      "Gang Xiong",
      "Xingyuan Dai",
      "Qinghai Miao",
      "Yisheng Lv",
      "Fei-Yue Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17262",
    "title": "Speak Out of Turn: Safety Vulnerability of Large Language Models in  Multi-turn Dialogue",
    "abstract": "Large Language Models (LLMs) have been demonstrated to generate illegal or unethical responses, particularly when subjected to \"jailbreak.\" Research on jailbreak has highlighted the safety issues of LLMs. However, prior studies have predominantly focused on single-turn dialogue, ignoring the potential complexities and risks presented by multi-turn dialogue, a crucial mode through which humans derive information from LLMs. In this paper, we argue that humans could exploit multi-turn dialogue to induce LLMs into generating harmful information. LLMs may not intend to reject cautionary or borderline unsafe queries, even if each turn is closely served for one malicious purpose in a multi-turn dialogue. Therefore, by decomposing an unsafe query into several sub-queries for multi-turn dialogue, we induced LLMs to answer harmful sub-questions incrementally, culminating in an overall harmful response. Our experiments, conducted across a wide range of LLMs, indicate current inadequacies in the safety mechanisms of LLMs in multi-turn dialogue. Our findings expose vulnerabilities of LLMs in complex scenarios involving multi-turn dialogue, presenting new challenges for the safety of LLMs. ",
    "url": "https://arxiv.org/abs/2402.17262",
    "authors": [
      "Zhenhong Zhou",
      "Jiuyang Xiang",
      "Haopeng Chen",
      "Quan Liu",
      "Zherui Li",
      "Sen Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17268",
    "title": "Reinforcement Learning Based Robust Volt/Var Control in Active  Distribution Networks With Imprecisely Known Delay",
    "abstract": "Active distribution networks (ADNs) incorporating massive photovoltaic (PV) devices encounter challenges of rapid voltage fluctuations and potential violations. Due to the fluctuation and intermittency of PV generation, the state gap, arising from time-inconsistent states and exacerbated by imprecisely known system delays, significantly impacts the accuracy of voltage control. This paper addresses this challenge by introducing a framework for delay adaptive Volt/Var control (VVC) in the presence of imprecisely known system delays to regulate the reactive power of PV inverters. The proposed approach formulates the voltage control, based on predicted system operation states, as a robust VVC problem. It employs sample selection from the state prediction interval to promptly identify the worst-performing system operation state. Furthermore, we leverage the decentralized partially observable Markov decision process (Dec-POMDP) to reformulate the robust VVC problem. We design Multiple Policy Networks and employ Multiple Policy Networks and Reward Shaping-based Multi-agent Twin Delayed Deep Deterministic Policy Gradient (MPNRS-MATD3) algorithm to efficiently address and solve the Dec-POMDP model-based problem. Simulation results show the delay adaption characteristic of our proposed framework, and the MPNRS-MATD3 outperforms other multi-agent reinforcement learning algorithms in robust voltage control. ",
    "url": "https://arxiv.org/abs/2402.17268",
    "authors": [
      "Hong Cheng",
      "Huan Luo",
      "Zhi Liu",
      "Wei Sun",
      "Weitao Li",
      "Qiyue Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.17269",
    "title": "Curriculum Learning Meets Directed Acyclic Graph for Multimodal Emotion  Recognition",
    "abstract": "Emotion recognition in conversation (ERC) is a crucial task in natural language processing and affective computing. This paper proposes MultiDAG+CL, a novel approach for Multimodal Emotion Recognition in Conversation (ERC) that employs Directed Acyclic Graph (DAG) to integrate textual, acoustic, and visual features within a unified framework. The model is enhanced by Curriculum Learning (CL) to address challenges related to emotional shifts and data imbalance. Curriculum learning facilitates the learning process by gradually presenting training samples in a meaningful order, thereby improving the model's performance in handling emotional variations and data imbalance. Experimental results on the IEMOCAP and MELD datasets demonstrate that the MultiDAG+CL models outperform baseline models. ",
    "url": "https://arxiv.org/abs/2402.17269",
    "authors": [
      "Cam-Van Thi Nguyen",
      "Cao-Bach Nguyen",
      "Quang-Thuy Ha",
      "Duc-Trong Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17270",
    "title": "Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social  Dilemmas",
    "abstract": "The study of cooperation within social dilemmas has long been a fundamental topic across various disciplines, including computer science and social science. Recent advancements in Artificial Intelligence (AI) have significantly reshaped this field, offering fresh insights into understanding and enhancing cooperation. This survey examines three key areas at the intersection of AI and cooperation in social dilemmas. First, focusing on multi-agent cooperation, we review the intrinsic and external motivations that support cooperation among rational agents, and the methods employed to develop effective strategies against diverse opponents. Second, looking into human-agent cooperation, we discuss the current AI algorithms for cooperating with humans and the human biases towards AI agents. Third, we review the emergent field of leveraging AI agents to enhance cooperation among humans. We conclude by discussing future research avenues, such as using large language models, establishing unified theoretical frameworks, revisiting existing theories of human cooperation, and exploring multiple real-world applications. ",
    "url": "https://arxiv.org/abs/2402.17270",
    "authors": [
      "Hao Guo",
      "Chunjiang Mu",
      "Yang Chen",
      "Chen Shen",
      "Shuyue Hu",
      "Zhen Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2402.17285",
    "title": "Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder  Super-resolution Network",
    "abstract": "Existing hyperspectral image (HSI) super-resolution (SR) methods struggle to effectively capture the complex spectral-spatial relationships and low-level details, while diffusion models represent a promising generative model known for their exceptional performance in modeling complex relations and learning high and low-level visual features. The direct application of diffusion models to HSI SR is hampered by challenges such as difficulties in model convergence and protracted inference time. In this work, we introduce a novel Group-Autoencoder (GAE) framework that synergistically combines with the diffusion model to construct a highly effective HSI SR model (DMGASR). Our proposed GAE framework encodes high-dimensional HSI data into low-dimensional latent space where the diffusion model works, thereby alleviating the difficulty of training the diffusion model while maintaining band correlation and considerably reducing inference time. Experimental results on both natural and remote sensing hyperspectral datasets demonstrate that the proposed method is superior to other state-of-the-art methods both visually and metrically. ",
    "url": "https://arxiv.org/abs/2402.17285",
    "authors": [
      "Zhaoyang Wang",
      "Dongyang Li",
      "Mingyang Zhang",
      "Hao Luo",
      "Maoguo Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17304",
    "title": "Probing Multimodal Large Language Models for Global and Local Semantic  Representation",
    "abstract": "The success of large language models has inspired researchers to transfer their exceptional representing ability to other modalities. Several recent works leverage image-caption alignment datasets to train multimodal large language models (MLLMs), which achieve state-of-the-art performance on image-to-text tasks. However, there are very few studies exploring whether MLLMs truly understand the complete image information, i.e., global information, or if they can only capture some local object information. In this study, we find that the intermediate layers of models can encode more global semantic information, whose representation vectors perform better on visual-language entailment tasks, rather than the topmost layers. We further probe models for local semantic representation through object detection tasks. And we draw a conclusion that the topmost layers may excessively focus on local information, leading to a diminished ability to encode global information. ",
    "url": "https://arxiv.org/abs/2402.17304",
    "authors": [
      "Mingxu Tao",
      "Quzhe Huang",
      "Kun Xu",
      "Liwei Chen",
      "Yansong Feng",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17316",
    "title": "Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via  Selective Entropy Distillation",
    "abstract": "The conventional deep learning paradigm often involves training a deep model on a server and then deploying the model or its distilled ones to resource-limited edge devices. Usually, the models shall remain fixed once deployed (at least for some period) due to the potential high cost of model adaptation for both the server and edge sides. However, in many real-world scenarios, the test environments may change dynamically (known as distribution shifts), which often results in degraded performance. Thus, one has to adapt the edge models promptly to attain promising performance. Moreover, with the increasing data collected at the edge, this paradigm also fails to further adapt the cloud model for better performance. To address these, we encounter two primary challenges: 1) the edge model has limited computation power and may only support forward propagation; 2) the data transmission budget between cloud and edge devices is limited in latency-sensitive scenarios. In this paper, we establish a Cloud-Edge Elastic Model Adaptation (CEMA) paradigm in which the edge models only need to perform forward propagation and the edge models can be adapted online. In our CEMA, to reduce the communication burden, we devise two criteria to exclude unnecessary samples from uploading to the cloud, i.e., dynamic unreliable and low-informative sample exclusion. Based on the uploaded samples, we update and distribute the affine parameters of normalization layers by distilling from the stronger foundation model to the edge model with a sample replay strategy. Extensive experimental results on ImageNet-C and ImageNet-R verify the effectiveness of our CEMA. ",
    "url": "https://arxiv.org/abs/2402.17316",
    "authors": [
      "Yaofo Chen",
      "Shuaicheng Niu",
      "Shoukai Xu",
      "Hengjie Song",
      "Yaowei Wang",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17318",
    "title": "Scaling Supervised Local Learning with Augmented Auxiliary Networks",
    "abstract": "Deep neural networks are typically trained using global error signals that backpropagate (BP) end-to-end, which is not only biologically implausible but also suffers from the update locking problem and requires huge memory consumption. Local learning, which updates each layer independently with a gradient-isolated auxiliary network, offers a promising alternative to address the above problems. However, existing local learning methods are confronted with a large accuracy gap with the BP counterpart, particularly for large-scale networks. This is due to the weak coupling between local layers and their subsequent network layers, as there is no gradient communication across layers. To tackle this issue, we put forward an augmented local learning method, dubbed AugLocal. AugLocal constructs each hidden layer's auxiliary network by uniformly selecting a small subset of layers from its subsequent network layers to enhance their synergy. We also propose to linearly reduce the depth of auxiliary networks as the hidden layer goes deeper, ensuring sufficient network capacity while reducing the computational cost of auxiliary networks. Our extensive experiments on four image classification datasets (i.e., CIFAR-10, SVHN, STL-10, and ImageNet) demonstrate that AugLocal can effectively scale up to tens of local layers with a comparable accuracy to BP-trained networks while reducing GPU memory usage by around 40%. The proposed AugLocal method, therefore, opens up a myriad of opportunities for training high-performance deep neural networks on resource-constrained platforms.Code is available at https://github.com/ChenxiangMA/AugLocal. ",
    "url": "https://arxiv.org/abs/2402.17318",
    "authors": [
      "Chenxiang Ma",
      "Jibin Wu",
      "Chenyang Si",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17319",
    "title": "A Vanilla Multi-Task Framework for Dense Visual Prediction Solution to  1st VCL Challenge -- Multi-Task Robustness Track",
    "abstract": "In this report, we present our solution to the multi-task robustness track of the 1st Visual Continual Learning (VCL) Challenge at ICCV 2023 Workshop. We propose a vanilla framework named UniNet that seamlessly combines various visual perception algorithms into a multi-task model. Specifically, we choose DETR3D, Mask2Former, and BinsFormer for 3D object detection, instance segmentation, and depth estimation tasks, respectively. The final submission is a single model with InternImage-L backbone, and achieves a 49.6 overall score (29.5 Det mAP, 80.3 mTPS, 46.4 Seg mAP, and 7.93 silog) on SHIFT validation set. Besides, we provide some interesting observations in our experiments which may facilitate the development of multi-task learning in dense visual prediction. ",
    "url": "https://arxiv.org/abs/2402.17319",
    "authors": [
      "Zehui Chen",
      "Qiuchen Wang",
      "Zhenyu Li",
      "Jiaming Liu",
      "Shanghang Zhang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17323",
    "title": "SDDGR: Stable Diffusion-based Deep Generative Replay for Class  Incremental Object Detection",
    "abstract": "In the field of class incremental learning (CIL), genera- tive replay has become increasingly prominent as a method to mitigate the catastrophic forgetting, alongside the con- tinuous improvements in generative models. However, its application in class incremental object detection (CIOD) has been significantly limited, primarily due to the com- plexities of scenes involving multiple labels. In this paper, we propose a novel approach called stable diffusion deep generative replay (SDDGR) for CIOD. Our method utilizes a diffusion-based generative model with pre-trained text- to-diffusion networks to generate realistic and diverse syn- thetic images. SDDGR incorporates an iterative refinement strategy to produce high-quality images encompassing old classes. Additionally, we adopt an L2 knowledge distilla- tion technique to improve the retention of prior knowledge in synthetic images. Furthermore, our approach includes pseudo-labeling for old objects within new task images, pre- venting misclassification as background elements. Exten- sive experiments on the COCO 2017 dataset demonstrate that SDDGR significantly outperforms existing algorithms, achieving a new state-of-the-art in various CIOD scenarios. The source code will be made available to the public. ",
    "url": "https://arxiv.org/abs/2402.17323",
    "authors": [
      "Junsu Kim",
      "Hoseong Cho",
      "Jihyeon Kim",
      "Yihalem Yimolal Tiruneh",
      "Seungryul Baek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17345",
    "title": "LocalGCL: Local-aware Contrastive Learning for Graphs",
    "abstract": "Graph representation learning (GRL) makes considerable progress recently, which encodes graphs with topological structures into low-dimensional embeddings. Meanwhile, the time-consuming and costly process of annotating graph labels manually prompts the growth of self-supervised learning (SSL) techniques. As a dominant approach of SSL, Contrastive learning (CL) learns discriminative representations by differentiating between positive and negative samples. However, when applied to graph data, it overemphasizes global patterns while neglecting local structures. To tackle the above issue, we propose \\underline{Local}-aware \\underline{G}raph \\underline{C}ontrastive \\underline{L}earning (\\textbf{\\methnametrim}), a self-supervised learning framework that supplementarily captures local graph information with masking-based modeling compared with vanilla contrastive learning. Extensive experiments validate the superiority of \\methname against state-of-the-art methods, demonstrating its promise as a comprehensive graph representation learner. ",
    "url": "https://arxiv.org/abs/2402.17345",
    "authors": [
      "Haojun Jiang",
      "Jiawei Sun",
      "Jie Li",
      "Chentao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17357",
    "title": "A robust parameterized enhanced shift-splitting preconditioner for  three-by-three block saddle point problems",
    "abstract": "This paper proposes a new parameterized enhanced shift-splitting {\\it (PESS)} preconditioner to solve the three-by-three block saddle point problem ({\\it SPP}). In addition, necessary and sufficient criteria are established for the convergence of the proposed {\\it PESS} iterative process for any random initial guess. Furthermore, we meticulously investigate the spectral bounds of the {\\it PESS} preconditioned matrix. Moreover, empirical investigation has been performed for the sensitivity analysis of the system, revealing the robustness of the proposed {\\it PESS} preconditioner. Numerical experiments are carried out to demonstrate the enhanced efficiency and robustness of the proposed {\\it PESS} preconditioner compared to the existing block diagonal and shift-splitting preconditioners. ",
    "url": "https://arxiv.org/abs/2402.17357",
    "authors": [
      "Sk. Safique Ahmad",
      "Pinki Khatun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.17363",
    "title": "CGGM: A conditional graph generation model with adaptive sparsity for  node anomaly detection in IoT networks",
    "abstract": "Dynamic graphs are extensively employed for detecting anomalous behavior in nodes within the Internet of Things (IoT). Generative models are often used to address the issue of imbalanced node categories in dynamic graphs. Nevertheless, the constraints it faces include the monotonicity of adjacency relationships, the difficulty in constructing multi-dimensional features for nodes, and the lack of a method for end-to-end generation of multiple categories of nodes. This paper presents a novel graph generation model, called CGGM, designed specifically to generate a larger number of nodes belonging to the minority class. The mechanism for generating an adjacency matrix, through adaptive sparsity, enhances flexibility in its structure. The feature generation module, called multidimensional features generator (MFG) to generate node features along with topological information. Labels are transformed into embedding vectors, serving as conditional constraints to control the generation of synthetic data across multiple categories. Using a multi-stage loss, the distribution of synthetic data is adjusted to closely resemble that of real data. In extensive experiments, we show that CGGM's synthetic data outperforms state-of-the-art methods across various metrics. Our results demonstrate efficient generation of diverse data categories, robustly enhancing multi-category classification model performance. ",
    "url": "https://arxiv.org/abs/2402.17363",
    "authors": [
      "Xianshi Su",
      "Munan Li",
      "Tongbang Jiang",
      "Hao Long"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17370",
    "title": "An Efficient MLP-based Point-guided Segmentation Network for Ore Images  with Ambiguous Boundary",
    "abstract": "The precise segmentation of ore images is critical to the successful execution of the beneficiation process. Due to the homogeneous appearance of the ores, which leads to low contrast and unclear boundaries, accurate segmentation becomes challenging, and recognition becomes problematic. This paper proposes a lightweight framework based on Multi-Layer Perceptron (MLP), which focuses on solving the problem of edge burring. Specifically, we introduce a lightweight backbone better suited for efficiently extracting low-level features. Besides, we design a feature pyramid network consisting of two MLP structures that balance local and global information thus enhancing detection accuracy. Furthermore, we propose a novel loss function that guides the prediction points to match the instance edge points to achieve clear object boundaries. We have conducted extensive experiments to validate the efficacy of our proposed method. Our approach achieves a remarkable processing speed of over 27 frames per second (FPS) with a model size of only 73 MB. Moreover, our method delivers a consistently high level of accuracy, with impressive performance scores of 60.4 and 48.9 in~$AP_{50}^{box}$ and~$AP_{50}^{mask}$ respectively, as compared to the currently available state-of-the-art techniques, when tested on the ore image dataset. The source code will be released at \\url{https://github.com/MVME-HBUT/ORENEXT}. ",
    "url": "https://arxiv.org/abs/2402.17370",
    "authors": [
      "Guodong Sun",
      "Yuting Peng",
      "Le Cheng",
      "Mengya Xu",
      "An Wang",
      "Bo Wu",
      "Hongliang Ren",
      "Yang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17371",
    "title": "A Dataset for Metaphor Detection in Early Medieval Hebrew Poetry",
    "abstract": "There is a large volume of late antique and medieval Hebrew texts. They represent a crucial linguistic and cultural bridge between Biblical and modern Hebrew. Poetry is prominent in these texts and one of its main haracteristics is the frequent use of metaphor. Distinguishing figurative and literal language use is a major task for scholars of the Humanities, especially in the fields of literature, linguistics, and hermeneutics. This paper presents a new, challenging dataset of late antique and medieval Hebrew poetry with expert annotations of metaphor, as well as some baseline results, which we hope will facilitate further research in this area. ",
    "url": "https://arxiv.org/abs/2402.17371",
    "authors": [
      "Michael Toker",
      "Oren Mishali",
      "Ophir M\u00fcnz-Manor",
      "Benny Kimelfeld",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.17390",
    "title": "Robustness-Congruent Adversarial Training for Secure Machine Learning  Model Updates",
    "abstract": "Machine-learning models demand for periodic updates to improve their average accuracy, exploiting novel architectures and additional data. However, a newly-updated model may commit mistakes that the previous model did not make. Such misclassifications are referred to as negative flips, and experienced by users as a regression of performance. In this work, we show that this problem also affects robustness to adversarial examples, thereby hindering the development of secure model update practices. In particular, when updating a model to improve its adversarial robustness, some previously-ineffective adversarial examples may become misclassified, causing a regression in the perceived security of the system. We propose a novel technique, named robustness-congruent adversarial training, to address this issue. It amounts to fine-tuning a model with adversarial training, while constraining it to retain higher robustness on the adversarial examples that were correctly classified before the update. We show that our algorithm and, more generally, learning with non-regression constraints, provides a theoretically-grounded framework to train consistent estimators. Our experiments on robust models for computer vision confirm that (i) both accuracy and robustness, even if improved after model update, can be affected by negative flips, and (ii) our robustness-congruent adversarial training can mitigate the problem, outperforming competing baseline methods. ",
    "url": "https://arxiv.org/abs/2402.17390",
    "authors": [
      "Daniele Angioni",
      "Luca Demetrio",
      "Maura Pintor",
      "Luca Oneto",
      "Davide Anguita",
      "Battista Biggio",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.17394",
    "title": "A Survey of Network Protocol Fuzzing: Model, Techniques and Directions",
    "abstract": "As one of the most successful and effective software testing techniques in recent years, fuzz testing has uncovered numerous bugs and vulnerabilities in modern software, including network protocol software. In contrast to other fuzzing targets, network protocol software exhibits its distinct characteristics and challenges, introducing a plethora of research questions that need to be addressed in the design and implementation of network protocol fuzzers. While some research work has evaluated and systematized the knowledge of general fuzzing techniques at a high level, there is a lack of similar analysis and summarization for fuzzing research specific to network protocols. This paper offers a comprehensive exposition of network protocol software's fuzzing-related features and conducts a systematic review of some representative advancements in network protocol fuzzing since its inception. We summarize state-of-the-art strategies and solutions in various aspects, propose a unified protocol fuzzing process model, and introduce the techniques involved in each stage of the model. At the same time, this paper also summarizes the promising research directions in the landscape of protocol fuzzing to foster exploration within the community for more efficient and intelligent modern network protocol fuzzing techniques. ",
    "url": "https://arxiv.org/abs/2402.17394",
    "authors": [
      "Shihao Jiang",
      "Yu Zhang",
      "Junqiang Li",
      "Hongfang Yu",
      "Long Luo",
      "Gang Sun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.17406",
    "title": "LSPT: Long-term Spatial Prompt Tuning for Visual Representation Learning",
    "abstract": "Visual Prompt Tuning (VPT) techniques have gained prominence for their capacity to adapt pre-trained Vision Transformers (ViTs) to downstream visual tasks using specialized learnable tokens termed as prompts. Contemporary VPT methodologies, especially when employed with self-supervised vision transformers, often default to the introduction of new learnable prompts or gated prompt tokens predominantly sourced from the model's previous block. A pivotal oversight in such approaches is their failure to harness the potential of long-range previous blocks as sources of prompts within each self-supervised ViT. To bridge this crucial gap, we introduce Long-term Spatial Prompt Tuning (LSPT) - a revolutionary approach to visual representation learning. Drawing inspiration from the intricacies of the human brain, LSPT ingeniously incorporates long-term gated prompts. This feature serves as temporal coding, curbing the risk of forgetting parameters acquired from earlier blocks. Further enhancing its prowess, LSPT brings into play patch tokens, serving as spatial coding. This is strategically designed to perpetually amass class-conscious features, thereby fortifying the model's prowess in distinguishing and identifying visual categories. To validate the efficacy of our proposed method, we engaged in rigorous experimentation across 5 FGVC and 19 VTAB-1K benchmarks. Our empirical findings underscore the superiority of LSPT, showcasing its ability to set new benchmarks in visual prompt tuning performance. ",
    "url": "https://arxiv.org/abs/2402.17406",
    "authors": [
      "Shentong Mo",
      "Yansen Wang",
      "Xufang Luo",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17407",
    "title": "A Neural Rewriting System to Solve Algorithmic Problems",
    "abstract": "Modern neural network architectures still struggle to learn algorithmic procedures that require to systematically apply compositional rules to solve out-of-distribution problem instances. In this work, we propose an original approach to learn algorithmic tasks inspired by rewriting systems, a classic framework in symbolic artificial intelligence. We show that a rewriting system can be implemented as a neural architecture composed by specialized modules: the Selector identifies the target sub-expression to process, the Solver simplifies the sub-expression by computing the corresponding result, and the Combiner produces a new version of the original expression by replacing the sub-expression with the solution provided. We evaluate our model on three types of algorithmic tasks that require simplifying symbolic formulas involving lists, arithmetic, and algebraic expressions. We test the extrapolation capabilities of the proposed architecture using formulas involving a higher number of operands and nesting levels than those seen during training, and we benchmark its performance against the Neural Data Router, a recent model specialized for systematic generalization, and a state-of-the-art large language model (GPT-4) probed with advanced prompting strategies. ",
    "url": "https://arxiv.org/abs/2402.17407",
    "authors": [
      "Flavio Petruzzellis",
      "Alberto Testolin",
      "Alessandro Sperduti"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.17410",
    "title": "A novel image space formalism of Fourier domain interpolation neural  networks for noise propagation analysis",
    "abstract": "Purpose: To develop an image space formalism of multi-layer convolutional neural networks (CNNs) for Fourier domain interpolation in MRI reconstructions and analytically estimate noise propagation during CNN inference. Theory and Methods: Nonlinear activations in the Fourier domain (also known as k-space) using complex-valued Rectifier Linear Units are expressed as elementwise multiplication with activation masks. This operation is transformed into a convolution in the image space. After network training in k-space, this approach provides an algebraic expression for the derivative of the reconstructed image with respect to the aliased coil images, which serve as the input tensors to the network in the image space. This allows the variance in the network inference to be estimated analytically and to be used to describe noise characteristics. Monte-Carlo simulations and numerical approaches based on auto-differentiation were used for validation. The framework was tested on retrospectively undersampled invivo brain images. Results: Inferences conducted in the image domain are quasi-identical to inferences in the k-space, underlined by corresponding quantitative metrics. Noise variance maps obtained from the analytical expression correspond with those obtained via Monte-Carlo simulations, as well as via an auto-differentiation approach. The noise resilience is well characterized, as in the case of classical Parallel Imaging. Komolgorov-Smirnov tests demonstrate Gaussian distributions of voxel magnitudes in variance maps obtained via Monte-Carlo simulations. Conclusion: The quasi-equivalent image space formalism for neural networks for k-space interpolation enables fast and accurate description of the noise characteristics during CNN inference, analogous to geometry-factor maps in traditional parallel imaging methods. ",
    "url": "https://arxiv.org/abs/2402.17410",
    "authors": [
      "Peter Dawood",
      "Felix Breuer",
      "Istvan Homolya",
      "Jannik Stebani",
      "Maximilian Gram",
      "Peter M. Jakob",
      "Moritz Zaiss",
      "Martin Blaimer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2402.17414",
    "title": "Neural Video Compression with Feature Modulation",
    "abstract": "The emerging conditional coding-based neural video codec (NVC) shows superiority over commonly-used residual coding-based codec and the latest NVC already claims to outperform the best traditional codec. However, there still exist critical problems blocking the practicality of NVC. In this paper, we propose a powerful conditional coding-based NVC that solves two critical problems via feature modulation. The first is how to support a wide quality range in a single model. Previous NVC with this capability only supports about 3.8 dB PSNR range on average. To tackle this limitation, we modulate the latent feature of the current frame via the learnable quantization scaler. During the training, we specially design the uniform quantization parameter sampling mechanism to improve the harmonization of encoding and quantization. This results in a better learning of the quantization scaler and helps our NVC support about 11.4 dB PSNR range. The second is how to make NVC still work under a long prediction chain. We expose that the previous SOTA NVC has an obvious quality degradation problem when using a large intra-period setting. To this end, we propose modulating the temporal feature with a periodically refreshing mechanism to boost the quality. %Besides solving the above two problems, we also design a single model that can support both RGB and YUV colorspaces. Notably, under single intra-frame setting, our codec can achieve 29.7\\% bitrate saving over previous SOTA NVC with 16\\% MACs reduction. Our codec serves as a notable landmark in the journey of NVC evolution. The codes are at https://github.com/microsoft/DCVC. ",
    "url": "https://arxiv.org/abs/2402.17414",
    "authors": [
      "Jiahao Li",
      "Bin Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.17420",
    "title": "PANDAS: Prototype-based Novel Class Discovery and Detection",
    "abstract": "Object detectors are typically trained once and for all on a fixed set of classes. However, this closed-world assumption is unrealistic in practice, as new classes will inevitably emerge after the detector is deployed in the wild. In this work, we look at ways to extend a detector trained for a set of base classes so it can i) spot the presence of novel classes, and ii) automatically enrich its repertoire to be able to detect those newly discovered classes together with the base ones. We propose PANDAS, a method for novel class discovery and detection. It discovers clusters representing novel classes from unlabeled data, and represents old and new classes with prototypes. During inference, a distance-based classifier uses these prototypes to assign a label to each detected object instance. The simplicity of our method makes it widely applicable. We experimentally demonstrate the effectiveness of PANDAS on the VOC 2012 and COCO-to-LVIS benchmarks. It performs favorably against the state of the art for this task while being computationally more affordable. ",
    "url": "https://arxiv.org/abs/2402.17420",
    "authors": [
      "Tyler L. Hayes",
      "C\u00e9sar R. de Souza",
      "Namil Kim",
      "Jiwon Kim",
      "Riccardo Volpi",
      "Diane Larlus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17442",
    "title": "Ansible Lightspeed: A Code Generation Service for IT Automation",
    "abstract": "The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for IT automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Red Hat Ansible Lightspeed with IBM Watson Code Assistant, further referred to as Ansible Lightspeed, is an LLM-based service designed explicitly for natural language to Ansible code generation. In this paper, we describe the design and implementation of the Ansible Lightspeed service and analyze feedback from thousands of real users. We examine diverse performance indicators, classified according to both immediate and extended utilization patterns along with user sentiments. The analysis shows that the user acceptance rate of Ansible Lightspeed suggestions is higher than comparable tools that are more general and not specific to a programming language. This remains true even after we use much more stringent criteria for what is considered an accepted model suggestion, discarding suggestions which were heavily edited after being accepted. The relatively high acceptance rate results in higher-than-expected user retention and generally positive user feedback. This paper provides insights on how a comparatively small, dedicated model performs on a domain-specific language and more importantly, how it is received by users. ",
    "url": "https://arxiv.org/abs/2402.17442",
    "authors": [
      "Priyam Sahoo",
      "Saurabh Pujar",
      "Ganesh Nalawade",
      "Richard Gebhardt",
      "Louis Mandel",
      "Luca Buratti"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.17472",
    "title": "Fraud Detection with Binding Global and Local Relational Interaction",
    "abstract": "Graph Neural Network has been proved to be effective for fraud detection for its capability to encode node interaction and aggregate features in a holistic view. Recently, Transformer network with great sequence encoding ability, has also outperformed other GNN-based methods in literatures. However, both GNN-based and Transformer-based networks only encode one perspective of the whole graph, while GNN encodes global features and Transformer network encodes local ones. Furthermore, previous works ignored encoding global interaction features of the heterogeneous graph with separate networks, thus leading to suboptimal performance. In this work, we present a novel framework called Relation-Aware GNN with transFormer (RAGFormer) which simultaneously embeds local and global features into a target node. The simple yet effective network applies a modified GAGA module where each transformer layer is followed by a cross-relation aggregation layer, to encode local embeddings and node interactions across different relations. Apart from the Transformer-based network, we further introduce a Relation-Aware GNN module to learn global embeddings, which is later merged into the local embeddings by an attention fusion module and a skip connection. Extensive experiments on two popular public datasets and an industrial dataset demonstrate that RAGFormer achieves the state-of-the-art performance. Substantial analysis experiments validate the effectiveness of each submodule of RAGFormer and its high efficiency in utilizing small-scale data and low hyper-parameter sensitivity. ",
    "url": "https://arxiv.org/abs/2402.17472",
    "authors": [
      "Haolin Li",
      "Shuyang Jiang",
      "Lifeng Zhang",
      "Siyuan Du",
      "Guangnan Ye",
      "Hongfeng Chai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17478",
    "title": "Can GPT-4 Identify Propaganda? Annotation and Detection of Propaganda  Spans in News Articles",
    "abstract": "The use of propaganda has spiked on mainstream and social media, aiming to manipulate or mislead users. While efforts to automatically detect propaganda techniques in textual, visual, or multimodal content have increased, most of them primarily focus on English content. The majority of the recent initiatives targeting medium to low-resource languages produced relatively small annotated datasets, with a skewed distribution, posing challenges for the development of sophisticated propaganda detection models. To address this challenge, we carefully develop the largest propaganda dataset to date, ArPro, comprised of 8K paragraphs from newspaper articles, labeled at the text span level following a taxonomy of 23 propagandistic techniques. Furthermore, our work offers the first attempt to understand the performance of large language models (LLMs), using GPT-4, for fine-grained propaganda detection from text. Results showed that GPT-4's performance degrades as the task moves from simply classifying a paragraph as propagandistic or not, to the fine-grained task of detecting propaganda techniques and their manifestation in text. Compared to models fine-tuned on the dataset for propaganda detection at different classification granularities, GPT-4 is still far behind. Finally, we evaluate GPT-4 on a dataset consisting of six other languages for span detection, and results suggest that the model struggles with the task across languages. Our dataset and resources will be released to the community. ",
    "url": "https://arxiv.org/abs/2402.17478",
    "authors": [
      "Maram Hasanain",
      "Fatema Ahmed",
      "Firoj Alam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.17509",
    "title": "Extreme Miscalibration and the Illusion of Adversarial Robustness",
    "abstract": "Deep learning-based Natural Language Processing (NLP) models are vulnerable to adversarial attacks, where small perturbations can cause a model to misclassify. Adversarial Training (AT) is often used to increase model robustness. However, we have discovered an intriguing phenomenon: deliberately or accidentally miscalibrating models masks gradients in a way that interferes with adversarial attack search methods, giving rise to an apparent increase in robustness. We show that this observed gain in robustness is an illusion of robustness (IOR), and demonstrate how an adversary can perform various forms of test-time temperature calibration to nullify the aforementioned interference and allow the adversarial attack to find adversarial examples. Hence, we urge the NLP community to incorporate test-time temperature scaling into their robustness evaluations to ensure that any observed gains are genuine. Finally, we show how the temperature can be scaled during \\textit{training} to improve genuine robustness. ",
    "url": "https://arxiv.org/abs/2402.17509",
    "authors": [
      "Vyas Raina",
      "Samson Tan",
      "Volkan Cevher",
      "Aditya Rawal",
      "Sheng Zha",
      "George Karypis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.17510",
    "title": "Demonstrating and Reducing Shortcuts in Vision-Language Representation  Learning",
    "abstract": "Vision-language models (VLMs) mainly rely on contrastive training to learn general-purpose representations of images and captions. We focus on the situation when one image is associated with several captions, each caption containing both information shared among all captions and unique information per caption about the scene depicted in the image. In such cases, it is unclear whether contrastive losses are sufficient for learning task-optimal representations that contain all the information provided by the captions or whether the contrastive learning setup encourages the learning of a simple shortcut that minimizes contrastive loss. We introduce synthetic shortcuts for vision-language: a training and evaluation framework where we inject synthetic shortcuts into image-text data. We show that contrastive VLMs trained from scratch or fine-tuned with data containing these synthetic shortcuts mainly learn features that represent the shortcut. Hence, contrastive losses are not sufficient to learn task-optimal representations, i.e., representations that contain all task-relevant information shared between the image and associated captions. We examine two methods to reduce shortcut learning in our training and evaluation framework: (i) latent target decoding and (ii) implicit feature modification. We show empirically that both methods improve performance on the evaluation task, but only partly reduce shortcut learning when training and evaluating with our shortcut learning framework. Hence, we show the difficulty and challenge of our shortcut learning framework for contrastive vision-language representation learning. ",
    "url": "https://arxiv.org/abs/2402.17510",
    "authors": [
      "Maurits Bleeker",
      "Mariya Hendriksen",
      "Andrew Yates",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17514",
    "title": "Robust Unsupervised Crowd Counting and Localization with Adaptive  Resolution SAM",
    "abstract": "The existing crowd counting models require extensive training data, which is time-consuming to annotate. To tackle this issue, we propose a simple yet effective crowd counting method by utilizing the Segment-Everything-Everywhere Model (SEEM), an adaptation of the Segmentation Anything Model (SAM), to generate pseudo-labels for training crowd counting models. However, our initial investigation reveals that SEEM's performance in dense crowd scenes is limited, primarily due to the omission of many persons in high-density areas. To overcome this limitation, we propose an adaptive resolution SEEM to handle the scale variations, occlusions, and overlapping of people within crowd scenes. Alongside this, we introduce a robust localization method, based on Gaussian Mixture Models, for predicting the head positions in the predicted people masks. Given the mask and point pseudo-labels, we propose a robust loss function, which is designed to exclude uncertain regions based on SEEM's predictions, thereby enhancing the training process of the counting networks. Finally, we propose an iterative method for generating pseudo-labels. This method aims at improving the quality of the segmentation masks by identifying more tiny persons in high-density regions, which are often missed in the first pseudo-labeling stage. Overall, our proposed method achieves the best unsupervised performance in crowd counting, while also being comparable results to some supervised methods. This makes it a highly effective and versatile tool for crowd counting, especially in situations where labeled data is not available. ",
    "url": "https://arxiv.org/abs/2402.17514",
    "authors": [
      "Jia Wan",
      "Qiangqiang Wu",
      "Wei Lin",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17517",
    "title": "Label-Noise Robust Diffusion Models",
    "abstract": "Conditional diffusion models have shown remarkable performance in various generative tasks, but training them requires large-scale datasets that often contain noise in conditional inputs, a.k.a. noisy labels. This noise leads to condition mismatch and quality degradation of generated data. This paper proposes Transition-aware weighted Denoising Score Matching (TDSM) for training conditional diffusion models with noisy labels, which is the first study in the line of diffusion models. The TDSM objective contains a weighted sum of score networks, incorporating instance-wise and time-dependent label transition probabilities. We introduce a transition-aware weight estimator, which leverages a time-dependent noisy-label classifier distinctively customized to the diffusion process. Through experiments across various datasets and noisy label settings, TDSM improves the quality of generated samples aligned with given conditions. Furthermore, our method improves generation performance even on prevalent benchmark datasets, which implies the potential noisy labels and their risk of generative model learning. Finally, we show the improved performance of TDSM on top of conventional noisy label corrections, which empirically proving its contribution as a part of label-noise robust generative models. Our code is available at: https://github.com/byeonghu-na/tdsm. ",
    "url": "https://arxiv.org/abs/2402.17517",
    "authors": [
      "Byeonghu Na",
      "Yeongmin Kim",
      "HeeSun Bae",
      "Jung Hyun Lee",
      "Se Jung Kwon",
      "Wanmo Kang",
      "Il-Chul Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17533",
    "title": "Black-box Adversarial Attacks Against Image Quality Assessment Models",
    "abstract": "The goal of No-Reference Image Quality Assessment (NR-IQA) is to predict the perceptual quality of an image in line with its subjective evaluation. To put the NR-IQA models into practice, it is essential to study their potential loopholes for model refinement. This paper makes the first attempt to explore the black-box adversarial attacks on NR-IQA models. Specifically, we first formulate the attack problem as maximizing the deviation between the estimated quality scores of original and perturbed images, while restricting the perturbed image distortions for visual quality preservation. Under such formulation, we then design a Bi-directional loss function to mislead the estimated quality scores of adversarial examples towards an opposite direction with maximum deviation. On this basis, we finally develop an efficient and effective black-box attack method against NR-IQA models. Extensive experiments reveal that all the evaluated NR-IQA models are vulnerable to the proposed attack method. And the generated perturbations are not transferable, enabling them to serve the investigation of specialities of disparate IQA models. ",
    "url": "https://arxiv.org/abs/2402.17533",
    "authors": [
      "Yu Ran",
      "Ao-Xiang Zhang",
      "Mingjie Li",
      "Weixuan Tang",
      "Yuan-Gen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.17550",
    "title": "Emergency Caching: Coded Caching-based Reliable Map Transmission in  Emergency Networks",
    "abstract": "Many rescue missions demand effective perception and real-time decision making, which highly rely on effective data collection and processing. In this study, we propose a three-layer architecture of emergency caching networks focusing on data collection and reliable transmission, by leveraging efficient perception and edge caching technologies. Based on this architecture, we propose a disaster map collection framework that integrates coded caching technologies. Our framework strategically caches coded fragments of maps across unmanned aerial vehicles (UAVs), fostering collaborative uploading for augmented transmission reliability. Additionally, we establish a comprehensive probability model to assess the effective recovery area of disaster maps. Towards the goal of utility maximization, we propose a deep reinforcement learning (DRL) based algorithm that jointly makes decisions about cooperative UAVs selection, bandwidth allocation and coded caching parameter adjustment, accommodating the real-time map updates in a dynamic disaster situation. Our proposed scheme is more effective than the non-coding caching scheme, as validated by simulation. ",
    "url": "https://arxiv.org/abs/2402.17550",
    "authors": [
      "Zeyu Tian",
      "Lianming Xu",
      "Liang Li",
      "Li Wang",
      "Aiguo Fei"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.17563",
    "title": "Structure-Guided Adversarial Training of Diffusion Models",
    "abstract": "Diffusion models have demonstrated exceptional efficacy in various generative applications. While existing models focus on minimizing a weighted sum of denoising score matching losses for data distribution modeling, their training primarily emphasizes instance-level optimization, overlooking valuable structural information within each mini-batch, indicative of pair-wise relationships among samples. To address this limitation, we introduce Structure-guided Adversarial training of Diffusion Models (SADM). In this pioneering approach, we compel the model to learn manifold structures between samples in each training batch. To ensure the model captures authentic manifold structures in the data distribution, we advocate adversarial training of the diffusion generator against a novel structure discriminator in a minimax game, distinguishing real manifold structures from the generated ones. SADM substantially improves existing diffusion transformers (DiT) and outperforms existing methods in image generation and cross-domain fine-tuning tasks across 12 datasets, establishing a new state-of-the-art FID of 1.58 and 2.11 on ImageNet for class-conditional image generation at resolutions of 256x256 and 512x512, respectively. ",
    "url": "https://arxiv.org/abs/2402.17563",
    "authors": [
      "Ling Yang",
      "Haotian Qian",
      "Zhilong Zhang",
      "Jingwei Liu",
      "Bin Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17572",
    "title": "Hyperdimensional computing: a fast, robust and interpretable paradigm  for biological data",
    "abstract": "Advances in bioinformatics are primarily due to new algorithms for processing diverse biological data sources. While sophisticated alignment algorithms have been pivotal in analyzing biological sequences, deep learning has substantially transformed bioinformatics, addressing sequence, structure, and functional analyses. However, these methods are incredibly data-hungry, compute-intensive and hard to interpret. Hyperdimensional computing (HDC) has recently emerged as an intriguing alternative. The key idea is that random vectors of high dimensionality can represent concepts such as sequence identity or phylogeny. These vectors can then be combined using simple operators for learning, reasoning or querying by exploiting the peculiar properties of high-dimensional spaces. Our work reviews and explores the potential of HDC for bioinformatics, emphasizing its efficiency, interpretability, and adeptness in handling multimodal and structured data. HDC holds a lot of potential for various omics data searching, biosignal analysis and health applications. ",
    "url": "https://arxiv.org/abs/2402.17572",
    "authors": [
      "Michiel Stock",
      "Dimitri Boeckaerts",
      "Pieter Dewulf",
      "Steff Taelman",
      "Maxime Van Haeverbeke",
      "Wim Van Criekinge",
      "Bernard De Baets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2402.17573",
    "title": "HBF MU-MIMO with Interference-Aware Beam Pair Link Allocation for  Beyond-5G mm-Wave Networks",
    "abstract": "Hybrid beamforming (HBF) multi-user multiple-input multiple-output (MU-MIMO) is a key technology for unlocking the directional millimeter-wave (mm-wave) nature for spatial multiplexing beyond current codebook-based 5G-NR networks. In order to suppress co-scheduled users' interference, HBF MU-MIMO is predicated on having sufficient radio frequency chains and accurate channel state information (CSI), which can otherwise lead to performance losses due to imperfect interference cancellation. In this work, we propose IABA, a 5G-NR standard-compliant beam pair link (BPL) allocation scheme for mitigating spatial interference in practical HBF MU-MIMO networks. IABA solves the network sum throughput optimization via either a distributed or a centralized BPL allocation using dedicated CSI reference signals for candidate BPL monitoring. We present a comprehensive study of practical multi-cell mm-wave networks and demonstrate that HBF MU-MIMO without interference-aware BPL allocation experiences strong residual interference which limits the achievable network performance. Our results show that IABA offers significant performance gains over the default interference-agnostic 5G-NR BPL allocation, and even allows HBF MU-MIMO to outperform the fully digital MU-MIMO baseline, by facilitating allocation of secondary BPLs other than the strongest BPL found during initial access. We further demonstrate the scalability of IABA with increased gNB antennas and densification for beyond-5G mm-wave networks. ",
    "url": "https://arxiv.org/abs/2402.17573",
    "authors": [
      "Aleksandar Ichkov",
      "Alexander Wietfeld",
      "Marina Petrova",
      "Ljiljana Simi\u0107"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.17589",
    "title": "PLReMix: Combating Noisy Labels with Pseudo-Label Relaxed Contrastive  Representation Learning",
    "abstract": "Recently, the application of Contrastive Representation Learning (CRL) in learning with noisy labels (LNL) has shown promising advancements due to its remarkable ability to learn well-distributed representations for better distinguishing noisy labels. However, CRL is mainly used as a pre-training technique, leading to a complicated multi-stage training pipeline. We also observed that trivially combining CRL with supervised LNL methods decreases performance. Using different images from the same class as negative pairs in CRL creates optimization conflicts between CRL and the supervised loss. To address these two issues, we propose an end-to-end PLReMix framework that avoids the complicated pipeline by introducing a Pseudo-Label Relaxed (PLR) contrastive loss to alleviate the conflicts between losses. This PLR loss constructs a reliable negative set of each sample by filtering out its inappropriate negative pairs that overlap at the top k indices of prediction probabilities, leading to more compact semantic clusters than vanilla CRL. Furthermore, a two-dimensional Gaussian Mixture Model (GMM) is adopted to distinguish clean and noisy samples by leveraging semantic information and model outputs simultaneously, which is expanded on the previously widely used one-dimensional form. The PLR loss and a semi-supervised loss are simultaneously applied to train on the GMM divided clean and noisy samples. Experiments on multiple benchmark datasets demonstrate the effectiveness of the proposed method. Our proposed PLR loss is scalable, which can be easily integrated into other LNL methods and boost their performance. Codes will be available. ",
    "url": "https://arxiv.org/abs/2402.17589",
    "authors": [
      "Xiaoyu Liu",
      "Beitong Zhou",
      "Cheng Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17595",
    "title": "Implicit Regularization via Spectral Neural Networks and Non-linear  Matrix Sensing",
    "abstract": "The phenomenon of implicit regularization has attracted interest in recent years as a fundamental aspect of the remarkable generalizing ability of neural networks. In a nutshell, it entails that gradient descent dynamics in many neural nets, even without any explicit regularizer in the loss function, converges to the solution of a regularized learning problem. However, known results attempting to theoretically explain this phenomenon focus overwhelmingly on the setting of linear neural nets, and the simplicity of the linear structure is particularly crucial to existing arguments. In this paper, we explore this problem in the context of more realistic neural networks with a general class of non-linear activation functions, and rigorously demonstrate the implicit regularization phenomenon for such networks in the setting of matrix sensing problems, together with rigorous rate guarantees that ensure exponentially fast convergence of gradient descent.In this vein, we contribute a network architecture called Spectral Neural Networks (abbrv. SNN) that is particularly suitable for matrix learning problems. Conceptually, this entails coordinatizing the space of matrices by their singular values and singular vectors, as opposed to by their entries, a potentially fruitful perspective for matrix learning. We demonstrate that the SNN architecture is inherently much more amenable to theoretical analysis than vanilla neural nets and confirm its effectiveness in the context of matrix sensing, via both mathematical guarantees and empirical investigations. We believe that the SNN architecture has the potential to be of wide applicability in a broad class of matrix learning scenarios. ",
    "url": "https://arxiv.org/abs/2402.17595",
    "authors": [
      "Hong T.M. Chu",
      "Subhro Ghosh",
      "Chi Thanh Lam",
      "Soumendu Sundar Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.17601",
    "title": "Advancing sleep detection by modelling weak label sets: A novel weakly  supervised learning approach",
    "abstract": "Understanding sleep and activity patterns plays a crucial role in physical and mental health. This study introduces a novel approach for sleep detection using weakly supervised learning for scenarios where reliable ground truth labels are unavailable. The proposed method relies on a set of weak labels, derived from the predictions generated by conventional sleep detection algorithms. Introducing a novel approach, we suggest a novel generalised non-linear statistical model in which the number of weak sleep labels is modelled as outcome of a binomial distribution. The probability of sleep in the binomial distribution is linked to the outcomes of neural networks trained to detect sleep based on actigraphy. We show that maximizing the likelihood function of the model, is equivalent to minimizing the soft cross-entropy loss. Additionally, we explored the use of the Brier score as a loss function for weak labels. The efficacy of the suggested modelling framework was demonstrated using the Multi-Ethnic Study of Atherosclerosis dataset. A \\gls{lstm} trained on the soft cross-entropy outperformed conventional sleep detection algorithms, other neural network architectures and loss functions in accuracy and model calibration. This research not only advances sleep detection techniques in scenarios where ground truth data is scarce but also contributes to the broader field of weakly supervised learning by introducing innovative approach in modelling sets of weak labels. ",
    "url": "https://arxiv.org/abs/2402.17601",
    "authors": [
      "Matthias Boeker",
      "Vajira Thambawita",
      "Michael Riegler",
      "P\u00e5l Halvorsen",
      "Hugo L. Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17606",
    "title": "Learning Topological Representations with Bidirectional Graph Attention  Network for Solving Job Shop Scheduling Problem",
    "abstract": "Existing learning-based methods for solving job shop scheduling problem (JSSP) usually use off-the-shelf GNN models tailored to undirected graphs and neglect the rich and meaningful topological structures of disjunctive graphs (DGs). This paper proposes the topology-aware bidirectional graph attention network (TBGAT), a novel GNN architecture based on the attention mechanism, to embed the DG for solving JSSP in a local search framework. Specifically, TBGAT embeds the DG from a forward and a backward view, respectively, where the messages are propagated by following the different topologies of the views and aggregated via graph attention. Then, we propose a novel operator based on the message-passing mechanism to calculate the forward and backward topological sorts of the DG, which are the features for characterizing the topological structures and exploited by our model. In addition, we theoretically and experimentally show that TBGAT has linear computational complexity to the number of jobs and machines, respectively, which strengthens the practical value of our method. Besides, extensive experiments on five synthetic datasets and seven classic benchmarks show that TBGAT achieves new SOTA results by outperforming a wide range of neural methods by a large margin. ",
    "url": "https://arxiv.org/abs/2402.17606",
    "authors": [
      "Cong Zhang",
      "Zhiguang Cao",
      "Yaoxin Wu",
      "Wen Song",
      "Jing Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17611",
    "title": "A Large-scale Evaluation of Pretraining Paradigms for the Detection of  Defects in Electroluminescence Solar Cell Images",
    "abstract": "Pretraining has been shown to improve performance in many domains, including semantic segmentation, especially in domains with limited labelled data. In this work, we perform a large-scale evaluation and benchmarking of various pretraining methods for Solar Cell Defect Detection (SCDD) in electroluminescence images, a field with limited labelled datasets. We cover supervised training with semantic segmentation, semi-supervised learning, and two self-supervised techniques. We also experiment with both in-distribution and out-of-distribution (OOD) pretraining and observe how this affects downstream performance. The results suggest that supervised training on a large OOD dataset (COCO), self-supervised pretraining on a large OOD dataset (ImageNet), and semi-supervised pretraining (CCT) all yield statistically equivalent performance for mean Intersection over Union (mIoU). We achieve a new state-of-the-art for SCDD and demonstrate that certain pretraining schemes result in superior performance on underrepresented classes. Additionally, we provide a large-scale unlabelled EL image dataset of $22000$ images, and a $642$-image labelled semantic segmentation EL dataset, for further research in developing self- and semi-supervised training techniques in this domain. ",
    "url": "https://arxiv.org/abs/2402.17611",
    "authors": [
      "David Torpey",
      "Lawrence Pratt",
      "Richard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17613",
    "title": "Neural Automated Writing Evaluation with Corrective Feedback",
    "abstract": "The utilization of technology in second language learning and teaching has become ubiquitous. For the assessment of writing specifically, automated writing evaluation (AWE) and grammatical error correction (GEC) have become immensely popular and effective methods for enhancing writing proficiency and delivering instant and individualized feedback to learners. By leveraging the power of natural language processing (NLP) and machine learning algorithms, AWE and GEC systems have been developed separately to provide language learners with automated corrective feedback and more accurate and unbiased scoring that would otherwise be subject to examiners. In this paper, we propose an integrated system for automated writing evaluation with corrective feedback as a means of bridging the gap between AWE and GEC results for second language learners. This system enables language learners to simulate the essay writing tests: a student writes and submits an essay, and the system returns the assessment of the writing along with suggested grammatical error corrections. Given that automated scoring and grammatical correction are more efficient and cost-effective than human grading, this integrated system would also alleviate the burden of manually correcting innumerable essays. ",
    "url": "https://arxiv.org/abs/2402.17613",
    "authors": [
      "Izia Xiaoxiao Wang",
      "Xihan Wu",
      "Edith Coates",
      "Min Zeng",
      "Jiexin Kuang",
      "Siliang Liu",
      "Mengyang Qiu",
      "Jungyeul Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.17641",
    "title": "Variational Learning is Effective for Large Deep Networks",
    "abstract": "We give extensive empirical evidence against the common belief that variational learning is ineffective for large neural networks. We show that an optimizer called Improved Variational Online Newton (IVON) consistently matches or outperforms Adam for training large networks such as GPT-2 and ResNets from scratch. IVON's computational costs are nearly identical to Adam but its predictive uncertainty is better. We show several new use cases of IVON where we improve fine-tuning and model merging in Large Language Models, accurately predict generalization error, and faithfully estimate sensitivity to data. We find overwhelming evidence in support of effectiveness of variational learning. ",
    "url": "https://arxiv.org/abs/2402.17641",
    "authors": [
      "Yuesong Shen",
      "Nico Daheim",
      "Bai Cong",
      "Peter Nickl",
      "Gian Maria Marconi",
      "Clement Bazan",
      "Rio Yokota",
      "Iryna Gurevych",
      "Daniel Cremers",
      "Mohammad Emtiyaz Khan",
      "Thomas M\u00f6llenhoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.17644",
    "title": "Are LLMs Capable of Data-based Statistical and Causal Reasoning?  Benchmarking Advanced Quantitative Reasoning with Data",
    "abstract": "Quantitative reasoning is a critical skill to analyze data, yet the assessment of such ability remains limited. To address this gap, we introduce the Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate Large Language Models' capability in statistical and causal reasoning with real-world data. The benchmark comprises a carefully constructed dataset of 411 questions accompanied by data sheets from textbooks, online learning materials, and academic papers. To compare models' quantitative reasoning abilities on data and text, we enrich the benchmark with an auxiliary set of 290 text-only questions, namely QRText. We evaluate natural language reasoning, program-based reasoning, and agent reasoning methods including Chain-of-Thought, Program-of-Thoughts, ReAct, and code interpreter assistants on diverse models. The strongest model GPT-4 achieves an accuracy of 58%, which has a large room for improvement. Among open-source models, Deepseek-coder-instruct, a code LLM pretrained on 2T tokens, gets the highest accuracy of 37%. Analysis reveals that models encounter difficulties in data analysis and causal reasoning, and struggle in using causal knowledge and provided data simultaneously. Code and data are in https://github.com/xxxiaol/QRData. ",
    "url": "https://arxiv.org/abs/2402.17644",
    "authors": [
      "Xiao Liu",
      "Zirui Wu",
      "Xueqing Wu",
      "Pan Lu",
      "Kai-Wei Chang",
      "Yansong Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17651",
    "title": "CSI-Free Optimization of Reconfigurable Intelligent Surfaces with  Interference by Using Multiport Network Theory",
    "abstract": "Reconfigurable Intelligent Surfaces (RIS) will play a pivotal role in next-generation wireless systems. Despite efforts to minimize pilot overhead associated with channel estimation, the necessity of configuring the RIS multiple times before obtaining reliable Channel State Information (CSI) may significantly diminish their benefits. Therefore, we propose a CSI-free approach that explores the feasibility of optimizing the RIS for the uplink of a communication system in the presence of interfering users without relying on CSI estimation but leveraging solely some a priori statistical knowledge of the channel. In this context, we consider a multiport network model that accounts for several aspects overlooked by traditional RIS models used in Communication Theory, such as mutual coupling among scattering elements and the presence of structural scattering. The proposed approach targets the maximization of the average achievable rate and is shown to achieve performance that, in some cases, can be very close to the case where the RIS is optimized leveraging perfect CSI. ",
    "url": "https://arxiv.org/abs/2402.17651",
    "authors": [
      "A. Abrardo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.17660",
    "title": "TorchMD-Net 2.0: Fast Neural Network Potentials for Molecular  Simulations",
    "abstract": "Achieving a balance between computational speed, prediction accuracy, and universal applicability in molecular simulations has been a persistent challenge. This paper presents substantial advancements in the TorchMD-Net software, a pivotal step forward in the shift from conventional force fields to neural network-based potentials. The evolution of TorchMD-Net into a more comprehensive and versatile framework is highlighted, incorporating cutting-edge architectures such as TensorNet. This transformation is achieved through a modular design approach, encouraging customized applications within the scientific community. The most notable enhancement is a significant improvement in computational efficiency, achieving a very remarkable acceleration in the computation of energy and forces for TensorNet models, with performance gains ranging from 2-fold to 10-fold over previous iterations. Other enhancements include highly optimized neighbor search algorithms that support periodic boundary conditions and the smooth integration with existing molecular dynamics frameworks. Additionally, the updated version introduces the capability to integrate physical priors, further enriching its application spectrum and utility in research. The software is available at https://github.com/torchmd/torchmd-net. ",
    "url": "https://arxiv.org/abs/2402.17660",
    "authors": [
      "Raul P. Pelaez",
      "Guillem Simeon",
      "Raimondas Galvelis",
      "Antonio Mirarchi",
      "Peter Eastman",
      "Stefan Doerr",
      "Philipp Th\u00f6lke",
      "Thomas E. Markland",
      "Gianni De Fabritiis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2402.17672",
    "title": "SDF2Net: Shallow to Deep Feature Fusion Network for PolSAR Image  Classification",
    "abstract": "Polarimetric synthetic aperture radar (PolSAR) images encompass valuable information that can facilitate extensive land cover interpretation and generate diverse output products. Extracting meaningful features from PolSAR data poses challenges distinct from those encountered in optical imagery. Deep learning (DL) methods offer effective solutions for overcoming these challenges in PolSAR feature extraction. Convolutional neural networks (CNNs) play a crucial role in capturing PolSAR image characteristics by leveraging kernel capabilities to consider local information and the complex-valued nature of PolSAR data. In this study, a novel three-branch fusion of complex-valued CNN, named the Shallow to Deep Feature Fusion Network (SDF2Net), is proposed for PolSAR image classification. To validate the performance of the proposed method, classification results are compared against multiple state-of-the-art approaches using the airborne synthetic aperture radar (AIRSAR) datasets of Flevoland and San Francisco, as well as the ESAR Oberpfaffenhofen dataset. The results indicate that the proposed approach demonstrates improvements in overallaccuracy, with a 1.3% and 0.8% enhancement for the AIRSAR datasets and a 0.5% improvement for the ESAR dataset. Analyses conducted on the Flevoland data underscore the effectiveness of the SDF2Net model, revealing a promising overall accuracy of 96.01% even with only a 1% sampling ratio. ",
    "url": "https://arxiv.org/abs/2402.17672",
    "authors": [
      "Mohammed Q. Alkhatib",
      "M. Sami Zitouni",
      "Mina Al-Saad",
      "Nour Aburaed",
      "Hussain Al-Ahmad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.17689",
    "title": "QoS prediction in radio vehicular environments via prior user  information",
    "abstract": "Reliable wireless communications play an important role in the automotive industry as it helps to enhance current use cases and enable new ones such as connected autonomous driving, platooning, cooperative maneuvering, teleoperated driving, and smart navigation. These and other use cases often rely on specific quality of service (QoS) levels for communication. Recently, the area of predictive quality of service (QoS) has received a great deal of attention as a key enabler to forecast communication quality well enough in advance. However, predicting QoS in a reliable manner is a notoriously difficult task. In this paper, we evaluate ML tree-ensemble methods to predict QoS in the range of minutes with data collected from a cellular test network. We discuss radio environment characteristics and we showcase how these can be used to improve ML performance and further support the uptake of ML in commercial networks. Specifically, we use the correlations of the measurements coming from the radio environment by including information of prior vehicles to enhance the prediction of the target vehicles. Moreover, we are extending prior art by showing how longer prediction horizons can be supported. ",
    "url": "https://arxiv.org/abs/2402.17689",
    "authors": [
      "Noor Ul Ain",
      "Rodrigo Hernang\u00f3mez",
      "Alexandros Palaios",
      "Martin Kasparick",
      "S\u0142awomir Sta\u0144czak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17705",
    "title": "Federated Learning for Estimating Heterogeneous Treatment Effects",
    "abstract": "Machine learning methods for estimating heterogeneous treatment effects (HTE) facilitate large-scale personalized decision-making across various domains such as healthcare, policy making, education, and more. Current machine learning approaches for HTE require access to substantial amounts of data per treatment, and the high costs associated with interventions makes centrally collecting so much data for each intervention a formidable challenge. To overcome this obstacle, in this work, we propose a novel framework for collaborative learning of HTE estimators across institutions via Federated Learning. We show that even under a diversity of interventions and subject populations across clients, one can jointly learn a common feature representation, while concurrently and privately learning the specific predictive functions for outcomes under distinct interventions across institutions. Our framework and the associated algorithm are based on this insight, and leverage tabular transformers to map multiple input data to feature representations which are then used for outcome prediction via multi-task learning. We also propose a novel way of federated training of personalised transformers that can work with heterogeneous input feature spaces. Experimental results on real-world clinical trial data demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2402.17705",
    "authors": [
      "Disha Makhija",
      "Joydeep Ghosh",
      "Yejin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17710",
    "title": "Understanding Neural Network Binarization with Forward and Backward  Proximal Quantizers",
    "abstract": "In neural network binarization, BinaryConnect (BC) and its variants are considered the standard. These methods apply the sign function in their forward pass and their respective gradients are backpropagated to update the weights. However, the derivative of the sign function is zero whenever defined, which consequently freezes training. Therefore, implementations of BC (e.g., BNN) usually replace the derivative of sign in the backward computation with identity or other approximate gradient alternatives. Although such practice works well empirically, it is largely a heuristic or ''training trick.'' We aim at shedding some light on these training tricks from the optimization perspective. Building from existing theory on ProxConnect (PC, a generalization of BC), we (1) equip PC with different forward-backward quantizers and obtain ProxConnect++ (PC++) that includes existing binarization techniques as special cases; (2) derive a principled way to synthesize forward-backward quantizers with automatic theoretical guarantees; (3) illustrate our theory by proposing an enhanced binarization algorithm BNN++; (4) conduct image classification experiments on CNNs and vision transformers, and empirically verify that BNN++ generally achieves competitive results on binarizing these models. ",
    "url": "https://arxiv.org/abs/2402.17710",
    "authors": [
      "Yiwei Lu",
      "Yaoliang Yu",
      "Xinlin Li",
      "Vahid Partovi Nia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17711",
    "title": "Interior penalty discontinuous Galerkin methods for the nearly  incompressible elasticity eigenvalue problem with heterogeneous media",
    "abstract": "This paper studies the family of interior penalty discontinuous Galerkin methods for solving the Herrmann formulation of the linear elasticity eigenvalue problem in heterogeneous media. By employing a weighted Lam\\'e coefficient norm within the framework of non-compact operators theory, we prove convergence of both continuous and discrete eigenvalue problems as the mesh size approaches zero, independently of the Lam\\'e constants. Additionally, we conduct an a posteriori analysis and propose a reliable and efficient estimator. The theoretical findings are supported by numerical experiments. ",
    "url": "https://arxiv.org/abs/2402.17711",
    "authors": [
      "Arbaz Khan",
      "Felipe Lepe",
      "Jesus Vellojin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.17729",
    "title": "Towards Fairness-Aware Adversarial Learning",
    "abstract": "Although adversarial training (AT) has proven effective in enhancing the model's robustness, the recently revealed issue of fairness in robustness has not been well addressed, i.e. the robust accuracy varies significantly among different categories. In this paper, instead of uniformly evaluating the model's average class performance, we delve into the issue of robust fairness, by considering the worst-case distribution across various classes. We propose a novel learning paradigm, named Fairness-Aware Adversarial Learning (FAAL). As a generalization of conventional AT, we re-define the problem of adversarial training as a min-max-max framework, to ensure both robustness and fairness of the trained model. Specifically, by taking advantage of distributional robust optimization, our method aims to find the worst distribution among different categories, and the solution is guaranteed to obtain the upper bound performance with high probability. In particular, FAAL can fine-tune an unfair robust model to be fair within only two epochs, without compromising the overall clean and robust accuracies. Extensive experiments on various image datasets validate the superior performance and efficiency of the proposed FAAL compared to other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2402.17729",
    "authors": [
      "Yanghao Zhang",
      "Tianle Zhang",
      "Ronghui Mu",
      "Xiaowei Huang",
      "Wenjie Ruan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17736",
    "title": "Learning-Based Algorithms for Graph Searching Problems",
    "abstract": "We consider the problem of graph searching with prediction recently introduced by Banerjee et al. (2022). In this problem, an agent, starting at some vertex $r$ has to traverse a (potentially unknown) graph $G$ to find a hidden goal node $g$ while minimizing the total distance travelled. We study a setting in which at any node $v$, the agent receives a noisy estimate of the distance from $v$ to $g$. We design algorithms for this search task on unknown graphs. We establish the first formal guarantees on unknown weighted graphs and provide lower bounds showing that the algorithms we propose have optimal or nearly-optimal dependence on the prediction error. Further, we perform numerical experiments demonstrating that in addition to being robust to adversarial error, our algorithms perform well in typical instances in which the error is stochastic. Finally, we provide alternative simpler performance bounds on the algorithms of Banerjee et al. (2022) for the case of searching on a known graph, and establish new lower bounds for this setting. ",
    "url": "https://arxiv.org/abs/2402.17736",
    "authors": [
      "Adela Frances DePavia",
      "Erasmo Tani",
      "Ali Vakilian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00997",
    "title": "Scaling Whole-Chip QAOA for Higher-Order Ising Spin Glass Models on  Heavy-Hex Graphs",
    "abstract": "We show through numerical simulation that the Quantum Alternating Operator Ansatz (QAOA) for higher-order, random-coefficient, heavy-hex compatible spin glass Ising models has strong parameter concentration across problem sizes from $16$ up to $127$ qubits for $p=1$ up to $p=5$, which allows for straight-forward transfer learning of QAOA angles on instance sizes where exhaustive grid-search is prohibitive even for $p>1$. We use Matrix Product State (MPS) simulation at different bond dimensions to obtain confidence in these results, and we obtain the optimal solutions to these combinatorial optimization problems using CPLEX. In order to assess the ability of current noisy quantum hardware to exploit such parameter concentration, we execute short-depth QAOA circuits (with a CNOT depth of 6 per $p$, resulting in circuits which contain $1420$ two qubit gates for $127$ qubit $p=5$ QAOA) on $100$ higher-order (cubic term) Ising models on IBM quantum superconducting processors with $16, 27, 127$ qubits using QAOA angles learned from a single $16$-qubit instance. We show that (i) the best quantum processors generally find lower energy solutions up to $p=3$ for 27 qubit systems and up to $p=2$ for 127 qubit systems and are overcome by noise at higher values of $p$, (ii) the best quantum processors find mean energies that are about a factor of two off from the noise-free numerical simulation results. Additional insights from our experiments are that large performance differences exist among different quantum processors even of the same generation and that dynamical decoupling significantly improve performance for some, but decrease performance for other quantum processors. Lastly we show $p=1$ QAOA angle mean energy landscapes computed using up to a $414$ qubit quantum computer, showing that the mean QAOA energy landscapes remain very similar as the problem size changes. ",
    "url": "https://arxiv.org/abs/2312.00997",
    "authors": [
      "Elijah Pelofske",
      "Andreas B\u00e4rtschi",
      "Lukasz Cincio",
      "John Golden",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2402.16865",
    "title": "Improve Robustness of Eye Disease Detection by including Learnable  Probabilistic Discrete Latent Variables into Machine Learning Models",
    "abstract": "Ocular diseases, ranging from diabetic retinopathy to glaucoma, present a significant public health challenge due to their prevalence and potential for causing vision impairment. Early and accurate diagnosis is crucial for effective treatment and management.In recent years, deep learning models have emerged as powerful tools for analysing medical images, including ocular imaging . However, challenges persist in model interpretability and uncertainty estimation, which are critical for clinical decision-making. This study introduces a novel application of GFlowOut, leveraging the probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over dropout masks, for the classification and analysis of ocular diseases using eye fundus images. We develop a robust and generalizable method that utilizes GFlowOut integrated with ResNet18 and ViT models as backbone in identifying various ocular conditions. This study employs a unique set of dropout masks - none, random, bottomup, and topdown - to enhance model performance in analyzing ocular images. Our results demonstrate that the bottomup GFlowOut mask significantly improves accuracy, outperforming the traditional dropout approach. ",
    "url": "https://arxiv.org/abs/2402.16865",
    "authors": [
      "Anirudh Prabhakaran",
      "YeKun Xiao",
      "Ching-Yu Cheng",
      "Dianbo Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17040",
    "title": "Robust Radiotherapy Planning with Spatially Based Uncertainty Sets",
    "abstract": "Radiotherapy treatment planning is a challenging large-scale optimization problem plagued by uncertainty. Following the robust optimization methodology, we propose a novel, spatially based uncertainty set for robust modeling of radiotherapy planning, producing solutions that are immune to unexpected changes in biological conditions. Our proposed uncertainty set realistically captures biological radiosensitivity patterns that are observed using recent advances in imaging, while its parameters can be personalized for individual patients. We exploit the structure of this set to devise a compact reformulation of the robust model. We develop a row-generation scheme to solve real, large-scale instances of the robust model. This method is then extended to a relaxation-based scheme for enforcing challenging, yet clinically important, dose-volume cardinality constraints. The computational performance of our algorithms, as well as the quality and robustness of the computed treatment plans, are demonstrated on simulated and real imaging data. Based on accepted performance measures, such as minimal target dose and homogeneity, these examples demonstrate that the spatially robust model achieves almost the same performance as the nominal model in the nominal scenario, and otherwise, the spatial model outperforms both the nominal and the box-uncertainty models. ",
    "url": "https://arxiv.org/abs/2402.17040",
    "authors": [
      "Noam Goldberg",
      "Mark P. Langer",
      "Shimrit Shtern"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2402.17087",
    "title": "A Note on Bayesian Networks with Latent Root Variables",
    "abstract": "We characterise the likelihood function computed from a Bayesian network with latent variables as root nodes. We show that the marginal distribution over the remaining, manifest, variables also factorises as a Bayesian network, which we call empirical. A dataset of observations of the manifest variables allows us to quantify the parameters of the empirical Bayesian net. We prove that (i) the likelihood of such a dataset from the original Bayesian network is dominated by the global maximum of the likelihood from the empirical one; and that (ii) such a maximum is attained if and only if the parameters of the Bayesian network are consistent with those of the empirical model. ",
    "url": "https://arxiv.org/abs/2402.17087",
    "authors": [
      "Marco Zaffalon",
      "Alessandro Antonucci"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17105",
    "title": "Minimum length word-representants of graph products",
    "abstract": "A graph $G = (V, E)$ is said to be word-representable if a word $w$ can be formed using the letters of the alphabet $V$ such that for every pair of vertices $x$ and $y$, $xy \\in E$ if and only if $x$ and $y$ alternate in $w$. Gaetz and Ji have recently introduced the notion of minimum length word-representants for word-representable graphs. They have also determined the minimum possible length of the word-representants for certain classes of graphs, such as trees and cycles. It is know that Cartesian and Rooted products preserve word-representability. Moreover, Broere constructed a uniform word representing the Cartesian product of $G$ and $K_n$ using occurrence based functions. In this paper, we study the minimum length of word-representants for Cartesian and Rooted products using morphism and occurrence based function, respectively. Also, we solve an open problem posed by Broere in his master thesis. This problem asks to construct a word for the Cartesian product of two arbitrary word-representable graphs. ",
    "url": "https://arxiv.org/abs/2402.17105",
    "authors": [
      "Eshwar Srinivasan",
      "Ramesh Hariharasubramanian"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.17148",
    "title": "Time series generation for option pricing on quantum computers using  tensor network",
    "abstract": "Finance, especially option pricing, is a promising industrial field that might benefit from quantum computing. While quantum algorithms for option pricing have been proposed, it is desired to devise more efficient implementations of costly operations in the algorithms, one of which is preparing a quantum state that encodes a probability distribution of the underlying asset price. In particular, in pricing a path-dependent option, we need to generate a state encoding a joint distribution of the underlying asset price at multiple time points, which is more demanding. To address these issues, we propose a novel approach using Matrix Product State (MPS) as a generative model for time series generation. To validate our approach, taking the Heston model as a target, we conduct numerical experiments to generate time series in the model. Our findings demonstrate the capability of the MPS model to generate paths in the Heston model, highlighting its potential for path-dependent option pricing on quantum computers. ",
    "url": "https://arxiv.org/abs/2402.17148",
    "authors": [
      "Nozomu Kobayashi",
      "Yoshiyuki Suimon",
      "Koichi Miyamoto"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2402.17187",
    "title": "PE-MVCNet: Multi-view and Cross-modal Fusion Network for Pulmonary  Embolism Prediction",
    "abstract": "The early detection of a pulmonary embolism (PE) is critical for enhancing patient survival rates. Both image-based and non-image-based features are of utmost importance in medical classification tasks. In a clinical setting, physicians tend to rely on the contextual information provided by Electronic Medical Records (EMR) to interpret medical imaging. However, very few models effectively integrate clinical information with imaging data. To address this shortcoming, we suggest a multimodal fusion methodology, termed PE-MVCNet, which capitalizes on Computed Tomography Pulmonary Angiography imaging and EMR data. This method comprises the Image-only module with an integrated multi-view block, the EMR-only module, and the Cross-modal Attention Fusion (CMAF) module. These modules cooperate to extract comprehensive features that subsequently generate predictions for PE. We conducted experiments using the publicly accessible Stanford University Medical Center dataset, achieving an AUROC of 94.1%, an accuracy rate of 90.2%, and an F1 score of 90.6%. Our proposed model outperforms existing methodologies, corroborating that our multimodal fusion model excels compared to models that use a single data modality. ",
    "url": "https://arxiv.org/abs/2402.17187",
    "authors": [
      "Zhaoxin Guo",
      "Zhipeng Wang",
      "Ruiquan Ge",
      "Jianxun Yu",
      "Feiwei Qin",
      "Yuan Tian",
      "Yuqing Peng",
      "Yonghong Li",
      "Changmiao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17196",
    "title": "Prediction of the SYM-H Index Using a Bayesian Deep Learning Method with  Uncertainty Quantification",
    "abstract": "We propose a novel deep learning framework, named SYMHnet, which employs a graph neural network and a bidirectional long short-term memory network to cooperatively learn patterns from solar wind and interplanetary magnetic field parameters for short-term forecasts of the SYM-H index based on 1-minute and 5-minute resolution data. SYMHnet takes, as input, the time series of the parameters' values provided by NASA's Space Science Data Coordinated Archive and predicts, as output, the SYM-H index value at time point t + w hours for a given time point t where w is 1 or 2. By incorporating Bayesian inference into the learning framework, SYMHnet can quantify both aleatoric (data) uncertainty and epistemic (model) uncertainty when predicting future SYM-H indices. Experimental results show that SYMHnet works well at quiet time and storm time, for both 1-minute and 5-minute resolution data. The results also show that SYMHnet generally performs better than related machine learning methods. For example, SYMHnet achieves a forecast skill score (FSS) of 0.343 compared to the FSS of 0.074 of a recent gradient boosting machine (GBM) method when predicting SYM-H indices (1 hour in advance) in a large storm (SYM-H = -393 nT) using 5-minute resolution data. When predicting the SYM-H indices (2 hours in advance) in the large storm, SYMHnet achieves an FSS of 0.553 compared to the FSS of 0.087 of the GBM method. In addition, SYMHnet can provide results for both data and model uncertainty quantification, whereas the related methods cannot. ",
    "url": "https://arxiv.org/abs/2402.17196",
    "authors": [
      "Yasser Abduallah",
      "Khalid A. Alobaid",
      "Jason T. L. Wang",
      "Haimin Wang",
      "Vania K. Jordanova",
      "Vasyl Yurchyshyn",
      "Huseyin Cavus",
      "Ju Jing"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17317",
    "title": "How we won BraTS 2023 Adult Glioma challenge? Just faking it! Enhanced  Synthetic Data Augmentation and Model Ensemble for brain tumour segmentation",
    "abstract": "Deep Learning is the state-of-the-art technology for segmenting brain tumours. However, this requires a lot of high-quality data, which is difficult to obtain, especially in the medical field. Therefore, our solutions address this problem by using unconventional mechanisms for data augmentation. Generative adversarial networks and registration are used to massively increase the amount of available samples for training three different deep learning models for brain tumour segmentation, the first task of the BraTS2023 challenge. The first model is the standard nnU-Net, the second is the Swin UNETR and the third is the winning solution of the BraTS 2021 Challenge. The entire pipeline is built on the nnU-Net implementation, except for the generation of the synthetic data. The use of convolutional algorithms and transformers is able to fill each other's knowledge gaps. Using the new metric, our best solution achieves the dice results 0.9005, 0.8673, 0.8509 and HD95 14.940, 14.467, 17.699 (whole tumour, tumour core and enhancing tumour) in the validation set. ",
    "url": "https://arxiv.org/abs/2402.17317",
    "authors": [
      "Andr\u00e9 Ferreira",
      "Naida Solak",
      "Jianning Li",
      "Philipp Dammann",
      "Jens Kleesiek",
      "Victor Alves",
      "Jan Egger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17386",
    "title": "A case study of sending graph neural networks back to the test bench for  applications in high-energy particle physics",
    "abstract": "In high-energy particle collisions, the primary collision products usually decay further resulting in tree-like, hierarchical structures with a priori unknown multiplicity. At the stable-particle level all decay products of a collision form permutation invariant sets of final state objects. The analogy to mathematical graphs gives rise to the idea that graph neural networks (GNNs), which naturally resemble these properties, should be best-suited to address many tasks related to high-energy particle physics. In this paper we describe a benchmark test of a typical GNN against neural networks of the well-established deep fully-connected feed-forward architecture. We aim at performing this comparison maximally unbiased in terms of nodes, hidden layers, or trainable parameters of the neural networks under study. As physics case we use the classification of the final state X produced in association with top quark-antiquark pairs in proton-proton collisions at the Large Hadron Collider at CERN, where X stands for a bottom quark-antiquark pair produced either non-resonantly or through the decay of an intermediately produced Z or Higgs boson. ",
    "url": "https://arxiv.org/abs/2402.17386",
    "authors": [
      "Emanuel Pfeffer",
      "Michael Wa\u00dfmer",
      "Yee-Ying Cung",
      "Roger Wolf",
      "Ulrich Husemann"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Artificial Intelligence (cs.AI)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2402.17500",
    "title": "Predicting Instability in Complex Oscillator Networks: Limitations and  Potentials of Network Measures and Machine Learning",
    "abstract": "A central question of network science is how functional properties of systems arise from their structure. For networked dynamical systems, structure is typically quantified with network measures. A functional property that is of theoretical and practical interest for oscillatory systems is the stability of synchrony to localized perturbations. Recently, Graph Neural Networks (GNNs) have been shown to predict this stability successfully; at the same time, network measures have struggled to paint a clear picture. Here we collect 46 relevant network measures and find that no small subset can reliably predict stability. The performance of GNNs can only be matched by combining all network measures and nodewise machine learning. However, unlike GNNs, this approach fails to extrapolate from network ensembles to several real power grid topologies. This suggests that correlations of network measures and function may be misleading, and that GNNs capture the causal relationship between structure and stability substantially better. ",
    "url": "https://arxiv.org/abs/2402.17500",
    "authors": [
      "Christian Nauck",
      "Michael Lindner",
      "Nora Molkenthin",
      "J\u00fcrgen Kurths",
      "Eckehard Sch\u00f6ll",
      "J\u00f6rg Raisch",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.17735",
    "title": "High-Fidelity Neural Phonetic Posteriorgrams",
    "abstract": "A phonetic posteriorgram (PPG) is a time-varying categorical distribution over acoustic units of speech (e.g., phonemes). PPGs are a popular representation in speech generation due to their ability to disentangle pronunciation features from speaker identity, allowing accurate reconstruction of pronunciation (e.g., voice conversion) and coarse-grained pronunciation editing (e.g., foreign accent conversion). In this paper, we demonstrably improve the quality of PPGs to produce a state-of-the-art interpretable PPG representation. We train an off-the-shelf speech synthesizer using our PPG representation and show that high-quality PPGs yield independent control over pitch and pronunciation. We further demonstrate novel uses of PPGs, such as an acoustic pronunciation distance and fine-grained pronunciation control. ",
    "url": "https://arxiv.org/abs/2402.17735",
    "authors": [
      "Cameron Churchwell",
      "Max Morrison",
      "Bryan Pardo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.17750",
    "title": "Scaling on-chip photonic neural processors using arbitrarily  programmable wave propagation",
    "abstract": "On-chip photonic processors for neural networks have potential benefits in both speed and energy efficiency but have not yet reached the scale at which they can outperform electronic processors. The dominant paradigm for designing on-chip photonics is to make networks of relatively bulky discrete components connected by one-dimensional waveguides. A far more compact alternative is to avoid explicitly defining any components and instead sculpt the continuous substrate of the photonic processor to directly perform the computation using waves freely propagating in two dimensions. We propose and demonstrate a device whose refractive index as a function of space, $n(x,z)$, can be rapidly reprogrammed, allowing arbitrary control over the wave propagation in the device. Our device, a 2D-programmable waveguide, combines photoconductive gain with the electro-optic effect to achieve massively parallel modulation of the refractive index of a slab waveguide, with an index modulation depth of $10^{-3}$ and approximately $10^4$ programmable degrees of freedom. We used a prototype device with a functional area of $12\\,\\text{mm}^2$ to perform neural-network inference with up to 49-dimensional input vectors in a single pass, achieving 96% accuracy on vowel classification and 86% accuracy on $7 \\times 7$-pixel MNIST handwritten-digit classification. This is a scale beyond that of previous photonic chips relying on discrete components, illustrating the benefit of the continuous-waves paradigm. In principle, with large enough chip area, the reprogrammability of the device's refractive index distribution enables the reconfigurable realization of any passive, linear photonic circuit or device. This promises the development of more compact and versatile photonic systems for a wide range of applications, including optical processing, smart sensing, spectroscopy, and optical communications. ",
    "url": "https://arxiv.org/abs/2402.17750",
    "authors": [
      "Tatsuhiro Onodera",
      "Martin M. Stein",
      "Benjamin A. Ash",
      "Mandar M. Sohoni",
      "Melissa Bosch",
      "Ryotatsu Yanagimoto",
      "Marc Jankowski",
      "Timothy P. McKenna",
      "Tianyu Wang",
      "Gennady Shvets",
      "Maxim R. Shcherbakov",
      "Logan G. Wright",
      "Peter L. McMahon"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.07324",
    "title": "OneLog: Towards End-to-End Training in Software Log Anomaly Detection",
    "abstract": " Title: OneLog: Towards End-to-End Training in Software Log Anomaly Detection ",
    "url": "https://arxiv.org/abs/2104.07324",
    "authors": [
      "Shayan Hashemi",
      "Mika M\u00e4ntyl\u00e4"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.02473",
    "title": "A Robust Cybersecurity Topic Classification Tool",
    "abstract": " Comments: Improved formatting ",
    "url": "https://arxiv.org/abs/2109.02473",
    "authors": [
      "Elijah Pelofske",
      "Lorie M. Liebrock",
      "Vincent Urias"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.13841",
    "title": "Adaptive Perturbation for Adversarial Attack",
    "abstract": " Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). 18 pages, 7 figures, 14 tables ",
    "url": "https://arxiv.org/abs/2111.13841",
    "authors": [
      "Zheng Yuan",
      "Jie Zhang",
      "Zhaoyan Jiang",
      "Liangliang Li",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15862",
    "title": "Snapture -- A Novel Neural Architecture for Combined Static and Dynamic  Hand Gesture Recognition",
    "abstract": " Comments: In Cognitive Computation(Accepted:30/06/2023, Published:17/07/2023),20 pages,20 figures,4 tables;Please find the published version/info to cite: this https URL;Repositories: this https URL, this https URL;This work was co-funded by Horizon Europe project TERAIS under Grant agreement number 101079338 ",
    "url": "https://arxiv.org/abs/2205.15862",
    "authors": [
      "Hassan Ali",
      "Doreen Jirak",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01723",
    "title": "Model-Checking for First-Order Logic with Disjoint Paths Predicates in  Proper Minor-Closed Graph Classes",
    "abstract": " Comments: An extended abstract of this paper appeared in the Proceedings of the 34th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2023) ",
    "url": "https://arxiv.org/abs/2211.01723",
    "authors": [
      "Petr A. Golovach",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2212.07892",
    "title": "Integrating Multimodal Data for Joint Generative Modeling of Complex  Dynamics",
    "abstract": " Comments: A previous version was published as a workshop paper for the AAAI 2023 Workshop MLmDS under the name \"Multimodal Teacher Forcing for Reconstructing Nonlinear Dynamical Systems\" ",
    "url": "https://arxiv.org/abs/2212.07892",
    "authors": [
      "Manuel Brenner",
      "Florian Hess",
      "Georgia Koppe",
      "Daniel Durstewitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2212.08147",
    "title": "Small-Signal Stability Impacts of Load and Network Dynamics on  Grid-Forming Inverters",
    "abstract": " Comments: Accepted on IEEE 2024 Conference on Innovative Smart Grid Technologies, North America (ISGT NA 2024) ",
    "url": "https://arxiv.org/abs/2212.08147",
    "authors": [
      "Rodrigo Henriquez-Auba",
      "Jose Daniel Lara",
      "Duncan S. Callaway"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.10002",
    "title": "Defending Against Disinformation Attacks in Open-Domain Question  Answering",
    "abstract": " Comments: Accepted to EACL 2024 ",
    "url": "https://arxiv.org/abs/2212.10002",
    "authors": [
      "Orion Weller",
      "Aleem Khan",
      "Nathaniel Weir",
      "Dawn Lawrie",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.02887",
    "title": "UVDoc: Neural Grid-based Document Unwarping",
    "abstract": " Comments: 14 pages, published in SIGGRAPH Asia 2023 Conference Papers ",
    "url": "https://arxiv.org/abs/2302.02887",
    "authors": [
      "Floor Verhoeven",
      "Tanguy Magne",
      "Olga Sorkine-Hornung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2302.05059",
    "title": "Effects of noise on the overparametrization of quantum neural networks",
    "abstract": " Comments: 14 + 6 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2302.05059",
    "authors": [
      "Diego Garc\u00eda-Mart\u00edn",
      "Martin Larocca",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12822",
    "title": "Automatic Prompt Augmentation and Selection with Chain-of-Thought from  Labeled Data",
    "abstract": " Comments: EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2302.12822",
    "authors": [
      "KaShun Shum",
      "Shizhe Diao",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.00968",
    "title": "Dynamic fairness-aware recommendation through multi-agent social choice",
    "abstract": " Title: Dynamic fairness-aware recommendation through multi-agent social choice ",
    "url": "https://arxiv.org/abs/2303.00968",
    "authors": [
      "Amanda Aird",
      "Paresha Farastu",
      "Joshua Sun",
      "Elena \u0160tefancov\u00e1",
      "Cassidy All",
      "Amy Voida",
      "Nicholas Mattei",
      "Robin Burke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08064",
    "title": "Online Neural Path Guiding with Normalized Anisotropic Spherical  Gaussians",
    "abstract": " Title: Online Neural Path Guiding with Normalized Anisotropic Spherical  Gaussians ",
    "url": "https://arxiv.org/abs/2303.08064",
    "authors": [
      "Jiawei Huang",
      "Akito Iizuka",
      "Hajime Tanaka",
      "Taku Komura",
      "Yoshifumi Kitamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.14537",
    "title": "Deep Augmentation: Self-Supervised Learning with Transformations in  Activation Space",
    "abstract": " Title: Deep Augmentation: Self-Supervised Learning with Transformations in  Activation Space ",
    "url": "https://arxiv.org/abs/2303.14537",
    "authors": [
      "Rickard Br\u00fcel-Gabrielsson",
      "Tongzhou Wang",
      "Manel Baradad",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16564",
    "title": "Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a  Bayesian Neural Network",
    "abstract": " Comments: We are revising this paper with significant changes ",
    "url": "https://arxiv.org/abs/2303.16564",
    "authors": [
      "Rebecca S Stone",
      "Nishant Ravikumar",
      "Andrew J Bulpitt",
      "David C Hogg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.01899",
    "title": "Cross-Class Feature Augmentation for Class Incremental Learning",
    "abstract": " Title: Cross-Class Feature Augmentation for Class Incremental Learning ",
    "url": "https://arxiv.org/abs/2304.01899",
    "authors": [
      "Taehoon Kim",
      "Jaeyoo Park",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.12501",
    "title": "The cross-sectional stock return predictions via quantum neural network  and tensor network",
    "abstract": " Comments: 19 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2304.12501",
    "authors": [
      "Nozomu Kobayashi",
      "Yoshiyuki Suimon",
      "Koichi Miyamoto",
      "Kosuke Mitarai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2305.07180",
    "title": "Robust Saliency-Aware Distillation for Few-shot Fine-grained Visual  Recognition",
    "abstract": " Comments: Accepted by IEEE Transactions on Multimedia ",
    "url": "https://arxiv.org/abs/2305.07180",
    "authors": [
      "Haiqi Liu",
      "C. L. Philip Chen",
      "Xinrong Gong",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07614",
    "title": "NevIR: Negation in Neural Information Retrieval",
    "abstract": " Comments: Accepted to EACL 2024 ",
    "url": "https://arxiv.org/abs/2305.07614",
    "authors": [
      "Orion Weller",
      "Dawn Lawrie",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12599",
    "title": "Abstract Meaning Representation-Based Logic-Driven Data Augmentation for  Logical Reasoning",
    "abstract": " Comments: The short version (v2) was accepted for oral presentation at the first LLM@IJCAI 2023 non-archival symposium; the full version is under review ",
    "url": "https://arxiv.org/abs/2305.12599",
    "authors": [
      "Qiming Bao",
      "Alex Yuxuan Peng",
      "Zhenyun Deng",
      "Wanjun Zhong",
      "Gael Gendron",
      "Timothy Pistotti",
      "Neset Tan",
      "Nathan Young",
      "Yang Chen",
      "Yonghua Zhu",
      "Paul Denny",
      "Michael Witbrock",
      "Jiamou Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12675",
    "title": "A Frustratingly Simple Decoding Method for Neural Text Generation",
    "abstract": " Comments: LREC-Coling 2024 ",
    "url": "https://arxiv.org/abs/2305.12675",
    "authors": [
      "Haoran Yang",
      "Deng Cai",
      "Huayang Li",
      "Wei Bi",
      "Wai Lam",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15698",
    "title": "Rethinking Diversity in Deep Neural Network Testing",
    "abstract": " Title: Rethinking Diversity in Deep Neural Network Testing ",
    "url": "https://arxiv.org/abs/2305.15698",
    "authors": [
      "Zi Wang",
      "Jihye Choi",
      "Ke Wang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.05812",
    "title": "HRTF upsampling with a generative adversarial network using a gnomonic  equiangular projection",
    "abstract": " Comments: 15 pages, 9 figures, Preprint (Accepted to IEEE/ACM Transactions on Audio, Speech, and Language Processing on the 15 Feb 2024) ",
    "url": "https://arxiv.org/abs/2306.05812",
    "authors": [
      "Aidan O. T. Hogg",
      "Mads Jenkins",
      "He Liu",
      "Isaac Squires",
      "Samuel J. Cooper",
      "Lorenzo Picinali"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.11339",
    "title": "Masking Augmentation for Supervised Learning",
    "abstract": " Comments: 17 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2306.11339",
    "authors": [
      "Byeongho Heo",
      "Taekyung Kim",
      "Sangdoo Yun",
      "Dongyoon Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.00676",
    "title": "Pay Attention to the Atlas: Atlas-Guided Test-Time Adaptation Method for  Robust 3D Medical Image Segmentation",
    "abstract": " Comments: Accepted by MICCAI BTSD-1001AI workshop. (Oral presentation).this https URL ",
    "url": "https://arxiv.org/abs/2307.00676",
    "authors": [
      "Jingjie Guo",
      "Weitong Zhang",
      "Matthew Sinclair",
      "Daniel Rueckert",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.04661",
    "title": "On the power of graph neural networks and the role of the activation  function",
    "abstract": " Title: On the power of graph neural networks and the role of the activation  function ",
    "url": "https://arxiv.org/abs/2307.04661",
    "authors": [
      "Sammy Khalife",
      "Amitabh Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08202",
    "title": "Enhancing Next-Generation Urban Connectivity: Is the Integrated  HAPS-Terrestrial Network a Solution?",
    "abstract": " Title: Enhancing Next-Generation Urban Connectivity: Is the Integrated  HAPS-Terrestrial Network a Solution? ",
    "url": "https://arxiv.org/abs/2307.08202",
    "authors": [
      "Afsoon Alidadi Shamsabadi",
      "Animesh Yadav",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12499",
    "title": "AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion  Models",
    "abstract": " Title: AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion  Models ",
    "url": "https://arxiv.org/abs/2307.12499",
    "authors": [
      "Xuelong Dai",
      "Kaisheng Liang",
      "Bin Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14723",
    "title": "EFLNet: Enhancing Feature Learning for Infrared Small Target Detection",
    "abstract": " Title: EFLNet: Enhancing Feature Learning for Infrared Small Target Detection ",
    "url": "https://arxiv.org/abs/2307.14723",
    "authors": [
      "Bo Yang",
      "Xinyu Zhang",
      "Jian Zhang",
      "Jun Luo",
      "Mingliang Zhou",
      "Yangjun Pi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05254",
    "title": "Data-driven Intra-Autonomous Systems Graph Generator",
    "abstract": " Comments: 14 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2308.05254",
    "authors": [
      "Caio Vinicius Dadauto",
      "Nelson Luis Saldanha da Fonseca",
      "Ricardo da Silva Torres"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.01657",
    "title": "Locally Stationary Graph Processes",
    "abstract": " Title: Locally Stationary Graph Processes ",
    "url": "https://arxiv.org/abs/2309.01657",
    "authors": [
      "Abdullah Canbolat",
      "Elif Vural"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.05388",
    "title": "Robust Single Rotation Averaging Revisited",
    "abstract": " Title: Robust Single Rotation Averaging Revisited ",
    "url": "https://arxiv.org/abs/2309.05388",
    "authors": [
      "Seong Hun Lee",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08532",
    "title": "Connecting Large Language Models with Evolutionary Algorithms Yields  Powerful Prompt Optimizers",
    "abstract": " Comments: International Conference on Learning Representations (ICLR) 2024 ",
    "url": "https://arxiv.org/abs/2309.08532",
    "authors": [
      "Qingyan Guo",
      "Rui Wang",
      "Junliang Guo",
      "Bei Li",
      "Kaitao Song",
      "Xu Tan",
      "Guoqing Liu",
      "Jiang Bian",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.14065",
    "title": "AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation",
    "abstract": " Title: AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation ",
    "url": "https://arxiv.org/abs/2309.14065",
    "authors": [
      "Siqi Du",
      "Weixi Wang",
      "Renzhong Guo",
      "Shengjun Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16595",
    "title": "Can LLMs Effectively Leverage Graph Structural Information through  Prompts, and Why?",
    "abstract": " Title: Can LLMs Effectively Leverage Graph Structural Information through  Prompts, and Why? ",
    "url": "https://arxiv.org/abs/2309.16595",
    "authors": [
      "Jin Huang",
      "Xingjian Zhang",
      "Qiaozhu Mei",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.02875",
    "title": "Approximating Robot Configuration Spaces with few Convex Sets using  Clique Covers of Visibility Graphs",
    "abstract": " Comments: 7 pages, 6 figures, accepted for publication at ICRA 2024 ",
    "url": "https://arxiv.org/abs/2310.02875",
    "authors": [
      "Peter Werner",
      "Alexandre Amice",
      "Tobia Marcucci",
      "Daniela Rus",
      "Russ Tedrake"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2310.04671",
    "title": "Visual Abductive Reasoning Meets Driving Hazard Prediction",
    "abstract": " Comments: Main Paper: 10 pages, Supplementary Materials: 28 pages ",
    "url": "https://arxiv.org/abs/2310.04671",
    "authors": [
      "Korawat Charoenpitaks",
      "Van-Quang Nguyen",
      "Masanori Suganuma",
      "Masahiro Takahashi",
      "Ryoma Niihara",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06823",
    "title": "NECO: NEural Collapse Based Out-of-distribution detection",
    "abstract": " Comments: Accepted to ICLR2024 ",
    "url": "https://arxiv.org/abs/2310.06823",
    "authors": [
      "Mou\u00efn Ben Ammar",
      "Nacim Belkhir",
      "Sebastian Popescu",
      "Antoine Manzanera",
      "Gianni Franchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06958",
    "title": "Comparing the Robustness of Modern No-Reference Image- and Video-Quality  Metrics to Adversarial Attacks",
    "abstract": " Title: Comparing the Robustness of Modern No-Reference Image- and Video-Quality  Metrics to Adversarial Attacks ",
    "url": "https://arxiv.org/abs/2310.06958",
    "authors": [
      "Anastasia Antsiferova",
      "Khaled Abud",
      "Aleksandr Gushchin",
      "Ekaterina Shumitskaya",
      "Sergey Lavrushkin",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.10556",
    "title": "Sample Complexity of Preference-Based Nonparametric Off-Policy  Evaluation with Deep Networks",
    "abstract": " Title: Sample Complexity of Preference-Based Nonparametric Off-Policy  Evaluation with Deep Networks ",
    "url": "https://arxiv.org/abs/2310.10556",
    "authors": [
      "Zihao Li",
      "Xiang Ji",
      "Minshuo Chen",
      "Mengdi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.14901",
    "title": "Series of Hessian-Vector Products for Tractable Saddle-Free Newton  Optimisation of Neural Networks",
    "abstract": " Comments: 37 pages, 10 figures, 5 tables. To appear in TMLR. First two authors' order randomised ",
    "url": "https://arxiv.org/abs/2310.14901",
    "authors": [
      "Elre T. Oldewage",
      "Ross M. Clarke",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18338",
    "title": "Small Language Models Fine-tuned to Coordinate Larger Language Models  improve Complex Reasoning",
    "abstract": " Comments: EMNLP 2023 (Typos corrected) ",
    "url": "https://arxiv.org/abs/2310.18338",
    "authors": [
      "Gurusha Juneja",
      "Subhabrata Dutta",
      "Soumen Chakrabarti",
      "Sunny Manchanda",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19608",
    "title": "On Feynman--Kac training of partial Bayesian neural networks",
    "abstract": " Comments: In AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2310.19608",
    "authors": [
      "Zheng Zhao",
      "Sebastian Mair",
      "Thomas B. Sch\u00f6n",
      "Jens Sj\u00f6lund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19944",
    "title": "Conditional Unscented Autoencoders for Trajectory Prediction",
    "abstract": " Title: Conditional Unscented Autoencoders for Trajectory Prediction ",
    "url": "https://arxiv.org/abs/2310.19944",
    "authors": [
      "Faris Janjo\u0161",
      "Marcel Hallgarten",
      "Anthony Knittel",
      "Maxim Dolgov",
      "Andreas Zell",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20426",
    "title": "Evolutionary Pareto Set Learning with Structure Constraints",
    "abstract": " Title: Evolutionary Pareto Set Learning with Structure Constraints ",
    "url": "https://arxiv.org/abs/2310.20426",
    "authors": [
      "Xi Lin",
      "Xiaoyuan Zhang",
      "Zhiyuan Yang",
      "Qingfu Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.06310",
    "title": "Labor Space: A Unifying Representation of the Labor Market via Large  Language Models",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2311.06310",
    "authors": [
      "Seongwoon Kim",
      "Yong-Yeol Ahn",
      "Jaehyuk Park"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09675",
    "title": "Where Do People Tell Stories Online? Story Detection Across Online  Communities",
    "abstract": " Title: Where Do People Tell Stories Online? Story Detection Across Online  Communities ",
    "url": "https://arxiv.org/abs/2311.09675",
    "authors": [
      "Maria Antoniak",
      "Joel Mire",
      "Maarten Sap",
      "Elliott Ash",
      "Andrew Piper"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.10801",
    "title": "Reinforcement Learning with Maskable Stock Representation for Portfolio  Management in Customizable Stock Pools",
    "abstract": " Title: Reinforcement Learning with Maskable Stock Representation for Portfolio  Management in Customizable Stock Pools ",
    "url": "https://arxiv.org/abs/2311.10801",
    "authors": [
      "Wentao Zhang",
      "Yilei Zhao",
      "Shuo Sun",
      "Jie Ying",
      "Yonggang Xie",
      "Zitao Song",
      "Xinrun Wang",
      "Bo An"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17456",
    "title": "DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with  Iterative Diffusion-Based Refinement",
    "abstract": " Comments: Accepted by CVPR 2024. Codes will be released on this https URL ",
    "url": "https://arxiv.org/abs/2311.17456",
    "authors": [
      "Jiuming Liu",
      "Guangming Wang",
      "Weicai Ye",
      "Chaokang Jiang",
      "Jinru Han",
      "Zhe Liu",
      "Guofeng Zhang",
      "Dalong Du",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.18460",
    "title": "Causal Fairness under Unobserved Confounding: A Neural Sensitivity  Framework",
    "abstract": " Title: Causal Fairness under Unobserved Confounding: A Neural Sensitivity  Framework ",
    "url": "https://arxiv.org/abs/2311.18460",
    "authors": [
      "Maresa Schr\u00f6der",
      "Dennis Frauen",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.05814",
    "title": "Neural Speech Embeddings for Speech Synthesis Based on Deep Generative  Networks",
    "abstract": " Comments: 4 pages ",
    "url": "https://arxiv.org/abs/2312.05814",
    "authors": [
      "Seo-Hyun Lee",
      "Young-Eun Lee",
      "Soowon Kim",
      "Byung-Kwan Ko",
      "Jun-Young Kim",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.08616",
    "title": "A Generalized Neural Diffusion Framework on Graphs",
    "abstract": " Comments: Accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2312.08616",
    "authors": [
      "Yibo Li",
      "Xiao Wang",
      "Hongrui Liu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.11468",
    "title": "Bias-Reduced Neural Networks for Parameter Estimation in Quantitative  MRI",
    "abstract": " Title: Bias-Reduced Neural Networks for Parameter Estimation in Quantitative  MRI ",
    "url": "https://arxiv.org/abs/2312.11468",
    "authors": [
      "Andrew Mao",
      "Sebastian Flassbeck",
      "Jakob Assl\u00e4nder"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12470",
    "title": "Rotated Multi-Scale Interaction Network for Referring Remote Sensing  Image Segmentation",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2312.12470",
    "authors": [
      "Sihan Liu",
      "Yiwei Ma",
      "Xiaoqing Zhang",
      "Haowei Wang",
      "Jiayi Ji",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.03797",
    "title": "Anatomy of Neural Language Models",
    "abstract": " Comments: 36 Pages; 25 Figures; some typos and notation errors are corrected in this version ",
    "url": "https://arxiv.org/abs/2401.03797",
    "authors": [
      "Majd Saleh",
      "St\u00e9phane Paquelet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.08860",
    "title": "Cross-Level Multi-Instance Distillation for Self-Supervised Fine-Grained  Visual Categorization",
    "abstract": " Comments: work in progress ",
    "url": "https://arxiv.org/abs/2401.08860",
    "authors": [
      "Qi Bi",
      "Wei Ji",
      "Jingjun Yi",
      "Haolan Zhan",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.10731",
    "title": "Removal and Selection: Improving RGB-Infrared Object Detection via  Coarse-to-Fine Fusion",
    "abstract": " Comments: 9pages, 7figures ",
    "url": "https://arxiv.org/abs/2401.10731",
    "authors": [
      "Tianyi Zhao",
      "Maoxun Yuan",
      "Xingxing Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.14009",
    "title": "On the Feasibility of Simple Transformer for Dynamic Graph Modeling",
    "abstract": " Comments: accepted by WWW'24 ",
    "url": "https://arxiv.org/abs/2401.14009",
    "authors": [
      "Yuxia Wu",
      "Yuan Fang",
      "Lizi Liao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.15906",
    "title": "Mean Estimation with User-Level Privacy for Spatio-Temporal IoT Datasets",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2401.15906",
    "authors": [
      "V. Arvind Rameshwar",
      "Anshoo Tandon",
      "Prajjwal Gupta",
      "Novoneel Chakraborty",
      "Abhay Sharma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2402.00849",
    "title": "Score-based Causal Representation Learning: Linear and General  Transformations",
    "abstract": " Comments: (updated literature review) Linear transformations: stronger results than our previous paper Score-based Causal Representation Learning with Interventions (arXiv:2301.08230). General transformations: results also appear in our paper General Identifiability and Achievability for Causal Representation Learning (arXiv:2310.15450) accepted to AISTATS 2024 (oral). arXiv admin note: text overlap with arXiv:2310.15450 ",
    "url": "https://arxiv.org/abs/2402.00849",
    "authors": [
      "Burak Var\u0131c\u0131",
      "Emre Acart\u00fcrk",
      "Karthikeyan Shanmugam",
      "Abhishek Kumar",
      "Ali Tajer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.02725",
    "title": "Cybersickness Detection through Head Movement Patterns: A Promising  Approach",
    "abstract": " Comments: 18 pages, 3 Figures, 3 Tables ",
    "url": "https://arxiv.org/abs/2402.02725",
    "authors": [
      "Masoud Salehi",
      "Nikoo Javadpour",
      "Brietta Beisner",
      "Mohammadamin Sanaei",
      "Stephen B. Gilbert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.04249",
    "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming  and Robust Refusal",
    "abstract": " Comments: Website: this https URL ",
    "url": "https://arxiv.org/abs/2402.04249",
    "authors": [
      "Mantas Mazeika",
      "Long Phan",
      "Xuwang Yin",
      "Andy Zou",
      "Zifan Wang",
      "Norman Mu",
      "Elham Sakhaee",
      "Nathaniel Li",
      "Steven Basart",
      "Bo Li",
      "David Forsyth",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07452",
    "title": "TriAug: Out-of-Distribution Detection for Imbalanced Breast Lesion in  Ultrasound",
    "abstract": " Title: TriAug: Out-of-Distribution Detection for Imbalanced Breast Lesion in  Ultrasound ",
    "url": "https://arxiv.org/abs/2402.07452",
    "authors": [
      "Yinyu Ye",
      "Shijing Chen",
      "Dong Ni",
      "Ruobing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11585",
    "title": "PolypNextLSTM: A lightweight and fast polyp video segmentation network  using ConvNext and ConvLSTM",
    "abstract": " Title: PolypNextLSTM: A lightweight and fast polyp video segmentation network  using ConvNext and ConvLSTM ",
    "url": "https://arxiv.org/abs/2402.11585",
    "authors": [
      "Debayan Bhattacharya",
      "Konrad Reuter",
      "Finn Behrendnt",
      "Lennart Maack",
      "Sarah Grube",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11793",
    "title": "Generative Kaleidoscopic Networks",
    "abstract": " Title: Generative Kaleidoscopic Networks ",
    "url": "https://arxiv.org/abs/2402.11793",
    "authors": [
      "Harsh Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.11996",
    "title": "ISCUTE: Instance Segmentation of Cables Using Text Embedding",
    "abstract": " Title: ISCUTE: Instance Segmentation of Cables Using Text Embedding ",
    "url": "https://arxiv.org/abs/2402.11996",
    "authors": [
      "Shir Kozlovsky",
      "Omkar Joglekar",
      "Dotan Di Castro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12026",
    "title": "Acquiring Clean Language Models from Backdoor Poisoned Datasets by  Downscaling Frequency Space",
    "abstract": " Title: Acquiring Clean Language Models from Backdoor Poisoned Datasets by  Downscaling Frequency Space ",
    "url": "https://arxiv.org/abs/2402.12026",
    "authors": [
      "Zongru Wu",
      "Zhuosheng Zhang",
      "Pengzhou Cheng",
      "Gongshen Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.13241",
    "title": "Federated Causal Discovery from Heterogeneous Data",
    "abstract": " Comments: ICLR 2024 ",
    "url": "https://arxiv.org/abs/2402.13241",
    "authors": [
      "Loka Li",
      "Ignavier Ng",
      "Gongxu Luo",
      "Biwei Huang",
      "Guangyi Chen",
      "Tongliang Liu",
      "Bin Gu",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.14392",
    "title": "Reading Relevant Feature from Global Representation Memory for Visual  Object Tracking",
    "abstract": " Comments: 9pages,5 figures, accepted by the Thirty-seventh Conference on Neural Information Processing Systems(Neurips 2023) ",
    "url": "https://arxiv.org/abs/2402.14392",
    "authors": [
      "Xinyu Zhou",
      "Pinxue Guo",
      "Lingyi Hong",
      "Jinglun Li",
      "Wei Zhang",
      "Weifeng Ge",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14611",
    "title": "Overcoming Dimensional Collapse in Self-supervised Contrastive Learning  for Medical Image Segmentation",
    "abstract": " Comments: Accepted at at ISBI-2024 (this https URL). 4 pages, 2 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2402.14611",
    "authors": [
      "Jamshid Hassanpour",
      "Vinkle Srivastav",
      "Didier Mutter",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.15180",
    "title": "Break the Breakout: Reinventing LM Defense Against Jailbreak Attacks  with Self-Refinement",
    "abstract": " Comments: under review ",
    "url": "https://arxiv.org/abs/2402.15180",
    "authors": [
      "Heegyu Kim",
      "Sehyun Yuk",
      "Hyunsouk Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.15183",
    "title": "GraphEdit: Large Language Models for Graph Structure Learning",
    "abstract": " Title: GraphEdit: Large Language Models for Graph Structure Learning ",
    "url": "https://arxiv.org/abs/2402.15183",
    "authors": [
      "Zirui Guo",
      "Lianghao Xia",
      "Yanhua Yu",
      "Yuling Wang",
      "Zixuan Yang",
      "Wei Wei",
      "Liang Pang",
      "Tat-Seng Chua",
      "Chao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15267",
    "title": "A Robust Defense against Adversarial Attacks on Deep Learning-based  Malware Detectors via (De)Randomized Smoothing",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2308.08906 ",
    "url": "https://arxiv.org/abs/2402.15267",
    "authors": [
      "Daniel Gibert",
      "Giulio Zizzo",
      "Quan Le",
      "Jordi Planes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15674",
    "title": "Formally Verified C Code Generation from Hybrid Communicating Sequential  Processes",
    "abstract": " Title: Formally Verified C Code Generation from Hybrid Communicating Sequential  Processes ",
    "url": "https://arxiv.org/abs/2402.15674",
    "authors": [
      "Shuling Wang",
      "Zekun Ji",
      "Bohua Zhan",
      "Xiong Xu",
      "Qiang Gao",
      "Naijun Zhan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.15958",
    "title": "On the dynamics of three-layer neural networks: initial condensation",
    "abstract": " Title: On the dynamics of three-layer neural networks: initial condensation ",
    "url": "https://arxiv.org/abs/2402.15958",
    "authors": [
      "Zheng-An Chen",
      "Tao Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2402.15968",
    "title": "CoDream: Exchanging dreams instead of models for federated aggregation  with heterogeneous models",
    "abstract": " Comments: 16 pages, 12 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2402.15968",
    "authors": [
      "Abhishek Singh",
      "Gauri Gupta",
      "Ritvik Kapila",
      "Yichuan Shi",
      "Alex Dang",
      "Sheshank Shankar",
      "Mohammed Ehab",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.16458",
    "title": "ID-XCB: Data-independent Debiasing for Fair and Accurate  Transformer-based Cyberbullying Detection",
    "abstract": " Title: ID-XCB: Data-independent Debiasing for Fair and Accurate  Transformer-based Cyberbullying Detection ",
    "url": "https://arxiv.org/abs/2402.16458",
    "authors": [
      "Peiling Yi",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.16726",
    "title": "Interpreting Grokked Transformers in Complex Modular Arithmetic",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2402.16726",
    "authors": [
      "Hiroki Furuta",
      "Gouki Minegishi",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.16782",
    "title": "Multiplex measures for higher-order networks",
    "abstract": " Title: Multiplex measures for higher-order networks ",
    "url": "https://arxiv.org/abs/2402.16782",
    "authors": [
      "Quintino Francesco Lotito",
      "Alberto Montresor",
      "Federico Battiston"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.16823",
    "title": "Language Agents as Optimizable Graphs",
    "abstract": " Comments: Project Website: this https URL ; Github Repo: this https URL ; Replace to fix typos ",
    "url": "https://arxiv.org/abs/2402.16823",
    "authors": [
      "Mingchen Zhuge",
      "Wenyi Wang",
      "Louis Kirsch",
      "Francesco Faccio",
      "Dmitrii Khizbullin",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2402.16825",
    "title": "Weighted Monte Carlo augmented spherical Fourier-Bessel convolutional  layers for 3D abdominal organ segmentation",
    "abstract": " Title: Weighted Monte Carlo augmented spherical Fourier-Bessel convolutional  layers for 3D abdominal organ segmentation ",
    "url": "https://arxiv.org/abs/2402.16825",
    "authors": [
      "Wenzhao Zhao",
      "Steffen Albert",
      "Barbara D. Wichtmann",
      "Angelika Maurer",
      "Ulrike Attenberger",
      "Frank G. Z\u00f6llner",
      "J\u00fcrgen Hesser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]