[
  {
    "id": "arXiv:2402.06655",
    "title": "Adversarial Text Purification: A Large Language Model Approach for  Defense",
    "abstract": "Adversarial purification is a defense mechanism for safeguarding classifiers against adversarial attacks without knowing the type of attacks or training of the classifier. These techniques characterize and eliminate adversarial perturbations from the attacked inputs, aiming to restore purified samples that retain similarity to the initially attacked ones and are correctly classified by the classifier. Due to the inherent challenges associated with characterizing noise perturbations for discrete inputs, adversarial text purification has been relatively unexplored. In this paper, we investigate the effectiveness of adversarial purification methods in defending text classifiers. We propose a novel adversarial text purification that harnesses the generative capabilities of Large Language Models (LLMs) to purify adversarial text without the need to explicitly characterize the discrete noise perturbations. We utilize prompt engineering to exploit LLMs for recovering the purified examples for given adversarial examples such that they are semantically similar and correctly classified. Our proposed method demonstrates remarkable performance over various classifiers, improving their accuracy under the attack by over 65% on average. ",
    "url": "https://arxiv.org/abs/2402.06655",
    "authors": [
      "Raha Moraffah",
      "Shubh Khandelwal",
      "Amrita Bhattacharjee",
      "Huan Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06659",
    "title": "Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language  Models",
    "abstract": "Vision-Language Models (VLMs) excel in generating textual responses from visual inputs, yet their versatility raises significant security concerns. This study takes the first step in exposing VLMs' susceptibility to data poisoning attacks that can manipulate responses to innocuous, everyday prompts. We introduce Shadowcast, a stealthy data poisoning attack method where poison samples are visually indistinguishable from benign images with matching texts. Shadowcast demonstrates effectiveness in two attack types. The first is Label Attack, tricking VLMs into misidentifying class labels, such as confusing Donald Trump for Joe Biden. The second is Persuasion Attack, which leverages VLMs' text generation capabilities to craft narratives, such as portraying junk food as health food, through persuasive and seemingly rational descriptions. We show that Shadowcast are highly effective in achieving attacker's intentions using as few as 50 poison samples. Moreover, these poison samples remain effective across various prompts and are transferable across different VLM architectures in the black-box setting. This work reveals how poisoned VLMs can generate convincing yet deceptive misinformation and underscores the importance of data quality for responsible deployments of VLMs. Our code is available at: https://github.com/umd-huang-lab/VLM-Poisoning. ",
    "url": "https://arxiv.org/abs/2402.06659",
    "authors": [
      "Yuancheng Xu",
      "Jiarui Yao",
      "Manli Shu",
      "Yanchao Sun",
      "Zichu Wu",
      "Ning Yu",
      "Tom Goldstein",
      "Furong Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06662",
    "title": "Sign Rank Limitations for Attention-Based Graph Decoders",
    "abstract": "Inner product-based decoders are among the most influential frameworks used to extract meaningful data from latent embeddings. However, such decoders have shown limitations in representation capacity in numerous works within the literature, which have been particularly notable in graph reconstruction problems. In this paper, we provide the first theoretical elucidation of this pervasive phenomenon in graph data, and suggest straightforward modifications to circumvent this issue without deviating from the inner product framework. ",
    "url": "https://arxiv.org/abs/2402.06662",
    "authors": [
      "Su Hyeong Lee",
      "Qingqi Zhang",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06663",
    "title": "Explainable Adversarial Learning Framework on Physical Layer Secret Keys  Combating Malicious Reconfigurable Intelligent Surface",
    "abstract": "The development of reconfigurable intelligent surfaces (RIS) is a double-edged sword to physical layer security (PLS). Whilst a legitimate RIS can yield beneficial impacts including increased channel randomness to enhance physical layer secret key generation (PL-SKG), malicious RIS can poison legitimate channels and crack most of existing PL-SKGs. In this work, we propose an adversarial learning framework between legitimate parties (namely Alice and Bob) to address this Man-in-the-middle malicious RIS (MITM-RIS) eavesdropping. First, the theoretical mutual information gap between legitimate pairs and MITM-RIS is deduced. Then, Alice and Bob leverage generative adversarial networks (GANs) to learn to achieve a common feature surface that does not have mutual information overlap with MITM-RIS. Next, we aid signal processing interpretation of black-box neural networks by using a symbolic explainable AI (xAI) representation. These symbolic terms of dominant neurons aid feature engineering-based validation and future design of PLS common feature space. Simulation results show that our proposed GAN-based and symbolic-based PL-SKGs can achieve high key agreement rates between legitimate users, and is even resistant to MITM-RIS Eve with the knowledge of legitimate feature generation (NNs or formulas). This therefore paves the way to secure wireless communications with untrusted reflective devices in future 6G. ",
    "url": "https://arxiv.org/abs/2402.06663",
    "authors": [
      "Zhuangkun Wei",
      "Wenxiu Hu",
      "Weisi Guo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06665",
    "title": "The Essential Role of Causality in Foundation World Models for Embodied  AI",
    "abstract": "Recent advances in foundation models, especially in large multi-modal models and conversational agents, have ignited interest in the potential of generally capable embodied agents. Such agents would require the ability to perform new tasks in many different real-world environments. However, current foundation models fail to accurately model physical interactions with the real world thus not sufficient for Embodied AI. The study of causality lends itself to the construction of veridical world models, which are crucial for accurately predicting the outcomes of possible interactions. This paper focuses on the prospects of building foundation world models for the upcoming generation of embodied agents and presents a novel viewpoint on the significance of causality within these. We posit that integrating causal considerations is vital to facilitate meaningful physical interactions with the world. Finally, we demystify misconceptions about causality in this context and present our outlook for future research. ",
    "url": "https://arxiv.org/abs/2402.06665",
    "authors": [
      "Tarun Gupta",
      "Wenbo Gong",
      "Chao Ma",
      "Nick Pawlowski",
      "Agrin Hilmkil",
      "Meyer Scetbon",
      "Ade Famoti",
      "Ashley Juan Llorens",
      "Jianfeng Gao",
      "Stefan Bauer",
      "Danica Kragic",
      "Bernhard Sch\u00f6lkopf",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.06674",
    "title": "Understanding Practical Membership Privacy of Deep Learning",
    "abstract": "We apply a state-of-the-art membership inference attack (MIA) to systematically test the practical privacy vulnerability of fine-tuning large image classification models.We focus on understanding the properties of data sets and samples that make them vulnerable to membership inference. In terms of data set properties, we find a strong power law dependence between the number of examples per class in the data and the MIA vulnerability, as measured by true positive rate of the attack at a low false positive rate. For an individual sample, large gradients at the end of training are strongly correlated with MIA vulnerability. ",
    "url": "https://arxiv.org/abs/2402.06674",
    "authors": [
      "Marlon Tobaben",
      "Gauri Pradhan",
      "Yuan He",
      "Joonas J\u00e4lk\u00f6",
      "Antti Honkela"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06675",
    "title": "A Masked language model for multi-source EHR trajectories contextual  representation learning",
    "abstract": "Using electronic health records data and machine learning to guide future decisions needs to address challenges, including 1) long/short-term dependencies and 2) interactions between diseases and interventions. Bidirectional transformers have effectively addressed the first challenge. Here we tackled the latter challenge by masking one source (e.g., ICD10 codes) and training the transformer to predict it using other sources (e.g., ATC codes). ",
    "url": "https://arxiv.org/abs/2402.06675",
    "authors": [
      "Ali Amirahmadi",
      "Mattias Ohlsson",
      "Kobra Etminani",
      "Olle Melander",
      "Jonas Bj\u00f6rk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06690",
    "title": "Neural Models for Source Code Synthesis and Completion",
    "abstract": "Natural language (NL) to code suggestion systems assist developers in Integrated Development Environments (IDEs) by translating NL utterances into compilable code snippet. The current approaches mainly involve hard-coded, rule-based systems based on semantic parsing. These systems make heavy use of hand-crafted rules that map patterns in NL or elements in its syntax parse tree to various query constructs and can only work on a limited subset of NL with a restricted NL syntax. These systems are unable to extract semantic information from the coding intents of the developer, and often fail to infer types, names, and the context of the source code to get accurate system-level code suggestions. In this master thesis, we present sequence-to-sequence deep learning models and training paradigms to map NL to general-purpose programming languages that can assist users with suggestions of source code snippets, given a NL intent, and also extend auto-completion functionality of the source code to users while they are writing source code. The developed architecture incorporates contextual awareness into neural models which generate source code tokens directly instead of generating parse trees/abstract meaning representations from the source code and converting them back to source code. The proposed pretraining strategy and the data augmentation techniques improve the performance of the proposed architecture. The proposed architecture has been found to exceed the performance of a neural semantic parser, TranX, based on the BLEU-4 metric by 10.82%. Thereafter, a finer analysis for the parsable code translations from the NL intent for CoNaLA challenge was introduced. The proposed system is bidirectional as it can be also used to generate NL code documentation given source code. Lastly, a RoBERTa masked language model for Python was proposed to extend the developed system for code completion. ",
    "url": "https://arxiv.org/abs/2402.06690",
    "authors": [
      "Mitodru Niyogi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.06695",
    "title": "Integrating LLMs for Explainable Fault Diagnosis in Complex Systems",
    "abstract": "This paper introduces an integrated system designed to enhance the explainability of fault diagnostics in complex systems, such as nuclear power plants, where operator understanding is critical for informed decision-making. By combining a physics-based diagnostic tool with a Large Language Model, we offer a novel solution that not only identifies faults but also provides clear, understandable explanations of their causes and implications. The system's efficacy is demonstrated through application to a molten salt facility, showcasing its ability to elucidate the connections between diagnosed faults and sensor data, answer operator queries, and evaluate historical sensor anomalies. Our approach underscores the importance of merging model-based diagnostics with advanced AI to improve the reliability and transparency of autonomous systems. ",
    "url": "https://arxiv.org/abs/2402.06695",
    "authors": [
      "Akshay J. Dave",
      "Tat Nghia Nguyen",
      "Richard B. Vilim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.06697",
    "title": "Feed-Forward Neural Networks as a Mixed-Integer Program",
    "abstract": "Deep neural networks (DNNs) are widely studied in various applications. A DNN consists of layers of neurons that compute affine combinations, apply nonlinear operations, and produce corresponding activations. The rectified linear unit (ReLU) is a typical nonlinear operator, outputting the max of its input and zero. In scenarios like max pooling, where multiple input values are involved, a fixed-parameter DNN can be modeled as a mixed-integer program (MIP). This formulation, with continuous variables representing unit outputs and binary variables for ReLU activation, finds applications across diverse domains. This study explores the formulation of trained ReLU neurons as MIP and applies MIP models for training neural networks (NNs). Specifically, it investigates interactions between MIP techniques and various NN architectures, including binary DNNs (employing step activation functions) and binarized DNNs (with weights and activations limited to $-1,0,+1$). The research focuses on training and evaluating proposed approaches through experiments on handwritten digit classification models. The comparative study assesses the performance of trained ReLU NNs, shedding light on the effectiveness of MIP formulations in enhancing training processes for NNs. ",
    "url": "https://arxiv.org/abs/2402.06697",
    "authors": [
      "Navid Aftabi",
      "Nima Moradi",
      "Fatemeh Mahroo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.06701",
    "title": "Privacy Profiles for Private Selection",
    "abstract": "Private selection mechanisms (e.g., Report Noisy Max, Sparse Vector) are fundamental primitives of differentially private (DP) data analysis with wide applications to private query release, voting, and hyperparameter tuning. Recent work (Liu and Talwar, 2019; Papernot and Steinke, 2022) has made significant progress in both generalizing private selection mechanisms and tightening their privacy analysis using modern numerical privacy accounting tools, e.g., R\\'enyi DP. But R\\'enyi DP is known to be lossy when $(\\epsilon,\\delta)$-DP is ultimately needed, and there is a trend to close the gap by directly handling privacy profiles, i.e., $\\delta$ as a function of $\\epsilon$ or its equivalent dual form known as $f$-DPs. In this paper, we work out an easy-to-use recipe that bounds the privacy profiles of ReportNoisyMax and PrivateTuning using the privacy profiles of the base algorithms they corral. Numerically, our approach improves over the RDP-based accounting in all regimes of interest and leads to substantial benefits in end-to-end private learning experiments. Our analysis also suggests new distributions, e.g., binomial distribution for randomizing the number of rounds that leads to more substantial improvements in certain regimes. ",
    "url": "https://arxiv.org/abs/2402.06701",
    "authors": [
      "Antti Koskela",
      "Rachel Redberg",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06706",
    "title": "CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with  GNNs",
    "abstract": "Graph Visualization, also known as Graph Drawing, aims to find geometric embeddings of graphs that optimize certain criteria. Stress is a widely used metric; stress is minimized when every pair of nodes is positioned at their shortest path distance. However, stress optimization presents computational challenges due to its inherent complexity and is usually solved using heuristics in practice. We introduce a scalable Graph Neural Network (GNN) based Graph Drawing framework with sub-quadratic runtime that can learn to optimize stress. Inspired by classical stress optimization techniques and force-directed layout algorithms, we create a coarsening hierarchy for the input graph. Beginning at the coarsest level, we iteratively refine and un-coarsen the layout, until we generate an embedding for the original graph. To enhance information propagation within the network, we propose a novel positional rewiring technique based on intermediate node positions. Our empirical evaluation demonstrates that the framework achieves state-of-the-art performance while remaining scalable. ",
    "url": "https://arxiv.org/abs/2402.06706",
    "authors": [
      "Florian Gr\u00f6tschla",
      "Jo\u00ebl Mathys",
      "Robert Veres",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06707",
    "title": "Multi-class real-time crash risk forecasting using convolutional neural  network: Istanbul case study",
    "abstract": "The performance of an artificial neural network (ANN) in forecasting crash risk is shown in this paper. To begin, some traffic and weather data are acquired as raw data. This data is then analyzed, and relevant characteristics are chosen to utilize as input data based on additional tree and Pearson correlation. Furthermore, crash and non-crash time data are separated; then, feature values for crash and non-crash events are written in three four-minute intervals prior to the crash and non-crash events using the average of all available values for that period. The number of non-crash samples was lowered after calculating crash likelihood for each period based on accident labeling. The proposed CNN model is capable of learning from recorded, processed, and categorized input characteristics such as traffic characteristics and meteorological conditions. The goal of this work is to forecast the chance of a real-time crash based on three periods before events. The area under the curve (AUC) for the receiver operating characteristic curve (ROC curve), as well as sensitivity as the true positive rate and specificity as the false positive rate, are shown and compared with three typical machine learning and neural network models. Finally, when it comes to the error value, AUC, sensitivity, and specificity parameters as performance variables, the executed model outperforms other models. The findings of this research suggest applying the CNN model as a multi-class prediction model for real-time crash risk prediction. Our emphasis is on multi-class prediction, while prior research used this for binary (two-class) categorization like crash and non-crash. ",
    "url": "https://arxiv.org/abs/2402.06707",
    "authors": [
      "Behnaz Alafi",
      "Saeid Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06716",
    "title": "Dynamic Graph Information Bottleneck",
    "abstract": "Dynamic Graphs widely exist in the real world, which carry complicated spatial and temporal feature patterns, challenging their representation learning. Dynamic Graph Neural Networks (DGNNs) have shown impressive predictive abilities by exploiting the intrinsic dynamics. However, DGNNs exhibit limited robustness, prone to adversarial attacks. This paper presents the novel Dynamic Graph Information Bottleneck (DGIB) framework to learn robust and discriminative representations. Leveraged by the Information Bottleneck (IB) principle, we first propose the expected optimal representations should satisfy the Minimal-Sufficient-Consensual (MSC) Condition. To compress redundant as well as conserve meritorious information into latent representation, DGIB iteratively directs and refines the structural and feature information flow passing through graph snapshots. To meet the MSC Condition, we decompose the overall IB objectives into DGIB$_{MS}$ and DGIB$_C$, in which the DGIB$_{MS}$ channel aims to learn the minimal and sufficient representations, with the DGIB$_{MS}$ channel guarantees the predictive consensus. Extensive experiments on real-world and synthetic dynamic graph datasets demonstrate the superior robustness of DGIB against adversarial attacks compared with state-of-the-art baselines in the link prediction task. To the best of our knowledge, DGIB is the first work to learn robust representations of dynamic graphs grounded in the information-theoretic IB principle. ",
    "url": "https://arxiv.org/abs/2402.06716",
    "authors": [
      "Haonan Yuan",
      "Qingyun Sun",
      "Xingcheng Fu",
      "Cheng Ji",
      "Jianxin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06729",
    "title": "Greedy Matchings in Bipartite Graphs with Ordered Vertex Sets",
    "abstract": "We define and study greedy matchings in vertex-ordered bipartite graphs. It is shown that each vertex-ordered bipartite graph has a unique greedy matching. The proof uses (a weak form of) Newman's lemma. The vertex ordering is called a preference relation. Given a vertex-ordered bipartite graph, the goal is to match every vertex of one vertex class but to leave unmatched as many as possible vertices of low preference in the other concept class. We investigate how well greedy algorithms perform in this setting. It is shown that they have optimal performance provided that the vertex-ordering is cleverly chosen. The study of greedy matchings is motivated by problems in learning theory like illustrating or teaching concepts by means of labeled examples. ",
    "url": "https://arxiv.org/abs/2402.06729",
    "authors": [
      "Hans U. Simon"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.06734",
    "title": "Corruption Robust Offline Reinforcement Learning with Human Feedback",
    "abstract": "We study data corruption robustness for reinforcement learning with human feedback (RLHF) in an offline setting. Given an offline dataset of pairs of trajectories along with feedback about human preferences, an $\\varepsilon$-fraction of the pairs is corrupted (e.g., feedback flipped or trajectory features manipulated), capturing an adversarial attack or noisy human preferences. We aim to design algorithms that identify a near-optimal policy from the corrupted data, with provable guarantees. Existing theoretical works have separately studied the settings of corruption robust RL (learning from scalar rewards directly under corruption) and offline RLHF (learning from human feedback without corruption); however, they are inapplicable to our problem of dealing with corrupted data in offline RLHF setting. To this end, we design novel corruption robust offline RLHF methods under various assumptions on the coverage of the data-generating distributions. At a high level, our methodology robustifies an offline RLHF framework by first learning a reward model along with confidence sets and then learning a pessimistic optimal policy over the confidence set. Our key insight is that learning optimal policy can be done by leveraging an offline corruption-robust RL oracle in different ways (e.g., zero-order oracle or first-order oracle), depending on the data coverage assumptions. To our knowledge, ours is the first work that provides provable corruption robust offline RLHF methods. ",
    "url": "https://arxiv.org/abs/2402.06734",
    "authors": [
      "Debmalya Mandal",
      "Andi Nika",
      "Parameswaran Kamalaruban",
      "Adish Singla",
      "Goran Radanovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06737",
    "title": "ExGRG: Explicitly-Generated Relation Graph for Self-Supervised  Representation Learning",
    "abstract": "Self-supervised Learning (SSL) has emerged as a powerful technique in pre-training deep learning models without relying on expensive annotated labels, instead leveraging embedded signals in unlabeled data. While SSL has shown remarkable success in computer vision tasks through intuitive data augmentation, its application to graph-structured data poses challenges due to the semantic-altering and counter-intuitive nature of graph augmentations. Addressing this limitation, this paper introduces a novel non-contrastive SSL approach to Explicitly Generate a compositional Relation Graph (ExGRG) instead of relying solely on the conventional augmentation-based implicit relation graph. ExGRG offers a framework for incorporating prior domain knowledge and online extracted information into the SSL invariance objective, drawing inspiration from the Laplacian Eigenmap and Expectation-Maximization (EM). Employing an EM perspective on SSL, our E-step involves relation graph generation to identify candidates to guide the SSL invariance objective, and M-step updates the model parameters by integrating the derived relational information. Extensive experimentation on diverse node classification datasets demonstrates the superiority of our method over state-of-the-art techniques, affirming ExGRG as an effective adoption of SSL for graph representation learning. ",
    "url": "https://arxiv.org/abs/2402.06737",
    "authors": [
      "Mahdi Naseri",
      "Mahdi Biparva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06751",
    "title": "Low-Rank Learning by Design: the Role of Network Architecture and  Activation Linearity in Gradient Rank Collapse",
    "abstract": "Our understanding of learning dynamics of deep neural networks (DNNs) remains incomplete. Recent research has begun to uncover the mathematical principles underlying these networks, including the phenomenon of \"Neural Collapse\", where linear classifiers within DNNs converge to specific geometrical structures during late-stage training. However, the role of geometric constraints in learning extends beyond this terminal phase. For instance, gradients in fully-connected layers naturally develop a low-rank structure due to the accumulation of rank-one outer products over a training batch. Despite the attention given to methods that exploit this structure for memory saving or regularization, the emergence of low-rank learning as an inherent aspect of certain DNN architectures has been under-explored. In this paper, we conduct a comprehensive study of gradient rank in DNNs, examining how architectural choices and structure of the data effect gradient rank bounds. Our theoretical analysis provides these bounds for training fully-connected, recurrent, and convolutional neural networks. We also demonstrate, both theoretically and empirically, how design choices like activation function linearity, bottleneck layer introduction, convolutional stride, and sequence truncation influence these bounds. Our findings not only contribute to the understanding of learning dynamics in DNNs, but also provide practical guidance for deep learning engineers to make informed design decisions. ",
    "url": "https://arxiv.org/abs/2402.06751",
    "authors": [
      "Bradley T. Baker",
      "Barak A. Pearlmutter",
      "Robyn Miller",
      "Vince D. Calhoun",
      "Sergey M. Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06761",
    "title": "Embedding Compression for Teacher-to-Student Knowledge Transfer",
    "abstract": "Common knowledge distillation methods require the teacher model and the student model to be trained on the same task. However, the usage of embeddings as teachers has also been proposed for different source tasks and target tasks. Prior work that uses embeddings as teachers ignores the fact that the teacher embeddings are likely to contain irrelevant knowledge for the target task. To address this problem, we propose to use an embedding compression module with a trainable teacher transformation to obtain a compact teacher embedding. Results show that adding the embedding compression module improves the classification performance, especially for unsupervised teacher embeddings. Moreover, student models trained with the guidance of embeddings show stronger generalizability. ",
    "url": "https://arxiv.org/abs/2402.06761",
    "authors": [
      "Yiwei Ding",
      "Alexander Lerch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06764",
    "title": "GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph  Alignment via Neighborhood Partitioning and Generative Subgraph Encoding",
    "abstract": "Integrating large language models (LLMs) with knowledge graphs derived from domain-specific data represents an important advancement towards more powerful and factual reasoning. As these models grow more capable, it is crucial to enable them to perform multi-step inferences over real-world knowledge graphs while minimizing hallucination. While large language models excel at conversation and text generation, their ability to reason over domain-specialized graphs of interconnected entities remains limited. For example, can we query a LLM to identify the optimal contact in a professional network for a specific goal, based on relationships and attributes in a private database? The answer is no--such capabilities lie beyond current methods. However, this question underscores a critical technical gap that must be addressed. Many high-value applications in areas such as science, security, and e-commerce rely on proprietary knowledge graphs encoding unique structures, relationships, and logical constraints. We introduce a fine-tuning framework for developing Graph-aligned LAnguage Models (GLaM) that transforms a knowledge graph into an alternate text representation with labeled question-answer pairs. We demonstrate that grounding the models in specific graph-based knowledge expands the models' capacity for structure-based reasoning. Our methodology leverages the large-language model's generative capabilities to create the dataset and proposes an efficient alternate to retrieval-augmented generation styled methods. ",
    "url": "https://arxiv.org/abs/2402.06764",
    "authors": [
      "Stefan Dernbach",
      "Khushbu Agarwal",
      "Alejandro Zuniga",
      "Michael Henry",
      "Sutanay Choudhury"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06766",
    "title": "Evaluation Metrics for Text Data Augmentation in NLP",
    "abstract": "Recent surveys on data augmentation for natural language processing have reported different techniques and advancements in the field. Several frameworks, tools, and repositories promote the implementation of text data augmentation pipelines. However, a lack of evaluation criteria and standards for method comparison due to different tasks, metrics, datasets, architectures, and experimental settings makes comparisons meaningless. Also, a lack of methods unification exists and text data augmentation research would benefit from unified metrics to compare different augmentation methods. Thus, academics and the industry endeavor relevant evaluation metrics for text data augmentation techniques. The contribution of this work is to provide a taxonomy of evaluation metrics for text augmentation methods and serve as a direction for a unified benchmark. The proposed taxonomy organizes categories that include tools for implementation and metrics calculation. Finally, with this study, we intend to present opportunities to explore the unification and standardization of text data augmentation metrics. ",
    "url": "https://arxiv.org/abs/2402.06766",
    "authors": [
      "Marcellus Amadeus",
      "William Alberto Cruz Casta\u00f1eda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06784",
    "title": "Transfer learning with generative models for object detection on limited  datasets",
    "abstract": "The availability of data is limited in some fields, especially for object detection tasks, where it is necessary to have correctly labeled bounding boxes around each object. A notable example of such data scarcity is found in the domain of marine biology, where it is useful to develop methods to automatically detect submarine species for environmental monitoring. To address this data limitation, the state-of-the-art machine learning strategies employ two main approaches. The first involves pretraining models on existing datasets before generalizing to the specific domain of interest. The second strategy is to create synthetic datasets specifically tailored to the target domain using methods like copy-paste techniques or ad-hoc simulators. The first strategy often faces a significant domain shift, while the second demands custom solutions crafted for the specific task. In response to these challenges, here we propose a transfer learning framework that is valid for a generic scenario. In this framework, generated images help to improve the performances of an object detector in a few-real data regime. This is achieved through a diffusion-based generative model that was pretrained on large generic datasets, and is not trained on the task-specific domain. We validate our approach on object detection tasks, specifically focusing on fishes in an underwater environment, and on the more common domain of cars in an urban setting. Our method achieves detection performance comparable to models trained on thousands of images, using only a few hundreds of input data. Our results pave the way for new generative AI-based protocols for machine learning applications in various domains, for instance ranging from geophysics to biology and medicine. ",
    "url": "https://arxiv.org/abs/2402.06784",
    "authors": [
      "Matteo Paiano",
      "Stefano Martina",
      "Carlotta Giannelli",
      "Filippo Caruso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.06787",
    "title": "ForestColl: Efficient Collective Communications on Heterogeneous Network  Fabrics",
    "abstract": "As modern DNN models grow ever larger, collective communications between the accelerators (allreduce, etc.) emerge as a significant performance bottleneck. Designing efficient communication schedules is challenging given today's highly diverse and heterogeneous network fabrics. In this paper, we present ForestColl, a tool that generates efficient schedules for any network topology. ForestColl constructs broadcast/aggregation spanning trees as the communication schedule, achieving theoretically minimum network congestion. Its schedule generation runs in strongly polynomial time and is highly scalable. ForestColl supports any network fabrics, including both switching fabrics and direct connections, as well as any network graph structure. We evaluated ForestColl on multi-cluster AMD MI250 and NVIDIA A100 platforms. ForestColl's schedules achieved up to 52\\% higher performance compared to the vendors' own optimized communication libraries, RCCL and NCCL. ForestColl also outperforms other state-of-the-art schedule generation techniques with both up to 61\\% more efficient generated schedules and orders of magnitude faster schedule generation speed. ",
    "url": "https://arxiv.org/abs/2402.06787",
    "authors": [
      "Liangyu Zhao",
      "Saeed Maleki",
      "Ziyue Yang",
      "Hossein Pourreza",
      "Aashaka Shah",
      "Changho Hwang",
      "Arvind Krishnamurthy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06803",
    "title": "On graphs with well distributed edge density",
    "abstract": "In this paper we introduce a class of graphs which we call average hereditary graphs. Most graphs that occur in the usual graph theory applications belongs to this class of graphs. Many popular types of graphs fall under this class, such as regular graphs, trees and other popular classes of graphs. We prove an upper bound for the chromatic number of average hereditary graphs, and show that this bound is an improvement on previous bounds. This class of graphs is explored further by proving some interesting properties regarding the class of average hereditary graphs. We analyze the computational complexity of deciding if an arbitrary graph is average hereditary. Then an equivalent condition and a polynomial time sufficient condition is provided for a graph to be average hereditary. We then provide a constructions for average hereditary graphs, using which an average hereditary graph can be recursively constructed. We also show that this class of graphs is closed under a binary operation, from this another construction is obtained for average hereditary graphs, and we see some interesting algebraic properties this class of graphs has. We then explore the effect on the complexity of graph 3-coloring problem when the input is restricted to average hereditary graphs. ",
    "url": "https://arxiv.org/abs/2402.06803",
    "authors": [
      "Syed Mujtaba Hassan",
      "Shahid Hussain"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.06805",
    "title": "Event-to-Video Conversion for Overhead Object Detection",
    "abstract": "Collecting overhead imagery using an event camera is desirable due to the energy efficiency of the image sensor compared to standard cameras. However, event cameras complicate downstream image processing, especially for complex tasks such as object detection. In this paper, we investigate the viability of event streams for overhead object detection. We demonstrate that across a number of standard modeling approaches, there is a significant gap in performance between dense event representations and corresponding RGB frames. We establish that this gap is, in part, due to a lack of overlap between the event representations and the pre-training data used to initialize the weights of the object detectors. Then, we apply event-to-video conversion models that convert event streams into gray-scale video to close this gap. We demonstrate that this approach results in a large performance increase, outperforming even event-specific object detection techniques on our overhead target task. These results suggest that better alignment between event representations and existing large pre-trained models may result in greater short-term performance gains compared to end-to-end event-specific architectural improvements. ",
    "url": "https://arxiv.org/abs/2402.06805",
    "authors": [
      "Darryl Hannan",
      "Ragib Arnab",
      "Gavin Parpart",
      "Garrett T. Kenyon",
      "Edward Kim",
      "Yijing Watkins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06808",
    "title": "Explain Variance of Prediction in Variational Time Series Models for  Clinical Deterioration Prediction",
    "abstract": "In healthcare, thanks to many model agnostic methods, explainability of the prediction scores made by deep learning applications has improved. However, we note that for daily or hourly risk of deterioration prediction of in-hospital patients, not only the predicted risk probability score matters, but also the variance of the risk scores play key roles in aiding clinical decision making. In this paper, we propose to use delta's method to approximate variance of prediction deterministically, such that the SHAP method can be adopted to attribute contribution of variance. The prediction variance is estimated by sampling the conditional hidden space in variational models and is propagated to input clinical variables based on Shapley values of the variance game. This approach works with variational time series models such as variational recurrent neural networks and variational transformers. We further argue that variational time series models are perfect fits for achieving a balance between predictive power and explainability through a series of experiments on a public clinical ICU datasets. Since SHAP values are additive, we also postulate that the SHAP importance of clinical variables with respect to prediction variations can guide their frequency of measurements. ",
    "url": "https://arxiv.org/abs/2402.06808",
    "authors": [
      "Jiacheng Liu",
      "Jaideep Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06811",
    "title": "Discipline and Label: A WEIRD Genealogy and Social Theory of Data  Annotation",
    "abstract": "Data annotation remains the sine qua non of machine learning and AI. Recent empirical work on data annotation has begun to highlight the importance of rater diversity for fairness, model performance, and new lines of research have begun to examine the working conditions for data annotation workers, the impacts and role of annotator subjectivity on labels, and the potential psychological harms from aspects of annotation work. This paper outlines a critical genealogy of data annotation; starting with its psychological and perceptual aspects. We draw on similarities with critiques of the rise of computerized lab-based psychological experiments in the 1970's which question whether these experiments permit the generalization of results beyond the laboratory settings within which these results are typically obtained. Do data annotations permit the generalization of results beyond the settings, or locations, in which they were obtained? Psychology is overly reliant on participants from Western, Educated, Industrialized, Rich, and Democratic societies (WEIRD). Many of the people who work as data annotation platform workers, however, are not from WEIRD countries; most data annotation workers are based in Global South countries. Social categorizations and classifications from WEIRD countries are imposed on non-WEIRD annotators through instructions and tasks, and through them, on data, which is then used to train or evaluate AI models in WEIRD countries. We synthesize evidence from several recent lines of research and argue that data annotation is a form of automated social categorization that risks entrenching outdated and static social categories that are in reality dynamic and changing. We propose a framework for understanding the interplay of the global social conditions of data annotation with the subjective phenomenological experience of data annotation work. ",
    "url": "https://arxiv.org/abs/2402.06811",
    "authors": [
      "Andrew Smart",
      "Ding Wang",
      "Ellis Monk",
      "Mark D\u00edaz",
      "Atoosa Kasirzadeh",
      "Erin Van Liemt",
      "Sonja Schmer-Galunder"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06812",
    "title": "A Kalman Filter Based Framework for Monitoring the Performance of  In-Hospital Mortality Prediction Models Over Time",
    "abstract": "Unlike in a clinical trial, where researchers get to determine the least number of positive and negative samples required, or in a machine learning study where the size and the class distribution of the validation set is static and known, in a real-world scenario, there is little control over the size and distribution of incoming patients. As a result, when measured during different time periods, evaluation metrics like Area under the Receiver Operating Curve (AUCROC) and Area Under the Precision-Recall Curve(AUCPR) may not be directly comparable. Therefore, in this study, for binary classifiers running in a long time period, we proposed to adjust these performance metrics for sample size and class distribution, so that a fair comparison can be made between two time periods. Note that the number of samples and the class distribution, namely the ratio of positive samples, are two robustness factors which affect the variance of AUCROC. To better estimate the mean of performance metrics and understand the change of performance over time, we propose a Kalman filter based framework with extrapolated variance adjusted for the total number of samples and the number of positive samples during different time periods. The efficacy of this method is demonstrated first on a synthetic dataset and then retrospectively applied to a 2-days ahead in-hospital mortality prediction model for COVID-19 patients during 2021 and 2022. Further, we conclude that our prediction model is not significantly affected by the evolution of the disease, improved treatments and changes in hospital operational plans. ",
    "url": "https://arxiv.org/abs/2402.06812",
    "authors": [
      "Jiacheng Liu",
      "Lisa Kirkland",
      "Jaideep Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06826",
    "title": "Neural Rendering based Urban Scene Reconstruction for Autonomous Driving",
    "abstract": "Dense 3D reconstruction has many applications in automated driving including automated annotation validation, multimodal data augmentation, providing ground truth annotations for systems lacking LiDAR, as well as enhancing auto-labeling accuracy. LiDAR provides highly accurate but sparse depth, whereas camera images enable estimation of dense depth but noisy particularly at long ranges. In this paper, we harness the strengths of both sensors and propose a multimodal 3D scene reconstruction using a framework combining neural implicit surfaces and radiance fields. In particular, our method estimates dense and accurate 3D structures and creates an implicit map representation based on signed distance fields, which can be further rendered into RGB images, and depth maps. A mesh can be extracted from the learned signed distance field and culled based on occlusion. Dynamic objects are efficiently filtered on the fly during sampling using 3D object detection models. We demonstrate qualitative and quantitative results on challenging automotive scenes. ",
    "url": "https://arxiv.org/abs/2402.06826",
    "authors": [
      "Shihao Shen",
      "Louis Kerofsky",
      "Varun Ravi Kumar",
      "Senthil Yogamani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.06827",
    "title": "RAMP: Boosting Adversarial Robustness Against Multiple $l_p$  Perturbations",
    "abstract": "There is considerable work on improving robustness against adversarial attacks bounded by a single $l_p$ norm using adversarial training (AT). However, the multiple-norm robustness (union accuracy) of AT models is still low. We observe that simultaneously obtaining good union and clean accuracy is hard since there are tradeoffs between robustness against multiple $l_p$ perturbations, and accuracy/robustness/efficiency. By analyzing the tradeoffs from the lens of distribution shifts, we identify the key tradeoff pair among $l_p$ attacks to boost efficiency and design a logit pairing loss to improve the union accuracy. Next, we connect natural training with AT via gradient projection, to find and incorporate useful information from natural training into AT, which moderates the accuracy/robustness tradeoff. Combining our contributions, we propose a framework called \\textbf{RAMP}, to boost the robustness against multiple $l_p$ perturbations. We show \\textbf{RAMP} can be easily adapted for both robust fine-tuning and full AT. For robust fine-tuning, \\textbf{RAMP} obtains a union accuracy up to $53.5\\%$ on CIFAR-10, and $29.7\\%$ on ImageNet. For training from scratch, \\textbf{RAMP} achieves SOTA union accuracy of $44.6\\%$ and relatively good clean accuracy of $81.2\\%$ on ResNet-18 against AutoAttack on CIFAR-10. ",
    "url": "https://arxiv.org/abs/2402.06827",
    "authors": [
      "Enyi Jiang",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06846",
    "title": "System-level Analysis of Adversarial Attacks and Defenses on  Intelligence in O-RAN based Cellular Networks",
    "abstract": "While the open architecture, open interfaces, and integration of intelligence within Open Radio Access Network technology hold the promise of transforming 5G and 6G networks, they also introduce cybersecurity vulnerabilities that hinder its widespread adoption. In this paper, we conduct a thorough system-level investigation of cyber threats, with a specific focus on machine learning (ML) intelligence components known as xApps within the O-RAN's near-real-time RAN Intelligent Controller (near-RT RIC) platform. Our study begins by developing a malicious xApp designed to execute adversarial attacks on two types of test data - spectrograms and key performance metrics (KPMs), stored in the RIC database within the near-RT RIC. To mitigate these threats, we utilize a distillation technique that involves training a teacher model at a high softmax temperature and transferring its knowledge to a student model trained at a lower softmax temperature, which is deployed as the robust ML model within xApp. We prototype an over-the-air LTE/5G O-RAN testbed to assess the impact of these attacks and the effectiveness of the distillation defense technique by leveraging an ML-based Interference Classification (InterClass) xApp as an example. We examine two versions of InterClass xApp under distinct scenarios, one based on Convolutional Neural Networks (CNNs) and another based on Deep Neural Networks (DNNs) using spectrograms and KPMs as input data respectively. Our findings reveal up to 100% and 96.3% degradation in the accuracy of both the CNN and DNN models respectively resulting in a significant decline in network performance under considered adversarial attacks. Under the strict latency constraints of the near-RT RIC closed control loop, our analysis shows that the distillation technique outperforms classical adversarial training by achieving an accuracy of up to 98.3% for mitigating such attacks. ",
    "url": "https://arxiv.org/abs/2402.06846",
    "authors": [
      "Azuka Chiejina",
      "Brian Kim",
      "Kaushik Chowhdury",
      "Vijay K. Shah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.06854",
    "title": "Gyroscope-Assisted Motion Deblurring Network",
    "abstract": "Image research has shown substantial attention in deblurring networks in recent years. Yet, their practical usage in real-world deblurring, especially motion blur, remains limited due to the lack of pixel-aligned training triplets (background, blurred image, and blur heat map) and restricted information inherent in blurred images. This paper presents a simple yet efficient framework to synthetic and restore motion blur images using Inertial Measurement Unit (IMU) data. Notably, the framework includes a strategy for training triplet generation, and a Gyroscope-Aided Motion Deblurring (GAMD) network for blurred image restoration. The rationale is that through harnessing IMU data, we can determine the transformation of the camera pose during the image exposure phase, facilitating the deduction of the motion trajectory (aka. blur trajectory) for each point inside the three-dimensional space. Thus, the synthetic triplets using our strategy are inherently close to natural motion blur, strictly pixel-aligned, and mass-producible. Through comprehensive experiments, we demonstrate the advantages of the proposed framework: only two-pixel errors between our synthetic and real-world blur trajectories, a marked improvement (around 33.17%) of the state-of-the-art deblurring method MIMO on Peak Signal-to-Noise Ratio (PSNR). ",
    "url": "https://arxiv.org/abs/2402.06854",
    "authors": [
      "Simin Luan",
      "Cong Yang",
      "Zeyd Boukhers",
      "Xue Qin",
      "Dongfeng Cheng",
      "Wei Sui",
      "Zhijun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06855",
    "title": "For Better or For Worse? Learning Minimum Variance Features With Label  Augmentation",
    "abstract": "Data augmentation has been pivotal in successfully training deep learning models on classification tasks over the past decade. An important subclass of data augmentation techniques - which includes both label smoothing and Mixup - involves modifying not only the input data but also the input label during model training. In this work, we analyze the role played by the label augmentation aspect of such methods. We prove that linear models on linearly separable data trained with label augmentation learn only the minimum variance features in the data, while standard training (which includes weight decay) can learn higher variance features. An important consequence of our results is negative: label smoothing and Mixup can be less robust to adversarial perturbations of the training data when compared to standard training. We verify that our theory reflects practice via a range of experiments on synthetic data and image classification benchmarks. ",
    "url": "https://arxiv.org/abs/2402.06855",
    "authors": [
      "Muthu Chidambaram",
      "Rong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06861",
    "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban  Knowledge Graph Construction",
    "abstract": "Urban knowledge graph has recently worked as an emerging building block to distill critical knowledge from multi-sourced urban data for diverse urban application scenarios. Despite its promising benefits, urban knowledge graph construction (UrbanKGC) still heavily relies on manual effort, hindering its potential advancement. This paper presents UrbanKGent, a unified large language model agent framework, for urban knowledge graph construction. Specifically, we first construct the knowledgeable instruction set for UrbanKGC tasks (such as relational triplet extraction and knowledge graph completion) via heterogeneity-aware and geospatial-infused instruction generation. Moreover, we propose a tool-augmented iterative trajectory refinement module to enhance and refine the trajectories distilled from GPT-4. Through hybrid instruction fine-tuning with augmented trajectories on Llama-2-13B, we obtain the UrbanKGC agent, UrbanKGent-13B. We perform a comprehensive evaluation on two real-world datasets using both human and GPT-4 self-evaluation. The experimental results demonstrate that UrbanKGent-13B not only can significantly outperform 21 baselines in UrbanKGC tasks, but also surpass the state-of-the-art LLM, GPT-4, by more than 10\\% with approximately 20 times lower cost. We deploy UrbanKGent-13B to provide online services, which can construct an UrbanKG with thousands of times richer relationships using only one-fifth of the data compared with the existing benchmark. Our data, code, and opensource UrbanKGC agent are available at https://github.com/usail-hkust/UrbanKGent. ",
    "url": "https://arxiv.org/abs/2402.06861",
    "authors": [
      "Yansong Ning",
      "Hao Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06864",
    "title": "Discriminative Adversarial Unlearning",
    "abstract": "We introduce a novel machine unlearning framework founded upon the established principles of the min-max optimization paradigm. We capitalize on the capabilities of strong Membership Inference Attacks (MIA) to facilitate the unlearning of specific samples from a trained model. We consider the scenario of two networks, the attacker $\\mathbf{A}$ and the trained defender $\\mathbf{D}$ pitted against each other in an adversarial objective, wherein the attacker aims at teasing out the information of the data to be unlearned in order to infer membership, and the defender unlearns to defend the network against the attack, whilst preserving its general performance. The algorithm can be trained end-to-end using backpropagation, following the well known iterative min-max approach in updating the attacker and the defender. We additionally incorporate a self-supervised objective effectively addressing the feature space discrepancies between the forget set and the validation set, enhancing unlearning performance. Our proposed algorithm closely approximates the ideal benchmark of retraining from scratch for both random sample forgetting and class-wise forgetting schemes on standard machine-unlearning datasets. Specifically, on the class unlearning scheme, the method demonstrates near-optimal performance and comprehensively overcomes known methods over the random sample forgetting scheme across all metrics and multiple network pruning strategies. ",
    "url": "https://arxiv.org/abs/2402.06864",
    "authors": [
      "Rohan Sharma",
      "Shijie Zhou",
      "Kaiyi Ji",
      "Changyou Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06892",
    "title": "Understanding Test-Time Augmentation",
    "abstract": "Test-Time Augmentation (TTA) is a very powerful heuristic that takes advantage of data augmentation during testing to produce averaged output. Despite the experimental effectiveness of TTA, there is insufficient discussion of its theoretical aspects. In this paper, we aim to give theoretical guarantees for TTA and clarify its behavior. ",
    "url": "https://arxiv.org/abs/2402.06892",
    "authors": [
      "Masanari Kimura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06901",
    "title": "Near-perfect Coverage Manifold Estimation in Cellular Networks via  conditional GAN",
    "abstract": "This paper presents a conditional generative adversarial network (cGAN) that translates base station location (BSL) information of any Region-of-Interest (RoI) to location-dependent coverage probability values within a subset of that region, called the region-of-evaluation (RoE). We train our network utilizing the BSL data of India, the USA, Germany, and Brazil. In comparison to the state-of-the-art convolutional neural networks (CNNs), our model improves the prediction error ($L_1$ difference between the coverage manifold generated by the network under consideration and that generated via simulation) by two orders of magnitude. Moreover, the cGAN-generated coverage manifolds appear to be almost visually indistinguishable from the ground truth. ",
    "url": "https://arxiv.org/abs/2402.06901",
    "authors": [
      "Washim Uddin Mondal",
      "Veni Goyal",
      "Satish V. Ukkusuri",
      "Goutam Das",
      "Di Wang",
      "Mohamed-Slim Alouini",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.06904",
    "title": "Benchmarking Frameworks and Comparative Studies of Controller Area  Network (CAN) Intrusion Detection Systems: A Review",
    "abstract": "The development of intrusion detection systems (IDS) for the in-vehicle Controller Area Network (CAN) bus is one of the main efforts being taken to secure the in-vehicle network against various cyberattacks, which have the potential to cause vehicles to malfunction and result in dangerous accidents. These CAN IDS are evaluated in disparate experimental conditions that vary in terms of the workload used, the features used, the metrics reported, etc., which makes direct comparison difficult. Therefore, there have been several benchmarking frameworks and comparative studies designed to evaluate CAN IDS in similar experimental conditions to understand their relative performance and facilitate the selection of the best CAN IDS for implementation in automotive networks. This work provides a comprehensive survey of CAN IDS benchmarking frameworks and comparative studies in the current literature. A CAN IDS evaluation design space is also proposed in this work, which draws from the wider CAN IDS literature. This is not only expected to serve as a guide for designing CAN IDS evaluation experiments but is also used for categorizing current benchmarking efforts. The surveyed works have been discussed on the basis of the five aspects in the design space-namely IDS type, attack model, evaluation type, workload generation, and evaluation metrics-and recommendations for future work have been identified. ",
    "url": "https://arxiv.org/abs/2402.06904",
    "authors": [
      "Shaila Sharmin",
      "Hafizah Mansor",
      "Andi Fitriah Abdul Kadir",
      "Normaziah A. Aziz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.06907",
    "title": "Investigating Consistency in Query-Based Meeting Summarization: A  Comparative Study of Different Embedding Methods",
    "abstract": "With more and more advanced data analysis techniques emerging, people will expect these techniques to be applied in more complex tasks and solve problems in our daily lives. Text Summarization is one of famous applications in Natural Language Processing (NLP) field. It aims to automatically generate summary with important information based on a given context, which is important when you have to deal with piles of documents. Summarization techniques can help capture key points in a short time and bring convenience in works. One of applicable situation is meeting summarization, especially for important meeting that tend to be long, complicated, multi-topic and multi-person. Therefore, when people want to review specific content from a meeting, it will be hard and time-consuming to find the related spans in the meeting transcript. However, most of previous works focus on doing summarization for newsletters, scientific articles...etc, which have a clear document structure and an official format. For the documents with complex structure like transcripts, we think those works are not quite suitable for meeting summarization. Besides, the consistency of summary is another issue common to be discussed in NLP field. To conquer challenges of meeting summarization, we are inspired by \"QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization\" proposed by Microsoft and we also propose our Locater model designed to extract relevant spans based on given transcript and query, which are then summarized by Summarizer model. Furthermore, we perform a comparative study by applying different word embedding techniques to improve summary consistency. ",
    "url": "https://arxiv.org/abs/2402.06907",
    "authors": [
      "Chen Jia-Chen",
      "Guillem Senabre",
      "Allane Caron"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.06908",
    "title": "Topological Neural Networks: Mitigating the Bottlenecks of Graph Neural  Networks via Higher-Order Interactions",
    "abstract": "The irreducible complexity of natural phenomena has led Graph Neural Networks to be employed as a standard model to perform representation learning tasks on graph-structured data. While their capacity to capture local and global patterns is remarkable, the implications associated with long-range and higher-order dependencies pose considerable challenges to such models. This work starts with a theoretical framework to reveal the impact of network's width, depth, and graph topology on the over-squashing phenomena in message-passing neural networks. Then, the work drifts towards, higher-order interactions and multi-relational inductive biases via Topological Neural Networks. Such models propagate messages through higher-dimensional structures, providing shortcuts or additional routes for information flow. With this construction, the underlying computational graph is no longer coupled with the input graph structure, thus mitigating the aforementioned bottlenecks while accounting also for higher-order interactions. Inspired by Graph Attention Networks, two topological attention networks are proposed: Simplicial and Cell Attention Networks. The rationale behind these architecture is to leverage the extended notion of neighbourhoods provided by the arrangement of groups of nodes within a simplicial or cell complex to design anisotropic aggregations able to measure the importance of the information coming from different regions of the domain. By doing so, they capture dependencies that conventional Graph Neural Networks might miss. Finally, a multi-way communication scheme is introduced with Enhanced Cellular Isomorphism Networks, which augment topological message passing schemes to enable a direct interactions among groups of nodes arranged in ring-like structures. ",
    "url": "https://arxiv.org/abs/2402.06908",
    "authors": [
      "Lorenzo Giusti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06912",
    "title": "Solving Deep Reinforcement Learning Benchmarks with Linear Policy  Networks",
    "abstract": "Although Deep Reinforcement Learning (DRL) methods can learn effective policies for challenging problems such as Atari games and robotics tasks, algorithms are complex and training times are often long. This study investigates how evolution strategies (ES) perform compared to gradient-based deep reinforcement learning methods. We use ES to optimize the weights of a neural network via neuroevolution, performing direct policy search. We benchmark both regular networks and policy networks consisting of a single linear layer from observations to actions; for three classical ES methods and for three gradient-based methods such as PPO. Our results reveal that ES can find effective linear policies for many RL benchmark tasks, in contrast to DRL methods that can only find successful policies using much larger networks, suggesting that current benchmarks are easier to solve than previously assumed. Interestingly, also for higher complexity tasks, ES achieves results comparable to gradient-based DRL algorithms. Furthermore, we find that by directly accessing the memory state of the game, ES are able to find successful policies in Atari, outperforming DQN. While gradient-based methods have dominated the field in recent years, ES offers an alternative that is easy to implement, parallelize, understand, and tune. ",
    "url": "https://arxiv.org/abs/2402.06912",
    "authors": [
      "Annie Wong",
      "Jacob de Nobel",
      "Thomas B\u00e4ck",
      "Aske Plaat",
      "Anna V. Kononova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06932",
    "title": "Learning Attributed Graphlets: Predictive Graph Mining by Graphlets with  Trainable Attribute",
    "abstract": "The graph classification problem has been widely studied; however, achieving an interpretable model with high predictive performance remains a challenging issue. This paper proposes an interpretable classification algorithm for attributed graph data, called LAGRA (Learning Attributed GRAphlets). LAGRA learns importance weights for small attributed subgraphs, called attributed graphlets (AGs), while simultaneously optimizing their attribute vectors. This enables us to obtain a combination of subgraph structures and their attribute vectors that strongly contribute to discriminating different classes. A significant characteristics of LAGRA is that all the subgraph structures in the training dataset can be considered as a candidate structures of AGs. This approach can explore all the potentially important subgraphs exhaustively, but obviously, a naive implementation can require a large amount of computations. To mitigate this issue, we propose an efficient pruning strategy by combining the proximal gradient descent and a graph mining tree search. Our pruning strategy can ensure that the quality of the solution is maintained compared to the result without pruning. We empirically demonstrate that LAGRA has superior or comparable prediction performance to the standard existing algorithms including graph neural networks, while using only a small number of AGs in an interpretable manner. ",
    "url": "https://arxiv.org/abs/2402.06932",
    "authors": [
      "Tajima Shinji",
      "Ren Sugihara",
      "Ryota Kitahara",
      "Masayuki Karasuyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06942",
    "title": "Toward Scalable Generative AI via Mixture of Experts in Mobile Edge  Networks",
    "abstract": "The advancement of generative artificial intelligence (GAI) has driven revolutionary applications like ChatGPT. The widespread of these applications relies on the mixture of experts (MoE), which contains multiple experts and selectively engages them for each task to lower operation costs while maintaining performance. Despite MoE, GAI faces challenges in resource consumption when deployed on user devices. This paper proposes mobile edge networks supported MoE-based GAI. We first review the MoE from traditional AI and GAI perspectives, including structure, principles, and applications. We then propose a framework that transfers subtasks to devices in mobile edge networks, aiding GAI model operation on user devices. We discuss challenges in this process and introduce a deep reinforcement learning based algorithm to select edge devices for subtask execution. Experimental results will show that our framework not only facilitates GAI's deployment on resource-limited devices but also generates higher-quality content compared to methods without edge network support. ",
    "url": "https://arxiv.org/abs/2402.06942",
    "authors": [
      "Jiacheng Wang",
      "Hongyang Du",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Dong In Kim",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.06951",
    "title": "Semantic Object-level Modeling for Robust Visual Camera Relocalization",
    "abstract": "Visual relocalization is crucial for autonomous visual localization and navigation of mobile robotics. Due to the improvement of CNN-based object detection algorithm, the robustness of visual relocalization is greatly enhanced especially in viewpoints where classical methods fail. However, ellipsoids (quadrics) generated by axis-aligned object detection may limit the accuracy of the object-level representation and degenerate the performance of visual relocalization system. In this paper, we propose a novel method of automatic object-level voxel modeling for accurate ellipsoidal representations of objects. As for visual relocalization, we design a better pose optimization strategy for camera pose recovery, to fully utilize the projection characteristics of 2D fitted ellipses and the 3D accurate ellipsoids. All of these modules are entirely intergrated into visual SLAM system. Experimental results show that our semantic object-level mapping and object-based visual relocalization methods significantly enhance the performance of visual relocalization in terms of robustness to new viewpoints. ",
    "url": "https://arxiv.org/abs/2402.06951",
    "authors": [
      "Yifan Zhu",
      "Lingjuan Miao",
      "Haitao Wu",
      "Zhiqiang Zhou",
      "Weiyi Chen",
      "Longwen Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.06955",
    "title": "Training dynamics in Physics-Informed Neural Networks with feature  mapping",
    "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as an iconic machine learning approach for solving Partial Differential Equations (PDEs). Although its variants have achieved significant progress, the empirical success of utilising feature mapping from the wider Implicit Neural Representations studies has been substantially neglected. We investigate the training dynamics of PINNs with a feature mapping layer via the limiting Conjugate Kernel and Neural Tangent Kernel, which sheds light on the convergence and generalisation of the model. We also show the inadequacy of commonly used Fourier-based feature mapping in some scenarios and propose the conditional positive definite Radial Basis Function as a better alternative. The empirical results reveal the efficacy of our method in diverse forward and inverse problem sets. This simple technique can be easily implemented in coordinate input networks and benefits the broad PINNs research. ",
    "url": "https://arxiv.org/abs/2402.06955",
    "authors": [
      "Chengxi Zeng",
      "Tilo Burghardt",
      "Alberto M Gambaruto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2402.06957",
    "title": "Architectural Neural Backdoors from First Principles",
    "abstract": "While previous research backdoored neural networks by changing their parameters, recent work uncovered a more insidious threat: backdoors embedded within the definition of the network's architecture. This involves injecting common architectural components, such as activation functions and pooling layers, to subtly introduce a backdoor behavior that persists even after (full re-)training. However, the full scope and implications of architectural backdoors have remained largely unexplored. Bober-Irizar et al. [2023] introduced the first architectural backdoor; they showed how to create a backdoor for a checkerboard pattern, but never explained how to target an arbitrary trigger pattern of choice. In this work we construct an arbitrary trigger detector which can be used to backdoor an architecture with no human supervision. This leads us to revisit the concept of architecture backdoors and taxonomise them, describing 12 distinct types. To gauge the difficulty of detecting such backdoors, we conducted a user study, revealing that ML developers can only identify suspicious components in common model definitions as backdoors in 37% of cases, while they surprisingly preferred backdoored models in 33% of cases. To contextualize these results, we find that language models outperform humans at the detection of backdoors. Finally, we discuss defenses against architectural backdoors, emphasizing the need for robust and comprehensive strategies to safeguard the integrity of ML systems. ",
    "url": "https://arxiv.org/abs/2402.06957",
    "authors": [
      "Harry Langford",
      "Ilia Shumailov",
      "Yiren Zhao",
      "Robert Mullins",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06959",
    "title": "SpeechCLIP+: Self-supervised multi-task representation learning for  speech via CLIP and speech-image data",
    "abstract": "The recently proposed visually grounded speech model SpeechCLIP is an innovative framework that bridges speech and text through images via CLIP without relying on text transcription. On this basis, this paper introduces two extensions to SpeechCLIP. First, we apply the Continuous Integrate-and-Fire (CIF) module to replace a fixed number of CLS tokens in the cascaded architecture. Second, we propose a new hybrid architecture that merges the cascaded and parallel architectures of SpeechCLIP into a multi-task learning framework. Our experimental evaluation is performed on the Flickr8k and SpokenCOCO datasets. The results show that in the speech keyword extraction task, the CIF-based cascaded SpeechCLIP model outperforms the previous cascaded SpeechCLIP model using a fixed number of CLS tokens. Furthermore, through our hybrid architecture, cascaded task learning boosts the performance of the parallel branch in image-speech retrieval tasks. ",
    "url": "https://arxiv.org/abs/2402.06959",
    "authors": [
      "Hsuan-Fu Wang",
      "Yi-Jen Shih",
      "Heng-Jui Chang",
      "Layne Berry",
      "Puyuan Peng",
      "Hung-yi Lee",
      "Hsin-Min Wang",
      "David Harwath"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.06966",
    "title": "DeepCover: Advancing RNN Test Coverage and Online Error Prediction using  State Machine Extraction",
    "abstract": "Recurrent neural networks (RNNs) have emerged as powerful tools for processing sequential data in various fields, including natural language processing and speech recognition. However, the lack of explainability in RNN models has limited their interpretability, posing challenges in understanding their internal workings. To address this issue, this paper proposes a methodology for extracting a state machine (SM) from an RNN-based model to provide insights into its internal function. The proposed SM extraction algorithm was assessed using four newly proposed metrics: Purity, Richness, Goodness, and Scale. The proposed methodology along with its assessment metrics contribute to increasing explainability in RNN models by providing a clear representation of their internal decision making process through the extracted SM. In addition to improving the explainability of RNNs, the extracted SM can be used to advance testing and and monitoring of the primary RNN-based model. To enhance RNN testing, we introduce six model coverage criteria based on the extracted SM, serving as metrics for evaluating the effectiveness of test suites designed to analyze the primary model. We also propose a tree-based model to predict the error probability of the primary model for each input based on the extracted SM. We evaluated our proposed online error prediction approach using the MNIST dataset and Mini Speech Commands dataset, achieving an area under the curve (AUC) exceeding 80\\% for the receiver operating characteristic (ROC) chart. ",
    "url": "https://arxiv.org/abs/2402.06966",
    "authors": [
      "Pouria Golshanrad",
      "Fathiyeh Faghih"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06976",
    "title": "Neural Rearrangement Planning for Object Retrieval from Confined Spaces  Perceivable by Robot's In-hand RGB-D Sensor",
    "abstract": "Rearrangement planning for object retrieval tasks from confined spaces is a challenging problem, primarily due to the lack of open space for robot motion and limited perception. Several traditional methods exist to solve object retrieval tasks, but they require overhead cameras for perception and a time-consuming exhaustive search to find a solution and often make unrealistic assumptions, such as having identical, simple geometry objects in the environment. This paper presents a neural object retrieval framework that efficiently performs rearrangement planning of unknown, arbitrary objects in confined spaces to retrieve the desired object using a given robot grasp. Our method actively senses the environment with the robot's in-hand camera. It then selects and relocates the non-target objects such that they do not block the robot path homotopy to the target object, thus also aiding an underlying path planner in quickly finding robot motion sequences. Furthermore, we demonstrate our framework in challenging scenarios, including real-world cabinet-like environments with arbitrary household objects. The results show that our framework achieves the best performance among all presented methods and is, on average, two orders of magnitude computationally faster than the best-performing baselines. ",
    "url": "https://arxiv.org/abs/2402.06976",
    "authors": [
      "Hanwen Ren",
      "Ahmed H. Qureshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.06984",
    "title": "Speech motion anomaly detection via cross-modal translation of 4D motion  fields from tagged MRI",
    "abstract": "Understanding the relationship between tongue motion patterns during speech and their resulting speech acoustic outcomes -- i.e., articulatory-acoustic relation -- is of great importance in assessing speech quality and developing innovative treatment and rehabilitative strategies. This is especially important when evaluating and detecting abnormal articulatory features in patients with speech-related disorders. In this work, we aim to develop a framework for detecting speech motion anomalies in conjunction with their corresponding speech acoustics. This is achieved through the use of a deep cross-modal translator trained on data from healthy individuals only, which bridges the gap between 4D motion fields obtained from tagged MRI and 2D spectrograms derived from speech acoustic data. The trained translator is used as an anomaly detector, by measuring the spectrogram reconstruction quality on healthy individuals or patients. In particular, the cross-modal translator is likely to yield limited generalization capabilities on patient data, which includes unseen out-of-distribution patterns and demonstrates subpar performance, when compared with healthy individuals.~A one-class SVM is then used to distinguish the spectrograms of healthy individuals from those of patients. To validate our framework, we collected a total of 39 paired tagged MRI and speech waveforms, consisting of data from 36 healthy individuals and 3 tongue cancer patients. We used both 3D convolutional and transformer-based deep translation models, training them on the healthy training set and then applying them to both the healthy and patient testing sets. Our framework demonstrates a capability to detect abnormal patient data, thereby illustrating its potential in enhancing the understanding of the articulatory-acoustic relation for both healthy individuals and patients. ",
    "url": "https://arxiv.org/abs/2402.06984",
    "authors": [
      "Xiaofeng Liu",
      "Fangxu Xing",
      "Jiachen Zhuo",
      "Maureen Stone",
      "Jerry L. Prince",
      "Georges El Fakhri",
      "Jonghye Woo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.06994",
    "title": "A Change Detection Reality Check",
    "abstract": "In recent years, there has been an explosion of proposed change detection deep learning architectures in the remote sensing literature. These approaches claim to offer state-of the-art performance on different standard benchmark datasets. However, has the field truly made significant progress? In this paper we perform experiments which conclude a simple U-Net segmentation baseline without training tricks or complicated architectural changes is still a top performer for the task of change detection. ",
    "url": "https://arxiv.org/abs/2402.06994",
    "authors": [
      "Isaac Corley",
      "Caleb Robinson",
      "Anthony Ortiz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07007",
    "title": "Nonlinear electro-elastic finite element analysis with neural network  constitutive models",
    "abstract": "In the present work, the applicability of physics-augmented neural network (PANN) constitutive models for complex electro-elastic finite element analysis is demonstrated. For the investigations, PANN models for electro-elastic material behavior at finite deformations are calibrated to different synthetically generated datasets, including an analytical isotropic potential, a homogenised rank-one laminate, and a homogenised metamaterial with a spherical inclusion. Subsequently, boundary value problems inspired by engineering applications of composite electro-elastic materials are considered. Scenarios with large electrically induced deformations and instabilities are particularly challenging and thus necessitate extensive investigations of the PANN constitutive models in the context of finite element analyses. First of all, an excellent prediction quality of the model is required for very general load cases occurring in the simulation. Furthermore, simulation of large deformations and instabilities poses challenges on the stability of the numerical solver, which is closely related to the constitutive model. In all cases studied, the PANN models yield excellent prediction qualities and a stable numerical behavior even in highly nonlinear scenarios. This can be traced back to the PANN models excellent performance in learning both the first and second derivatives of the ground truth electro-elastic potentials, even though it is only calibrated on the first derivatives. Overall, this work demonstrates the applicability of PANN constitutive models for the efficient and robust simulation of engineering applications of composite electro-elastic materials. ",
    "url": "https://arxiv.org/abs/2402.07007",
    "authors": [
      "Dominik K. Klein",
      "Rogelio Ortigosa",
      "Jes\u00fas Mart\u00ednez-Frutos",
      "Oliver Weeger"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2402.07035",
    "title": "Distilling Symbolic Priors for Concept Learning into Neural Networks",
    "abstract": "Humans can learn new concepts from a small number of examples by drawing on their inductive biases. These inductive biases have previously been captured by using Bayesian models defined over symbolic hypothesis spaces. Is it possible to create a neural network that displays the same inductive biases? We show that inductive biases that enable rapid concept learning can be instantiated in artificial neural networks by distilling a prior distribution from a symbolic Bayesian model via meta-learning, an approach for extracting the common structure from a set of tasks. By generating the set of tasks used in meta-learning from the prior distribution of a Bayesian model, we are able to transfer that prior into a neural network. We use this approach to create a neural network with an inductive bias towards concepts expressed as short logical formulas. Analyzing results from previous behavioral experiments in which people learned logical concepts from a few examples, we find that our meta-trained models are highly aligned with human performance. ",
    "url": "https://arxiv.org/abs/2402.07035",
    "authors": [
      "Ioana Marinescu",
      "R. Thomas McCoy",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07049",
    "title": "A Factor Graph Model of Trust for a Collaborative Multi-Agent System",
    "abstract": "In the field of Multi-Agent Systems (MAS), known for their openness, dynamism, and cooperative nature, the ability to trust the resources and services of other agents is crucial. Trust, in this setting, is the reliance and confidence an agent has in the information, behaviors, intentions, truthfulness, and capabilities of others within the system. Our paper introduces a new graphical approach that utilizes factor graphs to represent the interdependent behaviors and trustworthiness among agents. This includes modeling the behavior of robots as a trajectory of actions using a Gaussian process factor graph, which accounts for smoothness, obstacle avoidance, and trust-related factors. Our method for evaluating trust is decentralized and considers key interdependent sub-factors such as proximity safety, consistency, and cooperation. The overall system comprises a network of factor graphs that interact through trust-related factors and employs a Bayesian inference method to dynamically assess trust-based decisions with informed consent. The effectiveness of this method is validated via simulations and empirical tests with autonomous robots navigating unsignalized intersections. ",
    "url": "https://arxiv.org/abs/2402.07049",
    "authors": [
      "Behzad Akbari",
      "Mingfeng Yuan",
      "Hao Wang",
      "Haibin Zhu",
      "Jinjun Shan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07054",
    "title": "HNMblock: Blockchain technology powered Healthcare Network Model for  epidemiological monitoring, medical systems security, and wellness",
    "abstract": "In the ever-evolving healthcare sector, the widespread adoption of Internet of Things and wearable technologies facilitates remote patient monitoring. However, the existing client/server infrastructure poses significant security and privacy challenges, necessitating strict adherence to healthcare data regulations. To combat these issues, a decentralized approach is imperative, and blockchain technology emerges as a compelling solution for strengthening Internet of Things and medical systems security. This paper introduces HNMblock, a model that elevates the realms of epidemiological monitoring, medical system security, and wellness enhancement. By harnessing the transparency and immutability inherent in blockchain, HNMblock empowers real-time, tamper-proof tracking of epidemiological data, enabling swift responses to disease outbreaks. Furthermore, it fortifies the security of medical systems through advanced cryptographic techniques and smart contracts, with a paramount focus on safeguarding patient privacy. HNMblock also fosters personalized healthcare, encouraging patient involvement and data-informed decision-making. The integration of blockchain within the healthcare domain, as exemplified by HNMblock, holds the potential to revolutionize data management, epidemiological surveillance, and wellness, as meticulously explored in this research article. ",
    "url": "https://arxiv.org/abs/2402.07054",
    "authors": [
      "Naresh Kshetri",
      "Rahul Mishra",
      "Mir Mehedi Rahman",
      "Tanja Steigner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.07071",
    "title": "Modeling of Key Quality Indicators for End-to-End Network Management:  Preparing for 5G",
    "abstract": "Thanks to evolving cellular telecommunication networks, providers can deploy a wide range of services. Soon, 5G mobile networks will be available to handle all types of services and applications for vast numbers of users through their mobile equipment. To effectively manage new 5G systems, end-to-end (E2E) performance analysis and optimization will be key features. However, estimating the end-user experience is not an easy task for network operators. The amount of end-user performance information operators can measure from the network is limited, complicating this approach. Here we explore the calculation of service metrics [known as key quality indicators (KQIs)] from classic low-layer measurements and parameters. We propose a complete machine-learning (ML) modeling framework. This system's low-layer metrics can be applied to measure service-layer performance. To assess the approach, we implemented and evaluated the proposed system on a real cellular network testbed. ",
    "url": "https://arxiv.org/abs/2402.07071",
    "authors": [
      "Ana Herrera-Garcia",
      "Sergio Fortes",
      "Eduardo Baena",
      "Jessica Mendoza",
      "Carlos Baena",
      "Raquel Barco"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.07092",
    "title": "Generalizing Conversational Dense Retrieval via LLM-Cognition Data  Augmentation",
    "abstract": "Conversational search utilizes muli-turn natural language contexts to retrieve relevant passages. Existing conversational dense retrieval models mostly view a conversation as a fixed sequence of questions and responses, overlooking the severe data sparsity problem -- that is, users can perform a conversation in various ways, and these alternate conversations are unrecorded. Consequently, they often struggle to generalize to diverse conversations in real-world scenarios. In this work, we propose a framework for generalizing Conversational dense retrieval via LLM-cognition data Augmentation (ConvAug). ConvAug first generates multi-level augmented conversations to capture the diverse nature of conversational contexts. Inspired by human cognition, we devise a cognition-aware process to mitigate the generation of false positives, false negatives, and hallucinations. Moreover, we develop a difficulty-adaptive sample filter that selects challenging samples for complex conversations, thereby giving the model a larger learning space. A contrastive learning objective is then employed to train a better conversational context encoder. Extensive experiments conducted on four public datasets, under both normal and zero-shot settings, demonstrate the effectiveness, generalizability, and applicability of ConvAug. ",
    "url": "https://arxiv.org/abs/2402.07092",
    "authors": [
      "Haonan Chen",
      "Zhicheng Dou",
      "Kelong Mao",
      "Jiongnan Liu",
      "Ziliang Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.07098",
    "title": "Improving Pallet Detection Using Synthetic Data",
    "abstract": "The use of synthetic data in machine learning saves a significant amount of time when implementing an effective object detector. However, there is limited research in this domain. This study aims to improve upon previously applied implementations in the task of instance segmentation of pallets in a warehouse environment. This study proposes using synthetically generated domain-randomised data as well as data generated through Unity to achieve this. This study achieved performance improvements on the stacked and racked pallet categories by 69% and 50% mAP50, respectively when being evaluated on real data. Additionally, it was found that there was a considerable impact on the performance of a model when it was evaluated against images in a darker environment, dropping as low as 3% mAP50 when being evaluated on images with an 80% brightness reduction. This study also created a two-stage detector that used YOLOv8 and SAM, but this proved to have unstable performance. The use of domain-randomised data proved to have negligible performance improvements when compared to the Unity-generated data. ",
    "url": "https://arxiv.org/abs/2402.07098",
    "authors": [
      "Henry Gann",
      "Josiah Bull",
      "Trevor Gee",
      "Mahla Nejati"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07099",
    "title": "Rethinking the Capacity of Graph Neural Networks for Branching Strategy",
    "abstract": "Graph neural networks (GNNs) have been widely used to predict properties and heuristics of mixed-integer linear programs (MILPs) and hence accelerate MILP solvers. This paper investigates the capacity of GNNs to represent strong branching (SB) scores that provide an efficient strategy in the branch-and-bound algorithm. Although message-passing GNN (MP-GNN), as the simplest GNN structure, is frequently employed in the existing literature to learn SB scores, we prove a fundamental limitation in its expressive power -- there exist two MILP instances with different SB scores that cannot be distinguished by any MP-GNN, regardless of the number of parameters. In addition, we establish a universal approximation theorem for another GNN structure called the second-order folklore GNN (2-FGNN). We show that for any data distribution over MILPs, there always exists a 2-FGNN that can approximate the SB score with arbitrarily high accuracy and arbitrarily high probability. A small-scale numerical experiment is conducted to directly validate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2402.07099",
    "authors": [
      "Ziang Chen",
      "Jialin Liu",
      "Xiaohan Chen",
      "Xinshang Wang",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.07102",
    "title": "Future Prediction Can be a Strong Evidence of Good History  Representation in Partially Observable Environments",
    "abstract": "Learning a good history representation is one of the core challenges of reinforcement learning (RL) in partially observable environments. Recent works have shown the advantages of various auxiliary tasks for facilitating representation learning. However, the effectiveness of such auxiliary tasks has not been fully convincing, especially in partially observable environments that require long-term memorization and inference. In this empirical study, we investigate the effectiveness of future prediction for learning the representations of histories, possibly of extensive length, in partially observable environments. We first introduce an approach that decouples the task of learning history representations from policy optimization via future prediction. Then, our main contributions are two-fold: (a) we demonstrate that the performance of reinforcement learning is strongly correlated with the prediction accuracy of future observations in partially observable environments, and (b) our approach can significantly improve the overall end-to-end approach by preventing high-variance noisy signals from reinforcement learning objectives to influence the representation learning. We illustrate our claims on three types of benchmarks that necessitate the ability to process long histories for high returns. ",
    "url": "https://arxiv.org/abs/2402.07102",
    "authors": [
      "Jeongyeol Kwon",
      "Liu Yang",
      "Robert Nowak",
      "Josiah Hanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07119",
    "title": "Two-Stage Multi-task Self-Supervised Learning for Medical Image  Segmentation",
    "abstract": "Medical image segmentation has been significantly advanced by deep learning (DL) techniques, though the data scarcity inherent in medical applications poses a great challenge to DL-based segmentation methods. Self-supervised learning offers a solution by creating auxiliary learning tasks from the available dataset and then leveraging the knowledge acquired from solving auxiliary tasks to help better solve the target segmentation task. Different auxiliary tasks may have different properties and thus can help the target task to different extents. It is desired to leverage their complementary advantages to enhance the overall assistance to the target task. To achieve this, existing methods often adopt a joint training paradigm, which co-solves segmentation and auxiliary tasks by integrating their losses or intermediate gradients. However, direct coupling of losses or intermediate gradients risks undesirable interference because the knowledge acquired from solving each auxiliary task at every training step may not always benefit the target task. To address this issue, we propose a two-stage training approach. In the first stage, the target segmentation task will be independently co-solved with each auxiliary task in both joint training and pre-training modes, with the better model selected via validation performance. In the second stage, the models obtained with respect to each auxiliary task are converted into a single model using an ensemble knowledge distillation method. Our approach allows for making best use of each auxiliary task to create multiple elite segmentation models and then combine them into an even more powerful model. We employed five auxiliary tasks of different proprieties in our approach and applied it to train the U-Net model on an X-ray pneumothorax segmentation dataset. Experimental results demonstrate the superiority of our approach over several existing methods. ",
    "url": "https://arxiv.org/abs/2402.07119",
    "authors": [
      "Binyan Hu",
      "A. K. Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.07132",
    "title": "BAFLineDP: Code Bilinear Attention Fusion Framework for Line-Level  Defect Prediction",
    "abstract": "Software defect prediction aims to identify defect-prone code, aiding developers in optimizing testing resource allocation. Most defect prediction approaches primarily focus on coarse-grained, file-level defect prediction, which fails to provide developers with the precision required to locate defective code. Recently, some researchers have proposed fine-grained, line-level defect prediction methods. However, most of these approaches lack an in-depth consideration of the contextual semantics of code lines and neglect the local interaction information among code lines. To address the above issues, this paper presents a line-level defect prediction method grounded in a code bilinear attention fusion framework (BAFLineDP). This method discerns defective code files and lines by integrating source code line semantics, line-level context, and local interaction information between code lines and line-level context. Through an extensive analysis involving within- and cross-project defect prediction across 9 distinct projects encompassing 32 releases, our results demonstrate that BAFLineDP outperforms current advanced file-level and line-level defect prediction approaches. ",
    "url": "https://arxiv.org/abs/2402.07132",
    "authors": [
      "Shaojian Qiu",
      "Huihao Huang",
      "Jianxiang Luo",
      "Yingjie Kuang",
      "Haoyu Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.07138",
    "title": "Unprecedented Code Change Automation: The Fusion of LLMs and  Transformation by Example",
    "abstract": "Software developers often repeat code changes, known as \"code change patterns\" (CPATs), within and across projects. Automating these CPATs accelerates development, but current Transformation by Example (TBE) techniques are limited by the input examples' quality and quantity, missing variations with different syntax or flow yet semantically similar. Large Language Models (LLMs), trained on vast code datasets, can overcome these limitations by generating semantically equivalent, unseen CPAT variants, enhancing TBE effectiveness. We identified best practices for using LLMs to generate code variants meeting criteria of correctness, usefulness, and applicability. Implementing these in PyCraft, combining static and dynamic analysis with LLMs, we achieved an F-measure of 96.6% in identifying correct variants, expanding inputs by 58x on average, and automating changes to increase target codes by up to 39x. Patches from PyCraft were submitted to projects like microsoft/DeepSpeed and IBM/inFairness, with an 83% acceptance rate, validating our approach's usefulness. ",
    "url": "https://arxiv.org/abs/2402.07138",
    "authors": [
      "Malinda Dilhara",
      "Abhiram Bellur",
      "Timofey Bryksin",
      "Danny Dig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.07139",
    "title": "Towards Robust Car Following Dynamics Modeling via Blackbox Models:  Methodology, Analysis, and Recommendations",
    "abstract": "The selection of the target variable is important while learning parameters of the classical car following models like GIPPS, IDM, etc. There is a vast body of literature on which target variable is optimal for classical car following models, but there is no study that empirically evaluates the selection of optimal target variables for black-box models, such as LSTM, etc. The black-box models, like LSTM and Gaussian Process (GP) are increasingly being used to model car following behavior without wise selection of target variables. The current work tests different target variables, like acceleration, velocity, and headway, for three black-box models, i.e., GP, LSTM, and Kernel Ridge Regression. These models have different objective functions and work in different vector spaces, e.g., GP works in function space, and LSTM works in parameter space. The experiments show that the optimal target variable recommendations for black-box models differ from classical car following models depending on the objective function and the vector space. It is worth mentioning that models and datasets used during evaluation are diverse in nature: the datasets contained both automated and human-driven vehicle trajectories; the black-box models belong to both parametric and non-parametric classes of models. This diversity is important during the analysis of variance, wherein we try to find the interaction between datasets, models, and target variables. It is shown that the models and target variables interact and recommended target variables don't depend on the dataset under consideration. ",
    "url": "https://arxiv.org/abs/2402.07139",
    "authors": [
      "Muhammad Bilal Shahid",
      "Cody Fleming"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07152",
    "title": "Explainable Global Wildfire Prediction Models using Graph Neural  Networks",
    "abstract": "Wildfire prediction has become increasingly crucial due to the escalating impacts of climate change. Traditional CNN-based wildfire prediction models struggle with handling missing oceanic data and addressing the long-range dependencies across distant regions in meteorological data. In this paper, we introduce an innovative Graph Neural Network (GNN)-based model for global wildfire prediction. We propose a hybrid model that combines the spatial prowess of Graph Convolutional Networks (GCNs) with the temporal depth of Long Short-Term Memory (LSTM) networks. Our approach uniquely transforms global climate and wildfire data into a graph representation, addressing challenges such as null oceanic data locations and long-range dependencies inherent in traditional models. Benchmarking against established architectures using an unseen ensemble of JULES-INFERNO simulations, our model demonstrates superior predictive accuracy. Furthermore, we emphasise the model's explainability, unveiling potential wildfire correlation clusters through community detection and elucidating feature importance via Integrated Gradient analysis. Our findings not only advance the methodological domain of wildfire prediction but also underscore the importance of model transparency, offering valuable insights for stakeholders in wildfire management. ",
    "url": "https://arxiv.org/abs/2402.07152",
    "authors": [
      "Dayou Chen",
      "Sibo Cheng",
      "Jinwei Hu",
      "Matthew Kasoar",
      "Rossella Arcucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07153",
    "title": "Error Estimation for Physics-informed Neural Networks Approximating  Semilinear Wave Equations",
    "abstract": "This paper provides rigorous error bounds for physics-informed neural networks approximating the semilinear wave equation. We provide bounds for the generalization and training error in terms of the width of the network's layers and the number of training points for a tanh neural network with two hidden layers. Our main result is a bound of the total error in the $H^1([0,T];L^2(\\Omega))$-norm in terms of the training error and the number of training points, which can be made arbitrarily small under some assumptions. We illustrate our theoretical bounds with numerical experiments. ",
    "url": "https://arxiv.org/abs/2402.07153",
    "authors": [
      "Beatrice Lorenz",
      "Aras Bacho",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07166",
    "title": "Social Evolution of Published Text and The Emergence of Artificial  Intelligence Through Large Language Models and The Problem of Toxicity and  Bias",
    "abstract": "We provide a birds eye view of the rapid developments in AI and Deep Learning that has led to the path-breaking emergence of AI in Large Language Models. The aim of this study is to place all these developments in a pragmatic broader historical social perspective without any exaggerations while at the same time without any pessimism that created the AI winter in the 1970s to 1990s. We also at the same time point out toxicity, bias, memorization, sycophancy, logical inconsistencies, hallucinations that exist just as a warning to the overly optimistic. We note here that just as this emergence of AI seems to occur at a threshold point in the number of neural connections or weights, it has also been observed that human brain and especially the cortex region is nothing special or extraordinary but simply a case of scaled-up version of the primate brain and that even the human intelligence seems like an emergent phenomena of scale. ",
    "url": "https://arxiv.org/abs/2402.07166",
    "authors": [
      "Arifa Khan",
      "P. Saravanan",
      "S.K Venkatesan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07167",
    "title": "Large-Language-Model Empowered Dose Volume Histogram Prediction for  Intensity Modulated Radiotherapy",
    "abstract": "Treatment planning is currently a patient specific, time-consuming, and resource demanding task in radiotherapy. Dose-volume histogram (DVH) prediction plays a critical role in automating this process. The geometric relationship between DVHs in radiotherapy plans and organs-at-risk (OAR) and planning target volume (PTV) has been well established. This study explores the potential of deep learning models for predicting DVHs using images and subsequent human intervention facilitated by a large-language model (LLM) to enhance the planning quality. We propose a pipeline to convert unstructured images to a structured graph consisting of image-patch nodes and dose nodes. A novel Dose Graph Neural Network (DoseGNN) model is developed for predicting DVHs from the structured graph. The proposed DoseGNN is enhanced with the LLM to encode massive knowledge from prescriptions and interactive instructions from clinicians. In this study, we introduced an online human-AI collaboration (OHAC) system as a practical implementation of the concept proposed for the automation of intensity-modulated radiotherapy (IMRT) planning. In comparison to the widely-employed DL models used in radiotherapy, DoseGNN achieved mean square errors that were 80$\\%$, 76$\\%$ and 41.0$\\%$ of those predicted by Swin U-Net Transformer, 3D U-Net CNN and vanilla MLP, respectively. Moreover, the LLM-empowered DoseGNN model facilitates seamless adjustment to treatment plans through interaction with clinicians using natural language. ",
    "url": "https://arxiv.org/abs/2402.07167",
    "authors": [
      "Zehao Dong",
      "Yixin Chen",
      "Hiram Gay",
      "Yao Hao",
      "Geoffrey D. Hugo",
      "Pamela Samson",
      "Tianyu Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07180",
    "title": "MAGNETO: Edge AI for Human Activity Recognition -- Privacy and  Personalization",
    "abstract": "Human activity recognition (HAR) is a well-established field, significantly advanced by modern machine learning (ML) techniques. While companies have successfully integrated HAR into consumer products, they typically rely on a predefined activity set, which limits personalizations at the user level (edge devices). Despite advancements in Incremental Learning for updating models with new data, this often occurs on the Cloud, necessitating regular data transfers between cloud and edge devices, thus leading to data privacy issues. In this paper, we propose MAGNETO, an Edge AI platform that pushes HAR tasks from the Cloud to the Edge. MAGNETO allows incremental human activity learning directly on the Edge devices, without any data exchange with the Cloud. This enables strong privacy guarantees, low processing latency, and a high degree of personalization for users. In particular, we demonstrate MAGNETO in an Android device, validating the whole pipeline from data collection to result visualization. ",
    "url": "https://arxiv.org/abs/2402.07180",
    "authors": [
      "Jingwei Zuo",
      "George Arvanitakis",
      "Mthandazo Ndhlovu",
      "Hakim Hacid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.07183",
    "title": "A Random Ensemble of Encrypted Vision Transformers for Adversarially  Robust Defense",
    "abstract": "Deep neural networks (DNNs) are well known to be vulnerable to adversarial examples (AEs). In previous studies, the use of models encrypted with a secret key was demonstrated to be robust against white-box attacks, but not against black-box ones. In this paper, we propose a novel method using the vision transformer (ViT) that is a random ensemble of encrypted models for enhancing robustness against both white-box and black-box attacks. In addition, a benchmark attack method, called AutoAttack, is applied to models to test adversarial robustness objectively. In experiments, the method was demonstrated to be robust against not only white-box attacks but also black-box ones in an image classification task on the CIFAR-10 and ImageNet datasets. The method was also compared with the state-of-the-art in a standardized benchmark for adversarial robustness, RobustBench, and it was verified to outperform conventional defenses in terms of clean accuracy and robust accuracy. ",
    "url": "https://arxiv.org/abs/2402.07183",
    "authors": [
      "Ryota Iijima",
      "Sayaka Shiota",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07191",
    "title": "GSINA: Improving Subgraph Extraction for Graph Invariant Learning via  Graph Sinkhorn Attention",
    "abstract": "Graph invariant learning (GIL) has been an effective approach to discovering the invariant relationships between graph data and its labels for different graph learning tasks under various distribution shifts. Many recent endeavors of GIL focus on extracting the invariant subgraph from the input graph for prediction as a regularization strategy to improve the generalization performance of graph learning. Despite their success, such methods also have various limitations in obtaining their invariant subgraphs. In this paper, we provide in-depth analyses of the drawbacks of existing works and propose corresponding principles of our invariant subgraph extraction: 1) the sparsity, to filter out the variant features, 2) the softness, for a broader solution space, and 3) the differentiability, for a soundly end-to-end optimization. To meet these principles in one shot, we leverage the Optimal Transport (OT) theory and propose a novel graph attention mechanism called Graph Sinkhorn Attention (GSINA). This novel approach serves as a powerful regularization method for GIL tasks. By GSINA, we are able to obtain meaningful, differentiable invariant subgraphs with controllable sparsity and softness. Moreover, GSINA is a general graph learning framework that could handle GIL tasks of multiple data grain levels. Extensive experiments on both synthetic and real-world datasets validate the superiority of our GSINA, which outperforms the state-of-the-art GIL methods by large margins on both graph-level tasks and node-level tasks. Our code is publicly available at \\url{https://github.com/dingfangyu/GSINA}. ",
    "url": "https://arxiv.org/abs/2402.07191",
    "authors": [
      "Fangyu Ding",
      "Haiyang Wang",
      "Zhixuan Chu",
      "Tianming Li",
      "Zhaoping Hu",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07197",
    "title": "GraphTranslator: Aligning Graph Model to Large Language Model for  Open-ended Tasks",
    "abstract": "Large language models (LLMs) like ChatGPT, exhibit powerful zero-shot and instruction-following capabilities, have catalyzed a revolutionary transformation across diverse research fields of artificial intelligence, especially for open-ended tasks. While the idea is less explored in the graph domain, despite the availability of numerous powerful graph models (GMs), they are restricted to tasks in a pre-defined form. Although several methods applying LLMs to graphs have been proposed, they fail to simultaneously handle the pre-defined and open-ended tasks, with LLM as a node feature enhancer or as a standalone predictor. To break this dilemma, we propose to bridge the pretrained GM and LLM by a Translator, named GraphTranslator, aiming to leverage GM to handle the pre-defined tasks effectively and utilize the extended interface of LLMs to offer various open-ended tasks for GM. To train such Translator, we propose a Producer capable of constructing the graph-text alignment data along node information, neighbor information and model information. By treating the node representation as a type of language, the proposed GraphTranslator empowers an LLM to make predictions based on node representation and language instructions, providing a unified perspective for both pre-defined and open-ended tasks. Extensive results show that the proposed GraphTranslator effectively improves the results of zero-shot node classification. The graph question answering experiments reveal our GraphTranslator potential across a broad spectrum of open-ended applications through language instructions. ",
    "url": "https://arxiv.org/abs/2402.07197",
    "authors": [
      "Mengmei Zhang",
      "Mingwei Sun",
      "Peng Wang",
      "Shen Fan",
      "Yanhu Mo",
      "Xiaoxiao Xu",
      "Hong Liu",
      "Cheng Yang",
      "Chuan Shi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07199",
    "title": "Link-aware link prediction over temporal graph by pattern recognition",
    "abstract": "A temporal graph can be considered as a stream of links, each of which represents an interaction between two nodes at a certain time. On temporal graphs, link prediction is a common task, which aims to answer whether the query link is true or not. To do this task, previous methods usually focus on the learning of representations of the two nodes in the query link. We point out that the learned representation by their models may encode too much information with side effects for link prediction because they have not utilized the information of the query link, i.e., they are link-unaware. Based on this observation, we propose a link-aware model: historical links and the query link are input together into the following model layers to distinguish whether this input implies a reasonable pattern that ends with the query link. During this process, we focus on the modeling of link evolution patterns rather than node representations. Experiments on six datasets show that our model achieves strong performances compared with state-of-the-art baselines, and the results of link prediction are interpretable. The code and datasets are available on the project website: https://github.com/lbq8942/TGACN. ",
    "url": "https://arxiv.org/abs/2402.07199",
    "authors": [
      "Bingqing Liu",
      "Xikun Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07200",
    "title": "Outlier-Aware Training for Low-Bit Quantization of Structural  Re-Parameterized Networks",
    "abstract": "Lightweight design of Convolutional Neural Networks (CNNs) requires co-design efforts in the model architectures and compression techniques. As a novel design paradigm that separates training and inference, a structural re-parameterized (SR) network such as the representative RepVGG revitalizes the simple VGG-like network with a high accuracy comparable to advanced and often more complicated networks. However, the merging process in SR networks introduces outliers into weights, making their distribution distinct from conventional networks and thus heightening difficulties in quantization. To address this, we propose an operator-level improvement for training called Outlier Aware Batch Normalization (OABN). Additionally, to meet the demands of limited bitwidths while upkeeping the inference accuracy, we develop a clustering-based non-uniform quantization framework for Quantization-Aware Training (QAT) named ClusterQAT. Integrating OABN with ClusterQAT, the quantized performance of RepVGG is largely enhanced, particularly when the bitwidth falls below 8. ",
    "url": "https://arxiv.org/abs/2402.07200",
    "authors": [
      "Muqun Niu",
      "Yuan Ren",
      "Boyu Li",
      "Chenchen Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.07207",
    "title": "GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided  Generative Gaussian Splatting",
    "abstract": "We present GALA3D, generative 3D GAussians with LAyout-guided control, for effective compositional text-to-3D generation. We first utilize large language models (LLMs) to generate the initial layout and introduce a layout-guided 3D Gaussian representation for 3D content generation with adaptive geometric constraints. We then propose an object-scene compositional optimization mechanism with conditioned diffusion to collaboratively generate realistic 3D scenes with consistent geometry, texture, scale, and accurate interactions among multiple objects while simultaneously adjusting the coarse layout priors extracted from the LLMs to align with the generated scene. Experiments show that GALA3D is a user-friendly, end-to-end framework for state-of-the-art scene-level 3D content generation and controllable editing while ensuring the high fidelity of object-level entities within the scene. Source codes and models will be available at https://gala3d.github.io/. ",
    "url": "https://arxiv.org/abs/2402.07207",
    "authors": [
      "Xiaoyu Zhou",
      "Xingjian Ran",
      "Yajiao Xiong",
      "Jinlin He",
      "Zhiwei Lin",
      "Yongtao Wang",
      "Deqing Sun",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07216",
    "title": "A novel spatial-frequency domain network for zero-shot incremental  learning",
    "abstract": "Zero-shot incremental learning aims to enable the model to generalize to new classes without forgetting previously learned classes. However, the semantic gap between old and new sample classes can lead to catastrophic forgetting. Additionally, existing algorithms lack capturing significant information from each sample image domain, impairing models' classification performance. Therefore, this paper proposes a novel Spatial-Frequency Domain Network (SFDNet) which contains a Spatial-Frequency Feature Extraction (SFFE) module and Attention Feature Alignment (AFA) module to improve the Zero-Shot Translation for Class Incremental algorithm. Firstly, SFFE module is designed which contains a dual attention mechanism for obtaining salient spatial-frequency feature information. Secondly, a novel feature fusion module is conducted for obtaining fused spatial-frequency domain features. Thirdly, the Nearest Class Mean classifier is utilized to select the most suitable category. Finally, iteration between tasks is performed using the Zero-Shot Translation model. The proposed SFDNet has the ability to effectively extract spatial-frequency feature representation from input images, improve the accuracy of image classification, and fundamentally alleviate catastrophic forgetting. Extensive experiments on the CUB 200-2011 and CIFAR100 datasets demonstrate that our proposed algorithm outperforms state-of-the-art incremental learning algorithms. ",
    "url": "https://arxiv.org/abs/2402.07216",
    "authors": [
      "Jie Ren",
      "Yang Zhao",
      "Weichuan Zhang",
      "Changming Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07225",
    "title": "Rethinking Graph Masked Autoencoders through Alignment and Uniformity",
    "abstract": "Self-supervised learning on graphs can be bifurcated into contrastive and generative methods. Contrastive methods, also known as graph contrastive learning (GCL), have dominated graph self-supervised learning in the past few years, but the recent advent of graph masked autoencoder (GraphMAE) rekindles the momentum behind generative methods. Despite the empirical success of GraphMAE, there is still a dearth of theoretical understanding regarding its efficacy. Moreover, while both generative and contrastive methods have been shown to be effective, their connections and differences have yet to be thoroughly investigated. Therefore, we theoretically build a bridge between GraphMAE and GCL, and prove that the node-level reconstruction objective in GraphMAE implicitly performs context-level GCL. Based on our theoretical analysis, we further identify the limitations of the GraphMAE from the perspectives of alignment and uniformity, which have been considered as two key properties of high-quality representations in GCL. We point out that GraphMAE's alignment performance is restricted by the masking strategy, and the uniformity is not strictly guaranteed. To remedy the aforementioned limitations, we propose an Alignment-Uniformity enhanced Graph Masked AutoEncoder, named AUG-MAE. Specifically, we propose an easy-to-hard adversarial masking strategy to provide hard-to-align samples, which improves the alignment performance. Meanwhile, we introduce an explicit uniformity regularizer to ensure the uniformity of the learned representations. Experimental results on benchmark datasets demonstrate the superiority of our model over existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2402.07225",
    "authors": [
      "Liang Wang",
      "Xiang Tao",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07243",
    "title": "PIVOT-Net: Heterogeneous Point-Voxel-Tree-based Framework for Point  Cloud Compression",
    "abstract": "The universality of the point cloud format enables many 3D applications, making the compression of point clouds a critical phase in practice. Sampled as discrete 3D points, a point cloud approximates 2D surface(s) embedded in 3D with a finite bit-depth. However, the point distribution of a practical point cloud changes drastically as its bit-depth increases, requiring different methodologies for effective consumption/analysis. In this regard, a heterogeneous point cloud compression (PCC) framework is proposed. We unify typical point cloud representations -- point-based, voxel-based, and tree-based representations -- and their associated backbones under a learning-based framework to compress an input point cloud at different bit-depth levels. Having recognized the importance of voxel-domain processing, we augment the framework with a proposed context-aware upsampling for decoding and an enhanced voxel transformer for feature aggregation. Extensive experimentation demonstrates the state-of-the-art performance of our proposal on a wide range of point clouds. ",
    "url": "https://arxiv.org/abs/2402.07243",
    "authors": [
      "Jiahao Pang",
      "Kevin Bui",
      "Dong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.07248",
    "title": "Depth Separations in Neural Networks: Separating the Dimension from the  Accuracy",
    "abstract": "We prove an exponential separation between depth 2 and depth 3 neural networks, when approximating an $\\mathcal{O}(1)$-Lipschitz target function to constant accuracy, with respect to a distribution with support in $[0,1]^{d}$, assuming exponentially bounded weights. This addresses an open problem posed in \\citet{safran2019depth}, and proves that the curse of dimensionality manifests in depth 2 approximation, even in cases where the target function can be represented efficiently using depth 3. Previously, lower bounds that were used to separate depth 2 from depth 3 required that at least one of the Lipschitz parameter, target accuracy or (some measure of) the size of the domain of approximation scale polynomially with the input dimension, whereas we fix the former two and restrict our domain to the unit hypercube. Our lower bound holds for a wide variety of activation functions, and is based on a novel application of an average- to worst-case random self-reducibility argument, to reduce the problem to threshold circuits lower bounds. ",
    "url": "https://arxiv.org/abs/2402.07248",
    "authors": [
      "Itay Safran",
      "Daniel Reichman",
      "Paul Valiant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.07251",
    "title": "Physics-Informed Neural Networks with Hard Linear Equality Constraints",
    "abstract": "Surrogate modeling is used to replace computationally expensive simulations. Neural networks have been widely applied as surrogate models that enable efficient evaluations over complex physical systems. Despite this, neural networks are data-driven models and devoid of any physics. The incorporation of physics into neural networks can improve generalization and data efficiency. The physics-informed neural network (PINN) is an approach to leverage known physical constraints present in the data, but it cannot strictly satisfy them in the predictions. This work proposes a novel physics-informed neural network, KKT-hPINN, which rigorously guarantees hard linear equality constraints through projection layers derived from KKT conditions. Numerical experiments on Aspen models of a continuous stirred-tank reactor (CSTR) unit, an extractive distillation subsystem, and a chemical plant demonstrate that this model can further enhance the prediction accuracy. ",
    "url": "https://arxiv.org/abs/2402.07251",
    "authors": [
      "Hao Chen",
      "Gonzalo E. Constante Flores",
      "Can Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.07261",
    "title": "A Novel Technique to Parameterize Congestion Control in 6TiSCH IIoT  Networks",
    "abstract": "The Industrial Internet of Things (IIoT) refers to the use of interconnected smart devices, sensors, and other technologies to create a network of intelligent systems that can monitor and manage industrial processes. 6TiSCH (IPv6 over the Time Slotted Channel Hopping mode of IEEE 802.15.4e) as an enabling technology facilitates low-power and low-latency communication between IoT devices in industrial environments. The Routing Protocol for Low power and lossy networks (RPL), which is used as the de-facto routing protocol for 6TiSCH networks is observed to suffer from several limitations, especially during congestion in the network. Therefore, there is an immediate need for some modifications to the RPL to deal with this problem. Under traffic load which keeps on changing continuously at different instants of time, the proposed mechanism aims at finding the appropriate parent for a node that can forward the packet to the destination through the least congested path with minimal packet loss. This facilitates congestion management under dynamic traffic loads. For this, a new metric for routing using the concept of exponential weighting has been proposed, which takes the number of packets present in the queue of the node into account when choosing the parent at a particular instance of time. Additionally, the paper proposes a parent selection and swapping mechanism for congested networks. Performance evaluations are carried out in order to validate the proposed work. The results show an improvement in the performance of RPL under heavy and dynamic traffic loads. ",
    "url": "https://arxiv.org/abs/2402.07261",
    "authors": [
      "Kushal Chakraborty",
      "Aritra Kumar Dutta",
      "Mohammad Avesh Hussain",
      "Syed Raafay Mohiuddin",
      "Nikumani Choudhury",
      "Rakesh Matam",
      "Mithun Mukherjee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.07283",
    "title": "Power Transformer Fault Prediction Based on Knowledge Graphs",
    "abstract": "In this paper, we address the challenge of learning with limited fault data for power transformers. Traditional operation and maintenance tools lack effective predictive capabilities for potential faults. The scarcity of extensive fault data makes it difficult to apply machine learning techniques effectively. To solve this problem, we propose a novel approach that leverages the knowledge graph (KG) technology in combination with gradient boosting decision trees (GBDT). This method is designed to efficiently learn from a small set of high-dimensional data, integrating various factors influencing transformer faults and historical operational data. Our approach enables accurate safe state assessments and fault analyses of power transformers despite the limited fault characteristic data. Experimental results demonstrate that this method outperforms other learning approaches in prediction accuracy, such as artificial neural networks (ANN) and logistic regression (LR). Furthermore, it offers significant improvements in progressiveness, practicality, and potential for widespread application. ",
    "url": "https://arxiv.org/abs/2402.07283",
    "authors": [
      "Chao Wang",
      "Zhuo Chen",
      "Ziyan Zhang",
      "Chiyi Li",
      "Kai Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.07284",
    "title": "CLIPPER: Robust Data Association without an Initial Guess",
    "abstract": "Identifying correspondences in noisy data is a critically important step in estimation processes. When an informative initial estimation guess is available, the data association challenge is less acute; however, the existence of a high-quality initial guess is rare in most contexts. We explore graph-theoretic formulations for data association, which do not require an initial estimation guess. Existing graph-theoretic approaches optimize over unweighted graphs, discarding important consistency information encoded in weighted edges, and frequently attempt to solve NP-hard problems exactly. In contrast, we formulate a new optimization problem that fully leverages weighted graphs and seeks the densest edge-weighted clique. We introduce two relaxations to this problem: a convex semidefinite relaxation which we find to be empirically tight, and a fast first-order algorithm called CLIPPER which frequently arrives at nearly-optimal solutions in milliseconds. When evaluated on point cloud registration problems, our algorithms remain robust up to at least 95% outliers while existing algorithms begin breaking down at 80% outliers. Code is available at https://mit-acl.github.io/clipper. ",
    "url": "https://arxiv.org/abs/2402.07284",
    "authors": [
      "Parker C. Lusk",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07294",
    "title": "On the Effectiveness of Machine Learning-based Call Graph Pruning: An  Empirical Study",
    "abstract": "Static call graph (CG) construction often over-approximates call relations, leading to sound, but imprecise results. Recent research has explored machine learning (ML)-based CG pruning as a means to enhance precision by eliminating false edges. However, current methods suffer from a limited evaluation dataset, imbalanced training data, and reduced recall, which affects practical downstream analyses. Prior results were also not compared with advanced static CG construction techniques yet. This study tackles these issues. We introduce the NYXCorpus, a dataset of real-world Java programs with high test coverage and we collect traces from test executions and build a ground truth of dynamic CGs. We leverage these CGs to explore conservative pruning strategies during the training and inference of ML-based CG pruners. We conduct a comparative analysis of static CGs generated using zero control flow analysis (0-CFA) and those produced by a context-sensitive 1-CFA algorithm, evaluating both with and without pruning. We find that CG pruning is a difficult task for real-world Java projects and substantial improvements in the CG precision (+25%) meet reduced recall (-9%). However, our experiments show promising results: even when we favor recall over precision by using an F2 metric in our experiments, we can show that pruned CGs have comparable quality to a context-sensitive 1-CFA analysis while being computationally less demanding. Resulting CGs are much smaller (69%), and substantially faster (3.5x speed-up), with virtually unchanged results in our downstream analysis. ",
    "url": "https://arxiv.org/abs/2402.07294",
    "authors": [
      "Amir M. Mir",
      "Mehdi Keshani",
      "Sebastian Proksch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.07295",
    "title": "Training Heterogeneous Client Models using Knowledge Distillation in  Serverless Federated Learning",
    "abstract": "Federated Learning (FL) is an emerging machine learning paradigm that enables the collaborative training of a shared global model across distributed clients while keeping the data decentralized. Recent works on designing systems for efficient FL have shown that utilizing serverless computing technologies, particularly Function-as-a-Service (FaaS) for FL, can enhance resource efficiency, reduce training costs, and alleviate the complex infrastructure management burden on data holders. However, existing serverless FL systems implicitly assume a uniform global model architecture across all participating clients during training. This assumption fails to address fundamental challenges in practical FL due to the resource and statistical data heterogeneity among FL clients. To address these challenges and enable heterogeneous client models in serverless FL, we utilize Knowledge Distillation (KD) in this paper. Towards this, we propose novel optimized serverless workflows for two popular conventional federated KD techniques, i.e., FedMD and FedDF. We implement these workflows by introducing several extensions to an open-source serverless FL system called FedLess. Moreover, we comprehensively evaluate the two strategies on multiple datasets across varying levels of client data heterogeneity using heterogeneous client models with respect to accuracy, fine-grained training times, and costs. Results from our experiments demonstrate that serverless FedDF is more robust to extreme non-IID data distributions, is faster, and leads to lower costs than serverless FedMD. In addition, compared to the original implementation, our optimizations for particular steps in FedMD and FedDF lead to an average speedup of 3.5x and 1.76x across all datasets. ",
    "url": "https://arxiv.org/abs/2402.07295",
    "authors": [
      "Mohak Chadha",
      "Pulkit Khera",
      "Jianfeng Gu",
      "Osama Abboud",
      "Michael Gerndt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.07301",
    "title": "LISR: Learning Linear 3D Implicit Surface Representation Using Compactly  Supported Radial Basis Functions",
    "abstract": "Implicit 3D surface reconstruction of an object from its partial and noisy 3D point cloud scan is the classical geometry processing and 3D computer vision problem. In the literature, various 3D shape representations have been developed, differing in memory efficiency and shape retrieval effectiveness, such as volumetric, parametric, and implicit surfaces. Radial basis functions provide memory-efficient parameterization of the implicit surface. However, we show that training a neural network using the mean squared error between the ground-truth implicit surface and the linear basis-based implicit surfaces does not converge to the global solution. In this work, we propose locally supported compact radial basis functions for a linear representation of the implicit surface. This representation enables us to generate 3D shapes with arbitrary topologies at any resolution due to their continuous nature. We then propose a neural network architecture for learning the linear implicit shape representation of the 3D surface of an object. We learn linear implicit shapes within a supervised learning framework using ground truth Signed-Distance Field (SDF) data for guidance. The classical strategies face difficulties in finding linear implicit shapes from a given 3D point cloud due to numerical issues (requires solving inverse of a large matrix) in basis and query point selection. The proposed approach achieves better Chamfer distance and comparable F-score than the state-of-the-art approach on the benchmark dataset. We also show the effectiveness of the proposed approach by using it for the 3D shape completion task. ",
    "url": "https://arxiv.org/abs/2402.07301",
    "authors": [
      "Atharva Pandey",
      "Vishal Yadav",
      "Rajendra Nagar",
      "Santanu Chaudhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07310",
    "title": "BioNeRF: Biologically Plausible Neural Radiance Fields for View  Synthesis",
    "abstract": "This paper presents BioNeRF, a biologically plausible architecture that models scenes in a 3D representation and synthesizes new views through radiance fields. Since NeRF relies on the network weights to store the scene's 3-dimensional representation, BioNeRF implements a cognitive-inspired mechanism that fuses inputs from multiple sources into a memory-like structure, improving the storing capacity and extracting more intrinsic and correlated information. BioNeRF also mimics a behavior observed in pyramidal cells concerning contextual information, in which the memory is provided as the context and combined with the inputs of two subsequent neural models, one responsible for producing the volumetric densities and the other the colors used to render the scene. Experimental results show that BioNeRF outperforms state-of-the-art results concerning a quality measure that encodes human perception in two datasets: real-world images and synthetic data. ",
    "url": "https://arxiv.org/abs/2402.07310",
    "authors": [
      "Leandro A. Passos",
      "Douglas Rodrigues",
      "Danilo Jodas",
      "Kelton A. P. Costa",
      "Jo\u00e3o Paulo Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07323",
    "title": "Lessons Learned from Mining the Hugging Face Repository",
    "abstract": "The rapidly evolving fields of Machine Learning (ML) and Artificial Intelligence have witnessed the emergence of platforms like Hugging Face (HF) as central hubs for model development and sharing. This experience report synthesizes insights from two comprehensive studies conducted on HF, focusing on carbon emissions and the evolutionary and maintenance aspects of ML models. Our objective is to provide a practical guide for future researchers embarking on mining software repository studies within the HF ecosystem to enhance the quality of these studies. We delve into the intricacies of the replication package used in our studies, highlighting the pivotal tools and methodologies that facilitated our analysis. Furthermore, we propose a nuanced stratified sampling strategy tailored for the diverse HF Hub dataset, ensuring a representative and comprehensive analytical approach. The report also introduces preliminary guidelines, transitioning from repository mining to cohort studies, to establish causality in repository mining studies, particularly within the ML model of HF context. This transition is inspired by existing frameworks and is adapted to suit the unique characteristics of the HF model ecosystem. Our report serves as a guiding framework for researchers, contributing to the responsible and sustainable advancement of ML, and fostering a deeper understanding of the broader implications of ML models. ",
    "url": "https://arxiv.org/abs/2402.07323",
    "authors": [
      "Joel Casta\u00f1o",
      "Silverio Mart\u00ednez-Fern\u00e1ndez",
      "Xavier Franch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07338",
    "title": "Exploring Saliency Bias in Manipulation Detection",
    "abstract": "The social media-fuelled explosion of fake news and misinformation supported by tampered images has led to growth in the development of models and datasets for image manipulation detection. However, existing detection methods mostly treat media objects in isolation, without considering the impact of specific manipulations on viewer perception. Forensic datasets are usually analyzed based on the manipulation operations and corresponding pixel-based masks, but not on the semantics of the manipulation, i.e., type of scene, objects, and viewers' attention to scene content. The semantics of the manipulation play an important role in spreading misinformation through manipulated images. In an attempt to encourage further development of semantic-aware forensic approaches to understand visual misinformation, we propose a framework to analyze the trends of visual and semantic saliency in popular image manipulation datasets and their impact on detection. ",
    "url": "https://arxiv.org/abs/2402.07338",
    "authors": [
      "Joshua Krinsky",
      "Alan Bettis",
      "Qiuyu Tang",
      "Daniel Moreira",
      "Aparna Bharati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07340",
    "title": "Random Geometric Graph Alignment with Graph Neural Networks",
    "abstract": "We characterize the performance of graph neural networks for graph alignment problems in the presence of vertex feature information. More specifically, given two graphs that are independent perturbations of a single random geometric graph with noisy sparse features, the task is to recover an unknown one-to-one mapping between the vertices of the two graphs. We show under certain conditions on the sparsity and noise level of the feature vectors, a carefully designed one-layer graph neural network can with high probability recover the correct alignment between the vertices with the help of the graph structure. We also prove that our conditions on the noise level are tight up to logarithmic factors. Finally we compare the performance of the graph neural network to directly solving an assignment problem on the noisy vertex features. We demonstrate that when the noise level is at least constant this direct matching fails to have perfect recovery while the graph neural network can tolerate noise level growing as fast as a power of the size of the graph. ",
    "url": "https://arxiv.org/abs/2402.07340",
    "authors": [
      "Suqi Liu",
      "Morgane Austern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.07347",
    "title": "Accuracy of TextFooler black box adversarial attacks on 01 loss sign  activation neural network ensemble",
    "abstract": "Recent work has shown the defense of 01 loss sign activation neural networks against image classification adversarial attacks. A public challenge to attack the models on CIFAR10 dataset remains undefeated. We ask the following question in this study: are 01 loss sign activation neural networks hard to deceive with a popular black box text adversarial attack program called TextFooler? We study this question on four popular text classification datasets: IMDB reviews, Yelp reviews, MR sentiment classification, and AG news classification. We find that our 01 loss sign activation network is much harder to attack with TextFooler compared to sigmoid activation cross entropy and binary neural networks. We also study a 01 loss sign activation convolutional neural network with a novel global pooling step specific to sign activation networks. With this new variation we see a significant gain in adversarial accuracy rendering TextFooler practically useless against it. We make our code freely available at \\url{https://github.com/zero-one-loss/wordcnn01} and \\url{https://github.com/xyzacademic/mlp01example}. Our work here suggests that 01 loss sign activation networks could be further developed to create fool proof models against text adversarial attacks. ",
    "url": "https://arxiv.org/abs/2402.07347",
    "authors": [
      "Yunzhe Xue",
      "Usman Roshan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.07359",
    "title": "Structured Satellite-UAV-Terrestrial Networks for 6G Internet of Things",
    "abstract": "The upcoming sixth generation (6G) wireless communication network is envisioned to cover space, air, and maritime areas, in addition to urban-centered terrestrial coverage by the fifth generation (5G) network, to support intelligent Internet of Things (IoT). Towards this end, we investigate structured integration of satellites, unmanned aerial vehicles (UAVs), and terrestrial networks, aiming to serve future universal IoT possibly with a massive number of devices in the coverage holes of current 5G. The hybrid satellite-UAV-terrestrial network usually leads to high system complexity, due to the heterogeneity and dynamics of space/air/ground links. With a systematic thinking, we propose to create and exploit hierarchies for the integrated network. Four basic structures are discussed by learning from the synergies in our human body. To orchestrate multiple heterogeneous basic structures, we further propose a process-oriented on-demand coverage method, which characterizes the system behavior as a series of events over time and is able to tackle the system complexity elaborately. We also outline open issues for promoting the agility and intelligence of structured satellite-UAV-terrestrial networks in the making. ",
    "url": "https://arxiv.org/abs/2402.07359",
    "authors": [
      "Wei Feng",
      "Yanmin Wang",
      "Yunfei Chen",
      "Ning Ge",
      "Cheng-Xiang Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.07367",
    "title": "Utilizing Large LanguageModels to Detect Privacy Leaks in Mini-App Code",
    "abstract": "Mini-applications, commonly referred to as mini-apps, are compact software programs embedded within larger applications or platforms, offering targeted functionality without the need for separate installations. Typically web-based or cloud-hosted, these mini-apps streamline user experiences by providing focused services accessible through web browsers or mobile apps. Their simplicity, speed, and integration capabilities make them valuable additions to messaging platforms, social media networks, e-commerce sites, and various digital environments. WeChat Mini Programs, a prominent feature of China's leading messaging app, exemplify this trend, offering users a seamless array of services without additional downloads. Leveraging WeChat's extensive user base and payment infrastructure, Mini Programs facilitate efficient transactions and bridge online and offline experiences, shaping China's digital landscape significantly. This paper investigates the potential of employing Large Language Models (LLMs) to detect privacy breaches within WeChat Mini Programs. Given the widespread use of Mini Programs and growing concerns about data privacy, this research seeks to determine if LLMs can effectively identify instances of privacy leakage within this ecosystem. Through meticulous analysis and experimentation, we aim to highlight the efficacy of LLMs in safeguarding user privacy and security within the WeChat Mini Program environment, thereby contributing to a more secure digital landscape. ",
    "url": "https://arxiv.org/abs/2402.07367",
    "authors": [
      "Liming Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.07370",
    "title": "SelfSwapper: Self-Supervised Face Swapping via Shape Agnostic Masked  AutoEncoder",
    "abstract": "Face swapping has gained significant attention for its varied applications. The majority of previous face swapping approaches have relied on the seesaw game training scheme, which often leads to the instability of the model training and results in undesired samples with blended identities due to the target identity leakage problem. This paper introduces the Shape Agnostic Masked AutoEncoder (SAMAE) training scheme, a novel self-supervised approach designed to enhance face swapping model training. Our training scheme addresses the limitations of traditional training methods by circumventing the conventional seesaw game and introducing clear ground truth through its self-reconstruction training regime. It effectively mitigates identity leakage by masking facial regions of the input images and utilizing learned disentangled identity and non-identity features. Additionally, we tackle the shape misalignment problem with new techniques including perforation confusion and random mesh scaling, and establishes a new state-of-the-art, surpassing other baseline methods, preserving both identity and non-identity attributes, without sacrificing on either aspect. ",
    "url": "https://arxiv.org/abs/2402.07370",
    "authors": [
      "Jaeseong Lee",
      "Junha Hyung",
      "Sohyun Jeong",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07376",
    "title": "Unsupervised Discovery of Object-Centric Neural Fields",
    "abstract": "We study inferring 3D object-centric scene representations from a single image. While recent methods have shown potential in unsupervised 3D object discovery from simple synthetic images, they fail to generalize to real-world scenes with visually rich and diverse objects. This limitation stems from their object representations, which entangle objects' intrinsic attributes like shape and appearance with extrinsic, viewer-centric properties such as their 3D location. To address this bottleneck, we propose Unsupervised discovery of Object-Centric neural Fields (uOCF). uOCF focuses on learning the intrinsics of objects and models the extrinsics separately. Our approach significantly improves systematic generalization, thus enabling unsupervised learning of high-fidelity object-centric scene representations from sparse real-world images. To evaluate our approach, we collect three new datasets, including two real kitchen environments. Extensive experiments show that uOCF enables unsupervised discovery of visually rich objects from a single real image, allowing applications such as 3D object segmentation and scene manipulation. Notably, uOCF demonstrates zero-shot generalization to unseen objects from a single real image. Project page: https://red-fairy.github.io/uOCF/ ",
    "url": "https://arxiv.org/abs/2402.07376",
    "authors": [
      "Rundong Luo",
      "Hong-Xing Yu",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07381",
    "title": "RIS-Empowered LEO Satellite Networks for 6G: Promising Usage Scenarios  and Future Directions",
    "abstract": "Low-Earth orbit (LEO) satellite systems have been deemed a promising key enabler for current 5G and the forthcoming 6G wireless networks. Such LEO satellite constellations can provide worldwide three-dimensional coverage, high data rate, and scalability, thus enabling truly ubiquitous connectivity. On the other hand, another promising technology, reconfigurable intelligent surfaces (RISs), has emerged with favorable features, such as flexible deployment, cost & power efficiency, less transmission delay, noise-free nature, and in-band full-duplex structure. LEO satellite networks have many practical imperfections and limitations; however, exploiting RISs has been shown to be a potential solution to overcome these challenges. Particularly, RISs can enhance link quality, reduce the Doppler shift effect, and mitigate inter-/intra beam interference. In this article, we delve into exploiting RISs in LEO satellite networks. First, we present a holistic overview of LEO satellite communication and RIS technology, highlighting potential benefits and challenges. Second, we describe promising usage scenarios and applications in detail. Finally, we discuss potential future directions and challenges on RIS-empowered LEO networks, offering futuristic visions of the upcoming 6G era. ",
    "url": "https://arxiv.org/abs/2402.07381",
    "authors": [
      "Mesut Toka",
      "Byungju Lee",
      "Jaehyup Seong",
      "Aryan Kaushik",
      "Juhwan Lee",
      "Jungwoo Lee",
      "Namyoon Lee",
      "Wonjae Shin",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.07410",
    "title": "A Closer Look at the Robustness of Contrastive Language-Image  Pre-Training (CLIP)",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) models have demonstrated remarkable generalization capabilities across multiple challenging distribution shifts. However, there is still much to be explored in terms of their robustness to the variations of specific visual factors. In real-world applications, reliable and safe systems must consider other safety objectives beyond classification accuracy, such as predictive uncertainty. Yet, the effectiveness of CLIP models on such safety-related features is less-explored. Driven by the above, this work comprehensively investigates the safety objectives of CLIP models, specifically focusing on three key properties: resilience to visual factor variations, calibrated uncertainty estimations, and the ability to detect anomalous inputs. To this end, we study 83 CLIP models and 127 ImageNet classifiers. They are diverse in architecture, (pre)training distribution and training strategies. We consider 10 visual factors (e.g., shape and pattern), 5 types of out-of-distribution data, and 8 natural and challenging test conditions with different shift types, such as texture, style, and perturbation shifts. Our study has unveiled several previously unknown insights into CLIP models. For instance, they are not consistently more calibrated than other ImageNet models, which contradicts existing findings. Additionally, our analysis underscores the significance of training source design by showcasing its profound influence on the three safety-related properties. We believe our comprehensive study can shed light on and help guide the development of more robust and reliable CLIP models. ",
    "url": "https://arxiv.org/abs/2402.07410",
    "authors": [
      "Weijie Tu",
      "Weijian Deng",
      "Tom Gedeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07412",
    "title": "Auxiliary Reward Generation with Transition Distance Representation  Learning",
    "abstract": "Reinforcement learning (RL) has shown its strength in challenging sequential decision-making problems. The reward function in RL is crucial to the learning performance, as it serves as a measure of the task completion degree. In real-world problems, the rewards are predominantly human-designed, which requires laborious tuning, and is easily affected by human cognitive biases. To achieve automatic auxiliary reward generation, we propose a novel representation learning approach that can measure the ``transition distance'' between states. Building upon these representations, we introduce an auxiliary reward generation technique for both single-task and skill-chaining scenarios without the need for human knowledge. The proposed approach is evaluated in a wide range of manipulation tasks. The experiment results demonstrate the effectiveness of measuring the transition distance between states and the induced improvement by auxiliary rewards, which not only promotes better learning efficiency but also increases convergent stability. ",
    "url": "https://arxiv.org/abs/2402.07412",
    "authors": [
      "Siyuan Li",
      "Shijie Han",
      "Yingnan Zhao",
      "By Liang",
      "Peng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07415",
    "title": "Context-aware Multi-Model Object Detection for Diversely Heterogeneous  Compute Systems",
    "abstract": "In recent years, deep neural networks (DNNs) have gained widespread adoption for continuous mobile object detection (OD) tasks, particularly in autonomous systems. However, a prevalent issue in their deployment is the one-size-fits-all approach, where a single DNN is used, resulting in inefficient utilization of computational resources. This inefficiency is particularly detrimental in energy-constrained systems, as it degrades overall system efficiency. We identify that, the contextual information embedded in the input data stream (e.g. the frames in the camera feed that the OD models are run on) could be exploited to allow a more efficient multi-model-based OD process. In this paper, we propose SHIFT which continuously selects from a variety of DNN-based OD models depending on the dynamically changing contextual information and computational constraints. During this selection, SHIFT uniquely considers multi-accelerator execution to better optimize the energy-efficiency while satisfying the latency constraints. Our proposed methodology results in improvements of up to 7.5x in energy usage and 2.8x in latency compared to state-of-the-art GPU-based single model OD approaches. ",
    "url": "https://arxiv.org/abs/2402.07415",
    "authors": [
      "Justin Davis",
      "Mehmet E. Belviranli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.07419",
    "title": "Conditional Generative Models are Sufficient to Sample from Any Causal  Effect Estimand",
    "abstract": "Causal inference from observational data has recently found many applications in machine learning. While sound and complete algorithms exist to compute causal effects, many of these algorithms require explicit access to conditional likelihoods over the observational distribution, which is difficult to estimate in the high-dimensional regime, such as with images. To alleviate this issue, researchers have approached the problem by simulating causal relations with neural models and obtained impressive results. However, none of these existing approaches can be applied to generic scenarios such as causal graphs on image data with latent confounders, or obtain conditional interventional samples. In this paper, we show that any identifiable causal effect given an arbitrary causal graph can be computed through push-forward computations of conditional generative models. Based on this result, we devise a diffusion-based approach to sample from any (conditional) interventional distribution on image data. To showcase our algorithm's performance, we conduct experiments on a Colored MNIST dataset having both the treatment ($X$) and the target variables ($Y$) as images and obtain interventional samples from $P(y|do(x))$. As an application of our algorithm, we evaluate two large conditional generative models that are pre-trained on the CelebA dataset by analyzing the strength of spurious correlations and the level of disentanglement they achieve. ",
    "url": "https://arxiv.org/abs/2402.07419",
    "authors": [
      "Md Musfiqur Rahman",
      "Matt Jordan",
      "Murat Kocaoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.07442",
    "title": "Game Agent Driven by Free-Form Text Command: Using LLM-based Code  Generation and Behavior Branch",
    "abstract": "Several attempts have been made to implement text command control for game agents. However, current technologies are limited to processing predefined format commands. This paper proposes a pioneering text command control system for a game agent that can understand natural language commands expressed in free-form. The proposed system uses a large language model (LLM) for code generation to interpret and transform natural language commands into behavior branch, a proposed knowledge expression based on behavior trees, which facilitates execution by the game agent. This study conducted empirical validation within a game environment that simulates a Pok\\'emon game and involved multiple participants. The results confirmed the system's ability to understand and carry out natural language commands, representing a noteworthy in the realm of real-time language interactive game agents. Notice for the use of this material. The copyright of this material is retained by the Japanese Society for Artificial Intelligence (JSAI). This material is published here with the agreement of JSAI. Please be complied with Copyright Law of Japan if any users wish to reproduce, make derivative work, distribute or make available to the public any part or whole thereof. All Rights Reserved, Copyright (C) The Japanese Society for Artificial Intelligence. ",
    "url": "https://arxiv.org/abs/2402.07442",
    "authors": [
      "Ray Ito",
      "Junichiro Takahashi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07444",
    "title": "Malicious Package Detection using Metadata Information",
    "abstract": "Protecting software supply chains from malicious packages is paramount in the evolving landscape of software development. Attacks on the software supply chain involve attackers injecting harmful software into commonly used packages or libraries in a software repository. For instance, JavaScript uses Node Package Manager (NPM), and Python uses Python Package Index (PyPi) as their respective package repositories. In the past, NPM has had vulnerabilities such as the event-stream incident, where a malicious package was introduced into a popular NPM package, potentially impacting a wide range of projects. As the integration of third-party packages becomes increasingly ubiquitous in modern software development, accelerating the creation and deployment of applications, the need for a robust detection mechanism has become critical. On the other hand, due to the sheer volume of new packages being released daily, the task of identifying malicious packages presents a significant challenge. To address this issue, in this paper, we introduce a metadata-based malicious package detection model, MeMPtec. This model extracts a set of features from package metadata information. These extracted features are classified as either easy-to-manipulate (ETM) or difficult-to-manipulate (DTM) features based on monotonicity and restricted control properties. By utilising these metadata features, not only do we improve the effectiveness of detecting malicious packages, but also we demonstrate its resistance to adversarial attacks in comparison with existing state-of-the-art. Our experiments indicate a significant reduction in both false positives (up to 97.56%) and false negatives (up to 91.86%). ",
    "url": "https://arxiv.org/abs/2402.07444",
    "authors": [
      "S. Halder",
      "M. Bewong",
      "A. Mahboubi",
      "Y. Jiang",
      "R. Islam",
      "Z. Islam",
      "R. Ip",
      "E. Ahmed",
      "G. Ramachandran",
      "A. Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.07452",
    "title": "TriAug: Out-of-Distribution Detection for Robust Classification of  Imbalanced Breast Lesion in Ultrasound",
    "abstract": "Different diseases, such as histological subtypes of breast lesions, have severely varying incidence rates. Even trained with substantial amount of in-distribution (ID) data, models often encounter out-of-distribution (OOD) samples belonging to unseen classes in clinical reality. To address this, we propose a novel framework built upon a long-tailed OOD detection task for breast ultrasound images. It is equipped with a triplet state augmentation (TriAug) which improves ID classification accuracy while maintaining a promising OOD detection performance. Meanwhile, we designed a balanced sphere loss to handle the class imbalanced problem. ",
    "url": "https://arxiv.org/abs/2402.07452",
    "authors": [
      "Yinyu Ye",
      "Shijing Chen",
      "Dong Ni",
      "Ruobing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07458",
    "title": "On the Distance from Calibration in Sequential Prediction",
    "abstract": "We study a sequential binary prediction setting where the forecaster is evaluated in terms of the calibration distance, which is defined as the $L_1$ distance between the predicted values and the set of predictions that are perfectly calibrated in hindsight. This is analogous to a calibration measure recently proposed by B{\\l}asiok, Gopalan, Hu and Nakkiran (STOC 2023) for the offline setting. The calibration distance is a natural and intuitive measure of deviation from perfect calibration, and satisfies a Lipschitz continuity property which does not hold for many popular calibration measures, such as the $L_1$ calibration error and its variants. We prove that there is a forecasting algorithm that achieves an $O(\\sqrt{T})$ calibration distance in expectation on an adversarially chosen sequence of $T$ binary outcomes. At the core of this upper bound is a structural result showing that the calibration distance is accurately approximated by the lower calibration distance, which is a continuous relaxation of the former. We then show that an $O(\\sqrt{T})$ lower calibration distance can be achieved via a simple minimax argument and a reduction to online learning on a Lipschitz class. On the lower bound side, an $\\Omega(T^{1/3})$ calibration distance is shown to be unavoidable, even when the adversary outputs a sequence of independent random bits, and has an additional ability to early stop (i.e., to stop producing random bits and output the same bit in the remaining steps). Interestingly, without this early stopping, the forecaster can achieve a much smaller calibration distance of $\\mathrm{polylog}(T)$. ",
    "url": "https://arxiv.org/abs/2402.07458",
    "authors": [
      "Mingda Qiao",
      "Letian Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.07465",
    "title": "Score-Based Physics-Informed Neural Networks for High-Dimensional  Fokker-Planck Equations",
    "abstract": "The Fokker-Planck (FP) equation is a foundational PDE in stochastic processes. However, curse of dimensionality (CoD) poses challenge when dealing with high-dimensional FP PDEs. Although Monte Carlo and vanilla Physics-Informed Neural Networks (PINNs) have shown the potential to tackle CoD, both methods exhibit numerical errors in high dimensions when dealing with the probability density function (PDF) associated with Brownian motion. The point-wise PDF values tend to decrease exponentially as dimension increases, surpassing the precision of numerical simulations and resulting in substantial errors. Moreover, due to its massive sampling, Monte Carlo fails to offer fast sampling. Modeling the logarithm likelihood (LL) via vanilla PINNs transforms the FP equation into a difficult HJB equation, whose error grows rapidly with dimension. To this end, we propose a novel approach utilizing a score-based solver to fit the score function in SDEs. The score function, defined as the gradient of the LL, plays a fundamental role in inferring LL and PDF and enables fast SDE sampling. Three fitting methods, Score Matching (SM), Sliced SM (SSM), and Score-PINN, are introduced. The proposed score-based SDE solver operates in two stages: first, employing SM, SSM, or Score-PINN to acquire the score; and second, solving the LL via an ODE using the obtained score. Comparative evaluations across these methods showcase varying trade-offs. The proposed method is evaluated across diverse SDEs, including anisotropic OU processes, geometric Brownian, and Brownian with varying eigenspace. We also test various distributions, including Gaussian, Log-normal, Laplace, and Cauchy. The numerical results demonstrate the score-based SDE solver's stability, speed, and performance across different settings, solidifying its potential as a solution to CoD for high-dimensional FP equations. ",
    "url": "https://arxiv.org/abs/2402.07465",
    "authors": [
      "Zheyuan Hu",
      "Zhongqiang Zhang",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.07466",
    "title": "VCR: Video representation for Contextual Retrieval",
    "abstract": "Streamlining content discovery within media archives requires integrating advanced data representations and effective visualization techniques for clear communication of video topics to users. The proposed system addresses the challenge of efficiently navigating large video collections by exploiting a fusion of visual, audio, and textual features to accurately index and categorize video content through a text-based method. Additionally, semantic embeddings are employed to provide contextually relevant information and recommendations to users, resulting in an intuitive and engaging exploratory experience over our topics ontology map using OpenAI GPT-4. ",
    "url": "https://arxiv.org/abs/2402.07466",
    "authors": [
      "Oron Nir",
      "Idan Vidra",
      "Avi Neeman",
      "Barak Kinarti",
      "Ariel Shamir"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.07480",
    "title": "Topological Safeguard for Evasion Attack based on the Interpretability  of Artificial Neural Network Behavior",
    "abstract": "In the last years, Deep Learning technology has been proposed in different fields, bringing many advances in each of them, but identifying new threats in these solutions regarding cybersecurity. Those implemented models have brought several vulnerabilities associated with Deep Learning technology. Moreover, those allow taking advantage of the implemented model, obtaining private information, and even modifying the model's decision-making. Therefore, interest in studying those vulnerabilities/attacks and designing defenses to avoid or fight them is gaining prominence among researchers. In particular, the widely known evasion attack is being analyzed by researchers; thus, several defenses to avoid such a threat can be found in the literature. Since the presentation of the L-BFG algorithm, this threat concerns the research community. However, it continues developing new and ingenious countermeasures since there is no perfect defense for all the known evasion algorithms. In this work, a novel detector of evasion attacks is developed. It focuses on the information of the activations of the neurons given by the model when an input sample is injected. Moreover, it puts attention to the topology of the targeted deep learning model to analyze the activations according to which neurons are connecting. This approach has been decided because the literature shows that the targeted model's topology contains essential information about if the evasion attack occurs. For this purpose, a huge data preprocessing is required to introduce all this information in the detector, which uses the Graph Convolutional Neural Network (GCN) technology. Thus, it understands the topology of the target model, obtaining promising results and improving the outcomes presented in the literature related to similar defenses. ",
    "url": "https://arxiv.org/abs/2402.07480",
    "authors": [
      "Xabier Echeberria-Barrio",
      "Amaia Gil-Lerchundi",
      "I\u00f1igo Mendialdua",
      "Raul Orduna-Urrutia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07496",
    "title": "Understanding Deep Learning defenses Against Adversarial Examples  Through Visualizations for Dynamic Risk Assessment",
    "abstract": "In recent years, Deep Neural Network models have been developed in different fields, where they have brought many advances. However, they have also started to be used in tasks where risk is critical. A misdiagnosis of these models can lead to serious accidents or even death. This concern has led to an interest among researchers to study possible attacks on these models, discovering a long list of vulnerabilities, from which every model should be defended. The adversarial example attack is a widely known attack among researchers, who have developed several defenses to avoid such a threat. However, these defenses are as opaque as a deep neural network model, how they work is still unknown. This is why visualizing how they change the behavior of the target model is interesting in order to understand more precisely how the performance of the defended model is being modified. For this work, some defenses, against adversarial example attack, have been selected in order to visualize the behavior modification of each of them in the defended model. Adversarial training, dimensionality reduction and prediction similarity were the selected defenses, which have been developed using a model composed by convolution neural network layers and dense neural network layers. In each defense, the behavior of the original model has been compared with the behavior of the defended model, representing the target model by a graph in a visualization. ",
    "url": "https://arxiv.org/abs/2402.07496",
    "authors": [
      "Xabier Echeberria-Barrio",
      "Amaia Gil-Lerchundi",
      "Jon Egana-Zubia",
      "Raul Orduna-Urrutia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.07502",
    "title": "ClusterTabNet: Supervised clustering method for table detection and  table structure recognition",
    "abstract": "We present a novel deep-learning-based method to cluster words in documents which we apply to detect and recognize tables given the OCR output. We interpret table structure bottom-up as a graph of relations between pairs of words (belonging to the same row, column, header, as well as to the same table) and use a transformer encoder model to predict its adjacency matrix. We demonstrate the performance of our method on the PubTables-1M dataset as well as PubTabNet and FinTabNet datasets. Compared to the current state-of-the-art detection methods such as DETR and Faster R-CNN, our method achieves similar or better accuracy, while requiring a significantly smaller model. ",
    "url": "https://arxiv.org/abs/2402.07502",
    "authors": [
      "Marek Polewczyk",
      "Marco Spinaci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07506",
    "title": "NeuralSentinel: Safeguarding Neural Network Reliability and  Trustworthiness",
    "abstract": "The usage of Artificial Intelligence (AI) systems has increased exponentially, thanks to their ability to reduce the amount of data to be analyzed, the user efforts and preserving a high rate of accuracy. However, introducing this new element in the loop has converted them into attacked points that can compromise the reliability of the systems. This new scenario has raised crucial challenges regarding the reliability and trustworthiness of the AI models, as well as about the uncertainties in their response decisions, becoming even more crucial when applied in critical domains such as healthcare, chemical, electrical plants, etc. To contain these issues, in this paper, we present NeuralSentinel (NS), a tool able to validate the reliability and trustworthiness of AI models. This tool combines attack and defence strategies and explainability concepts to stress an AI model and help non-expert staff increase their confidence in this new system by understanding the model decisions. NS provide a simple and easy-to-use interface for helping humans in the loop dealing with all the needed information. This tool was deployed and used in a Hackathon event to evaluate the reliability of a skin cancer image detector. During the event, experts and non-experts attacked and defended the detector, learning which factors were the most important for model misclassification and which techniques were the most efficient. The event was also used to detect NS's limitations and gather feedback for further improvements. ",
    "url": "https://arxiv.org/abs/2402.07506",
    "authors": [
      "Xabier Echeberria-Barrio",
      "Mikel Gorricho",
      "Selene Valencia",
      "Francesco Zola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07507",
    "title": "Clustering Dynamics for Improved Speed Prediction Deriving from  Topographical GPS Registrations",
    "abstract": "A persistent challenge in the field of Intelligent Transportation Systems is to extract accurate traffic insights from geographic regions with scarce or no data coverage. To this end, we propose solutions for speed prediction using sparse GPS data points and their associated topographical and road design features. Our goal is to investigate whether we can use similarities in the terrain and infrastructure to train a machine learning model that can predict speed in regions where we lack transportation data. For this we create a Temporally Orientated Speed Dictionary Centered on Topographically Clustered Roads, which helps us to provide speed correlations to selected feature configurations. Our results show qualitative and quantitative improvement over new and standard regression methods. The presented framework provides a fresh perspective on devising strategies for missing data traffic analysis. ",
    "url": "https://arxiv.org/abs/2402.07507",
    "authors": [
      "Sarah Almeida Carneiro",
      "Giovanni Chierchia",
      "Aurelie Pirayre",
      "Laurent Najman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07523",
    "title": "Using Ensemble Inference to Improve Recall of Clone Detection",
    "abstract": "Large-scale source-code clone detection is a challenging task. In our previous work, we proposed an approach (SSCD) that leverages artificial neural networks and approximates nearest neighbour search to effectively and efficiently locate clones in large-scale bodies of code, in a time-efficient manner. However, our literature review suggests that the relative efficacy of differing neural network models has not been assessed in the context of large-scale clone detection approaches. In this work, we aim to assess several such models individually, in terms of their potential to maximize recall, while preserving a high level of precision during clone detection. We investigate if ensemble inference (in this case, using the results of more than one of these neural network models in combination) can further assist in this task. To assess this, we employed four state-of-the-art neural network models and evaluated them individually/in combination. The results, on an illustrative dataset of approximately 500K lines of C/C++ code, suggest that ensemble inference outperforms individual models in all trialled cases, when recall is concerned. Of individual models, the ADA model (belonging to the ChatGPT family of models) has the best performance. However commercial companies may not be prepared to hand their proprietary source code over to the cloud, as required by that approach. Consequently, they may be more interested in an ensemble-combination of CodeBERT-based and CodeT5 models, resulting in similar (if slightly lesser) recall and precision results. ",
    "url": "https://arxiv.org/abs/2402.07523",
    "authors": [
      "Gul Aftab Ahmed",
      "James Vincent Patten",
      "Yuanhua Han",
      "Guoxian Lu",
      "David Gregg",
      "Jim Buckley",
      "Muslim Chochlov"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.07531",
    "title": "Semantic Data for Humanities and Social Sciences (SDHSS): an Ecosystem  of CIDOC CRM Extensions for Research Data Production and Reuse",
    "abstract": "Given the challenge of giant knowledge graphs created by major eco-nomic actors, which could virtually replace research in the Humani-ties and Social Sciences (HSS) in responding to public concerns, thequestion arises of how to increase the value of research data throughtheir publication and networking, applying the FAIR principles. Bothan epistemological and a semantic analysis show that the most rel-evant part of research data is factual information, understood as arepresentation of the objects observed by the scientific disciplines,their properties and their relationships.This rich universe of information will be made understandable andtherefore reusable through the application of foundational ontologiesand a methodology based on the distinction between different levelsof abstraction, allowing the collective development of one or moreshared and reusable domain ontologies. This vision is being carriedout around the CIDOC CRM, as core ontology, and Semantic Datafor Humanities and Social Sciences (SDHSS), as a high-level exten-sion of it, as well as an ecosystem of sub-domain extensions that canbe easily managed through the ontome.net application. This willresult in an interoperability that is semantically richer than the sim-ple alignment of ontologies and less costly in terms of resources, andabove all adapted to the scientific and humanistic project of the HSS. ",
    "url": "https://arxiv.org/abs/2402.07531",
    "authors": [
      "Francesco Beretta"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.07536",
    "title": "BreakGPT: A Large Language Model with Multi-stage Structure for  Financial Breakout Detection",
    "abstract": "Trading range breakout (TRB) is a key method in the technical analysis of financial trading, widely employed by traders in financial markets such as stocks, futures, and foreign exchange. However, distinguishing between true and false breakout and providing the correct rationale cause significant challenges to investors. Recently, large language models have achieved success in various downstream applications, but their effectiveness in the domain of financial breakout detection has been subpar. The reason is that the unique data and specific knowledge are required in breakout detection. To address these issues, we introduce BreakGPT, the first large language model for financial breakout detection. Furthermore, we have developed a novel framework for large language models, namely multi-stage structure, effectively reducing mistakes in downstream applications. Experimental results indicate that compared to GPT-3.5, BreakGPT improves the accuracy of answers and rational by 44%, with the multi-stage structure contributing 17.6% to the improvement. Additionally, it outperforms ChatGPT-4 by 42.07%. Our Code is publicly available: https://github.com/Neviim96/BreakGPT ",
    "url": "https://arxiv.org/abs/2402.07536",
    "authors": [
      "Kang Zhang",
      "Osamu Yoshie",
      "Weiran Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07537",
    "title": "UAV-assisted Visual SLAM Generating Reconstructed 3D Scene Graphs in  GPS-denied Environments",
    "abstract": "Aerial robots play a vital role in various applications where the situational awareness of the robots concerning the environment is a fundamental demand. As one such use case, drones in GPS-denied environments require equipping with different sensors (e.g., vision sensors) that provide reliable sensing results while performing pose estimation and localization. In this paper, reconstructing the maps of indoor environments alongside generating 3D scene graphs for a high-level representation using a camera mounted on a drone is targeted. Accordingly, an aerial robot equipped with a companion computer and an RGB-D camera was built and employed to be appropriately integrated with a Visual Simultaneous Localization and Mapping (VSLAM) framework proposed by the authors. To enhance the situational awareness of the robot while reconstructing maps, various structural elements, including doors and walls, were labeled with printed fiducial markers, and a dictionary of the topological relations among them was fed to the system. The VSLAM system detects markers and reconstructs the map of the indoor areas enriched with higher-level semantic entities, including corridors and rooms. Another achievement is generating multi-layered vision-based situational graphs containing enhanced hierarchical representations of the indoor environment. In this regard, integrating VSLAM into the employed drone is the primary target of this paper to provide an end-to-end robot application for GPS-denied environments. To show the practicality of the system, various real-world condition experiments have been conducted in indoor scenarios with dissimilar structural layouts. Evaluations show the proposed drone application can perform adequately w.r.t. the ground-truth data and its baseline. ",
    "url": "https://arxiv.org/abs/2402.07537",
    "authors": [
      "Ahmed Radwan",
      "Ali Tourani",
      "Hriday Bavle",
      "Holger Voos",
      "Jose Luis Sanchez-Lopez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.07540",
    "title": "PKG API: A Tool for Personal Knowledge Graph Management",
    "abstract": "Personal knowledge graphs (PKGs) offer individuals a way to store and consolidate their fragmented personal data in a central place, improving service personalization while maintaining full user control. Despite their potential, practical PKG implementations with user-friendly interfaces remain scarce. This work addresses this gap by proposing a complete solution to represent, manage, and interface with PKGs. Our approach includes (1) a user-facing PKG Client, enabling end-users to administer their personal data easily via natural language statements, and (2) a service-oriented PKG API. To tackle the complexity of representing these statements within a PKG, we present an RDF-based PKG vocabulary that supports this, along with properties for access rights and provenance. ",
    "url": "https://arxiv.org/abs/2402.07540",
    "authors": [
      "Nolwenn Bernard",
      "Ivica Kostric",
      "Weronika \u0141ajewska",
      "Krisztian Balog",
      "Petra Galu\u0161\u010d\u00e1kov\u00e1",
      "Vinay Setty",
      "Martin G. Skj\u00e6veland"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.07542",
    "title": "ASAP-Repair: API-Specific Automated Program Repair Based on API Usage  Graphs",
    "abstract": "Modern software development relies on the reuse of code via Application Programming Interfaces (APIs). Such reuse relieves developers from learning and developing established algorithms and data structures anew, enabling them to focus on their problem at hand. However, there is also the risk of misusing an API due to a lack of understanding or proper documentation. While many techniques target API misuse detection, only limited efforts have been put into automatically repairing API misuses. In this paper, we present our advances on our technique API-Specific Automated Program Repair (ASAP-Repair). ASAP-Repair is intended to fix API misuses based on API Usage Graphs (AUGs) by leveraging API usage templates of state-of-the-art API misuse detectors. We demonstrate that ASAP-Repair is in principle applicable on an established API misuse dataset. Moreover, we discuss next steps and challenges to evolve ASAP-Repair towards a full-fledged Automatic Program Repair (APR) technique. ",
    "url": "https://arxiv.org/abs/2402.07542",
    "authors": [
      "Sebastian Nielebock",
      "Paul Blockhaus",
      "Jacob Kr\u00fcger",
      "Frank Ortmeier"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.07563",
    "title": "Joint User and Beam Selection in Millimeter Wave Networks",
    "abstract": "We study the problem of selecting a user equipment (UE) and a beam for each access point (AP) for concurrent transmissions in a millimeter wave (mmWave) network, such that the sum of weighted rates of UEs is maximized. We prove that this problem is NP-complete. We propose two algorithms -- Markov Chain Monte Carlo (MCMC) based and local interaction game (LIG) based UE and beam selection -- and prove that both of them asymptotically achieve the optimal solution. Also, we propose two fast greedy algorithms -- NGUB1 and NGUB2 -- for UE and beam selection. Through extensive simulations, we show that our proposed greedy algorithms outperform the most relevant algorithms proposed in prior work and perform close to the asymptotically optimal algorithms. ",
    "url": "https://arxiv.org/abs/2402.07563",
    "authors": [
      "Santosh Kumar Singh",
      "Satyabrata Sahu",
      "Ayushi Thawait",
      "Prasanna Chaporkar",
      "Gaurav S. Kasbekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.07570",
    "title": "Only the Curve Shape Matters: Training Foundation Models for Zero-Shot  Multivariate Time Series Forecasting through Next Curve Shape Prediction",
    "abstract": "We present General Time Transformer (GTT), an encoder-only style foundation model for zero-shot multivariate time series forecasting. GTT is pretrained on a large dataset of 200M high-quality time series samples spanning diverse domains. In our proposed framework, the task of multivariate time series forecasting is formulated as a channel-wise next curve shape prediction problem, where each time series sample is represented as a sequence of non-overlapping curve shapes with a unified numerical magnitude. GTT is trained to predict the next curve shape based on a window of past curve shapes in a channel-wise manner. Experimental results demonstrate that GTT exhibits superior zero-shot multivariate forecasting capabilities on unseen time series datasets, even surpassing state-of-the-art supervised baselines. Additionally, we investigate the impact of varying GTT model parameters and training dataset scales, observing that the scaling law also holds in the context of zero-shot multivariate time series forecasting. ",
    "url": "https://arxiv.org/abs/2402.07570",
    "authors": [
      "Cheng Feng",
      "Long Huang",
      "Denis Krompass"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07601",
    "title": "Topic-aware Most Influential Community Search in Social Networks",
    "abstract": "Community search is a problem aimed at searching for densely connected subgraphs within a network based on query conditions, which has recently attracted significant attention. However, most previous community search studies have overlooked the coexistence relationship among attributes. They typically assign a single attribute to each node or edge (e.g.,only considering influence scores or keywords), which is difficult for users to obtain a comprehensive and beneficial information. Additionally, most of them also ignored the uncertainty in the attribute graph. Therefore, in this paper, we introduce two novel community models, namely topic-based interaction graph and $(k,l,\\eta)$-influential community. The former is a directed ucertain graph generated by the query topic distribution provided by users, while the latter is used for solving the topic-aware most influential community search problem in social networks. Furthermore, we propose an online search algorithm which computes the influence value of each vertex by considering the topic-aware information diffusion process on interaction graphs. And then, we use a peeling-pruning strategy to iteratively find the topic-aware most $(k,l,\\eta)$-influential community. To further speed up the search performance, we devise two lightweight index structures which efficiently support the search for the topic-aware most influential community within an optimal time. We also propose three optimization methods to improve the space and time costs of the index-based approach. ",
    "url": "https://arxiv.org/abs/2402.07601",
    "authors": [
      "Long Teng",
      "Yanhao Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.07619",
    "title": "Developing a Multi-variate Prediction Model For COVID-19 From  Crowd-sourced Respiratory Voice Data",
    "abstract": "COVID-19 has affected more than 223 countries worldwide and in the Post-COVID Era, there is a pressing need for non-invasive, low-cost, and highly scalable solutions to detect COVID-19. We develop a deep learning model to identify COVID-19 from voice recording data. The novelty of this work is in the development of deep learning models for COVID-19 identification from only voice recordings. We use the Cambridge COVID-19 Sound database which contains 893 speech samples, crowd-sourced from 4352 participants via a COVID-19 Sounds app. Voice features including Mel-spectrograms and Mel-frequency cepstral coefficients (MFCC) and CNN Encoder features are extracted. Based on the voice data, we develop deep learning classification models to detect COVID-19 cases. These models include Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) and Hidden-Unit BERT (HuBERT). We compare their predictive power to baseline machine learning models. HuBERT achieves the highest accuracy of 86\\% and the highest AUC of 0.93. The results achieved with the proposed models suggest promising results in COVID-19 diagnosis from voice recordings when compared to the results obtained from the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2402.07619",
    "authors": [
      "Yuyang Yan",
      "Wafaa Aljbawi",
      "Sami O. Simons",
      "Visara Urovi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.07621",
    "title": "Correctness Verification of Neural Networks Approximating Differential  Equations",
    "abstract": "Verification of Neural Networks (NNs) that approximate the solution of Partial Differential Equations (PDEs) is a major milestone towards enhancing their trustworthiness and accelerating their deployment, especially for safety-critical systems. If successful, such NNs can become integral parts of simulation software tools which can accelerate the simulation of complex dynamic systems more than 100 times. However, the verification of these functions poses major challenges; it is not straightforward how to efficiently bound them or how to represent the derivative of the NN. This work addresses both these problems. First, we define the NN derivative as a finite difference approximation. Then, we formulate the PDE residual bounding problem alongside the Initial Value Problem's error propagation. Finally, for the first time, we tackle the problem of bounding an NN function without a priori knowledge of the output domain. For this, we build a parallel branching algorithm that combines the incomplete CROWN solver and Gradient Attack for termination and domain rejection conditions. We demonstrate the strengths and weaknesses of the proposed framework, and we suggest further work to enhance its efficiency. ",
    "url": "https://arxiv.org/abs/2402.07621",
    "authors": [
      "Petros Ellinas",
      "Rahul Nellikath",
      "Ignasi Ventura",
      "Jochen Stiasny",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07630",
    "title": "G-Retriever: Retrieval-Augmented Generation for Textual Graph  Understanding and Question Answering",
    "abstract": "Given a graph with textual attributes, we enable users to `chat with their graph': that is, to ask questions about the graph using a conversational interface. In response to a user's questions, our method provides textual replies and highlights the relevant parts of the graph. While existing works integrate large language models (LLMs) and graph neural networks (GNNs) in various ways, they mostly focus on either conventional graph tasks (such as node, edge, and graph classification), or on answering simple graph queries on small or synthetic graphs. In contrast, we develop a flexible question-answering framework targeting real-world textual graphs, applicable to multiple applications including scene graph understanding, common sense reasoning, and knowledge graph reasoning. Toward this goal, we first develop our Graph Question Answering (GraphQA) benchmark with data collected from different tasks. Then, we propose our G-Retriever approach, which integrates the strengths of GNNs, LLMs, and Retrieval-Augmented Generation (RAG), and can be fine-tuned to enhance graph understanding via soft prompting. To resist hallucination and to allow for textual graphs that greatly exceed the LLM's context window size, G-Retriever performs RAG over a graph by formulating this task as a Prize-Collecting Steiner Tree optimization problem. Empirical evaluations show that our method outperforms baselines on textual graph tasks from multiple domains, scales well with larger graph sizes, and resists hallucination. (Our codes and datasets are available at: https://github.com/XiaoxinHe/G-Retriever.) ",
    "url": "https://arxiv.org/abs/2402.07630",
    "authors": [
      "Xiaoxin He",
      "Yijun Tian",
      "Yifei Sun",
      "Nitesh V. Chawla",
      "Thomas Laurent",
      "Yann LeCun",
      "Xavier Bresson",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07633",
    "title": "Complete Instances Mining for Weakly Supervised Instance Segmentation",
    "abstract": "Weakly supervised instance segmentation (WSIS) using only image-level labels is a challenging task due to the difficulty of aligning coarse annotations with the finer task. However, with the advancement of deep neural networks (DNNs), WSIS has garnered significant attention. Following a proposal-based paradigm, we encounter a redundant segmentation problem resulting from a single instance being represented by multiple proposals. For example, we feed a picture of a dog and proposals into the network and expect to output only one proposal containing a dog, but the network outputs multiple proposals. To address this problem, we propose a novel approach for WSIS that focuses on the online refinement of complete instances through the use of MaskIoU heads to predict the integrity scores of proposals and a Complete Instances Mining (CIM) strategy to explicitly model the redundant segmentation problem and generate refined pseudo labels. Our approach allows the network to become aware of multiple instances and complete instances, and we further improve its robustness through the incorporation of an Anti-noise strategy. Empirical evaluations on the PASCAL VOC 2012 and MS COCO datasets demonstrate that our method achieves state-of-the-art performance with a notable margin. Our implementation will be made available at https://github.com/ZechengLi19/CIM. ",
    "url": "https://arxiv.org/abs/2402.07633",
    "authors": [
      "Zecheng Li",
      "Zening Zeng",
      "Yuqi Liang",
      "Jin-Gang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07635",
    "title": "Collaborative Semantic Occupancy Prediction with Hybrid Feature Fusion  in Connected Automated Vehicles",
    "abstract": "Collaborative perception in automated vehicles leverages the exchange of information between agents, aiming to elevate perception results. Previous camera-based collaborative 3D perception methods typically employ 3D bounding boxes or bird's eye views as representations of the environment. However, these approaches fall short in offering a comprehensive 3D environmental prediction. To bridge this gap, we introduce the first method for collaborative 3D semantic occupancy prediction. Particularly, it improves local 3D semantic occupancy predictions by hybrid fusion of (i) semantic and occupancy task features, and (ii) compressed orthogonal attention features shared between vehicles. Additionally, due to the lack of a collaborative perception dataset designed for semantic occupancy prediction, we augment a current collaborative perception dataset to include 3D collaborative semantic occupancy labels for a more robust evaluation. The experimental findings highlight that: (i) our collaborative semantic occupancy predictions excel above the results from single vehicles by over 30%, and (ii) models anchored on semantic occupancy outpace state-of-the-art collaborative 3D detection techniques in subsequent perception applications, showcasing enhanced accuracy and enriched semantic-awareness in road environments. ",
    "url": "https://arxiv.org/abs/2402.07635",
    "authors": [
      "Rui Song",
      "Chenwei Liang",
      "Hu Cao",
      "Zhiran Yan",
      "Walter Zimmer",
      "Markus Gross",
      "Andreas Festag",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07642",
    "title": "A Flow-based Credibility Metric for Safety-critical Pedestrian Detection",
    "abstract": "Safety is of utmost importance for perception in automated driving (AD). However, a prime safety concern in state-of-the art object detection is that standard evaluation schemes utilize safety-agnostic metrics to argue sufficient detection performance. Hence, it is imperative to leverage supplementary domain knowledge to accentuate safety-critical misdetections during evaluation tasks. To tackle the underspecification, this paper introduces a novel credibility metric, called c-flow, for pedestrian bounding boxes. To this end, c-flow relies on a complementary optical flow signal from image sequences and enhances the analyses of safety-critical misdetections without requiring additional labels. We implement and evaluate c-flow with a state-of-the-art pedestrian detector on a large AD dataset. Our analysis demonstrates that c-flow allows developers to identify safety-critical misdetections. ",
    "url": "https://arxiv.org/abs/2402.07642",
    "authors": [
      "Maria Lyssenko",
      "Christoph Gladisch",
      "Christian Heinzemann",
      "Matthias Woehrle",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07648",
    "title": "DeformNet: Latent Space Modeling and Dynamics Prediction for Deformable  Object Manipulation",
    "abstract": "Manipulating deformable objects is a ubiquitous task in household environments, demanding adequate representation and accurate dynamics prediction due to the objects' infinite degrees of freedom. This work proposes DeformNet, which utilizes latent space modeling with a learned 3D representation model to tackle these challenges effectively. The proposed representation model combines a PointNet encoder and a conditional neural radiance field (NeRF), facilitating a thorough acquisition of object deformations and variations in lighting conditions. To model the complex dynamics, we employ a recurrent state-space model (RSSM) that accurately predicts the transformation of the latent representation over time. Extensive simulation experiments with diverse objectives demonstrate the generalization capabilities of DeformNet for various deformable object manipulation tasks, even in the presence of previously unseen goals. Finally, we deploy DeformNet on an actual UR5 robotic arm to demonstrate its capability in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2402.07648",
    "authors": [
      "Chenchang Li",
      "Zihao Ai",
      "Tong Wu",
      "Xiaosa Li",
      "Wenbo Ding",
      "Huazhe Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.07659",
    "title": "Multi-Behavior Collaborative Filtering with Partial Order Graph  Convolutional Networks",
    "abstract": "Representing the information of multiple behaviors in the single graph collaborative filtering (CF) vector has been a long-standing challenge. This is because different behaviors naturally form separate behavior graphs and learn separate CF embeddings. Existing models merge the separate embeddings by appointing the CF embeddings for some behaviors as the primary embedding and utilizing other auxiliaries to enhance the primary embedding. However, this approach often results in the joint embedding performing well on the main tasks but poorly on the auxiliary ones. To address the problem arising from the separate behavior graphs, we propose the concept of Partial Order Graphs (POG). POG defines the partial order relation of multiple behaviors and models behavior combinations as weighted edges to merge separate behavior graphs into a joint POG. Theoretical proof verifies that POG can be generalized to any given set of multiple behaviors. Based on POG, we propose the tailored Partial Order Graph Convolutional Networks (POGCN) that convolute neighbors' information while considering the behavior relations between users and items. POGCN also introduces a partial-order BPR sampling strategy for efficient and effective multiple-behavior CF training. POGCN has been successfully deployed on the homepage of Alibaba for two months, providing recommendation services for over one billion users. Extensive offline experiments conducted on three public benchmark datasets demonstrate that POGCN outperforms state-of-the-art multi-behavior baselines across all types of behaviors. Furthermore, online A/B tests confirm the superiority of POGCN in billion-scale recommender systems. ",
    "url": "https://arxiv.org/abs/2402.07659",
    "authors": [
      "Yijie Zhang",
      "Yuanchen Bei",
      "Hao Chen",
      "Qijie Shen",
      "Zheng Yuan",
      "Huan Gong",
      "Senzhang Wang",
      "Feiran Huang",
      "Xiao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.07680",
    "title": "AYDIV: Adaptable Yielding 3D Object Detection via Integrated Contextual  Vision Transformer",
    "abstract": "Combining LiDAR and camera data has shown potential in enhancing short-distance object detection in autonomous driving systems. Yet, the fusion encounters difficulties with extended distance detection due to the contrast between LiDAR's sparse data and the dense resolution of cameras. Besides, discrepancies in the two data representations further complicate fusion methods. We introduce AYDIV, a novel framework integrating a tri-phase alignment process specifically designed to enhance long-distance detection even amidst data discrepancies. AYDIV consists of the Global Contextual Fusion Alignment Transformer (GCFAT), which improves the extraction of camera features and provides a deeper understanding of large-scale patterns; the Sparse Fused Feature Attention (SFFA), which fine-tunes the fusion of LiDAR and camera details; and the Volumetric Grid Attention (VGA) for a comprehensive spatial data fusion. AYDIV's performance on the Waymo Open Dataset (WOD) with an improvement of 1.24% in mAPH value(L2 difficulty) and the Argoverse2 Dataset with a performance improvement of 7.40% in AP value demonstrates its efficacy in comparison to other existing fusion-based methods. Our code is publicly available at https://github.com/sanjay-810/AYDIV2 ",
    "url": "https://arxiv.org/abs/2402.07680",
    "authors": [
      "Tanmoy Dam",
      "Sanjay Bhargav Dharavath",
      "Sameer Alam",
      "Nimrod Lilith",
      "Supriyo Chakraborty",
      "Mir Feroskhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.07687",
    "title": "Privacy-Preserving Gaze Data Streaming in Immersive Interactive Virtual  Reality: Robustness and User Experience",
    "abstract": "Eye tracking is routinely being incorporated into virtual reality (VR) systems. Prior research has shown that eye tracking data can be used for re-identification attacks. The state of our knowledge about currently existing privacy mechanisms is limited to privacy-utility trade-off curves based on data-centric metrics of utility, such as prediction error, and black-box threat models. We propose that for interactive VR applications, it is essential to consider user-centric notions of utility and a variety of threat models. We develop a methodology to evaluate real-time privacy mechanisms for interactive VR applications that incorporate subjective user experience and task performance metrics. We evaluate selected privacy mechanisms using this methodology and find that re-identification accuracy can be decreased to as low as 14% while maintaining a high usability score and reasonable task performance. Finally, we elucidate three threat scenarios (black-box, black-box with exemplars, and white-box) and assess how well the different privacy mechanisms hold up to these adversarial scenarios. This work advances the state of the art in VR privacy by providing a methodology for end-to-end assessment of the risk of re-identification attacks and potential mitigating solutions. ",
    "url": "https://arxiv.org/abs/2402.07687",
    "authors": [
      "Ethan Wilson",
      "Azim Ibragimov",
      "Michael J. Proulx",
      "Sai Deep Tetali",
      "Kevin Butler",
      "Eakta Jain"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.07689",
    "title": "OrderBkd: Textual backdoor attack through repositioning",
    "abstract": "The use of third-party datasets and pre-trained machine learning models poses a threat to NLP systems due to possibility of hidden backdoor attacks. Existing attacks involve poisoning the data samples such as insertion of tokens or sentence paraphrasing, which either alter the semantics of the original texts or can be detected. Our main difference from the previous work is that we use the reposition of a two words in a sentence as a trigger. By designing and applying specific part-of-speech (POS) based rules for selecting these tokens, we maintain high attack success rate on SST-2 and AG classification datasets while outperforming existing attacks in terms of perplexity and semantic similarity to the clean samples. In addition, we show the robustness of our attack to the ONION defense method. All the code and data for the paper can be obtained at https://github.com/alekseevskaia/OrderBkd. ",
    "url": "https://arxiv.org/abs/2402.07689",
    "authors": [
      "Irina Alekseevskaia",
      "Konstantin Arkhipenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07714",
    "title": "Adaptive Artificial Immune Networks for Mitigating DoS flooding Attacks",
    "abstract": "Denial of service attacks pose a threat in constant growth. This is mainly due to their tendency to gain in sophistication, ease of implementation, obfuscation and the recent improvements in occultation of fingerprints. On the other hand, progress towards self-organizing networks, and the different techniques involved in their development, such as software-defined networking, network-function virtualization, artificial intelligence or cloud computing, facilitates the design of new defensive strategies, more complete, consistent and able to adapt the defensive deployment to the current status of the network. In order to contribute to their development, in this paper, the use of artificial immune systems to mitigate denial of service attacks is proposed. The approach is based on building networks of distributed sensors suited to the requirements of the monitored environment. These components are capable of identifying threats and reacting according to the behavior of the biological defense mechanisms in human beings. It is accomplished by emulating the different immune reactions, the establishment of quarantine areas and the construction of immune memory. For their assessment, experiments with public domain datasets (KDD'99, CAIDA'07 and CAIDA'08) and simulations on various network configurations based on traffic samples gathered by the University Complutense of Madrid and flooding attacks generated by the tool DDoSIM were performed. ",
    "url": "https://arxiv.org/abs/2402.07714",
    "authors": [
      "Jorge Maestre Vidal",
      "Ana Lucila Sandoval Orozco",
      "Luis Javier Garc\u00eda Villalba"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.07738",
    "title": "Universal link predictor by In-context Learning",
    "abstract": "Link prediction is a crucial task in graph machine learning, where the goal is to infer missing or future links within a graph. Traditional approaches leverage heuristic methods based on widely observed connectivity patterns, offering broad applicability and generalizability without the need for model training. Despite their utility, these methods are limited by their reliance on human-derived heuristics and lack the adaptability of data-driven approaches. Conversely, parametric link predictors excel in automatically learning the connectivity patterns from data and achieving state-of-the-art but fail short to directly transfer across different graphs. Instead, it requires the cost of extensive training and hyperparameter optimization to adapt to the target graph. In this work, we introduce the Universal Link Predictor (UniLP), a novel model that combines the generalizability of heuristic approaches with the pattern learning capabilities of parametric models. UniLP is designed to autonomously identify connectivity patterns across diverse graphs, ready for immediate application to any unseen graph dataset without targeted training. We address the challenge of conflicting connectivity patterns-arising from the unique distributions of different graphs-through the implementation of In-context Learning (ICL). This approach allows UniLP to dynamically adjust to various target graphs based on contextual demonstrations, thereby avoiding negative transfer. Through rigorous experimentation, we demonstrate UniLP's effectiveness in adapting to new, unseen graphs at test time, showcasing its ability to perform comparably or even outperform parametric models that have been finetuned for specific datasets. Our findings highlight UniLP's potential to set a new standard in link prediction, combining the strengths of heuristic and parametric methods in a single, versatile framework. ",
    "url": "https://arxiv.org/abs/2402.07738",
    "authors": [
      "Kaiwen Dong",
      "Haitao Mao",
      "Zhichun Guo",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07753",
    "title": "Engineering Weighted Connectivity Augmentation Algorithms",
    "abstract": "Increasing the connectivity of a graph is a pivotal challenge in robust network design. The weighted connectivity augmentation problem is a common version of the problem that takes link costs into consideration. The problem is then to find a minimum cost subset of a given set of weighted links that increases the connectivity of a graph by one when the links are added to the edge set of the input instance. In this work, we give a first implementation of recently discovered better-than-2 approximations. Furthermore, we propose three new heuristic and one exact approach. These include a greedy algorithm considering link costs and the number of unique cuts covered, an approach based on minimum spanning trees and a local search algorithm that may improve a given solution by swapping links of paths. Our exact approach uses an ILP formulation with efficient cut enumeration as well as a fast initialization routine. We then perform an extensive experimental evaluation which shows that our algorithms are faster and yield the best solutions compared to the current state-of-the-art as well as the recently discovered better-than-2 approximation algorithms. Our novel local search algorithm can improve solution quality even further. ",
    "url": "https://arxiv.org/abs/2402.07753",
    "authors": [
      "Marcelo Fonseca Faraj",
      "Ernestine Gro\u00dfmann",
      "Felix Joos",
      "Thomas M\u00f6ller",
      "Christian Schulz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.07757",
    "title": "Towards an Understanding of Stepwise Inference in Transformers: A  Synthetic Graph Navigation Model",
    "abstract": "Stepwise inference protocols, such as scratchpads and chain-of-thought, help language models solve complex problems by decomposing them into a sequence of simpler subproblems. Despite the significant gain in performance achieved via these protocols, the underlying mechanisms of stepwise inference have remained elusive. To address this, we propose to study autoregressive Transformer models on a synthetic task that embodies the multi-step nature of problems where stepwise inference is generally most useful. Specifically, we define a graph navigation problem wherein a model is tasked with traversing a path from a start to a goal node on the graph. Despite is simplicity, we find we can empirically reproduce and analyze several phenomena observed at scale: (i) the stepwise inference reasoning gap, the cause of which we find in the structure of the training data; (ii) a diversity-accuracy tradeoff in model generations as sampling temperature varies; (iii) a simplicity bias in the model's output; and (iv) compositional generalization and a primacy bias with in-context exemplars. Overall, our work introduces a grounded, synthetic framework for studying stepwise inference and offers mechanistic hypotheses that can lay the foundation for a deeper understanding of this phenomenon. ",
    "url": "https://arxiv.org/abs/2402.07757",
    "authors": [
      "Mikail Khona",
      "Maya Okawa",
      "Jan Hula",
      "Rahul Ramesh",
      "Kento Nishi",
      "Robert Dick",
      "Ekdeep Singh Lubana",
      "Hidenori Tanaka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07776",
    "title": "TELLER: A Trustworthy Framework for Explainable, Generalizable and  Controllable Fake News Detection",
    "abstract": "The proliferation of fake news has emerged as a severe societal problem, raising significant interest from industry and academia. While existing deep-learning based methods have made progress in detecting fake news accurately, their reliability may be compromised caused by the non-transparent reasoning processes, poor generalization abilities and inherent risks of integration with large language models (LLMs). To address this challenge, we propose {\\methodname}, a novel framework for trustworthy fake news detection that prioritizes explainability, generalizability and controllability of models. This is achieved via a dual-system framework that integrates cognition and decision systems, adhering to the principles above. The cognition system harnesses human expertise to generate logical predicates, which guide LLMs in generating human-readable logic atoms. Meanwhile, the decision system deduces generalizable logic rules to aggregate these atoms, enabling the identification of the truthfulness of the input news across diverse domains and enhancing transparency in the decision-making process. Finally, we present comprehensive evaluation results on four datasets, demonstrating the feasibility and trustworthiness of our proposed framework. Our implementation is available at \\url{https://github.com/less-and-less-bugs/Trust_TELLER}. ",
    "url": "https://arxiv.org/abs/2402.07776",
    "authors": [
      "Hui Liu",
      "Wenya Wang",
      "Haoru Li",
      "Haoliang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.07787",
    "title": "Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment  Analysis",
    "abstract": "Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information. Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models. Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs. EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of each granularity feature and their synergistic interactions, resulting in a cumulative effect without additional computational expenses. Experimental findings on SemEval 2014 and Twitter datasets confirm EMGF's superiority over existing ABSA methods. ",
    "url": "https://arxiv.org/abs/2402.07787",
    "authors": [
      "Xiaowei Zhao",
      "Yong Zhou",
      "Xiujuan Xu",
      "Yu Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07822",
    "title": "Understanding fitness landscapes in morpho-evolution via local optima  networks",
    "abstract": "Morpho-evolution (ME) refers to the simultaneous optimisation of a robot's design and controller to maximise performance given a task and environment. Many genetic encodings have been proposed which are capable of representing design and control. Previous research has provided empirical comparisons between encodings in terms of their performance with respect to an objective function and the diversity of designs that are evaluated, however there has been no attempt to explain the observed findings. We address this by applying Local Optima Network (LON) analysis to investigate the structure of the fitness landscapes induced by three different encodings when evolving a robot for a locomotion task, shedding new light on the ease by which different fitness landscapes can be traversed by a search process. This is the first time LON analysis has been applied in the field of ME despite its popularity in combinatorial optimisation domains; the findings will facilitate design of new algorithms or operators that are customised to ME landscapes in the future. ",
    "url": "https://arxiv.org/abs/2402.07822",
    "authors": [
      "Sarah L. Thomson",
      "L\u00e9ni K. Le Goff",
      "Emma Hart",
      "Edgar Buchanan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.07841",
    "title": "Do Membership Inference Attacks Work on Large Language Models?",
    "abstract": "Membership inference attacks (MIAs) attempt to predict whether a particular datapoint is a member of a target model's training data. Despite extensive research on traditional machine learning models, there has been limited work studying MIA on the pre-training data of large language models (LLMs). We perform a large-scale evaluation of MIAs over a suite of language models (LMs) trained on the Pile, ranging from 160M to 12B parameters. We find that MIAs barely outperform random guessing for most settings across varying LLM sizes and domains. Our further analyses reveal that this poor performance can be attributed to (1) the combination of a large dataset and few training iterations, and (2) an inherently fuzzy boundary between members and non-members. We identify specific settings where LLMs have been shown to be vulnerable to membership inference and show that the apparent success in such settings can be attributed to a distribution shift, such as when members and non-members are drawn from the seemingly identical domain but with different temporal ranges. We release our code and data as a unified benchmark package that includes all existing MIAs, supporting future work. ",
    "url": "https://arxiv.org/abs/2402.07841",
    "authors": [
      "Michael Duan",
      "Anshuman Suri",
      "Niloofar Mireshghallah",
      "Sewon Min",
      "Weijia Shi",
      "Luke Zettlemoyer",
      "Yulia Tsvetkov",
      "Yejin Choi",
      "David Evans",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.07844",
    "title": "Mercury: An Efficiency Benchmark for LLM Code Synthesis",
    "abstract": "Despite advancements in evaluating Large Language Models (LLMs) for code synthesis, benchmarks have predominantly focused on functional correctness, overlooking the importance of code efficiency. We present Mercury, the first benchmark designated for assessing the code efficiency of LLM code synthesis tasks. Mercury consists of 1,889 programming tasks covering diverse difficulty levels alongside test case generators generating unlimited cases for comprehensive evaluation. Unlike existing benchmarks, Mercury integrates a novel metric Beyond@K to measure normalized code efficiency based on historical submissions, leading to a new evaluation indicator for code synthesis, which encourages generating functionally correct and computationally efficient code, mirroring the real-world software development standard. Our findings reveal that while LLMs demonstrate the remarkable capability to generate functionally correct code, there still exists a substantial gap in their efficiency output, underscoring a new frontier for LLM research and development. ",
    "url": "https://arxiv.org/abs/2402.07844",
    "authors": [
      "Mingzhe Du",
      "Anh Tuan Luu",
      "Bin Ji",
      "See-Kiong Ng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.07851",
    "title": "Comparing skill of historical rainfall data based monsoon rainfall  prediction in India with NCEP-NWP forecasts",
    "abstract": "In this draft we consider the problem of forecasting rainfall across India during the four monsoon months, one day as well as three days in advance. We train neural networks using historical daily gridded precipitation data for India obtained from IMD for the time period $1901- 2022$, at a spatial resolution of $1^{\\circ} \\times 1^{\\circ}$. This is compared with the numerical weather prediction (NWP) forecasts obtained from NCEP (National Centre for Environmental Prediction) available for the period 2011-2022. We conduct a detailed country wide analysis and separately analyze some of the most populated cities in India. Our conclusion is that forecasts obtained by applying deep learning to historical rainfall data are more accurate compared to NWP forecasts as well as predictions based on persistence. On average, compared to our predictions, forecasts from NCEP-NWP model have about 34% higher error for a single day prediction, and over 68% higher error for a three day prediction. Similarly, persistence estimates report a 29% higher error in a single day forecast, and over 54% error in a three day forecast. We further observe that data up to 20 days in the past is useful in reducing errors of one and three day forecasts, when a transformer based learning architecture, and to a lesser extent when an LSTM is used. A key conclusion suggested by our preliminary analysis is that NWP forecasts can be substantially improved upon through more and diverse data relevant to monsoon prediction combined with carefully selected neural network architecture. ",
    "url": "https://arxiv.org/abs/2402.07851",
    "authors": [
      "Apoorva Narula",
      "Aastha Jain",
      "Jatin Batra",
      "Sandeep Juneja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07860",
    "title": "On the Detection of Reviewer-Author Collusion Rings From Paper Bidding",
    "abstract": "A major threat to the peer-review systems of computer science conferences is the existence of \"collusion rings\" between reviewers. In such collusion rings, reviewers who have also submitted their own papers to the conference work together to manipulate the conference's paper assignment, with the aim of being assigned to review each other's papers. The most straightforward way that colluding reviewers can manipulate the paper assignment is by indicating their interest in each other's papers through strategic paper bidding. One potential approach to solve this important problem would be to detect the colluding reviewers from their manipulated bids, after which the conference can take appropriate action. While prior work has has developed effective techniques to detect other kinds of fraud, no research has yet established that detecting collusion rings is even possible. In this work, we tackle the question of whether it is feasible to detect collusion rings from the paper bidding. To answer this question, we conduct empirical analysis of two realistic conference bidding datasets, including evaluations of existing algorithms for fraud detection in other applications. We find that collusion rings can achieve considerable success at manipulating the paper assignment while remaining hidden from detection: for example, in one dataset, undetected colluders are able to achieve assignment to up to 30% of the papers authored by other colluders. In addition, when 10 colluders bid on all of each other's papers, no detection algorithm outputs a group of reviewers with more than 31% overlap with the true colluders. These results suggest that collusion cannot be effectively detected from the bidding, demonstrating the need to develop more complex detection algorithms that leverage additional metadata. ",
    "url": "https://arxiv.org/abs/2402.07860",
    "authors": [
      "Steven Jecmen",
      "Nihar B. Shah",
      "Fei Fang",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2402.07867",
    "title": "PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented  Generation of Large Language Models",
    "abstract": "Large language models (LLMs) have achieved remarkable success due to their exceptional generative capabilities. Despite their success, they also have inherent limitations such as a lack of up-to-date knowledge and hallucination. Retrieval-Augmented Generation (RAG) is a state-of-the-art technique to mitigate those limitations. In particular, given a question, RAG retrieves relevant knowledge from a knowledge database to augment the input of the LLM. For instance, the retrieved knowledge could be a set of top-k texts that are most semantically similar to the given question when the knowledge database contains millions of texts collected from Wikipedia. As a result, the LLM could utilize the retrieved knowledge as the context to generate an answer for the given question. Existing studies mainly focus on improving the accuracy or efficiency of RAG, leaving its security largely unexplored. We aim to bridge the gap in this work. Particularly, we propose PoisonedRAG , a set of knowledge poisoning attacks to RAG, where an attacker could inject a few poisoned texts into the knowledge database such that the LLM generates an attacker-chosen target answer for an attacker-chosen target question. We formulate knowledge poisoning attacks as an optimization problem, whose solution is a set of poisoned texts. Depending on the background knowledge (e.g., black-box and white-box settings) of an attacker on the RAG, we propose two solutions to solve the optimization problem, respectively. Our results on multiple benchmark datasets and LLMs show our attacks could achieve 90% attack success rates when injecting 5 poisoned texts for each target question into a database with millions of texts. We also evaluate recent defenses and our results show they are insufficient to defend against our attacks, highlighting the need for new defenses. ",
    "url": "https://arxiv.org/abs/2402.07867",
    "authors": [
      "Wei Zou",
      "Runpeng Geng",
      "Binghui Wang",
      "Jinyuan Jia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07878",
    "title": "Using Graph Theory for Improving Machine Learning-based Detection of  Cyber Attacks",
    "abstract": "Early detection of network intrusions and cyber threats is one of the main pillars of cybersecurity. One of the most effective approaches for this purpose is to analyze network traffic with the help of artificial intelligence algorithms, with the aim of detecting the possible presence of an attacker by distinguishing it from a legitimate user. This is commonly done by collecting the traffic exchanged between terminals in a network and analyzing it on a per-packet or per-connection basis. In this paper, we propose instead to perform pre-processing of network traffic under analysis with the aim of extracting some new metrics on which we can perform more efficient detection and overcome some limitations of classical approaches. These new metrics are based on graph theory, and consider the network as a whole, rather than focusing on individual packets or connections. Our approach is validated through experiments performed on publicly available data sets, from which it results that it can not only overcome some of the limitations of classical approaches, but also achieve a better detection capability of cyber threats. ",
    "url": "https://arxiv.org/abs/2402.07878",
    "authors": [
      "Giacomo Zonneveld",
      "Lorenzo Principi",
      "Marco Baldi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07884",
    "title": "Distributed Anomaly Detection in Modern Power Systems: A Penalty-based  Mitigation Approach",
    "abstract": "The evolving landscape of electric power networks, influenced by the integration of distributed energy resources require the development of novel power system monitoring and control architectures. This paper develops algorithm to monitor and detect anomalies of different parts of a power system that cannot be measured directly, by applying neighboring measurements and a dynamic probing technique in a distributed fashion. Additionally, the proposed method accurately assesses the severity of the anomaly. A decision-making algorithm is introduced to effectively penalize anomalous agents, ensuring vigilant oversight of the entire power system's functioning. Simulation results show the efficacy of algorithms in distributed anomaly detection and mitigation. ",
    "url": "https://arxiv.org/abs/2402.07884",
    "authors": [
      "Erfan Mehdipour Abadi",
      "Masoud H. Nazari"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.07894",
    "title": "MODIPHY: Multimodal Obscured Detection for IoT using PHantom  Convolution-Enabled Faster YOLO",
    "abstract": "Low-light conditions and occluded scenarios impede object detection in real-world Internet of Things (IoT) applications like autonomous vehicles and security systems. While advanced machine learning models strive for accuracy, their computational demands clash with the limitations of resource-constrained devices, hampering real-time performance. In our current research, we tackle this challenge, by introducing \"YOLO Phantom\", one of the smallest YOLO models ever conceived. YOLO Phantom utilizes the novel Phantom Convolution block, achieving comparable accuracy to the latest YOLOv8n model while simultaneously reducing both parameters and model size by 43%, resulting in a significant 19% reduction in Giga Floating Point Operations (GFLOPs). YOLO Phantom leverages transfer learning on our multimodal RGB-infrared dataset to address low-light and occlusion issues, equipping it with robust vision under adverse conditions. Its real-world efficacy is demonstrated on an IoT platform with advanced low-light and RGB cameras, seamlessly connecting to an AWS-based notification endpoint for efficient real-time object detection. Benchmarks reveal a substantial boost of 17% and 14% in frames per second (FPS) for thermal and RGB detection, respectively, compared to the baseline YOLOv8n model. For community contribution, both the code and the multimodal dataset are available on GitHub. ",
    "url": "https://arxiv.org/abs/2402.07894",
    "authors": [
      "Shubhabrata Mukherjee",
      "Cory Beard",
      "Zhu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07895",
    "title": "Detection of Spider Mites on Labrador Beans through Machine Learning  Approaches Using Custom Datasets",
    "abstract": "Amidst growing food production demands, early plant disease detection is essential to safeguard crops; this study proposes a visual machine learning approach for plant disease detection, harnessing RGB and NIR data collected in real-world conditions through a JAI FS-1600D-10GE camera to build an RGBN dataset. A two-stage early plant disease detection model with YOLOv8 and a sequential CNN was used to train on a dataset with partial labels, which showed a 3.6% increase in mAP compared to a single-stage end-to-end segmentation model. The sequential CNN model achieved 90.62% validation accuracy utilising RGBN data. An average of 6.25% validation accuracy increase is found using RGBN in classification compared to RGB using ResNet15 and the sequential CNN models. Further research and dataset improvements are needed to meet food production demands. ",
    "url": "https://arxiv.org/abs/2402.07895",
    "authors": [
      "Violet Liu",
      "Jason Chen",
      "Ans Qureshi",
      "Mahla Nejati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.06633",
    "title": "MDGNN: Multi-Relational Dynamic Graph Neural Network for Comprehensive  and Dynamic Stock Investment Prediction",
    "abstract": "The stock market is a crucial component of the financial system, but predicting the movement of stock prices is challenging due to the dynamic and intricate relations arising from various aspects such as economic indicators, financial reports, global news, and investor sentiment. Traditional sequential methods and graph-based models have been applied in stock movement prediction, but they have limitations in capturing the multifaceted and temporal influences in stock price movements. To address these challenges, the Multi-relational Dynamic Graph Neural Network (MDGNN) framework is proposed, which utilizes a discrete dynamic graph to comprehensively capture multifaceted relations among stocks and their evolution over time. The representation generated from the graph offers a complete perspective on the interrelationships among stocks and associated entities. Additionally, the power of the Transformer structure is leveraged to encode the temporal evolution of multiplex relations, providing a dynamic and effective approach to predicting stock investment. Further, our proposed MDGNN framework achieves the best performance in public datasets compared with state-of-the-art (SOTA) stock investment methods. ",
    "url": "https://arxiv.org/abs/2402.06633",
    "authors": [
      "Hao Qian",
      "Hongting Zhou",
      "Qian Zhao",
      "Hao Chen",
      "Hongxiang Yao",
      "Jingwei Wang",
      "Ziqi Liu",
      "Fei Yu",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06642",
    "title": "From GARCH to Neural Network for Volatility Forecast",
    "abstract": "Volatility, as a measure of uncertainty, plays a crucial role in numerous financial activities such as risk management. The Econometrics and Machine Learning communities have developed two distinct approaches for financial volatility forecasting: the stochastic approach and the neural network (NN) approach. Despite their individual strengths, these methodologies have conventionally evolved in separate research trajectories with little interaction between them. This study endeavors to bridge this gap by establishing an equivalence relationship between models of the GARCH family and their corresponding NN counterparts. With the equivalence relationship established, we introduce an innovative approach, named GARCH-NN, for constructing NN-based volatility models. It obtains the NN counterparts of GARCH models and integrates them as components into an established NN architecture, thereby seamlessly infusing volatility stylized facts (SFs) inherent in the GARCH models into the neural network. We develop the GARCH-LSTM model to showcase the power of the GARCH-NN approach. Experiment results validate that amalgamating the NN counterparts of the GARCH family models into established NN models leads to enhanced outcomes compared to employing the stochastic and NN models in isolation. ",
    "url": "https://arxiv.org/abs/2402.06642",
    "authors": [
      "Pengfei Zhao",
      "Haoren Zhu",
      "Wilfred Siu Hung NG",
      "Dik Lun Lee"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06656",
    "title": "DiffsFormer: A Diffusion Transformer on Stock Factor Augmentation",
    "abstract": "Machine learning models have demonstrated remarkable efficacy and efficiency in a wide range of stock forecasting tasks. However, the inherent challenges of data scarcity, including low signal-to-noise ratio (SNR) and data homogeneity, pose significant obstacles to accurate forecasting. To address this issue, we propose a novel approach that utilizes artificial intelligence-generated samples (AIGS) to enhance the training procedures. In our work, we introduce the Diffusion Model to generate stock factors with Transformer architecture (DiffsFormer). DiffsFormer is initially trained on a large-scale source domain, incorporating conditional guidance so as to capture global joint distribution. When presented with a specific downstream task, we employ DiffsFormer to augment the training procedure by editing existing samples. This editing step allows us to control the strength of the editing process, determining the extent to which the generated data deviates from the target domain. To evaluate the effectiveness of DiffsFormer augmented training, we conduct experiments on the CSI300 and CSI800 datasets, employing eight commonly used machine learning models. The proposed method achieves relative improvements of 7.2% and 27.8% in annualized return ratio for the respective datasets. Furthermore, we perform extensive experiments to gain insights into the functionality of DiffsFormer and its constituent components, elucidating how they address the challenges of data scarcity and enhance the overall model performance. Our research demonstrates the efficacy of leveraging AIGS and the DiffsFormer architecture to mitigate data scarcity in stock forecasting tasks. ",
    "url": "https://arxiv.org/abs/2402.06656",
    "authors": [
      "Yuan Gao",
      "Haokun Chen",
      "Xiang Wang",
      "Zhicai Wang",
      "Xue Wang",
      "Jinyang Gao",
      "Bolin Ding"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06666",
    "title": "Weather Prediction with Diffusion Guided by Realistic Forecast Processes",
    "abstract": "Weather forecasting remains a crucial yet challenging domain, where recently developed models based on deep learning (DL) have approached the performance of traditional numerical weather prediction (NWP) models. However, these DL models, often complex and resource-intensive, face limitations in flexibility post-training and in incorporating NWP predictions, leading to reliability concerns due to potential unphysical predictions. In response, we introduce a novel method that applies diffusion models (DM) for weather forecasting. In particular, our method can achieve both direct and iterative forecasting with the same modeling framework. Our model is not only capable of generating forecasts independently but also uniquely allows for the integration of NWP predictions, even with varying lead times, during its sampling process. The flexibility and controllability of our model empowers a more trustworthy DL system for the general weather community. Additionally, incorporating persistence and climatology data further enhances our model's long-term forecasting stability. Our empirical findings demonstrate the feasibility and generalizability of this approach, suggesting a promising direction for future, more sophisticated diffusion models without the need for retraining. ",
    "url": "https://arxiv.org/abs/2402.06666",
    "authors": [
      "Zhanxiang Hua",
      "Yutong He",
      "Chengqian Ma",
      "Alexandra Anderson-Frey"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06680",
    "title": "Social Physics Informed Diffusion Model for Crowd Simulation",
    "abstract": "Crowd simulation holds crucial applications in various domains, such as urban planning, architectural design, and traffic arrangement. In recent years, physics-informed machine learning methods have achieved state-of-the-art performance in crowd simulation but fail to model the heterogeneity and multi-modality of human movement comprehensively. In this paper, we propose a social physics-informed diffusion model named SPDiff to mitigate the above gap. SPDiff takes both the interactive and historical information of crowds in the current timeframe to reverse the diffusion process, thereby generating the distribution of pedestrian movement in the subsequent timeframe. Inspired by the well-known social physics model, i.e., Social Force, regarding crowd dynamics, we design a crowd interaction module to guide the denoising process and further enhance this module with the equivariant properties of crowd interactions. To mitigate error accumulation in long-term simulations, we propose a multi-frame rollout training algorithm for diffusion modeling. Experiments conducted on two real-world datasets demonstrate the superior performance of SPDiff in terms of macroscopic and microscopic evaluation metrics. Code and appendix are available at https://github.com/tsinghua-fib-lab/SPDiff. ",
    "url": "https://arxiv.org/abs/2402.06680",
    "authors": [
      "Hongyi Chen",
      "Jingtao Ding",
      "Yong Li",
      "Yue Wang",
      "Xiao-Ping Zhang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06753",
    "title": "Shortest-path percolation on complex networks",
    "abstract": "We propose a bond-percolation model intended to describe the consumption, and eventual exhaustion, of resources in transport networks. Edges forming minimum-length paths connecting demanded origin-destination nodes are removed if below a certain budget. As pairs of nodes are demanded and edges are removed, the macroscopic connected component of the graph disappears, i.e., the graph undergoes a percolation transition. Here, we study such a shortest-path-percolation transition in homogeneous random graphs where pairs of demanded origin-destination nodes are randomly generated, and fully characterize it by means of finite-size scaling analysis. If budget is finite, the transition is identical to the one of ordinary percolation, where a single giant cluster shrinks as edges are removed from the graph; for infinite budget, the transition becomes more abrupt than the one of ordinary percolation, being characterized by the sudden fragmentation of the giant connected component into a multitude of clusters of similar size. ",
    "url": "https://arxiv.org/abs/2402.06753",
    "authors": [
      "Minsuk Kim",
      "Filippo Radicchi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.06772",
    "title": "Retrosynthesis Prediction via Search in (Hyper) Graph",
    "abstract": "Predicting reactants from a specified core product stands as a fundamental challenge within organic synthesis, termed retrosynthesis prediction. Recently, semi-template-based methods and graph-edits-based methods have achieved good performance in terms of both interpretability and accuracy. However, due to their mechanisms these methods cannot predict complex reactions, e.g., reactions with multiple reaction center or attaching the same leaving group to more than one atom. In this study we propose a semi-template-based method, the \\textbf{Retro}synthesis via \\textbf{S}earch \\textbf{i}n (Hyper) \\textbf{G}raph (RetroSiG) framework to alleviate these limitations. In the proposed method, we turn the reaction center identification and the leaving group completion tasks as tasks of searching in the product molecular graph and leaving group hypergraph respectively. As a semi-template-based method RetroSiG has several advantages. First, RetroSiG is able to handle the complex reactions mentioned above by its novel search mechanism. Second, RetroSiG naturally exploits the hypergraph to model the implicit dependencies between leaving groups. Third, RetroSiG makes full use of the prior, i.e., one-hop constraint. It reduces the search space and enhances overall performance. Comprehensive experiments demonstrated that RetroSiG achieved competitive results. Furthermore, we conducted experiments to show the capability of RetroSiG in predicting complex reactions. Ablation experiments verified the efficacy of specific elements, such as the one-hop constraint and the leaving group hypergraph. ",
    "url": "https://arxiv.org/abs/2402.06772",
    "authors": [
      "Zixun Lan",
      "Binjie Hong",
      "Jiajun Zhu",
      "Zuo Zeng",
      "Zhenfu Liu",
      "Limin Yu",
      "Fei Ma"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06856",
    "title": "Community detection in the hypergraph stochastic block model and  reconstruction on hypertrees",
    "abstract": "We study the weak recovery problem on the $r$-uniform hypergraph stochastic block model ($r$-HSBM) with two balanced communities. In this model, $n$ vertices are randomly divided into two communities, and size-$r$ hyperedges are added randomly depending on whether all vertices in the hyperedge are in the same community. The goal of the weak recovery problem is to recover a non-trivial fraction of the communities given the hypergraph. Previously, Pal and Zhu (2021) established that weak recovery is always possible above a natural threshold called the Kesten-Stigum (KS) threshold. Gu and Polyanskiy (2023) proved that the KS threshold is tight if $r\\le 4$ or the expected degree $d$ is small. It remained open whether the KS threshold is tight for $r\\ge 5$ and large $d$. In this paper we determine the tightness of the KS threshold for any fixed $r$ and large $d$. We prove that for $r\\le 6$ and $d$ large enough, the KS threshold is tight. This shows that there is no information-computation gap in this regime. This partially confirms a conjecture of Angelini et al. (2015). For $r\\ge 7$, we prove that for $d$ large enough, the KS threshold is not tight, providing more evidence supporting the existence of an information-computation gap in this regime. Furthermore, we establish asymptotic bounds on the weak recovery threshold for fixed $r$ and large $d$. We also obtain a number of results regarding the closely-related broadcasting on hypertrees (BOHT) model, including the asymptotics of the reconstruction threshold for $r\\ge 7$ and impossibility of robust reconstruction at criticality. ",
    "url": "https://arxiv.org/abs/2402.06856",
    "authors": [
      "Yuzhou Gu",
      "Aaradhya Pandey"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.06884",
    "title": "Low-Rank Approximation of Structural Redundancy for Self-Supervised  Learning",
    "abstract": "We study the data-generating mechanism for reconstructive SSL to shed light on its effectiveness. With an infinite amount of labeled samples, we provide a sufficient and necessary condition for perfect linear approximation. The condition reveals a full-rank component that preserves the label classes of Y, along with a redundant component. Motivated by the condition, we propose to approximate the redundant component by a low-rank factorization and measure the approximation quality by introducing a new quantity $\\epsilon_s$, parameterized by the rank of factorization s. We incorporate $\\epsilon_s$ into the excess risk analysis under both linear regression and ridge regression settings, where the latter regularization approach is to handle scenarios when the dimension of the learned features is much larger than the number of labeled samples n for downstream tasks. We design three stylized experiments to compare SSL with supervised learning under different settings to support our theoretical findings. ",
    "url": "https://arxiv.org/abs/2402.06884",
    "authors": [
      "Kang Du",
      "Yu Xiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06888",
    "title": "Analysis of Self-Supervised Speech Models on Children's Speech and  Infant Vocalizations",
    "abstract": "To understand why self-supervised learning (SSL) models have empirically achieved strong performances on several speech-processing downstream tasks, numerous studies have focused on analyzing the encoded information of the SSL layer representations in adult speech. Limited work has investigated how pre-training and fine-tuning affect SSL models encoding children's speech and vocalizations. In this study, we aim to bridge this gap by probing SSL models on two relevant downstream tasks: (1) phoneme recognition (PR) on the speech of adults, older children (8-10 years old), and younger children (1-4 years old), and (2) vocalization classification (VC) distinguishing cry, fuss, and babble for infants under 14 months old. For younger children's PR, the superiority of fine-tuned SSL models is largely due to their ability to learn features that represent older children's speech and then adapt those features to the speech of younger children. For infant VC, SSL models pre-trained on large-scale home recordings learn to leverage phonetic representations at middle layers, and thereby enhance the performance of this task. ",
    "url": "https://arxiv.org/abs/2402.06888",
    "authors": [
      "Jialu Li",
      "Mark Hasegawa-Johnson",
      "Nancy L. McElwain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.06923",
    "title": "CochCeps-Augment: A Novel Self-Supervised Contrastive Learning Using  Cochlear Cepstrum-based Masking for Speech Emotion Recognition",
    "abstract": "Self-supervised learning (SSL) for automated speech recognition in terms of its emotional content, can be heavily degraded by the presence noise, affecting the efficiency of modeling the intricate temporal and spectral informative structures of speech. Recently, SSL on large speech datasets, as well as new audio-specific SSL proxy tasks, such as, temporal and frequency masking, have emerged, yielding superior performance compared to classic approaches drawn from the image augmentation domain. Our proposed contribution builds upon this successful paradigm by introducing CochCeps-Augment, a novel bio-inspired masking augmentation task for self-supervised contrastive learning of speech representations. Specifically, we utilize the newly introduced bio-inspired cochlear cepstrogram (CCGRAM) to derive noise robust representations of input speech, that are then further refined through a self-supervised learning scheme. The latter employs SimCLR to generate contrastive views of a CCGRAM through masking of its angle and quefrency dimensions. Our experimental approach and validations on the emotion recognition K-EmoCon benchmark dataset, for the first time via a speaker-independent approach, features unsupervised pre-training, linear probing and fine-tuning. Our results potentiate CochCeps-Augment to serve as a standard tool in speech emotion recognition analysis, showing the added value of incorporating bio-inspired masking as an informative augmentation task for self-supervision. Our code for implementing CochCeps-Augment will be made available at: https://github.com/GiannisZgs/CochCepsAugment. ",
    "url": "https://arxiv.org/abs/2402.06923",
    "authors": [
      "Ioannis Ziogas",
      "Hessa Alfalahi",
      "Ahsan H. Khandoker",
      "Leontios J. Hadjileontiadis"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.07025",
    "title": "Generalization Error of Graph Neural Networks in the Mean-field Regime",
    "abstract": "This work provides a theoretical framework for assessing the generalization error of graph classification tasks via graph neural networks in the over-parameterized regime, where the number of parameters surpasses the quantity of data points. We explore two widely utilized types of graph neural networks: graph convolutional neural networks and message passing graph neural networks. Prior to this study, existing bounds on the generalization error in the over-parametrized regime were uninformative, limiting our understanding of over-parameterized network performance. Our novel approach involves deriving upper bounds within the mean-field regime for evaluating the generalization error of these graph neural networks. We establish upper bounds with a convergence rate of $O(1/n)$, where $n$ is the number of graph samples. These upper bounds offer a theoretical assurance of the networks' performance on unseen data in the challenging over-parameterized regime and overall contribute to our understanding of their performance. ",
    "url": "https://arxiv.org/abs/2402.07025",
    "authors": [
      "Gholamali Aminian",
      "Yixuan He",
      "Gesine Reinert",
      "\u0141ukasz Szpruch",
      "Samuel N. Cohen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07192",
    "title": "Spatio-spectral classification of hyperspectral images for brain cancer  detection during surgical operations",
    "abstract": "Surgery for brain cancer is a major problem in neurosurgery. The diffuse infiltration into the surrounding normal brain by these tumors makes their accurate identification by the naked eye difficult. Since surgery is the common treatment for brain cancer, an accurate radical resection of the tumor leads to improved survival rates for patients. However, the identification of the tumor boundaries during surgery is challenging. Hyperspectral imaging is a noncontact, non-ionizing and non-invasive technique suitable for medical diagnosis. This study presents the development of a novel classification method taking into account the spatial and spectral characteristics of the hyperspectral images to help neurosurgeons to accurately determine the tumor boundaries in surgical-time during the resection, avoiding excessive excision of normal tissue or unintentionally leaving residual tumor. The algorithm proposed in this study to approach an efficient solution consists of a hybrid framework that combines both supervised and unsupervised machine learning methods. To evaluate the proposed approach, five hyperspectral images of surface of the brain affected by glioblastoma tumor in vivo from five different patients have been used. The final classification maps obtained have been analyzed and validated by specialists. These preliminary results are promising, obtaining an accurate delineation of the tumor area. ",
    "url": "https://arxiv.org/abs/2402.07192",
    "authors": [
      "H. Fabelo",
      "S. Ortega",
      "D. Ravi",
      "B. R. Kiran",
      "C. Sosa",
      "D. Bulters",
      "G. M. Callico",
      "H. Bulstrode",
      "A. Szolna",
      "J. F. Pineiro",
      "S. Kabwama",
      "D. Madronal",
      "R. Lazcano",
      "A. J. OShanahan",
      "S. Bisshopp",
      "M. Hernandez",
      "A. Baez-Quevedo",
      "G. Z. Yang",
      "B. Stanciulescu",
      "R. Salvador",
      "E. Juarez",
      "R. Sarmiento"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07307",
    "title": "Self-Consistent Conformal Prediction",
    "abstract": "In decision-making guided by machine learning, decision-makers often take identical actions in contexts with identical predicted outcomes. Conformal prediction helps decision-makers quantify outcome uncertainty for actions, allowing for better risk management. Inspired by this perspective, we introduce self-consistent conformal prediction, which yields both Venn-Abers calibrated predictions and conformal prediction intervals that are valid conditional on actions prompted by model predictions. Our procedure can be applied post-hoc to any black-box predictor to provide rigorous, action-specific decision-making guarantees. Numerical experiments show our approach strikes a balance between interval efficiency and conditional validity. ",
    "url": "https://arxiv.org/abs/2402.07307",
    "authors": [
      "Lars van der Laan",
      "Ahmed M. Alaa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.07357",
    "title": "Regression Trees for Fast and Adaptive Prediction Intervals",
    "abstract": "Predictive models make mistakes. Hence, there is a need to quantify the uncertainty associated with their predictions. Conformal inference has emerged as a powerful tool to create statistically valid prediction regions around point predictions, but its naive application to regression problems yields non-adaptive regions. New conformal scores, often relying upon quantile regressors or conditional density estimators, aim to address this limitation. Although they are useful for creating prediction bands, these scores are detached from the original goal of quantifying the uncertainty around an arbitrary predictive model. This paper presents a new, model-agnostic family of methods to calibrate prediction intervals for regression problems with local coverage guarantees. Our approach is based on pursuing the coarsest partition of the feature space that approximates conditional coverage. We create this partition by training regression trees and Random Forests on conformity scores. Our proposal is versatile, as it applies to various conformity scores and prediction settings and demonstrates superior scalability and performance compared to established baselines in simulated and real-world datasets. We provide a Python package locart that implements our methods using the standard scikit-learn interface. ",
    "url": "https://arxiv.org/abs/2402.07357",
    "authors": [
      "Luben M. C. Cabezas",
      "Mateus P. Otto",
      "Rafael Izbicki",
      "Rafael B. Stern"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07365",
    "title": "A Deep Learning Method for Optimal Investment Under Relative Performance  Criteria Among Heterogeneous Agents",
    "abstract": "Graphon games have been introduced to study games with many players who interact through a weighted graph of interaction. By passing to the limit, a game with a continuum of players is obtained, in which the interactions are through a graphon. In this paper, we focus on a graphon game for optimal investment under relative performance criteria, and we propose a deep learning method. The method builds upon two key ingredients: first, a characterization of Nash equilibria by forward-backward stochastic differential equations and, second, recent advances of machine learning algorithms for stochastic differential games. We provide numerical experiments on two different financial models. In each model, we compare the effect of several graphons, which correspond to different structures of interactions. ",
    "url": "https://arxiv.org/abs/2402.07365",
    "authors": [
      "Mathieu Lauri\u00e8re",
      "Ludovic Tangpi",
      "Xuchen Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07463",
    "title": "PyDMD: A Python package for robust dynamic mode decomposition",
    "abstract": "The dynamic mode decomposition (DMD) is a simple and powerful data-driven modeling technique that is capable of revealing coherent spatiotemporal patterns from data. The method's linear algebra-based formulation additionally allows for a variety of optimizations and extensions that make the algorithm practical and viable for real-world data analysis. As a result, DMD has grown to become a leading method for dynamical system analysis across multiple scientific disciplines. PyDMD is a Python package that implements DMD and several of its major variants. In this work, we expand the PyDMD package to include a number of cutting-edge DMD methods and tools specifically designed to handle dynamics that are noisy, multiscale, parameterized, prohibitively high-dimensional, or even strongly nonlinear. We provide a complete overview of the features available in PyDMD as of version 1.0, along with a brief overview of the theory behind the DMD algorithm, information for developers, tips regarding practical DMD usage, and introductory coding examples. All code is available at https://github.com/PyDMD/PyDMD . ",
    "url": "https://arxiv.org/abs/2402.07463",
    "authors": [
      "Sara M. Ichinaga",
      "Francesco Andreuzzi",
      "Nicola Demo",
      "Marco Tezzele",
      "Karl Lapo",
      "Gianluigi Rozza",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2402.07492",
    "title": "Convolutional Neural Networks for signal detection in real LIGO data",
    "abstract": "Searching the data of gravitational-wave detectors for signals from compact binary mergers is a computationally demanding task. Recently, machine learning algorithms have been proposed to address current and future challenges. However, the results of these publications often differ greatly due to differing choices in the evaluation procedure. The Machine Learning Gravitational-Wave Search Challenge was organized to resolve these issues and produce a unified framework for machine-learning search evaluation. Six teams submitted contributions, four of which are based on machine learning methods and two are state-of-the-art production analyses. This paper describes the submission from the team TPI FSU Jena and its updated variant. We also apply our algorithm to real O3b data and recover the relevant events of the GWTC-3 catalog. ",
    "url": "https://arxiv.org/abs/2402.07492",
    "authors": [
      "Ond\u0159ej Zelenka",
      "Bernd Br\u00fcgmann",
      "Frank Ohme"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2402.07637",
    "title": "Compressive Recovery of Signals Defined on Perturbed Graphs",
    "abstract": "Recovery of signals with elements defined on the nodes of a graph, from compressive measurements is an important problem, which can arise in various domains such as sensor networks, image reconstruction and group testing. In some scenarios, the graph may not be accurately known, and there may exist a few edge additions or deletions relative to a ground truth graph. Such perturbations, even if small in number, significantly affect the Graph Fourier Transform (GFT). This impedes recovery of signals which may have sparse representations in the GFT bases of the ground truth graph. We present an algorithm which simultaneously recovers the signal from the compressive measurements and also corrects the graph perturbations. We analyze some important theoretical properties of the algorithm. Our approach to correction for graph perturbations is based on model selection techniques such as cross-validation in compressed sensing. We validate our algorithm on signals which have a sparse representation in the GFT bases of many commonly used graphs in the network science literature. An application to compressive image reconstruction is also presented, where graph perturbations are modeled as undesirable graph edges linking pixels with significant intensity difference. In all experiments, our algorithm clearly outperforms baseline techniques which either ignore the perturbations or use first order approximations to the perturbations in the GFT bases. ",
    "url": "https://arxiv.org/abs/2402.07637",
    "authors": [
      "Sabyasachi Ghosh",
      "Ajit Rajwade"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.07684",
    "title": "Towards a Foundation Model for Brain Age Prediction using coVariance  Neural Networks",
    "abstract": "Brain age is the estimate of biological age derived from neuroimaging datasets using machine learning algorithms. Increasing brain age with respect to chronological age can reflect increased vulnerability to neurodegeneration and cognitive decline. In this paper, we study NeuroVNN, based on coVariance neural networks, as a paradigm for foundation model for the brain age prediction application. NeuroVNN is pre-trained as a regression model on healthy population to predict chronological age using cortical thickness features and fine-tuned to estimate brain age in different neurological contexts. Importantly, NeuroVNN adds anatomical interpretability to brain age and has a `scale-free' characteristic that allows its transference to datasets curated according to any arbitrary brain atlas. Our results demonstrate that NeuroVNN can extract biologically plausible brain age estimates in different populations, as well as transfer successfully to datasets of dimensionalities distinct from that for the dataset used to train NeuroVNN. ",
    "url": "https://arxiv.org/abs/2402.07684",
    "authors": [
      "Saurabh Sihag",
      "Gonzalo Mateos",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2402.07735",
    "title": "Graph Structure Inference with BAM: Introducing the Bilinear Attention  Mechanism",
    "abstract": "In statistics and machine learning, detecting dependencies in datasets is a central challenge. We propose a novel neural network model for supervised graph structure learning, i.e., the process of learning a mapping between observational data and their underlying dependence structure. The model is trained with variably shaped and coupled simulated input data and requires only a single forward pass through the trained network for inference. By leveraging structural equation models and employing randomly generated multivariate Chebyshev polynomials for the simulation of training data, our method demonstrates robust generalizability across both linear and various types of non-linear dependencies. We introduce a novel bilinear attention mechanism (BAM) for explicit processing of dependency information, which operates on the level of covariance matrices of transformed data and respects the geometry of the manifold of symmetric positive definite matrices. Empirical evaluation demonstrates the robustness of our method in detecting a wide range of dependencies, excelling in undirected graph estimation and proving competitive in completed partially directed acyclic graph estimation through a novel two-step approach. ",
    "url": "https://arxiv.org/abs/2402.07735",
    "authors": [
      "Philipp Froehlich",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.07759",
    "title": "Robust and accurate simulations of flows over orography using  non-conforming meshes",
    "abstract": "We systematically validate the static local mesh refinement capabilities of a recently proposed IMEX-DG scheme implemented in the framework of the deal.II library. Non-conforming meshes are employed in atmospheric flow simulations to increase the resolution around complex orography. A number of numerical experiments based on classical benchmarks with idealized as well as real orography profiles demonstrate that simulations with the refined mesh are stable for long lead times and no spurious effects arise at the interfaces of mesh regions with different resolutions. Moreover, correct values of the momentum flux are retrieved and the correct large-scale orographic response is established. Hence, large-scale orography-driven flow features can be simulated without loss of accuracy using a much lower total amount of degrees of freedom. In a context of spatial resolutions approaching the hectometric scale in numerical weather prediction models, these results support the use of locally refined, non-conforming meshes as a reliable and effective tool to greatly reduce the dependence of atmospheric models on orographic wave drag parametrizations. ",
    "url": "https://arxiv.org/abs/2402.07759",
    "authors": [
      "Giuseppe Orlando",
      "Tommaso Benacchio",
      "Luca Bonaventura"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2402.07762",
    "title": "Scalable Structure Learning for Sparse Context-Specific Causal Systems",
    "abstract": "Several approaches to graphically representing context-specific relations among jointly distributed categorical variables have been proposed, along with structure learning algorithms. While existing optimization-based methods have limited scalability due to the large number of context-specific models, the constraint-based methods are more prone to error than even constraint-based DAG learning algorithms since more relations must be tested. We present a hybrid algorithm for learning context-specific models that scales to hundreds of variables while testing no more constraints than standard DAG learning algorithms. Scalable learning is achieved through a combination of an order-based MCMC algorithm and sparsity assumptions analogous to those typically invoked for DAG models. To implement the method, we solve a special case of an open problem recently posed by Alon and Balogh. The method is shown to perform well on synthetic data and real world examples, in terms of both accuracy and scalability. ",
    "url": "https://arxiv.org/abs/2402.07762",
    "authors": [
      "Felix Leopoldo Rios",
      "Alex Markham",
      "Liam Solus"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.07763",
    "title": "Multi-level Optimal Control with Neural Surrogate Models",
    "abstract": "Optimal actuator and control design is studied as a multi-level optimisation problem, where the actuator design is evaluated based on the performance of the associated optimal closed loop. The evaluation of the optimal closed loop for a given actuator realisation is a computationally demanding task, for which the use of a neural network surrogate is proposed. The use of neural network surrogates to replace the lower level of the optimisation hierarchy enables the use of fast gradient-based and gradient-free consensus-based optimisation methods to determine the optimal actuator design. The effectiveness of the proposed surrogate models and optimisation methods is assessed in a test related to optimal actuator location for heat control. ",
    "url": "https://arxiv.org/abs/2402.07763",
    "authors": [
      "Dante Kalise",
      "Estefan\u00eda Loayza-Romero",
      "Kirsten A. Morris",
      "Zhengang Zhong"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:1711.01820",
    "title": "Game Theoretic Semi-Distributed D2D Resource Allocation Underlaying an  LTE Network",
    "abstract": " Title: Game Theoretic Semi-Distributed D2D Resource Allocation Underlaying an  LTE Network ",
    "url": "https://arxiv.org/abs/1711.01820",
    "authors": [
      "Anushree Neogi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2104.03527",
    "title": "Sparse NMF with Archetypal Regularization: Computational and Robustness  Properties",
    "abstract": " Title: Sparse NMF with Archetypal Regularization: Computational and Robustness  Properties ",
    "url": "https://arxiv.org/abs/2104.03527",
    "authors": [
      "Kayhan Behdin",
      "Rahul Mazumder"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.01805",
    "title": "Monoidal categories, representation gap and cryptography",
    "abstract": " Comments: 52 pages, many figures, revised version, comments welcome ",
    "url": "https://arxiv.org/abs/2201.01805",
    "authors": [
      "Mikhail Khovanov",
      "Maithreya Sitaraman",
      "Daniel Tubbenhauer"
    ],
    "subjectives": [
      "Representation Theory (math.RT)",
      "Cryptography and Security (cs.CR)",
      "Group Theory (math.GR)",
      "Quantum Algebra (math.QA)"
    ]
  },
  {
    "id": "arXiv:2207.06944",
    "title": "Differentially Private Graph Learning via Sensitivity-Bounded  Personalized PageRank",
    "abstract": " Title: Differentially Private Graph Learning via Sensitivity-Bounded  Personalized PageRank ",
    "url": "https://arxiv.org/abs/2207.06944",
    "authors": [
      "Alessandro Epasto",
      "Vahab Mirrokni",
      "Bryan Perozzi",
      "Anton Tsitsulin",
      "Peilin Zhong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.04448",
    "title": "NeuralVDB: High-resolution Sparse Volume Representation using  Hierarchical Neural Networks",
    "abstract": " Title: NeuralVDB: High-resolution Sparse Volume Representation using  Hierarchical Neural Networks ",
    "url": "https://arxiv.org/abs/2208.04448",
    "authors": [
      "Doyub Kim",
      "Minjae Lee",
      "Ken Museth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2208.07998",
    "title": "What Artificial Neural Networks Can Tell Us About Human Language  Acquisition",
    "abstract": " Comments: Please cite the published version with the following information: @incollection{warstadt2022artificial, title={What artificial neural networks can tell us about human language acquisition}, author={Warstadt, Alex and Bowman, Samuel R.}, booktitle={Algebraic Structures in Natural Language}, pages={17--60}, year={2022}, publisher={CRC Press} } ",
    "url": "https://arxiv.org/abs/2208.07998",
    "authors": [
      "Alex Warstadt",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07888",
    "title": "Guessing Random Additive Noise Decoding of Network Coded Data  Transmitted over Burst Error Channels",
    "abstract": " Comments: 16 double-column pages, 10 figures, 1 table. Extended version of paper presented at IEEE ISIT 2022. Submitted to IEEE Transactions on Vehicular Technology ",
    "url": "https://arxiv.org/abs/2210.07888",
    "authors": [
      "Ioannis Chatzigeorgiou",
      "Dmitry Savostyanov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.11640",
    "title": "Not All Asians are the Same: A Disaggregated Approach to Identifying  Anti-Asian Racism in Social Media",
    "abstract": " Comments: Accepted at theWebConf 2024 (formerly, WWW) ",
    "url": "https://arxiv.org/abs/2210.11640",
    "authors": [
      "Fan Wu",
      "Sanyam Lakhanpal",
      "Qian Li",
      "Kookjin Lee",
      "Doowon Kim",
      "Heewon Chae",
      "Hazel K. Kwon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.03846",
    "title": "Federated Causal Discovery From Interventions",
    "abstract": " Title: Federated Causal Discovery From Interventions ",
    "url": "https://arxiv.org/abs/2211.03846",
    "authors": [
      "Amin Abyaneh",
      "Nino Scherrer",
      "Patrick Schwab",
      "Stefan Bauer",
      "Bernhard Sch\u00f6lkopf",
      "Arash Mehrjou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.11137",
    "title": "Long Range Constraints for Neural Texture Synthesis Using Sliced  Wasserstein Loss",
    "abstract": " Comments: Added extra ablation studies ",
    "url": "https://arxiv.org/abs/2211.11137",
    "authors": [
      "Liping Yin",
      "Albert Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.07699",
    "title": "Retrieval-based Disentangled Representation Learning with Natural  Language Supervision",
    "abstract": " Title: Retrieval-based Disentangled Representation Learning with Natural  Language Supervision ",
    "url": "https://arxiv.org/abs/2212.07699",
    "authors": [
      "Jiawei Zhou",
      "Xiaoguang Li",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu",
      "Lei Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00270",
    "title": "NetEffect: Discovery and Exploitation of Generalized Network Effects",
    "abstract": " Comments: Accepted to PAKDD 2024 ",
    "url": "https://arxiv.org/abs/2301.00270",
    "authors": [
      "Meng-Chieh Lee",
      "Shubhranshu Shekhar",
      "Jaemin Yoo",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.04494",
    "title": "Multi-label Image Classification using Adaptive Graph Convolutional  Networks: from a Single Domain to Multiple Domains",
    "abstract": " Title: Multi-label Image Classification using Adaptive Graph Convolutional  Networks: from a Single Domain to Multiple Domains ",
    "url": "https://arxiv.org/abs/2301.04494",
    "authors": [
      "Indel Pal Singh",
      "Enjie Ghorbel",
      "Oyebade Oyedotun",
      "Djamila Aouada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.09505",
    "title": "Rethinking the Expressive Power of GNNs via Graph Biconnectivity",
    "abstract": " Comments: Extended from ICLR 2023 Outstanding Paper; 60 pages, 12 figures. Fix typos in the previous version ",
    "url": "https://arxiv.org/abs/2301.09505",
    "authors": [
      "Bohang Zhang",
      "Shengjie Luo",
      "Liwei Wang",
      "Di He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.05428",
    "title": "STERLING: Synergistic Representation Learning on Bipartite Graphs",
    "abstract": " Comments: Accepted by AAAI'2024 ",
    "url": "https://arxiv.org/abs/2302.05428",
    "authors": [
      "Baoyu Jing",
      "Yuchen Yan",
      "Kaize Ding",
      "Chanyoung Park",
      "Yada Zhu",
      "Huan Liu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11628",
    "title": "Provable Robustness Against a Union of $\\ell_0$ Adversarial Attacks",
    "abstract": " Comments: Accepted at AAAI 2024 -- Extended version including the supplementary material ",
    "url": "https://arxiv.org/abs/2302.11628",
    "authors": [
      "Zayd Hammoudeh",
      "Daniel Lowd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.13053",
    "title": "Scalable Neural Network Training over Distributed Graphs",
    "abstract": " Title: Scalable Neural Network Training over Distributed Graphs ",
    "url": "https://arxiv.org/abs/2302.13053",
    "authors": [
      "Aashish Kolluri",
      "Sarthak Choudhary",
      "Bryan Hooi",
      "Prateek Saxena"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.02812",
    "title": "Frames for signal processing on Cayley graphs",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2303.02812",
    "authors": [
      "Kathryn Beck",
      "Mahya Ghandehari",
      "Skyler Hudson",
      "Jenna Paltenstein"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.17304",
    "title": "Robust offset-free constrained Model Predictive Control with Long  Short-Term Memory Networks -- Extended version",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2303.17304",
    "authors": [
      "Irene Schimperna",
      "Lalo Magni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.07428",
    "title": "Bayesian Formal Synthesis of Unknown Systems via Robust Simulation  Relations",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2210.08269 ",
    "url": "https://arxiv.org/abs/2304.07428",
    "authors": [
      "Oliver Sch\u00f6n",
      "Birgit van Huijgevoort",
      "Sofie Haesaert",
      "Sadegh Soudjani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2305.06989",
    "title": "Neural Wave Functions for Superfluids",
    "abstract": " Comments: 15 pages, 5 figures. Talk presented at the 2023 APS March Meeting, March 5-10, 2023, Las Vegas, Nevada, United States ",
    "url": "https://arxiv.org/abs/2305.06989",
    "authors": [
      "Wan Tong Lou",
      "Halvard Sutterud",
      "Gino Cassella",
      "W.M.C. Foulkes",
      "Johannes Knolle",
      "David Pfau",
      "James S. Spencer"
    ],
    "subjectives": [
      "Quantum Gases (cond-mat.quant-gas)",
      "Superconductivity (cond-mat.supr-con)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2305.09824",
    "title": "On the Costs and Benefits of Adopting Lifelong Learning for Software  Analytics -- Empirical Study on Brown Build and Risk Prediction",
    "abstract": " Title: On the Costs and Benefits of Adopting Lifelong Learning for Software  Analytics -- Empirical Study on Brown Build and Risk Prediction ",
    "url": "https://arxiv.org/abs/2305.09824",
    "authors": [
      "Doriane Olewicki",
      "Sarra Habchi",
      "Mathieu Nayrolles",
      "Mojtaba Faramarzi",
      "Sarath Chandar",
      "Bram Adams"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.12975",
    "title": "Graphical Proof Theory I: Sequent Systems on Undirected Graphs",
    "abstract": " Title: Graphical Proof Theory I: Sequent Systems on Undirected Graphs ",
    "url": "https://arxiv.org/abs/2305.12975",
    "authors": [
      "Matteo Acclavio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2305.18377",
    "title": "BadLabel: A Robust Perspective on Evaluating and Enhancing Label-noise  Learning",
    "abstract": " Comments: IEEE T-PAMI 2024 Accept ",
    "url": "https://arxiv.org/abs/2305.18377",
    "authors": [
      "Jingfeng Zhang",
      "Bo Song",
      "Haohan Wang",
      "Bo Han",
      "Tongliang Liu",
      "Lei Liu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.00353",
    "title": "Constructing Semantics-Aware Adversarial Examples with Probabilistic  Perspective",
    "abstract": " Comments: 16 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2306.00353",
    "authors": [
      "Andi Zhang",
      "Mingtian Zhang",
      "Damon Wischik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.00809",
    "title": "Initial Guessing Bias: How Untrained Networks Favor Some Classes",
    "abstract": " Title: Initial Guessing Bias: How Untrained Networks Favor Some Classes ",
    "url": "https://arxiv.org/abs/2306.00809",
    "authors": [
      "Emanuele Francazi",
      "Aurelien Lucchi",
      "Marco Baity-Jesi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01745",
    "title": "Biomarker Discovery with Quantum Neural Networks: A Case-study in  CTLA4-Activation Pathways",
    "abstract": " Title: Biomarker Discovery with Quantum Neural Networks: A Case-study in  CTLA4-Activation Pathways ",
    "url": "https://arxiv.org/abs/2306.01745",
    "authors": [
      "Nam Nguyen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.04288",
    "title": "Revising deep learning methods in parking lot occupancy detection",
    "abstract": " Comments: 15 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2306.04288",
    "authors": [
      "Anastasia Martynova",
      "Mikhail Kuznetsov",
      "Vadim Porvatov",
      "Vladislav Tishin",
      "Andrey Kuznetsov",
      "Natalia Semenova",
      "Ksenia Kuznetsova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.04959",
    "title": "FedMLSecurity: A Benchmark for Attacks and Defenses in Federated  Learning and Federated LLMs",
    "abstract": " Title: FedMLSecurity: A Benchmark for Attacks and Defenses in Federated  Learning and Federated LLMs ",
    "url": "https://arxiv.org/abs/2306.04959",
    "authors": [
      "Shanshan Han",
      "Baturalp Buyukates",
      "Zijian Hu",
      "Han Jin",
      "Weizhao Jin",
      "Lichao Sun",
      "Xiaoyang Wang",
      "Wenxuan Wu",
      "Chulin Xie",
      "Yuhang Yao",
      "Kai Zhang",
      "Qifan Zhang",
      "Yuhui Zhang",
      "Carlee Joe-Wong",
      "Salman Avestimehr",
      "Chaoyang He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.05253",
    "title": "Quantum computing algorithms for inverse problems on graphs and an  NP-complete inverse problem",
    "abstract": " Comments: 42 pages, 3 figures; added numerical examples (appendix A) ",
    "url": "https://arxiv.org/abs/2306.05253",
    "authors": [
      "Joonas Ilmavirta",
      "Matti Lassas",
      "Jinpeng Lu",
      "Lauri Oksanen",
      "Lauri Ylinen"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2306.05859",
    "title": "Bring Your Own (Non-Robust) Algorithm to Solve Robust MDPs by Estimating  The Worst Kernel",
    "abstract": " Title: Bring Your Own (Non-Robust) Algorithm to Solve Robust MDPs by Estimating  The Worst Kernel ",
    "url": "https://arxiv.org/abs/2306.05859",
    "authors": [
      "Kaixin Wang",
      "Uri Gadot",
      "Navdeep Kumar",
      "Kfir Levy",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07521",
    "title": "Evaluating Bias and Noise Induced by the U.S. Census Bureau's Privacy  Protection Methods",
    "abstract": " Comments: 25 pages, 6 figures, 2 tables, plus appendices ",
    "url": "https://arxiv.org/abs/2306.07521",
    "authors": [
      "Christopher T. Kenny",
      "Cory McCartan",
      "Shiro Kuriwaki",
      "Tyler Simko",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2306.08125",
    "title": "Implicit Compressibility of Overparametrized Neural Networks Trained  with Heavy-Tailed SGD",
    "abstract": " Comments: 31 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2306.08125",
    "authors": [
      "Yijun Wan",
      "Melih Barsbey",
      "Abdellatif Zaidi",
      "Umut Simsekli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2306.08266",
    "title": "Analyzing Robustness of Angluin's L$^*$ Algorithm in Presence of Noise",
    "abstract": " Comments: 23 pages. arXiv admin note: substantial text overlap with arXiv:2209.10315 ",
    "url": "https://arxiv.org/abs/2306.08266",
    "authors": [
      "Lina Ye",
      "Igor Khmelnitsky",
      "Serge Haddad",
      "Beno\u00eet Barbot",
      "Benedikt Bollig",
      "Martin Leucker",
      "Daniel Neider",
      "Rajarshi Roy"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2306.14009",
    "title": "Boosting Multitask Learning on Graphs through Higher-Order Task  Affinities",
    "abstract": " Comments: 15 pages. Appeared in KDD 2023 ",
    "url": "https://arxiv.org/abs/2306.14009",
    "authors": [
      "Dongyue Li",
      "Haotian Ju",
      "Aneesh Sharma",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.14043",
    "title": "Machine Learning needs Better Randomness Standards: Randomised Smoothing  and PRNG-based attacks",
    "abstract": " Comments: USENIX Security 2024 (this https URL) ",
    "url": "https://arxiv.org/abs/2306.14043",
    "authors": [
      "Pranav Dahiya",
      "Ilia Shumailov",
      "Ross Anderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.14291",
    "title": "Hyp-OW: Exploiting Hierarchical Structure Learning with Hyperbolic  Distance Enhances Open World Object Detection",
    "abstract": " Comments: Accepted at AAAI 2024 || keywords: Open World Object Detection, Hyperbolic Distance, Unknown Detection, Deformable Transformers, Hierarchical Representation Learning ",
    "url": "https://arxiv.org/abs/2306.14291",
    "authors": [
      "Thang Doan",
      "Xin Li",
      "Sima Behpour",
      "Wenbin He",
      "Liang Gou",
      "Liu Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.01878",
    "title": "KDSTM: Neural Semi-supervised Topic Modeling with Knowledge Distillation",
    "abstract": " Comments: 12 pages, 4 figures, ICLR 2022 Workshop ",
    "url": "https://arxiv.org/abs/2307.01878",
    "authors": [
      "Weijie Xu",
      "Xiaoyu Jiang",
      "Jay Desai",
      "Bin Han",
      "Fuqin Yan",
      "Francis Iannacci"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.02349",
    "title": "Error Approximation and Bias Correction in Dynamic Problems using a  Recurrent Neural Network/Finite Element Hybrid Model",
    "abstract": " Title: Error Approximation and Bias Correction in Dynamic Problems using a  Recurrent Neural Network/Finite Element Hybrid Model ",
    "url": "https://arxiv.org/abs/2307.02349",
    "authors": [
      "Moritz von Tresckow",
      "Herbert De Gersem",
      "Dimitrios Loukrezis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2307.05329",
    "title": "Decoding the Popularity of TV Series: A Network Analysis Perspective",
    "abstract": " Title: Decoding the Popularity of TV Series: A Network Analysis Perspective ",
    "url": "https://arxiv.org/abs/2307.05329",
    "authors": [
      "Melody Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.07572",
    "title": "Harpa: High-Rate Phase Association with Travel Time Neural Fields",
    "abstract": " Title: Harpa: High-Rate Phase Association with Travel Time Neural Fields ",
    "url": "https://arxiv.org/abs/2307.07572",
    "authors": [
      "Cheng Shi",
      "Maarten V. de Hoop",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.08930",
    "title": "Unsupervised Deep Graph Matching Based on Cycle Consistency",
    "abstract": " Comments: 12 pages, 5 figures, 3 papers ",
    "url": "https://arxiv.org/abs/2307.08930",
    "authors": [
      "Siddharth Tourani",
      "Carsten Rother",
      "Muhammad Haris Khan",
      "Bogdan Savchynskyy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11280",
    "title": "Epsilon*: Privacy Metric for Machine Learning Models",
    "abstract": " Title: Epsilon*: Privacy Metric for Machine Learning Models ",
    "url": "https://arxiv.org/abs/2307.11280",
    "authors": [
      "Diana M. Negoescu",
      "Humberto Gonzalez",
      "Saad Eddin Al Orjany",
      "Jilei Yang",
      "Yuliia Lut",
      "Rahul Tandra",
      "Xiaowen Zhang",
      "Xinyi Zheng",
      "Zach Douglas",
      "Vidita Nolkha",
      "Parvez Ahammad",
      "Gennady Samorodnitsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.08925",
    "title": "A White-Box False Positive Adversarial Attack Method on Contrastive Loss  Based Offline Handwritten Signature Verification Models",
    "abstract": " Comments: 8 pages, 3 figures, 2 tables, accepted by the Proceedings of the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024 ",
    "url": "https://arxiv.org/abs/2308.08925",
    "authors": [
      "Zhongliang Guo",
      "Weiye Li",
      "Yifei Qian",
      "Ognjen Arandjelovi\u0107",
      "Lei Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09895",
    "title": "Knowledge Transfer from High-Resource to Low-Resource Programming  Languages for Code LLMs",
    "abstract": " Title: Knowledge Transfer from High-Resource to Low-Resource Programming  Languages for Code LLMs ",
    "url": "https://arxiv.org/abs/2308.09895",
    "authors": [
      "Federico Cassano",
      "John Gouwar",
      "Francesca Lucchetti",
      "Claire Schlesinger",
      "Anders Freeman",
      "Carolyn Jane Anderson",
      "Molly Q Feldman",
      "Michael Greenberg",
      "Abhinav Jangda",
      "Arjun Guha"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10743",
    "title": "Enhancing Adversarial Attacks: The Similar Target Method",
    "abstract": " Title: Enhancing Adversarial Attacks: The Similar Target Method ",
    "url": "https://arxiv.org/abs/2308.10743",
    "authors": [
      "Shuo Zhang",
      "Ziruo Wang",
      "Zikai Zhou",
      "Huanran Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.14081",
    "title": "U-SEANNet: A Simple, Efficient and Applied U-Shaped Network for  Diagnosis of Nasal Diseases on Nasal Endoscopic Images",
    "abstract": " Comments: There are some descriptive errors in the manuscript ",
    "url": "https://arxiv.org/abs/2308.14081",
    "authors": [
      "Yubiao Yue",
      "Jun Xue",
      "Chao Wang",
      "Haihua Liang",
      "Zhenzhang Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.15515",
    "title": "Scalable Algorithms for 2-Packing Sets on Arbitrary Graphs",
    "abstract": " Title: Scalable Algorithms for 2-Packing Sets on Arbitrary Graphs ",
    "url": "https://arxiv.org/abs/2308.15515",
    "authors": [
      "Jannick Borowitz",
      "Ernestine Gro\u00dfmann",
      "Christian Schulz",
      "Dominik Schweisgut"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.00438",
    "title": "A shape-based heuristic for the detection of urban block artifacts in  street networks",
    "abstract": " Comments: Accepted version. Zenodo: this https URL ; GitHub: this https URL ",
    "url": "https://arxiv.org/abs/2309.00438",
    "authors": [
      "Martin Fleischmann",
      "Anastassia Vybornova"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2309.01108",
    "title": "Acoustic-to-articulatory inversion for dysarthric speech: Are  pre-trained self-supervised representations favorable?",
    "abstract": " Comments: Accepted to IEEE ICASSP Workshops 2024 ",
    "url": "https://arxiv.org/abs/2309.01108",
    "authors": [
      "Sarthak Kumar Maharana",
      "Krishna Kamal Adidam",
      "Shoumik Nandi",
      "Ajitesh Srivastava"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.02705",
    "title": "Certifying LLM Safety against Adversarial Prompting",
    "abstract": " Title: Certifying LLM Safety against Adversarial Prompting ",
    "url": "https://arxiv.org/abs/2309.02705",
    "authors": [
      "Aounon Kumar",
      "Chirag Agarwal",
      "Suraj Srinivas",
      "Aaron Jiaxun Li",
      "Soheil Feizi",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03160",
    "title": "ResFields: Residual Neural Fields for Spatiotemporal Signals",
    "abstract": " Comments: [ICLR 2024 Spotlight] Project and code at: this https URL ",
    "url": "https://arxiv.org/abs/2309.03160",
    "authors": [
      "Marko Mihajlovic",
      "Sergey Prokudin",
      "Marc Pollefeys",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03320",
    "title": "CoNeS: Conditional neural fields with shift modulation for  multi-sequence MRI translation",
    "abstract": " Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL ",
    "url": "https://arxiv.org/abs/2309.03320",
    "authors": [
      "Yunjie Chen",
      "Marius Staring",
      "Olaf M. Neve",
      "Stephan R. Romeijn",
      "Erik F. Hensen",
      "Berit M. Verbist",
      "Jelmer M. Wolterink",
      "Qian Tao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08630",
    "title": "PCN: A Deep Learning Approach to Jet Tagging Utilizing Novel Graph  Construction Methods and Chebyshev Graph Convolutions",
    "abstract": " Comments: 14 pages, 2 figures, and 6 tables ",
    "url": "https://arxiv.org/abs/2309.08630",
    "authors": [
      "Yash Semlani",
      "Mihir Relan",
      "Krithik Ramesh"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2309.15048",
    "title": "Class Incremental Learning via Likelihood Ratio Based Task Prediction",
    "abstract": " Title: Class Incremental Learning via Likelihood Ratio Based Task Prediction ",
    "url": "https://arxiv.org/abs/2309.15048",
    "authors": [
      "Haowei Lin",
      "Yijia Shao",
      "Weinan Qian",
      "Ningxin Pan",
      "Yiduo Guo",
      "Bing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16002",
    "title": "Robust Blockwise Random Pivoting: Fast and Accurate Adaptive  Interpolative Decomposition",
    "abstract": " Title: Robust Blockwise Random Pivoting: Fast and Accurate Adaptive  Interpolative Decomposition ",
    "url": "https://arxiv.org/abs/2309.16002",
    "authors": [
      "Yijun Dong",
      "Chao Chen",
      "Per-Gunnar Martinsson",
      "Katherine Pearce"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.16457",
    "title": "Universal Sleep Decoder: Aligning awake and sleep neural representation  across subjects",
    "abstract": " Title: Universal Sleep Decoder: Aligning awake and sleep neural representation  across subjects ",
    "url": "https://arxiv.org/abs/2309.16457",
    "authors": [
      "Zhongtao Chen",
      "Hui Zheng",
      "Haiteng Wang",
      "Jianyang Zhou",
      "Lin Zheng",
      "Yunzhe Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2309.17348",
    "title": "Intrinsic Biologically Plausible Adversarial Training",
    "abstract": " Title: Intrinsic Biologically Plausible Adversarial Training ",
    "url": "https://arxiv.org/abs/2309.17348",
    "authors": [
      "Matilde Tristany Farinha",
      "Thomas Ortner",
      "Giorgia Dellaferrera",
      "Benjamin Grewe",
      "Angeliki Pantazi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03946",
    "title": "Improved prediction of ligand-protein binding affinities by  meta-modeling",
    "abstract": " Comments: 62 pages, 4 main tables, 6 main figures, 7 supplementary figures, and supporting information. For 9 supplementary tables and code, see this https URL ",
    "url": "https://arxiv.org/abs/2310.03946",
    "authors": [
      "Ho-Joon Lee",
      "Prashant S. Emani",
      "Mark B. Gerstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.04017",
    "title": "PGraphDTA: Improving Drug Target Interaction Prediction using Protein  Language Models and Contact Maps",
    "abstract": " Comments: AI for Science Workshop, NeurIPS 2023. 11 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2310.04017",
    "authors": [
      "Rakesh Bal",
      "Yijia Xiao",
      "Wei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.04470",
    "title": "Hierarchical Multi-Marginal Optimal Transport for Network Alignment",
    "abstract": " Comments: 14 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2310.04470",
    "authors": [
      "Zhichen Zeng",
      "Boxin Du",
      "Si Zhang",
      "Yinglong Xia",
      "Zhining Liu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04910",
    "title": "Faithful Knowledge Graph Explanations for Commonsense Reasoning",
    "abstract": " Title: Faithful Knowledge Graph Explanations for Commonsense Reasoning ",
    "url": "https://arxiv.org/abs/2310.04910",
    "authors": [
      "Weihe Zhai",
      "Arkaitz Zubiaga",
      "Bingquan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05842",
    "title": "Robust Angular Synchronization via Directed Graph Neural Networks",
    "abstract": " Comments: 9 pages for main text, ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.05842",
    "authors": [
      "Yixuan He",
      "Gesine Reinert",
      "David Wipf",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.06056",
    "title": "An Automated Tool to Detect Suicidal Susceptibility from Social Media  Posts",
    "abstract": " Comments: 9 pages, 13 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2310.06056",
    "authors": [
      "Yasin Dus",
      "Georgiy Nefedov"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.06085",
    "title": "Quantile-based Maximum Likelihood Training for Outlier Detection",
    "abstract": " Comments: Camera Ready Version AAAI 2024. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2310.06085",
    "authors": [
      "Masoud Taghikhah",
      "Nishant Kumar",
      "Sini\u0161a \u0160egvi\u0107",
      "Abouzar Eslami",
      "Stefan Gumhold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07779",
    "title": "Social Approval and Network Homophily as Motivators of Online Toxicity",
    "abstract": " Comments: 22 pages, 9 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2310.07779",
    "authors": [
      "Julie Jiang",
      "Luca Luceri",
      "Joseph B. Walther",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.07879",
    "title": "Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy  Risks",
    "abstract": " Title: Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy  Risks ",
    "url": "https://arxiv.org/abs/2310.07879",
    "authors": [
      "Hao-Ping Lee",
      "Yu-Ju Yang",
      "Thomas Serban von Davier",
      "Jodi Forlizzi",
      "Sauvik Das"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.09298",
    "title": "ByteStack-ID: Integrated Stacked Model Leveraging Payload Byte Frequency  for Grayscale Image-based Network Intrusion Detection",
    "abstract": " Comments: 6 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2310.09298",
    "authors": [
      "Irfan Khan",
      "Yasir Ali Farrukh",
      "Syed Wali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18376",
    "title": "SQLformer: Deep Auto-Regressive Query Graph Generation for Text-to-SQL  Translation",
    "abstract": " Comments: 11 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2310.18376",
    "authors": [
      "Adri\u00e1n Bazaga",
      "Pietro Li\u00f2",
      "Gos Micklem"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00164",
    "title": "Graph Neural Networks for Road Safety Modeling: Datasets and Evaluations  for Accident Analysis",
    "abstract": " Comments: 24 pages. Appeared in NeurIPS 2023 Datasets Track ",
    "url": "https://arxiv.org/abs/2311.00164",
    "authors": [
      "Abhinav Nippani",
      "Dongyue Li",
      "Haotian Ju",
      "Haris N. Koutsopoulos",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00440",
    "title": "Maximum $k$- vs. $\\ell$-colourings of graphs",
    "abstract": " Title: Maximum $k$- vs. $\\ell$-colourings of graphs ",
    "url": "https://arxiv.org/abs/2311.00440",
    "authors": [
      "Tamio-Vesa Nakajima",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.00886",
    "title": "COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised  Learning",
    "abstract": " Title: COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised  Learning ",
    "url": "https://arxiv.org/abs/2311.00886",
    "authors": [
      "Chuizheng Meng",
      "Yihe Dong",
      "Sercan \u00d6. Ar\u0131k",
      "Yan Liu",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01047",
    "title": "Improving Robustness via Tilted Exponential Layer: A  Communication-Theoretic Perspective",
    "abstract": " Comments: This manuscript has been accepted for publication at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS), 2024 ",
    "url": "https://arxiv.org/abs/2311.01047",
    "authors": [
      "Bhagyashree Puranik",
      "Ahmad Beirami",
      "Yao Qin",
      "Upamanyu Madhow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.01723",
    "title": "Towards Calibrated Robust Fine-Tuning of Vision-Language Models",
    "abstract": " Comments: Presented at the NeurIPS 2023 Workshop on Distribution Shifts (DistShift) ",
    "url": "https://arxiv.org/abs/2311.01723",
    "authors": [
      "Changdae Oh",
      "Hyesu Lim",
      "Mijoo Kim",
      "Jaegul Choo",
      "Alexander Hauptmann",
      "Zhi-Qi Cheng",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.02017",
    "title": "DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network  for Food Deliveries",
    "abstract": " Title: DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network  for Food Deliveries ",
    "url": "https://arxiv.org/abs/2311.02017",
    "authors": [
      "Ashman Mehra",
      "Snehanshu Saha",
      "Vaskar Raychoudhury",
      "Archana Mathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09393",
    "title": "Taypsi: Static Enforcement of Privacy Policies for Policy-Agnostic  Oblivious Computation",
    "abstract": " Title: Taypsi: Static Enforcement of Privacy Policies for Policy-Agnostic  Oblivious Computation ",
    "url": "https://arxiv.org/abs/2311.09393",
    "authors": [
      "Qianchuan Ye",
      "Benjamin Delaware"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.13917",
    "title": "Exploring the impact of social stress on the adaptive dynamics of  COVID-19: Typing the behavior of na\u00efve populations faced with epidemics",
    "abstract": " Comments: 29 pages, 16 figures, 1 table, 2 appendices ",
    "url": "https://arxiv.org/abs/2311.13917",
    "authors": [
      "Innokentiy Kastalskiy",
      "Andrei Zinovyev",
      "Evgeny Mirkes",
      "Victor Kazantsev",
      "Alexander N. Gorban"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.14361",
    "title": "Deciphering and integrating invariants for neural operator learning with  various physical mechanisms",
    "abstract": " Title: Deciphering and integrating invariants for neural operator learning with  various physical mechanisms ",
    "url": "https://arxiv.org/abs/2311.14361",
    "authors": [
      "Rui Zhang",
      "Qi Meng",
      "Zhi-Ming Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2311.15054",
    "title": "Detection of developmental language disorder in Cypriot Greek children  using a neural network algorithm",
    "abstract": " Comments: 15 pages, 3 figures, journal article ",
    "url": "https://arxiv.org/abs/2311.15054",
    "authors": [
      "Georgios P. Georgiou",
      "Elena Theodorou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16526",
    "title": "On robust overfitting: adversarial training induced distribution matters",
    "abstract": " Title: On robust overfitting: adversarial training induced distribution matters ",
    "url": "https://arxiv.org/abs/2311.16526",
    "authors": [
      "Runzhi Tian",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16594",
    "title": "Monitor Placement for Fault Localization in Deep Neural Network  Accelerators",
    "abstract": " Comments: Technical fallacies appear in this paper ",
    "url": "https://arxiv.org/abs/2311.16594",
    "authors": [
      "Wei-Kai Liu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.18575",
    "title": "Class Distribution Shifts in Zero-Shot Learning: Learning Robust  Representations",
    "abstract": " Title: Class Distribution Shifts in Zero-Shot Learning: Learning Robust  Representations ",
    "url": "https://arxiv.org/abs/2311.18575",
    "authors": [
      "Yuli Slavutsky",
      "Yuval Benjamini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01163",
    "title": "A New Learning Paradigm for Foundation Model-based Remote Sensing Change  Detection",
    "abstract": " Title: A New Learning Paradigm for Foundation Model-based Remote Sensing Change  Detection ",
    "url": "https://arxiv.org/abs/2312.01163",
    "authors": [
      "Kaiyu Li",
      "Xiangyong Cao",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01169",
    "title": "Virtual Category Learning: A Semi-Supervised Learning Method for Dense  Prediction with Extremely Limited Labels",
    "abstract": " Comments: T-PAMI accepted. arXiv admin note: text overlap with arXiv:2207.03433 ",
    "url": "https://arxiv.org/abs/2312.01169",
    "authors": [
      "Changrui Chen",
      "Jungong Han",
      "Kurt Debattista"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.02093",
    "title": "Cultural Differences in Students' Privacy Concerns in Learning Analytics  across Germany, South Korea, Spain, Sweden, and the United States",
    "abstract": " Title: Cultural Differences in Students' Privacy Concerns in Learning Analytics  across Germany, South Korea, Spain, Sweden, and the United States ",
    "url": "https://arxiv.org/abs/2312.02093",
    "authors": [
      "Olga Viberg",
      "Ren\u00e9 F. Kizilcec",
      "Ioana Jivet",
      "Alejandra Mart\u00ednez Mon\u00e9s",
      "Alice Oh",
      "Chantal Mutimukwe",
      "Stefan Hrastinski",
      "Maren Scheffel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.03731",
    "title": "MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs",
    "abstract": " Comments: Accepted by WWW2024 ",
    "url": "https://arxiv.org/abs/2312.03731",
    "authors": [
      "Xingtong Yu",
      "Chang Zhou",
      "Yuan Fang",
      "Xinming Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05974",
    "title": "Learning the Causal Structure of Networked Dynamical Systems under  Latent Nodes and Structured Noise",
    "abstract": " Comments: Accepted at The 38th AAAI Conference on Artificial Intelligence (Main Track). Final Camera-Ready Version ",
    "url": "https://arxiv.org/abs/2312.05974",
    "authors": [
      "Augusto Santos",
      "Diogo Rente",
      "Rui Seabra",
      "Jos\u00e9 M. F. Moura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.07364",
    "title": "Collapse-Aware Triplet Decoupling for Adversarially Robust Image  Retrieval",
    "abstract": " Title: Collapse-Aware Triplet Decoupling for Adversarially Robust Image  Retrieval ",
    "url": "https://arxiv.org/abs/2312.07364",
    "authors": [
      "Qiwei Tian",
      "Chenhao Lin",
      "Zhengyu Zhao",
      "Qian Li",
      "Chao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01404",
    "title": "Scalable network reconstruction in subquadratic time",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2401.01404",
    "authors": [
      "Tiago P. Peixoto"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.03092",
    "title": "Finite Expression Method for Learning Dynamics on Complex Networks",
    "abstract": " Title: Finite Expression Method for Learning Dynamics on Complex Networks ",
    "url": "https://arxiv.org/abs/2401.03092",
    "authors": [
      "Zezheng Song",
      "Chunmei Wang",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2401.09417",
    "title": "Vision Mamba: Efficient Visual Representation Learning with  Bidirectional State Space Model",
    "abstract": " Comments: Work in progress. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2401.09417",
    "authors": [
      "Lianghui Zhu",
      "Bencheng Liao",
      "Qian Zhang",
      "Xinlong Wang",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.09798",
    "title": "All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks",
    "abstract": " Comments: 12 pages, 4 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2401.09798",
    "authors": [
      "Kazuhiro Takemoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.13695",
    "title": "Inverse analysis of granular flows using differentiable graph neural  network simulator",
    "abstract": " Title: Inverse analysis of granular flows using differentiable graph neural  network simulator ",
    "url": "https://arxiv.org/abs/2401.13695",
    "authors": [
      "Yongjin Choi",
      "Krishna Kumar"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.14606",
    "title": "Challenging Low Homophily in Social Recommendation",
    "abstract": " Comments: This paper has been accepted by The Web Conference (WWW) 2024 ",
    "url": "https://arxiv.org/abs/2401.14606",
    "authors": [
      "Wei Jiang",
      "Xinyi Gao",
      "Guandong Xu",
      "Tong Chen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2401.14876",
    "title": "Cross-Space Adaptive Filter: Integrating Graph Topology and Node  Attributes for Alleviating the Over-smoothing Problem",
    "abstract": " Comments: Accepted to WWW 2024. V2: update the results on GCN-BC based on our rebuttal on OpenReview. Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2401.14876",
    "authors": [
      "Chen Huang",
      "Haoyang Li",
      "Yifan Zhang",
      "Wenqiang Lei",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.15741",
    "title": "SERNet-Former: Semantic Segmentation by Efficient Residual Network with  Attention-Boosting Gates and Attention-Fusion Networks",
    "abstract": " Title: SERNet-Former: Semantic Segmentation by Efficient Residual Network with  Attention-Boosting Gates and Attention-Fusion Networks ",
    "url": "https://arxiv.org/abs/2401.15741",
    "authors": [
      "Serdar Erisen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.16113",
    "title": "A parallel preconditioner for the all-at-once linear system from  evolutionary PDEs with Crank-Nicolson discretization",
    "abstract": " Comments: 18 pages, 5 figures and 4 tables (update some contexts) ",
    "url": "https://arxiv.org/abs/2401.16113",
    "authors": [
      "Yong-Liang Zhao",
      "Xian-Ming Gu",
      "Cornelis W. Oosterlee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.00326",
    "title": "PirateNets: Physics-informed Deep Learning with Residual Adaptive  Networks",
    "abstract": " Comments: 30Pages, 15 Figures, 8 Tables ",
    "url": "https://arxiv.org/abs/2402.00326",
    "authors": [
      "Sifan Wang",
      "Bowen Li",
      "Yuhan Chen",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.00746",
    "title": "Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model",
    "abstract": " Title: Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model ",
    "url": "https://arxiv.org/abs/2402.00746",
    "authors": [
      "Mingyu Jin",
      "Qinkai Yu",
      "Chong Zhang",
      "Dong Shu",
      "Suiyuan Zhu",
      "Mengnan Du",
      "Yongfeng Zhang",
      "Yanda Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01254",
    "title": "Neural Trajectory Model: Implicit Neural Trajectory Representation for  Trajectories Generation",
    "abstract": " Title: Neural Trajectory Model: Implicit Neural Trajectory Representation for  Trajectories Generation ",
    "url": "https://arxiv.org/abs/2402.01254",
    "authors": [
      "Zihan Yu",
      "Yuqing Tang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.01713",
    "title": "Prompting Large Language Models for Zero-Shot Clinical Prediction with  Structured Longitudinal Electronic Health Record Data",
    "abstract": " Title: Prompting Large Language Models for Zero-Shot Clinical Prediction with  Structured Longitudinal Electronic Health Record Data ",
    "url": "https://arxiv.org/abs/2402.01713",
    "authors": [
      "Yinghao Zhu",
      "Zixiang Wang",
      "Junyi Gao",
      "Yuning Tong",
      "Jingkun An",
      "Weibin Liao",
      "Ewen M. Harrison",
      "Liantao Ma",
      "Chengwei Pan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02047",
    "title": "Quality and Trust in LLM-generated Code",
    "abstract": " Title: Quality and Trust in LLM-generated Code ",
    "url": "https://arxiv.org/abs/2402.02047",
    "authors": [
      "Claudio Spiess",
      "David Gros",
      "Kunal Suresh Pai",
      "Michael Pradel",
      "Md Rafiqul Islam Rabin",
      "Amin Alipour",
      "Susmit Jha",
      "Prem Devanbu",
      "Toufique Ahmed"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02823",
    "title": "Evading Data Contamination Detection for Language Models is (too) Easy",
    "abstract": " Title: Evading Data Contamination Detection for Language Models is (too) Easy ",
    "url": "https://arxiv.org/abs/2402.02823",
    "authors": [
      "Jasper Dekoninck",
      "Mark Niklas M\u00fcller",
      "Maximilian Baader",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.03861",
    "title": "A Bernoulli-barycentric rational matrix collocation method with  preconditioning for a class of evolutionary PDEs",
    "abstract": " Comments: 23 pages, 6 figures, 9 tables (update some contexts) ",
    "url": "https://arxiv.org/abs/2402.03861",
    "authors": [
      "Wei-Hua Luo",
      "Xian-Ming Gu",
      "Bruno Carpentieri",
      "Jun Guo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.04554",
    "title": "BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial  Imagery",
    "abstract": " Title: BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial  Imagery ",
    "url": "https://arxiv.org/abs/2402.04554",
    "authors": [
      "Huiqing Zhang",
      "Yifei Xue",
      "Ming Liao",
      "Yizhen Lao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06033",
    "title": "An Inexact Halpern Iteration with Application to Distributionally Robust  Optimization",
    "abstract": " Comments: Correct a typo in the title and update authors' information ",
    "url": "https://arxiv.org/abs/2402.06033",
    "authors": [
      "Ling Liang",
      "Kim-Chuan Toh",
      "Jia-Jie Zhu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06187",
    "title": "Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask  Representation via Temporal Action-Driven Contrastive Loss",
    "abstract": " Title: Premier-TACO is a Few-Shot Policy Learner: Pretraining Multitask  Representation via Temporal Action-Driven Contrastive Loss ",
    "url": "https://arxiv.org/abs/2402.06187",
    "authors": [
      "Ruijie Zheng",
      "Yongyuan Liang",
      "Xiyao Wang",
      "Shuang Ma",
      "Hal Daum\u00e9 III",
      "Huazhe Xu",
      "John Langford",
      "Praveen Palanisamy",
      "Kalyan Shankar Basu",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  }
]