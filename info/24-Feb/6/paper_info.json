[
  {
    "id": "arXiv:2402.01642",
    "title": "Detection of Machine-Generated Text: Literature Survey",
    "abstract": "Since language models produce fake text quickly and easily, there is an oversupply of such content in the public domain. The degree of sophistication and writing style has reached a point where differentiating between human authored and machine-generated content is nearly impossible. As a result, works generated by language models rather than human authors have gained significant media attention and stirred controversy.Concerns regarding the possible influence of advanced language models on society have also arisen, needing a fuller knowledge of these processes. Natural language generation (NLG) and generative pre-trained transformer (GPT) models have revolutionized a variety of sectors: the scope not only permeated throughout journalism and customer service but also reached academia. To mitigate the hazardous implications that may arise from the use of these models, preventative measures must be implemented, such as providing human agents with the capacity to distinguish between artificially made and human composed texts utilizing automated systems and possibly reverse-engineered language models. Furthermore, to ensure a balanced and responsible approach, it is critical to have a full grasp of the socio-technological ramifications of these breakthroughs. This literature survey aims to compile and synthesize accomplishments and developments in the aforementioned work, while also identifying future prospects. It also gives an overview of machine-generated text trends and explores the larger societal implications. Ultimately, this survey intends to contribute to the development of robust and effective approaches for resolving the issues connected with the usage and detection of machine-generated text by exploring the interplay between the capabilities of language models and their possible implications. ",
    "url": "https://arxiv.org/abs/2402.01642",
    "authors": [
      "Dmytro Valiaiev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01648",
    "title": "Forecasting Imports in OECD Member Countries and Iran by Using Neural  Network Algorithms of LSTM",
    "abstract": "Artificial Neural Networks (ANN) which are a branch of artificial intelligence, have shown their high value in lots of applications and are used as a suitable forecasting method. Therefore, this study aims at forecasting imports in OECD member selected countries and Iran for 20 seasons from 2021 to 2025 by means of ANN. Data related to the imports of such countries collected over 50 years from 1970 to 2019 from valid resources including World Bank, WTO, IFM,the data turned into seasonal data to increase the number of collected data for better performance and high accuracy of the network by using Diz formula that there were totally 200 data related to imports. This study has used LSTM to analyse data in Pycharm. 75% of data considered as training data and 25% considered as test data and the results of the analysis were forecasted with 99% accuracy which revealed the validity and reliability of the output. Since the imports is consumption function and since the consumption is influenced during Covid-19 Pandemic, so it is time-consuming to correct and improve it to be influential on the imports, thus the imports in the years after Covid-19 Pandemic has had a fluctuating trend. ",
    "url": "https://arxiv.org/abs/2402.01648",
    "authors": [
      "Soheila Khajoui",
      "Saeid Dehyadegari",
      "Sayyed Abdolmajid Jalaee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2402.01655",
    "title": "A Deep Learning Approach Towards Student Performance Prediction in  Online Courses: Challenges Based on a Global Perspective",
    "abstract": "Analyzing and evaluating students' progress in any learning environment is stressful and time consuming if done using traditional analysis methods. This is further exasperated by the increasing number of students due to the shift of focus toward integrating the Internet technologies in education and the focus of academic institutions on moving toward e-Learning, blended, or online learning models. As a result, the topic of student performance prediction has become a vibrant research area in recent years. To address this, machine learning and data mining techniques have emerged as a viable solution. To that end, this work proposes the use of deep learning techniques (CNN and RNN-LSTM) to predict the students' performance at the midpoint stage of the online course delivery using three distinct datasets collected from three different regions of the world. Experimental results show that deep learning models have promising performance as they outperform other optimized traditional ML models in two of the three considered datasets while also having comparable performance for the third dataset. ",
    "url": "https://arxiv.org/abs/2402.01655",
    "authors": [
      "Abdallah Moubayed",
      "MohammadNoor Injadat",
      "Nouh Alhindawi",
      "Ghassan Samara",
      "Sara Abuasal",
      "Raed Alazaidah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01665",
    "title": "Knowledge-Driven Deep Learning Paradigms for Wireless Network  Optimization in 6G",
    "abstract": "In the sixth-generation (6G) networks, newly emerging diversified services of massive users in dynamic network environments are required to be satisfied by multi-dimensional heterogeneous resources. The resulting large-scale complicated network optimization problems are beyond the capability of model-based theoretical methods due to the overwhelming computational complexity and the long processing time. Although with fast online inference and universal approximation ability, data-driven deep learning (DL) heavily relies on abundant training data and lacks interpretability. To address these issues, a new paradigm called knowledge-driven DL has emerged, aiming to integrate proven domain knowledge into the construction of neural networks, thereby exploiting the strengths of both methods. This article provides a systematic review of knowledge-driven DL in wireless networks. Specifically, a holistic framework of knowledge-driven DL in wireless networks is proposed, where knowledge sources, knowledge representation, knowledge integration and knowledge application are forming as a closed loop. Then, a detailed taxonomy of knowledge integration approaches, including knowledge-assisted, knowledge-fused, and knowledge-embedded DL, is presented. Several open issues for future research are also discussed. The insights offered in this article provide a basic principle for the design of network optimization that incorporates communication-specific domain knowledge and DL, facilitating the realization of intelligent 6G networks. ",
    "url": "https://arxiv.org/abs/2402.01665",
    "authors": [
      "Ruijin Sun",
      "Nan Cheng",
      "Changle Li",
      "Fangjiong Chen",
      "Wen Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01675",
    "title": "Resource-efficient In-orbit Detection of Earth Objects",
    "abstract": "With the rapid proliferation of large Low Earth Orbit (LEO) satellite constellations, a huge amount of in-orbit data is generated and needs to be transmitted to the ground for processing. However, traditional LEO satellite constellations, which downlink raw data to the ground, are significantly restricted in transmission capability. Orbital edge computing (OEC), which exploits the computation capacities of LEO satellites and processes the raw data in orbit, is envisioned as a promising solution to relieve the downlink burden. Yet, with OEC, the bottleneck is shifted to the inelastic computation capacities. The computational bottleneck arises from two primary challenges that existing satellite systems have not adequately addressed: the inability to process all captured images and the limited energy supply available for satellite operations. In this work, we seek to fully exploit the scarce satellite computation and communication resources to achieve satellite-ground collaboration and present a satellite-ground collaborative system named TargetFuse for onboard object detection. TargetFuse incorporates a combination of techniques to minimize detection errors under energy and bandwidth constraints. Extensive experiments show that TargetFuse can reduce detection errors by 3.4 times on average, compared to onboard computing. TargetFuse achieves a 9.6 times improvement in bandwidth efficiency compared to the vanilla baseline under the limited bandwidth budget constraint. ",
    "url": "https://arxiv.org/abs/2402.01675",
    "authors": [
      "Qiyang Zhang",
      "Xin Yuan",
      "Ruolin Xing",
      "Yiran Zhang",
      "Zimu Zheng",
      "Xiao Ma",
      "Mengwei Xu",
      "Schahram Dustdar",
      "Shangguang Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.01677",
    "title": "Embedding Ontologies via Incoprorating Extensional and Intensional  Knowledge",
    "abstract": "Ontologies contain rich knowledge within domain, which can be divided into two categories, namely extensional knowledge and intensional knowledge. Extensional knowledge provides information about the concrete instances that belong to specific concepts in the ontology, while intensional knowledge details inherent properties, characteristics, and semantic associations among concepts. However, existing ontology embedding approaches fail to take both extensional knowledge and intensional knowledge into fine consideration simultaneously. In this paper, we propose a novel ontology embedding approach named EIKE (Extensional and Intensional Knowledge Embedding) by representing ontologies in two spaces, called extensional space and intensional space. EIKE presents a unified framework for embedding instances, concepts and their relations in an ontology, applying a geometry-based method to model extensional knowledge and a pretrained language model to model intensional knowledge, which can capture both structure information and textual information. Experimental results show that EIKE significantly outperforms state-of-the-art methods in three datasets for both triple classification and link prediction, indicating that EIKE provides a more comprehensive and representative perspective of the domain. ",
    "url": "https://arxiv.org/abs/2402.01677",
    "authors": [
      "Keyu Wang",
      "Guilin Qi",
      "Jiaoyan Chen",
      "Tianxing Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01681",
    "title": "Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social  Media Communications",
    "abstract": "Emojis, which encapsulate semantics beyond mere words or phrases, have become prevalent in social network communications. This has spurred increasing scholarly interest in exploring their attributes and functionalities. However, emoji-related research and application face two primary challenges. First, researchers typically rely on crowd-sourcing to annotate emojis in order to understand their sentiments, usage intentions, and semantic meanings. Second, subjective interpretations by users can often lead to misunderstandings of emojis and cause the communication barrier. Large Language Models (LLMs) have achieved significant success in various annotation tasks, with ChatGPT demonstrating expertise across multiple domains. In our study, we assess ChatGPT's effectiveness in handling previously annotated and downstream tasks. Our objective is to validate the hypothesis that ChatGPT can serve as a viable alternative to human annotators in emoji research and that its ability to explain emoji meanings can enhance clarity and transparency in online communications. Our findings indicate that ChatGPT has extensive knowledge of emojis. It is adept at elucidating the meaning of emojis across various application scenarios and demonstrates the potential to replace human annotators in a range of tasks. ",
    "url": "https://arxiv.org/abs/2402.01681",
    "authors": [
      "Yuhang Zhou",
      "Paiheng Xu",
      "Xiyao Wang",
      "Xuan Lu",
      "Ge Gao",
      "Wei Ai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01682",
    "title": "Leveraging Social Media Data to Identify Factors Influencing Public  Attitude Towards Accessibility, Socioeconomic Disparity and Public  Transportation",
    "abstract": "This study proposes a novel method to understand the factors affecting individuals' perception of transport accessibility, socioeconomic disparity, and public infrastructure. As opposed to the time consuming and expensive survey-based approach, this method can generate organic large-scale responses from social media and develop statistical models to understand individuals' perceptions of various transportation issues. This study retrieved and analyzed 36,098 tweets from New York City from March 19, 2020, to May 15, 2022. A state-of-the-art natural language processing algorithm is used for text mining and classification. A data fusion technique has been adopted to generate a series of socioeconomic traits that are used as explanatory variables in the model. The model results show that females and individuals of Asian origin tend to discuss transportation accessibility more than their counterparts, with those experiencing high neighborhood traffic also being more vocal. However, disadvantaged individuals, including the unemployed and those living in low-income neighborhoods or in areas with high natural hazard risks, tend to communicate less about such issues. As for socioeconomic disparity, individuals of Asian origin and those experiencing various types of air pollution are more likely to discuss these topics on Twitter, often with a negative sentiment. However, unemployed, or disadvantaged individuals, as well as those living in areas with high natural hazard risks or expected losses, are less inclined to tweet about this subject. Lack of internet accessibility could be a reason why many disadvantaged individuals do not tweet about transport accessibility and subsidized internet could be a possible solution. ",
    "url": "https://arxiv.org/abs/2402.01682",
    "authors": [
      "Khondhaker Al Momin",
      "Arif Mohaimin Sadri",
      "Md Sami Hasnine"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.01683",
    "title": "Community-based Behavioral Understanding of Crisis Activity Concerns  using Social Media Data: A Study on the 2023 Canadian Wildfires in New York  City",
    "abstract": "New York City (NYC) topped the global chart for the worst air pollution in June 2023, owing to the wildfire smoke drifting in from Canada. This unprecedented situation caused significant travel disruptions and shifts in traditional activity patterns of NYC residents. This study utilized large-scale social media data to study different crisis activity concerns (i.e., evacuation, staying indoors, shopping, and recreational activities among others) in the emergence of the 2023 Canadian wildfire smoke in NYC. In this regard, one week (June 02 through June 09, 2023) geotagged Twitter data from NYC were retrieved and used in the analysis. The tweets were processed using advanced text classification techniques and later integrated with national databases such as Social Security Administration data, Census, and American Community Survey. Finally, a model has been developed to make community inferences of different activity concerns in a major wildfire. The findings suggest, during wildfires, females are less likely to engage in discussions about evacuation, trips for medical, social, or recreational purposes, and commuting for work, likely influenced by workplaces maintaining operations despite poor air quality. There were also racial disparities in these discussions, with Asians being more likely than Hispanics to discuss evacuation and work commute, and African Americans being less likely to discuss social and recreational activities. Additionally, individuals from low-income neighborhoods and non-higher education students expressed fewer concerns about evacuation. This study provides valuable insights for policymakers, emergency planners, and public health officials, aiding them in formulating targeted communication strategies and equitable emergency response plans. ",
    "url": "https://arxiv.org/abs/2402.01683",
    "authors": [
      "Khondhaker Al Momin",
      "Md Sami Hasnine",
      "Arif Mohaimin Sadri"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.01690",
    "title": "Linguistic-Based Mild Cognitive Impairment Detection Using Informative  Loss",
    "abstract": "This paper presents a deep learning method using Natural Language Processing (NLP) techniques, to distinguish between Mild Cognitive Impairment (MCI) and Normal Cognitive (NC) conditions in older adults. We propose a framework that analyzes transcripts generated from video interviews collected within the I-CONECT study project, a randomized controlled trial aimed at improving cognitive functions through video chats. Our proposed NLP framework consists of two Transformer-based modules, namely Sentence Embedding (SE) and Sentence Cross Attention (SCA). First, the SE module captures contextual relationships between words within each sentence. Subsequently, the SCA module extracts temporal features from a sequence of sentences. This feature is then used by a Multi-Layer Perceptron (MLP) for the classification of subjects into MCI or NC. To build a robust model, we propose a novel loss function, called InfoLoss, that considers the reduction in entropy by observing each sequence of sentences to ultimately enhance the classification accuracy. The results of our comprehensive model evaluation using the I-CONECT dataset show that our framework can distinguish between MCI and NC with an average area under the curve of 84.75%. ",
    "url": "https://arxiv.org/abs/2402.01690",
    "authors": [
      "Ali Pourramezan Fard",
      "Mohammad H. Mahoor",
      "Muath Alsuhaibani",
      "Hiroko H. Dodgec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01692",
    "title": "Maximizing Data Efficiency for Cross-Lingual TTS Adaptation by  Self-Supervised Representation Mixing and Embedding Initialization",
    "abstract": "This paper presents an effective transfer learning framework for language adaptation in text-to-speech systems, with a focus on achieving language adaptation using minimal labeled and unlabeled data. While many works focus on reducing the usage of labeled data, very few consider minimizing the usage of unlabeled data. By utilizing self-supervised features in the pretraining stage, replacing the noisy portion of pseudo labels with these features during fine-tuning, and incorporating an embedding initialization trick, our method leverages more information from unlabeled data compared to conventional approaches. Experimental results show that our framework is able to synthesize intelligible speech in unseen languages with only 4 utterances of labeled data and 15 minutes of unlabeled data. Our methodology continues to surpass conventional techniques, even when a greater volume of data is accessible. These findings highlight the potential of our data-efficient language adaptation framework. ",
    "url": "https://arxiv.org/abs/2402.01692",
    "authors": [
      "Wei-Ping Huang",
      "Sung-Feng Huang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01697",
    "title": "APT-Pipe: An Automatic Prompt-Tuning Tool for Social Computing Data  Annotation",
    "abstract": "Recent research has highlighted the potential of LLM applications, like ChatGPT, for performing label annotation on social computing text. However, it is already well known that performance hinges on the quality of the input prompts. To address this, there has been a flurry of research into prompt tuning -- techniques and guidelines that attempt to improve the quality of prompts. Yet these largely rely on manual effort and prior knowledge of the dataset being annotated. To address this limitation, we propose APT-Pipe, an automated prompt-tuning pipeline. APT-Pipe aims to automatically tune prompts to enhance ChatGPT's text classification performance on any given dataset. We implement APT-Pipe and test it across twelve distinct text classification datasets. We find that prompts tuned by APT-Pipe help ChatGPT achieve higher weighted F1-score on nine out of twelve experimented datasets, with an improvement of 7.01% on average. We further highlight APT-Pipe's flexibility as a framework by showing how it can be extended to support additional tuning mechanisms. ",
    "url": "https://arxiv.org/abs/2402.01697",
    "authors": [
      "Yiming Zhu",
      "Zhizhuo Yin",
      "Ehsan-Ul Haq",
      "Lik-Hang Lee",
      "Gareth Tyson",
      "Pan Hui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01712",
    "title": "Socially Aware Synthetic Data Generation for Suicidal Ideation Detection  Using Large Language Models",
    "abstract": "Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation. ",
    "url": "https://arxiv.org/abs/2402.01712",
    "authors": [
      "Hamideh Ghanadian",
      "Isar Nejadgholi",
      "Hussein Al Osman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01713",
    "title": "Prompting Large Language Models for Zero-Shot Clinical Prediction with  Structured Longitudinal Electronic Health Record Data",
    "abstract": "The inherent complexity of structured longitudinal Electronic Health Records (EHR) data poses a significant challenge when integrated with Large Language Models (LLMs), which are traditionally tailored for natural language processing. Motivated by the urgent need for swift decision-making during new disease outbreaks, where traditional predictive models often fail due to a lack of historical data, this research investigates the adaptability of LLMs, like GPT-4, to EHR data. We particularly focus on their zero-shot capabilities, which enable them to make predictions in scenarios in which they haven't been explicitly trained. In response to the longitudinal, sparse, and knowledge-infused nature of EHR data, our prompting approach involves taking into account specific EHR characteristics such as units and reference ranges, and employing an in-context learning strategy that aligns with clinical contexts. Our comprehensive experiments on the MIMIC-IV and TJH datasets demonstrate that with our elaborately designed prompting framework, LLMs can improve prediction performance in key tasks such as mortality, length-of-stay, and 30-day readmission by about 35\\%, surpassing ML models in few-shot settings. Our research underscores the potential of LLMs in enhancing clinical decision-making, especially in urgent healthcare situations like the outbreak of emerging diseases with no labeled data. The code is publicly available at https://github.com/yhzhu99/llm4healthcare for reproducibility. ",
    "url": "https://arxiv.org/abs/2402.01713",
    "authors": [
      "Yinghao Zhu",
      "Zixiang Wang",
      "Junyi Gao",
      "Yuning Tong",
      "Jingkun An",
      "Weibin Liao",
      "Ewen M. Harrison",
      "Liantao Ma",
      "Chengwei Pan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01723",
    "title": "An Empirical Study on Large Language Models in Accuracy and Robustness  under Chinese Industrial Scenarios",
    "abstract": "Recent years have witnessed the rapid development of large language models (LLMs) in various domains. To better serve the large number of Chinese users, many commercial vendors in China have adopted localization strategies, training and providing local LLMs specifically customized for Chinese users. Furthermore, looking ahead, one of the key future applications of LLMs will be practical deployment in industrial production by enterprises and users in those sectors. However, the accuracy and robustness of LLMs in industrial scenarios have not been well studied. In this paper, we present a comprehensive empirical study on the accuracy and robustness of LLMs in the context of the Chinese industrial production area. We manually collected 1,200 domain-specific problems from 8 different industrial sectors to evaluate LLM accuracy. Furthermore, we designed a metamorphic testing framework containing four industrial-specific stability categories with eight abilities, totaling 13,631 questions with variants to evaluate LLM robustness. In total, we evaluated 9 different LLMs developed by Chinese vendors, as well as four different LLMs developed by global vendors. Our major findings include: (1) Current LLMs exhibit low accuracy in Chinese industrial contexts, with all LLMs scoring less than 0.6. (2) The robustness scores vary across industrial sectors, and local LLMs overall perform worse than global ones. (3) LLM robustness differs significantly across abilities. Global LLMs are more robust under logical-related variants, while advanced local LLMs perform better on problems related to understanding Chinese industrial terminology. Our study results provide valuable guidance for understanding and promoting the industrial domain capabilities of LLMs from both development and industrial enterprise perspectives. The results further motivate possible research directions and tooling support. ",
    "url": "https://arxiv.org/abs/2402.01723",
    "authors": [
      "Zongjie Li",
      "Wenying Qiu",
      "Pingchuan Ma",
      "Yichen Li",
      "You Li",
      "Sijia He",
      "Baozheng Jiang",
      "Shuai Wang",
      "Weixi Gu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01729",
    "title": "Contextualization Distillation from Large Language Model for Knowledge  Graph Completion",
    "abstract": "While textual information significantly enhances the performance of pre-trained language models (PLMs) in knowledge graph completion (KGC), the static and noisy nature of existing corpora collected from Wikipedia articles or synsets definitions often limits the potential of PLM-based KGC models. To surmount these challenges, we introduce the Contextualization Distillation strategy, a versatile plug-in-and-play approach compatible with both discriminative and generative KGC frameworks. Our method begins by instructing large language models (LLMs) to transform compact, structural triplets into context-rich segments. Subsequently, we introduce two tailored auxiliary tasks, reconstruction and contextualization, allowing smaller KGC models to assimilate insights from these enriched triplets. Comprehensive evaluations across diverse datasets and KGC techniques highlight the efficacy and adaptability of our approach, revealing consistent performance enhancements irrespective of underlying pipelines or architectures. Moreover, our analysis makes our method more explainable and provides insight into generating path selection, as well as the choosing of suitable distillation tasks. All the code and data in this work will be released at https://github.com/David-Li0406/Contextulization-Distillation ",
    "url": "https://arxiv.org/abs/2402.01729",
    "authors": [
      "Dawei Li",
      "Zhen Tan",
      "Tianlong Chen",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01767",
    "title": "HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents  QA",
    "abstract": "As language model agents leveraging external tools rapidly evolve, significant progress has been made in question-answering(QA) methodologies utilizing supplementary documents and the Retrieval-Augmented Generation (RAG) approach. This advancement has improved the response quality of language models and alleviates the appearance of hallucination. However, these methods exhibit limited retrieval accuracy when faced with massive indistinguishable documents, presenting notable challenges in their practical application. In response to these emerging challenges, we present HiQA, an advanced framework for multi-document question-answering (MDQA) that integrates cascading metadata into content as well as a multi-route retrieval mechanism. We also release a benchmark called MasQA to evaluate and research in MDQA. Finally, HiQA demonstrates the state-of-the-art performance in multi-document environments. ",
    "url": "https://arxiv.org/abs/2402.01767",
    "authors": [
      "Xinyue Chen",
      "Pengyu Gao",
      "Jiangjiang Song",
      "Xiaoyang Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01768",
    "title": "Enriched Physics-informed Neural Networks for Dynamic  Poisson-Nernst-Planck Systems",
    "abstract": "This paper proposes a meshless deep learning algorithm, enriched physics-informed neural networks (EPINNs), to solve dynamic Poisson-Nernst-Planck (PNP) equations with strong coupling and nonlinear characteristics. The EPINNs takes the traditional physics-informed neural networks as the foundation framework, and adds the adaptive loss weight to balance the loss functions, which automatically assigns the weights of losses by updating the parameters in each iteration based on the maximum likelihood estimate. The resampling strategy is employed in the EPINNs to accelerate the convergence of loss function. Meanwhile, the GPU parallel computing technique is adopted to accelerate the solving process. Four examples are provided to demonstrate the validity and effectiveness of the proposed method. Numerical results indicate that the new method has better applicability than traditional numerical methods in solving such coupled nonlinear systems. More importantly, the EPINNs is more accurate, stable, and fast than the traditional physics-informed neural networks. This work provides a simple and high-performance numerical tool for addressing PNPs with arbitrary boundary shapes and boundary conditions. ",
    "url": "https://arxiv.org/abs/2402.01768",
    "authors": [
      "Xujia Huang",
      "Fajie Wang",
      "Benrong Zhang",
      "Hanqing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2402.01782",
    "title": "Benchmarking Spiking Neural Network Learning Methods with Varying  Locality",
    "abstract": "Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics, have shown to achieve performance comparable to Artificial Neural Networks (ANNs) in several machine learning tasks. Information is processed as spikes within SNNs in an event-based mechanism that significantly reduces energy consumption. However, training SNNs is challenging due to the non-differentiable nature of the spiking mechanism. Traditional approaches, such as Backpropagation Through Time (BPTT), have shown effectiveness but comes with additional computational and memory costs and are biologically implausible. In contrast, recent works propose alternative learning methods with varying degrees of locality, demonstrating success in classification tasks. In this work, we show that these methods share similarities during the training process, while they present a trade-off between biological plausibility and performance. Further, this research examines the implicitly recurrent nature of SNNs and investigates the influence of addition of explicit recurrence to SNNs. We experimentally prove that the addition of explicit recurrent weights enhances the robustness of SNNs. We also investigate the performance of local learning methods under gradient and non-gradient based adversarial attacks. ",
    "url": "https://arxiv.org/abs/2402.01782",
    "authors": [
      "Jiaqi Lin",
      "Sen Lu",
      "Malyaban Bal",
      "Abhronil Sengupta"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01785",
    "title": "DoubleMLDeep: Estimation of Causal Effects with Multimodal Data",
    "abstract": "This paper explores the use of unstructured, multimodal data, namely text and images, in causal inference and treatment effect estimation. We propose a neural network architecture that is adapted to the double machine learning (DML) framework, specifically the partially linear model. An additional contribution of our paper is a new method to generate a semi-synthetic dataset which can be used to evaluate the performance of causal effect estimation in the presence of text and images as confounders. The proposed methods and architectures are evaluated on the semi-synthetic dataset and compared to standard approaches, highlighting the potential benefit of using text and images directly in causal studies. Our findings have implications for researchers and practitioners in economics, marketing, finance, medicine and data science in general who are interested in estimating causal quantities using non-traditional data. ",
    "url": "https://arxiv.org/abs/2402.01785",
    "authors": [
      "Sven Klaassen",
      "Jan Teichert-Kluge",
      "Philipp Bach",
      "Victor Chernozhukov",
      "Martin Spindler",
      "Suhas Vijaykumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01797",
    "title": "Robust support vector machines via conic optimization",
    "abstract": "We consider the problem of learning support vector machines robust to uncertainty. It has been established in the literature that typical loss functions, including the hinge loss, are sensible to data perturbations and outliers, thus performing poorly in the setting considered. In contrast, using the 0-1 loss or a suitable non-convex approximation results in robust estimators, at the expense of large computational costs. In this paper we use mixed-integer optimization techniques to derive a new loss function that better approximates the 0-1 loss compared with existing alternatives, while preserving the convexity of the learning problem. In our computational results, we show that the proposed estimator is competitive with the standard SVMs with the hinge loss in outlier-free regimes and better in the presence of outliers. ",
    "url": "https://arxiv.org/abs/2402.01797",
    "authors": [
      "Valentina Cepeda",
      "Andr\u00e9s G\u00f3mez",
      "Shaoning Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2402.01805",
    "title": "Exploring the Limitations of Graph Reasoning in Large Language Models",
    "abstract": "Pretrained Large Language Models have demonstrated various types of reasoning capabilities through language-based prompts alone. However, in this paper, we test the depth of graph reasoning for 5 different LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2 and Palm-2) through the problems of graph reasoning. In particular, we design 10 distinct problems of graph traversal, each representing increasing levels of complexity. Further, we analyze the performance of models across various settings such as varying sizes of graphs as well as different forms of k-shot prompting. We highlight various limitations, biases, and properties of LLMs through this benchmarking process, such as an inverse relation to the average degrees of freedom of traversal per node in graphs, the overall negative impact of k-shot prompting on graph reasoning tasks, and a positive response bias which prevents LLMs from identifying the absence of a valid solution. Finally, we propose a new prompting technique specially designed for graph traversal tasks, known as PathCompare, which shows a notable increase in the performance of LLMs in comparison to standard prompting and CoT. ",
    "url": "https://arxiv.org/abs/2402.01805",
    "authors": [
      "Palaash Agrawal",
      "Shavak Vasania",
      "Cheston Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01806",
    "title": "HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack  on Text",
    "abstract": "Black-box hard-label adversarial attack on text is a practical and challenging task, as the text data space is inherently discrete and non-differentiable, and only the predicted label is accessible. Research on this problem is still in the embryonic stage and only a few methods are available. Nevertheless, existing methods rely on the complex heuristic algorithm or unreliable gradient estimation strategy, which probably fall into the local optimum and inevitably consume numerous queries, thus are difficult to craft satisfactory adversarial examples with high semantic similarity and low perturbation rate in a limited query budget. To alleviate above issues, we propose a simple yet effective framework to generate high quality textual adversarial examples under the black-box hard-label attack scenarios, named HQA-Attack. Specifically, after initializing an adversarial example randomly, HQA-attack first constantly substitutes original words back as many as possible, thus shrinking the perturbation rate. Then it leverages the synonym set of the remaining changed words to further optimize the adversarial example with the direction which can improve the semantic similarity and satisfy the adversarial condition simultaneously. In addition, during the optimizing procedure, it searches a transition synonym word for each changed word, thus avoiding traversing the whole synonym set and reducing the query number to some extent. Extensive experimental results on five text classification datasets, three natural language inference datasets and two real-world APIs have shown that the proposed HQA-Attack method outperforms other strong baselines significantly. ",
    "url": "https://arxiv.org/abs/2402.01806",
    "authors": [
      "Han Liu",
      "Zhi Xu",
      "Xiaotong Zhang",
      "Feng Zhang",
      "Fenglong Ma",
      "Hongyang Chen",
      "Hong Yu",
      "Xianchao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01807",
    "title": "AOC-IDS: Autonomous Online Framework with Contrastive Learning for  Intrusion Detection",
    "abstract": "The rapid expansion of the Internet of Things (IoT) has raised increasing concern about targeted cyber attacks. Previous research primarily focused on static Intrusion Detection Systems (IDSs), which employ offline training to safeguard IoT systems. However, such static IDSs struggle with real-world scenarios where IoT system behaviors and attack strategies can undergo rapid evolution, necessitating dynamic and adaptable IDSs. In response to this challenge, we propose AOC-IDS, a novel online IDS that features an autonomous anomaly detection module (ADM) and a labor-free online framework for continual adaptation. In order to enhance data comprehension, the ADM employs an Autoencoder (AE) with a tailored Cluster Repelling Contrastive (CRC) loss function to generate distinctive representation from limited or incrementally incoming data in the online setting. Moreover, to reduce the burden of manual labeling, our online framework leverages pseudo-labels automatically generated from the decision-making process in the ADM to facilitate periodic updates of the ADM. The elimination of human intervention for labeling and decision-making boosts the system's compatibility and adaptability in the online setting to remain synchronized with dynamic environments. Experimental validation using the NSL-KDD and UNSW-NB15 datasets demonstrates the superior performance and adaptability of AOC-IDS, surpassing the state-of-the-art solutions. The code is released at https://github.com/xinchen930/AOC-IDS. ",
    "url": "https://arxiv.org/abs/2402.01807",
    "authors": [
      "Xinchen Zhang",
      "Running Zhao",
      "Zhihan Jiang",
      "Zhicong Sun",
      "Yulong Ding",
      "Edith C.H. Ngai",
      "Shuang-Hua Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.01808",
    "title": "KS-Net: Multi-band joint speech restoration and enhancement network for  2024 ICASSP SSI Challenge",
    "abstract": "This paper presents the speech restoration and enhancement system created by the 1024K team for the ICASSP 2024 Speech Signal Improvement (SSI) Challenge. Our system consists of a generative adversarial network (GAN) in complex-domain for speech restoration and a fine-grained multi-band fusion module for speech enhancement. In the blind test set of SSI, the proposed system achieves an overall mean opinion score (MOS) of 3.49 based on ITU-T P.804 and a Word Accuracy Rate (WAcc) of 0.78 for the real-time track, as well as an overall P.804 MOS of 3.43 and a WAcc of 0.78 for the non-real-time track, ranking 1st in both tracks. ",
    "url": "https://arxiv.org/abs/2402.01808",
    "authors": [
      "Guochen Yu",
      "Runqiang Han",
      "Chenglin Xu",
      "Haoran Zhao",
      "Nan Li",
      "Chen Zhang",
      "Xiguang Zheng",
      "Chao Zhou",
      "Qi Huang",
      "Bing Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.01811",
    "title": "A Distributionally Robust Optimisation Approach to Fair Credit Scoring",
    "abstract": "Credit scoring has been catalogued by the European Commission and the Executive Office of the US President as a high-risk classification task, a key concern being the potential harms of making loan approval decisions based on models that would be biased against certain groups. To address this concern, recent credit scoring research has considered a range of fairness-enhancing techniques put forward by the machine learning community to reduce bias and unfair treatment in classification systems. While the definition of fairness or the approach they follow to impose it may vary, most of these techniques, however, disregard the robustness of the results. This can create situations where unfair treatment is effectively corrected in the training set, but when producing out-of-sample classifications, unfair treatment is incurred again. Instead, in this paper, we will investigate how to apply Distributionally Robust Optimisation (DRO) methods to credit scoring, thereby empirically evaluating how they perform in terms of fairness, ability to classify correctly, and the robustness of the solution against changes in the marginal proportions. In so doing, we find DRO methods to provide a substantial improvement in terms of fairness, with almost no loss in performance. These results thus indicate that DRO can improve fairness in credit scoring, provided that further advances are made in efficiently implementing these systems. In addition, our analysis suggests that many of the commonly used fairness metrics are unsuitable for a credit scoring setting, as they depend on the choice of classification threshold. ",
    "url": "https://arxiv.org/abs/2402.01811",
    "authors": [
      "Pablo Casas",
      "Christophe Mues",
      "Huan Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.01813",
    "title": "An Educational Tool for Learning about Social Media Tracking, Profiling,  and Recommendation",
    "abstract": "This paper introduces an educational tool for classroom use, based on explainable AI (XAI), designed to demystify key social media mechanisms - tracking, profiling, and content recommendation - for novice learners. The tool provides a familiar, interactive interface that resonates with learners' experiences with popular social media platforms, while also offering the means to \"peek under the hood\" and exposing basic mechanisms of datafication. Learners gain first-hand experience of how even the slightest actions, such as pausing to view content, are captured and recorded in their digital footprint, and further distilled into a personal profile. The tool uses real-time visualizations and verbal explanations to create a sense of immediacy: each time the user acts, the resulting changes in their engagement history and their profile are displayed in a visually engaging and understandable manner. This paper discusses the potential of XAI and educational technology in transforming data and digital literacy education and in fostering the growth of children's privacy and security mindsets. ",
    "url": "https://arxiv.org/abs/2402.01813",
    "authors": [
      "Nicolas Pope",
      "Juho Kahila",
      "Jari Laru",
      "Henriikka Vartiainen",
      "Teemu Roos",
      "Matti Tedre"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.01825",
    "title": "Fractal Patterns May Unravel the Intelligence in Next-Token Prediction",
    "abstract": "We study the fractal structure of language, aiming to provide a precise formalism for quantifying properties that may have been previously suspected but not formally shown. We establish that language is: (1) self-similar, exhibiting complexities at all levels of granularity, with no particular characteristic context length, and (2) long-range dependent (LRD), with a Hurst parameter of approximately H=0.70. Based on these findings, we argue that short-term patterns/dependencies in language, such as in paragraphs, mirror the patterns/dependencies over larger scopes, like entire documents. This may shed some light on how next-token prediction can lead to a comprehension of the structure of text at multiple levels of granularity, from words and clauses to broader contexts and intents. We also demonstrate that fractal parameters improve upon perplexity-based bits-per-byte (BPB) in predicting downstream performance. We hope these findings offer a fresh perspective on language and the mechanisms underlying the success of LLMs. ",
    "url": "https://arxiv.org/abs/2402.01825",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Vinh Q. Tran",
      "Mostafa Dehghani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01841",
    "title": "COMET: Generating Commit Messages using Delta Graph Context  Representation",
    "abstract": "Commit messages explain code changes in a commit and facilitate collaboration among developers. Several commit message generation approaches have been proposed; however, they exhibit limited success in capturing the context of code changes. We propose Comet (Context-Aware Commit Message Generation), a novel approach that captures context of code changes using a graph-based representation and leverages a transformer-based model to generate high-quality commit messages. Our proposed method utilizes delta graph that we developed to effectively represent code differences. We also introduce a customizable quality assurance module to identify optimal messages, mitigating subjectivity in commit messages. Experiments show that Comet outperforms state-of-the-art techniques in terms of bleu-norm and meteor metrics while being comparable in terms of rogue-l. Additionally, we compare the proposed approach with the popular gpt-3.5-turbo model, along with gpt-4-turbo; the most capable GPT model, over zero-shot, one-shot, and multi-shot settings. We found Comet outperforming the GPT models, on five and four metrics respectively and provide competitive results with the two other metrics. The study has implications for researchers, tool developers, and software developers. Software developers may utilize Comet to generate context-aware commit messages. Researchers and tool developers can apply the proposed delta graph technique in similar contexts, like code review summarization. ",
    "url": "https://arxiv.org/abs/2402.01841",
    "authors": [
      "Abhinav Reddy Mandli",
      "Saurabhsingh Rajput",
      "Tushar Sharma"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01879",
    "title": "$\u03c3$-zero: Gradient-based Optimization of $\\ell_0$-norm Adversarial  Examples",
    "abstract": "Evaluating the adversarial robustness of deep networks to gradient-based attacks is challenging. While most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations, only a few investigate sparse $\\ell_1$- and $\\ell_0$-norm attacks. In particular, $\\ell_0$-norm attacks remain the least studied due to the inherent complexity of optimizing over a non-convex and non-differentiable constraint. However, evaluating adversarial robustness under these attacks could reveal weaknesses otherwise left untested with more conventional $\\ell_2$- and $\\ell_\\infty$-norm attacks. In this work, we propose a novel $\\ell_0$-norm attack, called $\\sigma$-zero, which leverages an ad hoc differentiable approximation of the $\\ell_0$ norm to facilitate gradient-based optimization, and an adaptive projection operator to dynamically adjust the trade-off between loss minimization and perturbation sparsity. Extensive evaluations using MNIST, CIFAR10, and ImageNet datasets, involving robust and non-robust models, show that $\\sigma$-zero finds minimum $\\ell_0$-norm adversarial examples without requiring any time-consuming hyperparameter tuning, and that it outperforms all competing sparse attacks in terms of success rate, perturbation size, and scalability. ",
    "url": "https://arxiv.org/abs/2402.01879",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Francesco Villani",
      "Maura Pintor",
      "Lea Sch\u00f6nherr",
      "Battista Biggio",
      "Marcello Pelillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01902",
    "title": "EBV: Electronic Bee-Veterinarian for Principled Mining and Forecasting  of Honeybee Time Series",
    "abstract": "Honeybees are vital for pollination and food production. Among many factors, extreme temperature (e.g., due to climate change) is particularly dangerous for bee health. Anticipating such extremities would allow beekeepers to take early preventive action. Thus, given sensor (temperature) time series data from beehives, how can we find patterns and do forecasting? Forecasting is crucial as it helps spot unexpected behavior and thus issue warnings to the beekeepers. In that case, what are the right models for forecasting? ARIMA, RNNs, or something else? We propose the EBV (Electronic Bee-Veterinarian) method, which has the following desirable properties: (i) principled: it is based on a) diffusion equations from physics and b) control theory for feedback-loop controllers; (ii) effective: it works well on multiple, real-world time sequences, (iii) explainable: it needs only a handful of parameters (e.g., bee strength) that beekeepers can easily understand and trust, and (iv) scalable: it performs linearly in time. We applied our method to multiple real-world time sequences, and found that it yields accurate forecasting (up to 49% improvement in RMSE compared to baselines), and segmentation. Specifically, discontinuities detected by EBV mostly coincide with domain expert's opinions, showcasing our approach's potential and practical feasibility. Moreover, EBV is scalable and fast, taking about 20 minutes on a stock laptop for reconstructing two months of sensor data. ",
    "url": "https://arxiv.org/abs/2402.01902",
    "authors": [
      "Mst. Shamima Hossain",
      "Christos Faloutsos",
      "Boris Baer",
      "Hyoseung Kim",
      "Vassilis J. Tsotras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01905",
    "title": "Carthago Delenda Est: Co-opetitive Indirect Information Diffusion Model  for Influence Operations on Online Social Media",
    "abstract": "For a state or non-state actor whose credibility is bankrupt, relying on bots to conduct non-attributable, non-accountable, and influence/information operations (info ops) that are grassroots in appearance but decentralized in actuality on social media can help circumvent the issue of trust deficit while advancing its interests. Planning and/or defending against decentralized info ops can be aided by computational simulations in lieu of ethically-fraught live experiments on social media. In this study, we introduce \\textit{Diluvsion}, an agent-based model for contested information propagation efforts on Twitter-like social media. The model emphasizes a user's belief in an opinion (stance) being impacted by the perception of potentially illusory popular support from constant incoming floods of indirect information, floods that can be cooperatively engineered in an uncoordinated manner by bots as they compete to spread their stances. Our model, which has been validated against real-world data, is an advancement over previous models because we account for engagement metrics in influencing stance adoption, non-social tie spreading of information, neutrality as a stance that can be spread, and themes that are analogous to media's framing effect and are symbiotic with respect to stance propagation. The strengths of the \\textit{Diluvsion} model are demonstrated in simulations of orthodox info ops, e.g., maximizing adoption of one stance; creating echo chambers; inducing polarization; and unorthodox info ops, e.g., simultaneous support of multiple stances as a Trojan horse tactic for the dissemination of a theme. ",
    "url": "https://arxiv.org/abs/2402.01905",
    "authors": [
      "Jwen Fai Low",
      "Benjamin C. M. Fung",
      "Farkhund Iqbal",
      "Claude Fachkha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2402.01913",
    "title": "TartanDrive 2.0: More Modalities and Better Infrastructure to Further  Self-Supervised Learning Research in Off-Road Driving Tasks",
    "abstract": "We present TartanDrive 2.0, a large-scale off-road driving dataset for self-supervised learning tasks. In 2021 we released TartanDrive 1.0, which is one of the largest datasets for off-road terrain. As a follow-up to our original dataset, we collected seven hours of data at speeds of up to 15m/s with the addition of three new LiDAR sensors alongside the original camera, inertial, GPS, and proprioceptive sensors. We also release the tools we use for collecting, processing, and querying the data, including our metadata system designed to further the utility of our data. Custom infrastructure allows end users to reconfigure the data to cater to their own platforms. These tools and infrastructure alongside the dataset are useful for a variety of tasks in the field of off-road autonomy and, by releasing them, we encourage collaborative data aggregation. These resources lower the barrier to entry to utilizing large-scale datasets, thereby helping facilitate the advancement of robotics in areas such as self-supervised learning, multi-modal perception, inverse reinforcement learning, and representation learning. The dataset is available at https://github.com/castacks/tartan drive 2.0. ",
    "url": "https://arxiv.org/abs/2402.01913",
    "authors": [
      "Matthew Sivaprakasam",
      "Parv Maheshwari",
      "Mateo Guaman Castro",
      "Samuel Triest",
      "Micah Nye",
      "Steve Willits",
      "Andrew Saba",
      "Wenshan Wang",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.01915",
    "title": "Robust Inverse Graphics via Probabilistic Inference",
    "abstract": "How do we infer a 3D scene from a single image in the presence of corruptions like rain, snow or fog? Straightforward domain randomization relies on knowing the family of corruptions ahead of time. Here, we propose a Bayesian approach-dubbed robust inverse graphics (RIG)-that relies on a strong scene prior and an uninformative uniform corruption prior, making it applicable to a wide range of corruptions. Given a single image, RIG performs posterior inference jointly over the scene and the corruption. We demonstrate this idea by training a neural radiance field (NeRF) scene prior and using a secondary NeRF to represent the corruptions over which we place an uninformative prior. RIG, trained only on clean data, outperforms depth estimators and alternative NeRF approaches that perform point estimation instead of full inference. The results hold for a number of scene prior architectures based on normalizing flows and diffusion models. For the latter, we develop reconstruction-guidance with auxiliary latents (ReGAL)-a diffusion conditioning algorithm that is applicable in the presence of auxiliary latent variables such as the corruption. RIG demonstrates how scene priors can be used beyond generation tasks. ",
    "url": "https://arxiv.org/abs/2402.01915",
    "authors": [
      "Tuan Anh Le",
      "Pavel Sountsov",
      "Matthew D. Hoffman",
      "Ben Lee",
      "Brian Patton",
      "Rif A. Saurous"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2402.01920",
    "title": "Preference Poisoning Attacks on Reward Model Learning",
    "abstract": "Learning utility, or reward, models from pairwise comparisons is a fundamental component in a number of application domains. These approaches inherently entail collecting preference information from people, with feedback often provided anonymously. Since preferences are subjective, there is no gold standard to compare against; yet, reliance of high-impact systems on preference learning creates a strong motivation for malicious actors to skew data collected in this fashion to their ends. We investigate the nature and extent of this vulnerability systematically by considering a threat model in which an attacker can flip a small subset of preference comparisons with the goal of either promoting or demoting a target outcome. First, we propose two classes of algorithmic approaches for these attacks: a principled gradient-based framework, and several variants of rank-by-distance methods. Next, we demonstrate the efficacy of best attacks in both these classes in successfully achieving malicious goals on datasets from three diverse domains: autonomous control, recommendation system, and textual prompt-response preference learning. We find that the best attacks are often highly successful, achieving in the most extreme case 100% success rate with only 0.3% of the data poisoned. However, which attack is best can vary significantly across domains, demonstrating the value of our comprehensive vulnerability analysis that involves several classes of attack algorithms. In addition, we observe that the simpler and more scalable rank-by-distance approaches are often competitive with the best, and on occasion significantly outperform gradient-based methods. Finally, we show that several state-of-the-art defenses against other classes of poisoning attacks exhibit, at best, limited efficacy in our setting. ",
    "url": "https://arxiv.org/abs/2402.01920",
    "authors": [
      "Junlin Wu",
      "Jiongxiao Wang",
      "Chaowei Xiao",
      "Chenguang Wang",
      "Ning Zhang",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01928",
    "title": "Robust Counterfactual Explanations in Machine Learning: A Survey",
    "abstract": "Counterfactual explanations (CEs) are advocated as being ideally suited to providing algorithmic recourse for subjects affected by the predictions of machine learning models. While CEs can be beneficial to affected individuals, recent work has exposed severe issues related to the robustness of state-of-the-art methods for obtaining CEs. Since a lack of robustness may compromise the validity of CEs, techniques to mitigate this risk are in order. In this survey, we review works in the rapidly growing area of robust CEs and perform an in-depth analysis of the forms of robustness they consider. We also discuss existing solutions and their limitations, providing a solid foundation for future developments. ",
    "url": "https://arxiv.org/abs/2402.01928",
    "authors": [
      "Junqi Jiang",
      "Francesco Leofante",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01929",
    "title": "Sample, estimate, aggregate: A recipe for causal discovery foundation  models",
    "abstract": "Causal discovery, the task of inferring causal structure from data, promises to accelerate scientific research, inform policy making, and more. However, the per-dataset nature of existing causal discovery algorithms renders them slow, data hungry, and brittle. Inspired by foundation models, we propose a causal discovery framework where a deep learning model is pretrained to resolve predictions from classical discovery algorithms run over smaller subsets of variables. This method is enabled by the observations that the outputs from classical algorithms are fast to compute for small problems, informative of (marginal) data structure, and their structure outputs as objects remain comparable across datasets. Our method achieves state-of-the-art performance on synthetic and realistic datasets, generalizes to data generating mechanisms not seen during training, and offers inference speeds that are orders of magnitude faster than existing models. ",
    "url": "https://arxiv.org/abs/2402.01929",
    "authors": [
      "Menghua Wu",
      "Yujia Bao",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01935",
    "title": "Code Representation Learning At Scale",
    "abstract": "Recent studies have shown that code language models at scale demonstrate significant performance gains on downstream tasks, i.e., code generation. However, most of the existing works on code representation learning train models at a hundred million parameter scale using very limited pretraining corpora. In this work, we fuel code representation learning with a vast amount of code data via a two-stage pretraining scheme. We first train the encoders via a mix that leverages both randomness in masking language modeling and the structure aspect of programming language. We then enhance the representations via contrastive learning with hard negative and hard positive constructed in an unsupervised manner. We establish an off-the-shelf encoder model that persistently outperforms the existing models on a wide variety of downstream tasks by large margins. To comprehend the factors contributing to successful code representation learning, we conduct detailed ablations and share our findings on (i) a customized and effective token-level denoising scheme for source code; (ii) the importance of hard negatives and hard positives; (iii) how the proposed bimodal contrastive learning boost the cross-lingual semantic search performance; and (iv) how the pretraining schemes decide the downstream task performance scales with the model size. ",
    "url": "https://arxiv.org/abs/2402.01935",
    "authors": [
      "Dejiao Zhang",
      "Wasi Ahmad",
      "Ming Tan",
      "Hantian Ding",
      "Ramesh Nallapati",
      "Dan Roth",
      "Xiaofei Ma",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01939",
    "title": "A Morphologically-Aware Dictionary-based Data Augmentation Technique for  Machine Translation of Under-Represented Languages",
    "abstract": "The availability of parallel texts is crucial to the performance of machine translation models. However, most of the world's languages face the predominant challenge of data scarcity. In this paper, we propose strategies to synthesize parallel data relying on morpho-syntactic information and using bilingual lexicons along with a small amount of seed parallel data. Our methodology adheres to a realistic scenario backed by the small parallel seed data. It is linguistically informed, as it aims to create augmented data that is more likely to be grammatically correct. We analyze how our synthetic data can be combined with raw parallel data and demonstrate a consistent improvement in performance in our experiments on 14 languages (28 English <-> X pairs) ranging from well- to very low-resource ones. Our method leads to improvements even when using only five seed sentences and a bilingual lexicon. ",
    "url": "https://arxiv.org/abs/2402.01939",
    "authors": [
      "Md Mahfuz Ibn Alam",
      "Sina Ahmadi",
      "Antonios Anastasopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01943",
    "title": "Precedence-Constrained Winter Value for Effective Graph Data Valuation",
    "abstract": "Data valuation is essential for quantifying data's worth, aiding in assessing data quality and determining fair compensation. While existing data valuation methods have proven effective in evaluating the value of Euclidean data, they face limitations when applied to the increasingly popular graph-structured data. Particularly, graph data valuation introduces unique challenges, primarily stemming from the intricate dependencies among nodes and the exponential growth in value estimation costs. To address the challenging problem of graph data valuation, we put forth an innovative solution, Precedence-Constrained Winter (PC-Winter) Value, to account for the complex graph structure. Furthermore, we develop a variety of strategies to address the computational challenges and enable efficient approximation of PC-Winter. Extensive experiments demonstrate the effectiveness of PC-Winter across diverse datasets and tasks. ",
    "url": "https://arxiv.org/abs/2402.01943",
    "authors": [
      "Hongliang Chi",
      "Jin Wei",
      "Charu Aggarwal",
      "Yao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01960",
    "title": "Calibrated Uncertainty Quantification for Operator Learning via  Conformal Prediction",
    "abstract": "Operator learning has been increasingly adopted in scientific and engineering applications, many of which require calibrated uncertainty quantification. Since the output of operator learning is a continuous function, quantifying uncertainty simultaneously at all points in the domain is challenging. Current methods consider calibration at a single point or over one scalar function or make strong assumptions such as Gaussianity. We propose a risk-controlling quantile neural operator, a distribution-free, finite-sample functional calibration conformal prediction method. We provide a theoretical calibration guarantee on the coverage rate, defined as the expected percentage of points on the function domain whose true value lies within the predicted uncertainty ball. Empirical results on a 2D Darcy flow and a 3D car surface pressure prediction tasks validate our theoretical results, demonstrating calibrated coverage and efficient uncertainty bands outperforming baseline methods. In particular, on the 3D problem, our method is the only one that meets the target calibration percentage (percentage of test samples for which the uncertainty estimates are calibrated) of 98\\%. ",
    "url": "https://arxiv.org/abs/2402.01960",
    "authors": [
      "Ziqi Ma",
      "Kamyar Azizzadenesheli",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01964",
    "title": "No Need to Look Back: An Efficient and Scalable Approach for Temporal  Network Representation Learning",
    "abstract": "Temporal graph representation learning (TGRL) is crucial for modeling complex, dynamic systems in real-world networks. Traditional TGRL methods, though effective, suffer from high computational demands and inference latency. This is mainly induced by their inefficient sampling of temporal neighbors by backtracking the interaction history of each node when making model inference. This paper introduces a novel efficient TGRL framework, No-Looking-Back (NLB). NLB employs a \"forward recent sampling\" strategy, which bypasses the need for backtracking historical interactions. This strategy is implemented using a GPU-executable size-constrained hash table for each node, recording down-sampled recent interactions, which enables rapid response to queries with minimal inference latency. The maintenance of this hash table is highly efficient, with $O(1)$ complexity. NLB is fully compatible with GPU processing, maximizing programmability, parallelism, and power efficiency. Empirical evaluations demonstrate that NLB matches or surpasses state-of-the-art methods in accuracy for link prediction and node classification across six real-world datasets. Significantly, it is 1.32-4.40 $\\times$ faster in training, 1.2-7.94 $\\times$ more energy efficient, and 1.97-5.02 $\\times$ more effective in reducing inference latency compared to the most competitive baselines. The link to the code: https://github.com/Graph-COM/NLB. ",
    "url": "https://arxiv.org/abs/2402.01964",
    "authors": [
      "Yuhong Luo",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01965",
    "title": "Analyzing Neural Network-Based Generative Diffusion Models through  Convex Optimization",
    "abstract": "Diffusion models are becoming widely used in state-of-the-art image, video and audio generation. Score-based diffusion models stand out among these methods, necessitating the estimation of score function of the input data distribution. In this study, we present a theoretical framework to analyze two-layer neural network-based diffusion models by reframing score matching and denoising score matching as convex optimization. Though existing diffusion theory is mainly asymptotic, we characterize the exact predicted score function and establish the convergence result for neural network-based diffusion models with finite data. This work contributes to understanding what neural network-based diffusion model learns in non-asymptotic settings. ",
    "url": "https://arxiv.org/abs/2402.01965",
    "authors": [
      "Fangzhao Zhang",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.01967",
    "title": "MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate  Speech and Target Detection Using Transformer Ensembles",
    "abstract": "The automatic identification of offensive language such as hate speech is important to keep discussions civil in online communities. Identifying hate speech in multimodal content is a particularly challenging task because offensiveness can be manifested in either words or images or a juxtaposition of the two. This paper presents the MasonPerplexity submission for the Shared Task on Multimodal Hate Speech Event Detection at CASE 2024 at EACL 2024. The task is divided into two sub-tasks: sub-task A focuses on the identification of hate speech and sub-task B focuses on the identification of targets in text-embedded images during political events. We use an XLM-roBERTa-large model for sub-task A and an ensemble approach combining XLM-roBERTa-base, BERTweet-large, and BERT-base for sub-task B. Our approach obtained 0.8347 F1-score in sub-task A and 0.6741 F1-score in sub-task B ranking 3rd on both sub-tasks. ",
    "url": "https://arxiv.org/abs/2402.01967",
    "authors": [
      "Amrita Ganguly",
      "Al Nahian Bin Emran",
      "Sadiya Sayara Chowdhury Puspo",
      "Md Nishat Raihan",
      "Dhiman Goswami",
      "Marcos Zampieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01969",
    "title": "Simulation-Enhanced Data Augmentation for Machine Learning Pathloss  Prediction",
    "abstract": "Machine learning (ML) offers a promising solution to pathloss prediction. However, its effectiveness can be degraded by the limited availability of data. To alleviate these challenges, this paper introduces a novel simulation-enhanced data augmentation method for ML pathloss prediction. Our method integrates synthetic data generated from a cellular coverage simulator and independently collected real-world datasets. These datasets were collected through an extensive measurement campaign in different environments, including farms, hilly terrains, and residential areas. This comprehensive data collection provides vital ground truth for model training. A set of channel features was engineered, including geographical attributes derived from LiDAR datasets. These features were then used to train our prediction model, incorporating the highly efficient and robust gradient boosting ML algorithm, CatBoost. The integration of synthetic data, as demonstrated in our study, significantly improves the generalizability of the model in different environments, achieving a remarkable improvement of approximately 12dB in terms of mean absolute error for the best-case scenario. Moreover, our analysis reveals that even a small fraction of measurements added to the simulation training set, with proper data balance, can significantly enhance the model's performance. ",
    "url": "https://arxiv.org/abs/2402.01969",
    "authors": [
      "Ahmed P. Mohamed",
      "Byunghyun Lee",
      "Yaguang Zhang",
      "Max Hollingsworth",
      "C. Robert Anderson",
      "James V. Krogmeier",
      "David J. Love"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.01974",
    "title": "Hypergraph-Transformer (HGT) for Interactive Event Prediction in  Laparoscopic and Robotic Surgery",
    "abstract": "Understanding and anticipating intraoperative events and actions is critical for intraoperative assistance and decision-making during minimally invasive surgery. Automated prediction of events, actions, and the following consequences is addressed through various computational approaches with the objective of augmenting surgeons' perception and decision-making capabilities. We propose a predictive neural network that is capable of understanding and predicting critical interactive aspects of surgical workflow from intra-abdominal video, while flexibly leveraging surgical knowledge graphs. The approach incorporates a hypergraph-transformer (HGT) structure that encodes expert knowledge into the network design and predicts the hidden embedding of the graph. We verify our approach on established surgical datasets and applications, including the detection and prediction of action triplets, and the achievement of the Critical View of Safety (CVS). Moreover, we address specific, safety-related tasks, such as predicting the clipping of cystic duct or artery without prior achievement of the CVS. Our results demonstrate the superiority of our approach compared to unstructured alternatives. ",
    "url": "https://arxiv.org/abs/2402.01974",
    "authors": [
      "Lianhao Yin",
      "Yutong Ban",
      "Jennifer Eckhoff",
      "Ozanan Meireles",
      "Daniela Rus",
      "Guy Rosman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01975",
    "title": "Structure-Aware E(3)-Invariant Molecular Conformer Aggregation Networks",
    "abstract": "A molecule's 2D representation consists of its atoms, their attributes, and the molecule's covalent bonds. A 3D (geometric) representation of a molecule is called a conformer and consists of its atom types and Cartesian coordinates. Every conformer has a potential energy, and the lower this energy, the more likely it occurs in nature. Most existing machine learning methods for molecular property prediction consider either 2D molecular graphs or 3D conformer structure representations in isolation. Inspired by recent work on using ensembles of conformers in conjunction with 2D graph representations, we propose E(3)-invariant molecular conformer aggregation networks. The method integrates a molecule's 2D representation with that of multiple of its conformers. Contrary to prior work, we propose a novel 2D--3D aggregation mechanism based on a differentiable solver for the \\emph{Fused Gromov-Wasserstein Barycenter} problem and the use of an efficient online conformer generation method based on distance geometry. We show that the proposed aggregation mechanism is E(3) invariant and provides an efficient GPU implementation. Moreover, we demonstrate that the aggregation mechanism helps to outperform state-of-the-art property prediction methods on established datasets significantly. ",
    "url": "https://arxiv.org/abs/2402.01975",
    "authors": [
      "Duy M. H. Nguyen",
      "Nina Lukashina",
      "Tai Nguyen",
      "An T. Le",
      "TrungTin Nguyen",
      "Nhat Ho",
      "Jan Peters",
      "Daniel Sonntag",
      "Viktor Zaverkin",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01976",
    "title": "MasonPerplexity at ClimateActivism 2024: Integrating Advanced Ensemble  Techniques and Data Augmentation for Climate Activism Stance and Hate Event  Identification",
    "abstract": "The task of identifying public opinions on social media, particularly regarding climate activism and the detection of hate events, has emerged as a critical area of research in our rapidly changing world. With a growing number of people voicing either to support or oppose to climate-related issues - understanding these diverse viewpoints has become increasingly vital. Our team, MasonPerplexity, participates in a significant research initiative focused on this subject. We extensively test various models and methods, discovering that our most effective results are achieved through ensemble modeling, enhanced by data augmentation techniques like back-translation. In the specific components of this research task, our team achieved notable positions, ranking 5th, 1st, and 6th in the respective sub-tasks, thereby illustrating the effectiveness of our approach in this important field of study. ",
    "url": "https://arxiv.org/abs/2402.01976",
    "authors": [
      "Al Nahian Bin Emran",
      "Amrita Ganguly",
      "Sadiya Sayara Chowdhury Puspo",
      "Dhiman Goswami",
      "Md Nishat Raihan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01980",
    "title": "SOCIALITE-LLAMA: An Instruction-Tuned Model for Social Scientific Tasks",
    "abstract": "Social science NLP tasks, such as emotion or humor detection, are required to capture the semantics along with the implicit pragmatics from text, often with limited amounts of training data. Instruction tuning has been shown to improve the many capabilities of large language models (LLMs) such as commonsense reasoning, reading comprehension, and computer programming. However, little is known about the effectiveness of instruction tuning on the social domain where implicit pragmatic cues are often needed to be captured. We explore the use of instruction tuning for social science NLP tasks and introduce Socialite-Llama -- an open-source, instruction-tuned Llama. On a suite of 20 social science tasks, Socialite-Llama improves upon the performance of Llama as well as matches or improves upon the performance of a state-of-the-art, multi-task finetuned model on a majority of them. Further, Socialite-Llama also leads to improvement on 5 out of 6 related social tasks as compared to Llama, suggesting instruction tuning can lead to generalized social understanding. All resources including our code, model and dataset can be found through bit.ly/socialitellama. ",
    "url": "https://arxiv.org/abs/2402.01980",
    "authors": [
      "Gourab Dey",
      "Adithya V Ganesan",
      "Yash Kumar Lal",
      "Manal Shah",
      "Shreyashee Sinha",
      "Matthew Matero",
      "Salvatore Giorgi",
      "Vivek Kulkarni",
      "H. Andrew Schwartz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01987",
    "title": "Online Transfer Learning for RSV Case Detection",
    "abstract": "Transfer learning has become a pivotal technique in machine learning, renowned for its effectiveness in various real-world applications. However, a significant challenge arises when applying this approach to sequential epidemiological data, often characterized by a scarcity of labeled information. To address this challenge, we introduce Predictive Volume-Adaptive Weighting (PVAW), a novel online multi-source transfer learning method. PVAW innovatively implements a dynamic weighting mechanism within an ensemble model, allowing for the automatic adjustment of weights based on the relevance and contribution of each source and target model. We demonstrate the effectiveness of PVAW through its application in analyzing Respiratory Syncytial Virus (RSV) data, collected over multiple seasons at the University of Pittsburgh Medical Center. Our method showcases significant improvements in model performance over existing baselines, highlighting the potential of online transfer learning in handling complex, sequential data. This study not only underscores the adaptability and sophistication of transfer learning in healthcare but also sets a new direction for future research in creating advanced predictive models. ",
    "url": "https://arxiv.org/abs/2402.01987",
    "authors": [
      "Yiming Sun",
      "Yuhe Gao",
      "Runxue Bao",
      "Gregory F. Cooper",
      "Jessi Espino",
      "Harry Hochheiser",
      "Marian G. Michaels",
      "John M. Aronis",
      "Ye Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01988",
    "title": "Low-power scalable multilayer optoelectronic neural networks enabled  with incoherent light",
    "abstract": "Optical approaches have made great strides towards the goal of high-speed, energy-efficient computing necessary for modern deep learning and AI applications. Read-in and read-out of data, however, limit the overall performance of existing approaches. This study introduces a multilayer optoelectronic computing framework that alternates between optical and optoelectronic layers to implement matrix-vector multiplications and rectified linear functions, respectively. Our framework is designed for real-time, parallelized operations, leveraging 2D arrays of LEDs and photodetectors connected via independent analog electronics. We experimentally demonstrate this approach using a system with a three-layer network with two hidden layers and operate it to recognize images from the MNIST database with a recognition accuracy of 92% and classify classes from a nonlinear spiral data with 86% accuracy. By implementing multiple layers of a deep neural network simultaneously, our approach significantly reduces the number of read-ins and read-outs required and paves the way for scalable optical accelerators requiring ultra low energy. ",
    "url": "https://arxiv.org/abs/2402.01988",
    "authors": [
      "Alexander Song",
      "Sai Nikhilesh Murty Kottapalli",
      "Rahul Goyal",
      "Bernhard Sch\u00f6lkopf",
      "Peer Fischer"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2402.01994",
    "title": "Human-Centered Privacy Research in the Age of Large Language Models",
    "abstract": "The emergence of large language models (LLMs), and their increased use in user-facing systems, has led to substantial privacy concerns. To date, research on these privacy concerns has been model-centered: exploring how LLMs lead to privacy risks like memorization, or can be used to infer personal characteristics about people from their content. We argue that there is a need for more research focusing on the human aspect of these privacy issues: e.g., research on how design paradigms for LLMs affect users' disclosure behaviors, users' mental models and preferences for privacy controls, and the design of tools, systems, and artifacts that empower end-users to reclaim ownership over their personal data. To build usable, efficient, and privacy-friendly systems powered by these models with imperfect privacy properties, our goal is to initiate discussions to outline an agenda for conducting human-centered research on privacy issues in LLM-powered systems. This Special Interest Group (SIG) aims to bring together researchers with backgrounds in usable security and privacy, human-AI collaboration, NLP, or any other related domains to share their perspectives and experiences on this problem, to help our community establish a collective understanding of the challenges, research opportunities, research methods, and strategies to collaborate with researchers outside of HCI. ",
    "url": "https://arxiv.org/abs/2402.01994",
    "authors": [
      "Tianshi Li",
      "Sauvik Das",
      "Hao-Ping Lee",
      "Dakuo Wang",
      "Bingsheng Yao",
      "Zhiping Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.01995",
    "title": "Online Uniform Risk Times Sampling: First Approximation Algorithms,  Learning Augmentation with Full Confidence Interval Integration",
    "abstract": "In digital health, the strategy of allocating a limited treatment budget across available risk times is crucial to reduce user fatigue. This strategy, however, encounters a significant obstacle due to the unknown actual number of risk times, a factor not adequately addressed by existing methods lacking theoretical guarantees. This paper introduces, for the first time, the online uniform risk times sampling problem within the approximation algorithm framework. We propose two online approximation algorithms for this problem, one with and one without learning augmentation, and provide rigorous theoretical performance guarantees for them using competitive ratio analysis. We assess the performance of our algorithms using both synthetic experiments and a real-world case study on HeartSteps mobile applications. ",
    "url": "https://arxiv.org/abs/2402.01995",
    "authors": [
      "Xueqing Liu",
      "Kyra Gan",
      "Esmaeil Keyvanshokooh",
      "Susan Murphy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.02000",
    "title": "A Survey on Graph Condensation",
    "abstract": "Analytics on large-scale graphs have posed significant challenges to computational efficiency and resource requirements. Recently, Graph condensation (GC) has emerged as a solution to address challenges arising from the escalating volume of graph data. The motivation of GC is to reduce the scale of large graphs to smaller ones while preserving essential information for downstream tasks. For a better understanding of GC and to distinguish it from other related topics, we present a formal definition of GC and establish a taxonomy that systematically categorizes existing methods into three types based on its objective, and classify the formulations to generate the condensed graphs into two categories as modifying the original graphs or synthetic completely new ones. Moreover, our survey includes a comprehensive analysis of datasets and evaluation metrics in this field. Finally, we conclude by addressing challenges and limitations, outlining future directions, and offering concise guidelines to inspire future research in this field. ",
    "url": "https://arxiv.org/abs/2402.02000",
    "authors": [
      "Hongjia Xu",
      "Liangliang Zhang",
      "Yao Ma",
      "Sheng Zhou",
      "Zhuonan Zheng",
      "Bu Jiajun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02005",
    "title": "Topology-Informed Graph Transformer",
    "abstract": "Transformers have revolutionized performance in Natural Language Processing and Vision, paving the way for their integration with Graph Neural Networks (GNNs). One key challenge in enhancing graph transformers is strengthening the discriminative power of distinguishing isomorphisms of graphs, which plays a crucial role in boosting their predictive performances. To address this challenge, we introduce 'Topology-Informed Graph Transformer (TIGT)', a novel transformer enhancing both discriminative power in detecting graph isomorphisms and the overall performance of Graph Transformers. TIGT consists of four components: A topological positional embedding layer using non-isomorphic universal covers based on cyclic subgraphs of graphs to ensure unique graph representation: A dual-path message-passing layer to explicitly encode topological characteristics throughout the encoder layers: A global attention mechanism: And a graph information layer to recalibrate channel-wise graph features for better feature representation. TIGT outperforms previous Graph Transformers in classifying synthetic dataset aimed at distinguishing isomorphism classes of graphs. Additionally, mathematical analysis and empirical evaluations highlight our model's competitive edge over state-of-the-art Graph Transformers across various benchmark datasets. ",
    "url": "https://arxiv.org/abs/2402.02005",
    "authors": [
      "Yun Young Choi",
      "Sun Woo Park",
      "Minho Lee",
      "Youngho Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02007",
    "title": "Understanding Time Series Anomaly State Detection through One-Class  Classification",
    "abstract": "For a long time, research on time series anomaly detection has mainly focused on finding outliers within a given time series. Admittedly, this is consistent with some practical problems, but in other practical application scenarios, people are concerned about: assuming a standard time series is given, how to judge whether another test time series deviates from the standard time series, which is more similar to the problem discussed in one-class classification (OCC). Therefore, in this article, we try to re-understand and define the time series anomaly detection problem through OCC, which we call 'time series anomaly state detection problem'. We first use stochastic processes and hypothesis testing to strictly define the 'time series anomaly state detection problem', and its corresponding anomalies. Then, we use the time series classification dataset to construct an artificial dataset corresponding to the problem. We compile 38 anomaly detection algorithms and correct some of the algorithms to adapt to handle this problem. Finally, through a large number of experiments, we fairly compare the actual performance of various time series anomaly detection algorithms, providing insights and directions for future research by researchers. ",
    "url": "https://arxiv.org/abs/2402.02007",
    "authors": [
      "Hanxu Zhou",
      "Yuan Zhang",
      "Guangjie Leng",
      "Ruofan Wang",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02009",
    "title": "Robust Multi-Task Learning with Excess Risks",
    "abstract": "Multi-task learning (MTL) considers learning a joint model for multiple tasks by optimizing a convex combination of all task losses. To solve the optimization problem, existing methods use an adaptive weight updating scheme, where task weights are dynamically adjusted based on their respective losses to prioritize difficult tasks. However, these algorithms face a great challenge whenever label noise is present, in which case excessive weights tend to be assigned to noisy tasks that have relatively large Bayes optimal errors, thereby overshadowing other tasks and causing performance to drop across the board. To overcome this limitation, we propose Multi-Task Learning with Excess Risks (ExcessMTL), an excess risk-based task balancing method that updates the task weights by their distances to convergence instead. Intuitively, ExcessMTL assigns higher weights to worse-trained tasks that are further from convergence. To estimate the excess risks, we develop an efficient and accurate method with Taylor approximation. Theoretically, we show that our proposed algorithm achieves convergence guarantees and Pareto stationarity. Empirically, we evaluate our algorithm on various MTL benchmarks and demonstrate its superior performance over existing methods in the presence of label noise. ",
    "url": "https://arxiv.org/abs/2402.02009",
    "authors": [
      "Yifei He",
      "Shiji Zhou",
      "Guojun Zhang",
      "Hyokun Yun",
      "Yi Xu",
      "Belinda Zeng",
      "Trishul Chilimbi",
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02020",
    "title": "NeuV-SLAM: Fast Neural Multiresolution Voxel Optimization for RGBD Dense  SLAM",
    "abstract": "We introduce NeuV-SLAM, a novel dense simultaneous localization and mapping pipeline based on neural multiresolution voxels, characterized by ultra-fast convergence and incremental expansion capabilities. This pipeline utilizes RGBD images as input to construct multiresolution neural voxels, achieving rapid convergence while maintaining robust incremental scene reconstruction and camera tracking. Central to our methodology is to propose a novel implicit representation, termed VDF that combines the implementation of neural signed distance field (SDF) voxels with an SDF activation strategy. This approach entails the direct optimization of color features and SDF values anchored within the voxels, substantially enhancing the rate of scene convergence. To ensure the acquisition of clear edge delineation, SDF activation is designed, which maintains exemplary scene representation fidelity even under constraints of voxel resolution. Furthermore, in pursuit of advancing rapid incremental expansion with low computational overhead, we developed hashMV, a novel hash-based multiresolution voxel management structure. This architecture is complemented by a strategically designed voxel generation technique that synergizes with a two-dimensional scene prior. Our empirical evaluations, conducted on the Replica and ScanNet Datasets, substantiate NeuV-SLAM's exceptional efficacy in terms of convergence speed, tracking accuracy, scene reconstruction, and rendering quality. ",
    "url": "https://arxiv.org/abs/2402.02020",
    "authors": [
      "Wenzhi Guo",
      "Bing Wang",
      "Lijun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.02023",
    "title": "Self-Supervised Contrastive Forecasting",
    "abstract": "Long-term forecasting presents unique challenges due to the time and memory complexity of handling long sequences. Existing methods, which rely on sliding windows to process long sequences, struggle to effectively capture long-term variations that are partially caught within the short window (i.e., outer-window variations). In this paper, we introduce a novel approach that overcomes this limitation by employing contrastive learning and enhanced decomposition architecture, specifically designed to focus on long-term variations. To this end, our contrastive loss incorporates global autocorrelation held in the whole time series, which facilitates the construction of positive and negative pairs in a self-supervised manner. When combined with our decomposition networks, our contrastive learning significantly improves long-term forecasting performance. Extensive experiments demonstrate that our approach outperforms 14 baseline models in multiple experiments over nine long-term benchmarks, especially in challenging scenarios that require a significantly long output for forecasting. Source code is available at https://github.com/junwoopark92/Self-Supervised-Contrastive-Forecsating. ",
    "url": "https://arxiv.org/abs/2402.02023",
    "authors": [
      "Junwoo Park",
      "Daehoon Gwak",
      "Jaegul Choo",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02026",
    "title": "Multimodal-Enhanced Objectness Learner for Corner Case Detection in  Autonomous Driving",
    "abstract": "Previous works on object detection have achieved high accuracy in closed-set scenarios, but their performance in open-world scenarios is not satisfactory. One of the challenging open-world problems is corner case detection in autonomous driving. Existing detectors struggle with these cases, relying heavily on visual appearance and exhibiting poor generalization ability. In this paper, we propose a solution by reducing the discrepancy between known and unknown classes and introduce a multimodal-enhanced objectness notion learner. Leveraging both vision-centric and image-text modalities, our semi-supervised learning framework imparts objectness knowledge to the student model, enabling class-aware detection. Our approach, Multimodal-Enhanced Objectness Learner (MENOL) for Corner Case Detection, significantly improves recall for novel classes with lower training costs. By achieving a 76.6% mAR-corner and 79.8% mAR-agnostic on the CODA-val dataset with just 5100 labeled training images, MENOL outperforms the baseline ORE by 71.3% and 60.6%, respectively. The code will be available at https://github.com/tryhiseyyysum/MENOL. ",
    "url": "https://arxiv.org/abs/2402.02026",
    "authors": [
      "Lixing Xiao",
      "Ruixiao Shi",
      "Xiaoyang Tang",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02031",
    "title": "Multi-fidelity physics constrained neural networks for dynamical systems",
    "abstract": "Physics-constrained neural networks are commonly employed to enhance prediction robustness compared to purely data-driven models, achieved through the inclusion of physical constraint losses during the model training process. However, one of the major challenges of physics-constrained neural networks consists of the training complexity especially for high-dimensional systems. In fact, conventional physics-constrained models rely on singular-fidelity data necessitating the assessment of physical constraints within high-dimensional fields, which introduces computational difficulties. Furthermore, due to the fixed input size of the neural networks, employing multi-fidelity training data can also be cumbersome. In this paper, we propose the Multi-Scale Physics-Constrained Neural Network (MSPCNN), which offers a novel methodology for incorporating data with different levels of fidelity into a unified latent space through a customised multi-fidelity autoencoder. Additionally, multiple decoders are concurrently trained to map latent representations of inputs into various fidelity physical spaces. As a result, during the training of predictive models, physical constraints can be evaluated within low-fidelity spaces, yielding a trade-off between training efficiency and accuracy. In addition, unlike conventional methods, MSPCNN also manages to employ multi-fidelity data to train the predictive model. We assess the performance of MSPCNN in two fluid dynamics problems, namely a two-dimensional Burgers' system and a shallow water system. Numerical results clearly demonstrate the enhancement of prediction accuracy and noise robustness when introducing physical constraints in low-fidelity fields. On the other hand, as expected, the training complexity can be significantly reduced by computing physical constraint loss in the low-fidelity field rather than the high-fidelity one. ",
    "url": "https://arxiv.org/abs/2402.02031",
    "authors": [
      "Hao Zhou",
      "Sibo Cheng",
      "Rossella Arcucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2402.02032",
    "title": "RobustTSF: Towards Theory and Design of Robust Time Series Forecasting  with Anomalies",
    "abstract": "Time series forecasting is an important and forefront task in many real-world applications. However, most of time series forecasting techniques assume that the training data is clean without anomalies. This assumption is unrealistic since the collected time series data can be contaminated in practice. The forecasting model will be inferior if it is directly trained by time series with anomalies. Thus it is essential to develop methods to automatically learn a robust forecasting model from the contaminated data. In this paper, we first statistically define three types of anomalies, then theoretically and experimentally analyze the loss robustness and sample robustness when these anomalies exist. Based on our analyses, we propose a simple and efficient algorithm to learn a robust forecasting model. Extensive experiments show that our method is highly robust and outperforms all existing approaches. The code is available at https://github.com/haochenglouis/RobustTSF. ",
    "url": "https://arxiv.org/abs/2402.02032",
    "authors": [
      "Hao Cheng",
      "Qingsong Wen",
      "Yang Liu",
      "Liang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02034",
    "title": "Universal Post-Training Reverse-Engineering Defense Against Backdoors in  Deep Neural Networks",
    "abstract": "A variety of defenses have been proposed against backdoors attacks on deep neural network (DNN) classifiers. Universal methods seek to reliably detect and/or mitigate backdoors irrespective of the incorporation mechanism used by the attacker, while reverse-engineering methods often explicitly assume one. In this paper, we describe a new detector that: relies on internal feature map of the defended DNN to detect and reverse-engineer the backdoor and identify its target class; can operate post-training (without access to the training dataset); is highly effective for various incorporation mechanisms (i.e., is universal); and which has low computational overhead and so is scalable. Our detection approach is evaluated for different attacks on a benchmark CIFAR-10 image classifier. ",
    "url": "https://arxiv.org/abs/2402.02034",
    "authors": [
      "Xi Li",
      "Hang Wang",
      "David J. Miller",
      "George Kesidis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.02036",
    "title": "Interpreting Graph Neural Networks with In-Distributed Proxies",
    "abstract": "Graph Neural Networks (GNNs) have become a building block in graph data processing, with wide applications in critical domains. The growing needs to deploy GNNs in high-stakes applications necessitate explainability for users in the decision-making processes. A popular paradigm for the explainability of GNNs is to identify explainable subgraphs by comparing their labels with the ones of original graphs. This task is challenging due to the substantial distributional shift from the original graphs in the training set to the set of explainable subgraphs, which prevents accurate prediction of labels with the subgraphs. To address it, in this paper, we propose a novel method that generates proxy graphs for explainable subgraphs that are in the distribution of training data. We introduce a parametric method that employs graph generators to produce proxy graphs. A new training objective based on information theory is designed to ensure that proxy graphs not only adhere to the distribution of training data but also preserve essential explanatory factors. Such generated proxy graphs can be reliably used for approximating the predictions of the true labels of explainable subgraphs. Empirical evaluations across various datasets demonstrate our method achieves more accurate explanations for GNNs. ",
    "url": "https://arxiv.org/abs/2402.02036",
    "authors": [
      "Zhuomin Chen",
      "Jiaxing Zhang",
      "Jingchao Ni",
      "Xiaoting Li",
      "Yuchen Bian",
      "Md Mezbahul Islam",
      "Ananda Mohan Mondal",
      "Hua Wei",
      "Dongsheng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02037",
    "title": "EffiBench: Benchmarking the Efficiency of Automatically Generated Code",
    "abstract": "Code generation models have increasingly become integral to aiding software development, offering assistance in tasks such as code completion, debugging, and code translation. Although current research has thoroughly examined the correctness of code produced by code generation models, a vital aspect, i.e., the efficiency of the generated code, has often been neglected. This paper presents EffiBench, a benchmark with 1,000 efficiency-critical coding problems for assessing the efficiency of code generated by code generation models. EffiBench contains a diverse set of LeetCode coding problems. Each problem is paired with an executable human-written canonical solution. With EffiBench, we empirically examine the capability of 21 Large Language Models (13 open-sourced and 8 closed-sourced) in generating efficient code. The results demonstrate that GPT-4-turbo generates the most efficient code, significantly outperforming Palm-2-chat-bison, Claude-instant-1, Gemini-pro, GPT-4, and GPT-3.5. Nevertheless, its code efficiency is still worse than the efficiency of human-written canonical solutions. In particular, the average and worst execution time of GPT-4-turbo generated code is 1.69 and 45.49 times that of the canonical solutions. ",
    "url": "https://arxiv.org/abs/2402.02037",
    "authors": [
      "Dong Huang",
      "Jie M.Zhang",
      "Yuhao Qing",
      "Heming Cui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.02045",
    "title": "MLIP: Enhancing Medical Visual Representation with Divergence Encoder  and Knowledge-guided Contrastive Learning",
    "abstract": "The scarcity of annotated data has sparked significant interest in unsupervised pre-training methods that leverage medical reports as auxiliary signals for medical visual representation learning. However, existing research overlooks the multi-granularity nature of medical visual representation and lacks suitable contrastive learning techniques to improve the models' generalizability across different granularities, leading to the underutilization of image-text information. To address this, we propose MLIP, a novel framework leveraging domain-specific medical knowledge as guiding signals to integrate language information into the visual domain through image-text contrastive learning. Our model includes global contrastive learning with our designed divergence encoder, local token-knowledge-patch alignment contrastive learning, and knowledge-guided category-level contrastive learning with expert knowledge. Experimental evaluations reveal the efficacy of our model in enhancing transfer performance for tasks such as image classification, object detection, and semantic segmentation. Notably, MLIP surpasses state-of-the-art methods even with limited annotated data, highlighting the potential of multimodal pre-training in advancing medical representation learning. ",
    "url": "https://arxiv.org/abs/2402.02045",
    "authors": [
      "Zhe Li",
      "Laurence T. Yang",
      "Bocheng Ren",
      "Xin Nie",
      "Zhangyang Gao",
      "Cheng Tan",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02046",
    "title": "TCI-Former: Thermal Conduction-Inspired Transformer for Infrared Small  Target Detection",
    "abstract": "Infrared small target detection (ISTD) is critical to national security and has been extensively applied in military areas. ISTD aims to segment small target pixels from background. Most ISTD networks focus on designing feature extraction blocks or feature fusion modules, but rarely describe the ISTD process from the feature map evolution perspective. In the ISTD process, the network attention gradually shifts towards target areas. We abstract this process as the directional movement of feature map pixels to target areas through convolution, pooling and interactions with surrounding pixels, which can be analogous to the movement of thermal particles constrained by surrounding variables and particles. In light of this analogy, we propose Thermal Conduction-Inspired Transformer (TCI-Former) based on the theoretical principles of thermal conduction. According to thermal conduction differential equation in heat dynamics, we derive the pixel movement differential equation (PMDE) in the image domain and further develop two modules: Thermal Conduction-Inspired Attention (TCIA) and Thermal Conduction Boundary Module (TCBM). TCIA incorporates finite difference method with PMDE to reach a numerical approximation so that target body features can be extracted. To further remove errors in boundary areas, TCBM is designed and supervised by boundary masks to refine target body features with fine boundary details. Experiments on IRSTD-1k and NUAA-SIRST demonstrate the superiority of our method. ",
    "url": "https://arxiv.org/abs/2402.02046",
    "authors": [
      "Tianxiang Chen",
      "Zhentao Tan",
      "Qi Chu",
      "Yue Wu",
      "Bin Liu",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02047",
    "title": "Quality and Trust in LLM-generated Code",
    "abstract": "Machine learning models are widely used but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or not. For example, outputs can be associated with a confidence measure; if this confidence measure is strongly associated with likelihood of correctness, then the model is said to be well-calibrated. In this case, for example, high-confidence outputs could be safely accepted, and low-confidence outputs rejected. Calibration has so far been studied in non-generative (e.g., classification) settings, especially in Software Engineering. However, generated code can quite often be wrong: Developers need to know when they should e.g., directly use, use after careful review, or discard model-generated code; thus Calibration is vital in generative settings. However, the notion of correctness of generated code is non-trivial, and thus so is Calibration. In this paper we make several contributions. We develop a framework for evaluating the Calibration of code-generating models. We consider several tasks, correctness criteria, datasets, and approaches, and find that by and large generative code models are not well-calibrated out of the box. We then show how Calibration can be improved, using standard methods such as Platt scaling. Our contributions will lead to better-calibrated decision-making in the current use of code generated by language models, and offers a framework for future research to further improve calibration methods for generative models in Software Engineering. ",
    "url": "https://arxiv.org/abs/2402.02047",
    "authors": [
      "Claudio Spiess",
      "David Gros",
      "Kunal Suresh Pai",
      "Michael Pradel",
      "Md Rafiqul Islam Rabin",
      "Susmit Jha",
      "Prem Devanbu",
      "Toufique Ahmed"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02051",
    "title": "Nonlinear subspace clustering by functional link neural networks",
    "abstract": "Nonlinear subspace clustering based on a feed-forward neural network has been demonstrated to provide better clustering accuracy than some advanced subspace clustering algorithms. While this approach demonstrates impressive outcomes, it involves a balance between effectiveness and computational cost. In this study, we employ a functional link neural network to transform data samples into a nonlinear domain. Subsequently, we acquire a self-representation matrix through a learning mechanism that builds upon the mapped samples. As the functional link neural network is a single-layer neural network, our proposed method achieves high computational efficiency while ensuring desirable clustering performance. By incorporating the local similarity regularization to enhance the grouping effect, our proposed method further improves the quality of the clustering results. Additionally, we introduce a convex combination subspace clustering scheme, which combining a linear subspace clustering method with the functional link neural network subspace clustering approach. This combination approach allows for a dynamic balance between linear and nonlinear representations. Extensive experiments confirm the advancement of our methods. The source code will be released on https://lshi91.github.io/ soon. ",
    "url": "https://arxiv.org/abs/2402.02051",
    "authors": [
      "Long Shi",
      "Lei Cao",
      "Zhongpu Chen",
      "Badong Chen",
      "Yu Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02054",
    "title": "Neural Scaling Laws on Graphs",
    "abstract": "Deep graph models (e.g., graph neural networks and graph transformers) have become important techniques for leveraging knowledge across various types of graphs. Yet, the scaling properties of deep graph models have not been systematically investigated, casting doubt on the feasibility of achieving large graph models through enlarging the model and dataset sizes. In this work, we delve into neural scaling laws on graphs from both model and data perspectives. We first verify the validity of such laws on graphs, establishing formulations to describe the scaling behaviors. For model scaling, we investigate the phenomenon of scaling law collapse and identify overfitting as the potential reason. Moreover, we reveal that the model depth of deep graph models can impact the model scaling behaviors, which differ from observations in other domains such as CV and NLP. For data scaling, we suggest that the number of graphs can not effectively metric the graph data volume in scaling law since the sizes of different graphs are highly irregular. Instead, we reform the data scaling law with the number of edges as the metric to address the irregular graph sizes. We further demonstrate the reformed law offers a unified view of the data scaling behaviors for various fundamental graph tasks including node classification, link prediction, and graph classification. This work provides valuable insights into neural scaling laws on graphs, which can serve as an essential step toward large graph models. ",
    "url": "https://arxiv.org/abs/2402.02054",
    "authors": [
      "Jingzhe Liu",
      "Haitao Mao",
      "Zhikai Chen",
      "Tong Zhao",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02060",
    "title": "DiffVein: A Unified Diffusion Network for Finger Vein Segmentation and  Authentication",
    "abstract": "Finger vein authentication, recognized for its high security and specificity, has become a focal point in biometric research. Traditional methods predominantly concentrate on vein feature extraction for discriminative modeling, with a limited exploration of generative approaches. Suffering from verification failure, existing methods often fail to obtain authentic vein patterns by segmentation. To fill this gap, we introduce DiffVein, a unified diffusion model-based framework which simultaneously addresses vein segmentation and authentication tasks. DiffVein is composed of two dedicated branches: one for segmentation and the other for denoising. For better feature interaction between these two branches, we introduce two specialized modules to improve their collective performance. The first, a mask condition module, incorporates the semantic information of vein patterns from the segmentation branch into the denoising process. Additionally, we also propose a Semantic Difference Transformer (SD-Former), which employs Fourier-space self-attention and cross-attention modules to extract category embedding before feeding it to the segmentation task. In this way, our framework allows for a dynamic interplay between diffusion and segmentation embeddings, thus vein segmentation and authentication tasks can inform and enhance each other in the joint training. To further optimize our model, we introduce a Fourier-space Structural Similarity (FourierSIM) loss function, which is tailored to improve the denoising network's learning efficacy. Extensive experiments on the USM and THU-MVFV3V datasets substantiates DiffVein's superior performance, setting new benchmarks in both vein segmentation and authentication tasks. ",
    "url": "https://arxiv.org/abs/2402.02060",
    "authors": [
      "Yanjun Liu",
      "Wenming Yang",
      "Qingmin Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02063",
    "title": "Improving the Learning of Code Review Successive Tasks with Cross-Task  Knowledge Distillation",
    "abstract": "Code review is a fundamental process in software development that plays a pivotal role in ensuring code quality and reducing the likelihood of errors and bugs. However, code review can be complex, subjective, and time-consuming. Quality estimation, comment generation, and code refinement constitute the three key tasks of this process, and their automation has traditionally been addressed separately in the literature using different approaches. In particular, recent efforts have focused on fine-tuning pre-trained language models to aid in code review tasks, with each task being considered in isolation. We believe that these tasks are interconnected, and their fine-tuning should consider this interconnection. In this paper, we introduce a novel deep-learning architecture, named DISCOREV, which employs cross-task knowledge distillation to address these tasks simultaneously. In our approach, we utilize a cascade of models to enhance both comment generation and code refinement models. The fine-tuning of the comment generation model is guided by the code refinement model, while the fine-tuning of the code refinement model is guided by the quality estimation model. We implement this guidance using two strategies: a feedback-based learning objective and an embedding alignment objective. We evaluate DISCOREV by comparing it to state-of-the-art methods based on independent training and fine-tuning. Our results show that our approach generates better review comments, as measured by the BLEU score, as well as more accurate code refinement according to the CodeBLEU score ",
    "url": "https://arxiv.org/abs/2402.02063",
    "authors": [
      "Oussama Ben Sghaier",
      "Houari Sahraoui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.02065",
    "title": "Training Implicit Networks for Image Deblurring using Jacobian-Free  Backpropagation",
    "abstract": "Recent efforts in applying implicit networks to solve inverse problems in imaging have achieved competitive or even superior results when compared to feedforward networks. These implicit networks only require constant memory during backpropagation, regardless of the number of layers. However, they are not necessarily easy to train. Gradient calculations are computationally expensive because they require backpropagating through a fixed point. In particular, this process requires solving a large linear system whose size is determined by the number of features in the fixed point iteration. This paper explores a recently proposed method, Jacobian-free Backpropagation (JFB), a backpropagation scheme that circumvents such calculation, in the context of image deblurring problems. Our results show that JFB is comparable against fine-tuned optimization schemes, state-of-the-art (SOTA) feedforward networks, and existing implicit networks at a reduced computational cost. ",
    "url": "https://arxiv.org/abs/2402.02065",
    "authors": [
      "Linghai Liu",
      "Shuaicheng Tong",
      "Lisa Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02067",
    "title": "RIDERS: Radar-Infrared Depth Estimation for Robust Sensing",
    "abstract": "Dense depth recovery is crucial in autonomous driving, serving as a foundational element for obstacle avoidance, 3D object detection, and local path planning. Adverse weather conditions, including haze, dust, rain, snow, and darkness, introduce significant challenges to accurate dense depth estimation, thereby posing substantial safety risks in autonomous driving. These challenges are particularly pronounced for traditional depth estimation methods that rely on short electromagnetic wave sensors, such as visible spectrum cameras and near-infrared LiDAR, due to their susceptibility to diffraction noise and occlusion in such environments. To fundamentally overcome this issue, we present a novel approach for robust metric depth estimation by fusing a millimeter-wave Radar and a monocular infrared thermal camera, which are capable of penetrating atmospheric particles and unaffected by lighting conditions. Our proposed Radar-Infrared fusion method achieves highly accurate and finely detailed dense depth estimation through three stages, including monocular depth prediction with global scale alignment, quasi-dense Radar augmentation by learning Radar-pixels correspondences, and local scale refinement of dense depth using a scale map learner. Our method achieves exceptional visual quality and accurate metric estimation by addressing the challenges of ambiguity and misalignment that arise from directly fusing multi-modal long-wave features. We evaluate the performance of our approach on the NTU4DRadLM dataset and our self-collected challenging ZJU-Multispectrum dataset. Especially noteworthy is the unprecedented robustness demonstrated by our proposed method in smoky scenarios. Our code will be released at \\url{https://github.com/MMOCKING/RIDERS}. ",
    "url": "https://arxiv.org/abs/2402.02067",
    "authors": [
      "Han Li",
      "Yukai Ma",
      "Yuehao Huang",
      "Yaqing Gu",
      "Weihua Xu",
      "Yong Liu",
      "Xingxing Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02078",
    "title": "Exploring the Robustness of Task-oriented Dialogue Systems for  Colloquial German Varieties",
    "abstract": "Mainstream cross-lingual task-oriented dialogue (ToD) systems leverage the transfer learning paradigm by training a joint model for intent recognition and slot-filling in English and applying it, zero-shot, to other languages. We address a gap in prior research, which often overlooked the transfer to lower-resource colloquial varieties due to limited test data. Inspired by prior work on English varieties, we craft and manually evaluate perturbation rules that transform German sentences into colloquial forms and use them to synthesize test sets in four ToD datasets. Our perturbation rules cover 18 distinct language phenomena, enabling us to explore the impact of each perturbation on slot and intent performance. Using these new datasets, we conduct an experimental evaluation across six different transformers. Here, we demonstrate that when applied to colloquial varieties, ToD systems maintain their intent recognition performance, losing 6% (4.62 percentage points) in accuracy on average. However, they exhibit a significant drop in slot detection, with a decrease of 31% (21 percentage points) in slot F1 score. Our findings are further supported by a transfer experiment from Standard American English to synthetic Urban African American Vernacular English. ",
    "url": "https://arxiv.org/abs/2402.02078",
    "authors": [
      "Ekaterina Artemova",
      "Verena Blaschke",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.02085",
    "title": "DeCoF: Generated Video Detection via Frame Consistency",
    "abstract": "The escalating quality of video generated by advanced video generation methods leads to new security challenges in society, which makes generated video detection an urgent research priority.To foster collaborative research in this area, we construct the first open-source dataset explicitly for generated video detection, providing a valuable resource for the community to benchmark and improve detection methodologies. Through a series of carefully designed probe experiments, our study explores the significance of temporal and spatial artifacts in developing general and robust detectors for generated video. Based on the principle of video frame consistency, we introduce a simple yet effective detection model (DeCoF) that eliminates the impact of spatial artifacts during generalizing feature learning. Our extensive experiments demonstrate the efficacy of DeCoF in detecting videos produced by unseen video generation models and confirm its powerful generalization capabilities across several commercial proprietary models. ",
    "url": "https://arxiv.org/abs/2402.02085",
    "authors": [
      "Long Ma",
      "Jiajia Zhang",
      "Hongping Deng",
      "Ningyu Zhang",
      "Yong Liao",
      "Haiyang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02090",
    "title": "Physical Perception Network and an All-weather Multi-modality Benchmark  for Adverse Weather Image Fusion",
    "abstract": "Multi-modality image fusion (MMIF) integrates the complementary information from different modal images to provide comprehensive and objective interpretation of a scenes. However, existing MMIF methods lack the ability to resist different weather interferences in real-life scenarios, preventing them from being useful in practical applications such as autonomous driving. To bridge this research gap, we proposed an all-weather MMIF model. Regarding deep learning architectures, their network designs are often viewed as a black box, which limits their multitasking capabilities. For deweathering module, we propose a physically-aware clear feature prediction module based on an atmospheric scattering model that can deduce variations in light transmittance from both scene illumination and depth. For fusion module, We utilize a learnable low-rank representation model to decompose images into low-rank and sparse components. This highly interpretable feature separation allows us to better observe and understand images. Furthermore, we have established a benchmark for MMIF research under extreme weather conditions. It encompasses multiple scenes under three types of weather: rain, haze, and snow, with each weather condition further subdivided into various impact levels. Extensive fusion experiments under adverse weather demonstrate that the proposed algorithm has excellent detail recovery and multi-modality feature extraction capabilities. ",
    "url": "https://arxiv.org/abs/2402.02090",
    "authors": [
      "Xilai Li",
      "Wuyang Liu",
      "Xiaosong Li",
      "Haishu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02096",
    "title": "Decomposition-based and Interference Perception for Infrared and Visible  Image Fusion in Complex Scenes",
    "abstract": "Infrared and visible image fusion has emerged as a prominent research in computer vision. However, little attention has been paid on complex scenes fusion, causing existing techniques to produce sub-optimal results when suffers from real interferences. To fill this gap, we propose a decomposition-based and interference perception image fusion method. Specifically, we classify the pixels of visible image from the degree of scattering of light transmission, based on which we then separate the detail and energy information of the image. This refined decomposition facilitates the proposed model in identifying more interfering pixels that are in complex scenes. To strike a balance between denoising and detail preservation, we propose an adaptive denoising scheme for fusing detail components. Meanwhile, we propose a new weighted fusion rule by considering the distribution of image energy information from the perspective of multiple directions. Extensive experiments in complex scenes fusions cover adverse weathers, noise, blur, overexposure, fire, as well as downstream tasks including semantic segmentation, object detection, salient object detection and depth estimation, consistently indicate the effectiveness and superiority of the proposed method compared with the recent representative methods. ",
    "url": "https://arxiv.org/abs/2402.02096",
    "authors": [
      "Xilai Li",
      "Xiaosong Li",
      "Haishu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02112",
    "title": "S-NeRF++: Autonomous Driving Simulation via Neural Reconstruction and  Generation",
    "abstract": "Autonomous driving simulation system plays a crucial role in enhancing self-driving data and simulating complex and rare traffic scenarios, ensuring navigation safety. However, traditional simulation systems, which often heavily rely on manual modeling and 2D image editing, struggled with scaling to extensive scenes and generating realistic simulation data. In this study, we present S-NeRF++, an innovative autonomous driving simulation system based on neural reconstruction. Trained on widely-used self-driving datasets such as nuScenes and Waymo, S-NeRF++ can generate a large number of realistic street scenes and foreground objects with high rendering quality as well as offering considerable flexibility in manipulation and simulation. Specifically, S-NeRF++ is an enhanced neural radiance field for synthesizing large-scale scenes and moving vehicles, with improved scene parameterization and camera pose learning. The system effectively utilizes noisy and sparse LiDAR data to refine training and address depth outliers, ensuring high quality reconstruction and novel-view rendering. It also provides a diverse foreground asset bank through reconstructing and generating different foreground vehicles to support comprehensive scenario creation. Moreover, we have developed an advanced foreground-background fusion pipeline that skillfully integrates illumination and shadow effects, further enhancing the realism of our simulations. With the high-quality simulated data provided by our S-NeRF++, we found the perception methods enjoy performance boost on several autonomous driving downstream tasks, which further demonstrate the effectiveness of our proposed simulator. ",
    "url": "https://arxiv.org/abs/2402.02112",
    "authors": [
      "Yurui Chen",
      "Junge Zhang",
      "Ziyang Xie",
      "Wenye Li",
      "Feihu Zhang",
      "Jiachen Lu",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02124",
    "title": "Grammar-based evolutionary approach for automated workflow composition  with domain-specific operators and ensemble diversity",
    "abstract": "The process of extracting valuable and novel insights from raw data involves a series of complex steps. In the realm of Automated Machine Learning (AutoML), a significant research focus is on automating aspects of this process, specifically tasks like selecting algorithms and optimising their hyper-parameters. A particularly challenging task in AutoML is automatic workflow composition (AWC). AWC aims to identify the most effective sequence of data preprocessing and ML algorithms, coupled with their best hyper-parameters, for a specific dataset. However, existing AWC methods are limited in how many and in what ways they can combine algorithms within a workflow. Addressing this gap, this paper introduces EvoFlow, a grammar-based evolutionary approach for AWC. EvoFlow enhances the flexibility in designing workflow structures, empowering practitioners to select algorithms that best fit their specific requirements. EvoFlow stands out by integrating two innovative features. First, it employs a suite of genetic operators, designed specifically for AWC, to optimise both the structure of workflows and their hyper-parameters. Second, it implements a novel updating mechanism that enriches the variety of predictions made by different workflows. Promoting this diversity helps prevent the algorithm from overfitting. With this aim, EvoFlow builds an ensemble whose workflows differ in their misclassified instances. To evaluate EvoFlow's effectiveness, we carried out empirical validation using a set of classification benchmarks. We begin with an ablation study to demonstrate the enhanced performance attributable to EvoFlow's unique components. Then, we compare EvoFlow with other AWC approaches, encompassing both evolutionary and non-evolutionary techniques. Our findings show that EvoFlow's specialised genetic operators and updating mechanism substantially outperform current leading methods[..] ",
    "url": "https://arxiv.org/abs/2402.02124",
    "authors": [
      "Rafael Barbudo",
      "Aurora Ram\u00edrez",
      "Jos\u00e9 Ra\u00fal Romero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02130",
    "title": "Rendering Graphs for Graph Reasoning in Multimodal Large Language Models",
    "abstract": "Large Language Models (LLMs) are increasingly used for various tasks with graph structures, such as robotic planning, knowledge graph completion, and common-sense reasoning. Though LLMs can comprehend graph information in a textual format, they overlook the rich visual modality, which is an intuitive way for humans to comprehend structural information and conduct graph reasoning. The potential benefits and capabilities of representing graph structures as visual images (i.e., visual graph) is still unexplored. In this paper, we take the first step in incorporating visual information into graph reasoning tasks and propose a new benchmark GITQA, where each sample is a tuple (graph, image, textual description). We conduct extensive experiments on the GITQA benchmark using state-of-the-art multimodal LLMs. Results on graph reasoning tasks show that combining textual and visual information together performs better than using one modality alone. Moreover, the LLaVA-7B/13B models finetuned on the training set achieve higher accuracy than the closed-source model GPT-4(V). We also study the effects of augmentations in graph reasoning. ",
    "url": "https://arxiv.org/abs/2402.02130",
    "authors": [
      "Yanbin Wei",
      "Shuai Fu",
      "Weisen Jiang",
      "James T. Kwok",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.02144",
    "title": "Probing Critical Learning Dynamics of PLMs for Hate Speech Detection",
    "abstract": "Despite the widespread adoption, there is a lack of research into how various critical aspects of pretrained language models (PLMs) affect their performance in hate speech detection. Through five research questions, our findings and recommendations lay the groundwork for empirically investigating different aspects of PLMs' use in hate speech detection. We deep dive into comparing different pretrained models, evaluating their seed robustness, finetuning settings, and the impact of pretraining data collection time. Our analysis reveals early peaks for downstream tasks during pretraining, the limited benefit of employing a more recent pretraining corpus, and the significance of specific layers during finetuning. We further call into question the use of domain-specific models and highlight the need for dynamic datasets for benchmarking hate speech detection. ",
    "url": "https://arxiv.org/abs/2402.02144",
    "authors": [
      "Sarah Masud",
      "Mohammad Aflah Khan",
      "Vikram Goyal",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.02150",
    "title": "Data-Driven Prediction of Seismic Intensity Distributions Featuring  Hybrid Classification-Regression Models",
    "abstract": "Earthquakes are among the most immediate and deadly natural disasters that humans face. Accurately forecasting the extent of earthquake damage and assessing potential risks can be instrumental in saving numerous lives. In this study, we developed linear regression models capable of predicting seismic intensity distributions based on earthquake parameters: location, depth, and magnitude. Because it is completely data-driven, it can predict intensity distributions without geographical information. The dataset comprises seismic intensity data from earthquakes that occurred in the vicinity of Japan between 1997 and 2020, specifically containing 1,857 instances of earthquakes with a magnitude of 5.0 or greater, sourced from the Japan Meteorological Agency. We trained both regression and classification models and combined them to take advantage of both to create a hybrid model. The proposed model outperformed commonly used Ground Motion Prediction Equations (GMPEs) in terms of the correlation coefficient, F1 score, and MCC. Furthermore, the proposed model can predict even abnormal seismic intensity distributions, a task at conventional GMPEs often struggle. ",
    "url": "https://arxiv.org/abs/2402.02150",
    "authors": [
      "Koyu Mizutani",
      "Haruki Mitarai",
      "Kakeru Miyazaki",
      "Soichiro Kumano",
      "Toshihiko Yamasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02154",
    "title": "Evaluating the Robustness of Off-Road Autonomous Driving Segmentation  against Adversarial Attacks: A Dataset-Centric analysis",
    "abstract": "This study investigates the vulnerability of semantic segmentation models to adversarial input perturbations, in the domain of off-road autonomous driving. Despite good performance in generic conditions, the state-of-the-art classifiers are often susceptible to (even) small perturbations, ultimately resulting in inaccurate predictions with high confidence. Prior research has directed their focus on making models more robust by modifying the architecture and training with noisy input images, but has not explored the influence of datasets in adversarial attacks. Our study aims to address this gap by examining the impact of non-robust features in off-road datasets and comparing the effects of adversarial attacks on different segmentation network architectures. To enable this, a robust dataset is created consisting of only robust features and training the networks on this robustified dataset. We present both qualitative and quantitative analysis of our findings, which have important implications on improving the robustness of machine learning models in off-road autonomous driving applications. Additionally, this work contributes to the safe navigation of autonomous robot Unimog U5023 in rough off-road unstructured environments by evaluating the robustness of segmentation outputs. The code is publicly available at https://github.com/rohtkumar/adversarial_attacks_ on_segmentation ",
    "url": "https://arxiv.org/abs/2402.02154",
    "authors": [
      "Pankaj Deoli",
      "Rohit Kumar",
      "Axel Vierling",
      "Karsten Berns"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02158",
    "title": "PatSTEG: Modeling Formation Dynamics of Patent Citation Networks via The  Semantic-Topological Evolutionary Graph",
    "abstract": "Patent documents in the patent database (PatDB) are crucial for research, development, and innovation as they contain valuable technical information. However, PatDB presents a multifaceted challenge compared to publicly available preprocessed databases due to the intricate nature of the patent text and the inherent sparsity within the patent citation network. Although patent text analysis and citation analysis bring new opportunities to explore patent data mining, no existing work exploits the complementation of them. To this end, we propose a joint semantic-topological evolutionary graph learning approach (PatSTEG) to model the formation dynamics of patent citation networks. More specifically, we first create a real-world dataset of Chinese patents named CNPat and leverage its patent texts and citations to construct a patent citation network. Then, PatSTEG is modeled to study the evolutionary dynamics of patent citation formation by considering the semantic and topological information jointly. Extensive experiments are conducted on CNPat and public datasets to prove the superiority of PatSTEG over other state-of-the-art methods. All the results provide valuable references for patent literature research and technical exploration. ",
    "url": "https://arxiv.org/abs/2402.02158",
    "authors": [
      "Ran Miao",
      "Xueyu Chen",
      "Liang Hu",
      "Zhifei Zhang",
      "Minghua Wan",
      "Qi Zhang",
      "Cairong Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2402.02160",
    "title": "Data Poisoning for In-context Learning",
    "abstract": "In the domain of large language models (LLMs), in-context learning (ICL) has been recognized for its innovative ability to adapt to new tasks, relying on examples rather than retraining or fine-tuning. This paper delves into the critical issue of ICL's susceptibility to data poisoning attacks, an area not yet fully explored. We wonder whether ICL is vulnerable, with adversaries capable of manipulating example data to degrade model performance. To address this, we introduce ICLPoison, a specialized attacking framework conceived to exploit the learning mechanisms of ICL. Our approach uniquely employs discrete text perturbations to strategically influence the hidden states of LLMs during the ICL process. We outline three representative strategies to implement attacks under our framework, each rigorously evaluated across a variety of models and tasks. Our comprehensive tests, including trials on the sophisticated GPT-4 model, demonstrate that ICL's performance is significantly compromised under our framework. These revelations indicate an urgent need for enhanced defense mechanisms to safeguard the integrity and reliability of LLMs in applications relying on in-context learning. ",
    "url": "https://arxiv.org/abs/2402.02160",
    "authors": [
      "Pengfei He",
      "Han Xu",
      "Yue Xing",
      "Hui Liu",
      "Makoto Yamada",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.02164",
    "title": "TSIS: A Supplementary Algorithm to t-SMILES for Fragment-based Molecular  Representation",
    "abstract": "String-based molecular representations, such as SMILES, are a de facto standard for linearly representing molecular information. However, the must be paired symbols and the parsing algorithm result in long grammatical dependencies, making it difficult for even state-of-the-art deep learning models to accurately comprehend the syntax and semantics. Although DeepSMILES and SELFIES have addressed certain limitations, they still struggle with advanced grammar, which makes some strings difficult to read. This study introduces a supplementary algorithm, TSIS (TSID Simplified), to t-SMILES family. Comparative experiments between TSIS and another fragment-based linear solution, SAFE, indicate that SAFE presents challenges in managing long-term dependencies in grammar. TSIS continues to use the tree defined in t-SMILES as its foundational data structure, which sets it apart from the SAFE model. The performance of TSIS models surpasses that of SAFE models, indicating that the tree structure of the t-SMILES family provides certain advantages. ",
    "url": "https://arxiv.org/abs/2402.02164",
    "authors": [
      "Juan-Ni Wu",
      "Tong Wang",
      "Li-Juan Tang",
      "Hai-Long Wu",
      "Ru-Qin Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2402.02165",
    "title": "Towards Optimal Adversarial Robust Q-learning with Bellman  Infinity-error",
    "abstract": "Establishing robust policies is essential to counter attacks or disturbances affecting deep reinforcement learning (DRL) agents. Recent studies explore state-adversarial robustness and suggest the potential lack of an optimal robust policy (ORP), posing challenges in setting strict robustness constraints. This work further investigates ORP: At first, we introduce a consistency assumption of policy (CAP) stating that optimal actions in the Markov decision process remain consistent with minor perturbations, supported by empirical and theoretical evidence. Building upon CAP, we crucially prove the existence of a deterministic and stationary ORP that aligns with the Bellman optimal policy. Furthermore, we illustrate the necessity of $L^{\\infty}$-norm when minimizing Bellman error to attain ORP. This finding clarifies the vulnerability of prior DRL algorithms that target the Bellman optimal policy with $L^{1}$-norm and motivates us to train a Consistent Adversarial Robust Deep Q-Network (CAR-DQN) by minimizing a surrogate of Bellman Infinity-error. The top-tier performance of CAR-DQN across various benchmarks validates its practical effectiveness and reinforces the soundness of our theoretical analysis. ",
    "url": "https://arxiv.org/abs/2402.02165",
    "authors": [
      "Haoran Li",
      "Zicheng Zhang",
      "Wang Luo",
      "Congying Han",
      "Yudong Hu",
      "Tiande Guo",
      "Shichen Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02168",
    "title": "One Graph Model for Cross-domain Dynamic Link Prediction",
    "abstract": "This work proposes DyExpert, a dynamic graph model for cross-domain link prediction. It can explicitly model historical evolving processes to learn the evolution pattern of a specific downstream graph and subsequently make pattern-specific link predictions. DyExpert adopts a decode-only transformer and is capable of efficiently parallel training and inference by \\textit{conditioned link generation} that integrates both evolution modeling and link prediction. DyExpert is trained by extensive dynamic graphs across diverse domains, comprising 6M dynamic edges. Extensive experiments on eight untrained graphs demonstrate that DyExpert achieves state-of-the-art performance in cross-domain link prediction. Compared to the advanced baseline under the same setting, DyExpert achieves an average of 11.40% improvement Average Precision across eight graphs. More impressive, it surpasses the fully supervised performance of 8 advanced baselines on 6 untrained graphs. ",
    "url": "https://arxiv.org/abs/2402.02168",
    "authors": [
      "Xuanwen Huang",
      "Wei Chow",
      "Yang Wang",
      "Ziwei Chai",
      "Chunping Wang",
      "Lei Chen",
      "Yang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02175",
    "title": "Enhancing Complex Question Answering over Knowledge Graphs through  Evidence Pattern Retrieval",
    "abstract": "Information retrieval (IR) methods for KGQA consist of two stages: subgraph extraction and answer reasoning. We argue current subgraph extraction methods underestimate the importance of structural dependencies among evidence facts. We propose Evidence Pattern Retrieval (EPR) to explicitly model the structural dependencies during subgraph extraction. We implement EPR by indexing the atomic adjacency pattern of resource pairs. Given a question, we perform dense retrieval to obtain atomic patterns formed by resource pairs. We then enumerate their combinations to construct candidate evidence patterns. These evidence patterns are scored using a neural model, and the best one is selected to extract a subgraph for downstream answer reasoning. Experimental results demonstrate that the EPR-based approach has significantly improved the F1 scores of IR-KGQA methods by over 10 points on ComplexWebQuestions and achieves competitive performance on WebQuestionsSP. ",
    "url": "https://arxiv.org/abs/2402.02175",
    "authors": [
      "Wentao Ding",
      "Jinmao Li",
      "Liangchuan Luo",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.02181",
    "title": "An Ontology-Based multi-domain model in Social Network Analysis:  Experimental validation and case study",
    "abstract": "The use of social network theory and methods of analysis have been applied to different domains in recent years, including public health. The complete procedure for carrying out a social network analysis (SNA) is a time-consuming task that entails a series of steps in which the expert in social network analysis could make mistakes. This research presents a multi-domain knowledge model capable of automatically gathering data and carrying out different social network analyses in different domains, without errors and obtaining the same conclusions that an expert in SNA would obtain. The model is represented in an ontology called OntoSNAQA, which is made up of classes, properties and rules representing the domains of People, Questionnaires and Social Network Analysis. Besides the ontology itself, different rules are represented by SWRL and SPARQL queries. A Knowledge Based System was created using OntoSNAQA and applied to a real case study in order to show the advantages of the approach. Finally, the results of an SNA analysis obtained through the model were compared to those obtained from some of the most widely used SNA applications: UCINET, Pajek, Cytoscape and Gephi, to test and confirm the validity of the model. ",
    "url": "https://arxiv.org/abs/2402.02181",
    "authors": [
      "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
      "Isa\u00edas Garc\u00eda-Rodr\u00edguez",
      "Carmen Benavides",
      "H\u00e9ctor Al\u00e1iz-Moret\u00f3n",
      "Jos\u00e9 Emilio Labra Gayo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02183",
    "title": "Detecting Respiratory Pathologies Using Convolutional Neural Networks  and Variational Autoencoders for Unbalancing Data",
    "abstract": "The aim of this paper was the detection of pathologies through respiratory sounds. The ICBHI (International Conference on Biomedical and Health Informatics) Benchmark was used. This dataset is composed of 920 sounds of which 810 are of chronic diseases, 75 of non-chronic diseases and only 35 of healthy individuals. As more than 88% of the samples of the dataset are from the same class (Chronic), the use of a Variational Convolutional Autoencoder was proposed to generate new labeled data and other well known oversampling techniques after determining that the dataset classes are unbalanced. Once the preprocessing step was carried out, a Convolutional Neural Network (CNN) was used to classify the respiratory sounds into healthy, chronic, and non-chronic disease. In addition, we carried out a more challenging classification trying to distinguish between the different types of pathologies or healthy: URTI, COPD, Bronchiectasis, Pneumonia, and Bronchiolitis. We achieved results up to 0.993 F-Score in the three-label classification and 0.990 F-Score in the more challenging six-class classification. ",
    "url": "https://arxiv.org/abs/2402.02183",
    "authors": [
      "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s",
      "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
      "Isa\u00edas Garc\u00eda-Rodr\u00edguez",
      "Carmen Benavides",
      "H\u00e9ctor Alaiz-Moret\u00f3n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02184",
    "title": "Sentiment analysis in non-fixed length audios using a Fully  Convolutional Neural Network",
    "abstract": "In this work, a sentiment analysis method that is capable of accepting audio of any length, without being fixed a priori, is proposed. Mel spectrogram and Mel Frequency Cepstral Coefficients are used as audio description methods and a Fully Convolutional Neural Network architecture is proposed as a classifier. The results have been validated using three well known datasets: EMODB, RAVDESS, and TESS. The results obtained were promising, outperforming the state-of-the-art methods. Also, thanks to the fact that the proposed method admits audios of any size, it allows a sentiment analysis to be made in near real time, which is very interesting for a wide range of fields such as call centers, medical consultations, or financial brokers. ",
    "url": "https://arxiv.org/abs/2402.02184",
    "authors": [
      "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s",
      "H\u00e9ctor Alaiz-Moret\u00f3n",
      "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
      "Isa\u00edas Garc\u00eda-Rodr\u00edguez",
      "Oscar Garc\u00eda-Olalla",
      "Carmen Benavides"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02186",
    "title": "Evolution Guided Generative Flow Networks",
    "abstract": "Generative Flow Networks (GFlowNets) are a family of probabilistic generative models that learn to sample compositional objects proportional to their rewards. One big challenge of GFlowNets is training them effectively when dealing with long time horizons and sparse rewards. To address this, we propose Evolution guided generative flow networks (EGFN), a simple but powerful augmentation to the GFlowNets training using Evolutionary algorithms (EA). Our method can work on top of any GFlowNets training objective, by training a set of agent parameters using EA, storing the resulting trajectories in the prioritized replay buffer, and training the GFlowNets agent using the stored trajectories. We present a thorough investigation over a wide range of toy and real-world benchmark tasks showing the effectiveness of our method in handling long trajectories and sparse rewards. ",
    "url": "https://arxiv.org/abs/2402.02186",
    "authors": [
      "Zarif Ikram",
      "Ling Pan",
      "Dianbo Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02188",
    "title": "Diabetes detection using deep learning techniques with oversampling and  feature augmentation",
    "abstract": "Background and objective: Diabetes is a chronic pathology which is affecting more and more people over the years. It gives rise to a large number of deaths each year. Furthermore, many people living with the disease do not realize the seriousness of their health status early enough. Late diagnosis brings about numerous health problems and a large number of deaths each year so the development of methods for the early diagnosis of this pathology is essential. Methods: In this paper, a pipeline based on deep learning techniques is proposed to predict diabetic people. It includes data augmentation using a variational autoencoder (VAE), feature augmentation using an sparse autoencoder (SAE) and a convolutional neural network for classification. Pima Indians Diabetes Database, which takes into account information on the patients such as the number of pregnancies, glucose or insulin level, blood pressure or age, has been evaluated. Results: A 92.31% of accuracy was obtained when CNN classifier is trained jointly the SAE for featuring augmentation over a well balanced dataset. This means an increment of 3.17% of accuracy with respect the state-of-the-art. Conclusions: Using a full deep learning pipeline for data preprocessing and classification has demonstrate to be very promising in the diabetes detection field outperforming the state-of-the-art proposals. ",
    "url": "https://arxiv.org/abs/2402.02188",
    "authors": [
      "Mar\u00eda Teresa Garc\u00eda-Ord\u00e1s",
      "Carmen Benavides",
      "Jos\u00e9 Alberto Ben\u00edtez-Andrades",
      "H\u00e9ctor Alaiz-Moret\u00f3n",
      "Isa\u00edas Garc\u00eda-Rodr\u00edguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02205",
    "title": "GPT-4V as Traffic Assistant: An In-depth Look at Vision Language Model  on Complex Traffic Events",
    "abstract": "The recognition and understanding of traffic incidents, particularly traffic accidents, is a topic of paramount importance in the realm of intelligent transportation systems and intelligent vehicles. This area has continually captured the extensive focus of both the academic and industrial sectors. Identifying and comprehending complex traffic events is highly challenging, primarily due to the intricate nature of traffic environments, diverse observational perspectives, and the multifaceted causes of accidents. These factors have persistently impeded the development of effective solutions. The advent of large vision-language models (VLMs) such as GPT-4V, has introduced innovative approaches to addressing this issue. In this paper, we explore the ability of GPT-4V with a set of representative traffic incident videos and delve into the model's capacity of understanding these complex traffic situations. We observe that GPT-4V demonstrates remarkable cognitive, reasoning, and decision-making ability in certain classic traffic events. Concurrently, we also identify certain limitations of GPT-4V, which constrain its understanding in more intricate scenarios. These limitations merit further exploration and resolution. ",
    "url": "https://arxiv.org/abs/2402.02205",
    "authors": [
      "Xingcheng Zhou",
      "Alois C. Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02208",
    "title": "Implicit Neural Representation of Tileable Material Textures",
    "abstract": "We explore sinusoidal neural networks to represent periodic tileable textures. Our approach leverages the Fourier series by initializing the first layer of a sinusoidal neural network with integer frequencies with a period $P$. We prove that the compositions of sinusoidal layers generate only integer frequencies with period $P$. As a result, our network learns a continuous representation of a periodic pattern, enabling direct evaluation at any spatial coordinate without the need for interpolation. To enforce the resulting pattern to be tileable, we add a regularization term, based on the Poisson equation, to the loss function. Our proposed neural implicit representation is compact and enables efficient reconstruction of high-resolution textures with high visual fidelity and sharpness across multiple levels of detail. We present applications of our approach in the domain of anti-aliased surface. ",
    "url": "https://arxiv.org/abs/2402.02208",
    "authors": [
      "Hallison Paz",
      "Tiago Novello",
      "Luiz Velho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02210",
    "title": "Wavelet-Decoupling Contrastive Enhancement Network for Fine-Grained  Skeleton-Based Action Recognition",
    "abstract": "Skeleton-based action recognition has attracted much attention, benefiting from its succinctness and robustness. However, the minimal inter-class variation in similar action sequences often leads to confusion. The inherent spatiotemporal coupling characteristics make it challenging to mine the subtle differences in joint motion trajectories, which is critical for distinguishing confusing fine-grained actions. To alleviate this problem, we propose a Wavelet-Attention Decoupling (WAD) module that utilizes discrete wavelet transform to effectively disentangle salient and subtle motion features in the time-frequency domain. Then, the decoupling attention adaptively recalibrates their temporal responses. To further amplify the discrepancies in these subtle motion features, we propose a Fine-grained Contrastive Enhancement (FCE) module to enhance attention towards trajectory features by contrastive learning. Extensive experiments are conducted on the coarse-grained dataset NTU RGB+D and the fine-grained dataset FineGYM. Our methods perform competitively compared to state-of-the-art methods and can discriminate confusing fine-grained actions well. ",
    "url": "https://arxiv.org/abs/2402.02210",
    "authors": [
      "Haochen Chang",
      "Jing Chen",
      "Yilin Li",
      "Jixiang Chen",
      "Xiaofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.02216",
    "title": "Graph Foundation Models",
    "abstract": "Graph Foundation Model (GFM) is a new trending research topic in the graph domain, aiming to develop a graph model capable of generalizing across different graphs and tasks. However, a versatile GFM has not yet been achieved. The key challenge in building GFM is how to enable positive transfer across graphs with diverse structural patterns. Inspired by the existing foundation models in the CV and NLP domains, we propose a novel perspective for the GFM development by advocating for a ``graph vocabulary'', in which the basic transferable units underlying graphs encode the invariance on graphs. We ground the graph vocabulary construction from essential aspects including network analysis, theoretical foundations, and stability. Such a vocabulary perspective can potentially advance the future GFM design following the neural scaling laws. ",
    "url": "https://arxiv.org/abs/2402.02216",
    "authors": [
      "Haitao Mao",
      "Zhikai Chen",
      "Wenzhuo Tang",
      "Jianan Zhao",
      "Yao Ma",
      "Tong Zhao",
      "Neil Shah",
      "Michael Galkin",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02219",
    "title": "Prediction-for-CompAction: navigation in social environments using  generalized cognitive maps",
    "abstract": "The ultimate navigation efficiency of mobile robots in human environments will depend on how we will appraise them: merely as impersonal machines or as human-like agents. In the latter case, an agent may take advantage of the cooperative collision avoidance, given that it possesses recursive cognition, i.e.,the agent's decisions depend on the decisions made by humans that in turn depend on the agent's decisions. To deal with this high-level cognitive skill, we propose a neural network architecture implementing Prediction-for-CompAction paradigm. The network predicts possible human-agent collisions and compacts the time dimension by projecting a given dynamic situation into a static map. Thereby emerging compact cognitive map can be readily used as a \"dynamic GPS\" for planning actions or mental evaluation of the convenience of cooperation in a given context. We provide numerical evidence that cooperation yields additional room for more efficient navigation in cluttered pedestrian flows, and the agent can choose path to the target significantly shorter than a robot treated by humans as a functional machine. Moreover, the navigation safety, i.e., the chances to avoid accidental collisions, increases under cooperation. Remarkably, these benefits yield no additional load to the mean society effort. Thus, the proposed strategy is socially compliant, and the humanoid agent can behave as \"one of us\". ",
    "url": "https://arxiv.org/abs/2402.02219",
    "authors": [
      "Jos\u00e9 Antonio Villacorta Atienza",
      "Carlos Calvo Tapia",
      "Valeriy A. Makarov Slizneva"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2402.02227",
    "title": "Invisible Finger: Practical Electromagnetic Interference Attack on  Touchscreen-based Electronic Devices",
    "abstract": "Touchscreen-based electronic devices such as smart phones and smart tablets are widely used in our daily life. While the security of electronic devices have been heavily investigated recently, the resilience of touchscreens against various attacks has yet to be thoroughly investigated. In this paper, for the first time, we show that touchscreen-based electronic devices are vulnerable to intentional electromagnetic interference (IEMI) attacks in a systematic way and how to conduct this attack in a practical way. Our contribution lies in not just demonstrating the attack, but also analyzing and quantifying the underlying mechanism allowing the novel IEMI attack on touchscreens in detail. We show how to calculate both the minimum amount of electric field and signal frequency required to induce touchscreen ghost touches. We further analyze our IEMI attack on real touchscreens with different magnitudes, frequencies, duration, and multitouch patterns. The mechanism of controlling the touchscreen-enabled electronic devices with IEMI signals is also elaborated. We design and evaluate an out-of-sight touchscreen locator and touch injection feedback mechanism to assist a practical IEMI attack. Our attack works directly on the touchscreen circuit regardless of the touchscreen scanning mechanism or operating system. Our attack can inject short-tap, long-press, and omni-directional gestures on touchscreens from a distance larger than the average thickness of common tabletops. Compared with the state-of-the-art touchscreen attack, ours can accurately inject different types of touch events without the need for sensing signal synchronization, which makes our attack more robust and practical. In addition, rather than showing a simple proof-of-concept attack, we present and demonstrate the first ready-to-use IEMI based touchscreen attack vector with end-to-end attack scenarios. ",
    "url": "https://arxiv.org/abs/2402.02227",
    "authors": [
      "Haoqi Shan",
      "Boyi Zhang",
      "Zihao Zhan",
      "Dean Sullivan",
      "Shuo Wang",
      "Yier Jin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.02230",
    "title": "Federated Learning with Differential Privacy",
    "abstract": "Federated learning (FL), as a type of distributed machine learning, is capable of significantly preserving client's private data from being shared among different parties. Nevertheless, private information can still be divulged by analyzing uploaded parameter weights from clients. In this report, we showcase our empirical benchmark of the effect of the number of clients and the addition of differential privacy (DP) mechanisms on the performance of the model on different types of data. Our results show that non-i.i.d and small datasets have the highest decrease in performance in a distributed and differentially private setting. ",
    "url": "https://arxiv.org/abs/2402.02230",
    "authors": [
      "Adrien Banse",
      "Jan Kreischer",
      "Xavier Oliva i J\u00fcrgens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.02234",
    "title": "Epidemics on Networks",
    "abstract": "Despite centuries of work on containment and mitigation strategies, infectious diseases are still a major problem facing humanity. This work is concerned with simulating heterogeneous contact structures and understanding how the structure of the underlying network affects the spread of the disease. For example, it has been empirically demonstrated and validated that scale free networks do not have an epidemic threshold. Understanding the relationship between network structure and disease dynamics can help to develop better mitigation strategies and more effective interventions. ",
    "url": "https://arxiv.org/abs/2402.02234",
    "authors": [
      "Jan Kreischer",
      "Adrian Iten",
      "Astrid Jehoul"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.02245",
    "title": "Revisiting Generative Adversarial Networks for Binary Semantic  Segmentation on Imbalanced Datasets",
    "abstract": "Anomalous pavement surface conditions detection aims to detect pixels representing anomalous states, such as cracks, on pavement surface images automatically by algorithms. Recently, deep learning models have been intensively applied to related topics with outstanding performance. However, most existing deep learning-related solutions rarely achieve a stable performance on diverse datasets. To address this issue, in this work, we propose a deep learning framework based on conditional Generative Adversarial Networks for anomalous region detection on pavement images at the pixel level. In particular, the proposed framework is developed to enhance the generator's ability to estimate the probability feature map from heterogeneous inputs with two training stages and multiscale feature representation. Moreover, several attention mechanisms are incorporated into the proposed framework to mitigate the performance deterioration of model training on severely imbalanced datasets. We implement experiments on six accessible pavement datasets. Extensive qualitative and quantitative experiments demonstrate that the proposed framework can achieve SOTA results on these datasets efficiently and robustly. ",
    "url": "https://arxiv.org/abs/2402.02245",
    "authors": [
      "Lei Xu",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02258",
    "title": "XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event  Prediction",
    "abstract": "Event prediction aims to forecast the time and type of a future event based on a historical event sequence. Despite its significance, several challenges exist, including the irregularity of time intervals between consecutive events, the existence of cycles, periodicity, and multi-scale event interactions, as well as the high computational costs for long event sequences. Existing neural temporal point processes (TPPs) methods do not capture the multi-scale nature of event interactions, which is common in many real-world applications such as clinical event data. To address these issues, we propose the cross-temporal-scale transformer (XTSFormer), designed specifically for irregularly timed event data. Our model comprises two vital components: a novel Feature-based Cycle-aware Time Positional Encoding (FCPE) that adeptly captures the cyclical nature of time, and a hierarchical multi-scale temporal attention mechanism. These scales are determined by a bottom-up clustering algorithm. Extensive experiments on several real-world datasets show that our XTSFormer outperforms several baseline methods in prediction performance. ",
    "url": "https://arxiv.org/abs/2402.02258",
    "authors": [
      "Tingsong Xiao",
      "Zelin Xu",
      "Wenchong He",
      "Jim Su",
      "Yupu Zhang",
      "Raymond Opoku",
      "Ronald Ison",
      "Jason Petho",
      "Jiang Bian",
      "Patrick Tighe",
      "Parisa Rashidi",
      "Zhe Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02262",
    "title": "Data Quality Matters: Suicide Intention Detection on Social Media Posts  Using a RoBERTa-CNN Model",
    "abstract": "Suicide remains a global health concern for the field of health, which urgently needs innovative approaches for early detection and intervention. In this paper, we focus on identifying suicidal intentions in SuicideWatch Reddit posts and present a novel approach to suicide detection using the cutting-edge RoBERTa-CNN model, a variant of RoBERTa (Robustly optimized BERT approach). RoBERTa is used for various Natural Language Processing (NLP) tasks, including text classification and sentiment analysis. The effectiveness of the RoBERTa lies in its ability to capture textual information and form semantic relationships within texts. By adding the Convolution Neural Network (CNN) layer to the original model, the RoBERTa enhances its ability to capture important patterns from heavy datasets. To evaluate the RoBERTa-CNN, we experimented on the Suicide and Depression Detection dataset and obtained solid results. For example, RoBERTa-CNN achieves 98% mean accuracy with the standard deviation (STD) of 0.0009. It also reaches over 97.5% mean AUC value with an STD of 0.0013. In the meanwhile, RoBERTa-CNN outperforms competitive methods, demonstrating the robustness and ability to capture nuanced linguistic patterns for suicidal intentions. Therefore, RoBERTa-CNN can detect suicide intention on text data very well. ",
    "url": "https://arxiv.org/abs/2402.02262",
    "authors": [
      "Emily Lin",
      "Jian Sun",
      "Hsingyu Chen",
      "Mohammad H. Mahoor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02275",
    "title": "SudokuSens: Enhancing Deep Learning Robustness for IoT Sensing  Applications using a Generative Approach",
    "abstract": "This paper introduces SudokuSens, a generative framework for automated generation of training data in machine-learning-based Internet-of-Things (IoT) applications, such that the generated synthetic data mimic experimental configurations not encountered during actual sensor data collection. The framework improves the robustness of resulting deep learning models, and is intended for IoT applications where data collection is expensive. The work is motivated by the fact that IoT time-series data entangle the signatures of observed objects with the confounding intrinsic properties of the surrounding environment and the dynamic environmental disturbances experienced. To incorporate sufficient diversity into the IoT training data, one therefore needs to consider a combinatorial explosion of training cases that are multiplicative in the number of objects considered and the possible environmental conditions in which such objects may be encountered. Our framework substantially reduces these multiplicative training needs. To decouple object signatures from environmental conditions, we employ a Conditional Variational Autoencoder (CVAE) that allows us to reduce data collection needs from multiplicative to (nearly) linear, while synthetically generating (data for) the missing conditions. To obtain robustness with respect to dynamic disturbances, a session-aware temporal contrastive learning approach is taken. Integrating the aforementioned two approaches, SudokuSens significantly improves the robustness of deep learning for IoT applications. We explore the degree to which SudokuSens benefits downstream inference tasks in different data sets and discuss conditions under which the approach is particularly effective. ",
    "url": "https://arxiv.org/abs/2402.02275",
    "authors": [
      "Tianshi Wang",
      "Jinyang Li",
      "Ruijie Wang",
      "Denizhan Kara",
      "Shengzhong Liu",
      "Davis Wertheimer",
      "Antoni Viros-i-Martin",
      "Raghu Ganti",
      "Mudhakar Srivatsa",
      "Tarek Abdelzaher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02277",
    "title": "Causal Bayesian Optimization via Exogenous Distribution Learning",
    "abstract": "Maximizing a target variable as an operational objective in a structured causal model is an important problem. Existing Causal Bayesian Optimization (CBO) methods either rely on hard interventions that alter the causal structure to maximize the reward; or introduce action nodes to endogenous variables so that the data generation mechanisms are adjusted to achieve the objective. In this paper, a novel method is introduced to learn the distribution of exogenous variables, which is typically ignored or marginalized through expectation by existing methods. Exogenous distribution learning improves the approximation accuracy of structured causal models in a surrogate model that is usually trained with limited observational data. Moreover, the learned exogenous distribution extends existing CBO to general causal schemes beyond Additive Noise Models (ANM). The recovery of exogenous variables allows us to use a more flexible prior for noise or unobserved hidden variables. A new CBO method is developed by leveraging the learned exogenous distribution. Experiments on different datasets and applications show the benefits of our proposed method. ",
    "url": "https://arxiv.org/abs/2402.02277",
    "authors": [
      "Shaogang Ren",
      "Xiaoning Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.02286",
    "title": "Multi-Level Feature Aggregation and Recursive Alignment Network for  Real-Time Semantic Segmentation",
    "abstract": "Real-time semantic segmentation is a crucial research for real-world applications. However, many methods lay particular emphasis on reducing the computational complexity and model size, while largely sacrificing the accuracy. In some scenarios, such as autonomous navigation and driver assistance system, accuracy and speed are equally important. To tackle this problem, we propose a novel Multi-level Feature Aggregation and Recursive Alignment Network (MFARANet), aiming to achieve high segmentation accuracy at real-time inference speed. We employ ResNet-18 as the backbone to ensure efficiency, and propose three core components to compensate for the reduced model capacity due to the shallow backbone. Specifically, we first design Multi-level Feature Aggregation Module (MFAM) to aggregate the hierarchical features in the encoder to each scale to benefit subsequent spatial alignment and multi-scale inference. Then, we build Recursive Alignment Module (RAM) by combining the flow-based alignment module with recursive upsampling architecture for accurate and efficient spatial alignment between multi-scale score maps. Finally, the Adaptive Scores Fusion Module (ASFM) is proposed to adaptively fuse multi-scale scores so that the final prediction can favor objects of multiple scales. Comprehensive experiments on three benchmark datasets including Cityscapes, CamVid and PASCAL-Context show the effectiveness and efficiency of our method. In particular, we achieve a better balance between speed and accuracy than state-of-the-art real-time methods on Cityscapes and CamVid datasets. Code is available at: https://github.com/Yanhua-Zhang/MFARANet. ",
    "url": "https://arxiv.org/abs/2402.02286",
    "authors": [
      "Yanhua Zhang",
      "Ke Zhang",
      "Jingyu Wang",
      "Yulin Wu",
      "Wuwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02287",
    "title": "Future Directions in Foundations of Graph Machine Learning",
    "abstract": "Machine learning on graphs, especially using graph neural networks (GNNs), has seen a surge in interest due to the wide availability of graph data across a broad spectrum of disciplines, from life to social and engineering sciences. Despite their practical success, our theoretical understanding of the properties of GNNs remains highly incomplete. Recent theoretical advancements primarily focus on elucidating the coarse-grained expressive power of GNNs, predominantly employing combinatorial techniques. However, these studies do not perfectly align with practice, particularly in understanding the generalization behavior of GNNs when trained with stochastic first-order optimization techniques. In this position paper, we argue that the graph machine learning community needs to shift its attention to developing a more balanced theory of graph machine learning, focusing on a more thorough understanding of the interplay of expressive power, generalization, and optimization. ",
    "url": "https://arxiv.org/abs/2402.02287",
    "authors": [
      "Christopher Morris",
      "Nadav Dym",
      "Haggai Maron",
      "\u0130smail \u0130lkan Ceylan",
      "Fabrizio Frasca",
      "Ron Levie",
      "Derek Lim",
      "Michael Bronstein",
      "Martin Grohe",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.02288",
    "title": "$\\textit{A Contrario}$ Paradigm for YOLO-based Infrared Small Target  Detection",
    "abstract": "Detecting small to tiny targets in infrared images is a challenging task in computer vision, especially when it comes to differentiating these targets from noisy or textured backgrounds. Traditional object detection methods such as YOLO struggle to detect tiny objects compared to segmentation neural networks, resulting in weaker performance when detecting small targets. To reduce the number of false alarms while maintaining a high detection rate, we introduce an $\\textit{a contrario}$ decision criterion into the training of a YOLO detector. The latter takes advantage of the $\\textit{unexpectedness}$ of small targets to discriminate them from complex backgrounds. Adding this statistical criterion to a YOLOv7-tiny bridges the performance gap between state-of-the-art segmentation methods for infrared small target detection and object detection networks. It also significantly increases the robustness of YOLO towards few-shot settings. ",
    "url": "https://arxiv.org/abs/2402.02288",
    "authors": [
      "Alina Ciocarlan",
      "Sylvie Le H\u00e9garat-Mascle",
      "Sidonie Lefebvre",
      "Arnaud Woiselle",
      "Clara Barbanson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02307",
    "title": "Joint Activity and Data Detection for Massive Grant-Free Access Using  Deterministic Non-Orthogonal Signatures",
    "abstract": "Grant-free access is a key enabler for connecting wireless devices with low latency and low signaling overhead in massive machine-type communications (mMTC). For massive grant-free access, user-specific signatures are uniquely assigned to mMTC devices. In this paper, we first derive a sufficient condition for the successful identification of active devices through maximum likelihood (ML) estimation in massive grant-free access. The condition is represented by the coherence of a signature sequence matrix containing the signatures of all devices. Then, we present a design framework of non-orthogonal signature sequences in a deterministic fashion. The design principle relies on unimodular masking sequences with low correlation, which are applied as masking sequences to the columns of the discrete Fourier transform (DFT) matrix. For example constructions, we use four polyphase masking sequences represented by characters over finite fields. Leveraging algebraic techniques, we show that the signature sequence matrix of proposed non-orthogonal sequences has theoretically bounded low coherence. Simulation results demonstrate that the deterministic non-orthogonal signatures achieve the excellent performance of joint activity and data detection by ML- and approximate message passing (AMP)-based algorithms for massive grant-free access in mMTC. ",
    "url": "https://arxiv.org/abs/2402.02307",
    "authors": [
      "Nam Yul Yu",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.02309",
    "title": "Jailbreaking Attack against Multimodal Large Language Model",
    "abstract": "This paper focuses on jailbreaking attacks against multi-modal large language models (MLLMs), seeking to elicit MLLMs to generate objectionable responses to harmful user queries. A maximum likelihood-based algorithm is proposed to find an \\emph{image Jailbreaking Prompt} (imgJP), enabling jailbreaks against MLLMs across multiple unseen prompts and images (i.e., data-universal property). Our approach exhibits strong model-transferability, as the generated imgJP can be transferred to jailbreak various models, including MiniGPT-v2, LLaVA, InstructBLIP, and mPLUG-Owl2, in a black-box manner. Moreover, we reveal a connection between MLLM-jailbreaks and LLM-jailbreaks. As a result, we introduce a construction-based method to harness our approach for LLM-jailbreaks, demonstrating greater efficiency than current state-of-the-art methods. The code is available here. \\textbf{Warning: some content generated by language models may be offensive to some readers.} ",
    "url": "https://arxiv.org/abs/2402.02309",
    "authors": [
      "Zhenxing Niu",
      "Haodong Ren",
      "Xinbo Gao",
      "Gang Hua",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02313",
    "title": "CNS-Edit: 3D Shape Editing via Coupled Neural Shape Optimization",
    "abstract": "This paper introduces a new approach based on a coupled representation and a neural volume optimization to implicitly perform 3D shape editing in latent space. This work has three innovations. First, we design the coupled neural shape (CNS) representation for supporting 3D shape editing. This representation includes a latent code, which captures high-level global semantics of the shape, and a 3D neural feature volume, which provides a spatial context to associate with the local shape changes given by the editing. Second, we formulate the coupled neural shape optimization procedure to co-optimize the two coupled components in the representation subject to the editing operation. Last, we offer various 3D shape editing operators, i.e., copy, resize, delete, and drag, and derive each into an objective for guiding the CNS optimization, such that we can iteratively co-optimize the latent code and neural feature volume to match the editing target. With our approach, we can achieve a rich variety of editing results that are not only aware of the shape semantics but are also not easy to achieve by existing approaches. Both quantitative and qualitative evaluations demonstrate the strong capabilities of our approach over the state-of-the-art solutions. ",
    "url": "https://arxiv.org/abs/2402.02313",
    "authors": [
      "Jingyu Hu",
      "Ka-Hei Hui",
      "Zhengzhe Liu",
      "Hao Zhang",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2402.02316",
    "title": "Your Diffusion Model is Secretly a Certifiably Robust Classifier",
    "abstract": "Diffusion models are recently employed as generative classifiers for robust classification. However, a comprehensive theoretical understanding of the robustness of diffusion classifiers is still lacking, leading us to question whether they will be vulnerable to future stronger attacks. In this study, we propose a new family of diffusion classifiers, named Noised Diffusion Classifiers~(NDCs), that possess state-of-the-art certified robustness. Specifically, we generalize the diffusion classifiers to classify Gaussian-corrupted data by deriving the evidence lower bounds (ELBOs) for these distributions, approximating the likelihood using the ELBO, and calculating classification probabilities via Bayes' theorem. We integrate these generalized diffusion classifiers with randomized smoothing to construct smoothed classifiers possessing non-constant Lipschitzness. Experimental results demonstrate the superior certified robustness of our proposed NDCs. Notably, we are the first to achieve 80\\%+ and 70\\%+ certified robustness on CIFAR-10 under adversarial perturbations with $\\ell_2$ norm less than 0.25 and 0.5, respectively, using a single off-the-shelf diffusion model without any additional data. ",
    "url": "https://arxiv.org/abs/2402.02316",
    "authors": [
      "Huanran Chen",
      "Yinpeng Dong",
      "Shitong Shao",
      "Zhongkai Hao",
      "Xiao Yang",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02321",
    "title": "Active Learning for Graphs with Noisy Structures",
    "abstract": "Graph Neural Networks (GNNs) have seen significant success in tasks such as node classification, largely contingent upon the availability of sufficient labeled nodes. Yet, the excessive cost of labeling large-scale graphs led to a focus on active learning on graphs, which aims for effective data selection to maximize downstream model performance. Notably, most existing methods assume reliable graph topology, while real-world scenarios often present noisy graphs. Given this, designing a successful active learning framework for noisy graphs is highly needed but challenging, as selecting data for labeling and obtaining a clean graph are two tasks naturally interdependent: selecting high-quality data requires clean graph structure while cleaning noisy graph structure requires sufficient labeled data. Considering the complexity mentioned above, we propose an active learning framework, GALClean, which has been specifically designed to adopt an iterative approach for conducting both data selection and graph purification simultaneously with best information learned from the prior iteration. Importantly, we summarize GALClean as an instance of the Expectation-Maximization algorithm, which provides a theoretical understanding of its design and mechanisms. This theory naturally leads to an enhanced version, GALClean+. Extensive experiments have demonstrated the effectiveness and robustness of our proposed method across various types and levels of noisy graphs. ",
    "url": "https://arxiv.org/abs/2402.02321",
    "authors": [
      "Hongliang Chi",
      "Cong Qi",
      "Suhang Wang",
      "Yao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02328",
    "title": "Data-driven algorithm design using neural networks with applications to  branch-and-cut",
    "abstract": "Data-driven algorithm design is a paradigm that uses statistical and machine learning techniques to select from a class of algorithms for a computational problem an algorithm that has the best expected performance with respect to some (unknown) distribution on the instances of the problem. We build upon recent work in this line of research by introducing the idea where, instead of selecting a single algorithm that has the best performance, we allow the possibility of selecting an algorithm based on the instance to be solved. In particular, given a representative sample of instances, we learn a neural network that maps an instance of the problem to the most appropriate algorithm {\\em for that instance}. We formalize this idea and derive rigorous sample complexity bounds for this learning problem, in the spirit of recent work in data-driven algorithm design. We then apply this approach to the problem of making good decisions in the branch-and-cut framework for mixed-integer optimization (e.g., which cut to add?). In other words, the neural network will take as input a mixed-integer optimization instance and output a decision that will result in a small branch-and-cut tree for that instance. Our computational results provide evidence that our particular way of using neural networks for cut selection can make a significant impact in reducing branch-and-cut tree sizes, compared to previous data-driven approaches. ",
    "url": "https://arxiv.org/abs/2402.02328",
    "authors": [
      "Hongyu Cheng",
      "Sammy Khalife",
      "Barbara Fiedorowicz",
      "Amitabh Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.02346",
    "title": "Closed-Loop Unsupervised Representation Disentanglement with $\u03b2$-VAE  Distillation and Diffusion Probabilistic Feedback",
    "abstract": "Representation disentanglement may help AI fundamentally understand the real world and thus benefit both discrimination and generation tasks. It currently has at least three unresolved core issues: (i) heavy reliance on label annotation and synthetic data -- causing poor generalization on natural scenarios; (ii) heuristic/hand-craft disentangling constraints make it hard to adaptively achieve an optimal training trade-off; (iii) lacking reasonable evaluation metric, especially for the real label-free data. To address these challenges, we propose a \\textbf{C}losed-\\textbf{L}oop unsupervised representation \\textbf{Dis}entanglement approach dubbed \\textbf{CL-Dis}. Specifically, we use diffusion-based autoencoder (Diff-AE) as a backbone while resorting to $\\beta$-VAE as a co-pilot to extract semantically disentangled representations. The strong generation ability of diffusion model and the good disentanglement ability of VAE model are complementary. To strengthen disentangling, VAE-latent distillation and diffusion-wise feedback are interconnected in a closed-loop system for a further mutual promotion. Then, a self-supervised \\textbf{Navigation} strategy is introduced to identify interpretable semantic directions in the disentangled latent space. Finally, a new metric based on content tracking is designed to evaluate the disentanglement effect. Experiments demonstrate the superiority of CL-Dis on applications like real image manipulation and visual analysis. ",
    "url": "https://arxiv.org/abs/2402.02346",
    "authors": [
      "Xin Jin",
      "Bohan Li",
      "BAAO Xie",
      "Wenyao Zhang",
      "Jinming Liu",
      "Ziqiang Li",
      "Tao Yang",
      "Wenjun Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02349",
    "title": "Vision Transformer-based Multimodal Feature Fusion Network for Lymphoma  Segmentation on PET/CT Images",
    "abstract": "Background: Diffuse large B-cell lymphoma (DLBCL) segmentation is a challenge in medical image analysis. Traditional segmentation methods for lymphoma struggle with the complex patterns and the presence of DLBCL lesions. Objective: We aim to develop an accurate method for lymphoma segmentation with 18F-Fluorodeoxyglucose positron emission tomography (PET) and computed tomography (CT) images. Methods: Our lymphoma segmentation approach combines a vision transformer with dual encoders, adeptly fusing PET and CT data via multimodal cross-attention fusion (MMCAF) module. In this study, PET and CT data from 165 DLBCL patients were analyzed. A 5-fold cross-validation was employed to evaluate the performance and generalization ability of our method. Ground truths were annotated by experienced nuclear medicine experts. We calculated the total metabolic tumor volume (TMTV) and performed a statistical analysis on our results. Results: The proposed method exhibited accurate performance in DLBCL lesion segmentation, achieving a Dice similarity coefficient of 0.9173$\\pm$0.0071, a Hausdorff distance of 2.71$\\pm$0.25mm, a sensitivity of 0.9462$\\pm$0.0223, and a specificity of 0.9986$\\pm$0.0008. Additionally, a Pearson correlation coefficient of 0.9030$\\pm$0.0179 and an R-square of 0.8586$\\pm$0.0173 were observed in TMTV when measured on manual annotation compared to our segmentation results. Conclusion: This study highlights the advantages of MMCAF and vision transformer for lymphoma segmentation using PET and CT, offering great promise for computer-aided lymphoma diagnosis and treatment. ",
    "url": "https://arxiv.org/abs/2402.02349",
    "authors": [
      "Huan Huang",
      "Liheng Qiu",
      "Shenmiao Yang",
      "Longxi Li",
      "Jiaofen Nan",
      "Yanting Li",
      "Chuang Han",
      "Fubao Zhu",
      "Chen Zhao",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02350",
    "title": "Interference-Aware Emergent Random Access Protocol for Downlink LEO  Satellite Networks",
    "abstract": "In this article, we propose a multi-agent deep reinforcement learning (MADRL) framework to train a multiple access protocol for downlink low earth orbit (LEO) satellite networks. By improving the existing learned protocol, emergent random access channel (eRACH), our proposed method, coined centralized and compressed emergent signaling for eRACH (Ce2RACH), can mitigate inter-satellite interference by exchanging additional signaling messages jointly learned through the MADRL training process. Simulations demonstrate that Ce2RACH achieves up to 36.65% higher network throughput compared to eRACH, while the cost of signaling messages increase linearly with the number of users. ",
    "url": "https://arxiv.org/abs/2402.02350",
    "authors": [
      "Chang-Yong Lim",
      "Jihong Park",
      "Jinho Choi",
      "Ju-Hyung Lee",
      "Daesub Oh",
      "Heewook Kim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02357",
    "title": "Multi-modal Causal Structure Learning and Root Cause Analysis",
    "abstract": "Effective root cause analysis (RCA) is vital for swiftly restoring services, minimizing losses, and ensuring the smooth operation and management of complex systems. Previous data-driven RCA methods, particularly those employing causal discovery techniques, have primarily focused on constructing dependency or causal graphs for backtracking the root causes. However, these methods often fall short as they rely solely on data from a single modality, thereby resulting in suboptimal solutions. In this work, we propose Mulan, a unified multi-modal causal structure learning method for root cause localization. We leverage a log-tailored language model to facilitate log representation learning, converting log sequences into time-series data. To explore intricate relationships across different modalities, we propose a contrastive learning-based approach to extract modality-invariant and modality-specific representations within a shared latent space. Additionally, we introduce a novel key performance indicator-aware attention mechanism for assessing modality reliability and co-learning a final causal graph. Finally, we employ random walk with restart to simulate system fault propagation and identify potential root causes. Extensive experiments on three real-world datasets validate the effectiveness of our proposed framework. ",
    "url": "https://arxiv.org/abs/2402.02357",
    "authors": [
      "Lecheng Zheng",
      "Zhengzhang Chen",
      "Jingrui He",
      "Haifeng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02362",
    "title": "Unification of Symmetries Inside Neural Networks: Transformer,  Feedforward and Neural ODE",
    "abstract": "Understanding the inner workings of neural networks, including transformers, remains one of the most challenging puzzles in machine learning. This study introduces a novel approach by applying the principles of gauge symmetries, a key concept in physics, to neural network architectures. By regarding model functions as physical observables, we find that parametric redundancies of various machine learning models can be interpreted as gauge symmetries. We mathematically formulate the parametric redundancies in neural ODEs, and find that their gauge symmetries are given by spacetime diffeomorphisms, which play a fundamental role in Einstein's theory of gravity. Viewing neural ODEs as a continuum version of feedforward neural networks, we show that the parametric redundancies in feedforward neural networks are indeed lifted to diffeomorphisms in neural ODEs. We further extend our analysis to transformer models, finding natural correspondences with neural ODEs and their gauge symmetries. The concept of gauge symmetries sheds light on the complex behavior of deep learning models through physics and provides us with a unifying perspective for analyzing various machine learning architectures. ",
    "url": "https://arxiv.org/abs/2402.02362",
    "authors": [
      "Koji Hashimoto",
      "Yuji Hirono",
      "Akiyoshi Sannai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "High Energy Physics - Theory (hep-th)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2402.02367",
    "title": "Exploring Intrinsic Properties of Medical Images for Self-Supervised  Binary Semantic Segmentation",
    "abstract": "Recent advancements in self-supervised learning have unlocked the potential to harness unlabeled data for auxiliary tasks, facilitating the learning of beneficial priors. This has been particularly advantageous in fields like medical image analysis, where labeled data are scarce. Although effective for classification tasks, this methodology has shown limitations in more complex applications, such as medical image segmentation. In this paper, we introduce Medical imaging Enhanced with Dynamic Self-Adaptive Semantic Segmentation (MedSASS), a dedicated self-supervised framework tailored for medical image segmentation. We evaluate MedSASS against existing state-of-the-art methods across four diverse medical datasets, showcasing its superiority. MedSASS outperforms existing CNN-based self-supervised methods by 3.83% and matches the performance of ViT-based methods. Furthermore, when MedSASS is trained end-to-end, covering both encoder and decoder, it demonstrates significant improvements of 14.4% for CNNs and 6% for ViT-based architectures compared to existing state-of-the-art self-supervised strategies. ",
    "url": "https://arxiv.org/abs/2402.02367",
    "authors": [
      "Pranav Singh",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02381",
    "title": "Empowering Computing and Networks Convergence System with Distributed  Cooperative Routing",
    "abstract": "The emergence of intelligent applications and recent advances in the fields of computing and networks are driving the development of computing and networks convergence (CNC) system. However, existing researches failed to achieve comprehensive scheduling optimization of computing and network resources. This shortfall results in some requirements of computing requests unable to be guaranteed in an end-to-end service pattern, negatively impacting the development of CNC systems. In this article, we propose a distributed cooperative routing framework for the CNC system to ensure the deadline requirements and minimize the computation cost of requests. The framework includes trading plane, management plane, control plane and forwarding plane. The cross-plane cooperative end-to-end routing schemes consider both computation efficiency of heterogeneous servers and the network congestion degrees while making routing plan, thereby determining where to execute requests and corresponding routing paths. Simulations results substantiates the performance of our routing schemes in scheduling computing requests in the CNC system. ",
    "url": "https://arxiv.org/abs/2402.02381",
    "authors": [
      "Yujiao Hu",
      "Qingmin Jia",
      "Meng Shen",
      "Renchao Xie",
      "Tao Huang",
      "F.Richard Yu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02389",
    "title": "KICGPT: Large Language Model with Knowledge in Context for Knowledge  Graph Completion",
    "abstract": "Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph incompleteness and supporting downstream applications. Many models have been proposed for KGC. They can be categorized into two main classes: triple-based and text-based approaches. Triple-based methods struggle with long-tail entities due to limited structural information and imbalanced entity distributions. Text-based methods alleviate this issue but require costly training for language models and specific finetuning for knowledge graphs, which limits their efficiency. To alleviate these limitations, in this paper, we propose KICGPT, a framework that integrates a large language model (LLM) and a triple-based KGC retriever. It alleviates the long-tail problem without incurring additional training overhead. KICGPT uses an in-context learning strategy called Knowledge Prompt, which encodes structural knowledge into demonstrations to guide the LLM. Empirical results on benchmark datasets demonstrate the effectiveness of KICGPT with smaller training overhead and no finetuning. ",
    "url": "https://arxiv.org/abs/2402.02389",
    "authors": [
      "Yanbin Wei",
      "Qiushi Huang",
      "James T. Kwok",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.02390",
    "title": "Improved Upper Bound for the Size of a Trifferent Code",
    "abstract": "A subset $\\mathcal{C}\\subseteq\\{0,1,2\\}^n$ is said to be a $\\textit{trifferent}$ code (of block length $n$) if for every three distinct codewords $x,y, z \\in \\mathcal{C}$, there is a coordinate $i\\in \\{1,2,\\ldots,n\\}$ where they all differ, that is, $\\{x(i),y(i),z(i)\\}$ is same as $\\{0,1,2\\}$. Let $T(n)$ denote the size of the largest trifferent code of block length $n$. Understanding the asymptotic behavior of $T(n)$ is closely related to determining the zero-error capacity of the $(3/2)$-channel defined by Elias'88, and is a long-standing open problem in the area. Elias had shown that $T(n)\\leq 2\\times (3/2)^n$ and prior to our work the best upper bound was $T(n)\\leq 0.6937 \\times (3/2)^n$ due to Kurz'23. We improve this bound to $T(n)\\leq c \\times n^{-2/5}\\times (3/2)^n$ where $c$ is an absolute constant. ",
    "url": "https://arxiv.org/abs/2402.02390",
    "authors": [
      "Siddharth Bhandari",
      "Abhishek Khetan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.02405",
    "title": "Angle Robustness Unmanned Aerial Vehicle Navigation in GNSS-Denied  Scenarios",
    "abstract": "Due to the inability to receive signals from the Global Navigation Satellite System (GNSS) in extreme conditions, achieving accurate and robust navigation for Unmanned Aerial Vehicles (UAVs) is a challenging task. Recently emerged, vision-based navigation has been a promising and feasible alternative to GNSS-based navigation. However, existing vision-based techniques are inadequate in addressing flight deviation caused by environmental disturbances and inaccurate position predictions in practical settings. In this paper, we present a novel angle robustness navigation paradigm to deal with flight deviation in point-to-point navigation tasks. Additionally, we propose a model that includes the Adaptive Feature Enhance Module, Cross-knowledge Attention-guided Module and Robust Task-oriented Head Module to accurately predict direction angles for high-precision navigation. To evaluate the vision-based navigation methods, we collect a new dataset termed as UAV_AR368. Furthermore, we design the Simulation Flight Testing Instrument (SFTI) using Google Earth to simulate different flight environments, thereby reducing the expenses associated with real flight testing. Experiment results demonstrate that the proposed model outperforms the state-of-the-art by achieving improvements of 26.0% and 45.6% in the success rate of arrival under ideal and disturbed circumstances, respectively. ",
    "url": "https://arxiv.org/abs/2402.02405",
    "authors": [
      "Yuxin Wang",
      "Zunlei Feng",
      "Haofei Zhang",
      "Yang Gao",
      "Jie Lei",
      "Li Sun",
      "Mingli Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02407",
    "title": "Defining Neural Network Architecture through Polytope Structures of  Dataset",
    "abstract": "Current theoretical and empirical research in neural networks suggests that complex datasets require large network architectures for thorough classification, yet the precise nature of this relationship remains unclear. This paper tackles this issue by defining upper and lower bounds for neural network widths, which are informed by the polytope structure of the dataset in question. We also delve into the application of these principles to simplicial complexes and specific manifold shapes, explaining how the requirement for network width varies in accordance with the geometric complexity of the dataset. Moreover, we develop an algorithm to investigate a converse situation where the polytope structure of a dataset can be inferred from its corresponding trained neural networks. Through our algorithm, it is established that popular datasets such as MNIST, Fashion-MNIST, and CIFAR10 can be efficiently encapsulated using no more than two polytopes with a small number of faces. ",
    "url": "https://arxiv.org/abs/2402.02407",
    "authors": [
      "Sangmin Lee",
      "Abbas Mammadov",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02425",
    "title": "EuLagNet: Eulerian Fluid Prediction with Lagrangian Dynamics",
    "abstract": "Accurately predicting the future fluid is important to extensive areas, such as meteorology, oceanology and aerodynamics. However, since the fluid is usually observed from an Eulerian perspective, its active and intricate dynamics are seriously obscured and confounded in static grids, bringing horny challenges to the prediction. This paper introduces a new Lagrangian-guided paradigm to tackle the tanglesome fluid dynamics. Instead of solely predicting the future based on Eulerian observations, we propose the Eulerian-Lagrangian Dual Recurrent Network (EuLagNet), which captures multiscale fluid dynamics by tracking movements of adaptively sampled key particles on multiple scales and integrating dynamics information over time. Concretely, a EuLag Block is presented to communicate the learned Eulerian and Lagrangian features at each moment and scale, where the motion of tracked particles is inferred from Eulerian observations and their accumulated dynamics information is incorporated into Eulerian fields to guide future prediction. Tracking key particles not only provides a clear and interpretable clue for fluid dynamics but also makes our model free from modeling complex correlations among massive grids for better efficiency. Experimentally, EuLagNet excels in three challenging fluid prediction tasks, covering both 2D and 3D, simulated and real-world fluids. ",
    "url": "https://arxiv.org/abs/2402.02425",
    "authors": [
      "Qilong Ma",
      "Haixu Wu",
      "Lanxiang Xing",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2402.02453",
    "title": "AI Art Neural Constellation: Revealing the Collective and Contrastive  State of AI-Generated and Human Art",
    "abstract": "Discovering the creative potentials of a random signal to various artistic expressions in aesthetic and conceptual richness is a ground for the recent success of generative machine learning as a way of art creation. To understand the new artistic medium better, we conduct a comprehensive analysis to position AI-generated art within the context of human art heritage. Our comparative analysis is based on an extensive dataset, dubbed ``ArtConstellation,'' consisting of annotations about art principles, likability, and emotions for 6,000 WikiArt and 3,200 AI-generated artworks. After training various state-of-the-art generative models, art samples are produced and compared with WikiArt data on the last hidden layer of a deep-CNN trained for style classification. We actively examined the various art principles to interpret the neural representations and used them to drive the comparative knowledge about human and AI-generated art. A key finding in the semantic analysis is that AI-generated artworks are visually related to the principle concepts for modern period art made in 1800-2000. In addition, through Out-Of-Distribution (OOD) and In-Distribution (ID) detection in CLIP space, we find that AI-generated artworks are ID to human art when they depict landscapes and geometric abstract figures, while detected as OOD when the machine art consists of deformed and twisted figures. We observe that machine-generated art is uniquely characterized by incomplete and reduced figuration. Lastly, we conducted a human survey about emotional experience. Color composition and familiar subjects are the key factors of likability and emotions in art appreciation. We propose our whole methodologies and collected dataset as our analytical framework to contrast human and AI-generated art, which we refer to as ``ArtNeuralConstellation''. Code is available at: https://github.com/faixan-khan/ArtNeuralConstellation ",
    "url": "https://arxiv.org/abs/2402.02453",
    "authors": [
      "Faizan Farooq Khan",
      "Diana Kim",
      "Divyansh Jha",
      "Youssef Mohamed",
      "Hanna H Chang",
      "Ahmed Elgammal",
      "Luba Elliott",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02454",
    "title": "On the Role of Initialization on the Implicit Bias in Deep Linear  Networks",
    "abstract": "Despite Deep Learning's (DL) empirical success, our theoretical understanding of its efficacy remains limited. One notable paradox is that while conventional wisdom discourages perfect data fitting, deep neural networks are designed to do just that, yet they generalize effectively. This study focuses on exploring this phenomenon attributed to the implicit bias at play. Various sources of implicit bias have been identified, such as step size, weight initialization, optimization algorithm, and number of parameters. In this work, we focus on investigating the implicit bias originating from weight initialization. To this end, we examine the problem of solving underdetermined linear systems in various contexts, scrutinizing the impact of initialization on the implicit regularization when using deep networks to solve such systems. Our findings elucidate the role of initialization in the optimization and generalization paradoxes, contributing to a more comprehensive understanding of DL's performance characteristics. ",
    "url": "https://arxiv.org/abs/2402.02454",
    "authors": [
      "Oria Gruber",
      "Haim Avron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.02456",
    "title": "Discovering More Effective Tensor Network Structure Search Algorithms  via Large Language Models (LLMs)",
    "abstract": "Tensor network structure search (TN-SS), aiming at searching for suitable tensor network (TN) structures in representing high-dimensional problems, largely promotes the efficacy of TN in various machine learning applications. Nonetheless, finding a satisfactory TN structure using existing algorithms remains challenging. To develop more effective algorithms and avoid the human labor-intensive development process, we explore the knowledge embedded in large language models (LLMs) for the automatic design of TN-SS algorithms. Our approach, dubbed GPTN-SS, leverages an elaborate crafting LLM-based prompting system that operates in an evolutionary-like manner. The experimental results, derived from real-world data, demonstrate that GPTN-SS can effectively leverage the insights gained from existing methods to develop novel TN-SS algorithms that achieve a better balance between exploration and exploitation. These algorithms exhibit superior performance in searching the high-quality TN structures for natural image compression and model parameters compression while also demonstrating generalizability in their performance. ",
    "url": "https://arxiv.org/abs/2402.02456",
    "authors": [
      "Junhua Zeng",
      "Guoxu Zhou",
      "Chao Li",
      "Zhun Sun",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02464",
    "title": "A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer",
    "abstract": "Can we model non-Euclidean graphs as pure language or even Euclidean vectors while retaining their inherent information? The non-Euclidean property have posed a long term challenge in graph modeling. Despite recent GNN and Graphformer efforts encoding graphs as Euclidean vectors, recovering original graph from the vectors remains a challenge. We introduce GraphsGPT, featuring a Graph2Seq encoder that transforms non-Euclidean graphs into learnable graph words in a Euclidean space, along with a GraphGPT decoder that reconstructs the original graph from graph words to ensure information equivalence. We pretrain GraphsGPT on 100M molecules and yield some interesting findings: (1) Pretrained Graph2Seq excels in graph representation learning, achieving state-of-the-art results on 8/9 graph classification and regression tasks. (2) Pretrained GraphGPT serves as a strong graph generator, demonstrated by its ability to perform both unconditional and conditional graph generation. (3) Graph2Seq+GraphGPT enables effective graph mixup in the Euclidean space, overcoming previously known non-Euclidean challenge. (4) Our proposed novel edge-centric GPT pretraining task is effective in graph fields, underscoring its success in both representation and generation. ",
    "url": "https://arxiv.org/abs/2402.02464",
    "authors": [
      "Zhangyang Gao",
      "Daize Dong",
      "Cheng Tan",
      "Jun Xia",
      "Bozhen Hu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02478",
    "title": "Why are hyperbolic neural networks effective? A study on hierarchical  representation capability",
    "abstract": "Hyperbolic Neural Networks (HNNs), operating in hyperbolic space, have been widely applied in recent years, motivated by the existence of an optimal embedding in hyperbolic space that can preserve data hierarchical relationships (termed Hierarchical Representation Capability, HRC) more accurately than Euclidean space. However, there is no evidence to suggest that HNNs can achieve this theoretical optimal embedding, leading to much research being built on flawed motivations. In this paper, we propose a benchmark for evaluating HRC and conduct a comprehensive analysis of why HNNs are effective through large-scale experiments. Inspired by the analysis results, we propose several pre-training strategies to enhance HRC and improve the performance of downstream tasks, further validating the reliability of the analysis. Experiments show that HNNs cannot achieve the theoretical optimal embedding. The HRC is significantly affected by the optimization objectives and hierarchical structures, and enhancing HRC through pre-training strategies can significantly improve the performance of HNNs. ",
    "url": "https://arxiv.org/abs/2402.02478",
    "authors": [
      "Shicheng Tan",
      "Huanjing Zhao",
      "Shu Zhao",
      "Yanping Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02511",
    "title": "PoCo: Policy Composition from and for Heterogeneous Robot Learning",
    "abstract": "Training general robotic policies from heterogeneous data for different tasks is a significant challenge. Existing robotic datasets vary in different modalities such as color, depth, tactile, and proprioceptive information, and collected in different domains such as simulation, real robots, and human videos. Current methods usually collect and pool all data from one domain to train a single policy to handle such heterogeneity in tasks and domains, which is prohibitively expensive and difficult. In this work, we present a flexible approach, dubbed Policy Composition, to combine information across such diverse modalities and domains for learning scene-level and task-level generalized manipulation skills, by composing different data distributions represented with diffusion models. Our method can use task-level composition for multi-task manipulation and be composed with analytic cost functions to adapt policy behaviors at inference time. We train our method on simulation, human, and real robot data and evaluate in tool-use tasks. The composed policy achieves robust and dexterous performance under varying scenes and tasks and outperforms baselines from a single data source in both simulation and real-world experiments. See https://liruiw.github.io/policycomp for more details . ",
    "url": "https://arxiv.org/abs/2402.02511",
    "authors": [
      "Lirui Wang",
      "Jialiang Zhao",
      "Yilun Du",
      "Edward H. Adelson",
      "Russ Tedrake"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02513",
    "title": "Early stopping by correlating online indicators in neural networks",
    "abstract": "In order to minimize the generalization error in neural networks, a novel technique to identify overfitting phenomena when training the learner is formally introduced. This enables support of a reliable and trustworthy early stopping condition, thus improving the predictive power of that type of modeling. Our proposal exploits the correlation over time in a collection of online indicators, namely characteristic functions for indicating if a set of hypotheses are met, associated with a range of independent stopping conditions built from a canary judgment to evaluate the presence of overfitting. That way, we provide a formal basis for decision making in terms of interrupting the learning process. As opposed to previous approaches focused on a single criterion, we take advantage of subsidiarities between independent assessments, thus seeking both a wider operating range and greater diagnostic reliability. With a view to illustrating the effectiveness of the halting condition described, we choose to work in the sphere of natural language processing, an operational continuum increasingly based on machine learning. As a case study, we focus on parser generation, one of the most demanding and complex tasks in the domain. The selection of cross-validation as a canary function enables an actual comparison with the most representative early stopping conditions based on overfitting identification, pointing to a promising start toward an optimal bias and variance control. ",
    "url": "https://arxiv.org/abs/2402.02513",
    "authors": [
      "Manuel Vilares Ferro",
      "Yerai Doval Mosquera",
      "Francisco J. Ribadas Pena",
      "Victor M. Darriba Bilbao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.02518",
    "title": "Latent Graph Diffusion: A Unified Framework for Generation and  Prediction on Graphs",
    "abstract": "In this paper, we propose the first framework that enables solving graph learning tasks of all levels (node, edge and graph) and all types (generation, regression and classification) with one model. We first propose Latent Graph Diffusion (LGD), a generative model that can generate node, edge, and graph-level features of all categories simultaneously. We achieve this goal by embedding the graph structures and features into a latent space leveraging a powerful encoder which can also be decoded, then training a diffusion model in the latent space. LGD is also capable of conditional generation through a specifically designed cross-attention mechanism. Then we formulate prediction tasks including regression and classification as (conditional) generation, which enables our LGD to solve tasks of all levels and all types with provable guarantees. We verify the effectiveness of our framework with extensive experiments, where our models achieve state-of-the-art or highly competitive results across generation and regression tasks. ",
    "url": "https://arxiv.org/abs/2402.02518",
    "authors": [
      "Zhou Cai",
      "Xiyuan Wang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02519",
    "title": "SIMPL: A Simple and Efficient Multi-agent Motion Prediction Baseline for  Autonomous Driving",
    "abstract": "This paper presents a Simple and effIcient Motion Prediction baseLine (SIMPL) for autonomous vehicles. Unlike conventional agent-centric methods with high accuracy but repetitive computations and scene-centric methods with compromised accuracy and generalizability, SIMPL delivers real-time, accurate motion predictions for all relevant traffic participants. To achieve improvements in both accuracy and inference speed, we propose a compact and efficient global feature fusion module that performs directed message passing in a symmetric manner, enabling the network to forecast future motion for all road users in a single feed-forward pass and mitigating accuracy loss caused by viewpoint shifting. Additionally, we investigate the continuous trajectory parameterization using Bernstein basis polynomials in trajectory decoding, allowing evaluations of states and their higher-order derivatives at any desired time point, which is valuable for downstream planning tasks. As a strong baseline, SIMPL exhibits highly competitive performance on Argoverse 1 & 2 motion forecasting benchmarks compared with other state-of-the-art methods. Furthermore, its lightweight design and low inference latency make SIMPL highly extensible and promising for real-world onboard deployment. We open-source the code at https://github.com/HKUST-Aerial-Robotics/SIMPL. ",
    "url": "https://arxiv.org/abs/2402.02519",
    "authors": [
      "Lu Zhang",
      "Peiliang Li",
      "Sikang Liu",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02540",
    "title": "Embedding Non-Distortive Cancelable Face Template Generation",
    "abstract": "Biometric authentication systems are crucial for security, but developing them involves various complexities, including privacy, security, and achieving high accuracy without directly storing pure biometric data in storage. We introduce an innovative image distortion technique that makes facial images unrecognizable to the eye but still identifiable by any custom embedding neural network model. Using the proposed approach, we test the reliability of biometric recognition networks by determining the maximum image distortion that does not change the predicted identity. Through experiments on MNIST and LFW datasets, we assess its effectiveness and compare it based on the traditional comparison metrics. ",
    "url": "https://arxiv.org/abs/2402.02540",
    "authors": [
      "Dmytro Zakharov",
      "Oleksandr Kuznetsov",
      "Emanuele Frontoni",
      "Natalia Kryvinska"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.02551",
    "title": "Obstacle Avoidance Deep Reinforcement Learning-Based Trajectory Planner  with Robust Low-Level Control for Robotic Manipulators",
    "abstract": "In robotics, contemporary strategies are learning-based, characterized by a complex black-box nature and a lack of interpretability, which may pose challenges in ensuring stability and safety. To address these issues, we propose integrating an obstacle-free deep reinforcement learning (DRL) trajectory planner with a novel auto-tuning low- and joint-level control strategy, all while actively engaging in the learning phase through interactions with the environment. This approach circumvents the complexities associated with computations while also addressing nonrepetitive and random obstacle avoidance tasks. First, a model-free DRL agent to plan velocity-bounded and obstacle-free motion is employed for a manipulator with 'n' degrees of freedom (DoF) in task space through joint-level reasoning. This plan is then input into a robust subsystem-based adaptive controller, which produces the necessary torques, while the Cuckoo Search Optimization (CSO) algorithm enhances control gains to minimize the time required to reach, time taken to stabilize, the maximum deviation from the desired value, and persistent tracking error in the steady state. This approach guarantees that position and velocity errors exponentially converge to zero, accounting for any initial and end-point variations, unknown modeling errors, and external disturbances. Theoretical assertions are validated through the presentation of simulation outcomes. ",
    "url": "https://arxiv.org/abs/2402.02551",
    "authors": [
      "Mehdi Heydari Shahna",
      "Seyed Adel Alizadeh Kolagar",
      "Jouni Mattila"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.02554",
    "title": "DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms  in Vision Transformers",
    "abstract": "Vision transformers have contributed greatly to advancements in the computer vision domain, demonstrating state-of-the-art performance in diverse tasks (e.g., image classification, object detection). However, their high computational requirements grow quadratically with the number of tokens used. Token sparsification techniques have been proposed to address this issue. These techniques employ an input-dependent strategy, in which uninformative tokens are discarded from the computation pipeline, improving the model's efficiency. However, their dynamism and average-case assumption makes them vulnerable to a new threat vector - carefully crafted adversarial examples capable of fooling the sparsification mechanism, resulting in worst-case performance. In this paper, we present DeSparsify, an attack targeting the availability of vision transformers that use token sparsification mechanisms. The attack aims to exhaust the operating system's resources, while maintaining its stealthiness. Our evaluation demonstrates the attack's effectiveness on three token sparsification techniques and examines the attack's transferability between them and its effect on the GPU resources. To mitigate the impact of the attack, we propose various countermeasures. ",
    "url": "https://arxiv.org/abs/2402.02554",
    "authors": [
      "Oryan Yehezkel",
      "Alon Zolfi",
      "Amit Baras",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02558",
    "title": "Enhancing Robustness in Biomedical NLI Models: A Probing Approach for  Clinical Trials",
    "abstract": "Large Language Models have revolutionized various fields and industries, such as Conversational AI, Content Generation, Information Retrieval, Business Intelligence, and Medical, to name a few. One major application in the field of medical is to analyze and investigate clinical trials for entailment tasks.However, It has been observed that Large Language Models are susceptible to shortcut learning, factual inconsistency, and performance degradation with little variation in context. Adversarial and robust testing is performed to ensure the integrity of models output. But, ambiguity still persists. In order to ensure the integrity of the reasoning performed and investigate the model has correct syntactic and semantic understanding probing is used. Here, I used mnestic probing to investigate the Sci-five model, trained on clinical trial. I investigated the model for feature learnt with respect to natural logic. To achieve the target, I trained task specific probes. Used these probes to investigate the final layers of trained model. Then, fine tuned the trained model using iterative null projection. The results shows that model accuracy improved. During experimentation, I observed that size of the probe has affect on the fine tuning process. ",
    "url": "https://arxiv.org/abs/2402.02558",
    "authors": [
      "Ata Mustafa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02564",
    "title": "A Truly Joint Neural Architecture for Segmentation and Parsing",
    "abstract": "Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the joint morpho-syntactic hypothesis, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline. In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art performance on parsing, tagging and segmentation of the Hebrew section of UD, using a single model. This proposed architecture is LLM-based and language agnostic, providing a solid foundation for MRLs to obtain further performance improvements and bridge the gap with other languages. ",
    "url": "https://arxiv.org/abs/2402.02564",
    "authors": [
      "Danit Yshaayahu Levi",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.02566",
    "title": "STAGE: Scalable and Traversability-Aware Graph based Exploration Planner  for Dynamically Varying Environments",
    "abstract": "In this article, we propose a novel navigation framework that leverages a two layered graph representation of the environment for efficient large-scale exploration, while it integrates a novel uncertainty awareness scheme to handle dynamic scene changes in previously explored areas. The framework is structured around a novel goal oriented graph representation, that consists of, i) the local sub-graph and ii) the global graph layer respectively. The local sub-graphs encode local volumetric gain locations as frontiers, based on the direct pointcloud visibility, allowing fast graph building and path planning. Additionally, the global graph is build in an efficient way, using node-edge information exchange only on overlapping regions of sequential sub-graphs. Different from the state-of-the-art graph based exploration methods, the proposed approach efficiently re-uses sub-graphs built in previous iterations to construct the global navigation layer. Another merit of the proposed scheme is the ability to handle scene changes (e.g. blocked pathways), adaptively updating the obstructed part of the global graph from traversable to not-traversable. This operation involved oriented sample space of a path segment in the global graph layer, while removing the respective edges from connected nodes of the global graph in cases of obstructions. As such, the exploration behavior is directing the robot to follow another route in the global re-positioning phase through path-way updates in the global graph. Finally, we showcase the performance of the method both in simulation runs as well as deployed in real-world scene involving a legged robot carrying camera and lidar sensor. ",
    "url": "https://arxiv.org/abs/2402.02566",
    "authors": [
      "Akash Patel",
      "Mario A V Saucedo",
      "Christoforos Kanellakis",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.02574",
    "title": "Spatio-temporal Prompting Network for Robust Video Feature Extraction",
    "abstract": "Frame quality deterioration is one of the main challenges in the field of video understanding. To compensate for the information loss caused by deteriorated frames, recent approaches exploit transformer-based integration modules to obtain spatio-temporal information. However, these integration modules are heavy and complex. Furthermore, each integration module is specifically tailored for its target task, making it difficult to generalise to multiple tasks. In this paper, we present a neat and unified framework, called Spatio-Temporal Prompting Network (STPN). It can efficiently extract robust and accurate video features by dynamically adjusting the input features in the backbone network. Specifically, STPN predicts several video prompts containing spatio-temporal information of neighbour frames. Then, these video prompts are prepended to the patch embeddings of the current frame as the updated input for video feature extraction. Moreover, STPN is easy to generalise to various video tasks because it does not contain task-specific modules. Without bells and whistles, STPN achieves state-of-the-art performance on three widely-used datasets for different video understanding tasks, i.e., ImageNetVID for video object detection, YouTubeVIS for video instance segmentation, and GOT-10k for visual object tracking. Code is available at https://github.com/guanxiongsun/vfe.pytorch. ",
    "url": "https://arxiv.org/abs/2402.02574",
    "authors": [
      "Guanxiong Sun",
      "Chi Wang",
      "Zhaoyu Zhang",
      "Jiankang Deng",
      "Stefanos Zafeiriou",
      "Yang Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02617",
    "title": "Layer-Wise Analysis of Self-Supervised Acoustic Word Embeddings: A Study  on Speech Emotion Recognition",
    "abstract": "The efficacy of self-supervised speech models has been validated, yet the optimal utilization of their representations remains challenging across diverse tasks. In this study, we delve into Acoustic Word Embeddings (AWEs), a fixed-length feature derived from continuous representations, to explore their advantages in specific tasks. AWEs have previously shown utility in capturing acoustic discriminability. In light of this, we propose measuring layer-wise similarity between AWEs and word embeddings, aiming to further investigate the inherent context within AWEs. Moreover, we evaluate the contribution of AWEs, in comparison to other types of speech features, in the context of Speech Emotion Recognition (SER). Through a comparative experiment and a layer-wise accuracy analysis on two distinct corpora, IEMOCAP and ESD, we explore differences between AWEs and raw self-supervised representations, as well as the proper utilization of AWEs alone and in combination with word embeddings. Our findings underscore the acoustic context conveyed by AWEs and showcase the highly competitive SER accuracies by appropriately employing AWEs. ",
    "url": "https://arxiv.org/abs/2402.02617",
    "authors": [
      "Alexandra Saliba",
      "Yuanchao Li",
      "Ramon Sanabria",
      "Catherine Lai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.02627",
    "title": "Stability Analysis of Various Symbolic Rule Extraction Methods from  Recurrent Neural Network",
    "abstract": "This paper analyzes two competing rule extraction methodologies: quantization and equivalence query. We trained $3600$ RNN models, extracting $18000$ DFA with a quantization approach (k-means and SOM) and $3600$ DFA by equivalence query($L^{*}$) methods across $10$ initialization seeds. We sampled the datasets from $7$ Tomita and $4$ Dyck grammars and trained them on $4$ RNN cells: LSTM, GRU, O2RNN, and MIRNN. The observations from our experiments establish the superior performance of O2RNN and quantization-based rule extraction over others. $L^{*}$, primarily proposed for regular grammars, performs similarly to quantization methods for Tomita languages when neural networks are perfectly trained. However, for partially trained RNNs, $L^{*}$ shows instability in the number of states in DFA, e.g., for Tomita 5 and Tomita 6 languages, $L^{*}$ produced more than $100$ states. In contrast, quantization methods result in rules with number of states very close to ground truth DFA. Among RNN cells, O2RNN produces stable DFA consistently compared to other cells. For Dyck Languages, we observe that although GRU outperforms other RNNs in network performance, the DFA extracted by O2RNN has higher performance and better stability. The stability is computed as the standard deviation of accuracy on test sets on networks trained across $10$ seeds. On Dyck Languages, quantization methods outperformed $L^{*}$ with better stability in accuracy and the number of states. $L^{*}$ often showed instability in accuracy in the order of $16\\% - 22\\%$ for GRU and MIRNN while deviation for quantization methods varied in $5\\% - 15\\%$. In many instances with LSTM and GRU, DFA's extracted by $L^{*}$ even failed to beat chance accuracy ($50\\%$), while those extracted by quantization method had standard deviation in the $7\\%-17\\%$ range. For O2RNN, both rule extraction methods had deviation in the $0.5\\% - 3\\%$ range. ",
    "url": "https://arxiv.org/abs/2402.02627",
    "authors": [
      "Neisarg Dave",
      "Daniel Kifer",
      "C. Lee Giles",
      "Ankur Mali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02629",
    "title": "PROSAC: Provably Safe Certification for Machine Learning Models under  Adversarial Attacks",
    "abstract": "It is widely known that state-of-the-art machine learning models, including vision and language models, can be seriously compromised by adversarial perturbations. It is therefore increasingly relevant to develop capabilities to certify their performance in the presence of the most effective adversarial attacks. Our paper offers a new approach to certify the performance of machine learning models in the presence of adversarial attacks with population level risk guarantees. In particular, we introduce the notion of $(\\alpha,\\zeta)$ machine learning model safety. We propose a hypothesis testing procedure, based on the availability of a calibration set, to derive statistical guarantees providing that the probability of declaring that the adversarial (population) risk of a machine learning model is less than $\\alpha$ (i.e. the model is safe), while the model is in fact unsafe (i.e. the model adversarial population risk is higher than $\\alpha$), is less than $\\zeta$. We also propose Bayesian optimization algorithms to determine efficiently whether a machine learning model is $(\\alpha,\\zeta)$-safe in the presence of an adversarial attack, along with statistical guarantees. We apply our framework to a range of machine learning models including various sizes of vision Transformer (ViT) and ResNet models impaired by a variety of adversarial attacks, such as AutoAttack, SquareAttack and natural evolution strategy attack, to illustrate the operation of our approach. Importantly, we show that ViT's are generally more robust to adversarial attacks than ResNets, and ViT-large is more robust than smaller models. Our approach goes beyond existing empirical adversarial risk-based certification guarantees. It formulates rigorous (and provable) performance guarantees that can be used to satisfy regulatory requirements mandating the use of state-of-the-art technical tools. ",
    "url": "https://arxiv.org/abs/2402.02629",
    "authors": [
      "Ziquan Liu",
      "Zhuo Zhi",
      "Ilija Bogunovic",
      "Carsten Gerner-Beuerle",
      "Miguel Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02636",
    "title": "Can Large Language Models Learn Independent Causal Mechanisms?",
    "abstract": "Despite impressive performance on language modelling and complex reasoning tasks, Large Language Models (LLMs) fall short on the same tasks in uncommon settings or with distribution shifts, exhibiting some lack of generalisation ability. This issue has usually been alleviated by feeding more training data into the LLM. However, this method is brittle, as the scope of tasks may not be readily predictable or may evolve, and updating the model with new data generally requires extensive additional training. By contrast, systems, such as causal models, that learn abstract variables and causal relationships can demonstrate increased robustness against changes in the distribution. One reason for this success is the existence and use of Independent Causal Mechanisms (ICMs) representing high-level concepts that only sparsely interact. In this work, we apply two concepts from causality to learn ICMs within LLMs. We develop a new LLM architecture composed of multiple sparsely interacting language modelling modules. We introduce a routing scheme to induce specialisation of the network into domain-specific modules. We also present a Mutual Information minimisation objective that trains a separate module to learn abstraction and domain-invariant mechanisms. We show that such causal constraints can improve out-of-distribution performance on abstract and causal reasoning tasks. ",
    "url": "https://arxiv.org/abs/2402.02636",
    "authors": [
      "Ga\u00ebl Gendron",
      "Bao Trung Nguyen",
      "Alex Yuxuan Peng",
      "Michael Witbrock",
      "Gillian Dobbie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02642",
    "title": "Object Graph Programming",
    "abstract": "We introduce Object Graph Programming (OGO), which enables reading and modifying an object graph (i.e., the entire state of the object heap) via declarative queries. OGO models the objects and their relations in the heap as an object graph thereby treating the heap as a graph database: each node in the graph is an object (e.g., an instance of a class or an instance of a metadata class) and each edge is a relation between objects (e.g., a field of one object references another object). We leverage Cypher, the most popular query language for graph databases, as OGO's query language. Unlike LINQ, which uses collections (e.g., List) as a source of data, OGO views the entire object graph as a single \"collection\". OGO is ideal for querying collections (just like LINQ), introspecting the runtime system state (e.g., finding all instances of a given class or accessing fields via reflection), and writing assertions that have access to the entire program state. We prototyped OGO for Java in two ways: (a) by translating an object graph into a Neo4j database on which we run Cypher queries, and (b) by implementing our own in-memory graph query engine that directly queries the object heap. We used OGO to rewrite hundreds of statements in large open-source projects into OGO queries. We report our experience and performance of our prototypes. ",
    "url": "https://arxiv.org/abs/2402.02642",
    "authors": [
      "Aditya Thimmaiah",
      "Leonidas Lampropoulos",
      "Christopher J. Rossbach",
      "Milos Gligoric"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.02644",
    "title": "Variational DAG Estimation via State Augmentation With Stochastic  Permutations",
    "abstract": "Estimating the structure of a Bayesian network, in the form of a directed acyclic graph (DAG), from observational data is a statistically and computationally hard problem with essential applications in areas such as causal discovery. Bayesian approaches are a promising direction for solving this task, as they allow for uncertainty quantification and deal with well-known identifiability issues. From a probabilistic inference perspective, the main challenges are (i) representing distributions over graphs that satisfy the DAG constraint and (ii) estimating a posterior over the underlying combinatorial space. We propose an approach that addresses these challenges by formulating a joint distribution on an augmented space of DAGs and permutations. We carry out posterior estimation via variational inference, where we exploit continuous relaxations of discrete distributions. We show that our approach can outperform competitive Bayesian and non-Bayesian benchmarks on a range of synthetic and real datasets. ",
    "url": "https://arxiv.org/abs/2402.02644",
    "authors": [
      "Edwin V. Bonilla",
      "Pantelis Elinas",
      "He Zhao",
      "Maurizio Filippone",
      "Vassili Kitsios",
      "Terry O'Kane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.02649",
    "title": "Densely Decoded Networks with Adaptive Deep Supervision for Medical  Image Segmentation",
    "abstract": "Medical image segmentation using deep neural networks has been highly successful. However, the effectiveness of these networks is often limited by inadequate dense prediction and inability to extract robust features. To achieve refined dense prediction, we propose densely decoded networks (ddn), by selectively introducing 'crutch' network connections. Such 'crutch' connections in each upsampling stage of the network decoder (1) enhance target localization by incorporating high resolution features from the encoder, and (2) improve segmentation by facilitating multi-stage contextual information flow. Further, we present a training strategy based on adaptive deep supervision (ads), which exploits and adapts specific attributes of input dataset, for robust feature extraction. In particular, ads strategically locates and deploys auxiliary supervision, by matching the average input object size with the layer-wise effective receptive fields (lerf) of a network, resulting in a class of ddns. Such inclusion of 'companion objective' from a specific hidden layer, helps the model pay close attention to some distinct input-dependent features, which the network might otherwise 'ignore' during training. Our new networks and training strategy are validated on 4 diverse datasets of different modalities, demonstrating their effectiveness. ",
    "url": "https://arxiv.org/abs/2402.02649",
    "authors": [
      "Suraj Mishra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02653",
    "title": "Learning with Mixture of Prototypes for Out-of-Distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection aims to detect testing samples far away from the in-distribution (ID) training data, which is crucial for the safe deployment of machine learning models in the real world. Distance-based OOD detection methods have emerged with enhanced deep representation learning. They identify unseen OOD samples by measuring their distances from ID class centroids or prototypes. However, existing approaches learn the representation relying on oversimplified data assumptions, e.g, modeling ID data of each class with one centroid class prototype or using loss functions not designed for OOD detection, which overlook the natural diversities within the data. Naively enforcing data samples of each class to be compact around only one prototype leads to inadequate modeling of realistic data and limited performance. To tackle these issues, we propose PrototypicAl Learning with a Mixture of prototypes (PALM) which models each class with multiple prototypes to capture the sample diversities, and learns more faithful and compact samples embeddings to enhance OOD detection. Our method automatically identifies and dynamically updates prototypes, assigning each sample to a subset of prototypes via reciprocal neighbor soft assignment weights. PALM optimizes a maximum likelihood estimation (MLE) loss to encourage the sample embeddings to be compact around the associated prototypes, as well as a contrastive loss on all prototypes to enhance intra-class compactness and inter-class discrimination at the prototype level. Moreover, the automatic estimation of prototypes enables our approach to be extended to the challenging OOD detection task with unlabelled ID data. Extensive experiments demonstrate the superiority of PALM, achieving state-of-the-art average AUROC performance of 93.82 on the challenging CIFAR-100 benchmark. Code is available at https://github.com/jeff024/PALM. ",
    "url": "https://arxiv.org/abs/2402.02653",
    "authors": [
      "Haodong Lu",
      "Dong Gong",
      "Shuo Wang",
      "Jason Xue",
      "Lina Yao",
      "Kristen Moore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02667",
    "title": "A Priori Error Estimation of Physics-Informed Neural Networks Solving  Allen--Cahn and Cahn--Hilliard Equations",
    "abstract": "This paper aims to analyze errors in the implementation of the Physics-Informed Neural Network (PINN) for solving the Allen--Cahn (AC) and Cahn--Hilliard (CH) partial differential equations (PDEs). The accuracy of PINN is still challenged when dealing with strongly non-linear and higher-order time-varying PDEs. To address this issue, we introduce a stable and bounded self-adaptive weighting scheme known as Residuals-RAE, which ensures fair training and effectively captures the solution. By incorporating this new training loss function, we conduct numerical experiments on 1D and 2D AC and CH systems to validate our theoretical findings. Our theoretical analysis demonstrates that feedforward neural networks with two hidden layers and tanh activation function effectively bound the PINN approximation errors for the solution field, temporal derivative, and nonlinear term of the AC and CH equations by the training loss and number of collocation points. ",
    "url": "https://arxiv.org/abs/2402.02667",
    "authors": [
      "Guangtao Zhang",
      "Jiani Lin",
      "Qijia Zhai",
      "Huiyu Yang",
      "Xujun Chen",
      "Xiaoning Zheng",
      "Ieng Tak Leong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2402.02678",
    "title": "Counterfactual Explanations of Black-box Machine Learning Models using  Causal Discovery with Applications to Credit Rating",
    "abstract": "Explainable artificial intelligence (XAI) has helped elucidate the internal mechanisms of machine learning algorithms, bolstering their reliability by demonstrating the basis of their predictions. Several XAI models consider causal relationships to explain models by examining the input-output relationships of prediction models and the dependencies between features. The majority of these models have been based their explanations on counterfactual probabilities, assuming that the causal graph is known. However, this assumption complicates the application of such models to real data, given that the causal relationships between features are unknown in most cases. Thus, this study proposed a novel XAI framework that relaxed the constraint that the causal graph is known. This framework leveraged counterfactual probabilities and additional prior information on causal structure, facilitating the integration of a causal graph estimated through causal discovery methods and a black-box classification model. Furthermore, explanatory scores were estimated based on counterfactual probabilities. Numerical experiments conducted employing artificial data confirmed the possibility of estimating the explanatory score more accurately than in the absence of a causal graph. Finally, as an application to real data, we constructed a classification model of credit ratings assigned by Shiga Bank, Shiga prefecture, Japan. We demonstrated the effectiveness of the proposed method in cases where the causal graph is unknown. ",
    "url": "https://arxiv.org/abs/2402.02678",
    "authors": [
      "Daisuke Takahashi",
      "Shohei Shimizu",
      "Takuma Tanaka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02692",
    "title": "Statistical Guarantees for Link Prediction using Graph Neural Networks",
    "abstract": "This paper derives statistical guarantees for the performance of Graph Neural Networks (GNNs) in link prediction tasks on graphs generated by a graphon. We propose a linear GNN architecture (LG-GNN) that produces consistent estimators for the underlying edge probabilities. We establish a bound on the mean squared error and give guarantees on the ability of LG-GNN to detect high-probability edges. Our guarantees hold for both sparse and dense graphs. Finally, we demonstrate some of the shortcomings of the classical GCN architecture, as well as verify our results on real and synthetic datasets. ",
    "url": "https://arxiv.org/abs/2402.02692",
    "authors": [
      "Alan Chung",
      "Amin Saberi",
      "Morgane Austern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.02695",
    "title": "Exploiting Class Probabilities for Black-box Sentence-level Attacks",
    "abstract": "Sentence-level attacks craft adversarial sentences that are synonymous with correctly-classified sentences but are misclassified by the text classifiers. Under the black-box setting, classifiers are only accessible through their feedback to queried inputs, which is predominately available in the form of class probabilities. Even though utilizing class probabilities results in stronger attacks, due to the challenges of using them for sentence-level attacks, existing attacks use either no feedback or only the class labels. Overcoming the challenges, we develop a novel algorithm that uses class probabilities for black-box sentence-level attacks, investigate the effectiveness of using class probabilities on the attack's success, and examine the question if it is worthy or practical to use class probabilities by black-box sentence-level attacks. We conduct extensive evaluations of the proposed attack comparing with the baselines across various classifiers and benchmark datasets. ",
    "url": "https://arxiv.org/abs/2402.02695",
    "authors": [
      "Raha Moraffah",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02696",
    "title": "Causal Feature Selection for Responsible Machine Learning",
    "abstract": "Machine Learning (ML) has become an integral aspect of many real-world applications. As a result, the need for responsible machine learning has emerged, focusing on aligning ML models to ethical and social values, while enhancing their reliability and trustworthiness. Responsible ML involves many issues. This survey addresses four main issues: interpretability, fairness, adversarial robustness, and domain generalization. Feature selection plays a pivotal role in the responsible ML tasks. However, building upon statistical correlations between variables can lead to spurious patterns with biases and compromised performance. This survey focuses on the current study of causal feature selection: what it is and how it can reinforce the four aspects of responsible ML. By identifying features with causal impacts on outcomes and distinguishing causality from correlation, causal feature selection is posited as a unique approach to ensuring ML models to be ethically and socially responsible in high-stakes applications. ",
    "url": "https://arxiv.org/abs/2402.02696",
    "authors": [
      "Raha Moraffah",
      "Paras Sheth",
      "Saketh Vishnubhatla",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02699",
    "title": "Adversarial Data Augmentation for Robust Speaker Verification",
    "abstract": "Data augmentation (DA) has gained widespread popularity in deep speaker models due to its ease of implementation and significant effectiveness. It enriches training data by simulating real-life acoustic variations, enabling deep neural networks to learn speaker-related representations while disregarding irrelevant acoustic variations, thereby improving robustness and generalization. However, a potential issue with the vanilla DA is augmentation residual, i.e., unwanted distortion caused by different types of augmentation. To address this problem, this paper proposes a novel approach called adversarial data augmentation (A-DA) which combines DA with adversarial learning. Specifically, it involves an additional augmentation classifier to categorize various augmentation types used in data augmentation. This adversarial learning empowers the network to generate speaker embeddings that can deceive the augmentation classifier, making the learned speaker embeddings more robust in the face of augmentation variations. Experiments conducted on VoxCeleb and CN-Celeb datasets demonstrate that our proposed A-DA outperforms standard DA in both augmentation matched and mismatched test conditions, showcasing its superior robustness and generalization against acoustic variations. ",
    "url": "https://arxiv.org/abs/2402.02699",
    "authors": [
      "Zhenyu Zhou",
      "Junhui Chen",
      "Namin Wang",
      "Lantian Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02705",
    "title": "Representation Surgery for Multi-Task Model Merging",
    "abstract": "Multi-task learning (MTL) compresses the information from multiple tasks into a unified backbone to improve computational efficiency and generalization. Recent work directly merges multiple independently trained models to perform MTL instead of collecting their raw data for joint training, greatly expanding the application scenarios of MTL. However, by visualizing the representation distribution of existing model merging schemes, we find that the merged model often suffers from the dilemma of representation bias. That is, there is a significant discrepancy in the representation distribution between the merged and individual models, resulting in poor performance of merged MTL. In this paper, we propose a representation surgery solution called \"Surgery\" to reduce representation bias in the merged model. Specifically, Surgery is a lightweight task-specific module that takes the representation of the merged model as input and attempts to output the biases contained in the representation from the merged model. We then designed an unsupervised optimization objective that updates the Surgery module by minimizing the distance between the merged model's representation and the individual model's representation. Extensive experiments demonstrate significant MTL performance improvements when our Surgery module is applied to state-of-the-art (SOTA) model merging schemes. ",
    "url": "https://arxiv.org/abs/2402.02705",
    "authors": [
      "Enneng Yang",
      "Li Shen",
      "Zhenyi Wang",
      "Guibing Guo",
      "Xiaojun Chen",
      "Xingwei Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02711",
    "title": "Architectural Strategies for the optimization of Physics-Informed Neural  Networks",
    "abstract": "Physics-informed neural networks (PINNs) offer a promising avenue for tackling both forward and inverse problems in partial differential equations (PDEs) by incorporating deep learning with fundamental physics principles. Despite their remarkable empirical success, PINNs have garnered a reputation for their notorious training challenges across a spectrum of PDEs. In this work, we delve into the intricacies of PINN optimization from a neural architecture perspective. Leveraging the Neural Tangent Kernel (NTK), our study reveals that Gaussian activations surpass several alternate activations when it comes to effectively training PINNs. Building on insights from numerical linear algebra, we introduce a preconditioned neural architecture, showcasing how such tailored architectures enhance the optimization process. Our theoretical findings are substantiated through rigorous validation against established PDEs within the scientific literature. ",
    "url": "https://arxiv.org/abs/2402.02711",
    "authors": [
      "Hemanth Saratchandran",
      "Shin-Fang Chng",
      "Simon Lucey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02720",
    "title": "Discounted Adaptive Online Prediction",
    "abstract": "Online learning is not always about memorizing everything. Since the future can be statistically very different from the past, a critical challenge is to gracefully forget the history while new data comes in. To formalize this intuition, we revisit the classical notion of discounted regret using recently developed techniques in adaptive online learning. Our main result is a new algorithm that adapts to the complexity of both the loss sequence and the comparator, improving the widespread non-adaptive algorithm - gradient descent with a constant learning rate. In particular, our theoretical guarantee does not require any structural assumption beyond convexity, and the algorithm is provably robust to suboptimal hyperparameter tuning. We further demonstrate such benefits through online conformal prediction, a downstream online learning task with set-membership decisions. ",
    "url": "https://arxiv.org/abs/2402.02720",
    "authors": [
      "Zhiyu Zhang",
      "David Bombara",
      "Heng Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.02724",
    "title": "FDNet: Frequency Domain Denoising Network For Cell Segmentation in  Astrocytes Derived From Induced Pluripotent Stem Cells",
    "abstract": "Artificially generated induced pluripotent stem cells (iPSCs) from somatic cells play an important role for disease modeling and drug screening of neurodegenerative diseases. Astrocytes differentiated from iPSCs are important targets to investigate neuronal metabolism. The astrocyte differentiation progress can be monitored through the variations of morphology observed from microscopy images at different differentiation stages, then determined by molecular biology techniques upon maturation. However, the astrocytes usually ``perfectly'' blend into the background and some of them are covered by interference information (i.e., dead cells, media sediments, and cell debris), which makes astrocytes difficult to observe. Due to the lack of annotated datasets, the existing state-of-the-art deep learning approaches cannot be used to address this issue. In this paper, we introduce a new task named astrocyte segmentation with a novel dataset, called IAI704, which contains 704 images and their corresponding pixel-level annotation masks. Moreover, a novel frequency domain denoising network, named FDNet, is proposed for astrocyte segmentation. In detail, our FDNet consists of a contextual information fusion module (CIF), an attention block (AB), and a Fourier transform block (FTB). CIF and AB fuse multi-scale feature embeddings to localize the astrocytes. FTB transforms feature embeddings into the frequency domain and conducts a high-pass filter to eliminate interference information. Experimental results demonstrate the superiority of our proposed FDNet over the state-of-the-art substitutes in astrocyte segmentation, shedding insights for iPSC differentiation progress prediction. ",
    "url": "https://arxiv.org/abs/2402.02724",
    "authors": [
      "Haoran Li",
      "Jiahua Shi",
      "Huaming Chen",
      "Bo Du",
      "Simon Maksour",
      "Gabrielle Phillips",
      "Mirella Dottori",
      "Jun Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02732",
    "title": "A Generative Approach to Surrogate-based Black-box Attacks",
    "abstract": "Surrogate-based black-box attacks have exposed the heightened vulnerability of DNNs. These attacks are designed to craft adversarial examples for any samples with black-box target feedback for only a given set of samples. State-of-the-art surrogate-based attacks involve training a discriminative surrogate that mimics the target's outputs. The goal is to learn the decision boundaries of the target. The surrogate is then attacked by white-box attacks to craft adversarial examples similar to the original samples but belong to other classes. With limited samples, the discriminative surrogate fails to accurately learn the target's decision boundaries, and these surrogate-based attacks suffer from low success rates. Different from the discriminative approach, we propose a generative surrogate that learns the distribution of samples residing on or close to the target's decision boundaries. The distribution learned by the generative surrogate can be used to craft adversarial examples that have imperceptible differences from the original samples but belong to other classes. The proposed generative approach results in attacks with remarkably high attack success rates on various targets and datasets. ",
    "url": "https://arxiv.org/abs/2402.02732",
    "authors": [
      "Raha Moraffah",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02738",
    "title": "Improving Robustness of LiDAR-Camera Fusion Model against Weather  Corruption from Fusion Strategy Perspective",
    "abstract": "In recent years, LiDAR-camera fusion models have markedly advanced 3D object detection tasks in autonomous driving. However, their robustness against common weather corruption such as fog, rain, snow, and sunlight in the intricate physical world remains underexplored. In this paper, we evaluate the robustness of fusion models from the perspective of fusion strategies on the corrupted dataset. Based on the evaluation, we further propose a concise yet practical fusion strategy to enhance the robustness of the fusion models, namely flexibly weighted fusing features from LiDAR and camera sources to adapt to varying weather scenarios. Experiments conducted on four types of fusion models, each with two distinct lightweight implementations, confirm the broad applicability and effectiveness of the approach. ",
    "url": "https://arxiv.org/abs/2402.02738",
    "authors": [
      "Yihao Huang",
      "Kaiyuan Yu",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Xiaojun Jia",
      "Tianlin Li",
      "Geguang Pu",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02739",
    "title": "DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models",
    "abstract": "In the exciting generative AI era, the diffusion model has emerged as a very powerful and widely adopted content generation and editing tool for various data modalities, making the study of their potential security risks very necessary and critical. Very recently, some pioneering works have shown the vulnerability of the diffusion model against backdoor attacks, calling for in-depth analysis and investigation of the security challenges of this popular and fundamental AI technique. In this paper, for the first time, we systematically explore the detectability of the poisoned noise input for the backdoored diffusion models, an important performance metric yet little explored in the existing works. Starting from the perspective of a defender, we first analyze the properties of the trigger pattern in the existing diffusion backdoor attacks, discovering the important role of distribution discrepancy in Trojan detection. Based on this finding, we propose a low-cost trigger detection mechanism that can effectively identify the poisoned input noise. We then take a further step to study the same problem from the attack side, proposing a backdoor attack strategy that can learn the unnoticeable trigger to evade our proposed detection scheme. Empirical evaluations across various diffusion models and datasets demonstrate the effectiveness of the proposed trigger detection and detection-evading attack strategy. For trigger detection, our distribution discrepancy-based solution can achieve a 100\\% detection rate for the Trojan triggers used in the existing works. For evading trigger detection, our proposed stealthy trigger design approach performs end-to-end learning to make the distribution of poisoned noise input approach that of benign noise, enabling nearly 100\\% detection pass rate with very high attack and benign performance for the backdoored diffusion models. ",
    "url": "https://arxiv.org/abs/2402.02739",
    "authors": [
      "Yang Sui",
      "Huy Phan",
      "Jinqi Xiao",
      "Tianfang Zhang",
      "Zijie Tang",
      "Cong Shi",
      "Yan Wang",
      "Yingying Chen",
      "Bo Yuan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02754",
    "title": "Focal Modulation Networks for Interpretable Sound Classification",
    "abstract": "The increasing success of deep neural networks has raised concerns about their inherent black-box nature, posing challenges related to interpretability and trust. While there has been extensive exploration of interpretation techniques in vision and language, interpretability in the audio domain has received limited attention, primarily focusing on post-hoc explanations. This paper addresses the problem of interpretability by-design in the audio domain by utilizing the recently proposed attention-free focal modulation networks (FocalNets). We apply FocalNets to the task of environmental sound classification for the first time and evaluate their interpretability properties on the popular ESC-50 dataset. Our method outperforms a similarly sized vision transformer both in terms of accuracy and interpretability. Furthermore, it is competitive against PIQ, a method specifically designed for post-hoc interpretation in the audio domain. ",
    "url": "https://arxiv.org/abs/2402.02754",
    "authors": [
      "Luca Della Libera",
      "Cem Subakan",
      "Mirco Ravanelli"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02761",
    "title": "Transmission Line Detection Based on Improved Hough Transform",
    "abstract": "To address the challenges of low detection accuracy and high false positive rates of transmission lines in UAV (Unmanned Aerial Vehicle) images, we explore the linear features and spatial distribution. We introduce an enhanced stochastic Hough transform technique tailored for detecting transmission lines in complex backgrounds. By employing the Hessian matrix for initial preprocessing of transmission lines, and utilizing boundary search and pixel row segmentation, our approach distinguishes transmission line areas from the background. We significantly reduce both false positives and missed detections, thereby improving the accuracy of transmission line identification. Experiments demonstrate that our method not only processes images more rapidly, but also yields superior detection results compared to conventional and random Hough transform methods. ",
    "url": "https://arxiv.org/abs/2402.02761",
    "authors": [
      "Wei Song",
      "Pei Li",
      "Man Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02771",
    "title": "TensoSDF: Roughness-aware Tensorial Representation for Robust Geometry  and Material Reconstruction",
    "abstract": "Reconstructing objects with realistic materials from multi-view images is problematic, since it is highly ill-posed. Although the neural reconstruction approaches have exhibited impressive reconstruction ability, they are designed for objects with specific materials (e.g., diffuse or specular materials). To this end, we propose a novel framework for robust geometry and material reconstruction, where the geometry is expressed with the implicit signed distance field (SDF) encoded by a tensorial representation, namely TensoSDF. At the core of our method is the roughness-aware incorporation of the radiance and reflectance fields, which enables a robust reconstruction of objects with arbitrary reflective materials. Furthermore, the tensorial representation enhances geometry details in the reconstructed surface and reduces the training time. Finally, we estimate the materials using an explicit mesh for efficient intersection computation and an implicit SDF for accurate representation. Consequently, our method can achieve more robust geometry reconstruction, outperform the previous works in terms of relighting quality, and reduce 50% training times and 70% inference time. ",
    "url": "https://arxiv.org/abs/2402.02771",
    "authors": [
      "Jia Li",
      "Lu Wang",
      "Lei Zhang",
      "Beibei Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2402.02781",
    "title": "Dual Knowledge Distillation for Efficient Sound Event Detection",
    "abstract": "Sound event detection (SED) is essential for recognizing specific sounds and their temporal locations within acoustic signals. This becomes challenging particularly for on-device applications, where computational resources are limited. To address this issue, we introduce a novel framework referred to as dual knowledge distillation for developing efficient SED systems in this work. Our proposed dual knowledge distillation commences with temporal-averaging knowledge distillation (TAKD), utilizing a mean student model derived from the temporal averaging of the student model's parameters. This allows the student model to indirectly learn from a pre-trained teacher model, ensuring a stable knowledge distillation. Subsequently, we introduce embedding-enhanced feature distillation (EEFD), which involves incorporating an embedding distillation layer within the student model to bolster contextual learning. On DCASE 2023 Task 4A public evaluation dataset, our proposed SED system with dual knowledge distillation having merely one-third of the baseline model's parameters, demonstrates superior performance in terms of PSDS1 and PSDS2. This highlights the importance of proposed dual knowledge distillation for compact SED systems, which can be ideal for edge devices. ",
    "url": "https://arxiv.org/abs/2402.02781",
    "authors": [
      "Yang Xiao",
      "Rohan Kumar Das"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02790",
    "title": "Stable and Robust Deep Learning By Hyperbolic Tangent Exponential Linear  Unit (TeLU)",
    "abstract": "In this paper, we introduce the Hyperbolic Tangent Exponential Linear Unit (TeLU), a novel neural network activation function, represented as $f(x) = x{\\cdot}tanh(e^x)$. TeLU is designed to overcome the limitations of conventional activation functions like ReLU, GELU, and Mish by addressing the vanishing and, to an extent, the exploding gradient problems. Our theoretical analysis and empirical assessments reveal that TeLU outperforms existing activation functions in stability and robustness, effectively adjusting activation outputs' mean towards zero for enhanced training stability and convergence. Extensive evaluations against popular activation functions (ReLU, GELU, SiLU, Mish, Logish, Smish) across advanced architectures, including Resnet-50, demonstrate TeLU's lower variance and superior performance, even under hyperparameter conditions optimized for other functions. In large-scale tests with challenging datasets like CIFAR-10, CIFAR-100, and TinyImageNet, encompassing 860 scenarios, TeLU consistently showcased its effectiveness, positioning itself as a potential new standard for neural network activation functions, boosting stability and performance in diverse deep learning applications. ",
    "url": "https://arxiv.org/abs/2402.02790",
    "authors": [
      "Alfredo Fernandez",
      "Ankur Mali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.02797",
    "title": "Joint Attention-Guided Feature Fusion Network for Saliency Detection of  Surface Defects",
    "abstract": "Surface defect inspection plays an important role in the process of industrial manufacture and production. Though Convolutional Neural Network (CNN) based defect inspection methods have made huge leaps, they still confront a lot of challenges such as defect scale variation, complex background, low contrast, and so on. To address these issues, we propose a joint attention-guided feature fusion network (JAFFNet) for saliency detection of surface defects based on the encoder-decoder network. JAFFNet mainly incorporates a joint attention-guided feature fusion (JAFF) module into decoding stages to adaptively fuse low-level and high-level features. The JAFF module learns to emphasize defect features and suppress background noise during feature fusion, which is beneficial for detecting low-contrast defects. In addition, JAFFNet introduces a dense receptive field (DRF) module following the encoder to capture features with rich context information, which helps detect defects of different scales. The JAFF module mainly utilizes a learned joint channel-spatial attention map provided by high-level semantic features to guide feature fusion. The attention map makes the model pay more attention to defect features. The DRF module utilizes a sequence of multi-receptive-field (MRF) units with each taking as inputs all the preceding MRF feature maps and the original input. The obtained DRF features capture rich context information with a large range of receptive fields. Extensive experiments conducted on SD-saliency-900, Magnetic tile, and DAGM 2007 indicate that our method achieves promising performance in comparison with other state-of-the-art methods. Meanwhile, our method reaches a real-time defect detection speed of 66 FPS. ",
    "url": "https://arxiv.org/abs/2402.02797",
    "authors": [
      "Xiaoheng Jiang",
      "Feng Yan",
      "Yang Lu",
      "Ke Wang",
      "Shuai Guo",
      "Tianzhu Zhang",
      "Yanwei Pang",
      "Jianwei Niu",
      "Mingliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02812",
    "title": "State estimation of urban air pollution with statistical, physical, and  super-learning graph models",
    "abstract": "We consider the problem of real-time reconstruction of urban air pollution maps. The task is challenging due to the heterogeneous sources of available data, the scarcity of direct measurements, the presence of noise, and the large surfaces that need to be considered. In this work, we introduce different reconstruction methods based on posing the problem on city graphs. Our strategies can be classified as fully data-driven, physics-driven, or hybrid, and we combine them with super-learning models. The performance of the methods is tested in the case of the inner city of Paris, France. ",
    "url": "https://arxiv.org/abs/2402.02812",
    "authors": [
      "Matthieu Dolbeault",
      "Olga Mula",
      "Agust\u00edn Somacal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2402.02823",
    "title": "Evading Data Contamination Detection for Language Models is (too) Easy",
    "abstract": "Large language models are widespread, with their performance on benchmarks frequently guiding user preferences for one model over another. However, the vast amount of data these models are trained on can inadvertently lead to contamination with public benchmarks, thus compromising performance measurements. While recently developed contamination detection methods try to address this issue, they overlook the possibility of deliberate contamination by malicious model providers aiming to evade detection. We argue that this setting is of crucial importance as it casts doubt on the reliability of public benchmarks. To more rigorously study this issue, we propose a categorization of both model providers and contamination detection methods. This reveals vulnerabilities in existing methods that we exploit with EAL, a simple yet effective contamination technique that significantly inflates benchmark performance while completely evading current detection methods. ",
    "url": "https://arxiv.org/abs/2402.02823",
    "authors": [
      "Jasper Dekoninck",
      "Mark Niklas M\u00fcller",
      "Maximilian Baader",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02827",
    "title": "PowerGraph: A power grid benchmark dataset for graph neural networks",
    "abstract": "Public Graph Neural Networks (GNN) benchmark datasets facilitate the use of GNN and enhance GNN applicability to diverse disciplines. The community currently lacks public datasets of electrical power grids for GNN applications. Indeed, GNNs can potentially capture complex power grid phenomena over alternative machine learning techniques. Power grids are complex engineered networks that are naturally amenable to graph representations. Therefore, GNN have the potential for capturing the behavior of power grids over alternative machine learning techniques. To this aim, we develop a graph dataset for cascading failure events, which are the major cause of blackouts in electric power grids. Historical blackout datasets are scarce and incomplete. The assessment of vulnerability and the identification of critical components are usually conducted via computationally expensive offline simulations of cascading failures. Instead, we propose using machine learning models for the online detection of cascading failures leveraging the knowledge of the system state at the onset of the cascade. We develop PowerGraph, a graph dataset modeling cascading failures in power grids, designed for two purposes, namely, i) training GNN models for different graph-level tasks including multi-class classification, binary classification, and regression, and ii) explaining GNN models. The dataset generated via a physics-based cascading failure model ensures the generality of the operating and environmental conditions by spanning diverse failure scenarios. In addition, we foster the use of the dataset to benchmark GNN explainability methods by assigning ground-truth edge-level explanations. PowerGraph helps the development of better GNN models for graph-level tasks and explainability, critical in many domains ranging from chemistry to biology, where the systems and processes can be described as graphs. ",
    "url": "https://arxiv.org/abs/2402.02827",
    "authors": [
      "Anna Varbella",
      "Kenza Amara",
      "Blazhe Gjorgiev",
      "Giovanni Sansavini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02833",
    "title": "Behavior Tree Capabilities for Dynamic Multi-Robot Task Allocation with  Heterogeneous Robot Teams",
    "abstract": "While individual robots are becoming increasingly capable, with new sensors and actuators, the complexity of expected missions increased exponentially in comparison. To cope with this complexity, heterogeneous teams of robots have become a significant research interest in recent years. Making effective use of the robots and their unique skills in a team is challenging. Dynamic runtime conditions often make static task allocations infeasible, therefore requiring a dynamic, capability-aware allocation of tasks to team members. To this end, we propose and implement a system that allows a user to specify missions using Bheavior Trees (BTs), which can then, at runtime, be dynamically allocated to the current robot team. The system allows to statically model an individual robot's capabilities within our ros_bt_py BT framework. It offers a runtime auction system to dynamically allocate tasks to the most capable robot in the current team. The system leverages utility values and pre-conditions to ensure that the allocation improves the overall mission execution quality while preventing faulty assignments. To evaluate the system, we simulated a find-and-decontaminate mission with a team of three heterogeneous robots and analyzed the utilization and overall mission times as metrics. Our results show that our system can improve the overall effectiveness of a team while allowing for intuitive mission specification and flexibility in the team composition. ",
    "url": "https://arxiv.org/abs/2402.02833",
    "authors": [
      "Georg Heppner",
      "David Oberacker",
      "Arne Roennau",
      "R\u00fcdiger Dillmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.02858",
    "title": "Deep autoregressive density nets vs neural ensembles for model-based  offline reinforcement learning",
    "abstract": "We consider the problem of offline reinforcement learning where only a set of system transitions is made available for policy optimization. Following recent advances in the field, we consider a model-based reinforcement learning algorithm that infers the system dynamics from the available data and performs policy optimization on imaginary model rollouts. This approach is vulnerable to exploiting model errors which can lead to catastrophic failures on the real system. The standard solution is to rely on ensembles for uncertainty heuristics and to avoid exploiting the model where it is too uncertain. We challenge the popular belief that we must resort to ensembles by showing that better performance can be obtained with a single well-calibrated autoregressive model on the D4RL benchmark. We also analyze static metrics of model-learning and conclude on the important model properties for the final performance of the agent. ",
    "url": "https://arxiv.org/abs/2402.02858",
    "authors": [
      "Abdelhakim Benechehab",
      "Albert Thomas",
      "Bal\u00e1zs K\u00e9gl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.02871",
    "title": "Code-Based Single-Server Private Information Retrieval: Circumventing  the Sub-Query Attack",
    "abstract": "Private information retrieval from a single server is considered, utilizing random linear codes. Presented is a modified version of the first code-based single-server computational PIR scheme proposed by Holzbaur, Hollanti, and Wachter-Zeh in [Holzbaur et al., \"Computational Code-Based Single-Server Private Information Retrieval\", 2020 IEEE ISIT]. The original scheme was broken in [Bordage et al., \"On the privacy of a code-based single-server computational PIR scheme\", Cryptogr. Comm., 2021] by an attack arising from highly probable rank differences in sub-matrices of the user's query. Here, this attack is now circumvented by ensuring that the sub-matrices have negligible rank difference. Furthermore, the rank difference cannot be attributed to the desired file index, thereby ensuring the privacy of the scheme. In the case of retrieving multiple files, the rate of the modified scheme is largely unaffected and at par with the original scheme. ",
    "url": "https://arxiv.org/abs/2402.02871",
    "authors": [
      "Neehar Verma",
      "Camilla Hollanti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.02886",
    "title": "Time-Distributed Backdoor Attacks on Federated Spiking Learning",
    "abstract": "This paper investigates the vulnerability of spiking neural networks (SNNs) and federated learning (FL) to backdoor attacks using neuromorphic data. Despite the efficiency of SNNs and the privacy advantages of FL, particularly in low-powered devices, we demonstrate that these systems are susceptible to such attacks. We first assess the viability of using FL with SNNs using neuromorphic data, showing its potential usage. Then, we evaluate the transferability of known FL attack methods to SNNs, finding that these lead to suboptimal attack performance. Therefore, we explore backdoor attacks involving single and multiple attackers to improve the attack performance. Our primary contribution is developing a novel attack strategy tailored to SNNs and FL, which distributes the backdoor trigger temporally and across malicious devices, enhancing the attack's effectiveness and stealthiness. In the best case, we achieve a 100 attack success rate, 0.13 MSE, and 98.9 SSIM. Moreover, we adapt and evaluate an existing defense against backdoor attacks, revealing its inadequacy in protecting SNNs. This study underscores the need for robust security measures in deploying SNNs and FL, particularly in the context of backdoor attacks. ",
    "url": "https://arxiv.org/abs/2402.02886",
    "authors": [
      "Gorka Abad",
      "Stjepan Picek",
      "Aitor Urbieta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.02889",
    "title": "Exploring Federated Self-Supervised Learning for General Purpose Audio  Understanding",
    "abstract": "The integration of Federated Learning (FL) and Self-supervised Learning (SSL) offers a unique and synergetic combination to exploit the audio data for general-purpose audio understanding, without compromising user data privacy. However, rare efforts have been made to investigate the SSL models in the FL regime for general-purpose audio understanding, especially when the training data is generated by large-scale heterogeneous audio sources. In this paper, we evaluate the performance of feature-matching and predictive audio-SSL techniques when integrated into large-scale FL settings simulated with non-independently identically distributed (non-iid) data. We propose a novel Federated SSL (F-SSL) framework, dubbed FASSL, that enables learning intermediate feature representations from large-scale decentralized heterogeneous clients, holding unlabelled audio data. Our study has found that audio F-SSL approaches perform on par with the centralized audio-SSL approaches on the audio-retrieval task. Extensive experiments demonstrate the effectiveness and significance of FASSL as it assists in obtaining the optimal global model for state-of-the-art FL aggregation methods. ",
    "url": "https://arxiv.org/abs/2402.02889",
    "authors": [
      "Yasar Abbas Ur Rehman",
      "Kin Wai Lau",
      "Yuyang Xie",
      "Lan Ma",
      "Jiajun Shen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02910",
    "title": "DS-MS-TCN: Otago Exercises Recognition with a Dual-Scale Multi-Stage  Temporal Convolutional Network",
    "abstract": "The Otago Exercise Program (OEP) represents a crucial rehabilitation initiative tailored for older adults, aimed at enhancing balance and strength. Despite previous efforts utilizing wearable sensors for OEP recognition, existing studies have exhibited limitations in terms of accuracy and robustness. This study addresses these limitations by employing a single waist-mounted Inertial Measurement Unit (IMU) to recognize OEP exercises among community-dwelling older adults in their daily lives. A cohort of 36 older adults participated in laboratory settings, supplemented by an additional 7 older adults recruited for at-home assessments. The study proposes a Dual-Scale Multi-Stage Temporal Convolutional Network (DS-MS-TCN) designed for two-level sequence-to-sequence classification, incorporating them in one loss function. In the first stage, the model focuses on recognizing each repetition of the exercises (micro labels). Subsequent stages extend the recognition to encompass the complete range of exercises (macro labels). The DS-MS-TCN model surpasses existing state-of-the-art deep learning models, achieving f1-scores exceeding 80% and Intersection over Union (IoU) f1-scores surpassing 60% for all four exercises evaluated. Notably, the model outperforms the prior study utilizing the sliding window technique, eliminating the need for post-processing stages and window size tuning. To our knowledge, we are the first to present a novel perspective on enhancing Human Activity Recognition (HAR) systems through the recognition of each repetition of activities. ",
    "url": "https://arxiv.org/abs/2402.02910",
    "authors": [
      "Meng Shang",
      "Lenore Dedeyne",
      "Jolan Dupont",
      "Laura Vercauteren",
      "Nadjia Amini",
      "Laurence Lapauw",
      "Evelien Gielen",
      "Sabine Verschueren",
      "Carolina Varon",
      "Walter De Raedt",
      "Bart Vanrumste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.02921",
    "title": "Mining a Minimal Set of Behavioral Patterns using Incremental Evaluation",
    "abstract": "Process mining provides methods to analyse event logs generated by information systems during the execution of processes. It thereby supports the design, validation, and execution of processes in domains ranging from healthcare, through manufacturing, to e-commerce. To explore the regularities of flexible processes that show a large behavioral variability, it was suggested to mine recurrent behavioral patterns that jointly describe the underlying process. Existing approaches to behavioral pattern mining, however, suffer from two limitations. First, they show limited scalability as incremental computation is incorporated only in the generation of pattern candidates, but not in the evaluation of their quality. Second, process analysis based on mined patterns shows limited effectiveness due to an overwhelmingly large number of patterns obtained in practical application scenarios, many of which are redundant. In this paper, we address these limitations to facilitate the analysis of complex, flexible processes based on behavioral patterns. Specifically, we improve COBPAM, our initial behavioral pattern mining algorithm, by an incremental procedure to evaluate the quality of pattern candidates, optimizing thereby its efficiency. Targeting a more effective use of the resulting patterns, we further propose pruning strategies for redundant patterns and show how relations between the remaining patterns are extracted and visualized to provide process insights. Our experiments with diverse real-world datasets indicate a considerable reduction of the runtime needed for pattern mining, while a qualitative assessment highlights how relations between patterns guide the analysis of the underlying process. ",
    "url": "https://arxiv.org/abs/2402.02921",
    "authors": [
      "Mehdi Acheli",
      "Daniela Grigori",
      "Matthias Weidlich"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02926",
    "title": "Automated Cognate Detection as a Supervised Link Prediction Task with  Cognate Transformer",
    "abstract": "Identification of cognates across related languages is one of the primary problems in historical linguistics. Automated cognate identification is helpful for several downstream tasks including identifying sound correspondences, proto-language reconstruction, phylogenetic classification, etc. Previous state-of-the-art methods for cognate identification are mostly based on distributions of phonemes computed across multilingual wordlists and make little use of the cognacy labels that define links among cognate clusters. In this paper, we present a transformer-based architecture inspired by computational biology for the task of automated cognate detection. Beyond a certain amount of supervision, this method performs better than the existing methods, and shows steady improvement with further increase in supervision, thereby proving the efficacy of utilizing the labeled information. We also demonstrate that accepting multiple sequence alignments as input and having an end-to-end architecture with link prediction head saves much computation time while simultaneously yielding superior performance. ",
    "url": "https://arxiv.org/abs/2402.02926",
    "authors": [
      "V.S.D.S.Mahesh Akavarapu",
      "Arnab Bhattacharya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02930",
    "title": "Embedding Hardware Approximations in Discrete Genetic-based Training for  Printed MLPs",
    "abstract": "Printed Electronics (PE) stands out as a promisingtechnology for widespread computing due to its distinct attributes, such as low costs and flexible manufacturing. Unlike traditional silicon-based technologies, PE enables stretchable, conformal,and non-toxic hardware. However, PE are constrained by larger feature sizes, making it challenging to implement complex circuits such as machine learning (ML) classifiers. Approximate computing has been proven to reduce the hardware cost of ML circuits such as Multilayer Perceptrons (MLPs). In this paper, we maximize the benefits of approximate computing by integrating hardware approximation into the MLP training process. Due to the discrete nature of hardware approximation, we propose and implement a genetic-based, approximate, hardware-aware training approach specifically designed for printed MLPs. For a 5% accuracy loss, our MLPs achieve over 5x area and power reduction compared to the baseline while outperforming state of-the-art approximate and stochastic printed MLPs. ",
    "url": "https://arxiv.org/abs/2402.02930",
    "authors": [
      "Florentia Afentaki",
      "Michael Hefenbrock",
      "Georgios Zervakis",
      "Mehdi B. Tahoori"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02933",
    "title": "InterpretCC: Conditional Computation for Inherently Interpretable Neural  Networks",
    "abstract": "Real-world interpretability for neural networks is a tradeoff between three concerns: 1) it requires humans to trust the explanation approximation (e.g. post-hoc approaches), 2) it compromises the understandability of the explanation (e.g. automatically identified feature masks), and 3) it compromises the model performance (e.g. decision trees). These shortcomings are unacceptable for human-facing domains, like education, healthcare, or natural language, which require trustworthy explanations, actionable interpretations, and accurate predictions. In this work, we present InterpretCC (interpretable conditional computation), a family of interpretable-by-design neural networks that guarantee human-centric interpretability while maintaining comparable performance to state-of-the-art models by adaptively and sparsely activating features before prediction. We extend this idea into an interpretable mixture-of-experts model, that allows humans to specify topics of interest, discretely separates the feature space for each data point into topical subnetworks, and adaptively and sparsely activates these topical subnetworks. We demonstrate variations of the InterpretCC architecture for text and tabular data across several real-world benchmarks: six online education courses, news classification, breast cancer diagnosis, and review sentiment. ",
    "url": "https://arxiv.org/abs/2402.02933",
    "authors": [
      "Vinitra Swamy",
      "Julian Blackwell",
      "Jibril Frej",
      "Martin Jaggi",
      "Tanja K\u00e4ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.02946",
    "title": "HoughToRadon Transform: New Neural Network Layer for Features  Improvement in Projection Space",
    "abstract": "In this paper, we introduce HoughToRadon Transform layer, a novel layer designed to improve the speed of neural networks incorporated with Hough Transform to solve semantic image segmentation problems. By placing it after a Hough Transform layer, \"inner\" convolutions receive modified feature maps with new beneficial properties, such as a smaller area of processed images and parameter space linearity by angle and shift. These properties were not presented in Hough Transform alone. Furthermore, HoughToRadon Transform layer allows us to adjust the size of intermediate feature maps using two new parameters, thus allowing us to balance the speed and quality of the resulting neural network. Our experiments on the open MIDV-500 dataset show that this new approach leads to time savings in document segmentation tasks and achieves state-of-the-art 97.7% accuracy, outperforming HoughEncoder with larger computational complexity. ",
    "url": "https://arxiv.org/abs/2402.02946",
    "authors": [
      "Alexandra Zhabitskaya",
      "Alexander Sheshkus",
      "Vladimir L. Arlazarov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.02949",
    "title": "Kernel PCA for Out-of-Distribution Detection",
    "abstract": "Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper nonlinear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, seeking subspaces where OoD and InD features are allocated with significantly different patterns. We devise two feature mappings that induce non-linear kernels in KPCA to advocate the separability between InD and OoD data in the subspace spanned by the principal components. Given any test sample, the reconstruction error in such subspace is then used to efficiently obtain the detection result with $\\mathcal{O}(1)$ time complexity in inference. Extensive empirical results on multiple OoD data sets and network structures verify the superiority of our KPCA-based detector in efficiency and efficacy with state-of-the-art OoD detection performances. ",
    "url": "https://arxiv.org/abs/2402.02949",
    "authors": [
      "Kun Fang",
      "Qinghua Tao",
      "Kexin Lv",
      "Mingzhen He",
      "Xiaolin Huang",
      "Jie Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02953",
    "title": "Unraveling the Key of Machine Learning Solutions for Android Malware  Detection",
    "abstract": "Android malware detection serves as the front line against malicious apps. With the rapid advancement of machine learning (ML), ML-based Android malware detection has attracted increasing attention due to its capability of automatically capturing malicious patterns from Android APKs. These learning-driven methods have reported promising results in detecting malware. However, the absence of an in-depth analysis of current research progress makes it difficult to gain a holistic picture of the state of the art in this area. This paper presents a comprehensive investigation to date into ML-based Android malware detection with empirical and quantitative analysis. We first survey the literature, categorizing contributions into a taxonomy based on the Android feature engineering and ML modeling pipeline. Then, we design a general-propose framework for ML-based Android malware detection, re-implement 12 representative approaches from different research communities, and evaluate them from three primary dimensions, i.e., effectiveness, robustness, and efficiency. The evaluation reveals that ML-based approaches still face open challenges and provides insightful findings like more powerful ML models are not the silver bullet for designing better malware detectors. We further summarize our findings and put forth recommendations to guide future research. ",
    "url": "https://arxiv.org/abs/2402.02953",
    "authors": [
      "Jiahao Liu",
      "Jun Zeng",
      "Fabio Pierazzi",
      "Lorenzo Cavallaro",
      "Zhenkai Liang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02982",
    "title": "Algorithms for Computing the Free Distance of Convolutional Codes",
    "abstract": "The free distance of a convolutional code is a reliable indicator of its performance. However its computation is not an easy task. In this paper, we present some algorithms to compute the free distance with good efficiency that work for convolutional codes of all rates and over any field. Furthermore we discuss why an algorithm which is claimed to be very efficient is incorrect. ",
    "url": "https://arxiv.org/abs/2402.02982",
    "authors": [
      "Zita Abreu",
      "Joachim Rosenthal",
      "Michael Schaller"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.02986",
    "title": "A Safety-Adapted Loss for Pedestrian Detection in Automated Driving",
    "abstract": "In safety-critical domains like automated driving (AD), errors by the object detector may endanger pedestrians and other vulnerable road users (VRU). As common evaluation metrics are not an adequate safety indicator, recent works employ approaches to identify safety-critical VRU and back-annotate the risk to the object detector. However, those approaches do not consider the safety factor in the deep neural network (DNN) training process. Thus, state-of-the-art DNN penalizes all misdetections equally irrespective of their criticality. Subsequently, to mitigate the occurrence of critical failure cases, i.e., false negatives, a safety-aware training strategy might be required to enhance the detection performance for critical pedestrians. In this paper, we propose a novel safety-aware loss variation that leverages the estimated per-pedestrian criticality scores during training. We exploit the reachability set-based time-to-collision (TTC-RSB) metric from the motion domain along with distance information to account for the worst-case threat quantifying the criticality. Our evaluation results using RetinaNet and FCOS on the nuScenes dataset demonstrate that training the models with our safety-aware loss function mitigates the misdetection of critical pedestrians without sacrificing performance for the general case, i.e., pedestrians outside the safety-critical zone. ",
    "url": "https://arxiv.org/abs/2402.02986",
    "authors": [
      "Maria Lyssenko",
      "Piyush Pimplikar",
      "Maarten Bieshaar",
      "Farzad Nozarian",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.02987",
    "title": "Conversation Reconstruction Attack Against GPT Models",
    "abstract": "In recent times, significant advancements have been made in the field of large language models (LLMs), represented by GPT series models. To optimize task execution, users often engage in multi-round conversations with GPT models hosted in cloud environments. These multi-round conversations, potentially replete with private information, require transmission and storage within the cloud. However, this operational paradigm introduces additional attack surfaces. In this paper, we first introduce a specific Conversation Reconstruction Attack targeting GPT models. Our introduced Conversation Reconstruction Attack is composed of two steps: hijacking a session and reconstructing the conversations. Subsequently, we offer an exhaustive evaluation of the privacy risks inherent in conversations when GPT models are subjected to the proposed attack. However, GPT-4 demonstrates certain robustness to the proposed attacks. We then introduce two advanced attacks aimed at better reconstructing previous conversations, specifically the UNR attack and the PBU attack. Our experimental findings indicate that the PBU attack yields substantial performance across all models, achieving semantic similarity scores exceeding 0.60, while the UNR attack is effective solely on GPT-3.5. Our results reveal the concern about privacy risks associated with conversations involving GPT models and aim to draw the community's attention to prevent the potential misuse of these models' remarkable capabilities. We will responsibly disclose our findings to the suppliers of related large language models. ",
    "url": "https://arxiv.org/abs/2402.02987",
    "authors": [
      "Junjie Chu",
      "Zeyang Sha",
      "Michael Backes",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.03028",
    "title": "Functional SDE approximation inspired by a deep operator network  architecture",
    "abstract": "A novel approach to approximate solutions of Stochastic Differential Equations (SDEs) by Deep Neural Networks is derived and analysed. The architecture is inspired by the notion of Deep Operator Networks (DeepONets), which is based on operator learning in function spaces in terms of a reduced basis also represented in the network. In our setting, we make use of a polynomial chaos expansion (PCE) of stochastic processes and call the corresponding architecture SDEONet. The PCE has been used extensively in the area of uncertainty quantification (UQ) with parametric partial differential equations. This however is not the case with SDE, where classical sampling methods dominate and functional approaches are seen rarely. A main challenge with truncated PCEs occurs due to the drastic growth of the number of components with respect to the maximum polynomial degree and the number of basis elements. The proposed SDEONet architecture aims to alleviate the issue of exponential complexity by learning an optimal sparse truncation of the Wiener chaos expansion. A complete convergence and complexity analysis is presented, making use of recent Neural Network approximation results. Numerical experiments illustrate the promising performance of the suggested approach in 1D and higher dimensions. ",
    "url": "https://arxiv.org/abs/2402.03028",
    "authors": [
      "Martin Eigel",
      "Charles Miranda"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03063",
    "title": "Independent set reconfiguration in H-free graphs",
    "abstract": "Given a graph $G$ and two independent sets of $G$, the independent set reconfiguration problem asks whether one independent set can be transformed into the other by moving a single vertex at a time, such that at each intermediate step we have an independent set of $G$. We study the complexity of this problem for $H$-free graphs under the token sliding and token jumping rule. Our contribution is twofold. First, we prove a reconfiguration analogue of Alekseev's theorem, showing that the problem is PSPACE-complete unless $H$ is a path or a subdivision of the claw. We then show that under the token sliding rule, the problem admits a polynomial-time algorithm if the input graph is fork-free. ",
    "url": "https://arxiv.org/abs/2402.03063",
    "authors": [
      "Valentin Bartier",
      "Nicolas Bousquet",
      "Moritz M\u00fchlenthaler"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.03068",
    "title": "A Note on Rounding Matchings in General Graphs",
    "abstract": "In this note, we revisit the rounding algorithm of Wajc. Wajc gave a fully-adaptive randomized algorithm that rounds a dynamic fractional matching in an unweighted bipartite graph to an integral matching of nearly the same value in $O(\\text{poly}(\\log n,\\frac{1}{\\varepsilon}))$ update time. We give show that the guarantees of this algorithm hold for general graphs as well. Additionally, we show useful properties of this subroutine which have applications in rounding weighted fractional matchings. ",
    "url": "https://arxiv.org/abs/2402.03068",
    "authors": [
      "Aditi Dudeja"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.03087",
    "title": "XNLP-hardness of Parameterized Problems on Planar Graphs",
    "abstract": "The class XNLP consists of (parameterized) problems that can be solved nondeterministically in $f(k)n^{O(1)}$ time and $f(k)\\log n$ space, where $n$ is the size of the input instance and $k$ the parameter. The class XALP consists of problems that can be solved in the above time and space with access to an additional stack. These two classes are a \"natural home\" for many standard graph problems and their generalizations. In this paper, we show the hardness of several problems on planar graphs, parameterized by outerplanarity, treewidth and pathwidth, thus strengthening several existing results. In particular, we show the XNLP-hardness of the following problems parameterized by outerplanarity: All-or-Nothing Flow, Target Outdegree Orientation, Capacitated (Red-Blue) Dominating Set, Target Set Selections etc. We also show the XNLP-completeness of Scattered Set parameterized by pathwidth and XALP-completeness parameterized by treewidth and outerplanarity. ",
    "url": "https://arxiv.org/abs/2402.03087",
    "authors": [
      "Hans L. Bodlaender",
      "Krisztina Szil\u00e1gyi"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2402.03092",
    "title": "Asynchronous dynamics of isomorphic Boolean networks",
    "abstract": "A Boolean network is a function $f:\\{0,1\\}^n\\to\\{0,1\\}^n$ from which several dynamics can be derived, depending on the context. The most classical ones are the synchronous and asynchronous dynamics. Both are digraphs on $\\{0,1\\}^n$, but the synchronous dynamics (which is identified with $f$) has an arc from $x$ to $f(x)$ while the asynchronous dynamics $\\mathcal{A}(f)$ has an arc from $x$ to $x+e_i$ whenever $x_i\\neq f_i(x)$. Clearly, $f$ and $\\mathcal{A}(f)$ share the same information, but what can be said on these objects up to isomorphism? We prove that if $\\mathcal{A}(f)$ is only known up to isomorphism then, with high probability, $f$ can be fully reconstructed up to isomorphism. We then show that the converse direction is far from being true. In particular, if $f$ is only known up to isomorphism, very little can be said on the attractors of $\\mathcal{A}(f)$. For instance, if $f$ has $p$ fixed points, then $\\mathcal{A}(f)$ has at least $\\max(1,p)$ attractors, and we prove that this trivial lower bound is tight: there always exists $h\\sim f$ such that $\\mathcal{A}(h)$ has exactly $\\max(1,p)$ attractors. But $\\mathcal{A}(f)$ may often have much more attractors since we prove that, with high probability, there exists $h\\sim f$ such that $\\mathcal{A}(h)$ has $\\Omega(2^n)$ attractors. ",
    "url": "https://arxiv.org/abs/2402.03092",
    "authors": [
      "Florian Bridoux",
      "Aymeric Picard Marchetto",
      "Adrien Richard"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.03094",
    "title": "Cross-Domain Few-Shot Object Detection via Enhanced Open-Set Object  Detector",
    "abstract": "This paper addresses the challenge of cross-domain few-shot object detection (CD-FSOD), aiming to develop an accurate object detector for novel domains with minimal labeled examples. While transformer-based open-set detectors e.g., DE-ViT~\\cite{zhang2023detect} have excelled in both open-vocabulary object detection and traditional few-shot object detection, detecting categories beyond those seen during training, we thus naturally raise two key questions: 1) can such open-set detection methods easily generalize to CD-FSOD? 2) If no, how to enhance the results of open-set methods when faced with significant domain gaps? To address the first question, we introduce several metrics to quantify domain variances and establish a new CD-FSOD benchmark with diverse domain metric values. Some State-Of-The-Art (SOTA) open-set object detection methods are evaluated on this benchmark, with evident performance degradation observed across out-of-domain datasets. This indicates the failure of adopting open-set detectors directly for CD-FSOD. Sequentially, to overcome the performance degradation issue and also to answer the second proposed question, we endeavor to enhance the vanilla DE-ViT. With several novel components including finetuning, a learnable prototype module, and a lightweight attention module, we present an improved Cross-Domain Vision Transformer for CD-FSOD (CD-ViTO). Experiments show that our CD-ViTO achieves impressive results on both out-of-domain and in-domain target datasets, establishing new SOTAs for both CD-FSOD and FSOD. All the datasets, codes, and models will be released to the community. ",
    "url": "https://arxiv.org/abs/2402.03094",
    "authors": [
      "Yuqian Fu",
      "Yu Wang",
      "Yixuan Pan",
      "Lian Huai",
      "Xingyu Qiu",
      "Zeyu Shangguan",
      "Tong Liu",
      "Lingjie Kong",
      "Yanwei Fu",
      "Luc Van Gool",
      "Xingqun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03095",
    "title": "Transcending Adversarial Perturbations: Manifold-Aided Adversarial  Examples with Legitimate Semantics",
    "abstract": "Deep neural networks were significantly vulnerable to adversarial examples manipulated by malicious tiny perturbations. Although most conventional adversarial attacks ensured the visual imperceptibility between adversarial examples and corresponding raw images by minimizing their geometric distance, these constraints on geometric distance led to limited attack transferability, inferior visual quality, and human-imperceptible interpretability. In this paper, we proposed a supervised semantic-transformation generative model to generate adversarial examples with real and legitimate semantics, wherein an unrestricted adversarial manifold containing continuous semantic variations was constructed for the first time to realize a legitimate transition from non-adversarial examples to adversarial ones. Comprehensive experiments on MNIST and industrial defect datasets showed that our adversarial examples not only exhibited better visual quality but also achieved superior attack transferability and more effective explanations for model vulnerabilities, indicating their great potential as generic adversarial examples. The code and pre-trained models were available at https://github.com/shuaili1027/MAELS.git. ",
    "url": "https://arxiv.org/abs/2402.03095",
    "authors": [
      "Shuai Li",
      "Xiaoyu Jiang",
      "Xiaoguang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03112",
    "title": "Infrared Spectra Prediction for Diazo Groups Utilizing a Machine  Learning Approach with Structural Attention Mechanism",
    "abstract": "Infrared (IR) spectroscopy is a pivotal technique in chemical research for elucidating molecular structures and dynamics through vibrational and rotational transitions. However, the intricate molecular fingerprints characterized by unique vibrational and rotational patterns present substantial analytical challenges. Here, we present a machine learning approach employing a Structural Attention Mechanism tailored to enhance the prediction and interpretation of infrared spectra, particularly for diazo compounds. Our model distinguishes itself by honing in on chemical information proximal to functional groups, thereby significantly bolstering the accuracy, robustness, and interpretability of spectral predictions. This method not only demystifies the correlations between infrared spectral features and molecular structures but also offers a scalable and efficient paradigm for dissecting complex molecular interactions. ",
    "url": "https://arxiv.org/abs/2402.03112",
    "authors": [
      "Chengchun Liu",
      "Fanyang Mo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2402.03114",
    "title": "Augmenting Security and Privacy in the Virtual Realm: An Analysis of  Extended Reality Devices",
    "abstract": "In this work, we present a device-centric analysis of security and privacy attacks and defenses on Extended Reality (XR) devices, highlighting the need for robust and privacy-aware security mechanisms. Based on our analysis, we present future research directions and propose design considerations to help ensure the security and privacy of XR devices. ",
    "url": "https://arxiv.org/abs/2402.03114",
    "authors": [
      "Derin Cayir",
      "Abbas Acar",
      "Riccardo Lazzeretti",
      "Marco Angelini",
      "Mauro Conti",
      "Selcuk Uluagac"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.03124",
    "title": "Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks",
    "abstract": "Gradient inversion attacks aim to reconstruct local training data from intermediate gradients exposed in the federated learning framework. Despite successful attacks, all previous methods, starting from reconstructing a single data point and then relaxing the single-image limit to batch level, are only tested under hard label constraints. Even for single-image reconstruction, we still lack an analysis-based algorithm to recover augmented soft labels. In this work, we change the focus from enlarging batchsize to investigating the hard label constraints, considering a more realistic circumstance where label smoothing and mixup techniques are used in the training process. In particular, we are the first to initiate a novel algorithm to simultaneously recover the ground-truth augmented label and the input feature of the last fully-connected layer from single-input gradients, and provide a necessary condition for any analytical-based label recovery methods. Extensive experiments testify to the label recovery accuracy, as well as the benefits to the following image reconstruction. We believe soft labels in classification tasks are worth further attention in gradient inversion attacks. ",
    "url": "https://arxiv.org/abs/2402.03124",
    "authors": [
      "Yanbo Wang",
      "Jian Liang",
      "Ran He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03130",
    "title": "User-Centric Evaluation of ChatGPT Capability of Generating R Program  Code",
    "abstract": "This paper reports an evaluation of ChatGPT's capability of generating R programming language code from natural language input. A dataset specially designed for generating R program code was constructed with metadata to support scenario-based testing and evaluation of code generation capabilities in various usage scenarios of different levels of difficulty and different types of programs. The evaluation takes a multiple attempt process in which the tester tries to complete the code generation task through a number of attempts until a satisfactory solution is obtained or gives up after a fixed number of maximal attempts. In each attempt the tester formulates a natural language input to ChatGPT based on the previous results and the task to be completed. In addition to the metrics of average numbers of attempts and average amount of time taken to complete the tasks, the final generated solutions are then assessed on a number of quality attributes, including accuracy, completeness, conciseness, readability, well structuredness, logic clarity, depth of ex-planation, and coverage of parameters. Our experiments demonstrated that ChatGPT is in general highly capable of generating high quality R program code as well as textual explanations although it may fail on hard programming tasks. The experiment data also shows that human developers can hardly learn from experiences naturally to improve the skill of using ChatGPT to generate code. ",
    "url": "https://arxiv.org/abs/2402.03130",
    "authors": [
      "Tanha Miah",
      "Hong Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.03139",
    "title": "Enhancing Neural Subset Selection: Integrating Background Information  into Set Representations",
    "abstract": "Learning neural subset selection tasks, such as compound selection in AI-aided drug discovery, have become increasingly pivotal across diverse applications. The existing methodologies in the field primarily concentrate on constructing models that capture the relationship between utility function values and subsets within their respective supersets. However, these approaches tend to overlook the valuable information contained within the superset when utilizing neural networks to model set functions. In this work, we address this oversight by adopting a probabilistic perspective. Our theoretical findings demonstrate that when the target value is conditioned on both the input set and subset, it is essential to incorporate an \\textit{invariant sufficient statistic} of the superset into the subset of interest for effective learning. This ensures that the output value remains invariant to permutations of the subset and its corresponding superset, enabling identification of the specific superset from which the subset originated. Motivated by these insights, we propose a simple yet effective information aggregation module designed to merge the representations of subsets and supersets from a permutation invariance perspective. Comprehensive empirical evaluations across diverse tasks and datasets validate the enhanced efficacy of our approach over conventional methods, underscoring the practicality and potency of our proposed strategies in real-world contexts. ",
    "url": "https://arxiv.org/abs/2402.03139",
    "authors": [
      "Binghui Xie",
      "Yatao Bian",
      "Kaiwen zhou",
      "Yongqiang Chen",
      "Peilin Zhao",
      "Bo Han",
      "Wei Meng",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03146",
    "title": "A Multi-step Loss Function for Robust Learning of the Dynamics in  Model-based Reinforcement Learning",
    "abstract": "In model-based reinforcement learning, most algorithms rely on simulating trajectories from one-step models of the dynamics learned on data. A critical challenge of this approach is the compounding of one-step prediction errors as the length of the trajectory grows. In this paper we tackle this issue by using a multi-step objective to train one-step models. Our objective is a weighted sum of the mean squared error (MSE) loss at various future horizons. We find that this new loss is particularly useful when the data is noisy (additive Gaussian noise in the observations), which is often the case in real-life environments. To support the multi-step loss, first we study its properties in two tractable cases: i) uni-dimensional linear system, and ii) two-parameter non-linear system. Second, we show in a variety of tasks (environments or datasets) that the models learned with this loss achieve a significant improvement in terms of the averaged R2-score on future prediction horizons. Finally, in the pure batch reinforcement learning setting, we demonstrate that one-step models serve as strong baselines when dynamics are deterministic, while multi-step models would be more advantageous in the presence of noise, highlighting the potential of our approach in real-world applications. ",
    "url": "https://arxiv.org/abs/2402.03146",
    "authors": [
      "Abdelhakim Benechehab",
      "Albert Thomas",
      "Giuseppe Paolo",
      "Maurizio Filippone",
      "Bal\u00e1zs K\u00e9gl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.03153",
    "title": "Learning solutions of parametric Navier-Stokes with physics-informed  neural networks",
    "abstract": "We leverage Physics-Informed Neural Networks (PINNs) to learn solution functions of parametric Navier-Stokes Equations (NSE). Our proposed approach results in a feasible optimization problem setup that bypasses PINNs' limitations in converging to solutions of highly nonlinear parametric-PDEs like NSE. We consider the parameter(s) of interest as inputs of PINNs along with spatio-temporal coordinates, and train PINNs on generated numerical solutions of parametric-PDES for instances of the parameters. We perform experiments on the classical 2D flow past cylinder problem aiming to learn velocities and pressure functions over a range of Reynolds numbers as parameter of interest. Provision of training data from generated numerical simulations allows for interpolation of the solution functions for a range of parameters. Therefore, we compare PINNs with unconstrained conventional Neural Networks (NN) on this problem setup to investigate the effectiveness of considering the PDEs regularization in the loss function. We show that our proposed approach results in optimizing PINN models that learn the solution functions while making sure that flow predictions are in line with conservational laws of mass and momentum. Our results show that PINN results in accurate prediction of gradients compared to NN model, this is clearly visible in predicted vorticity fields given that none of these models were trained on vorticity labels. ",
    "url": "https://arxiv.org/abs/2402.03153",
    "authors": [
      "M.Naderibeni",
      "M. J.T. Reinders",
      "L. Wu",
      "D. M.J. Tax"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03163",
    "title": "Linguistic features for sentence difficulty prediction in ABSA",
    "abstract": "One of the challenges of natural language understanding is to deal with the subjectivity of sentences, which may express opinions and emotions that add layers of complexity and nuance. Sentiment analysis is a field that aims to extract and analyze these subjective elements from text, and it can be applied at different levels of granularity, such as document, paragraph, sentence, or aspect. Aspect-based sentiment analysis is a well-studied topic with many available data sets and models. However, there is no clear definition of what makes a sentence difficult for aspect-based sentiment analysis. In this paper, we explore this question by conducting an experiment with three data sets: \"Laptops\", \"Restaurants\", and \"MTSC\" (Multi-Target-dependent Sentiment Classification), and a merged version of these three datasets. We study the impact of domain diversity and syntactic diversity on difficulty. We use a combination of classifiers to identify the most difficult sentences and analyze their characteristics. We employ two ways of defining sentence difficulty. The first one is binary and labels a sentence as difficult if the classifiers fail to correctly predict the sentiment polarity. The second one is a six-level scale based on how many of the top five best-performing classifiers can correctly predict the sentiment polarity. We also define 9 linguistic features that, combined, aim at estimating the difficulty at sentence level. ",
    "url": "https://arxiv.org/abs/2402.03163",
    "authors": [
      "Adrian-Gabriel Chifu",
      "S\u00e9bastien Fournier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.03166",
    "title": "RRWNet: Recursive Refinement Network for Effective Retinal Artery/Vein  Segmentation and Classification",
    "abstract": "The caliber and configuration of retinal blood vessels serve as important biomarkers for various diseases and medical conditions. A thorough analysis of the retinal vasculature requires the segmentation of blood vessels and their classification into arteries and veins, which is typically performed on color fundus images obtained by retinography, a widely used imaging technique. Nonetheless, manually performing these tasks is labor-intensive and prone to human error. Various automated methods have been proposed to address this problem. However, the current state of art in artery/vein segmentation and classification faces challenges due to manifest classification errors that affect the topological consistency of segmentation maps. This study presents an innovative end-to-end framework, RRWNet, designed to recursively refine semantic segmentation maps and correct manifest classification errors. The framework consists of a fully convolutional neural network with a Base subnetwork that generates base segmentation maps from input images, and a Recursive Refinement subnetwork that iteratively and recursively improves these maps. Evaluation on public datasets demonstrates the state-of-the-art performance of the proposed method, yielding more topologically consistent segmentation maps with fewer manifest classification errors than existing approaches. In addition, the Recursive Refinement module proves effective in post-processing segmentation maps from other methods, automatically correcting classification errors and improving topological consistency. The model code, weights, and predictions are publicly available at https://github.com/j-morano/rrwnet. ",
    "url": "https://arxiv.org/abs/2402.03166",
    "authors": [
      "Jos\u00e9 Morano",
      "Guilherme Aresta",
      "Hrvoje Bogunovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.03171",
    "title": "Homograph Attacks on Maghreb Sentiment Analyzers",
    "abstract": "We examine the impact of homograph attacks on the Sentiment Analysis (SA) task of different Arabic dialects from the Maghreb North-African countries. Homograph attacks result in a 65.3% decrease in transformer classification from an F1-score of 0.95 to 0.33 when data is written in \"Arabizi\". The goal of this study is to highlight LLMs weaknesses' and to prioritize ethical and responsible Machine Learning. ",
    "url": "https://arxiv.org/abs/2402.03171",
    "authors": [
      "Fatima Zahra Qachfar",
      "Rakesh M. Verma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03172",
    "title": "Accurate and Well-Calibrated ICD Code Assignment Through Attention Over  Diverse Label Embeddings",
    "abstract": "Although the International Classification of Diseases (ICD) has been adopted worldwide, manually assigning ICD codes to clinical text is time-consuming, error-prone, and expensive, motivating the development of automated approaches. This paper describes a novel approach for automated ICD coding, combining several ideas from previous related work. We specifically employ a strong Transformer-based model as a text encoder and, to handle lengthy clinical narratives, we explored either (a) adapting the base encoder model into a Longformer, or (b) dividing the text into chunks and processing each chunk independently. The representations produced by the encoder are combined with a label embedding mechanism that explores diverse ICD code synonyms. Experiments with different splits of the MIMIC-III dataset show that the proposed approach outperforms the current state-of-the-art models in ICD coding, with the label embeddings significantly contributing to the good performance. Our approach also leads to properly calibrated classification results, which can effectively inform downstream tasks such as quantification. ",
    "url": "https://arxiv.org/abs/2402.03172",
    "authors": [
      "Gon\u00e7alo Gomes",
      "Isabel Coutinho",
      "Bruno Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.03190",
    "title": "Unified Hallucination Detection for Multimodal Large Language Models",
    "abstract": "Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical application deployment. Prior research in this domain has been constrained by a narrow focus on singular tasks, an inadequate range of hallucination categories addressed, and a lack of detailed granularity. In response to these challenges, our work expands the investigative horizons of hallucination detection. We present a novel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate the evaluation of advancements in hallucination detection methods. Additionally, we unveil a novel unified multimodal hallucination detection framework, UNIHD, which leverages a suite of auxiliary tools to validate the occurrence of hallucinations robustly. We demonstrate the effectiveness of UNIHD through meticulous evaluation and comprehensive analysis. We also provide strategic insights on the application of specific tools for addressing various categories of hallucinations. ",
    "url": "https://arxiv.org/abs/2402.03190",
    "authors": [
      "Xiang Chen",
      "Chenxi Wang",
      "Yida Xue",
      "Ningyu Zhang",
      "Xiaoyan Yang",
      "Qiang Li",
      "Yue Shen",
      "Jinjie Gu",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.03196",
    "title": "Lightweight Masking Against Static Power Side-Channel Attacks",
    "abstract": "This paper presents a novel defense strategy against static power side-channel attacks (PSCAs), a critical threat to cryptographic security. Our method is based on (1) carefully tuning high-Vth versus low-Vth cell selection during synthesis, accounting for both security and timing impact, and (2), at runtime, randomly switching the operation between these cells. This approach serves to significantly obscure static power patterns, which are at the heart of static PSCAs. Our experimental results on a commercial 28nm node show a drastic increase in the effort required for a successful attack, namely up to 96 times more traces. When compared to prior countermeasures, ours incurs little cost, making it a lightweight defense. ",
    "url": "https://arxiv.org/abs/2402.03196",
    "authors": [
      "Jitendra Bhandari",
      "Mohammed Nabeel",
      "Likhitha Mankali",
      "Ozgur Sinanoglu",
      "Ramesh Karri",
      "Johann Knechtel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.03199",
    "title": "SOAP: A Social Authentication Protocol",
    "abstract": "Social authentication has been suggested as a usable authentication ceremony to replace manual key authentication in messaging applications. Using social authentication, chat partners authenticate their peers using digital identities managed by identity providers. In this paper, we formally define social authentication, present a protocol called SOAP that largely automates social authentication, formally prove SOAP's security, and demonstrate SOAP's practicality in two prototypes. One prototype is web-based, and the other is implemented in the open-source Signal messaging application. Using SOAP, users can significantly raise the bar for compromising their messaging accounts. In contrast to the default security provided by messaging applications such as Signal and WhatsApp, attackers must compromise both the messaging account and all identity provider-managed identities to attack a victim. In addition to its security and automation, SOAP is straightforward to adopt as it is built on top of the well-established OpenID Connect protocol. ",
    "url": "https://arxiv.org/abs/2402.03199",
    "authors": [
      "Felix Linker",
      "David Basin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.03235",
    "title": "ActiveAnno3D -- An Active Learning Framework for Multi-Modal 3D Object  Detection",
    "abstract": "The curation of large-scale datasets is still costly and requires much time and resources. Data is often manually labeled, and the challenge of creating high-quality datasets remains. In this work, we fill the research gap using active learning for multi-modal 3D object detection. We propose ActiveAnno3D, an active learning framework to select data samples for labeling that are of maximum informativeness for training. We explore various continuous training methods and integrate the most efficient method regarding computational demand and detection performance. Furthermore, we perform extensive experiments and ablation studies with BEVFusion and PV-RCNN on the nuScenes and TUM Traffic Intersection dataset. We show that we can achieve almost the same performance with PV-RCNN and the entropy-based query strategy when using only half of the training data (77.25 mAP compared to 83.50 mAP) of the TUM Traffic Intersection dataset. BEVFusion achieved an mAP of 64.31 when using half of the training data and 75.0 mAP when using the complete nuScenes dataset. We integrate our active learning framework into the proAnno labeling tool to enable AI-assisted data selection and labeling and minimize the labeling costs. Finally, we provide code, weights, and visualization results on our website: https://active3d-framework.github.io/active3d-framework. ",
    "url": "https://arxiv.org/abs/2402.03235",
    "authors": [
      "Ahmed Ghita",
      "Bj\u00f8rk Antoniussen",
      "Walter Zimmer",
      "Ross Greer",
      "Christian Cre\u00df",
      "Andreas M\u00f8gelmose",
      "Mohan M. Trivedi",
      "Alois C. Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03239",
    "title": "Bluesky and the AT Protocol: Usable Decentralized Social Media",
    "abstract": "Bluesky is a new social network built upon the AT Protocol, a decentralized foundation for public social media. It was launched in private beta in February 2023, and has grown to over 3 million registered users in the following year. In this paper we introduce the architecture of Bluesky and the AT Protocol, which is inspired by the web itself, but modernized to include streams of real-time updates and cryptographic authentication. We explain how the technical design of Bluesky is informed by our goals: to enable decentralization by having multiple interoperable providers for every part of the system; to make it easy for users to switch providers; to give users agency over the content they see; and to provide a simple user experience that does not burden users with complexity arising from the system's decentralized nature. The system's openness allows anybody to contribute to content moderation and community management, and we invite the research community to use Bluesky as a dataset and testing ground for new approaches in social media moderation. ",
    "url": "https://arxiv.org/abs/2402.03239",
    "authors": [
      "Martin Kleppmann",
      "Paul Frazee",
      "Jake Gold",
      "Jay Graber",
      "Daniel Holmgren",
      "Devin Ivy",
      "Jeromy Johnson",
      "Bryan Newbold",
      "Jaz Volpert"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.03243",
    "title": "PINN-BO: A Black-box Optimization Algorithm using Physics-Informed  Neural Networks",
    "abstract": "Black-box optimization is a powerful approach for discovering global optima in noisy and expensive black-box functions, a problem widely encountered in real-world scenarios. Recently, there has been a growing interest in leveraging domain knowledge to enhance the efficacy of machine learning methods. Partial Differential Equations (PDEs) often provide an effective means for elucidating the fundamental principles governing the black-box functions. In this paper, we propose PINN-BO, a black-box optimization algorithm employing Physics-Informed Neural Networks that integrates the knowledge from Partial Differential Equations (PDEs) to improve the sample efficiency of the optimization. We analyze the theoretical behavior of our algorithm in terms of regret bound using advances in NTK theory and prove that the use of the PDE alongside the black-box function evaluations, PINN-BO leads to a tighter regret bound. We perform several experiments on a variety of optimization tasks and show that our algorithm is more sample-efficient compared to existing methods. ",
    "url": "https://arxiv.org/abs/2402.03243",
    "authors": [
      "Dat Phan-Trong",
      "Hung The Tran",
      "Alistair Shilton",
      "Sunil Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03246",
    "title": "SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM",
    "abstract": "Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM), facilitating comprehensive scene interpretation. Recent advancements that integrate Gaussian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings through the use of explicit 3D Gaussian representations. Building on this progress, we propose SGS-SLAM, the first semantic dense visual SLAM system grounded in 3D Gaussians, which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation, outperforming existing methods meanwhile preserving real-time rendering ability. ",
    "url": "https://arxiv.org/abs/2402.03246",
    "authors": [
      "Mingrui Li",
      "Shuhong Liu",
      "Heng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.03270",
    "title": "Multiclass Classification Procedure for Detecting Attacks on MQTT-IoT  Protocol",
    "abstract": "The large number of sensors and actuators that make up the Internet of Things obliges these systems to use diverse technologies and protocols. This means that IoT networks are more heterogeneous than traditional networks. This gives rise to new challenges in cybersecurity to protect these systems and devices which are characterized by being connected continuously to the Internet. Intrusion detection systems (IDS) are used to protect IoT systems from the various anomalies and attacks at the network level. Intrusion Detection Systems (IDS) can be improved through machine learning techniques. Our work focuses on creating classification models that can feed an IDS using a dataset containing frames under attacks of an IoT system that uses the MQTT protocol. We have addressed two types of method for classifying the attacks, ensemble methods and deep learning models, more specifically recurrent networks with very satisfactory results. ",
    "url": "https://arxiv.org/abs/2402.03270",
    "authors": [
      "Hector Alaiz-Moreton",
      "Jose Aveleira-Mata",
      "Jorge Ondicol-Garcia",
      "Angel Luis Mu\u00f1oz-Casta\u00f1eda",
      "Isa\u00edas Garc\u00eda",
      "Carmen Benavides"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.03277",
    "title": "Event-based Product Carousel Recommendation with Query-Click Graph",
    "abstract": "Many current recommender systems mainly focus on the product-to-product recommendations and user-to-product recommendations even during the time of events rather than modeling the typical recommendations for the target event (e.g., festivals, seasonal activities, or social activities) without addressing the multiple aspects of the shopping demands for the target event. Product recommendations for the multiple aspects of the target event are usually generated by human curators who manually identify the aspects and select a list of aspect-related products (i.e., product carousel) for each aspect as recommendations. However, building a recommender system with machine learning is non-trivial due to the lack of both the ground truth of event-related aspects and the aspect-related products. To fill this gap, we define the novel problem as the event-based product carousel recommendations in e-commerce and propose an effective recommender system based on the query-click bipartite graph. We apply the iterative clustering algorithm over the query-click bipartite graph and infer the event-related aspects by the clusters of queries. The aspect-related recommendations are powered by the click-through rate of products regarding each aspect. We show through experiments that this approach effectively mines product carousels for the target event. ",
    "url": "https://arxiv.org/abs/2402.03277",
    "authors": [
      "Luyi Ma",
      "Nimesh Sinha",
      "Parth Vajge",
      "Jason HD Cho",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.03289",
    "title": "Make Every Move Count: LLM-based High-Quality RTL Code Generation Using  MCTS",
    "abstract": "Existing large language models (LLMs) for register transfer level code generation face challenges like compilation failures and suboptimal power, performance, and area (PPA) efficiency. This is due to the lack of PPA awareness in conventional transformer decoding algorithms. In response, we present an automated transformer decoding algorithm that integrates Monte Carlo tree-search for lookahead, guiding the transformer to produce compilable, functionally correct, and PPA-optimized code. Empirical evaluation with a fine-tuned language model on RTL codesets shows that our proposed technique consistently generates functionally correct code compared to prompting-only methods and effectively addresses the PPA-unawareness drawback of naive large language models. For the largest design generated by the state-of-the-art LLM (16-bit adder), our technique can achieve a 31.8% improvement in the area-delay product. ",
    "url": "https://arxiv.org/abs/2402.03289",
    "authors": [
      "Matthew DeLorenzo",
      "Animesh Basak Chowdhury",
      "Vasudev Gohil",
      "Shailja Thakur",
      "Ramesh Karri",
      "Siddharth Garg",
      "Jeyavijayan Rajendran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2402.03292",
    "title": "Zero-shot Object-Level OOD Detection with Context-Aware Inpainting",
    "abstract": "Machine learning algorithms are increasingly provided as black-box cloud services or pre-trained models, without access to their training data. This motivates the problem of zero-shot out-of-distribution (OOD) detection. Concretely, we aim to detect OOD objects that do not belong to the classifier's label set but are erroneously classified as in-distribution (ID) objects. Our approach, RONIN, uses an off-the-shelf diffusion model to replace detected objects with inpainting. RONIN conditions the inpainting process with the predicted ID label, drawing the input object closer to the in-distribution domain. As a result, the reconstructed object is very close to the original in the ID cases and far in the OOD cases, allowing RONIN to effectively distinguish ID and OOD samples. Throughout extensive experiments, we demonstrate that RONIN achieves competitive results compared to previous approaches across several datasets, both in zero-shot and non-zero-shot settings. ",
    "url": "https://arxiv.org/abs/2402.03292",
    "authors": [
      "Quang-Huy Nguyen",
      "Jin Peng Zhou",
      "Zhenzhen Liu",
      "Khanh-Huyen Bui",
      "Kilian Q. Weinberger",
      "Dung D. Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.03295",
    "title": "Ginger: An Efficient Curvature Approximation with Linear Complexity for  General Neural Networks",
    "abstract": "Second-order optimization approaches like the generalized Gauss-Newton method are considered more powerful as they utilize the curvature information of the objective function with preconditioning matrices. Albeit offering tempting theoretical benefits, they are not easily applicable to modern deep learning. The major reason is due to the quadratic memory and cubic time complexity to compute the inverse of the matrix. These requirements are infeasible even with state-of-the-art hardware. In this work, we propose Ginger, an eigendecomposition for the inverse of the generalized Gauss-Newton matrix. Our method enjoys efficient linear memory and time complexity for each iteration. Instead of approximating the conditioning matrix, we directly maintain its inverse to make the approximation more accurate. We provide the convergence result of Ginger for non-convex objectives. Our experiments on different tasks with different model architectures verify the effectiveness of our method. Our code is publicly available. ",
    "url": "https://arxiv.org/abs/2402.03295",
    "authors": [
      "Yongchang Hao",
      "Yanshuai Cao",
      "Lili Mou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.03306",
    "title": "Fast solutions to k-parity and k-synchronisation using parallel automata  networks",
    "abstract": "We present a family of automata networks that solve the k-parity problem when run in parallel. These solutions are constructed by connecting cliques in a non-cyclical fashion. The size of the local neighbourhood is linear in the size of the alphabet, and the convergence time is proven to always be the diameter of the interaction graph. We show that this family of solutions can be slightly altered to obtain an equivalent family of solutions to the k-synchronisation problem, which means that these solutions converge from any initial configuration to the cycle which contains all the uniform configurations over the alphabet, in order. ",
    "url": "https://arxiv.org/abs/2402.03306",
    "authors": [
      "Pac\u00f4me Perrotin",
      "Eurico Ruivo",
      "Pedro Paulo Balbi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.03309",
    "title": "AONeuS: A Neural Rendering Framework for Acoustic-Optical Sensor Fusion",
    "abstract": "Underwater perception and 3D surface reconstruction are challenging problems with broad applications in construction, security, marine archaeology, and environmental monitoring. Treacherous operating conditions, fragile surroundings, and limited navigation control often dictate that submersibles restrict their range of motion and, thus, the baseline over which they can capture measurements. In the context of 3D scene reconstruction, it is well-known that smaller baselines make reconstruction more challenging. Our work develops a physics-based multimodal acoustic-optical neural surface reconstruction framework (AONeuS) capable of effectively integrating high-resolution RGB measurements with low-resolution depth-resolved imaging sonar measurements. By fusing these complementary modalities, our framework can reconstruct accurate high-resolution 3D surfaces from measurements captured over heavily-restricted baselines. Through extensive simulations and in-lab experiments, we demonstrate that AONeuS dramatically outperforms recent RGB-only and sonar-only inverse-differentiable-rendering--based surface reconstruction methods. A website visualizing the results of our paper is located at this address: https://aoneus.github.io/ ",
    "url": "https://arxiv.org/abs/2402.03309",
    "authors": [
      "Mohamad Qadri",
      "Kevin Zhang",
      "Akshay Hinduja",
      "Michael Kaess",
      "Adithya Pediredla",
      "Christopher A. Metzler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03311",
    "title": "HASSOD: Hierarchical Adaptive Self-Supervised Object Detection",
    "abstract": "The human visual perception system demonstrates exceptional capabilities in learning without explicit supervision and understanding the part-to-whole composition of objects. Drawing inspiration from these two abilities, we propose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), a novel approach that learns to detect objects and understand their compositions without human supervision. HASSOD employs a hierarchical adaptive clustering strategy to group regions into object masks based on self-supervised visual representations, adaptively determining the number of objects per image. Furthermore, HASSOD identifies the hierarchical levels of objects in terms of composition, by analyzing coverage relations between masks and constructing tree structures. This additional self-supervised learning task leads to improved detection performance and enhanced interpretability. Lastly, we abandon the inefficient multi-round self-training process utilized in prior methods and instead adapt the Mean Teacher framework from semi-supervised learning, which leads to a smoother and more efficient training process. Through extensive experiments on prevalent image datasets, we demonstrate the superiority of HASSOD over existing methods, thereby advancing the state of the art in self-supervised object detection. Notably, we improve Mask AR from 20.2 to 22.5 on LVIS, and from 17.0 to 26.0 on SA-1B. Project page: https://HASSOD-NeurIPS23.github.io. ",
    "url": "https://arxiv.org/abs/2402.03311",
    "authors": [
      "Shengcao Cao",
      "Dhiraj Joshi",
      "Liang-Yan Gui",
      "Yu-Xiong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01744",
    "title": "Unveiling Molecular Moieties through Hierarchical Graph Explainability",
    "abstract": "Background: Graph Neural Networks (GNN) have emerged in very recent years as a powerful tool for supporting in silico Virtual Screening. In this work we present a GNN which uses Graph Convolutional architectures to achieve very accurate multi-target screening. We also devised a hierarchical Explainable Artificial Intelligence (XAI) technique to catch information directly at atom, ring, and whole molecule level by leveraging the message passing mechanism. In this way, we find the most relevant moieties involved in bioactivity prediction. Results: We report a state-of-the-art GNN classifier on twenty Cyclin-dependent Kinase targets in support of VS. Our classifier outperforms previous SOTA approaches proposed by the authors. Moreover, a CDK1-only high-sensitivity version of the GNN has been designed to use our explainer in order to avoid the inherent bias of multi-class models. The hierarchical explainer has been validated by an expert chemist on 19 approved drugs on CDK1. Our explainer provided information in accordance to the docking analysis for 17 out of the 19 test drugs. Conclusion: Our approach is a valid support for shortening both the screening and the hit-to-lead phase. Detailed knowledge about the molecular substructures that play a role in the inhibitory action, can help the computational chemist to gain insights into the pharmacophoric function of the molecule also for repurposing purposes. ",
    "url": "https://arxiv.org/abs/2402.01744",
    "authors": [
      "Paolo Sortino",
      "Salvatore Contino",
      "Ugo Perricone",
      "Roberto Pirrone"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2402.01791",
    "title": "Variational Quantum Circuits Enhanced Generative Adversarial Network",
    "abstract": "Generative adversarial network (GAN) is one of the widely-adopted machine-learning frameworks for a wide range of applications such as generating high-quality images, video, and audio contents. However, training a GAN could become computationally expensive for large neural networks. In this work, we propose a hybrid quantum-classical architecture for improving GAN (denoted as QC-GAN). The performance was examed numerically by benchmarking with a classical GAN using MindSpore Quantum on the task of hand-written image generation. The generator of the QC-GAN consists of a quantum variational circuit together with a one-layer neural network, and the discriminator consists of a traditional neural network. Leveraging the entangling and expressive power of quantum circuits, our hybrid architecture achieved better performance (Frechet Inception Distance) than the classical GAN, with much fewer training parameters and number of iterations for convergence. We have also demonstrated the superiority of QC-GAN over an alternative quantum GAN, namely pathGAN, which could hardly generate 16$\\times$16 or larger images. This work demonstrates the value of combining ideas from quantum computing with machine learning for both areas of Quantum-for-AI and AI-for-Quantum. ",
    "url": "https://arxiv.org/abs/2402.01791",
    "authors": [
      "Runqiu Shu",
      "Xusheng Xu",
      "Man-Hong Yung",
      "Wei Cui"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01809",
    "title": "PhenoLinker: Phenotype-Gene Link Prediction and Explanation using  Heterogeneous Graph Neural Networks",
    "abstract": "The association of a given human phenotype to a genetic variant remains a critical challenge for biology. We present a novel system called PhenoLinker capable of associating a score to a phenotype-gene relationship by using heterogeneous information networks and a convolutional neural network-based model for graphs, which can provide an explanation for the predictions. This system can aid in the discovery of new associations and in the understanding of the consequences of human genetic variation. ",
    "url": "https://arxiv.org/abs/2402.01809",
    "authors": [
      "Jose L. Mellina Andreu",
      "Luis Bernal",
      "Antonio F. Skarmeta",
      "Mina Ryten",
      "Sara \u00c1lvarez",
      "Alejandro Cisterna Garc\u00eda",
      "Juan A. Bot\u00eda"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01855",
    "title": "SPDE priors for uncertainty quantification of end-to-end neural data  assimilation schemes",
    "abstract": "The spatio-temporal interpolation of large geophysical datasets has historically been adressed by Optimal Interpolation (OI) and more sophisticated model-based or data-driven DA techniques. In the last ten years, the link established between Stochastic Partial Differential Equations (SPDE) and Gaussian Markov Random Fields (GMRF) opened a new way of handling both large datasets and physically-induced covariance matrix in Optimal Interpolation. Recent advances in the deep learning community also enables to adress this problem as neural architecture embedding data assimilation variational framework. The reconstruction task is seen as a joint learning problem of the prior involved in the variational inner cost and the gradient-based minimization of the latter: both prior models and solvers are stated as neural networks with automatic differentiation which can be trained by minimizing a loss function, typically stated as the mean squared error between some ground truth and the reconstruction. In this work, we draw from the SPDE-based Gaussian Processes to estimate complex prior models able to handle non-stationary covariances in both space and time and provide a stochastic framework for interpretability and uncertainty quantification. Our neural variational scheme is modified to embed an augmented state formulation with both state and SPDE parametrization to estimate. Instead of a neural prior, we use a stochastic PDE as surrogate model along the data assimilation window. The training involves a loss function for both reconstruction task and SPDE prior model, where the likelihood of the SPDE parameters given the true states is involved in the training. Because the prior is stochastic, we can easily draw samples in the prior distribution before conditioning to provide a flexible way to estimate the posterior distribution based on thousands of members. ",
    "url": "https://arxiv.org/abs/2402.01855",
    "authors": [
      "Maxime Beauchamp",
      "Nicolas Desassis",
      "J. Emmanuel Johnson",
      "Simon Benaichouche",
      "Pierre Tandeo",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.01972",
    "title": "Combining T-learning and DR-learning: a framework for oracle-efficient  estimation of causal contrasts",
    "abstract": "We introduce efficient plug-in (EP) learning, a novel framework for the estimation of heterogeneous causal contrasts, such as the conditional average treatment effect and conditional relative risk. The EP-learning framework enjoys the same oracle-efficiency as Neyman-orthogonal learning strategies, such as DR-learning and R-learning, while addressing some of their primary drawbacks, including that (i) their practical applicability can be hindered by loss function non-convexity; and (ii) they may suffer from poor performance and instability due to inverse probability weighting and pseudo-outcomes that violate bounds. To avoid these drawbacks, EP-learner constructs an efficient plug-in estimator of the population risk function for the causal contrast, thereby inheriting the stability and robustness properties of plug-in estimation strategies like T-learning. Under reasonable conditions, EP-learners based on empirical risk minimization are oracle-efficient, exhibiting asymptotic equivalence to the minimizer of an oracle-efficient one-step debiased estimator of the population risk function. In simulation experiments, we illustrate that EP-learners of the conditional average treatment effect and conditional relative risk outperform state-of-the-art competitors, including T-learner, R-learner, and DR-learner. Open-source implementations of the proposed methods are available in our R package hte3. ",
    "url": "https://arxiv.org/abs/2402.01972",
    "authors": [
      "Lars van der Laan",
      "Marco Carone",
      "Alex Luedtke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.02041",
    "title": "$\u03b1$-Divergence Loss Function for Neural Density Ratio Estimation",
    "abstract": "Recently, neural networks have produced state-of-the-art results for density-ratio estimation (DRE), a fundamental technique in machine learning. However, existing methods bear optimization issues that arise from the loss functions of DRE: a large sample requirement of Kullback--Leibler (KL)-divergence, vanishing of train loss gradients, and biased gradients of the loss functions. Thus, an $\\alpha$-divergence loss function ($\\alpha$-Div) that offers concise implementation and stable optimization is proposed in this paper. Furthermore, technical justifications for the proposed loss function are presented. The stability of the proposed loss function is empirically demonstrated and the estimation accuracy of DRE tasks is investigated. Additionally, this study presents a sample requirement for DRE using the proposed loss function in terms of the upper bound of $L_1$ error, which connects a curse of dimensionality as a common problem in high-dimensional DRE tasks. ",
    "url": "https://arxiv.org/abs/2402.02041",
    "authors": [
      "Yoshiaki Kitazawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02098",
    "title": "Self-attention Networks Localize When QK-eigenspectrum Concentrates",
    "abstract": "The self-attention mechanism prevails in modern machine learning. It has an interesting functionality of adaptively selecting tokens from an input sequence by modulating the degree of attention localization, which many researchers speculate is the basis of the powerful model performance but complicates the underlying mechanism of the learning dynamics. In recent years, mainly two arguments have connected attention localization to the model performances. One is the rank collapse, where the embedded tokens by a self-attention block become very similar across different tokens, leading to a less expressive network. The other is the entropy collapse, where the attention probability approaches non-uniform and entails low entropy, making the learning dynamics more likely to be trapped in plateaus. These two failure modes may apparently contradict each other because the rank and entropy collapses are relevant to uniform and non-uniform attention, respectively. To this end, we characterize the notion of attention localization by the eigenspectrum of query-key parameter matrices and reveal that a small eigenspectrum variance leads attention to be localized. Interestingly, the small eigenspectrum variance prevents both rank and entropy collapse, leading to better model expressivity and trainability. ",
    "url": "https://arxiv.org/abs/2402.02098",
    "authors": [
      "Han Bao",
      "Ryuichiro Hataya",
      "Ryo Karakida"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02397",
    "title": "Multiplexed all-optical permutation operations using a reconfigurable  diffractive optical network",
    "abstract": "Large-scale and high-dimensional permutation operations are important for various applications in e.g., telecommunications and encryption. Here, we demonstrate the use of all-optical diffractive computing to execute a set of high-dimensional permutation operations between an input and output field-of-view through layer rotations in a diffractive optical network. In this reconfigurable multiplexed material designed by deep learning, every diffractive layer has four orientations: 0, 90, 180, and 270 degrees. Each unique combination of these rotatable layers represents a distinct rotation state of the diffractive design tailored for a specific permutation operation. Therefore, a K-layer rotatable diffractive material is capable of all-optically performing up to 4^K independent permutation operations. The original input information can be decrypted by applying the specific inverse permutation matrix to output patterns, while applying other inverse operations will lead to loss of information. We demonstrated the feasibility of this reconfigurable multiplexed diffractive design by approximating 256 randomly selected permutation matrices using K=4 rotatable diffractive layers. We also experimentally validated this reconfigurable diffractive network using terahertz radiation and 3D-printed diffractive layers, providing a decent match to our numerical results. The presented rotation-multiplexed diffractive processor design is particularly useful due to its mechanical reconfigurability, offering multifunctional representation through a single fabrication process. ",
    "url": "https://arxiv.org/abs/2402.02397",
    "authors": [
      "Guangdong Ma",
      "Xilin Yang",
      "Bijie Bai",
      "Jingxi Li",
      "Yuhang Li",
      "Tianyi Gan",
      "Che-Yung Shen",
      "Yijie Zhang",
      "Yuzhu Li",
      "Mona Jarrahi",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.02487",
    "title": "Interplay between tie strength and neighbourhood topology in complex  networks: Granovetter's theory and beyond",
    "abstract": "Granovetter's weak ties theory is a very important sociological theory according to which a correlation between edge weight and the network's topology should exist. More specifically, the neighbourhood overlap of two nodes connected by an edge should be positively correlated with edge weight (tie strength). However, some real social networks exhibit a negative correlation - the most prominent example is the scientific collaboration network, for which overlap decreases with edge weight. It has been demonstrated that the aforementioned inconsistency with Granovetter's theory can be alleviated in the scientific collaboration network through the use of asymmetric measures. In this paper, we explain that while asymmetric measures are often necessary to describe complex networks and to confirm Granovetter's theory, their interpretation is not simple, and there are pitfalls that one must be wary of. The definitions of asymmetric weights and overlaps introduce structural correlations that must be filtered out. We show that correlation profiles can be used to overcome this problem. Using this technique, not only do we confirm Granovetter's theory in various real and artificial social networks, but we also show that Granovetter-like weight-topology correlations are present in other complex networks (e.g. metabolic and neural networks). Our results suggest that Granovetter's theory is a sociological manifestation of more general principles governing various types of complex networks. ",
    "url": "https://arxiv.org/abs/2402.02487",
    "authors": [
      "Maciej J Mrowinski",
      "Kamil P. Orzechowski",
      "Agata Fronczak",
      "Piotr Fronczak"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.02552",
    "title": "Neur2BiLO: Neural Bilevel Optimization",
    "abstract": "Bilevel optimization deals with nested problems in which a leader takes the first decision to minimize their objective function while accounting for a follower's best-response reaction. Constrained bilevel problems with integer variables are particularly notorious for their hardness. While exact solvers have been proposed for mixed-integer linear bilevel optimization, they tend to scale poorly with problem size and are hard to generalize to the non-linear case. On the other hand, problem-specific algorithms (exact and heuristic) are limited in scope. Under a data-driven setting in which similar instances of a bilevel problem are solved routinely, our proposed framework, Neur2BiLO, embeds a neural network approximation of the leader's or follower's value function, trained via supervised regression, into an easy-to-solve mixed-integer program. Neur2BiLO serves as a heuristic that produces high-quality solutions extremely fast for the bilevel knapsack interdiction problem, the \"critical node game\" from network security, a donor-recipient healthcare problem, and discrete network design from transportation planning. These problems are diverse in that they have linear or non-linear objectives/constraints and integer or mixed-integer variables, making Neur2BiLO unique in its versatility. ",
    "url": "https://arxiv.org/abs/2402.02552",
    "authors": [
      "Justin Dumouchelle",
      "Esther Julien",
      "Jannis Kurtz",
      "Elias B. Khalil"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02721",
    "title": "Quantum Switches for Gottesman-Kitaev-Preskill Qubit-based All-Photonic  Quantum Networks",
    "abstract": "The Gottesman-Kitaev-Preskill (GKP) code, being information theoretically near optimal for quantum communication over Gaussian thermal-loss optical channels, is likely to be the encoding of choice for advanced quantum networks of the future. Quantum repeaters based on GKP-encoded light have been shown to support high end-to-end entanglement rates across large distances despite realistic finite squeezing in GKP code preparation and homodyne detection inefficiencies. Here, we introduce a quantum switch for GKP-qubit-based quantum networks, whose architecture involves multiplexed GKP-qubit-based entanglement link generation with clients, and their all-photonic storage, together enabled by GKP-qubit graph state resources. For bipartite entanglement distribution between clients via entanglement swapping, the switch uses a multi-client generalization of a recently introduced $\\textit{entanglement-ranking-based link matching}$ protocol heuristic. Since generating the GKP-qubit graph state resource is hardware intensive, given a total resource budget and an arbitrary layout of clients, we address the question of their optimal allocation towards the different client-pair connections served by the switch such that the sum throughput of the switch is maximized while also being fair in terms of the individual entanglement rates. We illustrate our results for an exemplary data center network, where the data center is a client of a switch and all of its other clients aim to connect to the data center alone -- a scenario that also captures the general case of a gateway router connecting a local area network to a global network. Together with compatible quantum repeaters, our quantum switch provides a way to realize quantum networks of arbitrary topology. ",
    "url": "https://arxiv.org/abs/2402.02721",
    "authors": [
      "Mohadeseh Azari",
      "Paul Polakos",
      "Kaushik P. Seshadreesan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.02862",
    "title": "Graph Neural Machine: A New Model for Learning with Tabular Data",
    "abstract": "In recent years, there has been a growing interest in mapping data from different domains to graph structures. Among others, neural network models such as the multi-layer perceptron (MLP) can be modeled as graphs. In fact, MLPs can be represented as directed acyclic graphs. Graph neural networks (GNNs) have recently become the standard tool for performing machine learning tasks on graphs. In this work, we show that an MLP is equivalent to an asynchronous message passing GNN model which operates on the MLP's graph representation. We then propose a new machine learning model for tabular data, the so-called Graph Neural Machine (GNM), which replaces the MLP's directed acyclic graph with a nearly complete graph and which employs a synchronous message passing scheme. We show that a single GNM model can simulate multiple MLP models. We evaluate the proposed model in several classification and regression datasets. In most cases, the GNM model outperforms the MLP architecture. ",
    "url": "https://arxiv.org/abs/2402.02862",
    "authors": [
      "Giannis Nikolentzos",
      "Siyun Wang",
      "Johannes Lutzeyer",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02866",
    "title": "Quantum Normalizing Flows for Anomaly Detection",
    "abstract": "A Normalizing Flow computes a bijective mapping from an arbitrary distribution to a predefined (e.g. normal) distribution. Such a flow can be used to address different tasks, e.g. anomaly detection, once such a mapping has been learned. In this work we introduce Normalizing Flows for Quantum architectures, describe how to model and optimize such a flow and evaluate our method on example datasets. Our proposed models show competitive performance for anomaly detection compared to classical methods, e.g. based on isolation forests, the local outlier factor (LOF) or single-class SVMs, while being fully executable on a quantum computer. ",
    "url": "https://arxiv.org/abs/2402.02866",
    "authors": [
      "Bodo Rosenhahn",
      "Christoph Hirche"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02880",
    "title": "Unleashing the Expressive Power of Pulse-Based Quantum Neural Networks",
    "abstract": "Quantum machine learning (QML) based on Noisy Intermediate-Scale Quantum (NISQ) devices requires the optimal utilization of limited quantum resources. The commonly used gate-based QML models are convenient for software engineers, but their expressivity is restricted by the permissible circuit depth within a finite coherence time. In contrast, pulse-based models enable the construction of \"infinitely\" deep quantum neural networks within the same coherence time, which may unleash greater expressive power for complex learning tasks. In this paper, we investigate this potential from the perspective of quantum control theory. We first indicate that the nonlinearity of pulse-based models comes from the encoding process that can be viewed as the continuous limit of data-reuploading in gate-based models. Subsequently, we prove that the pulse-based model can approximate arbitrary nonlinear functions when the underlying physical system is ensemble controllable. Under this condition, numerical simulations show that the expressivity can be enhanced by either increasing the pulse length or the number of qubits. As anticipated, we demonstrate through numerical examples that the pulse-based model can unleash more expressive power compared to the gate-based model. These findings establish a theoretical foundation for understanding and designing expressive QML models using NISQ devices. ",
    "url": "https://arxiv.org/abs/2402.02880",
    "authors": [
      "Han-Xiao Tao",
      "Jiaqi Hu",
      "Re-Bing Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.02963",
    "title": "One-class anomaly detection through color-to-thermal AI for building  envelope inspection",
    "abstract": "We present a label-free method for detecting anomalies during thermographic inspection of building envelopes. It is based on the AI-driven prediction of thermal distributions from color images. Effectively the method performs as a one-class classifier of the thermal image regions with high mismatch between the predicted and actual thermal distributions. The algorithm can learn to identify certain features as normal or anomalous by selecting the target sample used for training. We demonstrated this principle by training the algorithm with data collected at different outdoors temperature, which lead to the detection of thermal bridges. The method can be implemented to assist human professionals during routine building inspections or combined with mobile platforms for automating examination of large areas. ",
    "url": "https://arxiv.org/abs/2402.02963",
    "authors": [
      "Polina Kurtser",
      "Kailun Feng",
      "Thomas Olofsson",
      "Aitor De Andres"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03015",
    "title": "Open-separating dominating codes in graphs",
    "abstract": "Using dominating sets to separate vertices of graphs is a well-studied problem in the larger domain of identification problems. In such problems, the objective is typically to separate any two vertices of a graph by their unique neighbourhoods in a suitably chosen dominating set of the graph. Such a dominating and separating set is often referred to as a \\emph{code} in the literature. Depending on the types of dominating and separating sets used, various problems arise under various names in the literature. In this paper, we introduce a new problem in the same realm of identification problems whereby the code, called the \\emph{open-separating dominating code}, or the \\emph{OSD-code} for short, is a dominating set and uses open neighbourhoods for separating vertices. The paper studies the fundamental properties concerning the existence, hardness and minimality of OSD-codes. Due to the emergence of a close and yet difficult to establish relation of the OSD-codes with another well-studied code in the literature called the open locating dominating codes, or OLD-codes for short, we compare the two on various graph classes. Finally, we also provide an equivalent reformulation of the problem of finding OSD-codes of a graph as a covering problem in a suitable hypergraph and discuss the polyhedra associated with OSD-codes, again in relation to OLD-codes of some graph classes already studied in this context. ",
    "url": "https://arxiv.org/abs/2402.03015",
    "authors": [
      "Dipayan Chakraborty",
      "Annegret K. Wagler"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.03058",
    "title": "Array Geometry-Robust Attention-Based Neural Beamformer for Moving  Speakers",
    "abstract": "Recently, a mask-based beamformer with attention-based spatial covariance matrix aggregator (ASA) was proposed, which was demonstrated to track moving sources accurately. However, the deep neural network model used in this algorithm is limited to a specific channel configuration, requiring a different model in case a different channel permutation, channel count, or microphone array geometry is considered. Addressing this limitation, in this paper, we investigate three approaches to improve the robustness of the ASA-based tracking method against such variations: incorporating random channel configurations during the training process, employing the transform-average-concatenate (TAC) method to process multi-channel input features (allowing for any channel count and enabling permutation invariance), and utilizing input features that are robust against variations of the channel configuration. Our experiments, conducted using the CHiME-3 and DEMAND datasets, demonstrate improved robustness against mismatches in channel permutations, channel counts, and microphone array geometries compared to the conventional ASA-based tracking method without compromising performance in matched conditions, suggesting that the mask-based beamformer with ASA integrating the proposed approaches has the potential to track moving sources for arbitrary microphone arrays. ",
    "url": "https://arxiv.org/abs/2402.03058",
    "authors": [
      "Marvin Tammen",
      "Tsubasa Ochiai",
      "Marc Delcroix",
      "Tomohiro Nakatani",
      "Shoko Araki",
      "Simon Doclo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.03231",
    "title": "Improved prediction of future user activity in online A/B testing",
    "abstract": "In online randomized experiments or A/B tests, accurate predictions of participant inclusion rates are of paramount importance. These predictions not only guide experimenters in optimizing the experiment's duration but also enhance the precision of treatment effect estimates. In this paper we present a novel, straightforward, and scalable Bayesian nonparametric approach for predicting the rate at which individuals will be exposed to interventions within the realm of online A/B testing. Our approach stands out by offering dual prediction capabilities: it forecasts both the quantity of new customers expected in future time windows and, unlike available alternative methods, the number of times they will be observed. We derive closed-form expressions for the posterior distributions of the quantities needed to form predictions about future user activity, thereby bypassing the need for numerical algorithms such as Markov chain Monte Carlo. After a comprehensive exposition of our model, we test its performance on experiments on real and simulated data, where we show its superior performance with respect to existing alternatives in the literature. ",
    "url": "https://arxiv.org/abs/2402.03231",
    "authors": [
      "Lorenzo Masoero",
      "Mario Beraha",
      "Thomas Richardson",
      "Stefano Favaro"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2402.03254",
    "title": "Minimum Description Length and Generalization Guarantees for  Representation Learning",
    "abstract": "A major challenge in designing efficient statistical supervised learning algorithms is finding representations that perform well not only on available training samples but also on unseen data. While the study of representation learning has spurred much interest, most existing such approaches are heuristic; and very little is known about theoretical generalization guarantees. In this paper, we establish a compressibility framework that allows us to derive upper bounds on the generalization error of a representation learning algorithm in terms of the \"Minimum Description Length\" (MDL) of the labels or the latent variables (representations). Rather than the mutual information between the encoder's input and the representation, which is often believed to reflect the algorithm's generalization capability in the related literature but in fact, falls short of doing so, our new bounds involve the \"multi-letter\" relative entropy between the distribution of the representations (or labels) of the training and test sets and a fixed prior. In particular, these new bounds reflect the structure of the encoder and are not vacuous for deterministic algorithms. Our compressibility approach, which is information-theoretic in nature, builds upon that of Blum-Langford for PAC-MDL bounds and introduces two essential ingredients: block-coding and lossy-compression. The latter allows our approach to subsume the so-called geometrical compressibility as a special case. To the best knowledge of the authors, the established generalization bounds are the first of their kind for Information Bottleneck (IB) type encoders and representation learning. Finally, we partly exploit the theoretical results by introducing a new data-dependent prior. Numerical simulations illustrate the advantages of well-chosen such priors over classical priors used in IB. ",
    "url": "https://arxiv.org/abs/2402.03254",
    "authors": [
      "Milad Sefidgaran",
      "Abdellatif Zaidi",
      "Piotr Krasnowski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1711.01820",
    "title": "Game Theoretic Semi-Distributed D2D Resource Allocation Underlaying an  LTE Network",
    "abstract": " Title: Game Theoretic Semi-Distributed D2D Resource Allocation Underlaying an  LTE Network ",
    "url": "https://arxiv.org/abs/1711.01820",
    "authors": [
      "Anushree Neogi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2105.09254",
    "title": "Multiply Robust Causal Mediation Analysis with Continuous Treatments",
    "abstract": " Title: Multiply Robust Causal Mediation Analysis with Continuous Treatments ",
    "url": "https://arxiv.org/abs/2105.09254",
    "authors": [
      "Numair Sani",
      "Yizhen Xu",
      "AmirEmad Ghassami",
      "Ilya Shpitser"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.15587",
    "title": "A sublinear query quantum algorithm for s-t minimum cut on dense simple  graphs",
    "abstract": " Comments: The proof of the upper bound on the time complexity in the first arXiv version contained a fatal flaw. In this version we remove the claim about time complexity and prove the result only for query complexity ",
    "url": "https://arxiv.org/abs/2110.15587",
    "authors": [
      "Simon Apers",
      "Arinta Auza",
      "Troy Lee"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2202.03482",
    "title": "Navigating Neural Space: Revisiting Concept Activation Vectors to  Overcome Directional Divergence",
    "abstract": " Title: Navigating Neural Space: Revisiting Concept Activation Vectors to  Overcome Directional Divergence ",
    "url": "https://arxiv.org/abs/2202.03482",
    "authors": [
      "Frederik Pahde",
      "Maximilian Dreyer",
      "Leander Weber",
      "Moritz Weckbecker",
      "Christopher J. Anders",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03844",
    "title": "EvoPruneDeepTL: An Evolutionary Pruning Model for Transfer Learning  based Deep Neural Networks",
    "abstract": " Title: EvoPruneDeepTL: An Evolutionary Pruning Model for Transfer Learning  based Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2202.03844",
    "authors": [
      "Javier Poyatos",
      "Daniel Molina",
      "Aritz. D. Martinez",
      "Javier Del Ser",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.04510",
    "title": "Translating Subgraphs to Nodes Makes Simple GNNs Strong and Efficient  for Subgraph Representation Learning",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2204.04510",
    "authors": [
      "Dongkwan Kim",
      "Alice Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.13842",
    "title": "Dive into Machine Learning Algorithms for Influenza Virus Host  Prediction with Hemagglutinin Sequences",
    "abstract": " Comments: Published at BioSystems; V1: minor typo correction; V2: minor typo correction and add more clarification in \"Cross-validation\" section ",
    "url": "https://arxiv.org/abs/2207.13842",
    "authors": [
      "Yanhua Xu",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11419",
    "title": "SSCFormer: Push the Limit of Chunk-wise Conformer for Streaming ASR  Using Sequentially Sampled Chunks and Chunked Causal Convolution",
    "abstract": " Comments: This manuscript has been accepted by SPL ",
    "url": "https://arxiv.org/abs/2211.11419",
    "authors": [
      "Fangyuan Wang",
      "Bo Xu",
      "Bo Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.15335",
    "title": "You Can Have Better Graph Neural Networks by Not Training Weights at  All: Finding Untrained GNNs Tickets",
    "abstract": " Comments: Accepted by the LoG conference 2022 as a spotlight ",
    "url": "https://arxiv.org/abs/2211.15335",
    "authors": [
      "Tianjin Huang",
      "Tianlong Chen",
      "Meng Fang",
      "Vlado Menkovski",
      "Jiaxu Zhao",
      "Lu Yin",
      "Yulong Pei",
      "Decebal Constantin Mocanu",
      "Zhangyang Wang",
      "Mykola Pechenizkiy",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.06808",
    "title": "Incentive-Aware Models of Financial Networks",
    "abstract": " Title: Incentive-Aware Models of Financial Networks ",
    "url": "https://arxiv.org/abs/2212.06808",
    "authors": [
      "Akhil Jalan",
      "Deepayan Chakrabarti",
      "Purnamrita Sarkar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.13336",
    "title": "The Fair Value of Data Under Heterogeneous Privacy Constraints in  Federated Learning",
    "abstract": " Comments: 29 pages, 5 figures, Accepted to TMLR ",
    "url": "https://arxiv.org/abs/2301.13336",
    "authors": [
      "Justin Kang",
      "Ramtin Pedarsani",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.03596",
    "title": "Graph Generation with Diffusion Mixture",
    "abstract": " Title: Graph Generation with Diffusion Mixture ",
    "url": "https://arxiv.org/abs/2302.03596",
    "authors": [
      "Jaehyeong Jo",
      "Dongki Kim",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06279",
    "title": "Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural  Networks with Neuromorphic Data",
    "abstract": " Comments: To appear in Network and Distributed System Security (NDSS) Symposium 2024 ",
    "url": "https://arxiv.org/abs/2302.06279",
    "authors": [
      "Gorka Abad",
      "Oguzhan Ersoy",
      "Stjepan Picek",
      "Aitor Urbieta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10253",
    "title": "Multiobjective Evolutionary Pruning of Deep Neural Networks with  Transfer Learning for improving their Performance and Robustness",
    "abstract": " Comments: 28 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2302.10253",
    "authors": [
      "Javier Poyatos",
      "Daniel Molina",
      "Aitor Mart\u00ednez",
      "Javier Del Ser",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06070",
    "title": "Thinness and its variations on some graph families and coloring graphs  of bounded thinness",
    "abstract": " Title: Thinness and its variations on some graph families and coloring graphs  of bounded thinness ",
    "url": "https://arxiv.org/abs/2303.06070",
    "authors": [
      "Flavia Bonomo-Braberman",
      "Eric Brandwein",
      "Fabiano S. Oliveira",
      "Moys\u00e9s S. Sampaio Jr.",
      "Agustin Sansone",
      "Jayme L. Szwarcfiter"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.13077",
    "title": "An Efficient Knowledge Transfer Strategy for Spiking Neural Networks  from Static to Event Domain",
    "abstract": " Comments: Accepted by AAAI 2024 (Oral). Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.13077",
    "authors": [
      "Xiang He",
      "Dongcheng Zhao",
      "Yang Li",
      "Guobin Shen",
      "Qingqun Kong",
      "Yi Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.08172",
    "title": "Pointwise convergence of Fourier series and deep neural network for the  indicator function of d-dimensional ball",
    "abstract": " Comments: When the version 2 was rejected (where I submitted it to an AI journal), I realized I needed to further clarify the key point, and also realized the field is rather Fourier analysis ",
    "url": "https://arxiv.org/abs/2304.08172",
    "authors": [
      "Ryota Kawasumi",
      "Tsuyoshi Yoneda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2304.09067",
    "title": "Performance of GAN-based augmentation for deep learning COVID-19 image  classification",
    "abstract": " Comments: To be published in prceedings of WMLQ2022 International Workshop on Machine Learning and Quantum Computing Applications in Medicine and Physics. Version updated after editorial review ",
    "url": "https://arxiv.org/abs/2304.09067",
    "authors": [
      "Oleksandr Fedoruk",
      "Konrad Klimaszewski",
      "Aleksander Ogonowski",
      "Rafa\u0142 Mo\u017cd\u017conek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2304.12290",
    "title": "Joint Message Detection and Channel Estimation for Unsourced Random  Access in Cell-Free User-Centric Wireless Networks",
    "abstract": " Comments: 45 pages, 9 figures, submitted to the IEEE Transactions on Information Theory ",
    "url": "https://arxiv.org/abs/2304.12290",
    "authors": [
      "Burak \u00c7akmak",
      "Eleni Gkiouzepi",
      "Manfred Opper",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.12770",
    "title": "Controlling Posterior Collapse by an Inverse Lipschitz Constraint on the  Decoder Network",
    "abstract": " Comments: accepted to ICML 2023, some notations adjusted from the submitted version ",
    "url": "https://arxiv.org/abs/2304.12770",
    "authors": [
      "Yuri Kinoshita",
      "Kenta Oono",
      "Kenji Fukumizu",
      "Yuichi Yoshida",
      "Shin-ichi Maeda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.14922",
    "title": "Supervised and Unsupervised Deep Learning Approaches for EEG Seizure  Prediction",
    "abstract": " Comments: 16 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2304.14922",
    "authors": [
      "Zakary Georgis-Yap",
      "Milos R. Popovic",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.04228",
    "title": "Heterogeneous Directed Hypergraph Neural Network over abstract syntax  tree (AST) for Code Classification",
    "abstract": " Comments: Published in the 35th International Conference on Software Engineering and Knowledge Engineering (SEKE 2023) as a regular paper ",
    "url": "https://arxiv.org/abs/2305.04228",
    "authors": [
      "Guang Yang",
      "Tiancheng Jin",
      "Liang Dou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.05875",
    "title": "Quantization Aware Attack: Enhancing Transferable Adversarial Attacks by  Model Quantization",
    "abstract": " Comments: Accepted by IEEE Transactions on Information Forensics and Security in 2024 ",
    "url": "https://arxiv.org/abs/2305.05875",
    "authors": [
      "Yulong Yang",
      "Chenhao Lin",
      "Qian Li",
      "Zhengyu Zhao",
      "Haoran Fan",
      "Chao Shen",
      "Dawei Zhou",
      "Nannan Wang",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.06773",
    "title": "Towards a Better Understanding of the Computer Vision Research Community  in Africa",
    "abstract": " Comments: Published in EAAMO'23 under ACM License. This work is part of our African computer vision grassroots research in Ro'ya - CV4Africa, this https URL ",
    "url": "https://arxiv.org/abs/2305.06773",
    "authors": [
      "Abdul-Hakeem Omotayo",
      "Mai Gamal",
      "Eman Ehab",
      "Gbetondji Dovonon",
      "Zainab Akinjobi",
      "Ismaila Lukman",
      "Houcemeddine Turki",
      "Mahmod Abdien",
      "Idriss Tondji",
      "Abigail Oppong",
      "Yvan Pimi",
      "Karim Gamal",
      "Ro'ya-CV4Africa",
      "Mennatullah Siam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08514",
    "title": "Generative Adversarial Networks for Spatio-Spectral Compression of  Hyperspectral Images",
    "abstract": " Title: Generative Adversarial Networks for Spatio-Spectral Compression of  Hyperspectral Images ",
    "url": "https://arxiv.org/abs/2305.08514",
    "authors": [
      "Akshara Preethy Byju",
      "Martin Hermann Paul Fuchs",
      "Alisa Walda",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.10110",
    "title": "Adaptive aggregation of Monte Carlo augmented decomposed filters for  efficient group-equivariant convolutional neural network",
    "abstract": " Title: Adaptive aggregation of Monte Carlo augmented decomposed filters for  efficient group-equivariant convolutional neural network ",
    "url": "https://arxiv.org/abs/2305.10110",
    "authors": [
      "Wenzhao Zhao",
      "Barbara D. Wichtmann",
      "Steffen Albert",
      "Angelika Maurer",
      "Frank G. Z\u00f6llner",
      "Ulrike Attenberger",
      "J\u00fcrgen Hesser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10267",
    "title": "State Representation Learning Using an Unbalanced Atlas",
    "abstract": " Title: State Representation Learning Using an Unbalanced Atlas ",
    "url": "https://arxiv.org/abs/2305.10267",
    "authors": [
      "Li Meng",
      "Morten Goodwin",
      "Anis Yazidi",
      "Paal Engelstad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11857",
    "title": "Computing high-dimensional optimal transport by flow neural networks",
    "abstract": " Title: Computing high-dimensional optimal transport by flow neural networks ",
    "url": "https://arxiv.org/abs/2305.11857",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.12809",
    "title": "Relabeling Minimal Training Subset to Flip a Prediction",
    "abstract": " Title: Relabeling Minimal Training Subset to Flip a Prediction ",
    "url": "https://arxiv.org/abs/2305.12809",
    "authors": [
      "Jinghan Yang",
      "Linjie Xu",
      "Lequan Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.13015",
    "title": "3D Rotation and Translation for Hyperbolic Knowledge Graph Embedding",
    "abstract": " Comments: 19 pages, EACL2024 main ",
    "url": "https://arxiv.org/abs/2305.13015",
    "authors": [
      "Yihua Zhu",
      "Hidetoshi Shimodaira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13954",
    "title": "Robust Prompt Optimization for Large Language Models Against  Distribution Shifts",
    "abstract": " Comments: EMNLP 2023 Main ",
    "url": "https://arxiv.org/abs/2305.13954",
    "authors": [
      "Moxin Li",
      "Wenjie Wang",
      "Fuli Feng",
      "Yixin Cao",
      "Jizhi Zhang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15244",
    "title": "Neural Lyapunov and Optimal Control",
    "abstract": " Title: Neural Lyapunov and Optimal Control ",
    "url": "https://arxiv.org/abs/2305.15244",
    "authors": [
      "Daniel Layeghi",
      "Steve Tonneau",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16368",
    "title": "Neural incomplete factorization: learning preconditioners for the  conjugate gradient method",
    "abstract": " Comments: Under review. 18 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2305.16368",
    "authors": [
      "Paul H\u00e4usner",
      "Ozan \u00d6ktem",
      "Jens Sj\u00f6lund"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16905",
    "title": "Improving Neural Additive Models with Bayesian Principles",
    "abstract": " Title: Improving Neural Additive Models with Bayesian Principles ",
    "url": "https://arxiv.org/abs/2305.16905",
    "authors": [
      "Kouroche Bouchiat",
      "Alexander Immer",
      "Hugo Y\u00e8che",
      "Gunnar R\u00e4tsch",
      "Vincent Fortuin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17326",
    "title": "Matrix Information Theory for Self-Supervised Learning",
    "abstract": " Title: Matrix Information Theory for Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2305.17326",
    "authors": [
      "Yifan Zhang",
      "Zhiquan Tan",
      "Jingqin Yang",
      "Weiran Huang",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01271",
    "title": "Towards Understanding Clean Generalization and Robust Overfitting in  Adversarial Training",
    "abstract": " Comments: 28 pages, comments welcome ",
    "url": "https://arxiv.org/abs/2306.01271",
    "authors": [
      "Binghui Li",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01992",
    "title": "On Size-Independent Sample Complexity of ReLU Networks",
    "abstract": " Comments: 4 pages ",
    "url": "https://arxiv.org/abs/2306.01992",
    "authors": [
      "Mark Sellke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.05035",
    "title": "Does Long-Term Series Forecasting Need Complex Attention and Extra Long  Inputs?",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2306.05035",
    "authors": [
      "Daojun Liang",
      "Haixia Zhang",
      "Dongfeng Yuan",
      "Xiaoyan Ma",
      "Dongyang Li",
      "Minggao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06347",
    "title": "DocChecker: Bootstrapping Code Large Language Model for Detecting and  Resolving Code-Comment Inconsistencies",
    "abstract": " Title: DocChecker: Bootstrapping Code Large Language Model for Detecting and  Resolving Code-Comment Inconsistencies ",
    "url": "https://arxiv.org/abs/2306.06347",
    "authors": [
      "Anh T. V. Dau",
      "Jin L. C. Guo",
      "Nghi D. Q. Bui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.07392",
    "title": "Learning Any-View 6DoF Robotic Grasping in Cluttered Scenes via Neural  Surface Rendering",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2306.07392",
    "authors": [
      "Snehal Jauhri",
      "Ishikaa Lunawat",
      "Georgia Chalvatzaki"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.08489",
    "title": "Analysis and Approximate Inference of Large Random Kronecker Graphs",
    "abstract": " Comments: 27 pages, 5 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2306.08489",
    "authors": [
      "Zhenyu Liao",
      "Yuanqian Xia",
      "Chengmei Niu",
      "Yong Xiao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2306.13339",
    "title": "TrustGuard: GNN-based Robust and Explainable Trust Evaluation with  Dynamicity Support",
    "abstract": " Comments: Accepted by IEEE TDSC. Code: this https URL ",
    "url": "https://arxiv.org/abs/2306.13339",
    "authors": [
      "Jie Wang",
      "Zheng Yan",
      "Jiahe Lan",
      "Elisa Bertino",
      "Witold Pedrycz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.14275",
    "title": "Enhancing Adversarial Training via Reweighting Optimization Trajectory",
    "abstract": " Comments: Accepted by ECML 2023 ",
    "url": "https://arxiv.org/abs/2306.14275",
    "authors": [
      "Tianjin Huang",
      "Shiwei Liu",
      "Tianlong Chen",
      "Meng Fang",
      "Li Shen",
      "Vlaod Menkovski",
      "Lu Yin",
      "Yulong Pei",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.00270",
    "title": "Real-time High-Resolution Neural Network with Semantic Guidance for  Crack Segmentation",
    "abstract": " Title: Real-time High-Resolution Neural Network with Semantic Guidance for  Crack Segmentation ",
    "url": "https://arxiv.org/abs/2307.00270",
    "authors": [
      "Yongshang Li",
      "Ronggui Ma",
      "Han Liu",
      "Gaoli Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.01171",
    "title": "Quantum Neural Estimation of Entropies",
    "abstract": " Comments: 14 pages, 2 figures; see also independent works of Shin, Lee, and Jeong at arXiv:2306.14566v1 and Lee, Kwon, and Lee at arXiv:2307.13511v2 ",
    "url": "https://arxiv.org/abs/2307.01171",
    "authors": [
      "Ziv Goldfeld",
      "Dhrumil Patel",
      "Sreejith Sreekumar",
      "Mark M. Wilde"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.01645",
    "title": "In-Domain Self-Supervised Learning Improves Remote Sensing Image Scene  Classification",
    "abstract": " Title: In-Domain Self-Supervised Learning Improves Remote Sensing Image Scene  Classification ",
    "url": "https://arxiv.org/abs/2307.01645",
    "authors": [
      "Ivica Dimitrovski",
      "Ivan Kitanovski",
      "Nikola Simidjievski",
      "Dragi Kocev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07354",
    "title": "PG-Triggers: Triggers for Property Graphs",
    "abstract": " Comments: 13 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2307.07354",
    "authors": [
      "Stefano Ceri",
      "Anna Bernasconi",
      "Alessia Gagliardi",
      "Davide Martinenghi",
      "Luigi Bellomarini",
      "Davide Magnanimi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2307.08430",
    "title": "Long-range Meta-path Search on Large-scale Heterogeneous Graphs",
    "abstract": " Comments: 17 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2307.08430",
    "authors": [
      "Chao Li",
      "Zijie Guo",
      "Qiuting He",
      "Hao Xu",
      "Kun He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.10249",
    "title": "RCM-Fusion: Radar-Camera Multi-Level Fusion for 3D Object Detection",
    "abstract": " Comments: Accepted by IEEE International Conference on Robotics and Automation (ICRA 2024), 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2307.10249",
    "authors": [
      "Jisong Kim",
      "Minjae Seong",
      "Geonho Bang",
      "Dongsuk Kum",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10843",
    "title": "Global Precipitation Nowcasting of Integrated Multi-satellitE Retrievals  for GPM: A U-Net Convolutional LSTM Architecture",
    "abstract": " Title: Global Precipitation Nowcasting of Integrated Multi-satellitE Retrievals  for GPM: A U-Net Convolutional LSTM Architecture ",
    "url": "https://arxiv.org/abs/2307.10843",
    "authors": [
      "Reyhaneh Rahimi",
      "Praveen Ravirathinam",
      "Ardeshir Ebtehaj",
      "Ali Behrangi",
      "Jackson Tan",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2307.15299",
    "title": "Differential Evolution Algorithm based Hyper-Parameters Selection of  Transformer Neural Network Model for Load Forecasting",
    "abstract": " Comments: 6 Pages, 6 Figures, 2 Tables, Accepted by the 14th IEEE International Symposium Series on Computational Intelligence (SSCI 2023), December 5-8, 2023, Mexico City, Mexico ",
    "url": "https://arxiv.org/abs/2307.15299",
    "authors": [
      "Anuvab Sen",
      "Arul Rhik Mazumder",
      "Udayon Sen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.04369",
    "title": "SSTFormer: Bridging Spiking Neural Network and Memory Support  Transformer for Frame-Event based Recognition",
    "abstract": " Comments: In Peer Review ",
    "url": "https://arxiv.org/abs/2308.04369",
    "authors": [
      "Xiao Wang",
      "Zongzhen Wu",
      "Yao Rong",
      "Lin Zhu",
      "Bo Jiang",
      "Jin Tang",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.07037",
    "title": "Bayesian Flow Networks",
    "abstract": " Title: Bayesian Flow Networks ",
    "url": "https://arxiv.org/abs/2308.07037",
    "authors": [
      "Alex Graves",
      "Rupesh Kumar Srivastava",
      "Timothy Atkinson",
      "Faustino Gomez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07134",
    "title": "Language is All a Graph Needs",
    "abstract": " Comments: In EACL 2024 ",
    "url": "https://arxiv.org/abs/2308.07134",
    "authors": [
      "Ruosong Ye",
      "Caiqi Zhang",
      "Runhui Wang",
      "Shuyuan Xu",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11129",
    "title": "Enhancing Graph Transformers with Hierarchical Distance Structural  Encoding",
    "abstract": " Title: Enhancing Graph Transformers with Hierarchical Distance Structural  Encoding ",
    "url": "https://arxiv.org/abs/2308.11129",
    "authors": [
      "Yuankai Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.11767",
    "title": "Detection of ChatGPT Fake Science with the xFakeBibs Learning Algorithm",
    "abstract": " Comments: 14 pages, 6 figures, 4 tables, 2 algorithms ",
    "url": "https://arxiv.org/abs/2308.11767",
    "authors": [
      "Ahmed Abdeen Hamed",
      "Xindong Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.12252",
    "title": "How Safe Am I Given What I See? Calibrated Prediction of Safety Chances  for Image-Controlled Autonomy",
    "abstract": " Title: How Safe Am I Given What I See? Calibrated Prediction of Safety Chances  for Image-Controlled Autonomy ",
    "url": "https://arxiv.org/abs/2308.12252",
    "authors": [
      "Zhenjiang Mao",
      "Carson Sobolewski",
      "Ivan Ruchkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14731",
    "title": "Distilled GPT for Source Code Summarization",
    "abstract": " Comments: 19 pages + 6 figures. Accepted to Automated Software Engineering Journal ",
    "url": "https://arxiv.org/abs/2308.14731",
    "authors": [
      "Chia-Yi Su",
      "Collin McMillan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.16262",
    "title": "Causal Strategic Learning with Competitive Selection",
    "abstract": " Comments: Added more discussions on assumptions and the algorithm, and expand the Conclusion ",
    "url": "https://arxiv.org/abs/2308.16262",
    "authors": [
      "Kiet Q. H. Vo",
      "Muneeb Aadil",
      "Siu Lun Chau",
      "Krikamol Muandet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.01098",
    "title": "martFL: Enabling Utility-Driven Data Marketplace with a Robust and  Verifiable Federated Learning Architecture",
    "abstract": " Comments: Another version of this paper is published in the proceedings of ACM Conference on Computer and Communications Security (CCS) 2023 ",
    "url": "https://arxiv.org/abs/2309.01098",
    "authors": [
      "Qi Li",
      "Zhuotao Liu",
      "Qi Li",
      "Ke Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.06847",
    "title": "Undetectable Selfish Mining",
    "abstract": " Title: Undetectable Selfish Mining ",
    "url": "https://arxiv.org/abs/2309.06847",
    "authors": [
      "Maryam Bahrani",
      "S. Matthew Weinberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.06902",
    "title": "CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign  Detection Under Extreme Conditions",
    "abstract": " Title: CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign  Detection Under Extreme Conditions ",
    "url": "https://arxiv.org/abs/2309.06902",
    "authors": [
      "Haoqin Hong",
      "Yue Zhou",
      "Xiangyu Shu",
      "Xiaofang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07002",
    "title": "Using Evolutionary Algorithms to Find Cache-Friendly Generalized Morton  Layouts for Arrays",
    "abstract": " Comments: Minor textual changes, update of Figure 3 to incorporate a bugfix, notational changes to Table 1, Figure 4, Table 2 (no effect on veracity), addition of artifact information ",
    "url": "https://arxiv.org/abs/2309.07002",
    "authors": [
      "Stephen Nicholas Swatman",
      "Ana-Lucia Varbanescu",
      "Andy D. Pimentel",
      "Andreas Salzburger",
      "Attila Krasznahorkay"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2309.07794",
    "title": "Improving Multimodal Classification of Social Media Posts by Leveraging  Image-Text Auxiliary Tasks",
    "abstract": " Comments: Accepted at EACL 2024 Findings ",
    "url": "https://arxiv.org/abs/2309.07794",
    "authors": [
      "Danae S\u00e1nchez Villegas",
      "Daniel Preo\u0163iuc-Pietro",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.08889",
    "title": "SafeShift: Safety-Informed Distribution Shifts for Robust Trajectory  Prediction in Autonomous Driving",
    "abstract": " Comments: 10 pages, 5 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2309.08889",
    "authors": [
      "Benjamin Stoler",
      "Ingrid Navarro",
      "Meghdeep Jana",
      "Soonmin Hwang",
      "Jonathan Francis",
      "Jean Oh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08999",
    "title": "Context-aware Adversarial Attack on Named Entity Recognition",
    "abstract": " Comments: Accepted to W-NUT at EACL 2024 ",
    "url": "https://arxiv.org/abs/2309.08999",
    "authors": [
      "Shuguang Chen",
      "Leonardo Neves",
      "Thamar Solorio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.10426",
    "title": "Multi-Object Graph Affordance Network: Enabling Goal-Oriented Planning  through Compound Object Affordances",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Submitted to Robotics and Automation Letters on February 2, 2024 ",
    "url": "https://arxiv.org/abs/2309.10426",
    "authors": [
      "Tuba Girgin",
      "Emre Ugur"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13567",
    "title": "MentaLLaMA: Interpretable Mental Health Analysis on Social Media with  Large Language Models",
    "abstract": " Comments: Accepted by WWW 2024 ",
    "url": "https://arxiv.org/abs/2309.13567",
    "authors": [
      "Kailai Yang",
      "Tianlin Zhang",
      "Ziyan Kuang",
      "Qianqian Xie",
      "Jimin Huang",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.14016",
    "title": "Virtuoso: High Resource Utilization and \u03bcs-scale Performance  Isolation in a Shared Virtual Machine TCP Network Stack",
    "abstract": " Comments: Under submission for conference peer review ",
    "url": "https://arxiv.org/abs/2309.14016",
    "authors": [
      "Matheus Stolet",
      "Liam Arzola",
      "Simon Peter",
      "Antoine Kaufmann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2309.16519",
    "title": "AtomSurf : Surface Representation for Learning on Protein Structures",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2309.16519",
    "authors": [
      "Vincent Mallet",
      "Souhaib Attaiki",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2310.05212",
    "title": "Interpretable Semiotics Networks Representing Awareness",
    "abstract": " Title: Interpretable Semiotics Networks Representing Awareness ",
    "url": "https://arxiv.org/abs/2310.05212",
    "authors": [
      "David Kupeev",
      "Eyal Nitcany"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.05453",
    "title": "Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation",
    "abstract": " Title: Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation ",
    "url": "https://arxiv.org/abs/2310.05453",
    "authors": [
      "Yuxiang Lai",
      "Yi Zhou",
      "Xinghong Liu",
      "Tao Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06112",
    "title": "Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK  Approach",
    "abstract": " Comments: In Twelfth International Conference on Learning Representations (ICLR 2024) ",
    "url": "https://arxiv.org/abs/2310.06112",
    "authors": [
      "Shaopeng Fu",
      "Di Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.06644",
    "title": "Zero-Level-Set Encoder for Neural Distance Fields",
    "abstract": " Title: Zero-Level-Set Encoder for Neural Distance Fields ",
    "url": "https://arxiv.org/abs/2310.06644",
    "authors": [
      "Stefan Rhys Jeske",
      "Jonathan Klein",
      "Dominik L. Michels",
      "Jan Bender"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.07129",
    "title": "The impact when neural min-sum variant meets ordered statistics decoding  of LDPC codes",
    "abstract": " Comments: 10 pages, 8 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2310.07129",
    "authors": [
      "Guangwen Li",
      "Xiao Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.07684",
    "title": "Hypergraph Neural Networks through the Lens of Message Passing: A Common  Perspective to Homophily and Architecture Design",
    "abstract": " Title: Hypergraph Neural Networks through the Lens of Message Passing: A Common  Perspective to Homophily and Architecture Design ",
    "url": "https://arxiv.org/abs/2310.07684",
    "authors": [
      "Lev Telyatnikov",
      "Maria Sofia Bucarelli",
      "Guillermo Bernardez",
      "Olga Zaghen",
      "Simone Scardapane",
      "Pietro Lio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.07891",
    "title": "A Theory of Non-Linear Feature Learning with One Gradient Step in  Two-Layer Neural Networks",
    "abstract": " Title: A Theory of Non-Linear Feature Learning with One Gradient Step in  Two-Layer Neural Networks ",
    "url": "https://arxiv.org/abs/2310.07891",
    "authors": [
      "Behrad Moniri",
      "Donghwan Lee",
      "Hamed Hassani",
      "Edgar Dobriban"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09486",
    "title": "Mirage: Model-Agnostic Graph Distillation for Graph Classification",
    "abstract": " Comments: 14 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2310.09486",
    "authors": [
      "Mridul Gupta",
      "Sahil Manchanda",
      "Hariprasad Kodamana",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10565",
    "title": "HelmFluid: Learning Helmholtz Dynamics for Interpretable Fluid  Prediction",
    "abstract": " Title: HelmFluid: Learning Helmholtz Dynamics for Interpretable Fluid  Prediction ",
    "url": "https://arxiv.org/abs/2310.10565",
    "authors": [
      "Lanxiang Xing",
      "Haixu Wu",
      "Yuezhou Ma",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.11334",
    "title": "Agent-Specific Effects: A Causal Effect Propagation Analysis in  Multi-Agent MDPs",
    "abstract": " Title: Agent-Specific Effects: A Causal Effect Propagation Analysis in  Multi-Agent MDPs ",
    "url": "https://arxiv.org/abs/2310.11334",
    "authors": [
      "Stelios Triantafyllou",
      "Aleksa Sukovic",
      "Debmalya Mandal",
      "Goran Radanovic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15524",
    "title": "On the Inherent Privacy Properties of Discrete Denoising Diffusion  Models",
    "abstract": " Comments: 52 pages ",
    "url": "https://arxiv.org/abs/2310.15524",
    "authors": [
      "Rongzhe Wei",
      "Eleonora Krea\u010di\u0107",
      "Haoyu Wang",
      "Haoteng Yin",
      "Eli Chien",
      "Vamsi K. Potluru",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16401",
    "title": "Graph Neural Networks with a Distribution of Parametrized Graphs",
    "abstract": " Title: Graph Neural Networks with a Distribution of Parametrized Graphs ",
    "url": "https://arxiv.org/abs/2310.16401",
    "authors": [
      "See Hian Lee",
      "Feng Ji",
      "Kelin Xia",
      "Wee Peng Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17451",
    "title": "Generating by Understanding: Neural Visual Generation with Logical  Symbol Groundings",
    "abstract": " Title: Generating by Understanding: Neural Visual Generation with Logical  Symbol Groundings ",
    "url": "https://arxiv.org/abs/2310.17451",
    "authors": [
      "Yifei Peng",
      "Yu Jin",
      "Zhexu Luo",
      "Yao-Xiang Ding",
      "Wang-Zhou Dai",
      "Zhong Ren",
      "Kun Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.18384",
    "title": "MicroNAS: Memory and Latency Constrained Hardware-Aware Neural  Architecture Search for Time Series Classification on Microcontrollers",
    "abstract": " Title: MicroNAS: Memory and Latency Constrained Hardware-Aware Neural  Architecture Search for Time Series Classification on Microcontrollers ",
    "url": "https://arxiv.org/abs/2310.18384",
    "authors": [
      "Tobias King",
      "Yexu Zhou",
      "Tobias R\u00f6ddiger",
      "Michael Beigl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18936",
    "title": "Adversarial Examples Are Not Real Features",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.18936",
    "authors": [
      "Ang Li",
      "Yifei Wang",
      "Yiwen Guo",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18961",
    "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection",
    "abstract": " Title: AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2310.18961",
    "authors": [
      "Qihang Zhou",
      "Guansong Pang",
      "Yu Tian",
      "Shibo He",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01441",
    "title": "Distilling Out-of-Distribution Robustness from Vision-Language  Foundation Models",
    "abstract": " Comments: Published in NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2311.01441",
    "authors": [
      "Andy Zhou",
      "Jindong Wang",
      "Yu-Xiong Wang",
      "Haohan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.02467",
    "title": "Individualized Policy Evaluation and Learning under Clustered Network  Interference",
    "abstract": " Title: Individualized Policy Evaluation and Learning under Clustered Network  Interference ",
    "url": "https://arxiv.org/abs/2311.02467",
    "authors": [
      "Yi Zhang",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2311.03415",
    "title": "PowerFlowNet: Power Flow Approximation Using Message Passing Graph  Neural Networks",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2311.03415",
    "authors": [
      "Nan Lin",
      "Stavros Orfanoudakis",
      "Nathan Ordonez Cardenas",
      "Juan S. Giraldo",
      "Pedro P. Vergara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.10246",
    "title": "Surprisal Driven $k$-NN for Robust and Interpretable Nonparametric  Learning",
    "abstract": " Title: Surprisal Driven $k$-NN for Robust and Interpretable Nonparametric  Learning ",
    "url": "https://arxiv.org/abs/2311.10246",
    "authors": [
      "Amartya Banerjee",
      "Christopher J. Hazard",
      "Jacob Beel",
      "Cade Mack",
      "Jack Xia",
      "Michael Resnick",
      "Will Goddin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.10642",
    "title": "Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as  an Alternative to Attention Layers in Transformers",
    "abstract": " Comments: Accepted at AAAI24(this https URL) ",
    "url": "https://arxiv.org/abs/2311.10642",
    "authors": [
      "Vukasin Bozic",
      "Danilo Dordevic",
      "Daniele Coppola",
      "Joseph Thommes",
      "Sidak Pal Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11514",
    "title": "HexGen: Generative Inference of Large-Scale Foundation Model over  Heterogeneous Decentralized Environment",
    "abstract": " Title: HexGen: Generative Inference of Large-Scale Foundation Model over  Heterogeneous Decentralized Environment ",
    "url": "https://arxiv.org/abs/2311.11514",
    "authors": [
      "Youhe Jiang",
      "Ran Yan",
      "Xiaozhe Yao",
      "Yang Zhou",
      "Beidi Chen",
      "Binhang Yuan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.12267",
    "title": "Learning Causal Representations from General Environments:  Identifiability and Intrinsic Ambiguity",
    "abstract": " Comments: 42 pages ",
    "url": "https://arxiv.org/abs/2311.12267",
    "authors": [
      "Jikai Jin",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.14736",
    "title": "Data Diversity Matters for Robust Instruction Tuning",
    "abstract": " Comments: 22 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2311.14736",
    "authors": [
      "Alexander Bukharin",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16148",
    "title": "Univariate Radial Basis Function Layers: Brain-inspired Deep Neural  Layers for Low-Dimensional Inputs",
    "abstract": " Title: Univariate Radial Basis Function Layers: Brain-inspired Deep Neural  Layers for Low-Dimensional Inputs ",
    "url": "https://arxiv.org/abs/2311.16148",
    "authors": [
      "Daniel Jost",
      "Basavasagar Patil",
      "Xavier Alameda-Pineda",
      "Chris Reinke"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17936",
    "title": "Diagnostics Using Nuclear Plant Cyber Attack Analysis Toolkit",
    "abstract": " Comments: Paper has been submitted to ANS for review ",
    "url": "https://arxiv.org/abs/2311.17936",
    "authors": [
      "Japan K. Patel",
      "Athi Varuttamaseni",
      "Robert W. Youngblood III",
      "John C. Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.18022",
    "title": "Compelling ReLU Network Initialization and Training to Leverage  Exponential Scaling with Depth",
    "abstract": " Comments: 13 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2311.18022",
    "authors": [
      "Max Milkert",
      "David Hyde",
      "Forrest Laine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01187",
    "title": "SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer",
    "abstract": " Title: SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer ",
    "url": "https://arxiv.org/abs/2312.01187",
    "authors": [
      "Renan A. Rojas-Gomez",
      "Karan Singhal",
      "Ali Etemad",
      "Alex Bijamov",
      "Warren R. Morningstar",
      "Philip Andrew Mansfield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.03885",
    "title": "Adapting Newton's Method to Neural Networks through a Summary of  Higher-Order Derivatives",
    "abstract": " Title: Adapting Newton's Method to Neural Networks through a Summary of  Higher-Order Derivatives ",
    "url": "https://arxiv.org/abs/2312.03885",
    "authors": [
      "Pierre Wolinski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2312.04693",
    "title": "GraphMETRO: Mitigating Complex Graph Distribution Shifts via Mixture of  Aligned Experts",
    "abstract": " Comments: Graph Neural Networks, Mixture-of-experts, Distribution Shifts, Generalization ",
    "url": "https://arxiv.org/abs/2312.04693",
    "authors": [
      "Shirley Wu",
      "Kaidi Cao",
      "Bruno Ribeiro",
      "James Zou",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06825",
    "title": "Utilization of Non-verbal Behaviour and Social Gaze in Classroom  Human-Robot Interaction Communications",
    "abstract": " Comments: In WTF Workshop Proceedings (arXiv:2401.04108) held in conjunction with the ACM conference on Conversational User Interfaces (CUI), 19 - 21/07 2023, in Eindhoven, The Netherlands ",
    "url": "https://arxiv.org/abs/2312.06825",
    "authors": [
      "Sahand Shaghaghi",
      "Pourya Aliasghari",
      "Bryan Tripp",
      "Kerstin Dautenhahn",
      "Chrystopher Nehaniv"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.08983",
    "title": "Interactive Humanoid: Online Full-Body Motion Reaction Synthesis with  Social Affordance Canonicalization and Forecasting",
    "abstract": " Title: Interactive Humanoid: Online Full-Body Motion Reaction Synthesis with  Social Affordance Canonicalization and Forecasting ",
    "url": "https://arxiv.org/abs/2312.08983",
    "authors": [
      "Yunze Liu",
      "Changxi Chen",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.11282",
    "title": "Evaluating and Enhancing Large Language Models for Conversational  Reasoning on Knowledge Graphs",
    "abstract": " Title: Evaluating and Enhancing Large Language Models for Conversational  Reasoning on Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2312.11282",
    "authors": [
      "Yuxuan Huang",
      "Lida Shi",
      "Anqi Liu",
      "Hao Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.11872",
    "title": "Beyond Prototypes: Semantic Anchor Regularization for Better  Representation Learning",
    "abstract": " Comments: AAAI 2024 ",
    "url": "https://arxiv.org/abs/2312.11872",
    "authors": [
      "Yanqi Ge",
      "Qiang Nie",
      "Ye Huang",
      "Yong Liu",
      "Chengjie Wang",
      "Feng Zheng",
      "Wen Li",
      "Lixin Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.16046",
    "title": "AdaNAS: Adaptively Post-processing with Self-supervised Neural  Architecture Search for Ensemble Rainfall Forecasts",
    "abstract": " Title: AdaNAS: Adaptively Post-processing with Self-supervised Neural  Architecture Search for Ensemble Rainfall Forecasts ",
    "url": "https://arxiv.org/abs/2312.16046",
    "authors": [
      "Yingpeng Wen",
      "Weijiang Yu",
      "Fudan Zheng",
      "Dan Huang",
      "Nong Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2312.17683",
    "title": "Malware Detection in IOT Systems Using Machine Learning Techniques",
    "abstract": " Title: Malware Detection in IOT Systems Using Machine Learning Techniques ",
    "url": "https://arxiv.org/abs/2312.17683",
    "authors": [
      "Ali Mehrban",
      "Pegah Ahadian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2401.01836",
    "title": "Neural Control: Concurrent System Identification and Control Learning  with Neural ODE",
    "abstract": " Comments: 9 pages, code open sourced in format of Google Colab notebooks; Resubmitted for adding missed references in the last submission ",
    "url": "https://arxiv.org/abs/2401.01836",
    "authors": [
      "Cheng Chi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.02130",
    "title": "Spectral-Based Graph Neural Networks for Complementary Item  Recommendation",
    "abstract": " Comments: Accepted by AAAI-24 ",
    "url": "https://arxiv.org/abs/2401.02130",
    "authors": [
      "Haitong Luo",
      "Xuying Meng",
      "Suhang Wang",
      "Hanyun Cao",
      "Weiyao Zhang",
      "Yequan Wang",
      "Yujun Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.02378",
    "title": "Opinion formation in the world trade network",
    "abstract": " Comments: 16 pages, 19 figures (including 9 figures present in Appendix section) and 1 table ",
    "url": "https://arxiv.org/abs/2401.02378",
    "authors": [
      "C\u00e9lestin Coquid\u00e9",
      "Jos\u00e9 Lages",
      "Dima L. Shepelyansky"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2401.05043",
    "title": "CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation  in Classification Tasks",
    "abstract": " Title: CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation  in Classification Tasks ",
    "url": "https://arxiv.org/abs/2401.05043",
    "authors": [
      "Kaizheng Wang",
      "Keivan Shariatmadar",
      "Shireen Kudukkil Manchingal",
      "Fabio Cuzzolin",
      "David Moens",
      "Hans Hallez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.05738",
    "title": "LKCA: Large Kernel Convolutional Attention",
    "abstract": " Title: LKCA: Large Kernel Convolutional Attention ",
    "url": "https://arxiv.org/abs/2401.05738",
    "authors": [
      "Chenghao Li",
      "Boheng Zeng",
      "Yi Lu",
      "Pengbo Shi",
      "Qingzi Chen",
      "Jirui Liu",
      "Lingyun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.07402",
    "title": "Improved Implicit Neural Representation with Fourier Bases  Reparameterized Training",
    "abstract": " Title: Improved Implicit Neural Representation with Fourier Bases  Reparameterized Training ",
    "url": "https://arxiv.org/abs/2401.07402",
    "authors": [
      "Kexuan Shi",
      "Xingyu Zhou",
      "Shuhang Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.08035",
    "title": "BanglaNet: Bangla Handwritten Character Recognition using Ensembling of  Convolutional Neural Network",
    "abstract": " Title: BanglaNet: Bangla Handwritten Character Recognition using Ensembling of  Convolutional Neural Network ",
    "url": "https://arxiv.org/abs/2401.08035",
    "authors": [
      "Chandrika Saha",
      "Md Mostafijur Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.08224",
    "title": "Privacy Preserving Adaptive Experiment Design",
    "abstract": " Comments: Add a table ",
    "url": "https://arxiv.org/abs/2401.08224",
    "authors": [
      "Jiachun Li",
      "Kaining Shi",
      "David Simchi-Levi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.08875",
    "title": "DCRMTA: Unbiased Causal Representation for Multi-touch Attribution",
    "abstract": " Comments: 9 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2401.08875",
    "authors": [
      "Jiaming Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2401.10244",
    "title": "Knowledge Graph Driven Recommendation System Algorithm",
    "abstract": " Title: Knowledge Graph Driven Recommendation System Algorithm ",
    "url": "https://arxiv.org/abs/2401.10244",
    "authors": [
      "Chaoyang Zhang",
      "Yanan Li",
      "Shen Chen",
      "Siwei Fan",
      "Wei Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.11373",
    "title": "Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing  Approach For Uncovering Edge Cases with Minimal Distribution Distortion",
    "abstract": " Comments: EACL 2024 - Main conference - Camera ready version ",
    "url": "https://arxiv.org/abs/2401.11373",
    "authors": [
      "Aly M. Kassem",
      "Sherif Saad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.11511",
    "title": "MobileARLoc: On-device Robust Absolute Localisation for Pervasive  Markerless Mobile AR",
    "abstract": " Comments: Accepted for publication at the 3rd edition of the Pervasive and Resource-Constrained AI (PerConAI) workshop (co-located with PerCom 2024). This article supersedes arXiv:2308.05394 ",
    "url": "https://arxiv.org/abs/2401.11511",
    "authors": [
      "Changkun Liu",
      "Yukun Zhao",
      "Tristan Braud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.14005",
    "title": "Cyber-Twin: Digital Twin-boosted Autonomous Attack Detection for  Vehicular Ad-Hoc Networks",
    "abstract": " Comments: 6 pages, 6 figures, IEEE International Conference on Communications (ICC) 2024 ",
    "url": "https://arxiv.org/abs/2401.14005",
    "authors": [
      "Yagmur Yigit",
      "Ioannis Panitsas",
      "Leandros Maglaras",
      "Leandros Tassiulas",
      "Berk Canberk"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.14580",
    "title": "Design Your Own Universe: A Physics-Informed Agnostic Method for  Enhancing Graph Neural Networks",
    "abstract": " Title: Design Your Own Universe: A Physics-Informed Agnostic Method for  Enhancing Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2401.14580",
    "authors": [
      "Dai Shi",
      "Andi Han",
      "Lequan Lin",
      "Yi Guo",
      "Zhiyong Wang",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.14705",
    "title": "Additional Look into GAN-based Augmentation for Deep Learning COVID-19  Image Classification",
    "abstract": " Comments: Submitted to Machine Graphics & Vision. Version with updated acknowledgments ",
    "url": "https://arxiv.org/abs/2401.14705",
    "authors": [
      "Oleksandr Fedoruk",
      "Konrad Klimaszewski",
      "Aleksander Ogonowski",
      "Micha\u0142 Kruk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.14999",
    "title": "The causal role of the Reddit collective action on the GameStop short  squeeze",
    "abstract": " Title: The causal role of the Reddit collective action on the GameStop short  squeeze ",
    "url": "https://arxiv.org/abs/2401.14999",
    "authors": [
      "Antonio Desiderio",
      "Luca Maria Aiello",
      "Giulio Cimini",
      "Laura Alessandretti"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.15222",
    "title": "Transfer Learning for the Prediction of Entity Modifiers in Clinical  Text: Application to Opioid Use Disorder Case Detection",
    "abstract": " Comments: 18 pages, 2 figures, 6 tables. To be submitted to the Journal of Biomedical Semantics ",
    "url": "https://arxiv.org/abs/2401.15222",
    "authors": [
      "Abdullateef I. Almudaifer",
      "Whitney Covington",
      "JaMor Hairston",
      "Zachary Deitch",
      "Ankit Anand",
      "Caleb M. Carroll",
      "Estera Crisan",
      "William Bradford",
      "Lauren Walter",
      "Eaton Ellen",
      "Sue S. Feldman",
      "John D. Osborne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.15285",
    "title": "Ransomware threat mitigation through network traffic analysis and  machine learning techniques",
    "abstract": " Title: Ransomware threat mitigation through network traffic analysis and  machine learning techniques ",
    "url": "https://arxiv.org/abs/2401.15285",
    "authors": [
      "Ali Mehrban",
      "Shirin Karimi Geransayeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.15313",
    "title": "Multi-Robot Relative Pose Estimation in SE(2) with Observability  Analysis: A Comparison of Extended Kalman Filtering and Robust Pose Graph  Optimization",
    "abstract": " Comments: 20 pages, 21 figures ",
    "url": "https://arxiv.org/abs/2401.15313",
    "authors": [
      "Kihoon Shin",
      "Hyunjae Sim",
      "Seungwon Nam",
      "Yonghee Kim",
      "Jae Hu",
      "Kwang-Ki K. Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2401.15906",
    "title": "Mean Estimation with User-Level Privacy for Spatio-Temporal IoT Datasets",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2401.15906",
    "authors": [
      "V. Arvind Rameshwar",
      "Anshoo Tandon",
      "Prajjwal Gupta",
      "Novoneel Chakraborty",
      "Abhay Sharma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2401.16808",
    "title": "Encoding Temporal Statistical-space Priors via Augmented Representation",
    "abstract": " Comments: pre-print ",
    "url": "https://arxiv.org/abs/2401.16808",
    "authors": [
      "Insu Choi",
      "Woosung Koh",
      "Gimin Kang",
      "Yuntae Jang",
      "Woo Chang Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.17219",
    "title": "Faster coloring and embedding in dense hypergraphs via stability",
    "abstract": " Comments: added a new statement in THM 1.2, fixed some typo, added a new reference ",
    "url": "https://arxiv.org/abs/2401.17219",
    "authors": [
      "Jianfeng Hou",
      "Xizhi Liu",
      "Hongbin Zhao"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2401.17263",
    "title": "Robust Prompt Optimization for Defending Language Models Against  Jailbreaking Attacks",
    "abstract": " Comments: website and code available at this https URL ",
    "url": "https://arxiv.org/abs/2401.17263",
    "authors": [
      "Andy Zhou",
      "Bo Li",
      "Haohan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.17612",
    "title": "IGCN: Integrative Graph Convolutional Networks for Multi-modal Data",
    "abstract": " Title: IGCN: Integrative Graph Convolutional Networks for Multi-modal Data ",
    "url": "https://arxiv.org/abs/2401.17612",
    "authors": [
      "Cagri Ozdemir",
      "Mohammad Al Olaimat",
      "Yashu Vashishath",
      "Serdar Bozdag",
      "Alzheimer's Disease Neuroimaging Initiative"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00024",
    "title": "Comparative Analysis of LLaMA and ChatGPT Embeddings for Molecule  Embedding",
    "abstract": " Title: Comparative Analysis of LLaMA and ChatGPT Embeddings for Molecule  Embedding ",
    "url": "https://arxiv.org/abs/2402.00024",
    "authors": [
      "Shaghayegh Sadeghi",
      "Alan Bui",
      "Ali Forooghi",
      "Jianguo Lu",
      "Alioune Ngom"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00672",
    "title": "Exploring Homogeneous and Heterogeneous Consistent Label Associations  for Unsupervised Visible-Infrared Person ReID",
    "abstract": " Title: Exploring Homogeneous and Heterogeneous Consistent Label Associations  for Unsupervised Visible-Infrared Person ReID ",
    "url": "https://arxiv.org/abs/2402.00672",
    "authors": [
      "Lingfeng He",
      "De Cheng",
      "Nannan Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00861",
    "title": "Evaluating Large Language Models for Generalization and Robustness via  Data Compression",
    "abstract": " Title: Evaluating Large Language Models for Generalization and Robustness via  Data Compression ",
    "url": "https://arxiv.org/abs/2402.00861",
    "authors": [
      "Yucheng Li",
      "Yunhao Guo",
      "Frank Guerin",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01204",
    "title": "A Survey on Self-Supervised Learning for Non-Sequential Tabular Data",
    "abstract": " Comments: The paper list can be found at this https URL ",
    "url": "https://arxiv.org/abs/2402.01204",
    "authors": [
      "Wei-Yao Wang",
      "Wei-Wei Du",
      "Derek Xu",
      "Wei Wang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01207",
    "title": "Efficient Causal Graph Discovery Using Large Language Models",
    "abstract": " Title: Efficient Causal Graph Discovery Using Large Language Models ",
    "url": "https://arxiv.org/abs/2402.01207",
    "authors": [
      "Thomas Jiralerspong",
      "Xiaoyin Chen",
      "Yash More",
      "Vedant Shah",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.01304",
    "title": "Phrase Grounding-based Style Transfer for Single-Domain Generalized  Object Detection",
    "abstract": " Comments: 16 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2402.01304",
    "authors": [
      "Hao Li",
      "Wei Wang",
      "Cong Wang",
      "Zhigang Luo",
      "Xinwang Liu",
      "Kenli Li",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01313",
    "title": "AutoGCN -- Towards Generic Human Activity Recognition with Neural  Architecture Search",
    "abstract": " Title: AutoGCN -- Towards Generic Human Activity Recognition with Neural  Architecture Search ",
    "url": "https://arxiv.org/abs/2402.01313",
    "authors": [
      "Felix Tempel",
      "Inga Str\u00fcmke",
      "Espen Alexander F. Ihlen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01391",
    "title": "StepCoder: Improve Code Generation with Reinforcement Learning from  Compiler Feedback",
    "abstract": " Comments: 13 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2402.01391",
    "authors": [
      "Shihan Dou",
      "Yan Liu",
      "Haoxiang Jia",
      "Limao Xiong",
      "Enyu Zhou",
      "Wei Shen",
      "Junjie Shan",
      "Caishuang Huang",
      "Xiao Wang",
      "Xiaoran Fan",
      "Zhiheng Xi",
      "Yuhao Zhou",
      "Tao Ji",
      "Rui Zheng",
      "Qi Zhang",
      "Xuanjing Huang",
      "Tao Gui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  }
]