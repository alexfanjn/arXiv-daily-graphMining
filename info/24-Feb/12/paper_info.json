[
  {
    "id": "arXiv:2402.05939",
    "title": "Uncertainty Awareness of Large Language Models Under Code Distribution  Shifts: A Benchmark Study",
    "abstract": "Large Language Models (LLMs) have been widely employed in programming language analysis to enhance human productivity. Yet, their reliability can be compromised by various code distribution shifts, leading to inconsistent outputs. While probabilistic methods are known to mitigate such impact through uncertainty calibration and estimation, their efficacy in the language domain remains underexplored compared to their application in image-based tasks. In this work, we first introduce a large-scale benchmark dataset, incorporating three realistic patterns of code distribution shifts at varying intensities. Then we thoroughly investigate state-of-the-art probabilistic methods applied to CodeLlama using these shifted code snippets. We observe that these methods generally improve the uncertainty awareness of CodeLlama, with increased calibration quality and higher uncertainty estimation~(UE) precision. However, our study further reveals varied performance dynamics across different criteria (e.g., calibration error vs misclassification detection) and trade-off between efficacy and efficiency, highlighting necessary methodological selection tailored to specific contexts. ",
    "url": "https://arxiv.org/abs/2402.05939",
    "authors": [
      "Yufei Li",
      "Simin Chen",
      "Yanghong Guo",
      "Wei Yang",
      "Yue Dong",
      "Cong Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.05940",
    "title": "Causal Relationship Network of Risk Factors Impacting Workday Loss in  Underground Coal Mines",
    "abstract": "This study aims to establish the causal relationship network between various factors leading to workday loss in underground coal mines using a novel causal artificial intelligence (AI) method. The analysis utilizes data obtained from the National Institute for Occupational Safety and Health (NIOSH). A total of 101,010 injury records from 3,982 unique underground coal mines spanning the years from 1990 to 2020 were extracted from the NIOSH database. Causal relationships were analyzed and visualized using a novel causal AI method called Grouped Greedy Equivalence Search (GGES). The impact of each variable on workday loss was assessed through intervention do-calculus adjustment (IDA) scores. Model training and validation were performed using the 10-fold cross-validation technique. Performance metrics, including adjacency precision (AP), adjacency recall (AR), arrowhead precision (AHP), and arrowhead recall (AHR), were utilized to evaluate the models. Findings revealed that after 2006, key direct causes of workday loss among mining employees included total mining experience, mean office employees, mean underground employees, county, and total mining experience (years). Total mining experience emerged as the most influential factor, whereas mean employees per mine exhibited the least influence. The analyses emphasized the significant role of total mining experience in determining workday loss. The models achieved optimal performance, with AP, AR, AHP, and AHR values measuring 0.694, 0.653, 0.386, and 0.345, respectively. This study demonstrates the feasibility of utilizing the new GGES method to clarify the causal factors behind the workday loss by analyzing employment demographics and injury records and establish their causal relationship network. ",
    "url": "https://arxiv.org/abs/2402.05940",
    "authors": [
      "Shangsi Ren",
      "Cameron A. Beeche",
      "Zhiyi Shi",
      "Maria Acevedo Garcia",
      "Katherine Zychowski",
      "Shuguang Leng",
      "Pedram Roghanchi",
      "Jiantao Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.05943",
    "title": "A hybrid IndRNNLSTM approach for real-time anomaly detection in  software-defined networks",
    "abstract": "Anomaly detection in SDN using data flow prediction is a difficult task. This problem is included in the category of time series and regression problems. Machine learning approaches are challenging in this field due to the manual selection of features. On the other hand, deep learning approaches have important features due to the automatic selection of features. Meanwhile, RNN-based approaches have been used the most. The LSTM and GRU approaches learn dependent entities well; on the other hand, the IndRNN approach learns non-dependent entities in time series. The proposed approach tried to use a combination of IndRNN and LSTM approaches to learn dependent and non-dependent features. Feature selection approaches also provide a suitable view of features for the models; for this purpose, four feature selection models, Filter, Wrapper, Embedded, and Autoencoder were used. The proposed IndRNNLSTM algorithm, in combination with Embedded, was able to achieve MAE=1.22 and RMSE=9.92 on NSL-KDD data. ",
    "url": "https://arxiv.org/abs/2402.05943",
    "authors": [
      "Sajjad Salem",
      "Salman Asoudeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.05944",
    "title": "Todyformer: Towards Holistic Dynamic Graph Transformers with  Structure-Aware Tokenization",
    "abstract": "Temporal Graph Neural Networks have garnered substantial attention for their capacity to model evolving structural and temporal patterns while exhibiting impressive performance. However, it is known that these architectures are encumbered by issues that constrain their performance, such as over-squashing and over-smoothing. Meanwhile, Transformers have demonstrated exceptional computational capacity to effectively address challenges related to long-range dependencies. Consequently, we introduce Todyformer-a novel Transformer-based neural network tailored for dynamic graphs. It unifies the local encoding capacity of Message-Passing Neural Networks (MPNNs) with the global encoding of Transformers through i) a novel patchifying paradigm for dynamic graphs to improve over-squashing, ii) a structure-aware parametric tokenization strategy leveraging MPNNs, iii) a Transformer with temporal positional-encoding to capture long-range dependencies, and iv) an encoding architecture that alternates between local and global contextualization, mitigating over-smoothing in MPNNs. Experimental evaluations on public benchmark datasets demonstrate that Todyformer consistently outperforms the state-of-the-art methods for downstream tasks. Furthermore, we illustrate the underlying aspects of the proposed model in effectively capturing extensive temporal dependencies in dynamic graphs. ",
    "url": "https://arxiv.org/abs/2402.05944",
    "authors": [
      "Mahdi Biparva",
      "Raika Karimi",
      "Faezeh Faez",
      "Yingxue Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.05946",
    "title": "Unveiling Latent Causal Rules: A Temporal Point Process Approach for  Abnormal Event Explanation",
    "abstract": "In high-stakes systems such as healthcare, it is critical to understand the causal reasons behind unusual events, such as sudden changes in patient's health. Unveiling the causal reasons helps with quick diagnoses and precise treatment planning. In this paper, we propose an automated method for uncovering \"if-then\" logic rules to explain observational events. We introduce temporal point processes to model the events of interest, and discover the set of latent rules to explain the occurrence of events. To achieve this, we employ an Expectation-Maximization (EM) algorithm. In the E-step, we calculate the likelihood of each event being explained by each discovered rule. In the M-step, we update both the rule set and model parameters to enhance the likelihood function's lower bound. Notably, we optimize the rule set in a differential manner. Our approach demonstrates accurate performance in both discovering rules and identifying root causes. We showcase its promising results using synthetic and real healthcare datasets. ",
    "url": "https://arxiv.org/abs/2402.05946",
    "authors": [
      "Yiling Kuang",
      "Chao Yang",
      "Yang Yang",
      "Shuang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05948",
    "title": "DE$^3$-BERT: Distance-Enhanced Early Exiting for BERT based on  Prototypical Networks",
    "abstract": "Early exiting has demonstrated its effectiveness in accelerating the inference of pre-trained language models like BERT by dynamically adjusting the number of layers executed. However, most existing early exiting methods only consider local information from an individual test sample to determine their exiting indicators, failing to leverage the global information offered by sample population. This leads to suboptimal estimation of prediction correctness, resulting in erroneous exiting decisions. To bridge the gap, we explore the necessity of effectively combining both local and global information to ensure reliable early exiting during inference. Purposefully, we leverage prototypical networks to learn class prototypes and devise a distance metric between samples and class prototypes. This enables us to utilize global information for estimating the correctness of early predictions. On this basis, we propose a novel Distance-Enhanced Early Exiting framework for BERT (DE$^3$-BERT). DE$^3$-BERT implements a hybrid exiting strategy that supplements classic entropy-based local information with distance-based global information to enhance the estimation of prediction correctness for more reliable early exiting decisions. Extensive experiments on the GLUE benchmark demonstrate that DE$^3$-BERT consistently outperforms state-of-the-art models under different speed-up ratios with minimal storage or computational overhead, yielding a better trade-off between model performance and inference efficiency. Additionally, an in-depth analysis further validates the generality and interpretability of our method. ",
    "url": "https://arxiv.org/abs/2402.05948",
    "authors": [
      "Jianing He",
      "Qi Zhang",
      "Weiping Ding",
      "Duoqian Miao",
      "Jun Zhao",
      "Liang Hu",
      "Longbing Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.05952",
    "title": "Advancing Graph Representation Learning with Large Language Models: A  Comprehensive Survey of Techniques",
    "abstract": "The integration of Large Language Models (LLMs) with Graph Representation Learning (GRL) marks a significant evolution in analyzing complex data structures. This collaboration harnesses the sophisticated linguistic capabilities of LLMs to improve the contextual understanding and adaptability of graph models, thereby broadening the scope and potential of GRL. Despite a growing body of research dedicated to integrating LLMs into the graph domain, a comprehensive review that deeply analyzes the core components and operations within these models is notably lacking. Our survey fills this gap by proposing a novel taxonomy that breaks down these models into primary components and operation techniques from a novel technical perspective. We further dissect recent literature into two primary components including knowledge extractors and organizers, and two operation techniques including integration and training stratigies, shedding light on effective model design and training strategies. Additionally, we identify and explore potential future research avenues in this nascent yet underexplored field, proposing paths for continued progress. ",
    "url": "https://arxiv.org/abs/2402.05952",
    "authors": [
      "Qiheng Mao",
      "Zemin Liu",
      "Chenghao Liu",
      "Zhuo Li",
      "Jianling Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.05962",
    "title": "EXGC: Bridging Efficiency and Explainability in Graph Condensation",
    "abstract": "Graph representation learning on vast datasets, like web data, has made significant strides. However, the associated computational and storage overheads raise concerns. In sight of this, Graph condensation (GCond) has been introduced to distill these large real datasets into a more concise yet information-rich synthetic graph. Despite acceleration efforts, existing GCond methods mainly grapple with efficiency, especially on expansive web data graphs. Hence, in this work, we pinpoint two major inefficiencies of current paradigms: (1) the concurrent updating of a vast parameter set, and (2) pronounced parameter redundancy. To counteract these two limitations correspondingly, we first (1) employ the Mean-Field variational approximation for convergence acceleration, and then (2) propose the objective of Gradient Information Bottleneck (GDIB) to prune redundancy. By incorporating the leading explanation techniques (e.g., GNNExplainer and GSAT) to instantiate the GDIB, our EXGC, the Efficient and eXplainable Graph Condensation method is proposed, which can markedly boost efficiency and inject explainability. Our extensive evaluations across eight datasets underscore EXGC's superiority and relevance. Code is available at https://github.com/MangoKiller/EXGC. ",
    "url": "https://arxiv.org/abs/2402.05962",
    "authors": [
      "Junfeng Fang",
      "Xinglin Li",
      "Yongduo Sui",
      "Yuan Gao",
      "Guibin Zhang",
      "Kun Wang",
      "Xiang Wang",
      "Xiangnan He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.05965",
    "title": "Hybrid Neural Representations for Spherical Data",
    "abstract": "In this paper, we study hybrid neural representations for spherical data, a domain of increasing relevance in scientific research. In particular, our work focuses on weather and climate data as well as comic microwave background (CMB) data. Although previous studies have delved into coordinate-based neural representations for spherical signals, they often fail to capture the intricate details of highly nonlinear signals. To address this limitation, we introduce a novel approach named Hybrid Neural Representations for Spherical data (HNeR-S). Our main idea is to use spherical feature-grids to obtain positional features which are combined with a multilayer perception to predict the target signal. We consider feature-grids with equirectangular and hierarchical equal area isolatitude pixelization structures that align with weather data and CMB data, respectively. We extensively verify the effectiveness of our HNeR-S for regression, super-resolution, temporal interpolation, and compression tasks. ",
    "url": "https://arxiv.org/abs/2402.05965",
    "authors": [
      "Hyomin Kim",
      "Yunhui Jang",
      "Jaeho Lee",
      "Sungsoo Ahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.05967",
    "title": "The last Dance : Robust backdoor attack via diffusion models and  bayesian approach",
    "abstract": "Diffusion models are state-of-the-art deep learning generative models that are trained on the principle of learning forward and backward diffusion processes via the progressive addition of noise and denoising. In this paper, we seek to trick audio-based DNN models, such as those in the Hugging Face framework, for example, those that focus on audio, in particular transformer-based artificial intelligence models, which are powerful machine learning models that save time and deliver faster, more efficient results. We demonstrate the feasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers derived from Hugging Face, a popular framework in the world of artificial intelligence (AI) research. The backdoor attack developed in this paper is based on poisoning the model's training data by incorporating backdoor diffusion sampling and a Bayesian approach to the distribution of poisoned data. ",
    "url": "https://arxiv.org/abs/2402.05967",
    "authors": [
      "Orson Mengara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.05970",
    "title": "Modeling Spatio-temporal Dynamical Systems with Neural Discrete Learning  and Levels-of-Experts",
    "abstract": "In this paper, we address the issue of modeling and estimating changes in the state of the spatio-temporal dynamical systems based on a sequence of observations like video frames. Traditional numerical simulation systems depend largely on the initial settings and correctness of the constructed partial differential equations (PDEs). Despite recent efforts yielding significant success in discovering data-driven PDEs with neural networks, the limitations posed by singular scenarios and the absence of local insights prevent them from performing effectively in a broader real-world context. To this end, this paper propose the universal expert module -- that is, optical flow estimation component, to capture the evolution laws of general physical processes in a data-driven fashion. To enhance local insight, we painstakingly design a finer-grained physical pipeline, since local characteristics may be influenced by various internal contextual information, which may contradict the macroscopic properties of the whole system. Further, we harness currently popular neural discrete learning to unveil the underlying important features in its latent space, this process better injects interpretability, which can help us obtain a powerful prior over these discrete random variables. We conduct extensive experiments and ablations to demonstrate that the proposed framework achieves large performance margins, compared with the existing SOTA baselines. ",
    "url": "https://arxiv.org/abs/2402.05970",
    "authors": [
      "Kun Wang",
      "Hao Wu",
      "Guibin Zhang",
      "Junfeng Fang",
      "Yuxuan Liang",
      "Yuankai Wu",
      "Roger Zimmermann",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05971",
    "title": "Are we making much progress? Revisiting chemical reaction yield  prediction from an imbalanced regression perspective",
    "abstract": "The yield of a chemical reaction quantifies the percentage of the target product formed in relation to the reactants consumed during the chemical reaction. Accurate yield prediction can guide chemists toward selecting high-yield reactions during synthesis planning, offering valuable insights before dedicating time and resources to wet lab experiments. While recent advancements in yield prediction have led to overall performance improvement across the entire yield range, an open challenge remains in enhancing predictions for high-yield reactions, which are of greater concern to chemists. In this paper, we argue that the performance gap in high-yield predictions results from the imbalanced distribution of real-world data skewed towards low-yield reactions, often due to unreacted starting materials and inherent ambiguities in the reaction processes. Despite this data imbalance, existing yield prediction methods continue to treat different yield ranges equally, assuming a balanced training distribution. Through extensive experiments on three real-world yield prediction datasets, we emphasize the urgent need to reframe reaction yield prediction as an imbalanced regression problem. Finally, we demonstrate that incorporating simple cost-sensitive re-weighting methods can significantly enhance the performance of yield prediction models on underrepresented high-yield regions. ",
    "url": "https://arxiv.org/abs/2402.05971",
    "authors": [
      "Yihong Ma",
      "Xiaobao Huang",
      "Bozhao Nan",
      "Nuno Moniz",
      "Xiangliang Zhang",
      "Olaf Wiest",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2402.05973",
    "title": "Blockchain-enabled Clustered and Scalable Federated Learning (BCS-FL)  Framework in UAV Networks",
    "abstract": "Privacy, scalability, and reliability are significant challenges in unmanned aerial vehicle (UAV) networks as distributed systems, especially when employing machine learning (ML) technologies with substantial data exchange. Recently, the application of federated learning (FL) to UAV networks has improved collaboration, privacy, resilience, and adaptability, making it a promising framework for UAV applications. However, implementing FL for UAV networks introduces drawbacks such as communication overhead, synchronization issues, scalability limitations, and resource constraints. To address these challenges, this paper presents the Blockchain-enabled Clustered and Scalable Federated Learning (BCS-FL) framework for UAV networks. This improves the decentralization, coordination, scalability, and efficiency of FL in large-scale UAV networks. The framework partitions UAV networks into separate clusters, coordinated by cluster head UAVs (CHs), to establish a connected graph. Clustering enables efficient coordination of updates to the ML model. Additionally, hybrid inter-cluster and intra-cluster model aggregation schemes generate the global model after each training round, improving collaboration and knowledge sharing among clusters. The numerical findings illustrate the achievement of convergence while also emphasizing the trade-offs between the effectiveness of training and communication efficiency. ",
    "url": "https://arxiv.org/abs/2402.05973",
    "authors": [
      "Sana Hafeez",
      "Lina Mohjazi",
      "Muhammad Ali Imran",
      "Yao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.05980",
    "title": "Do Large Code Models Understand Programming Concepts? A Black-box  Approach",
    "abstract": "Large Language Models' success on text generation has also made them better at code generation and coding tasks. While a lot of work has demonstrated their remarkable performance on tasks such as code completion and editing, it is still unclear as to why. We help bridge this gap by exploring to what degree auto-regressive models understand the logical constructs of the underlying programs. We propose Counterfactual Analysis for Programming Concept Predicates (CACP) as a counterfactual testing framework to evaluate whether Large Code Models understand programming concepts. With only black-box access to the model, we use CACP to evaluate ten popular Large Code Models for four different programming concepts. Our findings suggest that current models lack understanding of concepts such as data flow and control flow. ",
    "url": "https://arxiv.org/abs/2402.05980",
    "authors": [
      "Ashish Hooda",
      "Mihai Christodorescu",
      "Miltos Allamanis",
      "Aaron Wilson",
      "Kassem Fawaz",
      "Somesh Jha"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.06010",
    "title": "NPSVC++: Nonparallel Classifiers Encounter Representation Learning",
    "abstract": "This paper focuses on a specific family of classifiers called nonparallel support vector classifiers (NPSVCs). Different from typical classifiers, the training of an NPSVC involves the minimization of multiple objectives, resulting in the potential concerns of feature suboptimality and class dependency. Consequently, no effective learning scheme has been established to improve NPSVCs' performance through representation learning, especially deep learning. To break this bottleneck, we develop NPSVC++ based on multi-objective optimization, enabling the end-to-end learning of NPSVC and its features. By pursuing Pareto optimality, NPSVC++ theoretically ensures feature optimality across classes, hence effectively overcoming the two issues above. A general learning procedure via duality optimization is proposed, based on which we provide two applicable instances, K-NPSVC++ and D-NPSVC++. The experiments show their superiority over the existing methods and verify the efficacy of NPSVC++. ",
    "url": "https://arxiv.org/abs/2402.06010",
    "authors": [
      "Junhong Zhang",
      "Zhihui Lai",
      "Jie Zhou",
      "Guangfei Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.06021",
    "title": "One-Shot Coding over General Noisy Networks",
    "abstract": "We present a unified one-shot coding framework designed for communication and compression of messages among multiple nodes across a general acyclic noisy network. Our setting can be seen as a one-shot version of the acyclic discrete memoryless network studied by Lee and Chung, and noisy network coding studied by Lim, Kim, El Gamal and Chung. We design a proof technique, called the exponential process refinement lemma, that is rooted in the Poisson matching lemma by Li and Anantharam, and can significantly simplify the analyses of one-shot coding over multi-hop networks. Our one-shot coding theorem not only recovers a wide range of existing asymptotic results, but also yields novel one-shot achievability results in different multi-hop network information theory problems. In a broader context, our framework provides a unified one-shot bound applicable to any combination of source coding, channel coding and coding for computing problems. ",
    "url": "https://arxiv.org/abs/2402.06021",
    "authors": [
      "Yanxiao Liu",
      "Cheuk Ting Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.06030",
    "title": "Game-theoretic Counterfactual Explanation for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have been a powerful tool for node classification tasks in complex networks. However, their decision-making processes remain a black-box to users, making it challenging to understand the reasoning behind their predictions. Counterfactual explanations (CFE) have shown promise in enhancing the interpretability of machine learning models. Prior approaches to compute CFE for GNNS often are learning-based approaches that require training additional graphs. In this paper, we propose a semivalue-based, non-learning approach to generate CFE for node classification tasks, eliminating the need for any additional training. Our results reveals that computing Banzhaf values requires lower sample complexity in identifying the counterfactual explanations compared to other popular methods such as computing Shapley values. Our empirical evidence indicates computing Banzhaf values can achieve up to a fourfold speed up compared to Shapley values. We also design a thresholding method for computing Banzhaf values and show theoretical and empirical results on its robustness in noisy environments, making it superior to Shapley values. Furthermore, the thresholded Banzhaf values are shown to enhance efficiency without compromising the quality (i.e., fidelity) in the explanations in three popular graph datasets. ",
    "url": "https://arxiv.org/abs/2402.06030",
    "authors": [
      "Chirag Chhablani",
      "Sarthak Jain",
      "Akshay Channesh",
      "Ian A. Kash",
      "Sourav Medya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06035",
    "title": "AntiCopyPaster 2.0: Whitebox just-in-time code duplicates extraction",
    "abstract": "AntiCopyPaster is an IntelliJ IDEA plugin, implemented to detect and refactor duplicate code interactively as soon as a duplicate is introduced. The plugin only recommends the extraction of a duplicate when it is worth it. In contrast to current Extract Method refactoring approaches, our tool seamlessly integrates with the developer's workflow and actively provides recommendations for refactorings. This work extends our tool to allow developers to customize the detection rules, i.e., metrics, based on their needs and preferences. The plugin and its source code are publicly available on GitHub at https://github.com/refactorings/anti-copy-paster. The demonstration video can be found on YouTube: https://youtu.be/ Y1sbfpds2Ms. ",
    "url": "https://arxiv.org/abs/2402.06035",
    "authors": [
      "Eman Abdullah AlOmar",
      "Benjamin Knobloch",
      "Thomas Kain",
      "Christopher Kalish",
      "Mohamed Wiem Mkaouer",
      "Ali Ouni"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.06062",
    "title": "Peer Expectation in Robust Forecast Aggregation: The  Possibility/Impossibility",
    "abstract": "Recently a growing literature study a new forecast aggregation setting where each forecaster is additionally asked ``what's your expectation for the average of other forecasters' forecasts?''. However, most theoretic results in this setting focus on the scenarios where the additional second-order information helps optimally aggregate the forecasts. Here we adopt an adversarial approach and follow the robust forecast aggregation framework proposed by Arielia, Babichenkoa, and Smorodinsky 2018. We delicately analyze the possibility/impossibility of the new setting when there are two forecasters that either are refinement-ordered or receive conditionally independent and identically distributed (c.i.i.d.) signals. We also extend the setting to a higher level of expectation setting where we can additionally ask ``what's your expectation for the other forecaster's expectation for ...''. The results show that in the above settings, the additional second-order information can significantly improve the aggregation accuracy, and the higher the order, the higher the improvement. ",
    "url": "https://arxiv.org/abs/2402.06062",
    "authors": [
      "Yuqing Kong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2402.06078",
    "title": "Gaussian Mixture Models for Affordance Learning using Bayesian Networks",
    "abstract": "Affordances are fundamental descriptors of relationships between actions, objects and effects. They provide the means whereby a robot can predict effects, recognize actions, select objects and plan its behavior according to desired goals. This paper approaches the problem of an embodied agent exploring the world and learning these affordances autonomously from its sensory experiences. Models exist for learning the structure and the parameters of a Bayesian Network encoding this knowledge. Although Bayesian Networks are capable of dealing with uncertainty and redundancy, previous work considered complete observability of the discrete sensory data, which may lead to hard errors in the presence of noise. In this paper we consider a probabilistic representation of the sensors by Gaussian Mixture Models (GMMs) and explicitly taking into account the probability distribution contained in each discrete affordance concept, which can lead to a more correct learning. ",
    "url": "https://arxiv.org/abs/2402.06078",
    "authors": [
      "Pedro Os\u00f3rio",
      "Alexandre Bernardino",
      "Ruben Martinez-Cantin",
      "Jos\u00e9 Santos-Victor"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06087",
    "title": "Descriptive Kernel Convolution Network with Improved Random Walk Kernel",
    "abstract": "Graph kernels used to be the dominant approach to feature engineering for structured data, which are superseded by modern GNNs as the former lacks learnability. Recently, a suite of Kernel Convolution Networks (KCNs) successfully revitalized graph kernels by introducing learnability, which convolves input with learnable hidden graphs using a certain graph kernel. The random walk kernel (RWK) has been used as the default kernel in many KCNs, gaining increasing attention. In this paper, we first revisit the RWK and its current usage in KCNs, revealing several shortcomings of the existing designs, and propose an improved graph kernel RWK+, by introducing color-matching random walks and deriving its efficient computation. We then propose RWK+CN, a KCN that uses RWK+ as the core kernel to learn descriptive graph features with an unsupervised objective, which can not be achieved by GNNs. Further, by unrolling RWK+, we discover its connection with a regular GCN layer, and propose a novel GNN layer RWK+Conv. In the first part of experiments, we demonstrate the descriptive learning ability of RWK+CN with the improved random walk kernel RWK+ on unsupervised pattern mining tasks; in the second part, we show the effectiveness of RWK+ for a variety of KCN architectures and supervised graph learning tasks, and demonstrate the expressiveness of RWK+Conv layer, especially on the graph-level tasks. RWK+ and RWK+Conv adapt to various real-world applications, including web applications such as bot detection in a web-scale Twitter social network, and community classification in Reddit social interaction networks. ",
    "url": "https://arxiv.org/abs/2402.06087",
    "authors": [
      "Meng-Chieh Lee",
      "Lingxiao Zhao",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06098",
    "title": "Veni, Vidi, Vici: Solving the Myriad of Challenges before Knowledge  Graph Learning",
    "abstract": "Knowledge Graphs (KGs) have become increasingly common for representing large-scale linked data. However, their immense size has required graph learning systems to assist humans in analysis, interpretation, and pattern detection. While there have been promising results for researcher- and clinician- empowerment through a variety of KG learning systems, we identify four key deficiencies in state-of-the-art graph learning that simultaneously limit KG learning performance and diminish the ability of humans to interface optimally with these learning systems. These deficiencies are: 1) lack of expert knowledge integration, 2) instability to node degree extremity in the KG, 3) lack of consideration for uncertainty and relevance while learning, and 4) lack of explainability. Furthermore, we characterise state-of-the-art attempts to solve each of these problems and note that each attempt has largely been isolated from attempts to solve the other problems. Through a formalisation of these problems and a review of the literature that addresses them, we adopt the position that not only are deficiencies in these four key areas holding back human-KG empowerment, but that the divide-and-conquer approach to solving these problems as individual units rather than a whole is a significant barrier to the interface between humans and KG learning systems. We propose that it is only through integrated, holistic solutions to the limitations of KG learning systems that human and KG learning co-empowerment will be efficiently affected. We finally present our \"Veni, Vidi, Vici\" framework that sets a roadmap for effectively and efficiently shifting to a holistic co-empowerment model in both the KG learning and the broader machine learning domain. ",
    "url": "https://arxiv.org/abs/2402.06098",
    "authors": [
      "Jeffrey Sardina",
      "Luca Costabello",
      "Christophe Gu\u00e9ret"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06107",
    "title": "Multiple Instance Learning for Cheating Detection and Localization in  Online Examinations",
    "abstract": "The spread of the Coronavirus disease-2019 epidemic has caused many courses and exams to be conducted online. The cheating behavior detection model in examination invigilation systems plays a pivotal role in guaranteeing the equality of long-distance examinations. However, cheating behavior is rare, and most researchers do not comprehensively take into account features such as head posture, gaze angle, body posture, and background information in the task of cheating behavior detection. In this paper, we develop and present CHEESE, a CHEating detection framework via multiplE inStancE learning. The framework consists of a label generator that implements weak supervision and a feature encoder to learn discriminative features. In addition, the framework combines body posture and background features extracted by 3D convolution with eye gaze, head posture and facial features captured by OpenFace 2.0. These features are fed into the spatio-temporal graph module by stitching to analyze the spatio-temporal changes in video clips to detect the cheating behaviors. Our experiments on three datasets, UCF-Crime, ShanghaiTech and Online Exam Proctoring (OEP), prove the effectiveness of our method as compared to the state-of-the-art approaches, and obtain the frame-level AUC score of 87.58% on the OEP dataset. ",
    "url": "https://arxiv.org/abs/2402.06107",
    "authors": [
      "Yemeng Liu",
      "Jing Ren",
      "Jianshuo Xu",
      "Xiaomei Bai",
      "Roopdeep Kaur",
      "Feng Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06108",
    "title": "United We Fall: On the Nash Equilibria of Multiplex and Multilayer  Network Games",
    "abstract": "Network games provide a framework to study strategic decision making processes that are governed by structured interdependencies among agents. However, existing models do not account for environments in which agents simultaneously interact over multiple networks, or when agents operate over multiple action dimensions. In this paper, we propose new models of multiplex network games to capture the different modalities of interactions among strategic agents, and multilayer network games to capture their interactions over multiple action dimensions. We explore how the properties of the constituent networks of a multiplex/multilayer network can undermine or support the existence, uniqueness, and stability of the game's Nash equilibria. Notably, we highlight that both the largest and smallest eigenvalues of the constituent networks (reflecting their connectivity and two-sidedness, respectively) are instrumental in determining the uniqueness of the multiplex/multilayer network game's equilibrium. Together, our findings shed light on the reasons for the fragility of equilibria when agents interact over networks of networks, and point out potential interventions to alleviate them. ",
    "url": "https://arxiv.org/abs/2402.06108",
    "authors": [
      "Raman Ebrahimi",
      "Parinaz Naghizadeh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.06117",
    "title": "Spatially-Attentive Patch-Hierarchical Network with Adaptive Sampling  for Motion Deblurring",
    "abstract": "This paper tackles the problem of motion deblurring of dynamic scenes. Although end-to-end fully convolutional designs have recently advanced the state-of-the-art in non-uniform motion deblurring, their performance-complexity trade-off is still sub-optimal. Most existing approaches achieve a large receptive field by increasing the number of generic convolution layers and kernel size. In this work, we propose a pixel adaptive and feature attentive design for handling large blur variations across different spatial locations and process each test image adaptively. We design a content-aware global-local filtering module that significantly improves performance by considering not only global dependencies but also by dynamically exploiting neighboring pixel information. We further introduce a pixel-adaptive non-uniform sampling strategy that implicitly discovers the difficult-to-restore regions present in the image and, in turn, performs fine-grained refinement in a progressive manner. Extensive qualitative and quantitative comparisons with prior art on deblurring benchmarks demonstrate that our approach performs favorably against the state-of-the-art deblurring algorithms. ",
    "url": "https://arxiv.org/abs/2402.06117",
    "authors": [
      "Maitreya Suin",
      "Kuldeep Purohit",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06128",
    "title": "Rethinking Node-wise Propagation for Large-scale Graph Learning",
    "abstract": "Scalable graph neural networks (GNNs) have emerged as a promising technique, which exhibits superior predictive performance and high running efficiency across numerous large-scale graph-based web applications. However, (i) Most scalable GNNs tend to treat all nodes in graphs with the same propagation rules, neglecting their topological uniqueness; (ii) Existing node-wise propagation optimization strategies are insufficient on web-scale graphs with intricate topology, where a full portrayal of nodes' local properties is required. Intuitively, different nodes in web-scale graphs possess distinct topological roles, and therefore propagating them indiscriminately or neglect local contexts may compromise the quality of node representations. This intricate topology in web-scale graphs cannot be matched by small-scale scenarios. To address the above issues, we propose \\textbf{A}daptive \\textbf{T}opology-aware \\textbf{P}ropagation (ATP), which reduces potential high-bias propagation and extracts structural patterns of each node in a scalable manner to improve running efficiency and predictive performance. Remarkably, ATP is crafted to be a plug-and-play node-wise propagation optimization strategy, allowing for offline execution independent of the graph learning process in a new perspective. Therefore, this approach can be seamlessly integrated into most scalable GNNs while remain orthogonal to existing node-wise propagation optimization strategies. Extensive experiments on 12 datasets, including the most representative large-scale ogbn-papers100M, have demonstrated the effectiveness of ATP. Specifically, ATP has proven to be efficient in improving the performance of prevalent scalable GNNs for semi-supervised node classification while addressing redundant computational costs. ",
    "url": "https://arxiv.org/abs/2402.06128",
    "authors": [
      "Xunkai Li",
      "Jingyuan Ma",
      "Zhengyu Wu",
      "Daohan Su",
      "Wentao Zhang",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.06132",
    "title": "TETRIS: Towards Exploring the Robustness of Interactive Segmentation",
    "abstract": "Interactive segmentation methods rely on user inputs to iteratively update the selection mask. A click specifying the object of interest is arguably the most simple and intuitive interaction type, and thereby the most common choice for interactive segmentation. However, user clicking patterns in the interactive segmentation context remain unexplored. Accordingly, interactive segmentation evaluation strategies rely more on intuition and common sense rather than empirical studies (e.g., assuming that users tend to click in the center of the area with the largest error). In this work, we conduct a real user study to investigate real user clicking patterns. This study reveals that the intuitive assumption made in the common evaluation strategy may not hold. As a result, interactive segmentation models may show high scores in the standard benchmarks, but it does not imply that they would perform well in a real world scenario. To assess the applicability of interactive segmentation methods, we propose a novel evaluation strategy providing a more comprehensive analysis of a model's performance. To this end, we propose a methodology for finding extreme user inputs by a direct optimization in a white-box adversarial attack on the interactive segmentation model. Based on the performance with such adversarial user inputs, we assess the robustness of interactive segmentation models w.r.t click positions. Besides, we introduce a novel benchmark for measuring the robustness of interactive segmentation, and report the results of an extensive evaluation of dozens of models. ",
    "url": "https://arxiv.org/abs/2402.06132",
    "authors": [
      "Andrey Moskalenko",
      "Vlad Shakhuro",
      "Anna Vorontsova",
      "Anton Konushin",
      "Anton Antonov",
      "Alexander Krapukhin",
      "Denis Shepelev",
      "Konstantin Soshin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.06135",
    "title": "Jointly Learning Representations for Map Entities via Heterogeneous  Graph Contrastive Learning",
    "abstract": "The electronic map plays a crucial role in geographic information systems, serving various urban managerial scenarios and daily life services. Developing effective Map Entity Representation Learning (MERL) methods is crucial to extracting embedding information from electronic maps and converting map entities into representation vectors for downstream applications. However, existing MERL methods typically focus on one specific category of map entities, such as POIs, road segments, or land parcels, which is insufficient for real-world diverse map-based applications and might lose latent structural and semantic information interacting between entities of different types. Moreover, using representations generated by separate models for different map entities can introduce inconsistencies. Motivated by this, we propose a novel method named HOME-GCL for learning representations of multiple categories of map entities. Our approach utilizes a heterogeneous map entity graph (HOME graph) that integrates both road segments and land parcels into a unified framework. A HOME encoder with parcel-segment joint feature encoding and heterogeneous graph transformer is then deliberately designed to convert segments and parcels into representation vectors. Moreover, we introduce two types of contrastive learning tasks, namely intra-entity and inter-entity tasks, to train the encoder in a self-supervised manner. Extensive experiments on three large-scale datasets covering road segment-based, land parcel-based, and trajectory-based tasks demonstrate the superiority of our approach. To the best of our knowledge, HOME-GCL is the first attempt to jointly learn representations for road segments and land parcels using a unified model. ",
    "url": "https://arxiv.org/abs/2402.06135",
    "authors": [
      "Jiawei Jiang",
      "Yifan Yang",
      "Jingyuan Wang",
      "Junjie Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06137",
    "title": "On the Privacy of Selection Mechanisms with Gaussian Noise",
    "abstract": "Report Noisy Max and Above Threshold are two classical differentially private (DP) selection mechanisms. Their output is obtained by adding noise to a sequence of low-sensitivity queries and reporting the identity of the query whose (noisy) answer satisfies a certain condition. Pure DP guarantees for these mechanisms are easy to obtain when Laplace noise is added to the queries. On the other hand, when instantiated using Gaussian noise, standard analyses only yield approximate DP guarantees despite the fact that the outputs of these mechanisms lie in a discrete space. In this work, we revisit the analysis of Report Noisy Max and Above Threshold with Gaussian noise and show that, under the additional assumption that the underlying queries are bounded, it is possible to provide pure ex-ante DP bounds for Report Noisy Max and pure ex-post DP bounds for Above Threshold. The resulting bounds are tight and depend on closed-form expressions that can be numerically evaluated using standard methods. Empirically we find these lead to tighter privacy accounting in the high privacy, low data regime. Further, we propose a simple privacy filter for composing pure ex-post DP guarantees, and use it to derive a fully adaptive Gaussian Sparse Vector Technique mechanism. Finally, we provide experiments on mobility and energy consumption datasets demonstrating that our Sparse Vector Technique is practically competitive with previous approaches and requires less hyper-parameter tuning. ",
    "url": "https://arxiv.org/abs/2402.06137",
    "authors": [
      "Jonathan Lebensold",
      "Doina Precup",
      "Borja Balle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.06161",
    "title": "Resource Allocation for Channel Estimation in Reconfigurable Intelligent  Surface-Aided Multi-Cell Networks",
    "abstract": "Reconfigurable intelligent surface (RIS) is a promising solution to deal with the blockage-sensitivity of millimeter wave band and reduce the high energy consumption caused by network densification. However, deploying large scale RISs may not bring expected performance gain due to significant channel estimation overhead and non-negligible reflected interference. In this paper, we derive the analytical expressions of the coverage probability, area spectrum efficiency (ASE) and energy efficiency (EE) of a downlink RIS-aided multi-cell network. In order to optimize the network performance, we investigate the conditions for the optimal number of training symbols of each antenna-to-antenna and antenna-to-element path (referred to as the optimal unit training overhead) in channel estimation. Our study shows that: 1) RIS deployment is not `the more, the better', only when blockage objects are dense should one deploy more RISs; 2) the coverage probability is maximized when the unit training overhead is designed as large as possible; 3) however, the ASE-and-EE-optimal unit training overhead exists. It is a monotonically increasing function of the frame length and a monotonically decreasing function of the average signal-to-noise-ratio (in the high signal-to-noise-ratio region). Additionally, the optimal unit training overhead is smaller when communication ends deploy particularly few or many antennas. ",
    "url": "https://arxiv.org/abs/2402.06161",
    "authors": [
      "Yining Xu",
      "Sheng Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.06165",
    "title": "Learning Contrastive Feature Representations for Facial Action Unit  Detection",
    "abstract": "The predominant approach to facial action unit (AU) detection revolves around a supervised multi-label binary classification problem. Existing methodologies often encode pixel-level information of AUs, thereby imposing substantial demands on model complexity and expressiveness. Moreover, this practice elevates the susceptibility to overfitting due to the presence of noisy AU labels. In the present study, we introduce a contrastive learning framework enhanced by both supervised and self-supervised signals. The objective is to acquire discriminative features, deviating from the conventional pixel-level learning paradigm within the domain of AU detection. To address the challenge posed by noisy AU labels, we augment the supervised signal through the introduction of a self-supervised signal. This augmentation is achieved through positive sample sampling, encompassing three distinct types of positive sample pairs. Furthermore, to mitigate the imbalanced distribution of each AU type, we employ an importance re-weighting strategy tailored for minority AUs. The resulting loss, denoted as AUNCE, is proposed to encapsulate this strategy. Our experimental assessments, conducted on two widely-utilized benchmark datasets (BP4D and DISFA), underscore the superior performance of our approach compared to state-of-the-art methods in the realm of AU detection. ",
    "url": "https://arxiv.org/abs/2402.06165",
    "authors": [
      "Ziqiao Shang",
      "Bin Liu",
      "Fei Teng",
      "Tianrui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06171",
    "title": "Pushing Boundaries: Mixup's Influence on Neural Collapse",
    "abstract": "Mixup is a data augmentation strategy that employs convex combinations of training instances and their respective labels to augment the robustness and calibration of deep neural networks. Despite its widespread adoption, the nuanced mechanisms that underpin its success are not entirely understood. The observed phenomenon of Neural Collapse, where the last-layer activations and classifier of deep networks converge to a simplex equiangular tight frame (ETF), provides a compelling motivation to explore whether mixup induces alternative geometric configurations and whether those could explain its success. In this study, we delve into the last-layer activations of training data for deep networks subjected to mixup, aiming to uncover insights into its operational efficacy. Our investigation, spanning various architectures and dataset pairs, reveals that mixup's last-layer activations predominantly converge to a distinctive configuration different than one might expect. In this configuration, activations from mixed-up examples of identical classes align with the classifier, while those from different classes delineate channels along the decision boundary. Moreover, activations in earlier layers exhibit patterns, as if trained with manifold mixup. These findings are unexpected, as mixed-up features are not simple convex combinations of feature class means (as one might get, for example, by training mixup with the mean squared error loss). By analyzing this distinctive geometric configuration, we elucidate the mechanisms by which mixup enhances model calibration. To further validate our empirical observations, we conduct a theoretical analysis under the assumption of an unconstrained features model, utilizing the mixup loss. Through this, we characterize and derive the optimal last-layer features under the assumption that the classifier forms a simplex ETF. ",
    "url": "https://arxiv.org/abs/2402.06171",
    "authors": [
      "Quinn Fisher",
      "Haoming Meng",
      "Vardan Papyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06184",
    "title": "The boundary of neural network trainability is fractal",
    "abstract": "Some fractals -- for instance those associated with the Mandelbrot and quadratic Julia sets -- are computed by iterating a function, and identifying the boundary between hyperparameters for which the resulting series diverges or remains bounded. Neural network training similarly involves iterating an update function (e.g. repeated steps of gradient descent), can result in convergent or divergent behavior, and can be extremely sensitive to small changes in hyperparameters. Motivated by these similarities, we experimentally examine the boundary between neural network hyperparameters that lead to stable and divergent training. We find that this boundary is fractal over more than ten decades of scale in all tested configurations. ",
    "url": "https://arxiv.org/abs/2402.06184",
    "authors": [
      "Jascha Sohl-Dickstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2402.06187",
    "title": "Premier-TACO: Pretraining Multitask Representation via Temporal  Action-Driven Contrastive Loss",
    "abstract": "We present Premier-TACO, a multitask feature representation learning approach designed to improve few-shot policy learning efficiency in sequential decision-making tasks. Premier-TACO leverages a subset of multitask offline datasets for pretraining a general feature representation, which captures critical environmental dynamics and is fine-tuned using minimal expert demonstrations. It advances the temporal action contrastive learning (TACO) objective, known for state-of-the-art results in visual control tasks, by incorporating a novel negative example sampling strategy. This strategy is crucial in significantly boosting TACO's computational efficiency, making large-scale multitask offline pretraining feasible. Our extensive empirical evaluation in a diverse set of continuous control benchmarks including Deepmind Control Suite, MetaWorld, and LIBERO demonstrate Premier-TACO's effectiveness in pretraining visual representations, significantly enhancing few-shot imitation learning of novel tasks. Our code, pretraining data, as well as pretrained model checkpoints will be released at https://github.com/PremierTACO/premier-taco. ",
    "url": "https://arxiv.org/abs/2402.06187",
    "authors": [
      "Ruijie Zheng",
      "Yongyuan Liang",
      "Xiyao Wang",
      "Shuang Ma",
      "Hal Daum\u00e9 III",
      "Huazhe Xu",
      "John Langford",
      "Praveen Palanisamy",
      "Kalyan Shankar Basu",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.06188",
    "title": "A self-supervised framework for learning whole slide representations",
    "abstract": "Whole slide imaging is fundamental to biomedical microscopy and computational pathology. However, whole slide images (WSIs) present a complex computer vision challenge due to their gigapixel size, diverse histopathologic features, spatial heterogeneity, and limited/absent data annotations. These challenges highlight that supervised training alone can result in suboptimal whole slide representations. Self-supervised representation learning can achieve high-quality WSI visual feature learning for downstream diagnostic tasks, such as cancer diagnosis or molecular genetic prediction. Here, we present a general self-supervised whole slide learning (S3L) framework for gigapixel-scale self-supervision of WSIs. S3L combines data transformation strategies from transformer-based vision and language modeling into a single unified framework to generate paired views for self-supervision. S3L leverages the inherent regional heterogeneity, histologic feature variability, and information redundancy within WSIs to learn high-quality whole-slide representations. We benchmark S3L visual representations on two diagnostic tasks for two biomedical microscopy modalities. S3L significantly outperforms WSI baselines for cancer diagnosis and genetic mutation prediction. Additionally, S3L achieves good performance using both in-domain and out-of-distribution patch encoders, demonstrating good flexibility and generalizability. ",
    "url": "https://arxiv.org/abs/2402.06188",
    "authors": [
      "Xinhai Hou",
      "Cheng Jiang",
      "Akhil Kondepudi",
      "Yiwei Lyu",
      "Asadur Zaman Chowdury",
      "Honglak Lee",
      "Todd C. Hollon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06211",
    "title": "Fine-Tuning Surrogate Gradient Learning for Optimal Hardware Performance  in Spiking Neural Networks",
    "abstract": "The highly sparse activations in Spiking Neural Networks (SNNs) can provide tremendous energy efficiency benefits when carefully exploited in hardware. The behavior of sparsity in SNNs is uniquely shaped by the dataset and training hyperparameters. This work reveals novel insights into the impacts of training on hardware performance. Specifically, we explore the trade-offs between model accuracy and hardware efficiency. We focus on three key hyperparameters: surrogate gradient functions, beta, and membrane threshold. Results on an FPGA-based hardware platform show that the fast sigmoid surrogate function yields a lower firing rate with similar accuracy compared to the arctangent surrogate on the SVHN dataset. Furthermore, by cross-sweeping the beta and membrane threshold hyperparameters, we can achieve a 48% reduction in hardware-based inference latency with only 2.88% trade-off in inference accuracy compared to the default setting. Overall, this study highlights the importance of fine-tuning model hyperparameters as crucial for designing efficient SNN hardware accelerators, evidenced by the fine-tuned model achieving a 1.72x improvement in accelerator efficiency (FPS/W) compared to the most recent work. ",
    "url": "https://arxiv.org/abs/2402.06211",
    "authors": [
      "Ilkin Aliyev",
      "Tosiron Adegbija"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.06220",
    "title": "A Unified Causal View of Instruction Tuning",
    "abstract": "Instruction tuning on a mixture of tasks has improved zero-shot capabilities in natural language processing (NLP). Nevertheless, existing methods often learn features that exhibit correlations between instruction-formatted samples and target labels, rather than causal relationships. Termed as ``spurious correlation'' in statistics, such a correlation may change drastically in a new task, making the effect from the learned features to be misleading. To this end, we develop a meta Structural Causal Model (meta-SCM) to integrate different NLP tasks under a single causal structure of the data. Specifically, the meta-SCM introduces multiple latent factors that represent properties of source context, only some of which causally influence the target labels for a specific task. The key idea is to learn task-required causal factors and only use those to make predictions for a given task. Theoretically, we prove the causal factor can be identified without mixing information from others. Guided by the identifiability, we propose a Structural Instruction Tuning (SIT) method to learn the task-required causal representations that can mimic the causal factors for each task. The utility of our approach is verified by improvements of zero-shot ability on a range of unseen datasets and tasks. ",
    "url": "https://arxiv.org/abs/2402.06220",
    "authors": [
      "Lu Chen",
      "Wei Huang",
      "Ruqing Zhang",
      "Wei Chen",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.06223",
    "title": "Revealing Multimodal Contrastive Representation Learning through Latent  Partial Causal Models",
    "abstract": "Multimodal contrastive representation learning methods have proven successful across a range of domains, partly due to their ability to generate meaningful shared representations of complex phenomena. To enhance the depth of analysis and understanding of these acquired representations, we introduce a unified causal model specifically designed for multimodal data. By examining this model, we show that multimodal contrastive representation learning excels at identifying latent coupled variables within the proposed unified model, up to linear or permutation transformations resulting from different assumptions. Our findings illuminate the potential of pre-trained multimodal models, eg, CLIP, in learning disentangled representations through a surprisingly simple yet highly effective tool: linear independent component analysis. Experiments demonstrate the robustness of our findings, even when the assumptions are violated, and validate the effectiveness of the proposed method in learning disentangled representations. ",
    "url": "https://arxiv.org/abs/2402.06223",
    "authors": [
      "Yuhang Liu",
      "Zhen Zhang",
      "Dong Gong",
      "Biwei Huang",
      "Mingming Gong",
      "Anton van den Hengel",
      "Kun Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.06226",
    "title": "N-1 Reduced Optimal Power Flow Using Augmented Hierarchical Graph Neural  Network",
    "abstract": "Optimal power flow (OPF) is used to perform generation redispatch in power system real-time operations. N-1 OPF can ensure safe grid operations under diverse contingency scenarios. For large and intricate power networks with numerous variables and constraints, achieving an optimal solution for real-time N-1 OPF necessitates substantial computational resources. To mitigate this challenge, machine learning (ML) is introduced as an additional tool for predicting congested or heavily loaded lines dynamically. In this paper, an advanced ML model known as the augmented hierarchical graph neural network (AHGNN) was proposed to predict critical congested lines and create N-1 reduced OPF (N-1 ROPF). The proposed AHGNN-enabled N-1 ROPF can result in a remarkable reduction in computing time while retaining the solution quality. Several variations of GNN-based ML models are also implemented as benchmark to demonstrate effectiveness of the proposed AHGNN approach. Case studies prove the proposed AHGNN and the associated N-1 ROPF are highly effective in reducing computation time while preserving solution quality, highlighting the promising potential of ML, particularly GNN in enhancing power system operations. ",
    "url": "https://arxiv.org/abs/2402.06226",
    "authors": [
      "Thuan Pham",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06244",
    "title": "Quantifying and Enhancing Multi-modal Robustness with Modality  Preference",
    "abstract": "Multi-modal models have shown a promising capability to effectively integrate information from various sources, yet meanwhile, they are found vulnerable to pervasive perturbations, such as uni-modal attacks and missing conditions. To counter these perturbations, robust multi-modal representations are highly expected, which are positioned well away from the discriminative multi-modal decision boundary. In this paper, different from conventional empirical studies, we focus on a commonly used joint multi-modal framework and theoretically discover that larger uni-modal representation margins and more reliable integration for modalities are essential components for achieving higher robustness. This discovery can further explain the limitation of multi-modal robustness and the phenomenon that multi-modal models are often vulnerable to attacks on the specific modality. Moreover, our analysis reveals how the widespread issue, that the model has different preferences for modalities, limits the multi-modal robustness by influencing the essential components and could lead to attacks on the specific modality highly effective. Inspired by our theoretical finding, we introduce a training procedure called Certifiable Robust Multi-modal Training (CRMT), which can alleviate this influence from modality preference and explicitly regulate essential components to significantly improve robustness in a certifiable manner. Our method demonstrates substantial improvements in performance and robustness compared with existing methods. Furthermore, our training procedure can be easily extended to enhance other robust training strategies, highlighting its credibility and flexibility. ",
    "url": "https://arxiv.org/abs/2402.06244",
    "authors": [
      "Zequn Yang",
      "Yake Wei",
      "Ce Liang",
      "Di Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.06247",
    "title": "Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An  Empirical Study",
    "abstract": "Compared to Full-Model Fine-Tuning (FMFT), Parameter Efficient Fine-Tuning (PEFT) has demonstrated superior performance and lower computational overhead in several code understanding tasks, such as code summarization and code search. This advantage can be attributed to PEFT's ability to alleviate the catastrophic forgetting issue of Pre-trained Language Models (PLMs) by updating only a small number of parameters. As a result, PEFT effectively harnesses the pre-trained general-purpose knowledge for downstream tasks. However, existing studies primarily involve static code comprehension, aligning with the pre-training paradigm of recent PLMs and facilitating knowledge transfer, but they do not account for dynamic code changes. Thus, it remains unclear whether PEFT outperforms FMFT in task-specific adaptation for code-change-related tasks. To address this question, we examine two prevalent PEFT methods, namely Adapter Tuning (AT) and Low-Rank Adaptation (LoRA), and compare their performance with FMFT on five popular PLMs. Specifically, we evaluate their performance on two widely-studied code-change-related tasks: Just-In-Time Defect Prediction (JIT-DP) and Commit Message Generation (CMG). The results demonstrate that both AT and LoRA achieve state-of-the-art (SOTA) results in JIT-DP and exhibit comparable performances in CMG when compared to FMFT and other SOTA approaches. Furthermore, AT and LoRA exhibit superiority in cross-lingual and low-resource scenarios. We also conduct three probing tasks to explain the efficacy of PEFT techniques on JIT-DP and CMG tasks from both static and dynamic perspectives. The study indicates that PEFT, particularly through the use of AT and LoRA, offers promising advantages in code-change-related tasks, surpassing FMFT in certain aspects. ",
    "url": "https://arxiv.org/abs/2402.06247",
    "authors": [
      "Shuo Liu",
      "Jacky Keung",
      "Zhen Yang",
      "Fang Liu",
      "Qilin Zhou",
      "Yihan Liao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.06249",
    "title": "Anomaly Unveiled: Securing Image Classification against Adversarial  Patch Attacks",
    "abstract": "Adversarial patch attacks pose a significant threat to the practical deployment of deep learning systems. However, existing research primarily focuses on image pre-processing defenses, which often result in reduced classification accuracy for clean images and fail to effectively counter physically feasible attacks. In this paper, we investigate the behavior of adversarial patches as anomalies within the distribution of image information and leverage this insight to develop a robust defense strategy. Our proposed defense mechanism utilizes a clustering-based technique called DBSCAN to isolate anomalous image segments, which is carried out by a three-stage pipeline consisting of Segmenting, Isolating, and Blocking phases to identify and mitigate adversarial noise. Upon identifying adversarial components, we neutralize them by replacing them with the mean pixel value, surpassing alternative replacement options. Our model-agnostic defense mechanism is evaluated across multiple models and datasets, demonstrating its effectiveness in countering various adversarial patch attacks in image classification tasks. Our proposed approach significantly improves accuracy, increasing from 38.8\\% without the defense to 67.1\\% with the defense against LaVAN and GoogleAp attacks, surpassing prominent state-of-the-art methods such as LGS (53.86\\%) and Jujutsu (60\\%) ",
    "url": "https://arxiv.org/abs/2402.06249",
    "authors": [
      "Nandish Chattopadhyay",
      "Amira Guesmi",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.06255",
    "title": "Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial  Tuning",
    "abstract": "Although Large Language Models (LLMs) have achieved tremendous success in various applications, they are also susceptible to certain prompts that can induce them to bypass built-in safety measures and provide dangerous or illegal content, a phenomenon known as jailbreak. To protect LLMs from producing harmful information, various defense strategies are proposed, with most focusing on content filtering or adversarial training of models. In this paper, we propose an approach named Prompt Adversarial Tuning (PAT) to train a defense control mechanism, which is then embedded as a prefix to user prompts to implement our defense strategy. We design a training process similar to adversarial training to achieve our optimized goal, alternating between updating attack and defense controls. To our knowledge, we are the first to implement defense from the perspective of prompt tuning. Once employed, our method will hardly impact the operational efficiency of LLMs. Experiments show that our method is effective in both black-box and white-box settings, reducing the success rate of advanced attacks to nearly 0 while maintaining the benign answer rate of 80% to simple benign questions. Our work might potentially chart a new perspective for future explorations in LLM security. ",
    "url": "https://arxiv.org/abs/2402.06255",
    "authors": [
      "Yichuan Mo",
      "Yuji Wang",
      "Zeming Wei",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.06281",
    "title": "An Optimization Framework for Resource Allocation in Virtual Sensor  Networks",
    "abstract": "We propose an optimization framework to perform resource allocation in virtual sensor networks. Sensor network virtualization is a promising paradigm to improve flexibility of wireless sensor networks which allows to dynamically assign physical resources to multiple stakeholder applications. The proposed optimization framework aims at maximizing the total number of applications which can share a common physical network, while accounting for the distinguishing characteristics and limitations of the wireless sensor environment (limited storage, limited processing power, limited bandwidth, tight energy consumption requirements). The proposed framework is finally applied to realistic network topologies to assess the gain involved in letting multiple applications share a common physical network with respect to one-application, one-network vertical design approaches. ",
    "url": "https://arxiv.org/abs/2402.06281",
    "authors": [
      "Carmen Delgado",
      "Jos\u00e9 Ram\u00f3n G\u00e1llego",
      "Mar\u00eda Canales",
      "Jorge Ort\u00edn",
      "Sonda Bousnina",
      "Matteo Cesana"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.06284",
    "title": "Towards Chip-in-the-loop Spiking Neural Network Training via  Metropolis-Hastings Sampling",
    "abstract": "This paper studies the use of Metropolis-Hastings sampling for training Spiking Neural Network (SNN) hardware subject to strong unknown non-idealities, and compares the proposed approach to the common use of the backpropagation of error (backprop) algorithm and surrogate gradients, widely used to train SNNs in literature. Simulations are conducted within a chip-in-the-loop training context, where an SNN subject to unknown distortion must be trained to detect cancer from measurements, within a biomedical application context. Our results show that the proposed approach strongly outperforms the use of backprop by up to $27\\%$ higher accuracy when subject to strong hardware non-idealities. Furthermore, our results also show that the proposed approach outperforms backprop in terms of SNN generalization, needing $>10 \\times$ less training data for achieving effective accuracy. These findings make the proposed training approach well-suited for SNN implementations in analog subthreshold circuits and other emerging technologies where unknown hardware non-idealities can jeopardize backprop. ",
    "url": "https://arxiv.org/abs/2402.06284",
    "authors": [
      "Ali Safa",
      "Vikrant Jaltare",
      "Samira Sebt",
      "Kameron Gano",
      "Johannes Leugering",
      "Georges Gielen",
      "Gert Cauwenberghs"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06289",
    "title": "Evaluating Membership Inference Attacks and Defenses in Federated  Learning",
    "abstract": "Membership Inference Attacks (MIAs) pose a growing threat to privacy preservation in federated learning. The semi-honest attacker, e.g., the server, may determine whether a particular sample belongs to a target client according to the observed model information. This paper conducts an evaluation of existing MIAs and corresponding defense strategies. Our evaluation on MIAs reveals two important findings about the trend of MIAs. Firstly, combining model information from multiple communication rounds (Multi-temporal) enhances the overall effectiveness of MIAs compared to utilizing model information from a single epoch. Secondly, incorporating models from non-target clients (Multi-spatial) significantly improves the effectiveness of MIAs, particularly when the clients' data is homogeneous. This highlights the importance of considering the temporal and spatial model information in MIAs. Next, we assess the effectiveness via privacy-utility tradeoff for two type defense mechanisms against MIAs: Gradient Perturbation and Data Replacement. Our results demonstrate that Data Replacement mechanisms achieve a more optimal balance between preserving privacy and maintaining model utility. Therefore, we recommend the adoption of Data Replacement methods as a defense strategy against MIAs. Our code is available in https://github.com/Liar-Mask/FedMIA. ",
    "url": "https://arxiv.org/abs/2402.06289",
    "authors": [
      "Gongxi Zhu",
      "Donghao Li",
      "Hanlin Gu",
      "Yuxing Han",
      "Yuan Yao",
      "Lixin Fan",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.06294",
    "title": "Complexity of Boolean automata networks under block-parallel update  modes",
    "abstract": "Boolean automata networks (aka Boolean networks) are space-time discrete dynamical systems, studied as a model of computation and as a representative model of natural phenomena. A collection of simple entities (the automata) update their 0-1 states according to local rules. The dynamics of the network is highly sensitive to update modes, i.e., to the schedule according to which the automata apply their local rule. A new family of update modes appeared recently, called block-parallel, which is dual to the well studied block-sequential. Although basic, it embeds the rich feature of update repetitions among a temporal updating period, allowing for atypical asymptotic behaviors. In this paper, we prove that it is able to breed complex computations, squashing almost all decision problems on the dynamics to the traditionally highest (for reachability questions) class PSPACE. Despite obtaining these complexity bounds for a broad set of local and global properties, we also highlight a surprising gap: bijectivity is still coNP. ",
    "url": "https://arxiv.org/abs/2402.06294",
    "authors": [
      "K\u00e9vin Perrot",
      "Sylvain Sen\u00e9",
      "L\u00e9ah Tapin"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2402.06295",
    "title": "Multimodal Interpretable Data-Driven Models for Early Prediction of  Antimicrobial Multidrug Resistance Using Multivariate Time-Series",
    "abstract": "Electronic health records (EHR) is an inherently multimodal register of the patient's health status characterized by static data and multivariate time series (MTS). While MTS are a valuable tool for clinical prediction, their fusion with other data modalities can possibly result in more thorough insights and more accurate results. Deep neural networks (DNNs) have emerged as fundamental tools for identifying and defining underlying patterns in the healthcare domain. However, fundamental improvements in interpretability are needed for DNN models to be widely used in the clinical setting. In this study, we present an approach built on a collection of interpretable multimodal data-driven models that may anticipate and understand the emergence of antimicrobial multidrug resistance (AMR) germs in the intensive care unit (ICU) of the University Hospital of Fuenlabrada (Madrid, Spain). The profile and initial health status of the patient are modeled using static variables, while the evolution of the patient's health status during the ICU stay is modeled using several MTS, including mechanical ventilation and antibiotics intake. The multimodal DNNs models proposed in this paper include interpretable principles in addition to being effective at predicting AMR and providing an explainable prediction support system for AMR in the ICU. Furthermore, our proposed methodology based on multimodal models and interpretability schemes can be leveraged in additional clinical problems dealing with EHR data, broadening the impact and applicability of our results. ",
    "url": "https://arxiv.org/abs/2402.06295",
    "authors": [
      "Sergio Mart\u00ednez-Ag\u00fcero",
      "Antonio G. Marques",
      "Inmaculada Mora-Jim\u00e9nez",
      "Joaqu\u00edn Alv\u00e1rez-Rodr\u00edguez",
      "Cristina Soguero-Ruiza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2402.06297",
    "title": "Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex  Environments",
    "abstract": "Unmanned Aerial Vehicles need an online path planning capability to move in high-risk missions in unknown and complex environments to complete them safely. However, many algorithms reported in the literature may not return reliable trajectories to solve online problems in these scenarios. The Q-Learning algorithm, a Reinforcement Learning Technique, can generate trajectories in real-time and has demonstrated fast and reliable results. This technique, however, has the disadvantage of defining the iteration number. If this value is not well defined, it will take a long time or not return an optimal trajectory. Therefore, we propose a method to dynamically choose the number of iterations to obtain the best performance of Q-Learning. The proposed method is compared to the Q-Learning algorithm with a fixed number of iterations, A*, Rapid-Exploring Random Tree, and Particle Swarm Optimization. As a result, the proposed Q-learning algorithm demonstrates the efficacy and reliability of online path planning with a dynamic number of iterations to carry out online missions in unknown and complex environments. ",
    "url": "https://arxiv.org/abs/2402.06297",
    "authors": [
      "Lidia Gianne Souza da Rocha",
      "Kenny Anderson Queiroz Caldas",
      "Marco Henrique Terra",
      "Fabio Ramos",
      "Kelen Cristiane Teixeira Vivaldini"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.06315",
    "title": "Multisource Semisupervised Adversarial Domain Generalization Network for  Cross-Scene Sea\\textendash Land Clutter Classification",
    "abstract": "Deep learning (DL)-based sea\\textendash land clutter classification for sky-wave over-the-horizon-radar (OTHR) has become a novel research topic. In engineering applications, real-time predictions of sea\\textendash land clutter with existing distribution discrepancies are crucial. To solve this problem, this article proposes a novel Multisource Semisupervised Adversarial Domain Generalization Network (MSADGN) for cross-scene sea\\textendash land clutter classification. MSADGN can extract domain-invariant and domain-specific features from one labeled source domain and multiple unlabeled source domains, and then generalize these features to an arbitrary unseen target domain for real-time prediction of sea\\textendash land clutter. Specifically, MSADGN consists of three modules: domain-related pseudolabeling module, domain-invariant module, and domain-specific module. The first module introduces an improved pseudolabel method called domain-related pseudolabel, which is designed to generate reliable pseudolabels to fully exploit unlabeled source domains. The second module utilizes a generative adversarial network (GAN) with a multidiscriminator to extract domain-invariant features, to enhance the model's transferability in the target domain. The third module employs a parallel multiclassifier branch to extract domain-specific features, to enhance the model's discriminability in the target domain. The effectiveness of our method is validated in twelve domain generalizations (DG) scenarios. Meanwhile, we selected 10 state-of-the-art DG methods for comparison. The experimental results demonstrate the superiority of our method. ",
    "url": "https://arxiv.org/abs/2402.06315",
    "authors": [
      "Xiaoxuan Zhang",
      "Quan Pan",
      "Salvador Garc\u00eda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06323",
    "title": "How Uniform Random Weights Induce Non-uniform Bias: Typical  Interpolating Neural Networks Generalize with Narrow Teachers",
    "abstract": "Background. A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with Stochastic Gradient Descent (SGD) or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as SGD-trained NNs. Contributions. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN\" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant parameters to represent -- enabling learning with a sample complexity approximately proportional to the complexity of the teacher (roughly, the number of non-redundant parameters), rather than the student's. ",
    "url": "https://arxiv.org/abs/2402.06323",
    "authors": [
      "Gon Buzaglo",
      "Itamar Harel",
      "Mor Shpigel Nacson",
      "Alon Brutzkus",
      "Nathan Srebro",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.06326",
    "title": "Prompt Learning on Temporal Interaction Graphs",
    "abstract": "Temporal Interaction Graphs (TIGs) are widely utilized to represent real-world systems. To facilitate representation learning on TIGs, researchers have proposed a series of TIG models. However, these models are still facing two tough gaps between the pre-training and downstream predictions in their ``pre-train, predict'' training paradigm. First, the temporal discrepancy between the pre-training and inference data severely undermines the models' applicability in distant future predictions on the dynamically evolving data. Second, the semantic divergence between pretext and downstream tasks hinders their practical applications, as they struggle to align with their learning and prediction capabilities across application scenarios. Recently, the ``pre-train, prompt'' paradigm has emerged as a lightweight mechanism for model generalization. Applying this paradigm is a potential solution to solve the aforementioned challenges. However, the adaptation of this paradigm to TIGs is not straightforward. The application of prompting in static graph contexts falls short in temporal settings due to a lack of consideration for time-sensitive dynamics and a deficiency in expressive power. To address this issue, we introduce Temporal Interaction Graph Prompting (TIGPrompt), a versatile framework that seamlessly integrates with TIG models, bridging both the temporal and semantic gaps. In detail, we propose a temporal prompt generator to offer temporally-aware prompts for different tasks. These prompts stand out for their minimalistic design, relying solely on the tuning of the prompt generator with very little supervision data. To cater to varying computational resource demands, we propose an extended ``pre-train, prompt-based fine-tune'' paradigm, offering greater flexibility. Through extensive experiments, the TIGPrompt demonstrates the SOTA performance and remarkable efficiency advantages. ",
    "url": "https://arxiv.org/abs/2402.06326",
    "authors": [
      "Xi Chen",
      "Siwei Zhang",
      "Yun Xiong",
      "Xixi Wu",
      "Jiawei Zhang",
      "Xiangguo Sun",
      "Yao Zhang",
      "Yinglong Zhao",
      "Yulin Kang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.06329",
    "title": "A Network for structural dense displacement based on 3D deformable mesh  model and optical flow",
    "abstract": "This study proposes a Network to recognize displacement of a RC frame structure from a video by a monocular camera. The proposed Network consists of two modules which is FlowNet2 and POFRN-Net. FlowNet2 is used to generate dense optical flow as well as POFRN-Net is to extract pose parameter H. FlowNet2 convert two video frames into dense optical flow. POFRN-Net is inputted dense optical flow from FlowNet2 to output the pose parameter H. The displacement of any points of structure can be calculated from parameter H. The Fast Fourier Transform (FFT) is applied to obtain frequency domain signal from corresponding displacement signal. Furthermore, the comparison of the truth displacement on the First floor of the First video is shown in this study. Finally, the predicted displacements on four floors of RC frame structure of given three videos are exhibited in the last of this study. ",
    "url": "https://arxiv.org/abs/2402.06329",
    "authors": [
      "Peimian Du",
      "Qicheng Guo",
      "Yanru Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.06342",
    "title": "Promoting Target Data in Context-aware Neural Machine Translation",
    "abstract": "Standard context-aware neural machine translation (NMT) typically relies on parallel document-level data, exploiting both source and target contexts. Concatenation-based approaches in particular, still a strong baseline for document-level NMT, prepend source and/or target context sentences to the sentences to be translated, with model variants that exploit equal amounts of source and target data on each side achieving state-of-the-art results. In this work, we investigate whether target data should be further promoted within standard concatenation-based approaches, as most document-level phenomena rely on information that is present on the target language side. We evaluate novel concatenation-based variants where the target context is prepended to the source language, either in isolation or in combination with the source context. Experimental results in English-Russian and Basque-Spanish show that including target context in the source leads to large improvements on target language phenomena. On source-dependent phenomena, using only target language context in the source achieves parity with state-of-the-art concatenation approaches, or slightly underperforms, whereas combining source and target context on the source side leads to significant gains across the board. ",
    "url": "https://arxiv.org/abs/2402.06342",
    "authors": [
      "Harritxu Gete",
      "Thierry Etchegoyhen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.06352",
    "title": "Blockchain Bribing Attacks and the Efficacy of Counterincentives",
    "abstract": "We analyze bribing attacks in distributed ledgers from a game theoretic perspective. In bribing attacks, an adversary offers to maintainers a financial reward, in exchange for instructing them on how to behave, with the goal of attacking the protocol's properties. We consider two types of bribing, depending on how the bribes are awarded: i) guided bribing, where the bribe is given as long as the bribed party behaves as instructed; ii) effective bribing, where bribes are conditional on the attack's success, w.r.t. well-defined metrics. We analyze each type of attack in a game theoretic setting and identify relevant equilibria. In guided bribing, we show that the protocol is not an equilibrium and then describe good equilibria, where the attack is unsuccessful, and a negative one, where all parties are bribed such that the attack succeeds. In effective bribing, we show that both the protocol and the \"all bribed\" setting are equilibria. Using the identified equilibria, we then compute bounds on the Prices of Stability and Anarchy. Our results indicate that additional mitigations are needed for guided bribing, so our analysis concludes with incentive-based mitigation techniques, namely slashing and dilution. Here, we present two positive results, that both render the protocol an equilibrium and achieve maximal welfare for all parties, and a negative result, wherein an attack becomes more plausible if it severely affects the ledger's token's market price. ",
    "url": "https://arxiv.org/abs/2402.06352",
    "authors": [
      "Dimitris Karakostas",
      "Aggelos Kiayias",
      "Thomas Zacharias"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.06357",
    "title": "The SpongeNet Attack: Sponge Weight Poisoning of Deep Neural Networks",
    "abstract": "Sponge attacks aim to increase the energy consumption and computation time of neural networks deployed on hardware accelerators. Existing sponge attacks can be performed during inference via sponge examples or during training via Sponge Poisoning. Sponge examples leverage perturbations added to the model's input to increase energy and latency, while Sponge Poisoning alters the objective function of a model to induce inference-time energy/latency effects. In this work, we propose a novel sponge attack called SpongeNet. SpongeNet is the first sponge attack that is performed directly on the parameters of a pre-trained model. Our experiments show that SpongeNet can successfully increase the energy consumption of vision models with fewer samples required than Sponge Poisoning. Our experiments indicate that poisoning defenses are ineffective if not adjusted specifically for the defense against Sponge Poisoning (i.e., they decrease batch normalization bias values). Our work shows that SpongeNet is more effective on StarGAN than the state-of-the-art. Additionally, SpongeNet is stealthier than the previous Sponge Poisoning attack as it does not require significant changes in the victim model's weights. Our experiments indicate that the SpongeNet attack can be performed even when an attacker has access to only 1% of the entire dataset and reach up to 11% energy increase. ",
    "url": "https://arxiv.org/abs/2402.06357",
    "authors": [
      "Jona te Lintelo",
      "Stefanos Koffas",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06367",
    "title": "TEE4EHR: Transformer Event Encoder for Better Representation Learning in  Electronic Health Records",
    "abstract": "Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models. Additionally, the pattern of missing data in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient. Point process is a mathematical framework for analyzing event sequence data that is consistent with irregular sampling patterns. Our model, TEE4EHR, is a transformer event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs. The utility of our TEE has been investigated in a variety of benchmark event sequence datasets. Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model. Firstly, in a self-supervised learning approach, the TEE is jointly learned with an existing attention-based deep neural network which gives superior performance in negative log-likelihood and future event prediction. Besides, we propose an algorithm for aggregating attention weights that can reveal the interaction between the events. Secondly, we transfer and freeze the learned TEE to the downstream task for the outcome prediction, where it outperforms state-of-the-art models for handling irregularly sampled time series. Furthermore, our results demonstrate that our approach can improve representation learning in EHRs and can be useful for clinical prediction tasks. ",
    "url": "https://arxiv.org/abs/2402.06367",
    "authors": [
      "Hojjat Karami",
      "David Atienza",
      "Anisoara Ionescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06373",
    "title": "A new edge betweenness measure using a game theoretical approach: an  application to hierarchical community detection",
    "abstract": "In this paper we formally define the hierarchical clustering network problem (HCNP) as the problem to find a good hierarchical partition of a network. This new problem focuses on the dynamic process of the clustering rather than on the final picture of the clustering process. To address it, we introduce a new ierarchical clustering algorithm in networks, based on a new shortest path betweenness measure. To calculate it, the communication between each pair of nodes is weighed by he importance of the nodes that establish this communication. The weights or importance associated to each pair of nodes are calculated as the Shapley value of a game, named as the linear modularity game. This new measure, (the node-game shortest path betweenness measure), is used to obtain a hierarchical partition of the network by eliminating the link with the highest value. To evaluate the performance of our algorithm, we introduce several criteria that allow us to compare different dendrograms of a network from two point of view: modularity and homogeneity. Finally, we propose a faster algorithm based on a simplification of the node-game shortest path betweenness measure, whose order is quadratic on sparse networks. This fast version is competitive from a computational point of view with other hierarchical fast algorithms, and, in general, it provides better results. ",
    "url": "https://arxiv.org/abs/2402.06373",
    "authors": [
      "Daniel G\u00f3mez",
      "Javier Castro",
      "Inmaculada Guti\u00e9rrez",
      "Rosa Esp\u00ednola"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2402.06411",
    "title": "Exploiting spatial diversity for increasing the robustness of sound  source localization systems against reverberation",
    "abstract": "Acoustic reverberation is one of the most relevant factors that hampers the localization of a sound source inside a room. To date, several approaches have been proposed to deal with it, but have not always been evaluated under realistic conditions. This paper proposes exploiting spatial diversity as an alternative approach to achieve robustness against reverberation. The theoretical arguments supporting this approach are first presented and later confirmed by means of simulation results and real measurements. Simulations are run for reverberation times up to 2 s, thus providing results with a wider range of validity than in other previous research works. It is concluded that the use of systems consisting of several, sufficiently separated, small arrays leads to the best results in reverberant environments. Some recommendations are given regarding the choice of the array sizes, the separation among them, and the way to combine SRP-PHAT maps obtained from diverse arrays. ",
    "url": "https://arxiv.org/abs/2402.06411",
    "authors": [
      "Guillermo Garcia-Barrios",
      "Eduardo Latorre Iglesias",
      "Juana M. Gutierrez-Arriola",
      "Ruben Fraile",
      "Nicolas Saenz-Lechon",
      "Victor Jose Osma-Ruiz"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.06423",
    "title": "CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal  Curve Queries and Attention",
    "abstract": "In autonomous driving, 3D lane detection using monocular cameras is an important task for various downstream planning and control tasks. Recent CNN and Transformer approaches usually apply a two-stage scheme in the model design. The first stage transforms the image feature from a front image into a bird's-eye-view (BEV) representation. Subsequently, a sub-network processes the BEV feature map to generate the 3D detection results. However, these approaches heavily rely on a challenging image feature transformation module from a perspective view to a BEV representation. In our work, we present CurveFormer++, a single-stage Transformer-based method that does not require the image feature view transform module and directly infers 3D lane detection results from the perspective image features. Specifically, our approach models the 3D detection task as a curve propagation problem, where each lane is represented by a curve query with a dynamic and ordered anchor point set. By employing a Transformer decoder, the model can iteratively refine the 3D lane detection results. A curve cross-attention module is introduced in the Transformer decoder to calculate similarities between image features and curve queries of lanes. To handle varying lane lengths, we employ context sampling and anchor point restriction techniques to compute more relevant image features for a curve query. Furthermore, we apply a temporal fusion module that incorporates selected informative sparse curve queries and their corresponding anchor point sets to leverage historical lane information. In the experiments, we evaluate our approach for the 3D lane detection task on two publicly available real-world datasets. The results demonstrate that our method provides outstanding performance compared with both CNN and Transformer based methods. We also conduct ablation studies to analyze the impact of each component in our approach. ",
    "url": "https://arxiv.org/abs/2402.06423",
    "authors": [
      "Yifeng Bai",
      "Zhirong Chen",
      "Pengpeng Liang",
      "Erkang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06424",
    "title": "Reducing Latency for Multimedia Broadcast Services Over Mobile Networks",
    "abstract": "Multimedia services over mobile networks pose several challenges, such as the efficient management of radio resources or the latency induced by network delays and buffering requirements on the multimedia players. In Long Term Evolution (LTE) networks, the definition of multimedia broadcast services over a common radio channel addresses the shortage of radio resources but introduces the problem of network error recovery. In order to address network errors on LTE multimedia broadcast services, the current standards propose the combined use of forward error correction and unicast recovery techniques at the application level. This paper shows how to efficiently synchronize the broadcasting server and the multimedia players and how to reduce service latency by limiting the multimedia player buffer length. This is accomplished by analyzing the relation between the different parameters of the LTE multimedia broadcast service, the multimedia player buffer length, and service interruptions. A case study is simulated to confirm how the quality of the multimedia service is improved by applying our proposals. ",
    "url": "https://arxiv.org/abs/2402.06424",
    "authors": [
      "C. M. Lentisco",
      "L. Bellido",
      "A. C\u00e1rdenas",
      "R. F. Moyano",
      "D. Fern\u00e1ndez"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2402.06430",
    "title": "Polyarc bounded complex interval arithmetic",
    "abstract": "Complex interval arithmetic is a powerful tool for the analysis of computational errors. The naturally arising rectangular, polar, and circular (together called primitive) interval types are not closed under simple arithmetic operations and their use yields overly relaxed bounds. The later introduced polygonal type, on the other hand, allows for arbitrarily precise representaion of the above operations for a higher computational cost. We propose the polyarcular interval type as an effective extension of the previous types. The polyarcular interval can represent all primitive intervals and most of their arithmetic combinations precisely and has a approximation capability competing with that of the polygonal interval. In particular, in antenna tolerance analysis it can achieve perfect accuracy for lower computational cost then the polygonal type, which we show in a relevant case study. In this paper, we present a rigorous analysis of the arithmetic properties of all five interval types, involving a new algebro-geometric method of boundary analysis. ",
    "url": "https://arxiv.org/abs/2402.06430",
    "authors": [
      "G\u00e1bor Ger\u00e9b",
      "Andr\u00e1s S\u00e1ndor"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Algebraic Geometry (math.AG)"
    ]
  },
  {
    "id": "arXiv:2402.06441",
    "title": "Incorporating Taylor Series and Recursive Structure in Neural Networks  for Time Series Prediction",
    "abstract": "Time series analysis is relevant in various disciplines such as physics, biology, chemistry, and finance. In this paper, we present a novel neural network architecture that integrates elements from ResNet structures, while introducing the innovative incorporation of the Taylor series framework. This approach demonstrates notable enhancements in test accuracy across many of the baseline datasets investigated. Furthermore, we extend our method to incorporate a recursive step, which leads to even further improvements in test accuracy. Our findings underscore the potential of our proposed model to significantly advance time series analysis methodologies, offering promising avenues for future research and application. ",
    "url": "https://arxiv.org/abs/2402.06441",
    "authors": [
      "Jarrod Mau",
      "Kevin Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06499",
    "title": "BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in  heterogeneous data with cross-domain self-supervised learning",
    "abstract": "Background: Chest X-ray imaging-based abnormality localization, essential in diagnosing various diseases, faces significant clinical challenges due to complex interpretations and the growing workload of radiologists. While recent advances in deep learning offer promising solutions, there is still a critical issue of domain inconsistency in cross-domain transfer learning, which hampers the efficiency and accuracy of diagnostic processes. This study aims to address the domain inconsistency problem and improve autonomic abnormality localization performance of heterogeneous chest X-ray image analysis, by developing a self-supervised learning strategy called \"BarlwoTwins-CXR\". Methods: We utilized two publicly available datasets: the NIH Chest X-ray Dataset and the VinDr-CXR. The BarlowTwins-CXR approach was conducted in a two-stage training process. Initially, self-supervised pre-training was performed using an adjusted Barlow Twins algorithm on the NIH dataset with a Resnet50 backbone pre-trained on ImageNet. This was followed by supervised fine-tuning on the VinDr-CXR dataset using Faster R-CNN with Feature Pyramid Network (FPN). Results: Our experiments showed a significant improvement in model performance with BarlowTwins-CXR. The approach achieved a 3% increase in mAP50 accuracy compared to traditional ImageNet pre-trained models. In addition, the Ablation CAM method revealed enhanced precision in localizing chest abnormalities. Conclusion: BarlowTwins-CXR significantly enhances the efficiency and accuracy of chest X-ray image-based abnormality localization, outperforming traditional transfer learning methods and effectively overcoming domain inconsistency in cross-domain scenarios. Our experiment results demonstrate the potential of using self-supervised learning to improve the generalizability of models in medical settings with limited amounts of heterogeneous data. ",
    "url": "https://arxiv.org/abs/2402.06499",
    "authors": [
      "Haoyue Sheng",
      "Linrui Ma",
      "Jean-Francois Samson",
      "Dianbo Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06500",
    "title": "On the Fly Detection of Root Causes from Observed Data with Application  to IT Systems",
    "abstract": "This paper introduces a new structural causal model tailored for representing threshold-based IT systems and presents a new algorithm designed to rapidly detect root causes of anomalies in such systems. When root causes are not causally related, the method is proven to be correct; while an extension is proposed based on the intervention of an agent to relax this assumption. Our algorithm and its agent-based extension leverage causal discovery from offline data and engage in subgraph traversal when encountering new anomalies in online data. Our extensive experiments demonstrate the superior performance of our methods, even when applied to data generated from alternative structural causal models or real IT monitoring data. ",
    "url": "https://arxiv.org/abs/2402.06500",
    "authors": [
      "Lei Zan",
      "Charles K. Assaad",
      "Emilie Devijver",
      "Eric Gaussier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06504",
    "title": "Solving Complex Multi-UAV Mission Planning Problems using  Multi-objective Genetic Algorithms",
    "abstract": "Due to recent booming of UAVs technologies, these are being used in many fields involving complex tasks. Some of them involve a high risk to the vehicle driver, such as fire monitoring and rescue tasks, which make UAVs excellent for avoiding human risks. Mission Planning for UAVs is the process of planning the locations and actions (loading/dropping a load, taking videos/pictures, acquiring information) for the vehicles, typically over a time period. These vehicles are controlled from Ground Control Stations (GCSs) where human operators use rudimentary systems. This paper presents a new Multi-Objective Genetic Algorithm for solving complex Mission Planning Problems (MPP) involving a team of UAVs and a set of GCSs. A hybrid fitness function has been designed using a Constraint Satisfaction Problem (CSP) to check if solutions are valid and Pareto-based measures to look for optimal solutions. The algorithm has been tested on several datasets optimizing different variables of the mission, such as the makespan, the fuel consumption, distance, etc. Experimental results show that the new algorithm is able to obtain good solutions, however as the problem becomes more complex, the optimal solutions also become harder to find. ",
    "url": "https://arxiv.org/abs/2402.06504",
    "authors": [
      "Cristian Ramirez-Atencia",
      "Gema Bello-Orgaz",
      "Maria D R-Moreno",
      "David Camacho"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.06506",
    "title": "Classifying point clouds at the facade-level using geometric features  and deep learning networks",
    "abstract": "3D building models with facade details are playing an important role in many applications now. Classifying point clouds at facade-level is key to create such digital replicas of the real world. However, few studies have focused on such detailed classification with deep neural networks. We propose a method fusing geometric features with deep learning networks for point cloud classification at facade-level. Our experiments conclude that such early-fused features improve deep learning methods' performance. This method can be applied for compensating deep learning networks' ability in capturing local geometric information and promoting the advancement of semantic segmentation. ",
    "url": "https://arxiv.org/abs/2402.06506",
    "authors": [
      "Yue Tan",
      "Olaf Wysocki",
      "Ludwig Hoegner",
      "Uwe Stilla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06511",
    "title": "Toward Building a Semantic Network Inventory for Model-Driven Telemetry",
    "abstract": "Network telemetry based on data models is expected to become the standard mechanism for collecting operational data from network devices efficiently. But the wide variety of standard and proprietary data models along with the different implementations of telemetry protocols offered by network vendors, become a barrier when monitoring heterogeneous network infrastructures. To facilitate the integration and sharing of context information related to model-driven telemetry, this work proposes a semantic network inventory that integrates new information models specifically developed to capture context information in a vendor-agnostic fashion using current standards defined for context management. To automate the integration of this context information within the network inventory, a reference architecture is designed. Finally, a prototype of the solution is implemented and validated through a case study that illustrates how the network inventory can ease the operation of model-driven telemetry in multi-vendor networks. ",
    "url": "https://arxiv.org/abs/2402.06511",
    "authors": [
      "I. D. Mart\u00ednez-Casanueva",
      "D. Gonz\u00e1lez-Sanchez",
      "L. Bellido",
      "D. Fern\u00e1ndez",
      "D. R. L\u00f3pez"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.06512",
    "title": "Multimodal Clinical Trial Outcome Prediction with Large Language Models",
    "abstract": "The clinical trial is a pivotal and costly process, often spanning multiple years and requiring substantial financial resources. Therefore, the development of clinical trial outcome prediction models aims to exclude drugs likely to fail and holds the potential for significant cost savings. Recent data-driven attempts leverage deep learning methods to integrate multimodal data for predicting clinical trial outcomes. However, these approaches rely on manually designed modal-specific encoders, which limits both the extensibility to adapt new modalities and the ability to discern similar information patterns across different modalities. To address these issues, we propose a multimodal mixture-of-experts (LIFTED) approach for clinical trial outcome prediction. Specifically, LIFTED unifies different modality data by transforming them into natural language descriptions. Then, LIFTED constructs unified noise-resilient encoders to extract information from modal-specific language descriptions. Subsequently, a sparse Mixture-of-Experts framework is employed to further refine the representations, enabling LIFTED to identify similar information patterns across different modalities and extract more consistent representations from those patterns using the same expert model. Finally, a mixture-of-experts module is further employed to dynamically integrate different modality representations for prediction, which gives LIFTED the ability to automatically weigh different modalities and pay more attention to critical information. The experiments demonstrate that LIFTED significantly enhances performance in predicting clinical trial outcomes across all three phases compared to the best baseline, showcasing the effectiveness of our proposed key components. ",
    "url": "https://arxiv.org/abs/2402.06512",
    "authors": [
      "Wenhao Zheng",
      "Dongsheng Peng",
      "Hongxia Xu",
      "Hongtu Zhu",
      "Tianfan Fu",
      "Huaxiu Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.06531",
    "title": "Transferring facade labels between point clouds with semantic octrees  while considering change detection",
    "abstract": "Point clouds and high-resolution 3D data have become increasingly important in various fields, including surveying, construction, and virtual reality. However, simply having this data is not enough; to extract useful information, semantic labeling is crucial. In this context, we propose a method to transfer annotations from a labeled to an unlabeled point cloud using an octree structure. The structure also analyses changes between the point clouds. Our experiments confirm that our method effectively transfers annotations while addressing changes. The primary contribution of this project is the development of the method for automatic label transfer between two different point clouds that represent the same real-world object. The proposed method can be of great importance for data-driven deep learning algorithms as it can also allow circumventing stochastic transfer learning by deterministic label transfer between datasets depicting the same objects. ",
    "url": "https://arxiv.org/abs/2402.06531",
    "authors": [
      "Sophia Schwarz",
      "Tanja Pilz",
      "Olaf Wysocki",
      "Ludwig Hoegner",
      "Uwe Stilla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06532",
    "title": "Generative Adversarial Bayesian Optimization for Surrogate Objectives",
    "abstract": "Offline model-based policy optimization seeks to optimize a learned surrogate objective function without querying the true oracle objective during optimization. However, inaccurate surrogate model predictions are frequently encountered along the optimization trajectory. To address this limitation, we propose generative adversarial Bayesian optimization (GABO) using adaptive source critic regularization, a task-agnostic framework for Bayesian optimization that employs a Lipschitz-bounded source critic model to constrain the optimization trajectory to regions where the surrogate function is reliable. We show that under certain assumptions for the continuous input space prior, our algorithm dynamically adjusts the strength of the source critic regularization. GABO outperforms existing baselines on a number of different offline optimization tasks across a variety of scientific domains. Our code is available at https://github.com/michael-s-yao/gabo ",
    "url": "https://arxiv.org/abs/2402.06532",
    "authors": [
      "Michael S. Yao",
      "Yimeng Zeng",
      "Hamsa Bastani",
      "Jacob Gardner",
      "James C. Gee",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06537",
    "title": "Feature Density Estimation for Out-of-Distribution Detection via  Normalizing Flows",
    "abstract": "Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection. ",
    "url": "https://arxiv.org/abs/2402.06537",
    "authors": [
      "Evan D. Cook",
      "Marc-Antoine Lavoie",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.06549",
    "title": "Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection  via Retrieval-Augmented GPT-4 and LLaMA",
    "abstract": "This study details our approach for the CASE 2024 Shared Task on Climate Activism Stance and Hate Event Detection, focusing on Hate Speech Detection, Hate Speech Target Identification, and Stance Detection as classification challenges. We explored the capability of Large Language Models (LLMs), particularly GPT-4, in zero- or few-shot settings enhanced by retrieval augmentation and re-ranking for Tweet classification. Our goal was to determine if LLMs could match or surpass traditional methods in this context. We conducted an ablation study with LLaMA for comparison, and our results indicate that our models significantly outperformed the baselines, securing second place in the Target Detection task. The code for our submission is available at https://github.com/NaiveNeuron/bryndza-case-2024 ",
    "url": "https://arxiv.org/abs/2402.06549",
    "authors": [
      "Marek \u0160uppa",
      "Daniel Skala",
      "Daniela Ja\u0161\u0161",
      "Samuel Su\u010d\u00edk",
      "Andrej \u0160vec",
      "Peter Hra\u0161ka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06552",
    "title": "Deceptive Path Planning via Reinforcement Learning with Graph Neural  Networks",
    "abstract": "Deceptive path planning (DPP) is the problem of designing a path that hides its true goal from an outside observer. Existing methods for DPP rely on unrealistic assumptions, such as global state observability and perfect model knowledge, and are typically problem-specific, meaning that even minor changes to a previously solved problem can force expensive computation of an entirely new solution. Given these drawbacks, such methods do not generalize to unseen problem instances, lack scalability to realistic problem sizes, and preclude both on-the-fly tunability of deception levels and real-time adaptivity to changing environments. In this paper, we propose a reinforcement learning (RL)-based scheme for training policies to perform DPP over arbitrary weighted graphs that overcomes these issues. The core of our approach is the introduction of a local perception model for the agent, a new state space representation distilling the key components of the DPP problem, the use of graph neural network-based policies to facilitate generalization and scaling, and the introduction of new deception bonuses that translate the deception objectives of classical methods to the RL setting. Through extensive experimentation we show that, without additional fine-tuning, at test time the resulting policies successfully generalize, scale, enjoy tunable levels of deception, and adapt in real-time to changes in the environment. ",
    "url": "https://arxiv.org/abs/2402.06552",
    "authors": [
      "Michael Y. Fatemi",
      "Wesley A. Suttle",
      "Brian M. Sadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06580",
    "title": "SAE: Single Architecture Ensemble Neural Networks",
    "abstract": "Ensembles of separate neural networks (NNs) have shown superior accuracy and confidence calibration over single NN across tasks. Recent methods compress ensembles within a single network via early exits or multi-input multi-output frameworks. However, the landscape of these methods is fragmented thus far, making it difficult to choose the right approach for a given task. Furthermore, the algorithmic performance of these methods is behind the ensemble of separate NNs and requires extensive architecture tuning. We propose a novel methodology unifying these approaches into a Single Architecture Ensemble (SAE). Our method learns the optimal number and depth of exits per ensemble input in a single NN. This enables the SAE framework to flexibly tailor its configuration for a given architecture or application. We evaluate SAEs on image classification and regression across various network architecture types and sizes. We demonstrate competitive accuracy or confidence calibration to baselines while reducing the compute operations or parameter count by up to $1.5{\\sim}3.7\\times$. ",
    "url": "https://arxiv.org/abs/2402.06580",
    "authors": [
      "Martin Ferianc",
      "Hongxiang Fan",
      "Miguel Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06581",
    "title": "More than the Sum of Its Parts: Ensembling Backbone Networks for  Few-Shot Segmentation",
    "abstract": "Semantic segmentation is a key prerequisite to robust image understanding for applications in \\acrlong{ai} and Robotics. \\acrlong{fss}, in particular, concerns the extension and optimization of traditional segmentation methods in challenging conditions where limited training examples are available. A predominant approach in \\acrlong{fss} is to rely on a single backbone for visual feature extraction. Choosing which backbone to leverage is a deciding factor contributing to the overall performance. In this work, we interrogate on whether fusing features from different backbones can improve the ability of \\acrlong{fss} models to capture richer visual features. To tackle this question, we propose and compare two ensembling techniques-Independent Voting and Feature Fusion. Among the available \\acrlong{fss} methods, we implement the proposed ensembling techniques on PANet. The module dedicated to predicting segmentation masks from the backbone embeddings in PANet avoids trainable parameters, creating a controlled `in vitro' setting for isolating the impact of different ensembling strategies. Leveraging the complementary strengths of different backbones, our approach outperforms the original single-backbone PANet across standard benchmarks even in challenging one-shot learning scenarios. Specifically, it achieved a performance improvement of +7.37\\% on PASCAL-5\\textsuperscript{i} and of +10.68\\% on COCO-20\\textsuperscript{i} in the top-performing scenario where three backbones are combined. These results, together with the qualitative inspection of the predicted subject masks, suggest that relying on multiple backbones in PANet leads to a more comprehensive feature representation, thus expediting the successful application of \\acrlong{fss} methods in challenging, data-scarce environments. ",
    "url": "https://arxiv.org/abs/2402.06581",
    "authors": [
      "Nico Catalano",
      "Alessandro Maranelli",
      "Agnese Chiatti",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06596",
    "title": "Understanding the Weakness of Large Language Model Agents within a  Complex Android Environment",
    "abstract": "Large language models (LLMs) have empowered intelligent agents to execute intricate tasks within domain-specific software such as browsers and games. However, when applied to general-purpose software systems like operating systems, LLM agents face three primary challenges. Firstly, the action space is vast and dynamic, posing difficulties for LLM agents to maintain an up-to-date understanding and deliver accurate responses. Secondly, real-world tasks often require inter-application cooperation}, demanding farsighted planning from LLM agents. Thirdly, agents need to identify optimal solutions aligning with user constraints, such as security concerns and preferences. These challenges motivate AndroidArena, an environment and benchmark designed to evaluate LLM agents on a modern operating system. To address high-cost of manpower, we design a scalable and semi-automated method to construct the benchmark. In the task evaluation, AndroidArena incorporates accurate and adaptive metrics to address the issue of non-unique solutions. Our findings reveal that even state-of-the-art LLM agents struggle in cross-APP scenarios and adhering to specific constraints. Additionally, we identify a lack of four key capabilities, i.e., understanding, reasoning, exploration, and reflection, as primary reasons for the failure of LLM agents. Furthermore, we provide empirical analysis on the failure of reflection, and improve the success rate by 27% with our proposed exploration strategy. This work is the first to present valuable insights in understanding fine-grained weakness of LLM agents, and offers a path forward for future research in this area. Environment, benchmark, and evaluation code for AndroidArena are released at https://github.com/AndroidArenaAgent/AndroidArena. ",
    "url": "https://arxiv.org/abs/2402.06596",
    "authors": [
      "Mingzhe Xing",
      "Rongkai Zhang",
      "Hui Xue",
      "Qi Chen",
      "Fan Yang",
      "Zhen Xiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.06611",
    "title": "Image-based Deep Learning for the time-dependent prediction of fresh  concrete properties",
    "abstract": "Increasing the degree of digitisation and automation in the concrete production process can play a crucial role in reducing the CO$_2$ emissions that are associated with the production of concrete. In this paper, a method is presented that makes it possible to predict the properties of fresh concrete during the mixing process based on stereoscopic image sequences of the concretes flow behaviour. A Convolutional Neural Network (CNN) is used for the prediction, which receives the images supported by information on the mix design as input. In addition, the network receives temporal information in the form of the time difference between the time at which the images are taken and the time at which the reference values of the concretes are carried out. With this temporal information, the network implicitly learns the time-dependent behaviour of the concretes properties. The network predicts the slump flow diameter, the yield stress and the plastic viscosity. The time-dependent prediction potentially opens up the pathway to determine the temporal development of the fresh concrete properties already during mixing. This provides a huge advantage for the concrete industry. As a result, countermeasures can be taken in a timely manner. It is shown that an approach based on depth and optical flow images, supported by information of the mix design, achieves the best results. ",
    "url": "https://arxiv.org/abs/2402.06611",
    "authors": [
      "Max Meyer",
      "Amadeus Langer",
      "Max Mehltretter",
      "Dries Beyer",
      "Max Coenen",
      "Tobias Schack",
      "Michael Haist",
      "Christian Heipke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.06614",
    "title": "The Complexity of Sequential Prediction in Dynamical Systems",
    "abstract": "We study the problem of learning to predict the next state of a dynamical system when the underlying evolution function is unknown. Unlike previous work, we place no parametric assumptions on the dynamical system, and study the problem from a learning theory perspective. We define new combinatorial measures and dimensions and show that they quantify the optimal mistake and regret bounds in the realizable and agnostic setting respectively. ",
    "url": "https://arxiv.org/abs/2402.06614",
    "authors": [
      "Vinod Raman",
      "Unique Subedi",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.06622",
    "title": "A two-stage algorithm in evolutionary product unit neural networks for  classification",
    "abstract": "This paper presents a procedure to add broader diversity at the beginning of the evolutionary process. It consists of creating two initial populations with different parameter settings, evolving them for a small number of generations, selecting the best individuals from each population in the same proportion and combining them to constitute a new initial population. At this point the main loop of an evolutionary algorithm is applied to the new population. The results show that our proposal considerably improves both the efficiency of previous methodologies and also, significantly, their efficacy in most of the data sets. We have carried out our experimentation on twelve data sets from the UCI repository and two complex real-world problems which differ in their number of instances, features and classes. ",
    "url": "https://arxiv.org/abs/2402.06622",
    "authors": [
      "Antonio J. Tall\u00f3n-Ballesteros",
      "C\u00e9sar Herv\u00e1s-Mart\u00ednez"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.05972",
    "title": "Gaussian-process-regression-based method for the localization of  exceptional points in complex resonance spectra",
    "abstract": "Resonances in open quantum systems depending on at least two controllable parameters can show the phenomenon of exceptional points (EPs), where not only the eigenvalues but also the eigenvectors of two or more resonances coalesce. Their exact localization in the parameter space is challenging, in particular in systems, where the computation of the quantum spectra and resonances is numerically very expensive. We introduce an efficient machine learning algorithm to find exceptional points based on Gaussian process regression (GPR). The GPR-model is trained with an initial set of eigenvalue pairs belonging to an EP and used for a first estimation of the EP position via a numerically cheap root search. The estimate is then improved iteratively by adding selected exact eigenvalue pairs as training points to the GPR-model. The GPR-based method is developed and tested on a simple low-dimensional matrix model and then applied to a challenging real physical system, viz., the localization of EPs in the resonance spectra of excitons in cuprous oxide in external electric and magnetic fields. The precise computation of EPs, by taking into account the complete valence band structure and central-cell corrections of the crystal, can be the basis for the experimental observation of EPs in this system. ",
    "url": "https://arxiv.org/abs/2402.05972",
    "authors": [
      "Patrick Egenlauf",
      "Patric Rommel",
      "J\u00f6rg Main"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.05975",
    "title": "A Deep Learning Approach for Brain Tumor Classification and Segmentation  Using a Multiscale Convolutional Neural Network",
    "abstract": "In this paper, we present a fully automatic brain tumor segmentation and classification model using a Deep Convolutional Neural Network that includes a multiscale approach. One of the differences of our proposal with respect to previous works is that input images are processed in three spatial scales along different processing pathways. This mechanism is inspired in the inherent operation of the Human Visual System. The proposed neural model can analyze MRI images containing three types of tumors: meningioma, glioma, and pituitary tumor, over sagittal, coronal, and axial views and does not need preprocessing of input images to remove skull or vertebral column parts in advance. The performance of our method on a publicly available MRI image dataset of 3064 slices from 233 patients is compared with previously classical machine learning and deep learning published methods. In the comparison, our method remarkably obtained a tumor classification accuracy of 0.973, higher than the other approaches using the same database. ",
    "url": "https://arxiv.org/abs/2402.05975",
    "authors": [
      "Francisco Javier D\u00edaz-Pernas",
      "Mario Mart\u00ednez-Zarzuela",
      "M\u00edriam Ant\u00f3n-Rodr\u00edguez",
      "David Gonz\u00e1lez-Ortega"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06026",
    "title": "Quantum neural network with ensemble learning to mitigate barren  plateaus and cost function concentration",
    "abstract": "The rapid development of quantum computers promises transformative impacts across diverse fields of science and technology. Quantum neural networks (QNNs), as a forefront application, hold substantial potential. Despite the multitude of proposed models in the literature, persistent challenges, notably the vanishing gradient (VG) and cost function concentration (CFC) problems, impede their widespread success. In this study, we introduce a novel approach to quantum neural network construction, specifically addressing the issues of VG and CFC. Our methodology employs ensemble learning, advocating for the simultaneous deployment of multiple quantum circuits with a depth equal to $1$, a departure from the conventional use of a single quantum circuit with depth $L$. We assess the efficacy of our proposed model through a comparative analysis with a conventionally constructed QNN. The evaluation unfolds in the context of a classification problem, yielding valuable insights into the potential advantages of our innovative approach. ",
    "url": "https://arxiv.org/abs/2402.06026",
    "authors": [
      "Lucas Friedrich",
      "Jonas Maziero"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.06033",
    "title": "An Inexact Halpern Iteration for with Application to Distributionally  Robust Optimization",
    "abstract": "The Halpern iteration for solving monotone inclusion problems has gained increasing interests in recent years due to its simple form and appealing convergence properties. In this paper, we investigate the inexact variants of the scheme in both deterministic and stochastic settings. We conduct extensive convergence analysis and show that by choosing the inexactness tolerances appropriately, the inexact schemes admit an $O(k^{-1})$ convergence rate in terms of the (expected) residue norm. Our results relax the state-of-the-art inexactness conditions employed in the literature while sharing the same competitive convergence properties. We then demonstrate how the proposed methods can be applied for solving two classes of data-driven Wasserstein distributionally robust optimization problems that admit convex-concave min-max optimization reformulations. We highlight its capability of performing inexact computations for distributionally robust learning with stochastic first-order methods. ",
    "url": "https://arxiv.org/abs/2402.06033",
    "authors": [
      "Ling Liang",
      "Kim-Chuan Toh",
      "Jia-Jie Zhu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06063",
    "title": "3D-2D Neural Nets for Phase Retrieval in Noisy Interferometric Imaging",
    "abstract": "In recent years, neural networks have been used to solve phase retrieval problems in imaging with superior accuracy and speed than traditional techniques, especially in the presence of noise. However, in the context of interferometric imaging, phase noise has been largely unaddressed by existing neural network architectures. Such noise arises naturally in an interferometer due to mechanical instabilities or atmospheric turbulence, limiting measurement acquisition times and posing a challenge in scenarios with limited light intensity, such as remote sensing. Here, we introduce a 3D-2D Phase Retrieval U-Net (PRUNe) that takes noisy and randomly phase-shifted interferograms as inputs, and outputs a single 2D phase image. A 3D downsampling convolutional encoder captures correlations within and between frames to produce a 2D latent space, which is upsampled by a 2D decoder into a phase image. We test our model against a state-of-the-art singular value decomposition algorithm and find PRUNe reconstructions consistently show more accurate and smooth reconstructions, with a x2.5 - 4 lower mean squared error at multiple signal-to-noise ratios for interferograms with low (< 1 photon/pixel) and high (~100 photons/pixel) signal intensity. Our model presents a faster and more accurate approach to perform phase retrieval in extremely low light intensity interferometry in presence of phase noise, and will find application in other multi-frame noisy imaging techniques. ",
    "url": "https://arxiv.org/abs/2402.06063",
    "authors": [
      "Andrew H. Proppe",
      "Guillaume Thekkadath",
      "Duncan England",
      "Philip J. Bustard",
      "Fr\u00e9d\u00e9ric Bouchard",
      "Jeff S. Lundeen",
      "Benjamin J. Sussman"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.06246",
    "title": "Data-driven Joint Detection and Localization of Acoustic Reflectors",
    "abstract": "Room geometry inference algorithms rely on the localization of acoustic reflectors to identify boundary surfaces of an enclosure. Rooms with highly absorptive walls or walls at large distances from the measurement setup pose challenges for such algorithms. As it is not always possible to localize all walls, we present a data-driven method to jointly detect and localize acoustic reflectors that correspond to nearby and/or reflective walls. A multi-branch convolutional recurrent neural network is employed for this purpose. The network's input consists of a time-domain acoustic beamforming map, obtained via Radon transform from multi-channel room impulse responses. A modified loss function is proposed that forces the network to pay more attention to walls that can be estimated with a small error. Simulation results show that the proposed method can detect nearby and/or reflective walls and improve the localization performance for the detected walls. ",
    "url": "https://arxiv.org/abs/2402.06246",
    "authors": [
      "H. Nazim Bicer",
      "Cagdas Tuna",
      "Andreas Walther",
      "Emanu\u00ebl A. P. Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.06260",
    "title": "Vertex-minor universal graphs for generating entangled quantum  subsystems",
    "abstract": "We study the notion of $k$-stabilizer universal quantum state, that is, an $n$-qubit quantum state, such that it is possible to induce any stabilizer state on any $k$ qubits, by using only local operations and classical communications. These states generalize the notion of $k$-pairable states introduced by Bravyi et al., and can be studied from a combinatorial perspective using graph states and $k$-vertex-minor universal graphs. First, we demonstrate the existence of $k$-stabilizer universal graph states that are optimal in size with $n=\\Theta(k^2)$ qubits. We also provide parameters for which a random graph state on $\\Theta(k^2)$ qubits is $k$-stabilizer universal with high probability. Our second contribution consists of two explicit constructions of $k$-stabilizer universal graph states on $n = O(k^4)$ qubits. Both rely upon the incidence graph of the projective plane over a finite field $\\mathbb{F}_q$. This provides a major improvement over the previously known explicit construction of $k$-pairable graph states with $n = O(2^{3k})$, bringing forth a new and potentially powerful family of multipartite quantum resources. ",
    "url": "https://arxiv.org/abs/2402.06260",
    "authors": [
      "Maxime Cautr\u00e8s",
      "Nathan Claudet",
      "Mehdi Mhalla",
      "Simon Perdrix",
      "Valentin Savin",
      "St\u00e9phane Thomass\u00e9"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.06275",
    "title": "Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics",
    "abstract": "Smoothed particle hydrodynamics (SPH) is omnipresent in modern engineering and scientific disciplines. SPH is a class of Lagrangian schemes that discretize fluid dynamics via finite material points that are tracked through the evolving velocity field. Due to the particle-like nature of the simulation, graph neural networks (GNNs) have emerged as appealing and successful surrogates. However, the practical utility of such GNN-based simulators relies on their ability to faithfully model physics, providing accurate and stable predictions over long time horizons - which is a notoriously hard problem. In this work, we identify particle clustering originating from tensile instabilities as one of the primary pitfalls. Based on these insights, we enhance both training and rollout inference of state-of-the-art GNN-based simulators with varying components from standard SPH solvers, including pressure, viscous, and external force components. All neural SPH-enhanced simulators achieve better performance, often by orders of magnitude, than the baseline GNNs, allowing for significantly longer rollouts and significantly better physics modeling. Code available under (https://github.com/tumaer/neuralsph). ",
    "url": "https://arxiv.org/abs/2402.06275",
    "authors": [
      "Artur P. Toshev",
      "Jonas A. Erbesdobler",
      "Nikolaus A. Adams",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06338",
    "title": "Graphs without a 3-connected subgraph are 4-colorable",
    "abstract": "In 1972, Mader showed that every graph without a 3-connected subgraph is 4-degenerate and thus 5-colorable}. We show that the number 5 of colors can be replaced by 4, which is best possible. ",
    "url": "https://arxiv.org/abs/2402.06338",
    "authors": [
      "\u00c9douard Bonnet",
      "Carl Feghali",
      "St\u00e9phan Thomass\u00e9",
      "Nicolas Trotignon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.06455",
    "title": "Quantum Computing and Tensor Networks for Laminate Design: A Novel  Approach to Stacking Sequence Retrieval",
    "abstract": "As with many tasks in engineering, structural design frequently involves navigating complex and computationally expensive problems. A prime example is the weight optimization of laminated composite materials, which to this day remains a formidable task, due to an exponentially large configuration space and non-linear constraints. The rapidly developing field of quantum computation may offer novel approaches for addressing these intricate problems. However, before applying any quantum algorithm to a given problem, it must be translated into a form that is compatible with the underlying operations on a quantum computer. Our work specifically targets stacking sequence retrieval with lamination parameters. To adapt this problem for quantum computational methods, we map the possible stacking sequences onto a quantum state space. We further derive a linear operator, the Hamiltonian, within this state space that encapsulates the loss function inherent to the stacking sequence retrieval problem. Additionally, we demonstrate the incorporation of manufacturing constraints on stacking sequences as penalty terms in the Hamiltonian. This quantum representation is suitable for a variety of classical and quantum algorithms for finding the ground state of a quantum Hamiltonian. For a practical demonstration, we chose a classical tensor network algorithm, the DMRG algorithm, to numerically validate our approach. For this purpose, we derived a matrix product operator representation of the loss function Hamiltonian and the penalty terms. Numerical trials with this algorithm successfully yielded approximate solutions, while exhibiting a tradeoff between accuracy and runtime. Although this work primarily concentrates on quantum computation, the application of tensor network algorithms presents a novel quantum-inspired approach for stacking sequence retrieval. ",
    "url": "https://arxiv.org/abs/2402.06455",
    "authors": [
      "Arne Wulff",
      "Boyang Chen",
      "Matthew Steinberg",
      "Yinglu Tang",
      "Matthias M\u00f6ller",
      "Sebastian Feld"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2402.06525",
    "title": "Flexible infinite-width graph convolutional networks and the importance  of representation learning",
    "abstract": "A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become Gaussian process (GP) distributed. This is known as a neural network Gaussian process (NNGP). However, the NNGP kernel is fixed, and tunable only through a small number of hyperparameters, eliminating any possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well precisely because they are able to learn representations. Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of graph classification tasks. We develop a precise tool for this task, the graph convolutional deep kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a `knob' to control the amount of representation learning. We found that representation learning is necessary (in the sense that it gives dramatic performance improvements) in graph classification tasks and heterophilous node classification tasks, but not in homophilous node classification tasks. ",
    "url": "https://arxiv.org/abs/2402.06525",
    "authors": [
      "Ben Anson",
      "Edward Milsom",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06616",
    "title": "Bakry-\u00c9mery-Ricci curvature: An alternative network geometry measure  in the expanding toolbox of graph Ricci curvatures",
    "abstract": "The characterization of complex networks with tools originating in geometry, for instance through the statistics of so-called Ricci curvatures, is a well established tool of network science. There exist various types of such Ricci curvatures, capturing different aspects of network geometry. In the present work, we investigate Bakry-\\'Emery-Ricci curvature, a notion of discrete Ricci curvature that has been studied much in geometry, but so far has not been applied to networks. We explore on standard classes of artificial networks as well as on selected empirical ones to what the statistics of that curvature are similar to or different from that of other curvatures, how it is correlated to other important network measures, and what it tells us about the underlying network. We observe that most vertices typically have negative curvature. Random and small-world networks exhibit a narrow curvature distribution whereas other classes and most of the real-world networks possess a wide curvature distribution. When we compare Bakry-\\'Emery-Ricci curvature with two other discrete notions of Ricci-curvature, Forman-Ricci and Ollivier-Ricci curvature for both model and real-world networks, we observe a high positive correlation between Bakry-\\'Emery-Ricci and both Forman-Ricci and Ollivier-Ricci curvature, and in particular with the augmented version of Forman-Ricci curvature. Bakry-\\'Emery-Ricci curvature also exhibits a high negative correlation with the vertex centrality measure and degree for most of the model and real-world networks. However, it does not correlate with the clustering coefficient. Also, we investigate the importance of vertices with highly negative curvature values to maintain communication in the network. The computational time for Bakry-\\'Emery-Ricci curvature is shorter than that required for Ollivier-Ricci curvature but higher than for Augmented Forman-Ricci curvature. ",
    "url": "https://arxiv.org/abs/2402.06616",
    "authors": [
      "Madhumita Mondal",
      "Areejit Samal",
      "Florentin M\u00fcnch",
      "J\u00fcrgen Jost"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2007.06007",
    "title": "Universal Approximation Power of Deep Residual Neural Networks via  Nonlinear Control Theory",
    "abstract": " Comments: Sejun Park and Geonho Hwang brought to our atention a mistake in the proof of Theorem 5.1. This mistake is corrected in this version with the consequence of increasing the number of neurons per layer from n+1 to 2n+1 ",
    "url": "https://arxiv.org/abs/2007.06007",
    "authors": [
      "Paulo Tabuada",
      "Bahman Gharesifard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.11856",
    "title": "A Link between Coding Theory and Cross-Validation with Applications",
    "abstract": " Title: A Link between Coding Theory and Cross-Validation with Applications ",
    "url": "https://arxiv.org/abs/2103.11856",
    "authors": [
      "Tapio Pahikkala",
      "Parisa Movahedi",
      "Ileana Montoya",
      "Havu Miikonen",
      "Stephan Foldes",
      "Antti Airola",
      "Laszlo Major"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2108.13975",
    "title": "Extrapolated DIscontinuity Tracking for complex 2D shock interactions",
    "abstract": " Title: Extrapolated DIscontinuity Tracking for complex 2D shock interactions ",
    "url": "https://arxiv.org/abs/2108.13975",
    "authors": [
      "Mirco Ciallella",
      "Mario Ricchiuto",
      "Renato Paciorri",
      "Aldo Bonfiglioli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2202.10027",
    "title": "Toward More Generalized Malicious URL Detection Models",
    "abstract": " Title: Toward More Generalized Malicious URL Detection Models ",
    "url": "https://arxiv.org/abs/2202.10027",
    "authors": [
      "YunDa Tsai",
      "Cayon Liow",
      "Yin Sheng Siang",
      "Shou-De Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.12887",
    "title": "Fault-Tolerant Neural Networks from Biological Error Correction Codes",
    "abstract": " Title: Fault-Tolerant Neural Networks from Biological Error Correction Codes ",
    "url": "https://arxiv.org/abs/2202.12887",
    "authors": [
      "Alexander Zlokapa",
      "Andrew K. Tan",
      "John M. Martyn",
      "Ila R. Fiete",
      "Max Tegmark",
      "Isaac L. Chuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03535",
    "title": "A Multiplex Approach Against Disturbance Propagation in Nonlinear  Networks with Delays",
    "abstract": " Comments: This is an authors' version of the work that is published in IEEE Open Journal of Control Systems, 2024. The final version of record is available at this this https URL ",
    "url": "https://arxiv.org/abs/2206.03535",
    "authors": [
      "Shihao Xie",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.12203",
    "title": "Edge Multiway Cut and Node Multiway Cut are NP-complete on subcubic  graphs",
    "abstract": " Title: Edge Multiway Cut and Node Multiway Cut are NP-complete on subcubic  graphs ",
    "url": "https://arxiv.org/abs/2211.12203",
    "authors": [
      "Matthew Johnson",
      "Barnaby Martin",
      "Siani Smith",
      "Sukanya Pandey",
      "Daniel Paulusma",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.11048",
    "title": "Decidability of well quasi-order and atomicity for equivalence relations  under embedding orderings",
    "abstract": " Title: Decidability of well quasi-order and atomicity for equivalence relations  under embedding orderings ",
    "url": "https://arxiv.org/abs/2301.11048",
    "authors": [
      "V. Ironmonger",
      "N. Ruskuc"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.11584",
    "title": "Robust variance-regularized risk minimization with concomitant scaling",
    "abstract": " Comments: Revised version accepted to AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2301.11584",
    "authors": [
      "Matthew J. Holland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05262",
    "title": "Evaluation of Data Augmentation and Loss Functions in Semantic Image  Segmentation for Drilling Tool Wear Detection",
    "abstract": " Comments: This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Journal of Intelligent Manufacturing, and is available online at this https URL ",
    "url": "https://arxiv.org/abs/2302.05262",
    "authors": [
      "Elke Schlager",
      "Andreas Windisch",
      "Lukas Hanna",
      "Thomas Kl\u00fcnsner",
      "Elias Jan Hagendorfer",
      "Tamara Teppernegg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10890",
    "title": "Learning Interpretable Low-dimensional Representation via Physical  Symmetry",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2302.10890",
    "authors": [
      "Xuanjie Liu",
      "Daniel Chin",
      "Yichen Huang",
      "Gus Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.01734",
    "title": "AdvART: Adversarial Art for Camouflaged Object Detection Attacks",
    "abstract": " Title: AdvART: Adversarial Art for Camouflaged Object Detection Attacks ",
    "url": "https://arxiv.org/abs/2303.01734",
    "authors": [
      "Amira Guesmi",
      "Ioan Marius Bilasco",
      "Muhammad Shafique",
      "Ihsen Alouani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.01235",
    "title": "How Graph Structure and Label Dependencies Contribute to Node  Classification in a Large Network of Documents",
    "abstract": " Comments: 10 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2304.01235",
    "authors": [
      "Pirmin Lemberger",
      "Antoine Saillenfest"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2304.12522",
    "title": "A New Inexact Proximal Linear Algorithm with Adaptive Stopping Criteria  for Robust Phase Retrieval",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2304.12522",
    "authors": [
      "Zhong Zheng",
      "Shiqian Ma",
      "Lingzhou Xue"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.12707",
    "title": "Quantifying Association Capabilities of Large Language Models and Its  Implications on Privacy Leakage",
    "abstract": " Comments: EACL 2024 Findings ",
    "url": "https://arxiv.org/abs/2305.12707",
    "authors": [
      "Hanyin Shao",
      "Jie Huang",
      "Shen Zheng",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.02611",
    "title": "Stochastic Population Update Can Provably Be Helpful in Multi-Objective  Evolutionary Algorithms",
    "abstract": " Title: Stochastic Population Update Can Provably Be Helpful in Multi-Objective  Evolutionary Algorithms ",
    "url": "https://arxiv.org/abs/2306.02611",
    "authors": [
      "Chao Bian",
      "Yawen Zhou",
      "Miqing Li",
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06881",
    "title": "Unmasking Deepfakes: Masked Autoencoding Spatiotemporal Transformers for  Enhanced Video Forgery Detection",
    "abstract": " Comments: This paper has been accepted by IEEE International Joint Conference on Biometrics (IJCB 2023) ",
    "url": "https://arxiv.org/abs/2306.06881",
    "authors": [
      "Sayantan Das",
      "Mojtaba Kolahdouzi",
      "Levent \u00d6zparlak",
      "Will Hickie",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.10943",
    "title": "Probabilistic Matching of Real and Generated Data Statistics in  Generative Adversarial Networks",
    "abstract": " Title: Probabilistic Matching of Real and Generated Data Statistics in  Generative Adversarial Networks ",
    "url": "https://arxiv.org/abs/2306.10943",
    "authors": [
      "Philipp Pilar",
      "Niklas Wahlstr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.17302",
    "title": "Robust Roadside Perception: an Automated Data Synthesis Pipeline  Minimizing Human Annotation",
    "abstract": " Comments: Accepted by IEEE Transactions on Intelligent Vehicles ",
    "url": "https://arxiv.org/abs/2306.17302",
    "authors": [
      "Rusheng Zhang",
      "Depu Meng",
      "Lance Bassett",
      "Shengyin Shen",
      "Zhengxia Zou",
      "Henry X. Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.03789",
    "title": "Synthesizing Forestry Images Conditioned on Plant Phenotype Using a  Generative Adversarial Network",
    "abstract": " Title: Synthesizing Forestry Images Conditioned on Plant Phenotype Using a  Generative Adversarial Network ",
    "url": "https://arxiv.org/abs/2307.03789",
    "authors": [
      "Debasmita Pal",
      "Arun Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.04526",
    "title": "Self-Expanding Neural Networks",
    "abstract": " Comments: 17 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2307.04526",
    "authors": [
      "Rupert Mitchell",
      "Robin Menzenbach",
      "Kristian Kersting",
      "Martin Mundt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.05811",
    "title": "Twin-width of graphs on surfaces",
    "abstract": " Title: Twin-width of graphs on surfaces ",
    "url": "https://arxiv.org/abs/2307.05811",
    "authors": [
      "Daniel Kr\u00e1\u013e",
      "Krist\u00fdna Pek\u00e1rkov\u00e1",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2308.04451",
    "title": "Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning  Attacks",
    "abstract": " Comments: Accepted for publication at the International Conference on Program Comprehension 2024 ",
    "url": "https://arxiv.org/abs/2308.04451",
    "authors": [
      "Domenico Cotroneo",
      "Cristina Improta",
      "Pietro Liguori",
      "Roberto Natella"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.15515",
    "title": "Scalable Algorithms for 2-Packing Sets on Arbitrary Graphs",
    "abstract": " Title: Scalable Algorithms for 2-Packing Sets on Arbitrary Graphs ",
    "url": "https://arxiv.org/abs/2308.15515",
    "authors": [
      "Jannick Borowitz",
      "Ernestine Gro\u00dfmann",
      "Christian Schulz",
      "Dominik Schweisgut"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.16406",
    "title": "CktGNN: Circuit Graph Neural Network for Electronic Design Automation",
    "abstract": " Comments: Accepted by ICLR (International Conference on Learning Representations) 2023 ",
    "url": "https://arxiv.org/abs/2308.16406",
    "authors": [
      "Zehao Dong",
      "Weidong Cao",
      "Muhan Zhang",
      "Dacheng Tao",
      "Yixin Chen",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.00588",
    "title": "Discrete Morphological Neural Networks",
    "abstract": " Title: Discrete Morphological Neural Networks ",
    "url": "https://arxiv.org/abs/2309.00588",
    "authors": [
      "Diego Marcondes",
      "Junior Barrera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.00738",
    "title": "Rethinking the Power of Graph Canonization in Graph Representation  Learning with Stability",
    "abstract": " Title: Rethinking the Power of Graph Canonization in Graph Representation  Learning with Stability ",
    "url": "https://arxiv.org/abs/2309.00738",
    "authors": [
      "Zehao Dong",
      "Muhan Zhang",
      "Philip R.O. Payne",
      "Michael A Province",
      "Carlos Cruchaga",
      "Tianyu Zhao",
      "Fuhai Li",
      "Yixin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03631",
    "title": "Insights Into the Inner Workings of Transformer Models for Protein  Function Prediction",
    "abstract": " Comments: 26 pages, 12 figures, 5 tables, source code available at this https URL ",
    "url": "https://arxiv.org/abs/2309.03631",
    "authors": [
      "Markus Wenzel",
      "Erik Gr\u00fcner",
      "Nils Strodthoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2309.06358",
    "title": "Generative Data Augmentation using LLMs improves Distributional  Robustness in Question Answering",
    "abstract": " Comments: 10 tables, 1 figure, To appear at EACL 2024 Student Research Workshop ",
    "url": "https://arxiv.org/abs/2309.06358",
    "authors": [
      "Arijit Ghosh Chowdhury",
      "Aman Chadha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05207",
    "title": "Facial Action Unit Detection Based on Multi-task Learning Strategy for  Unlabeled Facial Images in the Wild",
    "abstract": " Comments: 15 pages, 6 figure, submitted to an Elsevier journal ",
    "url": "https://arxiv.org/abs/2310.05207",
    "authors": [
      "Ziqiao Shang",
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17042",
    "title": "StochGradAdam: Accelerating Neural Networks Training with Stochastic  Gradient Sampling",
    "abstract": " Title: StochGradAdam: Accelerating Neural Networks Training with Stochastic  Gradient Sampling ",
    "url": "https://arxiv.org/abs/2310.17042",
    "authors": [
      "Juyoung Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.06623",
    "title": "VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach  For Intelligent Highway Transportation Systems",
    "abstract": " Title: VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach  For Intelligent Highway Transportation Systems ",
    "url": "https://arxiv.org/abs/2311.06623",
    "authors": [
      "Armin Danesh Pazho",
      "Vinit Katariya",
      "Ghazal Alinezhad Noghre",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12944",
    "title": "SkyCharge: Deploying Unmanned Aerial Vehicles for Dynamic Load  Optimization in Solar Small Cell 5G Networks",
    "abstract": " Title: SkyCharge: Deploying Unmanned Aerial Vehicles for Dynamic Load  Optimization in Solar Small Cell 5G Networks ",
    "url": "https://arxiv.org/abs/2311.12944",
    "authors": [
      "Daksh Dave",
      "Vinay Chamola",
      "Sandeep Joshi",
      "Sherali Zeadally"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.15024",
    "title": "A Comperative Study of Watering Hole Attack Detection Using Supervised  Neural Network",
    "abstract": " Title: A Comperative Study of Watering Hole Attack Detection Using Supervised  Neural Network ",
    "url": "https://arxiv.org/abs/2311.15024",
    "authors": [
      "Mst. Nishita Aktar",
      "Sornali Akter",
      "Md. Nusaim Islam Saad",
      "Jakir Hosen Jisun",
      "Kh. Mustafizur Rahman",
      "Md. Nazmus Sakib"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.16594",
    "title": "Monitor Placement for Fault Localization in Deep Neural Network  Accelerators",
    "abstract": " Title: Monitor Placement for Fault Localization in Deep Neural Network  Accelerators ",
    "url": "https://arxiv.org/abs/2311.16594",
    "authors": [
      "Wei-Kai Liu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17943",
    "title": "LayerCollapse: Adaptive compression of neural networks",
    "abstract": " Title: LayerCollapse: Adaptive compression of neural networks ",
    "url": "https://arxiv.org/abs/2311.17943",
    "authors": [
      "Soheil Zibakhsh Shabgahi",
      "Mohammad Sohail Shariff",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14001",
    "title": "Deep Learning Based Face Recognition Method using Siamese Network",
    "abstract": " Title: Deep Learning Based Face Recognition Method using Siamese Network ",
    "url": "https://arxiv.org/abs/2312.14001",
    "authors": [
      "Enoch Solomon",
      "Abraham Woubie",
      "Eyael Solomon Emiru"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.15824",
    "title": "Self-Supervised Learning for Few-Shot Bird Sound Classification",
    "abstract": " Title: Self-Supervised Learning for Few-Shot Bird Sound Classification ",
    "url": "https://arxiv.org/abs/2312.15824",
    "authors": [
      "Ilyass Moummad",
      "Romain Serizel",
      "Nicolas Farrugia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2401.03003",
    "title": "AST-T5: Structure-Aware Pretraining for Code Generation and  Understanding",
    "abstract": " Title: AST-T5: Structure-Aware Pretraining for Code Generation and  Understanding ",
    "url": "https://arxiv.org/abs/2401.03003",
    "authors": [
      "Linyuan Gong",
      "Mostafa Elhoushi",
      "Alvin Cheung"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.09773",
    "title": "SEINE: Structure Encoding and Interaction Network for Nuclei Instance  Segmentation",
    "abstract": " Comments: 10 pages, 12 figures, 6 tables, submitted to TMI ",
    "url": "https://arxiv.org/abs/2401.09773",
    "authors": [
      "Ye Zhang",
      "Linghan Cai",
      "Ziyue Wang",
      "Yongbing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.14005",
    "title": "Cyber-Twin: Digital Twin-boosted Autonomous Attack Detection for  Vehicular Ad-Hoc Networks",
    "abstract": " Comments: 6 pages, 6 figures, IEEE International Conference on Communications (ICC) 2024 ",
    "url": "https://arxiv.org/abs/2401.14005",
    "authors": [
      "Yagmur Yigit",
      "Ioannis Panitsas",
      "Leandros Maglaras",
      "Leandros Tassiulas",
      "Berk Canberk"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.18030",
    "title": "Distributed fixed-point algorithms for dynamic convex optimization over  decentralized and unbalanced wireless networks",
    "abstract": " Comments: 1. Accepted 27th International Workshop on Smart Antennas (WSA 2024), and will be presented during the conference on March 17 to 19, 2024, Dresden, Germany. 2. New version with corrections ",
    "url": "https://arxiv.org/abs/2401.18030",
    "authors": [
      "Navneet Agrawal",
      "Renato L.G. Cavalcante",
      "Slawomir Stanczak"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2402.01344",
    "title": "Monotone, Bi-Lipschitz, and Polyak-Lojasiewicz Networks",
    "abstract": " Title: Monotone, Bi-Lipschitz, and Polyak-Lojasiewicz Networks ",
    "url": "https://arxiv.org/abs/2402.01344",
    "authors": [
      "Ruigang Wang",
      "Krishnamurthy Dvijotham",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.03646",
    "title": "Lens: A Foundation Model for Network Traffic in Cybersecurity",
    "abstract": " Title: Lens: A Foundation Model for Network Traffic in Cybersecurity ",
    "url": "https://arxiv.org/abs/2402.03646",
    "authors": [
      "Qineng Wang",
      "Chen Qian",
      "Xiaochang Li",
      "Ziyu Yao",
      "Huajie Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.03843",
    "title": "A new method for optical steel rope non-destructive damage detection",
    "abstract": " Title: A new method for optical steel rope non-destructive damage detection ",
    "url": "https://arxiv.org/abs/2402.03843",
    "authors": [
      "Yunqing Bao",
      "Bin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.04377",
    "title": "NeRCC: Nested-Regression Coded Computing for Resilient Distributed  Prediction Serving Systems",
    "abstract": " Title: NeRCC: Nested-Regression Coded Computing for Resilient Distributed  Prediction Serving Systems ",
    "url": "https://arxiv.org/abs/2402.04377",
    "authors": [
      "Parsa Moradi",
      "Mohammad Ali Maddah-Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.04424",
    "title": "Optimal Binary Signaling for a Two Sensor Gaussian MAC Network",
    "abstract": " Title: Optimal Binary Signaling for a Two Sensor Gaussian MAC Network ",
    "url": "https://arxiv.org/abs/2402.04424",
    "authors": [
      "Luca Sardellitti",
      "Glen Takahara",
      "Fady Alajaji"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.05027",
    "title": "Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs  with Recurrent Message Passing",
    "abstract": " Comments: Accepted at AAMAS 2024, version with appendix; revised sections 1 and 7, corrected table 1, final results unchanged ",
    "url": "https://arxiv.org/abs/2402.05027",
    "authors": [
      "Jannis Weil",
      "Zhenghua Bao",
      "Osama Abboud",
      "Tobias Meuser"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05203",
    "title": "Bellman Conformal Inference: Calibrating Prediction Intervals For Time  Series",
    "abstract": " Comments: 17 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2402.05203",
    "authors": [
      "Zitong Yang",
      "Emmanuel Cand\u00e8s",
      "Lihua Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.05347",
    "title": "Robust Implicit Adaptive Low Rank Time-Stepping Methods for Matrix  Differential Equations",
    "abstract": " Title: Robust Implicit Adaptive Low Rank Time-Stepping Methods for Matrix  Differential Equations ",
    "url": "https://arxiv.org/abs/2402.05347",
    "authors": [
      "Daniel Appel\u00f6",
      "Yingda Cheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.05391",
    "title": "Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey",
    "abstract": " Comments: Ongoing work; 55 pages, 11 Tables, 13 Figures, 619 citations; Paper list is available at this https URL ",
    "url": "https://arxiv.org/abs/2402.05391",
    "authors": [
      "Zhuo Chen",
      "Yichi Zhang",
      "Yin Fang",
      "Yuxia Geng",
      "Lingbing Guo",
      "Xiang Chen",
      "Qian Li",
      "Wen Zhang",
      "Jiaoyan Chen",
      "Yushan Zhu",
      "Jiaqi Li",
      "Xiaoze Liu",
      "Jeff Z. Pan",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.05532",
    "title": "NCRF: Neural Contact Radiance Fields for Free-Viewpoint Rendering of  Hand-Object Interaction",
    "abstract": " Comments: Accepted by 3DV 2024 ",
    "url": "https://arxiv.org/abs/2402.05532",
    "authors": [
      "Zhongqun Zhang",
      "Jifei Song",
      "Eduardo P\u00e9rez-Pellitero",
      "Yiren Zhou",
      "Hyung Jin Chang",
      "Ale\u0161 Leonardis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.05894",
    "title": "Large Language Model Meets Graph Neural Network in Knowledge  Distillation",
    "abstract": " Comments: 17 pages, 6 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2402.05894",
    "authors": [
      "Shengxiang Hu",
      "Guobing Zou",
      "Song Yang",
      "Yanglan Gan",
      "Bofeng Zhang",
      "Yixin Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]