[
  {
    "id": "arXiv:2402.00870",
    "title": "Prioritising Interactive Flows in Data Center Networks With Central  Control",
    "abstract": "Data centers are on the rise and scientists are re-thinking and re-designing networks for data centers. The concept of central control which was not effective in the Internet era is now gaining popularity and is used in many data centers due to lower scale of operation (compared to Internet), structured topologies and as the entire network resources is under a single entity's control. With new opportunities, data center networks also pose new problems. Data centers require: high utilization, low median, tail latencies and fairness. In the traditional systems, the bulk traffic generally stalls the interactive flows thereby affecting their flow completion times adversely. In this thesis, we deal with two problems relating to central controller assisted prioritization of interactive flow in data center networks. Fastpass is a centralized \"zero-queue\" data center network. But the central arbiter of Fastpass doesn't scale well for more than 256 nodes (or 8 cores). In our test runs, it supports only about 1.5 Terabits's of network traffic. In this work, we re-design their timeslot allocator of their central arbiter so that it scales linearly till 12 cores and supports about 1024 nodes and 7.1 Terabits's of network traffic. In the second part of the thesis, we deal with the problem of congestion control in a software defined network. We propose a framework, where the controller with its global view of the network actively participates in the congestion control decisions of the end TCP hosts, by setting the ECN bits of IPV4 packets appropriately. Our framework can be deployed very easily without any change to the end node TCPs or the SDN switches. We also show 30x improvement over TCP cubic and 1.7x improvement over RED in flow completion times of interactive traffic for one implementation of this framework. ",
    "url": "https://arxiv.org/abs/2402.00870",
    "authors": [
      "Mohana Prasad Sathya Moorthy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00874",
    "title": "dRG-MEC: Decentralized Reinforced Green Offloading for MEC-enabled Cloud  Network",
    "abstract": "Multi-access-Mobile Edge Computing (MEC) is a promising solution for computationally demanding rigorous applications, that can meet 6G network service requirements. However, edge servers incur high computation costs during task processing. In this paper, we proposed a technique to minimize the total computation and communication overhead for optimal resource utilization with joint computational offloading that enables a green environment. Our optimization problem is NP-hard; thus, we proposed a decentralized Reinforcement Learning (dRL) approach where we eliminate the problem of dimensionality and over-estimation of the value functions. Compared to baseline schemes our technique achieves a 37.03% reduction in total system costs. ",
    "url": "https://arxiv.org/abs/2402.00874",
    "authors": [
      "Asad Aftab",
      "Semeen Rehman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.00879",
    "title": "Graph Representation Learning for Contention and Interference Management  in Wireless Networks",
    "abstract": "Restricted access window (RAW) in Wi-Fi 802.11ah networks manages contention and interference by grouping users and allocating periodic time slots for each group's transmissions. We will find the optimal user grouping decisions in RAW to maximize the network's worst-case user throughput. We review existing user grouping approaches and highlight their performance limitations in the above problem. We propose formulating user grouping as a graph construction problem where vertices represent users and edge weights indicate the contention and interference. This formulation leverages the graph's max cut to group users and optimizes edge weights to construct the optimal graph whose max cut yields the optimal grouping decisions. To achieve this optimal graph construction, we design an actor-critic graph representation learning (AC-GRL) algorithm. Specifically, the actor neural network (NN) is trained to estimate the optimal graph's edge weights using path losses between users and access points. A graph cut procedure uses semidefinite programming to solve the max cut efficiently and return the grouping decisions for the given weights. The critic NN approximates user throughput achieved by the above-returned decisions and is used to improve the actor. Additionally, we present an architecture that uses the online-measured throughput and path losses to fine-tune the decisions in response to changes in user populations and their locations. Simulations show that our methods achieve $30\\%\\sim80\\%$ higher worst-case user throughput than the existing approaches and that the proposed architecture can further improve the worst-case user throughput by $5\\%\\sim30\\%$ while ensuring timely updates of grouping decisions. ",
    "url": "https://arxiv.org/abs/2402.00879",
    "authors": [
      "Zhouyou Gu",
      "Branka Vucetic",
      "Kishore Chikkam",
      "Pasquale Aliberti",
      "Wibowo Hardjawana"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.00888",
    "title": "Security and Privacy Challenges of Large Language Models: A Survey",
    "abstract": "Large Language Models (LLMs) have demonstrated extraordinary capabilities and contributed to multiple fields, such as generating and summarizing text, language translation, and question-answering. Nowadays, LLM is becoming a very popular tool in computerized language processing tasks, with the capability to analyze complicated linguistic patterns and provide relevant and appropriate responses depending on the context. While offering significant advantages, these models are also vulnerable to security and privacy attacks, such as jailbreaking attacks, data poisoning attacks, and Personally Identifiable Information (PII) leakage attacks. This survey provides a thorough review of the security and privacy challenges of LLMs for both training data and users, along with the application-based risks in various domains, such as transportation, education, and healthcare. We assess the extent of LLM vulnerabilities, investigate emerging security and privacy attacks for LLMs, and review the potential defense mechanisms. Additionally, the survey outlines existing research gaps in this domain and highlights future research directions. ",
    "url": "https://arxiv.org/abs/2402.00888",
    "authors": [
      "Badhan Chandra Das",
      "M. Hadi Amini",
      "Yanzhao Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.00892",
    "title": "EVA-GAN: Enhanced Various Audio Generation via Scalable Generative  Adversarial Networks",
    "abstract": "The advent of Large Models marks a new era in machine learning, significantly outperforming smaller models by leveraging vast datasets to capture and synthesize complex patterns. Despite these advancements, the exploration into scaling, especially in the audio generation domain, remains limited, with previous efforts didn't extend into the high-fidelity (HiFi) 44.1kHz domain and suffering from both spectral discontinuities and blurriness in the high-frequency domain, alongside a lack of robustness against out-of-domain data. These limitations restrict the applicability of models to diverse use cases, including music and singing generation. Our work introduces Enhanced Various Audio Generation via Scalable Generative Adversarial Networks (EVA-GAN), yields significant improvements over previous state-of-the-art in spectral and high-frequency reconstruction and robustness in out-of-domain data performance, enabling the generation of HiFi audios by employing an extensive dataset of 36,000 hours of 44.1kHz audio, a context-aware module, a Human-In-The-Loop artifact measurement toolkit, and expands the model to approximately 200 million parameters. Demonstrations of our work are available at https://double-blind-eva-gan.cc. ",
    "url": "https://arxiv.org/abs/2402.00892",
    "authors": [
      "Shijia Liao",
      "Shiyi Lan",
      "Arun George Zachariah"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.00896",
    "title": "Privacy and Security Implications of Cloud-Based AI Services : A Survey",
    "abstract": "This paper details the privacy and security landscape in today's cloud ecosystem and identifies that there is a gap in addressing the risks introduced by machine learning models. As machine learning algorithms continue to evolve and find applications across diverse domains, the need to categorize and quantify privacy and security risks becomes increasingly critical. With the emerging trend of AI-as-a-Service (AIaaS), machine learned AI models (or ML models) are deployed on the cloud by model providers and used by model consumers. We first survey the AIaaS landscape to document the various kinds of liabilities that ML models, especially Deep Neural Networks pose and then introduce a taxonomy to bridge this gap by holistically examining the risks that creators and consumers of ML models are exposed to and their known defences till date. Such a structured approach will be beneficial for ML model providers to create robust solutions. Likewise, ML model consumers will find it valuable to evaluate such solutions and understand the implications of their engagement with such services. The proposed taxonomies provide a foundational basis for solutions in private, secure and robust ML, paving the way for more transparent and resilient AI systems. ",
    "url": "https://arxiv.org/abs/2402.00896",
    "authors": [
      "Alka Luqman",
      "Riya Mahesh",
      "Anupam Chattopadhyay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00898",
    "title": "An Early Categorization of Prompt Injection Attacks on Large Language  Models",
    "abstract": "Large language models and AI chatbots have been at the forefront of democratizing artificial intelligence. However, the releases of ChatGPT and other similar tools have been followed by growing concerns regarding the difficulty of controlling large language models and their outputs. Currently, we are witnessing a cat-and-mouse game where users attempt to misuse the models with a novel attack called prompt injections. In contrast, the developers attempt to discover the vulnerabilities and block the attacks simultaneously. In this paper, we provide an overview of these emergent threats and present a categorization of prompt injections, which can guide future research on prompt injections and act as a checklist of vulnerabilities in the development of LLM interfaces. Moreover, based on previous literature and our own empirical research, we discuss the implications of prompt injections to LLM end users, developers, and researchers. ",
    "url": "https://arxiv.org/abs/2402.00898",
    "authors": [
      "Sippo Rossi",
      "Alisia Marianne Michel",
      "Raghava Rao Mukkamala",
      "Jason Bennett Thatcher"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00904",
    "title": "Graph Domain Adaptation: Challenges, Progress and Prospects",
    "abstract": "As graph representation learning often suffers from label scarcity problems in real-world applications, researchers have proposed graph domain adaptation (GDA) as an effective knowledge-transfer paradigm across graphs. In particular, to enhance model performance on target graphs with specific tasks, GDA introduces a bunch of task-related graphs as source graphs and adapts the knowledge learnt from source graphs to the target graphs. Since GDA combines the advantages of graph representation learning and domain adaptation, it has become a promising direction of transfer learning on graphs and has attracted an increasing amount of research interest in recent years. In this paper, we comprehensively overview the studies of GDA and present a detailed survey of recent advances. Specifically, we outline the research status and challenges, propose a taxonomy, introduce the details of representative works, and discuss the prospects. To the best of our knowledge, this paper is the first survey for graph domain adaptation. A detailed paper list is available at https://github.com/Skyorca/Awesome-Graph-Domain-Adaptation-Papers. ",
    "url": "https://arxiv.org/abs/2402.00904",
    "authors": [
      "Boshen Shi",
      "Yongqing Wang",
      "Fangda Guo",
      "Bingbing Xu",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00905",
    "title": "GPT-3.5 for Code Review Automation: How Do Few-Shot Learning, Prompt  Design, and Model Fine-Tuning Impact Their Performance?",
    "abstract": "Recently, several large language models (LLMs)-the large pre-trained models based on the transformer architecture-were proposed. Prior studies in the natural language processing field and software engineering field conducted experiments focusing on different approaches to leveraging LLMs for downstream tasks. However, the existing literature still lacks the study of different approaches to leveraging GPT-3.5 (e.g., prompt engineering, few-shot learning and model fine-tuning) for the code review automation task (i.e., automatically generating improved code from submitted code). Thus, little is known about how GPT-3.5 should be leveraged for this task. To fill this knowledge gap, we set out to investigate the impact of few-shot learning, prompt design (i.e., using a persona pattern), and model fine-tuning on GPT-3.5 for the code review automation task. Through the experimental study of the three code review automation datasets, we find that (1) when few-shot learning is performed, GPT-3.5 achieves at least 46.38% higher Exact Match and at least 3.97% higher CodeBLEU than GPT-3.5 that zero-shot learning is performed, (2) when persona is included in input prompts to generate improved code, GPT-3.5 achieves at least 1.02% lower Exact Match and 0.15% lower CodeBLEU than when persona is not included in input prompts, (3) fine-tuned GPT-3.5 achieves at least 9.74% higher Exact Match and 0.12% higher CodeBLEU than GPT-3.5 that zero-shot and few-shot learning is performed, and (4) fine-tuned GPT-3.5 achieves at least 11.48% higher Exact Match than the existing code review automation approaches. Based on our experiment results, we recommend that when using GPT-3.5 for code review automation (1) few-shot learning should be performed rather than zero-shot learning, (2) persona should not be included when constructing prompts, and (3) GPT-3.5 should be fine-tuned by using a small training dataset. ",
    "url": "https://arxiv.org/abs/2402.00905",
    "authors": [
      "Chanathip Pornprasit",
      "Chakkrit Tantithamthavorn"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.00906",
    "title": "BrainLeaks: On the Privacy-Preserving Properties of Neuromorphic  Architectures against Model Inversion Attacks",
    "abstract": "With the mainstream integration of machine learning into security-sensitive domains such as healthcare and finance, concerns about data privacy have intensified. Conventional artificial neural networks (ANNs) have been found vulnerable to several attacks that can leak sensitive data. Particularly, model inversion (MI) attacks enable the reconstruction of data samples that have been used to train the model. Neuromorphic architectures have emerged as a paradigm shift in neural computing, enabling asynchronous and energy-efficient computation. However, little to no existing work has investigated the privacy of neuromorphic architectures against model inversion. Our study is motivated by the intuition that the non-differentiable aspect of spiking neural networks (SNNs) might result in inherent privacy-preserving properties, especially against gradient-based attacks. To investigate this hypothesis, we propose a thorough exploration of SNNs' privacy-preserving capabilities. Specifically, we develop novel inversion attack strategies that are comprehensively designed to target SNNs, offering a comparative analysis with their conventional ANN counterparts. Our experiments, conducted on diverse event-based and static datasets, demonstrate the effectiveness of the proposed attack strategies and therefore questions the assumption of inherent privacy-preserving in neuromorphic architectures. ",
    "url": "https://arxiv.org/abs/2402.00906",
    "authors": [
      "Hamed Poursiami",
      "Ihsen Alouani",
      "Maryam Parsa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.00909",
    "title": "Generalizing GradCAM for Embedding Networks",
    "abstract": "Visualizing CNN is an important part in building trust and explaining model's prediction. Methods like CAM and GradCAM have been really successful in localizing area of the image responsible for the output but are only limited to classification models. In this paper, we present a new method EmbeddingCAM, which generalizes the Grad-CAM for embedding networks. We show that for classification networks, EmbeddingCAM reduces to GradCAM. We show the effectiveness of our method on CUB-200-2011 dataset and also present quantitative and qualitative analysis on the dataset. ",
    "url": "https://arxiv.org/abs/2402.00909",
    "authors": [
      "Mudit Bachhawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.00918",
    "title": "MUSTAN: Multi-scale Temporal Context as Attention for Robust Video  Foreground Segmentation",
    "abstract": "Video foreground segmentation (VFS) is an important computer vision task wherein one aims to segment the objects under motion from the background. Most of the current methods are image-based, i.e., rely only on spatial cues while ignoring motion cues. Therefore, they tend to overfit the training data and don't generalize well to out-of-domain (OOD) distribution. To solve the above problem, prior works exploited several cues such as optical flow, background subtraction mask, etc. However, having a video data with annotations like optical flow is a challenging task. In this paper, we utilize the temporal information and the spatial cues from the video data to improve OOD performance. However, the challenge lies in how we model the temporal information given the video data in an interpretable way creates a very noticeable difference. We therefore devise a strategy that integrates the temporal context of the video in the development of VFS. Our approach give rise to deep learning architectures, namely MUSTAN1 and MUSTAN2 and they are based on the idea of multi-scale temporal context as an attention, i.e., aids our models to learn better representations that are beneficial for VFS. Further, we introduce a new video dataset, namely Indoor Surveillance Dataset (ISD) for VFS. It has multiple annotations on a frame level such as foreground binary mask, depth map, and instance semantic annotations. Therefore, ISD can benefit other computer vision tasks. We validate the efficacy of our architectures and compare the performance with baselines. We demonstrate that proposed methods significantly outperform the benchmark methods on OOD. In addition, the performance of MUSTAN2 is significantly improved on certain video categories on OOD data due to ISD. ",
    "url": "https://arxiv.org/abs/2402.00918",
    "authors": [
      "Praveen Kumar Pokala",
      "Jaya Sai Kiran Patibandla",
      "Naveen Kumar Pandey",
      "Balakrishna Reddy Pailla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00920",
    "title": "Deep Learning Approaches for Network Traffic Classification in the  Internet of Things (IoT): A Survey",
    "abstract": "The Internet of Things (IoT) has witnessed unprecedented growth, resulting in a massive influx of diverse network traffic from interconnected devices. Effectively classifying this network traffic is crucial for optimizing resource allocation, enhancing security measures, and ensuring efficient network management in IoT systems. Deep learning has emerged as a powerful technique for network traffic classification due to its ability to automatically learn complex patterns and representations from raw data. This survey paper aims to provide a comprehensive overview of the existing deep learning approaches employed in network traffic classification specifically tailored for IoT environments. By systematically analyzing and categorizing the latest research contributions in this domain, we explore the strengths and limitations of various deep learning models in handling the unique challenges posed by IoT network traffic. Through this survey, we aim to offer researchers and practitioners valuable insights, identify research gaps, and provide directions for future research to further enhance the effectiveness and efficiency of deep learning-based network traffic classification in IoT. ",
    "url": "https://arxiv.org/abs/2402.00920",
    "authors": [
      "Jawad Hussain Kalwar",
      "Sania Bhatti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.00922",
    "title": "Towards post-quantum blockchain: A review on blockchain cryptography  resistant to quantum computing attacks",
    "abstract": "Blockchain and other Distributed Ledger Technologies (DLTs) have evolved significantly in the last years and their use has been suggested for numerous applications due to their ability to provide transparency, redundancy and accountability. In the case of blockchain, such characteristics are provided through public-key cryptography and hash functions. However, the fast progress of quantum computing has opened the possibility of performing attacks based on Grover's and Shor's algorithms in the near future. Such algorithms threaten both public-key cryptography and hash functions, forcing to redesign blockchains to make use of cryptosystems that withstand quantum attacks, thus creating which are known as post-quantum, quantum-proof, quantum-safe or quantum-resistant cryptosystems. For such a purpose, this article first studies current state of the art on post-quantum cryptosystems and how they can be applied to blockchains and DLTs. Moreover, the most relevant post-quantum blockchain systems are studied, as well as their main challenges. Furthermore, extensive comparisons are provided on the characteristics and performance of the most promising post-quantum public-key encryption and digital signature schemes for blockchains. Thus, this article seeks to provide a broad view and useful guidelines on post-quantum blockchain security to future blockchain researchers and developers. ",
    "url": "https://arxiv.org/abs/2402.00922",
    "authors": [
      "Tiago M. Fernandez-Carames",
      "Paula Fraga-Lamas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2402.00965",
    "title": "Multi-Modal Machine Learning Framework for Automated Seizure Detection  in Laboratory Rats",
    "abstract": "A multi-modal machine learning system uses multiple unique data sources and types to improve its performance. This article proposes a system that combines results from several types of models, all of which are trained on different data signals. As an example to illustrate the efficacy of the system, an experiment is described in which multiple types of data are collected from rats suffering from seizures. This data includes electrocorticography readings, piezoelectric motion sensor data, and video recordings. Separate models are trained on each type of data, with the goal of classifying each time frame as either containing a seizure or not. After each model has generated its classification predictions, these results are combined. While each data signal works adequately on its own for prediction purposes, the significant imbalance in class labels leads to increased numbers of false positives, which can be filtered and removed by utilizing all data sources. This paper will demonstrate that, after postprocessing and combination techniques, classification accuracy is improved with this multi-modal system when compared to the performance of each individual data source. ",
    "url": "https://arxiv.org/abs/2402.00965",
    "authors": [
      "Aaron Mullen",
      "Samuel E. Armstrong",
      "Jasmine Perdeh",
      "Bjorn Bauer",
      "Jeffrey Talbert",
      "V.K. Cody Bumgardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.00986",
    "title": "The Parallel Semantics Program Dependence Graph",
    "abstract": "A compiler's intermediate representation (IR) defines a program's execution plan by encoding its instructions and their relative order. Compiler optimizations aim to replace a given execution plan with a semantically-equivalent one that increases the program's performance for the target architecture. Alternative representations of an IR, like the Program Dependence Graph (PDG), aid this process by capturing the minimum set of constraints that semantically-equivalent execution plans must satisfy. Parallel programming like OpenMP extends a sequential execution plan by adding the possibility of running instructions in parallel, creating a parallel execution plan. Recently introduced parallel IRs, like TAPIR, explicitly encode a parallel execution plan. These new IRs finally make it possible for compilers to change the parallel execution plan expressed by programmers to better fit the target parallel architecture. Unfortunately, parallel IRs do not help compilers in identifying the set of parallel execution plans that preserve the original semantics. In other words, we are still lacking an alternative representation of parallel IRs to capture the minimum set of constraints that parallel execution plans must satisfy to be semantically-equivalent. Unfortunately, the PDG is not an ideal candidate for this task as it was designed for sequential code. We propose the Parallel Semantics Program Dependence Graph (PS-PDG) to precisely capture the salient program constraints that all semantically-equivalent parallel execution plans must satisfy. This paper defines the PS-PDG, justifies the necessity of each extension to the PDG, and demonstrates the increased optimization power of the PS-PDG over an existing PDG-based automatic-parallelizing compiler. Compilers can now rely on the PS-PDG to select different parallel execution plans while maintaining the same original semantics. ",
    "url": "https://arxiv.org/abs/2402.00986",
    "authors": [
      "Brian Homerding",
      "Atmn Patel",
      "Enrico Armenio Deiana",
      "Yian Su",
      "Zujun Tan",
      "Ziyang Xu",
      "Bhargav Reddy Godala",
      "David I. August",
      "Simone Campanoni"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2402.00987",
    "title": "Self-Supervised Contrastive Pre-Training for Multivariate Point  Processes",
    "abstract": "Self-supervision is one of the hallmarks of representation learning in the increasingly popular suite of foundation models including large language models such as BERT and GPT-3, but it has not been pursued in the context of multivariate event streams, to the best of our knowledge. We introduce a new paradigm for self-supervised learning for multivariate point processes using a transformer encoder. Specifically, we design a novel pre-training strategy for the encoder where we not only mask random event epochs but also insert randomly sampled \"void\" epochs where an event does not occur; this differs from the typical discrete-time pretext tasks such as word-masking in BERT but expands the effectiveness of masking to better capture continuous-time dynamics. To improve downstream tasks, we introduce a contrasting module that compares real events to simulated void instances. The pre-trained model can subsequently be fine-tuned on a potentially much smaller event dataset, similar conceptually to the typical transfer of popular pre-trained language models. We demonstrate the effectiveness of our proposed paradigm on the next-event prediction task using synthetic datasets and 3 real applications, observing a relative performance boost of as high as up to 20% compared to state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2402.00987",
    "authors": [
      "Xiao Shou",
      "Dharmashankar Subramanian",
      "Debarun Bhattacharjya",
      "Tian Gao",
      "Kristin P. Bennet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00994",
    "title": "A Cost-Efficient Approach for Creating Virtual Fitting Room using  Generative Adversarial Networks (GANs)",
    "abstract": "Customers all over the world want to see how the clothes fit them or not before purchasing. Therefore, customers by nature prefer brick-and-mortar clothes shopping so they can try on products before purchasing them. But after the Pandemic of COVID19 many sellers either shifted to online shopping or closed their fitting rooms which made the shopping process hesitant and doubtful. The fact that the clothes may not be suitable for their buyers after purchase led us to think about using new AI technologies to create an online platform or a virtual fitting room (VFR) in the form of a mobile application and a deployed model using a webpage that can be embedded later to any online store where they can try on any number of cloth items without physically trying them. Besides, it will save much searching time for their needs. Furthermore, it will reduce the crowding and headache in the physical shops by applying the same technology using a special type of mirror that will enable customers to try on faster. On the other hand, from business owners' perspective, this project will highly increase their online sales, besides, it will save the quality of the products by avoiding physical trials issues. The main approach used in this work is applying Generative Adversarial Networks (GANs) combined with image processing techniques to generate one output image from two input images which are the person image and the cloth image. This work achieved results that outperformed the state-of-the-art approaches found in literature. ",
    "url": "https://arxiv.org/abs/2402.00994",
    "authors": [
      "Kirolos Attallah",
      "Girgis Zaky",
      "Nourhan Abdelrhim",
      "Kyrillos Botros",
      "Amjad Dife",
      "Nermin Negied"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01001",
    "title": "Ensuring Data Privacy in AC Optimal Power Flow with a Distributed  Co-Simulation Framework",
    "abstract": "During the energy transition, the significance of collaborative management among institutions is rising, confronting challenges posed by data privacy concerns. Prevailing research on distributed approaches, as an alternative to centralized management, often lacks numerical convergence guarantees or is limited to single-machine numerical simulation. To address this, we present a distributed approach for solving AC Optimal Power Flow (OPF) problems within a geographically distributed environment. This involves integrating the energy system Co-Simulation (eCoSim) module in the eASiMOV framework with the convergence-guaranteed distributed optimization algorithm, i.e., the Augmented Lagrangian based Alternating Direction Inexact Newton method (ALADIN). Comprehensive evaluations across multiple system scenarios reveal a marginal performance slowdown compared to the centralized approach and the distributed approach executed on single machines -- a justified trade-off for enhanced data privacy. This investigation serves as empirical validation of the successful execution of distributed AC OPF within a geographically distributed environment, highlighting potential directions for future research. ",
    "url": "https://arxiv.org/abs/2402.01001",
    "authors": [
      "Xinliang Dai",
      "Alexander Kocher",
      "Jovana Kova\u010devi\u0107",
      "Burak Dindar",
      "Yuning Jiang",
      "Colin N. Jones",
      "H\u00fcseyin \u00c7akmak",
      "Veit Hagenmeyer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.01012",
    "title": "algoXSSF: Detection and analysis of cross-site request forgery (XSRF)  and cross-site scripting (XSS) attacks via Machine learning algorithms",
    "abstract": "The global rise of online users and online devices has ultimately given rise to the global internet population apart from several cybercrimes and cyberattacks. The combination of emerging new technology and powerful algorithms (of Artificial Intelligence, Deep Learning, and Machine Learning) is needed to counter defense web security including attacks on several search engines and websites. The unprecedented increase rate of cybercrime and website attacks urged for new technology consideration to protect data and information online. There have been recent and continuous cyberattacks on websites, web domains with ongoing data breaches including - GitHub account hack, data leaks on Twitter, malware in WordPress plugins, vulnerability in Tomcat server to name just a few. We have investigated with an in-depth study apart from the detection and analysis of two major cyberattacks (although there are many more types): cross-site request forgery (XSRF) and cross-site scripting (XSS) attacks. The easy identification of cyber trends and patterns with continuous improvement is possible within the edge of machine learning and AI algorithms. The use of machine learning algorithms would be extremely helpful to counter (apart from detection) the XSRF and XSS attacks. We have developed the algorithm and cyber defense framework - algoXSSF with machine learning algorithms embedded to combat malicious attacks (including Man-in-the-Middle attacks) on websites for detection and analysis. ",
    "url": "https://arxiv.org/abs/2402.01012",
    "authors": [
      "Naresh Kshetri",
      "Dilip Kumar",
      "James Hutson",
      "Navneet Kaur",
      "Omar Faruq Osama"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.01030",
    "title": "Executable Code Actions Elicit Better LLM Agents",
    "abstract": "Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges. LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools). This work proposes to use executable Python code to consolidate LLM agents' actions into a unified action space (CodeAct). Integrated with a Python interpreter, CodeAct can execute code actions and dynamically revise prior actions or emit new actions upon new observations through multi-turn interactions. Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate). The encouraging performance of CodeAct motivates us to build an open-source LLM agent that interacts with environments by executing interpretable code and collaborates with users using natural language. To this end, we collect an instruction-tuning dataset CodeActInstruct that consists of 7k multi-turn interactions using CodeAct. We show that it can be used with existing data to improve models in agent-oriented tasks without compromising their general capability. CodeActAgent, finetuned from Llama2 and Mistral, is integrated with Python interpreter and uniquely tailored to perform sophisticated tasks (e.g., model training) using existing libraries and autonomously self-debug. ",
    "url": "https://arxiv.org/abs/2402.01030",
    "authors": [
      "Xingyao Wang",
      "Yangyi Chen",
      "Lifan Yuan",
      "Yizhe Zhang",
      "Yunzhu Li",
      "Hao Peng",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01045",
    "title": "LatticeGraphNet: A two-scale graph neural operator for simulating  lattice structures",
    "abstract": "This study introduces a two-scale Graph Neural Operator (GNO), namely, LatticeGraphNet (LGN), designed as a surrogate model for costly nonlinear finite-element simulations of three-dimensional latticed parts and structures. LGN has two networks: LGN-i, learning the reduced dynamics of lattices, and LGN-ii, learning the mapping from the reduced representation onto the tetrahedral mesh. LGN can predict deformation for arbitrary lattices, therefore the name operator. Our approach significantly reduces inference time while maintaining high accuracy for unseen simulations, establishing the use of GNOs as efficient surrogate models for evaluating mechanical responses of lattices and structures. ",
    "url": "https://arxiv.org/abs/2402.01045",
    "authors": [
      "Ayush Jain",
      "Ehsan Haghighat",
      "Sai Nelaturi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2402.01058",
    "title": "Towards an Algebraic Framework For Approximating Functions Using Neural  Network Polynomials",
    "abstract": "We make the case for neural network objects and extend an already existing neural network calculus explained in detail in Chapter 2 on \\cite{bigbook}. Our aim will be to show that, yes, indeed, it makes sense to talk about neural network polynomials, neural network exponentials, sine, and cosines in the sense that they do indeed approximate their real number counterparts subject to limitations on certain of their parameters, $q$, and $\\varepsilon$. While doing this, we show that the parameter and depth growth are only polynomial on their desired accuracy (defined as a 1-norm difference over $\\mathbb{R}$), thereby showing that this approach to approximating, where a neural network in some sense has the structural properties of the function it is approximating is not entire intractable. ",
    "url": "https://arxiv.org/abs/2402.01058",
    "authors": [
      "Shakil Rafi",
      "Joshua Lee Padgett",
      "Ukash Nakarmi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Combinatorics (math.CO)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.01064",
    "title": "Semantic-Aware and Goal-Oriented Communications for Object Detection in  Wireless End-to-End Image Transmission",
    "abstract": "Semantic communication is focused on optimizing the exchange of information by transmitting only the most relevant data required to convey the intended message to the receiver and achieve the desired communication goal. For example, if we consider images as the information and the goal of the communication is object detection at the receiver side, the semantic of information would be the objects in each image. Therefore, by only transferring the semantics of images we can achieve the communication goal. In this paper, we propose a design framework for implementing semantic-aware and goal-oriented communication of images. To achieve this, we first define the baseline problem as a set of mathematical problems that can be optimized to improve the efficiency and effectiveness of the communication system. We consider two scenarios in which either the data rate or the error at the receiver is the limiting constraint. Our proposed system model and solution is inspired by the concept of auto-encoders, where the encoder and the decoder are respectively implemented at the transmitter and receiver to extract semantic information for specific object detection goals. Our numerical results validate the proposed design framework to achieve low error or near-optimal in a goal-oriented communication system while reducing the amount of data transfers. ",
    "url": "https://arxiv.org/abs/2402.01064",
    "authors": [
      "Fatemeh Zahra Safaeipour",
      "Morteza Hashemi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.01071",
    "title": "Chameleon: Foundation Models for Fairness-aware Multi-modal Data  Augmentation to Enhance Coverage of Minorities",
    "abstract": "The potential harms of the under-representation of minorities in training data, particularly in multi-modal settings, is a well-recognized concern. While there has been extensive effort in detecting such under-representation, resolution has remained a challenge. With recent advancements in generative AI, large language models and foundation models have emerged as versatile tools across various domains. In this paper, we propose Chameleon, a system that efficiently utilizes these tools to augment a data set with a minimal addition of synthetically generated tuples, in order to enhance the coverage of the under-represented groups. Our system follows a rejection sampling approach to ensure the generated tuples have a high quality and follow the underlying distribution. In order to minimize the rejection chance of the generated tuples, we propose multiple strategies for providing a guide for the foundation model. Our experiment results, in addition to confirming the efficiency of our proposed algorithms, illustrate the effectiveness of our approach, as the unfairness of the model in a downstream task significantly dropped after data repair using Chameleon. ",
    "url": "https://arxiv.org/abs/2402.01071",
    "authors": [
      "Mahdi Erfanian",
      "H. V. Jagadish",
      "Abolfazl Asudeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2402.01074",
    "title": "Neural Models and Algorithms for Sensorimotor Control of an Octopus Arm",
    "abstract": "In this article, a biophysically realistic model of a soft octopus arm with internal musculature is presented. The modeling is motivated by experimental observations of sensorimotor control where an arm localizes and reaches a target. Major contributions of this article are: (i) development of models to capture the mechanical properties of arm musculature, the electrical properties of the arm peripheral nervous system (PNS), and the coupling of PNS with muscular contractions; (ii) modeling the arm sensory system, including chemosensing and proprioception; and (iii) algorithms for sensorimotor control, which include a novel feedback neural motor control law for mimicking target-oriented arm reaching motions, and a novel consensus algorithm for solving sensing problems such as locating a food source from local chemical sensory information (exogenous) and arm deformation information (endogenous). Several analytical results, including rest-state characterization and stability properties of the proposed sensing and motor control algorithms, are provided. Numerical simulations demonstrate the efficacy of our approach. Qualitative comparisons against observed arm rest shapes and target-oriented reaching motions are also reported. ",
    "url": "https://arxiv.org/abs/2402.01074",
    "authors": [
      "Tixian Wang",
      "Udit Halder",
      "Ekaterina Gribkova",
      "Rhanor Gillette",
      "Mattia Gazzola",
      "Prashant G. Mehta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2402.01076",
    "title": "DoseGNN: Improving the Performance of Deep Learning Models in Adaptive  Dose-Volume Histogram Prediction through Graph Neural Networks",
    "abstract": "Dose-Volume Histogram (DVH) prediction is fundamental in radiation therapy that facilitate treatment planning, dose evaluation, plan comparison and etc. It helps to increase the ability to deliver precise and effective radiation treatments while managing potential toxicities to healthy tissues as needed to reduce the risk of complications. This paper extends recently disclosed research findings presented on AAPM (AAPM 65th Annual Meeting $\\&$ Exhibition) and includes necessary technique details. The objective is to design efficient deep learning models for DVH prediction on general radiotherapy platform equipped with high performance CBCT system, where input CT images and target dose images to predict may have different origins, spacing and sizes. Deep learning models widely-adopted in DVH prediction task are evaluated on the novel radiotherapy platform, and graph neural networks (GNNs) are shown to be the ideal architecture to construct a plug-and-play framework to improve predictive performance of base deep learning models in the adaptive setting. ",
    "url": "https://arxiv.org/abs/2402.01076",
    "authors": [
      "Zehao Dong",
      "Yixin Chen",
      "Tianyu Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01082",
    "title": "Salsa Fresca: Angular Embeddings and Pre-Training for ML Attacks on  Learning With Errors",
    "abstract": "Learning with Errors (LWE) is a hard math problem underlying recently standardized post-quantum cryptography (PQC) systems for key exchange and digital signatures. Prior work proposed new machine learning (ML)-based attacks on LWE problems with small, sparse secrets, but these attacks require millions of LWE samples to train on and take days to recover secrets. We propose three key methods -- better preprocessing, angular embeddings and model pre-training -- to improve these attacks, speeding up preprocessing by $25\\times$ and improving model sample efficiency by $10\\times$. We demonstrate for the first time that pre-training improves and reduces the cost of ML attacks on LWE. Our architecture improvements enable scaling to larger-dimension LWE problems: this work is the first instance of ML attacks recovering sparse binary secrets in dimension $n=1024$, the smallest dimension used in practice for homomorphic encryption applications of LWE where sparse binary secrets are proposed. ",
    "url": "https://arxiv.org/abs/2402.01082",
    "authors": [
      "Samuel Stevens",
      "Emily Wenger",
      "Cathy Li",
      "Niklas Nolte",
      "Eshika Saxena",
      "Fran\u00e7ois Charton",
      "Kristin Lauter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01095",
    "title": "How many views does your deep neural network use for prediction?",
    "abstract": "The generalization ability of Deep Neural Networks (DNNs) is still not fully understood, despite numerous theoretical and empirical analyses. Recently, Allen-Zhu & Li (2023) introduced the concept of multi-views to explain the generalization ability of DNNs, but their main target is ensemble or distilled models, and no method for estimating multi-views used in a prediction of a specific input is discussed. In this paper, we propose Minimal Sufficient Views (MSVs), which is similar to multi-views but can be efficiently computed for real images. MSVs is a set of minimal and distinct features in an input, each of which preserves a model's prediction for the input. We empirically show that there is a clear relationship between the number of MSVs and prediction accuracy across models, including convolutional and transformer models, suggesting that a multi-view like perspective is also important for understanding the generalization ability of (non-ensemble or non-distilled) DNNs. ",
    "url": "https://arxiv.org/abs/2402.01095",
    "authors": [
      "Keisuke Kawano",
      "Takuro Kutsuna",
      "Keisuke Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01107",
    "title": "Simulation of Graph Algorithms with Looped Transformers",
    "abstract": "The execution of graph algorithms using neural networks has recently attracted significant interest due to promising empirical progress. This motivates further understanding of how neural networks can replicate reasoning steps with relational data. In this work, we study the ability of transformer networks to simulate algorithms on graphs from a theoretical perspective. The architecture that we utilize is a looped transformer with extra attention heads that interact with the graph. We prove by construction that this architecture can simulate algorithms such as Dijkstra's shortest path algorithm, Breadth- and Depth-First Search, and Kosaraju's strongly connected components algorithm. The width of the network does not increase with the size of the input graph, which implies that the network can simulate the above algorithms for any graph. Despite this property, we show that there is a limit to simulation in our solution due to finite precision. Finally, we show a Turing Completeness result with constant width when the extra attention heads are utilized. ",
    "url": "https://arxiv.org/abs/2402.01107",
    "authors": [
      "Artur Back de Luca",
      "Kimon Fountoulakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2402.01114",
    "title": "Double-Dip: Thwarting Label-Only Membership Inference Attacks with  Transfer Learning and Randomization",
    "abstract": "Transfer learning (TL) has been demonstrated to improve DNN model performance when faced with a scarcity of training samples. However, the suitability of TL as a solution to reduce vulnerability of overfitted DNNs to privacy attacks is unexplored. A class of privacy attacks called membership inference attacks (MIAs) aim to determine whether a given sample belongs to the training dataset (member) or not (nonmember). We introduce Double-Dip, a systematic empirical study investigating the use of TL (Stage-1) combined with randomization (Stage-2) to thwart MIAs on overfitted DNNs without degrading classification accuracy. Our study examines the roles of shared feature space and parameter values between source and target models, number of frozen layers, and complexity of pretrained models. We evaluate Double-Dip on three (Target, Source) dataset paris: (i) (CIFAR-10, ImageNet), (ii) (GTSRB, ImageNet), (iii) (CelebA, VGGFace2). We consider four publicly available pretrained DNNs: (a) VGG-19, (b) ResNet-18, (c) Swin-T, and (d) FaceNet. Our experiments demonstrate that Stage-1 reduces adversary success while also significantly increasing classification accuracy of nonmembers against an adversary with either white-box or black-box DNN model access, attempting to carry out SOTA label-only MIAs. After Stage-2, success of an adversary carrying out a label-only MIA is further reduced to near 50%, bringing it closer to a random guess and showing the effectiveness of Double-Dip. Stage-2 of Double-Dip also achieves lower ASR and higher classification accuracy than regularization and differential privacy-based methods. ",
    "url": "https://arxiv.org/abs/2402.01114",
    "authors": [
      "Arezoo Rajabi",
      "Reeya Pimple",
      "Aiswarya Janardhanan",
      "Surudhi Asokraj",
      "Bhaskar Ramasubramanian",
      "Radha Poovendran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.01123",
    "title": "A Single Simple Patch is All You Need for AI-generated Image Detection",
    "abstract": "The recent development of generative models unleashes the potential of generating hyper-realistic fake images. To prevent the malicious usage of fake images, AI-generated image detection aims to distinguish fake images from real images. Nevertheless, existing methods usually suffer from poor generalizability across different generators. In this work, we propose an embarrassingly simple approach named SSP, i.e., feeding the noise pattern of a Single Simple Patch (SSP) to a binary classifier, which could achieve 14.6% relative improvement over the recent method on GenImage dataset. Our SSP method is very robust and generalizable, which could serve as a simple and competitive baseline for the future methods. ",
    "url": "https://arxiv.org/abs/2402.01123",
    "authors": [
      "Jiaxuan Chen",
      "Jieteng Yao",
      "Li Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01140",
    "title": "Root Cause Analysis In Microservice Using Neural Granger Causal  Discovery",
    "abstract": "In recent years, microservices have gained widespread adoption in IT operations due to their scalability, maintenance, and flexibility. However, it becomes challenging for site reliability engineers (SREs) to pinpoint the root cause due to the complex relationships in microservices when facing system malfunctions. Previous research employed structured learning methods (e.g., PC-algorithm) to establish causal relationships and derive root causes from causal graphs. Nevertheless, they ignored the temporal order of time series data and failed to leverage the rich information inherent in the temporal relationships. For instance, in cases where there is a sudden spike in CPU utilization, it can lead to an increase in latency for other microservices. However, in this scenario, the anomaly in CPU utilization occurs before the latency increase, rather than simultaneously. As a result, the PC-algorithm fails to capture such characteristics. To address these challenges, we propose RUN, a novel approach for root cause analysis using neural Granger causal discovery with contrastive learning. RUN enhances the backbone encoder by integrating contextual information from time series, and leverages a time series forecasting model to conduct neural Granger causal discovery. In addition, RUN incorporates Pagerank with a personalization vector to efficiently recommend the top-k root causes. Extensive experiments conducted on the synthetic and real-world microservice-based datasets demonstrate that RUN noticeably outperforms the state-of-the-art root cause analysis methods. Moreover, we provide an analysis scenario for the sock-shop case to showcase the practicality and efficacy of RUN in microservice-based applications. Our code is publicly available at https://github.com/zmlin1998/RUN. ",
    "url": "https://arxiv.org/abs/2402.01140",
    "authors": [
      "Cheng-Ming Lin",
      "Ching Chang",
      "Wei-Yao Wang",
      "Kuang-Da Wang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.01143",
    "title": "Learning Network Representations with Disentangled Graph Auto-Encoder",
    "abstract": "The (variational) graph auto-encoder is extensively employed for learning representations of graph-structured data. However, the formation of real-world graphs is a complex and heterogeneous process influenced by latent factors. Existing encoders are fundamentally holistic, neglecting the entanglement of latent factors. This not only makes graph analysis tasks less effective but also makes it harder to understand and explain the representations. Learning disentangled graph representations with (variational) graph auto-encoder poses significant challenges, and remains largely unexplored in the existing literature. In this article, we introduce the Disentangled Graph Auto-Encoder (DGA) and Disentangled Variational Graph Auto-Encoder (DVGA), approaches that leverage generative models to learn disentangled representations. Specifically, we first design a disentangled graph convolutional network with multi-channel message-passing layers, as the encoder aggregating information related to each disentangled latent factor. Subsequently, a component-wise flow is applied to each channel to enhance the expressive capabilities of disentangled variational graph auto-encoder. Additionally, we design a factor-wise decoder, considering the characteristics of disentangled representations. In order to further enhance the independence among representations, we introduce independence constraints on mapping channels for different latent factors. Empirical experiments on both synthetic and real-world datasets show the superiority of our proposed method compared to several state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2402.01143",
    "authors": [
      "Di Fan",
      "Chuanhou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01147",
    "title": "Efficient Reinforcement Learning for Routing Jobs in Heterogeneous  Queueing Systems",
    "abstract": "We consider the problem of efficiently routing jobs that arrive into a central queue to a system of heterogeneous servers. Unlike homogeneous systems, a threshold policy, that routes jobs to the slow server(s) when the queue length exceeds a certain threshold, is known to be optimal for the one-fast-one-slow two-server system. But an optimal policy for the multi-server system is unknown and non-trivial to find. While Reinforcement Learning (RL) has been recognized to have great potential for learning policies in such cases, our problem has an exponentially large state space size, rendering standard RL inefficient. In this work, we propose ACHQ, an efficient policy gradient based algorithm with a low dimensional soft threshold policy parameterization that leverages the underlying queueing structure. We provide stationary-point convergence guarantees for the general case and despite the low-dimensional parameterization prove that ACHQ converges to an approximate global optimum for the special case of two servers. Simulations demonstrate an improvement in expected response time of up to ~30% over the greedy policy that routes to the fastest available server. ",
    "url": "https://arxiv.org/abs/2402.01147",
    "authors": [
      "Neharika Jali",
      "Guannan Qu",
      "Weina Wang",
      "Gauri Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2402.01156",
    "title": "An Empirical Study on Low Code Programming using Traditional vs Large  Language Model Support",
    "abstract": "Low-code programming (LCP) refers to programming using models at higher levels of abstraction, resulting in less manual and more efficient programming, and reduced learning effort for amateur developers. Many LCP tools have rapidly evolved and have benefited from the concepts of visual programming languages (VPLs) and programming by demonstration (PBD). With huge increase in interest in using large language models (LLMs) in software engineering, LLM-based LCP has began to become increasingly important. However, the technical principles and application scenarios of traditional approaches to LCP and LLM-based LCP are significantly different. Understanding these key differences and characteristics in the application of the two approaches to LCP by users is crucial for LCP providers in improving existing and developing new LCP tools, and in better assisting users in choosing the appropriate LCP technology. We conducted an empirical study of both traditional LCP and LLM-based LCP. We analyzed developers' discussions on Stack Overflow (SO) over the past three years and then explored the similarities and differences between traditional LCP and LLM-based LCP features and developer feedback. Our findings reveal that while traditional LCP and LLM-based LCP share common primary usage scenarios, they significantly differ in scope, limitations and usage throughout the software development lifecycle, particularly during the implementation phase. We also examine how LLMs impact and integrate with LCP, discussing the latest technological developments in LLM-based LCP, such as its integration with VPLs and the application of LLM Agents in software engineering. ",
    "url": "https://arxiv.org/abs/2402.01156",
    "authors": [
      "Yongkun Liu",
      "Jiachi Chen",
      "Tingting Bi",
      "John Grundy",
      "Yanlin Wang",
      "Ting Chen",
      "Yutian Tang",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.01157",
    "title": "Source-Free Unsupervised Domain Adaptation with Hypothesis Consolidation  of Prediction Rationale",
    "abstract": "Source-Free Unsupervised Domain Adaptation (SFUDA) is a challenging task where a model needs to be adapted to a new domain without access to target domain labels or source domain data. The primary difficulty in this task is that the model's predictions may be inaccurate, and using these inaccurate predictions for model adaptation can lead to misleading results. To address this issue, this paper proposes a novel approach that considers multiple prediction hypotheses for each sample and investigates the rationale behind each hypothesis. By consolidating these hypothesis rationales, we identify the most likely correct hypotheses, which we then use as a pseudo-labeled set to support a semi-supervised learning procedure for model adaptation. To achieve the optimal performance, we propose a three-step adaptation process: model pre-adaptation, hypothesis consolidation, and semi-supervised learning. Extensive experimental results demonstrate that our approach achieves state-of-the-art performance in the SFUDA task and can be easily integrated into existing approaches to improve their performance. The codes are available at \\url{https://github.com/GANPerf/HCPR}. ",
    "url": "https://arxiv.org/abs/2402.01157",
    "authors": [
      "Yangyang Shu",
      "Xiaofeng Cao",
      "Qi Chen",
      "Bowen Zhang",
      "Ziqin Zhou",
      "Anton van den Hengel",
      "Lingqiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01158",
    "title": "LLM-Detector: Improving AI-Generated Chinese Text Detection with  Open-Source LLM Instruction Tuning",
    "abstract": "ChatGPT and other general large language models (LLMs) have achieved remarkable success, but they have also raised concerns about the misuse of AI-generated texts. Existing AI-generated text detection models, such as based on BERT and RoBERTa, are prone to in-domain over-fitting, leading to poor out-of-domain (OOD) detection performance. In this paper, we first collected Chinese text responses generated by human experts and 9 types of LLMs, for which to multiple domains questions, and further created a dataset that mixed human-written sentences and sentences polished by LLMs. We then proposed LLM-Detector, a novel method for both document-level and sentence-level text detection through Instruction Tuning of LLMs. Our method leverages the wealth of knowledge LLMs acquire during pre-training, enabling them to detect the text they generate. Instruction tuning aligns the model's responses with the user's expected text detection tasks. Experimental results show that previous methods struggle with sentence-level AI-generated text detection and OOD detection. In contrast, our proposed method not only significantly outperforms baseline methods in both sentence-level and document-level text detection but also demonstrates strong generalization capabilities. Furthermore, since LLM-Detector is trained based on open-source LLMs, it is easy to customize for deployment. ",
    "url": "https://arxiv.org/abs/2402.01158",
    "authors": [
      "Rongsheng Wang",
      "Haoming Chen",
      "Ruizhe Zhou",
      "Han Ma",
      "Yaofei Duan",
      "Yanlan Kang",
      "Songhua Yang",
      "Baoyu Fan",
      "Tao Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01163",
    "title": "Enhanced Urban Region Profiling with Adversarial Self-Supervised  Learning",
    "abstract": "Urban region profiling is pivotal for smart cities, but mining fine-grained semantics from noisy and incomplete urban data remains challenging. In response, we propose a novel self-supervised graph collaborative filtering model for urban region embedding called EUPAS. Specifically, region heterogeneous graphs containing human mobility data, point of interests (POIs) information, and geographic neighborhood details for each region are fed into the model, which generates region embeddings that preserve intra-region and inter-region dependencies through GCNs and multi-head attention. Meanwhile, we introduce spatial perturbation augmentation to generate positive samples that are semantically similar and spatially close to the anchor, preparing for subsequent contrastive learning. Furthermore, adversarial training is employed to construct an effective pretext task by generating strong positive pairs and mining hard negative pairs for the region embeddings. Finally, we jointly optimize supervised and self-supervised learning to encourage the model to capture the high-level semantics of region embeddings while ignoring the noisy and unimportant details. Extensive experiments on real-world datasets demonstrate the superiority of our model over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2402.01163",
    "authors": [
      "Weiliang Chan",
      "Qianqian Ren",
      "Jinbao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01173",
    "title": "Efficient Prompt Caching via Embedding Similarity",
    "abstract": "Large language models (LLMs) have achieved huge success in numerous natural language process (NLP) tasks. However, it faces the challenge of significant resource consumption during inference. In this paper, we aim to improve the inference efficiency of LLMs by prompt caching, i.e., if the current prompt can be answered by the same response of a previous prompt, one can directly utilize that previous response without calling the LLM. Specifically, we focus on the prediction accuracy of prompt caching for single-round question-answering tasks via embedding similarity. The existing embeddings of prompts mostly focus on whether two prompts are semantically similar, which is not necessarily equivalent to whether the same response can answer them. Therefore, we propose a distillation-based method to fine-tune the existing embeddings for better caching prediction. Theoretically, we provide finite-sample guarantees for the convergence of our method under different types of loss functions. Empirically, we carefully construct a hard dataset based on Kwiatkowski et al. (2019) where the existing embedding model (Wang et al., 2022) only achieves an AUC of 0.51. We then fine-tune the above embedding model, which significantly improves the AUC of caching prediction from 0.51 to 0.81. We also conduct simulations demonstrating that our trained models achieve better caching efficiency than the previous embedding model. ",
    "url": "https://arxiv.org/abs/2402.01173",
    "authors": [
      "Hanlin Zhu",
      "Banghua Zhu",
      "Jiantao Jiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01198",
    "title": "Physical Layer Location Privacy in SIMO Communication Using Fake Paths  Injection",
    "abstract": "Fake path injection is an emerging paradigm for inducing privacy over wireless networks. In this paper, fake paths are injected by the transmitter into a SIMO multipath communication channel to preserve her physical location from an eavesdropper. A novel statistical privacy metric is defined as the ratio between the largest (resp. smallest) eigenvalues of Bob's (resp. Eve's) Cram\\'er-Rao lower bound on the SIMO multipath channel parameters to assess the privacy enhancements. Leveraging the spectral properties of generalized Vandermonde matrices, bounds on the privacy margin of the proposed scheme are derived. Specifically, it is shown that the privacy margin increases quadratically in the inverse of the separation between the true and the fake paths under Eve's perspective. Numerical simulations further showcase the approach's benefit. ",
    "url": "https://arxiv.org/abs/2402.01198",
    "authors": [
      "Trong Duy Tran",
      "Maxime Ferreira Da Costa",
      "Linh Trung Nguyen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.01204",
    "title": "A Survey on Self-Supervised Learning for Non-Sequential Tabular Data",
    "abstract": "Self-supervised learning (SSL) has been incorporated into many state-of-the-art models in various domains, where SSL defines pretext tasks based on unlabeled datasets to learn contextualized and robust representations. Recently, SSL has been a new trend in exploring the representation learning capability in the realm of tabular data, which is more challenging due to not having explicit relations for learning descriptive representations. This survey aims to systematically review and summarize the recent progress and challenges of SSL for non-sequential tabular data (SSL4NS-TD). We first present a formal definition of NS-TD and clarify its correlation to related studies. Then, these approaches are categorized into three groups -- predictive learning, contrastive learning, and hybrid learning, with their motivations and strengths of representative methods within each direction. On top of this, application issues of SSL4NS-TD are presented, including automatic data engineering, cross-table transferability, and domain knowledge integration. In addition, we elaborate on existing benchmarks and datasets for NS-TD applications to discuss the performance of existing tabular models. Finally, we discuss the challenges of SSL4NS-TD and provide potential directions for future research. We expect our work to be useful in terms of encouraging more research on lowering the barrier to entry SSL for the tabular domain and improving the foundations for implicit tabular data. ",
    "url": "https://arxiv.org/abs/2402.01204",
    "authors": [
      "Wei-Yao Wang",
      "Wei-Wei Du",
      "Derek Xu",
      "Wei Wang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01207",
    "title": "Efficient Causal Graph Discovery Using Large Language Models",
    "abstract": "We propose a novel framework that leverages LLMs for full causal graph discovery. While previous LLM-based methods have used a pairwise query approach, this requires a quadratic number of queries which quickly becomes impractical for larger causal graphs. In contrast, the proposed framework uses a breadth-first search (BFS) approach which allows it to use only a linear number of queries. We also show that the proposed method can easily incorporate observational data when available, to improve performance. In addition to being more time and data-efficient, the proposed framework achieves state-of-the-art results on real-world causal graphs of varying sizes. The results demonstrate the effectiveness and efficiency of the proposed method in discovering causal relationships, showcasing its potential for broad applicability in causal graph discovery tasks across different domains. ",
    "url": "https://arxiv.org/abs/2402.01207",
    "authors": [
      "Thomas Jiralerspong",
      "Xiaoyin Chen",
      "Yash More",
      "Vedant Shah",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.01208",
    "title": "Location Agnostic Adaptive Rain Precipitation Prediction using Deep  Learning",
    "abstract": "Rain precipitation prediction is a challenging task as it depends on weather and meteorological features which vary from location to location. As a result, a prediction model that performs well at one location does not perform well at other locations due to the distribution shifts. In addition, due to global warming, the weather patterns are changing very rapidly year by year which creates the possibility of ineffectiveness of those models even at the same location as time passes. In our work, we have proposed an adaptive deep learning-based framework in order to provide a solution to the aforementioned challenges. Our method can generalize the model for the prediction of precipitation for any location where the methods without adaptation fail. Our method has shown 43.51%, 5.09%, and 38.62% improvement after adaptation using a deep neural network for predicting the precipitation of Paris, Los Angeles, and Tokyo, respectively. ",
    "url": "https://arxiv.org/abs/2402.01208",
    "authors": [
      "Md Shazid Islam",
      "Md Saydur Rahman",
      "Md Saad Ul Haque",
      "Farhana Akter Tumpa",
      "Md Sanzid Bin Hossain",
      "Abul Al Arabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01212",
    "title": "TSJNet: A Multi-modality Target and Semantic Awareness Joint-driven  Image Fusion Network",
    "abstract": "Multi-modality image fusion involves integrating complementary information from different modalities into a single image. Current methods primarily focus on enhancing image fusion with a single advanced task such as incorporating semantic or object-related information into the fusion process. This method creates challenges in achieving multiple objectives simultaneously. We introduce a target and semantic awareness joint-driven fusion network called TSJNet. TSJNet comprises fusion, detection, and segmentation subnetworks arranged in a series structure. It leverages object and semantically relevant information derived from dual high-level tasks to guide the fusion network. Additionally, We propose a local significant feature extraction module with a double parallel branch structure to fully capture the fine-grained features of cross-modal images and foster interaction among modalities, targets, and segmentation information. We conducted extensive experiments on four publicly available datasets (MSRS, M3FD, RoadScene, and LLVIP). The results demonstrate that TSJNet can generate visually pleasing fused results, achieving an average increase of 2.84% and 7.47% in object detection and segmentation mAP @0.5 and mIoU, respectively, compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2402.01212",
    "authors": [
      "Yuchan Jie",
      "Yushen Xu",
      "Xiaosong Li",
      "Haishu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01216",
    "title": "Robust Commutation Design: Applied to Switched Reluctance Motors",
    "abstract": "Switched Reluctance Motors (SRMs) are cost-effective electric actuators that utilize magnetic reluctance to generate torque, with torque ripple arising from unaccounted manufacturing defects in the rotor tooth geometry. This paper aims to design a versatile, resource-efficient commutation function for accurate closed-loop control of a range of SRMs, mitigating torque ripple despite manufacturing variations across SRMs and individual rotor teeth. The developed commutation function optimally distributes current between coils by leveraging the variance in the torque-current-angle model and is designed with few parameters for easy integration on affordable hardware. Monte Carlo simulations and experimental results show a tracking error reduction of up to 31% and 11%, respectively. The developed approach is beneficial for applications using a single driver for multiple systems and those constrained by memory or modeling effort, providing an economical solution for improved tracking performance and reduced acoustic noise. ",
    "url": "https://arxiv.org/abs/2402.01216",
    "authors": [
      "Max van Meer",
      "Gert Witvoet",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.01219",
    "title": "AI Code Generators for Security: Friend or Foe?",
    "abstract": "Recent advances of artificial intelligence (AI) code generators are opening new opportunities in software security research, including misuse by malicious actors. We review use cases for AI code generators for security and introduce an evaluation benchmark. ",
    "url": "https://arxiv.org/abs/2402.01219",
    "authors": [
      "Roberto Natella",
      "Pietro Liguori",
      "Cristina Improta",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.01220",
    "title": "Delving into Decision-based Black-box Attacks on Semantic Segmentation",
    "abstract": "Semantic segmentation is a fundamental visual task that finds extensive deployment in applications with security-sensitive considerations. Nonetheless, recent work illustrates the adversarial vulnerability of semantic segmentation models to white-box attacks. However, its adversarial robustness against black-box attacks has not been fully explored. In this paper, we present the first exploration of black-box decision-based attacks on semantic segmentation. First, we analyze the challenges that semantic segmentation brings to decision-based attacks through the case study. Then, to address these challenges, we first propose a decision-based attack on semantic segmentation, called Discrete Linear Attack (DLA). Based on random search and proxy index, we utilize the discrete linear noises for perturbation exploration and calibration to achieve efficient attack efficiency. We conduct adversarial robustness evaluation on 5 models from Cityscapes and ADE20K under 8 attacks. DLA shows its formidable power on Cityscapes by dramatically reducing PSPNet's mIoU from an impressive 77.83% to a mere 2.14% with just 50 queries. ",
    "url": "https://arxiv.org/abs/2402.01220",
    "authors": [
      "Zhaoyu Chen",
      "Zhengyang Shan",
      "Jingwen Chang",
      "Kaixun Jiang",
      "Dingkang Yang",
      "Yiting Cheng",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.01227",
    "title": "STAA-Net: A Sparse and Transferable Adversarial Attack for Speech  Emotion Recognition",
    "abstract": "Speech contains rich information on the emotions of humans, and Speech Emotion Recognition (SER) has been an important topic in the area of human-computer interaction. The robustness of SER models is crucial, particularly in privacy-sensitive and reliability-demanding domains like private healthcare. Recently, the vulnerability of deep neural networks in the audio domain to adversarial attacks has become a popular area of research. However, prior works on adversarial attacks in the audio domain primarily rely on iterative gradient-based techniques, which are time-consuming and prone to overfitting the specific threat model. Furthermore, the exploration of sparse perturbations, which have the potential for better stealthiness, remains limited in the audio domain. To address these challenges, we propose a generator-based attack method to generate sparse and transferable adversarial examples to deceive SER models in an end-to-end and efficient manner. We evaluate our method on two widely-used SER datasets, Database of Elicited Mood in Speech (DEMoS) and Interactive Emotional dyadic MOtion CAPture (IEMOCAP), and demonstrate its ability to generate successful sparse adversarial examples in an efficient manner. Moreover, our generated adversarial examples exhibit model-agnostic transferability, enabling effective adversarial attacks on advanced victim models. ",
    "url": "https://arxiv.org/abs/2402.01227",
    "authors": [
      "Yi Chang",
      "Zhao Ren",
      "Zixing Zhang",
      "Xin Jing",
      "Kun Qian",
      "Xi Shao",
      "Bin Hu",
      "Tanja Schultz",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.01230",
    "title": "Trees and co-trees in planar 3-connected planar graphs An easier proof  via Schnyder woods",
    "abstract": "Let $G$ be a 3-connected planar graph. Define the co-tree of a spanning tree $T$ of $G$ as the graph induced by the dual edges of $E(G)-E(T)$. The well-known cut-cycle duality implies that the co-tree is itself a tree. Let a $k$-tree be a spanning tree with maximum degree $k$. In 1970, Gr\\\"unbaum conjectured that every 3-connected planar graph contains a 3-tree whose co-tree is also a 3-tree. In 2014, Biedl showed that every such graph contains a 5-tree whose co-tree is a 5-tree. In this paper, we present an easier proof of Biedl's result using Schnyder woods. ",
    "url": "https://arxiv.org/abs/2402.01230",
    "authors": [
      "Christian Ortlieb",
      "Jens M. Schmidt"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2402.01242",
    "title": "Two Heads Are Better Than One: Boosting Graph Sparse Training via  Semantic and Topological Awareness",
    "abstract": "Graph Neural Networks (GNNs) excel in various graph learning tasks but face computational challenges when applied to large-scale graphs. A promising solution is to remove non-essential edges to reduce the computational overheads in GNN. Previous literature generally falls into two categories: topology-guided and semantic-guided. The former maintains certain graph topological properties yet often underperforms on GNNs due to low integration with neural network training. The latter performs well at lower sparsity on GNNs but faces performance collapse at higher sparsity levels. With this in mind, we take the first step to propose a new research line and concept termed Graph Sparse Training (GST), which dynamically manipulates sparsity at the data level. Specifically, GST initially constructs a topology & semantic anchor at a low training cost, followed by performing dynamic sparse training to align the sparse graph with the anchor. We introduce the Equilibria Sparsification Principle to guide this process, effectively balancing the preservation of both topological and semantic information. Ultimately, GST produces a sparse graph with maximum topological integrity and no performance degradation. Extensive experiments on 6 datasets and 5 backbones showcase that GST (I) identifies subgraphs at higher graph sparsity levels (1.67%~15.85% $\\uparrow$) than state-of-the-art sparsification methods, (II) preserves more key spectral properties, (III) achieves 1.27-3.42$\\times$ speedup in GNN inference and (IV) successfully helps graph adversarial defense and graph lottery tickets. ",
    "url": "https://arxiv.org/abs/2402.01242",
    "authors": [
      "Guibin Zhang",
      "Yanwei Yue",
      "Kun Wang",
      "Junfeng Fang",
      "Yongduo Sui",
      "Kai Wang",
      "Yuxuan Liang",
      "Dawei Cheng",
      "Shirui Pan",
      "Tianlong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01254",
    "title": "Neural Trajectory Model: Implicit Neural Trajectory Representation for  Trajectories Generation",
    "abstract": "Trajectory planning is a fundamental problem in robotics. It facilitates a wide range of applications in navigation and motion planning, control, and multi-agent coordination. Trajectory planning is a difficult problem due to its computational complexity and real-world environment complexity with uncertainty, non-linearity, and real-time requirements. The multi-agent trajectory planning problem adds another dimension of difficulty due to inter-agent interaction. Existing solutions are either search-based or optimization-based approaches with simplified assumptions of environment, limited planning speed, and limited scalability in the number of agents. In this work, we make the first attempt to reformulate single agent and multi-agent trajectory planning problem as query problems over an implicit neural representation of trajectories. We formulate such implicit representation as Neural Trajectory Models (NTM) which can be queried to generate nearly optimal trajectory in complex environments. We conduct experiments in simulation environments and demonstrate that NTM can solve single-agent and multi-agent trajectory planning problems. In the experiments, NTMs achieve (1) sub-millisecond panning time using GPUs, (2) almost avoiding all environment collision, (3) almost avoiding all inter-agent collision, and (4) generating almost shortest paths. We also demonstrate that the same NTM framework can also be used for trajectories correction and multi-trajectory conflict resolution refining low quality and conflicting multi-agent trajectories into nearly optimal solutions efficiently. (Open source code will be available at https://github.com/laser2099/neural-trajectory-model) ",
    "url": "https://arxiv.org/abs/2402.01254",
    "authors": [
      "Zihan Yu",
      "Yuqing Tang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.01269",
    "title": "Spectrum-guided Feature Enhancement Network for Event Person  Re-Identification",
    "abstract": "As a cutting-edge biosensor, the event camera holds significant potential in the field of computer vision, particularly regarding privacy preservation. However, compared to traditional cameras, event streams often contain noise and possess extremely sparse semantics, posing a formidable challenge for event-based person re-identification (event Re-ID). To address this, we introduce a novel event person re-identification network: the Spectrum-guided Feature Enhancement Network (SFE-Net). This network consists of two innovative components: the Multi-grain Spectrum Attention Mechanism (MSAM) and the Consecutive Patch Dropout Module (CPDM). MSAM employs a fourier spectrum transform strategy to filter event noise, while also utilizing an event-guided multi-granularity attention strategy to enhance and capture discriminative person semantics. CPDM employs a consecutive patch dropout strategy to generate multiple incomplete feature maps, encouraging the deep Re-ID model to equally perceive each effective region of the person's body and capture robust person descriptors. Extensive experiments on Event Re-ID datasets demonstrate that our SFE-Net achieves the best performance in this task. ",
    "url": "https://arxiv.org/abs/2402.01269",
    "authors": [
      "Hongchen Tan",
      "Yi Zhang",
      "Xiuping Liu",
      "Baocai Yin",
      "Nan Ma",
      "Xin Li",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01279",
    "title": "An Improved Viterbi Algorithm for a Class of Optimal Binary  Convolutional Codes",
    "abstract": "The most famous error-decoding algorithm for convolutional codes is the Viterbi algorithm. In this paper, we present a new reduced complexity version of this algorithm which can be applied to a class of binary convolutional codes with optimum column distances called k-partial simplex convolutional codes. ",
    "url": "https://arxiv.org/abs/2402.01279",
    "authors": [
      "Zita Abreu",
      "Julia Lieb",
      "Michael Schaller"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.01287",
    "title": "Spiking CenterNet: A Distillation-boosted Spiking Neural Network for  Object Detection",
    "abstract": "In the era of AI at the edge, self-driving cars, and climate change, the need for energy-efficient, small, embedded AI is growing. Spiking Neural Networks (SNNs) are a promising approach to address this challenge, with their event-driven information flow and sparse activations. We propose Spiking CenterNet for object detection on event data. It combines an SNN CenterNet adaptation with an efficient M2U-Net-based decoder. Our model significantly outperforms comparable previous work on Prophesee's challenging GEN1 Automotive Detection Dataset while using less than half the energy. Distilling the knowledge of a non-spiking teacher into our SNN further increases performance. To the best of our knowledge, our work is the first approach that takes advantage of knowledge distillation in the field of spiking object detection. ",
    "url": "https://arxiv.org/abs/2402.01287",
    "authors": [
      "Lennard Bodden",
      "Franziska Schwaiger",
      "Duc Bach Ha",
      "Lars Kreuzberg",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.01295",
    "title": "ExtremeCast: Boosting Extreme Value Prediction for Global Weather  Forecast",
    "abstract": "Data-driven weather forecast based on machine learning (ML) has experienced rapid development and demonstrated superior performance in the global medium-range forecast compared to traditional physics-based dynamical models. However, most of these ML models struggle with accurately predicting extreme weather, which is closely related to the extreme value prediction. Through mathematical analysis, we prove that the use of symmetric losses, such as the Mean Squared Error (MSE), leads to biased predictions and underestimation of extreme values. To address this issue, we introduce Exloss, a novel loss function that performs asymmetric optimization and highlights extreme values to obtain accurate extreme weather forecast. Furthermore, we introduce a training-free extreme value enhancement strategy named ExEnsemble, which increases the variance of pixel values and improves the forecast robustness. Combined with an advanced global weather forecast model, extensive experiments show that our solution can achieve state-of-the-art performance in extreme weather prediction, while maintaining the overall forecast accuracy comparable to the top medium-range forecast models. ",
    "url": "https://arxiv.org/abs/2402.01295",
    "authors": [
      "Wanghan Xu",
      "Kang Chen",
      "Tao Han",
      "Hao Chen",
      "Wanli Ouyang",
      "Lei Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.01296",
    "title": "Bi-CryptoNets: Leveraging Different-Level Privacy for Encrypted  Inference",
    "abstract": "Privacy-preserving neural networks have attracted increasing attention in recent years, and various algorithms have been developed to keep the balance between accuracy, computational complexity and information security from the cryptographic view. This work takes a different view from the input data and structure of neural networks. We decompose the input data (e.g., some images) into sensitive and insensitive segments according to importance and privacy. The sensitive segment includes some important and private information such as human faces and we take strong homomorphic encryption to keep security, whereas the insensitive one contains some background and we add perturbations. We propose the bi-CryptoNets, i.e., plaintext and ciphertext branches, to deal with two segments, respectively, and ciphertext branch could utilize the information from plaintext branch by unidirectional connections. We adopt knowledge distillation for our bi-CryptoNets by transferring representations from a well-trained teacher neural network. Empirical studies show the effectiveness and decrease of inference latency for our bi-CryptoNets. ",
    "url": "https://arxiv.org/abs/2402.01296",
    "authors": [
      "Man-Jie Yuan",
      "Zheng Zou",
      "Wei Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01304",
    "title": "Phrase Grounding-based Style Transfer for Single-Domain Generalized  Object Detection",
    "abstract": "Single-domain generalized object detection aims to enhance a model's generalizability to multiple unseen target domains using only data from a single source domain during training. This is a practical yet challenging task as it requires the model to address domain shift without incorporating target domain data into training. In this paper, we propose a novel phrase grounding-based style transfer (PGST) approach for the task. Specifically, we first define textual prompts to describe potential objects for each unseen target domain. Then, we leverage the grounded language-image pre-training (GLIP) model to learn the style of these target domains and achieve style transfer from the source to the target domain. The style-transferred source visual features are semantically rich and could be close to imaginary counterparts in the target domain. Finally, we employ these style-transferred visual features to fine-tune GLIP. By introducing imaginary counterparts, the detector could be effectively generalized to unseen target domains using only a single source domain for training. Extensive experimental results on five diverse weather driving benchmarks demonstrate our proposed approach achieves state-of-the-art performance, even surpassing some domain adaptive methods that incorporate target domain images into the training process.The source codes and pre-trained models will be made available. ",
    "url": "https://arxiv.org/abs/2402.01304",
    "authors": [
      "Hao Li",
      "Wei Wang",
      "Cong Wang",
      "Zhigang Luo",
      "Xinwang Liu",
      "Kenli Li",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01311",
    "title": "Deep Multimodal Fusion of Data with Heterogeneous Dimensionality via  Projective Networks",
    "abstract": "The use of multimodal imaging has led to significant improvements in the diagnosis and treatment of many diseases. Similar to clinical practice, some works have demonstrated the benefits of multimodal fusion for automatic segmentation and classification using deep learning-based methods. However, current segmentation methods are limited to fusion of modalities with the same dimensionality (e.g., 3D+3D, 2D+2D), which is not always possible, and the fusion strategies implemented by classification methods are incompatible with localization tasks. In this work, we propose a novel deep learning-based framework for the fusion of multimodal data with heterogeneous dimensionality (e.g., 3D+2D) that is compatible with localization tasks. The proposed framework extracts the features of the different modalities and projects them into the common feature subspace. The projected features are then fused and further processed to obtain the final prediction. The framework was validated on the following tasks: segmentation of geographic atrophy (GA), a late-stage manifestation of age-related macular degeneration, and segmentation of retinal blood vessels (RBV) in multimodal retinal imaging. Our results show that the proposed method outperforms the state-of-the-art monomodal methods on GA and RBV segmentation by up to 3.10% and 4.64% Dice, respectively. ",
    "url": "https://arxiv.org/abs/2402.01311",
    "authors": [
      "Jos\u00e9 Morano",
      "Guilherme Aresta",
      "Christoph Grechenig",
      "Ursula Schmidt-Erfurth",
      "Hrvoje Bogunovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2402.01313",
    "title": "AutoGCN -- Towards Generic Human Activity Recognition with Neural  Architecture Search",
    "abstract": "This paper introduces AutoGCN, a generic Neural Architecture Search (NAS) algorithm for Human Activity Recognition (HAR) using Graph Convolution Networks (GCNs). HAR has gained attention due to advances in deep learning, increased data availability, and enhanced computational capabilities. At the same time, GCNs have shown promising results in modeling relationships between body key points in a skeletal graph. While domain experts often craft dataset-specific GCN-based methods, their applicability beyond this specific context is severely limited. AutoGCN seeks to address this limitation by simultaneously searching for the ideal hyperparameters and architecture combination within a versatile search space using a reinforcement controller while balancing optimal exploration and exploitation behavior with a knowledge reservoir during the search process. We conduct extensive experiments on two large-scale datasets focused on skeleton-based action recognition to assess the proposed algorithm's performance. Our experimental results underscore the effectiveness of AutoGCN in constructing optimal GCN architectures for HAR, outperforming conventional NAS and GCN methods, as well as random search. These findings highlight the significance of a diverse search space and an expressive input representation to enhance the network performance and generalizability. ",
    "url": "https://arxiv.org/abs/2402.01313",
    "authors": [
      "Felix Tempel",
      "Inga Str\u00fcmke",
      "Espen Alexander F. Ihlen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01340",
    "title": "SignSGD with Federated Defense: Harnessing Adversarial Attacks through  Gradient Sign Decoding",
    "abstract": "Distributed learning is an effective approach to accelerate model training using multiple workers. However, substantial communication delays emerge between workers and a parameter server due to massive costs associated with communicating gradients. SignSGD with majority voting (signSGD-MV) is a simple yet effective optimizer that reduces communication costs through one-bit quantization, yet the convergence rates considerably decrease as adversarial workers increase. In this paper, we show that the convergence rate is invariant as the number of adversarial workers increases, provided that the number of adversarial workers is smaller than that of benign workers. The key idea showing this counter-intuitive result is our novel signSGD with federated defense (signSGD-FD). Unlike the traditional approaches, signSGD-FD exploits the gradient information sent by adversarial workers with the proper weights, which are obtained through gradient sign decoding. Experimental results demonstrate signSGD-FD achieves superior convergence rates over traditional algorithms in various adversarial attack scenarios. ",
    "url": "https://arxiv.org/abs/2402.01340",
    "authors": [
      "Chanho Park",
      "Namyoon Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.01341",
    "title": "Fundamental Properties of Causal Entropy and Information Gain",
    "abstract": "Recent developments enable the quantification of causal control given a structural causal model (SCM). This has been accomplished by introducing quantities which encode changes in the entropy of one variable when intervening on another. These measures, named causal entropy and causal information gain, aim to address limitations in existing information theoretical approaches for machine learning tasks where causality plays a crucial role. They have not yet been properly mathematically studied. Our research contributes to the formal understanding of the notions of causal entropy and causal information gain by establishing and analyzing fundamental properties of these concepts, including bounds and chain rules. Furthermore, we elucidate the relationship between causal entropy and stochastic interventions. We also propose definitions for causal conditional entropy and causal conditional information gain. Overall, this exploration paves the way for enhancing causal machine learning tasks through the study of recently-proposed information theoretic quantities grounded in considerations about causality. ",
    "url": "https://arxiv.org/abs/2402.01341",
    "authors": [
      "Francisco N. F. Q. Simoes",
      "Mehdi Dastani",
      "Thijs van Ommen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01344",
    "title": "Monotone, Bi-Lipschitz, and Polyak-\u0141ojasiewicz Networks",
    "abstract": "This paper presents a new \\emph{bi-Lipschitz} invertible neural network, the BiLipNet, which has the ability to control both its \\emph{Lipschitzness} (output sensitivity to input perturbations) and \\emph{inverse Lipschitzness} (input distinguishability from different outputs). The main contribution is a novel invertible residual layer with certified strong monotonicity and Lipschitzness, which we compose with orthogonal layers to build bi-Lipschitz networks. The certification is based on incremental quadratic constraints, which achieves much tighter bounds compared to spectral normalization. Moreover, we formulate the model inverse calculation as a three-operator splitting problem, for which fast algorithms are known. Based on the proposed bi-Lipschitz network, we introduce a new scalar-output network, the PLNet, which satisfies the Polyak-\\L{}ojasiewicz condition. It can be applied to learn non-convex surrogate losses with favourable properties, e.g., a unique and efficiently-computable global minimum. ",
    "url": "https://arxiv.org/abs/2402.01344",
    "authors": [
      "Ruigang Wang",
      "Krishnamurthy Dvijotham",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01353",
    "title": "Efficient compilation of expressive problem space specifications to  neural network solvers",
    "abstract": "Recent work has described the presence of the embedding gap in neural network verification. On one side of the gap is a high-level specification about the network's behaviour, written by a domain expert in terms of the interpretable problem space. On the other side are a logically-equivalent set of satisfiability queries, expressed in the uninterpretable embedding space in a form suitable for neural network solvers. In this paper we describe an algorithm for compiling the former to the latter. We explore and overcome complications that arise from targeting neural network solvers as opposed to standard SMT solvers. ",
    "url": "https://arxiv.org/abs/2402.01353",
    "authors": [
      "Matthew L. Daggitt",
      "Wen Kokke",
      "Robert Atkey"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01363",
    "title": "Bribe & Fork: Cheap Bribing Attacks via Forking Threat",
    "abstract": "In this work, we reexamine the vulnerability of Payment Channel Networks (PCNs) to bribing attacks, where an adversary incentivizes blockchain miners to deliberately ignore a specific transaction to undermine the punishment mechanism of PCNs. While previous studies have posited a prohibitive cost for such attacks, we show that this cost may be dramatically reduced (to approximately \\$125), thereby increasing the likelihood of these attacks. To this end, we introduce Bribe & Fork, a modified bribing attack that leverages the threat of a so-called feather fork which we analyze with a novel formal model for the mining game with forking. We empirically analyze historical data of some real-world blockchain implementations to evaluate the scale of this cost reduction. Our findings shed more light on the potential vulnerability of PCNs and highlight the need for robust solutions. ",
    "url": "https://arxiv.org/abs/2402.01363",
    "authors": [
      "Zeta Avarikioti",
      "Pawe\u0142 K\u0119dzior",
      "Tomasz Lizurej",
      "Tomasz Michalak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.01369",
    "title": "Cheating Suffix: Targeted Attack to Text-To-Image Diffusion Models with  Multi-Modal Priors",
    "abstract": "Diffusion models have been widely deployed in various image generation tasks, demonstrating an extraordinary connection between image and text modalities. However, they face challenges of being maliciously exploited to generate harmful or sensitive images by appending a specific suffix to the original prompt. Existing works mainly focus on using single-modal information to conduct attacks, which fails to utilize multi-modal features and results in less than satisfactory performance. Integrating multi-modal priors (MMP), i.e. both text and image features, we propose a targeted attack method named MMP-Attack in this work. Specifically, the goal of MMP-Attack is to add a target object into the image content while simultaneously removing the original object. The MMP-Attack shows a notable advantage over existing works with superior universality and transferability, which can effectively attack commercial text-to-image (T2I) models such as DALL-E 3. To the best of our knowledge, this marks the first successful attempt of transfer-based attack to commercial T2I models. Our code is publicly available at \\url{https://github.com/ydc123/MMP-Attack}. ",
    "url": "https://arxiv.org/abs/2402.01369",
    "authors": [
      "Dingcheng Yang",
      "Yang Bai",
      "Xiaojun Jia",
      "Yang Liu",
      "Xiaochun Cao",
      "Wenjian Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01391",
    "title": "StepCoder: Improve Code Generation with Reinforcement Learning from  Compiler Feedback",
    "abstract": "The advancement of large language models (LLMs) has significantly propelled the field of code generation. Previous work integrated reinforcement learning (RL) with compiler feedback for exploring the output space of LLMs to enhance code generation quality. However, the lengthy code generated by LLMs in response to complex human requirements makes RL exploration a challenge. Also, since the unit tests may not cover the complicated code, optimizing LLMs by using these unexecuted code snippets is ineffective. To tackle these challenges, we introduce StepCoder, a novel RL framework for code generation, consisting of two main components: CCCS addresses the exploration challenge by breaking the long sequences code generation task into a Curriculum of Code Completion Subtasks, while FGO only optimizes the model by masking the unexecuted code segments to provide Fine-Grained Optimization. In addition, we furthermore construct the APPS+ dataset for RL training, which is manually verified to ensure the correctness of unit tests. Experimental results show that our method improves the ability to explore the output space and outperforms state-of-the-art approaches in corresponding benchmarks. ",
    "url": "https://arxiv.org/abs/2402.01391",
    "authors": [
      "Shihan Dou",
      "Yan Liu",
      "Haoxiang Jia",
      "Limao Xiong",
      "Enyu Zhou",
      "Junjie Shan",
      "Caishuang Huang",
      "Wei Shen",
      "Xiaoran Fan",
      "Zhiheng Xi",
      "Yuhao Zhou",
      "Tao Ji",
      "Rui Zheng",
      "Qi Zhang",
      "Xuanjing Huang",
      "Tao Gui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01397",
    "title": "A survey on robustness in trajectory prediction for autonomous vehicles",
    "abstract": "Autonomous vehicles rely on accurate trajectory prediction to inform decision-making processes related to navigation and collision avoidance. However, current trajectory prediction models show signs of overfitting, which may lead to unsafe or suboptimal behavior. To address these challenges, this paper presents a comprehensive framework that categorizes and assesses the definitions and strategies used in the literature on evaluating and improving the robustness of trajectory prediction models. This involves a detailed exploration of various approaches, including data slicing methods, perturbation techniques, model architecture changes, and post-training adjustments. In the literature, we see many promising methods for increasing robustness, which are necessary for safe and reliable autonomous driving. ",
    "url": "https://arxiv.org/abs/2402.01397",
    "authors": [
      "Jeroen Hagenus",
      "Frederik Baymler Mathiesen",
      "Julian F. Schumann",
      "Arkady Zgonnikov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.01399",
    "title": "A Probabilistic Model to explain Self-Supervised Representation Learning",
    "abstract": "Self-supervised learning (SSL) learns representations by leveraging an auxiliary unsupervised task, such as classifying semantically related samples, e.g. different data augmentations or modalities. Of the many approaches to SSL, contrastive methods, e.g. SimCLR, CLIP and VicREG, have gained attention for learning representations that achieve downstream performance close to that of supervised learning. However, a theoretical understanding of the mechanism behind these methods eludes. We propose a generative latent variable model for the data and show that several families of discriminative self-supervised algorithms, including contrastive methods, approximately induce its latent structure over representations, providing a unifying theoretical framework. We also justify links to mutual information and the use of a projection head. Fitting our model generatively, as SimVE, improves performance over previous VAE methods on common benchmarks (e.g. FashionMNIST, CIFAR10, CelebA), narrows the gap to discriminative methods on _content_ classification and, as our analysis predicts, outperforms them where _style_ information is required, taking a step toward task-agnostic representations. ",
    "url": "https://arxiv.org/abs/2402.01399",
    "authors": [
      "Alice Bizeul",
      "Bernhard Sch\u00f6lkopf",
      "Carl Allen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01410",
    "title": "XAI for Skin Cancer Detection with Prototypes and Non-Expert Supervision",
    "abstract": "Skin cancer detection through dermoscopy image analysis is a critical task. However, existing models used for this purpose often lack interpretability and reliability, raising the concern of physicians due to their black-box nature. In this paper, we propose a novel approach for the diagnosis of melanoma using an interpretable prototypical-part model. We introduce a guided supervision based on non-expert feedback through the incorporation of: 1) binary masks, obtained automatically using a segmentation network; and 2) user-refined prototypes. These two distinct information pathways aim to ensure that the learned prototypes correspond to relevant areas within the skin lesion, excluding confounding factors beyond its boundaries. Experimental results demonstrate that, even without expert supervision, our approach achieves superior performance and generalization compared to non-interpretable models. ",
    "url": "https://arxiv.org/abs/2402.01410",
    "authors": [
      "Miguel Correia",
      "Alceu Bissoto",
      "Carlos Santiago",
      "Catarina Barata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01424",
    "title": "A Data-Driven Analysis of Robust Automatic Piano Transcription",
    "abstract": "Algorithms for automatic piano transcription have improved dramatically in recent years due to new datasets and modeling techniques. Recent developments have focused primarily on adapting new neural network architectures, such as the Transformer and Perceiver, in order to yield more accurate systems. In this work, we study transcription systems from the perspective of their training data. By measuring their performance on out-of-distribution annotated piano data, we show how these models can severely overfit to acoustic properties of the training data. We create a new set of audio for the MAESTRO dataset, captured automatically in a professional studio recording environment via Yamaha Disklavier playback. Using various data augmentation techniques when training with the original and re-performed versions of the MAESTRO dataset, we achieve state-of-the-art note-onset accuracy of 88.4 F1-score on the MAPS dataset, without seeing any of its training data. We subsequently analyze these data augmentation techniques in a series of ablation studies to better understand their influence on the resulting models. ",
    "url": "https://arxiv.org/abs/2402.01424",
    "authors": [
      "Drew Edwards",
      "Simon Dixon",
      "Emmanouil Benetos",
      "Akira Maezawa",
      "Yuta Kusaka"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.01438",
    "title": "Exploring the Effect of Multiple Natural Languages on Code Suggestion  Using GitHub Copilot",
    "abstract": "GitHub Copilot is an AI-enabled tool that automates program synthesis. It has gained significant attention since its launch in 2021. Recent studies have extensively examined Copilot's capabilities in various programming tasks, as well as its security issues. However, little is known about the effect of different natural languages on code suggestion. Natural language is considered a social bias in the field of NLP, and this bias could impact the diversity of software engineering. To address this gap, we conducted an empirical study to investigate the effect of three popular natural languages (English, Japanese, and Chinese) on Copilot. We used 756 questions of varying difficulty levels from AtCoder contests for evaluation purposes. The results highlight that the capability varies across natural languages, with Chinese achieving the worst performance. Furthermore, regardless of the type of natural language, the performance decreases significantly as the difficulty of questions increases. Our work represents the initial step in comprehending the significance of natural languages in Copilot's capability and introduces promising opportunities for future endeavors. ",
    "url": "https://arxiv.org/abs/2402.01438",
    "authors": [
      "Kei Koyanagi",
      "Dong Wang",
      "Kotaro Noguchi",
      "Masanari Kondo",
      "Alexander Serebrenik",
      "Yasutaka Kamei",
      "Naoyasu Ubayashi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.01443",
    "title": "Frenetix Motion Planner: High-Performance and Modular Trajectory  Planning Algorithm for Complex Autonomous Driving Scenarios",
    "abstract": "Our work aims to present a high-performance and modular sampling-based trajectory planning algorithm for autonomous vehicles. This algorithm is tailored to address the complex challenges in solution space construction and optimization problem formulation within the path planning domain. Our method employs a multi-objective optimization strategy for efficient navigation in static and highly dynamic environments, focusing on optimizing trajectory comfort, safety, and path precision. This algorithm was then used to analyze the algorithm performance and success rate in 1750 virtual complex urban and highway scenarios. Our results demonstrate fast calculation times (8ms for 800 trajectories), a high success rate in complex scenarios (88%), and easy adaptability with different modules presented. The most noticeable difference exhibited was the fast trajectory sampling, feasibility check, and cost evaluation step across various trajectory counts. While our study presents promising results, it's important to note that our assessments have been conducted exclusively in simulated environments, and real-world testing is required to fully validate our findings. The code and the additional modules used in this research are publicly available as open-source software and can be accessed at the following link: https://github.com/TUM-AVS/Frenetix-Motion-Planner. ",
    "url": "https://arxiv.org/abs/2402.01443",
    "authors": [
      "Korbinian Moller",
      "Rainer Trauth",
      "Gerald Wuersching",
      "Johannes Betz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.01446",
    "title": "Guidance Graph Optimization for Lifelong Multi-Agent Path Finding",
    "abstract": "We study how to use guidance to improve the throughput of lifelong Multi-Agent Path Finding (MAPF). Previous studies have demonstrated that while incorporating guidance, such as highways, can accelerate MAPF algorithms, this often results in a trade-off with solution quality. In addition, how to generate good guidance automatically remains largely unexplored, with current methods falling short of surpassing manually designed ones. In this work, we introduce the directed guidance graph as a versatile representation of guidance for lifelong MAPF, framing Guidance Graph Optimization (GGO) as the task of optimizing its edge weights. We present two GGO algorithms to automatically generate guidance for arbitrary lifelong MAPF algorithms and maps. The first method directly solves GGO by employing CMA-ES, a black-box optimization algorithm. The second method, PIU, optimizes an update model capable of generating guidance, demonstrating the ability to transfer optimized guidance graphs to larger maps with similar layouts. Empirically, we show that (1) our guidance graphs improve the throughput of three representative lifelong MAPF algorithms in four benchmark maps, and (2) our update model can generate guidance graphs for as large as $93 \\times 91$ maps and as many as 3000 agents. ",
    "url": "https://arxiv.org/abs/2402.01446",
    "authors": [
      "Yulun Zhang",
      "He Jiang",
      "Varun Bhatt",
      "Stefanos Nikolaidis",
      "Jiaoyang Li"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.01450",
    "title": "Improving importance estimation in covariate shift for providing  accurate prediction error",
    "abstract": "In traditional Machine Learning, the algorithms predictions are based on the assumption that the data follows the same distribution in both the training and the test datasets. However, in real world data this condition does not hold and, for instance, the distribution of the covariates changes whereas the conditional distribution of the targets remains unchanged. This situation is called covariate shift problem where standard error estimation may be no longer accurate. In this context, the importance is a measure commonly used to alleviate the influence of covariate shift on error estimations. The main drawback is that it is not easy to compute. The Kullback-Leibler Importance Estimation Procedure (KLIEP) is capable of estimating importance in a promising way. Despite its good performance, it fails to ignore target information, since it only includes the covariates information for computing the importance. In this direction, this paper explores the potential performance improvement if target information is considered in the computation of the importance. Then, a redefinition of the importance arises in order to be generalized in this way. Besides the potential improvement in performance, including target information make possible the application to a real application about plankton classification that motivates this research and characterized by its great dimensionality, since considering targets rather than covariates reduces the computation and the noise in the covariates. The impact of taking target information is also explored when Logistic Regression (LR), Kernel Mean Matching (KMM), Ensemble Kernel Mean Matching (EKMM) and the naive predecessor of KLIEP called Kernel Density Estimation (KDE) methods estimate the importance. The experimental results lead to a more accurate error estimation using target information, especially in case of the more promising method KLIEP. ",
    "url": "https://arxiv.org/abs/2402.01450",
    "authors": [
      "Laura Fdez-D\u00edaz",
      "Sara Gonz\u00e1lez Tomillo",
      "Elena Monta\u00f1\u00e9s",
      "Jos\u00e9 Ram\u00f3n Quevedo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01454",
    "title": "Integrating Large Language Models in Causal Discovery: A Statistical  Causal Approach",
    "abstract": "In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through \"statistical causal prompting (SCP)\" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach can thus address challenges such as dataset biases and limitations, illustrating the potential of LLMs to improve data-driven causal inference across diverse scientific domains. ",
    "url": "https://arxiv.org/abs/2402.01454",
    "authors": [
      "Masayuki Takayama",
      "Tadahisa Okuda",
      "Thong Pham",
      "Tatsuyoshi Ikenoue",
      "Shingo Fukuma",
      "Shohei Shimizu",
      "Akiyoshi Sannai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01484",
    "title": "Connecting the Dots: Is Mode-Connectedness the Key to Feasible  Sample-Based Inference in Bayesian Neural Networks?",
    "abstract": "A major challenge in sample-based inference (SBI) for Bayesian neural networks is the size and structure of the networks' parameter space. Our work shows that successful SBI is possible by embracing the characteristic relationship between weight and function space, uncovering a systematic link between overparameterization and the difficulty of the sampling problem. Through extensive experiments, we establish practical guidelines for sampling and convergence diagnosis. As a result, we present a Bayesian deep ensemble approach as an effective solution with competitive performance and uncertainty quantification. ",
    "url": "https://arxiv.org/abs/2402.01484",
    "authors": [
      "Emanuel Sommer",
      "Lisa Wimmer",
      "Theodore Papamarkou",
      "Ludwig Bothmann",
      "Bernd Bischl",
      "David R\u00fcgamer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01511",
    "title": "Simulation-based optimization of a production system topology -- a  neural network-assisted genetic algorithm",
    "abstract": "There is an abundance of prior research on the optimization of production systems, but there is a research gap when it comes to optimizing which components should be included in a design, and how they should be connected. To overcome this gap, a novel approach is presented for topology optimization of production systems using a genetic algorithm (GA). This GA employs similarity-based mutation and recombination for the creation of offspring, and discrete-event simulation for fitness evaluation. To reduce computational cost, an extension to the GA is presented in which a neural network functions as a surrogate model for simulation. Three types of neural networks are compared, and the type most effective as a surrogate model is chosen based on its optimization performance and computational cost. Both the unassisted GA and neural network-assisted GA are applied to an industrial case study and a scalability case study. These show that both approaches are effective at finding the optimal solution in industrial settings, and both scale well as the number of potential solutions increases, with the neural network-assisted GA having the better scalability of the two. ",
    "url": "https://arxiv.org/abs/2402.01511",
    "authors": [
      "N. Paape",
      "J.A.W.M. van Eekelen",
      "M.A. Reniers"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.01520",
    "title": "Low-Resource Cross-Domain Singing Voice Synthesis via Reduced  Self-Supervised Speech Representations",
    "abstract": "In this paper, we propose a singing voice synthesis model, Karaoker-SSL, that is trained only on text and speech data as a typical multi-speaker acoustic model. It is a low-resource pipeline that does not utilize any singing data end-to-end, since its vocoder is also trained on speech data. Karaoker-SSL is conditioned by self-supervised speech representations in an unsupervised manner. We preprocess these representations by selecting only a subset of their task-correlated dimensions. The conditioning module is indirectly guided to capture style information during training by multi-tasking. This is achieved with a Conformer-based module, which predicts the pitch from the acoustic model's output. Thus, Karaoker-SSL allows singing voice synthesis without reliance on hand-crafted and domain-specific features. There are also no requirements for text alignments or lyrics timestamps. To refine the voice quality, we employ a U-Net discriminator that is conditioned on the target speaker and follows a Diffusion GAN training scheme. ",
    "url": "https://arxiv.org/abs/2402.01520",
    "authors": [
      "Panos Kakoulidis",
      "Nikolaos Ellinas",
      "Georgios Vamvoukakis",
      "Myrsini Christidou",
      "Alexandra Vioni",
      "Georgia Maniati",
      "Junkwang Oh",
      "Gunu Jho",
      "Inchul Hwang",
      "Pirros Tsiakoulis",
      "Aimilios Chalamandaris"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.01533",
    "title": "Efficient and Effective Time-Series Forecasting with Spiking Neural  Networks",
    "abstract": "Spiking neural networks (SNNs), inspired by the spiking behavior of biological neurons, provide a unique pathway for capturing the intricacies of temporal data. However, applying SNNs to time-series forecasting is challenging due to difficulties in effective temporal alignment, complexities in encoding processes, and the absence of standardized guidelines for model selection. In this paper, we propose a framework for SNNs in time-series forecasting tasks, leveraging the efficiency of spiking neurons in processing temporal information. Through a series of experiments, we demonstrate that our proposed SNN-based approaches achieve comparable or superior results to traditional time-series forecasting methods on diverse benchmarks with much less energy consumption. Furthermore, we conduct detailed analysis experiments to assess the SNN's capacity to capture temporal dependencies within time-series data, offering valuable insights into its nuanced strengths and effectiveness in modeling the intricate dynamics of temporal data. Our study contributes to the expanding field of SNNs and offers a promising alternative for time-series forecasting tasks, presenting a pathway for the development of more biologically inspired and temporally aware forecasting models. ",
    "url": "https://arxiv.org/abs/2402.01533",
    "authors": [
      "Changze Lv",
      "Yansen Wang",
      "Dongqi Han",
      "Xiaoqing Zheng",
      "Xuanjing Huang",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2402.01543",
    "title": "Adaptive Optimization for Prediction with Missing Data",
    "abstract": "When training predictive models on data with missing entries, the most widely used and versatile approach is a pipeline technique where we first impute missing entries and then compute predictions. In this paper, we view prediction with missing data as a two-stage adaptive optimization problem and propose a new class of models, adaptive linear regression models, where the regression coefficients adapt to the set of observed features. We show that some adaptive linear regression models are equivalent to learning an imputation rule and a downstream linear regression model simultaneously instead of sequentially. We leverage this joint-impute-then-regress interpretation to generalize our framework to non-linear models. In settings where data is strongly not missing at random, our methods achieve a 2-10% improvement in out-of-sample accuracy. ",
    "url": "https://arxiv.org/abs/2402.01543",
    "authors": [
      "Dimitris Bertsimas",
      "Arthur Delarue",
      "Jean Pauphilet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01547",
    "title": "Contingency Detection in Modern Power Systems: A Stochastic Hybrid  System Method",
    "abstract": "This paper introduces a new stochastic hybrid system (SHS) framework for contingency detection in modern power systems (MPS). The framework uses stochastic hybrid system representations in state space models to expand and facilitate capability of contingency detection. In typical microgrids (MGs), buses may contain various synchronous generators, renewable generators, controllable loads, battery systems, regular loads, etc. For development of SHS models in power systems, this paper introduces the concept of dynamic and non-dynamic buses. By converting a physical power grid into a virtual linearized state space model and representing contingencies as random switching of system structures and parameters, this paper formulates the contingency detection problem as a joint estimation problem of discrete event and continuous states in stochastic hybrid systems. This method offers unique advantages, including using common measurement signals on voltage and current synchrophasors to detect different types and locations of contingencies, avoiding expensive local direct fault measurements and detecting certain contingencies that cannot be directly measured. The method employs a small and suitably-designed probing signal to sustain the ability of persistent contingency detection. Joint estimation algorithms are presented with their proven convergence and reliability properties. Examples that use an IEEE 5-bus system demonstrate the main ideas and derivation steps. Simulation case studies on an IEEE 33-bus system are used for detecting transmission line faults and sensor interruptions. ",
    "url": "https://arxiv.org/abs/2402.01547",
    "authors": [
      "Shuo Yuan",
      "Le Yi Wang",
      "George Yin",
      "Masoud H. Nazari"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.01552",
    "title": "Hardware Trojans in Quantum Circuits, Their Impacts, and Defense",
    "abstract": "The reliability of the outcome of a quantum circuit in near-term noisy quantum computers depends on the gate count and depth for a given problem. Circuits with a short depth and lower gate count can yield the correct solution more often than the variant with a higher gate count and depth. To work successfully for Noisy Intermediate Scale Quantum (NISQ) computers, quantum circuits need to be optimized efficiently using a compiler that decomposes high-level gates to native gates of the hardware. Many 3rd party compilers are being developed for lower compilation time, reduced circuit depth, and lower gate count for large quantum circuits. Such compilers, or even a specific release version of a compiler that is otherwise trustworthy, may be unreliable and give rise to security risks such as insertion of a quantum trojan during compilation that evades detection due to the lack of a golden/Oracle model in quantum computing. Trojans may corrupt the functionality to give flipped probabilities of basis states, or result in a lower probability of correct basis states in the output. In this paper, we investigate and discuss the impact of a single qubit Trojan (we have chosen a Hadamard gate and a NOT gate) inserted one at a time at various locations in benchmark quantum circuits without changing the the depth of the circuit. Results indicate an average of 16.18% degradation for the Hadamard Trojan without noise, and 7.78% with noise. For the NOT Trojan (with noise) there is 14.6% degradation over all possible inputs. We then discuss the detection of such Trojans in a quantum circuit using CNN-based classifier achieving an accuracy of 90%. ",
    "url": "https://arxiv.org/abs/2402.01552",
    "authors": [
      "Rupshali Roy",
      "Subrata Das",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.01557",
    "title": "Deep Continuous Networks",
    "abstract": "CNNs and computational models of biological vision share some fundamental principles, which opened new avenues of research. However, fruitful cross-field research is hampered by conventional CNN architectures being based on spatially and depthwise discrete representations, which cannot accommodate certain aspects of biological complexity such as continuously varying receptive field sizes and dynamics of neuronal responses. Here we propose deep continuous networks (DCNs), which combine spatially continuous filters, with the continuous depth framework of neural ODEs. This allows us to learn the spatial support of the filters during training, as well as model the continuous evolution of feature maps, linking DCNs closely to biological models. We show that DCNs are versatile and highly applicable to standard image classification and reconstruction problems, where they improve parameter and data efficiency, and allow for meta-parametrization. We illustrate the biological plausibility of the scale distributions learned by DCNs and explore their performance in a neuroscientifically inspired pattern completion task. Finally, we investigate an efficient implementation of DCNs by changing input contrast. ",
    "url": "https://arxiv.org/abs/2402.01557",
    "authors": [
      "Nergis Tomen",
      "Silvia L. Pintea",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01576",
    "title": "Training Adversarial yet Safe Agent to Characterize Safety Performance  of Highly Automated Vehicles",
    "abstract": "This paper focuses on safety performance testing and characterization of black-box highly automated vehicles (HAV). Existing testing approaches typically obtain the testing outcomes by deploying the HAV into a specific testing environment. Such a testing environment can involve various passively given testing strategies presented by other traffic participants such as (i) the naturalistic driving policy learned from human drivers, (ii) extracted concrete scenarios from real-world driving data, and (iii) model-based or data-driven adversarial testing methodologies focusing on forcing safety-critical events. The safety performance of HAV is further characterized by analyzing the obtained testing outcomes with a particular selected measure, such as the observed collision risk. The aforementioned testing practices suffer from the scarcity of safety-critical events, have limited operational design domain (ODD) coverage, or are biased toward long-tail unsafe cases. This paper presents a novel and informative testing strategy that differs from these existing practices. The proposal is inspired by the intuition that a relatively safer HAV driving policy would allow the traffic vehicles to exhibit a higher level of aggressiveness to achieve a certain fixed level of an overall safe outcome. One can specifically characterize such a HAV and traffic interactive strategy and use it as a safety performance indicator for the HAV. Under the proposed testing scheme, the HAV is evaluated under its full ODD with a reward function that represents a trade-off between safety and adversity in generating safety-critical events. The proposed methodology is demonstrated in simulation with various HAV designs under different operational design domains. ",
    "url": "https://arxiv.org/abs/2402.01576",
    "authors": [
      "Minghao Zhu",
      "Anmol Sidhu",
      "Keith A. Redmill"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.01577",
    "title": "Deep Active Learning for Data Mining from Conflict Text Corpora",
    "abstract": "High-resolution event data on armed conflict and related processes have revolutionized the study of political contention with datasets like UCDP GED, ACLED etc. However, most of these datasets limit themselves to collecting spatio-temporal (high-resolution) and intensity data. Information on dynamics, such as targets, tactics, purposes etc. are rarely collected owing to the extreme workload of collecting data. However, most datasets rely on a rich corpus of textual data allowing further mining of further information connected to each event. This paper proposes one such approach that is inexpensive and high performance, leveraging active learning - an iterative process of improving a machine learning model based on sequential (guided) human input. Active learning is employed to then step-wise train (fine-tuning) of a large, encoder-only language model adapted for extracting sub-classes of events relating to conflict dynamics. The approach shows performance similar to human (gold-standard) coding while reducing the amount of required human annotation by as much as 99%. ",
    "url": "https://arxiv.org/abs/2402.01577",
    "authors": [
      "Mihai Croicu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01582",
    "title": "Automating Sound Change Prediction for Phylogenetic Inference: A  Tukanoan Case Study",
    "abstract": "We describe a set of new methods to partially automate linguistic phylogenetic inference given (1) cognate sets with their respective protoforms and sound laws, (2) a mapping from phones to their articulatory features and (3) a typological database of sound changes. We train a neural network on these sound change data to weight articulatory distances between phones and predict intermediate sound change steps between historical protoforms and their modern descendants, replacing a linguistic expert in part of a parsimony-based phylogenetic inference algorithm. In our best experiments on Tukanoan languages, this method produces trees with a Generalized Quartet Distance of 0.12 from a tree that used expert annotations, a significant improvement over other semi-automated baselines. We discuss potential benefits and drawbacks to our neural approach and parsimony-based tree prediction. We also experiment with a minimal generalization learner for automatic sound law induction, finding it comparably effective to sound laws from expert annotation. Our code is publicly available at https://github.com/cmu-llab/aiscp. ",
    "url": "https://arxiv.org/abs/2402.01582",
    "authors": [
      "Kalvin Chang",
      "Nathaniel R. Robinson",
      "Anna Cai",
      "Ting Chen",
      "Annie Zhang",
      "David R. Mortensen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.01614",
    "title": "L2G2G: a Scalable Local-to-Global Network Embedding with Graph  Autoencoders",
    "abstract": "For analysing real-world networks, graph representation learning is a popular tool. These methods, such as a graph autoencoder (GAE), typically rely on low-dimensional representations, also called embeddings, which are obtained through minimising a loss function; these embeddings are used with a decoder for downstream tasks such as node classification and edge prediction. While GAEs tend to be fairly accurate, they suffer from scalability issues. For improved speed, a Local2Global approach, which combines graph patch embeddings based on eigenvector synchronisation, was shown to be fast and achieve good accuracy. Here we propose L2G2G, a Local2Global method which improves GAE accuracy without sacrificing scalability. This improvement is achieved by dynamically synchronising the latent node representations, while training the GAEs. It also benefits from the decoder computing an only local patch loss. Hence, aligning the local embeddings in each epoch utilises more information from the graph than a single post-training alignment does, while maintaining scalability. We illustrate on synthetic benchmarks, as well as real-world examples, that L2G2G achieves higher accuracy than the standard Local2Global approach and scales efficiently on the larger data sets. We find that for large and dense networks, it even outperforms the slow, but assumed more accurate, GAEs. ",
    "url": "https://arxiv.org/abs/2402.01614",
    "authors": [
      "Ruikang Ouyang",
      "Andrew Elliott",
      "Stratis Limnios",
      "Mihai Cucuringu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01617",
    "title": "A GP-based Robust Motion Planning Framework for Agile Autonomous Robot  Navigation and Recovery in Unknown Environments",
    "abstract": "For autonomous mobile robots, uncertainties in the environment and system model can lead to failure in the motion planning pipeline, resulting in potential collisions. In order to achieve a high level of robust autonomy, these robots should be able to proactively predict and recover from such failures. To this end, we propose a Gaussian Process (GP) based model for proactively detecting the risk of future motion planning failure. When this risk exceeds a certain threshold, a recovery behavior is triggered that leverages the same GP model to find a safe state from which the robot may continue towards the goal. The proposed approach is trained in simulation only and can generalize to real world environments on different robotic platforms. Simulations and physical experiments demonstrate that our framework is capable of both predicting planner failures and recovering the robot to states where planner success is likely, all while producing agile motion. ",
    "url": "https://arxiv.org/abs/2402.01617",
    "authors": [
      "Nicholas Mohammad",
      "Jacob Higgins",
      "Nicola Bezzo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01620",
    "title": "MAGDi: Structured Distillation of Multi-Agent Interaction Graphs  Improves Reasoning in Smaller Language Models",
    "abstract": "Multi-agent interactions between Large Language Model (LLM) agents have shown major improvements on diverse reasoning tasks. However, these involve long generations from multiple models across several rounds, making them expensive. Moreover, these multi-agent approaches fail to provide a final, single model for efficient inference. To address this, we introduce MAGDi, a new method for structured distillation of the reasoning interactions between multiple LLMs into smaller LMs. MAGDi teaches smaller models by representing multi-agent interactions as graphs, augmenting a base student model with a graph encoder, and distilling knowledge using three objective functions: next-token prediction, a contrastive loss between correct and incorrect reasoning, and a graph-based objective to model the interaction structure. Experiments on seven widely-used commonsense and math reasoning benchmarks show that MAGDi improves the reasoning capabilities of smaller models, outperforming several methods that distill from a single teacher and multiple teachers. Moreover, MAGDi also demonstrates an order of magnitude higher efficiency over its teachers. We conduct extensive analyses to show that MAGDi (1) enhances the generalizability to out-of-domain tasks, (2) scales positively with the size and strength of the base student model, and (3) obtains larger improvements (via our multi-teacher training) when applying self-consistency - an inference technique that relies on model diversity. ",
    "url": "https://arxiv.org/abs/2402.01620",
    "authors": [
      "Justin Chih-Yao Chen",
      "Swarnadeep Saha",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.00949",
    "title": "Geometry of Polynomial Neural Networks",
    "abstract": "We study the expressivity and learning process for polynomial neural networks (PNNs) with monomial activation functions. The weights of the network parametrize the neuromanifold. In this paper, we study certain neuromanifolds using tools from algebraic geometry: we give explicit descriptions as semialgebraic sets and characterize their Zariski closures, called neurovarieties. We study their dimension and associate an algebraic degree, the learning degree, to the neurovariety. The dimension serves as a geometric measure for the expressivity of the network, the learning degree is a measure for the complexity of training the network and provides upper bounds on the number of learnable functions. These theoretical results are accompanied with experiments. ",
    "url": "https://arxiv.org/abs/2402.00949",
    "authors": [
      "Kaie Kubjas",
      "Jiayi Li",
      "Maximilian Wiesmann"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.01092",
    "title": "A Dynamical Model of Neural Scaling Laws",
    "abstract": "On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-width dynamics at a rate $1/\\textit{width}$ but at late time exhibit a rate $\\textit{width}^{-c}$, where $c$ depends on the structure of the architecture and task. We show that our model exhibits this behavior. Lastly, our theory shows how the gap between training and test loss can gradually build up over time due to repeated reuse of data. ",
    "url": "https://arxiv.org/abs/2402.01092",
    "authors": [
      "Blake Bordelon",
      "Alexander Atanasov",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01138",
    "title": "Graph Neural Networks in EEG-based Emotion Recognition: A Survey",
    "abstract": "Compared to other modalities, EEG-based emotion recognition can intuitively respond to the emotional patterns in the human brain and, therefore, has become one of the most concerning tasks in the brain-computer interfaces field. Since dependencies within brain regions are closely related to emotion, a significant trend is to develop Graph Neural Networks (GNNs) for EEG-based emotion recognition. However, brain region dependencies in emotional EEG have physiological bases that distinguish GNNs in this field from those in other time series fields. Besides, there is neither a comprehensive review nor guidance for constructing GNNs in EEG-based emotion recognition. In the survey, our categorization reveals the commonalities and differences of existing approaches under a unified framework of graph construction. We analyze and categorize methods from three stages in the framework to provide clear guidance on constructing GNNs in EEG-based emotion recognition. In addition, we discuss several open challenges and future directions, such as Temporal full-connected graph and Graph condensation. ",
    "url": "https://arxiv.org/abs/2402.01138",
    "authors": [
      "Chenyu Liu",
      "Xinliang Zhou",
      "Yihao Wu",
      "Ruizhi Yang",
      "Liming Zhai",
      "Ziyu Jia",
      "Yang Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.01139",
    "title": "Online conformal prediction with decaying step sizes",
    "abstract": "We introduce a method for online conformal prediction with decaying step sizes. Like previous methods, ours possesses a retrospective guarantee of coverage for arbitrary sequences. However, unlike previous methods, we can simultaneously estimate a population quantile when it exists. Our theory and experiments indicate substantially improved practical properties: in particular, when the distribution is stable, the coverage is close to the desired level for every time point, not just on average over the observed sequence. ",
    "url": "https://arxiv.org/abs/2402.01139",
    "authors": [
      "Anastasios N. Angelopoulos",
      "Rina Foygel Barber",
      "Stephen Bates"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.01271",
    "title": "An Intra-BRNN and GB-RVQ Based END-TO-END Neural Audio Codec",
    "abstract": "Recently, neural networks have proven to be effective in performing speech coding task at low bitrates. However, under-utilization of intra-frame correlations and the error of quantizer specifically degrade the reconstructed audio quality. To improve the coding quality, we present an end-to-end neural speech codec, namely CBRC (Convolutional and Bidirectional Recurrent neural Codec). An interleaved structure using 1D-CNN and Intra-BRNN is designed to exploit the intra-frame correlations more efficiently. Furthermore, Group-wise and Beam-search Residual Vector Quantizer (GB-RVQ) is used to reduce the quantization noise. CBRC encodes audio every 20ms with no additional latency, which is suitable for real-time communication. Experimental results demonstrate the superiority of the proposed codec when comparing CBRC at 3kbps with Opus at 12kbps. ",
    "url": "https://arxiv.org/abs/2402.01271",
    "authors": [
      "Linping Xu",
      "Jiawei Jiang",
      "Dejun Zhang",
      "Xianjun Xia",
      "Li Chen",
      "Yijian Xiao",
      "Piao Ding",
      "Shenyi Song",
      "Sixing Yin",
      "Ferdous Sohel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2402.01338",
    "title": "Inferring the Langevin Equation with Uncertainty via Bayesian Neural  Networks",
    "abstract": "Pervasive across diverse domains, stochastic systems exhibit fluctuations in processes ranging from molecular dynamics to climate phenomena. The Langevin equation has served as a common mathematical model for studying such systems, enabling predictions of their temporal evolution and analyses of thermodynamic quantities, including absorbed heat, work done on the system, and entropy production. However, inferring the Langevin equation from observed trajectories remains challenging, particularly for nonlinear and high-dimensional systems. In this study, we present a comprehensive framework that employs Bayesian neural networks for inferring Langevin equations in both overdamped and underdamped regimes. Our framework first provides the drift force and diffusion matrix separately and then combines them to construct the Langevin equation. By providing a distribution of predictions instead of a single value, our approach allows us to assess prediction uncertainties, which can prevent potential misunderstandings and erroneous decisions about the system. We demonstrate the effectiveness of our framework in inferring Langevin equations for various scenarios including a neuron model and microscopic engine, highlighting its versatility and potential impact. ",
    "url": "https://arxiv.org/abs/2402.01338",
    "authors": [
      "Youngkyoung Bae",
      "Seungwoong Ha",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2402.01445",
    "title": "All graph state verification protocols are composably secure",
    "abstract": "Graph state verification protocols allow multiple parties to share a graph state while checking that the state is honestly prepared, even in the presence of malicious parties. Since graph states are the starting point of numerous quantum protocols, it is crucial to ensure that graph state verification protocols can safely be composed with other protocols, this property being known as composable security. Previous works [YDK21] conjectured that such a property could not be proven within the abstract cryptography framework: we disprove this conjecture by showing that all graph state verification protocols can be turned into a composably secure protocol with respect to the natural functionality for graph state preparation. Moreover, we show that any unchanged graph state verification protocols can also be considered as composably secure for a slightly different, yet useful, functionality. Finally, we show that these two results are optimal, in the sense that any such generic result, considering arbitrary black-box protocols, must either modify the protocol or consider a different functionality. Along the way, we show a protocol to generalize entanglement swapping to arbitrary graph states that might be of independent interest. ",
    "url": "https://arxiv.org/abs/2402.01445",
    "authors": [
      "L\u00e9o Colisson",
      "Damian Markham",
      "Raja Yehia"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.01542",
    "title": "Learning Collective Variables for Protein Folding with Labeled Data  Augmentation through Geodesic Interpolation",
    "abstract": "In molecular dynamics (MD) simulations, rare events, such as protein folding, are typically studied by means of enhanced sampling techniques, most of which rely on the definition of a collective variable (CV) along which the acceleration occurs. Obtaining an expressive CV is crucial, but often hindered by the lack of information about the particular event, e.g., the transition from unfolded to folded conformation. We propose a simulation-free data augmentation strategy using physics-inspired metrics to generate geodesic interpolations resembling protein folding transitions, thereby improving sampling efficiency without true transition state samples. Leveraging interpolation progress parameters, we introduce a regression-based learning scheme for CV models, which outperforms classifier-based methods when transition state data is limited and noisy ",
    "url": "https://arxiv.org/abs/2402.01542",
    "authors": [
      "Soojung Yang",
      "Juno Nam",
      "Johannes C. B. Dietschreit",
      "Rafael G\u00f3mez-Bombarelli"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2402.01585",
    "title": "Market proliferation and the impact of locational complexity on network  restructuring",
    "abstract": "This manuscript investigates the problem of locational complexity, a type of complexity that emanates from a companys territorial strategy. Using an entropy-based measure for supply chain structural complexity ( pars-complexity), we develop a theoretical framework for analysing the effects of locational complexity on the profitability of service/manufacturing networks. The proposed model is used to shed light on the reasons why network restructuring strategies may result ineffective at reducing complexity-related costs. Our contribution is three-fold. First, we develop a novel mathematical formulation of a facility location problem that integrates the pars-complexity measure in the decision process. Second, using this model, we propose a decomposition of the penalties imposed by locational complexity into (a) an intrinsic cost of structural complexity; and (b) an avoidable cost of ignoring such complexity in the decision process. Such a decomposition is a valuable tool for identifying more effective measures for tackling locational complexity, moreover, it has allowed us to provide an explanation to the so-called addiction to growth within the locational context. Finally, we propose three alternative strategies that attempt to mimic different approaches used in practice by companies that have engaged in network restructuring processes. The impact of those approaches is evaluated through extensive numerical experiments. Our experimental results suggest that network restructuring efforts that are not accompanied by a substantial reduction on the target market of the company, fail at reducing complexity-related costs and, therefore, have a limited impact on the companys profitability. ",
    "url": "https://arxiv.org/abs/2402.01585",
    "authors": [
      "J.M. Pinar-P\u00e9rez",
      "D. Ruiz-Hern\u00e1ndez",
      "M.B.C. Menezes"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.01596",
    "title": "Immersive Video Compression using Implicit Neural Representations",
    "abstract": "Recent work on implicit neural representations (INRs) has evidenced their potential for efficiently representing and encoding conventional video content. In this paper we, for the first time, extend their application to immersive (multi-view) videos, by proposing MV-HiNeRV, a new INR-based immersive video codec. MV-HiNeRV is an enhanced version of a state-of-the-art INR-based video codec, HiNeRV, which was developed for single-view video compression. We have modified the model to learn a different group of feature grids for each view, and share the learnt network parameters among all views. This enables the model to effectively exploit the spatio-temporal and the inter-view redundancy that exists within multi-view videos. The proposed codec was used to compress multi-view texture and depth video sequences in the MPEG Immersive Video (MIV) Common Test Conditions, and tested against the MIV Test model (TMIV) that uses the VVenC video codec. The results demonstrate the superior performance of MV-HiNeRV, with significant coding gains (up to 72.33%) over TMIV. The implementation of MV-HiNeRV will be published for further development and evaluation. ",
    "url": "https://arxiv.org/abs/2402.01596",
    "authors": [
      "Ho Man Kwan",
      "Fan Zhang",
      "Andrew Gower",
      "David Bull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.03158",
    "title": "Simple Imputation Rules for Prediction with Missing Data: Contrasting  Theoretical Guarantees with Empirical Performance",
    "abstract": " Title: Simple Imputation Rules for Prediction with Missing Data: Contrasting  Theoretical Guarantees with Empirical Performance ",
    "url": "https://arxiv.org/abs/2104.03158",
    "authors": [
      "Dimitris Bertsimas",
      "Arthur Delarue",
      "Jean Pauphilet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.14003",
    "title": "Connected greedy colourings of perfect graphs and other classes: the  good, the bad and the ugly",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2110.14003",
    "authors": [
      "Laurent Beaudou",
      "Caroline Brosse",
      "Oscar Defrain",
      "Florent Foucaud",
      "Aur\u00e9lie Lagoutte",
      "Vincent Limouzy",
      "Lucas Pastor"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.02997",
    "title": "TadML: A fast temporal action detection with Mechanics-MLP",
    "abstract": " Comments: 8 pages,3 figures ",
    "url": "https://arxiv.org/abs/2206.02997",
    "authors": [
      "Bowen Deng",
      "Dongchang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06854",
    "title": "On the explainable properties of 1-Lipschitz Neural Networks: An Optimal  Transport Perspective",
    "abstract": " Title: On the explainable properties of 1-Lipschitz Neural Networks: An Optimal  Transport Perspective ",
    "url": "https://arxiv.org/abs/2206.06854",
    "authors": [
      "Mathieu Serrurier",
      "Franck Mamalet",
      "Thomas Fel",
      "Louis B\u00e9thune",
      "Thibaut Boissin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.11004",
    "title": "Auto-Encoding Adversarial Imitation Learning",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2206.11004",
    "authors": [
      "Kaifeng Zhang",
      "Rui Zhao",
      "Ziming Zhang",
      "Yang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05317",
    "title": "CPO: Change Robust Panorama to Point Cloud Localization",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.05317",
    "authors": [
      "Junho Kim",
      "Hojun Jang",
      "Changwoon Choi",
      "Young Min Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11049",
    "title": "How Does a Deep Learning Model Architecture Impact Its Privacy? A  Comprehensive Study of Privacy Attacks on CNNs and Transformers",
    "abstract": " Comments: To appear in USENIX Security 2024 ",
    "url": "https://arxiv.org/abs/2210.11049",
    "authors": [
      "Guangsheng Zhang",
      "Bo Liu",
      "Huan Tian",
      "Tianqing Zhu",
      "Ming Ding",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.00133",
    "title": "Generative Adversarial Learning of Sinkhorn Algorithm Initializations",
    "abstract": " Comments: 15 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2212.00133",
    "authors": [
      "Jonathan Geuter",
      "Vaios Laschos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.01580",
    "title": "Untargeted Near-collision Attacks on Biometrics: Real-world Bounds and  Theoretical Limits",
    "abstract": " Comments: Addition of results ",
    "url": "https://arxiv.org/abs/2304.01580",
    "authors": [
      "Axel Durbet",
      "Paul-Marie Grollemund",
      "Kevin Thiry-Atighehchi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.07193",
    "title": "DINOv2: Learning Robust Visual Features without Supervision",
    "abstract": " Title: DINOv2: Learning Robust Visual Features without Supervision ",
    "url": "https://arxiv.org/abs/2304.07193",
    "authors": [
      "Maxime Oquab",
      "Timoth\u00e9e Darcet",
      "Th\u00e9o Moutakanni",
      "Huy Vo",
      "Marc Szafraniec",
      "Vasil Khalidov",
      "Pierre Fernandez",
      "Daniel Haziza",
      "Francisco Massa",
      "Alaaeldin El-Nouby",
      "Mahmoud Assran",
      "Nicolas Ballas",
      "Wojciech Galuba",
      "Russell Howes",
      "Po-Yao Huang",
      "Shang-Wen Li",
      "Ishan Misra",
      "Michael Rabbat",
      "Vasu Sharma",
      "Gabriel Synnaeve",
      "Hu Xu",
      "Herv\u00e9 Jegou",
      "Julien Mairal",
      "Patrick Labatut",
      "Armand Joulin",
      "Piotr Bojanowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.00309",
    "title": "Patent Mining by Extracting Functional Analysis Information Modelled As  Graph Structure: A Patent Knowledge-base Collaborative Building Approach",
    "abstract": " Comments: 20 pages, 8 figures, to be submitted later for peer review ",
    "url": "https://arxiv.org/abs/2305.00309",
    "authors": [
      "Manal E. Helal",
      "Mohammed E. Helal"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2305.17026",
    "title": "How Powerful are Decoder-Only Transformer Neural Models?",
    "abstract": " Title: How Powerful are Decoder-Only Transformer Neural Models? ",
    "url": "https://arxiv.org/abs/2305.17026",
    "authors": [
      "Jesse Roberts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19241",
    "title": "Accountable authentication with privacy protection: The Larch system for  universal login",
    "abstract": " Comments: This is an extended version of a paper appearing at OSDI 2023 ",
    "url": "https://arxiv.org/abs/2305.19241",
    "authors": [
      "Emma Dauterman",
      "Danny Lin",
      "Henry Corrigan-Gibbs",
      "David Mazi\u00e8res"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.09896",
    "title": "Is Self-Repair a Silver Bullet for Code Generation?",
    "abstract": " Comments: Accepted to ICLR 2024. Added additional Code Llama experiments and fixed a data processing error harming Code Llama's reported self-repair performance on HumanEval ",
    "url": "https://arxiv.org/abs/2306.09896",
    "authors": [
      "Theo X. Olausson",
      "Jeevana Priya Inala",
      "Chenglong Wang",
      "Jianfeng Gao",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.11313",
    "title": "Deep graph kernel point processes",
    "abstract": " Title: Deep graph kernel point processes ",
    "url": "https://arxiv.org/abs/2306.11313",
    "authors": [
      "Zheng Dong",
      "Matthew Repasky",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.06571",
    "title": "Unpacking polarization: Antagonism and Alignment in Signed Networks of  Online Interaction",
    "abstract": " Title: Unpacking polarization: Antagonism and Alignment in Signed Networks of  Online Interaction ",
    "url": "https://arxiv.org/abs/2307.06571",
    "authors": [
      "Emma Fraxanet",
      "Max Pellert",
      "Simon Schweighofer",
      "Vicen\u00e7 G\u00f3mez",
      "David Garcia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2307.07854",
    "title": "AdvFusion: Multilingual Adapter-based Knowledge Transfer for Code  Summarization",
    "abstract": " Comments: under submission ",
    "url": "https://arxiv.org/abs/2307.07854",
    "authors": [
      "Iman Saberi",
      "Fatemeh Fard",
      "Fuxiang Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.08143",
    "title": "IIANet: An Intra- and Inter-Modality Attention Network for Audio-Visual  Speech Separation",
    "abstract": " Comments: 18 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2308.08143",
    "authors": [
      "Kai Li",
      "Runxuan Yang",
      "Fuchun Sun",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.08480",
    "title": "Label Propagation Techniques for Artifact Detection in Imbalanced  Classes using Photoplethysmogram Signals",
    "abstract": " Comments: Under preparation to submit to IEEE for possible publications ",
    "url": "https://arxiv.org/abs/2308.08480",
    "authors": [
      "Clara Macabiau",
      "Thanh-Dung Le",
      "Kevin Albert",
      "Mana Shahriari",
      "Philippe Jouvet",
      "Rita Noumeir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.04836",
    "title": "Neural Semantic Surface Maps",
    "abstract": " Title: Neural Semantic Surface Maps ",
    "url": "https://arxiv.org/abs/2309.04836",
    "authors": [
      "Luca Morreale",
      "Noam Aigerman",
      "Vladimir G. Kim",
      "Niloy J. Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2309.05388",
    "title": "Robust Single Rotation Averaging Revisited",
    "abstract": " Comments: Added the url to the code (this https URL) ",
    "url": "https://arxiv.org/abs/2309.05388",
    "authors": [
      "Seong Hun Lee",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.06030",
    "title": "Federated Learning for Large-Scale Scene Modeling with Neural Radiance  Fields",
    "abstract": " Title: Federated Learning for Large-Scale Scene Modeling with Neural Radiance  Fields ",
    "url": "https://arxiv.org/abs/2309.06030",
    "authors": [
      "Teppei Suzuki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15687",
    "title": "Breaking On-Chip Communication Anonymity using Flow Correlation Attacks",
    "abstract": " Title: Breaking On-Chip Communication Anonymity using Flow Correlation Attacks ",
    "url": "https://arxiv.org/abs/2309.15687",
    "authors": [
      "Hansika Weerasena",
      "Prabhat Mishra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02258",
    "title": "A Neural Scaling Law from Lottery Ticket Ensembling",
    "abstract": " Comments: 14 pages, 13 figures. Note from authors: the theory in this paper is questionable; we are trying our best to fix it. Empirical results still stand ",
    "url": "https://arxiv.org/abs/2310.02258",
    "authors": [
      "Ziming Liu",
      "Max Tegmark"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.04584",
    "title": "An Algorithm to Train Unrestricted Sequential Discrete Morphological  Neural Networks",
    "abstract": " Title: An Algorithm to Train Unrestricted Sequential Discrete Morphological  Neural Networks ",
    "url": "https://arxiv.org/abs/2310.04584",
    "authors": [
      "Diego Marcondes",
      "Mariana Feldman",
      "Junior Barrera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05495",
    "title": "On the Convergence of Federated Averaging under Partial Participation  for Over-parameterized Neural Networks",
    "abstract": " Title: On the Convergence of Federated Averaging under Partial Participation  for Over-parameterized Neural Networks ",
    "url": "https://arxiv.org/abs/2310.05495",
    "authors": [
      "Xin Liu",
      "Wei li",
      "Dazhi Zhan",
      "Yu Pan",
      "Xin Ma",
      "Yu Ding",
      "Zhisong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18449",
    "title": "Conditional Generative Representation for Black-Box Optimization with  Implicit Constraints",
    "abstract": " Title: Conditional Generative Representation for Black-Box Optimization with  Implicit Constraints ",
    "url": "https://arxiv.org/abs/2310.18449",
    "authors": [
      "Wenqian Xing",
      "Jungho Lee",
      "Chong Liu",
      "Shixiang Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.02535",
    "title": "TokenMotion: Motion-Guided Vision Transformer for Video Camouflaged  Object Detection Via Learnable Token Selection",
    "abstract": " Comments: Revising Needed ",
    "url": "https://arxiv.org/abs/2311.02535",
    "authors": [
      "Zifan Yu",
      "Erfan Bank Tavakoli",
      "Meida Chen",
      "Suya You",
      "Raghuveer Rao",
      "Sanjeev Agarwal",
      "Fengbo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.06597",
    "title": "Understanding Grokking Through A Robustness Viewpoint",
    "abstract": " Title: Understanding Grokking Through A Robustness Viewpoint ",
    "url": "https://arxiv.org/abs/2311.06597",
    "authors": [
      "Zhiquan Tan",
      "Weiran Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07965",
    "title": "DQR-TTS: Semi-supervised Text-to-speech Synthesis with Dynamic Quantized  Representation",
    "abstract": " Comments: Accepted by the 13th IEEE International Conference on Big Data and Cloud Computing (IEEE BDCloud 2023) ",
    "url": "https://arxiv.org/abs/2311.07965",
    "authors": [
      "Jianzong Wang",
      "Pengcheng Li",
      "Xulong Zhang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.13870",
    "title": "Multi-intention Inverse Q-learning for Interpretable Behavior  Representation",
    "abstract": " Title: Multi-intention Inverse Q-learning for Interpretable Behavior  Representation ",
    "url": "https://arxiv.org/abs/2311.13870",
    "authors": [
      "Hao Zhu",
      "Brice De La Crompe",
      "Gabriel Kalweit",
      "Artur Schneider",
      "Maria Kalweit",
      "Ilka Diester",
      "Joschka Boedecker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2311.14506",
    "title": "Multi-Class Anomaly Detection based on Regularized Discriminative  Coupled hypersphere-based Feature Adaptation",
    "abstract": " Comments: 14 pages, 6 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2311.14506",
    "authors": [
      "Mehdi Rafiei",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.15679",
    "title": "Model-agnostic Body Part Relevance Assessment for Pedestrian Detection",
    "abstract": " Title: Model-agnostic Body Part Relevance Assessment for Pedestrian Detection ",
    "url": "https://arxiv.org/abs/2311.15679",
    "authors": [
      "Maurice G\u00fcnder",
      "Sneha Banerjee",
      "Rafet Sifa",
      "Christian Bauckhage"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17929",
    "title": "New Online Communities: Graph Deep Learning on Anonymous Voting Networks  to Identify Sybils in Polycentric Governance",
    "abstract": " Title: New Online Communities: Graph Deep Learning on Anonymous Voting Networks  to Identify Sybils in Polycentric Governance ",
    "url": "https://arxiv.org/abs/2311.17929",
    "authors": [
      "Quinn DuPont"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.17936",
    "title": "Diagnostics Using Nuclear Plant Cyber Attack Analysis Toolkit",
    "abstract": " Comments: Paper has been submitted to ANS for review ",
    "url": "https://arxiv.org/abs/2311.17936",
    "authors": [
      "Japan K. Patel",
      "Athi Varuttamaseni",
      "Robert W. Youngblood III",
      "John C. Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.05356",
    "title": "Neuron Patching: Neuron-level Model Editing on Code Generation and LLMs",
    "abstract": " Comments: 12 pages, 5 figures, 6 tables, under peer review ",
    "url": "https://arxiv.org/abs/2312.05356",
    "authors": [
      "Jian Gu",
      "Chunyang Chen",
      "Aldeida Aleti"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.09901",
    "title": "Temporally and Distributionally Robust Optimization for Cold-Start  Recommendation",
    "abstract": " Comments: Accepted by AAAI'24 ",
    "url": "https://arxiv.org/abs/2312.09901",
    "authors": [
      "Xinyu Lin",
      "Wenjie Wang",
      "Jujia Zhao",
      "Yongqi Li",
      "Fuli Feng",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.13884",
    "title": "Measures of Resilience to Cyber Contagion -- An Axiomatic Approach for  Complex Systems",
    "abstract": " Title: Measures of Resilience to Cyber Contagion -- An Axiomatic Approach for  Complex Systems ",
    "url": "https://arxiv.org/abs/2312.13884",
    "authors": [
      "Gregor Svindland",
      "Alexander Vo\u00df"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.07261",
    "title": "LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts",
    "abstract": " Comments: 14 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2401.07261",
    "authors": [
      "Shoupeng Ren",
      "Tianyu Tu",
      "Jian Liu",
      "Di Wu",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.09714",
    "title": "Robust virtual element methods for coupled stress-assisted diffusion  problems",
    "abstract": " Title: Robust virtual element methods for coupled stress-assisted diffusion  problems ",
    "url": "https://arxiv.org/abs/2401.09714",
    "authors": [
      "Rekha Khot",
      "Andres E. Rubiano",
      "Ricardo Ruiz-Baier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2401.11317",
    "title": "Third-Party Developers and Tool Development For Community Management on  Live Streaming Platform Twitch",
    "abstract": " Comments: Accepted by ACM CHI 2024 ",
    "url": "https://arxiv.org/abs/2401.11317",
    "authors": [
      "Jie Cai",
      "Ya-Fang Lin",
      "He Zhang",
      "John M. Carroll"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.13239",
    "title": "Adaptive Crowdsourcing Via Self-Supervised Learning",
    "abstract": " Comments: 33 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2401.13239",
    "authors": [
      "Anmol Kagrecha",
      "Henrik Marklund",
      "Benjamin Van Roy",
      "Hong Jun Jeon",
      "Richard Zeckhauser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2401.15459",
    "title": "Large Language Model as Synthesizer: Fusing Diverse Inputs for Better  Automatic Vulnerability Repair",
    "abstract": " Comments: Accepted in the ICSE 2024 Research Track with a slightly different title \"Out of Sight, Out of Mind: Better Automatic Vulnerability Repair by Broadening Input Ranges and Sources\" ",
    "url": "https://arxiv.org/abs/2401.15459",
    "authors": [
      "Xin Zhou",
      "Kisub Kim",
      "Bowen Xu",
      "DongGyun Han",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.15963",
    "title": "NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional  Correctness",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2401.15963",
    "authors": [
      "Manav Singhal",
      "Tushar Aggarwal",
      "Abhijeet Awasthi",
      "Nagarajan Natarajan",
      "Aditya Kanade"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.16775",
    "title": "Activity Detection for Massive Connectivity in Cell-free Networks with  Unknown Large-scale Fading, Channel Statistics, Noise Variance, and Activity  Probability: A Bayesian Approach",
    "abstract": " Comments: 16 pages, 9 figures, accepted for publication in IEEE Transactions on Signal Processing ",
    "url": "https://arxiv.org/abs/2401.16775",
    "authors": [
      "Hao Zhang",
      "Qingfeng Lin",
      "Yang Li",
      "Lei Cheng",
      "Yik-Chung Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.16942",
    "title": "Robust Price Discrimination",
    "abstract": " Title: Robust Price Discrimination ",
    "url": "https://arxiv.org/abs/2401.16942",
    "authors": [
      "Itai Arieli",
      "Yakov Babichenko",
      "Omer Madmon",
      "Moshe Tennenholtz"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2401.17233",
    "title": "Inf-Sup neural networks for high-dimensional elliptic PDE problems",
    "abstract": " Title: Inf-Sup neural networks for high-dimensional elliptic PDE problems ",
    "url": "https://arxiv.org/abs/2401.17233",
    "authors": [
      "Xiaokai Huo",
      "Hailiang Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2401.17270",
    "title": "YOLO-World: Real-Time Open-Vocabulary Object Detection",
    "abstract": " Comments: Work still in progress. Code & models are available at: this https URL ",
    "url": "https://arxiv.org/abs/2401.17270",
    "authors": [
      "Tianheng Cheng",
      "Lin Song",
      "Yixiao Ge",
      "Wenyu Liu",
      "Xinggang Wang",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.17435",
    "title": "Can Large Language Models Replace Economic Choice Prediction Labs?",
    "abstract": " Title: Can Large Language Models Replace Economic Choice Prediction Labs? ",
    "url": "https://arxiv.org/abs/2401.17435",
    "authors": [
      "Eilam Shapira",
      "Omer Madmon",
      "Roi Reichart",
      "Moshe Tennenholtz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Science and Game Theory (cs.GT)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2401.17615",
    "title": "Graph Multi-Similarity Learning for Molecular Property Prediction",
    "abstract": " Title: Graph Multi-Similarity Learning for Molecular Property Prediction ",
    "url": "https://arxiv.org/abs/2401.17615",
    "authors": [
      "Hao Xu",
      "Zhengyang Zhou",
      "Pengyu Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2401.17663",
    "title": "Social Robot Navigation with Adaptive Proxemics Based on Emotions",
    "abstract": " Comments: 5 pages, 3 figures, Proceeding of Towards Socially Intelligent Robots In Real World Applications: Challenges And Intricacies (SIRRW) Workshop, RO-MAN 2022, 3-7, August 2022, Naples, Italy ",
    "url": "https://arxiv.org/abs/2401.17663",
    "authors": [
      "Baris Bilen",
      "Hasan Kivrak",
      "Pinar Uluer",
      "Hatice Kose"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.00306",
    "title": "An Accurate and Low-Parameter Machine Learning Architecture for Next  Location Prediction",
    "abstract": " Comments: Paper was accepted and presented in person at the 2023 IEEE Future Networks World Forum, in Baltimore, Maryland, USA ",
    "url": "https://arxiv.org/abs/2402.00306",
    "authors": [
      "Calvin Jary",
      "Nafiseh Kahani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.00449",
    "title": "Efficient Training Spiking Neural Networks with Parallel Spiking Unit",
    "abstract": " Title: Efficient Training Spiking Neural Networks with Parallel Spiking Unit ",
    "url": "https://arxiv.org/abs/2402.00449",
    "authors": [
      "Yang Li",
      "Yinqian Sun",
      "Xiang He",
      "Yiting Dong",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  }
]