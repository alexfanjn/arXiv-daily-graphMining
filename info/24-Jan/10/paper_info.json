[
  {
    "id": "arXiv:2401.04133",
    "title": "SynHIN: Generating Synthetic Heterogeneous Information Network for  Explainable AI",
    "abstract": "Graph Neural Networks (GNNs) excel in various domains, from detecting e-commerce spam to social network classification problems. However, the lack of public graph datasets hampers research progress, particularly in heterogeneous information networks (HIN). The demand for datasets for fair HIN comparisons is growing due to advancements in GNN interpretation models. In response, we propose SynHIN, a unique method for generating synthetic heterogeneous information networks. SynHIN identifies motifs in real-world datasets, summarizes graph statistics, and constructs a synthetic network. Our approach utilizes In-Cluster and Out-Cluster Merge modules to build the synthetic HIN from primary motif clusters. After In/Our-Cluster mergers and a post-pruning process fitting the real dataset constraints, we ensure the synthetic graph statistics align closely with the reference one. SynHIN generates a synthetic heterogeneous graph dataset for node classification tasks, using the primary motif as the explanation ground truth. It can adapt and address the lack of heterogeneous graph datasets and motif ground truths, proving beneficial for assessing heterogeneous graph neural network explainers. We further present a benchmark dataset for future heterogeneous graph explainer model research. Our work marks a significant step towards explainable AI in HGNNs. ",
    "url": "https://arxiv.org/abs/2401.04133",
    "authors": [
      "Ming-Yi Hong",
      "Yi-Hsiang Huang",
      "You-Chen Teng",
      "Chih-Yu Wang",
      "Che Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.04134",
    "title": "Web Neural Network with Complete DiGraphs",
    "abstract": "This paper introduces a new neural network model that aims to mimic the biological brain more closely by structuring the network as a complete directed graph that processes continuous data for each timestep. Current neural networks have structures that vaguely mimic the brain structure, such as neurons, convolutions, and recurrence. The model proposed in this paper adds additional structural properties by introducing cycles into the neuron connections and removing the sequential nature commonly seen in other network layers. Furthermore, the model has continuous input and output, inspired by spiking neural networks, which allows the network to learn a process of classification, rather than simply returning the final result. ",
    "url": "https://arxiv.org/abs/2401.04134",
    "authors": [
      "Frank Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04135",
    "title": "Global-Aware Enhanced Spatial-Temporal Graph Recurrent Networks: A New  Framework For Traffic Flow Prediction",
    "abstract": "Traffic flow prediction plays a crucial role in alleviating traffic congestion and enhancing transport efficiency. While combining graph convolution networks with recurrent neural networks for spatial-temporal modeling is a common strategy in this realm, the restricted structure of recurrent neural networks limits their ability to capture global information. For spatial modeling, many prior studies learn a graph structure that is assumed to be fixed and uniform at all time steps, which may not be true. This paper introduces a novel traffic prediction framework, Global-Aware Enhanced Spatial-Temporal Graph Recurrent Network (GA-STGRN), comprising two core components: a spatial-temporal graph recurrent neural network and a global awareness layer. Within this framework, three innovative prediction models are formulated. A sequence-aware graph neural network is proposed and integrated into the Gated Recurrent Unit (GRU) to learn non-fixed graphs at different time steps and capture local temporal relationships. To enhance the model's global perception, three distinct global spatial-temporal transformer-like architectures (GST^2) are devised for the global awareness layer. We conduct extensive experiments on four real traffic datasets and the results demonstrate the superiority of our framework and the three concrete models. ",
    "url": "https://arxiv.org/abs/2401.04135",
    "authors": [
      "Haiyang Liu",
      "Chunjiang Zhu",
      "Detian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04136",
    "title": "The Stronger the Diffusion Model, the Easier the Backdoor: Data  Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline",
    "abstract": "The commercialization of diffusion models, renowned for their ability to generate high-quality images that are often indistinguishable from real ones, brings forth potential copyright concerns. Although attempts have been made to impede unauthorized access to copyrighted material during training and to subsequently prevent DMs from generating copyrighted images, the effectiveness of these solutions remains unverified. This study explores the vulnerabilities associated with copyright protection in DMs by introducing a backdoor data poisoning attack (SilentBadDiffusion) against text-to-image diffusion models. Our attack method operates without requiring access to or control over the diffusion model's training or fine-tuning processes; it merely involves the insertion of poisoning data into the clean training dataset. This data, comprising poisoning images equipped with prompts, is generated by leveraging the powerful capabilities of multimodal large language models and text-guided image inpainting techniques. Our experimental results and analysis confirm the method's effectiveness. By integrating a minor portion of non-copyright-infringing stealthy poisoning data into the clean dataset-rendering it free from suspicion-we can prompt the finetuned diffusion models to produce copyrighted content when activated by specific trigger prompts. These findings underline potential pitfalls in the prevailing copyright protection strategies and underscore the necessity for increased scrutiny and preventative measures against the misuse of DMs. ",
    "url": "https://arxiv.org/abs/2401.04136",
    "authors": [
      "Haonan Wang",
      "Qianli Shen",
      "Yao Tong",
      "Yang Zhang",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04144",
    "title": "Robust Calibration For Improved Weather Prediction Under Distributional  Shift",
    "abstract": "In this paper, we present results on improving out-of-domain weather prediction and uncertainty estimation as part of the \\texttt{Shifts Challenge on Robustness and Uncertainty under Real-World Distributional Shift} challenge. We find that by leveraging a mixture of experts in conjunction with an advanced data augmentation technique borrowed from the computer vision domain, in conjunction with robust \\textit{post-hoc} calibration of predictive uncertainties, we can potentially achieve more accurate and better-calibrated results with deep neural networks than with boosted tree models for tabular data. We quantify our predictions using several metrics and propose several future lines of inquiry and experimentation to boost performance. ",
    "url": "https://arxiv.org/abs/2401.04144",
    "authors": [
      "Sankalp Gilda",
      "Neel Bhandari",
      "Wendy Mak",
      "Andrea Panizza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04152",
    "title": "Cross-Speaker Encoding Network for Multi-Talker Speech Recognition",
    "abstract": "End-to-end multi-talker speech recognition has garnered great interest as an effective approach to directly transcribe overlapped speech from multiple speakers. Current methods typically adopt either 1) single-input multiple-output (SIMO) models with a branched encoder, or 2) single-input single-output (SISO) models based on attention-based encoder-decoder architecture with serialized output training (SOT). In this work, we propose a Cross-Speaker Encoding (CSE) network to address the limitations of SIMO models by aggregating cross-speaker representations. Furthermore, the CSE model is integrated with SOT to leverage both the advantages of SIMO and SISO while mitigating their drawbacks. To the best of our knowledge, this work represents an early effort to integrate SIMO and SISO for multi-talker speech recognition. Experiments on the two-speaker LibrispeechMix dataset show that the CES model reduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model reduces WER by 10% overall and by 16% on high-overlap speech compared to the SOT model. ",
    "url": "https://arxiv.org/abs/2401.04152",
    "authors": [
      "Jiawen Kang",
      "Lingwei Meng",
      "Mingyu Cui",
      "Haohan Guo",
      "Xixin Wu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2401.04192",
    "title": "Interactive Multi-Objective Evolutionary Optimization of Software  Architectures",
    "abstract": "While working on a software specification, designers usually need to evaluate different architectural alternatives to be sure that quality criteria are met. Even when these quality aspects could be expressed in terms of multiple software metrics, other qualitative factors cannot be numerically measured, but they are extracted from the engineer's know-how and prior experiences. In fact, detecting not only strong but also weak points in the different solutions seems to fit better with the way humans make their decisions. Putting the human in the loop brings new challenges to the search-based software engineering field, especially for those human-centered activities within the early analysis phase. This paper explores how the interactive evolutionary computation can serve as a basis for integrating the human's judgment into the search process. An interactive approach is proposed to discover software architectures, in which both quantitative and qualitative criteria are applied to guide a multi-objective evolutionary algorithm. The obtained feedback is incorporated into the fitness function using architectural preferences allowing the algorithm to discern between promising and poor solutions. Experimentation with real users has revealed that the proposed interaction mechanism can effectively guide the search towards those regions of the search space that are of real interest to the expert. ",
    "url": "https://arxiv.org/abs/2401.04192",
    "authors": [
      "Aurora Ram\u00edrez",
      "Jos\u00e9 Ra\u00fal Romero",
      "Sebasti\u00e1n Ventura"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2401.04230",
    "title": "SOAP: Cross-sensor Domain Adaptation for 3D Object Detection Using  Stationary Object Aggregation Pseudo-labelling",
    "abstract": "We consider the problem of cross-sensor domain adaptation in the context of LiDAR-based 3D object detection and propose Stationary Object Aggregation Pseudo-labelling (SOAP) to generate high quality pseudo-labels for stationary objects. In contrast to the current state-of-the-art in-domain practice of aggregating just a few input scans, SOAP aggregates entire sequences of point clouds at the input level to reduce the sensor domain gap. Then, by means of what we call quasi-stationary training and spatial consistency post-processing, the SOAP model generates accurate pseudo-labels for stationary objects, closing a minimum of 30.3% domain gap compared to few-frame detectors. Our results also show that state-of-the-art domain adaptation approaches can achieve even greater performance in combination with SOAP, in both the unsupervised and semi-supervised settings. ",
    "url": "https://arxiv.org/abs/2401.04230",
    "authors": [
      "Chengjie Huang",
      "Vahdat Abdelzad",
      "Sean Sedwards",
      "Krzysztof Czarnecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04241",
    "title": "Data-Agnostic Face Image Synthesis Detection Using Bayesian CNNs",
    "abstract": "Face image synthesis detection is considerably gaining attention because of the potential negative impact on society that this type of synthetic data brings. In this paper, we propose a data-agnostic solution to detect the face image synthesis process. Specifically, our solution is based on an anomaly detection framework that requires only real data to learn the inference process. It is therefore data-agnostic in the sense that it requires no synthetic face images. The solution uses the posterior probability with respect to the reference data to determine if new samples are synthetic or not. Our evaluation results using different synthesizers show that our solution is very competitive against the state-of-the-art, which requires synthetic data for training. ",
    "url": "https://arxiv.org/abs/2401.04241",
    "authors": [
      "Roberto Leyva",
      "Victor Sanchez",
      "Gregory Epiphaniou",
      "Carsten Maple"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04247",
    "title": "Robust Image Watermarking using Stable Diffusion",
    "abstract": "Watermarking images is critical for tracking image provenance and claiming ownership. With the advent of generative models, such as stable diffusion, able to create fake but realistic images, watermarking has become particularly important, e.g., to make generated images reliably identifiable. Unfortunately, the very same stable diffusion technology can remove watermarks injected using existing methods. To address this problem, we present a ZoDiac, which uses a pre-trained stable diffusion model to inject a watermark into the trainable latent space, resulting in watermarks that can be reliably detected in the latent vector, even when attacked. We evaluate ZoDiac on three benchmarks, MS-COCO, DiffusionDB, and WikiArt, and find that ZoDiac is robust against state-of-the-art watermark attacks, with a watermark detection rate over 98% and a false positive rate below 6.4%, outperforming state-of-the-art watermarking methods. Our research demonstrates that stable diffusion is a promising approach to robust watermarking, able to withstand even stable-diffusion-based attacks. ",
    "url": "https://arxiv.org/abs/2401.04247",
    "authors": [
      "Lijun Zhang",
      "Xiao Liu",
      "Antoni Viros Martin",
      "Cindy Xiong Bearfield",
      "Yuriy Brun",
      "Hui Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04250",
    "title": "Explaining the Power of Topological Data Analysis in Graph Machine  Learning",
    "abstract": "Topological Data Analysis (TDA) has been praised by researchers for its ability to capture intricate shapes and structures within data. TDA is considered robust in handling noisy and high-dimensional datasets, and its interpretability is believed to promote an intuitive understanding of model behavior. However, claims regarding the power and usefulness of TDA have only been partially tested in application domains where TDA-based models are compared to other graph machine learning approaches, such as graph neural networks. We meticulously test claims on TDA through a comprehensive set of experiments and validate their merits. Our results affirm TDA's robustness against outliers and its interpretability, aligning with proponents' arguments. However, we find that TDA does not significantly enhance the predictive power of existing methods in our specific experiments, while incurring significant computational costs. We investigate phenomena related to graph characteristics, such as small diameters and high clustering coefficients, to mitigate the computational expenses of TDA computations. Our results offer valuable perspectives on integrating TDA into graph machine learning tasks. ",
    "url": "https://arxiv.org/abs/2401.04250",
    "authors": [
      "Funmilola Mary Taiwo",
      "Umar Islambekov",
      "Cuneyt Gurcan Akcora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.04280",
    "title": "Predicting the structure of dynamic graphs",
    "abstract": "Dynamic graph embeddings, inductive and incremental learning facilitate predictive tasks such as node classification and link prediction. However, predicting the structure of a graph at a future time step from a time series of graphs, allowing for new nodes has not gained much attention. In this paper, we present such an approach. We use time series methods to predict the node degree at future time points and combine it with flux balance analysis -- a linear programming method used in biochemistry -- to obtain the structure of future graphs. Furthermore, we explore the predictive graph distribution for different parameter values. We evaluate this method using synthetic and real datasets and demonstrate its utility and applicability. ",
    "url": "https://arxiv.org/abs/2401.04280",
    "authors": [
      "Sevvandi Kandanaarachchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.04282",
    "title": "A Fast Graph Search Algorithm with Dynamic Optimization and Reduced  Histogram for Discrimination of Binary Classification Problem",
    "abstract": "This study develops a graph search algorithm to find the optimal discrimination path for the binary classification problem. The objective function is defined as the difference of variations between the true positive (TP) and false positive (FP). It uses the depth first search (DFS) algorithm to find the top-down paths for discrimination. It proposes a dynamic optimization procedure to optimize TP at the upper levels and then reduce FP at the lower levels. To accelerate computing speed with improving accuracy, it proposes a reduced histogram algorithm with variable bin size instead of looping over all data points, to find the feature threshold of discrimination. The algorithm is applied on top of a Support Vector Machine (SVM) model for a binary classification problem on whether a person is fit or unfit. It significantly improves TP and reduces FP of the SVM results (e.g., reduced FP by 90% with a loss of only\\ 5% TP). The graph search auto-generates 39 ranked discrimination paths within 9 seconds on an input of total 328,464 objects, using a dual-core Laptop computer with a processor of 2.59 GHz. ",
    "url": "https://arxiv.org/abs/2401.04282",
    "authors": [
      "Qinwu Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04316",
    "title": "Robust Control of An Aerial Manipulator Based on A Variable Inertia  Parameters Model",
    "abstract": "Aerial manipulator, which is composed of an UAV (Unmanned Aerial Vehicle) and a multi-link manipulator and can perform aerial manipulation, has shown great potential of applications. However, dynamic coupling between the UAV and the manipulator makes it difficult to control the aerial manipulator with high performance. In this paper, system modeling and control problem of the aerial manipulator are studied. Firstly, an UAV dynamic model is proposed with consideration of the dynamic coupling from an attached manipulator, which is treated as disturbance for the UAV. In the dynamic model, the disturbance is affected by the variable inertia parameters of the aerial manipulator system. Then, based on the proposed dynamic model, a disturbance compensation robust $H_{\\infty}$ controller is designed to stabilize flight of the UAV while the manipulator is in operation. Finally, experiments are conducted and the experimental results demonstrate the feasibility and validity of the proposed control scheme. ",
    "url": "https://arxiv.org/abs/2401.04316",
    "authors": [
      "Guangyu Zhang",
      "Yuqing He",
      "Bo Dai",
      "Feng Gu",
      "Jianda Han",
      "Guangjun Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2401.04330",
    "title": "BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method  guided by multi-scale feature information aggregation",
    "abstract": "The purpose of remote sensing image change detection (RSCD) is to detect differences between bi-temporal images taken at the same place. Deep learning has been extensively used to RSCD tasks, yielding significant results in terms of result recognition. However, due to the shooting angle of the satellite, the impacts of thin clouds, and certain lighting conditions, the problem of fuzzy edges in the change region in some remote sensing photographs cannot be properly handled using current RSCD algorithms. To solve this issue, we proposed a Body Decouple Multi-Scale by fearure Aggregation change detection (BD-MSA), a novel model that collects both global and local feature map information in the channel and space dimensions of the feature map during the training and prediction phases. This approach allows us to successfully extract the change region's boundary information while also divorcing the change region's main body from its boundary. Numerous studies have shown that the assessment metrics and evaluation effects of the model described in this paper on the publicly available datasets DSIFN-CD and S2Looking are the best when compared to other models. ",
    "url": "https://arxiv.org/abs/2401.04330",
    "authors": [
      "Yonghui Tan",
      "Xiaolong Li",
      "Yishu Chen",
      "Jinquan Ai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04331",
    "title": "Coupling Graph Neural Networks with Fractional Order Continuous  Dynamics: A Robustness Study",
    "abstract": "In this work, we rigorously investigate the robustness of graph neural fractional-order differential equation (FDE) models. This framework extends beyond traditional graph neural (integer-order) ordinary differential equation (ODE) models by implementing the time-fractional Caputo derivative. Utilizing fractional calculus allows our model to consider long-term memory during the feature updating process, diverging from the memoryless Markovian updates seen in traditional graph neural ODE models. The superiority of graph neural FDE models over graph neural ODE models has been established in environments free from attacks or perturbations. While traditional graph neural ODE models have been verified to possess a degree of stability and resilience in the presence of adversarial attacks in existing literature, the robustness of graph neural FDE models, especially under adversarial conditions, remains largely unexplored. This paper undertakes a detailed assessment of the robustness of graph neural FDE models. We establish a theoretical foundation outlining the robustness characteristics of graph neural FDE models, highlighting that they maintain more stringent output perturbation bounds in the face of input and graph topology disturbances, compared to their integer-order counterparts. Our empirical evaluations further confirm the enhanced robustness of graph neural FDE models, highlighting their potential in adversarially robust applications. ",
    "url": "https://arxiv.org/abs/2401.04331",
    "authors": [
      "Qiyu Kang",
      "Kai Zhao",
      "Yang Song",
      "Yihang Xie",
      "Yanan Zhao",
      "Sijie Wang",
      "Rui She",
      "Wee Peng Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04348",
    "title": "LAMPAT: Low-Rank Adaption for Multilingual Paraphrasing Using  Adversarial Training",
    "abstract": "Paraphrases are texts that convey the same meaning while using different words or sentence structures. It can be used as an automatic data augmentation tool for many Natural Language Processing tasks, especially when dealing with low-resource languages, where data shortage is a significant problem. To generate a paraphrase in multilingual settings, previous studies have leveraged the knowledge from the machine translation field, i.e., forming a paraphrase through zero-shot machine translation in the same language. Despite good performance on human evaluation, those methods still require parallel translation datasets, thus making them inapplicable to languages that do not have parallel corpora. To mitigate that problem, we proposed the first unsupervised multilingual paraphrasing model, LAMPAT ($\\textbf{L}$ow-rank $\\textbf{A}$daptation for $\\textbf{M}$ultilingual $\\textbf{P}$araphrasing using $\\textbf{A}$dversarial $\\textbf{T}$raining), by which monolingual dataset is sufficient enough to generate a human-like and diverse sentence. Throughout the experiments, we found out that our method not only works well for English but can generalize on unseen languages as well. Data and code are available at https://github.com/phkhanhtrinh23/LAMPAT. ",
    "url": "https://arxiv.org/abs/2401.04348",
    "authors": [
      "Khoi M.Le",
      "Trinh Pham",
      "Tho Quan",
      "Anh Tuan Luu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.04349",
    "title": "WebGPU-SPY: Finding Fingerprints in the Sandbox through GPU Cache  Attacks",
    "abstract": "Microarchitectural attacks on CPU structures have been studied in native applications, as well as in web browsers. These attacks continue to be a substantial threat to computing systems at all scales. With the proliferation of heterogeneous systems and integration of hardware accelerators in every computing system, modern web browsers provide the support of GPU-based acceleration for the graphics and rendering processes. Emerging web standards also support the GPU acceleration of general-purpose computation within web browsers. In this paper, we present a new attack vector for microarchitectural attacks in web browsers. We use emerging GPU accelerating APIs in modern browsers (specifically WebGPU) to launch a GPU-based cache side channel attack on the compute stack of the GPU that spies on victim activities on the graphics (rendering) stack of the GPU. Unlike prior works that rely on JavaScript APIs or software interfaces to build timing primitives, we build the timer using GPU hardware resources and develop a cache side channel attack on Intel's integrated GPUs. We leverage the GPU's inherent parallelism at different levels to develop high-resolution parallel attacks. We demonstrate that GPU-based cache attacks can achieve a precision of 90 for website fingerprinting of 100 top websites. We also discuss potential countermeasures against the proposed attack to secure the systems at a critical time when these web standards are being developed and before they are widely deployed. ",
    "url": "https://arxiv.org/abs/2401.04349",
    "authors": [
      "Ethan Ferguson",
      "Adam Wilson",
      "Hoda Naghibijouybari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2401.04350",
    "title": "Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial  Robustness",
    "abstract": "Large-scale pre-trained vision-language models like CLIP have demonstrated impressive performance across various tasks, and exhibit remarkable zero-shot generalization capability, while they are also vulnerable to imperceptible adversarial examples. Existing works typically employ adversarial training (fine-tuning) as a defense method against adversarial examples. However, direct application to the CLIP model may result in overfitting, compromising the model's capacity for generalization. In this paper, we propose Pre-trained Model Guided Adversarial Fine-Tuning (PMG-AFT) method, which leverages supervision from the original pre-trained model by carefully designing an auxiliary branch, to enhance the model's zero-shot adversarial robustness. Specifically, PMG-AFT minimizes the distance between the features of adversarial examples in the target model and those in the pre-trained model, aiming to preserve the generalization features already captured by the pre-trained model. Extensive Experiments on 15 zero-shot datasets demonstrate that PMG-AFT significantly outperforms the state-of-the-art method, improving the top-1 robust accuracy by an average of 4.99%. Furthermore, our approach consistently improves clean accuracy by an average of 8.72%. ",
    "url": "https://arxiv.org/abs/2401.04350",
    "authors": [
      "Sibo Wang",
      "Jie Zhang",
      "Zheng Yuan",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04351",
    "title": "A Change Point Detection Integrated Remaining Useful Life Estimation  Model under Variable Operating Conditions",
    "abstract": "By informing the onset of the degradation process, health status evaluation serves as a significant preliminary step for reliable remaining useful life (RUL) estimation of complex equipment. This paper proposes a novel temporal dynamics learning-based model for detecting change points of individual devices, even under variable operating conditions, and utilises the learnt change points to improve the RUL estimation accuracy. During offline model development, the multivariate sensor data are decomposed to learn fused temporal correlation features that are generalisable and representative of normal operation dynamics across multiple operating conditions. Monitoring statistics and control limit thresholds for normal behaviour are dynamically constructed from these learnt temporal features for the unsupervised detection of device-level change points. The detected change points then inform the degradation data labelling for training a long short-term memory (LSTM)-based RUL estimation model. During online monitoring, the temporal correlation dynamics of a query device is monitored for breach of the control limit derived in offline training. If a change point is detected, the device's RUL is estimated with the well-trained offline model for early preventive action. Using C-MAPSS turbofan engines as the case study, the proposed method improved the accuracy by 5.6\\% and 7.5\\% for two scenarios with six operating conditions, when compared to existing LSTM-based RUL estimation models that do not consider heterogeneous change points. ",
    "url": "https://arxiv.org/abs/2401.04351",
    "authors": [
      "Anushiya Arunan",
      "Yan Qin",
      "Xiaoli Li",
      "Chau Yuen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.04354",
    "title": "Knowledge-enhanced Multi-perspective Video Representation Learning for  Scene Recognition",
    "abstract": "With the explosive growth of video data in real-world applications, a comprehensive representation of videos becomes increasingly important. In this paper, we address the problem of video scene recognition, whose goal is to learn a high-level video representation to classify scenes in videos. Due to the diversity and complexity of video contents in realistic scenarios, this task remains a challenge. Most existing works identify scenes for videos only from visual or textual information in a temporal perspective, ignoring the valuable information hidden in single frames, while several earlier studies only recognize scenes for separate images in a non-temporal perspective. We argue that these two perspectives are both meaningful for this task and complementary to each other, meanwhile, externally introduced knowledge can also promote the comprehension of videos. We propose a novel two-stream framework to model video representations from multiple perspectives, i.e. temporal and non-temporal perspectives, and integrate the two perspectives in an end-to-end manner by self-distillation. Besides, we design a knowledge-enhanced feature fusion and label prediction method that contributes to naturally introducing knowledge into the task of video scene recognition. Experiments conducted on a real-world dataset demonstrate the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2401.04354",
    "authors": [
      "Xuzheng Yu",
      "Chen Jiang",
      "Wei Zhang",
      "Tian Gan",
      "Linlin Chao",
      "Jianan Zhao",
      "Yuan Cheng",
      "Qingpei Guo",
      "Wei Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04357",
    "title": "Iterative Feedback Network for Unsupervised Point Cloud Registration",
    "abstract": "As a fundamental problem in computer vision, point cloud registration aims to seek the optimal transformation for aligning a pair of point clouds. In most existing methods, the information flows are usually forward transferring, thus lacking the guidance from high-level information to low-level information. Besides, excessive high-level information may be overly redundant, and directly using it may conflict with the original low-level information. In this paper, we propose a novel Iterative Feedback Network (IFNet) for unsupervised point cloud registration, in which the representation of low-level features is efficiently enriched by rerouting subsequent high-level features. Specifically, our IFNet is built upon a series of Feedback Registration Block (FRB) modules, with each module responsible for generating the feedforward rigid transformation and feedback high-level features. These FRB modules are cascaded and recurrently unfolded over time. Further, the Feedback Transformer is designed to efficiently select relevant information from feedback high-level features, which is utilized to refine the low-level features. What's more, we incorporate a geometry-awareness descriptor to empower the network for making full use of most geometric information, which leads to more precise registration results. Extensive experiments on various benchmark datasets demonstrate the superior registration performance of our IFNet. ",
    "url": "https://arxiv.org/abs/2401.04357",
    "authors": [
      "Yifan Xie",
      "Boyu Wang",
      "Shiqi Li",
      "Jihua Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04361",
    "title": "Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive  Learning",
    "abstract": "Knowledge-grounded dialogue (KGD) learns to generate an informative response based on a given dialogue context and external knowledge (\\emph{e.g.}, knowledge graphs; KGs). Recently, the emergence of large language models (LLMs) and pre-training techniques has brought great success to knowledge-grounded dialogue. However, when building KGD systems in real applications, there are various real-world noises that are inevitable to face. For example, the dialogue context might involve perturbations such as misspellings and abbreviations. In addition, KGs typically suffer from incompletion and also might contain erroneous and outdated facts. Such real-world noises pose a challenge to the robustness of KGD systems and hinder their applications in the real world. In this paper, we propose an entity-based contrastive learning framework for improving the robustness of KGD. Specifically, we make use of the entity information in a KGD sample to create both its positive and negative samples which involve semantic-irrelevant and semantic-relevant perturbations, respectively. The contrastive learning framework ensures the KGD model is aware of these two types of perturbations, thus generating informative responses with the potentially noisy inputs in real applications. Experimental results on three benchmark datasets show that our method achieves new state-of-the-art performance in terms of automatic evaluation scores, verifying its effectiveness and potentiality. Furthermore, we show that our method can generate better responses than comparison models in both the noisy and the few-shot settings. ",
    "url": "https://arxiv.org/abs/2401.04361",
    "authors": [
      "Jiaan Wang",
      "Jianfeng Qu",
      "Kexin Wang",
      "Zhixu Li",
      "Wen Hua",
      "Ximing Li",
      "An Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04368",
    "title": "Enhancing Acute Kidney Injury Prediction through Integration of Drug  Features in Intensive Care Units",
    "abstract": "The relationship between acute kidney injury (AKI) prediction and nephrotoxic drugs, or drugs that adversely affect kidney function, is one that has yet to be explored in the critical care setting. One contributing factor to this gap in research is the limited investigation of drug modalities in the intensive care unit (ICU) context, due to the challenges of processing prescription data into the corresponding drug representations and a lack in the comprehensive understanding of these drug representations. This study addresses this gap by proposing a novel approach that leverages patient prescription data as a modality to improve existing models for AKI prediction. We base our research on Electronic Health Record (EHR) data, extracting the relevant patient prescription information and converting it into the selected drug representation for our research, the extended-connectivity fingerprint (ECFP). Furthermore, we adopt a unique multimodal approach, developing machine learning models and 1D Convolutional Neural Networks (CNN) applied to clinical drug representations, establishing a procedure which has not been used by any previous studies predicting AKI. The findings showcase a notable improvement in AKI prediction through the integration of drug embeddings and other patient cohort features. By using drug features represented as ECFP molecular fingerprints along with common cohort features such as demographics and lab test values, we achieved a considerable improvement in model performance for the AKI prediction task over the baseline model which does not include the drug representations as features, indicating that our distinct approach enhances existing baseline techniques and highlights the relevance of drug data in predicting AKI in the ICU setting ",
    "url": "https://arxiv.org/abs/2401.04368",
    "authors": [
      "Gabriel D. M. Manalu",
      "Mulomba Mukendi Christian",
      "Songhee You",
      "Hyebong Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04374",
    "title": "Towards Explainable Artificial Intelligence (XAI): A Data Mining  Perspective",
    "abstract": "Given the complexity and lack of transparency in deep neural networks (DNNs), extensive efforts have been made to make these systems more interpretable or explain their behaviors in accessible terms. Unlike most reviews, which focus on algorithmic and model-centric perspectives, this work takes a \"data-centric\" view, examining how data collection, processing, and analysis contribute to explainable AI (XAI). We categorize existing work into three categories subject to their purposes: interpretations of deep models, referring to feature attributions and reasoning processes that correlate data points with model outputs; influences of training data, examining the impact of training data nuances, such as data valuation and sample anomalies, on decision-making processes; and insights of domain knowledge, discovering latent patterns and fostering new knowledge from data and models to advance social values and scientific discovery. Specifically, we distill XAI methodologies into data mining operations on training and testing data across modalities, such as images, text, and tabular data, as well as on training logs, checkpoints, models and other DNN behavior descriptors. In this way, our study offers a comprehensive, data-centric examination of XAI from a lens of data mining methods and applications. ",
    "url": "https://arxiv.org/abs/2401.04374",
    "authors": [
      "Haoyi Xiong",
      "Xuhong L",
      "Xiaofei Zhang",
      "Jiamin Chen",
      "Xinhao Sun",
      "Yuchen Li",
      "Zeyi Sun",
      "Mengnan Du"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04378",
    "title": "Computing the Gerber-Shiu function with interest and a constant dividend  barrier by physics-informed neural networks",
    "abstract": "In this paper, we propose a new efficient method for calculating the Gerber-Shiu discounted penalty function. Generally, the Gerber-Shiu function usually satisfies a class of integro-differential equation. We introduce the physics-informed neural networks (PINN) which embed a differential equation into the loss of the neural network using automatic differentiation. In addition, PINN is more free to set boundary conditions and does not rely on the determination of the initial value. This gives us an idea to calculate more general Gerber-Shiu functions. Numerical examples are provided to illustrate the very good performance of our approximation. ",
    "url": "https://arxiv.org/abs/2401.04378",
    "authors": [
      "Zan Yu",
      "Lianzeng Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2401.04389",
    "title": "RaD-Net: A Repairing and Denoising Network for Speech Signal Improvement",
    "abstract": "This paper introduces our repairing and denoising network (RaD-Net) for the ICASSP 2024 Speech Signal Improvement (SSI) Challenge. We extend our previous framework based on a two-stage network and propose an upgraded model. Specifically, we replace the repairing network with COM-Net from TEA-PSE. In addition, multi-resolution discriminators and multi-band discriminators are adopted in the training stage. Finally, we use a three-step training strategy to optimize our model. We submit two models with different sets of parameters to meet the RTF requirement of the two tracks. According to the official results, the proposed systems rank 2nd in track 1 and 3rd in track 2. ",
    "url": "https://arxiv.org/abs/2401.04389",
    "authors": [
      "Mingshuai Liu",
      "Zhuangqi Chen",
      "Xiaopeng Yan",
      "Yuanjun Lv",
      "Xianjun Xia",
      "Chuanzeng Huang",
      "Yijian Xiao",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2401.04405",
    "title": "Optimal Transcoding Resolution Prediction for Efficient Per-Title  Bitrate Ladder Estimation",
    "abstract": "Adaptive video streaming requires efficient bitrate ladder construction to meet heterogeneous network conditions and end-user demands. Per-title optimized encoding typically traverses numerous encoding parameters to search the Pareto-optimal operating points for each video. Recently, researchers have attempted to predict the content-optimized bitrate ladder for pre-encoding overhead reduction. However, existing methods commonly estimate the encoding parameters on the Pareto front and still require subsequent pre-encodings. In this paper, we propose to directly predict the optimal transcoding resolution at each preset bitrate for efficient bitrate ladder construction. We adopt a Temporal Attentive Gated Recurrent Network to capture spatial-temporal features and predict transcoding resolutions as a multi-task classification problem. We demonstrate that content-optimized bitrate ladders can thus be efficiently determined without any pre-encoding. Our method well approximates the ground-truth bitrate-resolution pairs with a slight Bj{\\o}ntegaard Delta rate loss of 1.21% and significantly outperforms the state-of-the-art fixed ladder. ",
    "url": "https://arxiv.org/abs/2401.04405",
    "authors": [
      "Jinhai Yang",
      "Mengxi Guo",
      "Shijie Zhao",
      "Junlin Li",
      "Li Zhang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2401.04408",
    "title": "Fine-Grained Embedding Dimension Optimization During Training for  Recommender Systems",
    "abstract": "Huge embedding tables in modern Deep Learning Recommender Models (DLRM) require prohibitively large memory during training and inference. Aiming to reduce the memory footprint of training, this paper proposes FIne-grained In-Training Embedding Dimension optimization (FIITED). Given the observation that embedding vectors are not equally important, FIITED adjusts the dimension of each individual embedding vector continuously during training, assigning longer dimensions to more important embeddings while adapting to dynamic changes in data. A novel embedding storage system based on virtually-hashed physically-indexed hash tables is designed to efficiently implement the embedding dimension adjustment and effectively enable memory saving. Experiments on two industry models show that FIITED is able to reduce the size of embeddings by more than 65% while maintaining the trained model's quality, saving significantly more memory than a state-of-the-art in-training embedding pruning method. On public click-through rate prediction datasets, FIITED is able to prune up to 93.75%-99.75% embeddings without significant accuracy loss. ",
    "url": "https://arxiv.org/abs/2401.04408",
    "authors": [
      "Qinyi Luo",
      "Penghan Wang",
      "Wei Zhang",
      "Fan Lai",
      "Jiachen Mao",
      "Xiaohan Wei",
      "Jun Song",
      "Wei-Yu Tsai",
      "Shuai Yang",
      "Yuxi Hu",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04437",
    "title": "Empirical Analysis of Anomaly Detection on Hyperspectral Imaging Using  Dimension Reduction Methods",
    "abstract": "Recent studies try to use hyperspectral imaging (HSI) to detect foreign matters in products because it enables to visualize the invisible wavelengths including ultraviolet and infrared. Considering the enormous image channels of the HSI, several dimension reduction methods-e.g., PCA or UMAP-can be considered to reduce but those cannot ease the fundamental limitations, as follows: (1) latency of HSI capturing. (2) less explanation ability of the important channels. In this paper, to circumvent the aforementioned methods, one of the ways to channel reduction, on anomaly detection proposed HSI. Different from feature extraction methods (i.e., PCA or UMAP), feature selection can sort the feature by impact and show better explainability so we might redesign the task-optimized and cost-effective spectroscopic camera. Via the extensive experiment results with synthesized MVTec AD dataset, we confirm that the feature selection method shows 6.90x faster at the inference phase compared with feature extraction-based approaches while preserving anomaly detection performance. Ultimately, we conclude the advantage of feature selection which is effective yet fast. ",
    "url": "https://arxiv.org/abs/2401.04437",
    "authors": [
      "Dongeon Kim",
      "YeongHyeon Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04441",
    "title": "Image classification network enhancement methods based on knowledge  injection",
    "abstract": "The current deep neural network algorithm still stays in the end-to-end training supervision method like Image-Label pairs, which makes traditional algorithm is difficult to explain the reason for the results, and the prediction logic is difficult to understand and analyze. The current algorithm does not use the existing human knowledge information, which makes the model not in line with the human cognition model and makes the model not suitable for human use. In order to solve the above problems, the present invention provides a deep neural network training method based on the human knowledge, which uses the human cognition model to construct the deep neural network training model, and uses the existing human knowledge information to construct the deep neural network training model. This paper proposes a multi-level hierarchical deep learning algorithm, which is composed of multi-level hierarchical deep neural network architecture and multi-level hierarchical deep learning framework. The experimental results show that the proposed algorithm can effectively explain the hidden information of the neural network. The goal of our study is to improve the interpretability of deep neural networks (DNNs) by providing an analysis of the impact of knowledge injection on the classification task. We constructed a knowledge injection dataset with matching knowledge data and image classification data. The knowledge injection dataset is the benchmark dataset for the experiments in the paper. Our model expresses the improvement in interpretability and classification task performance of hidden layers at different scales. ",
    "url": "https://arxiv.org/abs/2401.04441",
    "authors": [
      "Yishuang Tian",
      "Ning Wang",
      "Liang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04463",
    "title": "D3AD: Dynamic Denoising Diffusion Probabilistic Model for Anomaly  Detection",
    "abstract": "Diffusion models have found valuable applications in anomaly detection by capturing the nominal data distribution and identifying anomalies via reconstruction. Despite their merits, they struggle to localize anomalies of varying scales, especially larger anomalies like entire missing components. Addressing this, we present a novel framework that enhances the capability of diffusion models, by extending the previous introduced implicit conditioning approach Meng et al. (2022) in three significant ways. First, we incorporate a dynamic step size computation that allows for variable noising steps in the forward process guided by an initial anomaly prediction. Second, we demonstrate that denoising an only scaled input, without any added noise, outperforms conventional denoising process. Third, we project images in a latent space to abstract away from fine details that interfere with reconstruction of large missing components. Additionally, we propose a fine-tuning mechanism that facilitates the model to effectively grasp the nuances of the target domain. Our method undergoes rigorous evaluation on two prominent anomaly detection datasets VISA and BTAD, yielding state-of-the-art performance. Importantly, our framework effectively localizes anomalies regardless of their scale, marking a pivotal advancement in diffusion-based anomaly detection. ",
    "url": "https://arxiv.org/abs/2401.04463",
    "authors": [
      "Justin Tebbe",
      "Jawad Tayyub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04481",
    "title": "Fighting Fire with Fire: Adversarial Prompting to Generate a  Misinformation Detection Dataset",
    "abstract": "The recent success in language generation capabilities of large language models (LLMs), such as GPT, Bard, Llama etc., can potentially lead to concerns about their possible misuse in inducing mass agitation and communal hatred via generating fake news and spreading misinformation. Traditional means of developing a misinformation ground-truth dataset does not scale well because of the extensive manual effort required to annotate the data. In this paper, we propose an LLM-based approach of creating silver-standard ground-truth datasets for identifying misinformation. Specifically speaking, given a trusted news article, our proposed approach involves prompting LLMs to automatically generate a summarised version of the original article. The prompts in our proposed approach act as a controlling mechanism to generate specific types of factual incorrectness in the generated summaries, e.g., incorrect quantities, false attributions etc. To investigate the usefulness of this dataset, we conduct a set of experiments where we train a range of supervised models for the task of misinformation detection. ",
    "url": "https://arxiv.org/abs/2401.04481",
    "authors": [
      "Shrey Satapara",
      "Parth Mehta",
      "Debasis Ganguly",
      "Sandip Modha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04486",
    "title": "Take A Shortcut Back: Mitigating the Gradient Vanishing for Training  Spiking Neural Networks",
    "abstract": "The Spiking Neural Network (SNN) is a biologically inspired neural network infrastructure that has recently garnered significant attention. It utilizes binary spike activations to transmit information, thereby replacing multiplications with additions and resulting in high energy efficiency. However, training an SNN directly poses a challenge due to the undefined gradient of the firing spike process. Although prior works have employed various surrogate gradient training methods that use an alternative function to replace the firing process during back-propagation, these approaches ignore an intrinsic problem: gradient vanishing. To address this issue, we propose a shortcut back-propagation method in our paper, which advocates for transmitting the gradient directly from the loss to the shallow layers. This enables us to present the gradient to the shallow layers directly, thereby significantly mitigating the gradient vanishing problem. Additionally, this method does not introduce any burden during the inference phase. To strike a balance between final accuracy and ease of training, we also propose an evolutionary training framework and implement it by inducing a balance coefficient that dynamically changes with the training epoch, which further improves the network's performance. Extensive experiments conducted over static and dynamic datasets using several popular network structures reveal that our method consistently outperforms state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2401.04486",
    "authors": [
      "Yufei Guo",
      "Yuanpei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04487",
    "title": "Online convex optimization for robust control of constrained dynamical  systems",
    "abstract": "This article investigates the problem of controlling linear time-invariant systems subject to time-varying and a priori unknown cost functions, state and input constraints, and exogenous disturbances. We combine the online convex optimization framework with tools from robust model predictive control to propose an algorithm that is able to guarantee robust constraint satisfaction. The performance of the closed loop emerging from application of our framework is studied in terms of its dynamic regret, which is proven to be bounded linearly by the variation of the cost functions and the magnitude of the disturbances. We corroborate our theoretical findings and illustrate implementational aspects of the proposed algorithm by a numerical case study of a tracking control problem of an autonomous vehicle. ",
    "url": "https://arxiv.org/abs/2401.04487",
    "authors": [
      "Marko Nonhoff",
      "Emiliano Dall'Anese",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2401.04494",
    "title": "Adaptive Asynchronous Work-Stealing for distributed load-balancing in  heterogeneous systems",
    "abstract": "Supercomputers have revolutionized how industries and scientific fields process large amounts of data. These machines group hundreds or thousands of computing nodes working together to execute time-consuming programs that require a large amount of computational resources. Over the years, supercomputers have expanded to include new and different technologies characterizing them as heterogeneous. However, executing a program in a heterogeneous environment requires attention to a specific aspect of performance degradation: load imbalance. In this research, we address the challenges associated with load imbalance when scheduling many homogeneous tasks in a heterogeneous environment. To address this issue, we introduce the concept of adaptive asynchronous work-stealing. This approach collects information about the nodes and utilizes it to improve work-stealing aspects, such as victim selection and task offloading. Additionally, the proposed approach eliminates the need for extra threads to communicate information, thereby reducing overhead when implementing a fully asynchronous approach. Our experimental results demonstrate a performance improvement of approximately 10.1\\% compared to other conventional and state-of-the-art implementations. ",
    "url": "https://arxiv.org/abs/2401.04494",
    "authors": [
      "Jo\u00e3o B. Fernandesa",
      "\u00cdtalo A. S. de Assis",
      "Idalmis M. S. Martins",
      "Tiago Barros",
      "Samuel Xavier-de-Souza"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2401.04507",
    "title": "TechGPT-2.0: A large language model project to solve the task of  knowledge graph construction",
    "abstract": "Large language models have exhibited robust performance across diverse natural language processing tasks. This report introduces TechGPT-2.0, a project designed to enhance the capabilities of large language models specifically in knowledge graph construction tasks, including named entity recognition (NER) and relationship triple extraction (RTE) tasks in NLP applications. Additionally, it serves as a LLM accessible for research within the Chinese open-source model community. We offer two 7B large language model weights and a QLoRA weight specialized for processing lengthy texts.Notably, TechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all functionalities from TechGPT-1.0, it exhibits robust text processing capabilities, particularly in the domains of medicine and law. Furthermore, we introduce new capabilities to the model, enabling it to process texts in various domains such as geographical areas, transportation, organizations, literary works, biology, natural sciences, astronomical objects, and architecture. These enhancements also fortified the model's adeptness in handling hallucinations, unanswerable queries, and lengthy texts. This report provides a comprehensive and detailed introduction to the full fine-tuning process on Huawei's Ascend servers, encompassing experiences in Ascend server debugging, instruction fine-tuning data processing, and model training. Our code is available at https://github.com/neukg/TechGPT-2.0 ",
    "url": "https://arxiv.org/abs/2401.04507",
    "authors": [
      "Jiaqi Wang",
      "Yuying Chang",
      "Zhong Li",
      "Ning An",
      "Qi Ma",
      "Lei Hei",
      "Haibo Luo",
      "Yifei Lu",
      "Feiliang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04514",
    "title": "Rewriting the Code: A Simple Method for Large Language Model Augmented  Code Search",
    "abstract": "In code search, the Generation-Augmented Retrieval (GAR) framework, which generates exemplar code snippets to augment queries, has emerged as a promising strategy to address the principal challenge of modality misalignment between code snippets and natural language queries, particularly with the demonstrated code generation capabilities of Large Language Models (LLMs). Nevertheless, our preliminary investigations indicate that the improvements conferred by such an LLM-augmented framework are somewhat constrained. This limitation could potentially be ascribed to the fact that the generated codes, albeit functionally accurate, frequently display a pronounced stylistic deviation from the ground truth code in the codebase. In this paper, we extend the foundational GAR framework and propose a simple yet effective method that additionally Rewrites the Code (ReCo) within the codebase for style normalization. Experimental results demonstrate that ReCo significantly boosts retrieval accuracy across sparse (up to 35.7%), zero-shot dense (up to 27.6%), and fine-tuned dense (up to 23.6%) retrieval settings in diverse search scenarios. To further elucidate the advantages of ReCo and stimulate research in code style normalization, we introduce Code Style Similarity, the first metric tailored to quantify stylistic similarities in code. Notably, our empirical findings reveal the inadequacy of existing metrics in capturing stylistic nuances. ",
    "url": "https://arxiv.org/abs/2401.04514",
    "authors": [
      "Haochen Li",
      "Xin Zhou",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04515",
    "title": "Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with  Large Language Models",
    "abstract": "This article investigates a zero-shot approach to hypernymy prediction using large language models (LLMs). The study employs a method based on text probability calculation, applying it to various generated prompts. The experiments demonstrate a strong correlation between the effectiveness of language model prompts and classic patterns, indicating that preliminary prompt selection can be carried out using smaller models before moving to larger ones. We also explore prompts for predicting co-hyponyms and improving hypernymy predictions by augmenting prompts with additional information through automatically identified co-hyponyms. An iterative approach is developed for predicting higher-level concepts, which further improves the quality on the BLESS dataset (MAP = 0.8). ",
    "url": "https://arxiv.org/abs/2401.04515",
    "authors": [
      "Mikhail Tikhomirov",
      "Natalia Loukachevitch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04550",
    "title": "WaveletFormerNet: A Transformer-based Wavelet Network for Real-world  Non-homogeneous and Dense Fog Removal",
    "abstract": "Although deep convolutional neural networks have achieved remarkable success in removing synthetic fog, it is essential to be able to process images taken in complex foggy conditions, such as dense or non-homogeneous fog, in the real world. However, the haze distribution in the real world is complex, and downsampling can lead to color distortion or loss of detail in the output results as the resolution of a feature map or image resolution decreases. In addition to the challenges of obtaining sufficient training data, overfitting can also arise in deep learning techniques for foggy image processing, which can limit the generalization abilities of the model, posing challenges for its practical applications in real-world scenarios. Considering these issues, this paper proposes a Transformer-based wavelet network (WaveletFormerNet) for real-world foggy image recovery. We embed the discrete wavelet transform into the Vision Transformer by proposing the WaveletFormer and IWaveletFormer blocks, aiming to alleviate texture detail loss and color distortion in the image due to downsampling. We introduce parallel convolution in the Transformer block, which allows for the capture of multi-frequency information in a lightweight mechanism. Additionally, we have implemented a feature aggregation module (FAM) to maintain image resolution and enhance the feature extraction capacity of our model, further contributing to its impressive performance in real-world foggy image recovery tasks. Extensive experiments demonstrate that our WaveletFormerNet performs better than state-of-the-art methods, as shown through quantitative and qualitative evaluations of minor model complexity. Additionally, our satisfactory results on real-world dust removal and application tests showcase the superior generalization ability and improved performance of WaveletFormerNet in computer vision-related applications. ",
    "url": "https://arxiv.org/abs/2401.04550",
    "authors": [
      "Shengli Zhang",
      "Zhiyong Tao",
      "Sen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04572",
    "title": "Robust Imitation Learning for Automated Game Testing",
    "abstract": "Game development is a long process that involves many stages before a product is ready for the market. Human play testing is among the most time consuming, as testers are required to repeatedly perform tasks in the search for errors in the code. Therefore, automated testing is seen as a key technology for the gaming industry, as it would dramatically improve development costs and efficiency. Toward this end, we propose EVOLUTE, a novel imitation learning-based architecture that combines behavioural cloning (BC) with energy based models (EBMs). EVOLUTE is a two-stream ensemble model that splits the action space of autonomous agents into continuous and discrete tasks. The EBM stream handles the continuous tasks, to have a more refined and adaptive control, while the BC stream handles discrete actions, to ease training. We evaluate the performance of EVOLUTE in a shooting-and-driving game, where the agent is required to navigate and continuously identify targets to attack. The proposed model has higher generalisation capabilities than standard BC approaches, showing a wider range of behaviours and higher performances. Also, EVOLUTE is easier to train than a pure end-to-end EBM model, as discrete tasks can be quite sparse in the dataset and cause model training to explore a much wider set of possible actions while training. ",
    "url": "https://arxiv.org/abs/2401.04572",
    "authors": [
      "Pierluigi Vito Amadori",
      "Timothy Bradley",
      "Ryan Spick",
      "Guy Moss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04612",
    "title": "Distribution-Free Conformal Joint Prediction Regions for Neural Marked  Temporal Point Processes",
    "abstract": "Sequences of labeled events observed at irregular intervals in continuous time are ubiquitous across various fields. Temporal Point Processes (TPPs) provide a mathematical framework for modeling these sequences, enabling inferences such as predicting the arrival time of future events and their associated label, called mark. However, due to model misspecification or lack of training data, these probabilistic models may provide a poor approximation of the true, unknown underlying process, with prediction regions extracted from them being unreliable estimates of the underlying uncertainty. This paper develops more reliable methods for uncertainty quantification in neural TPP models via the framework of conformal prediction. A primary objective is to generate a distribution-free joint prediction region for the arrival time and mark, with a finite-sample marginal coverage guarantee. A key challenge is to handle both a strictly positive, continuous response and a categorical response, without distributional assumptions. We first consider a simple but overly conservative approach that combines individual prediction regions for the event arrival time and mark. Then, we introduce a more effective method based on bivariate highest density regions derived from the joint predictive density of event arrival time and mark. By leveraging the dependencies between these two variables, this method exclude unlikely combinations of the two, resulting in sharper prediction regions while still attaining the pre-specified coverage level. We also explore the generation of individual univariate prediction regions for arrival times and marks through conformal regression and classification techniques. Moreover, we investigate the stronger notion of conditional coverage. Finally, through extensive experimentation on both simulated and real-world datasets, we assess the validity and efficiency of these methods. ",
    "url": "https://arxiv.org/abs/2401.04612",
    "authors": [
      "Victor Dheur",
      "Tanguy Bosser",
      "Rafael Izbicki",
      "Souhaib Ben Taieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04619",
    "title": "Language Detection for Transliterated Content",
    "abstract": "In the contemporary digital era, the Internet functions as an unparalleled catalyst, dismantling geographical and linguistic barriers particularly evident in texting. This evolution facilitates global communication, transcending physical distances and fostering dynamic cultural exchange. A notable trend is the widespread use of transliteration, where the English alphabet is employed to convey messages in native languages, posing a unique challenge for language technology in accurately detecting the source language. This paper addresses this challenge through a dataset of phone text messages in Hindi and Russian transliterated into English utilizing BERT for language classification and Google Translate API for transliteration conversion. The research pioneers innovative approaches to identify and convert transliterated text, navigating challenges in the diverse linguistic landscape of digital communication. Emphasizing the pivotal role of comprehensive datasets for training Large Language Models LLMs like BERT, our model showcases exceptional proficiency in accurately identifying and classifying languages from transliterated text. With a validation accuracy of 99% our models robust performance underscores its reliability. The comprehensive exploration of transliteration dynamics supported by innovative approaches and cutting edge technologies like BERT, positions our research at the forefront of addressing unique challenges in the linguistic landscape of digital communication. Beyond contributing to language identification and transliteration capabilities this work holds promise for applications in content moderation, analytics and fostering a globally connected community engaged in meaningful dialogue. ",
    "url": "https://arxiv.org/abs/2401.04619",
    "authors": [
      "Selva Kumar S",
      "Afifah Khan Mohammed Ajmal Khan",
      "Chirag Manjeshwar",
      "Imadh Ajaz Banday"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.04620",
    "title": "Agent Alignment in Evolving Social Norms",
    "abstract": "Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstrate that EvolutionaryAgent possesses the capability to align progressively better with the evolving social norms while maintaining its proficiency in general tasks. Effectiveness tests conducted on various open and closed-source LLMs as the foundation for agents also prove the applicability of our approach. ",
    "url": "https://arxiv.org/abs/2401.04620",
    "authors": [
      "Shimin Li",
      "Tianxiang Sun",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.04628",
    "title": "Multi-Neuron Representations of Hierarchical Concepts in Spiking Neural  Networks",
    "abstract": "We describe how hierarchical concepts can be represented in three types of layered neural networks. The aim is to support recognition of the concepts when partial information about the concepts is presented, and also when some of the neurons in the network might fail. Our failure model involves initial random failures. The three types of networks are: feed-forward networks with high connectivity, feed-forward networks with low connectivity, and layered networks with low connectivity and with both forward edges and \"lateral\" edges within layers. In order to achieve fault-tolerance, the representations all use multiple representative neurons for each concept. We show how recognition can work in all three of these settings, and quantify how the probability of correct recognition depends on several parameters, including the number of representatives and the neuron failure probability. We also discuss how these representations might be learned, in all three types of networks. For the feed-forward networks, the learning algorithms are similar to ones used in [4], whereas for networks with lateral edges, the algorithms are generally inspired by work on the assembly calculus [3, 6, 7]. ",
    "url": "https://arxiv.org/abs/2401.04628",
    "authors": [
      "Nancy A. Lynch"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2401.04632",
    "title": "Hypercomplex neural network in time series forecasting of stock data",
    "abstract": "The three classes of architectures for time series prediction were tested. They differ by input layers which contain either convolutional, LSTM, or dense hypercomplex layers for 4D algebras. The input was four related Stock Market time series, and the prediction of one of them is expected. The optimization of hyperparameters related to the classes of architectures was performed in order to compare the best neural networks within the class. The results show that in most cases, the architecture with a hypercomplex dense layer provides similar MAE accuracy to other architectures, however, with considerably less trainable parameters. Thanks to it, hypercomplex neural networks can be learned and process data faster than the other tested architectures. Moreover, the order of the input time series has an impact on effectively. ",
    "url": "https://arxiv.org/abs/2401.04632",
    "authors": [
      "Rados\u0142aw Kycia",
      "Agnieszka Niemczynowicz"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04636",
    "title": "On the Target Detection Performance of a Molecular Communication Network  with Multiple Mobile Nanomachines",
    "abstract": "A network of nanomachines (NMs) can be used to build a target detection system for a variety of promising applications. They have the potential to detect toxic chemicals, infectious bacteria, and biomarkers of dangerous diseases such as cancer within the human body. Many diseases and health disorders can be detected early and efficiently treated in the future by utilizing these systems. To fully grasp the potential of these systems, mathematical analysis is required. This paper describes an analytical framework for modeling and analyzing the performance of target detection systems composed of multiple mobile nanomachines of varying sizes with passive/absorbing boundaries. We consider both direct contact detection, in which NMs must physically contact the target to detect it, and indirect sensing, in which NMs must detect the marker molecules emitted by the target. The detection performance of such systems is calculated for degradable and non-degradable targets, as well as mobile and stationary targets. The derived expressions provide various insights, such as the effect of NM density and target degradation on detection probability. ",
    "url": "https://arxiv.org/abs/2401.04636",
    "authors": [
      "Nithin V. Sabu",
      "Abhishek K. Gupta"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.04638",
    "title": "Approximation Algorithms for Minimizing Congestion in Demand-Aware  Networks",
    "abstract": "Emerging reconfigurable optical communication technologies allow to enhance datacenter topologies with demand-aware links optimized towards traffic patterns. This paper studies the algorithmic problem of jointly optimizing topology and routing in such demand-aware networks to minimize congestion, along two dimensions: (1) splittable or unsplittable flows, and (2) whether routing is segregated, i.e., whether routes can or cannot combine both demand-aware and demand-oblivious (static) links. For splittable and segregated routing, we show that the problem is generally $2$-approximable, but APX-hard even for uniform demands induced by a bipartite demand graph. For unsplittable and segregated routing, we establish upper and lower bounds of $O\\left(\\log m/ \\log\\log m \\right)$ and $\\Omega\\left(\\log m/ \\log\\log m \\right)$, respectively, for polynomial-time approximation algorithms, where $m$ is the number of static links. We further reveal that under un-/splittable and non-segregated routing, even for demands of a single source (resp., destination), the problem cannot be approximated better than $\\Omega\\left(\\frac{c_{\\max}}{c_{\\min}} \\right)$ unless P=NP, where $c_{\\max}$ (resp., $c_{\\min}$) denotes the maximum (resp., minimum) capacity. It remains NP-hard for uniform capacities, but is tractable for a single commodity and uniform capacities. Our trace-driven simulations show a significant reduction in network congestion compared to existing solutions. ",
    "url": "https://arxiv.org/abs/2401.04638",
    "authors": [
      "Wenkai Dai",
      "Michael Dinitz",
      "Klaus-Tycho Foerster",
      "Long Luo",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2401.04647",
    "title": "Advancing Ante-Hoc Explainable Models through Generative Adversarial  Networks",
    "abstract": "This paper presents a novel concept learning framework for enhancing model interpretability and performance in visual classification tasks. Our approach appends an unsupervised explanation generator to the primary classifier network and makes use of adversarial training. During training, the explanation module is optimized to extract visual concepts from the classifier's latent representations, while the GAN-based module aims to discriminate images generated from concepts, from true images. This joint training scheme enables the model to implicitly align its internally learned concepts with human-interpretable visual properties. Comprehensive experiments demonstrate the robustness of our approach, while producing coherent concept activations. We analyse the learned concepts, showing their semantic concordance with object parts and visual attributes. We also study how perturbations in the adversarial training protocol impact both classification and concept acquisition. In summary, this work presents a significant step towards building inherently interpretable deep vision models with task-aligned concept representations - a key enabler for developing trustworthy AI for real-world perception tasks. ",
    "url": "https://arxiv.org/abs/2401.04647",
    "authors": [
      "Tanmay Garg",
      "Deepika Vemuri",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04679",
    "title": "RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation",
    "abstract": "We investigate parameter-efficient fine-tuning (PEFT) methods that can provide good accuracy under limited computational and memory budgets in the context of large language models (LLMs). We present a new PEFT method called Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA) that jointly trains $\\textit{low-rank}$ and $\\textit{highly-sparse}$ components on top of a set of fixed pretrained weights to efficiently approximate the performance of a full-fine-tuning (FFT) solution. Across a series of challenging generative tasks such as grade-school math and SQL query generation, which require fine-tuning for good performance, we show that RoSA outperforms both LoRA and pure sparse fine-tuning, at the same parameter budget. We provide system support for RoSA to complement the training algorithm, specifically in the form of sparse GPU kernels which enable memory- and computationally-efficient training. Our code will be made available at https://github.com/IST-DASLab/RoSA}{\\texttt{https://github.com/IST-DASLab/RoSA ",
    "url": "https://arxiv.org/abs/2401.04679",
    "authors": [
      "Mahdi Nikdan",
      "Soroush Tabesh",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04680",
    "title": "CoordGate: Efficiently Computing Spatially-Varying Convolutions in  Convolutional Neural Networks",
    "abstract": "Optical imaging systems are inherently limited in their resolution due to the point spread function (PSF), which applies a static, yet spatially-varying, convolution to the image. This degradation can be addressed via Convolutional Neural Networks (CNNs), particularly through deblurring techniques. However, current solutions face certain limitations in efficiently computing spatially-varying convolutions. In this paper we propose CoordGate, a novel lightweight module that uses a multiplicative gate and a coordinate encoding network to enable efficient computation of spatially-varying convolutions in CNNs. CoordGate allows for selective amplification or attenuation of filters based on their spatial position, effectively acting like a locally connected neural network. The effectiveness of the CoordGate solution is demonstrated within the context of U-Nets and applied to the challenging problem of image deblurring. The experimental results show that CoordGate outperforms conventional approaches, offering a more robust and spatially aware solution for CNNs in various computer vision applications. ",
    "url": "https://arxiv.org/abs/2401.04680",
    "authors": [
      "Sunny Howard",
      "Peter Norreys",
      "Andreas D\u00f6pp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2401.04727",
    "title": "Revisiting Adversarial Training at Scale",
    "abstract": "The machine learning community has witnessed a drastic change in the training pipeline, pivoted by those ''foundation models'' with unprecedented scales. However, the field of adversarial training is lagging behind, predominantly centered around small model sizes like ResNet-50, and tiny and low-resolution datasets like CIFAR-10. To bridge this transformation gap, this paper provides a modern re-examination with adversarial training, investigating its potential benefits when applied at scale. Additionally, we introduce an efficient and effective training strategy to enable adversarial training with giant models and web-scale data at an affordable computing cost. We denote this newly introduced framework as AdvXL. Empirical results demonstrate that AdvXL establishes new state-of-the-art robust accuracy records under AutoAttack on ImageNet-1K. For example, by training on DataComp-1B dataset, our AdvXL empowers a vanilla ViT-g model to substantially surpass the previous records of $l_{\\infty}$-, $l_{2}$-, and $l_{1}$-robust accuracy by margins of 11.4%, 14.2% and 12.9%, respectively. This achievement posits AdvXL as a pioneering approach, charting a new trajectory for the efficient training of robust visual representations at significantly larger scales. Our code is available at https://github.com/UCSC-VLAA/AdvXL. ",
    "url": "https://arxiv.org/abs/2401.04727",
    "authors": [
      "Zeyu Wang",
      "Xianhang Li",
      "Hongru Zhu",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04191",
    "title": "Dense Hopfield Networks in the Teacher-Student Setting",
    "abstract": "Dense Hopfield networks are known for their feature to prototype transition and adversarial robustness. However, previous theoretical studies have been mostly concerned with their storage capacity. We bridge this gap by studying the phase diagram of p-body Hopfield networks in the teacher-student setting of an unsupervised learning problem, uncovering ferromagnetic phases reminiscent of the prototype and feature learning regimes. On the Nishimori line, we find the critical size of the training set necessary for efficient pattern retrieval. Interestingly, we find that that the paramagnetic to ferromagnetic transition of the teacher-student setting coincides with the paramagnetic to spin-glass transition of the direct model, i.e. with random patterns. Outside of the Nishimori line, we investigate the learning performance in relation to the inference temperature and dataset noise. Moreover, we show that using a larger p for the student than the teacher gives the student an extensive tolerance to noise. We then derive a closed-form expression measuring the adversarial robustness of such a student at zero temperature, corroborating the positive correlation between number of parameters and robustness observed in large neural networks. We also use our model to clarify why the prototype phase of modern Hopfield networks is adversarially robust. ",
    "url": "https://arxiv.org/abs/2401.04191",
    "authors": [
      "Robin Th\u00e9riault",
      "Daniele Tantari"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2401.04286",
    "title": "Universal Consistency of Wide and Deep ReLU Neural Networks and Minimax  Optimal Convergence Rates for Kolmogorov-Donoho Optimal Function Classes",
    "abstract": "In this paper, we first extend the result of FL93 and prove universal consistency for a classification rule based on wide and deep ReLU neural networks trained on the logistic loss. Unlike the approach in FL93 that decomposes the estimation and empirical error, we directly analyze the classification risk based on the observation that a realization of a neural network that is wide enough is capable of interpolating an arbitrary number of points. Secondly, we give sufficient conditions for a class of probability measures under which classifiers based on neural networks achieve minimax optimal rates of convergence. Our result is motivated from the practitioner's observation that neural networks are often trained to achieve 0 training error, which is the case for our proposed neural network classifiers. Our proofs hinge on recent developments in empirical risk minimization and on approximation rates of deep ReLU neural networks for various function classes of interest. Applications to classical function spaces of smoothness illustrate the usefulness of our result. ",
    "url": "https://arxiv.org/abs/2401.04286",
    "authors": [
      "Hyunouk Ko",
      "Xiaoming Huo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04436",
    "title": "A Payne-Whitham model of urban traffic networks in the presence of  traffic lights and its application to traffic optimisation",
    "abstract": "Urban road transport is a major civilisational and economic challenge, affecting quality of life and economic activity. Addressing these challenges requires a multidisciplinary approach and sustainable urban planning strategies to mitigate the negative effects of traffic in cities. In this paper, we will introduce an extension of one of the most popular macroscopic traffic simulation models, the Payne-Whitham model. We will investigate how this model, originally designed to model highway traffic on straight road segments, can be adapted to more realistic conditions with arbitrary road network graphs and multiple intersections with traffic signals. Furthermore, we will showcase the practical application of this extension in experiments aimed at optimising traffic signal settings. For computational reasons, these experiments involve the adoption of surrogate models for approximating our extended Payne-Whitham model, and subsequently, we utilise various optimisation algorithms, e.g. SLSQP, resulting in the identification of traffic signal settings that enhance the average speed of cars, thereby facilitating smoother traffic flow. ",
    "url": "https://arxiv.org/abs/2401.04436",
    "authors": [
      "Mauritz Cartier van Dissel",
      "Pawe\u0142 Gora",
      "Drago\u015f Manea"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2401.04478",
    "title": "TwinBooster: Synergising Large Language Models with Barlow Twins and  Gradient Boosting for Enhanced Molecular Property Prediction",
    "abstract": "The success of drug discovery and development relies on the precise prediction of molecular activities and properties. While in silico molecular property prediction has shown remarkable potential, its use has been limited so far to assays for which large amounts of data are available. In this study, we use a fine-tuned large language model to integrate biological assays based on their textual information, coupled with Barlow Twins, a Siamese neural network using a novel self-supervised learning approach. This architecture uses both assay information and molecular fingerprints to extract the true molecular information. TwinBooster enables the prediction of properties of unseen bioassays and molecules by providing state-of-the-art zero-shot learning tasks. Remarkably, our artificial intelligence pipeline shows excellent performance on the FS-Mol benchmark. This breakthrough demonstrates the application of deep learning to critical property prediction tasks where data is typically scarce. By accelerating the early identification of active molecules in drug discovery and development, this method has the potential to help streamline the identification of novel therapeutics. ",
    "url": "https://arxiv.org/abs/2401.04478",
    "authors": [
      "Maximilian G. Schuh",
      "Davide Boldini",
      "Stephan A. Sieber"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04554",
    "title": "HIST-Critical Graphs and Malkevitch's Conjecture",
    "abstract": "In a given graph, a HIST is a spanning tree without $2$-valent vertices. Motivated by developing a better understanding of HIST-free graphs, i.e. graphs containing no HIST, in this article's first part we study HIST-critical graphs, i.e. HIST-free graphs in which every vertex-deleted subgraph does contain a HIST (e.g. a triangle). We give an almost complete characterisation of the orders for which these graphs exist and present an infinite family of planar examples which are $3$-connected and in which nearly all vertices are $4$-valent. This leads naturally to the second part in which we investigate planar $4$-regular graphs with and without HISTs, motivated by a conjecture of Malkevitch, which we computationally verify up to order $22$. First we enumerate HISTs in antiprisms, whereafter we present planar $4$-regular graphs with and without HISTs, obtained via line graphs. ",
    "url": "https://arxiv.org/abs/2401.04554",
    "authors": [
      "Jan Goedgebeur",
      "Kenta Noguchi",
      "Jarne Renders",
      "Carol T. Zamfirescu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2401.04579",
    "title": "A Deep Network for Explainable Prediction of Non-Imaging Phenotypes  using Anatomical Multi-View Data",
    "abstract": "Large datasets often contain multiple distinct feature sets, or views, that offer complementary information that can be exploited by multi-view learning methods to improve results. We investigate anatomical multi-view data, where each brain anatomical structure is described with multiple feature sets. In particular, we focus on sets of white matter microstructure and connectivity features from diffusion MRI, as well as sets of gray matter area and thickness features from structural MRI. We investigate machine learning methodology that applies multi-view approaches to improve the prediction of non-imaging phenotypes, including demographics (age), motor (strength), and cognition (picture vocabulary). We present an explainable multi-view network (EMV-Net) that can use different anatomical views to improve prediction performance. In this network, each individual anatomical view is processed by a view-specific feature extractor and the extracted information from each view is fused using a learnable weight. This is followed by a wavelet transform-based module to obtain complementary information across views which is then applied to calibrate the view-specific information. Additionally, the calibrator produces an attention-based calibration score to indicate anatomical structures' importance for interpretation. ",
    "url": "https://arxiv.org/abs/2401.04579",
    "authors": [
      "Yuxiang Wei",
      "Yuqian Chen",
      "Tengfei Xue",
      "Leo Zekelman",
      "Nikos Makris",
      "Yogesh Rathi",
      "Weidong Cai",
      "Fan Zhang",
      "Lauren J. O' Donnell"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2401.04726",
    "title": "Weighted degrees and truncated derived bibliographic networks",
    "abstract": "Large bibliographic networks are sparse -- the average node degree is small. This is not necessarily true for their product -- in some cases, it can ``explode'' (it is not sparse, increases in time and space complexity). An approach in such cases is to reduce the complexity of the problem by limiting our attention to a selected subset of important nodes and computing with corresponding truncated networks. The nodes can be selected by different criteria. An option is to consider the most important nodes in the derived network -- nodes with the largest weighted degree. It turns out that the weighted degrees in the derived network can be computed efficiently without computing the derived network itself. ",
    "url": "https://arxiv.org/abs/2401.04726",
    "authors": [
      "Vladimir Batagelj"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2201.12577",
    "title": "Volley Revolver: A Novel Matrix-Encoding Method for Privacy-Preserving  Neural Networks (Inference)",
    "abstract": " Comments: The encoding method we proposed in this work, $\\texttt{Volley Revolver}$, is particularly tailored for privacy-preserving neural networks. There is a good chance that it can be used to assist the private neural networks training, in which case for the backpropagation algorithm of the fully-connected layer the first matrix $A$ is revolved while the second matrix $B$ is settled to be still ",
    "url": "https://arxiv.org/abs/2201.12577",
    "authors": [
      "John Chiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01891",
    "title": "Weighted Isolation and Random Cut Forest Algorithms for Anomaly  Detection",
    "abstract": " Comments: 45 pages, 28 figures ",
    "url": "https://arxiv.org/abs/2202.01891",
    "authors": [
      "Sijin Yeom",
      "Jae-Hun Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09212",
    "title": "Molecule Generation for Drug Design: a Graph Learning Perspective",
    "abstract": " Title: Molecule Generation for Drug Design: a Graph Learning Perspective ",
    "url": "https://arxiv.org/abs/2202.09212",
    "authors": [
      "Nianzu Yang",
      "Huaijin Wu",
      "Kaipeng Zeng",
      "Yang Li",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03107",
    "title": "A probabilistic representation of the solution to a 1D evolution  equation in a medium with negative index",
    "abstract": " Title: A probabilistic representation of the solution to a 1D evolution  equation in a medium with negative index ",
    "url": "https://arxiv.org/abs/2206.03107",
    "authors": [
      "\u00c9ric Bonnetier",
      "Pierre Etor\u00e9",
      "Miguel Martinez"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2206.14068",
    "title": "FuSeBMC v4: Improving code coverage with smart seeds via BMC, fuzzing  and static analysis",
    "abstract": " Comments: 24 pages, In The Formal Aspects of Computing Journal (FAC 2023) ",
    "url": "https://arxiv.org/abs/2206.14068",
    "authors": [
      "Kaled M. Alshmrany",
      "Mohannad Aldughaim",
      "Ahmed Bhayat",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2209.14065",
    "title": "LL-GNN: Low Latency Graph Neural Networks on FPGAs for High Energy  Physics",
    "abstract": " Comments: This paper has been accepted by ACM Transactions on Embedded Computing Systems (TECS) ",
    "url": "https://arxiv.org/abs/2209.14065",
    "authors": [
      "Zhiqiang Que",
      "Hongxiang Fan",
      "Marcus Loo",
      "He Li",
      "Michaela Blott",
      "Maurizio Pierini",
      "Alexander Tapper",
      "Wayne Luk"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2210.16906",
    "title": "DyG2Vec: Efficient Representation Learning for Dynamic Graphs",
    "abstract": " Comments: Transactions on Machine Learning Research, 2023 ",
    "url": "https://arxiv.org/abs/2210.16906",
    "authors": [
      "Mohammad Ali Alomrani",
      "Mahdi Biparva",
      "Yingxue Zhang",
      "Mark Coates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.14555",
    "title": "Distribution Free Prediction Sets for Node Classification",
    "abstract": " Comments: Appeared at ICML 2023 ",
    "url": "https://arxiv.org/abs/2211.14555",
    "authors": [
      "Jase Clarkson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00950",
    "title": "Class-Continuous Conditional Generative Neural Radiance Field",
    "abstract": " Comments: BMVC 2023 (Accepted) ",
    "url": "https://arxiv.org/abs/2301.00950",
    "authors": [
      "Jiwook Kim",
      "Minhyeok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.01075",
    "title": "Conformal Prediction Regions for Time Series using Linear  Complementarity Programming",
    "abstract": " Title: Conformal Prediction Regions for Time Series using Linear  Complementarity Programming ",
    "url": "https://arxiv.org/abs/2304.01075",
    "authors": [
      "Matthew Cleaveland",
      "Insup Lee",
      "George J. Pappas",
      "Lars Lindemann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.01561",
    "title": "Optimal rates of approximation by shallow ReLU$^k$ neural networks and  applications to nonparametric regression",
    "abstract": " Comments: Version 3 improves some approximation bounds by using recent results from arXiv:2307.15285 ",
    "url": "https://arxiv.org/abs/2304.01561",
    "authors": [
      "Yunfei Yang",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.01899",
    "title": "Cross-Class Feature Augmentation for Class Incremental Learning",
    "abstract": " Title: Cross-Class Feature Augmentation for Class Incremental Learning ",
    "url": "https://arxiv.org/abs/2304.01899",
    "authors": [
      "Taehoon Kim",
      "Jaeyoo Park",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04232",
    "title": "Rate Adaptation in Delay-Sensitive and Energy-Constrained Large-Scale  IoT Networks",
    "abstract": " Title: Rate Adaptation in Delay-Sensitive and Energy-Constrained Large-Scale  IoT Networks ",
    "url": "https://arxiv.org/abs/2304.04232",
    "authors": [
      "Mostafa Emara",
      "Nour Kouzayha",
      "Hesham ElSawy",
      "Tareq Y. Al-Naffouri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.14811",
    "title": "NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance  Fields",
    "abstract": " Title: NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance  Fields ",
    "url": "https://arxiv.org/abs/2304.14811",
    "authors": [
      "Junge Zhang",
      "Feihu Zhang",
      "Shaochen Kuang",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.03292",
    "title": "FedNC: A Secure and Efficient Federated Learning Method with Network  Coding",
    "abstract": " Title: FedNC: A Secure and Efficient Federated Learning Method with Network  Coding ",
    "url": "https://arxiv.org/abs/2305.03292",
    "authors": [
      "Yuchen Shi",
      "Zheqi Zhu",
      "Pingyi Fan",
      "Khaled B. Letaief",
      "Chenghui Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.12021",
    "title": "A Secure and Robust Approach for Distance-Based Mutual Positioning of  Unmanned Aerial Vehicles",
    "abstract": " Comments: Accepted for presentation at the IEEE WCNC 2024 ",
    "url": "https://arxiv.org/abs/2305.12021",
    "authors": [
      "Bin Han",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.15747",
    "title": "Union Subgraph Neural Networks",
    "abstract": " Title: Union Subgraph Neural Networks ",
    "url": "https://arxiv.org/abs/2305.15747",
    "authors": [
      "Jiaxing Xu",
      "Aihu Zhang",
      "Qingtian Bian",
      "Vijay Prakash Dwivedi",
      "Yiping Ke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16713",
    "title": "ReConPatch : Contrastive Patch Representation Learning for Industrial  Anomaly Detection",
    "abstract": " Comments: 10 pages, 4 figures, supplementary added. Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024, pp. 2052-2061 ",
    "url": "https://arxiv.org/abs/2305.16713",
    "authors": [
      "Jeeho Hyun",
      "Sangyun Kim",
      "Giyoung Jeon",
      "Seung Hwan Kim",
      "Kyunghoon Bae",
      "Byung Jun Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06734",
    "title": "MLE-based Device Activity Detection under Rician Fading for Massive  Grant-free Access with Perfect and Imperfect Synchronization",
    "abstract": " Title: MLE-based Device Activity Detection under Rician Fading for Massive  Grant-free Access with Perfect and Imperfect Synchronization ",
    "url": "https://arxiv.org/abs/2306.06734",
    "authors": [
      "Wang Liu",
      "Ying Cui",
      "Feng Yang",
      "Lianghui Ding",
      "Jun Sun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.16741",
    "title": "Foundation Model for Endoscopy Video Analysis via Large-scale  Self-supervised Pre-train",
    "abstract": " Comments: MICCAI 2023 camera-ready version ",
    "url": "https://arxiv.org/abs/2306.16741",
    "authors": [
      "Zhao Wang",
      "Chang Liu",
      "Shaoting Zhang",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.03992",
    "title": "Stimulating the Diffusion Model for Image Denoising via Adaptive  Embedding and Ensembling",
    "abstract": " Comments: 18 pages,14 figures ",
    "url": "https://arxiv.org/abs/2307.03992",
    "authors": [
      "Tong Li",
      "Hansen Feng",
      "Lizhi Wang",
      "Zhiwei Xiong",
      "Hua Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12602",
    "title": "Shortest two disjoint paths in conservative graphs",
    "abstract": " Comments: A version of this paper has been accepted to the 41st International Symposium on Theoretical Aspects of Computer Science (STACS 2024) ",
    "url": "https://arxiv.org/abs/2307.12602",
    "authors": [
      "Ildik\u00f3 Schlotter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.15557",
    "title": "Dynamic algorithms for k-center on graphs",
    "abstract": " Comments: In Proceedings SODA 2024 ",
    "url": "https://arxiv.org/abs/2307.15557",
    "authors": [
      "Emilio Cruciani",
      "Sebastian Forster",
      "Gramoz Goranci",
      "Yasamin Nazari",
      "Antonis Skarlatos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.02281",
    "title": "s-ID: Causal Effect Identification in a Sub-Population",
    "abstract": " Comments: 24 pages, 15 figures, 1 table, To appear in AAAI 2024 conference ",
    "url": "https://arxiv.org/abs/2309.02281",
    "authors": [
      "Amir Mohammad Abouei",
      "Ehsan Mokhtarian",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.06212",
    "title": "Long-term drought prediction using deep neural networks based on  geospatial weather data",
    "abstract": " Title: Long-term drought prediction using deep neural networks based on  geospatial weather data ",
    "url": "https://arxiv.org/abs/2309.06212",
    "authors": [
      "Vsevolod Grabar",
      "Alexander Marusov",
      "Yury Maximov",
      "Nazar Sotiriadi",
      "Alexander Bulkin",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08876",
    "title": "Decoder-only Architecture for Speech Recognition with CTC Prompts and  Text Data Augmentation",
    "abstract": " Title: Decoder-only Architecture for Speech Recognition with CTC Prompts and  Text Data Augmentation ",
    "url": "https://arxiv.org/abs/2309.08876",
    "authors": [
      "Emiru Tsunoo",
      "Hayato Futami",
      "Yosuke Kashiwagi",
      "Siddhant Arora",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.14345",
    "title": "Bias Testing and Mitigation in LLM-based Code Generation",
    "abstract": " Comments: Title changed ",
    "url": "https://arxiv.org/abs/2309.14345",
    "authors": [
      "Dong Huang",
      "Qingwen Bu",
      "Jie Zhang",
      "Xiaofei Xie",
      "Junjie Chen",
      "Heming Cui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.15244",
    "title": "Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer  ReLU Neural Networks",
    "abstract": " Title: Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer  ReLU Neural Networks ",
    "url": "https://arxiv.org/abs/2309.15244",
    "authors": [
      "Yahong Yang",
      "Qipin Chen",
      "Wenrui Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.12081",
    "title": "DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical  Optimal Transport Framework",
    "abstract": " Title: DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical  Optimal Transport Framework ",
    "url": "https://arxiv.org/abs/2310.12081",
    "authors": [
      "Haoran Cheng",
      "Dixin Luo",
      "Hongteng Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17974",
    "title": "FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model  for Fault Recognition",
    "abstract": " Comments: The logical flow and background of the article need significant revisions ",
    "url": "https://arxiv.org/abs/2310.17974",
    "authors": [
      "Zeren Zhang",
      "Ran Chen",
      "Jinwen Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.19991",
    "title": "PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices",
    "abstract": " Title: PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices ",
    "url": "https://arxiv.org/abs/2310.19991",
    "authors": [
      "Minghao Yan",
      "Hongyi Wang",
      "Shivaram Venkataraman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2311.02960",
    "title": "Understanding Deep Representation Learning via Layerwise Feature  Compression and Discrimination",
    "abstract": " Comments: 61 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2311.02960",
    "authors": [
      "Peng Wang",
      "Xiao Li",
      "Can Yaras",
      "Zhihui Zhu",
      "Laura Balzano",
      "Wei Hu",
      "Qing Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.03975",
    "title": "Adaptive 3D Geometry-based Stochastic Channel Prediction for 3D DL  Selection",
    "abstract": " Comments: IEEE copyright. This work has been submitted to the IEEE conference for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2311.03975",
    "authors": [
      "Mervat Zarour",
      "Qiuheng Zhou",
      "Sergiy Melnyk",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.14295",
    "title": "Exploiting Active RIS in NOMA Networks with Hardware Impairments",
    "abstract": " Title: Exploiting Active RIS in NOMA Networks with Hardware Impairments ",
    "url": "https://arxiv.org/abs/2311.14295",
    "authors": [
      "Xinwei Yue",
      "Meiqi Song",
      "Chongjun Ouyang",
      "Yuanwei Liu",
      "Tian Li",
      "Tianwei Hou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.01022",
    "title": "Advanced Large Language Model (LLM)-Driven Verilog Development:  Enhancing Power, Performance, and Area Optimization in Code Synthesis",
    "abstract": " Title: Advanced Large Language Model (LLM)-Driven Verilog Development:  Enhancing Power, Performance, and Area Optimization in Code Synthesis ",
    "url": "https://arxiv.org/abs/2312.01022",
    "authors": [
      "Kiran Thorat",
      "Jiahui Zhao",
      "Yaotian Liu",
      "Hongwu Peng",
      "Xi Xie",
      "Bin Lei",
      "Jeff Zhang",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01424",
    "title": "Batch Hop-Constrained s-t Simple Path Query Processing in Large Graphs",
    "abstract": " Title: Batch Hop-Constrained s-t Simple Path Query Processing in Large Graphs ",
    "url": "https://arxiv.org/abs/2312.01424",
    "authors": [
      "Long Yuan",
      "Kongzhang Hao",
      "Xuemin Lin",
      "Wenjie Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2312.01468",
    "title": "Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in  Autonomous Driving",
    "abstract": " Title: Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in  Autonomous Driving ",
    "url": "https://arxiv.org/abs/2312.01468",
    "authors": [
      "Bo Yang",
      "Xiaoyu Ji",
      "Zizhi Jin",
      "Yushi Cheng",
      "Wenyuan Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01592",
    "title": "Expand BERT Representation with Visual Information via Grounded Language  Learning with Multimodal Partial Alignment",
    "abstract": " Title: Expand BERT Representation with Visual Information via Grounded Language  Learning with Multimodal Partial Alignment ",
    "url": "https://arxiv.org/abs/2312.01592",
    "authors": [
      "Cong-Duy Nguyen",
      "The-Anh Vu-Le",
      "Thong Nguyen",
      "Tho Quan",
      "Luu Anh Tuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.07302",
    "title": "From Knowledge Representation to Knowledge Organization and Back",
    "abstract": " Comments: International Conference on Information (iConference) 2024 - Wisdom, Well-being, Win-win - Springer LNCS, Springer Cham Switzerland ",
    "url": "https://arxiv.org/abs/2312.07302",
    "authors": [
      "Fausto Giunchiglia",
      "Mayukh Bagchi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2312.16964",
    "title": "Algorithms for Optimally Shifting Intervals under Intersection Graph  Models",
    "abstract": " Title: Algorithms for Optimally Shifting Intervals under Intersection Graph  Models ",
    "url": "https://arxiv.org/abs/2312.16964",
    "authors": [
      "Nicol\u00e1s Honorato Droguett",
      "Kazuhiro Kurita",
      "Tesshu Hanaka",
      "Hirotaka Ono"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2312.17673",
    "title": "Jatmo: Prompt Injection Defense by Task-Specific Finetuning",
    "abstract": " Comments: 24 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2312.17673",
    "authors": [
      "Julien Piet",
      "Maha Alrashed",
      "Chawin Sitawarin",
      "Sizhe Chen",
      "Zeming Wei",
      "Elizabeth Sun",
      "Basel Alomair",
      "David Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.00897",
    "title": "Masked Modeling for Self-supervised Representation Learning on Vision  and Beyond",
    "abstract": " Comments: Preprint v2 (fix typos and citations). GitHub project at this https URL ",
    "url": "https://arxiv.org/abs/2401.00897",
    "authors": [
      "Siyuan Li",
      "Luyuan Zhang",
      "Zedong Wang",
      "Di Wu",
      "Lirong Wu",
      "Zicheng Liu",
      "Jun Xia",
      "Cheng Tan",
      "Yang Liu",
      "Baigui Sun",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01990",
    "title": "GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised  Learning",
    "abstract": " Title: GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised  Learning ",
    "url": "https://arxiv.org/abs/2401.01990",
    "authors": [
      "Aarash Feizi",
      "Randall Balestriero",
      "Adriana Romero-Soriano",
      "Reihaneh Rabbany"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.02032",
    "title": "DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection",
    "abstract": " Comments: AAAI 2024 ",
    "url": "https://arxiv.org/abs/2401.02032",
    "authors": [
      "Yunfan Ye",
      "Kai Xu",
      "Yuhang Huang",
      "Renjiao Yi",
      "Zhiping Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.02615",
    "title": "AdvSQLi: Generating Adversarial SQL Injections against Real-world  WAF-as-a-service",
    "abstract": " Comments: Accepted by IEEE Transactions on Information Forensics and Security (IEEE TIFS) ",
    "url": "https://arxiv.org/abs/2401.02615",
    "authors": [
      "Zhenqing Qu",
      "Xiang Ling",
      "Ting Wang",
      "Xiang Chen",
      "Shouling Ji",
      "Chunming Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.02791",
    "title": "Weakly Semi-supervised Tool Detection in Minimally Invasive Surgery  Videos",
    "abstract": " Comments: Accepted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2401.02791",
    "authors": [
      "Ryo Fujii",
      "Ryo Hachiuma",
      "Hideo Saito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.03256",
    "title": "An Incrementally Expanding Approach for Updating PageRank on Dynamic  Graphs",
    "abstract": " Comments: 11 pages, 14 figures, 1 table ",
    "url": "https://arxiv.org/abs/2401.03256",
    "authors": [
      "Subhajit Sahu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2401.03369",
    "title": "Multi-Modal Representation Learning for Molecular Property Prediction:  Sequence, Graph, Geometry",
    "abstract": " Comments: 8 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2401.03369",
    "authors": [
      "Zeyu Wang",
      "Tianyi Jiang",
      "Jinhuan Wang",
      "Qi Xuan"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2401.03514",
    "title": "ROIC-DM: Robust Text Inference and Classification via Diffusion Model",
    "abstract": " Comments: under review ",
    "url": "https://arxiv.org/abs/2401.03514",
    "authors": [
      "Shilong Yuan",
      "Wei Yuan",
      "Hongzhi Yin",
      "Tieke He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.03728",
    "title": "Generalized Lagrangian Neural Networks",
    "abstract": " Title: Generalized Lagrangian Neural Networks ",
    "url": "https://arxiv.org/abs/2401.03728",
    "authors": [
      "Shanshan Xiao",
      "Jiawei Zhang",
      "Yifa Tang"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2401.03913",
    "title": "A Wasserstein Graph Distance Based on Distributions of Probabilistic  Node Embeddings",
    "abstract": " Title: A Wasserstein Graph Distance Based on Distributions of Probabilistic  Node Embeddings ",
    "url": "https://arxiv.org/abs/2401.03913",
    "authors": [
      "Michael Scholkemper",
      "Damin K\u00fchn",
      "Gerion Nabbefeld",
      "Simon Musall",
      "Bj\u00f6rn Kampa",
      "Michael T. Schaub"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.03988",
    "title": "A Primer on Temporal Graph Learning",
    "abstract": " Comments: 19 pages, 47 equations ",
    "url": "https://arxiv.org/abs/2401.03988",
    "authors": [
      "Aniq Ur Rahman",
      "Justin P. Coon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  }
]