[
  {
    "id": "arXiv:2401.00004",
    "title": "Informational non-reductionist theory of consciousness that providing  maximum accuracy of reality prediction",
    "abstract": "The paper considers a non-reductionist theory of consciousness, which is not reducible to theories of reality and to physiological or psychological theories. Following D.I.Dubrovsky's \"informational approach\" to the \"Mind-Brain Problem\", we consider the reality through the prism of information about observed phenomena, which, in turn, is perceived by subjective reality through sensations, perceptions, feelings, etc., which, in turn, are information about the corresponding brain processes. Within this framework the following principle of the Information Theory of Consciousness (ITS) development is put forward: the brain discovers all possible causal relations in the external world and makes all possible inferences by them. The paper shows that ITS built on this principle: (1) also base on the information laws of the structure of external world; (2) explains the structure and functioning of the brain functional systems and cellular ensembles; (3) ensures maximum accuracy of predictions and the anticipation of reality; (4) resolves emerging contradictions and (5) is an information theory of the brain's reflection of reality. ",
    "url": "https://arxiv.org/abs/2401.00004",
    "authors": [
      "E.E. Vityaev"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2401.00010",
    "title": "Professional Network Matters: Connections Empower Person-Job Fit",
    "abstract": "Online recruitment platforms typically employ Person-Job Fit models in the core service that automatically match suitable job seekers with appropriate job positions. While existing works leverage historical or contextual information, they often disregard a crucial aspect: job seekers' social relationships in professional networks. This paper emphasizes the importance of incorporating professional networks into the Person-Job Fit model. Our innovative approach consists of two stages: (1) defining a Workplace Heterogeneous Information Network (WHIN) to capture heterogeneous knowledge, including professional connections and pre-training representations of various entities using a heterogeneous graph neural network; (2) designing a Contextual Social Attention Graph Neural Network (CSAGNN) that supplements users' missing information with professional connections' contextual information. We introduce a job-specific attention mechanism in CSAGNN to handle noisy professional networks, leveraging pre-trained entity representations from WHIN. We demonstrate the effectiveness of our approach through experimental evaluations conducted across three real-world recruitment datasets from LinkedIn, showing superior performance compared to baseline models. ",
    "url": "https://arxiv.org/abs/2401.00010",
    "authors": [
      "Hao Chen",
      "Lun Du",
      "Yuxuan Lu",
      "Qiang Fu",
      "Xu Chen",
      "Shi Han",
      "Yanbin Kang",
      "Guangming Lu",
      "Zi Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00027",
    "title": "Efficient Multi-scale Network with Learnable Discrete Wavelet Transform  for Blind Motion Deblurring",
    "abstract": "Coarse-to-fine schemes are widely used in traditional single-image motion deblur; however, in the context of deep learning, existing multi-scale algorithms not only require the use of complex modules for feature fusion of low-scale RGB images and deep semantics, but also manually generate low-resolution pairs of images that do not have sufficient confidence. In this work, we propose a multi-scale network based on single-input and multiple-outputs(SIMO) for motion deblurring. This simplifies the complexity of algorithms based on a coarse-to-fine scheme. To alleviate restoration defects impacting detail information brought about by using a multi-scale architecture, we combine the characteristics of real-world blurring trajectories with a learnable wavelet transform module to focus on the directional continuity and frequency features of the step-by-step transitions between blurred images to sharp images. In conclusion, we propose a multi-scale network with a learnable discrete wavelet transform (MLWNet), which exhibits state-of-the-art performance on multiple real-world deblurred datasets, in terms of both subjective and objective quality as well as computational efficiency. ",
    "url": "https://arxiv.org/abs/2401.00027",
    "authors": [
      "Xin Gao",
      "Tianheng Qiu",
      "Xinyu Zhang",
      "Hanlin Bai",
      "Kang Liu",
      "Xuan Huang",
      "Hu Wei",
      "Guoying Zhang",
      "Huaping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00031",
    "title": "Self-supervised Pretraining for Decision Foundation Model: Formulation,  Pipeline and Challenges",
    "abstract": "Decision-making is a dynamic process requiring perception, memory, and reasoning to make choices and find optimal policies. Traditional approaches to decision-making suffer from sample efficiency and generalization, while large-scale self-supervised pretraining has enabled fast adaptation with fine-tuning or few-shot learning in language and vision. We thus argue to integrate knowledge acquired from generic large-scale self-supervised pretraining into downstream decision-making problems. We propose Pretrain-Then-Adapt pipeline and survey recent work on data collection, pretraining objectives and adaptation strategies for decision-making pretraining and downstream inference. Finally, we identify critical challenges and future directions for developing decision foundation model with the help of generic and flexible self-supervised pretraining. ",
    "url": "https://arxiv.org/abs/2401.00031",
    "authors": [
      "Xiaoqian Liu",
      "Jianbin Jiao",
      "Junge Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00036",
    "title": "Discrete Distribution Networks",
    "abstract": "We introduce a novel generative model, the Discrete Distribution Networks (DDN), that approximates data distribution using hierarchical discrete distributions. We posit that since the features within a network inherently contain distributional information, liberating the network from a single output to concurrently generate multiple samples proves to be highly effective. Therefore, DDN fits the target distribution, including continuous ones, by generating multiple discrete sample points. To capture finer details of the target data, DDN selects the output that is closest to the Ground Truth (GT) from the coarse results generated in the first layer. This selected output is then fed back into the network as a condition for the second layer, thereby generating new outputs more similar to the GT. As the number of DDN layers increases, the representational space of the outputs expands exponentially, and the generated samples become increasingly similar to the GT. This hierarchical output pattern of discrete distributions endows DDN with two intriguing properties: highly compressed representation and more general zero-shot conditional generation. We demonstrate the efficacy of DDN and these intriguing properties through experiments on CIFAR-10 and FFHQ. ",
    "url": "https://arxiv.org/abs/2401.00036",
    "authors": [
      "Lei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00058",
    "title": "Exploring the language of the sharing economy: Building trust and  reducing privacy concern on Airbnb in German and English",
    "abstract": "The text in the profile of those offering their properties in England in English and in Germany in German, are compared to explore whether trust is built, and privacy concerns are reduced in the same way. Six methods of building trust are used by the landlords: (1) the level of formality, (2) distance and proximity, (3) emotiveness and humor, (4) being assertive and passive aggressive, (5) conformity to the platform language style and terminology and (6) setting boundaries. Privacy concerns are not usually reduced directly as this is left to the platform. The findings indicate that language has a limited influence and the platform norms and habits are the biggest influence. ",
    "url": "https://arxiv.org/abs/2401.00058",
    "authors": [
      "Alex Zarifis",
      "Richard Ingham",
      "Julia Kroenung"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.00104",
    "title": "Causal State Distillation for Explainable Reinforcement Learning",
    "abstract": "Reinforcement learning (RL) is a powerful technique for training intelligent agents, but understanding why these agents make specific decisions can be quite challenging. This lack of transparency in RL models has been a long-standing problem, making it difficult for users to grasp the reasons behind an agent's behaviour. Various approaches have been explored to address this problem, with one promising avenue being reward decomposition (RD). RD is appealing as it sidesteps some of the concerns associated with other methods that attempt to rationalize an agent's behaviour in a post-hoc manner. RD works by exposing various facets of the rewards that contribute to the agent's objectives during training. However, RD alone has limitations as it primarily offers insights based on sub-rewards and does not delve into the intricate cause-and-effect relationships that occur within an RL agent's neural model. In this paper, we present an extension of RD that goes beyond sub-rewards to provide more informative explanations. Our approach is centred on a causal learning framework that leverages information-theoretic measures for explanation objectives that encourage three crucial properties of causal factors: \\emph{causal sufficiency}, \\emph{sparseness}, and \\emph{orthogonality}. These properties help us distill the cause-and-effect relationships between the agent's states and actions or rewards, allowing for a deeper understanding of its decision-making processes. Our framework is designed to generate local explanations and can be applied to a wide range of RL tasks with multiple reward channels. Through a series of experiments, we demonstrate that our approach offers more meaningful and insightful explanations for the agent's action selections. ",
    "url": "https://arxiv.org/abs/2401.00104",
    "authors": [
      "Wenhao Lu",
      "Xufeng Zhao",
      "Thilo Fryen",
      "Jae Hee Lee",
      "Mengdi Li",
      "Sven Magg",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2401.00112",
    "title": "Enabling Smart Retrofitting and Performance Anomaly Detection for a  Sensorized Vessel: A Maritime Industry Experience",
    "abstract": "The integration of sensorized vessels, enabling real-time data collection and machine learning-driven data analysis marks a pivotal advancement in the maritime industry. This transformative technology not only can enhance safety, efficiency, and sustainability but also usher in a new era of cost-effective and smart maritime transportation in our increasingly interconnected world. This study presents a deep learning-driven anomaly detection system augmented with interpretable machine learning models for identifying performance anomalies in an industrial sensorized vessel, called TUCANA. We Leverage a human-in-the-loop unsupervised process that involves utilizing standard and Long Short-Term Memory (LSTM) autoencoders augmented with interpretable surrogate models, i.e., random forest and decision tree, to add transparency and interpretability to the results provided by the deep learning models. The interpretable models also enable automated rule generation for translating the inference into human-readable rules. Additionally, the process also includes providing a projection of the results using t-distributed stochastic neighbor embedding (t-SNE), which helps with a better understanding of the structure and relationships within the data and assessment of the identified anomalies. We empirically evaluate the system using real data acquired from the vessel TUCANA and the results involve achieving over 80% precision and 90% recall with the LSTM model used in the process. The interpretable models also provide logical rules aligned with expert thinking, and the t-SNE-based projection enhances interpretability. Our system demonstrates that the proposed approach can be used effectively in real-world scenarios, offering transparency and precision in performance anomaly detection. ",
    "url": "https://arxiv.org/abs/2401.00112",
    "authors": [
      "Mahshid Helali Moghadam",
      "Mateusz Rzymowski",
      "Lukasz Kulas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00137",
    "title": "SSL-OTA: Unveiling Backdoor Threats in Self-Supervised Learning for  Object Detection",
    "abstract": "The extensive adoption of Self-supervised learning (SSL) has led to an increased security threat from backdoor attacks. While existing research has mainly focused on backdoor attacks in image classification, there has been limited exploration into their implications for object detection. In this work, we propose the first backdoor attack designed for object detection tasks in SSL scenarios, termed Object Transform Attack (SSL-OTA). SSL-OTA employs a trigger capable of altering predictions of the target object to the desired category, encompassing two attacks: Data Poisoning Attack (NA) and Dual-Source Blending Attack (DSBA). NA conducts data poisoning during downstream fine-tuning of the object detector, while DSBA additionally injects backdoors into the pre-trained encoder. We establish appropriate metrics and conduct extensive experiments on benchmark datasets, demonstrating the effectiveness and utility of our proposed attack. Notably, both NA and DSBA achieve high attack success rates (ASR) at extremely low poisoning rates (0.5%). The results underscore the importance of considering backdoor threats in SSL-based object detection and contribute a novel perspective to the field. ",
    "url": "https://arxiv.org/abs/2401.00137",
    "authors": [
      "Qiannan Wang",
      "Changchun Yin",
      "Liming Fang",
      "Lu Zhou",
      "Zhe Liu",
      "Run Wang",
      "Chenhao Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00139",
    "title": "Is Knowledge All Large Language Models Needed for Causal Reasoning?",
    "abstract": "This paper explores the causal reasoning of large language models (LLMs) to enhance their interpretability and reliability in advancing artificial intelligence. Despite the proficiency of LLMs in a range of tasks, their potential for understanding causality requires further exploration. We propose a novel causal attribution model that utilizes \"do-operators\" for constructing counterfactual scenarios, allowing us to systematically quantify the influence of input numerical data and LLMs' pre-existing knowledge on their causal reasoning processes. Our newly developed experimental setup assesses LLMs' reliance on contextual information and inherent knowledge across various domains. Our evaluation reveals that LLMs' causal reasoning ability depends on the context and domain-specific knowledge provided, and supports the argument that \"knowledge is, indeed, what LLMs principally require for sound causal reasoning\". On the contrary, in the absence of knowledge, LLMs still maintain a degree of causal reasoning using the available numerical data, albeit with limitations in the calculations. ",
    "url": "https://arxiv.org/abs/2401.00139",
    "authors": [
      "Hengrui Cai",
      "Shengjie Liu",
      "Rui Song"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2401.00148",
    "title": "TPatch: A Triggered Physical Adversarial Patch",
    "abstract": "Autonomous vehicles increasingly utilize the vision-based perception module to acquire information about driving environments and detect obstacles. Correct detection and classification are important to ensure safe driving decisions. Existing works have demonstrated the feasibility of fooling the perception models such as object detectors and image classifiers with printed adversarial patches. However, most of them are indiscriminately offensive to every passing autonomous vehicle. In this paper, we propose TPatch, a physical adversarial patch triggered by acoustic signals. Unlike other adversarial patches, TPatch remains benign under normal circumstances but can be triggered to launch a hiding, creating or altering attack by a designed distortion introduced by signal injection attacks towards cameras. To avoid the suspicion of human drivers and make the attack practical and robust in the real world, we propose a content-based camouflage method and an attack robustness enhancement method to strengthen it. Evaluations with three object detectors, YOLO V3/V5 and Faster R-CNN, and eight image classifiers demonstrate the effectiveness of TPatch in both the simulation and the real world. We also discuss possible defenses at the sensor, algorithm, and system levels. ",
    "url": "https://arxiv.org/abs/2401.00148",
    "authors": [
      "Wenjun Zhu",
      "Xiaoyu Ji",
      "Yushi Cheng",
      "Shibo Zhang",
      "Wenyuan Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00158",
    "title": "ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained  Language Models for Question Answering over Knowledge Graph",
    "abstract": "Question Answering over Knowledge Graph (KGQA) aims to seek answer entities for the natural language question from a large-scale Knowledge Graph~(KG). To better perform reasoning on KG, recent work typically adopts a pre-trained language model~(PLM) to model the question, and a graph neural network~(GNN) based module to perform multi-hop reasoning on the KG. Despite the effectiveness, due to the divergence in model architecture, the PLM and GNN are not closely integrated, limiting the knowledge sharing and fine-grained feature interactions. To solve it, we aim to simplify the above two-module approach, and develop a more capable PLM that can directly support subgraph reasoning for KGQA, namely ReasoningLM. In our approach, we propose a subgraph-aware self-attention mechanism to imitate the GNN for performing structured reasoning, and also adopt an adaptation tuning strategy to adapt the model parameters with 20,000 subgraphs with synthesized questions. After adaptation, the PLM can be parameter-efficient fine-tuned on downstream tasks. Experiments show that ReasoningLM surpasses state-of-the-art models by a large margin, even with fewer updated parameters and less training data. Our codes and data are publicly available at~\\url{https://github.com/RUCAIBox/ReasoningLM}. ",
    "url": "https://arxiv.org/abs/2401.00158",
    "authors": [
      "Jinhao Jiang",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Yaliang Li",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00161",
    "title": "DiffHybrid-UQ: Uncertainty Quantification for Differentiable Hybrid  Neural Modeling",
    "abstract": "The hybrid neural differentiable models mark a significant advancement in the field of scientific machine learning. These models, integrating numerical representations of known physics into deep neural networks, offer enhanced predictive capabilities and show great potential for data-driven modeling of complex physical systems. However, a critical and yet unaddressed challenge lies in the quantification of inherent uncertainties stemming from multiple sources. Addressing this gap, we introduce a novel method, DiffHybrid-UQ, for effective and efficient uncertainty propagation and estimation in hybrid neural differentiable models, leveraging the strengths of deep ensemble Bayesian learning and nonlinear transformations. Specifically, our approach effectively discerns and quantifies both aleatoric uncertainties, arising from data noise, and epistemic uncertainties, resulting from model-form discrepancies and data sparsity. This is achieved within a Bayesian model averaging framework, where aleatoric uncertainties are modeled through hybrid neural models. The unscented transformation plays a pivotal role in enabling the flow of these uncertainties through the nonlinear functions within the hybrid model. In contrast, epistemic uncertainties are estimated using an ensemble of stochastic gradient descent (SGD) trajectories. This approach offers a practical approximation to the posterior distribution of both the network parameters and the physical parameters. Notably, the DiffHybrid-UQ framework is designed for simplicity in implementation and high scalability, making it suitable for parallel computing environments. The merits of the proposed method have been demonstrated through problems governed by both ordinary and partial differentiable equations. ",
    "url": "https://arxiv.org/abs/2401.00161",
    "authors": [
      "Deepak Akhare",
      "Tengfei Luo",
      "Jian-Xun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00163",
    "title": "A clean-label graph backdoor attack method in node classification task",
    "abstract": "Backdoor attacks in the traditional graph neural networks (GNNs) field are easily detectable due to the dilemma of confusing labels. To explore the backdoor vulnerability of GNNs and create a more stealthy backdoor attack method, a clean-label graph backdoor attack method(CGBA) in the node classification task is proposed in this paper. Differently from existing backdoor attack methods, CGBA requires neither modification of node labels nor graph structure. Specifically, to solve the problem of inconsistency between the contents and labels of the samples, CGBA selects poisoning samples in a specific target class and uses the label of sample as the target label (i.e., clean-label) after injecting triggers into the target samples. To guarantee the similarity of neighboring nodes, the raw features of the nodes are elaborately picked as triggers to further improve the concealment of the triggers. Extensive experiments results show the effectiveness of our method. When the poisoning rate is 0.04, CGBA can achieve an average attack success rate of 87.8%, 98.9%, 89.1%, and 98.5%, respectively. ",
    "url": "https://arxiv.org/abs/2401.00163",
    "authors": [
      "Xiaogang Xing",
      "Ming Xu",
      "Yujing Bai",
      "Dongdong Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00164",
    "title": "Causal Stream Inclusions",
    "abstract": "We study solutions to systems of stream inclusions 'f in T(f)', where T is assumed to be causal in the sense that elements in output streams are determined by a finite history of inputs. For solving these inclusions we develop a correspondence of causality and contraction with respect to the prefix distance on streams. Now, based on this causality-contraction correspondence, we apply fixpoint principles for the spherically complete ultrametric space of streams to obtain solutions for causal stream inclusions. The underlying fixpoint iterations induce fixpoint induction principles for reasoning about solutions of causal stream inclusions. In addition, these fixpoint approximations induce anytime algorithms for computing finite stream prefixes of solutions. We illustrate the use of these developments for some central concepts of system design. ",
    "url": "https://arxiv.org/abs/2401.00164",
    "authors": [
      "Harald Ruess"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2401.00170",
    "title": "L3Cube-MahaSocialNER: A Social Media based Marathi NER Dataset and BERT  models",
    "abstract": "This work introduces the L3Cube-MahaSocialNER dataset, the first and largest social media dataset specifically designed for Named Entity Recognition (NER) in the Marathi language. The dataset comprises 18,000 manually labeled sentences covering eight entity classes, addressing challenges posed by social media data, including non-standard language and informal idioms. Deep learning models, including CNN, LSTM, BiLSTM, and Transformer models, are evaluated on the individual dataset with IOB and non-IOB notations. The results demonstrate the effectiveness of these models in accurately recognizing named entities in Marathi informal text. The L3Cube-MahaSocialNER dataset offers user-centric information extraction and supports real-time applications, providing a valuable resource for public opinion analysis, news, and marketing on social media platforms. We also show that the zero-shot results of the regular NER model are poor on the social NER test set thus highlighting the need for more social NER datasets. The datasets and models are publicly available at https://github.com/l3cube-pune/MarathiNLP ",
    "url": "https://arxiv.org/abs/2401.00170",
    "authors": [
      "Harsh Chaudhari",
      "Anuja Patil",
      "Dhanashree Lavekar",
      "Pranav Khairnar",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00180",
    "title": "Auxiliary Network-Enabled Attack Detection and Resilient Control of  Islanded AC Microgrid",
    "abstract": "This paper proposes a cyber-resilient distributed control strategy equipped with attack detection capabilities for islanded AC microgrids in the presence of bounded stealthy cyber attacks affecting both frequency and power information exchanged among neighboring distributed generators (DGs). The proposed control methodology relies on the construction of an auxiliary layer and the establishment of effective inter-layer cooperation between the actual DGs in the control layer and the virtual DGs in the auxiliary layer. This cooperation aims to achieve robust frequency restoration and proportional active power-sharing. It is shown that the in situ presence of a concealed auxiliary layer not only guarantees resilience against stealthy bounded attacks on both frequency and power-sharing but also facilitates a network-enabled attack identification mechanism. The paper provides rigorous proof of the stability of the closed-loop system and derives bounds for frequency and power deviations under attack conditions, offering insights into the impact of the attack signal, control and pinning gains, and network connectivity on the system's convergence properties. The performance of the proposed controllers is illustrated by simulating a networked islanded AC microgrid in a Simulink environment showcasing both attributes of attack resilience and attack detection. ",
    "url": "https://arxiv.org/abs/2401.00180",
    "authors": [
      "Vaibhav Vaishnav",
      "Anoop Jain",
      "Dushyant Sharma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.00186",
    "title": "A Novel Explanation Against Linear Neural Networks",
    "abstract": "Linear Regression and neural networks are widely used to model data. Neural networks distinguish themselves from linear regression with their use of activation functions that enable modeling nonlinear functions. The standard argument for these activation functions is that without them, neural networks only can model a line. However, a novel explanation we propose in this paper for the impracticality of neural networks without activation functions, or linear neural networks, is that they actually reduce both training and testing performance. Having more parameters makes LNNs harder to optimize, and thus they require more training iterations than linear regression to even potentially converge to the optimal solution. We prove this hypothesis through an analysis of the optimization of an LNN and rigorous testing comparing the performance between both LNNs and linear regression on synthethic, noisy datasets. ",
    "url": "https://arxiv.org/abs/2401.00186",
    "authors": [
      "Anish Lakkapragada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00192",
    "title": "Real-Time and Security-Aware Precoding in RIS-Empowered Multi-User  Wireless Networks",
    "abstract": "In this letter, we propose a deep-unfolding-based framework (DUNet) to maximize the secrecy rate in reconfigurable intelligent surface (RIS) empowered multi-user wireless networks. To tailor DUNet, first we relax the problem, decouple it into beamforming and phase shift subproblems, and propose an alternative optimization (AO) based solution for the relaxed problem. Second, we apply Karush-Kuhn-Tucker (KKT) conditions to obtain a closed-form solutions for the beamforming and the phase shift. Using deep-unfolding mechanism, we transform the closed-form solutions into a deep learning model (i.e., DUNet) that achieves a comparable performance to that of AO in terms of accuracy and about 25.6 times faster. ",
    "url": "https://arxiv.org/abs/2401.00192",
    "authors": [
      "Abuzar B. M. Adam",
      "Mohamed Amine Ouamri",
      "Mohammed Saleh Ali Muthanna",
      "Xingwang Li",
      "Mohammed A. M. Elhassan",
      "Ammar Muthanna"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.00237",
    "title": "A Novel Approach for Defect Detection of Wind Turbine Blade Using  Virtual Reality and Deep Learning",
    "abstract": "Wind turbines are subjected to continuous rotational stresses and unusual external forces such as storms, lightning, strikes by flying objects, etc., which may cause defects in turbine blades. Hence, it requires a periodical inspection to ensure proper functionality and avoid catastrophic failure. The task of inspection is challenging due to the remote location and inconvenient reachability by human inspection. Researchers used images with cropped defects from the wind turbine in the literature. They neglected possible background biases, which may hinder real-time and autonomous defect detection using aerial vehicles such as drones or others. To overcome such challenges, in this paper, we experiment with defect detection accuracy by having the defects with the background using a two-step deep-learning methodology. In the first step, we develop virtual models of wind turbines to synthesize the near-reality images for four types of common defects - cracks, leading edge erosion, bending, and light striking damage. The Unity perception package is used to generate wind turbine blade defects images with variations in background, randomness, camera angle, and light effects. In the second step, a customized U-Net architecture is trained to classify and segment the defect in turbine blades. The outcomes of U-Net architecture have been thoroughly tested and compared with 5-fold validation datasets. The proposed methodology provides reasonable defect detection accuracy, making it suitable for autonomous and remote inspection through aerial vehicles. ",
    "url": "https://arxiv.org/abs/2401.00237",
    "authors": [
      "Md Fazle Rabbi",
      "Solayman Hossain Emon",
      "Ehtesham Mahmud Nishat",
      "Tzu-Liang",
      "Tseng",
      "Atira Ferdoushi",
      "Chun-Che Huang",
      "Md Fashiar Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2401.00241",
    "title": "Image Super-resolution Reconstruction Network based on Enhanced Swin  Transformer via Alternating Aggregation of Local-Global Features",
    "abstract": "The Swin Transformer image super-resolution reconstruction network only relies on the long-range relationship of window attention and shifted window attention to explore features. This mechanism has two limitations. On the one hand, it only focuses on global features while ignoring local features. On the other hand, it is only concerned with spatial feature interactions while ignoring channel features and channel interactions, thus limiting its non-linear mapping ability. To address the above limitations, this paper proposes enhanced Swin Transformer modules via alternating aggregation of local-global features. In the local feature aggregation stage, this paper introduces shift convolution to realize the interaction between local spatial information and channel information. This paper proposes a block sparse global perception module in the global feature aggregation stage. This module organizes the spatial information first, then sends the recombination information into a spatial gating unit to implement the further interaction of spatial and channel information. Then, a multi-scale self-attention module and a low-parameter residual channel attention module are introduced to realize information aggregation at different scales. Finally, the proposed network is validated on five publicly available datasets. The experimental results show that the proposed network outperforms the other state-of-the-art super-resolution networks. ",
    "url": "https://arxiv.org/abs/2401.00241",
    "authors": [
      "Yuming Huang",
      "Yingpin Chen",
      "Changhui Wu",
      "Hanrong Xie",
      "Binhui Song",
      "Hui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00283",
    "title": "Near-Space Communications: The Last Piece of 6G Space-Air-Ground-Sea  Integrated Network Puzzle",
    "abstract": "This article presents a comprehensive study on the emerging near-space communications (NS-COM) within the context of space-air-ground-sea integrated network (SAGSIN). Specifically, we firstly explore the recent technical developments of NS-COM, followed by the discussions about motivations behind integrating NS-COM into SAGSIN. To further demonstrate the necessity of NS-COM, a comparative analysis between the NS-COM network and other counterparts in SAGSIN is conducted, covering aspects of deployment, coverage and channel characteristics. Afterwards, the technical aspects of NS-COM, including channel modeling, random access, channel estimation, array-based beam management and joint network optimization, are examined in detail. Furthermore, we explore the potential applications of NS-COM, such as structural expansion in SAGSIN communications, remote and urgent communications, weather monitoring and carbon neutrality. Finally, some promising research avenues are identified, including near-space-ground direct links, reconfigurable multiple input multiple output (MIMO) array, federated learning assisted NS-COM, maritime communication and free space optical (FSO) communication. Overall, this paper highlights that the NS-COM plays an indispensable role in the SAGSIN puzzle, providing substantial performance and coverage enhancement to the traditional SAGSIN architecture. ",
    "url": "https://arxiv.org/abs/2401.00283",
    "authors": [
      "Hongshan Liu",
      "Tong Qin",
      "Zhen Gao",
      "Keke Ying",
      "Ziwei Wan",
      "Jingjing Zhao",
      "Rui Na",
      "Zhongxiang Li",
      "Gaojie Chen",
      "Chun Hu",
      "Ruiqi Liu",
      "Yikun Mei",
      "Tuan Li",
      "Tianqi Mao",
      "Shuo Wang",
      "Dezhi Zheng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.00284",
    "title": "Evaluation is all you need. Prompting Generative Large Language Models  for Annotation Tasks in the Social Sciences. A Primer using Open Models",
    "abstract": "This paper explores the use of open generative Large Language Models (LLMs) for annotation tasks in the social sciences. The study highlights the challenges associated with proprietary models, such as limited reproducibility and privacy concerns, and advocates for the adoption of open (source) models that can be operated on independent devices. Two examples of annotation tasks, sentiment analysis in tweets and identification of leisure activities in childhood aspirational essays are provided. The study evaluates the performance of different prompting strategies and models (neural-chat-7b-v3-2, Starling-LM-7B-alpha, openchat_3.5, zephyr-7b-alpha and zephyr-7b-beta). The results indicate the need for careful validation and tailored prompt engineering. The study highlights the advantages of open models for data privacy and reproducibility. ",
    "url": "https://arxiv.org/abs/2401.00284",
    "authors": [
      "Maximilian Weber",
      "Merle Reichardt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.00287",
    "title": "The Art of Defending: A Systematic Evaluation and Analysis of LLM  Defense Strategies on Safety and Over-Defensiveness",
    "abstract": "As Large Language Models (LLMs) play an increasingly pivotal role in natural language processing applications, their safety concerns become critical areas of NLP research. This paper presents Safety and Over-Defensiveness Evaluation (SODE) benchmark: a collection of diverse safe and unsafe prompts with carefully designed evaluation methods that facilitate systematic evaluation, comparison, and analysis over 'safety' and 'over-defensiveness.' With SODE, we study a variety of LLM defense strategies over multiple state-of-the-art LLMs, which reveals several interesting and important findings, such as (a) the widely popular 'self-checking' techniques indeed improve the safety against unsafe inputs, but this comes at the cost of extreme over-defensiveness on the safe inputs, (b) providing a safety instruction along with in-context exemplars (of both safe and unsafe inputs) consistently improves safety and also mitigates undue over-defensiveness of the models, (c) providing contextual knowledge easily breaks the safety guardrails and makes the models more vulnerable to generating unsafe responses. Overall, our work reveals numerous such critical findings that we believe will pave the way and facilitate further research in improving the safety of LLMs. ",
    "url": "https://arxiv.org/abs/2401.00287",
    "authors": [
      "Neeraj Varshney",
      "Pavel Dolin",
      "Agastya Seth",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.00288",
    "title": "Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit",
    "abstract": "Code intelligence leverages machine learning techniques to extract knowledge from extensive code corpora, with the aim of developing intelligent tools to improve the quality and productivity of computer programming. Currently, there is already a thriving research community focusing on code intelligence, with efforts ranging from software engineering, machine learning, data mining, natural language processing, and programming languages. In this paper, we conduct a comprehensive literature review on deep learning for code intelligence, from the aspects of code representation learning, deep learning techniques, and application tasks. We also benchmark several state-of-the-art neural models for code intelligence, and provide an open-source toolkit tailored for the rapid prototyping of deep-learning-based code intelligence models. In particular, we inspect the existing code intelligence models under the basis of code representation learning, and provide a comprehensive overview to enhance comprehension of the present state of code intelligence. Furthermore, we publicly release the source code and data resources to provide the community with a ready-to-use benchmark, which can facilitate the evaluation and comparison of existing and future code intelligence models (https://xcodemind.github.io). At last, we also point out several challenging and promising directions for future research. ",
    "url": "https://arxiv.org/abs/2401.00288",
    "authors": [
      "Yao Wan",
      "Yang He",
      "Zhangqian Bi",
      "Jianguo Zhang",
      "Hongyu Zhang",
      "Yulei Sui",
      "Guandong Xu",
      "Hai Jin",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00297",
    "title": "A Novel Reinforcement Learning Routing Algorithm for Congestion Control  in Complex Networks",
    "abstract": "Despite technological advancements, the significance of interdisciplinary subjects like complex networks has grown. Exploring communication within these networks is crucial, with traffic becoming a key concern due to the expanding population and increased need for connections. Congestion tends to originate in specific network areas but quickly proliferates throughout. Consequently, understanding the transition from a flow-free state to a congested state is vital. Numerous studies have delved into comprehending the emergence and control of congestion in complex networks, falling into three general categories: soft strategies, hard strategies, and resource allocation strategies. This article introduces a routing algorithm leveraging reinforcement learning to address two primary objectives: congestion control and optimizing path length based on the shortest path algorithm, ultimately enhancing network throughput compared to previous methods. Notably, the proposed method proves effective not only in Barab\\'asi-Albert scale-free networks but also in other network models such as Watts-Strogatz (small-world) and Erd\\\"os-R\\'enyi (random network). Simulation experiment results demonstrate that, across various traffic scenarios and network topologies, the proposed method can enhance efficiency criteria by up to 30% while reducing maximum node congestion by five times. ",
    "url": "https://arxiv.org/abs/2401.00297",
    "authors": [
      "Seyed Hassan Yajadda",
      "Farshad Safaei"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00316",
    "title": "RASP for LSASS: Preventing Mimikatz-Related Attacks",
    "abstract": "The Windows authentication infrastructure relies on the Local Security Authority (LSA) system, with its integral component being lsass.exe. Regrettably, this framework is not impervious, presenting vulnerabilities that attract threat actors with malicious intent. By exploiting documented vulnerabilities sourced from the CVE database or leveraging sophisticated tools such as mimikatz, adversaries can successfully compromise user password-address information. In this comprehensive analysis, we delve into proactive measures aimed at fortifying the local authentication subsystem against potential threats. Moreover, we present empirical evidence derived from practical assessments of various defensive methodologies, including those articulated previously. This examination not only underscores the importance of proactive security measures but also assesses the practical efficacy of these strategies in real-world contexts. ",
    "url": "https://arxiv.org/abs/2401.00316",
    "authors": [
      "Anna Revazova",
      "Igor Korkin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2401.00334",
    "title": "Explainability-Driven Leaf Disease Classification using Adversarial  Training and Knowledge Distillation",
    "abstract": "This work focuses on plant leaf disease classification and explores three crucial aspects: adversarial training, model explainability, and model compression. The models' robustness against adversarial attacks is enhanced through adversarial training, ensuring accurate classification even in the presence of threats. Leveraging explainability techniques, we gain insights into the model's decision-making process, improving trust and transparency. Additionally, we explore model compression techniques to optimize computational efficiency while maintaining classification performance. Through our experiments, we determine that on a benchmark dataset, the robustness can be the price of the classification accuracy with performance reductions of 3%-20% for regular tests and gains of 50%-70% for adversarial attack tests. We also demonstrate that a student model can be 15-25 times more computationally efficient for a slight performance reduction, distilling the knowledge of more complex models. ",
    "url": "https://arxiv.org/abs/2401.00334",
    "authors": [
      "Sebastian-Vasile Echim",
      "Iulian-Marius T\u0103iatu",
      "Dumitru-Clementin Cercel",
      "Florin Pop"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00343",
    "title": "SHARE: Single-view Human Adversarial REconstruction",
    "abstract": "The accuracy of 3D Human Pose and Shape reconstruction (HPS) from an image is progressively improving. Yet, no known method is robust across all image distortion. To address issues due to variations of camera poses, we introduce SHARE, a novel fine-tuning method that utilizes adversarial data augmentation to enhance the robustness of existing HPS techniques. We perform a comprehensive analysis on the impact of camera poses on HPS reconstruction outcomes. We first generated large-scale image datasets captured systematically from diverse camera perspectives. We then established a mapping between camera poses and reconstruction errors as a continuous function that characterizes the relationship between camera poses and HPS quality. Leveraging this representation, we introduce RoME (Regions of Maximal Error), a novel sampling technique for our adversarial fine-tuning method. The SHARE framework is generalizable across various single-view HPS methods and we demonstrate its performance on HMR, SPIN, PARE, CLIFF and ExPose. Our results illustrate a reduction in mean joint errors across single-view HPS techniques, for images captured from multiple camera positions without compromising their baseline performance. In many challenging cases, our method surpasses the performance of existing models, highlighting its practical significance for diverse real-world applications. ",
    "url": "https://arxiv.org/abs/2401.00343",
    "authors": [
      "Shreelekha Revankar",
      "Shijia Liao",
      "Yu Shen",
      "Junbang Liang",
      "Huaishu Peng",
      "Ming Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00365",
    "title": "HQ-VAE: Hierarchical Discrete Representation Learning with Variational  Bayes",
    "abstract": "Vector quantization (VQ) is a technique to deterministically learn features with discrete codebook representations. It is commonly performed with a variational autoencoding model, VQ-VAE, which can be further extended to hierarchical structures for making high-fidelity reconstructions. However, such hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse issue, where the codebook is not efficiently used to express the data, and hence degrades reconstruction accuracy. To mitigate this problem, we propose a novel unified framework to stochastically learn hierarchical discrete representation on the basis of the variational Bayes framework, called hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training scheme. Our comprehensive experiments on image datasets show that HQ-VAE enhances codebook usage and improves reconstruction performance. We also validated HQ-VAE in terms of its applicability to a different modality with an audio dataset. ",
    "url": "https://arxiv.org/abs/2401.00365",
    "authors": [
      "Yuhta Takida",
      "Yukara Ikemiya",
      "Takashi Shibuya",
      "Kazuki Shimada",
      "Woosung Choi",
      "Chieh-Hsin Lai",
      "Naoki Murata",
      "Toshimitsu Uesaka",
      "Kengo Uchida",
      "Wei-Hsiang Liao",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00369",
    "title": "Analysis of biologically plausible neuron models for regression with  spiking neural networks",
    "abstract": "This paper explores the impact of biologically plausible neuron models on the performance of Spiking Neural Networks (SNNs) for regression tasks. While SNNs are widely recognized for classification tasks, their application to Scientific Machine Learning and regression remains underexplored. We focus on the membrane component of SNNs, comparing four neuron models: Leaky Integrate-and-Fire, FitzHugh-Nagumo, Izhikevich, and Hodgkin-Huxley. We investigate their effect on SNN accuracy and efficiency for function regression tasks, by using Euler and Runge-Kutta 4th-order approximation schemes. We show how more biologically plausible neuron models improve the accuracy of SNNs while reducing the number of spikes in the system. The latter represents an energetic gain on actual neuromorphic chips since it directly reflects the amount of energy required for the computations. ",
    "url": "https://arxiv.org/abs/2401.00369",
    "authors": [
      "Mario De Florio",
      "Adar Kahana",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2401.00371",
    "title": "Multi-Granularity Representation Learning for Sketch-based Dynamic Face  Image Retrieval",
    "abstract": "In specific scenarios, face sketch can be used to identify a person. However, drawing a face sketch often requires exceptional skill and is time-consuming, limiting its widespread applications in actual scenarios. The new framework of sketch less face image retrieval (SLFIR)[1] attempts to overcome the barriers by providing a means for humans and machines to interact during the drawing process. Considering SLFIR problem, there is a large gap between a partial sketch with few strokes and any whole face photo, resulting in poor performance at the early stages. In this study, we propose a multigranularity (MG) representation learning (MGRL) method to address the SLFIR problem, in which we learn the representation of different granularity regions for a partial sketch, and then, by combining all MG regions of the sketches and images, the final distance was determined. In the experiments, our method outperformed state-of-the-art baselines in terms of early retrieval on two accessible datasets. Codes are available at https://github.com/ddw2AIGROUP2CQUPT/MGRL. ",
    "url": "https://arxiv.org/abs/2401.00371",
    "authors": [
      "Liang Wang",
      "Dawei Dai",
      "Shiyu Fu",
      "Guoyin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00393",
    "title": "Generative Model-Driven Synthetic Training Image Generation: An Approach  to Cognition in Rail Defect Detection",
    "abstract": "Recent advancements in cognitive computing, with the integration of deep learning techniques, have facilitated the development of intelligent cognitive systems (ICS). This is particularly beneficial in the context of rail defect detection, where the ICS would emulate human-like analysis of image data for defect patterns. Despite the success of Convolutional Neural Networks (CNN) in visual defect classification, the scarcity of large datasets for rail defect detection remains a challenge due to infrequent accident events that would result in defective parts and images. Contemporary researchers have addressed this data scarcity challenge by exploring rule-based and generative data augmentation models. Among these, Variational Autoencoder (VAE) models can generate realistic data without extensive baseline datasets for noise modeling. This study proposes a VAE-based synthetic image generation technique for rail defects, incorporating weight decay regularization and image reconstruction loss to prevent overfitting. The proposed method is applied to create a synthetic dataset for the Canadian Pacific Railway (CPR) with just 50 real samples across five classes. Remarkably, 500 synthetic samples are generated with a minimal reconstruction loss of 0.021. A Visual Transformer (ViT) model underwent fine-tuning using this synthetic CPR dataset, achieving high accuracy rates (98%-99%) in classifying the five defect classes. This research offers a promising solution to the data scarcity challenge in rail defect detection, showcasing the potential for robust ICS development in this domain. ",
    "url": "https://arxiv.org/abs/2401.00393",
    "authors": [
      "Rahatara Ferdousi",
      "Chunsheng Yang",
      "M. Anwar Hossain",
      "Fedwa Laamarti",
      "M. Shamim Hossain",
      "Abdulmotaleb El Saddik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2401.00401",
    "title": "Multiplayer Battle Game-Inspired Optimizer for Complex Optimization  Problems",
    "abstract": "Various popular multiplayer battle royale games share a lot of common elements. Drawing from our observations, we summarized these shared characteristics and subsequently proposed a novel heuristic algorithm named multiplayer battle game-inspired optimizer (MBGO). The proposed MBGO streamlines mainstream multiplayer battle royale games into two discrete phases: movement and battle. Specifically, the movement phase incorporates the principles of commonly encountered ``safe zones'' to incentivize participants to relocate to areas with a higher survival potential. The battle phase simulates a range of strategies adopted by players in various situations to enhance the diversity of the population. To evaluate and analyze the performance of the proposed MBGO, we executed it alongside eight other algorithms, including three classics and five latest ones, across multiple diverse dimensions within the CEC2017 and CEC2020 benchmark functions. In addition, we employed several industrial design problems to evaluate the scalability and practicality of the proposed MBGO. The results of the statistical analysis reveal that the novel MBGO demonstrates significant competitiveness, excelling not only in convergence speed, but also in achieving high levels of convergence accuracy across both benchmark functions and real-world problems. ",
    "url": "https://arxiv.org/abs/2401.00401",
    "authors": [
      "Yuefeng Xu",
      "Rui Zhong",
      "Chao Zhang",
      "Jun Yu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2401.00406",
    "title": "Low-cost Geometry-based Eye Gaze Detection using Facial Landmarks  Generated through Deep Learning",
    "abstract": "Introduction: In the realm of human-computer interaction and behavioral research, accurate real-time gaze estimation is critical. Traditional methods often rely on expensive equipment or large datasets, which are impractical in many scenarios. This paper introduces a novel, geometry-based approach to address these challenges, utilizing consumer-grade hardware for broader applicability. Methods: We leverage novel face landmark detection neural networks capable of fast inference on consumer-grade chips to generate accurate and stable 3D landmarks of the face and iris. From these, we derive a small set of geometry-based descriptors, forming an 8-dimensional manifold representing the eye and head movements. These descriptors are then used to formulate linear equations for predicting eye-gaze direction. Results: Our approach demonstrates the ability to predict gaze with an angular error of less than 1.9 degrees, rivaling state-of-the-art systems while operating in real-time and requiring negligible computational resources. Conclusion: The developed method marks a significant step forward in gaze estimation technology, offering a highly accurate, efficient, and accessible alternative to traditional systems. It opens up new possibilities for real-time applications in diverse fields, from gaming to psychological research. ",
    "url": "https://arxiv.org/abs/2401.00406",
    "authors": [
      "Esther Enhui Ye",
      "John Enzhou Ye",
      "Joseph Ye",
      "Jacob Ye",
      "Runzhou Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00409",
    "title": "A Two-stream Hybrid CNN-Transformer Network for Skeleton-based Human  Interaction Recognition",
    "abstract": "Human Interaction Recognition is the process of identifying interactive actions between multiple participants in a specific situation. The aim is to recognise the action interactions between multiple entities and their meaning. Many single Convolutional Neural Network has issues, such as the inability to capture global instance interaction features or difficulty in training, leading to ambiguity in action semantics. In addition, the computational complexity of the Transformer cannot be ignored, and its ability to capture local information and motion features in the image is poor. In this work, we propose a Two-stream Hybrid CNN-Transformer Network (THCT-Net), which exploits the local specificity of CNN and models global dependencies through the Transformer. CNN and Transformer simultaneously model the entity, time and space relationships between interactive entities respectively. Specifically, Transformer-based stream integrates 3D convolutions with multi-head self-attention to learn inter-token correlations; We propose a new multi-branch CNN framework for CNN-based streams that automatically learns joint spatio-temporal features from skeleton sequences. The convolutional layer independently learns the local features of each joint neighborhood and aggregates the features of all joints. And the raw skeleton coordinates as well as their temporal difference are integrated with a dual-branch paradigm to fuse the motion features of the skeleton. Besides, a residual structure is added to speed up training convergence. Finally, the recognition results of the two branches are fused using parallel splicing. Experimental results on diverse and challenging datasets, demonstrate that the proposed method can better comprehend and infer the meaning and context of various actions, outperforming state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2401.00409",
    "authors": [
      "Ruoqi Yin",
      "Jianqin Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00414",
    "title": "Is It Possible to Backdoor Face Forgery Detection with Natural Triggers?",
    "abstract": "Deep neural networks have significantly improved the performance of face forgery detection models in discriminating Artificial Intelligent Generated Content (AIGC). However, their security is significantly threatened by the injection of triggers during model training (i.e., backdoor attacks). Although existing backdoor defenses and manual data selection can mitigate those using human-eye-sensitive triggers, such as patches or adversarial noises, the more challenging natural backdoor triggers remain insufficiently researched. To further investigate natural triggers, we propose a novel analysis-by-synthesis backdoor attack against face forgery detection models, which embeds natural triggers in the latent space. We thoroughly study such backdoor vulnerability from two perspectives: (1) Model Discrimination (Optimization-Based Trigger): we adopt a substitute detection model and find the trigger by minimizing the cross-entropy loss; (2) Data Distribution (Custom Trigger): we manipulate the uncommon facial attributes in the long-tailed distribution to generate poisoned samples without the supervision from detection models. Furthermore, to completely evaluate the detection models towards the latest AIGC, we utilize both state-of-the-art StyleGAN and Stable Diffusion for trigger generation. Finally, these backdoor triggers introduce specific semantic features to the generated poisoned samples (e.g., skin textures and smile), which are more natural and robust. Extensive experiments show that our method is superior from three levels: (1) Attack Success Rate: ours achieves a high attack success rate (over 99%) and incurs a small model accuracy drop (below 0.2%) with a low poisoning rate (less than 3%); (2) Backdoor Defense: ours shows better robust performance when faced with existing backdoor defense methods; (3) Human Inspection: ours is less human-eye-sensitive from a comprehensive user study. ",
    "url": "https://arxiv.org/abs/2401.00414",
    "authors": [
      "Xiaoxuan Han",
      "Songlin Yang",
      "Wei Wang",
      "Ziwen He",
      "Jing Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00416",
    "title": "SVFAP: Self-supervised Video Facial Affect Perceiver",
    "abstract": "Video-based facial affect analysis has recently attracted increasing attention owing to its critical role in human-computer interaction. Previous studies mainly focus on developing various deep learning architectures and training them in a fully supervised manner. Although significant progress has been achieved by these supervised methods, the longstanding lack of large-scale high-quality labeled data severely hinders their further improvements. Motivated by the recent success of self-supervised learning in computer vision, this paper introduces a self-supervised approach, termed Self-supervised Video Facial Affect Perceiver (SVFAP), to address the dilemma faced by supervised methods. Specifically, SVFAP leverages masked facial video autoencoding to perform self-supervised pre-training on massive unlabeled facial videos. Considering that large spatiotemporal redundancy exists in facial videos, we propose a novel temporal pyramid and spatial bottleneck Transformer as the encoder of SVFAP, which not only enjoys low computational cost but also achieves excellent performance. To verify the effectiveness of our method, we conduct experiments on nine datasets spanning three downstream tasks, including dynamic facial expression recognition, dimensional emotion recognition, and personality recognition. Comprehensive results demonstrate that SVFAP can learn powerful affect-related representations via large-scale self-supervised pre-training and it significantly outperforms previous state-of-the-art methods on all datasets. Codes will be available at https://github.com/sunlicai/SVFAP. ",
    "url": "https://arxiv.org/abs/2401.00416",
    "authors": [
      "Licai Sun",
      "Zheng Lian",
      "Kexin Wang",
      "Yu He",
      "Mingyu Xu",
      "Haiyang Sun",
      "Bin Liu",
      "Jianhua Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2401.00424",
    "title": "SDIF-DA: A Shallow-to-Deep Interaction Framework with Data Augmentation  for Multi-modal Intent Detection",
    "abstract": "Multi-modal intent detection aims to utilize various modalities to understand the user's intentions, which is essential for the deployment of dialogue systems in real-world scenarios. The two core challenges for multi-modal intent detection are (1) how to effectively align and fuse different features of modalities and (2) the limited labeled multi-modal intent training data. In this work, we introduce a shallow-to-deep interaction framework with data augmentation (SDIF-DA) to address the above challenges. Firstly, SDIF-DA leverages a shallow-to-deep interaction module to progressively and effectively align and fuse features across text, video, and audio modalities. Secondly, we propose a ChatGPT-based data augmentation approach to automatically augment sufficient training data. Experimental results demonstrate that SDIF-DA can effectively align and fuse multi-modal features by achieving state-of-the-art performance. In addition, extensive analyses show that the introduced data augmentation approach can successfully distill knowledge from the large language model. ",
    "url": "https://arxiv.org/abs/2401.00424",
    "authors": [
      "Shijue Huang",
      "Libo Qin",
      "Bingbing Wang",
      "Geng Tu",
      "Ruifeng Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.00429",
    "title": "Deeper and Wider Networks for Performance Metrics Prediction in  Communication Networks",
    "abstract": "In today's era, users have increasingly high expectations regarding the performance and efficiency of communication networks. Network operators aspire to achieve efficient network planning, operation, and optimization through Digital Twin Networks (DTN). The effectiveness of DTN heavily relies on the network model, with graph neural networks (GNN) playing a crucial role in network modeling. However, existing network modeling methods still lack a comprehensive understanding of communication networks. In this paper, we propose DWNet (Deeper and Wider Networks), a heterogeneous graph neural network modeling method based on data-driven approaches that aims to address end-to-end latency and jitter prediction in network models. This method stands out due to two distinctive features: firstly, it introduces deeper levels of state participation in the message passing process; secondly, it extensively integrates relevant features during the feature fusion process. Through experimental validation and evaluation, our model achieves higher prediction accuracy compared to previous research achievements, particularly when dealing with unseen network topologies during model training. Our model not only provides more accurate predictions but also demonstrates stronger generalization capabilities across diverse topological structures. ",
    "url": "https://arxiv.org/abs/2401.00429",
    "authors": [
      "Aijia Liu",
      "Shiqing Liu",
      "Xiaobing Pei"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.00438",
    "title": "SFGANS Self-supervised Future Generator for human ActioN Segmentation",
    "abstract": "The ability to locate and classify action segments in long untrimmed video is of particular interest to many applications such as autonomous cars, robotics and healthcare applications. Today, the most popular pipeline for action segmentation is composed of encoding the frames into feature vectors, which are then processed by a temporal model for segmentation. In this paper we present a self-supervised method that comes in the middle of the standard pipeline and generated refined representations of the original feature vectors. Experiments show that this method improves the performance of existing models on different sub-tasks of action segmentation, even without additional hyper parameter tuning. ",
    "url": "https://arxiv.org/abs/2401.00438",
    "authors": [
      "Or Berman",
      "Adam Goldbraikh",
      "Shlomi Laufer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00449",
    "title": "Teaching Digital Accessibility to Industry Professionals using the  Community of Practice Framework: An Experience Report",
    "abstract": "Despite recent initiatives aimed at improving accessibility, the field of digital accessibility remains markedly behind contemporary advancements in the software industry as a large number of real world software and web applications continue to fall short of accessibility requirements. A persisting skills deficit within the existing technology workforce has been an enduring impediment, hindering organizations from delivering truly accessible software products. This, in turn, elevates the risk of isolating and excluding a substantial portion of potential users. In this paper, we report lessons learned from a training program for teaching digital accessibility using the Communities of Practice (CoP) framework to industry professionals. We recruited 66 participants from a large multi-national software company and assigned them to two groups: one participating in a CoP and the other using self-paced learning. We report experiences from designing the training program, conducting the actual training, and assessing the efficiency of the two approaches. Based on these findings, we provide recommendations for practitioners in Learning and Development teams and educators in designing accessibility courses for industry professionals. ",
    "url": "https://arxiv.org/abs/2401.00449",
    "authors": [
      "Parthasarathy PD",
      "Swaroop Joshi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.00463",
    "title": "Analyzing Local Representations of Self-supervised Vision Transformers",
    "abstract": "In this paper, we present a comparative analysis of various self-supervised Vision Transformers (ViTs), focusing on their local representative power. Inspired by large language models, we examine the abilities of ViTs to perform various computer vision tasks with little to no fine-tuning. We design an evaluation framework to analyze the quality of local, i.e. patch-level, representations in the context of few-shot semantic segmentation, instance identification, object retrieval, and tracking. We discover that contrastive learning based methods like DINO produce more universal patch representations that can be immediately applied for downstream tasks with no parameter tuning, compared to masked image modeling. The embeddings learned using the latter approach, e.g. in masked autoencoders, have high variance features that harm distance-based algorithms, such as k-NN, and do not contain useful information for most downstream tasks. Furthermore, we demonstrate that removing these high-variance features enhances k-NN by providing an analysis of the benchmarks for this work and for Scale-MAE, a recent extension of masked autoencoders. Finally, we find an object instance retrieval setting where DINOv2, a model pretrained on two orders of magnitude more data, performs worse than its less compute-intensive counterpart DINO. ",
    "url": "https://arxiv.org/abs/2401.00463",
    "authors": [
      "Ani Vanyan",
      "Alvard Barseghyan",
      "Hakob Tamazyan",
      "Vahan Huroyan",
      "Hrant Khachatrian",
      "Martin Danelljan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00525",
    "title": "Pack and Measure: An Effective Approach for Influence Propagation in  Social Networks",
    "abstract": "The Influence Maximization problem under the Independent Cascade model (IC) is considered. The problem asks for a minimal set of vertices to serve as \"seed set\" from which a maximum influence propagation is expected. New seed-set selection methods are introduced based on the notions of a $d$-packing and vertex centrality. In particular, we focus on selecting seed-vertices that are far apart and whose influence-values are the highest in their local communities. Our best results are achieved via an initial computation of a $d$-Packing followed by selecting either vertices of high degree or high centrality in their respective closed neighborhoods. This overall \"Pack and Measure\" approach proves highly effective as a seed selection method. ",
    "url": "https://arxiv.org/abs/2401.00525",
    "authors": [
      "Faisal N. Abu-Khzam",
      "Ghinwa Bou Matar",
      "Sergio Thoumi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2401.00529",
    "title": "GraphGPT: Graph Learning with Generative Pre-trained Transformers",
    "abstract": "We introduce \\textit{GraphGPT}, a novel model for Graph learning by self-supervised Generative Pre-training Transformers. Our model transforms each graph or sampled subgraph into a sequence of tokens representing the node, edge and attributes reversibly using the Eulerian path first. Then we feed the tokens into a standard transformer decoder and pre-train it with the next-token-prediction (NTP) task. Lastly, we fine-tune the GraphGPT model with the supervised tasks. This intuitive, yet effective model achieves superior or close results to the state-of-the-art methods for the graph-, edge- and node-level tasks on the large scale molecular dataset PCQM4Mv2, the protein-protein association dataset ogbl-ppa and the ogbn-proteins dataset from the Open Graph Benchmark (OGB). Furthermore, the generative pre-training enables us to train GraphGPT up to 400M+ parameters with consistently increasing performance, which is beyond the capability of GNNs and previous graph transformers. The source code and pre-trained checkpoints will be released soon\\footnote{\\url{https://github.com/alibaba/graph-gpt}} to pave the way for the graph foundation model research, and also to assist the scientific discovery in pharmaceutical, chemistry, material and bio-informatics domains, etc. ",
    "url": "https://arxiv.org/abs/2401.00529",
    "authors": [
      "Qifang Zhao",
      "Weidong Ren",
      "Tianyu Li",
      "Xiaoxiao Xu",
      "Hong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00533",
    "title": "Convergence of the complex block Jacobi methods under the generalized  serial pivot strategies",
    "abstract": "The paper considers the convergence of the complex block Jacobi diagonalization methods under the large set of the generalized serial pivot strategies. The global convergence of the block methods for Hermitian, normal and $J$-Hermitian matrices is proven. In order to obtain the convergence results for the block methods that solve other eigenvalue problems, such as the generalized eigenvalue problem, we consider the convergence of a general block iterative process which uses the complex block Jacobi annihilators and operators. ",
    "url": "https://arxiv.org/abs/2401.00533",
    "authors": [
      "Erna Begovic",
      "Vjeran Hari"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2401.00551",
    "title": "A Generalist FaceX via Learning Unified Facial Representation",
    "abstract": "This work presents FaceX framework, a novel facial generalist model capable of handling diverse facial tasks simultaneously. To achieve this goal, we initially formulate a unified facial representation for a broad spectrum of facial editing tasks, which macroscopically decomposes a face into fundamental identity, intra-personal variation, and environmental factors. Based on this, we introduce Facial Omni-Representation Decomposing (FORD) for seamless manipulation of various facial components, microscopically decomposing the core aspects of most facial editing tasks. Furthermore, by leveraging the prior of a pretrained StableDiffusion (SD) to enhance generation quality and accelerate training, we design Facial Omni-Representation Steering (FORS) to first assemble unified facial representations and then effectively steer the SD-aware generation process by the efficient Facial Representation Controller (FRC). %Without any additional features, Our versatile FaceX achieves competitive performance compared to elaborate task-specific models on popular facial editing tasks. Full codes and models will be available at https://github.com/diffusion-facex/FaceX. ",
    "url": "https://arxiv.org/abs/2401.00551",
    "authors": [
      "Yue Han",
      "Jiangning Zhang",
      "Junwei Zhu",
      "Xiangtai Li",
      "Yanhao Ge",
      "Wei Li",
      "Chengjie Wang",
      "Yong Liu",
      "Xiaoming Liu",
      "Ying Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00561",
    "title": "QGLAB: A MATLAB Package for Computations on Quantum Graphs",
    "abstract": "We describe QGLAB, a new MATLAB package for analyzing partial differential equations on quantum graphs. The software is built on the existing, object-oriented MATLAB directed-graph class, inheriting its structure and adding additional easy-to-use features. The package allows one to construct a quantum graph and accurately compute the spectrum of elliptic operators, solutions to Poisson problems, the linear and nonlinear time evolution of a variety of PDEs, the continuation of branches of steady states (including locating and switching branches at bifurcations) and more. It uses a unified framework to implement finite-difference and Chebyshev discretizations of differential operators on a quantum graph. For simplicity, the package overloads many built-in MATLAB functions to work on the class. ",
    "url": "https://arxiv.org/abs/2401.00561",
    "authors": [
      "Roy H. Goodman",
      "Grace Conte",
      "Jeremy L. Marzuola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2401.00575",
    "title": "Neural Networks Against (and For) Self-Training: Classification with  Small Labeled and Large Unlabeled Sets",
    "abstract": "We propose a semi-supervised text classifier based on self-training using one positive and one negative property of neural networks. One of the weaknesses of self-training is the semantic drift problem, where noisy pseudo-labels accumulate over iterations and consequently the error rate soars. In order to tackle this challenge, we reshape the role of pseudo-labels and create a hierarchical order of information. In addition, a crucial step in self-training is to use the classifier confidence prediction to select the best candidate pseudo-labels. This step cannot be efficiently done by neural networks, because it is known that their output is poorly calibrated. To overcome this challenge, we propose a hybrid metric to replace the plain confidence measurement. Our metric takes into account the prediction uncertainty via a subsampling technique. We evaluate our model in a set of five standard benchmarks, and show that it significantly outperforms a set of ten diverse baseline models. Furthermore, we show that the improvement achieved by our model is additive to language model pretraining, which is a widely used technique for using unlabeled documents. Our code is available at https://github.com/p-karisani/RST. ",
    "url": "https://arxiv.org/abs/2401.00575",
    "authors": [
      "Payam Karisani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.00582",
    "title": "An Analysis of Embedding Layers and Similarity Scores using Siamese  Neural Networks",
    "abstract": "Large Lanugage Models (LLMs) are gaining increasing popularity in a variety of use cases, from language understanding and writing to assistance in application development. One of the most important aspects for optimal funcionality of LLMs is embedding layers. Word embeddings are distributed representations of words in a continuous vector space. In the context of LLMs, words or tokens from the input text are transformed into high-dimensional vectors using unique algorithms specific to the model. Our research examines the embedding algorithms from leading companies in the industry, such as OpenAI, Google's PaLM, and BERT. Using medical data, we have analyzed similarity scores of each embedding layer, observing differences in performance among each algorithm. To enhance each model and provide an additional encoding layer, we also implemented Siamese Neural Networks. After observing changes in performance with the addition of the model, we measured the carbon footage per epoch of training. The carbon footprint associated with large language models (LLMs) is a significant concern, and should be taken into consideration when selecting algorithms for a variety of use cases. Overall, our research compared the accuracy different, leading embedding algorithms and their carbon footage, allowing for a holistic review of each embedding algorithm. ",
    "url": "https://arxiv.org/abs/2401.00582",
    "authors": [
      "Yash Bingi",
      "Yiqiao Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00583",
    "title": "Improving the Privacy and Practicality of Objective Perturbation for  Differentially Private Linear Learners",
    "abstract": "In the arena of privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) has outstripped the objective perturbation mechanism in popularity and interest. Though unrivaled in versatility, DP-SGD requires a non-trivial privacy overhead (for privately tuning the model's hyperparameters) and a computational complexity which might be extravagant for simple models such as linear and logistic regression. This paper revamps the objective perturbation mechanism with tighter privacy analyses and new computational tools that boost it to perform competitively with DP-SGD on unconstrained convex generalized linear problems. ",
    "url": "https://arxiv.org/abs/2401.00583",
    "authors": [
      "Rachel Redberg",
      "Antti Koskela",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.00605",
    "title": "Distributed Multi-Object Tracking Under Limited Field of View  Heterogeneous Sensors with Density Clustering",
    "abstract": "We consider the problem of tracking multiple, unknown, and time-varying numbers of objects using a distributed network of heterogeneous sensors. In an effort to derive a formulation for practical settings, we consider limited and unknown sensor field-of-views (FoVs), sensors with limited local computational resources and communication channel capacity. The resulting distributed multi-object tracking algorithm involves solving an NP-hard multidimensional assignment problem either optimally for small-size problems or sub-optimally for general practical problems. For general problems, we propose an efficient distributed multi-object tracking algorithm that performs track-to-track fusion using a clustering-based analysis of the state space transformed into a density space to mitigate the complexity of the assignment problem. The proposed algorithm can more efficiently group local track estimates for fusion than existing approaches. To ensure we achieve globally consistent identities for tracks across a network of nodes as objects move between FoVs, we develop a graph-based algorithm to achieve label consensus and minimise track segmentation. Numerical experiments with a synthetic and a real-world trajectory dataset demonstrate that our proposed method is significantly more computationally efficient than state-of-the-art solutions, achieving similar tracking accuracy and bandwidth requirements but with improved label consistency. ",
    "url": "https://arxiv.org/abs/2401.00605",
    "authors": [
      "Fei Chen",
      "Hoa Van Nguyen",
      "Alex S. Leong",
      "Sabita Panicker",
      "Robin Baker",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.00608",
    "title": "Bringing Back the Context: Camera Trap Species Identification as Link  Prediction on Multimodal Knowledge Graphs",
    "abstract": "Camera traps are valuable tools in animal ecology for biodiversity monitoring and conservation. However, challenges like poor generalization to deployment at new unseen locations limit their practical application. Images are naturally associated with heterogeneous forms of context possibly in different modalities. In this work, we leverage the structured context associated with the camera trap images to improve out-of-distribution generalization for the task of species identification in camera traps. For example, a photo of a wild animal may be associated with information about where and when it was taken, as well as structured biology knowledge about the animal species. While typically overlooked by existing work, bringing back such context offers several potential benefits for better image understanding, such as addressing data scarcity and enhancing generalization. However, effectively integrating such heterogeneous context into the visual domain is a challenging problem. To address this, we propose a novel framework that reformulates species classification as link prediction in a multimodal knowledge graph (KG). This framework seamlessly integrates various forms of multimodal context for visual recognition. We apply this framework for out-of-distribution species classification on the iWildCam2020-WILDS and Snapshot Mountain Zebra datasets and achieve competitive performance with state-of-the-art approaches. Furthermore, our framework successfully incorporates biological taxonomy for improved generalization and enhances sample efficiency for recognizing under-represented species. ",
    "url": "https://arxiv.org/abs/2401.00608",
    "authors": [
      "Vardaan Pahuja",
      "Weidi Luo",
      "Yu Gu",
      "Cheng-Hao Tu",
      "Hong-You Chen",
      "Tanya Berger-Wolf",
      "Charles Stewart",
      "Song Gao",
      "Wei-Lun Chao",
      "Yu Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00616",
    "title": "GD^2-NeRF: Generative Detail Compensation via GAN and Diffusion for  One-shot Generalizable Neural Radiance Fields",
    "abstract": "In this paper, we focus on the One-shot Novel View Synthesis (O-NVS) task which targets synthesizing photo-realistic novel views given only one reference image per scene. Previous One-shot Generalizable Neural Radiance Fields (OG-NeRF) methods solve this task in an inference-time finetuning-free manner, yet suffer the blurry issue due to the encoder-only architecture that highly relies on the limited reference image. On the other hand, recent diffusion-based image-to-3d methods show vivid plausible results via distilling pre-trained 2D diffusion models into a 3D representation, yet require tedious per-scene optimization. Targeting these issues, we propose the GD^2-NeRF, a Generative Detail compensation framework via GAN and Diffusion that is both inference-time finetuning-free and with vivid plausible details. In detail, following a coarse-to-fine strategy, GD^2-NeRF is mainly composed of a One-stage Parallel Pipeline (OPP) and a 3D-consistent Detail Enhancer (Diff3DE). At the coarse stage, OPP first efficiently inserts the GAN model into the existing OG-NeRF pipeline for primarily relieving the blurry issue with in-distribution priors captured from the training dataset, achieving a good balance between sharpness (LPIPS, FID) and fidelity (PSNR, SSIM). Then, at the fine stage, Diff3DE further leverages the pre-trained image diffusion models to complement rich out-distribution details while maintaining decent 3D consistency. Extensive experiments on both the synthetic and real-world datasets show that GD$^2$-NeRF noticeably improves the details while without per-scene finetuning. ",
    "url": "https://arxiv.org/abs/2401.00616",
    "authors": [
      "Xiao Pan",
      "Zongxin Yang",
      "Shuai Bai",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00631",
    "title": "Coordinated Deep Neural Networks: A Versatile Edge Offloading Algorithm",
    "abstract": "As artificial intelligence (AI) applications continue to expand, there is a growing need for deep neural network (DNN) models. Although DNN models deployed at the edge are promising to provide AI as a service with low latency, their cooperation is yet to be explored. In this paper, we consider the DNN service providers share their computing resources as well as their models' parameters and allow other DNNs to offload their computations without mirroring. We propose a novel algorithm called coordinated DNNs on edge (\\textbf{CoDE}) that facilitates coordination among DNN services by creating multi-task DNNs out of individual models. CoDE aims to find the optimal path that results in the lowest possible cost, where the cost reflects the inference delay, model accuracy, and local computation workload. With CoDE, DNN models can make new paths for inference by using their own or other models' parameters. We then evaluate the performance of CoDE through numerical experiments. The results demonstrate a $75\\%$ reduction in the local service computation workload while degrading the accuracy by only $2\\%$ and having the same inference time in a balanced load condition. Under heavy load, CoDE can further decrease the inference time by $30\\%$ while the accuracy is reduced by only $4\\%$. ",
    "url": "https://arxiv.org/abs/2401.00631",
    "authors": [
      "Alireza Maleki",
      "Hamed Shah-Mansouri",
      "Babak H. Khalaj"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.00633",
    "title": "On Discprecncies between Perturbation Evaluations of Graph Neural  Network Attributions",
    "abstract": "Neural networks are increasingly finding their way into the realm of graphs and modeling relationships between features. Concurrently graph neural network explanation approaches are being invented to uncover relationships between the nodes of the graphs. However, there is a disparity between the existing attribution methods, and it is unclear which attribution to trust. Therefore research has introduced evaluation experiments that assess them from different perspectives. In this work, we assess attribution methods from a perspective not previously explored in the graph domain: retraining. The core idea is to retrain the network on important (or not important) relationships as identified by the attributions and evaluate how networks can generalize based on these relationships. We reformulate the retraining framework to sidestep issues lurking in the previous formulation and propose guidelines for correct analysis. We run our analysis on four state-of-the-art GNN attribution methods and five synthetic and real-world graph classification datasets. The analysis reveals that attributions perform variably depending on the dataset and the network. Most importantly, we observe that the famous GNNExplainer performs similarly to an arbitrary designation of edge importance. The study concludes that the retraining evaluation cannot be used as a generalized benchmark and recommends it as a toolset to evaluate attributions on a specifically addressed network, dataset, and sparsity. ",
    "url": "https://arxiv.org/abs/2401.00633",
    "authors": [
      "Razieh Rezaei",
      "Alireza Dizaji",
      "Ashkan Khakzar",
      "Anees Kazi",
      "Nassir Navab",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00651",
    "title": "IRWE: Inductive Random Walk for Joint Inference of Identity and Position  Network Embedding",
    "abstract": "Network embedding, which maps graphs to distributed representations, is a unified framework for various graph inference tasks. According to the topology properties (e.g., structural roles and community memberships of nodes) to be preserved, it can be categorized into the identity and position embedding. However, existing methods can only capture one type of property. Some approaches can support the inductive inference that generalizes the embedding model to new nodes or graphs but relies on the availability of attributes. Due to the complicated correlations between topology and attributes, it is unclear for some inductive methods which type of property they can capture. In this study, we explore a unified framework for the joint inductive inference of identity and position embeddings without attributes. An inductive random walk embedding (IRWE) method is proposed, which combines multiple attention units to handle the random walk on graph topology and simultaneously derives identity and position embeddings that are jointly optimized. In particular, we demonstrate that some random walk statistics can be informative features to characterize node identities and positions while supporting the inductive embedding inference. Experiments validate the superior performance of IRWE beyond various baselines for the transductive and inductive inference of identity and position embeddings. ",
    "url": "https://arxiv.org/abs/2401.00651",
    "authors": [
      "Meng Qin",
      "Dit-Yan Yeung"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.00652",
    "title": "From Covert Hiding to Visual Editing: Robust Generative Video  Steganography",
    "abstract": "Traditional video steganography methods are based on modifying the covert space for embedding, whereas we propose an innovative approach that embeds secret message within semantic feature for steganography during the video editing process. Although existing traditional video steganography methods display a certain level of security and embedding capacity, they lack adequate robustness against common distortions in online social networks (OSNs). In this paper, we introduce an end-to-end robust generative video steganography network (RoGVS), which achieves visual editing by modifying semantic feature of videos to embed secret message. We employ face-swapping scenario to showcase the visual editing effects. We first design a secret message embedding module to adaptively hide secret message into the semantic feature of videos. Extensive experiments display that the proposed RoGVS method applied to facial video datasets demonstrate its superiority over existing video and image steganography techniques in terms of both robustness and capacity. ",
    "url": "https://arxiv.org/abs/2401.00652",
    "authors": [
      "Xueying Mao",
      "Xiaoxiao Hu",
      "Wanli Peng",
      "Zhenliang Gan",
      "Qichao Ying",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00662",
    "title": "Enhancing Pre-trained ASR System Fine-tuning for Dysarthric Speech  Recognition using Adversarial Data Augmentation",
    "abstract": "Automatic recognition of dysarthric speech remains a highly challenging task to date. Neuro-motor conditions and co-occurring physical disabilities create difficulty in large-scale data collection for ASR system development. Adapting SSL pre-trained ASR models to limited dysarthric speech via data-intensive parameter fine-tuning leads to poor generalization. To this end, this paper presents an extensive comparative study of various data augmentation approaches to improve the robustness of pre-trained ASR model fine-tuning to dysarthric speech. These include: a) conventional speaker-independent perturbation of impaired speech; b) speaker-dependent speed perturbation, or GAN-based adversarial perturbation of normal, control speech based on their time alignment against parallel dysarthric speech; c) novel Spectral basis GAN-based adversarial data augmentation operating on non-parallel data. Experiments conducted on the UASpeech corpus suggest GAN-based data augmentation consistently outperforms fine-tuned Wav2vec2.0 and HuBERT models using no data augmentation and speed perturbation across different data expansion operating points by statistically significant word error rate (WER) reductions up to 2.01% and 0.96% absolute (9.03% and 4.63% relative) respectively on the UASpeech test set of 16 dysarthric speakers. After cross-system outputs rescoring, the best system produced the lowest published WER of 16.53% (46.47% on very low intelligibility) on UASpeech. ",
    "url": "https://arxiv.org/abs/2401.00662",
    "authors": [
      "Huimeng Wang",
      "Zengrui Jin",
      "Mengzhe Geng",
      "Shujie Hu",
      "Guinan Li",
      "Tianzi Wang",
      "Haoning Xu",
      "Xunying Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2401.00688",
    "title": "Inferring community structure in attributed hypergraphs using stochastic  block models",
    "abstract": "Hypergraphs are a representation of complex systems involving interactions among more than two entities and allow to investigation of higher-order structure and dynamics in real-world complex systems. Community structure is a common property observed in empirical networks in various domains. Stochastic block models have been employed to investigate community structure in networks. Node attribute data, often accompanying network data, has been found to potentially enhance the learning of community structure in dyadic networks. In this study, we develop a statistical framework that incorporates node attribute data into the learning of community structure in a hypergraph, employing a stochastic block model. We demonstrate that our model, which we refer to as HyperNEO, enhances the learning of community structure in synthetic and empirical hypergraphs when node attributes are sufficiently associated with the communities. Furthermore, we found that applying a dimensionality reduction method, UMAP, to the learned representations obtained using stochastic block models, including our model, maps nodes into a two-dimensional vector space while largely preserving community structure in empirical hypergraphs. We expect that our framework will broaden the investigation and understanding of higher-order community structure in real-world complex systems. ",
    "url": "https://arxiv.org/abs/2401.00688",
    "authors": [
      "Kazuki Nakajima",
      "Takeaki Uno"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00695",
    "title": "Credible Teacher for Semi-Supervised Object Detection in Open Scene",
    "abstract": "Semi-Supervised Object Detection (SSOD) has achieved resounding success by leveraging unlabeled data to improve detection performance. However, in Open Scene Semi-Supervised Object Detection (O-SSOD), unlabeled data may contains unknown objects not observed in the labeled data, which will increase uncertainty in the model's predictions for known objects. It is detrimental to the current methods that mainly rely on self-training, as more uncertainty leads to the lower localization and classification precision of pseudo labels. To this end, we propose Credible Teacher, an end-to-end framework. Credible Teacher adopts an interactive teaching mechanism using flexible labels to prevent uncertain pseudo labels from misleading the model and gradually reduces its uncertainty through the guidance of other credible pseudo labels. Empirical results have demonstrated our method effectively restrains the adverse effect caused by O-SSOD and significantly outperforms existing counterparts. ",
    "url": "https://arxiv.org/abs/2401.00695",
    "authors": [
      "Jingyu Zhuang",
      "Kuo Wang",
      "Liang Lin",
      "Guanbin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00700",
    "title": "An attempt to generate new bridge types from latent space of generative  adversarial network",
    "abstract": "Try to generate new bridge types using generative artificial intelligence technology. Symmetric structured image dataset of three-span beam bridge, arch bridge, cable-stayed bridge and suspension bridge are used . Based on Python programming language, TensorFlow and Keras deep learning platform framework , as well as Wasserstein loss function and Lipschitz constraints, generative adversarial network is constructed and trained. From the obtained low dimensional bridge-type latent space sampling, new bridge types with asymmetric structures can be generated. Generative adversarial network can create new bridge types by organically combining different structural components on the basis of human original bridge types. It has a certain degree of human original ability. Generative artificial intelligence technology can open up imagination space and inspire humanity. ",
    "url": "https://arxiv.org/abs/2401.00700",
    "authors": [
      "Hongjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00701",
    "title": "Towards Efficient and Effective Text-to-Video Retrieval with  Coarse-to-Fine Visual Representation Learning",
    "abstract": "In recent years, text-to-video retrieval methods based on CLIP have experienced rapid development. The primary direction of evolution is to exploit the much wider gamut of visual and textual cues to achieve alignment. Concretely, those methods with impressive performance often design a heavy fusion block for sentence (words)-video (frames) interaction, regardless of the prohibitive computation complexity. Nevertheless, these approaches are not optimal in terms of feature utilization and retrieval efficiency. To address this issue, we adopt multi-granularity visual feature learning, ensuring the model's comprehensiveness in capturing visual content features spanning from abstract to detailed levels during the training phase. To better leverage the multi-granularity features, we devise a two-stage retrieval architecture in the retrieval phase. This solution ingeniously balances the coarse and fine granularity of retrieval content. Moreover, it also strikes a harmonious equilibrium between retrieval effectiveness and efficiency. Specifically, in training phase, we design a parameter-free text-gated interaction block (TIB) for fine-grained video representation learning and embed an extra Pearson Constraint to optimize cross-modal representation learning. In retrieval phase, we use coarse-grained video representations for fast recall of top-k candidates, which are then reranked by fine-grained video representations. Extensive experiments on four benchmarks demonstrate the efficiency and effectiveness. Notably, our method achieves comparable performance with the current state-of-the-art methods while being nearly 50 times faster. ",
    "url": "https://arxiv.org/abs/2401.00701",
    "authors": [
      "Kaibin Tian",
      "Yanhua Cheng",
      "Yi Liu",
      "Xinglin Hou",
      "Quan Chen",
      "Han Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00708",
    "title": "Revisiting Nonlocal Self-Similarity from Continuous Representation",
    "abstract": "Nonlocal self-similarity (NSS) is an important prior that has been successfully applied in multi-dimensional data processing tasks, e.g., image and video recovery. However, existing NSS-based methods are solely suitable for meshgrid data such as images and videos, but are not suitable for emerging off-meshgrid data, e.g., point cloud and climate data. In this work, we revisit the NSS from the continuous representation perspective and propose a novel Continuous Representation-based NonLocal method (termed as CRNL), which has two innovative features as compared with classical nonlocal methods. First, based on the continuous representation, our CRNL unifies the measure of self-similarity for on-meshgrid and off-meshgrid data and thus is naturally suitable for both of them. Second, the nonlocal continuous groups can be more compactly and efficiently represented by the coupled low-rank function factorization, which simultaneously exploits the similarity within each group and across different groups, while classical nonlocal methods neglect the similarity across groups. This elaborately designed coupled mechanism allows our method to enjoy favorable performance over conventional NSS methods in terms of both effectiveness and efficiency. Extensive multi-dimensional data processing experiments on-meshgrid (e.g., image inpainting and image denoising) and off-meshgrid (e.g., climate data prediction and point cloud recovery) validate the versatility, effectiveness, and efficiency of our CRNL as compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2401.00708",
    "authors": [
      "Yisi Luo",
      "Xile Zhao",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2401.00713",
    "title": "A Survey on Graph Neural Networks in Intelligent Transportation Systems",
    "abstract": "Intelligent Transportation System (ITS) is vital in improving traffic congestion, reducing traffic accidents, optimizing urban planning, etc. However, due to the complexity of the traffic network, traditional machine learning and statistical methods are relegated to the background. With the advent of the artificial intelligence era, many deep learning frameworks have made remarkable progress in various fields and are now considered effective methods in many areas. As a deep learning method, Graph Neural Networks (GNNs) have emerged as a highly competitive method in the ITS field since 2019 due to their strong ability to model graph-related problems. As a result, more and more scholars pay attention to the applications of GNNs in transportation domains, which have shown excellent performance. However, most of the research in this area is still concentrated on traffic forecasting, while other ITS domains, such as autonomous vehicles and urban planning, still require more attention. This paper aims to review the applications of GNNs in six representative and emerging ITS domains: traffic forecasting, autonomous vehicles, traffic signal control, transportation safety, demand prediction, and parking management. We have reviewed extensive graph-related studies from 2018 to 2023, summarized their methods, features, and contributions, and presented them in informative tables or lists. Finally, we have identified the challenges of applying GNNs to ITS and suggested potential future directions. ",
    "url": "https://arxiv.org/abs/2401.00713",
    "authors": [
      "Hourun Li",
      "Yusheng Zhao",
      "Zhengyang Mao",
      "YiFang Qin",
      "Zhiping Xiao",
      "Jiaqi Feng",
      "Yiyang Gu",
      "Wei Ju",
      "Xiao Luo",
      "Ming Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00719",
    "title": "Depth Map Denoising Network and Lightweight Fusion Network for Enhanced  3D Face Recognition",
    "abstract": "With the increasing availability of consumer depth sensors, 3D face recognition (FR) has attracted more and more attention. However, the data acquired by these sensors are often coarse and noisy, making them impractical to use directly. In this paper, we introduce an innovative Depth map denoising network (DMDNet) based on the Denoising Implicit Image Function (DIIF) to reduce noise and enhance the quality of facial depth images for low-quality 3D FR. After generating clean depth faces using DMDNet, we further design a powerful recognition network called Lightweight Depth and Normal Fusion network (LDNFNet), which incorporates a multi-branch fusion block to learn unique and complementary features between different modalities such as depth and normal images. Comprehensive experiments conducted on four distinct low-quality databases demonstrate the effectiveness and robustness of our proposed methods. Furthermore, when combining DMDNet and LDNFNet, we achieve state-of-the-art results on the Lock3DFace database. ",
    "url": "https://arxiv.org/abs/2401.00719",
    "authors": [
      "Ruizhuo Xu",
      "Ke Wang",
      "Chao Deng",
      "Mei Wang",
      "Xi Chen",
      "Wenhui Huang",
      "Junlan Feng",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00722",
    "title": "BRAU-Net++: U-Shaped Hybrid CNN-Transformer Network for Medical Image  Segmentation",
    "abstract": "Accurate medical image segmentation is essential for clinical quantification, disease diagnosis, treatment planning and many other applications. Both convolution-based and transformer-based u-shaped architectures have made significant success in various medical image segmentation tasks. The former can efficiently learn local information of images while requiring much more image-specific inductive biases inherent to convolution operation. The latter can effectively capture long-range dependency at different feature scales using self-attention, whereas it typically encounters the challenges of quadratic compute and memory requirements with sequence length increasing. To address this problem, through integrating the merits of these two paradigms in a well-designed u-shaped architecture, we propose a hybrid yet effective CNN-Transformer network, named BRAU-Net++, for an accurate medical image segmentation task. Specifically, BRAU-Net++ uses bi-level routing attention as the core building block to design our u-shaped encoder-decoder structure, in which both encoder and decoder are hierarchically constructed, so as to learn global semantic information while reducing computational complexity. Furthermore, this network restructures skip connection by incorporating channel-spatial attention which adopts convolution operations, aiming to minimize local spatial information loss and amplify global dimension-interaction of multi-scale features. Extensive experiments on three public benchmark datasets demonstrate that our proposed approach surpasses other state-of-the-art methods including its baseline: BRAU-Net under almost all evaluation metrics. We achieve the average Dice-Similarity Coefficient (DSC) of 82.47, 90.10, and 92.94 on Synapse multi-organ segmentation, ISIC-2018 Challenge, and CVC-ClinicDB, as well as the mIoU of 84.01 and 88.17 on ISIC-2018 Challenge and CVC-ClinicDB, respectively. ",
    "url": "https://arxiv.org/abs/2401.00722",
    "authors": [
      "Libin Lan",
      "Pengzhou Cai",
      "Lu Jiang",
      "Xiaojuan Liu",
      "Yongmei Li",
      "Yudong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.00755",
    "title": "Saliency-Aware Regularized Graph Neural Network",
    "abstract": "The crux of graph classification lies in the effective representation learning for the entire graph. Typical graph neural networks focus on modeling the local dependencies when aggregating features of neighboring nodes, and obtain the representation for the entire graph by aggregating node features. Such methods have two potential limitations: 1) the global node saliency w.r.t. graph classification is not explicitly modeled, which is crucial since different nodes may have different semantic relevance to graph classification; 2) the graph representation directly aggregated from node features may have limited effectiveness to reflect graph-level information. In this work, we propose the Saliency-Aware Regularized Graph Neural Network (SAR-GNN) for graph classification, which consists of two core modules: 1) a traditional graph neural network serving as the backbone for learning node features and 2) the Graph Neural Memory designed to distill a compact graph representation from node features of the backbone. We first estimate the global node saliency by measuring the semantic similarity between the compact graph representation and node features. Then the learned saliency distribution is leveraged to regularize the neighborhood aggregation of the backbone, which facilitates the message passing of features for salient nodes and suppresses the less relevant nodes. Thus, our model can learn more effective graph representation. We demonstrate the merits of SAR-GNN by extensive experiments on seven datasets across various types of graph data. Code will be released. ",
    "url": "https://arxiv.org/abs/2401.00755",
    "authors": [
      "Wenjie Pei",
      "Weina Xu",
      "Zongze Wu",
      "Weichao Li",
      "Jinfan Wang",
      "Guangming Lu",
      "Xiangrong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00756",
    "title": "MPRE: Multi-perspective Patient Representation Extractor for Disease  Prediction",
    "abstract": "Patient representation learning based on electronic health records (EHR) is a critical task for disease prediction. This task aims to effectively extract useful information on dynamic features. Although various existing works have achieved remarkable progress, the model performance can be further improved by fully extracting the trends, variations, and the correlation between the trends and variations in dynamic features. In addition, sparse visit records limit the performance of deep learning models. To address these issues, we propose the Multi-perspective Patient Representation Extractor (MPRE) for disease prediction. Specifically, we propose Frequency Transformation Module (FTM) to extract the trend and variation information of dynamic features in the time-frequency domain, which can enhance the feature representation. In the 2D Multi-Extraction Network (2D MEN), we form the 2D temporal tensor based on trend and variation. Then, the correlations between trend and variation are captured by the proposed dilated operation. Moreover, we propose the First-Order Difference Attention Mechanism (FODAM) to calculate the contributions of differences in adjacent variations to the disease diagnosis adaptively. To evaluate the performance of MPRE and baseline methods, we conduct extensive experiments on two real-world public datasets. The experiment results show that MPRE outperforms state-of-the-art baseline methods in terms of AUROC and AUPRC. ",
    "url": "https://arxiv.org/abs/2401.00756",
    "authors": [
      "Ziyue Yu",
      "Jiayi Wang",
      "Wuman Luo",
      "Rita Tse",
      "Giovanni Pau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00763",
    "title": "New Job, New Gender? Measuring the Social Bias in Image Generation  Models",
    "abstract": "Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel metamorphic testing framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race, and age-neutral queries. These queries span 62 professions, 39 activities, 57 types of objects, and 70 personality traits. The framework then compares the edited images to the original seed images, focusing on any changes related to gender, race, and age. BiasPainter adopts a testing oracle that these characteristics should not be modified when subjected to neutral prompts. Built upon this design, BiasPainter can trigger the social bias and evaluate the fairness of image generation models. To evaluate the effectiveness of BiasPainter, we use BiasPainter to test five widely-used commercial image generation software and models, such as stable diffusion and Midjourney. Experimental results show that 100\\% of the generated test cases can successfully trigger social bias in image generation models. ",
    "url": "https://arxiv.org/abs/2401.00763",
    "authors": [
      "Wenxuan Wang",
      "Haonan Bai",
      "Jen-tse Huang",
      "Yuxuan Wan",
      "Youliang Yuan",
      "Haoyi Qiu",
      "Nanyun Peng",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2401.00773",
    "title": "Unsupervised Outlier Detection using Random Subspace and Subsampling  Ensembles of Dirichlet Process Mixtures",
    "abstract": "Probabilistic mixture models are acknowledged as a valuable tool for unsupervised outlier detection owing to their interpretability and intuitive grounding in statistical principles. Within this framework, Dirichlet process mixture models emerge as a compelling alternative to conventional finite mixture models for both clustering and outlier detection tasks. However, despite their evident advantages, the widespread adoption of Dirichlet process mixture models in unsupervised outlier detection has been hampered by challenges related to computational inefficiency and sensitivity to outliers during the construction of detectors. To tackle these challenges, we propose a novel outlier detection method based on ensembles of Dirichlet process Gaussian mixtures. The proposed method is a fully unsupervised algorithm that capitalizes on random subspace and subsampling ensembles, not only ensuring efficient computation but also enhancing the robustness of the resulting outlier detector. Moreover, the proposed method leverages variational inference for Dirichlet process mixtures to ensure efficient and fast computation. Empirical studies with benchmark datasets demonstrate that our method outperforms existing approaches for unsupervised outlier detection. ",
    "url": "https://arxiv.org/abs/2401.00773",
    "authors": [
      "Dongwook Kim",
      "Juyeon Park",
      "Hee Cheol Chung",
      "Seonghyun Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.00779",
    "title": "Temporal Validity Change Prediction",
    "abstract": "Temporal validity is an important property of text that is useful for many downstream applications, such as recommender systems, conversational AI, or story understanding. Existing benchmarking tasks often require models to identify the temporal validity duration of a single statement. However, in many cases, additional contextual information, such as sentences in a story or posts on a social media profile, can be collected from the available text stream. This contextual information may greatly alter the duration for which a statement is expected to be valid. We propose Temporal Validity Change Prediction, a natural language processing task benchmarking the capability of machine learning models to detect contextual statements that induce such change. We create a dataset consisting of temporal target statements sourced from Twitter and crowdsource sample context statements. We then benchmark a set of transformer-based language models on our dataset. Finally, we experiment with temporal validity duration prediction as an auxiliary task to improve the performance of the state-of-the-art model. ",
    "url": "https://arxiv.org/abs/2401.00779",
    "authors": [
      "Georg Wenzel",
      "Adam Jatowt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00781",
    "title": "Inferring Heterogeneous Treatment Effects of Crashes on Highway Traffic:  A Doubly Robust Causal Machine Learning Approach",
    "abstract": "Highway traffic crashes exert a considerable impact on both transportation systems and the economy. In this context, accurate and dependable emergency responses are crucial for effective traffic management. However, the influence of crashes on traffic status varies across diverse factors and may be biased due to selection bias. Therefore, there arises a necessity to accurately estimate the heterogeneous causal effects of crashes, thereby providing essential insights to facilitate individual-level emergency decision-making. This paper proposes a novel causal machine learning framework to estimate the causal effect of different types of crashes on highway speed. The Neyman-Rubin Causal Model (RCM) is employed to formulate this problem from a causal perspective. The Conditional Shapley Value Index (CSVI) is proposed based on causal graph theory to filter adverse variables, and the Structural Causal Model (SCM) is then adopted to define the statistical estimand for causal effects. The treatment effects are estimated by Doubly Robust Learning (DRL) methods, which combine doubly robust causal inference with classification and regression machine learning models. Experimental results from 4815 crashes on Highway Interstate 5 in Washington State reveal the heterogeneous treatment effects of crashes at varying distances and durations. The rear-end crashes cause more severe congestion and longer durations than other types of crashes, and the sideswipe crashes have the longest delayed impact. Additionally, the findings show that rear-end crashes affect traffic greater at night, while crash to objects has the most significant influence during peak hours. Statistical hypothesis tests, error metrics based on matched \"counterfactual outcomes\", and sensitive analyses are employed for assessment, and the results validate the accuracy and effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2401.00781",
    "authors": [
      "Shuang Li",
      "Ziyuan Pu",
      "Zhiyong Cui",
      "Seunghyeon Lee",
      "Xiucheng Guo",
      "Dong Ngoduy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.00788",
    "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language  Models",
    "abstract": "The high cost of full-parameter fine-tuning (FFT) of Large Language Models (LLMs) has led to a series of parameter-efficient fine-tuning (PEFT) methods. However, it remains unclear which methods provide the best cost-performance trade-off at different model scales. We introduce Astraios, a suite of 28 instruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up to 16 billion parameters. Through investigations across 5 tasks and 8 different datasets encompassing both code comprehension and code generation tasks, we find that FFT generally leads to the best downstream performance across all scales, and PEFT methods differ significantly in their efficacy based on the model scale. LoRA usually offers the most favorable trade-off between cost and performance. Further investigation into the effects of these methods on both model robustness and code security reveals that larger models tend to demonstrate reduced robustness and less security. At last, we explore the relationships among updated parameters, cross-entropy loss, and task performance. We find that the tuning effectiveness observed in small models generalizes well to larger models, and the validation loss in instruction tuning can be a reliable indicator of overall downstream performance. ",
    "url": "https://arxiv.org/abs/2401.00788",
    "authors": [
      "Terry Yue Zhuo",
      "Armel Zebaze",
      "Nitchakarn Suppattarachai",
      "Leandro von Werra",
      "Harm de Vries",
      "Qian Liu",
      "Niklas Muennighoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.00809",
    "title": "A review on different techniques used to combat the non-IID and  heterogeneous nature of data in FL",
    "abstract": "Federated Learning (FL) is a machine-learning approach enabling collaborative model training across multiple decentralized edge devices that hold local data samples, all without exchanging these samples. This collaborative process occurs under the supervision of a central server orchestrating the training or via a peer-to-peer network. The significance of FL is particularly pronounced in industries such as healthcare and finance, where data privacy holds paramount importance. However, training a model under the Federated learning setting brings forth several challenges, with one of the most prominent being the heterogeneity of data distribution among the edge devices. The data is typically non-independently and non-identically distributed (non-IID), thereby presenting challenges to model convergence. This report delves into the issues arising from non-IID and heterogeneous data and explores current algorithms designed to address these challenges. ",
    "url": "https://arxiv.org/abs/2401.00809",
    "authors": [
      "Venkataraman Natarajan Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00812",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code  Empowers Large Language Models to Serve as Intelligent Agents",
    "abstract": "The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs' training data. Specifically, beyond enhancing LLMs in code generation, we observe that these unique properties of code help (i) unlock the reasoning ability of LLMs, enabling their applications to a range of more complex natural language tasks; (ii) steer LLMs to produce structured and precise intermediate steps, which can then be connected to external execution ends through function calls; and (iii) take advantage of code compilation and execution environment, which also provides diverse feedback for model improvement. In addition, we trace how these profound capabilities of LLMs, brought by code, have led to their emergence as intelligent agents (IAs) in situations where the ability to understand instructions, decompose goals, plan and execute actions, and refine from feedback are crucial to their success on downstream tasks. Finally, we present several key challenges and future directions of empowering LLMs with code. ",
    "url": "https://arxiv.org/abs/2401.00812",
    "authors": [
      "Ke Yang",
      "Jiateng Liu",
      "John Wu",
      "Chaoqi Yang",
      "Yi R. Fung",
      "Sha Li",
      "Zixuan Huang",
      "Xu Cao",
      "Xingyao Wang",
      "Yiquan Wang",
      "Heng Ji",
      "Chengxiang Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.00825",
    "title": "Sharp-NeRF: Grid-based Fast Deblurring Neural Radiance Fields Using  Sharpness Prior",
    "abstract": "Neural Radiance Fields (NeRF) have shown remarkable performance in neural rendering-based novel view synthesis. However, NeRF suffers from severe visual quality degradation when the input images have been captured under imperfect conditions, such as poor illumination, defocus blurring, and lens aberrations. Especially, defocus blur is quite common in the images when they are normally captured using cameras. Although few recent studies have proposed to render sharp images of considerably high-quality, yet they still face many key challenges. In particular, those methods have employed a Multi-Layer Perceptron (MLP) based NeRF, which requires tremendous computational time. To overcome these shortcomings, this paper proposes a novel technique Sharp-NeRF -- a grid-based NeRF that renders clean and sharp images from the input blurry images within half an hour of training. To do so, we used several grid-based kernels to accurately model the sharpness/blurriness of the scene. The sharpness level of the pixels is computed to learn the spatially varying blur kernels. We have conducted experiments on the benchmarks consisting of blurry images and have evaluated full-reference and non-reference metrics. The qualitative and quantitative results have revealed that our approach renders the sharp novel views with vivid colors and fine details, and it has considerably faster training time than the previous works. Our project page is available at https://benhenryl.github.io/SharpNeRF/ ",
    "url": "https://arxiv.org/abs/2401.00825",
    "authors": [
      "Byeonghyeon Lee",
      "Howoong Lee",
      "Usman Ali",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2401.00828",
    "title": "Multi-Lattice Sampling of Quantum Field Theories via Neural Operators",
    "abstract": "We consider the problem of sampling discrete field configurations $\\phi$ from the Boltzmann distribution $[d\\phi] Z^{-1} e^{-S[\\phi]}$, where $S$ is the lattice-discretization of the continuous Euclidean action $\\mathcal S$ of some quantum field theory. Since such densities arise as the approximation of the underlying functional density $[\\mathcal D\\phi(x)] \\mathcal Z^{-1} e^{-\\mathcal S[\\phi(x)]}$, we frame the task as an instance of operator learning. In particular, we propose to approximate a time-dependent operator $\\mathcal V_t$ whose time integral provides a mapping between the functional distributions of the free theory $[\\mathcal D\\phi(x)] \\mathcal Z_0^{-1} e^{-\\mathcal S_{0}[\\phi(x)]}$ and of the target theory $[\\mathcal D\\phi(x)]\\mathcal Z^{-1}e^{-\\mathcal S[\\phi(x)]}$. Whenever a particular lattice is chosen, the operator $\\mathcal V_t$ can be discretized to a finite dimensional, time-dependent vector field $V_t$ which in turn induces a continuous normalizing flow between finite dimensional distributions over the chosen lattice. This flow can then be trained to be a diffeormorphism between the discretized free and target theories $[d\\phi] Z_0^{-1} e^{-S_{0}[\\phi]}$, $[d\\phi] Z^{-1}e^{-S[\\phi]}$. We run experiments on the $\\phi^4$-theory to explore to what extent such operator-based flow architectures generalize to lattice sizes they were not trained on and show that pretraining on smaller lattices can lead to speedup over training only a target lattice size. ",
    "url": "https://arxiv.org/abs/2401.00828",
    "authors": [
      "B\u00e1lint M\u00e1t\u00e9",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.00035",
    "title": "Learning About Structural Errors in Models of Complex Dynamical Systems",
    "abstract": "Complex dynamical systems are notoriously difficult to model because some degrees of freedom (e.g., small scales) may be computationally unresolvable or are incompletely understood, yet they are dynamically important. For example, the small scales of cloud dynamics and droplet formation are crucial for controlling climate, yet are unresolvable in global climate models. Semi-empirical closure models for the effects of unresolved degrees of freedom often exist and encode important domain-specific knowledge. Building on such closure models and correcting them through learning the structural errors can be an effective way of fusing data with domain knowledge. Here we describe a general approach, principles, and algorithms for learning about structural errors. Key to our approach is to include structural error models inside the models of complex systems, for example, in closure models for unresolved scales. The structural errors then map, usually nonlinearly, to observable data. As a result, however, mismatches between model output and data are only indirectly informative about structural errors, due to a lack of labeled pairs of inputs and outputs of structural error models. Additionally, derivatives of the model may not exist or be readily available. We discuss how structural error models can be learned from indirect data with derivative-free Kalman inversion algorithms and variants, how sparsity constraints enforce a \"do no harm\" principle, and various ways of modeling structural errors. We also discuss the merits of using non-local and/or stochastic error models. In addition, we demonstrate how data assimilation techniques can assist the learning about structural errors in non-ergodic systems. The concepts and algorithms are illustrated in two numerical examples based on the Lorenz-96 system and a human glucose-insulin model. ",
    "url": "https://arxiv.org/abs/2401.00035",
    "authors": [
      "Jin-Long Wu",
      "Matthew E. Levine",
      "Tapio Schneider",
      "Andrew Stuart"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2401.00225",
    "title": "Enhancing dysarthria speech feature representation with empirical mode  decomposition and Walsh-Hadamard transform",
    "abstract": "Dysarthria speech contains the pathological characteristics of vocal tract and vocal fold, but so far, they have not yet been included in traditional acoustic feature sets. Moreover, the nonlinearity and non-stationarity of speech have been ignored. In this paper, we propose a feature enhancement algorithm for dysarthria speech called WHFEMD. It combines empirical mode decomposition (EMD) and fast Walsh-Hadamard transform (FWHT) to enhance features. With the proposed algorithm, the fast Fourier transform of the dysarthria speech is first performed and then followed by EMD to get intrinsic mode functions (IMFs). After that, FWHT is used to output new coefficients and to extract statistical features based on IMFs, power spectral density, and enhanced gammatone frequency cepstral coefficients. To evaluate the proposed approach, we conducted experiments on two public pathological speech databases including UA Speech and TORGO. The results show that our algorithm performed better than traditional features in classification. We achieved improvements of 13.8% (UA Speech) and 3.84% (TORGO), respectively. Furthermore, the incorporation of an imbalanced classification algorithm to address data imbalance has resulted in a 12.18% increase in recognition accuracy. This algorithm effectively addresses the challenges of the imbalanced dataset and non-linearity in dysarthric speech and simultaneously provides a robust representation of the local pathological features of the vocal folds and tracts. ",
    "url": "https://arxiv.org/abs/2401.00225",
    "authors": [
      "Ting Zhu",
      "Shufei Duan",
      "Camille Dingam",
      "Huizhi Liang",
      "Wei Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.00269",
    "title": "Sample Robust Scheduling of Electricity-Gas Systems Under Wind Power  Uncertainty",
    "abstract": "This paper adopts a two-stage sample robust optimization (SRO) model to address the wind power penetrated unit commitment optimal energy flow (UC-OEF) problem for IEGSs. The two-stage SRO model can be approximately transformed into a computationally efficient form. Specifically, we employ linear decision rules to simplify the proposed UC-OEF model. Moreover, we further enhance the tractability of the simplified model by exploring its structural features and, accordingly, develop a solution method. ",
    "url": "https://arxiv.org/abs/2401.00269",
    "authors": [
      "Rong-Peng Liu",
      "Yunhe Hou",
      "Yujia Li",
      "Shunbo Lei",
      "Wei Wei",
      "Xiaozhe Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.00428",
    "title": "Training towards significance with the decorrelated event classifier  transformer neural network",
    "abstract": "Experimental particle physics uses machine learning for many of tasks, where one application is to classify signal and background events. The classification can be used to bin an analysis region to enhance the expected significance for a mass resonance search. In natural language processing, one of the leading neural network architectures is the transformer. In this work, an event classifier transformer is proposed to bin an analysis region, in which the network is trained with special techniques. The techniques developed here can enhance the significance and reduce the correlation between the network's output and the reconstructed mass. It is found that this trained network can perform better than boosted decision trees and feed-forward networks. ",
    "url": "https://arxiv.org/abs/2401.00428",
    "authors": [
      "Jaebak Kim"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00587",
    "title": "Brain Tumor Segmentation Based on Deep Learning, Attention Mechanisms,  and Energy-Based Uncertainty Prediction",
    "abstract": "Brain tumors are one of the deadliest forms of cancer with a mortality rate of over 80%. A quick and accurate diagnosis is crucial to increase the chance of survival. However, in medical analysis, the manual annotation and segmentation of a brain tumor can be a complicated task. Multiple MRI modalities are typically analyzed as they provide unique information regarding the tumor regions. Although these MRI modalities are helpful for segmenting gliomas, they tend to increase overfitting and computation. This paper proposes a region of interest detection algorithm that is implemented during data preprocessing to locate salient features and remove extraneous MRI data. This decreases the input size, allowing for more aggressive data augmentations and deeper neural networks. Following the preprocessing of the MRI modalities, a fully convolutional autoencoder with soft attention segments the different brain MRIs. When these deep learning algorithms are implemented in practice, analysts and physicians cannot differentiate between accurate and inaccurate predictions. Subsequently, test time augmentations and an energy-based model were used for voxel-based uncertainty predictions. Experimentation was conducted on the BraTS benchmarks and achieved state-of-the-art segmentation performance. Additionally, qualitative results were used to assess the segmentation models and uncertainty predictions. ",
    "url": "https://arxiv.org/abs/2401.00587",
    "authors": [
      "Zachary Schwehr",
      "Sriman Achanta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00611",
    "title": "A Compact Representation for Bayesian Neural Networks By Removing  Permutation Symmetry",
    "abstract": "Bayesian neural networks (BNNs) are a principled approach to modeling predictive uncertainties in deep learning, which are important in safety-critical applications. Since exact Bayesian inference over the weights in a BNN is intractable, various approximate inference methods exist, among which sampling methods such as Hamiltonian Monte Carlo (HMC) are often considered the gold standard. While HMC provides high-quality samples, it lacks interpretable summary statistics because its sample mean and variance is meaningless in neural networks due to permutation symmetry. In this paper, we first show that the role of permutations can be meaningfully quantified by a number of transpositions metric. We then show that the recently proposed rebasin method allows us to summarize HMC samples into a compact representation that provides a meaningful explicit uncertainty estimate for each weight in a neural network, thus unifying sampling methods with variational inference. We show that this compact representation allows us to compare trained BNNs directly in weight space across sampling methods and variational inference, and to efficiently prune neural networks trained without explicit Bayesian frameworks by exploiting uncertainty estimates from HMC. ",
    "url": "https://arxiv.org/abs/2401.00611",
    "authors": [
      "Tim Z. Xiao",
      "Weiyang Liu",
      "Robert Bamler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00692",
    "title": "Self-supervised learning for skin cancer diagnosis with limited training  data",
    "abstract": "Cancer diagnosis is a well-studied problem in machine learning since early detection of cancer is often the determining factor in prognosis. Supervised deep learning achieves excellent results in cancer image classification, usually through transfer learning. However, these models require large amounts of labelled data and for several types of cancer, large labelled datasets do not exist. In this paper, we demonstrate that a model pre-trained using a self-supervised learning algorithm known as Barlow Twins can outperform the conventional supervised transfer learning pipeline. We juxtapose two base models: i) pretrained in a supervised fashion on ImageNet; ii) pretrained in a self-supervised fashion on ImageNet. Both are subsequently fine tuned on a small labelled skin lesion dataset and evaluated on a large test set. We achieve a mean test accuracy of 70\\% for self-supervised transfer in comparison to 66\\% for supervised transfer. Interestingly, boosting performance further is possible by self-supervised pretraining a second time (on unlabelled skin lesion images) before subsequent fine tuning. This hints at an alternative path to collecting more labelled data in settings where this is challenging - namely just collecting more unlabelled images. Our framework is applicable to cancer image classification models in the low-labelled data regime. ",
    "url": "https://arxiv.org/abs/2401.00692",
    "authors": [
      "Hamish Haggerty",
      "Rohitash Chandra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00728",
    "title": "MultiFusionNet: Multilayer Multimodal Fusion of Deep Neural Networks for  Chest X-Ray Image Classification",
    "abstract": "Chest X-ray imaging is a critical diagnostic tool for identifying pulmonary diseases. However, manual interpretation of these images is time-consuming and error-prone. Automated systems utilizing convolutional neural networks (CNNs) have shown promise in improving the accuracy and efficiency of chest X-ray image classification. While previous work has mainly focused on using feature maps from the final convolution layer, there is a need to explore the benefits of leveraging additional layers for improved disease classification. Extracting robust features from limited medical image datasets remains a critical challenge. In this paper, we propose a novel deep learning-based multilayer multimodal fusion model that emphasizes extracting features from different layers and fusing them. Our disease detection model considers the discriminatory information captured by each layer. Furthermore, we propose the fusion of different-sized feature maps (FDSFM) module to effectively merge feature maps from diverse layers. The proposed model achieves a significantly higher accuracy of 97.21% and 99.60% for both three-class and two-class classifications, respectively. The proposed multilayer multimodal fusion model, along with the FDSFM module, holds promise for accurate disease classification and can also be extended to other disease classifications in chest X-ray images. ",
    "url": "https://arxiv.org/abs/2401.00728",
    "authors": [
      "Saurabh Agarwal",
      "K. V. Arya",
      "Yogesh Kumar Meena"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00746",
    "title": "Learn to integrate parts for whole through correlated neural variability",
    "abstract": "Sensory perception originates from the responses of sensory neurons, which react to a collection of sensory signals linked to various physical attributes of a singular perceptual object. Unraveling how the brain extracts perceptual information from these neuronal responses is a pivotal challenge in both computational neuroscience and machine learning. Here we introduce a statistical mechanical theory, where perceptual information is first encoded in the correlated variability of sensory neurons and then reformatted into the firing rates of downstream neurons. Applying this theory, we illustrate the encoding of motion direction using neural covariance and demonstrate high-fidelity direction recovery by spiking neural networks. Networks trained under this theory also show enhanced performance in classifying natural images, achieving higher accuracy and faster inference speed. Our results challenge the traditional view of neural covariance as a secondary factor in neural coding, highlighting its potential influence on brain function. ",
    "url": "https://arxiv.org/abs/2401.00746",
    "authors": [
      "Zhichao Zhu",
      "Yang Qi",
      "Wenlian Lu",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2401.00787",
    "title": "Quantum multiple gray scale images encryption scheme in the bit plane  representation model",
    "abstract": "After introducing a bit-plane quantum representation for a multi-image, we present a novel way to encrypt/decrypt multiple images using a quantum computer. Our encryption scheme is based on a two-stage scrambling of the images and of the bit planes on one hand and of the pixel positions on the other hand, each time using quantum baker maps. The resulting quantum multi-image is then diffused with controlled CNOT gates using a sine chaotification of a two-dimensional H\\'enon map as well as Chebyshev polynomials. The decryption is processed by operating all the inverse quantum gates in the reverse order. ",
    "url": "https://arxiv.org/abs/2401.00787",
    "authors": [
      "Claire I. Levaillant"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Quantum Algebra (math.QA)"
    ]
  },
  {
    "id": "arXiv:2205.00362",
    "title": "A Simple and General Duality Proof for Wasserstein Distributionally  Robust Optimization",
    "abstract": " Title: A Simple and General Duality Proof for Wasserstein Distributionally  Robust Optimization ",
    "url": "https://arxiv.org/abs/2205.00362",
    "authors": [
      "Luhao Zhang",
      "Jincheng Yang",
      "Rui Gao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.12987",
    "title": "FlowX: Towards Explainable Graph Neural Networks via Message Flows",
    "abstract": " Title: FlowX: Towards Explainable Graph Neural Networks via Message Flows ",
    "url": "https://arxiv.org/abs/2206.12987",
    "authors": [
      "Shurui Gui",
      "Hao Yuan",
      "Jie Wang",
      "Qicheng Lao",
      "Kang Li",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00946",
    "title": "Motion-aware Memory Network for Fast Video Salient Object Detection",
    "abstract": " Comments: 13 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2208.00946",
    "authors": [
      "Xing Zhao",
      "Haoran Liang",
      "Peipei Li",
      "Guodao Sun",
      "Dongdong Zhao",
      "Ronghua Liang",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03255",
    "title": "Goldfish: No More Attacks on Ethereum?!",
    "abstract": " Comments: Financial Cryptography and Data Security 2024 ",
    "url": "https://arxiv.org/abs/2209.03255",
    "authors": [
      "Francesco D'Amato",
      "Joachim Neu",
      "Ertem Nusret Tas",
      "David Tse"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2209.04030",
    "title": "Unraveling the Connections between Privacy and Certified Robustness in  Federated Learning Against Poisoning Attacks",
    "abstract": " Comments: ACM CCS 2023 ",
    "url": "https://arxiv.org/abs/2209.04030",
    "authors": [
      "Chulin Xie",
      "Yunhui Long",
      "Pin-Yu Chen",
      "Qinbin Li",
      "Arash Nourian",
      "Sanmi Koyejo",
      "Bo Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06971",
    "title": "Shot-frugal and Robust quantum kernel classifiers",
    "abstract": " Comments: 25 pages, 8 figs, 6 tables ",
    "url": "https://arxiv.org/abs/2210.06971",
    "authors": [
      "Abhay Shastry",
      "Abhijith Jayakumar",
      "Apoorva Patel",
      "Chiranjib Bhattacharyya"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14416",
    "title": "Residual Back Projection With Untrained Neural Networks",
    "abstract": " Title: Residual Back Projection With Untrained Neural Networks ",
    "url": "https://arxiv.org/abs/2210.14416",
    "authors": [
      "Ziyu Shu",
      "Alireza Entezari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.04153",
    "title": "Solution to a problem of Katona on counting cliques of weighted graphs",
    "abstract": " Comments: 14 pages, minor corrections made ",
    "url": "https://arxiv.org/abs/2211.04153",
    "authors": [
      "Peter Borg",
      "Carl Feghali",
      "R\u00e9mi Pellerin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.08508",
    "title": "Characterizing and Utilizing the Interplay between Quantum Technologies  and Non-Terrestrial Networks",
    "abstract": " Title: Characterizing and Utilizing the Interplay between Quantum Technologies  and Non-Terrestrial Networks ",
    "url": "https://arxiv.org/abs/2211.08508",
    "authors": [
      "Hayder Al-Hraishawi",
      "Junaid ur Rehman",
      "Mohsen Razavi",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12526",
    "title": "Outer Bounds on the CEO Problem with Privacy Constraints",
    "abstract": " Comments: 14 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2301.12526",
    "authors": [
      "Vamoua Yachongka",
      "Hideki Yagi",
      "Hideki Ochiai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.00293",
    "title": "A Survey of Methods, Challenges and Perspectives in Causality",
    "abstract": " Comments: 40 pages, 37 pages for the main paper and 3 pages for the supplement, 8 figures, submitted to ACM Computing Surveys ",
    "url": "https://arxiv.org/abs/2302.00293",
    "authors": [
      "Ga\u00ebl Gendron",
      "Michael Witbrock",
      "Gillian Dobbie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.05765",
    "title": "Adversarial Online Collaborative Filtering",
    "abstract": " Title: Adversarial Online Collaborative Filtering ",
    "url": "https://arxiv.org/abs/2302.05765",
    "authors": [
      "Stephen Pasteris",
      "Fabio Vitale",
      "Mark Herbster",
      "Claudio Gentile",
      "Andre' Panisson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16212",
    "title": "A Multi-objective Complex Network Pruning Framework Based on  Divide-and-conquer and Global Performance Impairment Ranking",
    "abstract": " Title: A Multi-objective Complex Network Pruning Framework Based on  Divide-and-conquer and Global Performance Impairment Ranking ",
    "url": "https://arxiv.org/abs/2303.16212",
    "authors": [
      "Ronghua Shang",
      "Songling Zhu",
      "Yinan Wu",
      "Weitong Zhang",
      "Licheng Jiao",
      "Songhua Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.13710",
    "title": "Hopfield model with planted patterns: a teacher-student self-supervised  learning model",
    "abstract": " Comments: 27 pages, 5 figures, typo in the free energy corrected ",
    "url": "https://arxiv.org/abs/2304.13710",
    "authors": [
      "Francesco Alemanno",
      "Luca Camanzi",
      "Gianluca Manzan",
      "Daniele Tantari"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2305.09126",
    "title": "Transfer Learning for Causal Effect Estimation",
    "abstract": " Comments: Preliminary version, titled \"Transfer causal learning: Causal effect estimation with knowledge transfer\", has been presented in ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH), 2023; see the arXiv version in v2 ",
    "url": "https://arxiv.org/abs/2305.09126",
    "authors": [
      "Song Wei",
      "Hanyu Zhang",
      "Ronald Moore",
      "Rishikesan Kamaleswaran",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16283",
    "title": "CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graph  Diffusion",
    "abstract": " Comments: NeurIPS 2023 camera-ready ",
    "url": "https://arxiv.org/abs/2305.16283",
    "authors": [
      "Guangyao Zhai",
      "Evin P\u0131nar \u00d6rnek",
      "Shun-Cheng Wu",
      "Yan Di",
      "Federico Tombari",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16943",
    "title": "DiffusionNAG: Predictor-guided Neural Architecture Generation with  Diffusion Models",
    "abstract": " Title: DiffusionNAG: Predictor-guided Neural Architecture Generation with  Diffusion Models ",
    "url": "https://arxiv.org/abs/2305.16943",
    "authors": [
      "Sohyun An",
      "Hayeon Lee",
      "Jaehyeong Jo",
      "Seanie Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17939",
    "title": "Fourier Analysis on Robustness of Graph Convolutional Neural Networks  for Skeleton-based Action Recognition",
    "abstract": " Comments: 18 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2305.17939",
    "authors": [
      "Nariki Tanaka",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18601",
    "title": "BRICS: Bi-level feature Representation of Image CollectionS",
    "abstract": " Title: BRICS: Bi-level feature Representation of Image CollectionS ",
    "url": "https://arxiv.org/abs/2305.18601",
    "authors": [
      "Dingdong Yang",
      "Yizhi Wang",
      "Ali Mahdavi-Amiri",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.12345",
    "title": "The Effect of Noise on the Emergence of Continuous Norms and its  Evolutionary Dynamics",
    "abstract": " Comments: Accepted for publication in the Proceedings of the Artificial Life Conference 2023 (ALIFE 2023), MIT Press ",
    "url": "https://arxiv.org/abs/2306.12345",
    "authors": [
      "Stavros Anagnou",
      "Daniel Polani",
      "Christoph Salge"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2306.13319",
    "title": "A SAT Solver and Computer Algebra Attack on the Minimum Kochen-Specker  Problem",
    "abstract": " Title: A SAT Solver and Computer Algebra Attack on the Minimum Kochen-Specker  Problem ",
    "url": "https://arxiv.org/abs/2306.13319",
    "authors": [
      "Zhengyu Li",
      "Curtis Bright",
      "Vijay Ganesh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.13746",
    "title": "Revisiting inference after prediction",
    "abstract": " Title: Revisiting inference after prediction ",
    "url": "https://arxiv.org/abs/2306.13746",
    "authors": [
      "Keshav Motwani",
      "Daniela Witten"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13941",
    "title": "Grassroots Social Networking: Where Members Own and Control their  Personal Information and Social Graph",
    "abstract": " Title: Grassroots Social Networking: Where Members Own and Control their  Personal Information and Social Graph ",
    "url": "https://arxiv.org/abs/2306.13941",
    "authors": [
      "Ehud Shapiro"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.03407",
    "title": "Spatially Varying Nanophotonic Neural Networks",
    "abstract": " Title: Spatially Varying Nanophotonic Neural Networks ",
    "url": "https://arxiv.org/abs/2308.03407",
    "authors": [
      "Kaixuan Wei",
      "Xiao Li",
      "Johannes Froech",
      "Praneeth Chakravarthula",
      "James Whitehead",
      "Ethan Tseng",
      "Arka Majumdar",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.04102",
    "title": "Asynchronous Evolution of Deep Neural Network Architectures",
    "abstract": " Title: Asynchronous Evolution of Deep Neural Network Architectures ",
    "url": "https://arxiv.org/abs/2308.04102",
    "authors": [
      "Jason Liang",
      "Hormoz Shahrzad",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06412",
    "title": "Taming Self-Training for Open-Vocabulary Object Detection",
    "abstract": " Comments: 19 pages, 8 figures. Code: this https URL ",
    "url": "https://arxiv.org/abs/2308.06412",
    "authors": [
      "Shiyu Zhao",
      "Samuel Schulter",
      "Long Zhao",
      "Zhixing Zhang",
      "Vijay Kumar B.G",
      "Yumin Suh",
      "Manmohan Chandraker",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10273",
    "title": "Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing  Continuous Conditional Generative Adversarial Networks",
    "abstract": " Title: Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing  Continuous Conditional Generative Adversarial Networks ",
    "url": "https://arxiv.org/abs/2308.10273",
    "authors": [
      "Xin Ding",
      "Yongwei Wang",
      "Zuheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.12210",
    "title": "ULDP-FL: Federated Learning with Across Silo User-Level Differential  Privacy",
    "abstract": " Title: ULDP-FL: Federated Learning with Across Silo User-Level Differential  Privacy ",
    "url": "https://arxiv.org/abs/2308.12210",
    "authors": [
      "Fumiyuki Kato",
      "Li Xiong",
      "Shun Takagi",
      "Yang Cao",
      "Masatoshi Yoshikawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.14279",
    "title": "Sampling unknown large networks restricted by low sampling rates",
    "abstract": " Comments: 25 pages,11 figures ",
    "url": "https://arxiv.org/abs/2308.14279",
    "authors": [
      "Bo Jiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.00993",
    "title": "A Boosted Machine Learning Framework for the Improvement of Phase and  Crystal Structure Prediction of High Entropy Alloys Using Thermodynamic and  Configurational Parameters",
    "abstract": " Comments: We want to modify this paper and extend some parts of it ",
    "url": "https://arxiv.org/abs/2309.00993",
    "authors": [
      "Debsundar Dey",
      "Suchandan Das",
      "Anik Pal",
      "Santanu Dey",
      "Chandan Kumar Raul",
      "Arghya Chatterjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03537",
    "title": "Data-Adaptive Graph Framelets with Generalized Vanishing Moments for  Graph Signal Processing",
    "abstract": " Title: Data-Adaptive Graph Framelets with Generalized Vanishing Moments for  Graph Signal Processing ",
    "url": "https://arxiv.org/abs/2309.03537",
    "authors": [
      "Ruigang Zheng",
      "Xiaosheng Zhuang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11766",
    "title": "Dictionary Attack on IMU-based Gait Authentication",
    "abstract": " Comments: 12 pages, 9 figures, accepted at AISec23 colocated with ACM CCS, November 30, 2023, Copenhagen, Denmark ",
    "url": "https://arxiv.org/abs/2309.11766",
    "authors": [
      "Rajesh Kumar",
      "Can Isik",
      "Chilukuri K. Mohan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.02128",
    "title": "Semantic Code Graph -- an information model to facilitate software  comprehension",
    "abstract": " Title: Semantic Code Graph -- an information model to facilitate software  comprehension ",
    "url": "https://arxiv.org/abs/2310.02128",
    "authors": [
      "Krzysztof Borowski",
      "Bartosz Bali\u015b",
      "Tomasz Orzechowski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.03940",
    "title": "Hard View Selection for Self-Supervised Learning",
    "abstract": " Title: Hard View Selection for Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2310.03940",
    "authors": [
      "Fabio Ferreira",
      "Ivo Rapant",
      "Frank Hutter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05450",
    "title": "Empower Nested Boolean Logic via Self-Supervised Curriculum Learning",
    "abstract": " Comments: Accepted by EMNLP2023 ",
    "url": "https://arxiv.org/abs/2310.05450",
    "authors": [
      "Hongqiu Wu",
      "Linfeng Liu",
      "Hai Zhao",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09130",
    "title": "Split-and-Denoise: Protect large language model inference with local  differential privacy",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2310.09130",
    "authors": [
      "Peihua Mai",
      "Ran Yan",
      "Zhe Huang",
      "Youjia Yang",
      "Yan Pang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.10483",
    "title": "Passive Inference Attacks on Split Learning via Adversarial  Regularization",
    "abstract": " Comments: 17 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2310.10483",
    "authors": [
      "Xiaochen Zhu",
      "Xinjian Luo",
      "Yuncheng Wu",
      "Yangfan Jiang",
      "Xiaokui Xiao",
      "Beng Chin Ooi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01752",
    "title": "Low Overhead Beam Alignment for Mobile Millimeter Channel Based on  Continuous-Time Prediction",
    "abstract": " Comments: To be published in the proceedings of IEEE WCNC 2024 ",
    "url": "https://arxiv.org/abs/2311.01752",
    "authors": [
      "Huang-Chou Lin",
      "Kuang-Hao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.03198",
    "title": "LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for  Place Recognition",
    "abstract": " Comments: Accepted by IEEE Robotics and Automation Letters (RAL) 2023 ",
    "url": "https://arxiv.org/abs/2311.03198",
    "authors": [
      "Zijie Zhou",
      "Jingyi Xu",
      "Guangming Xiong",
      "Junyi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.06542",
    "title": "Generation Of Colors using Bidirectional Long Short Term Memory Networks",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2311.06542",
    "authors": [
      "A. Sinha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10116",
    "title": "Wildfire Smoke Detection with Cross Contrast Patch Embedding",
    "abstract": " Title: Wildfire Smoke Detection with Cross Contrast Patch Embedding ",
    "url": "https://arxiv.org/abs/2311.10116",
    "authors": [
      "Chong Wang",
      "Cheng Xu",
      "Adeel Akram",
      "Zhilin Shan",
      "Qixing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.13091",
    "title": "Stable Unlearnable Example: Enhancing the Robustness of Unlearnable  Examples via Stable Error-Minimizing Noise",
    "abstract": " Comments: Accepted to AAAI 2024 ",
    "url": "https://arxiv.org/abs/2311.13091",
    "authors": [
      "Yixin Liu",
      "Kaidi Xu",
      "Xun Chen",
      "Lichao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.15654",
    "title": "Event Detection in Time Series: Universal Deep Learning Approach",
    "abstract": " Comments: To be submitted to ICML 2024 ",
    "url": "https://arxiv.org/abs/2311.15654",
    "authors": [
      "Menouar Azib",
      "Benjamin Renard",
      "Philippe Garnier",
      "Vincent G\u00e9not",
      "Nicolas Andr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.04501",
    "title": "Graph Metanetworks for Processing Diverse Neural Architectures",
    "abstract": " Comments: 29 pages. v2 updated experimental results and details ",
    "url": "https://arxiv.org/abs/2312.04501",
    "authors": [
      "Derek Lim",
      "Haggai Maron",
      "Marc T. Law",
      "Jonathan Lorraine",
      "James Lucas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.05241",
    "title": "Contra generative AI detection in higher education assessments",
    "abstract": " Comments: v2: added references, fixed typos. 20 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2312.05241",
    "authors": [
      "Cesare G. Ardito"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.06907",
    "title": "w2v-SELD: A Sound Event Localization and Detection Framework for  Self-Supervised Spatial Audio Pre-Training",
    "abstract": " Comments: 17 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2312.06907",
    "authors": [
      "Orlem Lima dos Santos",
      "Karen Rosero",
      "Roberto de Alencar Lotufo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.08299",
    "title": "Conceptualizing Suicidal Behavior: Utilizing Explanations of Predicted  Outcomes to Analyze Longitudinal Social Media Data",
    "abstract": " Comments: Presented at ICMLA 2023, Special Session: Machine Learning in Health, 8 pages, 6 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2312.08299",
    "authors": [
      "Van Minh Nguyen",
      "Nasheen Nur",
      "William Stern",
      "Thomas Mercer",
      "Chiradeep Sen",
      "Siddhartha Bhattacharyya",
      "Victor Tumbiolo",
      "Seng Jhing Goh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.09086",
    "title": "COMBHelper: A Neural Approach to Reduce Search Space for Graph  Combinatorial Problems",
    "abstract": " Title: COMBHelper: A Neural Approach to Reduce Search Space for Graph  Combinatorial Problems ",
    "url": "https://arxiv.org/abs/2312.09086",
    "authors": [
      "Hao Tian",
      "Sourav Medya",
      "Wei Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.10402",
    "title": "Annotation-free Automatic Music Transcription with Scalable Synthetic  Data and Adversarial Domain Confusion",
    "abstract": " Comments: 7 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2312.10402",
    "authors": [
      "Gakusei Sato",
      "Taketo Akama"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.15826",
    "title": "Adversarial Item Promotion on Visually-Aware Recommender Systems by  Guided Diffusion",
    "abstract": " Title: Adversarial Item Promotion on Visually-Aware Recommender Systems by  Guided Diffusion ",
    "url": "https://arxiv.org/abs/2312.15826",
    "authors": [
      "Lijian Chen",
      "Wei Yuan",
      "Tong Chen",
      "Quoc Viet Hung Nguyen",
      "Guanhua Ye",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.16580",
    "title": "VLCounter: Text-aware Visual Representation for Zero-Shot Object  Counting",
    "abstract": " Comments: Accepted to AAAI 2024. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2312.16580",
    "authors": [
      "Seunggu Kang",
      "WonJun Moon",
      "Euiyeon Kim",
      "Jae-Pil Heo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.17122",
    "title": "Large Language Model for Causal Decision Making",
    "abstract": " Title: Large Language Model for Causal Decision Making ",
    "url": "https://arxiv.org/abs/2312.17122",
    "authors": [
      "Haitao Jiang",
      "Lin Ge",
      "Yuhe Gao",
      "Jianian Wang",
      "Rui Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.17163",
    "title": "FENet: Focusing Enhanced Network for Lane Detection",
    "abstract": " Comments: 12 pages including appendix. The website will be released soon ",
    "url": "https://arxiv.org/abs/2312.17163",
    "authors": [
      "Liman Wang",
      "Hanyang Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]