[
  {
    "id": "arXiv:2401.01341",
    "title": "ATLASv2: ATLAS Attack Engagements, Version 2",
    "abstract": "ATLASv2 is based on a previously generated dataset included in \"ATLAS: A Sequence-based Learning Approach for Attack Investigation.\" The original ATLAS dataset is comprised of Windows Security Auditing system logs, Firefox logs, and DNS logs via WireShark. In ATLASv2, we aim to enrich the ATLAS dataset with higher quality background noise and additional logging vantage points. This work replicates the ten attack scenarios described in ATLAS, but extends the logging to include Sysmon logs and events tracked through VMware Carbon Black Cloud. The main contribution of ATLASv2 is to improve the quality of the benign system activity and the integration of the attack scenarios. Instead of relying on automated scripts to generate activity, we had two researchers use the victim machines as their primary work stations throughout the course of the engagement. This allowed us to capture system logs on actual user behavior. Additionally, the researchers conducted the attacks in a lab setup allowing the integration of the attack into the work flow of the victim user. This allows the ATLASv2 dataset to provide realistic system logs that mirror the system log activity generated in real-world attacks. ",
    "url": "https://arxiv.org/abs/2401.01341",
    "authors": [
      "Andy Riddle",
      "Kim Westfall",
      "Adam Bates"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.01342",
    "title": "Securing the Digital World: Protecting smart infrastructures and digital  industries with Artificial Intelligence (AI)-enabled malware and intrusion  detection",
    "abstract": "The last decades have been characterized by unprecedented technological advances, many of them powered by modern technologies such as Artificial Intelligence (AI) and Machine Learning (ML). The world has become more digitally connected than ever, but we face major challenges. One of the most significant is cybercrime, which has emerged as a global threat to governments, businesses, and civil societies. The pervasiveness of digital technologies combined with a constantly shifting technological foundation has created a complex and powerful playground for cybercriminals, which triggered a surge in demand for intelligent threat detection systems based on machine and deep learning. This paper investigates AI-based cyber threat detection to protect our modern digital ecosystems. The primary focus is on evaluating ML-based classifiers and ensembles for anomaly-based malware detection and network intrusion detection and how to integrate those models in the context of network security, mobile security, and IoT security. The discussion highlights the challenges when deploying and integrating AI-enabled cybersecurity solutions into existing enterprise systems and IT infrastructures, including options to overcome those challenges. Finally, the paper provides future research directions to further increase the security and resilience of our modern digital industries, infrastructures, and ecosystems. ",
    "url": "https://arxiv.org/abs/2401.01342",
    "authors": [
      "Marc Schmitt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01343",
    "title": "IoTGeM: Generalizable Models for Behaviour-Based IoT Attack Detection",
    "abstract": "Previous research on behaviour-based attack detection on networks of IoT devices has resulted in machine learning models whose ability to adapt to unseen data is limited, and often not demonstrated. In this paper we present an approach for modelling IoT network attacks that focuses on generalizability, yet also leads to better detection and performance. First, we present an improved rolling window approach for feature extraction, and introduce a multi-step feature selection process that reduces overfitting. Second, we build and test models using isolated train and test datasets, thereby avoiding common data leaks that have limited the generalizability of previous models. Third, we rigorously evaluate our methodology using a diverse portfolio of machine learning models, evaluation metrics and datasets. Finally, we build confidence in the models by using explainable AI techniques, allowing us to identify the features that underlie accurate detection of attacks. ",
    "url": "https://arxiv.org/abs/2401.01343",
    "authors": [
      "Kahraman Kostas",
      "Mike Just",
      "Michael A. Lones"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2401.01361",
    "title": "Optimizing Convolutional Neural Network Architecture",
    "abstract": "Convolutional Neural Networks (CNN) are widely used to face challenging tasks like speech recognition, natural language processing or computer vision. As CNN architectures get larger and more complex, their computational requirements increase, incurring significant energetic costs and challenging their deployment on resource-restricted devices. In this paper, we propose Optimizing Convolutional Neural Network Architecture (OCNNA), a novel CNN optimization and construction method based on pruning and knowledge distillation designed to establish the importance of convolutional layers. The proposal has been evaluated though a thorough empirical study including the best known datasets (CIFAR-10, CIFAR-100 and Imagenet) and CNN architectures (VGG-16, ResNet-50, DenseNet-40 and MobileNet), setting Accuracy Drop and Remaining Parameters Ratio as objective metrics to compare the performance of OCNNA against the other state-of-art approaches. Our method has been compared with more than 20 convolutional neural network simplification algorithms obtaining outstanding results. As a result, OCNNA is a competitive CNN constructing method which could ease the deployment of neural networks into IoT or resource-limited devices. ",
    "url": "https://arxiv.org/abs/2401.01361",
    "authors": [
      "Luis Balderas",
      "Miguel Lastra",
      "Jos\u00e9 M. Ben\u00edtez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01362",
    "title": "Assisting Blind People Using Object Detection with Vocal Feedback",
    "abstract": "For visually impaired people, it is highly difficult to make independent movement and safely move in both indoors and outdoors environment. Furthermore, these physically and visually challenges prevent them from in day-today live activities. Similarly, they have problem perceiving objects of surrounding environment that may pose a risk to them. The proposed approach suggests detection of objects in real-time video by using a web camera, for the object identification, process. You Look Only Once (YOLO) model is utilized which is CNN-based real-time object detection technique. Additionally, The OpenCV libraries of Python is used to implement the software program as well as deep learning process is performed. Image recognition results are transferred to the visually impaired users in audible form by means of Google text-to-speech library and determine object location relative to its position in the screen. The obtaining result was evaluated by using the mean Average Precision (mAP), and it was found that the proposed approach achieves excellent results when it compared to previous approaches. ",
    "url": "https://arxiv.org/abs/2401.01362",
    "authors": [
      "Heba Najm",
      "Khirallah Elferjani",
      "Alhaam Alariyibi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01370",
    "title": "Fast Quantum Convolutional Neural Networks for Low-Complexity Object  Detection in Autonomous Driving Applications",
    "abstract": "Spurred by consistent advances and innovation in deep learning, object detection applications have become prevalent, particularly in autonomous driving that leverages various visual data. As convolutional neural networks (CNNs) are being optimized, the performances and computation speeds of object detection in autonomous driving have been significantly improved. However, due to the exponentially rapid growth in the complexity and scale of data used in object detection, there are limitations in terms of computation speeds while conducting object detection solely with classical computing. Motivated by this, quantum convolution-based object detection (QCOD) is proposed to adopt quantum computing to perform object detection at high speed. The QCOD utilizes our proposed fast quantum convolution that uploads input channel information and re-constructs output channels for achieving reduced computational complexity and thus improving performances. Lastly, the extensive experiments with KITTI autonomous driving object detection dataset verify that the proposed fast quantum convolution and QCOD are successfully operated in real object detection applications. ",
    "url": "https://arxiv.org/abs/2401.01370",
    "authors": [
      "Hankyul Baek",
      "Donghyeon Kim",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2401.01373",
    "title": "Boosting Defect Detection in Manufacturing using Tensor Convolutional  Neural Networks",
    "abstract": "Defect detection is one of the most important yet challenging tasks in the quality control stage in the manufacturing sector. In this work, we introduce a Tensor Convolutional Neural Network (T-CNN) and examine its performance on a real defect detection application in one of the components of the ultrasonic sensors produced at Robert Bosch's manufacturing plants. Our quantum-inspired T-CNN operates on a reduced model parameter space to substantially improve the training speed and performance of an equivalent CNN model without sacrificing accuracy. More specifically, we demonstrate how T-CNNs are able to reach the same performance as classical CNNs as measured by quality metrics, with up to fifteen times fewer parameters and 4% to 19% faster training times. Our results demonstrate that the T-CNN greatly outperforms the results of traditional human visual inspection, providing value in a current real application in manufacturing. ",
    "url": "https://arxiv.org/abs/2401.01373",
    "authors": [
      "Pablo Martin-Ramiro",
      "Unai Sainz de la Maza",
      "Roman Orus",
      "Samuel Mugel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2401.01377",
    "title": "Does Few-shot Learning Suffer from Backdoor Attacks?",
    "abstract": "The field of few-shot learning (FSL) has shown promising results in scenarios where training data is limited, but its vulnerability to backdoor attacks remains largely unexplored. We first explore this topic by first evaluating the performance of the existing backdoor attack methods on few-shot learning scenarios. Unlike in standard supervised learning, existing backdoor attack methods failed to perform an effective attack in FSL due to two main issues. Firstly, the model tends to overfit to either benign features or trigger features, causing a tough trade-off between attack success rate and benign accuracy. Secondly, due to the small number of training samples, the dirty label or visible trigger in the support set can be easily detected by victims, which reduces the stealthiness of attacks. It seemed that FSL could survive from backdoor attacks. However, in this paper, we propose the Few-shot Learning Backdoor Attack (FLBA) to show that FSL can still be vulnerable to backdoor attacks. Specifically, we first generate a trigger to maximize the gap between poisoned and benign features. It enables the model to learn both benign and trigger features, which solves the problem of overfitting. To make it more stealthy, we hide the trigger by optimizing two types of imperceptible perturbation, namely attractive and repulsive perturbation, instead of attaching the trigger directly. Once we obtain the perturbations, we can poison all samples in the benign support set into a hidden poisoned support set and fine-tune the model on it. Our method demonstrates a high Attack Success Rate (ASR) in FSL tasks with different few-shot learning paradigms while preserving clean accuracy and maintaining stealthiness. This study reveals that few-shot learning still suffers from backdoor attacks, and its security should be given attention. ",
    "url": "https://arxiv.org/abs/2401.01377",
    "authors": [
      "Xinwei Liu",
      "Xiaojun Jia",
      "Jindong Gu",
      "Yuan Xun",
      "Siyuan Liang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01379",
    "title": "The predictive power of the Blockhain transaction networks: Towards a  new generation of network science market indicators",
    "abstract": "Currently cryptocurrencies and Decentralized Finance (DeFi), which enable financial services on public blockchains, represents a new growing trend in finance. In contrast to financial markets, ruled by traditional corporations, DeFi is completely transparent as it keeps records of all transactions that occur in the network and makes them publicly available. The availability of the data represents an opportunity to analyze and understand the market from the complexity that emerges from the interactions of the actors (users, bots and companies) operating in the embedded market. In this paper we focus on the Ethereum network and our main goal is to show that the properties of the underlying transaction network provide further and useful information to forecast the evolution of the market. We aim to separate the non redundant effects of the blockchain transaction network properties from classic technical indicators and social media trends in the future price of Ethereum. To this end, we build two machine learning models to predict the future trend of the market. The first one serves as a base model and considers a set of the most relevant features according to the current scientific literature including technical indicators and social media trends. The second model considers the features of the base model, together with the network properties computed from the transaction networks. We found that the full model outperforms the base model and can anticipate 46 more rises in the price than the base model and 19 more falls. ",
    "url": "https://arxiv.org/abs/2401.01379",
    "authors": [
      "Mar Grande",
      "Florentino Borondo",
      "Javier Borondo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2401.01384",
    "title": "Strong Transitivity Relations and Graph Neural Networks",
    "abstract": "Local neighborhoods play a crucial role in embedding generation in graph-based learning. It is commonly believed that nodes ought to have embeddings that resemble those of their neighbors. In this research, we try to carefully expand the concept of similarity from nearby neighborhoods to the entire graph. We provide an extension of similarity that is based on transitivity relations, which enables Graph Neural Networks (GNNs) to capture both global similarities and local similarities over the whole graph. We introduce Transitivity Graph Neural Network (TransGNN), which more than local node similarities, takes into account global similarities by distinguishing strong transitivity relations from weak ones and exploiting them. We evaluate our model over several real-world datasets and showed that it considerably improves the performance of several well-known GNN models, for tasks such as node classification. ",
    "url": "https://arxiv.org/abs/2401.01384",
    "authors": [
      "Yassin Mohamadi",
      "Mostafa Haghir Chehreghani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01394",
    "title": "Unveiling the Stealthy Threat: Analyzing Slow Drift GPS Spoofing Attacks  for Autonomous Vehicles in Urban Environments and Enabling the Resilience",
    "abstract": "Autonomous vehicles (AVs) rely on the Global Positioning System (GPS) or Global Navigation Satellite Systems (GNSS) for precise (Positioning, Navigation, and Timing) PNT solutions. However, the vulnerability of GPS signals to intentional and unintended threats due to their lack of encryption and weak signal strength poses serious risks, thereby reducing the reliability of AVs. GPS spoofing is a complex and damaging attack that deceives AVs by altering GPS receivers to calculate false position and tracking information leading to misdirection. This study explores a stealthy slow drift GPS spoofing attack, replicating the victim AV's satellite reception pattern while changing pseudo ranges to deceive the AV, particularly during turns. The attack is designed to gradually deviate from the correct route, making real-time detection challenging and jeopardizing user safety. We present a system and study methodology for constructing covert spoofing attacks on AVs, investigating the correlation between original and spoofed pseudo ranges to create effective defenses. By closely following the victim vehicle and using the same satellite signals, the attacker executes the attack precisely. Changing the pseudo ranges confuses the AV, leading it to incorrect destinations while remaining oblivious to the manipulation. The gradual deviation from the actual route further conceals the attack, hindering its swift identification. The experiments showcase a robust correlation between the original and spoofed pseudo ranges, with R square values varying between 0.99 and 1. This strong correlation facilitates effective evaluation and mitigation of spoofing signals. ",
    "url": "https://arxiv.org/abs/2401.01394",
    "authors": [
      "Sagar Dasgupta",
      "Abdullah Ahmed",
      "Mizanur Rahman",
      "Thejesh N. Bandi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.01404",
    "title": "Scalable network reconstruction in subquadratic time",
    "abstract": "Network reconstruction consists in determining the unobserved pairwise couplings between $N$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. A major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $O(N^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $O(N)$. Here we present a general algorithm applicable to a broad range of reconstruction problems that achieves its result in subquadratic time, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\\log N)$, but with a more typical log-linear complexity of $O(N\\log^2N)$. Our algorithm relies on a stochastic second neighbor search that produces the best edge candidates with high probability, thus bypassing an exhaustive quadratic search. In practice, our algorithm achieves a performance that is many orders of magnitude faster than the quadratic baseline, allows for easy parallelization, and thus enables the reconstruction of networks with hundreds of thousands and even millions of nodes and edges. ",
    "url": "https://arxiv.org/abs/2401.01404",
    "authors": [
      "Tiago P. Peixoto"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.01412",
    "title": "P-TimeSync: A Precise Time Synchronization Simulation with Network  Propagation Delays",
    "abstract": "Time serves as the foundation of modern society and will continue to grow in value in the future world. Unlike previous research papers, authors delve into various time sources, ranging from atomic time and GPS time to quartz time. Specifically, we explore the time uncertainty associated with the four major Global Navigation Satellite Systems. Additionally, we provide a summary of eight metrics used to evaluate time accuracy. In existing time synchronization simulations provide partial usages. However, our research introduces a comprehensive and precise time synchronization simulation named P-TimeSync, leading to a better understanding of time synchronization in distributed environments. It is a state-of-the-art simulation tool for time because (1) it can simulate atomic clocks and quartz clocks with user-defined software clock algorithms, (2) the simulation provides nanosecond-level precision time across different network propagation paths and distances, (3) the tool offers a visualization platform with classic algorithms for distributed time synchronization, such as Cristian's algorithm and Berkeley algorithm, and (4) the simulation includes three time-sync attack functions, including distributed denial-of-service (DDoS) attack, IP spoofer, and router hijacker. The simulation easily allows for the redefinition of configurations and functions, supporting advanced research and development. The simulation tool could be downloaded via the website: https://github.com/rui5097/purdue_timesync ",
    "url": "https://arxiv.org/abs/2401.01412",
    "authors": [
      "Wei Dai",
      "Rui Zhang",
      "Jinwei Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2401.01416",
    "title": "Flexible Control Flow Graph Alignment for Delivering Data-Driven  Feedback to Novice Programming Learners",
    "abstract": "Supporting learners in introductory programming assignments at scale is a necessity. This support includes automated feedback on what learners did incorrectly. Existing approaches cast the problem as automatically repairing learners' incorrect programs extrapolating the data from an existing correct program from other learners. However, such approaches are limited because they only compare programs with similar control flow and order of statements. A potentially valuable set of repair feedback from flexible comparisons is thus missing. In this paper, we present several modifications to CLARA, a data-driven automated repair approach that is open source, to deal with real-world introductory programs. We extend CLARA's abstract syntax tree processor to handle common introductory programming constructs. Additionally, we propose a flexible alignment algorithm over control flow graphs where we enrich nodes with semantic annotations extracted from programs using operations and calls. Using this alignment, we modify an incorrect program's control flow graph to match the correct programs to apply CLARA's original repair process. We evaluate our approach against a baseline on the twenty most popular programming problems in Codeforces. Our results indicate that flexible alignment has a significantly higher percentage of successful repairs at 46% compared to 5% for baseline CLARA. Our implementation is available at https://github.com/towhidabsar/clara. ",
    "url": "https://arxiv.org/abs/2401.01416",
    "authors": [
      "Md Towhidul Absar Chowdhury",
      "Maheen Riaz Contractor",
      "Carlos R. Rivero"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.01426",
    "title": "Modular Learning of Deep Causal Generative Models for High-dimensional  Causal Inference",
    "abstract": "Pearl's causal hierarchy establishes a clear separation between observational, interventional, and counterfactual questions. Researchers proposed sound and complete algorithms to compute identifiable causal queries at a given level of the hierarchy using the causal structure and data from the lower levels of the hierarchy. However, most of these algorithms assume that we can accurately estimate the probability distribution of the data, which is an impractical assumption for high-dimensional variables such as images. On the other hand, modern generative deep learning architectures can be trained to learn how to accurately sample from such high-dimensional distributions. Especially with the recent rise of foundation models for images, it is desirable to leverage pre-trained models to answer causal queries with such high-dimensional data. To address this, we propose a sequential training algorithm that, given the causal structure and a pre-trained conditional generative model, can train a deep causal generative model, which utilizes the pre-trained model and can provably sample from identifiable interventional and counterfactual distributions. Our algorithm, called Modular-DCM, uses adversarial training to learn the network weights, and to the best of our knowledge, is the first algorithm that can make use of pre-trained models and provably sample from any identifiable causal query in the presence of latent confounders with high-dimensional data. We demonstrate the utility of our algorithm using semi-synthetic and real-world datasets containing images as variables in the causal structure. ",
    "url": "https://arxiv.org/abs/2401.01426",
    "authors": [
      "Md Musfiqur Rahman",
      "Murat Kocaoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.01458",
    "title": "Concurrent Self-testing of Neural Networks Using Uncertainty Fingerprint",
    "abstract": "Neural networks (NNs) are increasingly used in always-on safety-critical applications deployed on hardware accelerators (NN-HAs) employing various memory technologies. Reliable continuous operation of NN is essential for safety-critical applications. During online operation, NNs are susceptible to single and multiple permanent and soft errors due to factors such as radiation, aging, and thermal effects. Explicit NN-HA testing methods cannot detect transient faults during inference, are unsuitable for always-on applications, and require extensive test vector generation and storage. Therefore, in this paper, we propose the \\emph{uncertainty fingerprint} approach representing the online fault status of NN. Furthermore, we propose a dual head NN topology specifically designed to produce uncertainty fingerprints and the primary prediction of the NN in \\emph{a single shot}. During the online operation, by matching the uncertainty fingerprint, we can concurrently self-test NNs with up to $100\\%$ coverage with a low false positive rate while maintaining a similar performance of the primary task. Compared to existing works, memory overhead is reduced by up to $243.7$ MB, multiply and accumulate (MAC) operation is reduced by up to $10000\\times$, and false-positive rates are reduced by up to $89\\%$. ",
    "url": "https://arxiv.org/abs/2401.01458",
    "authors": [
      "Soyed Tuhin Ahmed",
      "Mehdi B. tahoori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2401.01476",
    "title": "On Rank-Monotone Graph Operations and Minimal Obstruction Graphs for the  Lov\u00e1sz--Schrijver SDP Hierarchy",
    "abstract": "We study the lift-and-project rank of the stable set polytopes of graphs with respect to the Lov\\'{a}sz--Schrijver SDP operator $\\text{LS}_+$, with a particular focus on finding and characterizing the smallest graphs with a given $\\text{LS}_+$-rank (the least number of iterations of the $\\text{LS}_+$ operator on the fractional stable set polytope to compute the stable set polytope). We introduce a generalized vertex-stretching operation that appears to be promising in generating $\\text{LS}_+$-minimal graphs and study its properties. We also provide several new $\\text{LS}_+$-minimal graphs, most notably the first known instances of $12$-vertex graphs with $\\text{LS}_+$-rank $4$, which provides the first advance in this direction since Escalante, Montelar, and Nasini's discovery of a $9$-vertex graph with $\\text{LS}_+$-rank $3$ in 2006. ",
    "url": "https://arxiv.org/abs/2401.01476",
    "authors": [
      "Yu Hin Au",
      "Levent Tun\u00e7el"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2401.01482",
    "title": "Incorporating Geo-Diverse Knowledge into Prompting for Increased  Geographical Robustness in Object Recognition",
    "abstract": "Existing object recognition models have been shown to lack robustness in diverse geographical scenarios due to significant domain shifts in design and context. Class representations need to be adapted to more accurately reflect an object concept under these shifts. In the absence of training data from target geographies, we hypothesize that geography-specific descriptive knowledge of object categories can be leveraged to enhance robustness. For this purpose, we explore the feasibility of probing a large-language model for geography-specific object knowledge, and we investigate integrating knowledge in zero-shot and learnable soft prompting with the CLIP vision-language model. In particular, we propose a geography knowledge regularization method to ensure that soft prompts trained on a source set of geographies generalize to an unseen target set of geographies. Our gains on DollarStreet when generalizing from a model trained only on data from Europe are as large as +2.8 on countries from Africa, and +4.6 on the hardest classes. We further show competitive performance vs. few-shot target training, and provide insights into how descriptive knowledge captures geographical differences. ",
    "url": "https://arxiv.org/abs/2401.01482",
    "authors": [
      "Kyle Buettner",
      "Sina Malakouti",
      "Xiang Lorraine Li",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01487",
    "title": "Natural Language Processing and Multimodal Stock Price Prediction",
    "abstract": "In the realm of financial decision-making, predicting stock prices is pivotal. Artificial intelligence techniques such as long short-term memory networks (LSTMs), support-vector machines (SVMs), and natural language processing (NLP) models are commonly employed to predict said prices. This paper utilizes stock percentage change as training data, in contrast to the traditional use of raw currency values, with a focus on analyzing publicly released news articles. The choice of percentage change aims to provide models with context regarding the significance of price fluctuations and overall price change impact on a given stock. The study employs specialized BERT natural language processing models to predict stock price trends, with a particular emphasis on various data modalities. The results showcase the capabilities of such strategies with a small natural language processing model to accurately predict overall stock trends, and highlight the effectiveness of certain data features and sector-specific data. ",
    "url": "https://arxiv.org/abs/2401.01487",
    "authors": [
      "Kevin Taylor",
      "Jerry Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.01491",
    "title": "A Hybrid Neural Network Model For Predicting The Nitrate Concentration  In The Recirculating Aquaculture System",
    "abstract": "This study was groundbreaking in its application of neural network models for nitrate management in the Recirculating Aquaculture System (RAS). A hybrid neural network model was proposed, which accurately predicted daily nitrate concentration and its trends using six water quality parameters. We conducted a 105-day aquaculture experiment, during which we collected 450 samples from five sets of RAS to train our model (C-L-A model) which incorporates Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and self-Attention. Furthermore, we obtained 90 samples from a standalone RAS as the testing data to evaluate the performance of the model in practical applications. The experimental results proved that the C-L-A model accurately predicted nitrate concentration in RAS and maintained good performance even with a reduced proportion of training data. We recommend using water quality parameters from the past 7 days to forecast future nitrate concentration, as this timeframe allows the model to achieve maximum generalization capability. Additionally, we compared the performance of the C-L-A model with three basic neural network models (CNN, LSTM, self-Attention) as well as three hybrid neural network models (CNN-LSTM, CNN-Attention, LSTM-Attention). The results demonstrated that the C-L-A model (R2=0.956) significantly outperformed the other neural network models (R2=0.901-0.927). Our study suggests that the utilization of neural network models, specifically the C-L-A model, could potentially assist the RAS industry in conserving resources for daily nitrate monitoring. ",
    "url": "https://arxiv.org/abs/2401.01491",
    "authors": [
      "Xiangyu Fan",
      "Jiaxin Lia",
      "Yingzhe Wang",
      "Yingsha Qu",
      "Hao Li",
      "Keming Qu",
      "Zhengguo Cui"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2401.01495",
    "title": "A Two-Stage Multimodal Emotion Recognition Model Based on Graph  Contrastive Learning",
    "abstract": "In terms of human-computer interaction, it is becoming more and more important to correctly understand the user's emotional state in a conversation, so the task of multimodal emotion recognition (MER) started to receive more attention. However, existing emotion classification methods usually perform classification only once. Sentences are likely to be misclassified in a single round of classification. Previous work usually ignores the similarities and differences between different morphological features in the fusion process. To address the above issues, we propose a two-stage emotion recognition model based on graph contrastive learning (TS-GCL). First, we encode the original dataset with different preprocessing modalities. Second, a graph contrastive learning (GCL) strategy is introduced for these three modal data with other structures to learn similarities and differences within and between modalities. Finally, we use MLP twice to achieve the final emotion classification. This staged classification method can help the model to better focus on different levels of emotional information, thereby improving the performance of the model. Extensive experiments show that TS-GCL has superior performance on IEMOCAP and MELD datasets compared with previous methods. ",
    "url": "https://arxiv.org/abs/2401.01495",
    "authors": [
      "Wei Ai",
      "FuChen Zhang",
      "Tao Meng",
      "YunTao Shou",
      "HongEn Shao",
      "Keqin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.01502",
    "title": "Pontryagin Neural Operator for Solving Parametric General-Sum  Differential Games",
    "abstract": "The values of two-player general-sum differential games are viscosity solutions to Hamilton-Jacobi-Isaacs (HJI) equations. Value and policy approximations for such games suffer from the curse of dimensionality (CoD). Alleviating CoD through physics-informed neural networks (PINN) encounters convergence issues when value discontinuity is present due to state constraints. On top of these challenges, it is often necessary to learn generalizable values and policies across a parametric space of games, e.g., for game parameter inference when information is incomplete. To address these challenges, we propose in this paper a Pontryagin-mode neural operator that outperforms existing state-of-the-art (SOTA) on safety performance across games with parametric state constraints. Our key contribution is the introduction of a costate loss defined on the discrepancy between forward and backward costate rollouts, which are computationally cheap. We show that the discontinuity of costate dynamics (in the presence of state constraints) effectively enables the learning of discontinuous values, without requiring manually supervised data as suggested by the current SOTA. More importantly, we show that the close relationship between costates and policies makes the former critical in learning feedback control policies with generalizable safety performance. ",
    "url": "https://arxiv.org/abs/2401.01502",
    "authors": [
      "Lei Zhang",
      "Mukesh Ghimire",
      "Zhe Xu",
      "Wenlong Zhang",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2401.01505",
    "title": "Sports-QA: A Large-Scale Video Question Answering Benchmark for Complex  and Professional Sports",
    "abstract": "Reasoning over sports videos for question answering is an important task with numerous applications, such as player training and information retrieval. However, this task has not been explored due to the lack of relevant datasets and the challenging nature it presents. Most datasets for video question answering (VideoQA) focus mainly on general and coarse-grained understanding of daily-life videos, which is not applicable to sports scenarios requiring professional action understanding and fine-grained motion analysis. In this paper, we introduce the first dataset, named Sports-QA, specifically designed for the sports VideoQA task. The Sports-QA dataset includes various types of questions, such as descriptions, chronologies, causalities, and counterfactual conditions, covering multiple sports. Furthermore, to address the characteristics of the sports VideoQA task, we propose a new Auto-Focus Transformer (AFT) capable of automatically focusing on particular scales of temporal information for question answering. We conduct extensive experiments on Sports-QA, including baseline studies and the evaluation of different methods. The results demonstrate that our AFT achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2401.01505",
    "authors": [
      "Haopeng Li",
      "Andong Deng",
      "Qiuhong Ke",
      "Jun Liu",
      "Hossein Rahmani",
      "Yulan Guo",
      "Bernt Schiele",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01521",
    "title": "Quantum Leak: Timing Side-Channel Attacks on Cloud-Based Quantum  Services",
    "abstract": "Quantum computing offers significant acceleration capabilities over its classical counterpart in various application domains. Consequently, there has been substantial focus on improving quantum computing capabilities. However, to date, the security implications of these quantum computing platforms have been largely overlooked. With the emergence of cloud-based quantum computing services, it is critical to investigate the extension of classical computer security threats to the realm of quantum computing. In this study, we investigated timing-based side-channel vulnerabilities within IBM's cloud-based quantum service. The proposed attack effectively subverts the confidentiality of the executed quantum algorithm, using a more realistic threat model compared to existing approaches. Our experimental results, conducted using IBM's quantum cloud service, demonstrate that with just 10 measurements, it is possible to identify the underlying quantum computer that executed the circuit. Moreover, when evaluated using the popular Grover circuit, we showcase the ability to leak the quantum oracle with a mere 500 measurements. These findings underline the pressing need to address timing-based vulnerabilities in quantum computing platforms and advocate for enhanced security measures to safeguard sensitive quantum algorithms and data. ",
    "url": "https://arxiv.org/abs/2401.01521",
    "authors": [
      "Chao Lu",
      "Esha Telang",
      "Aydin Aysu",
      "Kanad Basu"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2401.01522",
    "title": "LORE++: Logical Location Regression Network for Table Structure  Recognition with Pre-training",
    "abstract": "Table structure recognition (TSR) aims at extracting tables in images into machine-understandable formats. Recent methods solve this problem by predicting the adjacency relations of detected cell boxes or learning to directly generate the corresponding markup sequences from the table images. However, existing approaches either count on additional heuristic rules to recover the table structures, or face challenges in capturing long-range dependencies within tables, resulting in increased complexity. In this paper, we propose an alternative paradigm. We model TSR as a logical location regression problem and propose a new TSR framework called LORE, standing for LOgical location REgression network, which for the first time regresses logical location as well as spatial location of table cells in a unified network. Our proposed LORE is conceptually simpler, easier to train, and more accurate than other paradigms of TSR. Moreover, inspired by the persuasive success of pre-trained models on a number of computer vision and natural language processing tasks, we propose two pre-training tasks to enrich the spatial and logical representations at the feature level of LORE, resulting in an upgraded version called LORE++. The incorporation of pre-training in LORE++ has proven to enjoy significant advantages, leading to a substantial enhancement in terms of accuracy, generalization, and few-shot capability compared to its predecessor. Experiments on standard benchmarks against methods of previous paradigms demonstrate the superiority of LORE++, which highlights the potential and promising prospect of the logical location regression paradigm for TSR. ",
    "url": "https://arxiv.org/abs/2401.01522",
    "authors": [
      "Rujiao Long",
      "Hangdi Xing",
      "Zhibo Yang",
      "Qi Zheng",
      "Zhi Yu",
      "Cong Yao",
      "Fei Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01523",
    "title": "GOAT-Bench: Safety Insights to Large Multimodal Models through  Meme-Based Social Abuse",
    "abstract": "The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness, misogyny, offensiveness, sarcasm, and harmful content. Our extensive experiments across a range of LMMs reveal that current models still exhibit a deficiency in safety awareness, showing insensitivity to various forms of implicit abuse. We posit that this shortfall represents a critical impediment to the realization of safe artificial intelligence. The GOAT-Bench and accompanying resources are publicly accessible at https://goatlmm.github.io/, contributing to ongoing research in this vital field. ",
    "url": "https://arxiv.org/abs/2401.01523",
    "authors": [
      "Hongzhan Lin",
      "Ziyang Luo",
      "Bo Wang",
      "Ruichao Yang",
      "Jing Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01524",
    "title": "Multimodal self-supervised learning for lesion localization",
    "abstract": "Multimodal deep learning utilizing imaging and diagnostic reports has made impressive progress in the field of medical imaging diagnostics, demonstrating a particularly strong capability for auxiliary diagnosis in cases where sufficient annotation information is lacking. Nonetheless, localizing diseases accurately without detailed positional annotations remains a challenge. Although existing methods have attempted to utilize local information to achieve fine-grained semantic alignment, their capability in extracting the fine-grained semantics of the comprehensive contextual within reports is limited. To solve this problem, we introduce a new method that takes full sentences from textual reports as the basic units for local semantic alignment. Our approach combines chest X-ray images with their corresponding textual reports, performing contrastive learning at both global and local levels. The leading results obtained by our method on multiple datasets confirm its efficacy in the task of lesion localization. ",
    "url": "https://arxiv.org/abs/2401.01524",
    "authors": [
      "Hao Yang",
      "Hong-Yu Zhou",
      "Cheng Li",
      "Weijian Huang",
      "Jiarun Liu",
      "Yong Liang",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01527",
    "title": "Poisoning Attacks against Recommender Systems: A Survey",
    "abstract": "Modern recommender systems have seen substantial success, yet they remain vulnerable to malicious activities, notably poisoning attacks. These attacks involve injecting malicious data into the training datasets of RS, thereby compromising their integrity and manipulating recommendation outcomes for gaining illicit profits. This survey paper provides a systematic and up-to-date review of the research landscape on Poisoning Attacks against Recommendation (PAR). A novel and comprehensive taxonomy is proposed, categorizing existing PAR methodologies into three distinct categories: Component-Specific, Goal-Driven, and Capability Probing. For each category, we discuss its mechanism in detail, along with associated methods. Furthermore, this paper highlights potential future research avenues in this domain. Additionally, to facilitate and benchmark the empirical comparison of PAR, we introduce an open-source library, ARLib, which encompasses a comprehensive collection of PAR models and common datasets. The library is released at \\url{https://github.com/CoderWZW/ARLib}. ",
    "url": "https://arxiv.org/abs/2401.01527",
    "authors": [
      "Zongwei Wang",
      "Min Gao",
      "Junliang Yu",
      "Hao Ma",
      "Hongzhi Yin",
      "Shazia Sadiq"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2401.01537",
    "title": "The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of  Triggers",
    "abstract": "The area of Machine Learning as a Service (MLaaS) is experiencing increased implementation due to recent advancements in the AI (Artificial Intelligence) industry. However, this spike has prompted concerns regarding AI defense mechanisms, specifically regarding potential covert attacks from third-party providers that cannot be entirely trusted. Recent research has uncovered that auditory backdoors may use certain modifications as their initiating mechanism. DynamicTrigger is introduced as a methodology for carrying out dynamic backdoor attacks that use cleverly designed tweaks to ensure that corrupted samples are indistinguishable from clean. By utilizing fluctuating signal sampling rates and masking speaker identities through dynamic sound triggers (such as the clapping of hands), it is possible to deceive speech recognition systems (ASR). Our empirical testing demonstrates that DynamicTrigger is both potent and stealthy, achieving impressive success rates during covert attacks while maintaining exceptional accuracy with non-poisoned datasets. ",
    "url": "https://arxiv.org/abs/2401.01537",
    "authors": [
      "Orson Mengara"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01542",
    "title": "Adversarial Machine Learning-Enabled Anonymization of OpenWiFi Data",
    "abstract": "Data privacy and protection through anonymization is a critical issue for network operators or data owners before it is forwarded for other possible use of data. With the adoption of Artificial Intelligence (AI), data anonymization augments the likelihood of covering up necessary sensitive information; preventing data leakage and information loss. OpenWiFi networks are vulnerable to any adversary who is trying to gain access or knowledge on traffic regardless of the knowledge possessed by data owners. The odds for discovery of actual traffic information is addressed by applied conditional tabular generative adversarial network (CTGAN). CTGAN yields synthetic data; which disguises as actual data but fostering hidden acute information of actual data. In this paper, the similarity assessment of synthetic with actual data is showcased in terms of clustering algorithms followed by a comparison of performance for unsupervised cluster validation metrics. A well-known algorithm, K-means outperforms other algorithms in terms of similarity assessment of synthetic data over real data while achieving nearest scores 0.634, 23714.57, and 0.598 as Silhouette, Calinski and Harabasz and Davies Bouldin metric respectively. On exploiting a comparative analysis in validation scores among several algorithms, K-means forms the epitome of unsupervised clustering algorithms ensuring explicit usage of synthetic data at the same time a replacement for real data. Hence, the experimental results aim to show the viability of using CTGAN-generated synthetic data in lieu of publishing anonymized data to be utilized in various applications. ",
    "url": "https://arxiv.org/abs/2401.01542",
    "authors": [
      "Samhita Kuili",
      "Kareem Dabbour",
      "Irtiza Hasan",
      "Andrea Herscovich",
      "Burak Kantarci",
      "Marcel Chenier",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01545",
    "title": "DDN-SLAM: Real-time Dense Dynamic Neural Implicit SLAM with Joint  Semantic Encoding",
    "abstract": "We propose DDN-SLAM, a real-time dense neural implicit semantic SLAM system designed for dynamic scenes. While existing neural implicit SLAM systems perform well in static scenes, they often encounter challenges in real-world environments with dynamic interferences, leading to ineffective tracking and mapping. DDN-SLAM utilizes the priors provided by the deep semantic system, combined with conditional probability fields, for segmentation.By constructing depth-guided static masks and employing joint multi-resolution hashing encoding, we ensure fast hole filling and high-quality mapping while mitigating the effects of dynamic information interference. To enhance tracking robustness, we utilize sparse feature points validated with optical flow and keyframes, enabling loop closure detection and global bundle optimization. Furthermore, DDN-SLAM supports monocular, stereo, and RGB-D inputs, operating robustly at a frequency of 20-30Hz. Extensive experiments on 6 virtual/real datasets demonstrate that our method outperforms state-of-the-art approaches in both dynamic and static scenes. ",
    "url": "https://arxiv.org/abs/2401.01545",
    "authors": [
      "Mingrui Li",
      "Jiaming He",
      "Guangan Jiang",
      "Hongyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2401.01548",
    "title": "Boosting of Implicit Neural Representation-based Image Denoiser",
    "abstract": "Implicit Neural Representation (INR) has emerged as an effective method for unsupervised image denoising. However, INR models are typically overparameterized; consequently, these models are prone to overfitting during learning, resulting in suboptimal results, even noisy ones. To tackle this problem, we propose a general recipe for regularizing INR models in image denoising. In detail, we propose to iteratively substitute the supervision signal with the mean value derived from both the prediction and supervision signal during the learning process. We theoretically prove that such a simple iterative substitute can gradually enhance the signal-to-noise ratio of the supervision signal, thereby benefiting INR models during the learning process. Our experimental results demonstrate that INR models can be effectively regularized by the proposed approach, relieving overfitting and boosting image denoising performance. ",
    "url": "https://arxiv.org/abs/2401.01548",
    "authors": [
      "Zipei Yan",
      "Zhengji Liu",
      "Jizhou Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01549",
    "title": "Towards Modeling Uncertainties of Self-explaining Neural Networks via  Conformal Prediction",
    "abstract": "Despite the recent progress in deep neural networks (DNNs), it remains challenging to explain the predictions made by DNNs. Existing explanation methods for DNNs mainly focus on post-hoc explanations where another explanatory model is employed to provide explanations. The fact that post-hoc methods can fail to reveal the actual original reasoning process of DNNs raises the need to build DNNs with built-in interpretability. Motivated by this, many self-explaining neural networks have been proposed to generate not only accurate predictions but also clear and intuitive insights into why a particular decision was made. However, existing self-explaining networks are limited in providing distribution-free uncertainty quantification for the two simultaneously generated prediction outcomes (i.e., a sample's final prediction and its corresponding explanations for interpreting that prediction). Importantly, they also fail to establish a connection between the confidence values assigned to the generated explanations in the interpretation layer and those allocated to the final predictions in the ultimate prediction layer. To tackle the aforementioned challenges, in this paper, we design a novel uncertainty modeling framework for self-explaining networks, which not only demonstrates strong distribution-free uncertainty modeling performance for the generated explanations in the interpretation layer but also excels in producing efficient and effective prediction sets for the final predictions based on the informative high-level basis explanations. We perform the theoretical analysis for the proposed framework. Extensive experimental evaluation demonstrates the effectiveness of the proposed uncertainty framework. ",
    "url": "https://arxiv.org/abs/2401.01549",
    "authors": [
      "Wei Qian",
      "Chenxu Zhao",
      "Yangyi Li",
      "Fenglong Ma",
      "Chao Zhang",
      "Mengdi Huai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01563",
    "title": "Towards Multi-Objective High-Dimensional Feature Selection via  Evolutionary Multitasking",
    "abstract": "Evolutionary Multitasking (EMT) paradigm, an emerging research topic in evolutionary computation, has been successfully applied in solving high-dimensional feature selection (FS) problems recently. However, existing EMT-based FS methods suffer from several limitations, such as a single mode of multitask generation, conducting the same generic evolutionary search for all tasks, relying on implicit transfer mechanisms through sole solution encodings, and employing single-objective transformation, which result in inadequate knowledge acquisition, exploitation, and transfer. To this end, this paper develops a novel EMT framework for multiobjective high-dimensional feature selection problems, namely MO-FSEMT. In particular, multiple auxiliary tasks are constructed by distinct formulation methods to provide diverse search spaces and information representations and then simultaneously addressed with the original task through a multi-slover-based multitask optimization scheme. Each task has an independent population with task-specific representations and is solved using separate evolutionary solvers with different biases and search preferences. A task-specific knowledge transfer mechanism is designed to leverage the advantage information of each task, enabling the discovery and effective transmission of high-quality solutions during the search process. Comprehensive experimental results demonstrate that our MO-FSEMT framework can achieve overall superior performance compared to the state-of-the-art FS methods on 26 datasets. Moreover, the ablation studies verify the contributions of different components of the proposed MO-FSEMT. ",
    "url": "https://arxiv.org/abs/2401.01563",
    "authors": [
      "Yinglan Feng",
      "Liang Feng",
      "Songbai Liu",
      "Sam Kwong",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2401.01566",
    "title": "Team IELAB at TREC Clinical Trial Track 2023: Enhancing Clinical Trial  Retrieval with Neural Rankers and Large Language Models",
    "abstract": "We describe team ielab from CSIRO and The University of Queensland's approach to the 2023 TREC Clinical Trials Track. Our approach was to use neural rankers but to utilise Large Language Models to overcome the issue of lack of training data for such rankers. Specifically, we employ ChatGPT to generate relevant patient descriptions for randomly selected clinical trials from the corpus. This synthetic dataset, combined with human-annotated training data from previous years, is used to train both dense and sparse retrievers based on PubmedBERT. Additionally, a cross-encoder re-ranker is integrated into the system. To further enhance the effectiveness of our approach, we prompting GPT-4 as a TREC annotator to provide judgments on our run files. These judgments are subsequently employed to re-rank the results. This architecture tightly integrates strong PubmedBERT-based rankers with the aid of SOTA Large Language Models, demonstrating a new approach to clinical trial retrieval. ",
    "url": "https://arxiv.org/abs/2401.01566",
    "authors": [
      "Shengyao Zhuang",
      "Bevan Koopman",
      "Guido Zuccon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2401.01571",
    "title": "CodeFuse-Query: A Data-Centric Static Code Analysis System for  Large-Scale Organizations",
    "abstract": "In the domain of large-scale software development, the demands for dynamic and multifaceted static code analysis exceed the capabilities of traditional tools. To bridge this gap, we present CodeFuse-Query, a system that redefines static code analysis through the fusion of Domain Optimized System Design and Logic Oriented Computation Design. CodeFuse-Query reimagines code analysis as a data computation task, support scanning over 10 billion lines of code daily and more than 300 different tasks. It optimizes resource utilization, prioritizes data reusability, applies incremental code extraction, and introduces tasks types specially for Code Change, underscoring its domain-optimized design. The system's logic-oriented facet employs Datalog, utilizing a unique two-tiered schema, COREF, to convert source code into data facts. Through Godel, a distinctive language, CodeFuse-Query enables formulation of complex tasks as logical expressions, harnessing Datalog's declarative prowess. This paper provides empirical evidence of CodeFuse-Query's transformative approach, demonstrating its robustness, scalability, and efficiency. We also highlight its real-world impact and diverse applications, emphasizing its potential to reshape the landscape of static code analysis in the context of large-scale software development.Furthermore, in the spirit of collaboration and advancing the field, our project is open-sourced and the repository is available for public access ",
    "url": "https://arxiv.org/abs/2401.01571",
    "authors": [
      "Xiaoheng Xie",
      "Gang Fan",
      "Xiaojun Lin",
      "Ang Zhou",
      "Shijie Li",
      "Xunjin Zheng",
      "Yinan Liang",
      "Yu Zhang",
      "Na Yu",
      "Haokun Li",
      "Xinyu Chen",
      "Yingzhuang Chen",
      "Yi Zhen",
      "Dejun Dong",
      "Xianjin Fu",
      "Jinzhou Su",
      "Fuxiong Pan",
      "Pengshuai Luo",
      "Youzheng Feng",
      "Ruoxiang Hu",
      "Jing Fan",
      "Jinguo Zhou",
      "Xiao Xiao",
      "Peng Di"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2401.01572",
    "title": "Hallucinations in Neural Automatic Speech Recognition: Identifying  Errors and Hallucinatory Models",
    "abstract": "Hallucinations are a type of output error produced by deep neural networks. While this has been studied in natural language processing, they have not been researched previously in automatic speech recognition. Here, we define hallucinations in ASR as transcriptions generated by a model that are semantically unrelated to the source utterance, yet still fluent and coherent. The similarity of hallucinations to probable natural language outputs of the model creates a danger of deception and impacts the credibility of the system. We show that commonly used metrics, such as word error rates, cannot differentiate between hallucinatory and non-hallucinatory models. To address this, we propose a perturbation-based method for assessing the susceptibility of an automatic speech recognition (ASR) model to hallucination at test time, which does not require access to the training dataset. We demonstrate that this method helps to distinguish between hallucinatory and non-hallucinatory models that have similar baseline word error rates. We further explore the relationship between the types of ASR errors and the types of dataset noise to determine what types of noise are most likely to create hallucinatory outputs. We devise a framework for identifying hallucinations by analysing their semantic connection with the ground truth and their fluency. Finally, we discover how to induce hallucinations with a random noise injection to the utterance. ",
    "url": "https://arxiv.org/abs/2401.01572",
    "authors": [
      "Rita Frieske",
      "Bertram E. Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2401.01573",
    "title": "View Distribution Alignment with Progressive Adversarial Learning for  UAV Visual Geo-Localization",
    "abstract": "Unmanned Aerial Vehicle (UAV) visual geo-localization aims to match images of the same geographic target captured from different views, i.e., the UAV view and the satellite view. It is very challenging due to the large appearance differences in UAV-satellite image pairs. Previous works map images captured by UAVs and satellites to a shared feature space and employ a classification framework to learn location-dependent features while neglecting the overall distribution shift between the UAV view and the satellite view. In this paper, we address these limitations by introducing distribution alignment of the two views to shorten their distance in a common space. Specifically, we propose an end-to-end network, called PVDA (Progressive View Distribution Alignment). During training, feature encoder, location classifier, and view discriminator are jointly optimized by a novel progressive adversarial learning strategy. Competition between feature encoder and view discriminator prompts both of them to be stronger. It turns out that the adversarial learning is progressively emphasized until UAV-view images are indistinguishable from satellite-view images. As a result, the proposed PVDA becomes powerful in learning location-dependent yet view-invariant features with good scalability towards unseen images of new locations. Compared to the state-of-the-art methods, the proposed PVDA requires less inference time but has achieved superior performance on the University-1652 dataset. ",
    "url": "https://arxiv.org/abs/2401.01573",
    "authors": [
      "Cuiwei Liu",
      "Jiahao Liu",
      "Huaijun Qiu",
      "Zhaokui Li",
      "Xiangbin Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01575",
    "title": "Enhancing Generalization of Invisible Facial Privacy Cloak via Gradient  Accumulation",
    "abstract": "The blooming of social media and face recognition (FR) systems has increased people's concern about privacy and security. A new type of adversarial privacy cloak (class-universal) can be applied to all the images of regular users, to prevent malicious FR systems from acquiring their identity information. In this work, we discover the optimization dilemma in the existing methods -- the local optima problem in large-batch optimization and the gradient information elimination problem in small-batch optimization. To solve these problems, we propose Gradient Accumulation (GA) to aggregate multiple small-batch gradients into a one-step iterative gradient to enhance the gradient stability and reduce the usage of quantization operations. Experiments show that our proposed method achieves high performance on the Privacy-Commons dataset against black-box face recognition models. ",
    "url": "https://arxiv.org/abs/2401.01575",
    "authors": [
      "Xuannan Liu",
      "Yaoyao Zhong",
      "Weihong Deng",
      "Hongzhi Shi",
      "Xingchen Cui",
      "Yunfeng Yin",
      "Dongchao Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01587",
    "title": "Real-Time Human Fall Detection using a Lightweight Pose Estimation  Technique",
    "abstract": "The elderly population is increasing rapidly around the world. There are no enough caretakers for them. Use of AI-based in-home medical care systems is gaining momentum due to this. Human fall detection is one of the most important tasks of medical care system for the aged people. Human fall is a common problem among elderly people. Detection of a fall and providing medical help as early as possible is very important to reduce any further complexity. The chances of death and other medical complications can be reduced by detecting and providing medical help as early as possible after the fall. There are many state-of-the-art fall detection techniques available these days, but the majority of them need very high computing power. In this paper, we proposed a lightweight and fast human fall detection system using pose estimation. We used `Movenet' for human joins key-points extraction. Our proposed method can work in real-time on any low-computing device with any basic camera. All computation can be processed locally, so there is no problem of privacy of the subject. We used two datasets `GMDCSA' and `URFD' for the experiment. We got the sensitivity value of 0.9375 and 0.9167 for the dataset `GMDCSA' and `URFD' respectively. The source code and the dataset GMDCSA of our work are available online to access. ",
    "url": "https://arxiv.org/abs/2401.01587",
    "authors": [
      "Ekram Alam",
      "Abu Sufian",
      "Paramartha Dutta",
      "Marco Leo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01589",
    "title": "The Security and Privacy of Mobile Edge Computing: An Artificial  Intelligence Perspective",
    "abstract": "Mobile Edge Computing (MEC) is a new computing paradigm that enables cloud computing and information technology (IT) services to be delivered at the network's edge. By shifting the load of cloud computing to individual local servers, MEC helps meet the requirements of ultralow latency, localized data processing, and extends the potential of Internet of Things (IoT) for end-users. However, the crosscutting nature of MEC and the multidisciplinary components necessary for its deployment have presented additional security and privacy concerns. Fortunately, Artificial Intelligence (AI) algorithms can cope with excessively unpredictable and complex data, which offers a distinct advantage in dealing with sophisticated and developing adversaries in the security industry. Hence, in this paper we comprehensively provide a survey of security and privacy in MEC from the perspective of AI. On the one hand, we use European Telecommunications Standards Institute (ETSI) MEC reference architecture as our based framework while merging the Software Defined Network (SDN) and Network Function Virtualization (NFV) to better illustrate a serviceable platform of MEC. On the other hand, we focus on new security and privacy issues, as well as potential solutions from the viewpoints of AI. Finally, we comprehensively discuss the opportunities and challenges associated with applying AI to MEC security and privacy as possible future research directions. ",
    "url": "https://arxiv.org/abs/2401.01589",
    "authors": [
      "Cheng Wang",
      "Zenghui Yuan",
      "Pan Zhou",
      "Zichuan Xu",
      "Ruixuan Li",
      "Dapeng Oliver Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.01591",
    "title": "MLIP: Medical Language-Image Pre-training with Masked Local  Representation Learning",
    "abstract": "Existing contrastive language-image pre-training aims to learn a joint representation by matching abundant image-text pairs. However, the number of image-text pairs in medical datasets is usually orders of magnitude smaller than that in natural datasets. Besides, medical image-text pairs often involve numerous complex fine-grained correspondences. This paper aims to enhance the data efficiency by introducing multiple-to-multiple local relationship modeling to capture denser supervisions. More specifically, we propose a Medical Language-Image Pre-training (MLIP) framework, which exploits the limited image-text medical data more efficiently through patch-sentence matching. Furthermore, we introduce a masked contrastive learning strategy with semantic integrity estimation to reduce redundancy in images while preserving the underlying semantics. Our evaluation results show that MLIP outperforms previous work in zero/few-shot classification and few-shot segmentation tasks by a large margin. ",
    "url": "https://arxiv.org/abs/2401.01591",
    "authors": [
      "Jiarun Liu",
      "Hong-Yu Zhou",
      "Cheng Li",
      "Weijian Huang",
      "Hao Yang",
      "Yong Liang",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01609",
    "title": "Entropy-based Probing Beam Selection and Beam Prediction via Deep  Learning",
    "abstract": "Hierarchical beam search in mmWave communications incurs substantial training overhead, necessitating deep learning-enabled beam predictions to effectively leverage channel priors and mitigate this overhead. In this study, we introduce a comprehensive probabilistic model of power distribution in beamspace, and formulate the joint optimization problem of probing beam selection and probabilistic beam prediction as an entropy minimization problem. Then, we propose a greedy scheme to iteratively and alternately solve this problem, where a transformer-based beam predictor is trained to estimate the conditional power distribution based on the probing beams and user location within each iteration, and the trained predictor selects an unmeasured beam that minimizes the entropy of remaining beams. To further reduce the number of interactions and the computational complexity of the iterative scheme, we propose a two-stage probing beam selection scheme. Firstly, probing beams are selected from a location-specific codebook designed by an entropy-based criterion, and predictions are made with corresponding feedback. Secondly, the optimal beam is identified using additional probing beams with the highest predicted power values. Simulation results demonstrate the superiority of the proposed schemes compared to hierarchical beam search and beam prediction with uniform probing beams. ",
    "url": "https://arxiv.org/abs/2401.01609",
    "authors": [
      "Fan Meng",
      "Cheng Zhang",
      "Yongming Huang",
      "Zhilei Zhang",
      "Xiaoyu Bai",
      "Zhaohua Lu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.01620",
    "title": "Large Language Model Capabilities in Perioperative Risk Prediction and  Prognostication",
    "abstract": "We investigate whether general-domain large language models such as GPT-4 Turbo can perform risk stratification and predict post-operative outcome measures using a description of the procedure and a patient's clinical notes derived from the electronic health record. We examine predictive performance on 8 different tasks: prediction of ASA Physical Status Classification, hospital admission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1 duration, hospital duration, and ICU duration. Few-shot and chain-of-thought prompting improves predictive performance for several of the tasks. We achieve F1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU admission, and 0.86 for hospital mortality. Performance on duration prediction tasks were universally poor across all prompt strategies. Current generation large language models can assist clinicians in perioperative risk stratification on classification tasks and produce high-quality natural language summaries and explanations. ",
    "url": "https://arxiv.org/abs/2401.01620",
    "authors": [
      "Philip Chung",
      "Christine T Fong",
      "Andrew M Walters",
      "Nima Aghaeepour",
      "Meliha Yetisgen",
      "Vikas N O'Reilly-Shah"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.01624",
    "title": "Context-Aware Interaction Network for RGB-T Semantic Segmentation",
    "abstract": "RGB-T semantic segmentation is a key technique for autonomous driving scenes understanding. For the existing RGB-T semantic segmentation methods, however, the effective exploration of the complementary relationship between different modalities is not implemented in the information interaction between multiple levels. To address such an issue, the Context-Aware Interaction Network (CAINet) is proposed for RGB-T semantic segmentation, which constructs interaction space to exploit auxiliary tasks and global context for explicitly guided learning. Specifically, we propose a Context-Aware Complementary Reasoning (CACR) module aimed at establishing the complementary relationship between multimodal features with the long-term context in both spatial and channel dimensions. Further, considering the importance of global contextual and detailed information, we propose the Global Context Modeling (GCM) module and Detail Aggregation (DA) module, and we introduce specific auxiliary supervision to explicitly guide the context interaction and refine the segmentation map. Extensive experiments on two benchmark datasets of MFNet and PST900 demonstrate that the proposed CAINet achieves state-of-the-art performance. The code is available at https://github.com/YingLv1106/CAINet. ",
    "url": "https://arxiv.org/abs/2401.01624",
    "authors": [
      "Ying Lv",
      "Zhi Liu",
      "Gongyang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01625",
    "title": "SCALA: Sparsification-based Contrastive Learning for Anomaly Detection  on Attributed Networks",
    "abstract": "Anomaly detection on attributed networks aims to find the nodes whose behaviors are significantly different from other majority nodes. Generally, network data contains information about relationships between entities, and the anomaly is usually embodied in these relationships. Therefore, how to comprehensively model complex interaction patterns in networks is still a major focus. It can be observed that anomalies in networks violate the homophily assumption. However, most existing studies only considered this phenomenon obliquely rather than explicitly. Besides, the node representation of normal entities can be perturbed easily by the noise relationships introduced by anomalous nodes. To address the above issues, we present a novel contrastive learning framework for anomaly detection on attributed networks, \\textbf{SCALA}, aiming to improve the embedding quality of the network and provide a new measurement of qualifying the anomaly score for each node by introducing sparsification into the conventional method. Extensive experiments are conducted on five benchmark real-world datasets and the results show that SCALA consistently outperforms all baseline methods significantly. ",
    "url": "https://arxiv.org/abs/2401.01625",
    "authors": [
      "Enbo He",
      "Yitong Hao",
      "Yue Zhang",
      "Guisheng Yin",
      "Lina Yao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01626",
    "title": "On the Expressive Power of Graph Neural Networks",
    "abstract": "The study of Graph Neural Networks has received considerable interest in the past few years. By extending deep learning to graph-structured data, GNNs can solve a diverse set of tasks in fields including social science, chemistry, and medicine. The development of GNN architectures has largely been focused on improving empirical performance on tasks like node or graph classification. However, a line of recent work has instead sought to find GNN architectures that have desirable theoretical properties - by studying their expressive power and designing architectures that maximize this expressiveness. While there is no consensus on the best way to define the expressiveness of a GNN, it can be viewed from several well-motivated perspectives. Perhaps the most natural approach is to study the universal approximation properties of GNNs, much in the way that this has been studied extensively for MLPs. Another direction focuses on the extent to which GNNs can distinguish between different graph structures, relating this to the graph isomorphism test. Besides, a GNN's ability to compute graph properties such as graph moments has been suggested as another form of expressiveness. All of these different definitions are complementary and have yielded different recommendations for GNN architecture choices. In this paper, we would like to give an overview of the notion of \"expressive power\" of GNNs and provide some valuable insights regarding the design choices of GNNs. ",
    "url": "https://arxiv.org/abs/2401.01626",
    "authors": [
      "Ashwin Nalwade",
      "Kelly Marshall",
      "Axel Eladi",
      "Umang Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01636",
    "title": "Efficient UAVs Deployment and Resource Allocation in UAV-Relay Assisted  Public Safety Networks for Video Transmission",
    "abstract": "Wireless communication highly depends on the cellular ground base station (GBS). A failure of the cellular GBS, fully or partially, during natural or man-made disasters creates a communication gap in the disaster-affected areas. In such situations, public safety communication (PSC) can significantly save the national infrastructure, property, and lives. Throughout emergencies, the PSC can provide mission-critical communication and video transmission services in the affected area. Unmanned aerial vehicles (UAVs) as flying base stations (UAV-BSs) are particularly suitable for PSC services as they are flexible, mobile, and easily deployable. This manuscript considers a multi-UAV-assisted PSC network with an observational UAV receiving videos from the affected area's ground users (AGUs) and transmitting them to the nearby GBS via a relay UAV. The objective of the proposed study is to maximize the average utility of the video streams generated by the AGUs upon reaching the GBS. This is achieved by optimizing the positions of the observational and relay UAVs, as well as the distribution of communication resources, such as bandwidth, and transmit power, while satisfying the system-designed constraints, such as transmission rate, rate outage probability, transmit power budget, and available bandwidth. To this end, a joint UAVs placement and resource allocation problem is mathematically formulated. The proposed problem poses a significant challenge for a solution. Considering the block coordinate descent and successive convex approximation techniques, an efficient iterative algorithm is proposed. Finally, simulation results are provided which show that our proposed approach outperforms the existing methods. ",
    "url": "https://arxiv.org/abs/2401.01636",
    "authors": [
      "Naveed Khan",
      "Ayaz Ahmad",
      "Abdul Wakeel",
      "Zeeshan Kaleem",
      "Bushra Rashid",
      "Waqas Khalid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.01637",
    "title": "Social Media Ready Caption Generation for Brands",
    "abstract": "Social media advertisements are key for brand marketing, aiming to attract consumers with captivating captions and pictures or logos. While previous research has focused on generating captions for general images, incorporating brand personalities into social media captioning remains unexplored. Brand personalities are shown to be affecting consumers' behaviours and social interactions and thus are proven to be a key aspect of marketing strategies. Current open-source multimodal LLMs are not directly suited for this task. Hence, we propose a pipeline solution to assist brands in creating engaging social media captions that align with the image and the brand personalities. Our architecture is based on two parts: a the first part contains an image captioning model that takes in an image that the brand wants to post online and gives a plain English caption; b the second part takes in the generated caption along with the target brand personality and outputs a catchy personality-aligned social media caption. Along with brand personality, our system also gives users the flexibility to provide hashtags, Instagram handles, URLs, and named entities they want the caption to contain, making the captions more semantically related to the social media handles. Comparative evaluations against various baselines demonstrate the effectiveness of our approach, both qualitatively and quantitatively. ",
    "url": "https://arxiv.org/abs/2401.01637",
    "authors": [
      "Himanshu Maheshwari",
      "Koustava Goswami",
      "Apoorv Saxena",
      "Balaji Vasan Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.01640",
    "title": "Evaluating Fairness in Self-supervised and Supervised Models for  Sequential Data",
    "abstract": "Self-supervised learning (SSL) has become the de facto training paradigm of large models where pre-training is followed by supervised fine-tuning using domain-specific data and labels. Hypothesizing that SSL models would learn more generic, hence less biased, representations, this study explores the impact of pre-training and fine-tuning strategies on fairness (i.e., performing equally on different demographic breakdowns). Motivated by human-centric applications on real-world timeseries data, we interpret inductive biases on the model, layer, and metric levels by systematically comparing SSL models to their supervised counterparts. Our findings demonstrate that SSL has the capacity to achieve performance on par with supervised methods while significantly enhancing fairness--exhibiting up to a 27% increase in fairness with a mere 1% loss in performance through self-supervision. Ultimately, this work underscores SSL's potential in human-centric computing, particularly high-stakes, data-scarce application domains like healthcare. ",
    "url": "https://arxiv.org/abs/2401.01640",
    "authors": [
      "Sofia Yfantidou",
      "Dimitris Spathis",
      "Marios Constantinides",
      "Athena Vakali",
      "Daniele Quercia",
      "Fahim Kawsar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.01643",
    "title": "S3Net: Innovating Stereo Matching and Semantic Segmentation with a  Single-Branch Semantic Stereo Network in Satellite Epipolar Imagery",
    "abstract": "Stereo matching and semantic segmentation are significant tasks in binocular satellite 3D reconstruction. However, previous studies primarily view these as independent parallel tasks, lacking an integrated multitask learning framework. This work introduces a solution, the Single-branch Semantic Stereo Network (S3Net), which innovatively combines semantic segmentation and stereo matching using Self-Fuse and Mutual-Fuse modules. Unlike preceding methods that utilize semantic or disparity information independently, our method dentifies and leverages the intrinsic link between these two tasks, leading to a more accurate understanding of semantic information and disparity estimation. Comparative testing on the US3D dataset proves the effectiveness of our S3Net. Our model improves the mIoU in semantic segmentation from 61.38 to 67.39, and reduces the D1-Error and average endpoint error (EPE) in disparity estimation from 10.051 to 9.579 and 1.439 to 1.403 respectively, surpassing existing competitive methods. Our codes are available at:https://github.com/CVEO/S3Net. ",
    "url": "https://arxiv.org/abs/2401.01643",
    "authors": [
      "Qingyuan Yang",
      "Guanzhou Chen",
      "Xiaoliang Tan",
      "Tong Wang",
      "Jiaqi Wang",
      "Xiaodong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01646",
    "title": "Prototypical Information Bottlenecking and Disentangling for Multimodal  Cancer Survival Prediction",
    "abstract": "Multimodal learning significantly benefits cancer survival prediction, especially the integration of pathological images and genomic data. Despite advantages of multimodal learning for cancer survival prediction, massive redundancy in multimodal data prevents it from extracting discriminative and compact information: (1) An extensive amount of intra-modal task-unrelated information blurs discriminability, especially for gigapixel whole slide images (WSIs) with many patches in pathology and thousands of pathways in genomic data, leading to an ``intra-modal redundancy\" issue. (2) Duplicated information among modalities dominates the representation of multimodal data, which makes modality-specific information prone to being ignored, resulting in an ``inter-modal redundancy\" issue. To address these, we propose a new framework, Prototypical Information Bottlenecking and Disentangling (PIBD), consisting of Prototypical Information Bottleneck (PIB) module for intra-modal redundancy and Prototypical Information Disentanglement (PID) module for inter-modal redundancy. Specifically, a variant of information bottleneck, PIB, is proposed to model prototypes approximating a bunch of instances for different risk levels, which can be used for selection of discriminative instances within modality. PID module decouples entangled multimodal data into compact distinct components: modality-common and modality-specific knowledge, under the guidance of the joint prototypical distribution. Extensive experiments on five cancer benchmark datasets demonstrated our superiority over other methods. ",
    "url": "https://arxiv.org/abs/2401.01646",
    "authors": [
      "Yilan Zhang",
      "Yingxue Xu",
      "Jianqi Chen",
      "Fengying Xie",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01647",
    "title": "SIGNeRF: Scene Integrated Generation for Neural Radiance Fields",
    "abstract": "Advances in image diffusion models have recently led to notable improvements in the generation of high-quality images. In combination with Neural Radiance Fields (NeRFs), they enabled new opportunities in 3D generation. However, most generative 3D approaches are object-centric and applying them to editing existing photorealistic scenes is not trivial. We propose SIGNeRF, a novel approach for fast and controllable NeRF scene editing and scene-integrated object generation. A new generative update strategy ensures 3D consistency across the edited images, without requiring iterative optimization. We find that depth-conditioned diffusion models inherently possess the capability to generate 3D consistent views by requesting a grid of images instead of single views. Based on these insights, we introduce a multi-view reference sheet of modified images. Our method updates an image collection consistently based on the reference sheet and refines the original NeRF with the newly generated image set in one go. By exploiting the depth conditioning mechanism of the image diffusion model, we gain fine control over the spatial location of the edit and enforce shape guidance by a selected region or an external mesh. ",
    "url": "https://arxiv.org/abs/2401.01647",
    "authors": [
      "Jan-Niklas Dihlmann",
      "Andreas Engelhardt",
      "Hendrik Lensch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2401.01652",
    "title": "Near Real-Time Data-Driven Control of Virtual Reality Traffic in Open  Radio Access Network",
    "abstract": "In mobile networks, Open Radio Access Network (ORAN) provides a framework for implementing network slicing that interacts with the resources at the lower layers. Both monitoring and Radio Access Network (RAN) control is feasible for both 4G and 5G systems. In this work, we consider how data-driven resource allocation in a 4G context can enable adaptive slice allocation to steer the experienced latency of Virtual Reality (VR) traffic towards a requested latency. We develop an xApp for the near real-time RAN Intelligent Controller (RIC) that embeds a heuristic algorithm for latency control, aiming to: (1) maintain latency of a VR stream around a requested value; and (2) improve the available RAN allocation to offer higher bit rate to another user. We have experimentally demonstrated the proposed approach in an ORAN testbed. Our results show that the data-driven approach can dynamically follow the variation of the traffic load while satisfying the required latency. This results in 15.8% more resources to secondary users than a latency-equivalent static allocation. ",
    "url": "https://arxiv.org/abs/2401.01652",
    "authors": [
      "Andreas Casparsen",
      "Beatriz Soret",
      "Jimmy Jessen Nielsen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2401.01659",
    "title": "DiffYOLO: Object Detection for Anti-Noise via YOLO and Diffusion Models",
    "abstract": "Object detection models represented by YOLO series have been widely used and have achieved great results on the high quality datasets, but not all the working conditions are ideal. To settle down the problem of locating targets on low quality datasets, the existing methods either train a new object detection network, or need a large collection of low-quality datasets to train. However, we propose a framework in this paper and apply it on the YOLO models called DiffYOLO. Specifically, we extract feature maps from the denoising diffusion probabilistic models to enhance the well-trained models, which allows us fine-tune YOLO on high-quality datasets and test on low-quality datasets. The results proved this framework can not only prove the performance on noisy datasets, but also prove the detection results on high-quality test datasets. We will supplement more experiments later (with various datasets and network architectures). ",
    "url": "https://arxiv.org/abs/2401.01659",
    "authors": [
      "Yichen Liu",
      "Huajian Zhang",
      "Daqing Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01701",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "abstract": "Large languages models (LLMs) trained on datasets of publicly available source code have established a new state-of-the-art in code completion. However, these models are mostly unaware of the code that already exists within a specific project, preventing the models from making good use of existing APIs. Instead, LLMs often invent, or \"hallucinate\", non-existent APIs or produce variants of already existing code. Although the API information is available to IDEs, the input size limit of LLMs prevents code completion techniques from including all relevant context into the prompt. This paper presents De-Hallucinator, an LLM-based code completion technique that grounds the predictions of a model through a novel combination of retrieving suitable API references and iteratively querying the model with increasingly suitable context information in the prompt. The approach exploits the observation that LLMs often predict code that resembles the desired completion, but that fails to correctly refer to already existing APIs. De-Hallucinator automatically identifies project-specific API references related to the code prefix and to the model's initial predictions and adds these references into the prompt. Our evaluation applies the approach to the task of predicting API usages in open-source Python projects. We show that De-Hallucinator consistently improves the predicted code across four state-of-the-art LLMs compared to querying the model only with the code before the cursor. In particular, the approach improves the edit distance of the predicted code by 23-51% and the recall of correctly predicted API usages by 24-61% relative to the baseline. ",
    "url": "https://arxiv.org/abs/2401.01701",
    "authors": [
      "Aryaz Eghbali",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.01710",
    "title": "EPA: Neural Collapse Inspired Robust Out-of-Distribution Detector",
    "abstract": "Out-of-distribution (OOD) detection plays a crucial role in ensuring the security of neural networks. Existing works have leveraged the fact that In-distribution (ID) samples form a subspace in the feature space, achieving state-of-the-art (SOTA) performance. However, the comprehensive characteristics of the ID subspace still leave under-explored. Recently, the discovery of Neural Collapse ($\\mathcal{NC}$) sheds light on novel properties of the ID subspace. Leveraging insight from $\\mathcal{NC}$, we observe that the Principal Angle between the features and the ID feature subspace forms a superior representation for measuring the likelihood of OOD. Building upon this observation, we propose a novel $\\mathcal{NC}$-inspired OOD scoring function, named Entropy-enhanced Principal Angle (EPA), which integrates both the global characteristic of the ID subspace and its inner property. We experimentally compare EPA with various SOTA approaches, validating its superior performance and robustness across different network architectures and OOD datasets. ",
    "url": "https://arxiv.org/abs/2401.01710",
    "authors": [
      "Jiawei Zhang",
      "Yufan Chen",
      "Cheng Jin",
      "Lei Zhu",
      "Yuantao Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.01711",
    "title": "Evaluating Large Language Models in Semantic Parsing for Conversational  Question Answering over Knowledge Graphs",
    "abstract": "Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-shot performance. ",
    "url": "https://arxiv.org/abs/2401.01711",
    "authors": [
      "Phillip Schneider",
      "Manuel Klettner",
      "Kristiina Jokinen",
      "Elena Simperl",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2401.01728",
    "title": "Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices",
    "abstract": "Modern deep learning models, growing larger and more complex, have demonstrated exceptional generalization and accuracy due to training on huge datasets. This trend is expected to continue. However, the increasing size of these models poses challenges in training, as traditional centralized methods are limited by memory constraints at such scales. This paper proposes an asynchronous decentralized training paradigm for large modern deep learning models that harnesses the compute power of regular heterogeneous PCs with limited resources connected across the internet to achieve favourable performance metrics. Ravnest facilitates decentralized training by efficiently organizing compute nodes into clusters with similar data transfer rates and compute capabilities, without necessitating that each node hosts the entire model. These clusters engage in $\\textit{Zero-Bubble Asynchronous Model Parallel}$ training, and a $\\textit{Parallel Multi-Ring All-Reduce}$ method is employed to effectively execute global parameter averaging across all clusters. We have framed our asynchronous SGD loss function as a block structured optimization problem with delayed updates and derived an optimal convergence rate of $O\\left(\\frac{1}{\\sqrt{K}}\\right)$. We further discuss linear speedup with respect to the number of participating clusters and the bound on the staleness parameter. ",
    "url": "https://arxiv.org/abs/2401.01728",
    "authors": [
      "Anirudh Rajiv Menon",
      "Unnikrishnan Menon",
      "Kailash Ahirwar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2401.01732",
    "title": "Task and Explanation Network",
    "abstract": "Explainability in deep networks has gained increased importance in recent years. We argue herein that an AI must be tasked not just with a task but also with an explanation of why said task was accomplished as such. We present a basic framework -- Task and Explanation Network (TENet) -- which fully integrates task completion and its explanation. We believe that the field of AI as a whole should insist -- quite emphatically -- on explainability. ",
    "url": "https://arxiv.org/abs/2401.01732",
    "authors": [
      "Moshe Sipper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2401.01733",
    "title": "Investigating the Suitability of Concept Drift Detection for Detecting  Leakages in Water Distribution Networks",
    "abstract": "Leakages are a major risk in water distribution networks as they cause water loss and increase contamination risks. Leakage detection is a difficult task due to the complex dynamics of water distribution networks. In particular, small leakages are hard to detect. From a machine-learning perspective, leakages can be modeled as concept drift. Thus, a wide variety of drift detection schemes seems to be a suitable choice for detecting leakages. In this work, we explore the potential of model-loss-based and distribution-based drift detection methods to tackle leakage detection. We additionally discuss the issue of temporal dependencies in the data and propose a way to cope with it when applying distribution-based detection. We evaluate different methods systematically for leakages of different sizes and detection times. Additionally, we propose a first drift-detection-based technique for localizing leakages. ",
    "url": "https://arxiv.org/abs/2401.01733",
    "authors": [
      "Valerie Vaquet",
      "Fabian Hinder",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01750",
    "title": "Towards Robust Semantic Segmentation against Patch-based Attack via  Attention Refinement",
    "abstract": "The attention mechanism has been proven effective on various visual tasks in recent years. In the semantic segmentation task, the attention mechanism is applied in various methods, including the case of both Convolution Neural Networks (CNN) and Vision Transformer (ViT) as backbones. However, we observe that the attention mechanism is vulnerable to patch-based adversarial attacks. Through the analysis of the effective receptive field, we attribute it to the fact that the wide receptive field brought by global attention may lead to the spread of the adversarial patch. To address this issue, in this paper, we propose a Robust Attention Mechanism (RAM) to improve the robustness of the semantic segmentation model, which can notably relieve the vulnerability against patch-based attacks. Compared to the vallina attention mechanism, RAM introduces two novel modules called Max Attention Suppression and Random Attention Dropout, both of which aim to refine the attention matrix and limit the influence of a single adversarial patch on the semantic segmentation results of other positions. Extensive experiments demonstrate the effectiveness of our RAM to improve the robustness of semantic segmentation models against various patch-based attack methods under different attack settings. ",
    "url": "https://arxiv.org/abs/2401.01750",
    "authors": [
      "Zheng Yuan",
      "Jie Zhang",
      "Yude Wang",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01751",
    "title": "Text mining arXiv: a look through quantitative finance papers",
    "abstract": "This paper explores articles hosted on the arXiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. Employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arXiv from 1997 to 2022. We extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. Additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2401.01751",
    "authors": [
      "Michele Leonardo Bianchi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)",
      "General Finance (q-fin.GN)"
    ]
  },
  {
    "id": "arXiv:2401.01752",
    "title": "FullLoRA-AT: Efficiently Boosting the Robustness of Pretrained Vision  Transformers",
    "abstract": "In recent years, the Vision Transformer (ViT) model has gradually become mainstream in various computer vision tasks, and the robustness of the model has received increasing attention. However, existing large models tend to prioritize performance during training, potentially neglecting the robustness, which may lead to serious security concerns. In this paper, we establish a new challenge: exploring how to use a small number of additional parameters for adversarial finetuning to quickly and effectively enhance the adversarial robustness of a standardly trained model. To address this challenge, we develop the novel LNLoRA module, incorporating a learnable layer normalization before the conventional LoRA module, which helps mitigate magnitude differences in parameters between the adversarial and standard training paradigms. Furthermore, we propose the FullLoRA-AT framework by integrating the learnable LNLoRA modules into all key components of ViT-based models while keeping the pretrained model frozen, which can significantly improve the model robustness via adversarial finetuning in a parameter-efficient manner. Extensive experiments on CIFAR-10, CIFAR-100, and Imagenette demonstrate the superiority of our proposed FullLoRA-AT framework. It achieves comparable robustness with full finetuning while only requiring about 5% of the learnable parameters. This also effectively addresses concerns regarding extra model storage space and enormous training time caused by adversarial finetuning. ",
    "url": "https://arxiv.org/abs/2401.01752",
    "authors": [
      "Zheng Yuan",
      "Jie Zhang",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01754",
    "title": "Using AI/ML to Find and Remediate Enterprise Secrets in Code & Document  Sharing Platforms",
    "abstract": "We introduce a new challenge to the software development community: 1) leveraging AI to accurately detect and flag up secrets in code and on popular document sharing platforms that frequently used by developers, such as Confluence and 2) automatically remediating the detections (e.g. by suggesting password vault functionality). This is a challenging, and mostly unaddressed task. Existing methods leverage heuristics and regular expressions, that can be very noisy, and therefore increase toil on developers. The next step - modifying code itself - to automatically remediate a detection, is a complex task. We introduce two baseline AI models that have good detection performance and propose an automatic mechanism for remediating secrets found in code, opening up the study of this task to the wider community. ",
    "url": "https://arxiv.org/abs/2401.01754",
    "authors": [
      "Gregor Kerr",
      "David Algorry",
      "Senad Ibraimoski",
      "Peter Maciver",
      "Sean Moran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01759",
    "title": "VGA: Vision and Graph Fused Attention Network for Rumor Detection",
    "abstract": "With the development of social media, rumors have been spread broadly on social media platforms, causing great harm to society. Beside textual information, many rumors also use manipulated images or conceal textual information within images to deceive people and avoid being detected, making multimodal rumor detection be a critical problem. The majority of multimodal rumor detection methods mainly concentrate on extracting features of source claims and their corresponding images, while ignoring the comments of rumors and their propagation structures. These comments and structures imply the wisdom of crowds and are proved to be crucial to debunk rumors. Moreover, these methods usually only extract visual features in a basic manner, seldom consider tampering or textual information in images. Therefore, in this study, we propose a novel Vision and Graph Fused Attention Network (VGA) for rumor detection to utilize propagation structures among posts so as to obtain the crowd opinions and further explore visual tampering features, as well as the textual information hidden in images. We conduct extensive experiments on three datasets, demonstrating that VGA can effectively detect multimodal rumors and outperform state-of-the-art methods significantly. ",
    "url": "https://arxiv.org/abs/2401.01759",
    "authors": [
      "Lin Bai",
      "Caiyan Jia",
      "Ziying Song",
      "Chaoqun Cui"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2401.01761",
    "title": "Cross-target Stance Detection by Exploiting Target Analytical  Perspectives",
    "abstract": "Cross-target stance detection (CTSD) is an important task, which infers the attitude of the destination target by utilizing annotated data derived from the source target. One important approach in CTSD is to extract domain-invariant features to bridge the knowledge gap between multiple targets. However, the analysis of informal and short text structure, and implicit expressions, complicate the extraction of domain-invariant knowledge. In this paper, we propose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the analysis perspective as a bridge to transfer knowledge. First, we develop a two-stage instruct-based chain-of-thought method (TsCoT) to elicit target analysis perspectives and provide natural language explanations (NLEs) from multiple viewpoints by formulating instructions based on large language model (LLM). Second, we propose a multi-perspective prompt-tuning framework (MultiPLN) to fuse the NLEs into the stance predictor. Extensive experiments results demonstrate the superiority of MPPT against the state-of-the-art baseline methods. ",
    "url": "https://arxiv.org/abs/2401.01761",
    "authors": [
      "Daijun Ding",
      "Rong Chen",
      "Bowen Zhang",
      "Xu Huang",
      "Li Dong",
      "Xiaowen Zhao",
      "Ge Song",
      "Liwen Jing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.01764",
    "title": "Understanding the Detrimental Class-level Effects of Data Augmentation",
    "abstract": "Data augmentation (DA) encodes invariance and provides implicit regularization critical to a model's performance in image classification tasks. However, while DA improves average accuracy, recent studies have shown that its impact can be highly class dependent: achieving optimal average accuracy comes at the cost of significantly hurting individual class accuracy by as much as 20% on ImageNet. There has been little progress in resolving class-level accuracy drops due to a limited understanding of these effects. In this work, we present a framework for understanding how DA interacts with class-level learning dynamics. Using higher-quality multi-label annotations on ImageNet, we systematically categorize the affected classes and find that the majority are inherently ambiguous, co-occur, or involve fine-grained distinctions, while DA controls the model's bias towards one of the closely related classes. While many of the previously reported performance drops are explained by multi-label annotations, our analysis of class confusions reveals other sources of accuracy degradation. We show that simple class-conditional augmentation strategies informed by our framework improve performance on the negatively affected classes. ",
    "url": "https://arxiv.org/abs/2401.01764",
    "authors": [
      "Polina Kirichenko",
      "Mark Ibrahim",
      "Randall Balestriero",
      "Diane Bouchacourt",
      "Ramakrishna Vedantam",
      "Hamed Firooz",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01772",
    "title": "A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons  and Adaptable Structure",
    "abstract": "Artificial neural networks (ANNs) have permeated various disciplinary domains, ranging from bioinformatics to financial analytics, where their application has become an indispensable facet of contemporary scientific research endeavors. However, the inherent limitations of traditional neural networks arise due to their relatively fixed network structures and activation functions. 1, The type of activation function is single and relatively fixed, which leads to poor \"unit representation ability\" of the network, and it is often used to solve simple problems with very complex networks; 2, the network structure is not adaptive, it is easy to cause network structure redundant or insufficient. To address the aforementioned issues, this study proposes a novel neural network called X-Net. By utilizing our designed Alternating Backpropagation mechanism, X-Net dynamically selects appropriate activation functions based on derivative information during training to enhance the network's representation capability for specific tasks. Simultaneously, it accurately adjusts the network structure at the neuron level to accommodate tasks of varying complexities and reduce computational costs. Through a series of experiments, we demonstrate the dual advantages of X-Net in terms of reducing model size and improving representation power. Specifically, in terms of the number of parameters, X-Net is only 3$\\%$ of baselines on average, and only 1.4$\\%$ under some tasks. In terms of representation ability, X-Net can achieve an average $R^2$=0.985 on the fitting task by only optimizing the activation function without introducing any parameters. Finally, we also tested the ability of X-Net to help scientific discovery on data from multiple disciplines such as society, energy, environment, and aerospace, and achieved concise and good results. ",
    "url": "https://arxiv.org/abs/2401.01772",
    "authors": [
      "Yanjie Li",
      "Weijun Li",
      "Lina Yu",
      "Min Wu",
      "Jinyi Liu",
      "Wenqiang Li",
      "Meilan Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2401.01783",
    "title": "Approximating Numerical Flux by Fourier Neural Operators for the  Hyperbolic Conservation Laws",
    "abstract": "Classical numerical schemes exist for solving PDEs numerically, and recently, neural network-based methods have been developed. However, methodologies using neural networks, such as PINN and neural operators, lack robustness and generalization power. To compensate for such drawbacks, there are many types of research combining classical numerical schemes and machine learning methods by replacing a small portion of the numerical schemes with neural networks. In this work, we focus on hyperbolic conservation laws and replace numerical fluxes in the numerical schemes by neural operator. For this, we construct losses that are motivated by numerical schemes for conservation laws and approximate numerical flux by FNO. Through experiments, we show that our methodology has advantages of both numerical schemes and FNO by comparing with original methods. For instance, we demonstrate our method gains robustness, resolution invariance property, and feasibility of a data-driven method. Our method especially has the ability to predict continuously in time and generalization power on the out-of-distribution samples, which are challenges to be tackled for existing neural operator methods. ",
    "url": "https://arxiv.org/abs/2401.01783",
    "authors": [
      "Taeyoung Kim",
      "Myungjoo Sang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01801",
    "title": "A quatum inspired neural network for geometric modeling",
    "abstract": "By conceiving physical systems as 3D many-body point clouds, geometric graph neural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased promising performance. In particular, their effective message-passing mechanics make them adept at modeling molecules and crystalline materials. However, current geometric GNNs only offer a mean-field approximation of the many-body system, encapsulated within two-body message passing, thus falling short in capturing intricate relationships within these geometric graphs. To address this limitation, tensor networks, widely employed by computational physics to handle manybody systems using high-order tensors, have been introduced. Nevertheless, integrating these tensorized networks into the message-passing framework of GNNs faces scalability and symmetry conservation (e.g., permutation and rotation) challenges. In response, we introduce an innovative equivariant Matrix Product State (MPS)-based message-passing strategy, through achieving an efficient implementation of the tensor contraction operation. Our method effectively models complex many-body relationships, suppressing mean-field approximations, and captures symmetries within geometric graphs. Importantly, it seamlessly replaces the standard message-passing and layer-aggregation modules intrinsic to geometric GNNs. We empirically validate the superior accuracy of our approach on benchmark tasks, including predicting classical Newton systems and quantum tensor Hamiltonian matrices. To our knowledge, our approach represents the inaugural utilization of parameterized geometric tensor networks. ",
    "url": "https://arxiv.org/abs/2401.01801",
    "authors": [
      "Weitao Du",
      "Shengchao Liu",
      "Hongyu Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2401.01813",
    "title": "Signal Processing in the Retina: Interpretable Graph Classifier to  Predict Ganglion Cell Responses",
    "abstract": "It is a popular hypothesis in neuroscience that ganglion cells in the retina are activated by selectively detecting visual features in an observed scene. While ganglion cell firings can be predicted via data-trained deep neural nets, the networks remain indecipherable, thus providing little understanding of the cells' underlying operations. To extract knowledge from the cell firings, in this paper we learn an interpretable graph-based classifier from data to predict the firings of ganglion cells in response to visual stimuli. Specifically, we learn a positive semi-definite (PSD) metric matrix $\\mathbf{M} \\succeq 0$ that defines Mahalanobis distances between graph nodes (visual events) endowed with pre-computed feature vectors; the computed inter-node distances lead to edge weights and a combinatorial graph that is amenable to binary classification. Mathematically, we define the objective of metric matrix $\\mathbf{M}$ optimization using a graph adaptation of large margin nearest neighbor (LMNN), which is rewritten as a semi-definite programming (SDP) problem. We solve it efficiently via a fast approximation called Gershgorin disc perfect alignment (GDPA) linearization. The learned metric matrix $\\mathbf{M}$ provides interpretability: important features are identified along $\\mathbf{M}$'s diagonal, and their mutual relationships are inferred from off-diagonal terms. Our fast metric learning framework can be applied to other biological systems with pre-chosen features that require interpretation. ",
    "url": "https://arxiv.org/abs/2401.01813",
    "authors": [
      "Yasaman Parhizkar",
      "Gene Cheung",
      "Andrew W. Eckford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2401.01830",
    "title": "Iterative Mask Filling: An Effective Text Augmentation Method Using  Masked Language Modeling",
    "abstract": "Data augmentation is an effective technique for improving the performance of machine learning models. However, it has not been explored as extensively in natural language processing (NLP) as it has in computer vision. In this paper, we propose a novel text augmentation method that leverages the Fill-Mask feature of the transformer-based BERT model. Our method involves iteratively masking words in a sentence and replacing them with language model predictions. We have tested our proposed method on various NLP tasks and found it to be effective in many cases. Our results are presented along with a comparison to existing augmentation methods. Experimental results show that our proposed method significantly improves performance, especially on topic classification datasets. ",
    "url": "https://arxiv.org/abs/2401.01830",
    "authors": [
      "Himmet Toprak Kesgin",
      "Mehmet Fatih Amasyali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01836",
    "title": "NODEC: Neural ODE For Optimal Control of Unknown Dynamical Systems",
    "abstract": "Controlling complex dynamical systems is generally associated with minimizing certain control objectives with known dynamics under the variational calculus framework. For systems with unknown dynamics, an additional step of dynamics modeling is required. However, any inaccuracy in dynamics modeling will lead to sub-optimality in the resulting control function. Another set of approaches for controlling unknown dynamical systems - reinforcement learning, folds the dynamics modeling into controller training via value function approximation or policy gradient through extensively interacting with the environment, but it suffers from low data efficiency. To address these, we introduce NODEC, a novel framework for controlling unknown dynamical systems, which combines dynamics modelling and controller training using a coupled neural ODE model. Through an intriguing interplay between the two coupled neural networks, NODEC learns system dynamics as well as optimal controls that guides the unknown dynamical system towards target states. Our experiments demonstrate the effectiveness and data efficiency of NODEC for learning optimal control of unknown dynamical systems. ",
    "url": "https://arxiv.org/abs/2401.01836",
    "authors": [
      "Cheng Chi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01846",
    "title": "DGDNN: Decoupled Graph Diffusion Neural Network for Stock Movement  Prediction",
    "abstract": "Forecasting future stock trends remains challenging for academia and industry due to stochastic inter-stock dynamics and hierarchical intra-stock dynamics influencing stock prices. In recent years, graph neural networks have achieved remarkable performance in this problem by formulating multiple stocks as graph-structured data. However, most of these approaches rely on artificially defined factors to construct static stock graphs, which fail to capture the intrinsic interdependencies between stocks that rapidly evolve. In addition, these methods often ignore the hierarchical features of the stocks and lose distinctive information within. In this work, we propose a novel graph learning approach implemented without expert knowledge to address these issues. First, our approach automatically constructs dynamic stock graphs by entropy-driven edge generation from a signal processing perspective. Then, we further learn task-optimal dependencies between stocks via a generalized graph diffusion process on constructed stock graphs. Last, a decoupled representation learning scheme is adopted to capture distinctive hierarchical intra-stock features. Experimental results demonstrate substantial improvements over state-of-the-art baselines on real-world datasets. Moreover, the ablation study and sensitivity study further illustrate the effectiveness of the proposed method in modeling the time-evolving inter-stock and intra-stock dynamics. ",
    "url": "https://arxiv.org/abs/2401.01846",
    "authors": [
      "Zinuo You",
      "Zijian Shi",
      "Hongbo Bo",
      "John Cartlidge",
      "Li Zhang",
      "Yan Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2401.01851",
    "title": "The Power of Training: How Different Neural Network Setups Influence the  Energy Demand",
    "abstract": "This work examines the effects of variations in machine learning training regimes and learning paradigms on the corresponding energy consumption. While increasing data availability and innovation in high-performance hardware fuels the training of sophisticated models, it also supports the fading perception of energy consumption and carbon emission. Therefore, the goal of this work is to create awareness about the energy impact of general training parameters and processes, from learning rate over batch size to knowledge transfer. Multiple setups with different hyperparameter initializations are evaluated on two different hardware configurations to obtain meaningful results. Experiments on pretraining and multitask training are conducted on top of the baseline results to determine their potential towards sustainable machine learning. ",
    "url": "https://arxiv.org/abs/2401.01851",
    "authors": [
      "Daniel Gei\u00dfler",
      "Bo Zhou",
      "Mengxi Liu",
      "Sungho Suh",
      "Paul Lukowicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2401.01855",
    "title": "Transformer Neural Autoregressive Flows",
    "abstract": "Density estimation, a central problem in machine learning, can be performed using Normalizing Flows (NFs). NFs comprise a sequence of invertible transformations, that turn a complex target distribution into a simple one, by exploiting the change of variables theorem. Neural Autoregressive Flows (NAFs) and Block Neural Autoregressive Flows (B-NAFs) are arguably the most perfomant members of the NF family. However, they suffer scalability issues and training instability due to the constraints imposed on the network structure. In this paper, we propose a novel solution to these challenges by exploiting transformers to define a new class of neural flows called Transformer Neural Autoregressive Flows (T-NAFs). T-NAFs treat each dimension of a random variable as a separate input token, using attention masking to enforce an autoregressive constraint. We take an amortization-inspired approach where the transformer outputs the parameters of an invertible transformation. The experimental results demonstrate that T-NAFs consistently match or outperform NAFs and B-NAFs across multiple datasets from the UCI benchmark. Remarkably, T-NAFs achieve these results using an order of magnitude fewer parameters than previous approaches, without composing multiple flows. ",
    "url": "https://arxiv.org/abs/2401.01855",
    "authors": [
      "Massimiliano Patacchiola",
      "Aliaksandra Shysheya",
      "Katja Hofmann",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.01865",
    "title": "Attackers reveal their arsenal: An investigation of adversarial  techniques in CTI reports",
    "abstract": "Context: Cybersecurity vendors often publish cyber threat intelligence (CTI) reports, referring to the written artifacts on technical and forensic analysis of the techniques used by the malware in APT attacks. Objective: The goal of this research is to inform cybersecurity practitioners about how adversaries form cyberattacks through an analysis of adversarial techniques documented in cyberthreat intelligence reports. Dataset: We use 594 adversarial techniques cataloged in MITRE ATT\\&CK. We systematically construct a set of 667 CTI reports that MITRE ATT\\&CK used as citations in the descriptions of the cataloged adversarial techniques. Methodology: We analyze the frequency and trend of adversarial techniques, followed by a qualitative analysis of the implementation of techniques. Next, we perform association rule mining to identify pairs of techniques recurring in APT attacks. We then perform qualitative analysis to identify the underlying relations among the techniques in the recurring pairs. Findings: The set of 667 CTI reports documents 10,370 techniques in total, and we identify 19 prevalent techniques accounting for 37.3\\% of documented techniques. We also identify 425 statistically significant recurring pairs and seven types of relations among the techniques in these pairs. The top three among the seven relationships suggest that techniques used by the malware inter-relate with one another in terms of (a) abusing or affecting the same system assets, (b) executing in sequences, and (c) overlapping in their implementations. Overall, the study quantifies how adversaries leverage techniques through malware in APT attacks based on publicly reported documents. We advocate organizations prioritize their defense against the identified prevalent techniques and actively hunt for potential malicious intrusion based on the identified pairs of techniques. ",
    "url": "https://arxiv.org/abs/2401.01865",
    "authors": [
      "Md Rayhanur Rahman",
      "Setu Kumar Basak",
      "Rezvan Mahdavi Hezaveh",
      "Laurie Williams"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.01881",
    "title": "Robust Control Barrier Functions using Uncertainty Estimation with  Application to Mobile Robots",
    "abstract": "Model uncertainty poses a significant challenge to the implementation of safety-critical control systems. With this as motivation, this paper proposes a safe control design approach that guarantees the robustness of nonlinear feedback systems in the presence of matched or unmatched unmodelled system dynamics and external disturbances. Our approach couples control barrier functions (CBFs) with a new uncertainty/disturbance estimator to ensure robust safety against input and state-dependent model uncertainties. We prove upper bounds on the estimator's error and estimated outputs. We use an uncertainty estimator-based composite feedback control law to adaptively improve robust control performance under hard safety constraints by compensating for the matched uncertainty. Then, we robustify existing CBF constraints with this uncertainty estimate and the estimation error bounds to ensure robust safety via a quadratic program (CBF-QP). We also extend our method to higher-order CBFs (HOCBFs) to achieve safety under unmatched uncertainty, which causes relative degree differences with respect to control input and disturbance. We assume the relative degree difference is at most one, resulting in a second-order cone (SOC) condition. The proposed robust HOCBFs method is demonstrated in a simulation of an uncertain elastic actuator control problem. Finally, the efficacy of our method is experimentally demonstrated on a tracked robot with slope-induced matched and unmatched perturbations. ",
    "url": "https://arxiv.org/abs/2401.01881",
    "authors": [
      "Ersin Das",
      "Joel W. Burdick"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2401.01883",
    "title": "Mining Temporal Attack Patterns from Cyberthreat Intelligence Reports",
    "abstract": "Defending from cyberattacks requires practitioners to operate on high-level adversary behavior. Cyberthreat intelligence (CTI) reports on past cyberattack incidents describe the chain of malicious actions with respect to time. To avoid repeating cyberattack incidents, practitioners must proactively identify and defend against recurring chain of actions - which we refer to as temporal attack patterns. Automatically mining the patterns among actions provides structured and actionable information on the adversary behavior of past cyberattacks. The goal of this paper is to aid security practitioners in prioritizing and proactive defense against cyberattacks by mining temporal attack patterns from cyberthreat intelligence reports. To this end, we propose ChronoCTI, an automated pipeline for mining temporal attack patterns from cyberthreat intelligence (CTI) reports of past cyberattacks. To construct ChronoCTI, we build the ground truth dataset of temporal attack patterns and apply state-of-the-art large language models, natural language processing, and machine learning techniques. We apply ChronoCTI on a set of 713 CTI reports, where we identify 124 temporal attack patterns - which we categorize into nine pattern categories. We identify that the most prevalent pattern category is to trick victim users into executing malicious code to initiate the attack, followed by bypassing the anti-malware system in the victim network. Based on the observed patterns, we advocate organizations to train users about cybersecurity best practices, introduce immutable operating systems with limited functionalities, and enforce multi-user authentications. Moreover, we advocate practitioners to leverage the automated mining capability of ChronoCTI and design countermeasures against the recurring attack patterns. ",
    "url": "https://arxiv.org/abs/2401.01883",
    "authors": [
      "Md Rayhanur Rahman",
      "Brandon Wroblewski",
      "Quinn Matthews",
      "Brantley Morgan",
      "Tim Menzies",
      "Laurie Williams"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.01349",
    "title": "The Anatomy Spread of Online Opinion Polarization: The Pivotal Role of  Super-Spreaders in Social Networks",
    "abstract": "The study investigates the role of 'superspreaders' in shaping opinions within networks, distinguishing three types: A, B, and C. Type A has a significant influence in shaping opinions, Type B acts as a counterbalance to A, and Type C functions like media, providing an objective viewpoint and potentially regulating A and B's influence. The research uses a confidence coefficient and z-score to survey superspreaders' behaviors, with a focus on the conditions affecting group dynamics and opinion formation, including environmental factors and forgetfulness over time. The findings offer insights for improving online communication security and understanding social influence. ",
    "url": "https://arxiv.org/abs/2401.01349",
    "authors": [
      "Yasuko Kawahata"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01364",
    "title": "Multi-Modal Cognitive Maps based on Neural Networks trained on Successor  Representations",
    "abstract": "Cognitive maps are a proposed concept on how the brain efficiently organizes memories and retrieves context out of them. The entorhinal-hippocampal complex is heavily involved in episodic and relational memory processing, as well as spatial navigation and is thought to built cognitive maps via place and grid cells. To make use of the promising properties of cognitive maps, we set up a multi-modal neural network using successor representations which is able to model place cell dynamics and cognitive map representations. Here, we use multi-modal inputs consisting of images and word embeddings. The network learns the similarities between novel inputs and the training database and therefore the representation of the cognitive map successfully. Subsequently, the prediction of the network can be used to infer from one modality to another with over $90\\%$ accuracy. The proposed method could therefore be a building block to improve current AI systems for better understanding of the environment and the different modalities in which objects appear. The association of specific modalities with certain encounters can therefore lead to context awareness in novel situations when similar encounters with less information occur and additional information can be inferred from the learned cognitive map. Cognitive maps, as represented by the entorhinal-hippocampal complex in the brain, organize and retrieve context from memories, suggesting that large language models (LLMs) like ChatGPT could harness similar architectures to function as a high-level processing center, akin to how the hippocampus operates within the cortex hierarchy. Finally, by utilizing multi-modal inputs, LLMs can potentially bridge the gap between different forms of data (like images and words), paving the way for context-awareness and grounding of abstract concepts through learned associations, addressing the grounding problem in AI. ",
    "url": "https://arxiv.org/abs/2401.01364",
    "authors": [
      "Paul Stoewer",
      "Achim Schilling",
      "Andreas Maier",
      "Patrick Krauss"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2401.01473",
    "title": "Self-supervised Reflective Learning through Self-distillation and Online  Clustering for Speaker Representation Learning",
    "abstract": "Speaker representation learning is critical for modern voice recognition systems. While supervised learning techniques require extensive labeled data, unsupervised methodologies can leverage vast unlabeled corpora, offering a scalable solution. This paper introduces self-supervised reflective learning (SSRL), a novel paradigm that streamlines existing iterative unsupervised frameworks. SSRL integrates self-supervised knowledge distillation with online clustering to refine pseudo labels and train the model without iterative bottlenecks. Specifically, a teacher model continually refines pseudo labels through online clustering, providing dynamic supervision signals to train the student model. The student model undergoes noisy student training with input and model noise to boost its modeling capacity. The teacher model is updated via an exponential moving average of the student, acting as an ensemble of past iterations. Further, a pseudo label queue retains historical labels for consistency, and noisy label modeling directs learning towards clean samples. Experiments on VoxCeleb show SSRL's superiority over current iterative approaches, surpassing the performance of a 5-round method in just a single training round. Ablation studies validate the contributions of key components like noisy label modeling and pseudo label queues. Moreover, consistent improvements in pseudo labeling and the convergence of cluster counts demonstrate SSRL's effectiveness in deciphering unlabeled data. This work marks an important advancement in efficient and accurate speaker representation learning through the novel reflective learning paradigm. ",
    "url": "https://arxiv.org/abs/2401.01473",
    "authors": [
      "Danwei Cai",
      "Zexin Cai",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2401.01496",
    "title": "From Pixel to Slide image: Polarization Modality-based Pathological  Diagnosis Using Representation Learning",
    "abstract": "Thyroid cancer is the most common endocrine malignancy, and accurately distinguishing between benign and malignant thyroid tumors is crucial for developing effective treatment plans in clinical practice. Pathologically, thyroid tumors pose diagnostic challenges due to improper specimen sampling. In this study, we have designed a three-stage model using representation learning to integrate pixel-level and slice-level annotations for distinguishing thyroid tumors. This structure includes a pathology structure recognition method to predict structures related to thyroid tumors, an encoder-decoder network to extract pixel-level annotation information by learning the feature representations of image blocks, and an attention-based learning mechanism for the final classification task. This mechanism learns the importance of different image blocks in a pathological region, globally considering the information from each block. In the third stage, all information from the image blocks in a region is aggregated using attention mechanisms, followed by classification to determine the category of the region. Experimental results demonstrate that our proposed method can predict microscopic structures more accurately. After color-coding, the method achieves results on unstained pathology slides that approximate the quality of Hematoxylin and eosin staining, reducing the need for stained pathology slides. Furthermore, by leveraging the concept of indirect measurement and extracting polarized features from structures correlated with lesions, the proposed method can also classify samples where membrane structures cannot be obtained through sampling, providing a potential objective and highly accurate indirect diagnostic technique for thyroid tumors. ",
    "url": "https://arxiv.org/abs/2401.01496",
    "authors": [
      "Jia Dong",
      "Yao Yao",
      "Yang Dong",
      "Hui Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01498",
    "title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic  Token Prediction",
    "abstract": "We propose a novel text-to-speech (TTS) framework centered around a neural transducer. Our approach divides the whole TTS pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. For a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR) speech generator efficiently synthesizes waveforms from these semantic tokens. Additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. This decoupled framework reduces the training complexity of TTS while allowing each stage to focus on semantic and acoustic modeling. Our experimental results on zero-shot adaptive TTS demonstrate that our model surpasses the baseline in terms of speech quality and speaker similarity, both objectively and subjectively. We also delve into the inference speed and prosody control capabilities of our approach, highlighting the potential of neural transducers in TTS frameworks. ",
    "url": "https://arxiv.org/abs/2401.01498",
    "authors": [
      "Minchan Kim",
      "Myeonghun Jeong",
      "Byoung Jin Choi",
      "Semin Kim",
      "Joun Yeop Lee",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2401.01608",
    "title": "Interference Management in 5G and Beyond Networks",
    "abstract": "During the last decade, wireless data services have had an incredible impact on people's lives in ways we could never have imagined. The number of mobile devices has increased exponentially and data traffic has almost doubled every year. Undoubtedly, the rate of growth will continue to be rapid with the explosive increase in demands for data rates, latency, massive connectivity, network reliability, and energy efficiency. In order to manage this level of growth and meet these requirements, the fifth-generation (5G) mobile communications network is envisioned as a revolutionary advancement combining various improvements to previous mobile generation networks and new technologies, including the use of millimeter wavebands (mm-wave), massive multiple-input multipleoutput (mMIMO) multi-beam antennas, network densification, dynamic Time Division Duplex (TDD) transmission, and new waveforms with mixed numerologies. New revolutionary features including terahertz (THz) communications and the integration of Non-Terrestrial Networks (NTN) can further improve the performance and signal quality for future 6G networks. However, despite the inevitable benefits of all these key technologies, the heterogeneous and ultra-flexible structure of the 5G and beyond network brings non-orthogonality into the system and generates significant interference that needs to be handled carefully. Therefore, it is essential to design effective interference management schemes to mitigate severe and sometimes unpredictable interference in mobile networks. In this paper, we provide a comprehensive review of interference management in 5G and Beyond networks and discuss its future evolution. We start with a unified classification and a detailed explanation of the different types of interference and continue by presenting our taxonomy of existing interference management approaches. Then, after explaining interference measurement reports and signaling, we provide for each type of interference identified, an in-depth literature review and technical discussion of appropriate management schemes. We finish by discussing the main interference challenges that will be encountered in future 6G networks and by presenting insights on the suggested new interference management approaches, including useful guidelines for an AI-based solution. This review will provide a first-hand guide to the industry in determining the most relevant technology for interference management, and will also allow for consideration of future challenges and research directions. ",
    "url": "https://arxiv.org/abs/2401.01608",
    "authors": [
      "Nessrine Trabelsi",
      "Lamia Chaari Fourati",
      "Chung Shue Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2401.01681",
    "title": "Hamiltonicity of Schrijver graphs and stable Kneser graphs",
    "abstract": "For integers $k\\geq 1$ and $n\\geq 2k+1$, the Schrijver graph $S(n,k)$ has as vertices all $k$-element subsets of $[n]:=\\{1,2,\\ldots,n\\}$ that contain no two cyclically adjacent elements, and an edge between any two disjoint sets. More generally, for integers $k\\geq 1$, $s\\geq 2$, and $n \\geq sk+1$, the $s$-stable Kneser graph $S(n,k,s)$ has as vertices all $k$-element subsets of $[n]$ in which any two elements are in cyclical distance at least $s$. We prove that all the graphs $S(n,k,s)$, in particular Schrijver graphs $S(n,k)=S(n,k,2)$, admit a Hamilton cycle that can be computed in time $\\mathcal{O}(n)$ per generated vertex. ",
    "url": "https://arxiv.org/abs/2401.01681",
    "authors": [
      "Torsten M\u00fctze",
      "Namrata"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2401.01685",
    "title": "Modality Exchange Network for Retinogeniculate Visual Pathway  Segmentation",
    "abstract": "Accurate segmentation of the retinogeniculate visual pathway (RGVP) aids in the diagnosis and treatment of visual disorders by identifying disruptions or abnormalities within the pathway. However, the complex anatomical structure and connectivity of RGVP make it challenging to achieve accurate segmentation. In this study, we propose a novel Modality Exchange Network (ME-Net) that effectively utilizes multi-modal magnetic resonance (MR) imaging information to enhance RGVP segmentation. Our ME-Net has two main contributions. Firstly, we introduce an effective multi-modal soft-exchange technique. Specifically, we design a channel and spatially mixed attention module to exchange modality information between T1-weighted and fractional anisotropy MR images. Secondly, we propose a cross-fusion module that further enhances the fusion of information between the two modalities. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches in terms of RGVP segmentation performance. ",
    "url": "https://arxiv.org/abs/2401.01685",
    "authors": [
      "Hua Han",
      "Cheng Li",
      "Lei Xie",
      "Yuanjing Feng",
      "Alou Diakite",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01874",
    "title": "Graph Neural Networks for Surfactant Multi-Property Prediction",
    "abstract": "Surfactants are of high importance in different industrial sectors such as cosmetics, detergents, oil recovery and drug delivery systems. Therefore, many quantitative structure-property relationship (QSPR) models have been developed for surfactants. Each predictive model typically focuses on one surfactant class, mostly nonionics. Graph Neural Networks (GNNs) have exhibited a great predictive performance for property prediction of ionic liquids, polymers and drugs in general. Specifically for surfactants, GNNs can successfully predict critical micelle concentration (CMC), a key surfactant property associated with micellization. A key factor in the predictive ability of QSPR and GNN models is the data available for training. Based on extensive literature search, we create the largest available CMC database with 429 molecules and the first large data collection for surface excess concentration ($\\Gamma$$_{m}$), another surfactant property associated with foaming, with 164 molecules. Then, we develop GNN models to predict the CMC and $\\Gamma$$_{m}$ and we explore different learning approaches, i.e., single- and multi-task learning, as well as different training strategies, namely ensemble and transfer learning. We find that a multi-task GNN with ensemble learning trained on all $\\Gamma$$_{m}$ and CMC data performs best. Finally, we test the ability of our CMC model to generalize on industrial grade pure component surfactants. The GNN yields highly accurate predictions for CMC, showing great potential for future industrial applications. ",
    "url": "https://arxiv.org/abs/2401.01874",
    "authors": [
      "Christoforos Brozos",
      "Jan G. Rittig",
      "Sandip Bhattacharya",
      "Elie Akanny",
      "Christina Kohlmann",
      "Alexander Mitsos"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.03958",
    "title": "TrAISformer -- A Transformer Network with Sparse Augmented Data  Representation and Cross Entropy Loss for AIS-based Vessel Trajectory  Prediction",
    "abstract": " Title: TrAISformer -- A Transformer Network with Sparse Augmented Data  Representation and Cross Entropy Loss for AIS-based Vessel Trajectory  Prediction ",
    "url": "https://arxiv.org/abs/2109.03958",
    "authors": [
      "Duong Nguyen",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04514",
    "title": "Large independent sets in recursive Markov random graphs",
    "abstract": " Comments: reorganisation with technical proofs at end; background on Markov graphs; some open questions; clarifications; corrections of typos ",
    "url": "https://arxiv.org/abs/2207.04514",
    "authors": [
      "Akshay Gupte",
      "Yiran Zhu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2208.10962",
    "title": "Prediction of good reaction coordinates and future evolution of MD  trajectories using Regularized Sparse Autoencoders: A novel deep learning  approach",
    "abstract": " Title: Prediction of good reaction coordinates and future evolution of MD  trajectories using Regularized Sparse Autoencoders: A novel deep learning  approach ",
    "url": "https://arxiv.org/abs/2208.10962",
    "authors": [
      "Abhijit Gupta"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.12511",
    "title": "Lower Difficulty and Better Robustness: A Bregman Divergence Perspective  for Adversarial Training",
    "abstract": " Title: Lower Difficulty and Better Robustness: A Bregman Divergence Perspective  for Adversarial Training ",
    "url": "https://arxiv.org/abs/2208.12511",
    "authors": [
      "Zihui Wu",
      "Haichang Gao",
      "Bingqian Zhou",
      "Xiaoyan Guo",
      "Shudong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12282",
    "title": "Bridging the Gap Between Target Networks and Functional Regularization",
    "abstract": " Comments: The published version of this paper (TMLR 2023) is available at arXiv:2106.02613 and this https URL ",
    "url": "https://arxiv.org/abs/2210.12282",
    "authors": [
      "Alexandre Piche",
      "Valentin Thomas",
      "Joseph Marino",
      "Rafael Pardinas",
      "Gian Maria Marconi",
      "Christopher Pal",
      "Mohammad Emtiyaz Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05987",
    "title": "Selective classification using a robust meta-learning approach",
    "abstract": " Title: Selective classification using a robust meta-learning approach ",
    "url": "https://arxiv.org/abs/2212.05987",
    "authors": [
      "Nishant Jain",
      "Karthikeyan Shanmugam",
      "Pradeep Shenoy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.14484",
    "title": "OriCon3D: Effective 3D Object Detection using Orientation and Confidence",
    "abstract": " Title: OriCon3D: Effective 3D Object Detection using Orientation and Confidence ",
    "url": "https://arxiv.org/abs/2304.14484",
    "authors": [
      "Dhyey Manish Rajani",
      "Surya Pratap Singh",
      "Rahul Kashyap Swayampakula"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.00011",
    "title": "Adversarial Representation Learning for Robust Privacy Preservation in  Audio",
    "abstract": " Comments: Published in IEEE Open Journal of Signal Processing ",
    "url": "https://arxiv.org/abs/2305.00011",
    "authors": [
      "Shayan Gharib",
      "Minh Tran",
      "Diep Luong",
      "Konstantinos Drossos",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.17998",
    "title": "Infinite Eulerian trails are computable on graphs with vertices of  infinite degree",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2305.17998",
    "authors": [
      "Nicanor Carrasco-Vargas"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2306.07618",
    "title": "Hyperbolic Graph Diffusion Model",
    "abstract": " Comments: accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2306.07618",
    "authors": [
      "Lingfeng Wen",
      "Xuan Tang",
      "Mingjie Ouyang",
      "Xiangxiang Shen",
      "Jian Yang",
      "Daxin Zhu",
      "Mingsong Chen",
      "Xian Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.16309",
    "title": "Raphtory: The temporal graph engine for Rust and Python",
    "abstract": " Title: Raphtory: The temporal graph engine for Rust and Python ",
    "url": "https://arxiv.org/abs/2306.16309",
    "authors": [
      "Ben Steer",
      "Naomi Arnold",
      "Cheick Tidiane Ba",
      "Renaud Lambiotte",
      "Haaroon Yousaf",
      "Lucas Jeub",
      "Fabian Murariu",
      "Shivam Kapoor",
      "Pedro Rico",
      "Rachel Chan",
      "Louis Chan",
      "James Alford",
      "Richard G. Clegg",
      "Felix Cuadrado",
      "Matthew Russell Barnes",
      "Peijie Zhong",
      "John N. Pougu\u00e9 Biyong",
      "Alhamza Alnaimi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.17408",
    "title": "LMBot: Distilling Graph Knowledge into Language Model for Graph-less  Deployment in Twitter Bot Detection",
    "abstract": " Comments: 11 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2306.17408",
    "authors": [
      "Zijian Cai",
      "Zhaoxuan Tan",
      "Zhenyu Lei",
      "Zifeng Zhu",
      "Hongrui Wang",
      "Qinghua Zheng",
      "Minnan Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.00859",
    "title": "CardiGraphormer: Unveiling the Power of Self-Supervised Learning in  Revolutionizing Drug Discovery",
    "abstract": " Title: CardiGraphormer: Unveiling the Power of Self-Supervised Learning in  Revolutionizing Drug Discovery ",
    "url": "https://arxiv.org/abs/2307.00859",
    "authors": [
      "Abhijit Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.04049",
    "title": "Parallel Algorithms Align with Neural Execution",
    "abstract": " Comments: 13 pages, 7 figures, Proceedings of the Second Learning on Graphs Conference (LoG 2023), PMLR 231 ",
    "url": "https://arxiv.org/abs/2307.04049",
    "authors": [
      "Valerie Engelmayer",
      "Dobrik Georgiev",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14823",
    "title": "Fading memory as inductive bias in residual recurrent networks",
    "abstract": " Title: Fading memory as inductive bias in residual recurrent networks ",
    "url": "https://arxiv.org/abs/2307.14823",
    "authors": [
      "Igor Dubinin",
      "Felix Effenberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.00583",
    "title": "Semisupervised Anomaly Detection using Support Vector Regression with  Quantum Kernel",
    "abstract": " Comments: Accepted to IEEE International Conference on Quantum Computing and Engineering (QCE) 2023 ",
    "url": "https://arxiv.org/abs/2308.00583",
    "authors": [
      "Kilian Tscharke",
      "Sebastian Issel",
      "Pascal Debus"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09595",
    "title": "Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents",
    "abstract": " Comments: Accepted at AAAI-24 conference ",
    "url": "https://arxiv.org/abs/2308.09595",
    "authors": [
      "Arrasy Rahman",
      "Jiaxun Cui",
      "Peter Stone"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14279",
    "title": "Sampling unknown large networks restricted by low sampling rates",
    "abstract": " Comments: 25 pages,11 figures ",
    "url": "https://arxiv.org/abs/2308.14279",
    "authors": [
      "Bo Jiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.02084",
    "title": "Unsupervised Out-of-Distribution Detection by Restoring Lossy Inputs  with Variational Autoencoder",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2309.02084",
    "authors": [
      "Zezhen Zeng",
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00488",
    "title": "On Memorization and Privacy Risks of Sharpness Aware Minimization",
    "abstract": " Title: On Memorization and Privacy Risks of Sharpness Aware Minimization ",
    "url": "https://arxiv.org/abs/2310.00488",
    "authors": [
      "Young In Kim",
      "Pratiksha Agrawal",
      "Johannes O. Royset",
      "Rajiv Khanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04171",
    "title": "Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection",
    "abstract": " Comments: 5 pages, 3 figures, 3 tables. Machine Learning on Graphs (MLoG) Workshop at the 23rd IEEE International Conference on Data Mining (ICDM 2023) ",
    "url": "https://arxiv.org/abs/2310.04171",
    "authors": [
      "Heehyeon Kim",
      "Jinhyeok Choi",
      "Joyce Jiyoung Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.05354",
    "title": "An Initial Investigation of Neural Replay Simulator for Over-the-Air  Adversarial Perturbations to Automatic Speaker Verification",
    "abstract": " Comments: Accepted in ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2310.05354",
    "authors": [
      "Jiaqi Li",
      "Li Wang",
      "Liumeng Xue",
      "Lei Wang",
      "Zhizheng Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.17097",
    "title": "Navigating Data Heterogeneity in Federated Learning A Semi-Supervised  Federated Object Detection",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.17097",
    "authors": [
      "Taehyeon Kim",
      "Eric Lin",
      "Junu Lee",
      "Christian Lau",
      "Vaikkunth Mugunthan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.17190",
    "title": "Lookup Table meets Local Laplacian Filter: Pyramid Reconstruction  Network for Tone Mapping",
    "abstract": " Comments: 12 pages, 6 figures, accepted by NeurlPS 2023 ",
    "url": "https://arxiv.org/abs/2310.17190",
    "authors": [
      "Feng Zhang",
      "Ming Tian",
      "Zhiqiang Li",
      "Bin Xu",
      "Qingbo Lu",
      "Changxin Gao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.19274",
    "title": "Prediction of Effective Elastic Moduli of Rocks using Graph Neural  Networks",
    "abstract": " Title: Prediction of Effective Elastic Moduli of Rocks using Graph Neural  Networks ",
    "url": "https://arxiv.org/abs/2310.19274",
    "authors": [
      "Jaehong Chung",
      "Rasool Ahmad",
      "WaiChing Sun",
      "Wei Cai",
      "Tapan Mukerji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2312.05840",
    "title": "Topological Data Analysis for Neural Network Analysis: A Comprehensive  Survey",
    "abstract": " Comments: 70 pages, 7 figures. 4 references added. Minor changes in the text. Part of generative models reestructured to improve generality and clarity of exposition ",
    "url": "https://arxiv.org/abs/2312.05840",
    "authors": [
      "Rub\u00e9n Ballester",
      "Carles Casacuberta",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2312.13863",
    "title": "Manipulating Trajectory Prediction with Backdoors",
    "abstract": " Comments: 9 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2312.13863",
    "authors": [
      "Kaouther Messaoud",
      "Kathrin Grosse",
      "Mickael Chen",
      "Matthieu Cord",
      "Patrick P\u00e9rez",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2401.00695",
    "title": "Credible Teacher for Semi-Supervised Object Detection in Open Scene",
    "abstract": " Comments: Accpet by ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2401.00695",
    "authors": [
      "Jingyu Zhuang",
      "Kuo Wang",
      "Liang Lin",
      "Guanbin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]