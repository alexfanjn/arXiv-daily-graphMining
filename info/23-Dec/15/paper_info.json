[
  {
    "id": "arXiv:2312.08374",
    "title": "Unsupervised Social Event Detection via Hybrid Graph Contrastive  Learning and Reinforced Incremental Clustering",
    "abstract": "Detecting events from social media data streams is gradually attracting researchers. The innate challenge for detecting events is to extract discriminative information from social media data thereby assigning the data into different events. Due to the excessive diversity and high updating frequency of social data, using supervised approaches to detect events from social messages is hardly achieved. To this end, recent works explore learning discriminative information from social messages by leveraging graph contrastive learning (GCL) and embedding clustering in an unsupervised manner. However, two intrinsic issues exist in benchmark methods: conventional GCL can only roughly explore partial attributes, thereby insufficiently learning the discriminative information of social messages; for benchmark methods, the learned embeddings are clustered in the latent space by taking advantage of certain specific prior knowledge, which conflicts with the principle of unsupervised learning paradigm. In this paper, we propose a novel unsupervised social media event detection method via hybrid graph contrastive learning and reinforced incremental clustering (HCRC), which uses hybrid graph contrastive learning to comprehensively learn semantic and structural discriminative information from social messages and reinforced incremental clustering to perform efficient clustering in a solidly unsupervised manner. We conduct comprehensive experiments to evaluate HCRC on the Twitter and Maven datasets. The experimental results demonstrate that our approach yields consistent significant performance boosts. In traditional incremental setting, semi-supervised incremental setting and solidly unsupervised setting, the model performance has achieved maximum improvements of 53%, 45%, and 37%, respectively. ",
    "url": "https://arxiv.org/abs/2312.08374",
    "authors": [
      "Yuanyuan Guo",
      "Zehua Zang",
      "Hang Gao",
      "Xiao Xu",
      "Rui Wang",
      "Lixiang Liu",
      "Jiangmeng Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08377",
    "title": "ALGNet: Attention Light Graph Memory Network for Medical Recommendation  System",
    "abstract": "Medication recommendation is a vital task for improving patient care and reducing adverse events. However, existing methods often fail to capture the complex and dynamic relationships among patient medical records, drug efficacy and safety, and drug-drug interactions (DDI). In this paper, we propose ALGNet, a novel model that leverages light graph convolutional networks (LGCN) and augmentation memory networks (AMN) to enhance medication recommendation. LGCN can efficiently encode the patient records and the DDI graph into low-dimensional embeddings, while AMN can augment the patient representation with external knowledge from a memory module. We evaluate our model on the MIMIC-III dataset and show that it outperforms several baselines in terms of recommendation accuracy and DDI avoidance. We also conduct an ablation study to analyze the effects of different components of our model. Our results demonstrate that ALGNet can achieve superior performance with less computation and more interpretability. The implementation of this paper can be found at: https://github.com/huyquoctrinh/ALGNet. ",
    "url": "https://arxiv.org/abs/2312.08377",
    "authors": [
      "Minh-Van Nguyen",
      "Duy-Thinh Nguyen",
      "Quoc-Huy Trinh",
      "Bac-Hoai Le"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2312.08378",
    "title": "Singular Value Penalization and Semantic Data Augmentation for Fully  Test-Time Adaptation",
    "abstract": "Fully test-time adaptation (FTTA) adapts a model that is trained on a source domain to a target domain during the testing phase, where the two domains follow different distributions and source data is unavailable during the training phase. Existing methods usually adopt entropy minimization to reduce the uncertainty of target prediction results, and improve the FTTA performance accordingly. However, they fail to ensure the diversity in target prediction results. Recent domain adaptation study has shown that maximizing the sum of singular values of prediction results can simultaneously enhance their confidence (discriminability) and diversity. However, during the training phase, larger singular values usually take up a dominant position in loss maximization. This results in the model being more inclined to enhance discriminability for easily distinguishable classes, and the improvement in diversity is insufficiently effective. Furthermore, the adaptation and prediction in FTTA only use data from the current batch, which may lead to the risk of overfitting. To address the aforementioned issues, we propose maximizing the sum of singular values while minimizing their variance. This enables the model's focus toward the smaller singular values, enhancing discriminability between more challenging classes and effectively increasing the diversity of prediction results. Moreover, we incorporate data from the previous batch to realize semantic data augmentation for the current batch, reducing the risk of overfitting. Extensive experiments on benchmark datasets show our proposed approach outperforms some compared state-of-the-art FTTA methods. ",
    "url": "https://arxiv.org/abs/2312.08378",
    "authors": [
      "Houcheng Su",
      "Daixian Liu",
      "Mengzhu Wang",
      "Wei Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08383",
    "title": "Improving age prediction: Utilizing LSTM-based dynamic forecasting for  data augmentation in multivariate time series analysis",
    "abstract": "The high dimensionality and complexity of neuroimaging data necessitate large datasets to develop robust and high-performing deep learning models. However, the neuroimaging field is notably hampered by the scarcity of such datasets. In this work, we proposed a data augmentation and validation framework that utilizes dynamic forecasting with Long Short-Term Memory (LSTM) networks to enrich datasets. We extended multivariate time series data by predicting the time courses of independent component networks (ICNs) in both one-step and recursive configurations. The effectiveness of these augmented datasets was then compared with the original data using various deep learning models designed for chronological age prediction tasks. The results suggest that our approach improves model performance, providing a robust solution to overcome the challenges presented by the limited size of neuroimaging datasets. ",
    "url": "https://arxiv.org/abs/2312.08383",
    "authors": [
      "Yutong Gao",
      "Charles A. Ellis",
      "Vince D. Calhoun",
      "Robyn L. Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08388",
    "title": "Exploring Graph Based Approaches for Author Name Disambiguation",
    "abstract": "In many applications, such as scientific literature management, researcher search, social network analysis and etc, Name Disambiguation (aiming at disambiguating WhoIsWho) has been a challenging problem. In addition, the growth of scientific literature makes the problem more difficult and urgent. Although name disambiguation has been extensively studied in academia and industry, the problem has not been solved well due to the clutter of data and the complexity of the same name scenario. In this work, we aim to explore models that can perform the task of name disambiguation using the network structure that is intrinsic to the problem and present an analysis of the models. ",
    "url": "https://arxiv.org/abs/2312.08388",
    "authors": [
      "Chetanya Rastogi",
      "Prabhat Agarwal",
      "Shreya Singh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08394",
    "title": "From HODL to MOON: Understanding Community Evolution, Emotional  Dynamics, and Price Interplay in the Cryptocurrency Ecosystem",
    "abstract": "This paper presents a large-scale analysis of the cryptocurrency community on Reddit, shedding light on the intricate relationship between the evolution of their activity, emotional dynamics, and price movements. We analyze over 130M posts on 122 cryptocurrency-related subreddits using temporal analysis, statistical modeling, and emotion detection. While /r/CryptoCurrency and /r/dogecoin are the most active subreddits, we find an overall surge in cryptocurrency-related activity in 2021, followed by a sharp decline. We also uncover a strong relationship in terms of cross-correlation between online activity and the price of various coins, with the changes in the number of posts mostly leading the price changes. Backtesting analysis shows that a straightforward strategy based on the cross-correlation where one buys/sells a coin if the daily number of posts about it is greater/less than the previous would have led to a 3x return on investment. Finally, we shed light on the emotional dynamics of the cryptocurrency communities, finding that joy becomes a prominent indicator during upward market performance, while a decline in the market manifests an increase in anger. ",
    "url": "https://arxiv.org/abs/2312.08394",
    "authors": [
      "Kostantinos Papadamou",
      "Jay Patel",
      "Jeremy Blackburn",
      "Philipp Jovanovic",
      "Emiliano De Cristofaro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.08401",
    "title": "Balanced and Deterministic Weight-sharing Helps Network Performance",
    "abstract": "Weight-sharing plays a significant role in the success of many deep neural networks, by increasing memory efficiency and incorporating useful inductive priors about the problem into the network. But understanding how weight-sharing can be used effectively in general is a topic that has not been studied extensively. Chen et al. [2015] proposed HashedNets, which augments a multi-layer perceptron with a hash table, as a method for neural network compression. We generalize this method into a framework (ArbNets) that allows for efficient arbitrary weight-sharing, and use it to study the role of weight-sharing in neural networks. We show that common neural networks can be expressed as ArbNets with different hash functions. We also present two novel hash functions, the Dirichlet hash and the Neighborhood hash, and use them to demonstrate experimentally that balanced and deterministic weight-sharing helps with the performance of a neural network. ",
    "url": "https://arxiv.org/abs/2312.08401",
    "authors": [
      "Oscar Chang",
      "Hod Lipson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08410",
    "title": "Universal Approximation Property of Random Neural Networks",
    "abstract": "In this paper, we study random neural networks which are single-hidden-layer feedforward neural networks whose weights and biases are randomly initialized. After this random initialization, only the linear readout needs to be trained, which can be performed efficiently, e.g., by the least squares method. By viewing random neural networks as Banach space-valued random variables, we prove their universal approximation properties within suitable Bochner spaces. Hereby, the corresponding Banach space can be more general than the space of continuous functions over a compact subset of a Euclidean space, namely, e.g., an $L^p$-space or a Sobolev space, where the latter includes the approximation of the derivatives. Moreover, we derive some approximation rates and develop an explicit algorithm to learn a deterministic function by a random neural network. In addition, we provide a full error analysis and study when random neural networks overcome the curse of dimensionality in the sense that the training costs scale at most polynomially in the input and output dimension. Furthermore, we show in two numerical examples the empirical advantages of random neural networks compared to fully trained deterministic neural networks. ",
    "url": "https://arxiv.org/abs/2312.08410",
    "authors": [
      "Ariel Neufeld",
      "Philipp Schmocker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.08413",
    "title": "Privacy Constrained Fairness Estimation for Decision Trees",
    "abstract": "The protection of sensitive data becomes more vital, as data increases in value and potency. Furthermore, the pressure increases from regulators and society on model developers to make their Artificial Intelligence (AI) models non-discriminatory. To boot, there is a need for interpretable, transparent AI models for high-stakes tasks. In general, measuring the fairness of any AI model requires the sensitive attributes of the individuals in the dataset, thus raising privacy concerns. In this work, the trade-offs between fairness, privacy and interpretability are further explored. We specifically examine the Statistical Parity (SP) of Decision Trees (DTs) with Differential Privacy (DP), that are each popular methods in their respective subfield. We propose a novel method, dubbed Privacy-Aware Fairness Estimation of Rules (PAFER), that can estimate SP in a DP-aware manner for DTs. DP, making use of a third-party legal entity that securely holds this sensitive data, guarantees privacy by adding noise to the sensitive data. We experimentally compare several DP mechanisms. We show that using the Laplacian mechanism, the method is able to estimate SP with low error while guaranteeing the privacy of the individuals in the dataset with high certainty. We further show experimentally and theoretically that the method performs better for DTs that humans generally find easier to interpret. ",
    "url": "https://arxiv.org/abs/2312.08413",
    "authors": [
      "Florian van der Steen",
      "Fr\u00e9 Vink",
      "Heysem Kaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.08418",
    "title": "Automatic Bug Detection in Games using LSTM Networks",
    "abstract": "We introduced a new framework to detect perceptual bugs using a Long Short-Term Memory (LSTM) network, which detects bugs in video games as anomalies. The detected buggy frames are then clustered to determine the category of the occurred bug. The framework was evaluated on two First Person Shooter (FPS) games. Results show the effectiveness of the framework. ",
    "url": "https://arxiv.org/abs/2312.08418",
    "authors": [
      "Elham Azizi",
      "Loutfouz Zaman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.08459",
    "title": "FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head  Models",
    "abstract": "We introduce FaceTalk, a novel generative approach designed for synthesizing high-fidelity 3D motion sequences of talking human heads from input audio signal. To capture the expressive, detailed nature of human heads, including hair, ears, and finer-scale eye movements, we propose to couple speech signal with the latent space of neural parametric head models to create high-fidelity, temporally coherent motion sequences. We propose a new latent diffusion model for this task, operating in the expression space of neural parametric head models, to synthesize audio-driven realistic head sequences. In the absence of a dataset with corresponding NPHM expressions to audio, we optimize for these correspondences to produce a dataset of temporally-optimized NPHM expressions fit to audio-video recordings of people talking. To the best of our knowledge, this is the first work to propose a generative approach for realistic and high-quality motion synthesis of volumetric human heads, representing a significant advancement in the field of audio-driven 3D animation. Notably, our approach stands out in its ability to generate plausible motion sequences that can produce high-fidelity head animation coupled with the NPHM shape space. Our experimental results substantiate the effectiveness of FaceTalk, consistently achieving superior and visually natural motion, encompassing diverse facial expressions and styles, outperforming existing methods by 75% in perceptual user study evaluation. ",
    "url": "https://arxiv.org/abs/2312.08459",
    "authors": [
      "Shivangi Aneja",
      "Justus Thies",
      "Angela Dai",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.08461",
    "title": "Space-Time Approximation with Shallow Neural Networks in Fourier  Lebesgue spaces",
    "abstract": "Approximation capabilities of shallow neural networks (SNNs) form an integral part in understanding the properties of deep neural networks (DNNs). In the study of these approximation capabilities some very popular classes of target functions are the so-called spectral Barron spaces. This spaces are of special interest when it comes to the approximation of partial differential equation (PDE) solutions. It has been shown that the solution of certain static PDEs will lie in some spectral Barron space. In order to alleviate the limitation to static PDEs and include a time-domain that might have a different regularity than the space domain, we extend the notion of spectral Barron spaces to anisotropic weighted Fourier-Lebesgue spaces. In doing so, we consider target functions that have two blocks of variables, among which each block is allowed to have different decay and integrability properties. For these target functions we first study the inclusion of anisotropic weighted Fourier-Lebesgue spaces in the Bochner-Sobolev spaces. With that we can now also measure the approximation error in terms of an anisotropic Sobolev norm, namely the Bochner-Sobolev norm. We use this observation in a second step where we establish a bound on the approximation rate for functions from the anisotropic weighted Fourier-Lebesgue spaces and approximation via SNNs in the Bochner-Sobolev norm. ",
    "url": "https://arxiv.org/abs/2312.08461",
    "authors": [
      "Ahmed Abdeljawad",
      "Thomas Dittrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.08511",
    "title": "The Relative Value of Prediction in Algorithmic Decision Making",
    "abstract": "Algorithmic predictions are increasingly used to inform the allocations of goods and interventions in the public sphere. In these domains, predictions serve as a means to an end. They provide stakeholders with insights into likelihood of future events as a means to improve decision making quality, and enhance social welfare. However, if maximizing welfare is the ultimate goal, prediction is only a small piece of the puzzle. There are various other policy levers a social planner might pursue in order to improve bottom-line outcomes, such as expanding access to available goods, or increasing the effect sizes of interventions. Given this broad range of design decisions, a basic question to ask is: What is the relative value of prediction in algorithmic decision making? How do the improvements in welfare arising from better predictions compare to those of other policy levers? The goal of our work is to initiate the formal study of these questions. Our main results are theoretical in nature. We identify simple, sharp conditions determining the relative value of prediction vis-\\`a-vis expanding access, within several statistical models that are popular amongst quantitative social scientists. Furthermore, we illustrate how these theoretical insights may be used to guide the design of algorithmic decision making systems in practice. ",
    "url": "https://arxiv.org/abs/2312.08511",
    "authors": [
      "Juan Carlos Perdomo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.08515",
    "title": "Simplicial Representation Learning with Neural $k$-forms",
    "abstract": "Geometric deep learning extends deep learning to incorporate information about the geometry and topology data, especially in complex domains like graphs. Despite the popularity of message passing in this field, it has limitations such as the need for graph rewiring, ambiguity in interpreting data, and over-smoothing. In this paper, we take a different approach, focusing on leveraging geometric information from simplicial complexes embedded in $\\mathbb{R}^n$ using node coordinates. We use differential k-forms in \\mathbb{R}^n to create representations of simplices, offering interpretability and geometric consistency without message passing. This approach also enables us to apply differential geometry tools and achieve universal approximation. Our method is efficient, versatile, and applicable to various input complexes, including graphs, simplicial complexes, and cell complexes. It outperforms existing message passing neural networks in harnessing information from geometrical graphs with node features serving as coordinates. ",
    "url": "https://arxiv.org/abs/2312.08515",
    "authors": [
      "Kelly Maggs",
      "Celia Hacker",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2312.08535",
    "title": "Occupancy Detection Based on Electricity Consumption",
    "abstract": "This article presents a new methodology for extracting intervals when a home is vacant from low-frequency electricity consumption data. The approach combines multiple algorithms, including change point detection, classification, period detection, and periodic spikes retrieval. It shows encouraging results on both simulated and real consumption curves. This approach offers practical insights for optimizing energy use and holds potential benefits for residential consumers and utility companies in terms of energy cost reduction and sustainability. Further research is needed to enhance its applicability in diverse settings and with larger datasets. ",
    "url": "https://arxiv.org/abs/2312.08535",
    "authors": [
      "Thomas Brilland",
      "Guillaume Matheron",
      "Laetitia Leduc",
      "Yukihide Nakada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.08539",
    "title": "On Searching for Minimal Integer Representation of Undirected Graphs",
    "abstract": "Minimal and efficient graph representations are key to store, communicate, and sample the search space of graphs and networks while meeting user-defined criteria. In this paper, we investigate the feasibility of gradient-free optimization heuristics based on Differential Evolution to search for minimal integer representations of undirected graphs. The class of Differential Evolution algorithms are population-based gradient-free optimization heuristics having found a relevant attention in the nonconvex and nonlinear optimization communities. Our computational experiments using eight classes of Differential Evolution schemes and graph instances with varying degrees of sparsity have shown the merit of attaining minimal numbers for graph encoding/representation rendered by exploration-oriented strategies within few function evaluations. Our results have the potential to elucidate new number-based encoding and sample-based algorithms for graph representation, network design and optimization. ",
    "url": "https://arxiv.org/abs/2312.08539",
    "authors": [
      "Victor Parque",
      "Tomoyuki Miyashita"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2312.08543",
    "title": "Unveiling Diversity: Empowering OSS Project Leaders with Community  Diversity and Turnover Dashboards",
    "abstract": "Managing open-source software (OSS) projects requires managing communities of contributors. In particular, it is essential for project leaders to understand their community's diversity and turnover. We present CommunityTapestry, a dynamic real-time community dashboard, which presents key diversity and turnover signals that we identified from the literature and through participatory design sessions with stakeholders. We evaluated CommunityTapestry with an OSS project's contributors and Project Management Committee members, who explored the dashboard using their own project data. Our study results demonstrate that CommunityTapestry increased participants' awareness of their community composition and the diversity and turnover rates in the project. It helped them identify areas of improvement and gave them actionable information. ",
    "url": "https://arxiv.org/abs/2312.08543",
    "authors": [
      "Mariam Guizani",
      "Zixuan Feng",
      "Emily Judith Arteaga",
      "Luis Ca\u00f1as-D\u00edaz",
      "Alexander Serebrenik",
      "Anita Sarma"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.08550",
    "title": "Harmonics of Learning: Universal Fourier Features Emerge in Invariant  Networks",
    "abstract": "In this work, we formally prove that, under certain conditions, if a neural network is invariant to a finite group then its weights recover the Fourier transform on that group. This provides a mathematical explanation for the emergence of Fourier features -- a ubiquitous phenomenon in both biological and artificial learning systems. The results hold even for non-commutative groups, in which case the Fourier transform encodes all the irreducible unitary group representations. Our findings have consequences for the problem of symmetry discovery. Specifically, we demonstrate that the algebraic structure of an unknown group can be recovered from the weights of a network that is at least approximately invariant within certain bounds. Overall, this work contributes to a foundation for an algebraic learning theory of invariant neural network representations. ",
    "url": "https://arxiv.org/abs/2312.08550",
    "authors": [
      "Giovanni Luca Marchetti",
      "Christopher Hillar",
      "Danica Kragic",
      "Sophia Sanborn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.08558",
    "title": "G-MEMP: Gaze-Enhanced Multimodal Ego-Motion Prediction in Driving",
    "abstract": "Understanding the decision-making process of drivers is one of the keys to ensuring road safety. While the driver intent and the resulting ego-motion trajectory are valuable in developing driver-assistance systems, existing methods mostly focus on the motions of other vehicles. In contrast, we focus on inferring the ego trajectory of a driver's vehicle using their gaze data. For this purpose, we first collect a new dataset, GEM, which contains high-fidelity ego-motion videos paired with drivers' eye-tracking data and GPS coordinates. Next, we develop G-MEMP, a novel multimodal ego-trajectory prediction network that combines GPS and video input with gaze data. We also propose a new metric called Path Complexity Index (PCI) to measure the trajectory complexity. We perform extensive evaluations of the proposed method on both GEM and DR(eye)VE, an existing benchmark dataset. The results show that G-MEMP significantly outperforms state-of-the-art methods in both benchmarks. Furthermore, ablation studies demonstrate over 20% improvement in average displacement using gaze data, particularly in challenging driving scenarios with a high PCI. The data, code, and models can be found at https://eth-ait.github.io/g-memp/. ",
    "url": "https://arxiv.org/abs/2312.08558",
    "authors": [
      "M. Eren Akbiyik",
      "Nedko Savov",
      "Danda Pani Paudel",
      "Nikola Popovic",
      "Christian Vater",
      "Otmar Hilliges",
      "Luc Van Gool",
      "Xi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08571",
    "title": "PhasePerturbation: Speech Data Augmentation via Phase Perturbation for  Automatic Speech Recognition",
    "abstract": "Most of the current speech data augmentation methods operate on either the raw waveform or the amplitude spectrum of speech. In this paper, we propose a novel speech data augmentation method called PhasePerturbation that operates dynamically on the phase spectrum of speech. Instead of statically rotating a phase by a constant degree, PhasePerturbation utilizes three dynamic phase spectrum operations, i.e., a randomization operation, a frequency masking operation, and a temporal masking operation, to enhance the diversity of speech data. We conduct experiments on wav2vec2.0 pre-trained ASR models by fine-tuning them with the PhasePerturbation augmented TIMIT corpus. The experimental results demonstrate 10.9\\% relative reduction in the word error rate (WER) compared with the baseline model fine-tuned without any augmentation operation. Furthermore, the proposed method achieves additional improvements (12.9\\% and 15.9\\%) in WER by complementing the Vocal Tract Length Perturbation (VTLP) and the SpecAug, which are both amplitude spectrum-based augmentation methods. The results highlight the capability of PhasePerturbation to improve the current amplitude spectrum-based augmentation methods. ",
    "url": "https://arxiv.org/abs/2312.08571",
    "authors": [
      "Chengxi Lei",
      "Satwinder Singh",
      "Feng Hou",
      "Xiaoyun Jia",
      "Ruili Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.08591",
    "title": "Joint2Human: High-quality 3D Human Generation via Compact Spherical  Embedding of 3D Joints",
    "abstract": "3D human generation is increasingly significant in various applications. However, the direct use of 2D generative methods in 3D generation often results in significant loss of local details, while methods that reconstruct geometry from generated images struggle with global view consistency. In this work, we introduce Joint2Human, a novel method that leverages 2D diffusion models to generate detailed 3D human geometry directly, ensuring both global structure and local details. To achieve this, we employ the Fourier occupancy field (FOF) representation, enabling the direct production of 3D shapes as preliminary results using 2D generative models. With the proposed high-frequency enhancer and the multi-view recarving strategy, our method can seamlessly integrate the details from different views into a uniform global shape.To better utilize the 3D human prior and enhance control over the generated geometry, we introduce a compact spherical embedding of 3D joints. This allows for effective application of pose guidance during the generation process. Additionally, our method is capable of generating 3D humans guided by textual inputs. Our experimental results demonstrate the capability of our method to ensure global structure, local details, high resolution, and low computational cost, simultaneously. More results and code can be found on our project page at this http URL ",
    "url": "https://arxiv.org/abs/2312.08591",
    "authors": [
      "Muxin Zhang",
      "Qiao Feng",
      "Zhuo Su",
      "Chao Wen",
      "Zhou Xue",
      "Kun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08604",
    "title": "Verification of Neural Reachable Tubes via Scenario Optimization and  Conformal Prediction",
    "abstract": "Learning-based approaches for controlling safety-critical systems are rapidly growing in popularity; thus, it is important to assure their performance and safety. Hamilton-Jacobi (HJ) reachability analysis is a popular formal verification tool for providing such guarantees, since it can handle general nonlinear system dynamics, bounded adversarial system disturbances, and state and input constraints. However, its computational and memory complexity scales exponentially with the state dimension, making it intractable for large-scale systems. To overcome this challenge, neural approaches, such as DeepReach, have been used to synthesize reachable tubes and safety controllers for high-dimensional systems. However, verifying these neural reachable tubes remains challenging. In this work, we propose two verification methods, based on robust scenario optimization and conformal prediction, to provide probabilistic safety guarantees for neural reachable tubes. Our methods allow a direct trade-off between resilience to outlier errors in the neural tube, which are inevitable in a learning-based approach, and the strength of the probabilistic safety guarantee. Furthermore, we show that split conformal prediction, a widely used method in the machine learning community for uncertainty quantification, reduces to a scenario-based approach, making the two methods equivalent not only for verification of neural reachable tubes but also more generally. To our knowledge, our proof is the first in the literature to show a strong relationship between conformal prediction and scenario optimization. Finally, we propose an outlier-adjusted verification approach that uses the error distribution in neural reachable tubes to recover greater safe volumes. We demonstrate the efficacy of the proposed approaches for the high-dimensional problems of multi-vehicle collision avoidance and rocket landing with no-go zones. ",
    "url": "https://arxiv.org/abs/2312.08604",
    "authors": [
      "Albert Lin",
      "Somil Bansal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.08616",
    "title": "A Generalized Neural Diffusion Framework on Graphs",
    "abstract": "Recent studies reveal the connection between GNNs and the diffusion process, which motivates many diffusion-based GNNs to be proposed. However, since these two mechanisms are closely related, one fundamental question naturally arises: Is there a general diffusion framework that can formally unify these GNNs? The answer to this question can not only deepen our understanding of the learning process of GNNs, but also may open a new door to design a broad new class of GNNs. In this paper, we propose a general diffusion equation framework with the fidelity term, which formally establishes the relationship between the diffusion process with more GNNs. Meanwhile, with this framework, we identify one characteristic of graph diffusion networks, i.e., the current neural diffusion process only corresponds to the first-order diffusion equation. However, by an experimental investigation, we show that the labels of high-order neighbors actually exhibit monophily property, which induces the similarity based on labels among high-order neighbors without requiring the similarity among first-order neighbors. This discovery motives to design a new high-order neighbor-aware diffusion equation, and derive a new type of graph diffusion network (HiD-Net) based on the framework. With the high-order diffusion equation, HiD-Net is more robust against attacks and works on both homophily and heterophily graphs. We not only theoretically analyze the relation between HiD-Net with high-order random walk, but also provide a theoretical convergence guarantee. Extensive experimental results well demonstrate the effectiveness of HiD-Net over state-of-the-art graph diffusion networks. ",
    "url": "https://arxiv.org/abs/2312.08616",
    "authors": [
      "Yibo Li",
      "Xiao Wang",
      "Hongrui Liu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08639",
    "title": "On the complexity of list $\\mathcal H$-packing for sparse graph classes",
    "abstract": "The problem of packing as many subgraphs isomorphic to $H \\in \\mathcal H$ as possible in a graph for a class $\\mathcal H$ of graphs is well studied in the literature. Both vertex-disjoint and edge-disjoint versions are known to be NP-complete for $H$ that contains at least three vertices and at least three edges, respectively. In this paper, we consider ``list variants'' of these problems: Given a graph $G$, an integer $k$, and a collection $\\mathcal L_{\\mathcal H}$ of subgraphs of $G$ isomorphic to some $H \\in \\mathcal H$, the goal is to compute $k$ subgraphs in $\\mathcal L_{\\mathcal H}$ that are pairwise vertex- or edge-disjoint. We show several positive and negative results, focusing on classes of sparse graphs, such as bounded-degree graphs, planar graphs, and bounded-treewidth graphs. ",
    "url": "https://arxiv.org/abs/2312.08639",
    "authors": [
      "Tatsuya Gima",
      "Tesshu Hanaka",
      "Yasuaki Kobayashi",
      "Yota Otachi",
      "Tomohito Shirai",
      "Akira Suzuki",
      "Yuma Tamura",
      "Xiao Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2312.08646",
    "title": "Guarding the Grid: Enhancing Resilience in Automated Residential Demand  Response Against False Data Injection Attacks",
    "abstract": "Utility companies are increasingly leveraging residential demand flexibility and the proliferation of smart/IoT devices to enhance the effectiveness of residential demand response (DR) programs through automated device scheduling. However, the adoption of distributed architectures in these systems exposes them to the risk of false data injection attacks (FDIAs), where adversaries can manipulate decision-making processes by injecting false data. Given the limited control utility companies have over these distributed systems and data, the need for reliable implementations to enhance the resilience of residential DR schemes against FDIAs is paramount. In this work, we present a comprehensive framework that combines DR optimisation, anomaly detection, and strategies for mitigating the impacts of attacks to create a resilient and automated device scheduling system. To validate the robustness of our framework against FDIAs, we performed an evaluation using real-world data sets, highlighting its effectiveness in securing residential DR systems. ",
    "url": "https://arxiv.org/abs/2312.08646",
    "authors": [
      "Thusitha Dayaratne",
      "Carsten Rudolph",
      "Ariel Liebman",
      "Mahsa Salehi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.08648",
    "title": "CLIP-guided Federated Learning on Heterogeneous and Long-Tailed Data",
    "abstract": "Federated learning (FL) provides a decentralized machine learning paradigm where a server collaborates with a group of clients to learn a global model without accessing the clients' data. User heterogeneity is a significant challenge for FL, which together with the class-distribution imbalance further enhances the difficulty of FL. Great progress has been made in large vision-language models, such as Contrastive Language-Image Pre-training (CLIP), which paves a new way for image classification and object recognition. Inspired by the success of CLIP on few-shot and zero-shot learning, we use CLIP to optimize the federated learning between server and client models under its vision-language supervision. It is promising to mitigate the user heterogeneity and class-distribution balance due to the powerful cross-modality representation and rich open-vocabulary prior knowledge. In this paper, we propose the CLIP-guided FL (CLIP2FL) method on heterogeneous and long-tailed data. In CLIP2FL, the knowledge of the off-the-shelf CLIP model is transferred to the client-server models, and a bridge is built between the client and server. Specifically, for client-side learning, knowledge distillation is conducted between client models and CLIP to improve the ability of client-side feature representation. For server-side learning, in order to mitigate the heterogeneity and class-distribution imbalance, we generate federated features to retrain the server model. A prototype contrastive learning with the supervision of the text encoder of CLIP is introduced to generate federated features depending on the client-side gradients, and they are used to retrain a balanced server classifier. ",
    "url": "https://arxiv.org/abs/2312.08648",
    "authors": [
      "Jiangming Shi",
      "Shanshan Zheng",
      "Xiangbo Yin",
      "Yang Lu",
      "Yuan Xie",
      "Yanyun Qu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08651",
    "title": "Towards Inductive Robustness: Distilling and Fostering Wave-induced  Resonance in Transductive GCNs Against Graph Adversarial Attacks",
    "abstract": "Graph neural networks (GNNs) have recently been shown to be vulnerable to adversarial attacks, where slight perturbations in the graph structure can lead to erroneous predictions. However, current robust models for defending against such attacks inherit the transductive limitations of graph convolutional networks (GCNs). As a result, they are constrained by fixed structures and do not naturally generalize to unseen nodes. Here, we discover that transductive GCNs inherently possess a distillable robustness, achieved through a wave-induced resonance process. Based on this, we foster this resonance to facilitate inductive and robust learning. Specifically, we first prove that the signal formed by GCN-driven message passing (MP) is equivalent to the edge-based Laplacian wave, where, within a wave system, resonance can naturally emerge between the signal and its transmitting medium. This resonance provides inherent resistance to malicious perturbations inflicted on the signal system. We then prove that merely three MP iterations within GCNs can induce signal resonance between nodes and edges, manifesting as a coupling between nodes and their distillable surrounding local subgraph. Consequently, we present Graph Resonance-fostering Network (GRN) to foster this resonance via learning node representations from their distilled resonating subgraphs. By capturing the edge-transmitted signals within this subgraph and integrating them with the node signal, GRN embeds these combined signals into the central node's representation. This node-wise embedding approach allows for generalization to unseen nodes. We validate our theoretical findings with experiments, and demonstrate that GRN generalizes robustness to unseen nodes, whilst maintaining state-of-the-art classification accuracy on perturbed graphs. ",
    "url": "https://arxiv.org/abs/2312.08651",
    "authors": [
      "Ao Liu",
      "Wenshan Li",
      "Tao Li",
      "Beibei Li",
      "Hanyuan Huang",
      "Pan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08653",
    "title": "A Simple Knowledge Distillation Framework for Open-world Object  Detection",
    "abstract": "Open World Object Detection (OWOD) is a novel computer vision task with a considerable challenge, bridging the gap between classic object detection (OD) benchmarks and real-world object detection. In addition to detecting and classifying seen/known objects, OWOD algorithms are expected to localize all potential unseen/unknown objects and incrementally learn them. The large pre-trained vision-language grounding models (VLM,eg, GLIP) have rich knowledge about the open world, but are limited by text prompts and cannot localize indescribable objects. However, there are many detection scenarios which pre-defined language descriptions are unavailable during inference. In this paper, we attempt to specialize the VLM model for OWOD task by distilling its open-world knowledge into a language-agnostic detector. Surprisingly, we observe that the combination of a simple knowledge distillation approach and the automatic pseudo-labeling mechanism in OWOD can achieve better performance for unknown object detection, even with a small amount of data. Unfortunately, knowledge distillation for unknown objects severely affects the learning of detectors with conventional structures for known objects, leading to catastrophic forgetting. To alleviate these problems, we propose the down-weight loss function for knowledge distillation from vision-language to single vision modality. Meanwhile, we decouple the learning of localization and recognition to reduce the impact of category interactions of known and unknown objects on the localization learning process. Comprehensive experiments performed on MS-COCO and PASCAL VOC demonstrate the effectiveness of our methods. ",
    "url": "https://arxiv.org/abs/2312.08653",
    "authors": [
      "Shuailei Ma",
      "Yuefeng Wang",
      "Ying Wei",
      "Jiaqi Fan",
      "Xinyu Sun",
      "Peihao Chen",
      "Enming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08654",
    "title": "Automated detection of Zika and dengue in Aedes aegypti using neural  spiking analysis",
    "abstract": "Mosquito-borne diseases present considerable risks to the health of both animals and humans. Aedes aegypti mosquitoes are the primary vectors for numerous medically important viruses such as dengue, Zika, yellow fever, and chikungunya. To characterize this mosquito neural activity, it is essential to classify the generated electrical spikes. However, no open-source neural spike classification method is currently available for mosquitoes. Our work presented in this paper provides an innovative artificial intelligence-based method to classify the neural spikes in uninfected, dengue-infected, and Zika-infected mosquitoes. Aiming for outstanding performance, the method employs a fusion of normalization, feature importance, and dimension reduction for the preprocessing and combines convolutional neural network and extra gradient boosting (XGBoost) for classification. The method uses the electrical spiking activity data of mosquito neurons recorded by microelectrode array technology. We used data from 0, 1, 2, 3, and 7 days post-infection, containing over 15 million samples, to analyze the method's performance. The performance of the proposed method was evaluated using accuracy, precision, recall, and the F1 scores. The results obtained from the method highlight its remarkable performance in differentiating infected vs uninfected mosquito samples, achieving an average of 98.1%. The performance was also compared with 6 other machine learning algorithms to further assess the method's capability. The method outperformed all other machine learning algorithms' performance. Overall, this research serves as an efficient method to classify the neural spikes of Aedes aegypti mosquitoes and can assist in unraveling the complex interactions between pathogens and mosquitoes. ",
    "url": "https://arxiv.org/abs/2312.08654",
    "authors": [
      "Danial Sharifrazi",
      "Nouman Javed",
      "Roohallah Alizadehsani",
      "Prasad N. Paradkar",
      "U. Rajendra Acharya",
      "Asim Bhatti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2312.08656",
    "title": "MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural  Networks Training",
    "abstract": "In the acceleration of deep neural network training, the GPU has become the mainstream platform. GPUs face substantial challenges on GNNs, such as workload imbalance and memory access irregularities, leading to underutilized hardware. Existing solutions such as PyG, DGL with cuSPARSE, and GNNAdvisor frameworks partially address these challenges but memory traffic is still significant. We argue that drastic performance improvements can only be achieved by the vertical optimization of algorithm and system innovations, rather than treating the speedup optimization as an \"after-thought\" (i.e., (i) given a GNN algorithm, designing an accelerator, or (ii) given hardware, mainly optimizing the GNN algorithm). In this paper, we present MaxK-GNN, an advanced high-performance GPU training system integrating algorithm and system innovation. (i) We introduce the MaxK nonlinearity and provide a theoretical analysis of MaxK nonlinearity as a universal approximator, and present the Compressed Balanced Sparse Row (CBSR) format, designed to store the data and index of the feature matrix after nonlinearity; (ii) We design a coalescing enhanced forward computation with row-wise product-based SpGEMM Kernel using CBSR for input feature matrix fetching and strategic placement of a sparse output accumulation buffer in shared memory; (iii) We develop an optimized backward computation with outer product-based and SSpMM Kernel. We conduct extensive evaluations of MaxK-GNN and report the end-to-end system run-time. Experiments show that MaxK-GNN system could approach the theoretical speedup limit according to Amdahl's law. We achieve comparable accuracy to SOTA GNNs, but at a significantly increased speed: 3.22/4.24 times speedup (vs. theoretical limits, 5.52/7.27 times) on Reddit compared to DGL and GNNAdvisor implementations. ",
    "url": "https://arxiv.org/abs/2312.08656",
    "authors": [
      "Hongwu Peng",
      "Xi Xie",
      "Kaustubh Shivdikar",
      "MD Amit Hasan",
      "Jiahui Zhao",
      "Shaoyi Huang",
      "Omer Khan",
      "David Kaeli",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.08659",
    "title": "On the Image-Based Detection of Tomato and Corn leaves Diseases : An  in-depth comparative experiments",
    "abstract": "The research introduces a novel plant disease detection model based on Convolutional Neural Networks (CNN) for plant image classification, marking a significant contribution to image categorization. The innovative training approach enables a streamlined and efficient system implementation. The model classifies two distinct plant diseases into four categories, presenting a novel technique for plant disease identification. In Experiment 1, Inception-V3, Dense-Net-121, ResNet-101-V2, and Xception models were employed for CNN training. The newly created plant disease image dataset includes 1963 tomato plant images and 7316 corn plant images from the PlantVillage dataset. Of these, 1374 tomato images and 5121 corn images were used for training, while 589 tomato images and 2195 corn images were used for testing/validation. Results indicate that the Xception model outperforms the other three models, yielding val_accuracy values of 95.08% and 92.21% for the tomato and corn datasets, with corresponding val_loss values of 0.3108 and 0.4204, respectively. In Experiment 2, CNN with Batch Normalization achieved disease detection rates of approximately 99.89% in the training set and val_accuracy values exceeding 97.52%, accompanied by a val_loss of 0.103. Experiment 3 employed a CNN architecture as the base model, introducing additional layers in Model 2, skip connections in Model 3, and regularizations in Model 4. Detailed experiment results and model efficiency are outlined in the paper's sub-section 1.5. Experiment 4 involved combining all corn and tomato images, utilizing various models, including MobileNet (val_accuracy=86.73%), EfficientNetB0 (val_accuracy=93.973%), Xception (val_accuracy=74.91%), InceptionResNetV2 (val_accuracy=31.03%), and CNN (59.79%). Additionally, our proposed model achieved a val_accuracy of 84.42%. ",
    "url": "https://arxiv.org/abs/2312.08659",
    "authors": [
      "Affan Yasin",
      "Rubia Fatima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08660",
    "title": "Low-rank constrained multichannel signal denoising considering  channel-dependent sensitivity inspired by self-supervised learning for  optical fiber sensing",
    "abstract": "Optical fiber sensing is a technology wherein audio, vibrations, and temperature are detected using an optical fiber; especially the audio/vibrations-aware sensing is called distributed acoustic sensing (DAS). In DAS, observed data, which is comprised of multichannel data, has suffered from severe noise levels because of the optical noise or the installation methods. In conventional methods for denoising DAS data, signal-processing- or deep-neural-network (DNN)-based models have been studied. The signal-processing-based methods have the interpretability, i.e., non-black box. The DNN-based methods are good at flexibility designing network architectures and objective functions, that is, priors. However, there is no balance between the interpretability and the flexibility of priors in the DAS studies. The DNN-based methods also require a large amount of training data in general. To address the problems, we propose a DNN-structure signal-processing-based denoising method in this paper. As the priors of DAS, we employ spatial knowledge; low rank and channel-dependent sensitivity using the DNN-based structure. The result of fiber-acoustic sensing shows that the proposed method outperforms the conventional methods and the robustness to the number of the spatial ranks. Moreover, the optimized parameters of the proposed method indicate the relationship with the channel sensitivity; the interpretability. ",
    "url": "https://arxiv.org/abs/2312.08660",
    "authors": [
      "Noriyuki Tonami",
      "Wataru Kohno",
      "Sakiko Mishima",
      "Yumi Arai",
      "Reishi Kondo",
      "Tomoyuki Hino"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.08667",
    "title": "Data and Model Poisoning Backdoor Attacks on Wireless Federated  Learning, and the Defense Mechanisms: A Comprehensive Survey",
    "abstract": "Due to the greatly improved capabilities of devices, massive data, and increasing concern about data privacy, Federated Learning (FL) has been increasingly considered for applications to wireless communication networks (WCNs). Wireless FL (WFL) is a distributed method of training a global deep learning model in which a large number of participants each train a local model on their training datasets and then upload the local model updates to a central server. However, in general, non-independent and identically distributed (non-IID) data of WCNs raises concerns about robustness, as a malicious participant could potentially inject a \"backdoor\" into the global model by uploading poisoned data or models over WCN. This could cause the model to misclassify malicious inputs as a specific target class while behaving normally with benign inputs. This survey provides a comprehensive review of the latest backdoor attacks and defense mechanisms. It classifies them according to their targets (data poisoning or model poisoning), the attack phase (local data collection, training, or aggregation), and defense stage (local training, before aggregation, during aggregation, or after aggregation). The strengths and limitations of existing attack strategies and defense mechanisms are analyzed in detail. Comparisons of existing attack methods and defense designs are carried out, pointing to noteworthy findings, open challenges, and potential future research directions related to security and privacy of WFL. ",
    "url": "https://arxiv.org/abs/2312.08667",
    "authors": [
      "Yichen Wan",
      "Youyang Qu",
      "Wei Ni",
      "Yong Xiang",
      "Longxiang Gao",
      "Ekram Hossain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08671",
    "title": "Uplifting the Expressive Power of Graph Neural Networks through Graph  Partitioning",
    "abstract": "Graph Neural Networks (GNNs) have paved its way for being a cornerstone in graph related learning tasks. From a theoretical perspective, the expressive power of GNNs is primarily characterised according to their ability to distinguish non-isomorphic graphs. It is a well-known fact that most of the conventional GNNs are upper-bounded by Weisfeiler-Lehman graph isomorphism test (1-WL). In this work, we study the expressive power of graph neural networks through the lens of graph partitioning. This follows from our observation that permutation invariant graph partitioning enables a powerful way of exploring structural interactions among vertex sets and subgraphs, and can help uplifting the expressive power of GNNs efficiently. Based on this, we first establish a theoretical connection between graph partitioning and graph isomorphism. Then we introduce a novel GNN architecture, namely Graph Partitioning Neural Networks (GPNNs). We theoretically analyse how a graph partitioning scheme and different kinds of structural interactions relate to the k-WL hierarchy. Empirically, we demonstrate its superior performance over existing GNN models in a variety of graph benchmark tasks. ",
    "url": "https://arxiv.org/abs/2312.08671",
    "authors": [
      "Asela Hevapathige",
      "Qing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08672",
    "title": "CAT: A Causally Graph Attention Network for Trimming Heterophilic Graph",
    "abstract": "Local Attention-guided Message Passing Mechanism (LAMP) adopted in Graph Attention Networks (GATs) is designed to adaptively learn the importance of neighboring nodes for better local aggregation on the graph, which can bring the representations of similar neighbors closer effectively, thus showing stronger discrimination ability. However, existing GATs suffer from a significant discrimination ability decline in heterophilic graphs because the high proportion of dissimilar neighbors can weaken the self-attention of the central node, jointly resulting in the deviation of the central node from similar nodes in the representation space. This kind of effect generated by neighboring nodes is called the Distraction Effect (DE) in this paper. To estimate and weaken the DE of neighboring nodes, we propose a Causally graph Attention network for Trimming heterophilic graph (CAT). To estimate the DE, since the DE are generated through two paths (grab the attention assigned to neighbors and reduce the self-attention of the central node), we use Total Effect to model DE, which is a kind of causal estimand and can be estimated from intervened data; To weaken the DE, we identify the neighbors with the highest DE (we call them Distraction Neighbors) and remove them. We adopt three representative GATs as the base model within the proposed CAT framework and conduct experiments on seven heterophilic datasets in three different sizes. Comparative experiments show that CAT can improve the node classification accuracy of all base GAT models. Ablation experiments and visualization further validate the enhancement of discrimination ability brought by CAT. The source code is available at https://github.com/GeoX-Lab/CAT. ",
    "url": "https://arxiv.org/abs/2312.08672",
    "authors": [
      "Silu He",
      "Qinyao Luo",
      "Xinsha Fu",
      "Ling Zhao",
      "Ronghua Du",
      "Haifeng Lia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.08675",
    "title": "AVA: Inconspicuous Attribute Variation-based Adversarial Attack  bypassing DeepFake Detection",
    "abstract": "While DeepFake applications are becoming popular in recent years, their abuses pose a serious privacy threat. Unfortunately, most related detection algorithms to mitigate the abuse issues are inherently vulnerable to adversarial attacks because they are built atop DNN-based classification models, and the literature has demonstrated that they could be bypassed by introducing pixel-level perturbations. Though corresponding mitigation has been proposed, we have identified a new attribute-variation-based adversarial attack (AVA) that perturbs the latent space via a combination of Gaussian prior and semantic discriminator to bypass such mitigation. It perturbs the semantics in the attribute space of DeepFake images, which are inconspicuous to human beings (e.g., mouth open) but can result in substantial differences in DeepFake detection. We evaluate our proposed AVA attack on nine state-of-the-art DeepFake detection algorithms and applications. The empirical results demonstrate that AVA attack defeats the state-of-the-art black box attacks against DeepFake detectors and achieves more than a 95% success rate on two commercial DeepFake detectors. Moreover, our human study indicates that AVA-generated DeepFake images are often imperceptible to humans, which presents huge security and privacy concerns. ",
    "url": "https://arxiv.org/abs/2312.08675",
    "authors": [
      "Xiangtao Meng",
      "Li Wang",
      "Shanqing Guo",
      "Lei Ju",
      "Qingchuan Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.08676",
    "title": "SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross  Attention",
    "abstract": "Zero-shot voice conversion (VC) aims to transfer the source speaker timbre to arbitrary unseen target speaker timbre, while keeping the linguistic content unchanged. Although the voice of generated speech can be controlled by providing the speaker embedding of the target speaker, the speaker similarity still lags behind the ground truth recordings. In this paper, we propose SEF-VC, a speaker embedding free voice conversion model, which is designed to learn and incorporate speaker timbre from reference speech via a powerful position-agnostic cross-attention mechanism, and then reconstruct waveform from HuBERT semantic tokens in a non-autoregressive manner. The concise design of SEF-VC enhances its training stability and voice conversion performance. Objective and subjective evaluations demonstrate the superiority of SEF-VC to generate high-quality speech with better similarity to target reference than strong zero-shot VC baselines, even for very short reference speeches. ",
    "url": "https://arxiv.org/abs/2312.08676",
    "authors": [
      "Junjie Li",
      "Yiwei Guo",
      "Xie Chen",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.08680",
    "title": "Heterogeneous Graph Neural Architecture Search with GPT-4",
    "abstract": "Heterogeneous graph neural architecture search (HGNAS) represents a powerful tool for automatically designing effective heterogeneous graph neural networks. However, existing HGNAS algorithms suffer from inefficient searches and unstable results. In this paper, we present a new GPT-4 based HGNAS model to improve the search efficiency and search accuracy of HGNAS. Specifically, we present a new GPT-4 enhanced Heterogeneous Graph Neural Architecture Search (GHGNAS for short). The basic idea of GHGNAS is to design a set of prompts that can guide GPT-4 toward the task of generating new heterogeneous graph neural architectures. By iteratively asking GPT-4 with the prompts, GHGNAS continually validates the accuracy of the generated HGNNs and uses the feedback to further optimize the prompts. Experimental results show that GHGNAS can design new HGNNs by leveraging the powerful generalization capability of GPT-4. Moreover, GHGNAS runs more effectively and stably than previous HGNAS models based on reinforcement learning and differentiable search algorithms. ",
    "url": "https://arxiv.org/abs/2312.08680",
    "authors": [
      "Haoyuan Dong",
      "Yang Gao",
      "Haishuai Wang",
      "Hong Yang",
      "Peng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08685",
    "title": "Privacy Amplification by Iteration for ADMM with (Strongly) Convex  Objective Functions",
    "abstract": "We examine a private ADMM variant for (strongly) convex objectives which is a primal-dual iterative method. Each iteration has a user with a private function used to update the primal variable, masked by Gaussian noise for local privacy, without directly adding noise to the dual variable. Privacy amplification by iteration explores if noises from later iterations can enhance the privacy guarantee when releasing final variables after the last iteration. Cyffers et al. [ICML 2023] explored privacy amplification by iteration for the proximal ADMM variant, where a user's entire private function is accessed and noise is added to the primal variable. In contrast, we examine a private ADMM variant requiring just one gradient access to a user's function, but both primal and dual variables must be passed between successive iterations. To apply Balle et al.'s [NeurIPS 2019] coupling framework to the gradient ADMM variant, we tackle technical challenges with novel ideas. First, we address the non-expansive mapping issue in ADMM iterations by using a customized norm. Second, because the dual variables are not masked with any noise directly, their privacy guarantees are achieved by treating two consecutive noisy ADMM iterations as a Markov operator. Our main result is that the privacy guarantee for the gradient ADMM variant can be amplified proportionally to the number of iterations. For strongly convex objective functions, this amplification exponentially increases with the number of iterations. These amplification results align with the previously studied special case of stochastic gradient descent. ",
    "url": "https://arxiv.org/abs/2312.08685",
    "authors": [
      "T-H. Hubert Chan",
      "Hao Xie",
      "Mengshi Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2312.08692",
    "title": "SpectralNeRF: Physically Based Spectral Rendering with Neural Radiance  Field",
    "abstract": "In this paper, we propose SpectralNeRF, an end-to-end Neural Radiance Field (NeRF)-based architecture for high-quality physically based rendering from a novel spectral perspective. We modify the classical spectral rendering into two main steps, 1) the generation of a series of spectrum maps spanning different wavelengths, 2) the combination of these spectrum maps for the RGB output. Our SpectralNeRF follows these two steps through the proposed multi-layer perceptron (MLP)-based architecture (SpectralMLP) and Spectrum Attention UNet (SAUNet). Given the ray origin and the ray direction, the SpectralMLP constructs the spectral radiance field to obtain spectrum maps of novel views, which are then sent to the SAUNet to produce RGB images of white-light illumination. Applying NeRF to build up the spectral rendering is a more physically-based way from the perspective of ray-tracing. Further, the spectral radiance fields decompose difficult scenes and improve the performance of NeRF-based methods. Comprehensive experimental results demonstrate the proposed SpectralNeRF is superior to recent NeRF-based methods when synthesizing new views on synthetic and real datasets. The codes and datasets are available at https://github.com/liru0126/SpectralNeRF. ",
    "url": "https://arxiv.org/abs/2312.08692",
    "authors": [
      "Ru Li",
      "Jia Liu",
      "Guanghui Liu",
      "Shengping Zhang",
      "Bing Zeng",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08701",
    "title": "Enabling End-to-End Secure Federated Learning in Biomedical Research on  Heterogeneous Computing Environments with APPFLx",
    "abstract": "Facilitating large-scale, cross-institutional collaboration in biomedical machine learning projects requires a trustworthy and resilient federated learning (FL) environment to ensure that sensitive information such as protected health information is kept confidential. In this work, we introduce APPFLx, a low-code FL framework that enables the easy setup, configuration, and running of FL experiments across organizational and administrative boundaries while providing secure end-to-end communication, privacy-preserving functionality, and identity management. APPFLx is completely agnostic to the underlying computational infrastructure of participating clients. We demonstrate the capability of APPFLx as an easy-to-use framework for accelerating biomedical studies across institutions and healthcare systems while maintaining the protection of private medical data in two case studies: (1) predicting participant age from electrocardiogram (ECG) waveforms, and (2) detecting COVID-19 disease from chest radiographs. These experiments were performed securely across heterogeneous compute resources, including a mixture of on-premise high-performance computing and cloud computing, and highlight the role of federated learning in improving model generalizability and performance when aggregating data from multiple healthcare systems. Finally, we demonstrate that APPFLx serves as a convenient and easy-to-use framework for accelerating biomedical studies across institutions and healthcare system while maintaining the protection of private medical data. ",
    "url": "https://arxiv.org/abs/2312.08701",
    "authors": [
      "Trung-Hieu Hoang",
      "Jordan Fuhrman",
      "Ravi Madduri",
      "Miao Li",
      "Pranshu Chaturvedi",
      "Zilinghan Li",
      "Kibaek Kim",
      "Minseok Ryu",
      "Ryan Chard",
      "E. A. Huerta",
      "Maryellen Giger"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.08704",
    "title": "PairingNet: A Learning-based Pair-searching and -matching Network for  Image Fragments",
    "abstract": "In this paper, we propose a learning-based image fragment pair-searching and -matching approach to solve the challenging restoration problem. Existing works use rule-based methods to match similar contour shapes or textures, which are always difficult to tune hyperparameters for extensive data and computationally time-consuming. Therefore, we propose a neural network that can effectively utilize neighbor textures with contour shape information to fundamentally improve performance. First, we employ a graph-based network to extract the local contour and texture features of fragments. Then, for the pair-searching task, we adopt a linear transformer-based module to integrate these local features and use contrastive loss to encode the global features of each fragment. For the pair-matching task, we design a weighted fusion module to dynamically fuse extracted local contour and texture features, and formulate a similarity matrix for each pair of fragments to calculate the matching score and infer the adjacent segment of contours. To faithfully evaluate our proposed network, we created a new image fragment dataset through an algorithm we designed that tears complete images into irregular fragments. The experimental results show that our proposed network achieves excellent pair-searching accuracy, reduces matching errors, and significantly reduces computational time. Details, sourcecode, and data are available in our supplementary material. ",
    "url": "https://arxiv.org/abs/2312.08704",
    "authors": [
      "Rixin Zhou",
      "Ding Xia",
      "Yi Zhang",
      "Honglin Pang",
      "Xi Yang",
      "Chuntao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2312.08727",
    "title": "Calibration-compatible Listwise Distillation of Privileged Features for  CTR Prediction",
    "abstract": "In machine learning systems, privileged features refer to the features that are available during offline training but inaccessible for online serving. Previous studies have recognized the importance of privileged features and explored ways to tackle online-offline discrepancies. A typical practice is privileged features distillation (PFD): train a teacher model using all features (including privileged ones) and then distill the knowledge from the teacher model using a student model (excluding the privileged features), which is then employed for online serving. In practice, the pointwise cross-entropy loss is often adopted for PFD. However, this loss is insufficient to distill the ranking ability for CTR prediction. First, it does not consider the non-i.i.d. characteristic of the data distribution, i.e., other items on the same page significantly impact the click probability of the candidate item. Second, it fails to consider the relative item order ranked by the teacher model's predictions, which is essential to distill the ranking ability. To address these issues, we first extend the pointwise-based PFD to the listwise-based PFD. We then define the calibration-compatible property of distillation loss and show that commonly used listwise losses do not satisfy this property when employed as distillation loss, thus compromising the model's calibration ability, which is another important measure for CTR prediction. To tackle this dilemma, we propose Calibration-compatible LIstwise Distillation (CLID), which employs carefully-designed listwise distillation loss to achieve better ranking ability than the pointwise-based PFD while preserving the model's calibration ability. We theoretically prove it is calibration-compatible. Extensive experiments on public datasets and a production dataset collected from the display advertising system of Alibaba further demonstrate the effectiveness of CLID. ",
    "url": "https://arxiv.org/abs/2312.08727",
    "authors": [
      "Xiaoqiang Gui",
      "Yueyao Cheng",
      "Xiang-Rong Sheng",
      "Yunfeng Zhao",
      "Guoxian Yu",
      "Shuguang Han",
      "Yuning Jiang",
      "Jian Xu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.08730",
    "title": "Towards Robust and Expressive Whole-body Human Pose and Shape Estimation",
    "abstract": "Whole-body pose and shape estimation aims to jointly predict different behaviors (e.g., pose, hand gesture, facial expression) of the entire human body from a monocular image. Existing methods often exhibit degraded performance under the complexity of in-the-wild scenarios. We argue that the accuracy and reliability of these models are significantly affected by the quality of the predicted \\textit{bounding box}, e.g., the scale and alignment of body parts. The natural discrepancy between the ideal bounding box annotations and model detection results is particularly detrimental to the performance of whole-body pose and shape estimation. In this paper, we propose a novel framework to enhance the robustness of whole-body pose and shape estimation. Our framework incorporates three new modules to address the above challenges from three perspectives: \\textbf{1) Localization Module} enhances the model's awareness of the subject's location and semantics within the image space. \\textbf{2) Contrastive Feature Extraction Module} encourages the model to be invariant to robust augmentations by incorporating contrastive loss with dedicated positive samples. \\textbf{3) Pixel Alignment Module} ensures the reprojected mesh from the predicted camera and body model parameters are accurate and pixel-aligned. We perform comprehensive experiments to demonstrate the effectiveness of our proposed framework on body, hands, face and whole-body benchmarks. Codebase is available at \\url{https://github.com/robosmplx/robosmplx}. ",
    "url": "https://arxiv.org/abs/2312.08730",
    "authors": [
      "Hui EnPang",
      "Zhongang Cai",
      "Lei Yang",
      "Qingyi Tao",
      "Zhonghua Wu",
      "Tianwei Zhang",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08737",
    "title": "JPIS: A Joint Model for Profile-based Intent Detection and Slot Filling  with Slot-to-Intent Attention",
    "abstract": "Profile-based intent detection and slot filling are important tasks aimed at reducing the ambiguity in user utterances by leveraging user-specific supporting profile information. However, research in these two tasks has not been extensively explored. To fill this gap, we propose a joint model, namely JPIS, designed to enhance profile-based intent detection and slot filling. JPIS incorporates the supporting profile information into its encoder and introduces a slot-to-intent attention mechanism to transfer slot information representations to intent detection. Experimental results show that our JPIS substantially outperforms previous profile-based models, establishing a new state-of-the-art performance in overall accuracy on the Chinese benchmark dataset ProSLU. ",
    "url": "https://arxiv.org/abs/2312.08737",
    "authors": [
      "Thinh Pham",
      "Dat Quoc Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.08747",
    "title": "Dissecting vocabulary biases datasets through statistical testing and  automated data augmentation for artifact mitigation in Natural Language  Inference",
    "abstract": "In recent years, the availability of large-scale annotated datasets, such as the Stanford Natural Language Inference and the Multi-Genre Natural Language Inference, coupled with the advent of pre-trained language models, has significantly contributed to the development of the natural language inference domain. However, these crowdsourced annotated datasets often contain biases or dataset artifacts, leading to overestimated model performance and poor generalization. In this work, we focus on investigating dataset artifacts and developing strategies to address these issues. Through the utilization of a novel statistical testing procedure, we discover a significant association between vocabulary distribution and text entailment classes, emphasizing vocabulary as a notable source of biases. To mitigate these issues, we propose several automatic data augmentation strategies spanning character to word levels. By fine-tuning the ELECTRA pre-trained language model, we compare the performance of boosted models with augmented data against their baseline counterparts. The experiments demonstrate that the proposed approaches effectively enhance model accuracy and reduce biases by up to 0.66% and 1.14%, respectively. ",
    "url": "https://arxiv.org/abs/2312.08747",
    "authors": [
      "Dat Thanh Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.08751",
    "title": "Improve Robustness of Reinforcement Learning against Observation  Perturbations via $l_\\infty$ Lipschitz Policy Networks",
    "abstract": "Deep Reinforcement Learning (DRL) has achieved remarkable advances in sequential decision tasks. However, recent works have revealed that DRL agents are susceptible to slight perturbations in observations. This vulnerability raises concerns regarding the effectiveness and robustness of deploying such agents in real-world applications. In this work, we propose a novel robust reinforcement learning method called SortRL, which improves the robustness of DRL policies against observation perturbations from the perspective of the network architecture. We employ a novel architecture for the policy network that incorporates global $l_\\infty$ Lipschitz continuity and provide a convenient method to enhance policy robustness based on the output margin. Besides, a training framework is designed for SortRL, which solves given tasks while maintaining robustness against $l_\\infty$ bounded perturbations on the observations. Several experiments are conducted to evaluate the effectiveness of our method, including classic control tasks and video games. The results demonstrate that SortRL achieves state-of-the-art robustness performance against different perturbation strength. ",
    "url": "https://arxiv.org/abs/2312.08751",
    "authors": [
      "Buqing Nie",
      "Jingtian Ji",
      "Yangqing Fu",
      "Yue Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08759",
    "title": "$\u03c7$-binding functions for squares of bipartite graphs and its  subclasses",
    "abstract": "A class of graphs $\\mathcal{G}$ is $\\chi$-bounded if there exists a function $f$ such that $\\chi(G) \\leq f(\\omega(G))$ for each graph $G \\in \\mathcal{G}$, where $\\chi(G)$ and $\\omega(G)$ are the chromatic and clique number of $G$, respectively. The square of a graph $G$, denoted as $G^2$, is the graph with the same vertex set as $G$ in which two vertices are adjacent when they are at a distance at most two in $G$. In this paper, we study the $\\chi$-boundedness of squares of bipartite graphs and its subclasses. Note that the class of squares of graphs, in general, admit a quadratic $\\chi$-binding function. Moreover there exist bipartite graphs $B$ for which $\\chi\\left(B^2\\right)$ is $\\Omega\\left(\\frac{\\left(\\omega\\left(B^2\\right)\\right)^2 }{\\log \\omega\\left(B^2\\right)}\\right)$. We first ask the following question: \"What sub-classes of bipartite graphs have a linear $\\chi$-binding function?\" We focus on the class of convex bipartite graphs and prove the following result: for any convex bipartite graph $G$, $\\chi\\left(G^2\\right) \\leq \\frac{3 \\omega\\left(G^2\\right)}{2}$. Our proof also yields a polynomial-time $3/2$-approximation algorithm for coloring squares of convex bipartite graphs. We then introduce a notion called \"partite testable properties\" for the squares of bipartite graphs. We say that a graph property $P$ is partite testable for the squares of bipartite graphs if for a bipartite graph $G=(A,B,E)$, whenever the induced subgraphs $G^2[A]$ and $G^2[B]$ satisfies the property $P$ then $G^2$ also satisfies the property $P$. Here, we discuss whether some of the well-known graph properties like perfectness, chordality, (anti-hole)-freeness, etc. are partite testable or not. As a consequence, we prove that the squares of biconvex bipartite graphs are perfect. ",
    "url": "https://arxiv.org/abs/2312.08759",
    "authors": [
      "Dibyayan Chakraborty",
      "L. Sunil Chandran",
      "Dalu Jacob",
      "Raji R. Pillai"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2312.08760",
    "title": "CF-NeRF: Camera Parameter Free Neural Radiance Fields with Incremental  Learning",
    "abstract": "Neural Radiance Fields (NeRF) have demonstrated impressive performance in novel view synthesis. However, NeRF and most of its variants still rely on traditional complex pipelines to provide extrinsic and intrinsic camera parameters, such as COLMAP. Recent works, like NeRFmm, BARF, and L2G-NeRF, directly treat camera parameters as learnable and estimate them through differential volume rendering. However, these methods work for forward-looking scenes with slight motions and fail to tackle the rotation scenario in practice. To overcome this limitation, we propose a novel \\underline{c}amera parameter \\underline{f}ree neural radiance field (CF-NeRF), which incrementally reconstructs 3D representations and recovers the camera parameters inspired by incremental structure from motion (SfM). Given a sequence of images, CF-NeRF estimates the camera parameters of images one by one and reconstructs the scene through initialization, implicit localization, and implicit optimization. To evaluate our method, we use a challenging real-world dataset NeRFBuster which provides 12 scenes under complex trajectories. Results demonstrate that CF-NeRF is robust to camera rotation and achieves state-of-the-art results without providing prior information and constraints. ",
    "url": "https://arxiv.org/abs/2312.08760",
    "authors": [
      "Qingsong Yan",
      "Qiang Wang",
      "Kaiyong Zhao",
      "Jie Chen",
      "Bo Li",
      "Xiaowen Chu",
      "Fei Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08786",
    "title": "Heterogenous Network Analytics of Small Group Teamwork: Using Multimodal  Data to Uncover Individual Behavioral Engagement Strategies",
    "abstract": "Individual behavioral engagement is an important indicator of active learning in collaborative settings, encompassing multidimensional behaviors mediated through various interaction modes. Little existing work has explored the use of multimodal process data to understand individual behavioral engagement in face-to-face collaborative learning settings. In this study we bridge this gap, for the first time, introducing a heterogeneous tripartite network approach to analyze the interconnections among multimodal process data in collaborative learning. Students' behavioral engagement strategies are analyzed based on their interaction patterns with various spatial locations and verbal communication types using a heterogeneous tripartite network. The multimodal collaborative learning process data were collected from 15 teams of four students. We conducted stochastic blockmodeling on a projection of the heterogeneous tripartite network to cluster students into groups that shared similar spatial and oral engagement patterns. We found two distinct clusters of students, whose characteristic behavioural engagement strategies were identified by extracting interaction patterns that were statistically significant relative to a multinomial null model. The two identified clusters also exhibited a statistically significant difference regarding students' perceived collaboration satisfaction and teacher-assessed team performance level. This study advances collaboration analytics methodology and provides new insights into personalized support in collaborative learning. ",
    "url": "https://arxiv.org/abs/2312.08786",
    "authors": [
      "Shihui Feng",
      "Lixiang Yan",
      "Linxuan Zhao",
      "Roberto Martinez Maldonado",
      "Dragan Ga\u0161evi\u0107"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.08810",
    "title": "Deep Learning-Based Cyber-Attack Detection Model for Smart Grids",
    "abstract": "In this paper, a novel artificial intelligence-based cyber-attack detection model for smart grids is developed to stop data integrity cyber-attacks (DIAs) on the received load data by supervisory control and data acquisition (SCADA). In the proposed model, first the load data is forecasted using a regression model and after processing stage, the processed data is clustered using the unsupervised learning method. In this work, in order to achieve the best performance, three load forecasting methods (i.e. extra tree regression (ETR), long short-term memory (LSTM) and bidirectional long short-term memory (BiLSTM)) are utilized as regression models and their performance is compared. For clustering and outlying detection, the covariance elliptic envelope (EE) is employed as an unsupervised learning method. To examine the proposed model, the hourly load data of the power company of the city of Johor in Malaysia is employed and Two common DIAs, which are DIAs targeting economic loss and DIAs targeting blackouts, are used to evaluate the accuracy of detection methods in several scenarios. The simulation results show that the proposed EE-BiLSTM method can perform more robust and accurate compared to the other two methods. ",
    "url": "https://arxiv.org/abs/2312.08810",
    "authors": [
      "Mojtaba Mohammadi",
      "Arshia Aflaki",
      "Abdollah Kavousifard",
      "Mohsen Gitizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.08825",
    "title": "Guided Diffusion from Self-Supervised Diffusion Features",
    "abstract": "Guidance serves as a key concept in diffusion models, yet its effectiveness is often limited by the need for extra data annotation or classifier pretraining. That is why guidance was harnessed from self-supervised learning backbones, like DINO. However, recent studies have revealed that the feature representation derived from diffusion model itself is discriminative for numerous downstream tasks as well, which prompts us to propose a framework to extract guidance from, and specifically for, diffusion models. Our research has yielded several significant contributions. Firstly, the guidance signals from diffusion models are on par with those from class-conditioned diffusion models. Secondly, feature regularization, when based on the Sinkhorn-Knopp algorithm, can further enhance feature discriminability in comparison to unconditional diffusion models. Thirdly, we have constructed an online training approach that can concurrently derive guidance from diffusion models for diffusion models. Lastly, we have extended the application of diffusion models along the constant velocity path of ODE to achieve a more favorable balance between sampling steps and fidelity. The performance of our methods has been outstanding, outperforming related baseline comparisons in large-resolution datasets, such as ImageNet256, ImageNet256-100 and LSUN-Churches. Our code will be released. ",
    "url": "https://arxiv.org/abs/2312.08825",
    "authors": [
      "Vincent Tao Hu",
      "Yunlu Chen",
      "Mathilde Caron",
      "Yuki M. Asano",
      "Cees G. M. Snoek",
      "Bjorn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08839",
    "title": "Exploration of visual prompt in Grounded pre-trained open-set detection",
    "abstract": "Text prompts are crucial for generalizing pre-trained open-set object detection models to new categories. However, current methods for text prompts are limited as they require manual feedback when generalizing to new categories, which restricts their ability to model complex scenes, often leading to incorrect detection results. To address this limitation, we propose a novel visual prompt method that learns new category knowledge from a few labeled images, which generalizes the pre-trained detection model to the new category. To allow visual prompts to represent new categories adequately, we propose a statistical-based prompt construction module that is not limited by predefined vocabulary lengths, thus allowing more vectors to be used when representing categories. We further utilize the category dictionaries in the pre-training dataset to design task-specific similarity dictionaries, which make visual prompts more discriminative. We evaluate the method on the ODinW dataset and show that it outperforms existing prompt learning methods and performs more consistently in combinatorial inference. ",
    "url": "https://arxiv.org/abs/2312.08839",
    "authors": [
      "Qibo Chen",
      "Weizhong Jin",
      "Shuchang Li",
      "Mengdi Liu",
      "Li Yu",
      "Jian Jiang",
      "Xiaozheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08847",
    "title": "Knowledge-Driven Modulation of Neural Networks with Attention Mechanism  for Next Activity Prediction",
    "abstract": "Predictive Process Monitoring (PPM) aims at leveraging historic process execution data to predict how ongoing executions will continue up to their completion. In recent years, PPM techniques for the prediction of the next activities have matured significantly, mainly thanks to the use of Neural Networks (NNs) as a predictor. While their performance is difficult to beat in the general case, there are specific situations where background process knowledge can be helpful. Such knowledge can be leveraged for improving the quality of predictions for exceptional process executions or when the process changes due to a concept drift. In this paper, we present a Symbolic[Neuro] system that leverages background knowledge expressed in terms of a procedural process model to offset the under-sampling in the training data. More specifically, we make predictions using NNs with attention mechanism, an emerging technology in the NN field. The system has been tested on several real-life logs showing an improvement in the performance of the prediction task. ",
    "url": "https://arxiv.org/abs/2312.08847",
    "authors": [
      "Ivan Donadello",
      "Jonghyeon Ko",
      "Fabrizio Maria Maggi",
      "Jan Mendling",
      "Francesco Riva",
      "Matthias Weidlich"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.08851",
    "title": "Achelous++: Power-Oriented Water-Surface Panoptic Perception Framework  on Edge Devices based on Vision-Radar Fusion and Pruning of Heterogeneous  Modalities",
    "abstract": "Urban water-surface robust perception serves as the foundation for intelligent monitoring of aquatic environments and the autonomous navigation and operation of unmanned vessels, especially in the context of waterway safety. It is worth noting that current multi-sensor fusion and multi-task learning models consume substantial power and heavily rely on high-power GPUs for inference. This contributes to increased carbon emissions, a concern that runs counter to the prevailing emphasis on environmental preservation and the pursuit of sustainable, low-carbon urban environments. In light of these concerns, this paper concentrates on low-power, lightweight, multi-task panoptic perception through the fusion of visual and 4D radar data, which is seen as a promising low-cost perception method. We propose a framework named Achelous++ that facilitates the development and comprehensive evaluation of multi-task water-surface panoptic perception models. Achelous++ can simultaneously execute five perception tasks with high speed and low power consumption, including object detection, object semantic segmentation, drivable-area segmentation, waterline segmentation, and radar point cloud semantic segmentation. Furthermore, to meet the demand for developers to customize models for real-time inference on low-performance devices, a novel multi-modal pruning strategy known as Heterogeneous-Aware SynFlow (HA-SynFlow) is proposed. Besides, Achelous++ also supports random pruning at initialization with different layer-wise sparsity, such as Uniform and Erdos-Renyi-Kernel (ERK). Overall, our Achelous++ framework achieves state-of-the-art performance on the WaterScenes benchmark, excelling in both accuracy and power efficiency compared to other single-task and multi-task models. We release and maintain the code at https://github.com/GuanRunwei/Achelous. ",
    "url": "https://arxiv.org/abs/2312.08851",
    "authors": [
      "Runwei Guan",
      "Haocheng Zhao",
      "Shanliang Yao",
      "Ka Lok Man",
      "Xiaohui Zhu",
      "Limin Yu",
      "Yong Yue",
      "Jeremy Smith",
      "Eng Gee Lim",
      "Weiping Ding",
      "Yutao Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.08852",
    "title": "ERASE: Error-Resilient Representation Learning on Graphs for Label Noise  Tolerance",
    "abstract": "Deep learning has achieved remarkable success in graph-related tasks, yet this accomplishment heavily relies on large-scale high-quality annotated datasets. However, acquiring such datasets can be cost-prohibitive, leading to the practical use of labels obtained from economically efficient sources such as web searches and user tags. Unfortunately, these labels often come with noise, compromising the generalization performance of deep networks. To tackle this challenge and enhance the robustness of deep learning models against label noise in graph-based tasks, we propose a method called ERASE (Error-Resilient representation learning on graphs for lAbel noiSe tolerancE). The core idea of ERASE is to learn representations with error tolerance by maximizing coding rate reduction. Particularly, we introduce a decoupled label propagation method for learning representations. Before training, noisy labels are pre-corrected through structural denoising. During training, ERASE combines prototype pseudo-labels with propagated denoised labels and updates representations with error resilience, which significantly improves the generalization performance in node classification. The proposed method allows us to more effectively withstand errors caused by mislabeled nodes, thereby strengthening the robustness of deep networks in handling noisy graph data. Extensive experimental results show that our method can outperform multiple baselines with clear margins in broad noise levels and enjoy great scalability. Codes are released at https://github.com/eraseai/erase. ",
    "url": "https://arxiv.org/abs/2312.08852",
    "authors": [
      "Ling-Hao Chen",
      "Yuanshuo Zhang",
      "Taohua Huang",
      "Liangcai Su",
      "Zeyi Lin",
      "Xi Xiao",
      "Xiaobo Xia",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08859",
    "title": "BVI-Artefact: An Artefact Detection Benchmark Dataset for Streamed  Videos",
    "abstract": "Professionally generated content (PGC) streamed online can contain visual artefacts that degrade the quality of user experience. These artefacts arise from different stages of the streaming pipeline, including acquisition, post-production, compression, and transmission. To better guide streaming experience enhancement, it is important to detect specific artefacts at the user end in the absence of a pristine reference. In this work, we address the lack of a comprehensive benchmark for artefact detection within streamed PGC, via the creation and validation of a large database, BVI-Artefact. Considering the ten most relevant artefact types encountered in video streaming, we collected and generated 480 video sequences, each containing various artefacts with associated binary artefact labels. Based on this new database, existing artefact detection methods are benchmarked, with results showing the challenging nature of this tasks and indicating the requirement of more reliable artefact detection methods. To facilitate further research in this area, we have made BVI-Artifact publicly available at https://chenfeng-bristol.github.io/BVI-Artefact/ ",
    "url": "https://arxiv.org/abs/2312.08859",
    "authors": [
      "Chen Feng",
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08871",
    "title": "VoxelKP: A Voxel-based Network Architecture for Human Keypoint  Estimation in LiDAR Data",
    "abstract": "We present \\textit{VoxelKP}, a novel fully sparse network architecture tailored for human keypoint estimation in LiDAR data. The key challenge is that objects are distributed sparsely in 3D space, while human keypoint detection requires detailed local information wherever humans are present. We propose four novel ideas in this paper. First, we propose sparse selective kernels to capture multi-scale context. Second, we introduce sparse box-attention to focus on learning spatial correlations between keypoints within each human instance. Third, we incorporate a spatial encoding to leverage absolute 3D coordinates when projecting 3D voxels to a 2D grid encoding a bird's eye view. Finally, we propose hybrid feature learning to combine the processing of per-voxel features with sparse convolution. We evaluate our method on the Waymo dataset and achieve an improvement of $27\\%$ on the MPJPE metric compared to the state-of-the-art, \\textit{HUM3DIL}, trained on the same data, and $12\\%$ against the state-of-the-art, \\textit{GC-KPL}, pretrained on a $25\\times$ larger dataset. To the best of our knowledge, \\textit{VoxelKP} is the first single-staged, fully sparse network that is specifically designed for addressing the challenging task of 3D keypoint estimation from LiDAR data, achieving state-of-the-art performances. Our code is available at \\url{https://github.com/shijianjian/VoxelKP}. ",
    "url": "https://arxiv.org/abs/2312.08871",
    "authors": [
      "Jian Shi",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08876",
    "title": "OpenSight: A Simple Open-Vocabulary Framework for LiDAR-Based Object  Detection",
    "abstract": "Traditional LiDAR-based object detection research primarily focuses on closed-set scenarios, which falls short in complex real-world applications. Directly transferring existing 2D open-vocabulary models with some known LiDAR classes for open-vocabulary ability, however, tends to suffer from over-fitting problems: The obtained model will detect the known objects, even presented with a novel category. In this paper, we propose OpenSight, a more advanced 2D-3D modeling framework for LiDAR-based open-vocabulary detection. OpenSight utilizes 2D-3D geometric priors for the initial discernment and localization of generic objects, followed by a more specific semantic interpretation of the detected objects. The process begins by generating 2D boxes for generic objects from the accompanying camera images of LiDAR. These 2D boxes, together with LiDAR points, are then lifted back into the LiDAR space to estimate corresponding 3D boxes. For better generic object perception, our framework integrates both temporal and spatial-aware constraints. Temporal awareness correlates the predicted 3D boxes across consecutive timestamps, recalibrating the missed or inaccurate boxes. The spatial awareness randomly places some ``precisely'' estimated 3D boxes at varying distances, increasing the visibility of generic objects. To interpret the specific semantics of detected objects, we develop a cross-modal alignment and fusion module to first align 3D features with 2D image embeddings and then fuse the aligned 3D-2D features for semantic decoding. Our experiments indicate that our method establishes state-of-the-art open-vocabulary performance on widely used 3D detection benchmarks and effectively identifies objects for new categories of interest. ",
    "url": "https://arxiv.org/abs/2312.08876",
    "authors": [
      "Hu Zhang",
      "Jianhua Xu",
      "Tao Tang",
      "Haiyang Sun",
      "Xin Yu",
      "Zi Huang",
      "Kaicheng Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08877",
    "title": "May the Noise be with you: Adversarial Training without Adversarial  Examples",
    "abstract": "In this paper, we investigate the following question: Can we obtain adversarially-trained models without training on adversarial examples? Our intuition is that training a model with inherent stochasticity, i.e., optimizing the parameters by minimizing a stochastic loss function, yields a robust expectation function that is non-stochastic. In contrast to related methods that introduce noise at the input level, our proposed approach incorporates inherent stochasticity by embedding Gaussian noise within the layers of the NN model at training time. We model the propagation of noise through the layers, introducing a closed-form stochastic loss function that encapsulates a noise variance parameter. Additionally, we contribute a formalized noise-aware gradient, enabling the optimization of model parameters while accounting for stochasticity. Our experimental results confirm that the expectation model of a stochastic architecture trained on benign distribution is adversarially robust. Interestingly, we find that the impact of the applied Gaussian noise's standard deviation on both robustness and baseline accuracy closely mirrors the impact of the noise magnitude employed in adversarial training. Our work contributes adversarially trained networks using a completely different approach, with empirically similar robustness to adversarial training. ",
    "url": "https://arxiv.org/abs/2312.08877",
    "authors": [
      "Ayoub Arous",
      "Andres F Lopez-Lopera",
      "Nael Abu-Ghazaleh",
      "Ihsen Alouani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08878",
    "title": "Domain Prompt Learning with Quaternion Networks",
    "abstract": "Prompt learning has emerged as an effective and data-efficient technique in large Vision-Language Models (VLMs). However, when adapting VLMs to specialized domains such as remote sensing and medical imaging, domain prompt learning remains underexplored. While large-scale domain-specific foundation models can help tackle this challenge, their concentration on a single vision level makes it challenging to prompt both vision and language modalities. To overcome this, we propose to leverage domain-specific knowledge from domain-specific foundation models to transfer the robust recognition ability of VLMs from generalized to specialized domains, using quaternion networks. Specifically, the proposed method involves using domain-specific vision features from domain-specific foundation models to guide the transformation of generalized contextual embeddings from the language branch into a specialized space within the quaternion networks. Moreover, we present a hierarchical approach that generates vision prompt features by analyzing intermodal relationships between hierarchical language prompt features and domain-specific vision features. In this way, quaternion networks can effectively mine the intermodal relationships in the specific domain, facilitating domain-specific vision-language contrastive learning. Extensive experiments on domain-specific datasets show that our proposed method achieves new state-of-the-art results in prompt learning. ",
    "url": "https://arxiv.org/abs/2312.08878",
    "authors": [
      "Qinglong Cao",
      "Zhengqin Xu",
      "Yuntian Chen",
      "Chao Ma",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2312.08879",
    "title": "Regularizing Self-supervised 3D Scene Flows with Surface Awareness and  Cyclic Consistency",
    "abstract": "Learning without supervision how to predict 3D scene flows from point clouds is central to many vision systems. We propose a novel learning framework for this task which improves the necessary regularization. Relying on the assumption that scene elements are mostly rigid, current smoothness losses are built on the definition of ``rigid clusters\" in the input point clouds. The definition of these clusters is challenging and has a major impact on the quality of predicted flows. We introduce two new consistency losses that enlarge clusters while preventing them from spreading over distinct objects. In particular, we enforce \\emph{temporal} consistency with a forward-backward cyclic loss and \\emph{spatial} consistency by considering surface orientation similarity in addition to spatial proximity. The proposed losses are model-independent and can thus be used in a plug-and-play fashion to significantly improve the performance of existing models, as demonstrated on two top-performing ones. We also showcase the effectiveness and generalization capability of our framework on four standard sensor-unique driving datasets, achieving state-of-the-art performance in 3D scene flow estimation. Our codes are available anonymously on \\url{https://github.com/vacany/sac-flow}. ",
    "url": "https://arxiv.org/abs/2312.08879",
    "authors": [
      "Patrik Vacek",
      "David Hurych",
      "Karel Zimmermann",
      "Patrick Perez",
      "Tomas Svoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08880",
    "title": "GenDet: Towards Good Generalizations for AI-Generated Image Detection",
    "abstract": "The misuse of AI imagery can have harmful societal effects, prompting the creation of detectors to combat issues like the spread of fake news. Existing methods can effectively detect images generated by seen generators, but it is challenging to detect those generated by unseen generators. They do not concentrate on amplifying the output discrepancy when detectors process real versus fake images. This results in a close output distribution of real and fake samples, increasing classification difficulty in detecting unseen generators. This paper addresses the unseen-generator detection problem by considering this task from the perspective of anomaly detection and proposes an adversarial teacher-student discrepancy-aware framework. Our method encourages smaller output discrepancies between the student and the teacher models for real images while aiming for larger discrepancies for fake images. We employ adversarial learning to train a feature augmenter, which promotes smaller discrepancies between teacher and student networks when the inputs are fake images. Our method has achieved state-of-the-art on public benchmarks, and the visualization results show that a large output discrepancy is maintained when faced with various types of generators. ",
    "url": "https://arxiv.org/abs/2312.08880",
    "authors": [
      "Mingjian Zhu",
      "Hanting Chen",
      "Mouxiao Huang",
      "Wei Li",
      "Hailin Hu",
      "Jie Hu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08882",
    "title": "Neural Video Fields Editing",
    "abstract": "Diffusion models have revolutionized text-driven video editing. However, applying these methods to real-world editing encounters two significant challenges: (1) the rapid increase in graphics memory demand as the number of frames grows, and (2) the inter-frame inconsistency in edited videos. To this end, we propose NVEdit, a novel text-driven video editing framework designed to mitigate memory overhead and improve consistent editing for real-world long videos. Specifically, we construct a neural video field, powered by tri-plane and sparse grid, to enable encoding long videos with hundreds of frames in a memory-efficient manner. Next, we update the video field through off-the-shelf Text-to-Image (T2I) models to impart text-driven editing effects. A progressive optimization strategy is developed to preserve original temporal priors. Importantly, both the neural video field and T2I model are adaptable and replaceable, thus inspiring future research. Experiments demonstrate that our approach successfully edits hundreds of frames with impressive inter-frame consistency. ",
    "url": "https://arxiv.org/abs/2312.08882",
    "authors": [
      "Shuzhou Yang",
      "Chong Mou",
      "Jiwen Yu",
      "Yuhan Wang",
      "Xiandong Meng",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08890",
    "title": "Defenses in Adversarial Machine Learning: A Survey",
    "abstract": "Adversarial phenomenon has been widely observed in machine learning (ML) systems, especially in those using deep neural networks, describing that ML systems may produce inconsistent and incomprehensible predictions with humans at some particular cases. This phenomenon poses a serious security threat to the practical application of ML systems, and several advanced attack paradigms have been developed to explore it, mainly including backdoor attacks, weight attacks, and adversarial examples. For each individual attack paradigm, various defense paradigms have been developed to improve the model robustness against the corresponding attack paradigm. However, due to the independence and diversity of these defense paradigms, it is difficult to examine the overall robustness of an ML system against different kinds of attacks.This survey aims to build a systematic review of all existing defense paradigms from a unified perspective. Specifically, from the life-cycle perspective, we factorize a complete machine learning system into five stages, including pre-training, training, post-training, deployment, and inference stages, respectively. Then, we present a clear taxonomy to categorize and review representative defense methods at each individual stage. The unified perspective and presented taxonomies not only facilitate the analysis of the mechanism of each defense paradigm but also help us to understand connections and differences among different defense paradigms, which may inspire future research to develop more advanced, comprehensive defenses. ",
    "url": "https://arxiv.org/abs/2312.08890",
    "authors": [
      "Baoyuan Wu",
      "Shaokui Wei",
      "Mingli Zhu",
      "Meixi Zheng",
      "Zihao Zhu",
      "Mingda Zhang",
      "Hongrui Chen",
      "Danni Yuan",
      "Li Liu",
      "Qingshan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08894",
    "title": "HAROOD: Human Activity Classification and Out-of-Distribution Detection  with Short-Range FMCW Radar",
    "abstract": "We propose HAROOD as a short-range FMCW radar-based human activity classifier and out-of-distribution (OOD) detector. It aims to classify human sitting, standing, and walking activities and to detect any other moving or stationary object as OOD. We introduce a two-stage network. The first stage is trained with a novel loss function that includes intermediate reconstruction loss, intermediate contrastive loss, and triplet loss. The second stage uses the first stage's output as its input and is trained with cross-entropy loss. It creates a simple classifier that performs the activity classification. On our dataset collected by 60 GHz short-range FMCW radar, we achieve an average classification accuracy of 96.51%. Also, we achieve an average AUROC of 95.04% as an OOD detector. Additionally, our extensive evaluations demonstrate the superiority of HAROOD over the state-of-the-art OOD detection methods in terms of standard OOD detection metrics. ",
    "url": "https://arxiv.org/abs/2312.08894",
    "authors": [
      "Sabri Mustafa Kahya",
      "Muhammet Sami Yavuz",
      "Eckehard Steinbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.08898",
    "title": "Detection and Defense of Unlearnable Examples",
    "abstract": "Privacy preserving has become increasingly critical with the emergence of social media. Unlearnable examples have been proposed to avoid leaking personal information on the Internet by degrading generalization abilities of deep learning models. However, our study reveals that unlearnable examples are easily detectable. We provide theoretical results on linear separability of certain unlearnable poisoned dataset and simple network based detection methods that can identify all existing unlearnable examples, as demonstrated by extensive experiments. Detectability of unlearnable examples with simple networks motivates us to design a novel defense method. We propose using stronger data augmentations coupled with adversarial noises generated by simple networks, to degrade the detectability and thus provide effective defense against unlearnable examples with a lower cost. Adversarial training with large budgets is a widely-used defense method on unlearnable examples. We establish quantitative criteria between the poison and adversarial budgets which determine the existence of robust unlearnable examples or the failure of the adversarial defense. ",
    "url": "https://arxiv.org/abs/2312.08898",
    "authors": [
      "Yifan Zhu",
      "Lijia Yu",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.08912",
    "title": "Dataset Distillation via Adversarial Prediction Matching",
    "abstract": "Dataset distillation is the technique of synthesizing smaller condensed datasets from large original datasets while retaining necessary information to persist the effect. In this paper, we approach the dataset distillation problem from a novel perspective: we regard minimizing the prediction discrepancy on the real data distribution between models, which are respectively trained on the large original dataset and on the small distilled dataset, as a conduit for condensing information from the raw data into the distilled version. An adversarial framework is proposed to solve the problem efficiently. In contrast to existing distillation methods involving nested optimization or long-range gradient unrolling, our approach hinges on single-level optimization. This ensures the memory efficiency of our method and provides a flexible tradeoff between time and memory budgets, allowing us to distil ImageNet-1K using a minimum of only 6.5GB of GPU memory. Under the optimal tradeoff strategy, it requires only 2.5$\\times$ less memory and 5$\\times$ less runtime compared to the state-of-the-art. Empirically, our method can produce synthetic datasets just 10% the size of the original, yet achieve, on average, 94% of the test accuracy of models trained on the full original datasets including ImageNet-1K, significantly surpassing state-of-the-art. Additionally, extensive tests reveal that our distilled datasets excel in cross-architecture generalization capabilities. ",
    "url": "https://arxiv.org/abs/2312.08912",
    "authors": [
      "Mingyang Chen",
      "Bo Huang",
      "Junda Lu",
      "Bing Li",
      "Yi Wang",
      "Minhao Cheng",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08926",
    "title": "Modeling Complex Mathematical Reasoning via Large Language Model based  MathAgent",
    "abstract": "Large language models (LLMs) face challenges in solving complex mathematical problems that require comprehensive capacities to parse the statements, associate domain knowledge, perform compound logical reasoning, and integrate the intermediate rationales. Tackling all these problems once could be arduous for LLMs, thus leading to confusion in generation. In this work, we explore the potential of enhancing LLMs with agents by meticulous decomposition and modeling of mathematical reasoning process. Specifically, we propose a formal description of the mathematical solving and extend LLMs with an agent-based zero-shot framework named $\\bf{P}$lanner-$\\bf{R}$easoner-$\\bf{E}$xecutor-$\\bf{R}$eflector (PRER). We further provide and implement two MathAgents that define the logical forms and inherent relations via a pool of actions in different grains and orientations: MathAgent-M adapts its actions to LLMs, while MathAgent-H aligns with humankind. Experiments on miniF2F and MATH have demonstrated the effectiveness of PRER and proposed MathAgents, achieving an increase of $12.3\\%$($53.9\\%\\xrightarrow{}66.2\\%$) on the MiniF2F, $9.2\\%$ ($49.8\\%\\xrightarrow{}59.0\\%$) on MATH, and $13.2\\%$($23.2\\%\\xrightarrow{}35.4\\%$) for level-5 problems of MATH against GPT-4. Further analytical results provide more insightful perspectives on exploiting the behaviors of LLMs as agents. ",
    "url": "https://arxiv.org/abs/2312.08926",
    "authors": [
      "Haoran Liao",
      "Qinyi Du",
      "Shaohua Hu",
      "Hao He",
      "Yanyan Xu",
      "Jidong Tian",
      "Yaohui Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.08939",
    "title": "EAT: Towards Long-Tailed Out-of-Distribution Detection",
    "abstract": "Despite recent advancements in out-of-distribution (OOD) detection, most current studies assume a class-balanced in-distribution training dataset, which is rarely the case in real-world scenarios. This paper addresses the challenging task of long-tailed OOD detection, where the in-distribution data follows a long-tailed class distribution. The main difficulty lies in distinguishing OOD data from samples belonging to the tail classes, as the ability of a classifier to detect OOD instances is not strongly correlated with its accuracy on the in-distribution classes. To overcome this issue, we propose two simple ideas: (1) Expanding the in-distribution class space by introducing multiple abstention classes. This approach allows us to build a detector with clear decision boundaries by training on OOD data using virtual labels. (2) Augmenting the context-limited tail classes by overlaying images onto the context-rich OOD data. This technique encourages the model to pay more attention to the discriminative features of the tail classes. We provide a clue for separating in-distribution and OOD data by analyzing gradient noise. Through extensive experiments, we demonstrate that our method outperforms the current state-of-the-art on various benchmark datasets. Moreover, our method can be used as an add-on for existing long-tail learning approaches, significantly enhancing their OOD detection performance. Code is available at: https://github.com/Stomach-ache/Long-Tailed-OOD-Detection . ",
    "url": "https://arxiv.org/abs/2312.08939",
    "authors": [
      "Tong Wei",
      "Bo-Lin Wang",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08948",
    "title": "LSTM Network Analysis of Vehicle-Type Fatalities on Great Britain's  Roads",
    "abstract": "This study harnesses the predictive capabilities of Long Short-Term Memory (LSTM) networks to analyse and predict road traffic accidents in Great Britain. It addresses the challenge of traffic accident forecasting, which is paramount for devising effective preventive measures. We utilised an extensive dataset encompassing reported collisions, casualties, and vehicles involvements from 1926 to 2022, provided by the Department for Transport (DfT). The data underwent stringent processing to rectify missing values and normalise features, ensuring robust LSTM network input. ",
    "url": "https://arxiv.org/abs/2312.08948",
    "authors": [
      "Abiodun Finbarrs Oketunji",
      "James Hanify",
      "Salter Heffron-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.08950",
    "title": "Detecting Active Attacks in Over-the-Air Computation using Dummy Samples",
    "abstract": "Over-the-Air (OtA) computation is a newly emerged concept for computing functions of data from distributed nodes by taking advantage of the wave superposition property of wireless channels. Despite its advantage in communication efficiency, OtA computation is associated with significant security and privacy concerns that have so far not been thoroughly investigated, especially in the case of active attacks. In this paper, we propose and evaluate a detection scheme against active attacks in OtA computation systems. More explicitly, we consider an active attacker which is an external node sending random or misleading data to alter the aggregated data received by the server. To detect the presence of the attacker, in every communication period, legitimate users send some dummy samples in addition to the real data. We propose a detector design that relies on the existence of a shared secret only known by the legitimate users and the server, that can be used to hide the transmitted signal in a secret subspace. After the server projects the received vector back to the original subspace, the dummy samples can be used to detect active attacks. We show that this design achieves good detection performance for a small cost in terms of channel resources. ",
    "url": "https://arxiv.org/abs/2312.08950",
    "authors": [
      "David Nordlund",
      "Zheng Chen",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.08951",
    "title": "Multi-Scene Generalized Trajectory Global Graph Solver with Composite  Nodes for Multiple Object Tracking",
    "abstract": "The global multi-object tracking (MOT) system can consider interaction, occlusion, and other ``visual blur'' scenarios to ensure effective object tracking in long videos. Among them, graph-based tracking-by-detection paradigms achieve surprising performance. However, their fully-connected nature poses storage space requirements that challenge algorithm handling long videos. Currently, commonly used methods are still generated trajectories by building one-forward associations across frames. Such matches produced under the guidance of first-order similarity information may not be optimal from a longer-time perspective. Moreover, they often lack an end-to-end scheme for correcting mismatches. This paper proposes the Composite Node Message Passing Network (CoNo-Link), a multi-scene generalized framework for modeling ultra-long frames information for association. CoNo-Link's solution is a low-storage overhead method for building constrained connected graphs. In addition to the previous method of treating objects as nodes, the network innovatively treats object trajectories as nodes for information interaction, improving the graph neural network's feature representation capability. Specifically, we formulate the graph-building problem as a top-k selection task for some reliable objects or trajectories. Our model can learn better predictions on longer-time scales by adding composite nodes. As a result, our method outperforms the state-of-the-art in several commonly used datasets. ",
    "url": "https://arxiv.org/abs/2312.08951",
    "authors": [
      "Yan Gao",
      "Haojun Xu",
      "Nannan Wang",
      "Jie Li",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08968",
    "title": "Detecting value-expressive text posts in Russian social media",
    "abstract": "Basic values are concepts or beliefs which pertain to desirable end-states and transcend specific situations. Studying personal values in social media can illuminate how and why societal values evolve especially when the stimuli-based methods, such as surveys, are inefficient, for instance, in hard-to-reach populations. On the other hand, user-generated content is driven by the massive use of stereotyped, culturally defined speech constructions rather than authentic expressions of personal values. We aimed to find a model that can accurately detect value-expressive posts in Russian social media VKontakte. A training dataset of 5,035 posts was annotated by three experts, 304 crowd-workers and ChatGPT. Crowd-workers and experts showed only moderate agreement in categorizing posts. ChatGPT was more consistent but struggled with spam detection. We applied an ensemble of human- and AI-assisted annotation involving active learning approach, subsequently trained several LLMs and selected a model based on embeddings from pre-trained fine-tuned rubert-tiny2, and reached a high quality of value detection with F1 = 0.75 (F1-macro = 0.80). This model provides a crucial step to a study of values within and between Russian social media users. ",
    "url": "https://arxiv.org/abs/2312.08968",
    "authors": [
      "Maria Milkova",
      "Maksim Rudnev",
      "Lidia Okolskaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08976",
    "title": "Entity-Augmented Code Generation",
    "abstract": "The current state-of-the-art large language models (LLMs) are effective in generating high-quality text and encapsulating a broad spectrum of world knowledge. However, these models often hallucinate during generation and are not designed to utilize external information sources. To enable requests to the external knowledge bases, also called knowledge grounding, retrieval-augmented LLMs were introduced. For now, their applications have largely involved Open Domain Question Answering, Abstractive Question Answering, and such. In this paper, we broaden the scope of retrieval-augmented LLMs by venturing into a new task - code generation using external entities. For this task, we collect and publish a new dataset for project-level code generation, where the model should reuse functions defined in the project during generation. As we show, existing retrieval-augmented LLMs fail to assign relevance scores between similar entity names, and to mitigate it, they expand entity names with description context and append it to the input. In practice, due to the limited context size they can not accommodate the indefinitely large context of the whole project. To solve this issue, we propose a novel end-to-end trainable architecture with an scalable entity retriever injected directly into the LLM decoder. We demonstrate that our model can outperform common baselines in several scenarios, including project-level code generation, as well as Bash and SQL scripting. ",
    "url": "https://arxiv.org/abs/2312.08976",
    "authors": [
      "Anton Shapkin",
      "Denis Litvinov",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08979",
    "title": "Multi-CMGAN+/+: Leveraging Multi-Objective Speech Quality Metric  Prediction for Speech Enhancement",
    "abstract": "Neural network based approaches to speech enhancement have shown to be particularly powerful, being able to leverage a data-driven approach to result in a significant performance gain versus other approaches. Such approaches are reliant on artificially created labelled training data such that the neural model can be trained using intrusive loss functions which compare the output of the model with clean reference speech. Performance of such systems when enhancing real-world audio often suffers relative to their performance on simulated test data. In this work, a non-intrusive multi-metric prediction approach is introduced, wherein a model trained on artificial labelled data using inference of an adversarially trained metric prediction neural network. The proposed approach shows improved performance versus state-of-the-art systems on the recent CHiME-7 challenge \\ac{UDASE} task evaluation sets. ",
    "url": "https://arxiv.org/abs/2312.08979",
    "authors": [
      "George Close",
      "William Ravenscroft",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.08983",
    "title": "Interactive Humanoid: Online Full-Body Motion Reaction Synthesis with  Social Affordance Canonicalization and Forecasting",
    "abstract": "We focus on the human-humanoid interaction task optionally with an object. We propose a new task named online full-body motion reaction synthesis, which generates humanoid reactions based on the human actor's motions. The previous work only focuses on human interaction without objects and generates body reactions without hand. Besides, they also do not consider the task as an online setting, which means the inability to observe information beyond the current moment in practical situations. To support this task, we construct two datasets named HHI and CoChair and propose a unified method. Specifically, we propose to construct a social affordance representation. We first select a social affordance carrier and use SE(3)-Equivariant Neural Networks to learn the local frame for the carrier, then we canonicalize the social affordance. Besides, we propose a social affordance forecasting scheme to enable the reactor to predict based on the imagined future. Experiments demonstrate that our approach can effectively generate high-quality reactions on HHI and CoChair. Furthermore, we also validate our method on existing human interaction datasets Interhuman and Chi3D. ",
    "url": "https://arxiv.org/abs/2312.08983",
    "authors": [
      "Yunze Liu",
      "Changxi Chen",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08996",
    "title": "Decremental Matching in General Weighted Graphs",
    "abstract": "In this paper, we consider the problem of maintaining a $(1-\\varepsilon)$-approximate maximum weight matching in a dynamic graph $G$, while the adversary makes changes to the edges of the graph. In the fully dynamic setting, where both edge insertions and deletions are allowed, Gupta and Peng gave an algorithm for this problem with an update time of $\\tilde{O}_{\\varepsilon}(\\sqrt{m})$. We study a natural relaxation of this problem, namely the decremental model, where the adversary is only allowed to delete edges. For the cardinality version of this problem in general (possibly, non-bipartite) graphs, Assadi, Bernstein, and Dudeja gave a decremental algorithm with update time $O_{\\varepsilon}(\\text{poly}(\\log n))$. However, beating $\\tilde{O}_{\\varepsilon}(\\sqrt{m})$ update time remained an open problem for the \\emph{weighted} version in \\emph{general graphs}. In this paper, we bridge the gap between unweighted and weighted general graphs for the decremental setting. We give a $O_{\\varepsilon}(\\text{poly}(\\log n))$ update time algorithm that maintains a $(1-\\varepsilon)$-approximate maximum weight matching under adversarial deletions. Like the decremental algorithm of Assadi, Bernstein, and Dudeja, our algorithm is randomized, but works against an adaptive adversary. It also matches the time bound for the cardinality version upto dependencies on $\\varepsilon$ and a $\\log R$ factor, where $R$ is the ratio between the maximum and minimum edge weight in $G$. ",
    "url": "https://arxiv.org/abs/2312.08996",
    "authors": [
      "Aditi Dudeja"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2312.09000",
    "title": "ComOM at VLSP 2023: A Dual-Stage Framework with BERTology and Unified  Multi-Task Instruction Tuning Model for Vietnamese Comparative Opinion Mining",
    "abstract": "The ComOM shared task aims to extract comparative opinions from product reviews in Vietnamese language. There are two sub-tasks, including (1) Comparative Sentence Identification (CSI) and (2) Comparative Element Extraction (CEE). The first task is to identify whether the input is a comparative review, and the purpose of the second task is to extract the quintuplets mentioned in the comparative review. To address this task, our team proposes a two-stage system based on fine-tuning a BERTology model for the CSI task and unified multi-task instruction tuning for the CEE task. Besides, we apply the simple data augmentation technique to increase the size of the dataset for training our model in the second stage. Experimental results show that our approach outperforms the other competitors and has achieved the top score on the official private test. ",
    "url": "https://arxiv.org/abs/2312.09000",
    "authors": [
      "Dang Van Thin",
      "Duong Ngoc Hao",
      "Ngan Luu-Thuy Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.09007",
    "title": "LLMind: Orchestrating AI and IoT with LLMs for Complex Task Execution",
    "abstract": "In this article, we introduce LLMind, an innovative AI framework that utilizes large language models (LLMs) as a central orchestrator. The framework integrates LLMs with domain-specific AI modules, enabling IoT devices to collaborate effectively in executing complex tasks. The LLM performs planning and generates control scripts using a reliable and precise language-code transformation approach based on finite state machines (FSMs). The LLM engages in natural conversations with users, employing role-playing techniques to generate contextually appropriate responses. Additionally, users can interact easily with the AI agent via a user-friendly social media platform. The framework also incorporates semantic analysis and response optimization techniques to enhance speed and effectiveness. Ultimately, this framework is designed not only to innovate IoT device control and enrich user experiences but also to foster an intelligent and integrated IoT device ecosystem that evolves and becomes more sophisticated through continuing user and machine interactions. ",
    "url": "https://arxiv.org/abs/2312.09007",
    "authors": [
      "Hongwei Cui",
      "Yuyang Du",
      "Qun Yang",
      "Yulin Shao",
      "Soung Chang Liew"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.09015",
    "title": "Uncertainty in GNN Learning Evaluations: A Comparison Between Measures  for Quantifying Randomness in GNN Community Detection",
    "abstract": "(1) The enhanced capability of Graph Neural Networks (GNNs) in unsupervised community detection of clustered nodes is attributed to their capacity to encode both the connectivity and feature information spaces of graphs. The identification of latent communities holds practical significance in various domains, from social networks to genomics. Current real-world performance benchmarks are perplexing due to the multitude of decisions influencing GNN evaluations for this task. (2) Three metrics are compared to assess the consistency of algorithm rankings in the presence of randomness. The consistency and quality of performance between the results under a hyperparameter optimisation with the default hyperparameters is evaluated. (3) The results compare hyperparameter optimisation with default hyperparameters, revealing a significant performance loss when neglecting hyperparameter investigation. A comparison of metrics indicates that ties in ranks can substantially alter the quantification of randomness. (4) Ensuring adherence to the same evaluation criteria may result in notable differences in the reported performance of methods for this task. The $W$ Randomness coefficient, based on the Wasserstein distance, is identified as providing the most robust assessment of randomness. ",
    "url": "https://arxiv.org/abs/2312.09015",
    "authors": [
      "William Leeney",
      "Ryan McConville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2312.09016",
    "title": "Symmetry Breaking and Equivariant Neural Networks",
    "abstract": "Using symmetry as an inductive bias in deep learning has been proven to be a principled approach for sample-efficient model design. However, the relationship between symmetry and the imperative for equivariance in neural networks is not always obvious. Here, we analyze a key limitation that arises in equivariant functions: their incapacity to break symmetry at the level of individual data samples. In response, we introduce a novel notion of 'relaxed equivariance' that circumvents this limitation. We further demonstrate how to incorporate this relaxation into equivariant multilayer perceptrons (E-MLPs), offering an alternative to the noise-injection method. The relevance of symmetry breaking is then discussed in various application domains: physics, graph representation learning, combinatorial optimization and equivariant decoding. ",
    "url": "https://arxiv.org/abs/2312.09016",
    "authors": [
      "S\u00e9kou-Oumar Kaba",
      "Siamak Ravanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.09023",
    "title": "A Framework for Exploring Federated Community Detection",
    "abstract": "Federated Learning is machine learning in the context of a network of clients whilst maintaining data residency and/or privacy constraints. Community detection is the unsupervised discovery of clusters of nodes within graph-structured data. The intersection of these two fields uncovers much opportunity, but also challenge. For example, it adds complexity due to missing connectivity information between privately held graphs. In this work, we explore the potential of federated community detection by conducting initial experiments across a range of existing datasets that showcase the gap in performance introduced by the distributed data. We demonstrate that isolated models would benefit from collaboration establishing a framework for investigating challenges within this domain. The intricacies of these research frontiers are discussed alongside proposed solutions to these issues. ",
    "url": "https://arxiv.org/abs/2312.09023",
    "authors": [
      "William Leeney",
      "Ryan McConville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2312.09025",
    "title": "On the Complexity of Simultaneous Geometric Embedding for Edge-Disjoint  Graphs",
    "abstract": "Simultaneous Geometric Embedding (SGE) asks whether, for a given collection of graphs on the same vertex set V, there is an embedding of V in the plane that admits a crossing-free drawing with straightline edges for each of the given graphs. It is known that SGE is $\\exists\\mathbb{R}$-complete, that is, the problem is polynomially equivalent to deciding whether a system of polynomial equations and inequalities with integer coefficients has a real solution. We prove that SGE remains $\\exists\\mathbb{R}$-complete for edge-disjoint input graphs, that is, for collections of graphs without so-called public edges. As an intermediate result, we prove that it is $\\exists\\mathbb{R}$-complete to decide whether a directional walk without repeating edges is realizable. Here, a directional walk consists of a sequence of not-necessarily distinct vertices (a walk) and a function prescribing for each inner position whether the walk shall turn left or shall turn right. A directional walk is realizable, if there is an embedding of its vertices in the plane such that the embedded walk turns according to the given directions. Previously it was known that realization is $\\exists\\mathbb{R}$-complete to decide for directional walks repeating each edge at most 336 times. This answers two questions posed by Schaefer [\"On the Complexity of Some Geometric Problems With Fixed Parameters\", JGAA 2021]. ",
    "url": "https://arxiv.org/abs/2312.09025",
    "authors": [
      "Benedikt K\u00fcnzel",
      "Jonathan Rollin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2312.09027",
    "title": "DRAM-Locker: A General-Purpose DRAM Protection Mechanism against  Adversarial DNN Weight Attacks",
    "abstract": "In this work, we propose DRAM-Locker as a robust general-purpose defense mechanism that can protect DRAM against various adversarial Deep Neural Network (DNN) weight attacks affecting data or page tables. DRAM-Locker harnesses the capabilities of in-DRAM swapping combined with a lock-table to prevent attackers from singling out specific DRAM rows to safeguard DNN's weight parameters. Our results indicate that DRAM-Locker can deliver a high level of protection downgrading the performance of targeted weight attacks to a random attack level. Furthermore, the proposed defense mechanism demonstrates no reduction in accuracy when applied to CIFAR-10 and CIFAR-100. Importantly, DRAM-Locker does not necessitate any software retraining or result in extra hardware burden. ",
    "url": "https://arxiv.org/abs/2312.09027",
    "authors": [
      "Ranyang Zhou",
      "Sabbir Ahmed",
      "Arman Roohi",
      "Adnan Siraj Rakin",
      "Shaahin Angizi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2312.09028",
    "title": "Design Space Exploration of Low-Bit Quantized Neural Networks for Visual  Place Recognition",
    "abstract": "Visual Place Recognition (VPR) is a critical task for performing global re-localization in visual perception systems. It requires the ability to accurately recognize a previously visited location under variations such as illumination, occlusion, appearance and viewpoint. In the case of robotic systems and augmented reality, the target devices for deployment are battery powered edge devices. Therefore whilst the accuracy of VPR methods is important so too is memory consumption and latency. Recently new works have focused on the recall@1 metric as a performance measure with limited focus on resource utilization. This has resulted in methods that use deep learning models too large to deploy on low powered edge devices. We hypothesize that these large models are highly over-parameterized and can be optimized to satisfy the constraints of a low powered embedded system whilst maintaining high recall performance. Our work studies the impact of compact convolutional network architecture design in combination with full-precision and mixed-precision post-training quantization on VPR performance. Importantly we not only measure performance via the recall@1 score but also measure memory consumption and latency. We characterize the design implications on memory, latency and recall scores and provide a number of design recommendations for VPR systems under these resource limitations. ",
    "url": "https://arxiv.org/abs/2312.09028",
    "authors": [
      "Oliver Grainge",
      "Michael Milford",
      "Indu Bodala",
      "Sarvapali D. Ramchurn",
      "Shoaib Ehsan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.09030",
    "title": "Dual Branch Network Towards Accurate Printed Mathematical Expression  Recognition",
    "abstract": "Over the past years, Printed Mathematical Expression Recognition (PMER) has progressed rapidly. However, due to the insufficient context information captured by Convolutional Neural Networks, some mathematical symbols might be incorrectly recognized or missed. To tackle this problem, in this paper, a Dual Branch transformer-based Network (DBN) is proposed to learn both local and global context information for accurate PMER. In our DBN, local and global features are extracted simultaneously, and a Context Coupling Module (CCM) is developed to complement the features between the global and local contexts. CCM adopts an interactive manner so that the coupled context clues are highly correlated to each expression symbol. Additionally, we design a Dynamic Soft Target (DST) strategy to utilize the similarities among symbol categories for reasonable label generation. Our experimental results have demonstrated that DBN can accurately recognize mathematical expressions and has achieved state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2312.09030",
    "authors": [
      "Yuqing Wang",
      "Zhenyu Weng",
      "Zhaokun Zhou",
      "Shuaijian Ji",
      "Zhongjie Ye",
      "Yuesheng Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.09040",
    "title": "STaR: Distilling Speech Temporal Relation for Lightweight Speech  Self-Supervised Learning Models",
    "abstract": "Albeit great performance of Transformer-based speech selfsupervised learning (SSL) models, their large parameter size and computational cost make them unfavorable to utilize. In this study, we propose to compress the speech SSL models by distilling speech temporal relation (STaR). Unlike previous works that directly match the representation for each speech frame, STaR distillation transfers temporal relation between speech frames, which is more suitable for lightweight student with limited capacity. We explore three STaR distillation objectives and select the best combination as the final STaR loss. Our model distilled from HuBERT BASE achieves an overall score of 79.8 on SUPERB benchmark, the best performance among models with up to 27 million parameters. We show that our method is applicable across different speech SSL models and maintains robust performance with further reduced parameters. ",
    "url": "https://arxiv.org/abs/2312.09040",
    "authors": [
      "Kangwook Jang",
      "Sungnyun Kim",
      "Hoirin Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.09041",
    "title": "Graph Neural Networks with Diverse Spectral Filtering",
    "abstract": "Spectral Graph Neural Networks (GNNs) have achieved tremendous success in graph machine learning, with polynomial filters applied for graph convolutions, where all nodes share the identical filter weights to mine their local contexts. Despite the success, existing spectral GNNs usually fail to deal with complex networks (e.g., WWW) due to such homogeneous spectral filtering setting that ignores the regional heterogeneity as typically seen in real-world networks. To tackle this issue, we propose a novel diverse spectral filtering (DSF) framework, which automatically learns node-specific filter weights to exploit the varying local structure properly. Particularly, the diverse filter weights consist of two components -- A global one shared among all nodes, and a local one that varies along network edges to reflect node difference arising from distinct graph parts -- to balance between local and global information. As such, not only can the global graph characteristics be captured, but also the diverse local patterns can be mined with awareness of different node positions. Interestingly, we formulate a novel optimization problem to assist in learning diverse filters, which also enables us to enhance any spectral GNNs with our DSF framework. We showcase the proposed framework on three state-of-the-arts including GPR-GNN, BernNet, and JacobiConv. Extensive experiments over 10 benchmark datasets demonstrate that our framework can consistently boost model performance by up to 4.92% in node classification tasks, producing diverse filters with enhanced interpretability. Code is available at \\url{https://github.com/jingweio/DSF}. ",
    "url": "https://arxiv.org/abs/2312.09041",
    "authors": [
      "Jingwei Guo",
      "Kaizhu Huang",
      "Xinping Yi",
      "Rui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.09048",
    "title": "On The Expressivity of Recurrent Neural Cascades",
    "abstract": "Recurrent Neural Cascades (RNCs) are the recurrent neural networks with no cyclic dependencies among recurrent neurons. This class of recurrent networks has received a lot of attention in practice. Besides training methods for a fixed architecture such as backpropagation, the cascade architecture naturally allows for constructive learning methods, where recurrent nodes are added incrementally one at a time, often yielding smaller networks. Furthermore, acyclicity amounts to a structural prior that even for the same number of neurons yields a more favourable sample complexity compared to a fully-connected architecture. A central question is whether the advantages of the cascade architecture come at the cost of a reduced expressivity. We provide new insights into this question. We show that the regular languages captured by RNCs with sign and tanh activation with positive recurrent weights are the star-free regular languages. In order to establish our results we developed a novel framework where capabilities of RNCs are accessed by analysing which semigroups and groups a single neuron is able to implement. A notable implication of our framework is that RNCs can achieve the expressivity of all regular languages by introducing neurons that can implement groups. ",
    "url": "https://arxiv.org/abs/2312.09048",
    "authors": [
      "Nadezda Alexandrovna Knorozova",
      "Alessandro Ronca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.09050",
    "title": "A Sparse Cross Attention-based Graph Convolution Network with Auxiliary  Information Awareness for Traffic Flow Prediction",
    "abstract": "Deep graph convolution networks (GCNs) have recently shown excellent performance in traffic prediction tasks. However, they face some challenges. First, few existing models consider the influence of auxiliary information, i.e., weather and holidays, which may result in a poor grasp of spatial-temporal dynamics of traffic data. Second, both the construction of a dynamic adjacent matrix and regular graph convolution operations have quadratic computation complexity, which restricts the scalability of GCN-based models. To address such challenges, this work proposes a deep encoder-decoder model entitled AIMSAN. It contains an auxiliary information-aware module (AIM) and sparse cross attention-based graph convolution network (SAN). The former learns multi-attribute auxiliary information and obtains its embedded presentation of different time-window sizes. The latter uses a cross-attention mechanism to construct dynamic adjacent matrices by fusing traffic data and embedded auxiliary data. Then, SAN applies diffusion GCN on traffic data to mine rich spatial-temporal dynamics. Furthermore, AIMSAN considers and uses the spatial sparseness of traffic nodes to reduce the quadratic computation complexity. Experimental results on three public traffic datasets demonstrate that the proposed method outperforms other counterparts in terms of various performance indices. Specifically, the proposed method has competitive performance with the state-of-the-art algorithms but saves 35.74% of GPU memory usage, 42.25% of training time, and 45.51% of validation time on average. ",
    "url": "https://arxiv.org/abs/2312.09050",
    "authors": [
      "Lingqiang Chen",
      "Qinglin Zhao",
      "Guanghui Li",
      "Mengchu Zhou",
      "Chenglong Dai",
      "Yiming Feng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.09056",
    "title": "ReCoRe: Regularized Contrastive Representation Learning of World Model",
    "abstract": "While recent model-free Reinforcement Learning (RL) methods have demonstrated human-level effectiveness in gaming environments, their success in everyday tasks like visual navigation has been limited, particularly under significant appearance variations. This limitation arises from (i) poor sample efficiency and (ii) over-fitting to training scenarios. To address these challenges, we present a world model that learns invariant features using (i) contrastive unsupervised learning and (ii) an intervention-invariant regularizer. Learning an explicit representation of the world dynamics i.e. a world model, improves sample efficiency while contrastive learning implicitly enforces learning of invariant features, which improves generalization. However, the naive integration of contrastive loss to world models fails due to a lack of supervisory signals to the visual encoder, as world-model-based RL methods independently optimize representation learning and agent policy. To overcome this issue, we propose an intervention-invariant regularizer in the form of an auxiliary task such as depth prediction, image denoising, etc., that explicitly enforces invariance to style-interventions. Our method outperforms current state-of-the-art model-based and model-free RL methods and significantly on out-of-distribution point navigation task evaluated on the iGibson benchmark. We further demonstrate that our approach, with only visual observations, outperforms recent language-guided foundation models for point navigation, which is essential for deployment on robots with limited computation capabilities. Finally, we demonstrate that our proposed model excels at the sim-to-real transfer of its perception module on Gibson benchmark. ",
    "url": "https://arxiv.org/abs/2312.09056",
    "authors": [
      "Rudra P.K. Poudel",
      "Harit Pandya",
      "Stephan Liwicki",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.09057",
    "title": "On the Difficulty of Defending Contrastive Learning against Backdoor  Attacks",
    "abstract": "Recent studies have shown that contrastive learning, like supervised learning, is highly vulnerable to backdoor attacks wherein malicious functions are injected into target models, only to be activated by specific triggers. However, thus far it remains under-explored how contrastive backdoor attacks fundamentally differ from their supervised counterparts, which impedes the development of effective defenses against the emerging threat. This work represents a solid step toward answering this critical question. Specifically, we define TRL, a unified framework that encompasses both supervised and contrastive backdoor attacks. Through the lens of TRL, we uncover that the two types of attacks operate through distinctive mechanisms: in supervised attacks, the learning of benign and backdoor tasks tends to occur independently, while in contrastive attacks, the two tasks are deeply intertwined both in their representations and throughout their learning processes. This distinction leads to the disparate learning dynamics and feature distributions of supervised and contrastive attacks. More importantly, we reveal that the specificities of contrastive backdoor attacks entail important implications from a defense perspective: existing defenses for supervised attacks are often inadequate and not easily retrofitted to contrastive attacks. We also explore several alternative defenses and discuss their potential challenges. Our findings highlight the need for defenses tailored to the specificities of contrastive backdoor attacks, pointing to promising directions for future research. ",
    "url": "https://arxiv.org/abs/2312.09057",
    "authors": [
      "Changjiang Li",
      "Ren Pang",
      "Bochuan Cao",
      "Zhaohan Xi",
      "Jinghui Chen",
      "Shouling Ji",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.09076",
    "title": "ProSGNeRF: Progressive Dynamic Neural Scene Graph with Frequency  Modulated Auto-Encoder in Urban Scenes",
    "abstract": "Implicit neural representation has demonstrated promising results in view synthesis for large and complex scenes. However, existing approaches either fail to capture the fast-moving objects or need to build the scene graph without camera ego-motions, leading to low-quality synthesized views of the scene. We aim to jointly solve the view synthesis problem of large-scale urban scenes and fast-moving vehicles, which is more practical and challenging. To this end, we first leverage a graph structure to learn the local scene representations of dynamic objects and the background. Then, we design a progressive scheme that dynamically allocates a new local scene graph trained with frames within a temporal window, allowing us to scale up the representation to an arbitrarily large scene. Besides, the training views of urban scenes are relatively sparse, which leads to a significant decline in reconstruction accuracy for dynamic objects. Therefore, we design a frequency auto-encoder network to encode the latent code and regularize the frequency range of objects, which can enhance the representation of dynamic objects and address the issue of sparse image inputs. Additionally, we employ lidar point projection to maintain geometry consistency in large-scale urban scenes. Experimental results demonstrate that our method achieves state-of-the-art view synthesis accuracy, object manipulation, and scene roaming ability. The code will be open-sourced upon paper acceptance. ",
    "url": "https://arxiv.org/abs/2312.09076",
    "authors": [
      "Tianchen Deng",
      "Siyang Liu",
      "Xuan Wang",
      "Yejia Liu",
      "Danwei Wang",
      "Weidong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.09077",
    "title": "Entropy Regularization and Faster Decremental Matching in General Graphs",
    "abstract": "We provide an algorithm that maintains, against an adaptive adversary, a $(1-\\varepsilon)$-approximate maximum matching in $n$-node $m$-edge general (not necessarily bipartite) undirected graph undergoing edge deletions with high probability with (amortized) $O(\\mathrm{poly}(\\varepsilon^{-1}, \\log n))$ time per update. We also obtain the same update time for maintaining a fractional approximate weighted matching (and hence an approximation to the value of the maximum weight matching) and an integral approximate weighted matching in dense graphs. Our unweighted result improves upon the prior state-of-the-art which includes a $\\mathrm{poly}(\\log{n}) \\cdot 2^{O(1/\\varepsilon^2)}$ update time [Assadi-Bernstein-Dudeja 2022] and an $O(\\sqrt{m} \\varepsilon^{-2})$ update time [Gupta-Peng 2013], and our weighted result improves upon the $O(\\sqrt{m}\\varepsilon^{-O(1/\\varepsilon)}\\log{n})$ update time due to [Gupta-Peng 2013]. To obtain our results, we generalize a recent optimization approach to dynamic algorithms from [Jambulapati-Jin-Sidford-Tian 2022]. We show that repeatedly solving entropy-regularized optimization problems yields a lazy updating scheme for fractional decremental problems with a near-optimal number of updates. To apply this framework we develop optimization methods compatible with it and new dynamic rounding algorithms for the matching polytope. ",
    "url": "https://arxiv.org/abs/2312.09077",
    "authors": [
      "Jiale Chen",
      "Aaron Sidford",
      "Ta-Wei Tu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2312.09078",
    "title": "Coevolutionary Algorithm for Building Robust Decision Trees under  Minimax Regret",
    "abstract": "In recent years, there has been growing interest in developing robust machine learning (ML) models that can withstand adversarial attacks, including one of the most widely adopted, efficient, and interpretable ML algorithms-decision trees (DTs). This paper proposes a novel coevolutionary algorithm (CoEvoRDT) designed to create robust DTs capable of handling noisy high-dimensional data in adversarial contexts. Motivated by the limitations of traditional DT algorithms, we leverage adaptive coevolution to allow DTs to evolve and learn from interactions with perturbed input data. CoEvoRDT alternately evolves competing populations of DTs and perturbed features, enabling construction of DTs with desired properties. CoEvoRDT is easily adaptable to various target metrics, allowing the use of tailored robustness criteria such as minimax regret. Furthermore, CoEvoRDT has potential to improve the results of other state-of-the-art methods by incorporating their outcomes (DTs they produce) into the initial population and optimize them in the process of coevolution. Inspired by the game theory, CoEvoRDT utilizes mixed Nash equilibrium to enhance convergence. The method is tested on 20 popular datasets and shows superior performance compared to 4 state-of-the-art algorithms. It outperformed all competing methods on 13 datasets with adversarial accuracy metrics, and on all 20 considered datasets with minimax regret. Strong experimental results and flexibility in choosing the error measure make CoEvoRDT a promising approach for constructing robust DTs in real-world applications. ",
    "url": "https://arxiv.org/abs/2312.09078",
    "authors": [
      "Adam \u017bychowski",
      "Andrew Perrault",
      "Jacek Ma\u0144dziuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.09082",
    "title": "Learned Fusion: 3D Object Detection using Calibration-Free Transformer  Feature Fusion",
    "abstract": "The state of the art in 3D object detection using sensor fusion heavily relies on calibration quality, which is difficult to maintain in large scale deployment outside a lab environment. We present the first calibration-free approach for 3D object detection. Thus, eliminating the need for complex and costly calibration procedures. Our approach uses transformers to map the features between multiple views of different sensors at multiple abstraction levels. In an extensive evaluation for object detection, we not only show that our approach outperforms single modal setups by 14.1% in BEV mAP, but also that the transformer indeed learns mapping. By showing calibration is not necessary for sensor fusion, we hope to motivate other researchers following the direction of calibration-free fusion. Additionally, resulting approaches have a substantial resilience against rotation and translation changes. ",
    "url": "https://arxiv.org/abs/2312.09082",
    "authors": [
      "Michael F\u00fcrst",
      "Rahul Jakkamsetty",
      "Ren\u00e9 Schuster",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.09086",
    "title": "COMBHelper: A Neural Approach to Reduce Search Space for Graph  Combinatorial Problems",
    "abstract": "Combinatorial Optimization (CO) problems over graphs appear routinely in many applications such as in optimizing traffic, viral marketing in social networks, and matching for job allocation. Due to their combinatorial nature, these problems are often NP-hard. Existing approximation algorithms and heuristics rely on the search space to find the solutions and become time-consuming when this space is large. In this paper, we design a neural method called COMBHelper to reduce this space and thus improve the efficiency of the traditional CO algorithms based on node selection. Specifically, it employs a Graph Neural Network (GNN) to identify promising nodes for the solution set. This pruned search space is then fed to the traditional CO algorithms. COMBHelper also uses a Knowledge Distillation (KD) module and a problem-specific boosting module to bring further efficiency and efficacy. Our extensive experiments show that the traditional CO algorithms with COMBHelper are at least 2 times faster than their original versions. ",
    "url": "https://arxiv.org/abs/2312.09086",
    "authors": [
      "Hao Tian",
      "Sourav Medya",
      "Wei Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.09095",
    "title": "ColNeRF: Collaboration for Generalizable Sparse Input Neural Radiance  Field",
    "abstract": "Neural Radiance Fields (NeRF) have demonstrated impressive potential in synthesizing novel views from dense input, however, their effectiveness is challenged when dealing with sparse input. Existing approaches that incorporate additional depth or semantic supervision can alleviate this issue to an extent. However, the process of supervision collection is not only costly but also potentially inaccurate, leading to poor performance and generalization ability in diverse scenarios. In our work, we introduce a novel model: the Collaborative Neural Radiance Fields (ColNeRF) designed to work with sparse input. The collaboration in ColNeRF includes both the cooperation between sparse input images and the cooperation between the output of the neural radiation field. Through this, we construct a novel collaborative module that aligns information from various views and meanwhile imposes self-supervised constraints to ensure multi-view consistency in both geometry and appearance. A Collaborative Cross-View Volume Integration module (CCVI) is proposed to capture complex occlusions and implicitly infer the spatial location of objects. Moreover, we introduce self-supervision of target rays projected in multiple directions to ensure geometric and color consistency in adjacent regions. Benefiting from the collaboration at the input and output ends, ColNeRF is capable of capturing richer and more generalized scene representation, thereby facilitating higher-quality results of the novel view synthesis. Extensive experiments demonstrate that ColNeRF outperforms state-of-the-art sparse input generalizable NeRF methods. Furthermore, our approach exhibits superiority in fine-tuning towards adapting to new scenes, achieving competitive performance compared to per-scene optimized NeRF-based methods while significantly reducing computational costs. Our code is available at: https://github.com/eezkni/ColNeRF. ",
    "url": "https://arxiv.org/abs/2312.09095",
    "authors": [
      "Zhangkai Ni",
      "Peiqi Yang",
      "Wenhan Yang",
      "Lin Ma",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.09116",
    "title": "Numerical Computation of Non-Equilateral Quantum Graph Spectra",
    "abstract": "In the broad range of studies related to quantum graphs, quantum graph spectra appear as a topic of special interest. They are important in the context of diffusion type problems posed on metric graphs. Theoretical findings suggest that quantum graph eigenvalues can be found as the solutions of a nonlinear eigenvalue problem, and in the special case of equilateral graphs, even as the solutions of a linear eigenvalue problem on the underlying combinatorial graph. The latter, remarkable relation to combinatorial graph spectra will be exploited to derive a solver for the general, non-equilateral case. Eigenvalue estimates from equilateral approximations will be applied as initial guesses in a Newton-trace iteration to solve the nonlinear eigenvalue problem. ",
    "url": "https://arxiv.org/abs/2312.09116",
    "authors": [
      "Chong-Son Dr\u00f6ge",
      "Anna Weller"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.09143",
    "title": "F1-EV Score: Measuring the Likelihood of Estimating a Good Decision  Threshold for Semi-Supervised Anomaly Detection",
    "abstract": "Anomalous sound detection (ASD) systems are usually compared by using threshold-independent performance measures such as AUC-ROC. However, for practical applications a decision threshold is needed to decide whether a given test sample is normal or anomalous. Estimating such a threshold is highly non-trivial in a semi-supervised setting where only normal training samples are available. In this work, F1-EV a novel threshold-independent performance measure for ASD systems that also includes the likelihood of estimating a good decision threshold is proposed and motivated using specific toy examples. In experimental evaluations, multiple performance measures are evaluated for all systems submitted to the ASD task of the DCASE Challenge 2023. It is shown that F1-EV is strongly correlated with AUC-ROC while having a significantly stronger correlation with the F1-score obtained with estimated and optimal decision thresholds than AUC-ROC. ",
    "url": "https://arxiv.org/abs/2312.09143",
    "authors": [
      "Kevin Wilkinghoff",
      "Keisuke Imoto"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.09154",
    "title": "CMG-Net: Robust Normal Estimation for Point Clouds via Chamfer Normal  Distance and Multi-scale Geometry",
    "abstract": "This work presents an accurate and robust method for estimating normals from point clouds. In contrast to predecessor approaches that minimize the deviations between the annotated and the predicted normals directly, leading to direction inconsistency, we first propose a new metric termed Chamfer Normal Distance to address this issue. This not only mitigates the challenge but also facilitates network training and substantially enhances the network robustness against noise. Subsequently, we devise an innovative architecture that encompasses Multi-scale Local Feature Aggregation and Hierarchical Geometric Information Fusion. This design empowers the network to capture intricate geometric details more effectively and alleviate the ambiguity in scale selection. Extensive experiments demonstrate that our method achieves the state-of-the-art performance on both synthetic and real-world datasets, particularly in scenarios contaminated by noise. Our implementation is available at https://github.com/YingruiWoo/CMG-Net_Pytorch. ",
    "url": "https://arxiv.org/abs/2312.09154",
    "authors": [
      "Yingrui Wu",
      "Mingyang Zhao",
      "Keqiang Li",
      "Weize Quan",
      "Tianqi Yu",
      "Jianfeng Yang",
      "Xiaohong Jia",
      "Dong-Ming Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.09167",
    "title": "Maximizing Nash Social Welfare under Two-Sided Preferences",
    "abstract": "The maximum Nash social welfare (NSW) -- which maximizes the geometric mean of agents' utilities -- is a fundamental solution concept with remarkable fairness and efficiency guarantees. The computational aspects of NSW have been extensively studied for one-sided preferences where a set of agents have preferences over a set of resources. Our work deviates from this trend and studies NSW maximization for two-sided preferences, wherein a set of workers and firms, each having a cardinal valuation function, are matched with each other. We provide a systematic study of the computational complexity of maximizing NSW for many-to-one matchings under two-sided preferences. Our main negative result is that maximizing NSW is NP-hard even in a highly restricted setting where each firm has capacity 2, all valuations are in the range {0,1,2}, and each agent positively values at most three other agents. In search of positive results, we develop approximation algorithms as well as parameterized algorithms in terms of natural parameters such as the number of workers, the number of firms, and the firms' capacities. We also provide algorithms for restricted domains such as symmetric binary valuations and bounded degree instances. ",
    "url": "https://arxiv.org/abs/2312.09167",
    "authors": [
      "Pallavi Jain",
      "Rohit Vaish"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2312.09197",
    "title": "Model-Free Change Point Detection for Mixing Processes",
    "abstract": "This paper considers the change point detection problem under dependent samples. In particular, we provide performance guarantees for the MMD-CUSUM test under $\\alpha$, $\\beta$, and $\\phi$-mixing processes, which significantly expands its utility beyond the i.i.d. and Markovian cases used in previous studies. We obtain lower bounds for average-run-length (ARL) and upper bounds for average-detection-delay (ADD) in terms of the threshold parameter. We show that the MMD-CUSUM test enjoys the same level of performance as the i.i.d. case under $\\phi$-mixing processes. The MMD-CUSUM test also achieves strong performance under $\\alpha$/$\\beta$-mixing processes, which are significantly more relaxed than existing results. The MMD-CUSUM test statistic adapts to different settings without modifications, rendering it a completely data-driven, dependence-agnostic change point detection scheme. Numerical simulations are provided at the end to evaluate our findings. ",
    "url": "https://arxiv.org/abs/2312.09197",
    "authors": [
      "Hao Chen",
      "Abhishek Gupta",
      "Yin Sun",
      "Ness Shroff"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.09219",
    "title": "NestE: Modeling Nested Relational Structures for Knowledge Graph  Reasoning",
    "abstract": "Reasoning with knowledge graphs (KGs) has primarily focused on triple-shaped facts. Recent advancements have been explored to enhance the semantics of these facts by incorporating more potent representations, such as hyper-relational facts. However, these approaches are limited to \\emph{atomic facts}, which describe a single piece of information. This paper extends beyond \\emph{atomic facts} and delves into \\emph{nested facts}, represented by quoted triples where subjects and objects are triples themselves (e.g., ((\\emph{BarackObama}, \\emph{holds\\_position}, \\emph{President}), \\emph{succeed\\_by}, (\\emph{DonaldTrump}, \\emph{holds\\_position}, \\emph{President}))). These nested facts enable the expression of complex semantics like \\emph{situations} over time and \\emph{logical patterns} over entities and relations. In response, we introduce NestE, a novel KG embedding approach that captures the semantics of both atomic and nested factual knowledge. NestE represents each atomic fact as a $1\\times3$ matrix, and each nested relation is modeled as a $3\\times3$ matrix that rotates the $1\\times3$ atomic fact matrix through matrix multiplication. Each element of the matrix is represented as a complex number in the generalized 4D hypercomplex space, including (spherical) quaternions, hyperbolic quaternions, and split-quaternions. Through thorough analysis, we demonstrate the embedding's efficacy in capturing diverse logical patterns over nested facts, surpassing the confines of first-order logic-like expressions. Our experimental results showcase NestE's significant performance gains over current baselines in triple prediction and conditional link prediction. The code and pre-trained models are open available at https://github.com/xiongbo010/NestE. ",
    "url": "https://arxiv.org/abs/2312.09219",
    "authors": [
      "Bo Xiong",
      "Mojtaba Nayyeri",
      "Linhao Luo",
      "Zihao Wang",
      "Shirui Pan",
      "Steffen Staab"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.09243",
    "title": "OccNeRF: Self-Supervised Multi-Camera Occupancy Prediction with Neural  Radiance Fields",
    "abstract": "As a fundamental task of vision-based perception, 3D occupancy prediction reconstructs 3D structures of surrounding environments. It provides detailed information for autonomous driving planning and navigation. However, most existing methods heavily rely on the LiDAR point clouds to generate occupancy ground truth, which is not available in the vision-based system. In this paper, we propose an OccNeRF method for self-supervised multi-camera occupancy prediction. Different from bounded 3D occupancy labels, we need to consider unbounded scenes with raw image supervision. To solve the issue, we parameterize the reconstructed occupancy fields and reorganize the sampling strategy. The neural rendering is adopted to convert occupancy fields to multi-camera depth maps, supervised by multi-frame photometric consistency. Moreover, for semantic occupancy prediction, we design several strategies to polish the prompts and filter the outputs of a pretrained open-vocabulary 2D segmentation model. Extensive experiments for both self-supervised depth estimation and semantic occupancy prediction tasks on nuScenes dataset demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2312.09243",
    "authors": [
      "Chubin Zhang",
      "Juncheng Yan",
      "Yi Wei",
      "Jiaxin Li",
      "Li Liu",
      "Yansong Tang",
      "Yueqi Duan",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08519",
    "title": "Toward a More Biologically Plausible Neural Network Model of Latent  Cause Inference",
    "abstract": "Humans spontaneously perceive a continuous stream of experience as discrete events. It has been hypothesized that this ability is supported by latent cause inference (LCI). We implemented this hypothesis using Latent Cause Network (LCNet), a neural network model of LCI. LCNet interacts with a Bayesian LCI mechanism that activates a unique context vector for each inferred latent cause. This architecture makes LCNet more biologically plausible than existing models of LCI and supports extraction of shared structure across latent causes. Across three simulations, we found that LCNet could 1) extract shared structure across latent causes in a function-learning task while avoiding catastrophic interference, 2) capture human data on curriculum effects in schema learning, and 3) infer the underlying event structure when processing naturalistic videos of daily activities. Our work provides a biologically plausible computational model that can operate in both laboratory experiment settings and naturalistic settings, opening up the possibility of providing a unified model of event cognition. ",
    "url": "https://arxiv.org/abs/2312.08519",
    "authors": [
      "Qihong Lu",
      "Tan T. Nguyen",
      "Qiong Zhang",
      "Uri Hasson",
      "Thomas L. Griffiths",
      "Jeffrey M. Zacks",
      "Samuel J. Gershman",
      "Kenneth A. Norman"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08622",
    "title": "Scalable Ensemble-based Detection Method against Adversarial Attacks for  speaker verification",
    "abstract": "Automatic speaker verification (ASV) is highly susceptible to adversarial attacks. Purification modules are usually adopted as a pre-processing to mitigate adversarial noise. However, they are commonly implemented across diverse experimental settings, rendering direct comparisons challenging. This paper comprehensively compares mainstream purification techniques in a unified framework. We find these methods often face a trade-off between user experience and security, as they struggle to simultaneously maintain genuine sample performance and reduce adversarial perturbations. To address this challenge, some efforts have extended purification modules to encompass detection capabilities, aiming to alleviate the trade-off. However, advanced purification modules will always come into the stage to surpass previous detection method. As a result, we further propose an easy-to-follow ensemble approach that integrates advanced purification modules for detection, achieving state-of-the-art (SOTA) performance in countering adversarial noise. Our ensemble method has great potential due to its compatibility with future advanced purification techniques. ",
    "url": "https://arxiv.org/abs/2312.08622",
    "authors": [
      "Haibin Wu",
      "Heng-Cheng Kuo",
      "Yu Tsao",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.08625",
    "title": "Graph Network Surrogate Model for Subsurface Flow Optimization",
    "abstract": "The optimization of well locations and controls is an important step in the design of subsurface flow operations such as oil production or geological CO2 storage. These optimization problems can be computationally expensive, however, as many potential candidate solutions must be evaluated. In this study, we propose a graph network surrogate model (GNSM) for optimizing well placement and controls. The GNSM transforms the flow model into a computational graph that involves an encoding-processing-decoding architecture. Separate networks are constructed to provide global predictions for the pressure and saturation state variables. Model performance is enhanced through the inclusion of the single-phase steady-state pressure solution as a feature. A multistage multistep strategy is used for training. The trained GNSM is applied to predict flow responses in a 2D unstructured model of a channelized reservoir. Results are presented for a large set of test cases, in which five injection wells and five production wells are placed randomly throughout the model, with a random control variable (bottom-hole pressure) assigned to each well. Median relative error in pressure and saturation for 300 such test cases is 1-2%. The ability of the trained GNSM to provide accurate predictions for a new (geologically similar) permeability realization is demonstrated. Finally, the trained GNSM is used to optimize well locations and controls with a differential evolution algorithm. GNSM-based optimization results are comparable to those from simulation-based optimization, with a runtime speedup of a factor of 36. Much larger speedups are expected if the method is used for robust optimization, in which each candidate solution is evaluated on multiple geological models. ",
    "url": "https://arxiv.org/abs/2312.08625",
    "authors": [
      "Haoyu Tang",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08641",
    "title": "Towards Automatic Data Augmentation for Disordered Speech Recognition",
    "abstract": "Automatic recognition of disordered speech remains a highly challenging task to date due to data scarcity. This paper presents a reinforcement learning (RL) based on-the-fly data augmentation approach for training state-of-the-art PyChain TDNN and end-to-end Conformer ASR systems on such data. The handcrafted temporal and spectral mask operations in the standard SpecAugment method that are task and system dependent, together with additionally introduced minimum and maximum cut-offs of these time-frequency masks, are now automatically learned using an RNN-based policy controller and tightly integrated with ASR system training. Experiments on the UASpeech corpus suggest the proposed RL-based data augmentation approach consistently produced performance superior or comparable that obtained using expert or handcrafted SpecAugment policies. Our RL auto-augmented PyChain TDNN system produced an overall WER of 28.79% on the UASpeech test set of 16 dysarthric speakers. ",
    "url": "https://arxiv.org/abs/2312.08641",
    "authors": [
      "Zengrui Jin",
      "Xurong Xie",
      "Tianzi Wang",
      "Mengzhe Geng",
      "Jiajun Deng",
      "Guinan Li",
      "Shujie Hu",
      "Xunying Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.08670",
    "title": "Temporal-Spatial Entropy Balancing for Causal Continuous  Treatment-Effect Estimation",
    "abstract": "In the field of intracity freight transportation, changes in order volume are significantly influenced by temporal and spatial factors. When building subsidy and pricing strategies, predicting the causal effects of these strategies on order volume is crucial. In the process of calculating causal effects, confounding variables can have an impact. Traditional methods to control confounding variables handle data from a holistic perspective, which cannot ensure the precision of causal effects in specific temporal and spatial dimensions. However, temporal and spatial dimensions are extremely critical in the logistics field, and this limitation may directly affect the precision of subsidy and pricing strategies. To address these issues, this study proposes a technique based on flexible temporal-spatial grid partitioning. Furthermore, based on the flexible grid partitioning technique, we further propose a continuous entropy balancing method in the temporal-spatial domain, which named TS-EBCT (Temporal-Spatial Entropy Balancing for Causal Continue Treatments). The method proposed in this paper has been tested on two simulation datasets and two real datasets, all of which have achieved excellent performance. In fact, after applying the TS-EBCT method to the intracity freight transportation field, the prediction accuracy of the causal effect has been significantly improved. It brings good business benefits to the company's subsidy and pricing strategies. ",
    "url": "https://arxiv.org/abs/2312.08670",
    "authors": [
      "Tao Hu",
      "Honglong Zhang",
      "Fan Zeng",
      "Min Du",
      "XiangKun Du",
      "Yue Zheng",
      "Mengran Zhang",
      "Dan Yang",
      "Jihao Wu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08766",
    "title": "A Dual Convolutional Neural Network Pipeline for Melanoma Diagnostics  and Prognostics",
    "abstract": "Melanoma is a type of cancer that begins in the cells controlling the pigment of the skin, and it is often referred to as the most dangerous skin cancer. Diagnosing melanoma can be time-consuming, and a recent increase in melanoma incidents indicates a growing demand for a more efficient diagnostic process. This paper presents a pipeline for melanoma diagnostics, leveraging two convolutional neural networks, a diagnosis, and a prognosis model. The diagnostic model is responsible for localizing malignant patches across whole slide images and delivering a patient-level diagnosis as malignant or benign. Further, the prognosis model utilizes the diagnostic model's output to provide a patient-level prognosis as good or bad. The full pipeline has an F1 score of 0.79 when tested on data from the same distribution as it was trained on. ",
    "url": "https://arxiv.org/abs/2312.08766",
    "authors": [
      "Marie B\u00f8-Sande",
      "Edvin Benjaminsen",
      "Neel Kanwal",
      "Saul Fuster",
      "Helga Hardardottir",
      "Ingrid Lundal",
      "Emiel A.M. Janssen",
      "Kjersti Engan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.09004",
    "title": "Holistic chemical evaluation reveals pitfalls in reaction prediction  models",
    "abstract": "The prediction of chemical reactions has gained significant interest within the machine learning community in recent years, owing to its complexity and crucial applications in chemistry. However, model evaluation for this task has been mostly limited to simple metrics like top-k accuracy, which obfuscates fine details of a model's limitations. Inspired by progress in other fields, we propose a new assessment scheme that builds on top of current approaches, steering towards a more holistic evaluation. We introduce the following key components for this goal: CHORISO, a curated dataset along with multiple tailored splits to recreate chemically relevant scenarios, and a collection of metrics that provide a holistic view of a model's advantages and limitations. Application of this method to state-of-the-art models reveals important differences on sensitive fronts, especially stereoselectivity and chemical out-of-distribution generalization. Our work paves the way towards robust prediction models that can ultimately accelerate chemical discovery. ",
    "url": "https://arxiv.org/abs/2312.09004",
    "authors": [
      "Victor Sabanza Gil",
      "Andres M. Bran",
      "Malte Franke",
      "Remi Schlama",
      "Jeremy S. Luterbacher",
      "Philippe Schwaller"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.09022",
    "title": "Brain Diffuser with Hierarchical Transformer for MCI Causality Analysis",
    "abstract": "Effective connectivity estimation plays a crucial role in understanding the interactions and information flow between different brain regions. However, the functional time series used for estimating effective connentivity is derived from certain software, which may lead to large computing errors because of different parameter settings and degrade the ability to model complex causal relationships between brain regions. In this paper, a brain diffuser with hierarchical transformer (BDHT) is proposed to estimate effective connectivity for mild cognitive impairment (MCI) analysis. To our best knowledge, the proposed brain diffuer is the first generative model to apply diffusion models in the application of generating and analyzing multimodal brain networks. Specifically, the BDHT leverages the structural connectivity to guide the reverse processes in an efficient way. It makes the denoising process more reliable and guarantees effective connectivity estimation accuracy. To improve denoising quality, the hierarchical denoising transformer is designed to learn multi-scale features in topological space. Furthermore, the GraphConFormer block can concentrate on both global and adjacent connectivity information. By stacking the multi-head attention and graph convolutional network, the proposed model enhances structure-function complementarity and improves the ability in noise estimation. Experimental evaluations of the denoising diffusion model demonstrate its effectiveness in estimating effective connectivity. The method achieves superior performance in terms of accuracy and robustness compared to existing approaches. It can captures both unidirectal and bidirectional interactions between brain regions, providing a comprehensive understanding of the brain's information processing mechanisms. ",
    "url": "https://arxiv.org/abs/2312.09022",
    "authors": [
      "Qiankun Zuo",
      "Ling Chen",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2312.09034",
    "title": "Fusion of Audio and Visual Embeddings for Sound Event Localization and  Detection",
    "abstract": "Sound event localization and detection (SELD) combines two subtasks: sound event detection (SED) and direction of arrival (DOA) estimation. SELD is usually tackled as an audio-only problem, but visual information has been recently included. Few audio-visual (AV)-SELD works have been published and most employ vision via face/object bounding boxes, or human pose keypoints. In contrast, we explore the integration of audio and visual feature embeddings extracted with pre-trained deep networks. For the visual modality, we tested ResNet50 and Inflated 3D ConvNet (I3D). Our comparison of AV fusion methods includes the AV-Conformer and Cross-Modal Attentive Fusion (CMAF) model. Our best models outperform the DCASE 2023 Task3 audio-only and AV baselines by a wide margin on the development set of the STARSS23 dataset, making them competitive amongst state-of-the-art results of the AV challenge, without model ensembling, heavy data augmentation, or prediction post-processing. Such techniques and further pre-training could be applied as next steps to improve performance. ",
    "url": "https://arxiv.org/abs/2312.09034",
    "authors": [
      "Davide Berghi",
      "Peipei Wu",
      "Jinzheng Zhao",
      "Wenwu Wang",
      "Philip J. B. Jackson"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2312.09061",
    "title": "Fair Clustering: A Causal Perspective",
    "abstract": "Clustering algorithms may unintentionally propagate or intensify existing disparities, leading to unfair representations or biased decision-making. Current fair clustering methods rely on notions of fairness that do not capture any information on the underlying causal mechanisms. We show that optimising for non-causal fairness notions can paradoxically induce direct discriminatory effects from a causal standpoint. We present a clustering approach that incorporates causal fairness metrics to provide a more nuanced approach to fairness in unsupervised learning. Our approach enables the specification of the causal fairness metrics that should be minimised. We demonstrate the efficacy of our methodology using datasets known to harbour unfair biases. ",
    "url": "https://arxiv.org/abs/2312.09061",
    "authors": [
      "Fritz Bayer",
      "Drago Plecko",
      "Niko Beerenwinkel",
      "Jack Kuipers"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.09131",
    "title": "Physics-Informed Neural Network Lyapunov Functions: PDE  Characterization, Learning, and Verification",
    "abstract": "We provide a systematic investigation of using physics-informed neural networks to compute Lyapunov functions. We encode Lyapunov conditions as a partial differential equation (PDE) and use this for training neural network Lyapunov functions. We analyze the analytical properties of the solutions to the Lyapunov and Zubov PDEs. In particular, we show that employing the Zubov equation in training neural Lyapunov functions can lead to approximate regions of attraction close to the true domain of attraction. We then provide sufficient conditions for the learned neural Lyapunov functions that can be readily verified by satisfiability modulo theories (SMT) solvers, enabling formal verification of both local stability analysis and region-of-attraction estimates in the large. Through a number of nonlinear examples, ranging from low to high dimensions, we demonstrate that the proposed framework can outperform traditional sums-of-squares (SOS) Lyapunov functions obtained using semidefinite programming (SDP). ",
    "url": "https://arxiv.org/abs/2312.09131",
    "authors": [
      "Jun Liu",
      "Yiming Meng",
      "Maxwell Fitzsimmons",
      "Ruikun Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2104.11893",
    "title": "LGD-GCN: Local and Global Disentangled Graph Convolutional Networks",
    "abstract": " Comments: add additinal code and paper links ",
    "url": "https://arxiv.org/abs/2104.11893",
    "authors": [
      "Jingwei Guo",
      "Kaizhu Huang",
      "Xinping Yi",
      "Rui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04678",
    "title": "Polynomial Turing Compressions for Some Graph Problems Parameterized by  Modular-Width",
    "abstract": " Comments: 18 pages ",
    "url": "https://arxiv.org/abs/2201.04678",
    "authors": [
      "Weidong Luo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.01793",
    "title": "Using random graphs to sample repulsive Gibbs point processes with  arbitrary-range potentials",
    "abstract": " Title: Using random graphs to sample repulsive Gibbs point processes with  arbitrary-range potentials ",
    "url": "https://arxiv.org/abs/2204.01793",
    "authors": [
      "Tobias Friedrich",
      "Andreas G\u00f6bel",
      "Maximilian Katzmann",
      "Martin Krejca",
      "Marcus Pappik"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.10083",
    "title": "A Unified Experiment Design Approach for Cyclic and Acyclic Causal  Models",
    "abstract": " Comments: 31 pages, 6 figures, 1 table, accepted in JMLR ",
    "url": "https://arxiv.org/abs/2205.10083",
    "authors": [
      "Ehsan Mokhtarian",
      "Saber Salehkaleybar",
      "AmirEmad Ghassami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03538",
    "title": "WIDESim: A toolkit for simulating resource management techniques of  scientific Workflows In Distributed Environments with graph topology",
    "abstract": " Title: WIDESim: A toolkit for simulating resource management techniques of  scientific Workflows In Distributed Environments with graph topology ",
    "url": "https://arxiv.org/abs/2206.03538",
    "authors": [
      "Mohammad Amin Rayej",
      "Hajar Siar",
      "Ahmadreza Hamzei",
      "Mohammad Sadegh Majidi Yazdi",
      "Parsa Mohammadian",
      "Mohammad Izadi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.11792",
    "title": "Two-dimensional total absorption spectroscopy with conditional  generative adversarial networks",
    "abstract": " Title: Two-dimensional total absorption spectroscopy with conditional  generative adversarial networks ",
    "url": "https://arxiv.org/abs/2206.11792",
    "authors": [
      "Cade Dembski",
      "Michelle P. Kuchera",
      "Sean Liddick",
      "Raghu Ramanujan",
      "Artemis Spyrou"
    ],
    "subjectives": [
      "Nuclear Experiment (nucl-ex)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05742",
    "title": "Curved Representation Space of Vision Transformers",
    "abstract": " Comments: AAAI 2024 ",
    "url": "https://arxiv.org/abs/2210.05742",
    "authors": [
      "Juyeop Kim",
      "Junha Park",
      "Songkuk Kim",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12986",
    "title": "Physics-informed neural networks for pathloss prediction",
    "abstract": " Comments: 5 pages, 5 figures, accepted at MLSP 2023 ",
    "url": "https://arxiv.org/abs/2211.12986",
    "authors": [
      "Steffen Limmer",
      "Alberto Martinez Alba",
      "Nicola Michailow"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14158",
    "title": "An Isolation-Aware Online Virtual Network Embedding via Deep  Reinforcement Learning",
    "abstract": " Comments: 7 pages, 9 figures, 3 tables, 2 algorithms ",
    "url": "https://arxiv.org/abs/2211.14158",
    "authors": [
      "Ali Gohar",
      "Chunming Rong",
      "Sanghwan Lee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01196",
    "title": "Vector Symbolic Finite State Machines in Attractor Neural Networks",
    "abstract": " Comments: 26 pages, 13 figures. This is the authors' final version before publication in Neural Computation ",
    "url": "https://arxiv.org/abs/2212.01196",
    "authors": [
      "Madison Cotteret",
      "Hugh Greatorex",
      "Martin Ziegler",
      "Elisabetta Chicca"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2212.06605",
    "title": "Dimensionality reduction on complex vector spaces for Euclidean distance  with dynamic weights",
    "abstract": " Title: Dimensionality reduction on complex vector spaces for Euclidean distance  with dynamic weights ",
    "url": "https://arxiv.org/abs/2212.06605",
    "authors": [
      "Paolo Pellizzoni",
      "Simone Moretti",
      "Francesco Silvestri"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2212.13120",
    "title": "Neural Structure Fields with Application to Crystal Structure  Autoencoders",
    "abstract": " Comments: 17 pages , 7 figures, 4 tables. 15 pages Supplementary Information ",
    "url": "https://arxiv.org/abs/2212.13120",
    "authors": [
      "Naoya Chiba",
      "Yuta Suzuki",
      "Tatsunori Taniai",
      "Ryo Igarashi",
      "Yoshitaka Ushiku",
      "Kotaro Saito",
      "Kanta Ono"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2301.12562",
    "title": "Simplifying Subgraph Representation Learning for Scalable Link  Prediction",
    "abstract": " Title: Simplifying Subgraph Representation Learning for Scalable Link  Prediction ",
    "url": "https://arxiv.org/abs/2301.12562",
    "authors": [
      "Paul Louis",
      "Shweta Ann Jacob",
      "Amirali Salehi-Abari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.06228",
    "title": "Unsupervised Detection of Behavioural Drifts with Dynamic Clustering and  Trajectory Analysis",
    "abstract": " Comments: Accepted to IEEE TKDE ",
    "url": "https://arxiv.org/abs/2302.06228",
    "authors": [
      "Bardh Prenkaj",
      "Paola Velardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.13020",
    "title": "DCLP: Neural Architecture Predictor with Curriculum Contrastive Learning",
    "abstract": " Comments: Accepted by AAAI24 ",
    "url": "https://arxiv.org/abs/2302.13020",
    "authors": [
      "Shenghe Zheng",
      "Hongzhi Wang",
      "Tianyu Mu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.01141",
    "title": "DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint  Satisfaction",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2303.01141",
    "authors": [
      "Kshitij Goyal",
      "Sebastijan Dumancic",
      "Hendrik Blockeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.02904",
    "title": "Social Cue Detection and Analysis Using Transfer Entropy",
    "abstract": " Comments: 9 pages, 5 figures. Preprint. To be published in Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI '24), March 11--14, 2024, Boulder, CO, USA ",
    "url": "https://arxiv.org/abs/2303.02904",
    "authors": [
      "Haoyang Jiang",
      "Elizabeth A. Croft",
      "Michael G. Burke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.13056",
    "title": "Predicting the Initial Conditions of the Universe using a Deterministic  Neural Network",
    "abstract": " Comments: Camera ready version for NeurIPS 2023 AI for Science workshop this https URL ",
    "url": "https://arxiv.org/abs/2303.13056",
    "authors": [
      "Vaibhav Jindal",
      "Albert Liang",
      "Aarti Singh",
      "Shirley Ho",
      "Drew Jamieson"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.10337",
    "title": "Prediction of the evolution of the nuclear reactor core parameters using  artificial neural network",
    "abstract": " Title: Prediction of the evolution of the nuclear reactor core parameters using  artificial neural network ",
    "url": "https://arxiv.org/abs/2304.10337",
    "authors": [
      "Krzysztof Palmi",
      "Wojciech Kubinski",
      "Piotr Darnowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10847",
    "title": "Large Language Models can be Guided to Evade AI-Generated Text Detection",
    "abstract": " Title: Large Language Models can be Guided to Evade AI-Generated Text Detection ",
    "url": "https://arxiv.org/abs/2305.10847",
    "authors": [
      "Ning Lu",
      "Shengcai Liu",
      "Rui He",
      "Qi Wang",
      "Yew-Soon Ong",
      "Ke Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14141",
    "title": "Learning Remote Sensing Object Detection with Single Point Supervision",
    "abstract": " Comments: Accepted by IEEE TGRS; 16 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2305.14141",
    "authors": [
      "Shitian He",
      "Huanxin Zou",
      "Yingqian Wang",
      "Boyang Li",
      "Xu Cao",
      "Ning Jing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16846",
    "title": "Lagrangian Flow Networks for Conservation Laws",
    "abstract": " Title: Lagrangian Flow Networks for Conservation Laws ",
    "url": "https://arxiv.org/abs/2305.16846",
    "authors": [
      "F. Arend Torres",
      "Marcello Massimo Negri",
      "Marco Inversi",
      "Jonathan Aellen",
      "Volker Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.03480",
    "title": "GSHOT: Few-shot Generative Modeling of Labeled Graphs",
    "abstract": " Comments: Accepted in Learning on Graph Conference (LOG,2023),this https URL ",
    "url": "https://arxiv.org/abs/2306.03480",
    "authors": [
      "Sahil Manchanda",
      "Shubham Gupta",
      "Sayan Ranu",
      "Srikanta Bedathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.07562",
    "title": "Statistical Beamformer Exploiting Non-stationarity and Sparsity with  Spatially Constrained ICA for Robust Speech Recognition",
    "abstract": " Title: Statistical Beamformer Exploiting Non-stationarity and Sparsity with  Spatially Constrained ICA for Robust Speech Recognition ",
    "url": "https://arxiv.org/abs/2306.07562",
    "authors": [
      "Ui-Hyeop Shin",
      "Hyung-Min Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2307.00293",
    "title": "AutoST: Training-free Neural Architecture Search for Spiking  Transformers",
    "abstract": " Comments: ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2307.00293",
    "authors": [
      "Ziqing Wang",
      "Qidong Zhao",
      "Jinku Cui",
      "Xu Liu",
      "Dongkuan Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.03223",
    "title": "Neural Network Field Theories: Non-Gaussianity, Actions, and Locality",
    "abstract": " Comments: 49 pages, plus references and appendices ",
    "url": "https://arxiv.org/abs/2307.03223",
    "authors": [
      "Mehmet Demirtas",
      "James Halverson",
      "Anindita Maiti",
      "Matthew D. Schwartz",
      "Keegan Stoner"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.06009",
    "title": "A Linear Algebraic Framework for Dynamic Scheduling Over Memory-Equipped  Quantum Networks",
    "abstract": " Comments: 19 pages, 7 figures. Accepted for publication in \"IEEE Transactions on Quantum Engineering\" ",
    "url": "https://arxiv.org/abs/2307.06009",
    "authors": [
      "Paolo Fittipaldi",
      "Anastasios Giovanidis",
      "Fr\u00e9d\u00e9ric Grosshans"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.16506",
    "title": "Explainable Equivariant Neural Networks for Particle Physics: PELICAN",
    "abstract": " Comments: 50 pages, 34 figures, 12 tables ",
    "url": "https://arxiv.org/abs/2307.16506",
    "authors": [
      "Alexander Bogatskiy",
      "Timothy Hoffman",
      "David W. Miller",
      "Jan T. Offermann",
      "Xiaoyang Liu"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2308.03443",
    "title": "Doubly Robust Estimator for Off-Policy Evaluation with Large Action  Spaces",
    "abstract": " Comments: 14 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2308.03443",
    "authors": [
      "Tatsuhiro Shimizu",
      "Laura Forastiere"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.03669",
    "title": "Diffusion Model in Causal Inference with Unmeasured Confounders",
    "abstract": " Comments: 14 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2308.03669",
    "authors": [
      "Tatsuhiro Shimizu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.05890",
    "title": "A Study of the Landscape of Privacy Policies of Smart Devices",
    "abstract": " Title: A Study of the Landscape of Privacy Policies of Smart Devices ",
    "url": "https://arxiv.org/abs/2308.05890",
    "authors": [
      "Aamir Hamid",
      "Hemanth Reddy Samidi",
      "Tim Finin",
      "Primal Pappachan",
      "Roberto Yus"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2308.10273",
    "title": "Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing  Continuous Conditional Generative Adversarial Networks",
    "abstract": " Title: Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing  Continuous Conditional Generative Adversarial Networks ",
    "url": "https://arxiv.org/abs/2308.10273",
    "authors": [
      "Xin Ding",
      "Yongwei Wang",
      "Zuheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11918",
    "title": "AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet  Underwater Object Detection",
    "abstract": " Title: AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet  Underwater Object Detection ",
    "url": "https://arxiv.org/abs/2308.11918",
    "authors": [
      "Jingchun Zhou",
      "Zongxin He",
      "Kin-Man Lam",
      "Yudong Wang",
      "Weishi Zhang",
      "ChunLe Guo",
      "Chongyi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13772",
    "title": "Boosting Residual Networks with Group Knowledge",
    "abstract": " Comments: Accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2308.13772",
    "authors": [
      "Shengji Tang",
      "Peng Ye",
      "Baopu Li",
      "Weihao Lin",
      "Tao Chen",
      "Tong He",
      "Chong Yu",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14015",
    "title": "Slimmed optical neural networks with multiplexed neuron sets and a  corresponding backpropagation training algorithm",
    "abstract": " Title: Slimmed optical neural networks with multiplexed neuron sets and a  corresponding backpropagation training algorithm ",
    "url": "https://arxiv.org/abs/2308.14015",
    "authors": [
      "Yi-Feng Liu",
      "Rui-Yao Ren",
      "Dai-Bao Hou",
      "Hai-Zhong Weng",
      "Bo-Wen Wang",
      "Ke-Jie Huang",
      "Xing Lin",
      "Feng Liu",
      "Chen-Hui Li",
      "Chao-Yuan Jin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2309.05395",
    "title": "SABLE: Secure And Byzantine robust LEarning",
    "abstract": " Title: SABLE: Secure And Byzantine robust LEarning ",
    "url": "https://arxiv.org/abs/2309.05395",
    "authors": [
      "Antoine Choffrut",
      "Rachid Guerraoui",
      "Rafael Pinot",
      "Renaud Sirdey",
      "John Stephan",
      "Martin Zuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.06157",
    "title": "Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for  Remaining Useful Life Prediction and Operational Condition Identification of  Rotating Machines",
    "abstract": " Title: Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for  Remaining Useful Life Prediction and Operational Condition Identification of  Rotating Machines ",
    "url": "https://arxiv.org/abs/2309.06157",
    "authors": [
      "Khoa Tran",
      "Hai-Canh Vu",
      "Lam Pham",
      "Nassim Boudaoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11814",
    "title": "Micromechanics-Informed Parametric Deep Material Network for Physics  Behavior Prediction of Heterogeneous Materials with a Varying Morphology",
    "abstract": " Title: Micromechanics-Informed Parametric Deep Material Network for Physics  Behavior Prediction of Heterogeneous Materials with a Varying Morphology ",
    "url": "https://arxiv.org/abs/2309.11814",
    "authors": [
      "Tianyi Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.00268",
    "title": "Unravel Anomalies: An End-to-end Seasonal-Trend Decomposition Approach  for Time Series Anomaly Detection",
    "abstract": " Comments: Published in ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 14-19 April 2024 in Seoul, Korea ",
    "url": "https://arxiv.org/abs/2310.00268",
    "authors": [
      "Zhenwei Zhang",
      "Ruiqi Wang",
      "Ran Ding",
      "Yuantao Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01794",
    "title": "GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers  through In-depth Benchmarking",
    "abstract": " Title: GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers  through In-depth Benchmarking ",
    "url": "https://arxiv.org/abs/2310.01794",
    "authors": [
      "Mert Kosan",
      "Samidha Verma",
      "Burouj Armgaan",
      "Khushbu Pahwa",
      "Ambuj Singh",
      "Sourav Medya",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03175",
    "title": "Impedance Leakage Vulnerability and its Utilization in  Reverse-engineering Embedded Software",
    "abstract": " Title: Impedance Leakage Vulnerability and its Utilization in  Reverse-engineering Embedded Software ",
    "url": "https://arxiv.org/abs/2310.03175",
    "authors": [
      "Md Sadik Awal",
      "Md Tauhidur Rahman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.05804",
    "title": "Learning Language-guided Adaptive Hyper-modality Representation for  Multimodal Sentiment Analysis",
    "abstract": " Comments: Published in EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2310.05804",
    "authors": [
      "Haoyu Zhang",
      "Yu Wang",
      "Guanghao Yin",
      "Kejun Liu",
      "Yuanyuan Liu",
      "Tianshu Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.06372",
    "title": "Leveraging Diffusion-Based Image Variations for Robust Training on  Poisoned Data",
    "abstract": " Comments: Published at NeurIPS 2023 Workshop on Backdoors in Deep Learning: The Good, the Bad, and the Ugly ",
    "url": "https://arxiv.org/abs/2310.06372",
    "authors": [
      "Lukas Struppek",
      "Martin B. Hentschel",
      "Clifton Poth",
      "Dominik Hintersdorf",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06470",
    "title": "Focus on Local Regions for Query-based Object Detection",
    "abstract": " Title: Focus on Local Regions for Query-based Object Detection ",
    "url": "https://arxiv.org/abs/2310.06470",
    "authors": [
      "Hongbin Xu",
      "Yamei Xia",
      "Shuai Zhao",
      "Bo Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15140",
    "title": "AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large  Language Models",
    "abstract": " Comments: Version 2 updates: Added comparison of three more evaluation methods and their reliability check using human labeling. Added results for jailbreaking Llama2 (individual behavior) and included complexity and hyperparameter analysis. Revised objectives for prompt leaking. Other minor changes made ",
    "url": "https://arxiv.org/abs/2310.15140",
    "authors": [
      "Sicheng Zhu",
      "Ruiyi Zhang",
      "Bang An",
      "Gang Wu",
      "Joe Barrow",
      "Zichao Wang",
      "Furong Huang",
      "Ani Nenkova",
      "Tong Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16121",
    "title": "19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics",
    "abstract": " Comments: 5 pages, submitted to the \"Machine Learning and the Physical Sciences\" NeurIPS 2023 Workshop ",
    "url": "https://arxiv.org/abs/2310.16121",
    "authors": [
      "Alexander Bogatskiy",
      "Timothy Hoffman",
      "Jan T. Offermann"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2310.19704",
    "title": "A Survey on Knowledge Editing of Neural Networks",
    "abstract": " Title: A Survey on Knowledge Editing of Neural Networks ",
    "url": "https://arxiv.org/abs/2310.19704",
    "authors": [
      "Vittorio Mazzia",
      "Alessandro Pedrani",
      "Andrea Caciolai",
      "Kay Rottmann",
      "Davide Bernardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.02558",
    "title": "Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity  with Free-Flying Robots",
    "abstract": " Comments: 11 pages, 7 figures, Manuscript presented at the 74th International Astronautical Congress, IAC 2023, Baku, Azerbaijan, 2 - 6 October 2023 ",
    "url": "https://arxiv.org/abs/2311.02558",
    "authors": [
      "Holly Dinkel",
      "Julia Di",
      "Jamie Santos",
      "Keenan Albee",
      "Paulo Borges",
      "Marina Moreira",
      "Oleg Alexandrov",
      "Brian Coltin",
      "Trey Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.06497",
    "title": "DRUformer: Enhancing the driving scene Important object detection with  driving relationship self-understanding",
    "abstract": " Title: DRUformer: Enhancing the driving scene Important object detection with  driving relationship self-understanding ",
    "url": "https://arxiv.org/abs/2311.06497",
    "authors": [
      "Yingjie Niu",
      "Ming Ding",
      "Keisuke Fujii",
      "Kento Ohtani",
      "Alexander Carballo",
      "Kazuya Takeda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08141",
    "title": "GMTR: Graph Matching Transformers",
    "abstract": " Title: GMTR: Graph Matching Transformers ",
    "url": "https://arxiv.org/abs/2311.08141",
    "authors": [
      "Jinpei Guo",
      "Shaofeng Zhang",
      "Runzhong Wang",
      "Chang Liu",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.14388",
    "title": "A Parameterized Generative Adversarial Network Using Cyclic Projection  for Explainable Medical Image Classification",
    "abstract": " Comments: 5 pages, 4 figures. This work has been submitted to the IEEE ICASSP for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2311.14388",
    "authors": [
      "Xiangyu Xiong",
      "Yue Sun",
      "Xiaohong Liu",
      "Chan-Tong Lam",
      "Tong Tong",
      "Hao Chen",
      "Qinquan Gao",
      "Wei Ke",
      "Tao Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17516",
    "title": "MMA-Diffusion: MultiModal Attack on Diffusion Models",
    "abstract": " Title: MMA-Diffusion: MultiModal Attack on Diffusion Models ",
    "url": "https://arxiv.org/abs/2311.17516",
    "authors": [
      "Yijun Yang",
      "Ruiyuan Gao",
      "Xiaosen Wang",
      "Tsung-Yi Ho",
      "Nan Xu",
      "Qiang Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00265",
    "title": "RoboSync: Efficient Real-Time Operating System for Social Robots with  Customizable Behaviour",
    "abstract": " Title: RoboSync: Efficient Real-Time Operating System for Social Robots with  Customizable Behaviour ",
    "url": "https://arxiv.org/abs/2312.00265",
    "authors": [
      "Cheng Tang",
      "Yijing Feng",
      "Yue Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.01397",
    "title": "Visual Prompting Upgrades Neural Network Sparsification: A Data-Model  Perspective",
    "abstract": " Title: Visual Prompting Upgrades Neural Network Sparsification: A Data-Model  Perspective ",
    "url": "https://arxiv.org/abs/2312.01397",
    "authors": [
      "Can Jin",
      "Tianjin Huang",
      "Yihua Zhang",
      "Mykola Pechenizkiy",
      "Sijia Liu",
      "Shiwei Liu",
      "Tianlong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01878",
    "title": "HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot  Prompt Learning",
    "abstract": " Comments: Accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2312.01878",
    "authors": [
      "Xingtong Yu",
      "Yuan Fang",
      "Zemin Liu",
      "Xinming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.03404",
    "title": "A Cyclical Route Linking Fundamental Mechanism and AI Algorithm: An  Example from Poisson's Ratio in Amorphous Networks",
    "abstract": " Comments: 15 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2312.03404",
    "authors": [
      "Changliang Zhu",
      "Chenchao Fang",
      "Zhipeng Jin",
      "Baowen Li",
      "Xiangying Shen",
      "Lei Xu"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.03731",
    "title": "MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2312.03731",
    "authors": [
      "Xingtong Yu",
      "Chang Zhou",
      "Yuan Fang",
      "Xinming Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06887",
    "title": "Understanding and Leveraging the Learning Phases of Neural Networks",
    "abstract": " Comments: Accepted at AAAI 2024. This is the extended version with all proofs and additional experiments ",
    "url": "https://arxiv.org/abs/2312.06887",
    "authors": [
      "Johannes Schneider",
      "Mohit Prabhushankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.07180",
    "title": "Context-Aware Iteration Policy Network for Efficient Optical Flow  Estimation",
    "abstract": " Comments: 2024, Association for the Advancement of Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2312.07180",
    "authors": [
      "Ri Cheng",
      "Ruian He",
      "Xuhao Jiang",
      "Shili Zhou",
      "Weimin Tan",
      "Bo Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.07871",
    "title": "MLNet: Mutual Learning Network with Neighborhood Invariance for  Universal Domain Adaptation",
    "abstract": " Comments: Accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2312.07871",
    "authors": [
      "Yanzuo Lu",
      "Meng Shen",
      "Andy J Ma",
      "Xiaohua Xie",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.07976",
    "title": "Challenges of YOLO Series for Object Detection in Extremely Heavy Rain:  CALRA Simulator based Synthetic Evaluation Dataset",
    "abstract": " Title: Challenges of YOLO Series for Object Detection in Extremely Heavy Rain:  CALRA Simulator based Synthetic Evaluation Dataset ",
    "url": "https://arxiv.org/abs/2312.07976",
    "authors": [
      "T. Kim",
      "H. Jeon",
      "Y. Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08009",
    "title": "Semi-Supervised Class-Agnostic Motion Prediction with Pseudo Label  Regeneration and BEVMix",
    "abstract": " Comments: This paper is accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2312.08009",
    "authors": [
      "Kewei Wang",
      "Yizheng Wu",
      "Zhiyu Pan",
      "Xingyi Li",
      "Ke Xian",
      "Zhe Wang",
      "Zhiguo Cao",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08140",
    "title": "GVE-LPA: Fast Label Propagation Algorithm (LPA) for Community Detection  in Shared Memory Setting",
    "abstract": " Comments: 7 pages, 7 figures, 1 table. arXiv admin note: text overlap with arXiv:2312.04876 ",
    "url": "https://arxiv.org/abs/2312.08140",
    "authors": [
      "Subhajit Sahu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  }
]