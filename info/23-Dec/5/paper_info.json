[
  {
    "id": "arXiv:2312.00795",
    "title": "Talent-Interview: Web-Client Cheating Detection for Online Exams",
    "abstract": "Online exams are more attractive after the Covid-19 pandemic. Furthermore, during recruitment, online exams are used. However, there are more cheating possibilities for online exams. Assigning a proctor for each exam increases cost. At this point, automatic proctor systems detect possible cheating status. This article proposes an end-to-end system and submodules to get better results for online proctoring. Object detection, face recognition, human voice detection, and segmentation are used in our system. Furthermore, our proposed model works on the PCs of users, meaning a client-based system. So, server cost is eliminated. As far as we know, it is the first time the client-based online proctoring system has been used for recruitment. Online exams are more attractive after the Covid-19 pandemic. Furthermore, during recruitment, online exams are used. However, there are more cheating possibilities for online exams. Assigning a proctor for each exam increases cost. At this point, automatic proctor systems detect possible cheating status. This article proposes an end-to-end system and submodules to get better results for online proctoring. Object detection, face recognition, human voice detection, and segmentation are used in our system. Furthermore, our proposed model works on the PCs of users, meaning a client-based system. So, server cost is eliminated. As far as we know, it is the first time the client-based online proctoring system has been used for recruitment. Furthermore, this cheating system works at https://www.talent-interview.com/tr/. ",
    "url": "https://arxiv.org/abs/2312.00795",
    "authors": [
      "Mert Ege",
      "Mustafa Ceyhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.00804",
    "title": "Automatic detection of problem-gambling signs from online texts using  large language models",
    "abstract": "Problem gambling is a major public health concern and is associated with profound psychological distress and economic problems. There are numerous gambling communities on the internet where users exchange information about games, gambling tactics, as well as gambling-related problems. Individuals exhibiting higher levels of problem gambling engage more in such communities. Online gambling communities may provide insights into problem-gambling behaviour. Using data scraped from a major German gambling discussion board, we fine-tuned a large language model, specifically a Bidirectional Encoder Representations from Transformers (BERT) model, to predict signs of problem-gambling from forum posts. Training data were generated by manual annotation and by taking into account diagnostic criteria and gambling-related cognitive distortions. Using k-fold cross-validation, our models achieved a precision of 0.95 and F1 score of 0.71, demonstrating that satisfactory classification performance can be achieved by generating high-quality training material through manual annotation based on diagnostic criteria. The current study confirms that a BERT-based model can be reliably used on small data sets and to detect signatures of problem gambling in online communication data. Such computational approaches may have potential for the detection of changes in problem-gambling prevalence among online users. ",
    "url": "https://arxiv.org/abs/2312.00804",
    "authors": [
      "Elke Smith",
      "Nils Reiter",
      "Jan Peters"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00817",
    "title": "TimelyGPT: Recurrent Convolutional Transformer for Long Time-series  Representation",
    "abstract": "Pre-trained models (PTMs) have gained prominence in Natural Language Processing and Computer Vision domains. When it comes to time-series PTMs, their development has been limited. Previous research on time-series transformers has mainly been devoted to small-scale tasks, yet these models have not consistently outperformed traditional models. Additionally, the performance of these transformers on large-scale data remains unexplored. These findings raise doubts about Transformer's capabilities to scale up and capture temporal dependencies. In this study, we re-examine time-series transformers and identify the shortcomings of prior studies. Drawing from these insights, we then introduce a pioneering architecture called Timely Generative Pre-trained Transformer (\\model). This architecture integrates recurrent attention and temporal convolution modules to effectively capture global-local temporal dependencies in long sequences. The relative position embedding with time decay can effectively deal with trend and periodic patterns from time-series. Our experiments show that \\model~excels in modeling continuously monitored biosignal as well as irregularly-sampled time-series data commonly observed in longitudinal electronic health records. This breakthrough suggests a priority shift in time-series deep learning research, moving from small-scale modeling from scratch to large-scale pre-training. ",
    "url": "https://arxiv.org/abs/2312.00817",
    "authors": [
      "Ziyang Song",
      "Qincheng Lu",
      "Hao Xu",
      "Yue Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00819",
    "title": "Large Language Models for Travel Behavior Prediction",
    "abstract": "Travel behavior prediction is a fundamental task in transportation demand management. The conventional methods for travel behavior prediction rely on numerical data to construct mathematical models and calibrate model parameters to represent human preferences. Recent advancement in large language models (LLMs) has shown great reasoning abilities to solve complex problems. In this study, we propose to use LLMs to predict travel behavior with prompt engineering without data-based parameter learning. Specifically, we carefully design our prompts that include 1) task description, 2) travel characteristics, 3) individual attributes, and 4) guides of thinking with domain knowledge, and ask the LLMs to predict an individual's travel behavior and explain the results. We select the travel mode choice task as a case study. Results show that, though no training samples are provided, LLM-based predictions have competitive accuracy and F1-score as canonical supervised learning methods such as multinomial logit, random forest, and neural networks. LLMs can also output reasons that support their prediction. However, though in most of the cases, the output explanations are reasonable, we still observe cases that violate logic or with hallucinations. ",
    "url": "https://arxiv.org/abs/2312.00819",
    "authors": [
      "Baichuan Mo",
      "Hanyong Xu",
      "Dingyi Zhuang",
      "Ruoyun Ma",
      "Xiaotong Guo",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00824",
    "title": "Variational Self-Supervised Contrastive Learning Using Beta Divergence",
    "abstract": "Learning a discriminative semantic space using unlabelled and noisy data remains unaddressed in a multi-label setting. We present a contrastive self-supervised learning method which is robust to data noise, grounded in the domain of variational methods. The method (VCL) utilizes variational contrastive learning with beta-divergence to learn robustly from unlabelled datasets, including uncurated and noisy datasets. We demonstrate the effectiveness of the proposed method through rigorous experiments including linear evaluation and fine-tuning scenarios with multi-label datasets in the face understanding domain. In almost all tested scenarios, VCL surpasses the performance of state-of-the-art self-supervised methods, achieving a noteworthy increase in accuracy. ",
    "url": "https://arxiv.org/abs/2312.00824",
    "authors": [
      "Mehmet Can Yavuz",
      "Berrin Yanikoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00825",
    "title": "Probing and Mitigating Intersectional Social Biases in Vision-Language  Models with Counterfactual Examples",
    "abstract": "While vision-language models (VLMs) have achieved remarkable performance improvements recently, there is growing evidence that these models also posses harmful biases with respect to social attributes such as gender and race. Prior studies have primarily focused on probing such bias attributes individually while ignoring biases associated with intersections between social attributes. This could be due to the difficulty of collecting an exhaustive set of image-text pairs for various combinations of social attributes. To address this challenge, we employ text-to-image diffusion models to produce counterfactual examples for probing intserctional social biases at scale. Our approach utilizes Stable Diffusion with cross attention control to produce sets of counterfactual image-text pairs that are highly similar in their depiction of a subject (e.g., a given occupation) while differing only in their depiction of intersectional social attributes (e.g., race & gender). Through our over-generate-then-filter methodology, we produce SocialCounterfactuals, a high-quality dataset containing over 171k image-text pairs for probing intersectional biases related to gender, race, and physical characteristics. We conduct extensive experiments to demonstrate the usefulness of our generated dataset for probing and mitigating intersectional social biases in state-of-the-art VLMs. ",
    "url": "https://arxiv.org/abs/2312.00825",
    "authors": [
      "Phillip Howard",
      "Avinash Madasu",
      "Tiep Le",
      "Gustavo Lujan Moreno",
      "Anahita Bhiwandiwalla",
      "Vasudev Lal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00827",
    "title": "A Unified Framework for Connecting Noise Modeling to Boost Noise  Detection",
    "abstract": "Noisy labels can impair model performance, making the study of learning with noisy labels an important topic. Two conventional approaches are noise modeling and noise detection. However, these two methods are typically studied independently, and there has been limited work on their collaboration. In this work, we explore the integration of these two approaches, proposing an interconnected structure with three crucial blocks: noise modeling, source knowledge identification, and enhanced noise detection using noise source-knowledge-integration methods. This collaboration structure offers advantages such as discriminating hard negatives and preserving genuinely clean labels that might be suspiciously noisy. Our experiments on four datasets, featuring three types of noise and different combinations of each block, demonstrate the efficacy of these components' collaboration. Our collaborative structure methods achieve up to a 10% increase in top-1 classification accuracy in synthesized noise datasets and 3-5% in real-world noisy datasets. The results also suggest that these components make distinct contributions to overall performance across various noise scenarios. These findings provide valuable insights for designing noisy label learning methods customized for specific noise scenarios in the future. Our code is accessible to the public. ",
    "url": "https://arxiv.org/abs/2312.00827",
    "authors": [
      "Siqi Wang",
      "Chau Pham",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00839",
    "title": "PipeOptim: Ensuring Effective 1F1B Schedule with Optimizer-Dependent  Weight Prediction",
    "abstract": "Asynchronous pipeline model parallelism with a \"1F1B\" (one forward, one backward) schedule generates little bubble overhead and always provides quite a high throughput. However, the \"1F1B\" schedule inevitably leads to weight inconsistency and weight staleness issues due to the cross-training of different mini-batches across GPUs. To simultaneously address these two problems, in this paper, we propose an optimizer-dependent weight prediction strategy (a.k.a PipeOptim) for asynchronous pipeline training. The key insight of our proposal is that we employ a weight prediction strategy in the forward pass to ensure that each mini-batch uses consistent and staleness-free weights to compute the forward pass. To be concrete, we first construct the weight prediction scheme based on the update rule of the used optimizer when training the deep neural network models. Then throughout the \"1F1B\" pipelined training, each mini-batch is mandated to execute weight prediction ahead of the forward pass, subsequently employing the predicted weights to perform the forward pass. As a result, PipeOptim 1) inherits the advantage of the \"1F1B\" schedule and generates pretty high throughput, and 2) can ensure effective parameter learning regardless of the type of the used optimizer. To verify the effectiveness of our proposal, we conducted extensive experimental evaluations using eight different deep-learning models spanning three machine-learning tasks including image classification, sentiment analysis, and machine translation. The experiment results demonstrate that PipeOptim outperforms the popular pipelined approaches including GPipe, PipeDream, PipeDream-2BW, and SpecTrain. The code of PipeOptim will be accessible at https://github.com/guanleics/PipeOptim. ",
    "url": "https://arxiv.org/abs/2312.00839",
    "authors": [
      "Lei Guan",
      "Dongsheng Li",
      "Jiye Liang",
      "Wenjian Wang",
      "Xicheng Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00843",
    "title": "Exploring the Robustness of Decentralized Training for Large Language  Models",
    "abstract": "Decentralized training of large language models has emerged as an effective way to democratize this technology. However, the potential threats associated with this approach have not been carefully discussed, which would hinder the development of decentralized training infrastructures. This paper aims to initiate discussion towards this end by exploring the robustness of decentralized training from three main perspectives. First, we demonstrate the vulnerabilities inherent in decentralized training frameworks in terms of hardware, data, and models. Second, we highlight the fundamental difference between decentralized foundation model training and vanilla federated learning, where the security techniques employed in federated learning cannot be applied directly. Third, we discuss the essential components required for a robust and efficient decentralized training framework and present a case study by modeling a concrete threat model. Our objective in this vision paper is to emphasize the importance of addressing security concerns in the context of decentralized training for large language models. ",
    "url": "https://arxiv.org/abs/2312.00843",
    "authors": [
      "Lin Lu",
      "Chenxi Dai",
      "Wangcheng Tao",
      "Binhang Yuan",
      "Yanan Sun",
      "Pan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00846",
    "title": "NeuSG: Neural Implicit Surface Reconstruction with 3D Gaussian Splatting  Guidance",
    "abstract": "Existing neural implicit surface reconstruction methods have achieved impressive performance in multi-view 3D reconstruction by leveraging explicit geometry priors such as depth maps or point clouds as regularization. However, the reconstruction results still lack fine details because of the over-smoothed depth map or sparse point cloud. In this work, we propose a neural implicit surface reconstruction pipeline with guidance from 3D Gaussian Splatting to recover highly detailed surfaces. The advantage of 3D Gaussian Splatting is that it can generate dense point clouds with detailed structure. Nonetheless, a naive adoption of 3D Gaussian Splatting can fail since the generated points are the centers of 3D Gaussians that do not necessarily lie on the surface. We thus introduce a scale regularizer to pull the centers close to the surface by enforcing the 3D Gaussians to be extremely thin. Moreover, we propose to refine the point cloud from 3D Gaussians Splatting with the normal priors from the surface predicted by neural implicit models instead of using a fixed set of points as guidance. Consequently, the quality of surface reconstruction improves from the guidance of the more accurate 3D Gaussian splatting. By jointly optimizing the 3D Gaussian Splatting and the neural implicit model, our approach benefits from both representations and generates complete surfaces with intricate details. Experiments on Tanks and Temples verify the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2312.00846",
    "authors": [
      "Hanlin Chen",
      "Chen Li",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00874",
    "title": "Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs  in Language Pretraining",
    "abstract": "The knowledge graph is a structure to store and represent knowledge, and recent studies have discussed its capability to assist language models for various applications. Some variations of knowledge graphs aim to record arguments and their relations for computational argumentation tasks. However, many must simplify semantic types to fit specific schemas, thus losing flexibility and expression ability. In this paper, we propose the Hierarchical Argumentation Graph (Hi-ArG), a new structure to organize arguments. We also introduce two approaches to exploit Hi-ArG, including a text-graph multi-modal model GreaseArG and a new pre-training framework augmented with graph information. Experiments on two argumentation tasks have shown that after further pre-training and fine-tuning, GreaseArG supersedes same-scale language models on these tasks, while incorporating graph information during further pre-training can also improve the performance of vanilla language models. Code for this paper is available at https://github.com/ljcleo/Hi-ArG . ",
    "url": "https://arxiv.org/abs/2312.00874",
    "authors": [
      "Jingcong Liang",
      "Rong Ye",
      "Meng Han",
      "Qi Zhang",
      "Ruofei Lai",
      "Xinyu Zhang",
      "Zhao Cao",
      "Xuanjing Huang",
      "Zhongyu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00907",
    "title": "Extreme Event Prediction with Multi-agent Reinforcement Learning-based  Parametrization of Atmospheric and Oceanic Turbulence",
    "abstract": "Global climate models (GCMs) are the main tools for understanding and predicting climate change. However, due to limited numerical resolutions, these models suffer from major structural uncertainties; e.g., they cannot resolve critical processes such as small-scale eddies in atmospheric and oceanic turbulence. Thus, such small-scale processes have to be represented as a function of the resolved scales via closures (parametrization). The accuracy of these closures is particularly important for capturing climate extremes. Traditionally, such closures are based on heuristics and simplifying assumptions about the unresolved physics. Recently, supervised-learned closures, trained offline on high-fidelity data, have been shown to outperform the classical physics-based closures. However, this approach requires a significant amount of high-fidelity training data and can also lead to instabilities. Reinforcement learning is emerging as a potent alternative for developing such closures as it requires only low-order statistics and leads to stable closures. In Scientific Multi-Agent Reinforcement Learning (SMARL) computational elements serve a dual role of discretization points and learning agents. We leverage SMARL and fundamentals of turbulence physics to learn closures for prototypes of atmospheric and oceanic turbulence. The policy is trained using only the enstrophy spectrum, which is nearly invariant and can be estimated from a few high-fidelity samples (these few samples are far from enough for supervised/offline learning). We show that these closures lead to stable low-resolution simulations that, at a fraction of the cost, can reproduce the high-fidelity simulations' statistics, including the tails of the probability density functions. The results demonstrate the high potential of SMARL for closure modeling for GCMs, especially in the regime of scarce data and indirect observations. ",
    "url": "https://arxiv.org/abs/2312.00907",
    "authors": [
      "Rambod Mojgani",
      "Daniel Waelchli",
      "Yifei Guan",
      "Petros Koumoutsakos",
      "Pedram Hassanzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2312.00918",
    "title": "PACE: A Program Analysis Framework for Continuous Performance Prediction",
    "abstract": "Software development teams establish elaborate continuous integration pipelines containing automated test cases to accelerate the development process of software. Automated tests help to verify the correctness of code modifications decreasing the response time to changing requirements. However, when the software teams do not track the performance impact of pending modifications, they may need to spend considerable time refactoring existing code. This paper presents PACE, a program analysis framework that provides continuous feedback on the performance impact of pending code updates. We design performance microbenchmarks by mapping the execution time of functional test cases given a code update. We map microbenchmarks to code stylometry features and feed them to predictors for performance predictions. Our experiments achieved significant performance in predicting code performance, outperforming current state-of-the-art by 75% on neural-represented code stylometry features. ",
    "url": "https://arxiv.org/abs/2312.00918",
    "authors": [
      "Chidera Biringa",
      "Gokhan Kul"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2312.00933",
    "title": "Privacy Preserving Event Detection",
    "abstract": "This paper presents a privacy-preserving event detection scheme based on measurements made by a network of sensors. A diameter-like decision statistic made up of the marginal types of the measurements observed by the sensors is employed. The proposed detection scheme can achieve the best type-I error exponent as the type-II error rate is required to be negligible. Detection performance with finite-length observations is also demonstrated through a simulation example of spectrum sensing. Privacy protection is achieved by obfuscating the type data with random zero-modulo-sum numbers that are generated and distributed via the exchange of encrypted messages among the sensors. The privacy-preserving performance against ``honest but curious'' adversaries, including colluding sensors, the fusion center, and external eavesdroppers, is analyzed through a series of cryptographic games. It is shown that the probability that any probabilistic polynomial time adversary successfully estimates the sensors' measured types can not be much better than independent guessing, when there are at least two non-colluding sensors. ",
    "url": "https://arxiv.org/abs/2312.00933",
    "authors": [
      "Xiaoshan Wang",
      "Tan F. Wong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2312.00950",
    "title": "Improve Supervised Representation Learning with Masked Image Modeling",
    "abstract": "Training visual embeddings with labeled data supervision has been the de facto setup for representation learning in computer vision. Inspired by recent success of adopting masked image modeling (MIM) in self-supervised representation learning, we propose a simple yet effective setup that can easily integrate MIM into existing supervised training paradigms. In our design, in addition to the original classification task applied to a vision transformer image encoder, we add a shallow transformer-based decoder on top of the encoder and introduce an MIM task which tries to reconstruct image tokens based on masked image inputs. We show with minimal change in architecture and no overhead in inference that this setup is able to improve the quality of the learned representations for downstream tasks such as classification, image retrieval, and semantic segmentation. We conduct a comprehensive study and evaluation of our setup on public benchmarks. On ImageNet-1k, our ViT-B/14 model achieves 81.72% validation accuracy, 2.01% higher than the baseline model. On K-Nearest-Neighbor image retrieval evaluation with ImageNet-1k, the same model outperforms the baseline by 1.32%. We also show that this setup can be easily scaled to larger models and datasets. Code and checkpoints will be released. ",
    "url": "https://arxiv.org/abs/2312.00950",
    "authors": [
      "Kaifeng Chen",
      "Daniel Salz",
      "Huiwen Chang",
      "Kihyuk Sohn",
      "Dilip Krishnan",
      "Mojtaba Seyedhosseini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00978",
    "title": "Combining Kernelized Autoencoding and Centroid Prediction for Dynamic  Multi-objective Optimization",
    "abstract": "Evolutionary algorithms face significant challenges when dealing with dynamic multi-objective optimization because Pareto optimal solutions and/or Pareto optimal fronts change. This paper proposes a unified paradigm, which combines the kernelized autoncoding evolutionary search and the centriod-based prediction (denoted by KAEP), for solving dynamic multi-objective optimization problems (DMOPs). Specifically, whenever a change is detected, KAEP reacts effectively to it by generating two subpopulations. The first subpoulation is generated by a simple centriod-based prediction strategy. For the second initial subpopulation, the kernel autoencoder is derived to predict the moving of the Pareto-optimal solutions based on the historical elite solutions. In this way, an initial population is predicted by the proposed combination strategies with good convergence and diversity, which can be effective for solving DMOPs. The performance of our proposed method is compared with five state-of-the-art algorithms on a number of complex benchmark problems. Empirical results fully demonstrate the superiority of our proposed method on most test instances. ",
    "url": "https://arxiv.org/abs/2312.00978",
    "authors": [
      "Zhanglu Hou",
      "Juan Zou",
      "Gan Ruan",
      "Yuan Liu",
      "Yizhang Xia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.00987",
    "title": "Deep Generative Attacks and Countermeasures for Data-Driven Offline  Signature Verification",
    "abstract": "While previous studies have explored attacks via random, simple, and skilled forgeries, generative attacks have received limited attention in the data-driven signature verification (DASV) process. Thus, this paper explores the impact of generative attacks on DASV and proposes practical and interpretable countermeasures. We investigate the power of two prominent Deep Generative Models (DGMs), Variational Auto-encoders (VAE) and Conditional Generative Adversarial Networks (CGAN), on their ability to generate signatures that would successfully deceive DASV. Additionally, we evaluate the quality of generated images using the Structural Similarity Index measure (SSIM) and use the same to explain the attack's success. Finally, we propose countermeasures that effectively reduce the impact of deep generative attacks on DASV. We first generated six synthetic datasets from three benchmark offline-signature datasets viz. CEDAR, BHSig260- Bengali, and BHSig260-Hindi using VAE and CGAN. Then, we built baseline DASVs using Xception, ResNet152V2, and DenseNet201. These DASVs achieved average (over the three datasets) False Accept Rates (FARs) of 2.55%, 3.17%, and 1.06%, respectively. Then, we attacked these baselines using the synthetic datasets. The VAE-generated signatures increased average FARs to 10.4%, 10.1%, and 7.5%, while CGAN-generated signatures to 32.5%, 30%, and 26.1%. The variation in the effectiveness of attack for VAE and CGAN was investigated further and explained by a strong (rho = -0.86) negative correlation between FARs and SSIMs. We created another set of synthetic datasets and used the same to retrain the DASVs. The retained baseline showed significant robustness to random, skilled, and generative attacks as the FARs shrank to less than 1% on average. The findings underscore the importance of studying generative attacks and potential countermeasures for DASV. ",
    "url": "https://arxiv.org/abs/2312.00987",
    "authors": [
      "An Ngo",
      "MinhPhuong Cao",
      "Rajesh Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.00989",
    "title": "Scrappy: SeCure Rate Assuring Protocol with PrivacY",
    "abstract": "Preventing abusive activities caused by adversaries accessing online services at a rate exceeding that expected by websites has become an ever-increasing problem. CAPTCHAs and SMS authentication are widely used to provide a solution by implementing rate limiting, although they are becoming less effective, and some are considered privacy-invasive. In light of this, many studies have proposed better rate-limiting systems that protect the privacy of legitimate users while blocking malicious actors. However, they suffer from one or more shortcomings: (1) assume trust in the underlying hardware and (2) are vulnerable to side-channel attacks. Motivated by the aforementioned issues, this paper proposes Scrappy: SeCure Rate Assuring Protocol with PrivacY. Scrappy allows clients to generate unforgeable yet unlinkable rate-assuring proofs, which provides the server with cryptographic guarantees that the client is not misbehaving. We design Scrappy using a combination of DAA and hardware security devices. Scrappy is implemented over three types of devices, including one that can immediately be deployed in the real world. Our baseline evaluation shows that the end-to-end latency of Scrappy is minimal, taking only 0.32 seconds, and uses only 679 bytes of bandwidth when transferring necessary data. We also conduct an extensive security evaluation, showing that the rate-limiting capability of Scrappy is unaffected even if the hardware security device is compromised. ",
    "url": "https://arxiv.org/abs/2312.00989",
    "authors": [
      "Kosei Akama",
      "Yoshimichi Nakatsuka",
      "Masaaki Sato",
      "Keisuke Uehara"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.01001",
    "title": "Learning county from pixels: Corn yield prediction with  attention-weighted multiple instance learning",
    "abstract": "Remote sensing technology has become a promising tool in yield prediction. Most prior work employs satellite imagery for county-level corn yield prediction by spatially aggregating all pixels within a county into a single value, potentially overlooking the detailed information and valuable insights offered by more granular data. To this end, this research examines each county at the pixel level and applies multiple instance learning to leverage detailed information within a county. In addition, our method addresses the \"mixed pixel\" issue caused by the inconsistent resolution between feature datasets and crop mask, which may introduce noise into the model and therefore hinder accurate yield prediction. Specifically, the attention mechanism is employed to automatically assign weights to different pixels, which can mitigate the influence of mixed pixels. The experimental results show that the developed model outperforms four other machine learning models over the past five years in the U.S. corn belt and demonstrates its best performance in 2022, achieving a coefficient of determination (R2) value of 0.84 and a root mean square error (RMSE) of 0.83. This paper demonstrates the advantages of our approach from both spatial and temporal perspectives. Furthermore, through an in-depth study of the relationship between mixed pixels and attention, it is verified that our approach can capture critical feature information while filtering out noise from mixed pixels. ",
    "url": "https://arxiv.org/abs/2312.01001",
    "authors": [
      "Xiaoyu Wang",
      "Yuchi Ma",
      "Qunying Huang",
      "Zhengwei Yang",
      "Zhou Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01003",
    "title": "Self-Evolving Neural Radiance Fields",
    "abstract": "Recently, neural radiance field (NeRF) has shown remarkable performance in novel view synthesis and 3D reconstruction. However, it still requires abundant high-quality images, limiting its applicability in real-world scenarios. To overcome this limitation, recent works have focused on training NeRF only with sparse viewpoints by giving additional regularizations, often called few-shot NeRF. We observe that due to the under-constrained nature of the task, solely using additional regularization is not enough to prevent the model from overfitting to sparse viewpoints. In this paper, we propose a novel framework, dubbed Self-Evolving Neural Radiance Fields (SE-NeRF), that applies a self-training framework to NeRF to address these problems. We formulate few-shot NeRF into a teacher-student framework to guide the network to learn a more robust representation of the scene by training the student with additional pseudo labels generated from the teacher. By distilling ray-level pseudo labels using distinct distillation schemes for reliable and unreliable rays obtained with our novel reliability estimation method, we enable NeRF to learn a more accurate and robust geometry of the 3D scene. We show and evaluate that applying our self-training framework to existing models improves the quality of the rendered images and achieves state-of-the-art performance in multiple settings. ",
    "url": "https://arxiv.org/abs/2312.01003",
    "authors": [
      "Jaewoo Jung",
      "Jisang Han",
      "Jiwon Kang",
      "Seongchan Kim",
      "Min-Seop Kwak",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01006",
    "title": "Dual-Teacher De-biasing Distillation Framework for Multi-domain Fake  News Detection",
    "abstract": "Multi-domain fake news detection aims to identify whether various news from different domains is real or fake and has become urgent and important. However, existing methods are dedicated to improving the overall performance of fake news detection, ignoring the fact that unbalanced data leads to disparate treatment for different domains, i.e., the domain bias problem. To solve this problem, we propose the Dual-Teacher De-biasing Distillation framework (DTDBD) to mitigate bias across different domains. Following the knowledge distillation methods, DTDBD adopts a teacher-student structure, where pre-trained large teachers instruct a student model. In particular, the DTDBD consists of an unbiased teacher and a clean teacher that jointly guide the student model in mitigating domain bias and maintaining performance. For the unbiased teacher, we introduce an adversarial de-biasing distillation loss to instruct the student model in learning unbiased domain knowledge. For the clean teacher, we design domain knowledge distillation loss, which effectively incentivizes the student model to focus on representing domain features while maintaining performance. Moreover, we present a momentum-based dynamic adjustment algorithm to trade off the effects of two teachers. Extensive experiments on Chinese and English datasets show that the proposed method substantially outperforms the state-of-the-art baseline methods in terms of bias metrics while guaranteeing competitive performance. ",
    "url": "https://arxiv.org/abs/2312.01006",
    "authors": [
      "Jiayang Li",
      "Xuan Feng",
      "Tianlong Gu",
      "Liang Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.01022",
    "title": "Advanced Language Model-Driven Verilog Development: Enhancing Power,  Performance, and Area Optimization in Code Synthesis",
    "abstract": "The increasing use of Advanced Language Models (ALMs) in diverse sectors, particularly due to their impressive capability to generate top-tier content following linguistic instructions, forms the core of this investigation. This study probes into ALMs' deployment in electronic hardware design, with a specific emphasis on the synthesis and enhancement of Verilog programming. We introduce an innovative framework, crafted to assess and amplify ALMs' productivity in this niche. The methodology commences with the initial crafting of Verilog programming via ALMs, succeeded by a distinct dual-stage refinement protocol. The premier stage prioritizes augmenting the code's operational and linguistic precision, while the latter stage is dedicated to aligning the code with Power-Performance-Area (PPA) benchmarks, a pivotal component in proficient hardware design. This bifurcated strategy, merging error remediation with PPA enhancement, has yielded substantial upgrades in the caliber of ALM-created Verilog programming. Our framework achieves an 81.37% rate in linguistic accuracy and 62.0% in operational efficacy in programming synthesis, surpassing current leading-edge techniques, such as 73% in linguistic accuracy and 46% in operational efficacy. These findings illuminate ALMs' aptitude in tackling complex technical domains and signal a positive shift in the mechanization of hardware design operations. ",
    "url": "https://arxiv.org/abs/2312.01022",
    "authors": [
      "Kiran Thorat",
      "Jiahui Zhao",
      "Yaotian Liu",
      "Hongwu Peng",
      "Xi Xie",
      "Bin Lei",
      "Jeff Zhang",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01024",
    "title": "Hybrid Quantum Neural Network in High-dimensional Data Classification",
    "abstract": "The research explores the potential of quantum deep learning models to address challenging machine learning problems that classical deep learning models find difficult to tackle. We introduce a novel model architecture that combines classical convolutional layers with a quantum neural network, aiming to surpass state-of-the-art accuracy while maintaining a compact model size. The experiment is to classify high-dimensional audio data from the Bird-CLEF 2021 dataset. Our evaluation focuses on key metrics, including training duration, model accuracy, and total model size. This research demonstrates the promising potential of quantum machine learning in enhancing machine learning tasks and solving practical machine learning challenges available today. ",
    "url": "https://arxiv.org/abs/2312.01024",
    "authors": [
      "Hao-Yuan Chen",
      "Yen-Jui Chang",
      "Shih-Wei Liao",
      "Ching-Ray Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2312.01029",
    "title": "RNN-BOF: A Multivariate Global Recurrent Neural Network for Binary  Outcome Forecasting of Inpatient Aggression",
    "abstract": "Psychometric assessment instruments aid clinicians by providing methods of assessing the future risk of adverse events such as aggression. Existing machine learning approaches have treated this as a classification problem, predicting the probability of an adverse event in a fixed future time period from the scores produced by both psychometric instruments and clinical and demographic covariates. We instead propose modelling a patient's future risk using a time series methodology that learns from longitudinal data and produces a probabilistic binary forecast that indicates the presence of the adverse event in the next time period. Based on the recent success of Deep Neural Nets for globally forecasting across many time series, we introduce a global multivariate Recurrent Neural Network for Binary Outcome Forecasting, that trains from and for a population of patient time series to produce individual probabilistic risk assessments. We use a moving window training scheme on a real world dataset of 83 patients, where the main binary time series represents the presence of aggressive events and covariate time series represent clinical or demographic features and psychometric measures. On this dataset our approach was capable of a significant performance increase against both benchmark psychometric instruments and previously used machine learning methodologies. ",
    "url": "https://arxiv.org/abs/2312.01029",
    "authors": [
      "Aidan Quinn",
      "Melanie Simmons",
      "Benjamin Spivak",
      "Christoph Bergmeir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01045",
    "title": "PROFL: A Privacy-Preserving Federated Learning Method with Stringent  Defense Against Poisoning Attacks",
    "abstract": "Federated Learning (FL) faces two major issues: privacy leakage and poisoning attacks, which may seriously undermine the reliability and security of the system. Overcoming them simultaneously poses a great challenge. This is because privacy protection policies prohibit access to users' local gradients to avoid privacy leakage, while Byzantine-robust methods necessitate access to these gradients to defend against poisoning attacks. To address these problems, we propose a novel privacy-preserving Byzantine-robust FL framework PROFL. PROFL is based on the two-trapdoor additional homomorphic encryption algorithm and blinding techniques to ensure the data privacy of the entire FL process. During the defense process, PROFL first utilize secure Multi-Krum algorithm to remove malicious gradients at the user level. Then, according to the Pauta criterion, we innovatively propose a statistic-based privacy-preserving defense algorithm to eliminate outlier interference at the feature level and resist impersonation poisoning attacks with stronger concealment. Detailed theoretical analysis proves the security and efficiency of the proposed method. We conducted extensive experiments on two benchmark datasets, and PROFL improved accuracy by 39% to 75% across different attack settings compared to similar privacy-preserving robust methods, demonstrating its significant advantage in robustness. ",
    "url": "https://arxiv.org/abs/2312.01045",
    "authors": [
      "Yisheng Zhong",
      "Li-Ping Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01049",
    "title": "Joint User Association and Resource Allocation for Multi-Cell Networks  with Adaptive Semantic Communication",
    "abstract": "Semantic communication is a promising communication paradigm that utilizes Deep Neural Networks (DNNs) to extract the information relevant to downstream tasks, hence significantly reducing the amount of transmitted data. In current practice, the semantic communication transmitter for a specific task is typically pre-trained and shared by all users. However, due to user heterogeneity, it is desirable to use different transmitters according to the available computational and communication resources of users. In this paper, we first show that it is possible to dynamically adjust the computational and communication overhead of DNN-based transmitters, thereby achieving adaptive semantic communication. After that, we investigate the user association and resource allocation problem in a multi-cell network where users are equipped with adaptive semantic communication transmitters. To solve this problem, we decompose it into three subproblems involving the scheduling of each user, the resource allocation of each base station (BS), and the user association between users and BSs. Then we solve each problem progressively based on the solution of the previous subproblem. The final algorithm can obtain near-optimal solutions in polynomial time. Numerical results show that our algorithm outperforms benchmarks under various situations. ",
    "url": "https://arxiv.org/abs/2312.01049",
    "authors": [
      "Xingqiu He",
      "Chaoqun You",
      "Tony Q.S. Quek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.01050",
    "title": "Detection and Analysis of Stress-Related Posts in Reddit Acamedic  Communities",
    "abstract": "Nowadays, the significance of monitoring stress levels and recognizing early signs of mental illness cannot be overstated. Automatic stress detection in text can proactively help manage stress and protect mental well-being. In today's digital era, social media platforms reflect the psychological well-being and stress levels within various communities. This study focuses on detecting and analyzing stress-related posts in Reddit academic communities. Due to online education and remote work, these communities have become central for academic discussions and support. We classify text as stressed or not using natural language processing and machine learning classifiers, with Dreaddit as our training dataset, which contains labeled data from Reddit. Next, we collect and analyze posts from various academic subreddits. We identified that the most effective individual feature for stress detection is the Bag of Words, paired with the Logistic Regression classifier, achieving a 77.78% accuracy rate and an F1 score of 0.79 on the DReaddit dataset. This combination also performs best in stress detection on human-annotated datasets, with a 72% accuracy rate. Our key findings reveal that posts and comments in professors Reddit communities are the most stressful, compared to other academic levels, including bachelor, graduate, and Ph.D. students. This research contributes to our understanding of the stress levels within academic communities. It can help academic institutions and online communities develop measures and interventions to address this issue effectively. ",
    "url": "https://arxiv.org/abs/2312.01050",
    "authors": [
      "Nazzere Oryngozha",
      "Pakizar Shamoi",
      "Ayan Igali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.01052",
    "title": "Structured, Complex and Time-complete Temporal Event Forecasting",
    "abstract": "Temporal event forecasting aims to predict what will happen next given the observed events in history. Previous formulations of temporal event are unstructured, atomic, or lacking full temporal information, thus largely restricting the representation quality and forecasting ability of temporal events. To address these limitations, we introduce a novel formulation for Structured, Complex, and Time-complete Temporal Event (SCTc-TE). Based on this new formulation, we develop a simple and fully automated pipeline for constructing such SCTc-TEs from a large amount of news articles. Furthermore, we propose a novel model that leverages both Local and Global contexts for SCTc-TE forecasting, named LoGo. To evaluate our model, we construct two large-scale datasets named MidEast-TE and GDELT-TE. Extensive evaluations demonstrate the advantages of our datasets in multiple aspects, while experimental results justify the effectiveness of our forecasting model LoGo. We release the code and dataset via https://github.com/yecchen/GDELT-ComplexEvent. ",
    "url": "https://arxiv.org/abs/2312.01052",
    "authors": [
      "Yunshan Ma",
      "Chenchen Ye",
      "Zijian Wu",
      "Xiang Wang",
      "Yixin Cao",
      "Liang Pang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.01056",
    "title": "Investigating the Surrogate Modeling Capabilities of Continuous Time  Echo State Networks",
    "abstract": "Continuous Time Echo State Networks (CTESN) are a promising yet under-explored surrogate modeling technique for dynamical systems, particularly those governed by stiff Ordinary Differential Equations (ODEs). This paper critically investigates the effects of important hyper-parameters and algorithmic choices on the generalization capability of CTESN surrogates on two benchmark problems governed by Robertson's equations. The method is also used to parametrize the initial conditions of a system of ODEs that realistically model automobile collisions, solving them accurately up to 200 times faster than numerical ODE solvers. The results of this paper demonstrate the ability of CTESN surrogates to accurately predict sharp transients and highly nonlinear system responses, and their utility in speeding up the solution of stiff ODE systems, allowing for their use in diverse applications from accelerated design optimization to digital twins. ",
    "url": "https://arxiv.org/abs/2312.01056",
    "authors": [
      "Saakaar Bhatnagar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2312.01060",
    "title": "Spectrum-driven Mixed-frequency Network for Hyperspectral Salient Object  Detection",
    "abstract": "Hyperspectral salient object detection (HSOD) aims to detect spectrally salient objects in hyperspectral images (HSIs). However, existing methods inadequately utilize spectral information by either converting HSIs into false-color images or converging neural networks with clustering. We propose a novel approach that fully leverages the spectral characteristics by extracting two distinct frequency components from the spectrum: low-frequency Spectral Saliency and high-frequency Spectral Edge. The Spectral Saliency approximates the region of salient objects, while the Spectral Edge captures edge information of salient objects. These two complementary components, crucial for HSOD, are derived by computing from the inter-layer spectral angular distance of the Gaussian pyramid and the intra-neighborhood spectral angular gradients, respectively. To effectively utilize this dual-frequency information, we introduce a novel lightweight Spectrum-driven Mixed-frequency Network (SMN). SMN incorporates two parameter-free plug-and-play operators, namely Spectral Saliency Generator and Spectral Edge Operator, to extract the Spectral Saliency and Spectral Edge components from the input HSI independently. Subsequently, the Mixed-frequency Attention module, comprised of two frequency-dependent heads, intelligently combines the embedded features of edge and saliency information, resulting in a mixed-frequency feature representation. Furthermore, a saliency-edge-aware decoder progressively scales up the mixed-frequency feature while preserving rich detail and saliency information for accurate salient object prediction. Extensive experiments conducted on the HS-SOD benchmark and our custom dataset HSOD-BIT demonstrate that our SMN outperforms state-of-the-art methods regarding HSOD performance. Code and dataset will be available at https://github.com/laprf/SMN. ",
    "url": "https://arxiv.org/abs/2312.01060",
    "authors": [
      "Peifu Liu",
      "Tingfa Xu",
      "Huan Chen",
      "Shiyun Zhou",
      "Haolin Qin",
      "Jianan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01062",
    "title": "Acoustic Signal Analysis with Deep Neural Network for Detecting Fault  Diagnosis in Industrial Machines",
    "abstract": "Detecting machine malfunctions at an early stage is crucial for reducing interruptions in operational processes within industrial settings. Recently, the deep learning approach has started to be preferred for the detection of failures in machines. Deep learning provides an effective solution in fault detection processes thanks to automatic feature extraction. In this study, a deep learning-based system was designed to analyze the sound signals produced by industrial machines. Acoustic sound signals were converted into Mel spectrograms. For the purpose of classifying spectrogram images, the DenseNet-169 model, a deep learning architecture recognized for its effectiveness in image classification tasks, was used. The model was trained using the transfer learning method on the MIMII dataset including sounds from four types of industrial machines. The results showed that the proposed method reached an accuracy rate varying between 97.17% and 99.87% at different Sound Noise Rate levels. ",
    "url": "https://arxiv.org/abs/2312.01062",
    "authors": [
      "Mustafa Yurdakul",
      "Sakir Tasdemir"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01065",
    "title": "Scholarly Knowledge Graph Construction from Published Software Packages",
    "abstract": "The value of structured scholarly knowledge for research and society at large is well understood, but producing scholarly knowledge (i.e., knowledge traditionally published in articles) in structured form remains a challenge. We propose an approach for automatically extracting scholarly knowledge from published software packages by static analysis of their metadata and contents (scripts and data) and populating a scholarly knowledge graph with the extracted knowledge. Our approach is based on mining scientific software packages linked to article publications by extracting metadata and analyzing the Abstract Syntax Tree (AST) of the source code to obtain information about the used and produced data as well as operations performed on data. The resulting knowledge graph includes articles, software packages metadata, and computational techniques applied to input data utilized as materials in research work. The knowledge graph also includes the results reported as scholarly knowledge in articles. ",
    "url": "https://arxiv.org/abs/2312.01065",
    "authors": [
      "Muhammad Haris",
      "S\u00f6ren Auer",
      "Markus Stocker"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2312.01066",
    "title": "A Database System for State Management in Stateful Network Service  Function Chains [Vision]",
    "abstract": "Network Function Virtualization (NFV) heralds a transformative era in network function deployment, enabling the orchestration of Service Function Chains (SFCs) for delivering complex and dynamic network services. Yet, the development and sustenance of stateful SFCs remain challenging, with intricate demands for usability in SFC development, performance, and execution correctness. In this paper, we present DB4NFV, a database system designed to address these challenges. Central to DB4NFV is the integration of transactional semantics into the entire lifecycle of stateful SFC, a core idea that enhances all aspects of the system. This integration provides an intuitive and well-structured API, which greatly simplifies the development of stateful SFCs. Concurrently, transactional semantics facilitate the optimization of runtime performance by efficiently leveraging modern multicore architectures. Moreover, by encapsulating state operations as transactions, DB4NFV achieves robustness, even at the entire chain level, ensuring reliable operation across varying network conditions. Consequently, DB4NFV marks a substantial forward leap in NFV state management, leveraging transactional semantics to achieve a harmonious blend of usability, efficiency, and robustness, thus facilitating the effective deployment of stateful SFCs in contemporary network infrastructures. ",
    "url": "https://arxiv.org/abs/2312.01066",
    "authors": [
      "Zhonghao Yang",
      "Shuhao Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2312.01071",
    "title": "Hybrid Hierarchical DRL Enabled Resource Allocation for Secure  Transmission in Multi-IRS-Assisted Sensing-Enhanced Spectrum Sharing Networks",
    "abstract": "Secure communications are of paramount importance in spectrum sharing networks due to the allocation and sharing characteristics of spectrum resources. To further explore the potential of intelligent reflective surfaces (IRSs) in enhancing spectrum sharing and secure transmission performance, a multiple intelligent reflection surface (multi-IRS)-assisted sensing-enhanced wideband spectrum sharing network is investigated by considering physical layer security techniques. An intelligent resource allocation scheme based on double deep Q networks (D3QN) algorithm and soft Actor-Critic (SAC) algorithm is proposed to maximize the secure transmission rate of the secondary network by jointly optimizing IRS pairings, subchannel assignment, transmit beamforming of the secondary base station, reflection coefficients of IRSs and the sensing time. To tackle the sparse reward problem caused by a significant amount of reflection elements of multiple IRSs, the method of hierarchical reinforcement learning is exploited. An alternative optimization (AO)-based conventional mathematical scheme is introduced to verify the computational complexity advantage of our proposed intelligent scheme. Simulation results demonstrate the efficiency of our proposed intelligent scheme as well as the superiority of multi-IRS design in enhancing secrecy rate and spectrum utilization. It is shown that inappropriate deployment of IRSs can reduce the security performance with the presence of multiple eavesdroppers (Eves), and the arrangement of IRSs deserves further consideration. ",
    "url": "https://arxiv.org/abs/2312.01071",
    "authors": [
      "Lingyi Wang",
      "Wei Wu",
      "Fuhui Zhou",
      "Qihui Wu",
      "Octavia A. Dobre",
      "Tony Q.S. Quek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.01081",
    "title": "Adaptive Resource Allocation for Semantic Communication Networks",
    "abstract": "Semantic communication, recognized as a promising technology for future intelligent applications, has received widespread research attention. Despite the potential of semantic communication to enhance transmission reliability, especially in low signal-to-noise (SNR) environments, the critical issue of resource allocation and compatibility in the dynamic wireless environment remains largely unexplored. In this paper, we propose an adaptive semantic resource allocation paradigm with semantic-bit quantization (SBQ) compatibly for existing wireless communications, where the inaccurate environment perception introduced by the additional mapping relationship between semantic metrics and transmission metrics is solved. In order to investigate the performance of semantic communication networks, the quality of service for semantic communication (SC-QoS), including the semantic quantization efficiency (SQE) and transmission latency, is proposed for the first time. A problem of maximizing the overall effective SC-QoS is formulated by jointly optimizing the transmit beamforming of the base station, the bits for semantic representation, the subchannel assignment, and the bandwidth resource allocation. To address the non-convex formulated problem, an intelligent resource allocation scheme is proposed based on a hybrid deep reinforcement learning (DRL) algorithm, where the intelligent agent can perceive both semantic tasks and dynamic wireless environments. Simulation results demonstrate that our design can effectively combat semantic noise and achieve superior performance in wireless communications compared to several benchmark schemes. Furthermore, compared to mapping-guided paradigm based resource allocation schemes, our proposed adaptive scheme can achieve up to 13% performance improvement in terms of SC-QoS. ",
    "url": "https://arxiv.org/abs/2312.01081",
    "authors": [
      "Lingyi Wang",
      "Wei Wu",
      "Fuhui Zhou",
      "Zhaohui Yang",
      "Zhijin Qin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01085",
    "title": "RobustCalib: Robust Lidar-Camera Extrinsic Calibration with Consistency  Learning",
    "abstract": "Current traditional methods for LiDAR-camera extrinsics estimation depend on offline targets and human efforts, while learning-based approaches resort to iterative refinement for calibration results, posing constraints on their generalization and application in on-board systems. In this paper, we propose a novel approach to address the extrinsic calibration problem in a robust, automatic, and single-shot manner. Instead of directly optimizing extrinsics, we leverage the consistency learning between LiDAR and camera to implement implicit re-calibartion. Specially, we introduce an appearance-consistency loss and a geometric-consistency loss to minimizing the inconsitency between the attrbutes (e.g., intensity and depth) of projected LiDAR points and the predicted ones. This design not only enhances adaptability to various scenarios but also enables a simple and efficient formulation during inference. We conduct comprehensive experiments on different datasets, and the results demonstrate that our method achieves accurate and robust performance. To promote further research and development in this area, we will release our model and code. ",
    "url": "https://arxiv.org/abs/2312.01085",
    "authors": [
      "Shuang Xu",
      "Sifan Zhou",
      "Zhi Tian",
      "Jizhou Ma",
      "Qiong Nie",
      "Xiangxiang Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01100",
    "title": "Prior-Aware Robust Beam Alignment for Low-SNR Millimeter-Wave  Communications",
    "abstract": "This paper presents a robust beam alignment technique for millimeter-wave communications in low signal-to-noise ratio (SNR) environments. The core strategy of our technique is to repeatedly transmit the most probable beam candidates to reduce beam misalignment probability induced by noise. Specifically, for a given beam training overhead, both the selection of candidates and the number of repetitions for each beam candidate are optimized based on channel prior information. To achieve this, a deep neural network is employed to learn the prior probability of the optimal beam at each location. The beam misalignment probability is then analyzed based on the channel prior, forming the basis for an optimization problem aimed at minimizing the analyzed beam misalignment probability. A closed-form solution is derived for a special case with two beam candidates, and an efficient algorithm is developed for general cases with multiple beam candidates. Simulation results using the DeepMIMO dataset demonstrate the superior performance of our technique in dynamic low-SNR communication environments when compared to existing beam alignment techniques. ",
    "url": "https://arxiv.org/abs/2312.01100",
    "authors": [
      "Jihun Park",
      "Yongjeong Oh",
      "Jaewon Yun",
      "Seonjung Kim",
      "Yo-Seb Jeon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.01105",
    "title": "S2P3: Self-Supervised Polarimetric Pose Prediction",
    "abstract": "This paper proposes the first self-supervised 6D object pose prediction from multimodal RGB+polarimetric images. The novel training paradigm comprises 1) a physical model to extract geometric information of polarized light, 2) a teacher-student knowledge distillation scheme and 3) a self-supervised loss formulation through differentiable rendering and an invertible physical constraint. Both networks leverage the physical properties of polarized light to learn robust geometric representations by encoding shape priors and polarization characteristics derived from our physical model. Geometric pseudo-labels from the teacher support the student network without the need for annotated real data. Dense appearance and geometric information of objects are obtained through a differentiable renderer with the predicted pose for self-supervised direct coupling. The student network additionally features our proposed invertible formulation of the physical shape priors that enables end-to-end self-supervised training through physical constraints of derived polarization characteristics compared against polarimetric input images. We specifically focus on photometrically challenging objects with texture-less or reflective surfaces and transparent materials for which the most prominent performance gain is reported. ",
    "url": "https://arxiv.org/abs/2312.01105",
    "authors": [
      "Patrick Ruhkamp",
      "Daoyi Gao",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01113",
    "title": "Malicious code detection in android: the role of sequence  characteristics and disassembling methods",
    "abstract": "The acceptance and widespread use of the Android operating system drew the attention of both legitimate developers and malware authors, which resulted in a significant number of benign and malicious applications available on various online markets. Since the signature-based methods fall short for detecting malicious software effectively considering the vast number of applications, machine learning techniques in this field have also become widespread. In this context, stating the acquired accuracy values in the contingency tables in malware detection studies has become a popular and efficient method and enabled researchers to evaluate their methodologies comparatively. In this study, we wanted to investigate and emphasize the factors that may affect the accuracy values of the models managed by researchers, particularly the disassembly method and the input data characteristics. Firstly, we developed a model that tackles the malware detection problem from a Natural Language Processing (NLP) perspective using Long Short-Term Memory (LSTM). Then, we experimented with different base units (instruction, basic block, method, and class) and representations of source code obtained from three commonly used disassembling tools (JEB, IDA, and Apktool) and examined the results. Our findings exhibit that the disassembly method and different input representations affect the model results. More specifically, the datasets collected by the Apktool achieved better results compared to the other two disassemblers. ",
    "url": "https://arxiv.org/abs/2312.01113",
    "authors": [
      "Pinar G. Balikcioglu",
      "Melih Sirlanci",
      "Ozge A. Kucuk",
      "Bulut Ulukapi",
      "Ramazan K. Turkmen",
      "Cengiz Acarturk"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.01118",
    "title": "Beyond Accuracy: Statistical Measures and Benchmark for Evaluation of  Representation from Self-Supervised Learning",
    "abstract": "Recently, self-supervised metric learning has raised attention for the potential to learn a generic distance function. It overcomes the limitations of conventional supervised one, e.g., scalability and label biases. Despite progress in this domain, current benchmarks, incorporating a narrow scope of classes, stop the nuanced evaluation of semantic representations. To bridge this gap, we introduce a large-scale benchmark with diversity and granularity of classes, Statistical Metric Learning Benchmark (SMLB) built upon ImageNet-21K and WordNet. SMLB is designed to rigorously evaluate the discriminative discernment and generalizability across more than 14M images, 20K classes, and 16K taxonomic nodes. Alongside, we propose novel evaluation metrics -- `overlap' for separability and `aSTD' for consistency -- to measure distance statistical information, which are efficient and robust to the change of class number. Our benchmark offers a novel perspective of evaluating the quality of representations beyond accuracy. Our findings reveal the limitations of supervised learning and the class bias inherent in SSL models, offering insights into potential areas for future model enhancement. ",
    "url": "https://arxiv.org/abs/2312.01118",
    "authors": [
      "Jiantao Wu",
      "Shentong Mo",
      "Sara Atito",
      "Josef Kittler",
      "Zhenhua Feng",
      "Muhammad Awais"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01137",
    "title": "Fast and Robust Sparsity-Aware Block Diagonal Representation",
    "abstract": "The block diagonal structure of an affinity matrix is a commonly desired property in cluster analysis because it represents clusters of feature vectors by non-zero coefficients that are concentrated in blocks. However, recovering a block diagonal affinity matrix is challenging in real-world applications, in which the data may be subject to outliers and heavy-tailed noise that obscure the hidden cluster structure. To address this issue, we first analyze the effect of different fundamental outlier types in graph-based cluster analysis. A key idea that simplifies the analysis is to introduce a vector that represents a block diagonal matrix as a piece-wise linear function of the similarity coefficients that form the affinity matrix. We reformulate the problem as a robust piece-wise linear fitting problem and propose a Fast and Robust Sparsity-Aware Block Diagonal Representation (FRS-BDR) method, which jointly estimates cluster memberships and the number of blocks. Comprehensive experiments on a variety of real-world applications demonstrate the effectiveness of FRS-BDR in terms of clustering accuracy, robustness against corrupted features, computation time and cluster enumeration performance. ",
    "url": "https://arxiv.org/abs/2312.01137",
    "authors": [
      "Aylin Tastan",
      "Michael Muma",
      "Abdelhak M.Zoubir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.01148",
    "title": "Has Anything Changed? 3D Change Detection by 2D Segmentation Masks",
    "abstract": "As capturing devices become common, 3D scans of interior spaces are acquired on a daily basis. Through scene comparison over time, information about objects in the scene and their changes is inferred. This information is important for robots and AR and VR devices, in order to operate in an immersive virtual experience. We thus propose an unsupervised object discovery method that identifies added, moved, or removed objects without any prior knowledge of what objects exist in the scene. We model this problem as a combination of a 3D change detection and a 2D segmentation task. Our algorithm leverages generic 2D segmentation masks to refine an initial but incomplete set of 3D change detections. The initial changes, acquired through render-and-compare likely correspond to movable objects. The incomplete detections are refined through graph optimization, distilling the information of the 2D segmentation masks in the 3D space. Experiments on the 3Rscan dataset prove that our method outperforms competitive baselines, with SoTA results. ",
    "url": "https://arxiv.org/abs/2312.01148",
    "authors": [
      "Aikaterini Adam",
      "Konstantinos Karantzalos",
      "Lazaros Grammatikopoulos",
      "Torsten Sattler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01150",
    "title": "Pointer Networks Trained Better via Evolutionary Algorithms",
    "abstract": "Pointer Network (PtrNet) is a specific neural network for solving Combinatorial Optimization Problems (COPs). While PtrNets offer real-time feed-forward inference for complex COPs instances, its quality of the results tends to be less satisfactory. One possible reason is that such issue suffers from the lack of global search ability of the gradient descent, which is frequently employed in traditional PtrNet training methods including both supervised learning and reinforcement learning. To improve the performance of PtrNet, this paper delves deeply into the advantages of training PtrNet with Evolutionary Algorithms (EAs), which have been widely acknowledged for not easily getting trapped by local optima. Extensive empirical studies based on the Travelling Salesman Problem (TSP) have been conducted. Results demonstrate that PtrNet trained with EA can consistently perform much better inference results than eight state-of-the-art methods on various problem scales. Compared with gradient descent based PtrNet training methods, EA achieves up to 30.21\\% improvement in quality of the solution with the same computational time. With this advantage, this paper is able to at the first time report the results of solving 1000-dimensional TSPs by training a PtrNet on the same dimensionality, which strongly suggests that scaling up the training instances is in need to improve the performance of PtrNet on solving higher-dimensional COPs. ",
    "url": "https://arxiv.org/abs/2312.01150",
    "authors": [
      "Muyao Zhong",
      "Shengcai Liu",
      "Bingdong Li",
      "Haobo Fu",
      "Chao Qian",
      "Ke Tand",
      "Peng Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.01163",
    "title": "A New Learning Paradigm for Foundation Model-based Remote Sensing Change  Detection",
    "abstract": "Change detection (CD) is a critical task to observe and analyze dynamic processes of land cover. Although numerous deep learning-based CD models have performed excellently, their further performance improvements are constrained by the limited knowledge extracted from the given labelled data. On the other hand, the foundation models that emerged recently contain a huge amount of knowledge by scaling up across data modalities and proxy tasks. In this paper, we propose a Bi-Temporal Adapter Network (BAN), which is a universal foundation model-based CD adaptation framework aiming to extract the knowledge of foundation models for CD. The proposed BAN contains three parts, i.e. frozen foundation model (e.g., CLIP), bitemporal adapter branch (Bi-TAB), and bridging modules between them. Specifically, the Bi-TAB can be either an existing arbitrary CD model or some hand-crafted stacked blocks. The bridging modules are designed to align the general features with the task/domain-specific features and inject the selected general knowledge into the Bi-TAB. To our knowledge, this is the first universal framework to adapt the foundation model to the CD task. Extensive experiments show the effectiveness of our BAN in improving the performance of existing CD methods (e.g., up to 4.08\\% IoU improvement) with only a few additional learnable parameters. More importantly, these successful practices show us the potential of foundation models for remote sensing CD. The code is available at \\url{https://github.com/likyoo/BAN} and will be supported in our Open-CD \\url{https://github.com/likyoo/open-cd}. ",
    "url": "https://arxiv.org/abs/2312.01163",
    "authors": [
      "Kaiyu Li",
      "Xiangyong Cao",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01167",
    "title": "Meta-Learned Attribute Self-Interaction Network for Continual and  Generalized Zero-Shot Learning",
    "abstract": "Zero-shot learning (ZSL) is a promising approach to generalizing a model to categories unseen during training by leveraging class attributes, but challenges remain. Recently, methods using generative models to combat bias towards classes seen during training have pushed state of the art, but these generative models can be slow or computationally expensive to train. Also, these generative models assume that the attribute vector of each unseen class is available a priori at training, which is not always practical. Additionally, while many previous ZSL methods assume a one-time adaptation to unseen classes, in reality, the world is always changing, necessitating a constant adjustment of deployed models. Models unprepared to handle a sequential stream of data are likely to experience catastrophic forgetting. We propose a Meta-learned Attribute self-Interaction Network (MAIN) for continual ZSL. By pairing attribute self-interaction trained using meta-learning with inverse regularization of the attribute encoder, we are able to outperform state-of-the-art results without leveraging the unseen class attributes while also being able to train our models substantially faster (>100x) than expensive generative-based approaches. We demonstrate this with experiments on five standard ZSL datasets (CUB, aPY, AWA1, AWA2, and SUN) in the generalized zero-shot learning and continual (fixed/dynamic) zero-shot learning settings. Extensive ablations and analyses demonstrate the efficacy of various components proposed. ",
    "url": "https://arxiv.org/abs/2312.01167",
    "authors": [
      "Vinay K Verma",
      "Nikhil Mehta",
      "Kevin J Liang",
      "Aakansha Mishra",
      "Lawrence Carin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.01169",
    "title": "Virtual Category Learning: A Semi-Supervised Learning Method for Dense  Prediction with Extremely Limited Labels",
    "abstract": "Due to the costliness of labelled data in real-world applications, semi-supervised learning, underpinned by pseudo labelling, is an appealing solution. However, handling confusing samples is nontrivial: discarding valuable confusing samples would compromise the model generalisation while using them for training would exacerbate the issue of confirmation bias caused by the resulting inevitable mislabelling. To solve this problem, this paper proposes to use confusing samples proactively without label correction. Specifically, a Virtual Category (VC) is assigned to each confusing sample in such a way that it can safely contribute to the model optimisation even without a concrete label. This provides an upper bound for inter-class information sharing capacity, which eventually leads to a better embedding space. Extensive experiments on two mainstream dense prediction tasks -- semantic segmentation and object detection, demonstrate that the proposed VC learning significantly surpasses the state-of-the-art, especially when only very few labels are available. Our intriguing findings highlight the usage of VC learning in dense vision tasks. ",
    "url": "https://arxiv.org/abs/2312.01169",
    "authors": [
      "Changrui Chen",
      "Jungong Han",
      "Kurt Debattista"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01170",
    "title": "Power-balanced Memristive Cryptographic Implementation Against Side  Channel Attacks",
    "abstract": "Memristors, as emerging nano-devices, offer promising performance and exhibit rich electrical dynamic behavior. Having already found success in applications such as neuromorphic and in-memory computing, researchers are now exploring their potential for cryptographic implementations. In this study, we present a novel power-balanced hiding strategy utilizing memristor groups to conceal power consumption in cryptographic logic circuits. Our approach ensures consistent power costs of all 16 logic gates in Complementary-Resistive-Switching-with-Reading (CRS-R) logic family during writing and reading cycles regardless of Logic Input Variable (LIV) values. By constructing hiding groups, we enable an effective power balance in each gate hiding group. Furthermore, experimental validation of our strategy includes the implementation of a cryptographic construction, xor4SBox, using NOR gates. The circuit construction without the hiding strategy and with the hiding strategy undergo T-test analysis, confirming the significant improvement achieved with our approach. Our work presents a substantial advancement in power-balanced hiding methods, offering enhanced security and efficiency in logic circuits. ",
    "url": "https://arxiv.org/abs/2312.01170",
    "authors": [
      "Ziang Chen",
      "Li-Wei Chen",
      "Xianyue Zhao",
      "Kefeng Li",
      "Heidemarie Schmidt",
      "Ilia Polian",
      "Nan Du"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.01187",
    "title": "SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer",
    "abstract": "Self-supervised learning relies heavily on data augmentation to extract meaningful representations from unlabeled images. While existing state-of-the-art augmentation pipelines incorporate a wide range of primitive transformations, these often disregard natural image structure. Thus, augmented samples can exhibit degraded semantic information and low stylistic diversity, affecting downstream performance of self-supervised representations. To overcome this, we propose SASSL: Style Augmentations for Self Supervised Learning, a novel augmentation technique based on Neural Style Transfer. The method decouples semantic and stylistic attributes in images and applies transformations exclusively to the style while preserving content, generating diverse augmented samples that better retain their semantic properties. Experimental results show our technique achieves a top-1 classification performance improvement of more than 2% on ImageNet compared to the well-established MoCo v2. We also measure transfer learning performance across five diverse datasets, observing significant improvements of up to 3.75%. Our experiments indicate that decoupling style from content information and transferring style across datasets to diversify augmentations can significantly improve downstream performance of self-supervised representations. ",
    "url": "https://arxiv.org/abs/2312.01187",
    "authors": [
      "Renan A. Rojas-Gomez",
      "Karan Singhal",
      "Ali Etemad",
      "Alex Bijamov",
      "Warren R. Morningstar",
      "Philip Andrew Mansfield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.01196",
    "title": "Neural Parametric Gaussians for Monocular Non-Rigid Object  Reconstruction",
    "abstract": "Reconstructing dynamic objects from monocular videos is a severely underconstrained and challenging problem, and recent work has approached it in various directions. However, owing to the ill-posed nature of this problem, there has been no solution that can provide consistent, high-quality novel views from camera positions that are significantly different from the training views. In this work, we introduce Neural Parametric Gaussians (NPGs) to take on this challenge by imposing a two-stage approach: first, we fit a low-rank neural deformation model, which then is used as regularization for non-rigid reconstruction in the second stage. The first stage learns the object's deformations such that it preserves consistency in novel views. The second stage obtains high reconstruction quality by optimizing 3D Gaussians that are driven by the coarse model. To this end, we introduce a local 3D Gaussian representation, where temporally shared Gaussians are anchored in and deformed by local oriented volumes. The resulting combined model can be rendered as radiance fields, resulting in high-quality photo-realistic reconstructions of the non-rigidly deforming objects, maintaining 3D consistency across novel views. We demonstrate that NPGs achieve superior results compared to previous works, especially in challenging scenarios with few multi-view cues. ",
    "url": "https://arxiv.org/abs/2312.01196",
    "authors": [
      "Devikalyan Das",
      "Christopher Wewer",
      "Raza Yunus",
      "Eddy Ilg",
      "Jan Eric Lenssen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01197",
    "title": "Short-term Precipitation Forecasting in The Netherlands: An Application  of Convolutional LSTM neural networks to weather radar data",
    "abstract": "This work addresses the challenge of short-term precipitation forecasting by applying Convolutional Long Short-Term Memory (ConvLSTM) neural networks to weather radar data from the Royal Netherlands Meteorological Institute (KNMI). The research exploits the combination of Convolutional Neural Networks (CNNs) layers for spatial pattern recognition and LSTM network layers for modelling temporal sequences, integrating these strengths into a ConvLSTM architecture. The model was trained and validated on weather radar data from the Netherlands. The model is an autoencoder consisting of nine layers, uniquely combining convolutional operations with LSTMs temporal processing, enabling it to capture the movement and intensity of precipitation systems. The training set comprised of sequences of radar images, with the model being tasked to predict precipitation patterns 1.5 hours ahead using the preceding data. Results indicate high accuracy in predicting the direction and intensity of precipitation movements. The findings of this study underscore the significant potential of ConvLSTM networks in meteorological forecasting, particularly in regions with complex weather patterns. It contributes to the field by offering a more accurate, data-driven approach to weather prediction, highlighting the broader applicability of ConvLSTM networks in meteorological tasks. ",
    "url": "https://arxiv.org/abs/2312.01197",
    "authors": [
      "Petros Demetrakopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01200",
    "title": "FRAUDability: Estimating Users' Susceptibility to Financial Fraud Using  Adversarial Machine Learning",
    "abstract": "In recent years, financial fraud detection systems have become very efficient at detecting fraud, which is a major threat faced by e-commerce platforms. Such systems often include machine learning-based algorithms aimed at detecting and reporting fraudulent activity. In this paper, we examine the application of adversarial learning based ranking techniques in the fraud detection domain and propose FRAUDability, a method for the estimation of a financial fraud detection system's performance for every user. We are motivated by the assumption that \"not all users are created equal\" -- while some users are well protected by fraud detection algorithms, others tend to pose a challenge to such systems. The proposed method produces scores, namely \"fraudability scores,\" which are numerical estimations of a fraud detection system's ability to detect financial fraud for a specific user, given his/her unique activity in the financial system. Our fraudability scores enable those tasked with defending users in a financial platform to focus their attention and resources on users with high fraudability scores to better protect them. We validate our method using a real e-commerce platform's dataset and demonstrate the application of fraudability scores from the attacker's perspective, on the platform, and more specifically, on the fraud detection systems used by the e-commerce enterprise. We show that the scores can also help attackers increase their financial profit by 54%, by engaging solely with users with high fraudability scores, avoiding those users whose spending habits enable more accurate fraud detection. ",
    "url": "https://arxiv.org/abs/2312.01200",
    "authors": [
      "Chen Doytshman",
      "Satoru Momiyama",
      "Inderjeet Singh",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.01201",
    "title": "PAC Privacy Preserving Diffusion Models",
    "abstract": "Data privacy protection is garnering increased attention among researchers. Diffusion models (DMs), particularly with strict differential privacy, can potentially produce images with both high privacy and visual quality. However, challenges arise in ensuring robust protection in privatizing specific data attributes, areas where current models often fall short. To address these challenges, we introduce the PAC Privacy Preserving Diffusion Model, a model leverages diffusion principles and ensure Probably Approximately Correct (PAC) privacy. We enhance privacy protection by integrating a private classifier guidance into the Langevin Sampling Process. Additionally, recognizing the gap in measuring the privacy of models, we have developed a novel metric to gauge privacy levels. Our model, assessed with this new metric and supported by Gaussian matrix computations for the PAC bound, has shown superior performance in privacy protection over existing leading private generative models according to benchmark tests. ",
    "url": "https://arxiv.org/abs/2312.01201",
    "authors": [
      "Qipan Xu",
      "Youlong Ding",
      "Jie Gao",
      "Hao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01213",
    "title": "Recent Advances in Scalable Energy-Efficient and Trustworthy Spiking  Neural networks: from Algorithms to Technology",
    "abstract": "Neuromorphic computing and, in particular, spiking neural networks (SNNs) have become an attractive alternative to deep neural networks for a broad range of signal processing applications, processing static and/or temporal inputs from different sensory modalities, including audio and vision sensors. In this paper, we start with a description of recent advances in algorithmic and optimization innovations to efficiently train and scale low-latency, and energy-efficient spiking neural networks (SNNs) for complex machine learning applications. We then discuss the recent efforts in algorithm-architecture co-design that explores the inherent trade-offs between achieving high energy-efficiency and low latency while still providing high accuracy and trustworthiness. We then describe the underlying hardware that has been developed to leverage such algorithmic innovations in an efficient way. In particular, we describe a hybrid method to integrate significant portions of the model's computation within both memory components as well as the sensor itself. Finally, we discuss the potential path forward for research in building deployable SNN systems identifying key challenges in the algorithm-hardware-application co-design space with an emphasis on trustworthiness. ",
    "url": "https://arxiv.org/abs/2312.01213",
    "authors": [
      "Souvik Kundu",
      "Rui-Jie Zhu",
      "Akhilesh Jaiswal",
      "Peter A. Beerel"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01216",
    "title": "Individual Behavioral Insights in Schizophrenia: A Network Analysis and  Mobile Sensing Approach",
    "abstract": "Digital phenotyping in mental health often consists of collecting behavioral and experience-based information through sensory and self-reported data from devices such as smartphones. Such rich and comprehensive data could be used to develop insights into the relationships between daily behavior and a range of mental health conditions. However, current analytical approaches have shown limited application due to these datasets being both high dimensional and multimodal in nature. This study demonstrates the first use of a principled method which consolidates the complexities of subjective self-reported data (Ecological Momentary Assessments - EMAs) with concurrent sensor-based data. In this study the CrossCheck dataset is used to analyse data from 50 participants diagnosed with schizophrenia. Network Analysis is applied to EMAs at an individual (n-of-1) level while sensor data is used to identify periods of various behavioral context. Networks generated during periods of certain behavioral contexts, such as variations in the daily number of locations visited, were found to significantly differ from baseline networks and networks generated from randomly sampled periods of time. The framework presented here lays a foundation to reveal behavioural contexts and the concurrent impact of self-reporting at an n-of-1 level. These insights are valuable in the management of serious mental illnesses such as schizophrenia. ",
    "url": "https://arxiv.org/abs/2312.01216",
    "authors": [
      "Andy Davies",
      "Eiko Fried",
      "Hane Aung",
      "Omar Costilla-Reyes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2312.01217",
    "title": "Understanding Opinions Towards Climate Change on Social Media",
    "abstract": "Social media platforms such as Twitter (now known as X) have revolutionized how the public engage with important societal and political topics. Recently, climate change discussions on social media became a catalyst for political polarization and the spreading of misinformation. In this work, we aim to understand how real world events influence the opinions of individuals towards climate change related topics on social media. To this end, we extracted and analyzed a dataset of 13.6 millions tweets sent by 3.6 million users from 2006 to 2019. Then, we construct a temporal graph from the user-user mentions network and utilize the Louvain community detection algorithm to analyze the changes in community structure around Conference of the Parties on Climate Change~(COP) events. Next, we also apply tools from the Natural Language Processing literature to perform sentiment analysis and topic modeling on the tweets. Our work acts as a first step towards understanding the evolution of pro-climate change communities around COP events. Answering these questions helps us understand how to raise people's awareness towards climate change thus hopefully calling on more individuals to join the collaborative effort in slowing down climate change. ",
    "url": "https://arxiv.org/abs/2312.01217",
    "authors": [
      "Yashaswi Pupneja",
      "Joseph Zou",
      "Sacha L\u00e9vy",
      "Shenyang Huang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01219",
    "title": "A hierarchical event correlation model for real time threat detection  and response",
    "abstract": "Intrusion detection systems perform post-compromise detection of security breaches whenever preventive measures such as firewalls do not avert an attack. However, these systems raise a vast number of alerts that must be analysed and triaged by security analysts. This process is largely manual, tedious and time-consuming. Alert correlation is a technique that tries to reduce the number of intrusion alerts by aggregating those that are related in some way. However, the correlation is performed outside the IDS through third-party systems and tools, after the high volume of alerts has already been raised. These other third-party systems add to the complexity of security operations. In this paper, we build on the very researched area of correlation techniques by developing a novel hierarchical event correlation model that promises to reduce the number of alerts issued by an Intrusion Detection System. This is achieved by correlating the events before the IDS classifies them. The proposed model takes the best of features from similarity and graph-based correlation techniques to deliver an ensemble capability not possible by either approach separately. Further, we propose a correlation process for correlation of events rather than alerts as is the case in current art. We further develop our own correlation and clustering algorithm which is tailor-made to the correlation and clustering of network event data. The model is implemented as a proof of concept with experiments run on the DARPA 99 Intrusion detection set. The correlation achieved 87 percent data reduction through aggregation, producing nearly 21000 clusters in about 30 seconds. ",
    "url": "https://arxiv.org/abs/2312.01219",
    "authors": [
      "Herbert Maosa",
      "Karim Ouazzane",
      "Mohamed Chahine Ghanem"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.01220",
    "title": "Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation",
    "abstract": "Detecting objects in low-light scenarios presents a persistent challenge, as detectors trained on well-lit data exhibit significant performance degradation on low-light data due to the low visibility. Previous methods mitigate this issue by investigating image enhancement or object detection techniques using low-light image datasets. However, the progress is impeded by the inherent difficulties associated with collecting and annotating low-light images. To address this challenge, we propose to boost low-light object detection with zero-shot day-night domain adaptation, which aims to generalize a detector from well-lit scenarios to low-light ones without requiring real low-light data. We first design a reflectance representation learning module to learn Retinex-based illumination invariance in images with a carefully designed illumination invariance reinforcement strategy. Next, an interchange-redecomposition-coherence procedure is introduced to improve over the vanilla Retinex image decomposition process by performing two sequential image decompositions and introducing a redecomposition cohering loss. Extensive experiments on ExDark, DARK FACE and CODaN datasets show strong low-light generalizability of our method. ",
    "url": "https://arxiv.org/abs/2312.01220",
    "authors": [
      "Zhipeng Du",
      "Miaojing Shi",
      "Jiankang Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01225",
    "title": "UCE-FID: Using Large Unlabeled, Medium Crowdsourced-Labeled, and Small  Expert-Labeled Tweets for Foodborne Illness Detection",
    "abstract": "Foodborne illnesses significantly impact public health. Deep learning surveillance applications using social media data aim to detect early warning signals. However, labeling foodborne illness-related tweets for model training requires extensive human resources, making it challenging to collect a sufficient number of high-quality labels for tweets within a limited budget. The severe class imbalance resulting from the scarcity of foodborne illness-related tweets among the vast volume of social media further exacerbates the problem. Classifiers trained on a class-imbalanced dataset are biased towards the majority class, making accurate detection difficult. To overcome these challenges, we propose EGAL, a deep learning framework for foodborne illness detection that uses small expert-labeled tweets augmented by crowdsourced-labeled and massive unlabeled data. Specifically, by leveraging tweets labeled by experts as a reward set, EGAL learns to assign a weight of zero to incorrectly labeled tweets to mitigate their negative influence. Other tweets receive proportionate weights to counter-balance the unbalanced class distribution. Extensive experiments on real-world \\textit{TWEET-FID} data show that EGAL outperforms strong baseline models across different settings, including varying expert-labeled set sizes and class imbalance ratios. A case study on a multistate outbreak of Salmonella Typhimurium infection linked to packaged salad greens demonstrates how the trained model captures relevant tweets offering valuable outbreak insights. EGAL, funded by the U.S. Department of Agriculture (USDA), has the potential to be deployed for real-time analysis of tweet streaming, contributing to foodborne illness outbreak surveillance efforts. ",
    "url": "https://arxiv.org/abs/2312.01225",
    "authors": [
      "Ruofan Hu",
      "Dongyu Zhang",
      "Dandan Tao",
      "Huayi Zhang",
      "Hao Feng",
      "Elke Rundensteiner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.01241",
    "title": "Just-in-Time Security Patch Detection -- LLM At the Rescue for Data  Augmentation",
    "abstract": "In the face of growing vulnerabilities found in open-source software, the need to identify {discreet} security patches has become paramount. The lack of consistency in how software providers handle maintenance often leads to the release of security patches without comprehensive advisories, leaving users vulnerable to unaddressed security risks. To address this pressing issue, we introduce a novel security patch detection system, LLMDA, which capitalizes on Large Language Models (LLMs) and code-text alignment methodologies for patch review, data enhancement, and feature combination. Within LLMDA, we initially utilize LLMs for examining patches and expanding data of PatchDB and SPI-DB, two security patch datasets from recent literature. We then use labeled instructions to direct our LLMDA, differentiating patches based on security relevance. Following this, we apply a PTFormer to merge patches with code, formulating hybrid attributes that encompass both the innate details and the interconnections between the patches and the code. This distinctive combination method allows our system to capture more insights from the combined context of patches and code, hence improving detection precision. Finally, we devise a probabilistic batch contrastive learning mechanism within batches to augment the capability of the our LLMDA in discerning security patches. The results reveal that LLMDA significantly surpasses the start of the art techniques in detecting security patches, underscoring its promise in fortifying software maintenance. ",
    "url": "https://arxiv.org/abs/2312.01241",
    "authors": [
      "Xunzhu Tang",
      "Zhenghan Chen",
      "Kisub Kim",
      "Haoye Tian",
      "Saad Ezzini",
      "Jacques Klein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01262",
    "title": "A Review and A Robust Framework of Data-Efficient 3D Scene Parsing with  Traditional/Learned 3D Descriptors",
    "abstract": "Existing state-of-the-art 3D point cloud understanding methods merely perform well in a fully supervised manner. To the best of our knowledge, there exists no unified framework that simultaneously solves the downstream high-level understanding tasks including both segmentation and detection, especially when labels are extremely limited. This work presents a general and simple framework to tackle point cloud understanding when labels are limited. The first contribution is that we have done extensive methodology comparisons of traditional and learned 3D descriptors for the task of weakly supervised 3D scene understanding, and validated that our adapted traditional PFH-based 3D descriptors show excellent generalization ability across different domains. The second contribution is that we proposed a learning-based region merging strategy based on the affinity provided by both the traditional/learned 3D descriptors and learned semantics. The merging process takes both low-level geometric and high-level semantic feature correlations into consideration. Experimental results demonstrate that our framework has the best performance among the three most important weakly supervised point clouds understanding tasks including semantic segmentation, instance segmentation, and object detection even when very limited number of points are labeled. Our method, termed Region Merging 3D (RM3D), has superior performance on ScanNet data-efficient learning online benchmarks and other four large-scale 3D understanding benchmarks under various experimental settings, outperforming current arts by a margin for various 3D understanding tasks without complicated learning strategies such as active learning. ",
    "url": "https://arxiv.org/abs/2312.01262",
    "authors": [
      "Kangcheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.01274",
    "title": "Learning to Compose SuperWeights for Neural Parameter Allocation Search",
    "abstract": "Neural parameter allocation search (NPAS) automates parameter sharing by obtaining weights for a network given an arbitrary, fixed parameter budget. Prior work has two major drawbacks we aim to address. First, there is a disconnect in the sharing pattern between the search and training steps, where weights are warped for layers of different sizes during the search to measure similarity, but not during training, resulting in reduced performance. To address this, we generate layer weights by learning to compose sets of SuperWeights, which represent a group of trainable parameters. These SuperWeights are created to be large enough so they can be used to represent any layer in the network, but small enough that they are computationally efficient. The second drawback we address is the method of measuring similarity between shared parameters. Whereas prior work compared the weights themselves, we argue this does not take into account the amount of conflict between the shared weights. Instead, we use gradient information to identify layers with shared weights that wish to diverge from each other. We demonstrate that our SuperWeight Networks consistently boost performance over the state-of-the-art on the ImageNet and CIFAR datasets in the NPAS setting. We further show that our approach can generate parameters for many network architectures using the same set of weights. This enables us to support tasks like efficient ensembling and anytime prediction, outperforming fully-parameterized ensembles with 17% fewer parameters. ",
    "url": "https://arxiv.org/abs/2312.01274",
    "authors": [
      "Piotr Teterwak",
      "Soren Nelson",
      "Nikoli Dryden",
      "Dina Bashkirova",
      "Kate Saenko",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01283",
    "title": "Deeper into Self-Supervised Monocular Indoor Depth Estimation",
    "abstract": "Monocular depth estimation using Convolutional Neural Networks (CNNs) has shown impressive performance in outdoor driving scenes. However, self-supervised learning of indoor depth from monocular sequences is quite challenging for researchers because of the following two main reasons. One is the large areas of low-texture regions and the other is the complex ego-motion on indoor training datasets. In this work, our proposed method, named IndoorDepth, consists of two innovations. In particular, we first propose a novel photometric loss with improved structural similarity (SSIM) function to tackle the challenge from low-texture regions. Moreover, in order to further mitigate the issue of inaccurate ego-motion prediction, multiple photometric losses at different stages are used to train a deeper pose network with two residual pose blocks. Subsequent ablation study can validate the effectiveness of each new idea. Experiments on the NYUv2 benchmark demonstrate that our IndoorDepth outperforms the previous state-of-the-art methods by a large margin. In addition, we also validate the generalization ability of our method on ScanNet dataset. Code is availabe at https://github.com/fcntes/IndoorDepth. ",
    "url": "https://arxiv.org/abs/2312.01283",
    "authors": [
      "Chao Fan",
      "Zhenyu Yin",
      "Yue Li",
      "Feiqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01286",
    "title": "Continuous Convolutional Neural Networks for Disruption Prediction in  Nuclear Fusion Plasmas",
    "abstract": "Grid decarbonization for climate change requires dispatchable carbon-free energy like nuclear fusion. The tokamak concept offers a promising path for fusion, but one of the foremost challenges in implementation is the occurrence of energetic plasma disruptions. In this study, we delve into Machine Learning approaches to predict plasma state outcomes. Our contributions are twofold: (1) We present a novel application of Continuous Convolutional Neural Networks for disruption prediction and (2) We examine the advantages and disadvantages of continuous models over discrete models for disruption prediction by comparing our model with the previous, discrete state of the art, and show that continuous models offer significantly better performance (Area Under the Receiver Operating Characteristic Curve = 0.974 v.s. 0.799) with fewer parameters ",
    "url": "https://arxiv.org/abs/2312.01286",
    "authors": [
      "William F Arnold",
      "Lucas Spangher",
      "Christina Rea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2312.01299",
    "title": "Robust Non-parametric Knowledge-based Diffusion Least Mean Squares over  Adaptive Networks",
    "abstract": "The present study proposes incorporating non-parametric knowledge into the diffusion least-mean-squares algorithm in the framework of a maximum a posteriori (MAP) estimation. The proposed algorithm leads to a robust estimation of an unknown parameter vector in a group of cooperative estimators. Utilizing kernel density estimation and buffering some intermediate estimations, the prior distribution and conditional likelihood of the parameters vector in each node are calculated. Pseudo Huber loss function is used for designing the likelihood function. Also, an error thresholding function is defined to reduce the computational overhead as well as more relaxation against noise, which stops the update every time an error is less than a predefined threshold. The performance of the proposed algorithm is examined in the stationary and non-stationary scenarios in the presence of Gaussian and non-Gaussian noise. Results show the robustness of the proposed algorithm in the presence of different noise types. ",
    "url": "https://arxiv.org/abs/2312.01299",
    "authors": [
      "Soheil Ashkezari-Toussi",
      "Hadi sadoghi-Yazdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01301",
    "title": "Churn Prediction via Multimodal Fusion Learning:Integrating Customer  Financial Literacy, Voice, and Behavioral Data",
    "abstract": "In todays competitive landscape, businesses grapple with customer retention. Churn prediction models, although beneficial, often lack accuracy due to the reliance on a single data source. The intricate nature of human behavior and high dimensional customer data further complicate these efforts. To address these concerns, this paper proposes a multimodal fusion learning model for identifying customer churn risk levels in financial service providers. Our multimodal approach integrates customer sentiments financial literacy (FL) level, and financial behavioral data, enabling more accurate and bias-free churn prediction models. The proposed FL model utilizes a SMOGN COREG supervised model to gauge customer FL levels from their financial data. The baseline churn model applies an ensemble artificial neural network and oversampling techniques to predict churn propensity in high-dimensional financial data. We also incorporate a speech emotion recognition model employing a pre-trained CNN-VGG16 to recognize customer emotions based on pitch, energy, and tone. To integrate these diverse features while retaining unique insights, we introduced late and hybrid fusion techniques that complementary boost coordinated multimodal co learning. Robust metrics were utilized to evaluate the proposed multimodal fusion model and hence the approach validity, including mean average precision and macro-averaged F1 score. Our novel approach demonstrates a marked improvement in churn prediction, achieving a test accuracy of 91.2%, a Mean Average Precision (MAP) score of 66, and a Macro-Averaged F1 score of 54 through the proposed hybrid fusion learning technique compared with late fusion and baseline models. Furthermore, the analysis demonstrates a positive correlation between negative emotions, low FL scores, and high-risk customers. ",
    "url": "https://arxiv.org/abs/2312.01301",
    "authors": [
      "David Hason Rudd",
      "Huan Huo",
      "Md Rafiqul Islam",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2312.01335",
    "title": "Facial Emotion Recognition Under Mask Coverage Using a Data Augmentation  Technique",
    "abstract": "Identifying human emotions using AI-based computer vision systems, when individuals wear face masks, presents a new challenge in the current Covid-19 pandemic. In this study, we propose a facial emotion recognition system capable of recognizing emotions from individuals wearing different face masks. A novel data augmentation technique was utilized to improve the performance of our model using four mask types for each face image. We evaluated the effectiveness of four convolutional neural networks, Alexnet, Squeezenet, Resnet50 and VGGFace2 that were trained using transfer learning. The experimental findings revealed that our model works effectively in multi-mask mode compared to single-mask mode. The VGGFace2 network achieved the highest accuracy rate, with 97.82% for the person-dependent mode and 74.21% for the person-independent mode using the JAFFE dataset. However, we evaluated our proposed model using the UIBVFED dataset. The Resnet50 has demonstrated superior performance, with accuracies of 73.68% for the person-dependent mode and 59.57% for the person-independent mode. Moreover, we employed metrics such as precision, sensitivity, specificity, AUC, F1 score, and confusion matrix to measure our system's efficiency in detail. Additionally, the LIME algorithm was used to visualize CNN's decision-making strategy. ",
    "url": "https://arxiv.org/abs/2312.01335",
    "authors": [
      "Aref Farhadipour",
      "Pouya Taghipour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2312.01342",
    "title": "Graph Coordinates and Conventional Neural Networks -- An Alternative for  Graph Neural Networks",
    "abstract": "Graph-based data present unique challenges and opportunities for machine learning. Graph Neural Networks (GNNs), and especially those algorithms that capture graph topology through message passing for neighborhood aggregation, have been a leading solution. However, these networks often require substantial computational resources and may not optimally leverage the information contained in the graph's topology, particularly for large-scale or complex graphs. We propose Topology Coordinate Neural Network (TCNN) and Directional Virtual Coordinate Neural Network (DVCNN) as novel and efficient alternatives to message passing GNNs, that directly leverage the graph's topology, sidestepping the computational challenges presented by competing algorithms. Our proposed methods can be viewed as a reprise of classic techniques for graph embedding for neural network feature engineering, but they are novel in that our embedding techniques leverage ideas in Graph Coordinates (GC) that are lacking in current practice. Experimental results, benchmarked against the Open Graph Benchmark Leaderboard, demonstrate that TCNN and DVCNN achieve competitive or superior performance to message passing GNNs. For similar levels of accuracy and ROC-AUC, TCNN and DVCNN need far fewer trainable parameters than contenders of the OGBN Leaderboard. The proposed TCNN architecture requires fewer parameters than any neural network method currently listed in the OGBN Leaderboard for both OGBN-Proteins and OGBN-Products datasets. Conversely, our methods achieve higher performance for a similar number of trainable parameters. By providing an efficient and effective alternative to message passing GNNs, our work expands the toolbox of techniques for graph-based machine learning. ",
    "url": "https://arxiv.org/abs/2312.01342",
    "authors": [
      "Zheyi Qin",
      "Randy Paffenroth",
      "Anura P. Jayasumana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01357",
    "title": "Analyze the robustness of three NMF algorithms (Robust NMF with L1 norm,  L2-1 norm NMF, L2 NMF)",
    "abstract": "Non-negative matrix factorization (NMF) and its variants have been widely employed in clustering and classification tasks (Long, & Jian , 2021). However, noises can seriously affect the results of our experiments. Our research is dedicated to investigating the noise robustness of non-negative matrix factorization (NMF) in the face of different types of noise. Specifically, we adopt three different NMF algorithms, namely L1 NMF, L2 NMF, and L21 NMF, and use the ORL and YaleB data sets to simulate a series of experiments with salt-and-pepper noise and Block-occlusion noise separately. In the experiment, we use a variety of evaluation indicators, including root mean square error (RMSE), accuracy (ACC), and normalized mutual information (NMI), to evaluate the performance of different NMF algorithms in noisy environments. Through these indicators, we quantify the resistance of NMF algorithms to noise and gain insights into their feasibility in practical applications. ",
    "url": "https://arxiv.org/abs/2312.01357",
    "authors": [
      "Cheng Zeng",
      "Jiaqi Tian",
      "Yixuan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01361",
    "title": "MoEC: Mixture of Experts Implicit Neural Compression",
    "abstract": "Emerging Implicit Neural Representation (INR) is a promising data compression technique, which represents the data using the parameters of a Deep Neural Network (DNN). Existing methods manually partition a complex scene into local regions and overfit the INRs into those regions. However, manually designing the partition scheme for a complex scene is very challenging and fails to jointly learn the partition and INRs. To solve the problem, we propose MoEC, a novel implicit neural compression method based on the theory of mixture of experts. Specifically, we use a gating network to automatically assign a specific INR to a 3D point in the scene. The gating network is trained jointly with the INRs of different local regions. Compared with block-wise and tree-structured partitions, our learnable partition can adaptively find the optimal partition in an end-to-end manner. We conduct detailed experiments on massive and diverse biomedical data to demonstrate the advantages of MoEC against existing approaches. In most of experiment settings, we have achieved state-of-the-art results. Especially in cases of extreme compression ratios, such as 6000x, we are able to uphold the PSNR of 48.16. ",
    "url": "https://arxiv.org/abs/2312.01361",
    "authors": [
      "Jianchen Zhao",
      "Cheng-Ching Tseng",
      "Ming Lu",
      "Ruichuan An",
      "Xiaobao Wei",
      "He Sun",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2312.01392",
    "title": "Neural Network Characterization and Entropy Regulated Data Balancing  through Principal Component Analysis",
    "abstract": "This paper examines the relationship between the behavior of a neural network and the distribution formed from the projections of the data records into the space spanned by the low-order principal components of the training data. For example, in a benchmark calculation involving rotated and unrotated MNIST digits, classes (digits) that are mapped far from the origin in a low-dimensional principal component space and that overlap minimally with other digits converge rapidly and exhibit high degrees of accuracy in neural network calculations that employ the associated components of each data record as inputs. Further, if the space spanned by these low-order principal components is divided into bins and the input data records that are mapped into a given bin averaged, the resulting pattern can be distinguished by its geometric features which interpolate between those of adjacent bins in an analogous manner to variational autoencoders. Based on this observation, a simply realized data balancing procedure can be realized by evaluating the entropy associated with each histogram bin and subsequently repeating the original image data associated with the bin by a number of times that is determined from this entropy. ",
    "url": "https://arxiv.org/abs/2312.01392",
    "authors": [
      "David Yevick",
      "Karolina Hutchison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01397",
    "title": "Visual Prompting Upgrades Neural Network Sparsification: A Data-Model  Perspective",
    "abstract": "The rapid development of large-scale deep learning models questions the affordability of hardware platforms, which necessitates the pruning to reduce their computational and memory footprints. Sparse neural networks as the product, have demonstrated numerous favorable benefits like low complexity, undamaged generalization, etc. Most of the prominent pruning strategies are invented from a model-centric perspective, focusing on searching and preserving crucial weights by analyzing network topologies. However, the role of data and its interplay with model-centric pruning has remained relatively unexplored. In this research, we introduce a novel data-model co-design perspective: to promote superior weight sparsity by learning important model topology and adequate input data in a synergetic manner. Specifically, customized Visual Prompts are mounted to upgrade neural Network sparsification in our proposed VPNs framework. As a pioneering effort, this paper conducts systematic investigations about the impact of different visual prompts on model pruning and suggests an effective joint optimization approach. Extensive experiments with 3 network architectures and 8 datasets evidence the substantial performance improvements from VPNs over existing start-of-the-art pruning algorithms. Furthermore, we find that subnetworks discovered by VPNs from pre-trained models enjoy better transferability across diverse downstream scenarios. These insights shed light on new promising possibilities of data-model co-designs for vision model sparsification. ",
    "url": "https://arxiv.org/abs/2312.01397",
    "authors": [
      "Can Jin",
      "Tianjin Huang",
      "Yihua Zhang",
      "Mykola Pechenizkiy",
      "Sijia Liu",
      "Shiwei Liu",
      "Tianlong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01403",
    "title": "OplixNet: Towards Area-Efficient Optical Split-Complex Networks with  Real-to-Complex Data Assignment and Knowledge Distillation",
    "abstract": "Having the potential for high speed, high throughput, and low energy cost, optical neural networks (ONNs) have emerged as a promising candidate for accelerating deep learning tasks. In conventional ONNs, light amplitudes are modulated at the input and detected at the output. However, the light phases are still ignored in conventional structures, although they can also carry information for computing. To address this issue, in this paper, we propose a framework called OplixNet to compress the areas of ONNs by modulating input image data into the amplitudes and phase parts of light signals. The input and output parts of the ONNs are redesigned to make full use of both amplitude and phase information. Moreover, mutual learning across different ONN structures is introduced to maintain the accuracy. Experimental results demonstrate that the proposed framework significantly reduces the areas of ONNs with the accuracy within an acceptable range. For instance, 75.03% area is reduced with a 0.33% accuracy decrease on fully connected neural network (FCNN) and 74.88% area is reduced with a 2.38% accuracy decrease on ResNet-32. ",
    "url": "https://arxiv.org/abs/2312.01403",
    "authors": [
      "Ruidi Qiu",
      "Amro Eldebiky",
      "Grace Li Zhang",
      "Xunzhao Yin",
      "Cheng Zhuo",
      "Ulf Schlichtmann",
      "Bing Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.01424",
    "title": "Batch Hop-Constrained s-t Simple Path Query Processing in Large Graphs",
    "abstract": "Hop-constrained s-t simple path (HC-s-t path) enumeration is a fundamental problem in graph analysis. Existing solutions for this problem focus on optimizing the processing performance of a single query. However, in practice, it is more often that multiple HC-s-t path queries are issued simultaneously and processed as a batch. Therefore, we study the problem of batch HC-s-t path query processing in this paper and aim to compute the results of all queries concurrently and efficiently as a batch. To achieve this goal, we first propose the concept of HC-s path query which can precisely characterize the common computation among different queries.We then devise a two-phase HC-s path query detection algorithm to identify the common HC-s path queries for the given HC-s-t path queries. Based on the detected HC-s path queries, we further devise an efficient HC-s-t path enumeration algorithm in which the common computation represented by HC-s path queries are effectively shared. We conduct extensive experiments on real-world graphs and the experimental results demonstrate that our proposed algorithm is efficient and scalable regarding processing multiple HC-s-t path queries in large graphs at billion-scale. ",
    "url": "https://arxiv.org/abs/2312.01424",
    "authors": [
      "Kongzhang Hao",
      "Long Yuan",
      "Xuemin Lin",
      "Wenjie Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2312.01436",
    "title": "Robust Resource Partitioning Approach for ARINC 653 RTOS",
    "abstract": "Modern airborne operating systems implement the concept of robust time and resource partitioning imposed by the standards for aerospace and airborne-embedded software systems, such as ARINC 653. While these standards do provide a considerable amount of design choices in regards to resource partitioning on the architectural and API levels, such as isolated memory spaces between the application partitions, predefined resource configuration, and unidirectional ports with limited queue and message sizes for inter-partition communication, they do not specify how an operating system should implement them in software. Furthermore, they often tend to set the minimal level of the required guarantees, for example, in terms of memory permissions, and disregard the hardware state of the art, which presently can provide considerably stronger guarantees at no extra cost. In the paper we present an architecture of robust resource partitioning for ARINC 653 real-time operating systems based on completely static MMU configuration. The architecture was implemented on different types of airborne hardware, including platforms with TLB-based and page table-based MMU. Key benefits of the proposed approach include minimised run-time overhead and simpler verification of the memory subsystem. ",
    "url": "https://arxiv.org/abs/2312.01436",
    "authors": [
      "Vitaly Cheptsov",
      "Alexey Khoroshilov"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2312.01445",
    "title": "Classification of Home Network Problems with Transformers",
    "abstract": "We propose a classifier that can identify ten common home network problems based on the raw textual output of networking tools such as ping, dig, and ip. Our deep learning model uses an encoder-only transformer architecture with a particular pre-tokenizer that we propose for splitting the tool output into token sequences. The use of transformers distinguishes our approach from related work on network problem classification, which still primarily relies on non-deep-learning methods. Our model achieves high accuracy in our experiments, demonstrating the high potential of transformer-based problem classification for the home network. ",
    "url": "https://arxiv.org/abs/2312.01445",
    "authors": [
      "Jeremias D\u00f6tterl",
      "Zahra Hemmati Fard"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01467",
    "title": "Online Dominating Set and Coloring for Geometric Intersection Graphs",
    "abstract": "We present online deterministic algorithms for minimum coloring and minimum dominating set problems in the context of geometric intersection graphs. We consider a graph parameter: the independent kissing number $\\zeta$, which is a number equal to `the size of the largest induced star in the graph $-1$'. For a graph with an independent kissing number at most $\\zeta$, we show that the famous greedy algorithm achieves an optimal competitive ratio of $\\zeta$ for the minimum dominating set and the minimum independent dominating set problems. However, for the minimum connected dominating set problem, we obtain a competitive ratio of at most $2\\zeta$. To complement this, we prove that for the minimum connected dominating set problem, any deterministic online algorithm has a competitive ratio of at least $2(\\zeta-1)$ for the geometric intersection graph of translates of a convex object in $\\mathbb{R}^2$. Next, for the minimum coloring problem, we obtain algorithms having a competitive ratio of $O\\left({\\zeta'}{\\log m}\\right)$ for geometric intersection graphs of bounded scaled $\\alpha$-fat objects in $\\mathbb{R}^d$ having widths in the interval $[1,m]$, where $\\zeta'$ is the independent kissing number of the geometric intersection graph of bounded scaled $\\alpha$-fat objects having widths in the interval $[1,2]$. Finally, we investigate the value of $\\zeta$ for geometric intersection graphs of various families of geometric objects. ",
    "url": "https://arxiv.org/abs/2312.01467",
    "authors": [
      "Minati De",
      "Sambhav Khurana",
      "Satyam Singh"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2312.01468",
    "title": "Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in  Autonomous Driving",
    "abstract": "Our study assesses the adversarial robustness of LiDAR-camera fusion models in 3D object detection. We introduce an attack technique that, by simply adding a limited number of physically constrained adversarial points above a car, can make the car undetectable by the fusion model. Experimental results reveal that even without changes to the image data channel, the fusion model can be deceived solely by manipulating the LiDAR data channel. This finding raises safety concerns in the field of autonomous driving. Further, we explore how the quantity of adversarial points, the distance between the front-near car and the LiDAR-equipped car, and various angular factors affect the attack success rate. We believe our research can contribute to the understanding of multi-sensor robustness, offering insights and guidance to enhance the safety of autonomous driving. ",
    "url": "https://arxiv.org/abs/2312.01468",
    "authors": [
      "Bo Yang",
      "Xiaoyu Ji",
      "Xiaoyu Ji",
      "Xiaoyu Ji",
      "Xiaoyu Ji"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01488",
    "title": "ADT: Agent-based Dynamic Thresholding for Anomaly Detection",
    "abstract": "The complexity and scale of IT systems are increasing dramatically, posing many challenges to real-world anomaly detection. Deep learning anomaly detection has emerged, aiming at feature learning and anomaly scoring, which has gained tremendous success. However, little work has been done on the thresholding problem despite it being a critical factor for the effectiveness of anomaly detection. In this paper, we model thresholding in anomaly detection as a Markov Decision Process and propose an agent-based dynamic thresholding (ADT) framework based on a deep Q-network. The proposed method can be integrated into many systems that require dynamic thresholding. An auto-encoder is utilized in this study to obtain feature representations and produce anomaly scores for complex input data. ADT can adjust thresholds adaptively by utilizing the anomaly scores from the auto-encoder and significantly improve anomaly detection performance. The properties of ADT are studied through experiments on three real-world datasets and compared with benchmarks, hence demonstrating its thresholding capability, data-efficient learning, stability, and robustness. Our study validates the effectiveness of reinforcement learning in optimal thresholding control in anomaly detection. ",
    "url": "https://arxiv.org/abs/2312.01488",
    "authors": [
      "Xue Yang",
      "Enda Howley",
      "Micheal Schukat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01490",
    "title": "GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment  Draping",
    "abstract": "Recent neural, physics-based modeling of garment deformations allows faster and visually aesthetic results as opposed to the existing methods. Material-specific parameters are used by the formulation to control the garment inextensibility. This delivers unrealistic results with physically implausible stretching. Oftentimes, the draped garment is pushed inside the body which is either corrected by an expensive post-processing, thus adding to further inconsistent stretching; or by deploying a separate training regime for each body type, restricting its scalability. Additionally, the flawed skinning process deployed by existing methods produces incorrect results on loose garments. In this paper, we introduce a geometrical constraint to the existing formulation that is collision-aware and imposes garment inextensibility wherever possible. Thus, we obtain realistic results where draped clothes stretch only while covering bigger body regions. Furthermore, we propose a geometry-aware garment skinning method by defining a body-garment closeness measure which works for all garment types, especially the loose ones. ",
    "url": "https://arxiv.org/abs/2312.01490",
    "authors": [
      "Ruochen Chen",
      "Liming Chen",
      "Shaifali Parashar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01498",
    "title": "Learning Neural Traffic Rules",
    "abstract": "Extensive research has been devoted to the field of multi-agent navigation. Recently, there has been remarkable progress attributed to the emergence of learning-based techniques with substantially elevated intelligence and realism. Nonetheless, prevailing learned models face limitations in terms of scalability and effectiveness, primarily due to their agent-centric nature, i.e., the learned neural policy is individually deployed on each agent. Inspired by the efficiency observed in real-world traffic networks, we present an environment-centric navigation policy. Our method learns a set of traffic rules to coordinate a vast group of unintelligent agents that possess only basic collision-avoidance capabilities. Our method segments the environment into distinct blocks and parameterizes the traffic rule using a Graph Recurrent Neural Network (GRNN) over the block network. Each GRNN node is trained to modulate the velocities of agents as they traverse through. Using either Imitation Learning (IL) or Reinforcement Learning (RL) schemes, we demonstrate the efficacy of our neural traffic rules in resolving agent congestion, closely resembling real-world traffic regulations. Our method handles up to $240$ agents at real-time and generalizes across diverse agent and environment configurations. ",
    "url": "https://arxiv.org/abs/2312.01498",
    "authors": [
      "Xuan Zhang",
      "Xifeng Gao",
      "Kui Wu",
      "Zherong Pan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.01502",
    "title": "Normed Spaces for Graph Embedding",
    "abstract": "Theoretical results from discrete geometry suggest that normed spaces can abstractly embed finite metric spaces with surprisingly low theoretical bounds on distortion in low dimensions. In this paper, inspired by this theoretical insight, we highlight normed spaces as a more flexible and computationally efficient alternative to several popular Riemannian manifolds for learning graph embeddings. Normed space embeddings significantly outperform several popular manifolds on a large range of synthetic and real-world graph reconstruction benchmark datasets while requiring significantly fewer computational resources. We also empirically verify the superiority of normed space embeddings on growing families of graphs associated with negative, zero, and positive curvature, further reinforcing the flexibility of normed spaces in capturing diverse graph structures as graph sizes increase. Lastly, we demonstrate the utility of normed space embeddings on two applied graph embedding tasks, namely, link prediction and recommender systems. Our work highlights the potential of normed spaces for geometric graph representation learning, raises new research questions, and offers a valuable tool for experimental mathematics in the field of finite metric space embeddings. We make our code and data publically available. ",
    "url": "https://arxiv.org/abs/2312.01502",
    "authors": [
      "Diaaeldin Taha",
      "Wei Zhao",
      "J. Maxwell Riestenberg",
      "Michael Strube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.01521",
    "title": "Neural Markov Prolog",
    "abstract": "The recent rapid advance of AI has been driven largely by innovations in neural network architectures. A concomitant concern is how to understand these resulting systems. In this paper, we propose a tool to assist in both the design of further innovative architectures and the simple yet precise communication of their structure. We propose the language Neural Markov Prolog (NMP), based on both Markov logic and Prolog, as a means to both bridge first order logic and neural network design and to allow for the easy generation and presentation of architectures for images, text, relational databases, or other target data types or their mixtures. ",
    "url": "https://arxiv.org/abs/2312.01521",
    "authors": [
      "Alexander Thomson",
      "David Page"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2312.01522",
    "title": "G2D: From Global to Dense Radiography Representation Learning via  Vision-Language Pre-training",
    "abstract": "Recently, medical vision-language pre-training (VLP) has reached substantial progress to learn global visual representation from medical images and their paired radiology reports. However, medical imaging tasks in real world usually require finer granularity in visual features. These tasks include visual localization tasks (e.g., semantic segmentation, object detection) and visual grounding task. Yet, current medical VLP methods face challenges in learning these fine-grained features, as they primarily focus on brute-force alignment between image patches and individual text tokens for local visual feature learning, which is suboptimal for downstream dense prediction tasks. In this work, we propose a new VLP framework, named \\textbf{G}lobal to \\textbf{D}ense level representation learning (G2D) that achieves significantly improved granularity and more accurate grounding for the learned features, compared to existing medical VLP approaches. In particular, G2D learns dense and semantically-grounded image representations via a pseudo segmentation task parallel with the global vision-language alignment. Notably, generating pseudo segmentation targets does not incur extra trainable parameters: they are obtained on the fly during VLP with a parameter-free processor. G2D achieves superior performance across 6 medical imaging tasks and 25 diseases, particularly in semantic segmentation, which necessitates fine-grained, semantically-grounded image features. In this task, G2D surpasses peer models even when fine-tuned with just 1\\% of the training data, compared to the 100\\% used by these models. The code will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2312.01522",
    "authors": [
      "Che Liu",
      "Cheng Ouyang",
      "Sibo Cheng",
      "Anand Shah",
      "Wenjia Bai",
      "Rossella Arcucci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01524",
    "title": "Code Swarm: A Code Generation Tool Based on the Automatic Derivation of  Transformation Rule Set",
    "abstract": "Automatic generation of software code from system design models remains an actively explored research area for the past several years. A number of tools are currently available to facilitate and automate the task of generating code from software models. To the best of our knowledge, existing software tools rely on an explicitly defined transformation rule set to perform the model-to-code transformation process. In this paper, we introduce a novel tool named Code Swarm, abbreviated as CodS, that automatically generates implementation code from system design models by utilizing a swarm-based approach. Specifically, CodS is capable of generating Java code from the class and state models of the software system by making use of the previously solved model-to-code transformation examples. Our tool enables the designers to specify behavioural actions in the input models using the Action Specification Language (ASL). We use an industrial case study of the Elevator Control System (ECS) to perform the experimental validation of our tool. Our results indicate that the code generated by CodS is correct and consistent with the input design models. CodS performs the process of automatic code generation without taking the explicit transformation rule set or languages metamodels information as input, which distinguishes it from all the existing automatic code generation tools. ",
    "url": "https://arxiv.org/abs/2312.01524",
    "authors": [
      "Hina Mahmood",
      "Atif Aftab Jilani",
      "Abdul Rauf"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.01538",
    "title": "Recurrent Distance-Encoding Neural Networks for Graph Representation  Learning",
    "abstract": "Graph neural networks based on iterative one-hop message passing have been shown to struggle in harnessing information from distant nodes effectively. Conversely, graph transformers allow each node to attend to all other nodes directly, but suffer from high computational complexity and have to rely on ad-hoc positional encoding to bake in the graph inductive bias. In this paper, we propose a new architecture to reconcile these challenges. Our approach stems from the recent breakthroughs in long-range modeling provided by deep state-space models on sequential data: for a given target node, our model aggregates other nodes by their shortest distances to the target and uses a parallelizable linear recurrent network over the chain of distances to provide a natural encoding of its neighborhood structure. With no need for positional encoding, we empirically show that the performance of our model is highly competitive compared with that of state-of-the-art graph transformers on various benchmarks, at a drastically reduced computational complexity. In addition, we show that our model is theoretically more expressive than one-hop message passing neural networks. ",
    "url": "https://arxiv.org/abs/2312.01538",
    "authors": [
      "Yuhui Ding",
      "Antonio Orvieto",
      "Bobby He",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.01540",
    "title": "Robust Computer Vision in an Ever-Changing World: A Survey of Techniques  for Tackling Distribution Shifts",
    "abstract": "AI applications are becoming increasingly visible to the general public. There is a notable gap between the theoretical assumptions researchers make about computer vision models and the reality those models face when deployed in the real world. One of the critical reasons for this gap is a challenging problem known as distribution shift. Distribution shifts tend to vary with complexity of the data, dataset size, and application type. In our paper, we discuss the identification of such a prominent gap, exploring the concept of distribution shift and its critical significance. We provide an in-depth overview of various types of distribution shifts, elucidate their distinctions, and explore techniques within the realm of the data-centric domain employed to address them. Distribution shifts can occur during every phase of the machine learning pipeline, from the data collection stage to the stage of training a machine learning model to the stage of final model deployment. As a result, it raises concerns about the overall robustness of the machine learning techniques for computer vision applications that are deployed publicly for consumers. Different deep learning models each tailored for specific type of data and tasks, architectural pipelines; highlighting how variations in data preprocessing and feature extraction can impact robustness., data augmentation strategies (e.g. geometric, synthetic and learning-based); demonstrating their role in enhancing model generalization, and training mechanisms (e.g. transfer learning, zero-shot) fall under the umbrella of data-centric methods. Each of these components form an integral part of the neural-network we analyze contributing uniquely to strengthening model robustness against distribution shifts. We compare and contrast numerous AI models that are built for mitigating shifts in hidden stratification and spurious correlations, ... ",
    "url": "https://arxiv.org/abs/2312.01540",
    "authors": [
      "Eashan Adhikarla",
      "Kai Zhang",
      "Jun Yu",
      "Lichao Sun",
      "John Nicholson",
      "Brian D. Davison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01541",
    "title": "Revisiting Non-separable Binary Classification and its Applications in  Anomaly Detection",
    "abstract": "The inability to linearly classify XOR has motivated much of deep learning. We revisit this age-old problem and show that linear classification of XOR is indeed possible. Instead of separating data between halfspaces, we propose a slightly different paradigm, equality separation, that adapts the SVM objective to distinguish data within or outside the margin. Our classifier can then be integrated into neural network pipelines with a smooth approximation. From its properties, we intuit that equality separation is suitable for anomaly detection. To formalize this notion, we introduce closing numbers, a quantitative measure on the capacity for classifiers to form closed decision regions for anomaly detection. Springboarding from this theoretical connection between binary classification and anomaly detection, we test our hypothesis on supervised anomaly detection experiments, showing that equality separation can detect both seen and unseen anomalies. ",
    "url": "https://arxiv.org/abs/2312.01541",
    "authors": [
      "Matthew Lau",
      "Ismaila Seck",
      "Athanasios P Meliopoulos",
      "Wenke Lee",
      "Eugene Ndiaye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.01546",
    "title": "Learning Channel Capacity with Neural Mutual Information Estimator Based  on Message Importance Measure",
    "abstract": "Channel capacity estimation plays a crucial role in beyond 5G intelligent communications. Despite its significance, this task is challenging for a majority of channels, especially for the complex channels not modeled as the well-known typical ones. Recently, neural networks have been used in mutual information estimation and optimization. They are particularly considered as efficient tools for learning channel capacity. In this paper, we propose a cooperative framework to simultaneously estimate channel capacity and design the optimal codebook. First, we will leverage MIM-based GAN, a novel form of generative adversarial network (GAN) using message importance measure (MIM) as the information distance, into mutual information estimation, and develop a novel method, named MIM-based mutual information estimator (MMIE). Then, we design a generalized cooperative framework for channel capacity learning, in which a generator is regarded as an encoder producing the channel input, while a discriminator is the mutual information estimator that assesses the performance of the generator. Through the adversarial training, the generator automatically learns the optimal codebook and the discriminator estimates the channel capacity. Numerical experiments will demonstrate that compared with several conventional estimators, the MMIE achieves state-of-the-art performance in terms of accuracy and stability. ",
    "url": "https://arxiv.org/abs/2312.01546",
    "authors": [
      "Zhefan Li",
      "Rui She",
      "Pingyi Fan",
      "Chenghui Peng",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.01558",
    "title": "Hyperspectral Image Compression Using Sampling and Implicit Neural  Representations",
    "abstract": "Hyperspectral images, which record the electromagnetic spectrum for a pixel in the image of a scene, often store hundreds of channels per pixel and contain an order of magnitude more information than a similarly-sized RBG color image. Consequently, concomitant with the decreasing cost of capturing these images, there is a need to develop efficient techniques for storing, transmitting, and analyzing hyperspectral images. This paper develops a method for hyperspectral image compression using implicit neural representations where a multilayer perceptron network F with sinusoidal activation functions \"learns\" to map pixel locations to pixel intensities for a given hyperspectral image I. F thus acts as a compressed encoding of this image, and the original image is reconstructed by evaluating F at each pixel location. We use a sampling method with two factors: window size and sampling rate to reduce the compression time. We have evaluated our method on four benchmarks -- Indian Pines, Jasper Ridge, Pavia University, and Cuprite using PSNR and SSIM -- and we show that the proposed method achieves better compression than JPEG, JPEG2000, and PCA-DCT at low bitrates. Besides, we compare our results with the learning-based methods like PCA+JPEG2000, FPCA+JPEG2000, 3D DCT, 3D DWT+SVR, and WSRC and show the corresponding results in the \"Compression Results\" section. We also show that our methods with sampling achieve better speed and performance than our method without sampling. ",
    "url": "https://arxiv.org/abs/2312.01558",
    "authors": [
      "Shima Rezasoltani",
      "Faisal Z. Qureshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2312.01560",
    "title": "RaftGP: Random Fast Graph Partitioning",
    "abstract": "Graph partitioning (GP), a.k.a. community detection, is a classic problem that divides the node set of a graph into densely-connected blocks. Following prior work on the IEEE HPEC Graph Challenge benchmark and recent advances in graph machine learning, we propose a novel RAndom FasT Graph Partitioning (RaftGP) method based on an efficient graph embedding scheme. It uses the Gaussian random projection to extract community-preserving features from classic GP objectives. These features are fed into a graph neural network (GNN) to derive low-dimensional node embeddings. Surprisingly, our experiments demonstrate that a randomly initialized GNN even without training is enough for RaftGP to derive informative community-preserving embeddings and support high-quality GP. To enable the derived embeddings to tackle GP, we introduce a hierarchical model selection algorithm that simultaneously determines the number of blocks and the corresponding GP result. We evaluate RaftGP on the Graph Challenge benchmark and compare the performance with five baselines, where our method can achieve a better trade-off between quality and efficiency. In particular, compared to the baseline algorithm of the IEEE HPEC Graph Challenge, our method is 6.68x -- 23.9x faster on graphs with 1E3 -- 5E4 nodes and at least 64.5x faster on larger (1E5 node) graphs on which the baseline takes more than 1E4 seconds. Our method achieves better accuracy on all test cases. We also develop a new graph generator to address some limitations of the original generator in the benchmark. ",
    "url": "https://arxiv.org/abs/2312.01560",
    "authors": [
      "Yu Gao",
      "Meng Qin",
      "Yibin Ding",
      "Li Zeng",
      "Chaorui Zhang",
      "Weixi Zhang",
      "Wei Han",
      "Rongqian Zhao",
      "Bo Bai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.01561",
    "title": "Multi-View Person Matching and 3D Pose Estimation with Arbitrary  Uncalibrated Camera Networks",
    "abstract": "Cross-view person matching and 3D human pose estimation in multi-camera networks are particularly difficult when the cameras are extrinsically uncalibrated. Existing efforts generally require large amounts of 3D data for training neural networks or known camera poses for geometric constraints to solve the problem. However, camera poses and 3D data annotation are usually expensive and not always available. We present a method, PME, that solves the two tasks without requiring either information. Our idea is to address cross-view person matching as a clustering problem using each person as a cluster center, then obtain correspondences from person matches, and estimate 3D human poses through multi-view triangulation and bundle adjustment. We solve the clustering problem by introducing a \"size constraint\" using the number of cameras and a \"source constraint\" using the fact that two people from the same camera view should not match, to narrow the solution space to a small feasible region. The 2D human poses used in clustering are obtained through a pre-trained 2D pose detector, so our method does not require expensive 3D training data for each new scene. We extensively evaluate our method on three open datasets and two indoor and outdoor datasets collected using arbitrarily set cameras. Our method outperforms other methods by a large margin on cross-view person matching, reaches SOTA performance on 3D human pose estimation without using either camera poses or 3D training data, and shows good generalization ability across five datasets of various environment settings. ",
    "url": "https://arxiv.org/abs/2312.01561",
    "authors": [
      "Yan Xu",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01568",
    "title": "Multimodal Speech Emotion Recognition Using Modality-specific  Self-Supervised Frameworks",
    "abstract": "Emotion recognition is a topic of significant interest in assistive robotics due to the need to equip robots with the ability to comprehend human behavior, facilitating their effective interaction in our society. Consequently, efficient and dependable emotion recognition systems supporting optimal human-machine communication are required. Multi-modality (including speech, audio, text, images, and videos) is typically exploited in emotion recognition tasks. Much relevant research is based on merging multiple data modalities and training deep learning models utilizing low-level data representations. However, most existing emotion databases are not large (or complex) enough to allow machine learning approaches to learn detailed representations. This paper explores modalityspecific pre-trained transformer frameworks for self-supervised learning of speech and text representations for data-efficient emotion recognition while achieving state-of-the-art performance in recognizing emotions. This model applies feature-level fusion using nonverbal cue data points from motion capture to provide multimodal speech emotion recognition. The model was trained using the publicly available IEMOCAP dataset, achieving an overall accuracy of 77.58% for four emotions, outperforming state-of-the-art approaches ",
    "url": "https://arxiv.org/abs/2312.01568",
    "authors": [
      "Rutherford Agbeshi Patamia",
      "Paulo E. Santos",
      "Kingsley Nketia Acheampong",
      "Favour Ekong",
      "Kwabena Sarpong",
      "She Kun"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.01576",
    "title": "Learning Efficient Unsupervised Satellite Image-based Building Damage  Detection",
    "abstract": "Existing Building Damage Detection (BDD) methods always require labour-intensive pixel-level annotations of buildings and their conditions, hence largely limiting their applications. In this paper, we investigate a challenging yet practical scenario of BDD, Unsupervised Building Damage Detection (U-BDD), where only unlabelled pre- and post-disaster satellite image pairs are provided. As a pilot study, we have first proposed an advanced U-BDD baseline that leverages pre-trained vision-language foundation models (i.e., Grounding DINO, SAM and CLIP) to address the U-BDD task. However, the apparent domain gap between satellite and generic images causes low confidence in the foundation models used to identify buildings and their damages. In response, we further present a novel self-supervised framework, U-BDD++, which improves upon the U-BDD baseline by addressing domain-specific issues associated with satellite imagery. Furthermore, the new Building Proposal Generation (BPG) module and the CLIP-enabled noisy Building Proposal Selection (CLIP-BPS) module in U-BDD++ ensure high-quality self-training. Extensive experiments on the widely used building damage assessment benchmark demonstrate the effectiveness of the proposed method for unsupervised building damage detection. The presented annotation-free and foundation model-based paradigm ensures an efficient learning phase. This study opens a new direction for real-world BDD and sets a strong baseline for future research. ",
    "url": "https://arxiv.org/abs/2312.01576",
    "authors": [
      "Yiyun Zhang",
      "Zijian Wang",
      "Yadan Luo",
      "Xin Yu",
      "Zi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2312.01583",
    "title": "Efficient Collision Detection Oriented Motion Primitives for Path  Planning",
    "abstract": "Mobile robots in dynamic environments require fast planning, especially when onboard computational resources are limited. While classic potential field based algorithms may suffice in simple scenarios, in most cases algorithms able to escape local minima are necessary. Configuration-space search algorithms have proven to provide a good trade-off between quality of the solutions and search time. Literature presents a wide variety of approaches that speed up this search by reducing the number of edges that need to be inspected. Much less attention was instead given to reducing the time necessary to evaluate the cost of a single edge. This paper addresses this point by associating edges to motion primitives that prioritize fast collision detection. We show how biarcs can be used as motion primitives that enable fast collision detection, while still providing smooth, tangent continuous paths. The proposed approach does not assume a disc shaped hitbox, making it appealing for all robots with very different width and length or for differential drive robots with active wheels located far from the robot's center. ",
    "url": "https://arxiv.org/abs/2312.01583",
    "authors": [
      "Fabio DallaLibera",
      "Abe Shinya",
      "Ando Takeshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.01585",
    "title": "OCGEC: One-class Graph Embedding Classification for DNN Backdoor  Detection",
    "abstract": "Deep neural networks (DNNs) have been found vulnerable to backdoor attacks, raising security concerns about their deployment in mission-critical applications. There are various approaches to detect backdoor attacks, however they all make certain assumptions about the target attack to be detected and require equal and huge numbers of clean and backdoor samples for training, which renders these detection methods quite limiting in real-world circumstances. This study proposes a novel one-class classification framework called One-class Graph Embedding Classification (OCGEC) that uses GNNs for model-level backdoor detection with only a little amount of clean data. First, we train thousands of tiny models as raw datasets from a small number of clean datasets. Following that, we design a ingenious model-to-graph method for converting the model's structural details and weight features into graph data. We then pre-train a generative self-supervised graph autoencoder (GAE) to better learn the features of benign models in order to detect backdoor models without knowing the attack strategy. After that, we dynamically combine the GAE and one-class classifier optimization goals to form classification boundaries that distinguish backdoor models from benign models. Our OCGEC combines the powerful representation capabilities of graph neural networks with the utility of one-class classification techniques in the field of anomaly detection. In comparison to other baselines, it achieves AUC scores of more than 98% on a number of tasks, which far exceeds existing methods for detection even when they rely on a huge number of positive and negative samples. Our pioneering application of graphic scenarios for generic backdoor detection can provide new insights that can be used to improve other backdoor defense tasks. Code is available at https://github.com/jhy549/OCGEC. ",
    "url": "https://arxiv.org/abs/2312.01585",
    "authors": [
      "Haoyu Jiang",
      "Haiyang Yu",
      "Nan Li",
      "Ping Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.01588",
    "title": "ActiveClean: Generating Line-Level Vulnerability Data via Active  Learning",
    "abstract": "Deep learning vulnerability detection tools are increasing in popularity and have been shown to be effective. These tools rely on large volume of high quality training data, which are very hard to get. Most of the currently available datasets provide function-level labels, reporting whether a function is vulnerable or not vulnerable. However, for a vulnerability detection to be useful, we need to also know the lines that are relevant to the vulnerability. This paper makes efforts towards developing systematic tools and proposes. ActiveClean to generate the large volume of line-level vulnerability data from commits. That is, in addition to function-level labels, it also reports which lines in the function are likely responsible for vulnerability detection. In the past, static analysis has been applied to clean commits to generate line-level data. Our approach based on active learning, which is easy to use and scalable, provide a complementary approach to static analysis. We designed semantic and syntactic properties from commit lines and use them to train the model. We evaluated our approach on both Java and C datasets processing more than 4.3K commits and 119K commit lines. AcitveClean achieved an F1 score between 70-74. Further, we also show that active learning is effective by using just 400 training data to reach F1 score of 70.23. Using ActiveClean, we generate the line-level labels for the entire FFMpeg project in the Devign dataset, including 5K functions, and also detected incorrect function-level labels. We demonstrated that using our cleaned data, LineVul, a SOTA line-level vulnerability detection tool, detected 70 more vulnerable lines and 18 more vulnerable functions, and improved Top 10 accuracy from 66% to 73%. ",
    "url": "https://arxiv.org/abs/2312.01588",
    "authors": [
      "Ashwin Kallingal Joshy",
      "Mirza Sanjida Alam",
      "Shaila Sharmin",
      "Qi Li",
      "Wei Le"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01592",
    "title": "Expand BERT Representation with Visual Information via Grounded Language  Learning with Multimodal Partial Alignment",
    "abstract": "Language models have been supervised with both language-only objective and visual grounding in existing studies of visual-grounded language learning. However, due to differences in the distribution and scale of visual-grounded datasets and language corpora, the language model tends to mix up the context of the tokens that occurred in the grounded data with those that do not. As a result, during representation learning, there is a mismatch between the visual information and the contextual meaning of the sentence. To overcome this limitation, we propose GroundedBERT - a grounded language learning method that enhances the BERT representation with visually grounded information. GroundedBERT comprises two components: (i) the original BERT which captures the contextual representation of words learned from the language corpora, and (ii) a visual grounding module which captures visual information learned from visual-grounded datasets. Moreover, we employ Optimal Transport (OT), specifically its partial variant, to solve the fractional alignment problem between the two modalities. Our proposed method significantly outperforms the baseline language models on various language tasks of the GLUE and SQuAD datasets. ",
    "url": "https://arxiv.org/abs/2312.01592",
    "authors": [
      "Cong-Duy Nguyen",
      "The-Anh Vu-Le",
      "Thong Nguyen",
      "Tho Quan",
      "Luu Anh Tuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.01601",
    "title": "Local-Global History-aware Contrastive Learning for Temporal Knowledge  Graph Reasoning",
    "abstract": "Temporal knowledge graphs (TKGs) have been identified as a promising approach to represent the dynamics of facts along the timeline. The extrapolation of TKG is to predict unknowable facts happening in the future, holding significant practical value across diverse fields. Most extrapolation studies in TKGs focus on modeling global historical fact repeating and cyclic patterns, as well as local historical adjacent fact evolution patterns, showing promising performance in predicting future unknown facts. Yet, existing methods still face two major challenges: (1) They usually neglect the importance of historical information in KG snapshots related to the queries when encoding the local and global historical information; (2) They exhibit weak anti-noise capabilities, which hinders their performance when the inputs are contaminated with noise.To this end, we propose a novel \\blue{Lo}cal-\\blue{g}lobal history-aware \\blue{C}ontrastive \\blue{L}earning model (\\blue{LogCL}) for TKG reasoning, which adopts contrastive learning to better guide the fusion of local and global historical information and enhance the ability to resist interference. Specifically, for the first challenge, LogCL proposes an entity-aware attention mechanism applied to the local and global historical facts encoder, which captures the key historical information related to queries. For the latter issue, LogCL designs four historical query contrast patterns, effectively improving the robustness of the model. The experimental results on four benchmark datasets demonstrate that LogCL delivers better and more robust performance than the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2312.01601",
    "authors": [
      "Wei Chen",
      "Huaiyu Wan",
      "Yuting Wu",
      "Shuyuan Zhao",
      "Jiayaqi Cheng",
      "Yuxin Li",
      "Youfang Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01605",
    "title": "TextAug: Test time Text Augmentation for Multimodal Person  Re-identification",
    "abstract": "Multimodal Person Reidentification is gaining popularity in the research community due to its effectiveness compared to counter-part unimodal frameworks. However, the bottleneck for multimodal deep learning is the need for a large volume of multimodal training examples. Data augmentation techniques such as cropping, flipping, rotation, etc. are often employed in the image domain to improve the generalization of deep learning models. Augmenting in other modalities than images, such as text, is challenging and requires significant computational resources and external data sources. In this study, we investigate the effectiveness of two computer vision data augmentation techniques: cutout and cutmix, for text augmentation in multi-modal person re-identification. Our approach merges these two augmentation strategies into one strategy called CutMixOut which involves randomly removing words or sub-phrases from a sentence (Cutout) and blending parts of two or more sentences to create diverse examples (CutMix) with a certain probability assigned to each operation. This augmentation was implemented at inference time without any prior training. Our results demonstrate that the proposed technique is simple and effective in improving the performance on multiple multimodal person re-identification benchmarks. ",
    "url": "https://arxiv.org/abs/2312.01605",
    "authors": [
      "Mulham Fawakherji",
      "Eduard Vazquez",
      "Pasquale Giampa",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01607",
    "title": "Monte Carlo Experiments of Network Effects in Randomized Controlled  Trials",
    "abstract": "I run Monte Carlo simulations of content production over random Watts-Strogatz graphs to show various effects relevant to modeling and understanding Randomized Controlled Trials on social networks: the network effect, spillover effect, experiment dampening effect, intrinsic dampening effect, clustering effect, degree distribution effect and the experiment size effect. I will also define some simple metrics to measure their strength. When running experiments these potentially unexpected effects must be understood and controlled for in some manner, such as modeling the underlying graph structure to establish a baseline. ",
    "url": "https://arxiv.org/abs/2312.01607",
    "authors": [
      "M\u00e1rton Trencs\u00e9ni"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.01612",
    "title": "xNeuSM: Explainable Neural Subgraph Matching with Graph Learnable  Multi-hop Attention Networks",
    "abstract": "Subgraph matching is a challenging problem with a wide range of applications in database systems, biochemistry, and cognitive science. It involves determining whether a given query graph is present within a larger target graph. Traditional graph-matching algorithms provide precise results but face challenges in large graph instances due to the NP-complete problem, limiting their practical applicability. In contrast, recent neural network-based approximations offer more scalable solutions, but often lack interpretable node correspondences. To address these limitations, this article presents xNeuSM: Explainable Neural Subgraph Matching which introduces Graph Learnable Multi-hop Attention Networks (GLeMA) that adaptively learns the parameters governing the attention factor decay for each node across hops rather than relying on fixed hyperparameters. We provide a theoretical analysis establishing error bounds for GLeMA's approximation of multi-hop attention as a function of the number of hops. Additionally, we prove that learning distinct attention decay factors for each node leads to a correct approximation of multi-hop attention. Empirical evaluation on real-world datasets shows that xNeuSM achieves substantial improvements in prediction accuracy of up to 34% compared to approximate baselines and, notably, at least a seven-fold faster query time than exact algorithms. The source code of our implementation is available at https://github.com/martinakaduc/xNeuSM. ",
    "url": "https://arxiv.org/abs/2312.01612",
    "authors": [
      "Duc Q. Nguyen",
      "Thanh Toan Nguyen",
      "Tho quan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01617",
    "title": "Heroes: Lightweight Federated Learning with Neural Composition and  Adaptive Local Update in Heterogeneous Edge Networks",
    "abstract": "Federated Learning (FL) enables distributed clients to collaboratively train models without exposing their private data. However, it is difficult to implement efficient FL due to limited resources. Most existing works compress the transmitted gradients or prune the global model to reduce the resource cost, but leave the compressed or pruned parameters under-optimized, which degrades the training performance. To address this issue, the neural composition technique constructs size-adjustable models by composing low-rank tensors, allowing every parameter in the global model to learn the knowledge from all clients. Nevertheless, some tensors can only be optimized by a small fraction of clients, thus the global model may get insufficient training, leading to a long completion time, especially in heterogeneous edge scenarios. To this end, we enhance the neural composition technique, enabling all parameters to be fully trained. Further, we propose a lightweight FL framework, called Heroes, with enhanced neural composition and adaptive local update. A greedy-based algorithm is designed to adaptively assign the proper tensors and local update frequencies for participating clients according to their heterogeneous capabilities and resource budgets. Extensive experiments demonstrate that Heroes can reduce traffic consumption by about 72.05\\% and provide up to 2.97$\\times$ speedup compared to the baselines. ",
    "url": "https://arxiv.org/abs/2312.01617",
    "authors": [
      "Jiaming Yan",
      "Jianchun Liu",
      "Shilong Wang",
      "Hongli Xu",
      "Haifeng Liu",
      "Jianhua Zhou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.01625",
    "title": "Interference-Constrained Scheduling of a Cognitive Multi-hop Underwater  Acoustic Network",
    "abstract": "This paper investigates optimal scheduling for a cognitive multi-hop underwater acoustic network with a primary user interference constraint. The network consists of primary and secondary users, with multi-hop transmission adopted for both user types to provide reliable communications. Critical characteristics of underwater acoustic channels, including significant propagation delay, distance-and-frequency dependent attenuation, half-duplex modem, and inter-hop interference, are taken into account in the design and analysis. In particular, time-slot allocation is found to be more effective than frequency-slot allocation due to the underwater channel model. The goal of the network scheduling problem is to maximize the end-to-end throughput of the overall system while limiting the throughput loss of primary users. Both centralized and decentralized approaches are considered. Partially Observable Markov Decision Processes (POMDP) framework is applied to formulate the optimization problem, and an optimal dynamic programming algorithm is derived. However, the optimal dynamic programming solution is computationally intractable. Key properties are shown for the objective function, enabling the design of approximate schemes with significant complexity reduction. Numerical results show that the proposed schemes significantly increase system throughput while maintaining the primary throughput loss constraint. Under certain traffic conditions, the throughput gain over frequency-slot allocation schemes can be as high as 50%. ",
    "url": "https://arxiv.org/abs/2312.01625",
    "authors": [
      "Chen Peng",
      "Urbashi Mitra"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.01632",
    "title": "GaussianHead: Impressive 3D Gaussian-based Head Avatars with Dynamic  Hybrid Neural Field",
    "abstract": "Previous head avatar methods have mostly relied on fixed explicit primitives (mesh, point) or implicit surfaces (Sign Distance Function) and volumetric neural radiance field, it challenging to strike a balance among high fidelity, training speed, and resource consumption. The recent popularity of hybrid field has brought novel representation, but is limited by relying on parameterization factors obtained through fixed mappings. We propose GaussianHead: an head avatar algorithm based on anisotropic 3D gaussian primitives. We leverage canonical gaussians to represent dynamic scenes. Using explicit \"dynamic\" tri-plane as an efficient container for parameterized head geometry, aligned well with factors in the underlying geometry and tri-plane, we obtain aligned canonical factors for the canonical gaussians. With a tiny MLP, factors are decoded into opacity and spherical harmonic coefficients of 3D gaussian primitives. Finally, we use efficient differentiable gaussian rasterizer for rendering. Our approach benefits significantly from our novel representation based on 3D gaussians, and the proper alignment transformation of underlying geometry structures and factors in tri-plane eliminates biases introduced by fixed mappings. Compared to state-of-the-art techniques, we achieve optimal visual results in tasks such as self-reconstruction, novel view synthesis, and cross-identity reenactment while maintaining high rendering efficiency (0.12s per frame). Even the pores around the nose are clearly visible in some cases. Code and additional video can be found on the project homepage. ",
    "url": "https://arxiv.org/abs/2312.01632",
    "authors": [
      "Jie Wang",
      "Xianyan Li",
      "Jiucheng Xie",
      "Feng Xu",
      "Hao Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01634",
    "title": "Robust Streaming, Sampling, and a Perspective on Online Learning",
    "abstract": "In this work we present an overview of statistical learning, followed by a survey of robust streaming techniques and challenges, culminating in several rigorous results proving the relationship that we motivate and hint at throughout the journey. Furthermore, we unify often disjoint theorems in a shared framework and notation to clarify the deep connections that are discovered. We hope that by approaching these results from a shared perspective, already aware of the technical connections that exist, we can enlighten the study of both fields and perhaps motivate new and previously unconsidered directions of research. ",
    "url": "https://arxiv.org/abs/2312.01634",
    "authors": [
      "Evan Dogariu",
      "Jiatong Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.01639",
    "title": "On the Effectiveness of Large Language Models in Domain-Specific Code  Generation",
    "abstract": "Large language models (LLMs) such as ChatGPT have shown remarkable capabilities in code generation. Despite their great success, their effectiveness within particular domains (e.g., web development) necessitates further evaluation. In this study, we conduct an empirical study of domain-specific code generation with LLMs. We demonstrate that LLMs exhibit sub-optimal performance in generating domain-specific code, due to their limited proficiency in utilizing domain-specific libraries. We further observe that incorporating API knowledge as prompts can empower LLMs to generate more professional code. Based on these findings, we further investigate how to efficiently incorporate API knowledge into the code generation process. We experiment with three strategies for incorporating domain knowledge, namely, external knowledge inquirer, chain-of-thought prompting, and chain-of-thought fine-tuning. We refer to these strategies as a new code generation approach called DomCoder. Experimental results show that all strategies of DomCoder lead to improvement in the effectiveness of domain-specific code generation under certain settings. The results also show that there is still ample room for further improvement, based on which we suggest possible future works. ",
    "url": "https://arxiv.org/abs/2312.01639",
    "authors": [
      "Meng Chen",
      "Hongyu Zhang",
      "Chengcheng Wan",
      "Zhao Wei",
      "Yong Xu",
      "Juhong Wang",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.01648",
    "title": "Characterizing Large Language Model Geometry Solves Toxicity Detection  and Generation",
    "abstract": "Large Language Models~(LLMs) drive current AI breakthroughs despite very little being known about their internal representations, e.g., how to extract a few informative features to solve various downstream tasks. To provide a practical and principled answer, we propose to characterize LLMs from a geometric perspective. We obtain in closed form (i) the intrinsic dimension in which the Multi-Head Attention embeddings are constrained to exist and (ii) the partition and per-region affine mappings of the per-layer feedforward networks. Our results are informative, do not rely on approximations, and are actionable. First, we show that, motivated by our geometric interpretation, we can bypass Llama$2$'s RLHF by controlling its embedding's intrinsic dimension through informed prompt manipulation. Second, we derive $7$ interpretable spline features that can be extracted from any (pre-trained) LLM layer, providing a rich abstract representation of their inputs. Those features alone ($224$ for Mistral-7B and Llama$2$-7B) are sufficient to help solve toxicity detection, infer the domain of the prompt, and even tackle the Jigsaw challenge, which aims at characterizing the type of toxicity of various prompts. Our results demonstrate how, even in large-scale regimes, exact theoretical results can answer practical questions in language models. Code: \\url{https://github.com/RandallBalestriero/SplineLLM}. ",
    "url": "https://arxiv.org/abs/2312.01648",
    "authors": [
      "Randall Balestriero",
      "Romain Cosentino",
      "Sarath Shekkizhar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01653",
    "title": "An End-to-End Network Pruning Pipeline with Sparsity Enforcement",
    "abstract": "Neural networks have emerged as a powerful tool for solving complex tasks across various domains, but their increasing size and computational requirements have posed significant challenges in deploying them on resource-constrained devices. Neural network sparsification, and in particular pruning, has emerged as an effective technique to alleviate these challenges by reducing model size, computational complexity, and memory footprint while maintaining competitive performance. However, many pruning pipelines modify the standard training pipeline at only a single stage, if at all. In this work, we look to develop an end-to-end training pipeline that befits neural network pruning and sparsification at all stages of training. To do so, we make use of nonstandard model parameter initialization, pre-pruning training methodologies, and post-pruning training optimizations. We conduct experiments utilizing combinations of these methods, in addition to different techniques used in the pruning step, and find that our combined pipeline can achieve significant gains over current state of the art approaches to neural network sparsification. ",
    "url": "https://arxiv.org/abs/2312.01653",
    "authors": [
      "Evan Dogariu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01657",
    "title": "On Tuning Neural ODE for Stability, Consistency and Faster Convergence",
    "abstract": "Neural-ODE parameterize a differential equation using continuous depth neural network and solve it using numerical ODE-integrator. These models offer a constant memory cost compared to models with discrete sequence of hidden layers in which memory cost increases linearly with the number of layers. In addition to memory efficiency, other benefits of neural-ode include adaptability of evaluation approach to input, and flexibility to choose numerical precision or fast training. However, despite having all these benefits, it still has some limitations. We identify the ODE-integrator (also called ODE-solver) as the weakest link in the chain as it may have stability, consistency and convergence (CCS) issues and may suffer from slower convergence or may not converge at all. We propose a first-order Nesterov's accelerated gradient (NAG) based ODE-solver which is proven to be tuned vis-a-vis CCS conditions. We empirically demonstrate the efficacy of our approach by training faster, while achieving better or comparable performance against neural-ode employing other fixed-step explicit ODE-solvers as well discrete depth models such as ResNet in three different tasks including supervised classification, density estimation, and time-series modelling. ",
    "url": "https://arxiv.org/abs/2312.01657",
    "authors": [
      "Sheikh Waqas Akhtar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.01672",
    "title": "STADEE: STAtistics-based DEEp Detection of Machine Generated Text",
    "abstract": "We present STADEE, a \\textbf{STA}tistics-based \\textbf{DEE}p detection method to identify machine-generated text, addressing the limitations of current methods that rely heavily on fine-tuning pre-trained language models (PLMs). STADEE integrates key statistical text features with a deep classifier, focusing on aspects like token probability and cumulative probability, crucial for handling nucleus sampling. Tested across diverse datasets and scenarios (in-domain, out-of-domain, and in-the-wild), STADEE demonstrates superior performance, achieving an 87.05% F1 score in-domain and outperforming both traditional statistical methods and fine-tuned PLMs, especially in out-of-domain and in-the-wild settings, highlighting its effectiveness and generalizability. ",
    "url": "https://arxiv.org/abs/2312.01672",
    "authors": [
      "Zheng Chen",
      "Huming Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01677",
    "title": "Multi-task Image Restoration Guided By Robust DINO Features",
    "abstract": "Multi-task image restoration has gained significant interest due to its inherent versatility and efficiency compared to its single-task counterpart. Despite its potential, performance degradation is observed with an increase in the number of tasks, primarily attributed to the distinct nature of each restoration task. Addressing this challenge, we introduce \\mbox{\\textbf{DINO-IR}}, a novel multi-task image restoration approach leveraging robust features extracted from DINOv2. Our empirical analysis shows that while shallow features of DINOv2 capture rich low-level image characteristics, the deep features ensure a robust semantic representation insensitive to degradations while preserving high-frequency contour details. Building on these features, we devise specialized components, including multi-layer semantic fusion module, DINO-Restore adaption and fusion module, and DINO perception contrastive loss, to integrate DINOv2 features into the restoration paradigm. Equipped with the aforementioned components, our DINO-IR performs favorably against existing multi-task image restoration approaches in various tasks by a large margin, indicating the superiority and necessity of reinforcing the robust features for multi-task image restoration. ",
    "url": "https://arxiv.org/abs/2312.01677",
    "authors": [
      "Xin Lin",
      "Chao Ren",
      "Kelvin C.K. Chan",
      "Lu Qi",
      "Jinshan Pan",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01681",
    "title": "Malicious Lateral Movement in 5G Core With Network Slicing And Its  Detection",
    "abstract": "5G networks are susceptible to cyber attacks due to reasons such as implementation issues and vulnerabilities in 3GPP standard specifications. In this work, we propose lateral movement strategies in a 5G Core (5GC) with network slicing enabled, as part of a larger attack campaign by well-resourced adversaries such as APT groups. Further, we present 5GLatte, a system to detect such malicious lateral movement. 5GLatte operates on a host-container access graph built using host/NF container logs collected from the 5GC. Paths inferred from the access graph are scored based on selected filtering criteria and subsequently presented as input to a threshold-based anomaly detection algorithm to reveal malicious lateral movement paths. We evaluate 5GLatte on a dataset containing attack campaigns (based on MITRE ATT&CK and FiGHT frameworks) launched in a 5G test environment which shows that compared to other lateral movement detectors based on state-of-the-art, it can achieve higher true positive rates with similar false positive rates. ",
    "url": "https://arxiv.org/abs/2312.01681",
    "authors": [
      "Ayush Kumar",
      "Vrizlynn L.L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.01687",
    "title": "Optimizing Bus Travel: A Novel Approach to Feature Mining with P-KMEANS  and P-LDA Algorithms",
    "abstract": "Customizing services for bus travel can bolster its attractiveness, optimize usage, alleviate traffic congestion, and diminish carbon emissions. This potential is realized by harnessing recent advancements in positioning communication facilities, the Internet of Things, and artificial intelligence for feature mining in public transportation. However, the inherent complexities of disorganized and unstructured public transportation data introduce substantial challenges to travel feature extraction. This study presents a bus travel feature extraction method rooted in Point of Interest (POI) data, employing enhanced P-KMENAS and P-LDA algorithms to overcome these limitations. While the KMEANS algorithm adeptly segments passenger travel paths into distinct clusters, its outcomes can be influenced by the initial K value. On the other hand, Latent Dirichlet Allocation (LDA) excels at feature identification and probabilistic interpretations yet encounters difficulties with feature intermingling and nuanced sub-feature interactions. Incorporating the POI dimension enhances our understanding of travel behavior, aligning it more closely with passenger attributes and facilitating easier data analysis. By incorporating POI data, our refined P-KMENAS and P-LDA algorithms grant a holistic insight into travel behaviors and attributes, effectively mitigating the limitations above. Consequently, this POI-centric algorithm effectively amalgamates diverse POI attributes, delineates varied travel contexts, and imparts probabilistic metrics to feature properties. Our method successfully mines the diverse aspects of bus travel, such as age, occupation, gender, sports, cost, safety, and personality traits. It effectively calculates relationships between individual travel behaviors and assigns explanatory and evaluative probabilities to POI labels, thereby enhancing bus travel optimization. ",
    "url": "https://arxiv.org/abs/2312.01687",
    "authors": [
      "Hongjie Liu",
      "Haotian Shi",
      "Sicheng Fu",
      "Tengfei Yuan",
      "Xinhuan Zhang",
      "Hongzhe Xu",
      "Bin Ran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01688",
    "title": "Tab-Attention: Self-Attention-based Stacked Generalization for  Imbalanced Credit Default Prediction",
    "abstract": "Accurately credit default prediction faces challenges due to imbalanced data and low correlation between features and labels. Existing default prediction studies on the basis of gradient boosting decision trees (GBDT), deep learning techniques, and feature selection strategies can have varying degrees of success depending on the specific task. Motivated by this, we propose Tab-Attention, a novel self-attention-based stacked generalization method for credit default prediction. This approach ensembles the potential proprietary knowledge contributions from multi-view feature spaces, to cope with low feature correlation and imbalance. We organize multi-view feature spaces according to the latent linear or nonlinear strengths between features and labels. Meanwhile, the f1 score assists the model in imbalance training to find the optimal state for identifying minority default samples. Our Tab-Attention achieves superior Recall_1 and f1_1 of default intention recognition than existing GBDT-based models and advanced deep learning by about 32.92% and 16.05% on average, respectively, while maintaining outstanding overall performance and prediction performance for non-default samples. The proposed method could ensemble essential knowledge through the self-attention mechanism, which is of great significance for a more robust future prediction system. ",
    "url": "https://arxiv.org/abs/2312.01688",
    "authors": [
      "Yandan Tan",
      "Hongbin Zhu",
      "JieWu",
      "Hongfeng Chai"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2312.01696",
    "title": "BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection",
    "abstract": "Recently, the rise of query-based Transformer decoders is reshaping camera-based 3D object detection. These query-based decoders are surpassing the traditional dense BEV (Bird's Eye View)-based methods. However, we argue that dense BEV frameworks remain important due to their outstanding abilities in depth estimation and object localization, depicting 3D scenes accurately and comprehensively. This paper aims to address the drawbacks of the existing dense BEV-based 3D object detectors by introducing our proposed enhanced components, including a CRF-modulated depth estimation module enforcing object-level consistencies, a long-term temporal aggregation module with extended receptive fields, and a two-stage object decoder combining perspective techniques with CRF-modulated depth embedding. These enhancements lead to a \"modernized\" dense BEV framework dubbed BEVNeXt. On the nuScenes benchmark, BEVNeXt outperforms both BEV-based and query-based frameworks under various settings, achieving a state-of-the-art result of 64.2 NDS on the nuScenes test set. ",
    "url": "https://arxiv.org/abs/2312.01696",
    "authors": [
      "Zhenxin Li",
      "Shiyi Lan",
      "Jose M. Alvarez",
      "Zuxuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01713",
    "title": "Disentangled Interaction Representation for One-Stage Human-Object  Interaction Detection",
    "abstract": "Human-Object Interaction (HOI) detection is a core task for human-centric image understanding. Recent one-stage methods adopt a transformer decoder to collect image-wide cues that are useful for interaction prediction; however, the interaction representations obtained using this method are entangled and lack interpretability. In contrast, traditional two-stage methods benefit significantly from their ability to compose interaction features in a disentangled and explainable manner. In this paper, we improve the performance of one-stage methods by enabling them to extract disentangled interaction representations. First, we propose Shunted Cross-Attention (SCA) to extract human appearance, object appearance, and global context features using different cross-attention heads. This is achieved by imposing different masks on the cross-attention maps produced by the different heads. Second, we introduce the Interaction-aware Pose Estimation (IPE) task to learn interaction-relevant human pose features using a disentangled decoder. This is achieved with a novel attention module that accurately captures the human keypoints relevant to the current interaction category. Finally, our approach fuses the appearance feature and pose feature via element-wise addition to form the interaction representation. Experimental results show that our approach can be readily applied to existing one-stage HOI detectors. Moreover, we achieve state-of-the-art performance on two benchmarks: HICO-DET and V-COCO. ",
    "url": "https://arxiv.org/abs/2312.01713",
    "authors": [
      "Xubin Zhong",
      "Changxing Ding",
      "Yupeng Hu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01721",
    "title": "The Self-Loop Paradox: Investigating the Impact of Self-Loops on Graph  Neural Networks",
    "abstract": "Many Graph Neural Networks (GNNs) add self-loops to a graph to include feature information about a node itself at each layer. However, if the GNN consists of more than one layer, this information can return to its origin via cycles in the graph topology. Intuition suggests that this \"backflow\" of information should be larger in graphs with self-loops compared to graphs without. In this work, we counter this intuition and show that for certain GNN architectures, the information a node gains from itself can be smaller in graphs with self-loops compared to the same graphs without. We adopt an analytical approach for the study of statistical graph ensembles with a given degree sequence and show that this phenomenon, which we call the self-loop paradox, can depend both on the number of GNN layers $k$ and whether $k$ is even or odd. We experimentally validate our theoretical findings in a synthetic node classification task and investigate its practical relevance in 23 real-world graphs. ",
    "url": "https://arxiv.org/abs/2312.01721",
    "authors": [
      "Moritz Lampert",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01728",
    "title": "ImputeFormer: Graph Transformers for Generalizable Spatiotemporal  Imputation",
    "abstract": "This paper focuses on the multivariate time series imputation problem using deep neural architectures. The ubiquitous issue of missing data in both scientific and engineering tasks necessitates the development of an effective and general imputation model. Leveraging the wisdom and expertise garnered from low-rank imputation methods, we power the canonical Transformers with three key knowledge-driven enhancements, including projected temporal attention, global adaptive graph convolution, and Fourier imputation loss. These task-agnostic inductive biases exploit the inherent structures of incomplete time series, and thus make our model versatile for a variety of imputation problems. We demonstrate its superiority in terms of accuracy, efficiency, and flexibility on heterogeneous datasets, including traffic speed, traffic volume, solar energy, smart metering, and air quality. Comprehensive case studies are performed to further strengthen the interpretability. Promising empirical results provide strong conviction that incorporating time series primitives, such as low-rank properties, can substantially facilitate the development of a generalizable model to approach a wide range of spatiotemporal imputation problems. ",
    "url": "https://arxiv.org/abs/2312.01728",
    "authors": [
      "Tong Nie",
      "Guoyang Qin",
      "Yuewen Mei",
      "Jian Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01729",
    "title": "EdgeConvFormer: Dynamic Graph CNN and Transformer based Anomaly  Detection in Multivariate Time Series",
    "abstract": "Transformer-based models for anomaly detection in multivariate time series can benefit from the self-attention mechanism due to its advantage in modeling long-term dependencies. However, Transformer-based anomaly detection models have problems such as a large amount of data being required for training, standard positional encoding is not suitable for multivariate time series data, and the interdependence between time series is not considered. To address these limitations, we propose a novel anomaly detection method, named EdgeConvFormer, which integrates Time2vec embedding, stacked dynamic graph CNN, and Transformer to extract global and local spatial-time information. This design of EdgeConvFormer empowers it with decomposition capacities for complex time series, progressive spatiotemporal correlation discovery between time series, and representation aggregation of multi-scale features. Experiments demonstrate that EdgeConvFormer can learn the spatial-temporal correlations from multivariate time series data and achieve better anomaly detection performance than the state-of-the-art approaches on many real-world datasets of different scales. ",
    "url": "https://arxiv.org/abs/2312.01729",
    "authors": [
      "Jie Liu",
      "Qilin Li",
      "Senjian An",
      "Bradley Ezard",
      "Ling Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01732",
    "title": "Likelihood-Aware Semantic Alignment for Full-Spectrum  Out-of-Distribution Detection",
    "abstract": "Full-spectrum out-of-distribution (F-OOD) detection aims to accurately recognize in-distribution (ID) samples while encountering semantic and covariate shifts simultaneously. However, existing out-of-distribution (OOD) detectors tend to overfit the covariance information and ignore intrinsic semantic correlation, inadequate for adapting to complex domain transformations. To address this issue, we propose a Likelihood-Aware Semantic Alignment (LSA) framework to promote the image-text correspondence into semantically high-likelihood regions. LSA consists of an offline Gaussian sampling strategy which efficiently samples semantic-relevant visual embeddings from the class-conditional Gaussian distribution, and a bidirectional prompt customization mechanism that adjusts both ID-related and negative context for discriminative ID/OOD boundary. Extensive experiments demonstrate the remarkable OOD detection performance of our proposed LSA especially on the intractable Near-OOD setting, surpassing existing methods by a margin of $15.26\\%$ and $18.88\\%$ on two F-OOD benchmarks, respectively. ",
    "url": "https://arxiv.org/abs/2312.01732",
    "authors": [
      "Fan Lu",
      "Kai Zhu",
      "Kecheng Zheng",
      "Wei Zhai",
      "Yang Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01739",
    "title": "Divide-and-Conquer Strategy for Large-Scale Dynamic Bayesian Network  Structure Learning",
    "abstract": "Dynamic Bayesian Networks (DBNs), renowned for their interpretability, have become increasingly vital in representing complex stochastic processes in various domains such as gene expression analysis, healthcare, and traffic prediction. Structure learning of DBNs from data is challenging, particularly for datasets with thousands of variables. Most current algorithms for DBN structure learning are adaptations from those used in static Bayesian Networks (BNs), and are typically focused on small-scale problems. In order to solve large-scale problems while taking full advantage of existing algorithms, this paper introduces a novel divide-and-conquer strategy, originally developed for static BNs, and adapts it for large-scale DBN structure learning. In this work, we specifically concentrate on 2 Time-sliced Bayesian Networks (2-TBNs), a special class of DBNs. Furthermore, we leverage the prior knowledge of 2-TBNs to enhance the performance of the strategy we introduce. Our approach significantly improves the scalability and accuracy of 2-TBN structure learning. Experimental results demonstrate the effectiveness of our method, showing substantial improvements over existing algorithms in both computational efficiency and structure learning accuracy. On problem instances with more than 1,000 variables, our approach improves two accuracy metrics by 74.45% and 110.94% on average , respectively, while reducing runtime by 93.65% on average. ",
    "url": "https://arxiv.org/abs/2312.01739",
    "authors": [
      "Hui Ouyang",
      "Cheng Chen",
      "Ke Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01741",
    "title": "SRSNetwork: Siamese Reconstruction-Segmentation Networks based on  Dynamic-Parameter Convolution",
    "abstract": "In this paper, we present a high-performance deep neural network for weak target image segmentation, including medical image segmentation and infrared image segmentation. To this end, this work analyzes the existing dynamic convolutions and proposes dynamic parameter convolution (DPConv). Furthermore, it reevaluates the relationship between reconstruction tasks and segmentation tasks from the perspective of DPConv, leading to the proposal of a dual-network model called the Siamese Reconstruction-Segmentation Network (SRSNet). The proposed model is not only a universal network but also enhances the segmentation performance without altering its structure, leveraging the reconstruction task. Additionally, as the amount of training data for the reconstruction network increases, the performance of the segmentation network also improves synchronously. On seven datasets including five medical datasets and two infrared image datasets, our SRSNet consistently achieves the best segmentation results. The code is released at https://github.com/fidshu/SRSNet. ",
    "url": "https://arxiv.org/abs/2312.01741",
    "authors": [
      "Bingkun Nian",
      "Fenghe Tang",
      "Jianrui Ding",
      "Pingping Zhang",
      "Jie Yang",
      "S.Kevin Zhou",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01751",
    "title": "Joint Task Partitioning and Parallel Scheduling in Device-Assisted  Mobile Edge Networks",
    "abstract": "With the development of the Internet of Things (IoT), certain IoT devices have the capability to not only accomplish their own tasks but also simultaneously assist other resource-constrained devices. Therefore, this paper considers a device-assisted mobile edge computing system that leverages auxiliary IoT devices to alleviate the computational burden on the edge computing server and enhance the overall system performance. In this study, computationally intensive tasks are decomposed into multiple partitions, and each task partition can be processed in parallel on an IoT device or the edge server. The objective of this research is to develop an efficient online algorithm that addresses the joint optimization of task partitioning and parallel scheduling under time-varying system states, posing challenges to conventional numerical optimization methods. To address these challenges, a framework called online task partitioning action and parallel scheduling policy generation (OTPPS) is proposed, which is based on deep reinforcement learning (DRL). Specifically, the framework leverages a deep neural network (DNN) to learn the optimal partitioning action for each task by mapping input states. Furthermore, it is demonstrated that the remaining parallel scheduling problem exhibits NP-hard complexity when considering a specific task partitioning action. To address this subproblem, a fair and delay-minimized task scheduling (FDMTS) algorithm is designed. Extensive evaluation results demonstrate that OTPPS achieves near-optimal average delay performance and consistently high fairness levels in various environmental states compared to other baseline schemes. ",
    "url": "https://arxiv.org/abs/2312.01751",
    "authors": [
      "Yang Li",
      "Xinlei Ge",
      "Bo Lei",
      "Xing Zhang",
      "Wenbo Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.01760",
    "title": "On Gradient Boosted Decision Trees and Neural Rankers: A Case-Study on  Short-Video Recommendations at ShareChat",
    "abstract": "Practitioners who wish to build real-world applications that rely on ranking models, need to decide which modelling paradigm to follow. This is not an easy choice to make, as the research literature on this topic has been shifting in recent years. In particular, whilst Gradient Boosted Decision Trees (GBDTs) have reigned supreme for more than a decade, the flexibility of neural networks has allowed them to catch up, and recent works report accuracy metrics that are on par. Nevertheless, practical systems require considerations beyond mere accuracy metrics to decide on a modelling approach. This work describes our experiences in balancing some of the trade-offs that arise, presenting a case study on a short-video recommendation application. We highlight (1) neural networks' ability to handle large training data size, user- and item-embeddings allows for more accurate models than GBDTs in this setting, and (2) because GBDTs are less reliant on specialised hardware, they can provide an equally accurate model at a lower cost. We believe these findings are of relevance to researchers in both academia and industry, and hope they can inspire practitioners who need to make similar modelling choices in the future. ",
    "url": "https://arxiv.org/abs/2312.01760",
    "authors": [
      "Olivier Jeunen",
      "Hitesh Sagtani",
      "Himanshu Doi",
      "Rasul Karimov",
      "Neeti Pokharna",
      "Danish Kalim",
      "Aleksei Ustimenko",
      "Christopher Green",
      "Wenzhe Shi",
      "Rishabh Mehrotra"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.01764",
    "title": "Dynamic Erasing Network Based on Multi-Scale Temporal Features for  Weakly Supervised Video Anomaly Detection",
    "abstract": "The goal of weakly supervised video anomaly detection is to learn a detection model using only video-level labeled data. However, prior studies typically divide videos into fixed-length segments without considering the complexity or duration of anomalies. Moreover, these studies usually just detect the most abnormal segments, potentially overlooking the completeness of anomalies. To address these limitations, we propose a Dynamic Erasing Network (DE-Net) for weakly supervised video anomaly detection, which learns multi-scale temporal features. Specifically, to handle duration variations of abnormal events, we first propose a multi-scale temporal modeling module, capable of extracting features from segments of varying lengths and capturing both local and global visual information across different temporal scales. Then, we design a dynamic erasing strategy, which dynamically assesses the completeness of the detected anomalies and erases prominent abnormal segments in order to encourage the model to discover gentle abnormal segments in a video. The proposed method obtains favorable performance compared to several state-of-the-art approaches on three datasets: XD-Violence, TAD, and UCF-Crime. Code will be made available at https://github.com/ArielZc/DE-Net. ",
    "url": "https://arxiv.org/abs/2312.01764",
    "authors": [
      "Chen Zhang",
      "Guorong Li",
      "Yuankai Qi",
      "Hanhua Ye",
      "Laiyun Qing",
      "Ming-Hsuan Yang",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01768",
    "title": "Localizing and Assessing Node Significance in Default Mode Network using  Sub-Community Detection in Mild Cognitive Impairment",
    "abstract": "Our study aims to utilize fMRI to identify the affected brain regions within the Default Mode Network (DMN) in subjects with Mild Cognitive Impairment (MCI), using a novel Node Significance Score (NSS). We construct subject-specific DMN graphs by employing partial correlation of Regions of Interest (ROIs) that make-up the DMN. For the DMN graph, ROIs are the nodes and edges are determined based on partial correlation. Four popular community detection algorithms (Clique Percolation Method (CPM), Louvain algorithm, Greedy Modularity and Leading Eigenvectors) are applied to determine the largest sub-community. NSS ratings are derived for each node, considering (I) frequency in the largest sub-community within a class across all subjects and (II) occurrence in the largest sub-community according to all four methods. After computing the NSS of each ROI in both healthy and MCI subjects, we quantify the score disparity to identify nodes most impacted by MCI. The results reveal a disparity exceeding 20% for 10 DMN nodes, maximally for PCC and Fusiform, showing 45.69% and 43.08% disparity. This aligns with existing medical literature, additionally providing a quantitative measure that enables the ordering of the affected ROIs. These findings offer valuable insights and could lead to treatment strategies aggressively targeting the affected nodes. ",
    "url": "https://arxiv.org/abs/2312.01768",
    "authors": [
      "Ameiy Acharya",
      "Chakka Sai Pradeep",
      "Neelam Sinha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01779",
    "title": "Viral transmission in pedestrian crowds: Coupling an open-source code  assessing the risks of airborne contagion with diverse pedestrian dynamics  models",
    "abstract": "We study viral transmission in crowds via the short-ranged airborne pathway using a purely model-based approach. Our goal is two-pronged. Firstly, we illustrate with a concrete and pedagogical case study how to estimate the risks of new viral infections by coupling pedestrian simulations with the transmission algorithm that we recently released as open-source code. The algorithm hinges on pre-computed viral concentration maps derived from computational fluid dynamics (CFD) simulations. Secondly, we investigate to what extent the transmission risk predictions depend on the pedestrian dynamics model in use. For the simple bidirectional flow under consideration, the predictions are found to be surprisingly stable across initial conditions and models, despite the different microscopic arrangements of the simulated crowd, as long as the crowd evolves in a qualitatively similarly way. On the other hand, when major changes are observed in the crowd's behaviour, notably whenever a jam occurs at the centre of the channel, the estimated risks surge drastically. ",
    "url": "https://arxiv.org/abs/2312.01779",
    "authors": [
      "Alexandre Nicolas",
      "Simon Mendez"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2312.01786",
    "title": "Output-sensitive Complexity of Multi-Objective Integer Network Flow  Problems",
    "abstract": "This paper addresses the output-sensitive complexity for linear multi-objective integer minimum cost flow (MOIMCF) problems and provides insights about the time complexity for enumerating all supported nondominated vectors. The paper shows that there can not exist an output-polynomial time algorithm for the enumeration of all supported nondominated vectors that determine the vectors in an ordered way in the outcome space unless NP = P. Moreover, novel methods for identifying supported nondominated vectors in bi-objective minimum cost flow (BOIMCF) problems are proposed, accompanied by a numerical comparison between decision- and objective-space methods. A novel, equivalent and more compact formulation of the minimum cost flow ILP formulation used in the e-constrained-scalarization approach is introduced, demonstrating enhanced efficiency in the numerical tests ",
    "url": "https://arxiv.org/abs/2312.01786",
    "authors": [
      "David K\u00f6nen",
      "Michael Stiglmayr"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2312.01787",
    "title": "Developing Linguistic Patterns to Mitigate Inherent Human Bias in  Offensive Language Detection",
    "abstract": "With the proliferation of social media, there has been a sharp increase in offensive content, particularly targeting vulnerable groups, exacerbating social problems such as hatred, racism, and sexism. Detecting offensive language use is crucial to prevent offensive language from being widely shared on social media. However, the accurate detection of irony, implication, and various forms of hate speech on social media remains a challenge. Natural language-based deep learning models require extensive training with large, comprehensive, and labeled datasets. Unfortunately, manually creating such datasets is both costly and error-prone. Additionally, the presence of human-bias in offensive language datasets is a major concern for deep learning models. In this paper, we propose a linguistic data augmentation approach to reduce bias in labeling processes, which aims to mitigate the influence of human bias by leveraging the power of machines to improve the accuracy and fairness of labeling processes. This approach has the potential to improve offensive language classification tasks across multiple languages and reduce the prevalence of offensive content on social media. ",
    "url": "https://arxiv.org/abs/2312.01787",
    "authors": [
      "Toygar Tanyel",
      "Besher Alkurdi",
      "Serkan Ayvaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01789",
    "title": "Two-stage optimized unified adversarial patch for attacking  visible-infrared cross-modal detectors in the physical world",
    "abstract": "Currently, many studies have addressed security concerns related to visible and infrared detectors independently. In practical scenarios, utilizing cross-modal detectors for tasks proves more reliable than relying on single-modal detectors. Despite this, there is a lack of comprehensive security evaluations for cross-modal detectors. While existing research has explored the feasibility of attacks against cross-modal detectors, the implementation of a robust attack remains unaddressed. This work introduces the Two-stage Optimized Unified Adversarial Patch (TOUAP) designed for performing attacks against visible-infrared cross-modal detectors in real-world, black-box settings. The TOUAP employs a two-stage optimization process: firstly, PSO optimizes an irregular polygonal infrared patch to attack the infrared detector; secondly, the color QR code is optimized, and the shape information of the infrared patch from the first stage is used as a mask. The resulting irregular polygon visible modal patch executes an attack on the visible detector. Through extensive experiments conducted in both digital and physical environments, we validate the effectiveness and robustness of the proposed method. As the TOUAP surpasses baseline performance, we advocate for its widespread attention. ",
    "url": "https://arxiv.org/abs/2312.01789",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01790",
    "title": "Exploring Multi-Modal Fusion for Image Manipulation Detection and  Localization",
    "abstract": "Recent image manipulation localization and detection techniques usually leverage forensic artifacts and traces that are produced by a noise-sensitive filter, such as SRM and Bayar convolution. In this paper, we showcase that different filters commonly used in such approaches excel at unveiling different types of manipulations and provide complementary forensic traces. Thus, we explore ways of merging the outputs of such filters and aim to leverage the complementary nature of the artifacts produced to perform image manipulation localization and detection (IMLD). We propose two distinct methods: one that produces independent features from each forensic filter and then fuses them (this is referred to as late fusion) and one that performs early mixing of different modal outputs and produces early combined features (this is referred to as early fusion). We demonstrate that both approaches achieve competitive performance for both image manipulation localization and detection, outperforming state-of-the-art models across several datasets. ",
    "url": "https://arxiv.org/abs/2312.01790",
    "authors": [
      "Konstantinos Triaridis",
      "Vasileios Mezaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01800",
    "title": "Collaborative Neural Painting",
    "abstract": "The process of painting fosters creativity and rational planning. However, existing generative AI mostly focuses on producing visually pleasant artworks, without emphasizing the painting process. We introduce a novel task, Collaborative Neural Painting (CNP), to facilitate collaborative art painting generation between humans and machines. Given any number of user-input brushstrokes as the context or just the desired object class, CNP should produce a sequence of strokes supporting the completion of a coherent painting. Importantly, the process can be gradual and iterative, so allowing users' modifications at any phase until the completion. Moreover, we propose to solve this task using a painting representation based on a sequence of parametrized strokes, which makes it easy both editing and composition operations. These parametrized strokes are processed by a Transformer-based architecture with a novel attention mechanism to model the relationship between the input strokes and the strokes to complete. We also propose a new masking scheme to reflect the interactive nature of CNP and adopt diffusion models as the basic learning process for its effectiveness and diversity in the generative field. Finally, to develop and validate methods on the novel task, we introduce a new dataset of painted objects and an evaluation protocol to benchmark CNP both quantitatively and qualitatively. We demonstrate the effectiveness of our approach and the potential of the CNP task as a promising avenue for future research. ",
    "url": "https://arxiv.org/abs/2312.01800",
    "authors": [
      "Nicola Dall'Asen",
      "Willi Menapace",
      "Elia Peruzzo",
      "Enver Sangineto",
      "Yiming Wang",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01804",
    "title": "Minimizing Maximum Dissatisfaction in the Allocation of Indivisible  Items under a Common Preference Graph",
    "abstract": "We consider the task of allocating indivisible items to agents, when the agents' preferences over the items are identical. The preferences are captured by means of a directed acyclic graph, with vertices representing items and an edge $(a,b)$ meaning that each of the agents prefers item $a$ over item $b$. The dissatisfaction of an agent is measured by the number of items that the agent does not receive and also does not receive any more preferred item. The aim is to allocate the items to the agents in a fair way, i.e., to minimize the maximum dissatisfaction among the agents. We study the status of computational complexity of that problem and establish the following dichotomy: the problem is NP-hard for the case of at least three agents, even on fairly restricted graphs, but polynomially solvable for two agents. We also provide several polynomial-time results with respect to different underlying graph structures, such as graphs of width at most two and tree-like structures such as stars and matchings. These findings are complemented with fixed parameter tractability results related to path modules and independent set modules. Techniques employed in the paper include bottleneck assignment problem, greedy algorithm, dynamic programming, maximum network flow, and integer linear programming. ",
    "url": "https://arxiv.org/abs/2312.01804",
    "authors": [
      "Nina Chiarelli",
      "Cl\u00e9ment Dallard",
      "Andreas Darmann",
      "Stefan Lendl",
      "Martin Milani\u010d",
      "Peter Mur\u0161i\u010d",
      "Ulrich Pferschy"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2312.01837",
    "title": "Prompting Disentangled Embeddings for Knowledge Graph Completion with  Pre-trained Language Model",
    "abstract": "Both graph structures and textual information play a critical role in Knowledge Graph Completion (KGC). With the success of Pre-trained Language Models (PLMs) such as BERT, they have been applied for text encoding for KGC. However, the current methods mostly prefer to fine-tune PLMs, leading to huge training costs and limited scalability to larger PLMs. In contrast, we propose to utilize prompts and perform KGC on a frozen PLM with only the prompts trained. Accordingly, we propose a new KGC method named PDKGC with two prompts -- a hard task prompt which is to adapt the KGC task to the PLM pre-training task of token prediction, and a disentangled structure prompt which learns disentangled graph representation so as to enable the PLM to combine more relevant structure knowledge with the text information. With the two prompts, PDKGC builds a textual predictor and a structural predictor, respectively, and their combination leads to more comprehensive entity prediction. Solid evaluation on two widely used KGC datasets has shown that PDKGC often outperforms the baselines including the state-of-the-art, and its components are all effective. Our codes and data are available at https://github.com/genggengcss/PDKGC. ",
    "url": "https://arxiv.org/abs/2312.01837",
    "authors": [
      "Yuxia Geng",
      "Jiaoyan Chen",
      "Yuhang Zeng",
      "Zhuo Chen",
      "Wen Zhang",
      "Jeff Z. Pan",
      "Yuxiang Wang",
      "Xiaoliang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.01878",
    "title": "HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot  Prompt Learning",
    "abstract": "Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs) are prominent techniques for homogeneous and heterogeneous graph representation learning, yet their performance in an end-to-end supervised framework greatly depends on the availability of task-specific supervision. To reduce the labeling cost, pre-training on self-supervised pretext tasks has become a popular paradigm,but there is often a gap between the pre-trained model and downstream tasks, stemming from the divergence in their objectives. To bridge the gap, prompt learning has risen as a promising direction especially in few-shot settings, without the need to fully fine-tune the pre-trained model. While there has been some early exploration of prompt-based learning on graphs, they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs that are prevalent in downstream applications. In this paper, we propose HGPROMPT, a novel pre-training and prompting framework to unify not only pre-training and downstream tasks but also homogeneous and heterogeneous graphs via a dual-template design. Moreover, we propose dual-prompt in HGPROMPT to assist a downstream task in locating the most relevant prior to bridge the gaps caused by not only feature variations but also heterogeneity differences across tasks. Finally, we thoroughly evaluate and analyze HGPROMPT through extensive experiments on three public datasets. ",
    "url": "https://arxiv.org/abs/2312.01878",
    "authors": [
      "Xingtong Yu",
      "Zemin Liu",
      "Yuan Fang",
      "Xinming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01886",
    "title": "InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language  Models",
    "abstract": "Large vision-language models (LVLMs) have demonstrated their incredible capability in image understanding and response generation. However, this rich visual interaction also makes LVLMs vulnerable to adversarial examples. In this paper, we formulate a novel and practical gray-box attack scenario that the adversary can only access the visual encoder of the victim LVLM, without the knowledge of its prompts (which are often proprietary for service providers and not publicly available) and its underlying large language model (LLM). This practical setting poses challenges to the cross-prompt and cross-model transferability of targeted adversarial attack, which aims to confuse the LVLM to output a response that is semantically similar to the attacker's chosen target text. To this end, we propose an instruction-tuned targeted attack (dubbed InstructTA) to deliver the targeted adversarial attack on LVLMs with high transferability. Initially, we utilize a public text-to-image generative model to \"reverse\" the target response into a target image, and employ GPT-4 to infer a reasonable instruction $\\boldsymbol{p}^\\prime$ from the target response. We then form a local surrogate model (sharing the same visual encoder with the victim LVLM) to extract instruction-aware features of an adversarial image example and the target image, and minimize the distance between these two features to optimize the adversarial example. To further improve the transferability, we augment the instruction $\\boldsymbol{p}^\\prime$ with instructions paraphrased from an LLM. Extensive experiments demonstrate the superiority of our proposed method in targeted attack performance and transferability. ",
    "url": "https://arxiv.org/abs/2312.01886",
    "authors": [
      "Xunguang Wang",
      "Zhenlan Ji",
      "Pingchuan Ma",
      "Zongjie Li",
      "Shuai Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01887",
    "title": "Non-Intrusive Load Monitoring for Feeder-Level EV Charging Detection:  Sliding Window-based Approaches to Offline and Online Detection",
    "abstract": "Understanding electric vehicle (EV) charging on the distribution network is key to effective EV charging management and aiding decarbonization across the energy and transport sectors. Advanced metering infrastructure has allowed distribution system operators and utility companies to collect high-resolution load data from their networks. These advancements enable the non-intrusive load monitoring (NILM) technique to detect EV charging using load measurement data. While existing studies primarily focused on NILM for EV charging detection in individual households, there is a research gap on EV charging detection at the feeder level, presenting unique challenges due to the combined load measurement from multiple households. In this paper, we develop a novel and effective approach for EV detection at the feeder level, involving sliding-window feature extraction and classical machine learning techniques, specifically models like XGBoost and Random Forest. Our developed method offers a lightweight and efficient solution, capable of quick training. Moreover, our developed method is versatile, supporting both offline and online EV charging detection. Our experimental results demonstrate high-accuracy EV charging detection at the feeder level, achieving an F-Score of 98.88% in offline detection and 93.01% in online detection. ",
    "url": "https://arxiv.org/abs/2312.01887",
    "authors": [
      "Cameron Martin",
      "Fucai Ke",
      "Hao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.01895",
    "title": "An In-Depth Survey on Virtualization Technologies in 6G Integrated  Terrestrial and Non-Terrestrial Networks",
    "abstract": "6G networks are envisioned to deliver a large diversity of applications and meet stringent quality of service (QoS) requirements. Hence, integrated terrestrial and non-terrestrial networks (TN-NTNs) are anticipated to be key enabling technologies. However, the TN-NTNs integration faces a number of challenges that could be addressed through network virtualization technologies such as Software-Defined Networking (SDN), Network Function Virtualization (NFV) and network slicing. In this survey, we provide a comprehensive review on the adaptation of these networking paradigms in 6G networks. We begin with a brief overview on NTNs and virtualization techniques. Then, we highlight the integral role of Artificial Intelligence in improving network virtualization by summarizing major research areas where AI models are applied. Building on this foundation, the survey identifies the main issues arising from the adaptation of SDN, NFV, and network slicing in integrated TN-NTNs, and proposes a taxonomy of integrated TN-NTNs virtualization offering a thorough review of relevant contributions. The taxonomy is built on a four-level classification indicating for each study the level of TN-NTNs integration, the used virtualization technology, the addressed problem, the type of the study and the proposed solution, which can be based on conventional or AI-enabled methods. Moreover, we present a summary on the simulation tools commonly used in the testing and validation of such networks. Finally, we discuss open issues and give insights on future research directions for the advancement of integrated TN-NTNs virtualization in the 6G era. ",
    "url": "https://arxiv.org/abs/2312.01895",
    "authors": [
      "Sahar Ammar",
      "Chun Pong Lau",
      "Basem Shihada"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.01897",
    "title": "Adapting Short-Term Transformers for Action Detection in Untrimmed  Videos",
    "abstract": "Vision transformer (ViT) has shown high potential in video recognition, owing to its flexible design, adaptable self-attention mechanisms, and the efficacy of masked pre-training. Yet, it still remains unclear how to adapt these pre-trained short-term ViTs for temporal action detection (TAD) in untrimmed videos. The existing works treat them as off-the-shelf feature extractors for each short trimmed snippet without capturing the fine-grained relation among different snippets in a broader temporal context. To mitigate this issue, this paper focuses on designing a new mechanism for adapting these pre-trained ViT models as a unified long-form video transformer to fully unleash its modeling power in capturing inter-snippet relation, while still keeping low computation overhead and memory consumption for efficient TAD. To this end, we design effective cross-snippet propagation modules to gradually exchange short-term video information among different snippets from two levels. For inner-backbone information propagation, we introduce a cross-snippet propagation strategy to enable multi-snippet temporal feature interaction inside the backbone. For post-backbone information propagation, we propose temporal transformer layers for further clip-level modeling. With the plain ViT-B pre-trained with VideoMAE, our end-to-end temporal action detector (ViT-TAD) yields a very competitive performance to previous temporal action detectors, riching up to 69.0 average mAP on THUMOS14, 37.12 average mAP on ActivityNet-1.3 and 17.20 average mAP on FineAction. ",
    "url": "https://arxiv.org/abs/2312.01897",
    "authors": [
      "Min Yang",
      "Huan Gao",
      "Ping Guo",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01904",
    "title": "Unsupervised Anomaly Detection using Aggregated Normative Diffusion",
    "abstract": "Early detection of anomalies in medical images such as brain MRI is highly relevant for diagnosis and treatment of many conditions. Supervised machine learning methods are limited to a small number of pathologies where there is good availability of labeled data. In contrast, unsupervised anomaly detection (UAD) has the potential to identify a broader spectrum of anomalies by spotting deviations from normal patterns. Our research demonstrates that existing state-of-the-art UAD approaches do not generalise well to diverse types of anomalies in realistic multi-modal MR data. To overcome this, we introduce a new UAD method named Aggregated Normative Diffusion (ANDi). ANDi operates by aggregating differences between predicted denoising steps and ground truth backwards transitions in Denoising Diffusion Probabilistic Models (DDPMs) that have been trained on pyramidal Gaussian noise. We validate ANDi against three recent UAD baselines, and across three diverse brain MRI datasets. We show that ANDi, in some cases, substantially surpasses these baselines and shows increased robustness to varying types of anomalies. Particularly in detecting multiple sclerosis (MS) lesions, ANDi achieves improvements of up to 178% in terms of AUPRC. ",
    "url": "https://arxiv.org/abs/2312.01904",
    "authors": [
      "Alexander Frotscher",
      "Jaivardhan Kapoor",
      "Thomas Wolfers",
      "Christian F. Baumgartner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2312.01912",
    "title": "Resource Leak Checker (RLC#) for C# Code using CodeQL",
    "abstract": "Resource leaks occur when a program fails to release a finite resource after it is no longer needed. These leaks are a significant cause of real-world crashes and performance issues. Given their critical impact on software performance and security, detecting and preventing resource leaks is a crucial problem. Recent research has proposed a specify-and-check approach to prevent resource leaks. In this approach, programmers write resource management specifications that guide how resources are stored, passed around, and released within an application. We have developed a tool called RLC#, for detecting resource leaks in C# code. Inspired by the Resource Leak Checker (RLC) from the Checker Framework, RLC# employs CodeQL for intraprocedural data flow analysis. The tool operates in a modular fashion and relies on resource management specifications integrated at method boundaries for interprocedural analysis. In practice, RLC# has successfully identified 24 resource leaks in open-source projects and internal proprietary Azure microservices. Its implementation is declarative, and it scales well. While it incurs a reasonable false positive rate, the burden on developers is minimal, involving the addition of specifications to the source code. ",
    "url": "https://arxiv.org/abs/2312.01912",
    "authors": [
      "Pritam Gharat",
      "Narges Shadab",
      "Shrey Tiwari",
      "Shuvendu Lahiri",
      "Akash Lal"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2312.01915",
    "title": "A Reliable Representation with Bidirectional Transition Model for Visual  Reinforcement Learning Generalization",
    "abstract": "Visual reinforcement learning has proven effective in solving control tasks with high-dimensional observations. However, extracting reliable and generalizable representations from vision-based observations remains a central challenge. Inspired by the human thought process, when the representation extracted from the observation can predict the future and trace history, the representation is reliable and accurate in comprehending the environment. Based on this concept, we introduce a Bidirectional Transition (BiT) model, which leverages the ability to bidirectionally predict environmental transitions both forward and backward to extract reliable representations. Our model demonstrates competitive generalization performance and sample efficiency on two settings of the DeepMind Control suite. Additionally, we utilize robotic manipulation and CARLA simulators to demonstrate the wide applicability of our method. ",
    "url": "https://arxiv.org/abs/2312.01915",
    "authors": [
      "Xiaobo Hu",
      "Youfang Lin",
      "Yue Liu",
      "Jinwen Wang",
      "Shuo Wang",
      "Hehe Fan",
      "Kai Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01919",
    "title": "COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy  Prediction",
    "abstract": "The autonomous driving community has shown significant interest in 3D occupancy prediction, driven by its exceptional geometric perception and general object recognition capabilities. To achieve this, current works try to construct a Tri-Perspective View (TPV) or Occupancy (OCC) representation extending from the Bird-Eye-View perception. However, compressed views like TPV representation lose 3D geometry information while raw and sparse OCC representation requires heavy but reducant computational costs. To address the above limitations, we propose Compact Occupancy TRansformer (COTR), with a geometry-aware occupancy encoder and a semantic-aware group decoder to reconstruct a compact 3D OCC representation. The occupancy encoder first generates a compact geometrical OCC feature through efficient explicit-implicit view transformation. Then, the occupancy decoder further enhances the semantic discriminability of the compact OCC representation by a coarse-to-fine semantic grouping strategy. Empirical experiments show that there are evident performance gains across multiple baselines, e.g., COTR outperforms baselines with a relative improvement of 8%-15%, demonstrating the superiority of our method. ",
    "url": "https://arxiv.org/abs/2312.01919",
    "authors": [
      "Qihang Ma",
      "Xin Tan",
      "Yanyun Qu",
      "Lizhuang Ma",
      "Zhizhong Zhang",
      "Yuan Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01921",
    "title": "A Machine Learning Approach Towards SKILL Code Autocompletion",
    "abstract": "As Moore's Law continues to increase the complexity of electronic systems, Electronic Design Automation (EDA) must advance to meet global demand. An important example of an EDA technology is SKILL, a scripting language used to customize and extend EDA software. Recently, code generation models using the transformer architecture have achieved impressive results in academic settings and have even been used in commercial developer tools to improve developer productivity. To the best of our knowledge, this study is the first to apply transformers to SKILL code autocompletion towards improving the productivity of hardware design engineers. In this study, a novel, data-efficient methodology for generating SKILL code is proposed and experimentally validated. More specifically, we propose a novel methodology for (i) creating a high-quality SKILL dataset with both unlabeled and labeled data, (ii) a training strategy where T5 models pre-trained on general programming language code are fine-tuned on our custom SKILL dataset using unsupervised and supervised learning, and (iii) evaluating synthesized SKILL code. We show that models trained using the proposed methodology outperform baselines in terms of human-judgment score and BLEU score. A major challenge faced was the extremely small amount of available SKILL code data that can be used to train a transformer model to generate SKILL code. Despite our validated improvements, the extremely small dataset available to us was still not enough to train a model that can reliably autocomplete SKILL code. We discuss this and other limitations as well as future work that could address these limitations. ",
    "url": "https://arxiv.org/abs/2312.01921",
    "authors": [
      "Enrique Dehaerne",
      "Bappaditya Dey",
      "Wannes Meert"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2312.01928",
    "title": "Consensus-Based Distributed Nonlinear Filtering with Kernel Mean  Embedding",
    "abstract": "This paper proposes a consensus-based distributed nonlinear filter with kernel mean embedding (KME). This fills with gap of posterior density approximation with KME for distributed nonlinear dynamic systems. To approximate the posterior density, the system state is embedded into a higher-dimensional reproducing kernel Hilbert space (RKHS), and then the nonlinear measurement function is linearly converted. As a result, an update rule of KME of posterior distribution is established in the RKHS. To show the proposed distributed filter being capable of achieving the centralized estimation accuracy, a centralized filter, serving as an extension of the standard Kalman filter in the state space to the RKHS, is developed first. Benefited from the KME, the proposed distributed filter converges to the centralized one while maintaining the distributed pattern. Two examples are introduced to demonstrate the effectiveness of the developed filters in target tracking scenarios including nearly constantly moving target and turning target, respectively, with bearing-only, range and bearing measurements. ",
    "url": "https://arxiv.org/abs/2312.01928",
    "authors": [
      "Liping Guo",
      "Jimin Wang",
      "Yanlong Zhao",
      "Ji-Feng Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.01934",
    "title": "Efficiency of Unsupervised Anomaly Detection Methods on Software Logs",
    "abstract": "Software log analysis can be laborious and time consuming. Time and labeled data are usually lacking in industrial settings. This paper studies unsupervised and time efficient methods for anomaly detection. We study two custom and two established models. The custom models are: an OOV (Out-Of-Vocabulary) detector, which counts the terms in the test data that are not present in the training data, and the Rarity Model (RM), which calculates a rarity score for terms based on their infrequency. The established models are KMeans and Isolation Forest. The models are evaluated on four public datasets (BGL, Thunderbird, Hadoop, HDFS) with three different representation techniques for the log messages (Words, character Trigrams, Parsed events). We used the AUC-ROC metric for the evaluation. The results reveal discrepancies based on the dataset and representation technique. Different configurations are advised based on specific requirements. For speed, the OOV detector with word representation is optimal. For accuracy, the OOV detector combined with trigram representation yields the highest AUC-ROC (0.846). When dealing with unfiltered data where training includes both normal and anomalous instances, the most effective combination is the Isolation Forest with event representation, achieving an AUC-ROC of 0.829. ",
    "url": "https://arxiv.org/abs/2312.01934",
    "authors": [
      "Jesse Nyyss\u00f6l\u00e4",
      "Mika M\u00e4ntyl\u00e4"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.01941",
    "title": "Intrusion Detection System with Machine Learning and Multiple Datasets",
    "abstract": "As Artificial Intelligence (AI) technologies continue to gain traction in the modern-day world, they ultimately pose an immediate threat to current cybersecurity systems via exploitative methods. Prompt engineering is a relatively new field that explores various prompt designs that can hijack large language models (LLMs). If used by an unethical attacker, it can enable an AI system to offer malicious insights and code to them. In this paper, an enhanced intrusion detection system (IDS) that utilizes machine learning (ML) and hyperparameter tuning is explored, which can improve a model's performance in terms of accuracy and efficacy. Ultimately, this improved system can be used to combat the attacks made by unethical hackers. A standard IDS is solely configured with pre-configured rules and patterns; however, with the utilization of machine learning, implicit and different patterns can be generated through the models' hyperparameter settings and parameters. In addition, the IDS will be equipped with multiple datasets so that the accuracy of the models improves. We evaluate the performance of multiple ML models and their respective hyperparameter settings through various metrics to compare their results to other models and past research work. The results of the proposed multi-dataset integration method yielded an accuracy score of 99.9% when equipped with the XGBoost and random forest classifiers and RandomizedSearchCV hyperparameter technique. ",
    "url": "https://arxiv.org/abs/2312.01941",
    "authors": [
      "Haiyan Xuan",
      "Mohith Manohar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.01954",
    "title": "Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large  Language Models",
    "abstract": "In this work, we tested the Triplet Extraction (TE) capabilities of a variety of Large Language Models (LLMs) of different sizes in the Zero- and Few-Shots settings. In detail, we proposed a pipeline that dynamically gathers contextual information from a Knowledge Base (KB), both in the form of context triplets and of (sentence, triplets) pairs as examples, and provides it to the LLM through a prompt. The additional context allowed the LLMs to be competitive with all the older fully trained baselines based on the Bidirectional Long Short-Term Memory (BiLSTM) Network architecture. We further conducted a detailed analysis of the quality of the gathered KB context, finding it to be strongly correlated with the final TE performance of the model. In contrast, the size of the model appeared to only logarithmically improve the TE capabilities of the LLMs. ",
    "url": "https://arxiv.org/abs/2312.01954",
    "authors": [
      "Andrea Papaluca",
      "Daniel Krefl",
      "Sergio Mendez Rodriguez",
      "Artem Lensky",
      "Hanna Suominen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.01985",
    "title": "UniGS: Unified Representation for Image Generation and Segmentation",
    "abstract": "This paper introduces a novel unified representation of diffusion models for image generation and segmentation. Specifically, we use a colormap to represent entity-level masks, addressing the challenge of varying entity numbers while aligning the representation closely with the image RGB domain. Two novel modules, including the location-aware color palette and progressive dichotomy module, are proposed to support our mask representation. On the one hand, a location-aware palette guarantees the colors' consistency to entities' locations. On the other hand, the progressive dichotomy module can efficiently decode the synthesized colormap to high-quality entity-level masks in a depth-first binary search without knowing the cluster numbers. To tackle the issue of lacking large-scale segmentation training data, we employ an inpainting pipeline and then improve the flexibility of diffusion models across various tasks, including inpainting, image synthesis, referring segmentation, and entity segmentation. Comprehensive experiments validate the efficiency of our approach, demonstrating comparable segmentation mask quality to state-of-the-art and adaptability to multiple tasks. The code will be released at \\href{https://github.com/qqlu/Entity}{https://github.com/qqlu/Entity}. ",
    "url": "https://arxiv.org/abs/2312.01985",
    "authors": [
      "Lu Qi",
      "Lehan Yang",
      "Weidong Guo",
      "Yu Xu",
      "Bo Du",
      "Varun Jampani",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01990",
    "title": "SARA-RT: Scaling up Robotics Transformers with Self-Adaptive Robust  Attention",
    "abstract": "We present Self-Adaptive Robust Attention for Robotics Transformers (SARA-RT): a new paradigm for addressing the emerging challenge of scaling up Robotics Transformers (RT) for on-robot deployment. SARA-RT relies on the new method of fine-tuning proposed by us, called up-training. It converts pre-trained or already fine-tuned Transformer-based robotic policies of quadratic time complexity (including massive billion-parameter vision-language-action models or VLAs), into their efficient linear-attention counterparts maintaining high quality. We demonstrate the effectiveness of SARA-RT by speeding up: (a) the class of recently introduced RT-2 models, the first VLA robotic policies pre-trained on internet-scale data, as well as (b) Point Cloud Transformer (PCT) robotic policies operating on large point clouds. We complement our results with the rigorous mathematical analysis providing deeper insight into the phenomenon of SARA. ",
    "url": "https://arxiv.org/abs/2312.01990",
    "authors": [
      "Isabel Leal",
      "Krzysztof Choromanski",
      "Deepali Jain",
      "Avinava Dubey",
      "Jake Varley",
      "Michael Ryoo",
      "Yao Lu",
      "Frederick Liu",
      "Vikas Sindhwani",
      "Quan Vuong",
      "Tamas Sarlos",
      "Ken Oslund",
      "Karol Hausman",
      "Kanishka Rao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01994",
    "title": "A Generative Self-Supervised Framework using Functional Connectivity in  fMRI Data",
    "abstract": "Deep neural networks trained on Functional Connectivity (FC) networks extracted from functional Magnetic Resonance Imaging (fMRI) data have gained popularity due to the increasing availability of data and advances in model architectures, including Graph Neural Network (GNN). Recent research on the application of GNN to FC suggests that exploiting the time-varying properties of the FC could significantly improve the accuracy and interpretability of the model prediction. However, the high cost of acquiring high-quality fMRI data and corresponding phenotypic labels poses a hurdle to their application in real-world settings, such that a model na\\\"ively trained in a supervised fashion can suffer from insufficient performance or a lack of generalization on a small number of data. In addition, most Self-Supervised Learning (SSL) approaches for GNNs to date adopt a contrastive strategy, which tends to lose appropriate semantic information when the graph structure is perturbed or does not leverage both spatial and temporal information simultaneously. In light of these challenges, we propose a generative SSL approach that is tailored to effectively harness spatio-temporal information within dynamic FC. Our empirical results, experimented with large-scale (>50,000) fMRI datasets, demonstrate that our approach learns valuable representations and enables the construction of accurate and robust models when fine-tuned for downstream tasks. ",
    "url": "https://arxiv.org/abs/2312.01994",
    "authors": [
      "Jungwon Choi",
      "Seongho Keum",
      "EungGu Yun",
      "Byung-Hoon Kim",
      "Juho Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2312.02015",
    "title": "ColonNeRF: Neural Radiance Fields for High-Fidelity Long-Sequence  Colonoscopy Reconstruction",
    "abstract": "Colonoscopy reconstruction is pivotal for diagnosing colorectal cancer. However, accurate long-sequence colonoscopy reconstruction faces three major challenges: (1) dissimilarity among segments of the colon due to its meandering and convoluted shape; (2) co-existence of simple and intricately folded geometry structures; (3) sparse viewpoints due to constrained camera trajectories. To tackle these challenges, we introduce a new reconstruction framework based on neural radiance field (NeRF), named ColonNeRF, which leverages neural rendering for novel view synthesis of long-sequence colonoscopy. Specifically, to reconstruct the entire colon in a piecewise manner, our ColonNeRF introduces a region division and integration module, effectively reducing shape dissimilarity and ensuring geometric consistency in each segment. To learn both the simple and complex geometry in a unified framework, our ColonNeRF incorporates a multi-level fusion module that progressively models the colon regions from easy to hard. Additionally, to overcome the challenges from sparse views, we devise a DensiNet module for densifying camera poses under the guidance of semantic consistency. We conduct extensive experiments on both synthetic and real-world datasets to evaluate our ColonNeRF. Quantitatively, our ColonNeRF outperforms existing methods on two benchmarks over four evaluation metrics. Notably, our LPIPS-ALEX scores exhibit a substantial increase of about 67%-85% on the SimCol-to-3D dataset. Qualitatively, our reconstruction visualizations show much clearer textures and more accurate geometric details. These sufficiently demonstrate our superior performance over the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2312.02015",
    "authors": [
      "Yufei Shi",
      "Beijia Lu",
      "Jia-Wei Liu",
      "Ming Li",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.02037",
    "title": "GFS: Graph-based Feature Synthesis for Prediction over Relational  Databases",
    "abstract": "Relational databases are extensively utilized in a variety of modern information system applications, and they always carry valuable data patterns. There are a huge number of data mining or machine learning tasks conducted on relational databases. However, it is worth noting that there are limited machine learning models specifically designed for relational databases, as most models are primarily tailored for single table settings. Consequently, the prevalent approach for training machine learning models on data stored in relational databases involves performing feature engineering to merge the data from multiple tables into a single table and subsequently applying single table models. This approach not only requires significant effort in feature engineering but also destroys the inherent relational structure present in the data. To address these challenges, we propose a novel framework called Graph-based Feature Synthesis (GFS). GFS formulates the relational database as a heterogeneous graph, thereby preserving the relational structure within the data. By leveraging the inductive bias from single table models, GFS effectively captures the intricate relationships inherent in each table. Additionally, the whole framework eliminates the need for manual feature engineering. In the extensive experiment over four real-world multi-table relational databases, GFS outperforms previous methods designed for relational databases, demonstrating its superior performance. ",
    "url": "https://arxiv.org/abs/2312.02037",
    "authors": [
      "Han Zhang",
      "Quan Gan",
      "David Wipf",
      "Weinan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2312.02078",
    "title": "Integrating AI into CCTV Systems: A Comprehensive Evaluation of Smart  Video Surveillance in Community Space",
    "abstract": "This article presents an AI-enabled Smart Video Surveillance (SVS) designed to enhance safety in community spaces such as educational and recreational areas, and small businesses. The proposed system innovatively integrates with existing CCTV and wired camera networks, simplifying its adoption across various community cases to leverage recent AI advancements. Our SVS system, focusing on privacy, uses metadata instead of pixel data for activity recognition, aligning with ethical standards. It features cloud-based infrastructure and a mobile app for real-time, privacy-conscious alerts in communities. This article notably pioneers a comprehensive real-world evaluation of the SVS system, covering AI-driven visual processing, statistical analysis, database management, cloud communication, and user notifications. It's also the first to assess an end-to-end anomaly detection system's performance, vital for identifying potential public safety incidents. For our evaluation, we implemented the system in a community college, serving as an ideal model to exemplify the proposed system's capabilities. Our findings in this setting demonstrate the system's robustness, with throughput, latency, and scalability effectively managing 16 CCTV cameras. The system maintained a consistent 16.5 frames per second (FPS) over a 21-hour operation. The average end-to-end latency for detecting behavioral anomalies and alerting users was 26.76 seconds. ",
    "url": "https://arxiv.org/abs/2312.02078",
    "authors": [
      "Shanle Yao",
      "Babak Rahimi Ardabili",
      "Armin Danesh Pazho",
      "Ghazal Alinezhad Noghre",
      "Christopher Neff",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.02079",
    "title": "Deep Set Neural Networks for forecasting asynchronous bioprocess  timeseries",
    "abstract": "Cultivation experiments often produce sparse and irregular time series. Classical approaches based on mechanistic models, like Maximum Likelihood fitting or Monte-Carlo Markov chain sampling, can easily account for sparsity and time-grid irregularities, but most statistical and Machine Learning tools are not designed for handling sparse data out-of-the-box. Among popular approaches there are various schemes for filling missing values (imputation) and interpolation into a regular grid (alignment). However, such methods transfer the biases of the interpolation or imputation models to the target model. We show that Deep Set Neural Networks equipped with triplet encoding of the input data can successfully handle bio-process data without any need for imputation or alignment procedures. The method is agnostic to the particular nature of the time series and can be adapted for any task, for example, online monitoring, predictive control, design of experiments, etc. In this work, we focus on forecasting. We argue that such an approach is especially suitable for typical cultivation processes, demonstrate the performance of the method on several forecasting tasks using data generated from macrokinetic growth models under realistic conditions, and compare the method to a conventional fitting procedure and methods based on imputation and alignment. ",
    "url": "https://arxiv.org/abs/2312.02079",
    "authors": [
      "Maxim Borisyak",
      "Stefan Born",
      "Peter Neubauer",
      "Nicol\u00e1s Cruz-Bournazou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.02093",
    "title": "Cultural Differences in Students' Privacy Concerns in Learning Analytics  across Germany, South Korea, Spain, Sweden, and the United States",
    "abstract": "Applications of learning analytics (LA) can raise concerns from students about their privacy in higher education contexts. Developing effective privacy-enhancing practices requires a systematic understanding of students' privacy concerns and how they vary across national and cultural dimensions. We conducted a survey study with established instruments to measure privacy concerns and cultural values for university students in five countries (Germany, South Korea, Spain, Sweden, and the United States; N = 762). The results show that students generally trusted institutions with their data and disclosed information as they perceived the risks to be manageable even though they felt somewhat limited in their ability to control their privacy. Across the five countries, German and Swedish students stood out as the most trusting and least concerned, especially compared to US students who reported greater perceived risk and less control. Students in South Korea and Spain responded similarly on all five privacy dimensions (perceived privacy risk, perceived privacy control, privacy concerns, trusting beliefs, and non-self-disclosure behavior), despite their significant cultural differences. Culture measured at the individual level affected the antecedents and outcomes of privacy concerns more than country-level culture. Perceived privacy risk and privacy control increase with power distance. Trusting beliefs increase with a desire for uncertainty avoidance and lower masculinity. Non-self-disclosure behaviors rise with power distance and masculinity, and decrease with more uncertainty avoidance. Thus, cultural values related to trust in institutions, social equality and risk-taking should be considered when developing privacy-enhancing practices and policies in higher education. ",
    "url": "https://arxiv.org/abs/2312.02093",
    "authors": [
      "Olga Viberg",
      "Ren\u00e9 F. Kizilcec",
      "Ioana Jivet",
      "Alejandra Mart\u00ednez Mon\u00e9s",
      "Alice Oh",
      "Chantal Mutimukwe",
      "Stefan Hrastinski",
      "Maren Scheffel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.02102",
    "title": "Mitigating Data Injection Attacks on Federated Learning",
    "abstract": "Federated learning is a technique that allows multiple entities to collaboratively train models using their data without compromising data privacy. However, despite its advantages, federated learning can be susceptible to false data injection attacks. In these scenarios, a malicious entity with control over specific agents in the network can manipulate the learning process, leading to a suboptimal model. Consequently, addressing these data injection attacks presents a significant research challenge in federated learning systems. In this paper, we propose a novel technique to detect and mitigate data injection attacks on federated learning systems. Our mitigation method is a local scheme, performed during a single instance of training by the coordinating node, allowing the mitigation during the convergence of the algorithm. Whenever an agent is suspected to be an attacker, its data will be ignored for a certain period, this decision will often be re-evaluated. We prove that with probability 1, after a finite time, all attackers will be ignored while the probability of ignoring a trustful agent becomes 0, provided that there is a majority of truthful agents. Simulations show that when the coordinating node detects and isolates all the attackers, the model recovers and converges to the truthful model. ",
    "url": "https://arxiv.org/abs/2312.02102",
    "authors": [
      "Or Shalom",
      "Amir Leshem",
      "Waheed U. Bajwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.02103",
    "title": "Learning Pseudo-Labeler beyond Noun Concepts for Open-Vocabulary Object  Detection",
    "abstract": "Open-vocabulary object detection (OVOD) has recently gained significant attention as a crucial step toward achieving human-like visual intelligence. Existing OVOD methods extend target vocabulary from pre-defined categories to open-world by transferring knowledge of arbitrary concepts from vision-language pre-training models to the detectors. While previous methods have shown remarkable successes, they suffer from indirect supervision or limited transferable concepts. In this paper, we propose a simple yet effective method to directly learn region-text alignment for arbitrary concepts. Specifically, the proposed method aims to learn arbitrary image-to-text mapping for pseudo-labeling of arbitrary concepts, named Pseudo-Labeling for Arbitrary Concepts (PLAC). The proposed method shows competitive performance on the standard OVOD benchmark for noun concepts and a large improvement on referring expression comprehension benchmark for arbitrary concepts. ",
    "url": "https://arxiv.org/abs/2312.02103",
    "authors": [
      "Sunghun Kang",
      "Junbum Cha",
      "Jonghwan Mun",
      "Byungseok Roh",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.02111",
    "title": "TriDeNT: Triple Deep Network Training for Privileged Knowledge  Distillation in Histopathology",
    "abstract": "Computational pathology models rarely utilise data that will not be available for inference. This means most models cannot learn from highly informative data such as additional immunohistochemical (IHC) stains and spatial transcriptomics. We present TriDeNT, a novel self-supervised method for utilising privileged data that is not available during inference to improve performance. We demonstrate the efficacy of this method for a range of different paired data including immunohistochemistry, spatial transcriptomics and expert nuclei annotations. In all settings, TriDeNT outperforms other state-of-the-art methods in downstream tasks, with observed improvements of up to 101%. Furthermore, we provide qualitative and quantitative measurements of the features learned by these models and how they differ from baselines. TriDeNT offers a novel method to distil knowledge from scarce or costly data during training, to create significantly better models for routine inputs. ",
    "url": "https://arxiv.org/abs/2312.02111",
    "authors": [
      "Lucas Farndale",
      "Robert Insall",
      "Ke Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2312.02112",
    "title": "Distributed Optimization with Feasible Set Privacy",
    "abstract": "We consider the setup of a constrained optimization problem with two agents $E_1$ and $E_2$ who jointly wish to learn the optimal solution set while keeping their feasible sets $\\mathcal{P}_1$ and $\\mathcal{P}_2$ private from each other. The objective function $f$ is globally known and each feasible set is a collection of points from a global alphabet. We adopt a sequential symmetric private information retrieval (SPIR) framework where one of the agents (say $E_1$) privately checks in $\\mathcal{P}_2$, the presence of candidate solutions of the problem constrained to $\\mathcal{P}_1$ only, while learning no further information on $\\mathcal{P}_2$ than the solution alone. Further, we extract an information theoretically private threshold PSI (ThPSI) protocol from our scheme and characterize its download cost. We show that, compared to privately acquiring the feasible set $\\mathcal{P}_1\\cap \\mathcal{P}_2$ using an SPIR-based private set intersection (PSI) protocol, and finding the optimum, our scheme is better as it incurs less information leakage and less download cost than the former. Over all possible uniform mappings of $f$ to a fixed range of values, our scheme outperforms the former with a high probability. ",
    "url": "https://arxiv.org/abs/2312.02112",
    "authors": [
      "Shreya Meel",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.02120",
    "title": "Magicoder: Source Code Is All You Need",
    "abstract": "We introduce Magicoder, a series of fully open-source (code, weights, and data) Large Language Models (LLMs) for code that significantly closes the gap with top code models while having no more than 7B parameters. Magicoder models are trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets to generate high-quality instruction data for code. Our main motivation is to mitigate the inherent bias of the synthetic data generated by LLMs by empowering them with a wealth of open-source references for the production of more diverse, realistic, and controllable data. The orthogonality of OSS-Instruct and other data generation methods like Evol-Instruct further enables us to build an enhanced MagicoderS. Both Magicoder and MagicoderS substantially outperform state-of-the-art code models with similar or even larger sizes on a wide range of coding benchmarks, including Python text-to-code generation, multilingual coding, and data-science program completion. Notably, MagicoderS-CL-7B based on CodeLlama even surpasses the prominent ChatGPT on HumanEval+ (66.5 vs. 65.9 in pass@1). Overall, OSS-Instruct opens a new direction for low-bias and high-quality instruction tuning using abundant open-source references. ",
    "url": "https://arxiv.org/abs/2312.02120",
    "authors": [
      "Yuxiang Wei",
      "Zhe Wang",
      "Jiawei Liu",
      "Yifeng Ding",
      "Lingming Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.02142",
    "title": "Object Recognition as Next Token Prediction",
    "abstract": "We present an approach to pose object recognition as next token prediction. The idea is to apply a language decoder that auto-regressively predicts the text tokens from image embeddings to form labels. To ground this prediction process in auto-regression, we customize a non-causal attention mask for the decoder, incorporating two key features: modeling tokens from different labels to be independent, and treating image tokens as a prefix. This masking mechanism inspires an efficient method - one-shot sampling - to simultaneously sample tokens of multiple labels in parallel and rank generated labels by their probabilities during inference. To further enhance the efficiency, we propose a simple strategy to construct a compact decoder by simply discarding the intermediate blocks of a pretrained language model. This approach yields a decoder that matches the full model's performance while being notably more efficient. The code is available at https://github.com/kaiyuyue/nxtp ",
    "url": "https://arxiv.org/abs/2312.02142",
    "authors": [
      "Kaiyu Yue",
      "Bor-Chun Chen",
      "Jonas Geiping",
      "Hengduo Li",
      "Tom Goldstein",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.02144",
    "title": "Optimizing Camera Configurations for Multi-View Pedestrian Detection",
    "abstract": "Jointly considering multiple camera views (multi-view) is very effective for pedestrian detection under occlusion. For such multi-view systems, it is critical to have well-designed camera configurations, including camera locations, directions, and fields-of-view (FoVs). Usually, these configurations are crafted based on human experience or heuristics. In this work, we present a novel solution that features a transformer-based camera configuration generator. Using reinforcement learning, this generator autonomously explores vast combinations within the action space and searches for configurations that give the highest detection accuracy according to the training dataset. The generator learns advanced techniques like maximizing coverage, minimizing occlusion, and promoting collaboration. Across multiple simulation scenarios, the configurations generated by our transformer-based model consistently outperform random search, heuristic-based methods, and configurations designed by human experts, shedding light on future camera layout optimization. ",
    "url": "https://arxiv.org/abs/2312.02144",
    "authors": [
      "Yunzhong Hou",
      "Xingjian Leng",
      "Tom Gedeon",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.02147",
    "title": "Rejuvenating image-GPT as Strong Visual Representation Learners",
    "abstract": "This paper enhances image-GPT (iGPT), one of the pioneering works that introduce autoregressive pretraining to predict next pixels for visual representation learning. Two simple yet essential changes are made. First, we shift the prediction target from raw pixels to semantic tokens, enabling a higher-level understanding of visual content. Second, we supplement the autoregressive modeling by instructing the model to predict not only the next tokens but also the visible tokens. This pipeline is particularly effective when semantic tokens are encoded by discriminatively trained models, such as CLIP. We introduce this novel approach as D-iGPT. Extensive experiments showcase that D-iGPT excels as a strong learner of visual representations: A notable achievement of D-iGPT is its compelling performance on the ImageNet-1K dataset -- by training on publicly available datasets, D-iGPT achieves 89.5\\% top-1 accuracy with a vanilla ViT-Large model. This model also shows strong generalization on the downstream task and robustness on out-of-distribution samples. Code is avaiable at \\href{https://github.com/OliverRensu/D-iGPT}{https://github.com/OliverRensu/D-iGPT}. ",
    "url": "https://arxiv.org/abs/2312.02147",
    "authors": [
      "Sucheng Ren",
      "Zeyu Wang",
      "Hongru Zhu",
      "Junfei Xiao",
      "Alan Yuille",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.02157",
    "title": "Mesh-Guided Neural Implicit Field Editing",
    "abstract": "Neural implicit fields have emerged as a powerful 3D representation for reconstructing and rendering photo-realistic views, yet they possess limited editability. Conversely, explicit 3D representations, such as polygonal meshes, offer ease of editing but may not be as suitable for rendering high-quality novel views. To harness the strengths of both representations, we propose a new approach that employs a mesh as a guiding mechanism in editing the neural radiance field. We first introduce a differentiable method using marching tetrahedra for polygonal mesh extraction from the neural implicit field and then design a differentiable color extractor to assign colors obtained from the volume renderings to this extracted mesh. This differentiable colored mesh allows gradient back-propagation from the explicit mesh to the implicit fields, empowering users to easily manipulate the geometry and color of neural implicit fields. To enhance user control from coarse-grained to fine-grained levels, we introduce an octree-based structure into its optimization. This structure prioritizes the edited regions and the surface part, making our method achieve fine-grained edits to the neural implicit field and accommodate various user modifications, including object additions, component removals, specific area deformations, and adjustments to local and global colors. Through extensive experiments involving diverse scenes and editing operations, we have demonstrated the capabilities and effectiveness of our method. Our project page is: \\url{https://cassiepython.github.io/MNeuEdit/} ",
    "url": "https://arxiv.org/abs/2312.02157",
    "authors": [
      "Can Wang",
      "Mingming He",
      "Menglei Chai",
      "Dongdong Chen",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00811",
    "title": "Seizure detection from Electroencephalogram signals via Wavelets and  Graph Theory metrics",
    "abstract": "Epilepsy is one of the most prevalent neurological conditions, where an epileptic seizure is a transient occurrence due to abnormal, excessive and synchronous activity in the brain. Electroencephalogram signals emanating from the brain may be captured, analysed and then play a significant role in detection and prediction of epileptic seizures. In this work we enhance upon a previous approach that relied on the differing properties of the wavelet transform. Here we apply the Maximum Overlap Discrete Wavelet Transform to both reduce signal \\textit{noise} and use signal variance exhibited at differing inherent frequency levels to develop various metrics of connection between the electrodes placed upon the scalp. %The properties of both the noise reduced signal and the interconnected electrodes differ significantly during the different brain states. Using short duration epochs, to approximate close to real time monitoring, together with simple statistical parameters derived from the reconstructed noise reduced signals we initiate seizure detection. To further improve performance we utilise graph theoretic indicators from derived electrode connectivity. From there we build the attribute space. We utilise open-source software and publicly available data to highlight the superior Recall/Sensitivity performance of our approach, when compared to existing published methods. ",
    "url": "https://arxiv.org/abs/2312.00811",
    "authors": [
      "Paul Grant",
      "Md Zahidul Islam"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2312.00842",
    "title": "ESM-NBR: fast and accurate nucleic acid-binding residue prediction via  protein language model feature representation and multi-task learning",
    "abstract": "Protein-nucleic acid interactions play a very important role in a variety of biological activities. Accurate identification of nucleic acid-binding residues is a critical step in understanding the interaction mechanisms. Although many computationally based methods have been developed to predict nucleic acid-binding residues, challenges remain. In this study, a fast and accurate sequence-based method, called ESM-NBR, is proposed. In ESM-NBR, we first use the large protein language model ESM2 to extract discriminative biological properties feature representation from protein primary sequences; then, a multi-task deep learning model composed of stacked bidirectional long short-term memory (BiLSTM) and multi-layer perceptron (MLP) networks is employed to explore common and private information of DNA- and RNA-binding residues with ESM2 feature as input. Experimental results on benchmark data sets demonstrate that the prediction performance of ESM2 feature representation comprehensively outperforms evolutionary information-based hidden Markov model (HMM) features. Meanwhile, the ESM-NBR obtains the MCC values for DNA-binding residues prediction of 0.427 and 0.391 on two independent test sets, which are 18.61 and 10.45% higher than those of the second-best methods, respectively. Moreover, by completely discarding the time-cost multiple sequence alignment process, the prediction speed of ESM-NBR far exceeds that of existing methods (5.52s for a protein sequence of length 500, which is about 16 times faster than the second-fastest method). A user-friendly standalone package and the data of ESM-NBR are freely available for academic use at: https://github.com/wwzll123/ESM-NBR. ",
    "url": "https://arxiv.org/abs/2312.00842",
    "authors": [
      "Wenwu Zeng",
      "Dafeng Lv",
      "Wenjuan Liu",
      "Shaoliang Peng"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00854",
    "title": "A Probabilistic Neural Twin for Treatment Planning in Peripheral  Pulmonary Artery Stenosis",
    "abstract": "The substantial computational cost of high-fidelity models in numerical hemodynamics has, so far, relegated their use mainly to offline treatment planning. New breakthroughs in data-driven architectures and optimization techniques for fast surrogate modeling provide an exciting opportunity to overcome these limitations, enabling the use of such technology for time-critical decisions. We discuss an application to the repair of multiple stenosis in peripheral pulmonary artery disease through either transcatheter pulmonary artery rehabilitation or surgery, where it is of interest to achieve desired pressures and flows at specific locations in the pulmonary artery tree, while minimizing the risk for the patient. Since different degrees of success can be achieved in practice during treatment, we formulate the problem in probability, and solve it through a sample-based approach. We propose a new offline-online pipeline for probabilsitic real-time treatment planning which combines offline assimilation of boundary conditions, model reduction, and training dataset generation with online estimation of marginal probabilities, possibly conditioned on the degree of augmentation observed in already repaired lesions. Moreover, we propose a new approach for the parametrization of arbitrarily shaped vascular repairs through iterative corrections of a zero-dimensional approximant. We demonstrate this pipeline for a diseased model of the pulmonary artery tree available through the Vascular Model Repository. ",
    "url": "https://arxiv.org/abs/2312.00854",
    "authors": [
      "John D. Lee",
      "Jakob Richter",
      "Martin R. Pfaller",
      "Jason M. Szafron",
      "Karthik Menon",
      "Andrea Zanoni",
      "Michael R. Ma",
      "Jeffrey A. Feinstein",
      "Jacqueline Kreutzer",
      "Alison L. Marsden",
      "Daniele E. Schiavazzi"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2312.00859",
    "title": "Random Walks Performed by Topologically-Specific Agents on Complex  Networks",
    "abstract": "Random walks by single-node agents have been systematically conducted on various types of complex networks in order to investigate how their topologies can affect the dynamics of the agents. However, by fitting any network node, these agents do not engage in topological interactions with the network. In the present work, we describe random walks on complex networks performed by agents that are actually small graphs. These agents can only occupy admissible portions of the network onto which they fit topologically, hence their name being taken as topologically-specific agents. These agents are also allowed to move to adjacent subgraphs in the network, which have each node adjacent to the original respective node of the agent. Two types of random walks are considered here: uniformly random and influenced by an external field. The performance of the random walks performed by three types of topologically-specific agents is studied respectively to the obtained coverage considering three types of complex networks (geometrical, Erd\\H{o}s-R\\'enyi, and Barab\\'asi-Albert). The number of nodes displaced at each random walk step is also obtained and analyzed. Several interesting results are reported and discussed, including the fact that, despite its intrinsic node degree heterogeneity, Barab\\'asi-Albert networks tend to allow relatively smooth and effective coverage by all the considered topologically-specific agents. Erd\\H{o}s-R\\'enyi networks were also found to yield large dispersions of node coverage. In addition, the triangle agent was found to allow more effective random walks respectively to any of the three considered networks. ",
    "url": "https://arxiv.org/abs/2312.00859",
    "authors": [
      "Alexandre Benatti",
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2312.00921",
    "title": "Bitstream Organization for Parallel Entropy Coding on Neural  Network-based Video Codecs",
    "abstract": "Video compression systems must support increasing bandwidth and data throughput at low cost and power, and can be limited by entropy coding bottlenecks. Efficiency can be greatly improved by parallelizing coding, which can be done at much larger scales with new neural-based codecs, but with some compression loss related to data organization. We analyze the bit rate overhead needed to support multiple bitstreams for concurrent decoding, and for its minimization propose a method for compressing parallel-decoding entry points, using bidirectional bitstream packing, and a new form of jointly optimizing arithmetic coding termination. It is shown that those techniques significantly lower the overhead, making it easier to reduce it to a small fraction of the average bitstream size, like, for example, less than 1% and 0.1% when the average number of bitstream bytes is respectively larger than 95 and 1,200 bytes. ",
    "url": "https://arxiv.org/abs/2312.00921",
    "authors": [
      "Amir Said",
      "Hoang Le",
      "Farzad Farhadzadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2312.00928",
    "title": "The Hat Guessing Number of Cactus Graphs and Cycles",
    "abstract": "We study the hat guessing game on graphs. In this game, a player is placed on each vertex $v$ of a graph $G$ and assigned a colored hat from $h(v)$ possible colors. Each player makes a deterministic guess on their hat color based on the colors assigned to the players on neighboring vertices, and the players win if at least one player correctly guesses his assigned color. If there exists a strategy that ensures at least one player guesses correctly for every possible assignment of colors, the game defined by $\\langle G,h\\rangle$ is called winning. The hat guessing number of $G$ is the largest integer $q$ so that if $h(v)=q$ for all $v\\in G$ then $\\langle G,h\\rangle$ is winning. In this note, we determine whether $\\langle G,h\\rangle $ is winning for any $h$ whenever $G$ is a cycle, resolving a conjecture of Kokhas and Latyshev in the affirmative and extending it. We then use this result to determine the hat guessing number of every cactus graph, graphs in which every pair of cycles share at most one vertex. ",
    "url": "https://arxiv.org/abs/2312.00928",
    "authors": [
      "Jeremy Chizewer",
      "I.M.J. McInnis",
      "Mehrdad Sohrabi",
      "Shriya Kaistha"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2312.00975",
    "title": "Noisy probing dose facilitated dose prediction for pencil beam scanning  proton therapy: physics enhances generalizability",
    "abstract": "Purpose: Prior AI-based dose prediction studies in photon and proton therapy often neglect underlying physics, limiting their generalizability to handle outlier clinical cases, especially for pencil beam scanning proton therapy (PBSPT). Our aim is to design a physics-aware and generalizable AI-based PBSPT dose prediction method that has the underlying physics considered to achieve high generalizability to properly handle the outlier clinical cases. Methods and Materials: This study analyzed PBSPT plans of 103 prostate and 78 lung cancer patients from our institution,with each case comprising CT images, structure sets, and plan doses from our Monte-Carlo dose engine (serving as the ground truth). Three methods were evaluated in the ablation study: the ROI-based method, the beam mask and sliding window method, and the noisy probing dose method. Twelve cases with uncommon beam angles or prescription doses tested the methods' generalizability to rare treatment planning scenarios. Performance evaluation used DVH indices, 3D Gamma passing rates (3%/2mm/10%), and dice coefficients for dose agreement. Results: The noisy probing dose method showed improved agreement of DVH indices, 3D Gamma passing rates, and dice coefficients compared to the conventional methods for the testing cases. The noisy probing dose method showed better generalizability in the 6 outlier cases than the ROI-based and beam mask-based methods with 3D Gamma passing rates (for prostate cancer, targets: 89.32%$\\pm$1.45% vs. 93.48%$\\pm$1.51% vs. 96.79%$\\pm$0.83%, OARs: 85.87%$\\pm$1.73% vs. 91.15%$\\pm$1.13% vs. 94.29%$\\pm$1.01%). The dose predictions were completed within 0.3 seconds. Conclusions: We've devised a novel noisy probing dose method for PBSPT dose prediction in prostate and lung cancer patients. With more physics included, it enhances the generalizability of dose prediction in handling outlier clinical cases. ",
    "url": "https://arxiv.org/abs/2312.00975",
    "authors": [
      "Lian Zhang",
      "Jason M. Holmes",
      "Zhengliang Liu",
      "Hongying Feng",
      "Terence T. Sio",
      "Carlos E. Vargas",
      "Sameer R. Keole",
      "Kristin St\u00fctzer",
      "Sheng Li",
      "Tianming Liu",
      "Jiajian Shen",
      "William W. Wong",
      "Sujay A. Vora",
      "Wei Liu"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00991",
    "title": "Convergences for Minimax Optimization Problems over Infinite-Dimensional  Spaces Towards Stability in Adversarial Training",
    "abstract": "Training neural networks that require adversarial optimization, such as generative adversarial networks (GANs) and unsupervised domain adaptations (UDAs), suffers from instability. This instability problem comes from the difficulty of the minimax optimization, and there have been various approaches in GANs and UDAs to overcome this problem. In this study, we tackle this problem theoretically through a functional analysis. Specifically, we show the convergence property of the minimax problem by the gradient descent over the infinite-dimensional spaces of continuous functions and probability measures under certain conditions. Using this setting, we can discuss GANs and UDAs comprehensively, which have been studied independently. In addition, we show that the conditions necessary for the convergence property are interpreted as stabilization techniques of adversarial training such as the spectral normalization and the gradient penalty. ",
    "url": "https://arxiv.org/abs/2312.00991",
    "authors": [
      "Takashi Furuya",
      "Satoshi Okuda",
      "Kazuma Suetake",
      "Yoshihide Sawada"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2312.01046",
    "title": "Bagged Regularized $k$-Distances for Anomaly Detection",
    "abstract": "We consider the paradigm of unsupervised anomaly detection, which involves the identification of anomalies within a dataset in the absence of labeled examples. Though distance-based methods are top-performing for unsupervised anomaly detection, they suffer heavily from the sensitivity to the choice of the number of the nearest neighbors. In this paper, we propose a new distance-based algorithm called bagged regularized $k$-distances for anomaly detection (BRDAD) converting the unsupervised anomaly detection problem into a convex optimization problem. Our BRDAD algorithm selects the weights by minimizing the surrogate risk, i.e., the finite sample bound of the empirical risk of the bagged weighted $k$-distances for density estimation (BWDDE). This approach enables us to successfully address the sensitivity challenge of the hyperparameter choice in distance-based algorithms. Moreover, when dealing with large-scale datasets, the efficiency issues can be addressed by the incorporated bagging technique in our BRDAD algorithm. On the theoretical side, we establish fast convergence rates of the AUC regret of our algorithm and demonstrate that the bagging technique significantly reduces the computational complexity. On the practical side, we conduct numerical experiments on anomaly detection benchmarks to illustrate the insensitivity of parameter selection of our algorithm compared with other state-of-the-art distance-based methods. Moreover, promising improvements are brought by applying the bagging technique in our algorithm on real-world datasets. ",
    "url": "https://arxiv.org/abs/2312.01046",
    "authors": [
      "Yuchao Cai",
      "Yuheng Ma",
      "Hanfang Yang",
      "Hanyuan Hang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2312.01061",
    "title": "Spectral-wise Implicit Neural Representation for Hyperspectral Image  Reconstruction",
    "abstract": "Coded Aperture Snapshot Spectral Imaging (CASSI) reconstruction aims to recover the 3D spatial-spectral signal from 2D measurement. Existing methods for reconstructing Hyperspectral Image (HSI) typically involve learning mappings from a 2D compressed image to a predetermined set of discrete spectral bands. However, this approach overlooks the inherent continuity of the spectral information. In this study, we propose an innovative method called Spectral-wise Implicit Neural Representation (SINR) as a pioneering step toward addressing this limitation. SINR introduces a continuous spectral amplification process for HSI reconstruction, enabling spectral super-resolution with customizable magnification factors. To achieve this, we leverage the concept of implicit neural representation. Specifically, our approach introduces a spectral-wise attention mechanism that treats individual channels as distinct tokens, thereby capturing global spectral dependencies. Additionally, our approach incorporates two components, namely a Fourier coordinate encoder and a spectral scale factor module. The Fourier coordinate encoder enhances the SINR's ability to emphasize high-frequency components, while the spectral scale factor module guides the SINR to adapt to the variable number of spectral channels. Notably, the SINR framework enhances the flexibility of CASSI reconstruction by accommodating an unlimited number of spectral bands in the desired output. Extensive experiments demonstrate that our SINR outperforms baseline methods. By enabling continuous reconstruction within the CASSI framework, we take the initial stride toward integrating implicit neural representation into the field. ",
    "url": "https://arxiv.org/abs/2312.01061",
    "authors": [
      "Huan Chen",
      "Wangcai Zhao",
      "Tingfa Xu",
      "Shiyun Zhou",
      "Peifu Liu",
      "Jianan Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01128",
    "title": "SPEEDNet: Salient Pyramidal Enhancement Encoder-Decoder Network for  Colonoscopy Images",
    "abstract": "Accurate identification and precise delineation of regions of significance, such as tumors or lesions, is a pivotal goal in medical imaging analysis. This paper proposes SPEEDNet, a novel architecture for precisely segmenting lesions within colonoscopy images. SPEEDNet uses a novel block named Dilated-Involutional Pyramidal Convolution Fusion (DIPC). A DIPC block combines the dilated involution layers pairwise into a pyramidal structure to convert the feature maps into a compact space. This lowers the total number of parameters while improving the learning of representations across an optimal receptive field, thereby reducing the blurring effect. On the EBHISeg dataset, SPEEDNet outperforms three previous networks: UNet, FeedNet, and AttesResDUNet. Specifically, SPEEDNet attains an average dice score of 0.952 and a recall of 0.971. Qualitative results and ablation studies provide additional insights into the effectiveness of SPEEDNet. The model size of SPEEDNet is 9.81 MB, significantly smaller than that of UNet (22.84 MB), FeedNet(185.58 MB), and AttesResDUNet (140.09 MB). ",
    "url": "https://arxiv.org/abs/2312.01128",
    "authors": [
      "Tushir Sahu",
      "Vidhi Bhatt",
      "Sai Chandra Teja R",
      "Sparsh Mittal",
      "Nagesh Kumar S"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01210",
    "title": "When accurate prediction models yield harmful self-fulfilling prophecies",
    "abstract": "Prediction models are popular in medical research and practice. By predicting an outcome of interest for specific patients, these models may help inform difficult treatment decisions, and are often hailed as the poster children for personalized, data-driven healthcare. We show however, that using prediction models for decision making can lead to harmful decisions, even when the predictions exhibit good discrimination after deployment. These models are harmful self-fulfilling prophecies: their deployment harms a group of patients but the worse outcome of these patients does not invalidate the predictive power of the model. Our main result is a formal characterization of a set of such prediction models. Next we show that models that are well calibrated before} and after deployment are useless for decision making as they made no change in the data distribution. These results point to the need to revise standard practices for validation, deployment and evaluation of prediction models that are used in medical decisions. ",
    "url": "https://arxiv.org/abs/2312.01210",
    "authors": [
      "Wouter A.C. van Amsterdam",
      "Nan van Geloven",
      "Jesse Krijthe",
      "Rajesh Ranganth",
      "Giovanni Cin\u00e1"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.01228",
    "title": "Mixed-Integer Optimisation of Graph Neural Networks for Computer-Aided  Molecular Design",
    "abstract": "ReLU neural networks have been modelled as constraints in mixed integer linear programming (MILP), enabling surrogate-based optimisation in various domains and efficient solution of machine learning certification problems. However, previous works are mostly limited to MLPs. Graph neural networks (GNNs) can learn from non-euclidean data structures such as molecular structures efficiently and are thus highly relevant to computer-aided molecular design (CAMD). We propose a bilinear formulation for ReLU Graph Convolutional Neural Networks and a MILP formulation for ReLU GraphSAGE models. These formulations enable solving optimisation problems with trained GNNs embedded to global optimality. We apply our optimization approach to an illustrative CAMD case study where the formulations of the trained GNNs are used to design molecules with optimal boiling points. ",
    "url": "https://arxiv.org/abs/2312.01228",
    "authors": [
      "Tom McDonald",
      "Calvin Tsay",
      "Artur M. Schweidtmann",
      "Neil Yorke-Smith"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.01275",
    "title": "A Review of Link Prediction Applications in Network Biology",
    "abstract": "In the domain of network biology, the interactions among heterogeneous genomic and molecular entities are represented through networks. Link prediction (LP) methodologies are instrumental in inferring missing or prospective associations within these biological networks. In this review, we systematically dissect the attributes of local, centrality, and embedding-based LP approaches, applied to static and dynamic biological networks. We undertake an examination of the current applications of LP metrics for predicting links between diseases, genes, proteins, RNA, microbiomes, drugs, and neurons. We carry out comprehensive performance evaluations on established biological network datasets to show the practical applications of standard LP models. Moreover, we compare the similarity in prediction trends among the models and the specific network attributes that contribute to effective link prediction, before underscoring the role of LP in addressing the formidable challenges prevalent in biological systems, ranging from noise, bias, and data sparseness to interpretability. We conclude the review with an exploration of the essential characteristics expected from future LP models, poised to advance our comprehension of the intricate interactions governing biological systems. ",
    "url": "https://arxiv.org/abs/2312.01275",
    "authors": [
      "Ahmad F. Al Musawi",
      "Satyaki Roy",
      "Preetam Ghosh"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.01296",
    "title": "Anomaly Detection Under Uncertainty Using Distributionally Robust  Optimization Approach",
    "abstract": "Anomaly detection is defined as the problem of finding data points that do not follow the patterns of the majority. Among the various proposed methods for solving this problem, classification-based methods, including one-class Support Vector Machines (SVM) are considered effective and state-of-the-art. The one-class SVM method aims to find a decision boundary to distinguish between normal data points and anomalies using only the normal data. On the other hand, most real-world problems involve some degree of uncertainty, where the true probability distribution of each data point is unknown, and estimating it is often difficult and costly. Assuming partial distribution information such as the first and second-order moments is known, a distributionally robust chance-constrained model is proposed in which the probability of misclassification is low. By utilizing a mapping function to a higher dimensional space, the proposed model will be capable of classifying origin-inseparable datasets. Also, by adopting the kernel idea, the need for explicitly knowing the mapping is eliminated, computations can be performed in the input space, and computational complexity is reduced. Computational results validate the robustness of the proposed model under different probability distributions and also the superiority of the proposed model compared to the standard one-class SVM in terms of various evaluation metrics. ",
    "url": "https://arxiv.org/abs/2312.01296",
    "authors": [
      "Amir Hossein Noormohammadia",
      "Seyed Ali MirHassania",
      "Farnaz Hooshmand Khaligh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01448",
    "title": "Driven transparent quantum graphs",
    "abstract": "In this paper, we discuss the concept of quantum graphs with transparent vertices by considering the case where the graph interacts with an external time-independent field. In particular, we address the problem of transparent boundary conditions for quantum graphs, building on previous work on transparent boundary conditions for the stationary Schrodinger equation on a line. Physically relevant constraints making the vertex transparent under boundary conditions in the form of (weight) continuity and Kirchhoff rules are derived using two methods, the scattering approach and transparent boundary conditions for the time-independent Schrodinger equation. The latter is derived by extending the transparent boundary condition concept to the time-independent Schrodinger equation on driven quantum graphs. We also discuss how the eigenvalues and eigenfunctions of a quantum graph are influenced not only by its topology, but also by the shape(type) of a potential when an external field is involved. ",
    "url": "https://arxiv.org/abs/2312.01448",
    "authors": [
      "J.R. Yusupov",
      "M. Ehrhardt",
      "Kh.Sh. Matyokubov",
      "D.U. Matrasulov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.01527",
    "title": "NovoMol: Recurrent Neural Network for Orally Bioavailable Drug Design  and Validation on PDGFR\u03b1 Receptor",
    "abstract": "Longer timelines and lower success rates of drug candidates limit the productivity of clinical trials in the pharmaceutical industry. Promising de novo drug design techniques help solve this by exploring a broader chemical space, efficiently generating new molecules, and providing improved therapies. However, optimizing for molecular characteristics found in approved oral drugs remains a challenge, limiting de novo usage. In this work, we propose NovoMol, a novel de novo method using recurrent neural networks to mass-generate drug molecules with high oral bioavailability, increasing clinical trial time efficiency. Molecules were optimized for desirable traits and ranked using the quantitative estimate of drug-likeness (QED). Generated molecules meeting QED's oral bioavailability threshold were used to retrain the neural network, and, after five training cycles, 76% of generated molecules passed this strict threshold and 96% passed the traditionally used Lipinski's Rule of Five. The trained model was then used to generate specific drug candidates for the cancer-related PDGFR{\\alpha} receptor and 44% of generated candidates had better binding affinity than the current state-of-the-art drug, Imatinib (with a receptor binding affinity of -9.4 kcal/mol), and the best-generated candidate at -12.9 kcal/mol. NovoMol provides a time/cost-efficient AI-based de novo method offering promising drug candidates for clinical trials. ",
    "url": "https://arxiv.org/abs/2312.01527",
    "authors": [
      "Ishir Rao"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2312.01573",
    "title": "Survey on deep learning in multimodal medical imaging for cancer  detection",
    "abstract": "The task of multimodal cancer detection is to determine the locations and categories of lesions by using different imaging techniques, which is one of the key research methods for cancer diagnosis. Recently, deep learning-based object detection has made significant developments due to its strength in semantic feature extraction and nonlinear function fitting. However, multimodal cancer detection remains challenging due to morphological differences in lesions, interpatient variability, difficulty in annotation, and imaging artifacts. In this survey, we mainly investigate over 150 papers in recent years with respect to multimodal cancer detection using deep learning, with a focus on datasets and solutions to various challenges such as data annotation, variance between classes, small-scale lesions, and occlusion. We also provide an overview of the advantages and drawbacks of each approach. Finally, we discuss the current scope of work and provide directions for the future development of multimodal cancer detection. ",
    "url": "https://arxiv.org/abs/2312.01573",
    "authors": [
      "Yan Tian",
      "Zhaocheng Xu",
      "Yujun Ma",
      "Weiping Ding",
      "Ruili Wang",
      "Zhihong Gao",
      "Guohua Cheng",
      "Linyang He",
      "Xuran Zhao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01679",
    "title": "Adversarial Medical Image with Hierarchical Feature Hiding",
    "abstract": "Deep learning based methods for medical images can be easily compromised by adversarial examples (AEs), posing a great security flaw in clinical decision-making. It has been discovered that conventional adversarial attacks like PGD which optimize the classification logits, are easy to distinguish in the feature space, resulting in accurate reactive defenses. To better understand this phenomenon and reassess the reliability of the reactive defenses for medical AEs, we thoroughly investigate the characteristic of conventional medical AEs. Specifically, we first theoretically prove that conventional adversarial attacks change the outputs by continuously optimizing vulnerable features in a fixed direction, thereby leading to outlier representations in the feature space. Then, a stress test is conducted to reveal the vulnerability of medical images, by comparing with natural images. Interestingly, this vulnerability is a double-edged sword, which can be exploited to hide AEs. We then propose a simple-yet-effective hierarchical feature constraint (HFC), a novel add-on to conventional white-box attacks, which assists to hide the adversarial feature in the target feature distribution. The proposed method is evaluated on three medical datasets, both 2D and 3D, with different modalities. The experimental results demonstrate the superiority of HFC, \\emph{i.e.,} it bypasses an array of state-of-the-art adversarial medical AE detectors more efficiently than competing adaptive attacks, which reveals the deficiencies of medical reactive defense and allows to develop more robust defenses in future. ",
    "url": "https://arxiv.org/abs/2312.01679",
    "authors": [
      "Qingsong Yao",
      "Zecheng He",
      "Yuexiang Li",
      "Yi Lin",
      "Kai Ma",
      "Yefeng Zheng",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01689",
    "title": "Fast and accurate sparse-view CBCT reconstruction using meta-learned  neural attenuation field and hash-encoding regularization",
    "abstract": "Cone beam computed tomography (CBCT) is an emerging medical imaging technique to visualize the internal anatomical structures of patients. During a CBCT scan, several projection images of different angles or views are collectively utilized to reconstruct a tomographic image. However, reducing the number of projections in a CBCT scan while preserving the quality of a reconstructed image is challenging due to the nature of an ill-posed inverse problem. Recently, a neural attenuation field (NAF) method was proposed by adopting a neural radiance field algorithm as a new way for CBCT reconstruction, demonstrating fast and promising results using only 50 views. However, decreasing the number of projections is still preferable to reduce potential radiation exposure, and a faster reconstruction time is required considering a typical scan time. In this work, we propose a fast and accurate sparse-view CBCT reconstruction (FACT) method to provide better reconstruction quality and faster optimization speed in the minimal number of view acquisitions ($<$ 50 views). In the FACT method, we meta-trained a neural network and a hash-encoder using a few scans (= 15), and a new regularization technique is utilized to reconstruct the details of an anatomical structure. In conclusion, we have shown that the FACT method produced better, and faster reconstruction results over the other conventional algorithms based on CBCT scans of different body parts (chest, head, and abdomen) and CT vendors (Siemens, Phillips, and GE). ",
    "url": "https://arxiv.org/abs/2312.01689",
    "authors": [
      "Heejun Shin",
      "Taehee Kim",
      "Jongho Lee",
      "Seyoung Chun",
      "Seungryung Cho",
      "Dongmyung Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01726",
    "title": "Simultaneous Alignment and Surface Regression Using Hybrid 2D-3D  Networks for 3D Coherent Layer Segmentation of Retinal OCT Images with Full  and Sparse Annotations",
    "abstract": "Layer segmentation is important to quantitative analysis of retinal optical coherence tomography (OCT). Recently, deep learning based methods have been developed to automate this task and yield remarkable performance. However, due to the large spatial gap and potential mismatch between the B-scans of an OCT volume, all of them were based on 2D segmentation of individual B-scans, which may lose the continuity and diagnostic information of the retinal layers in 3D space. Besides, most of these methods required dense annotation of the OCT volumes, which is labor-intensive and expertise-demanding. This work presents a novel framework based on hybrid 2D-3D convolutional neural networks (CNNs) to obtain continuous 3D retinal layer surfaces from OCT volumes, which works well with both full and sparse annotations. The 2D features of individual B-scans are extracted by an encoder consisting of 2D convolutions. These 2D features are then used to produce the alignment displacement vectors and layer segmentation by two 3D decoders coupled via a spatial transformer module. Two losses are proposed to utilize the retinal layers' natural property of being smooth for B-scan alignment and layer segmentation, respectively, and are the key to the semi-supervised learning with sparse annotation. The entire framework is trained end-to-end. To the best of our knowledge, this is the first work that attempts 3D retinal layer segmentation in volumetric OCT images based on CNNs. Experiments on a synthetic dataset and three public clinical datasets show that our framework can effectively align the B-scans for potential motion correction, and achieves superior performance to state-of-the-art 2D deep learning methods in terms of both layer segmentation accuracy and cross-B-scan 3D continuity in both fully and semi-supervised settings, thus offering more clinical values than previous works. ",
    "url": "https://arxiv.org/abs/2312.01726",
    "authors": [
      "Hong Liu",
      "Dong Wei",
      "Donghuan Lu",
      "Xiaoying Tang",
      "Liansheng Wang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01999",
    "title": "SRTransGAN: Image Super-Resolution using Transformer based Generative  Adversarial Network",
    "abstract": "Image super-resolution aims to synthesize high-resolution image from a low-resolution image. It is an active area to overcome the resolution limitations in several applications like low-resolution object-recognition, medical image enhancement, etc. The generative adversarial network (GAN) based methods have been the state-of-the-art for image super-resolution by utilizing the convolutional neural networks (CNNs) based generator and discriminator networks. However, the CNNs are not able to exploit the global information very effectively in contrast to the transformers, which are the recent breakthrough in deep learning by exploiting the self-attention mechanism. Motivated from the success of transformers in language and vision applications, we propose a SRTransGAN for image super-resolution using transformer based GAN. Specifically, we propose a novel transformer-based encoder-decoder network as a generator to generate 2x images and 4x images. We design the discriminator network using vision transformer which uses the image as sequence of patches and hence useful for binary classification between synthesized and real high-resolution images. The proposed SRTransGAN outperforms the existing methods by 4.38 % on an average of PSNR and SSIM scores. We also analyze the saliency map to understand the learning ability of the proposed method. ",
    "url": "https://arxiv.org/abs/2312.01999",
    "authors": [
      "Neeraj Baghel",
      "Shiv Ram Dubey",
      "Satish Kumar Singh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2003.03923",
    "title": "Deconfounded Image Captioning: A Causal Retrospect",
    "abstract": " Title: Deconfounded Image Captioning: A Causal Retrospect ",
    "url": "https://arxiv.org/abs/2003.03923",
    "authors": [
      "Xu Yang",
      "Hanwang Zhang",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.13742",
    "title": "MineGAN++: Mining Generative Models for Efficient Knowledge Transfer to  Limited Data Domains",
    "abstract": " Comments: accepted at IJCV. arXiv admin note: substantial text overlap with arXiv:1912.05270 ",
    "url": "https://arxiv.org/abs/2104.13742",
    "authors": [
      "Yaxing Wang",
      "Abel Gonzalez-Garcia",
      "Chenshen Wu",
      "Luis Herranz",
      "Fahad Shahbaz Khan",
      "Shangling Jui",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.08758",
    "title": "Denial-of-Service Attack Detection via Differential Analysis of  Generalized Entropy Progressions",
    "abstract": " Title: Denial-of-Service Attack Detection via Differential Analysis of  Generalized Entropy Progressions ",
    "url": "https://arxiv.org/abs/2109.08758",
    "authors": [
      "Omer Subasi",
      "Joseph Manzano",
      "Kevin Barker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.01592",
    "title": "Biphasic Face Photo-Sketch Synthesis via Semantic-Driven Generative  Adversarial Network with Graph Representation Learning",
    "abstract": " Comments: Accepted to IEEE TNNLS ",
    "url": "https://arxiv.org/abs/2201.01592",
    "authors": [
      "Xingqun Qi",
      "Muyi Sun",
      "Zijian Wang",
      "Jiaming Liu",
      "Qi Li",
      "Fang Zhao",
      "Shanghang Zhang",
      "Caifeng Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11720",
    "title": "ENS-t-SNE: Embedding Neighborhoods Simultaneously t-SNE",
    "abstract": " Title: ENS-t-SNE: Embedding Neighborhoods Simultaneously t-SNE ",
    "url": "https://arxiv.org/abs/2205.11720",
    "authors": [
      "Jacob Miller",
      "Vahan Huroyan",
      "Raymundo Navarrete",
      "Md Iqbal Hossain",
      "Stephen Kobourov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2206.05669",
    "title": "Universality and approximation bounds for echo state networks with  random weights",
    "abstract": " Title: Universality and approximation bounds for echo state networks with  random weights ",
    "url": "https://arxiv.org/abs/2206.05669",
    "authors": [
      "Zhen Li",
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.05784",
    "title": "Distilled Non-Semantic Speech Embeddings with Binary Neural Networks for  Low-Resource Devices",
    "abstract": " Title: Distilled Non-Semantic Speech Embeddings with Binary Neural Networks for  Low-Resource Devices ",
    "url": "https://arxiv.org/abs/2207.05784",
    "authors": [
      "Harlin Lee",
      "Aaqib Saeed"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.13381",
    "title": "Look Closer to Your Enemy: Learning to Attack via Teacher-Student  Mimicking",
    "abstract": " Title: Look Closer to Your Enemy: Learning to Attack via Teacher-Student  Mimicking ",
    "url": "https://arxiv.org/abs/2207.13381",
    "authors": [
      "Mingjie Wang",
      "Jianxiong Guo",
      "Sirui Li",
      "Dingwen Xiao",
      "Zhiqing Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00339",
    "title": "GraphMFT: A Graph Network based Multimodal Fusion Technique for Emotion  Recognition in Conversation",
    "abstract": " Comments: Accepted by Neurocomputing ",
    "url": "https://arxiv.org/abs/2208.00339",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.03326",
    "title": "Variational Autoencoders for Anomaly Detection in Respiratory Sounds",
    "abstract": " Comments: Published at ICANN 2022 ",
    "url": "https://arxiv.org/abs/2208.03326",
    "authors": [
      "Michele Cozzatti",
      "Federico Simonetta",
      "Stavros Ntalampiras"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2208.09590",
    "title": "Data-Driven Causal Effect Estimation Based on Graphical Causal  Modelling: A Survey",
    "abstract": " Comments: 35 pages, 10 figures and 2 table, Accepted by ACM Computing Surveys ",
    "url": "https://arxiv.org/abs/2208.09590",
    "authors": [
      "Debo Cheng",
      "Jiuyong Li",
      "Lin Liu",
      "Jixue Liu",
      "Thuc Duy Le"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.01432",
    "title": "From Monte Carlo to neural networks approximations of boundary value  problems",
    "abstract": " Title: From Monte Carlo to neural networks approximations of boundary value  problems ",
    "url": "https://arxiv.org/abs/2209.01432",
    "authors": [
      "Lucian Beznea",
      "Iulian Cimpean",
      "Oana Lupascu-Stamate",
      "Ionel Popescu",
      "Arghir Zarnescu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2209.02973",
    "title": "Foundations of probability-raising causality in Markov decision  processes",
    "abstract": " Comments: Submission for Logical Methods in Computer Science (special issue FoSSaCS 2022) ",
    "url": "https://arxiv.org/abs/2209.02973",
    "authors": [
      "Christel Baier",
      "Jakob Piribauer",
      "Robin Ziemek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2209.11638",
    "title": "GSP-Based MAP Estimation of Graph Signals",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2209.11638",
    "authors": [
      "Guy Sagi",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2209.15146",
    "title": "Ensemble Machine Learning Model Trained on a New Synthesized Dataset  Generalizes Well for Stress Prediction Using Wearable Devices",
    "abstract": " Comments: 37 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2209.15146",
    "authors": [
      "Gideon Vos",
      "Kelly Trinh",
      "Zoltan Sarnyai",
      "Mostafa Rahimi Azghadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.00094",
    "title": "Improving Robustness with Adaptive Weight Decay",
    "abstract": " Title: Improving Robustness with Adaptive Weight Decay ",
    "url": "https://arxiv.org/abs/2210.00094",
    "authors": [
      "Amin Ghiasi",
      "Ali Shafahi",
      "Reza Ardekani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03728",
    "title": "Representing Data as Atoms: Unifying Intra- and Inter-Sample  Relationship to Discretize Data Representation",
    "abstract": " Title: Representing Data as Atoms: Unifying Intra- and Inter-Sample  Relationship to Discretize Data Representation ",
    "url": "https://arxiv.org/abs/2210.03728",
    "authors": [
      "Yi-Lin Tuan",
      "Zih-Yun Chiu",
      "William Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13770",
    "title": "The Virality of Hate Speech on Social Media",
    "abstract": " Comments: Accepted at CSCW 24 ",
    "url": "https://arxiv.org/abs/2210.13770",
    "authors": [
      "Abdurahman Maarouf",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.03570",
    "title": "Do highly over-parameterized neural networks generalize since bad  solutions are rare?",
    "abstract": " Title: Do highly over-parameterized neural networks generalize since bad  solutions are rare? ",
    "url": "https://arxiv.org/abs/2211.03570",
    "authors": [
      "Julius Martinetz",
      "Thomas Martinetz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09983",
    "title": "Universal Approximation Property of Fully Convolutional Neural Networks  with Zero Padding",
    "abstract": " Title: Universal Approximation Property of Fully Convolutional Neural Networks  with Zero Padding ",
    "url": "https://arxiv.org/abs/2211.09983",
    "authors": [
      "Geonho Hwang",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.11530",
    "title": "Open-Set Object Detection Using Classification-free Object Proposal and  Instance-level Contrastive Learning",
    "abstract": " Comments: IEEE Robotics and Automation Letters ",
    "url": "https://arxiv.org/abs/2211.11530",
    "authors": [
      "Zhongxiang Zhou",
      "Yifei Yang",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.09209",
    "title": "CDIO-CT collaborative strategy for solving complex STEM problems in  system modeling and simulation: an illustration of solving the period of  mathematical pendulum",
    "abstract": " Comments: 27 pages, 12 figures, 11 tables ",
    "url": "https://arxiv.org/abs/2212.09209",
    "authors": [
      "Hong-Yan Zhang",
      "Yu Zhou",
      "Yu-Tao Li",
      "Fu-Yun Li",
      "Yong-Hui Jiang"
    ],
    "subjectives": [
      "Physics Education (physics.ed-ph)",
      "Computers and Society (cs.CY)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2212.09928",
    "title": "Improving the Robustness of Summarization Models by Detecting and  Removing Input Noise",
    "abstract": " Comments: EMNLP Findings 2023 Camera Ready ",
    "url": "https://arxiv.org/abs/2212.09928",
    "authors": [
      "Kundan Krishna",
      "Yao Zhao",
      "Jie Ren",
      "Balaji Lakshminarayanan",
      "Jiaming Luo",
      "Mohammad Saleh",
      "Peter J. Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.04517",
    "title": "A new sampling methodology for defining heterogeneous subsets of samples  for training image segmentation algorithms",
    "abstract": " Comments: 10 pages, 9 figures. Under review ",
    "url": "https://arxiv.org/abs/2301.04517",
    "authors": [
      "Matheus Viana da Silva",
      "Nat\u00e1lia de Carvalho Santos",
      "Julie Ouellette",
      "Baptiste Lacoste",
      "Cesar Henrique Comin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.07475",
    "title": "Curvilinear object segmentation in medical images based on ODoS filter  and deep learning network",
    "abstract": " Comments: 20 pages, 8 figures. Applied Intelligence, 2023 ",
    "url": "https://arxiv.org/abs/2301.07475",
    "authors": [
      "Yuanyuan Peng",
      "Lin Pan",
      "Pengpeng Luan",
      "Hongbin Tu",
      "Xiong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.09602",
    "title": "Adapting the Hypersphere Loss Function from Anomaly Detection to Anomaly  Segmentation",
    "abstract": " Comments: Submitted to the 2023 IEEE International Conference on Image Processing (ICIP 2023) ",
    "url": "https://arxiv.org/abs/2301.09602",
    "authors": [
      "Joao P. C. Bertoldo",
      "Santiago Velasco-Forero",
      "Jesus Angulo",
      "Etienne Decenci\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13687",
    "title": "Crossover Can Guarantee Exponential Speed-Ups in Evolutionary  Multi-Objective Optimisation",
    "abstract": " Comments: This is a significant extension of the previous version. We extend the results to uniform crossover and also investigate effects of hypermutation. The previous version is available both on arXiv (arXiv:2301.13687v1) and in AAAI Publications (this https URL) ",
    "url": "https://arxiv.org/abs/2301.13687",
    "authors": [
      "Duc-Cuong Dang",
      "Andre Opris",
      "Dirk Sudholt"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.01178",
    "title": "Convolutional Neural Operators for robust and accurate learning of PDEs",
    "abstract": " Title: Convolutional Neural Operators for robust and accurate learning of PDEs ",
    "url": "https://arxiv.org/abs/2302.01178",
    "authors": [
      "Bogdan Raoni\u0107",
      "Roberto Molinaro",
      "Tim De Ryck",
      "Tobias Rohner",
      "Francesca Bartolucci",
      "Rima Alaifari",
      "Siddhartha Mishra",
      "Emmanuel de B\u00e9zenac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03750",
    "title": "Linking convolutional kernel size to generalization bias in face  analysis CNNs",
    "abstract": " Comments: WACV 2024 ",
    "url": "https://arxiv.org/abs/2302.03750",
    "authors": [
      "Hao Liang",
      "Josue Ortega Caro",
      "Vikram Maheshri",
      "Ankit B. Patel",
      "Guha Balakrishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.01287",
    "title": "High-throughput optical neural networks based on temporal computing",
    "abstract": " Title: High-throughput optical neural networks based on temporal computing ",
    "url": "https://arxiv.org/abs/2303.01287",
    "authors": [
      "Shuang Zheng",
      "Jiawei Zhang",
      "Weifeng Zhang"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2303.06222",
    "title": "Robust MADER: Decentralized Multiagent Trajectory Planner Robust to  Communication Delay in Dynamic Environments",
    "abstract": " Comments: 8 pagers, 10 figures,. arXiv admin note: substantial text overlap with arXiv:2209.13667 ",
    "url": "https://arxiv.org/abs/2303.06222",
    "authors": [
      "Kota Kondo",
      "Reinaldo Figueroa",
      "Juan Rached",
      "Jesus Tordesillas",
      "Parker C. Lusk",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.08240",
    "title": "Parametric Surface Constrained Upsampler Network for Point Cloud",
    "abstract": " Comments: Update Supplementary Files ",
    "url": "https://arxiv.org/abs/2303.08240",
    "authors": [
      "Pingping Cai",
      "Zhenyao Wu",
      "Xinyi Wu",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09051",
    "title": "Robust Evaluation of Diffusion-Based Adversarial Purification",
    "abstract": " Comments: Accepted by ICCV 2023, oral presentation. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.09051",
    "authors": [
      "Minjong Lee",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17783",
    "title": "Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with  Wavelet Augmentation Transformer",
    "abstract": " Comments: 11 pages, 7 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2303.17783",
    "authors": [
      "Yuang Ai",
      "Xiaoqiang Zhou",
      "Huaibo Huang",
      "Lei Zhang",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.00306",
    "title": "CapsFlow: Optical Flow Estimation with Capsule Networks",
    "abstract": " Comments: Newer version added to correct issue in the conference name of the previous version uploaded on April 1st ",
    "url": "https://arxiv.org/abs/2304.00306",
    "authors": [
      "Rahul Chand",
      "Rajat Arora",
      "K Ram Prabhakar",
      "R Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.05467",
    "title": "Structured IQC Synthesis of Robust $\\mathcal{H}_2$ Controllers in the  Frequency Domain",
    "abstract": " Comments: 6 pages, 4 figures, accepted for IFAC World Congress 2023. Shortened to satisfy submission page limit (removed one numerical example and compressed remaining text) ",
    "url": "https://arxiv.org/abs/2304.05467",
    "authors": [
      "Maximilian Sch\u00fctte",
      "Annika Eichler",
      "Herbert Werner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.10159",
    "title": "Deep-Q Learning with Hybrid Quantum Neural Network on Solving Maze  Problems",
    "abstract": " Title: Deep-Q Learning with Hybrid Quantum Neural Network on Solving Maze  Problems ",
    "url": "https://arxiv.org/abs/2304.10159",
    "authors": [
      "Hao-Yuan Chen",
      "Yen-Jui Chang",
      "Shih-Wei Liao",
      "Ching-Ray Chang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11464",
    "title": "Model-Free Learning of Two-Stage Beamformers for Passive IRS-Aided  Network Design",
    "abstract": " Title: Model-Free Learning of Two-Stage Beamformers for Passive IRS-Aided  Network Design ",
    "url": "https://arxiv.org/abs/2304.11464",
    "authors": [
      "Hassaan Hashmi",
      "Spyridon Pougkakiotis",
      "Dionysios S. Kalogerias"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.11761",
    "title": "Hier-RTLMP: A Hierarchical Automatic Macro Placer for Large-scale  Complex IP Blocks",
    "abstract": " Title: Hier-RTLMP: A Hierarchical Automatic Macro Placer for Large-scale  Complex IP Blocks ",
    "url": "https://arxiv.org/abs/2304.11761",
    "authors": [
      "Andrew B. Kahng",
      "Ravi Varadarajan",
      "Zhiang Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.13695",
    "title": "Efficient Approximation for Subgraph-Hitting Problems in Sparse Graphs  and Geometric Intersection Graphs",
    "abstract": " Comments: 52 pages, subsuming the article arXiv:2304.12789 ",
    "url": "https://arxiv.org/abs/2304.13695",
    "authors": [
      "Zden\u011bk Dvo\u0159\u00e1k",
      "Daniel Lokshtanov",
      "Fahad Panolan",
      "Saket Saurabh",
      "Jie Xue",
      "Meirav Zehavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.06898",
    "title": "Identifying vital nodes through augmented random walks on higher-order  networks",
    "abstract": " Title: Identifying vital nodes through augmented random walks on higher-order  networks ",
    "url": "https://arxiv.org/abs/2305.06898",
    "authors": [
      "Yujie Zeng",
      "Yiming Huang",
      "Xiao-Long Ren",
      "Linyuan L\u00fc"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2305.13269",
    "title": "Chain-of-Knowledge: Grounding Large Language Models via Dynamic  Knowledge Adapting over Heterogeneous Sources",
    "abstract": " Title: Chain-of-Knowledge: Grounding Large Language Models via Dynamic  Knowledge Adapting over Heterogeneous Sources ",
    "url": "https://arxiv.org/abs/2305.13269",
    "authors": [
      "Xingxuan Li",
      "Ruochen Zhao",
      "Yew Ken Chia",
      "Bosheng Ding",
      "Shafiq Joty",
      "Soujanya Poria",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14735",
    "title": "Centering the Margins: Outlier-Based Identification of Harmed  Populations in Toxicity Detection",
    "abstract": " Comments: EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.14735",
    "authors": [
      "Vyoma Raman",
      "Eve Fleisig",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14912",
    "title": "SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from  Regularized Modeling Perspective",
    "abstract": " Title: SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from  Regularized Modeling Perspective ",
    "url": "https://arxiv.org/abs/2305.14912",
    "authors": [
      "Yu-Bang Zheng",
      "Xi-Le Zhao",
      "Junhua Zeng",
      "Chao Li",
      "Qibin Zhao",
      "Heng-Chao Li",
      "Ting-Zhu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16746",
    "title": "CNN Feature Map Augmentation for Single-Source Domain Generalization",
    "abstract": " Comments: In proceedings of IEEE BigDataService2023 (this https URL) ",
    "url": "https://arxiv.org/abs/2305.16746",
    "authors": [
      "Aristotelis Ballas",
      "Christos Diou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19125",
    "title": "Graph Generation with $K^2$-trees",
    "abstract": " Comments: 24 pages ",
    "url": "https://arxiv.org/abs/2305.19125",
    "authors": [
      "Yunhui Jang",
      "Dongwoo Kim",
      "Sungsoo Ahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.02956",
    "title": "Explicit Neural Surfaces: Learning Continuous Geometry With Deformation  Fields",
    "abstract": " Title: Explicit Neural Surfaces: Learning Continuous Geometry With Deformation  Fields ",
    "url": "https://arxiv.org/abs/2306.02956",
    "authors": [
      "Thomas Walker",
      "Octave Mariotti",
      "Amir Vaxman",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2306.06082",
    "title": "Augmentation-aware Self-supervised Learning with Conditioned Projector",
    "abstract": " Comments: Prepint under review. Code: this https URL ",
    "url": "https://arxiv.org/abs/2306.06082",
    "authors": [
      "Marcin Przewi\u0119\u017alikowski",
      "Mateusz Pyla",
      "Bartosz Zieli\u0144ski",
      "Bart\u0142omiej Twardowski",
      "Jacek Tabor",
      "Marek \u015amieja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.08736",
    "title": "LoSh: Long-Short Text Joint Prediction Network for Referring Video  Object Segmentation",
    "abstract": " Comments: 11 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2306.08736",
    "authors": [
      "Linfeng Yuan",
      "Miaojing Shi",
      "Zijie Yue",
      "Qijun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.10933",
    "title": "Towards Open-World Recommendation with Knowledge Augmentation from Large  Language Models",
    "abstract": " Title: Towards Open-World Recommendation with Knowledge Augmentation from Large  Language Models ",
    "url": "https://arxiv.org/abs/2306.10933",
    "authors": [
      "Yunjia Xi",
      "Weiwen Liu",
      "Jianghao Lin",
      "Xiaoling Cai",
      "Hong Zhu",
      "Jieming Zhu",
      "Bo Chen",
      "Ruiming Tang",
      "Weinan Zhang",
      "Rui Zhang",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.13387",
    "title": "Improved Competitive Ratios for Online Bipartite Matching on Degree  Bounded Graphs",
    "abstract": " Comments: Some error was discovered in the analysis for the stochastic setting ",
    "url": "https://arxiv.org/abs/2306.13387",
    "authors": [
      "Yilong Feng",
      "Xiaowei Wu",
      "Shengwei Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.15427",
    "title": "Adversarial Training for Graph Neural Networks: Pitfalls, Solutions, and  New Directions",
    "abstract": " Comments: Published as a conference paper at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.15427",
    "authors": [
      "Lukas Gosch",
      "Simon Geisler",
      "Daniel Sturm",
      "Bertrand Charpentier",
      "Daniel Z\u00fcgner",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.02129",
    "title": "How Deep Neural Networks Learn Compositional Data: The Random Hierarchy  Model",
    "abstract": " Comments: 9 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2307.02129",
    "authors": [
      "Francesco Cagnetta",
      "Leonardo Petrini",
      "Umberto M. Tomasini",
      "Alessandro Favero",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.07566",
    "title": "Reconstruction of 3-Axis Seismocardiogram from Right-to-left and  Head-to-foot Components Using A Long Short-Term Memory Network",
    "abstract": " Title: Reconstruction of 3-Axis Seismocardiogram from Right-to-left and  Head-to-foot Components Using A Long Short-Term Memory Network ",
    "url": "https://arxiv.org/abs/2307.07566",
    "authors": [
      "Mohammad Muntasir Rahman",
      "Amirtah\u00e0 Taebi"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.07816",
    "title": "Minimal Random Code Learning with Mean-KL Parameterization",
    "abstract": " Comments: ICML Neural Compression Workshop 2023 ",
    "url": "https://arxiv.org/abs/2307.07816",
    "authors": [
      "Jihao Andreas Lin",
      "Gergely Flamich",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.08165",
    "title": "On short edges in complete topological graphs",
    "abstract": " Title: On short edges in complete topological graphs ",
    "url": "https://arxiv.org/abs/2307.08165",
    "authors": [
      "Andrew Suk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2307.08596",
    "title": "Omnipotent Adversarial Training in the Wild",
    "abstract": " Title: Omnipotent Adversarial Training in the Wild ",
    "url": "https://arxiv.org/abs/2307.08596",
    "authors": [
      "Guanlin Li",
      "Kangjie Chen",
      "Yuan Xu",
      "Han Qiu",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10135",
    "title": "A Hierarchical Architecture for Neural Materials",
    "abstract": " Title: A Hierarchical Architecture for Neural Materials ",
    "url": "https://arxiv.org/abs/2307.10135",
    "authors": [
      "Bowen Xue",
      "Shuang Zhao",
      "Henrik Wann Jensen",
      "Zahra Montazeri"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10205",
    "title": "Alleviating the Effect of Data Imbalance on Adversarial Training",
    "abstract": " Title: Alleviating the Effect of Data Imbalance on Adversarial Training ",
    "url": "https://arxiv.org/abs/2307.10205",
    "authors": [
      "Guanlin Li",
      "Guowen Xu",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01729",
    "title": "Telematics Combined Actuarial Neural Networks for Cross-Sectional and  Longitudinal Claim Count Data",
    "abstract": " Comments: 30 pages, 10 tables, 6 figures ",
    "url": "https://arxiv.org/abs/2308.01729",
    "authors": [
      "Francis Duval",
      "Jean-Philippe Boucher",
      "Mathieu Pigeon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01987",
    "title": "Bengali Fake Reviews: A Benchmark Dataset and Detection System",
    "abstract": " Title: Bengali Fake Reviews: A Benchmark Dataset and Detection System ",
    "url": "https://arxiv.org/abs/2308.01987",
    "authors": [
      "G. M. Shahariar",
      "Md. Tanvir Rouf Shawon",
      "Faisal Muhammad Shah",
      "Mohammad Shafiul Alam",
      "Md. Shahriar Mahbub"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.02715",
    "title": "Fluid Viscosity Prediction Leveraging Computer Vision and Robot  Interaction",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2308.02715",
    "authors": [
      "Jong Hoon Park",
      "Gauri Pramod Dalwankar",
      "Alison Bartsch",
      "Abraham George",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.03982",
    "title": "PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2308.03982",
    "authors": [
      "Ming Nie",
      "Yujing Xue",
      "Chunwei Wang",
      "Chaoqiang Ye",
      "Hang Xu",
      "Xinge Zhu",
      "Qingqiu Huang",
      "Michael Bi Mi",
      "Xinchao Wang",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.04774",
    "title": "E$^3$-UAV: An Edge-based Energy-Efficient Object Detection System for  Unmanned Aerial Vehicles",
    "abstract": " Comments: 16 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2308.04774",
    "authors": [
      "Jiashun Suo",
      "Xingzhou Zhang",
      "Weisong Shi",
      "Wei Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.09296",
    "title": "CARLA: Self-supervised Contrastive Representation Learning for Time  Series Anomaly Detection",
    "abstract": " Comments: 14 pages, 7 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2308.09296",
    "authors": [
      "Zahra Zamanzadeh Darban",
      "Geoffrey I. Webb",
      "Shirui Pan",
      "Charu C. Aggarwal",
      "Mahsa Salehi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.11138",
    "title": "NLP-based detection of systematic anomalies among the narratives of  consumer complaints",
    "abstract": " Title: NLP-based detection of systematic anomalies among the narratives of  consumer complaints ",
    "url": "https://arxiv.org/abs/2308.11138",
    "authors": [
      "Peiheng Gao",
      "Ning Sun",
      "Xuefeng Wang",
      "Chen Yang",
      "Ri\u010dardas Zitikis"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computation and Language (cs.CL)",
      "Risk Management (q-fin.RM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.11239",
    "title": "LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and  Bootstrapped Self-training",
    "abstract": " Comments: Accepted to British Machine Vision Conference (BMVC) 2023 ",
    "url": "https://arxiv.org/abs/2308.11239",
    "authors": [
      "Silky Singh",
      "Shripad Deshmukh",
      "Mausoom Sarkar",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14015",
    "title": "Slimmed optical neural networks with multiplexed neuron sets and a  corresponding backpropagation training algorithm",
    "abstract": " Title: Slimmed optical neural networks with multiplexed neuron sets and a  corresponding backpropagation training algorithm ",
    "url": "https://arxiv.org/abs/2308.14015",
    "authors": [
      "Yi-Feng Liu",
      "Rui-Yao Ren",
      "Dai-Bao Hou",
      "Hai-Zhong Weng",
      "Bo-Wen Wang",
      "Ke-Jie Huang",
      "Xing Lin",
      "Feng Liu",
      "Chen-Hui Li",
      "Chao-Yuan Jin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2308.15984",
    "title": "Learning Structure-from-Motion with Graph Attention Networks",
    "abstract": " Comments: Added additional metrics ",
    "url": "https://arxiv.org/abs/2308.15984",
    "authors": [
      "Lucas Brynte",
      "Jos\u00e9 Pedro Iglesias",
      "Carl Olsson",
      "Fredrik Kahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.16458",
    "title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual  Pragmatic Knowledge",
    "abstract": " Title: BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual  Pragmatic Knowledge ",
    "url": "https://arxiv.org/abs/2308.16458",
    "authors": [
      "Xiangru Tang",
      "Bill Qian",
      "Rick Gao",
      "Jiakang Chen",
      "Xinyun Chen",
      "Mark Gerstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.02539",
    "title": "A Generalized Bandsplit Neural Network for Cinematic Audio Source  Separation",
    "abstract": " Comments: Accepted to the IEEE Open Journal of Signal Processing (ICASSP 2024 Track) ",
    "url": "https://arxiv.org/abs/2309.02539",
    "authors": [
      "Karn N. Watcharasupat",
      "Chih-Wei Wu",
      "Yiwei Ding",
      "Iroro Orife",
      "Aaron J. Hipple",
      "Phillip A. Williams",
      "Scott Kramer",
      "Alexander Lerch",
      "William Wolcott"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.04730",
    "title": "Integrated Robotics Networks with Co-optimization of Drone Placement and  Air-Ground Communications",
    "abstract": " Comments: Accepted by VTC2023-Fall, 5 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2309.04730",
    "authors": [
      "Menghao Hu",
      "Tong Zhang",
      "Shuai Wang",
      "Guoliang Li",
      "Yingyang Chen",
      "Qiang Li",
      "Gaojie Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.06647",
    "title": "Composing Control Barrier Functions for Complex Safety Specifications",
    "abstract": " Comments: Accepted to the IEEE Control System Letters (L-CSS) and the 2024 American Control Conference (ACC). 6 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2309.06647",
    "authors": [
      "Tamas G. Molnar",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2309.06838",
    "title": "Supervised Machine Learning and Physics based Machine Learning approach  for prediction of peak temperature distribution in Additive Friction Stir  Deposition of Aluminium Alloy",
    "abstract": " Title: Supervised Machine Learning and Physics based Machine Learning approach  for prediction of peak temperature distribution in Additive Friction Stir  Deposition of Aluminium Alloy ",
    "url": "https://arxiv.org/abs/2309.06838",
    "authors": [
      "Akshansh Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.08420",
    "title": "FedDCSR: Federated Cross-domain Sequential Recommendation via  Disentangled Representation Learning",
    "abstract": " Title: FedDCSR: Federated Cross-domain Sequential Recommendation via  Disentangled Representation Learning ",
    "url": "https://arxiv.org/abs/2309.08420",
    "authors": [
      "Hongyu Zhang",
      "Dongyi Zheng",
      "Xu Yang",
      "Jiyuan Feng",
      "Qing Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.11759",
    "title": "Symbol Detection for Coarsely Quantized OTFS",
    "abstract": " Comments: 5 pages ",
    "url": "https://arxiv.org/abs/2309.11759",
    "authors": [
      "Junwei He",
      "Haochuan Zhang",
      "Chao Dong",
      "Huimin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.13132",
    "title": "Understanding Calibration of Deep Neural Networks for Medical Image  Classification",
    "abstract": " Comments: Accepted in Computer Methods and Programs in Biomedicine Journal ",
    "url": "https://arxiv.org/abs/2309.13132",
    "authors": [
      "Abhishek Singh Sambyal",
      "Usma Niyaz",
      "Narayanan C. Krishnan",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15325",
    "title": "Neural Operators for Accelerating Scientific Simulations and Design",
    "abstract": " Title: Neural Operators for Accelerating Scientific Simulations and Design ",
    "url": "https://arxiv.org/abs/2309.15325",
    "authors": [
      "Kamyar Azizzadenesheli",
      "Nikola Kovachki",
      "Zongyi Li",
      "Miguel Liu-Schiaffini",
      "Jean Kossaifi",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2309.16583",
    "title": "GPT-Fathom: Benchmarking Large Language Models to Decipher the  Evolutionary Path towards GPT-4 and Beyond",
    "abstract": " Title: GPT-Fathom: Benchmarking Large Language Models to Decipher the  Evolutionary Path towards GPT-4 and Beyond ",
    "url": "https://arxiv.org/abs/2309.16583",
    "authors": [
      "Shen Zheng",
      "Yuyu Zhang",
      "Yijie Zhu",
      "Chenguang Xi",
      "Pengyang Gao",
      "Xun Zhou",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00052",
    "title": "AI ensemble for signal detection of higher order gravitational wave  modes of quasi-circular, spinning, non-precessing binary black hole mergers",
    "abstract": " Comments: 4 pages, 2 figures, 1 table; v2: 5 pages, 2 figures, 1 table, accepted to NeurIPS 2023 workshop on Machine Learning and the Physical Sciences ",
    "url": "https://arxiv.org/abs/2310.00052",
    "authors": [
      "Minyang Tian",
      "E. A. Huerta",
      "Huihuo Zheng"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2310.02048",
    "title": "Exploring Generalisability of Self-Distillation with No Labels for  SAR-Based Vegetation Prediction",
    "abstract": " Comments: 10 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2310.02048",
    "authors": [
      "Laura Mart\u00ednez-Ferrer",
      "Anna Jungbluth",
      "Joseph A. Gallego-Mejia",
      "Matt Allen",
      "Francisco Dorr",
      "Freddie Kalaitzis",
      "Ra\u00fal Ramos-Poll\u00e1n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10316",
    "title": "Spectral representation of two-sided signals from $\\ell_\\infty$ and  applications to signal processing",
    "abstract": " Title: Spectral representation of two-sided signals from $\\ell_\\infty$ and  applications to signal processing ",
    "url": "https://arxiv.org/abs/2310.10316",
    "authors": [
      "Nikolai Dokuchaev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2310.11730",
    "title": "Federated Heterogeneous Graph Neural Network for Privacy-preserving  Recommendation",
    "abstract": " Comments: some mistakes ",
    "url": "https://arxiv.org/abs/2310.11730",
    "authors": [
      "Bo Yan",
      "Yang Cao",
      "Haoyu Wang",
      "Wenchuan Yang",
      "Junping Du",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.11829",
    "title": "Towards Graph Foundation Models: A Survey and Beyond",
    "abstract": " Title: Towards Graph Foundation Models: A Survey and Beyond ",
    "url": "https://arxiv.org/abs/2310.11829",
    "authors": [
      "Jiawei Liu",
      "Cheng Yang",
      "Zhiyuan Lu",
      "Junze Chen",
      "Yibo Li",
      "Mengmei Zhang",
      "Ting Bai",
      "Yuan Fang",
      "Lichao Sun",
      "Philip S. Yu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15015",
    "title": "Leveraging Deep Learning for Abstractive Code Summarization of  Unofficial Documentation",
    "abstract": " Title: Leveraging Deep Learning for Abstractive Code Summarization of  Unofficial Documentation ",
    "url": "https://arxiv.org/abs/2310.15015",
    "authors": [
      "AmirHossein Naghshzan",
      "Latifa Guerrouj",
      "Olga Baysal"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15020",
    "title": "Invariance is Key to Generalization: Examining the Role of  Representation in Sim-to-Real Transfer for Visual Navigation",
    "abstract": " Comments: 11 pages, accepted by the 18th International Symposium on Experimental Robotics (ISER 2023) and published within the Springer Proceedings in Advanced Robotics (SPAR) ",
    "url": "https://arxiv.org/abs/2310.15020",
    "authors": [
      "Bo Ai",
      "Zhanxin Wu",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16267",
    "title": "Student Classroom Behavior Detection based on Spatio-Temporal Network  and Multi-Model Fusion",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2310.02522; text overlap with arXiv:2306.03318 ",
    "url": "https://arxiv.org/abs/2310.16267",
    "authors": [
      "Fan Yang",
      "Xiaofei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17378",
    "title": "Optimization dependent generalization bound for ReLU networks based on  sensitivity in the tangent bundle",
    "abstract": " Comments: 17 pages, 5 figures, OPT2023: 15th Annual Workshop on Optimization for Machine Learning at the 37th NeurIPS 2023, New Orleans, LA, USA ",
    "url": "https://arxiv.org/abs/2310.17378",
    "authors": [
      "D\u00e1niel R\u00e1cz",
      "Mih\u00e1ly Petreczky",
      "Andr\u00e1s Csert\u00e1n",
      "B\u00e1lint Dar\u00f3czy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17769",
    "title": "Social Contract AI: Aligning AI Assistants with Implicit Group Norms",
    "abstract": " Comments: SoLaR NeurIPS 2023 Workshop (this https URL) ",
    "url": "https://arxiv.org/abs/2310.17769",
    "authors": [
      "Jan-Philipp Fr\u00e4nken",
      "Sam Kwok",
      "Peixuan Ye",
      "Kanishk Gandhi",
      "Dilip Arumugam",
      "Jared Moore",
      "Alex Tamkin",
      "Tobias Gerstenberg",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18961",
    "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection",
    "abstract": " Title: AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2310.18961",
    "authors": [
      "Qihang Zhou",
      "Guansong Pang",
      "Yu Tian",
      "Shibo He",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.04625",
    "title": "A Comprehensive Summarization and Evaluation of Feature Refinement  Modules for CTR Prediction",
    "abstract": " Title: A Comprehensive Summarization and Evaluation of Feature Refinement  Modules for CTR Prediction ",
    "url": "https://arxiv.org/abs/2311.04625",
    "authors": [
      "Fangye Wang",
      "Hansu Gu",
      "Dongsheng Li",
      "Tun Lu",
      "Peng Zhang",
      "Li Shang",
      "Ning Gu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.05435",
    "title": "Parkinson's Disease Detection through Vocal Biomarkers and Advanced  Machine Learning Algorithms",
    "abstract": " Title: Parkinson's Disease Detection through Vocal Biomarkers and Advanced  Machine Learning Algorithms ",
    "url": "https://arxiv.org/abs/2311.05435",
    "authors": [
      "Md Abu Sayed",
      "Maliha Tayaba",
      "MD Tanvir Islam",
      "Md Eyasin Ul Islam Pavel",
      "Md Tuhin Mia",
      "Eftekhar Hossain Ayon",
      "Nur Nob",
      "Bishnu Padh Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.06650",
    "title": "Heuristic Optimal Transport in Branching Networks",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2311.06650",
    "authors": [
      "M. Andrecut"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.06851",
    "title": "Automatic Textual Normalization for Hate Speech Detection",
    "abstract": " Comments: Accepted to present at 2023 International Conference on Intelligent Systems Design and Applications (ISDA2023) ",
    "url": "https://arxiv.org/abs/2311.06851",
    "authors": [
      "Anh Thi-Hoang Nguyen",
      "Dung Ha Nguyen",
      "Nguyet Thi Nguyen",
      "Khanh Thanh-Duy Ho",
      "Kiet Van Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09018",
    "title": "On the Foundation of Distributionally Robust Reinforcement Learning",
    "abstract": " Title: On the Foundation of Distributionally Robust Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2311.09018",
    "authors": [
      "Shengbo Wang",
      "Nian Si",
      "Jose Blanchet",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.11824",
    "title": "Neural Graph Collaborative Filtering Using Variational Inference",
    "abstract": " Comments: Submitted for PAKDD2024 conference,12 pages ",
    "url": "https://arxiv.org/abs/2311.11824",
    "authors": [
      "Narges Sadat Fazeli Dehkordi",
      "Hadi Zare",
      "Parham Moradi",
      "Mahdi Jalili"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12275",
    "title": "Enabling On-Device Large Language Model Personalization with  Self-Supervised Data Selection and Synthesis",
    "abstract": " Comments: 6 pages, 3 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2311.12275",
    "authors": [
      "Ruiyang Qin",
      "Jun Xia",
      "Zhenge Jia",
      "Meng Jiang",
      "Ahmed Abbasi",
      "Peipei Zhou",
      "Jingtong Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.12589",
    "title": "Improving Source-Free Target Adaptation with Vision Transformers  Leveraging Domain Representation Images",
    "abstract": " Comments: Requesting withdrawal due to significant overlap with prior research that wasn't appropriately acknowledged in our manuscript. The decision is made to uphold academic integrity ",
    "url": "https://arxiv.org/abs/2311.12589",
    "authors": [
      "Gauransh Sawhney",
      "Daksh Dave",
      "Adeel Ahmed",
      "Jiechao Gao",
      "Khalid Saleem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.13162",
    "title": "Top-L Most Influential Community Detection Over Social Networks  (Technical Report)",
    "abstract": " Title: Top-L Most Influential Community Detection Over Social Networks  (Technical Report) ",
    "url": "https://arxiv.org/abs/2311.13162",
    "authors": [
      "Nan Zhang",
      "Yutong Ye",
      "Xiang Lian",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.14750",
    "title": "Attribute-Aware Representation Rectification for Generalized Zero-Shot  Learning",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2311.14750",
    "authors": [
      "Zhijie Rao",
      "Jingcai Guo",
      "Xiaocheng Lu",
      "Qihua Zhou",
      "Jie Zhang",
      "Kang Wei",
      "Chenxin Li",
      "Song Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.14836",
    "title": "Custom Data Augmentation for low resource ASR using Bark and  Retrieval-Based Voice Conversion",
    "abstract": " Title: Custom Data Augmentation for low resource ASR using Bark and  Retrieval-Based Voice Conversion ",
    "url": "https://arxiv.org/abs/2311.14836",
    "authors": [
      "Anand Kamble",
      "Aniket Tathe",
      "Suyash Kumbharkar",
      "Atharva Bhandare",
      "Anirban C. Mitra"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.15112",
    "title": "Everybody Needs a Little HELP: Explaining Graphs via Hierarchical  Concepts",
    "abstract": " Comments: 33 pages, 16 figures, accepted at the NeurIPS 2023 GLFrontiers Workshop ",
    "url": "https://arxiv.org/abs/2311.15112",
    "authors": [
      "Jonas J\u00fcr\u00df",
      "Lucie Charlotte Magister",
      "Pietro Barbiero",
      "Pietro Li\u00f2",
      "Nikola Simidjievski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16450",
    "title": "Typhoon Intensity Prediction with Vision Transformer",
    "abstract": " Comments: 8 pages, 2 figures, accepted by Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2311.16450",
    "authors": [
      "Huanxin Chen",
      "Pengshuai Yin",
      "Huichou Huang",
      "Qingyao Wu",
      "Ruirui Liu",
      "Xiatian Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17259",
    "title": "SoUnD Framework: Analyzing (So)cial Representation in (Un)structured  (D)ata",
    "abstract": " Title: SoUnD Framework: Analyzing (So)cial Representation in (Un)structured  (D)ata ",
    "url": "https://arxiv.org/abs/2311.17259",
    "authors": [
      "Mark D\u00edaz",
      "Sunipa Dev",
      "Emily Reif",
      "Emily Denton",
      "Vinodkumar Prabhakaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.17629",
    "title": "Efficient Decoder for End-to-End Oriented Object Detection in Remote  Sensing Images",
    "abstract": " Comments: 11 pages, 7 figures, 13 tables ",
    "url": "https://arxiv.org/abs/2311.17629",
    "authors": [
      "Jiaqi Zhao",
      "Zeyu Ding",
      "Yong Zhou",
      "Hancheng Zhu",
      "Wenliang Du",
      "Rui Yao",
      "Abdulmotaleb El Saddik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.18061",
    "title": "TransNAS-TSAD: Harnessing Transformers for Multi-Objective Neural  Architecture Search in Time Series Anomaly Detection",
    "abstract": " Comments: 32 pages , 4 figures, It will submitted to a journal ",
    "url": "https://arxiv.org/abs/2311.18061",
    "authors": [
      "Ijaz Ul Haq",
      "Byung Suk Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.18539",
    "title": "Bridging Both Worlds in Semantics and Time: Domain Knowledge Based  Analysis and Correlation of Industrial Process Attacks",
    "abstract": " Title: Bridging Both Worlds in Semantics and Time: Domain Knowledge Based  Analysis and Correlation of Industrial Process Attacks ",
    "url": "https://arxiv.org/abs/2311.18539",
    "authors": [
      "Moses Ike",
      "Kandy Phan",
      "Anwesh Badapanda",
      "Matthew Landen",
      "Keaton Sadoski",
      "Wanda Guo",
      "Asfahan Shah",
      "Saman Zonouz",
      "Wenke Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.18545",
    "title": "Decentralized Deepfake Detection Blockchain Network using Dynamic  Algorithm management",
    "abstract": " Title: Decentralized Deepfake Detection Blockchain Network using Dynamic  Algorithm management ",
    "url": "https://arxiv.org/abs/2311.18545",
    "authors": [
      "Dipankar Sarkar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00102",
    "title": "FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network  And Feature Embedding Aggregation",
    "abstract": " Comments: Accepted by Proceedings on Engineering Sciences ",
    "url": "https://arxiv.org/abs/2312.00102",
    "authors": [
      "Fanfei Meng",
      "Lele Zhang",
      "Yu Chen",
      "Yuxin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]