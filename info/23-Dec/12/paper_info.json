[
  {
    "id": "arXiv:2312.05276",
    "title": "Making Large Language Models Better Knowledge Miners for Online  Marketing with Progressive Prompting Augmentation",
    "abstract": "Nowadays, the rapid development of mobile economy has promoted the flourishing of online marketing campaigns, whose success greatly hinges on the efficient matching between user preferences and desired marketing campaigns where a well-established Marketing-oriented Knowledge Graph (dubbed as MoKG) could serve as the critical \"bridge\" for preference propagation. In this paper, we seek to carefully prompt a Large Language Model (LLM) with domain-level knowledge as a better marketing-oriented knowledge miner for marketing-oriented knowledge graph construction, which is however non-trivial, suffering from several inevitable issues in real-world marketing scenarios, i.e., uncontrollable relation generation of LLMs,insufficient prompting ability of a single prompt, the unaffordable deployment cost of LLMs. To this end, we propose PAIR, a novel Progressive prompting Augmented mIning fRamework for harvesting marketing-oriented knowledge graph with LLMs. In particular, we reduce the pure relation generation to an LLM based adaptive relation filtering process through the knowledge-empowered prompting technique. Next, we steer LLMs for entity expansion with progressive prompting augmentation,followed by a reliable aggregation with comprehensive consideration of both self-consistency and semantic relatedness. In terms of online serving, we specialize in a small and white-box PAIR (i.e.,LightPAIR),which is fine-tuned with a high-quality corpus provided by a strong teacher-LLM. Extensive experiments and practical applications in audience targeting verify the effectiveness of the proposed (Light)PAIR. ",
    "url": "https://arxiv.org/abs/2312.05276",
    "authors": [
      "Chunjing Gan",
      "Dan Yang",
      "Binbin Hu",
      "Ziqi Liu",
      "Yue Shen",
      "Zhiqiang Zhang",
      "Jinjie Gu",
      "Jun Zhou",
      "Guannan Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05277",
    "title": "3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D  Detection",
    "abstract": "A major challenge in monocular 3D object detection is the limited diversity and quantity of objects in real datasets. While augmenting real scenes with virtual objects holds promise to improve both the diversity and quantity of the objects, it remains elusive due to the lack of an effective 3D object insertion method in complex real captured scenes. In this work, we study augmenting complex real indoor scenes with virtual objects for monocular 3D object detection. The main challenge is to automatically identify plausible physical properties for virtual assets (e.g., locations, appearances, sizes, etc.) in cluttered real scenes. To address this challenge, we propose a physically plausible indoor 3D object insertion approach to automatically copy virtual objects and paste them into real scenes. The resulting objects in scenes have 3D bounding boxes with plausible physical locations and appearances. In particular, our method first identifies physically feasible locations and poses for the inserted objects to prevent collisions with the existing room layout. Subsequently, it estimates spatially-varying illumination for the insertion location, enabling the immersive blending of the virtual objects into the original scene with plausible appearances and cast shadows. We show that our augmentation method significantly improves existing monocular 3D object models and achieves state-of-the-art performance. For the first time, we demonstrate that a physically plausible 3D object insertion, serving as a generative data augmentation technique, can lead to significant improvements for discriminative downstream tasks such as monocular 3D object detection. Project website: https://gyhandy.github.io/3D-Copy-Paste/ ",
    "url": "https://arxiv.org/abs/2312.05277",
    "authors": [
      "Yunhao Ge",
      "Hong-Xing Yu",
      "Cheng Zhao",
      "Yuliang Guo",
      "Xinyu Huang",
      "Liu Ren",
      "Laurent Itti",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05283",
    "title": "Nuvo: Neural UV Mapping for Unruly 3D Representations",
    "abstract": "Existing UV mapping algorithms are designed to operate on well-behaved meshes, instead of the geometry representations produced by state-of-the-art 3D reconstruction and generation techniques. As such, applying these methods to the volume densities recovered by neural radiance fields and related techniques (or meshes triangulated from such fields) results in texture atlases that are too fragmented to be useful for tasks such as view synthesis or appearance editing. We present a UV mapping method designed to operate on geometry produced by 3D reconstruction and generation techniques. Instead of computing a mapping defined on a mesh's vertices, our method Nuvo uses a neural field to represent a continuous UV mapping, and optimizes it to be a valid and well-behaved mapping for just the set of visible points, i.e. only points that affect the scene's appearance. We show that our model is robust to the challenges posed by ill-behaved geometry, and that it produces editable UV mappings that can represent detailed appearance. ",
    "url": "https://arxiv.org/abs/2312.05283",
    "authors": [
      "Pratul P. Srinivasan",
      "Stephan J. Garbin",
      "Dor Verbin",
      "Jonathan T. Barron",
      "Ben Mildenhall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2312.05290",
    "title": "Noise Adaptor in Spiking Neural Networks",
    "abstract": "Recent strides in low-latency spiking neural network (SNN) algorithms have drawn significant interest, particularly due to their event-driven computing nature and fast inference capability. One of the most efficient ways to construct a low-latency SNN is by converting a pre-trained, low-bit artificial neural network (ANN) into an SNN. However, this conversion process faces two main challenges: First, converting SNNs from low-bit ANNs can lead to ``occasional noise\" -- the phenomenon where occasional spikes are generated in spiking neurons where they should not be -- during inference, which significantly lowers SNN accuracy. Second, although low-latency SNNs initially show fast improvements in accuracy with time steps, these accuracy growths soon plateau, resulting in their peak accuracy lagging behind both full-precision ANNs and traditional ``long-latency SNNs'' that prioritize precision over speed. In response to these two challenges, this paper introduces a novel technique named ``noise adaptor.'' Noise adaptor can model occasional noise during training and implicitly optimize SNN accuracy, particularly at high simulation times $T$. Our research utilizes the ResNet model for a comprehensive analysis of the impact of the noise adaptor on low-latency SNNs. The results demonstrate that our method outperforms the previously reported quant-ANN-to-SNN conversion technique. We achieved an accuracy of 95.95\\% within 4 time steps on CIFAR-10 using ResNet-18, and an accuracy of 74.37\\% within 64 time steps on ImageNet using ResNet-50. Remarkably, these results were obtained without resorting to any noise correction methods during SNN inference, such as negative spikes or two-stage SNN simulations. Our approach significantly boosts the peak accuracy of low-latency SNNs, bringing them on par with the accuracy of full-precision ANNs. Code will be open source. ",
    "url": "https://arxiv.org/abs/2312.05290",
    "authors": [
      "Chen Li",
      "Bipin Rajendran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05323",
    "title": "BaRiFlex: A Robotic Gripper with Versatility and Collision Robustness  for Robot Learning",
    "abstract": "We present a new approach to robot hand design specifically suited for successfully implementing robot learning methods to accomplish tasks in daily human environments. We introduce BaRiFlex, an innovative gripper design that alleviates the issues caused by unexpected contact and collisions during robot learning, offering robustness, grasping versatility, task versatility, and simplicity to the learning processes. This achievement is enabled by the incorporation of low-inertia actuators, providing high Back-drivability, and the strategic combination of Rigid and Flexible materials which enhances versatility and the gripper's resilience against unpredicted collisions. Furthermore, the integration of flexible Fin-Ray linkages and rigid linkages allows the gripper to execute compliant grasping and precise pinching. We conducted rigorous performance tests to characterize the novel gripper's compliance, durability, grasping and task versatility, and precision. We also integrated the BaRiFlex with a 7 Degree of Freedom (DoF) Franka Emika's Panda robotic arm to evaluate its capacity to support a trial-and-error (reinforcement learning) training procedure. The results of our experimental study are then compared to those obtained using the original rigid Franka Hand and a reference Fin-Ray soft gripper, demonstrating the superior capabilities and advantages of our developed gripper system. ",
    "url": "https://arxiv.org/abs/2312.05323",
    "authors": [
      "Gu-Cheol Jeong",
      "Arpit Bahety",
      "Gabriel Pedraza",
      "Ashish D. Deshpande",
      "Roberto Mart\u00edn-Mart\u00edn"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.05330",
    "title": "Multi-view Inversion for 3D-aware Generative Adversarial Networks",
    "abstract": "Current 3D GAN inversion methods for human heads typically use only one single frontal image to reconstruct the whole 3D head model. This leaves out meaningful information when multi-view data or dynamic videos are available. Our method builds on existing state-of-the-art 3D GAN inversion techniques to allow for consistent and simultaneous inversion of multiple views of the same subject. We employ a multi-latent extension to handle inconsistencies present in dynamic face videos to re-synthesize consistent 3D representations from the sequence. As our method uses additional information about the target subject, we observe significant enhancements in both geometric accuracy and image quality, particularly when rendering from wide viewing angles. Moreover, we demonstrate the editability of our inverted 3D renderings, which distinguishes them from NeRF-based scene reconstructions. ",
    "url": "https://arxiv.org/abs/2312.05330",
    "authors": [
      "Florian Barthel",
      "Anna Hilsmann",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05337",
    "title": "Artificial Neural Nets and the Representation of Human Concepts",
    "abstract": "What do artificial neural networks (ANNs) learn? The machine learning (ML) community shares the narrative that ANNs must develop abstract human concepts to perform complex tasks. Some go even further and believe that these concepts are stored in individual units of the network. Based on current research, I systematically investigate the assumptions underlying this narrative. I conclude that ANNs are indeed capable of performing complex prediction tasks, and that they may learn human and non-human concepts to do so. However, evidence indicates that ANNs do not represent these concepts in individual units. ",
    "url": "https://arxiv.org/abs/2312.05337",
    "authors": [
      "Timo Freiesleben"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05348",
    "title": "High-Quality Live Video Streaming via Transcoding Time Prediction and  Preset Selection",
    "abstract": "Video streaming often requires transcoding content into different resolutions and bitrates to match the recipient's internet speed and screen capabilities. Video encoders like x264 offer various presets, each with different tradeoffs between transcoding time and rate-distortion performance. Choosing the best preset for video transcoding is difficult, especially for live streaming, as trying all the presets and choosing the best one is not feasible. One solution is to predict each preset's transcoding time and select the preset that ensures the highest quality while adhering to live streaming time constraints. Prediction of video transcoding time is also critical in minimizing streaming delays, deploying resource management algorithms, and load balancing. We propose a learning-based framework for predicting the transcoding time of videos across various presets. Our predictor's features for video transcoding time prediction are derived directly from the ingested stream, primarily from the header or metadata. As a result, only minimal additional delay is incurred for feature extraction, rendering our approach ideal for live-streaming applications. We evaluated our learning-based transcoding time prediction using a dataset of videos. The results demonstrate that our framework can accurately predict the transcoding time for different presets, with a mean absolute percentage error (MAPE) of nearly 5.0%. Leveraging these predictions, we then select the most suitable transcoding preset for live video streaming. Utilizing our transcoding time prediction-based preset selection improved Peak Signal-to-Noise Ratio (PSNR) of up to 5 dB. ",
    "url": "https://arxiv.org/abs/2312.05348",
    "authors": [
      "Zahra Nabizadeh Shahre-Babak",
      "Nader Karimi",
      "Krishna Rapaka",
      "Tarek Amara",
      "Shadrokh Samavi",
      "Shahram Shirani"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05356",
    "title": "Neuron Patching: Neuron-level Model Editing on Code Generation and LLMs",
    "abstract": "Large Language Models are successfully adopted in software engineering, especially in code generation. Updating these models with new knowledge is very expensive, and is often required to fully realize their value. In this paper, we propose a novel and effective model editing approach, \\textsc{MENT}, to patch LLMs in coding tasks. Based on the mechanism of generative LLMs, \\textsc{MENT} enables model editing in next-token predictions, and further supports common coding tasks. \\textsc{MENT} is effective, efficient, and reliable. It can correct a neural model by patching 1 or 2 neurons. As the pioneer work on neuron-level model editing of generative models, we formalize the editing process and introduce the involved concepts. Besides, we also introduce new measures to evaluate its generalization ability, and build a benchmark for further study. Our approach is evaluated on three coding tasks, including API-seq recommendation, line-level code generation, and pseudocode-to-code transaction. It outperforms the state-of-the-art by a significant margin on both effectiveness and efficiency measures. In addition, we demonstrate the usages of \\textsc{MENT} for LLM reasoning in software engineering. By editing the LLM knowledge with \\textsc{MENT}, the directly or indirectly dependent behaviors in the chain-of-thought change accordingly and automatically. ",
    "url": "https://arxiv.org/abs/2312.05356",
    "authors": [
      "Jian Gu",
      "Chunyang Chen",
      "Aldeida Aleti"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05361",
    "title": "Emergence and Function of Abstract Representations in Self-Supervised  Transformers",
    "abstract": "Human intelligence relies in part on our brains' ability to create abstract mental models that succinctly capture the hidden blueprint of our reality. Such abstract world models notably allow us to rapidly navigate novel situations by generalizing prior knowledge, a trait deep learning systems have historically struggled to replicate. However, the recent shift from supervised to self-supervised objectives, combined with expressive transformer-based architectures, have yielded powerful foundation models that appear to learn versatile representations that can support a wide range of downstream tasks. This promising development raises the intriguing possibility of such models developing in silico abstract world models. We test this hypothesis by studying the inner workings of small-scale transformers trained to reconstruct partially masked visual scenes generated from a simple blueprint. We show that the network develops intermediate abstract representations, or abstractions, that encode all semantic features of the dataset. These abstractions manifest as low-dimensional manifolds where the embeddings of semantically related tokens transiently converge, thus allowing for the generalization of downstream computations. Using precise manipulation experiments, we demonstrate that abstractions are central to the network's decision-making process. Our research also suggests that these abstractions are compositionally structured, exhibiting features like contextual independence and part-whole relationships that mirror the compositional nature of the dataset. Finally, we introduce a Language-Enhanced Architecture (LEA) designed to encourage the network to articulate its computations. We find that LEA develops an abstraction-centric language that can be easily interpreted, allowing us to more readily access and steer the network's decision-making process. ",
    "url": "https://arxiv.org/abs/2312.05361",
    "authors": [
      "Quentin RV. Ferry",
      "Joshua Ching",
      "Takashi Kawai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05386",
    "title": "Model Extraction Attacks Revisited",
    "abstract": "Model extraction (ME) attacks represent one major threat to Machine-Learning-as-a-Service (MLaaS) platforms by ``stealing'' the functionality of confidential machine-learning models through querying black-box APIs. Over seven years have passed since ME attacks were first conceptualized in the seminal work. During this period, substantial advances have been made in both ME attacks and MLaaS platforms, raising the intriguing question: How has the vulnerability of MLaaS platforms to ME attacks been evolving? In this work, we conduct an in-depth study to answer this critical question. Specifically, we characterize the vulnerability of current, mainstream MLaaS platforms to ME attacks from multiple perspectives including attack strategies, learning techniques, surrogate-model design, and benchmark tasks. Many of our findings challenge previously reported results, suggesting emerging patterns of ME vulnerability. Further, by analyzing the vulnerability of the same MLaaS platforms using historical datasets from the past four years, we retrospectively characterize the evolution of ME vulnerability over time, leading to a set of interesting findings. Finally, we make suggestions about improving the current practice of MLaaS in terms of attack robustness. Our study sheds light on the current state of ME vulnerability in the wild and points to several promising directions for future research. ",
    "url": "https://arxiv.org/abs/2312.05386",
    "authors": [
      "Jiacheng Liang",
      "Ren Pang",
      "Changjiang Li",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.05397",
    "title": "On the Performance of Temporal Difference Learning With Neural Networks",
    "abstract": "Neural Temporal Difference (TD) Learning is an approximate temporal difference method for policy evaluation that uses a neural network for function approximation. Analysis of Neural TD Learning has proven to be challenging. In this paper we provide a convergence analysis of Neural TD Learning with a projection onto $B(\\theta_0, \\omega)$, a ball of fixed radius $\\omega$ around the initial point $\\theta_0$. We show an approximation bound of $O(\\epsilon) + \\tilde{O} (1/\\sqrt{m})$ where $\\epsilon$ is the approximation quality of the best neural network in $B(\\theta_0, \\omega)$ and $m$ is the width of all hidden layers in the network. ",
    "url": "https://arxiv.org/abs/2312.05397",
    "authors": [
      "Haoxing Tian",
      "Ioannis Ch. Paschalidis",
      "Alex Olshevsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05398",
    "title": "Generative Network Layer for Communication Systems with Artificial  Intelligence",
    "abstract": "The traditional role of the network layer is the transfer of packet replicas from source to destination through intermediate network nodes. We present a generative network layer that uses Generative AI (GenAI) at intermediate or edge network nodes and analyze its impact on the required data rates in the network. We conduct a case study where the GenAI-aided nodes generate images from prompts that consist of substantially compressed latent representations. The results from network flow analyses under image quality constraints show that the generative network layer can achieve an improvement of more than 100% in terms of the required data rate. ",
    "url": "https://arxiv.org/abs/2312.05398",
    "authors": [
      "Mathias Thorsager",
      "Israel Leyva-Mayorga",
      "Beatriz Soret",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05404",
    "title": "Disentangled Latent Representation Learning for Tackling the Confounding  M-Bias Problem in Causal Inference",
    "abstract": "In causal inference, it is a fundamental task to estimate the causal effect from observational data. However, latent confounders pose major challenges in causal inference in observational data, for example, confounding bias and M-bias. Recent data-driven causal effect estimators tackle the confounding bias problem via balanced representation learning, but assume no M-bias in the system, thus they fail to handle the M-bias. In this paper, we identify a challenging and unsolved problem caused by a variable that leads to confounding bias and M-bias simultaneously. To address this problem with co-occurring M-bias and confounding bias, we propose a novel Disentangled Latent Representation learning framework for learning latent representations from proxy variables for unbiased Causal effect Estimation (DLRCE) from observational data. Specifically, DLRCE learns three sets of latent representations from the measured proxy variables to adjust for the confounding bias and M-bias. Extensive experiments on both synthetic and three real-world datasets demonstrate that DLRCE significantly outperforms the state-of-the-art estimators in the case of the presence of both confounding bias and M-bias. ",
    "url": "https://arxiv.org/abs/2312.05404",
    "authors": [
      "Debo Cheng",
      "Yang Xie",
      "Ziqi Xu",
      "Jiuyong Li",
      "Lin Liu",
      "Jixue Liu",
      "Yinghao Zhang",
      "Zaiwen Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.05410",
    "title": "Rethinking materials simulations: Blending direct numerical simulations  with neural operators",
    "abstract": "Direct numerical simulations (DNS) are accurate but computationally expensive for predicting materials evolution across timescales, due to the complexity of the underlying evolution equations, the nature of multiscale spatio-temporal interactions, and the need to reach long-time integration. We develop a new method that blends numerical solvers with neural operators to accelerate such simulations. This methodology is based on the integration of a community numerical solver with a U-Net neural operator, enhanced by a temporal-conditioning mechanism that enables accurate extrapolation and efficient time-to-solution predictions of the dynamics. We demonstrate the effectiveness of this framework on simulations of microstructure evolution during physical vapor deposition modeled via the phase-field method. Such simulations exhibit high spatial gradients due to the co-evolution of different material phases with simultaneous slow and fast materials dynamics. We establish accurate extrapolation of the coupled solver with up to 16.5$\\times$ speed-up compared to DNS. This methodology is generalizable to a broad range of evolutionary models, from solid mechanics, to fluid dynamics, geophysics, climate, and more. ",
    "url": "https://arxiv.org/abs/2312.05410",
    "authors": [
      "Vivek Oommen",
      "Khemraj Shukla",
      "Saaketh Desai",
      "Remi Dingreville",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2312.05432",
    "title": "Fusing Multiple Algorithms for Heterogeneous Online Learning",
    "abstract": "This study addresses the challenge of online learning in contexts where agents accumulate disparate data, face resource constraints, and use different local algorithms. This paper introduces the Switched Online Learning Algorithm (SOLA), designed to solve the heterogeneous online learning problem by amalgamating updates from diverse agents through a dynamic switching mechanism contingent upon their respective performance and available resources. We theoretically analyze the design of the selecting mechanism to ensure that the regret of SOLA is bounded. Our findings show that the number of changes in selection needs to be bounded by a parameter dependent on the performance of the different local algorithms. Additionally, two test cases are presented to emphasize the effectiveness of SOLA, first on an online linear regression problem and then on an online classification problem with the MNIST dataset. ",
    "url": "https://arxiv.org/abs/2312.05432",
    "authors": [
      "Darshan Gadginmath",
      "Shivanshu Tripathi",
      "Fabio Pasqualetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2312.05435",
    "title": "Enhancing Robustness of Foundation Model Representations under  Provenance-related Distribution Shifts",
    "abstract": "Foundation models are a current focus of attention in both industry and academia. While they have shown their capabilities in a variety of tasks, in-depth research is required to determine their robustness to distribution shift when used as a basis for supervised machine learning. This is especially important in the context of clinical data, with particular limitations related to data accessibility, lack of pretraining materials, and limited availability of high-quality annotations. In this work, we examine the stability of models based on representations from foundation models under distribution shift. We focus on confounding by provenance, a form of distribution shift that emerges in the context of multi-institutional datasets when there are differences in source-specific language use and class distributions. Using a sampling strategy that synthetically induces varying degrees of distribution shift, we evaluate the extent to which representations from foundation models result in predictions that are inherently robust to confounding by provenance. Additionally, we examine the effectiveness of a straightforward confounding adjustment method inspired by Pearl's conception of backdoor adjustment. Results indicate that while foundation models do show some out-of-the-box robustness to confounding-by-provenance related distribution shifts, this can be considerably improved through adjustment. These findings suggest a need for deliberate adjustment of predictive models using representations from foundation models in the context of source-specific distributional differences. ",
    "url": "https://arxiv.org/abs/2312.05435",
    "authors": [
      "Xiruo Ding",
      "Zhecheng Sheng",
      "Brian Hur",
      "Feng Chen",
      "Serguei V. S. Pakhomov",
      "Trevor Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.05461",
    "title": "STREAMLINE: An Automated Machine Learning Pipeline for Biomedicine  Applied to Examine the Utility of Photography-Based Phenotypes for OSA  Prediction Across International Sleep Centers",
    "abstract": "While machine learning (ML) includes a valuable array of tools for analyzing biomedical data, significant time and expertise is required to assemble effective, rigorous, and unbiased pipelines. Automated ML (AutoML) tools seek to facilitate ML application by automating a subset of analysis pipeline elements. In this study we develop and validate a Simple, Transparent, End-to-end Automated Machine Learning Pipeline (STREAMLINE) and apply it to investigate the added utility of photography-based phenotypes for predicting obstructive sleep apnea (OSA); a common and underdiagnosed condition associated with a variety of health, economic, and safety consequences. STREAMLINE is designed to tackle biomedical binary classification tasks while adhering to best practices and accommodating complexity, scalability, reproducibility, customization, and model interpretation. Benchmarking analyses validated the efficacy of STREAMLINE across data simulations with increasingly complex patterns of association. Then we applied STREAMLINE to evaluate the utility of demographics (DEM), self-reported comorbidities (DX), symptoms (SYM), and photography-based craniofacial (CF) and intraoral (IO) anatomy measures in predicting any OSA or moderate/severe OSA using 3,111 participants from Sleep Apnea Global Interdisciplinary Consortium (SAGIC). OSA analyses identified a significant increase in ROC-AUC when adding CF to DEM+DX+SYM to predict moderate/severe OSA. A consistent but non-significant increase in PRC-AUC was observed with the addition of each subsequent feature set to predict any OSA, with CF and IO yielding minimal improvements. Application of STREAMLINE to OSA data suggests that CF features provide additional value in predicting moderate/severe OSA, but neither CF nor IO features meaningfully improved the prediction of any OSA beyond established demographics, comorbidity and symptom characteristics. ",
    "url": "https://arxiv.org/abs/2312.05461",
    "authors": [
      "Ryan J. Urbanowicz",
      "Harsh Bandhey",
      "Brendan T. Keenan",
      "Greg Maislin",
      "Sy Hwang",
      "Danielle L. Mowery",
      "Shannon M. Lynch",
      "Diego R. Mazzotti",
      "Fang Han",
      "Qing Yun Li",
      "Thomas Penzel",
      "Sergio Tufik",
      "Lia Bittencourt",
      "Thorarinn Gislason",
      "Philip de Chazal",
      "Bhajan Singh",
      "Nigel McArdle",
      "Ning-Hung Chen",
      "Allan Pack",
      "Richard J. Schwab",
      "Peter A. Cistulli",
      "Ulysses J. Magalang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05462",
    "title": "HumanReg: Self-supervised Non-rigid Registration of Human Point Cloud",
    "abstract": "In this paper, we present a novel registration framework, HumanReg, that learns a non-rigid transformation between two human point clouds end-to-end. We introduce body prior into the registration process to efficiently handle this type of point cloud. Unlike most exsisting supervised registration techniques that require expensive point-wise flow annotations, HumanReg can be trained in a self-supervised manner benefiting from a set of novel loss functions. To make our model better converge on real-world data, we also propose a pretraining strategy, and a synthetic dataset (HumanSyn4D) consists of dynamic, sparse human point clouds and their auto-generated ground truth annotations. Our experiments shows that HumanReg achieves state-of-the-art performance on CAPE-512 dataset and gains a qualitative result on another more challenging real-world dataset. Furthermore, our ablation studies demonstrate the effectiveness of our synthetic dataset and novel loss functions. Our code and synthetic dataset is available at https://github.com/chenyifanthu/HumanReg. ",
    "url": "https://arxiv.org/abs/2312.05462",
    "authors": [
      "Yifan Chen",
      "Zhiyu Pan",
      "Zhicheng Zhong",
      "Wenxuan Guo",
      "Jianjiang Feng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05467",
    "title": "Textual Toxicity in Social Media: Understanding the Bangla Toxic  Language Expressed in Facebook Comment",
    "abstract": "Social Media is a repository of digital literature including user-generated content. The users of social media are expressing their opinion with diverse mediums such as text, emojis, memes, and also through other visual and textual mediums. A major portion of these media elements could be treated as harmful to others and they are known by many words including Cyberbullying and Toxic Language . The goal of this research paper is to analyze a curated and value-added dataset of toxic language titled ToxLex_bn . It is an exhaustive wordlist that can be used as classifier material to detect toxicity in social media. The toxic language/script used by the Bengali community as cyberbullying, hate speech and moral policing became major trends in social media culture in Bangladesh and West Bengal. The toxicity became so high that the victims has to post as a counter or release explanation video for the haters. Most cases are pointed to women celebrity and their relation, dress, lifestyle are became trolled and toxicity flooded in comments boxes. Not only celebrity bashing but also hates occurred between Hindu Muslims, India-Bangladesh, Two opponents of 1971 and these are very common for virtual conflict in the comment thread. Even many times facebook comment causes sue and legal matters in Bangladesh and thus it requires more study. In this study, a Bangla toxic language dataset has been analyzed which was inputted by the user in Bengali script & language. For this, about 1968 unique bigrams or phrases as wordlists have been analyzed which are derived from 2207590 comments. It is assumed that this analysis will reinforce the detection of Bangla's toxic language used in social media and thus cure this virtual disease. ",
    "url": "https://arxiv.org/abs/2312.05467",
    "authors": [
      "Mohammad Mamun Or Rashid"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.05468",
    "title": "Image and Data Mining in Reticular Chemistry Using GPT-4V",
    "abstract": "The integration of artificial intelligence into scientific research has reached a new pinnacle with GPT-4V, a large language model featuring enhanced vision capabilities, accessible through ChatGPT or an API. This study demonstrates the remarkable ability of GPT-4V to navigate and obtain complex data for metal-organic frameworks, especially from graphical sources. Our approach involved an automated process of converting 346 scholarly articles into 6240 images, which represents a benchmark dataset in this task, followed by deploying GPT-4V to categorize and analyze these images using natural language prompts. This methodology enabled GPT-4V to accurately identify and interpret key plots integral to MOF characterization, such as nitrogen isotherms, PXRD patterns, and TGA curves, among others, with accuracy and recall above 93%. The model's proficiency in extracting critical information from these plots not only underscores its capability in data mining but also highlights its potential in aiding the creation of comprehensive digital databases for reticular chemistry. In addition, the extracted nitrogen isotherm data from the selected literature allowed for a comparison between theoretical and experimental porosity values for over 200 compounds, highlighting certain discrepancies and underscoring the importance of integrating computational and experimental data. This work highlights the potential of AI in accelerating scientific discovery and innovation, bridging the gap between computational tools and experimental research, and paving the way for more efficient, inclusive, and comprehensive scientific inquiry. ",
    "url": "https://arxiv.org/abs/2312.05468",
    "authors": [
      "Zhiling Zheng",
      "Zhiguo He",
      "Omar Khattab",
      "Nakul Rampal",
      "Matei A. Zaharia",
      "Christian Borgs",
      "Jennifer T. Chayes",
      "Omar M. Yaghi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.05473",
    "title": "Self Model for Embodied Intelligence: Modeling Full-Body Human  Musculoskeletal System and Locomotion Control with Hierarchical  Low-Dimensional Representation",
    "abstract": "Modeling and control of the human musculoskeletal system is important for understanding human motion, developing embodied intelligence, and optimizing human-robot interaction systems. However, current open-source models are restricted to a limited range of body parts and often with a reduced number of muscles. There is also a lack of algorithms capable of controlling over 600 muscles to generate reasonable human movements. To fill this gap, we build a comprehensive musculoskeletal model with 90 body segments, 206 joints, and 700 muscle-tendon units, allowing simulation of full-body dynamics and interaction with various devices. We develop a new algorithm using low-dimensional representation and hierarchical deep reinforcement learning to achieve state-of-the-art full-body control. We validate the effectiveness of our model and algorithm in simulations and on real human locomotion data. The musculoskeletal model, along with its control algorithm, will be made available to the research community to promote a deeper understanding of human motion control and better design of interactive robots. ",
    "url": "https://arxiv.org/abs/2312.05473",
    "authors": [
      "Kaibo He",
      "Chenhui Zuo",
      "Jing Shao",
      "Yanan Sui"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05479",
    "title": "Exploring Sparsity in Graph Transformers",
    "abstract": "Graph Transformers (GTs) have achieved impressive results on various graph-related tasks. However, the huge computational cost of GTs hinders their deployment and application, especially in resource-constrained environments. Therefore, in this paper, we explore the feasibility of sparsifying GTs, a significant yet under-explored topic. We first discuss the redundancy of GTs based on the characteristics of existing GT models, and then propose a comprehensive \\textbf{G}raph \\textbf{T}ransformer \\textbf{SP}arsification (GTSP) framework that helps to reduce the computational complexity of GTs from four dimensions: the input graph data, attention heads, model layers, and model weights. Specifically, GTSP designs differentiable masks for each individual compressible component, enabling effective end-to-end pruning. We examine our GTSP through extensive experiments on prominent GTs, including GraphTrans, Graphormer, and GraphGPS. The experimental results substantiate that GTSP effectively cuts computational costs, accompanied by only marginal decreases in accuracy or, in some cases, even improvements. For instance, GTSP yields a reduction of 30\\% in Floating Point Operations while contributing to a 1.8\\% increase in Area Under the Curve accuracy on OGBG-HIV dataset. Furthermore, we provide several insights on the characteristics of attention heads and the behavior of attention mechanisms, all of which have immense potential to inspire future research endeavors in this domain. ",
    "url": "https://arxiv.org/abs/2312.05479",
    "authors": [
      "Chuang Liu",
      "Yibing Zhan",
      "Xueqi Ma",
      "Liang Ding",
      "Dapeng Tao",
      "Jia Wu",
      "Wenbin Hu",
      "Bo Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05490",
    "title": "Shapley Values-enabled Progressive Pseudo Bag Augmentation for Whole  Slide Image Classification",
    "abstract": "In computational pathology, whole slide image (WSI) classification presents a formidable challenge due to its gigapixel resolution and limited fine-grained annotations. Multiple instance learning (MIL) offers a weakly supervised solution, yet refining instance-level information from bag-level labels remains complex. While most of the conventional MIL methods use attention scores to estimate instance importance scores (IIS) which contribute to the prediction of the slide labels, these often lead to skewed attention distributions and inaccuracies in identifying crucial instances. To address these issues, we propose a new approach inspired by cooperative game theory: employing Shapley values to assess each instance's contribution, thereby improving IIS estimation. The computation of the Shapley value is then accelerated using attention, meanwhile retaining the enhanced instance identification and prioritization. We further introduce a framework for the progressive assignment of pseudo bags based on estimated IIS, encouraging more balanced attention distributions in MIL models. Our extensive experiments on CAMELYON-16, BRACS, and TCGA-LUNG datasets show our method's superiority over existing state-of-the-art approaches, offering enhanced interpretability and class-wise insights. We will release the code upon acceptance. ",
    "url": "https://arxiv.org/abs/2312.05490",
    "authors": [
      "Renao Yan",
      "Qiehe Sun",
      "Cheng Jin",
      "Yiqing Liu",
      "Yonghong He",
      "Tian Guan",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05502",
    "title": "Poisoning $\\times$ Evasion: Symbiotic Adversarial Robustness for Graph  Neural Networks",
    "abstract": "It is well-known that deep learning models are vulnerable to small input perturbations. Such perturbed instances are called adversarial examples. Adversarial examples are commonly crafted to fool a model either at training time (poisoning) or test time (evasion). In this work, we study the symbiosis of poisoning and evasion. We show that combining both threat models can substantially improve the devastating efficacy of adversarial attacks. Specifically, we study the robustness of Graph Neural Networks (GNNs) under structure perturbations and devise a memory-efficient adaptive end-to-end attack for the novel threat model using first-order optimization. ",
    "url": "https://arxiv.org/abs/2312.05502",
    "authors": [
      "Ege Erdogan",
      "Simon Geisler",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05508",
    "title": "Improving Adversarial Robust Fairness via Anti-Bias Soft Label  Distillation",
    "abstract": "Adversarial Training (AT) has been widely proved to be an effective method to improve the adversarial robustness against adversarial examples for Deep Neural Networks (DNNs). As a variant of AT, Adversarial Robustness Distillation (ARD) has demonstrated its superior performance in improving the robustness of small student models with the guidance of large teacher models. However, both AT and ARD encounter the robust fairness problem: these models exhibit strong robustness when facing part of classes (easy class), but weak robustness when facing others (hard class). In this paper, we give an in-depth analysis of the potential factors and argue that the smoothness degree of samples' soft labels for different classes (i.e., hard class or easy class) will affect the robust fairness of DNN models from both empirical observation and theoretical analysis. Based on the above finding, we propose an Anti-Bias Soft Label Distillation (ABSLD) method to mitigate the adversarial robust fairness problem within the framework of Knowledge Distillation (KD). Specifically, ABSLD adaptively reduces the student's error risk gap between different classes to achieve fairness by adjusting the class-wise smoothness degree of samples' soft labels during the training process, and the smoothness degree of soft labels is controlled by assigning different temperatures in KD to different classes. Extensive experiments demonstrate that ABSLD outperforms state-of-the-art AT, ARD, and robust fairness methods in terms of overall performance of robustness and fairness. ",
    "url": "https://arxiv.org/abs/2312.05508",
    "authors": [
      "Shiji Zhao",
      "Xizhe Wang",
      "Xingxing Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.05519",
    "title": "Isomorphic-Consistent Variational Graph Auto-Encoders for Multi-Level  Graph Representation Learning",
    "abstract": "Graph representation learning is a fundamental research theme and can be generalized to benefit multiple downstream tasks from the node and link levels to the higher graph level. In practice, it is desirable to develop task-agnostic general graph representation learning methods that are typically trained in an unsupervised manner. Related research reveals that the power of graph representation learning methods depends on whether they can differentiate distinct graph structures as different embeddings and map isomorphic graphs to consistent embeddings (i.e., the isomorphic consistency of graph models). However, for task-agnostic general graph representation learning, existing unsupervised graph models, represented by the variational graph auto-encoders (VGAEs), can only keep the isomorphic consistency within the subgraphs of 1-hop neighborhoods and thus usually manifest inferior performance on the more difficult higher-level tasks. To overcome the limitations of existing unsupervised methods, in this paper, we propose the Isomorphic-Consistent VGAE (IsoC-VGAE) for multi-level task-agnostic graph representation learning. We first devise a decoding scheme to provide a theoretical guarantee of keeping the isomorphic consistency under the settings of unsupervised learning. We then propose the Inverse Graph Neural Network (Inv-GNN) decoder as its intuitive realization, which trains the model via reconstructing the GNN node embeddings with multi-hop neighborhood information, so as to maintain the high-order isomorphic consistency within the VGAE framework. We conduct extensive experiments on the representative graph learning tasks at different levels, including node classification, link prediction and graph classification, and the results verify that our proposed model generally outperforms both the state-of-the-art unsupervised methods and representative supervised methods. ",
    "url": "https://arxiv.org/abs/2312.05519",
    "authors": [
      "Hanxuan Yang",
      "Qingchao Kong",
      "Wenji Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05520",
    "title": "Augmenty: A Python Library for Structured Text Augmentation",
    "abstract": "Augmnety is a Python library for structured text augmentation. It is built on top of spaCy and allows for augmentation of both the text and its annotations. Augmenty provides a wide range of augmenters which can be combined in a flexible manner to create complex augmentation pipelines. It also includes a set of primitives that can be used to create custom augmenters such as word replacement augmenters. This functionality allows for augmentations within a range of applications such as named entity recognition (NER), part-of-speech tagging, and dependency parsing. ",
    "url": "https://arxiv.org/abs/2312.05520",
    "authors": [
      "Kenneth Enevoldsen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.05526",
    "title": "Reinforcement Neighborhood Selection for Unsupervised Graph Anomaly  Detection",
    "abstract": "Unsupervised graph anomaly detection is crucial for various practical applications as it aims to identify anomalies in a graph that exhibit rare patterns deviating significantly from the majority of nodes. Recent advancements have utilized Graph Neural Networks (GNNs) to learn high-quality node representations for anomaly detection by aggregating information from neighborhoods. However, the presence of anomalies may render the observed neighborhood unreliable and result in misleading information aggregation for node representation learning. Selecting the proper neighborhood is critical for graph anomaly detection but also challenging due to the absence of anomaly-oriented guidance and the interdependence with representation learning. To address these issues, we utilize the advantages of reinforcement learning in adaptively learning in complex environments and propose a novel method that incorporates Reinforcement neighborhood selection for unsupervised graph ANomaly Detection (RAND). RAND begins by enriching the candidate neighbor pool of the given central node with multiple types of indirect neighbors. Next, RAND designs a tailored reinforcement anomaly evaluation module to assess the reliability and reward of considering the given neighbor. Finally, RAND selects the most reliable subset of neighbors based on these rewards and introduces an anomaly-aware aggregator to amplify messages from reliable neighbors while diminishing messages from unreliable ones. Extensive experiments on both three synthetic and two real-world datasets demonstrate that RAND outperforms the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2312.05526",
    "authors": [
      "Yuanchen Bei",
      "Sheng Zhou",
      "Qiaoyu Tan",
      "Hao Xu",
      "Hao Chen",
      "Zhao Li",
      "Jiajun Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05540",
    "title": "Federated Causality Learning with Explainable Adaptive Optimization",
    "abstract": "Discovering the causality from observational data is a crucial task in various scientific domains. With increasing awareness of privacy, data are not allowed to be exposed, and it is very hard to learn causal graphs from dispersed data, since these data may have different distributions. In this paper, we propose a federated causal discovery strategy (FedCausal) to learn the unified global causal graph from decentralized heterogeneous data. We design a global optimization formula to naturally aggregate the causal graphs from client data and constrain the acyclicity of the global graph without exposing local data. Unlike other federated causal learning algorithms, FedCausal unifies the local and global optimizations into a complete directed acyclic graph (DAG) learning process with a flexible optimization objective. We prove that this optimization objective has a high interpretability and can adaptively handle homogeneous and heterogeneous data. Experimental results on synthetic and real datasets show that FedCausal can effectively deal with non-independently and identically distributed (non-iid) data and has a superior performance. ",
    "url": "https://arxiv.org/abs/2312.05540",
    "authors": [
      "Dezhi Yang",
      "Xintong He",
      "Jun Wang",
      "Guoxian Yu",
      "Carlotta Domeniconi",
      "Jinglin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05541",
    "title": "DPoser: Diffusion Model as Robust 3D Human Pose Prior",
    "abstract": "Modeling human pose is a cornerstone in applications from human-robot interaction to augmented reality, yet crafting a robust human pose prior remains a challenge due to biomechanical constraints and diverse human movements. Traditional priors like VAEs and NDFs often fall short in realism and generalization, especially in extreme conditions such as unseen noisy poses. To address these issues, we introduce DPoser, a robust and versatile human pose prior built upon diffusion models. Designed with optimization frameworks, DPoser seamlessly integrates into various pose-centric applications, including human mesh recovery, pose completion, and motion denoising. Specifically, by formulating these tasks as inverse problems, we employ variational diffusion sampling for efficient solving. Furthermore, acknowledging the disparity between the articulated poses we focus on and structured images in previous research, we propose a truncated timestep scheduling to boost performance on downstream tasks. Our exhaustive experiments demonstrate DPoser's superiority over existing state-of-the-art pose priors across multiple tasks. ",
    "url": "https://arxiv.org/abs/2312.05541",
    "authors": [
      "Junzhe Lu",
      "Jing Lin",
      "Hongkun Dou",
      "Yulun Zhang",
      "Yue Deng",
      "Haoqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05549",
    "title": "Multi-granularity Causal Structure Learning",
    "abstract": "Unveil, model, and comprehend the causal mechanisms underpinning natural phenomena stand as fundamental endeavors across myriad scientific disciplines. Meanwhile, new knowledge emerges when discovering causal relationships from data. Existing causal learning algorithms predominantly focus on the isolated effects of variables, overlook the intricate interplay of multiple variables and their collective behavioral patterns. Furthermore, the ubiquity of high-dimensional data exacts a substantial temporal cost for causal algorithms. In this paper, we develop a novel method called MgCSL (Multi-granularity Causal Structure Learning), which first leverages sparse auto-encoder to explore coarse-graining strategies and causal abstractions from micro-variables to macro-ones. MgCSL then takes multi-granularity variables as inputs to train multilayer perceptrons and to delve the causality between variables. To enhance the efficacy on high-dimensional data, MgCSL introduces a simplified acyclicity constraint to adeptly search the directed acyclic graph among variables. Experimental results show that MgCSL outperforms competitive baselines, and finds out explainable causal connections on fMRI datasets. ",
    "url": "https://arxiv.org/abs/2312.05549",
    "authors": [
      "Jiaxuan Liang",
      "Jun Wang",
      "Guoxian Yu",
      "Shuyin Xia",
      "Guoyin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.05550",
    "title": "D3A-TS: Denoising-Driven Data Augmentation in Time Series",
    "abstract": "It has been demonstrated that the amount of data is crucial in data-driven machine learning methods. Data is always valuable, but in some tasks, it is almost like gold. This occurs in engineering areas where data is scarce or very expensive to obtain, such as predictive maintenance, where faults are rare. In this context, a mechanism to generate synthetic data can be very useful. While in fields such as Computer Vision or Natural Language Processing synthetic data generation has been extensively explored with promising results, in other domains such as time series it has received less attention. This work specifically focuses on studying and analyzing the use of different techniques for data augmentation in time series for classification and regression problems. The proposed approach involves the use of diffusion probabilistic models, which have recently achieved successful results in the field of Image Processing, for data augmentation in time series. Additionally, the use of meta-attributes to condition the data augmentation process is investigated. The results highlight the high utility of this methodology in creating synthetic data to train classification and regression models. To assess the results, six different datasets from diverse domains were employed, showcasing versatility in terms of input size and output types. Finally, an extensive ablation study is conducted to further support the obtained outcomes. ",
    "url": "https://arxiv.org/abs/2312.05550",
    "authors": [
      "David Solis-Martin",
      "Juan Galan-Paez",
      "Joaquin Borrego-Diaz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05562",
    "title": "Chain-of-Thought in Neural Code Generation: From and For Lightweight  Language Models",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in code generation. The integration of Chain of Thought (CoT) reasoning can further boost their performance. However, current CoT methods often require manual writing or LLMs with over 100 billion parameters to generate, impeding their applicability in resource-constrained scenarios. In this study, we investigate lightweight Language Models (lLMs), which are defined to have fewer than 10 billion parameters. Empirically, we find that most lLMs cannot generate high-quality CoTs when prompted by the few-shot method, but can take advantage of high-quality CoTs generated elsewhere to improve their performance in code generation. Based on these findings, we design a novel approach COTTON which can leverage lLMs to automatically generate CoTs for code generation. We synthesize new datasets and conduct extensive experiments on various benchmarks. The results show that the CoTs generated by COTTON outperform the baselines in terms of automated and human evaluation metrics. In particular, the CoTs generated by COTTON boost various lLMs to achieve higher performance gains than those generated by LLMs such as ChatGLM (130B), and are competitive with those generated by gpt-3.5-turbo (175B). Our study also showcases the potential of lLMs in software engineering applications. ",
    "url": "https://arxiv.org/abs/2312.05562",
    "authors": [
      "Guang Yang",
      "Yu Zhou",
      "Xiang Chen",
      "Xiangyu Zhang",
      "Terry Yue Zhuo",
      "Taolue Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.05583",
    "title": "Better Neural PDE Solvers Through Data-Free Mesh Movers",
    "abstract": "Recently, neural networks have been extensively employed to solve partial differential equations (PDEs) in physical system modeling. While major studies focus on learning system evolution on predefined static mesh discretizations, some methods utilize reinforcement learning or supervised learning techniques to create adaptive and dynamic meshes, due to the dynamic nature of these systems. However, these approaches face two primary challenges: (1) the need for expensive optimal mesh data, and (2) the change of the solution space's degree of freedom and topology during mesh refinement. To address these challenges, this paper proposes a neural PDE solver with a neural mesh adapter. To begin with, we introduce a novel data-free neural mesh adaptor, called Data-free Mesh Mover (DMM), with two main innovations. Firstly, it is an operator that maps the solution to adaptive meshes and is trained using the Monge-Ampere equation without optimal mesh data. Secondly, it dynamically changes the mesh by moving existing nodes rather than adding or deleting nodes and edges. Theoretical analysis shows that meshes generated by DMM have the lowest interpolation error bound. Based on DMM, to efficiently and accurately model dynamic systems, we develop a moving mesh based neural PDE solver (MM-PDE) that embeds the moving mesh with a two-branch architecture and a learnable interpolation framework to preserve information within the data. Empirical experiments demonstrate that our method generates suitable meshes and considerably enhances accuracy when modeling widely considered PDE systems. ",
    "url": "https://arxiv.org/abs/2312.05583",
    "authors": [
      "Peiyan Hu",
      "Yue Wang",
      "Zhi-Ming Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.05596",
    "title": "Factorized Explainer for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have received increasing attention due to their ability to learn from graph-structured data. To open the black-box of these deep learning models, post-hoc instance-level explanation methods have been proposed to understand GNN predictions. These methods seek to discover substructures that explain the prediction behavior of a trained GNN. In this paper, we show analytically that for a large class of explanation tasks, conventional approaches, which are based on the principle of graph information bottleneck (GIB), admit trivial solutions that do not align with the notion of explainability. Instead, we argue that a modified GIB principle may be used to avoid the aforementioned trivial solutions. We further introduce a novel factorized explanation model with theoretical performance guarantees. The modified GIB is used to analyze the structural properties of the proposed factorized explainer. We conduct extensive experiments on both synthetic and real-world datasets to validate the effectiveness of our proposed factorized explainer over existing approaches. ",
    "url": "https://arxiv.org/abs/2312.05596",
    "authors": [
      "Rundong Huang",
      "Farhad Shirani",
      "Dongsheng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05601",
    "title": "A Meshless Solver for Blood Flow Simulations in Elastic Vessels Using  Physics-Informed Neural Network",
    "abstract": "Investigating blood flow in the cardiovascular system is crucial for assessing cardiovascular health. Computational approaches offer some non-invasive alternatives to measure blood flow dynamics. Numerical simulations based on traditional methods such as finite-element and other numerical discretizations have been extensively studied and have yielded excellent results. However, adapting these methods to real-life simulations remains a complex task. In this paper, we propose a method that offers flexibility and can efficiently handle real-life simulations. We suggest utilizing the physics-informed neural network (PINN) to solve the Navier-Stokes equation in a deformable domain, specifically addressing the simulation of blood flow in elastic vessels. Our approach models blood flow using an incompressible, viscous Navier-Stokes equation in an Arbitrary Lagrangian-Eulerian form. The mechanical model for the vessel wall structure is formulated by an equation of Newton's second law of momentum and linear elasticity to the force exerted by the fluid flow. Our method is a mesh-free approach that eliminates the need for discretization and meshing of the computational domain. This makes it highly efficient in solving simulations involving complex geometries. Additionally, with the availability of well-developed open-source machine learning framework packages and parallel modules, our method can easily be accelerated through GPU computing and parallel computing. To evaluate our approach, we conducted experiments on regular cylinder vessels as well as vessels with plaque on their walls. We compared our results to a solution calculated by Finite Element Methods using a dense grid and small time steps, which we considered as the ground truth solution. We report the relative error and the time consumed to solve the problem, highlighting the advantages of our method. ",
    "url": "https://arxiv.org/abs/2312.05601",
    "authors": [
      "Han Zhang",
      "Raymond Chan",
      "Xue-Cheng Tai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2312.05605",
    "title": "TCNCA: Temporal Convolution Network with Chunked Attention for Scalable  Sequence Processing",
    "abstract": "MEGA is a recent transformer-based architecture, which utilizes a linear recurrent operator whose parallel computation, based on the FFT, scales as $O(LlogL)$, with $L$ being the sequence length. We build upon their approach by replacing the linear recurrence with a special temporal convolutional network which permits larger receptive field size with shallower networks, and reduces the computational complexity to $O(L)$. The resulting model is called TCNCA, a Temporal Convolutional Network with Chunked Attention. We evaluate TCNCA on EnWik8 language modeling, long-range-arena (LRA) sequence classification, as well as a synthetic reasoning benchmark associative recall. On EnWik8, TCNCA outperforms MEGA, reaching a lower loss with $1.37\\times$/$1.24\\times$ faster forward/backward pass during training. The dilated convolutions used in TCNCA are consistently and significantly faster operations than the FFT-based parallelized recurrence in GPUs, making them a scalable candidate for handling very large sequence lengths: they are up to $7.07\\times$/$2.86\\times$ faster in the forward/backward pass for sequences up to 131k. Further on LRA, TCNCA achieves, on average, $1.28\\times$ speed-up during inference with similar accuracy to what MEGA achieves. On associative recall, we find that even a simplified version of TCNCA, without excessive multiplicative and additive interactions, remains superior or competitive to MEGA on a range of sequence lengths and vocabulary sizes. ",
    "url": "https://arxiv.org/abs/2312.05605",
    "authors": [
      "Aleksandar Terzic",
      "Michael Hersche",
      "Geethan Karunaratne",
      "Luca Benini",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05623",
    "title": "Impact of Urban Street Geometry on the Detection Probability of  Automotive Radars",
    "abstract": "Prior works have analyzed the performance of millimeter wave automotive radars in the presence of diverse clutter and interference scenarios using stochastic geometry tools instead of more time-consuming measurement studies or system-level simulations. In these works, the distributions of radars or discrete clutter scatterers were modeled as Poisson point processes in the Euclidean space. However, since most automotive radars are likely to be mounted on vehicles and road infrastructure, road geometries are an important factor that must be considered. Instead of considering each road geometry as an individual case for study, in this work, we model each case as a specific instance of an underlying Poisson line process and further model the distribution of vehicles on the road as a Poisson point process - forming a Poisson line Cox process. Then, through the use of stochastic geometry tools, we estimate the average number of interfering radars for specific road and vehicular densities and the effect of radar parameters such as noise and beamwidth on the radar detection metrics. The numerical results are validated with Monte Carlo simulations. ",
    "url": "https://arxiv.org/abs/2312.05623",
    "authors": [
      "Mohammad Taha Shah",
      "Ankit Kumar",
      "Gourab Ghatak",
      "Shobha Sundar Ram"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.05642",
    "title": "Speed Up Federated Learning in Heterogeneous Environment: A Dynamic  Tiering Approach",
    "abstract": "Federated learning (FL) enables collaboratively training a model while keeping the training data decentralized and private. However, one significant impediment to training a model using FL, especially large models, is the resource constraints of devices with heterogeneous computation and communication capacities as well as varying task sizes. Such heterogeneity would render significant variations in the training time of clients, resulting in a longer overall training time as well as a waste of resources in faster clients. To tackle these heterogeneity issues, we propose the Dynamic Tiering-based Federated Learning (DTFL) system where slower clients dynamically offload part of the model to the server to alleviate resource constraints and speed up training. By leveraging the concept of Split Learning, DTFL offloads different portions of the global model to clients in different tiers and enables each client to update the models in parallel via local-loss-based training. This helps reduce the computation and communication demand on resource-constrained devices and thus mitigates the straggler problem. DTFL introduces a dynamic tier scheduler that uses tier profiling to estimate the expected training time of each client, based on their historical training time, communication speed, and dataset size. The dynamic tier scheduler assigns clients to suitable tiers to minimize the overall training time in each round. We first theoretically prove the convergence properties of DTFL. We then train large models (ResNet-56 and ResNet-110) on popular image datasets (CIFAR-10, CIFAR-100, CINIC-10, and HAM10000) under both IID and non-IID systems. Extensive experimental results show that compared with state-of-the-art FL methods, DTFL can significantly reduce the training time while maintaining model accuracy. ",
    "url": "https://arxiv.org/abs/2312.05642",
    "authors": [
      "Seyed Mahmoud Sajjadi Mohammadabadi",
      "Syed Zawad",
      "Feng Yan",
      "Lei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2312.05643",
    "title": "NiSNN-A: Non-iterative Spiking Neural Networks with Attention with  Application to Motor Imagery EEG Classification",
    "abstract": "Motor imagery, an important category in electroencephalogram (EEG) research, often intersects with scenarios demanding low energy consumption, such as portable medical devices and isolated environment operations. Traditional deep learning algorithms, despite their effectiveness, are characterized by significant computational demands accompanied by high energy usage. As an alternative, spiking neural networks (SNNs), inspired by the biological functions of the brain, emerge as a promising energy-efficient solution. However, SNNs typically exhibit lower accuracy than their counterpart convolutional neural networks (CNNs). Although attention mechanisms successfully increase network accuracy by focusing on relevant features, their integration in the SNN framework remains an open question. In this work, we combine the SNN and the attention mechanisms for the EEG classification, aiming to improve precision and reduce energy consumption. To this end, we first propose a Non-iterative Leaky Integrate-and-Fire (LIF) neuron model, overcoming the gradient issues in the traditional SNNs using the Iterative LIF neurons. Then, we introduce the sequence-based attention mechanisms to refine the feature map. We evaluated the proposed Non-iterative SNN with Attention (NiSNN-A) model on OpenBMI, a large-scale motor imagery dataset. Experiment results demonstrate that 1) our model outperforms other SNN models by achieving higher accuracy, 2) our model increases energy efficiency compared to the counterpart CNN models (i.e., by 2.27 times) while maintaining comparable accuracy. ",
    "url": "https://arxiv.org/abs/2312.05643",
    "authors": [
      "Chuhan Zhang",
      "Wei Pan",
      "Cosimo Della Santina"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05654",
    "title": "Spectral methods for Neural Integral Equations",
    "abstract": "Neural integral equations are deep learning models based on the theory of integral equations, where the model consists of an integral operator and the corresponding equation (of the second kind) which is learned through an optimization procedure. This approach allows to leverage the nonlocal properties of integral operators in machine learning, but it is computationally expensive. In this article, we introduce a framework for neural integral equations based on spectral methods that allows us to learn an operator in the spectral domain, resulting in a cheaper computational cost, as well as in high interpolation accuracy. We study the properties of our methods and show various theoretical guarantees regarding the approximation capabilities of the model, and convergence to solutions of the numerical methods. We provide numerical experiments to demonstrate the practical effectiveness of the resulting model. ",
    "url": "https://arxiv.org/abs/2312.05654",
    "authors": [
      "Emanuele Zappala"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2312.05657",
    "title": "Leveraging Reinforcement Learning and Large Language Models for Code  Optimization",
    "abstract": "Code optimization is a daunting task that requires a significant level of expertise from experienced programmers. This level of expertise is not sufficient when compared to the rapid development of new hardware architectures. Towards advancing the whole code optimization process, recent approaches rely on machine learning and artificial intelligence techniques. This paper introduces a new framework to decrease the complexity of code optimization. The proposed framework builds on large language models (LLMs) and reinforcement learning (RL) and enables LLMs to receive feedback from their environment (i.e., unit tests) during the fine-tuning process. We compare our framework with existing state-of-the-art models and show that it is more efficient with respect to speed and computational usage, as a result of the decrement in training steps and its applicability to models with fewer parameters. Additionally, our framework reduces the possibility of logical and syntactical errors. Toward evaluating our approach, we run several experiments on the PIE dataset using a CodeT5 language model and RRHF, a new reinforcement learning algorithm. We adopt a variety of evaluation metrics with regards to optimization quality, and speedup. The evaluation results demonstrate that the proposed framework has similar results in comparison with existing models using shorter training times and smaller pre-trained models. In particular, we accomplish an increase of 5.6% and 2.2 over the baseline models concerning the %OP T and SP metrics. ",
    "url": "https://arxiv.org/abs/2312.05657",
    "authors": [
      "Shukai Duan",
      "Nikos Kanakaris",
      "Xiongye Xiao",
      "Heng Ping",
      "Chenyu Zhou",
      "Nesreen K. Ahmed",
      "Guixiang Ma",
      "Mihai Capota",
      "Theodore L. Willke",
      "Shahin Nazarian",
      "Paul Bogdan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.05659",
    "title": "Optimal Unbiased Randomizers for Regression with Label Differential  Privacy",
    "abstract": "We propose a new family of label randomizers for training regression models under the constraint of label differential privacy (DP). In particular, we leverage the trade-offs between bias and variance to construct better label randomizers depending on a privately estimated prior distribution over the labels. We demonstrate that these randomizers achieve state-of-the-art privacy-utility trade-offs on several datasets, highlighting the importance of reducing bias when training neural networks with label DP. We also provide theoretical results shedding light on the structural properties of the optimal unbiased randomizers. ",
    "url": "https://arxiv.org/abs/2312.05659",
    "authors": [
      "Ashwinkumar Badanidiyuru",
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Ethan Leeman",
      "Pasin Manurangsi",
      "Avinash V Varadarajan",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.05662",
    "title": "Understanding the Effect of Model Compression on Social Bias in Large  Language Models",
    "abstract": "Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model's predictions in downstream tasks, leading to representational harm. Many strategies have been proposed to mitigate the effects of inappropriate social biases learned during pretraining. Simultaneously, methods for model compression have become increasingly popular to reduce the computational burden of LLMs. Despite the popularity and need for both approaches, little work has been done to explore the interplay between these two. We perform a carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs. Longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time. ",
    "url": "https://arxiv.org/abs/2312.05662",
    "authors": [
      "Gustavo Gon\u00e7alves",
      "Emma Strubell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.05666",
    "title": "Towards a Graph Neural Network-Based Approach for Estimating Hidden  States in Cyber Attack Simulations",
    "abstract": "This work-in-progress paper introduces a prototype for a novel Graph Neural Network (GNN) based approach to estimate hidden states in cyber attack simulations. Utilizing the Meta Attack Language (MAL) in conjunction with Relational Dynamic Decision Language (RDDL) conformant simulations, our framework aims to map the intricate complexity of cyber attacks with a vast number of possible vectors in the simulations. While the prototype is yet to be completed and validated, we discuss its foundational concepts, the architecture, and the potential implications for the field of computer security. ",
    "url": "https://arxiv.org/abs/2312.05666",
    "authors": [
      "Pontus Johnson",
      "Mathias Ekstedt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.05668",
    "title": "Polarization in Decentralized Online Social Networks",
    "abstract": "Centralized social media platforms are currently experiencing a shift in user engagement, drawing attention to alternative paradigms like Decentralized Online Social Networks (DOSNs). The rising popularity of DOSNs finds its root in the accessibility of open-source software, enabling anyone to create a new instance (i.e., server) and participate in a decentralized network known as Fediverse. Despite this growing momentum, there has been a lack of studies addressing the effect of positive and negative interactions among instances within DOSNs. This work aims to fill this gap by presenting a preliminary examination of instances' polarization in DOSNs, focusing on Mastodon -- the most widely recognized decentralized social media platform, boasting over 10M users and nearly 20K instances to date. Our results suggest that polarization in the Fediverse emerges in unique ways, influenced by the desire to foster a federated environment between instances, also facilitating the isolation of instances that may pose potential risks to the Fediverse. ",
    "url": "https://arxiv.org/abs/2312.05668",
    "authors": [
      "Lucio La Cava",
      "Domenico Mandaglio",
      "Andrea Tagarelli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2312.05671",
    "title": "Hate Speech and Offensive Content Detection in Indo-Aryan Languages: A  Battle of LSTM and Transformers",
    "abstract": "Social media platforms serve as accessible outlets for individuals to express their thoughts and experiences, resulting in an influx of user-generated data spanning all age groups. While these platforms enable free expression, they also present significant challenges, including the proliferation of hate speech and offensive content. Such objectionable language disrupts objective discourse and can lead to radicalization of debates, ultimately threatening democratic values. Consequently, organizations have taken steps to monitor and curb abusive behavior, necessitating automated methods for identifying suspicious posts. This paper contributes to Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC) 2023 shared tasks track. We, team Z-AGI Labs, conduct a comprehensive comparative analysis of hate speech classification across five distinct languages: Bengali, Assamese, Bodo, Sinhala, and Gujarati. Our study encompasses a wide range of pre-trained models, including Bert variants, XLM-R, and LSTM models, to assess their performance in identifying hate speech across these languages. Results reveal intriguing variations in model performance. Notably, Bert Base Multilingual Cased emerges as a strong performer across languages, achieving an F1 score of 0.67027 for Bengali and 0.70525 for Assamese. At the same time, it significantly outperforms other models with an impressive F1 score of 0.83009 for Bodo. In Sinhala, XLM-R stands out with an F1 score of 0.83493, whereas for Gujarati, a custom LSTM-based model outshined with an F1 score of 0.76601. This study offers valuable insights into the suitability of various pre-trained models for hate speech detection in multilingual settings. By considering the nuances of each, our research contributes to an informed model selection for building robust hate speech detection systems. ",
    "url": "https://arxiv.org/abs/2312.05671",
    "authors": [
      "Nikhil Narayan",
      "Mrutyunjay Biswal",
      "Pramod Goyal",
      "Abhranta Panigrahi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.05673",
    "title": "Modeling Homophily in Exponential-Family Random Graph Models for  Bipartite Networks",
    "abstract": "Homophily, the tendency of individuals who are alike to form ties with one another, is an important concept in the study of social networks. Yet accounting for homophily effects is complicated in the context of bipartite networks where ties connect individuals not with one another but rather with a separate set of nodes, which might also be individuals but which are often an entirely different type of objects. As a result, much work on the effect of homophily in a bipartite network proceeds by first eliminating the bipartite structure, collapsing a two-mode network to a one-mode network and thereby ignoring potentially meaningful structure in the data. We introduce a set of methods to model homophily on bipartite networks without losing information in this way, then we demonstrate that these methods allow for substantively interesting findings in management science not possible using standard techniques. These methods are implemented in the widely-used ergm package for R. ",
    "url": "https://arxiv.org/abs/2312.05673",
    "authors": [
      "Rashmi P. Bomiriya",
      "Alina R. Kuvelkar",
      "David R. Hunter",
      "Steffen Triebel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2312.05679",
    "title": "Schr\u00f6dinger's control and estimation paradigm with spatio-temporal  distributions on graphs",
    "abstract": "The problem of reconciling a prior probability law with data was introduced by E. Schr\\\"odinger in 1931/32. It represents an early formulation of a maximum likelihood problem. The specific formulation can also be seen as the control problem to modify the law of a diffusion process so as to match specifications on marginal distributions at given times. Thereby, in recent years, this so-called {\\em Schr\\\"odinger Bridge problem} has been at the center of the development of uncertainty control. However, an unstudied facet of this program has been to address uncertainty in space and time, modeling the effect of tasks being completed, instead of imposing specifications at fixed times. The present work is a first study to extend Schr\\\"odinger's paradigm on such an issue. It is developed in the context of Markov chains and random walks on graphs. Specifically, we study the case where one marginal distribution represents the initial state occupation of a Markov chain, while others represent first-arrival time distributions at absorbing states signifying completion of tasks. We establish that when the prior is Markov, a Markov policy is once again optimal with respect to a likelihood cost that follows Schr\\\"odinger's dictum. ",
    "url": "https://arxiv.org/abs/2312.05679",
    "authors": [
      "Asmaa Eldesoukey",
      "Tryphon T. Georgiou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2312.05686",
    "title": "Privacy Preserving Multi-Agent Reinforcement Learning in Supply Chains",
    "abstract": "This paper addresses privacy concerns in multi-agent reinforcement learning (MARL), specifically within the context of supply chains where individual strategic data must remain confidential. Organizations within the supply chain are modeled as agents, each seeking to optimize their own objectives while interacting with others. As each organization's strategy is contingent on neighboring strategies, maintaining privacy of state and action-related information is crucial. To tackle this challenge, we propose a game-theoretic, privacy-preserving mechanism, utilizing a secure multi-party computation (MPC) framework in MARL settings. Our major contribution is the successful implementation of a secure MPC framework, SecFloat on EzPC, to solve this problem. However, simply implementing policy gradient methods such as MADDPG operations using SecFloat, while conceptually feasible, would be programmatically intractable. To overcome this hurdle, we devise a novel approach that breaks down the forward and backward pass of the neural network into elementary operations compatible with SecFloat , creating efficient and secure versions of the MADDPG algorithm. Furthermore, we present a learning mechanism that carries out floating point operations in a privacy-preserving manner, an important feature for successful learning in MARL framework. Experiments reveal that there is on average 68.19% less supply chain wastage in 2 PC compared to no data share, while also giving on average 42.27% better average cumulative revenue for each player. This work paves the way for practical, privacy-preserving MARL, promising significant improvements in secure computation within supply chain contexts and broadly. ",
    "url": "https://arxiv.org/abs/2312.05686",
    "authors": [
      "Ananta Mukherjee",
      "Peeyush Kumar",
      "Boling Yang",
      "Nishanth Chandran",
      "Divya Gupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05695",
    "title": "The Counterattack of CNNs in Self-Supervised Learning: Larger Kernel  Size might be All You Need",
    "abstract": "Vision Transformers have been rapidly uprising in computer vision thanks to their outstanding scaling trends, and gradually replacing convolutional neural networks (CNNs). Recent works on self-supervised learning (SSL) introduce siamese pre-training tasks, on which Transformer backbones continue to demonstrate ever stronger results than CNNs. People come to believe that Transformers or self-attention modules are inherently more suitable than CNNs in the context of SSL. However, it is noteworthy that most if not all prior arts of SSL with CNNs chose the standard ResNets as their backbones, whose architecture effectiveness is known to already lag behind advanced Vision Transformers. Therefore, it remains unclear whether the self-attention operation is crucial for the recent advances in SSL - or CNNs can deliver the same excellence with more advanced designs, too? Can we close the SSL performance gap between Transformers and CNNs? To answer these intriguing questions, we apply self-supervised pre-training to the recently proposed, stronger lager-kernel CNN architecture and conduct an apple-to-apple comparison with Transformers, in their SSL performance. Our results show that we are able to build pure CNN SSL architectures that perform on par with or better than the best SSL-trained Transformers, by just scaling up convolutional kernel sizes besides other small tweaks. Impressively, when transferring to the downstream tasks \\texttt{MS COCO} detection and segmentation, our SSL pre-trained CNN model (trained in 100 epochs) achieves the same good performance as the 300-epoch pre-trained Transformer counterpart. We hope this work can help to better understand what is essential (or not) for self-supervised learning backbones. ",
    "url": "https://arxiv.org/abs/2312.05695",
    "authors": [
      "Tianjin Huang",
      "Shiwei Liu",
      "Tianlong Chen",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05698",
    "title": "Unsupervised Multi-modal Feature Alignment for Time Series  Representation Learning",
    "abstract": "In recent times, the field of unsupervised representation learning (URL) for time series data has garnered significant interest due to its remarkable adaptability across diverse downstream applications. Unsupervised learning goals differ from downstream tasks, making it tricky to ensure downstream task utility by focusing only on temporal feature characterization. Researchers have proposed multiple transformations to extract discriminative patterns implied in informative time series, trying to fill the gap. Despite the introduction of a variety of feature engineering techniques, e.g. spectral domain, wavelet transformed features, features in image form and symbolic features etc. the utilization of intricate feature fusion methods and dependence on heterogeneous features during inference hampers the scalability of the solutions. To address this, our study introduces an innovative approach that focuses on aligning and binding time series representations encoded from different modalities, inspired by spectral graph theory, thereby guiding the neural encoder to uncover latent pattern associations among these multi-modal features. In contrast to conventional methods that fuse features from multiple modalities, our proposed approach simplifies the neural architecture by retaining a single time series encoder, consequently leading to preserved scalability. We further demonstrate and prove mechanisms for the encoder to maintain better inductive bias. In our experimental evaluation, we validated the proposed method on a diverse set of time series datasets from various domains. Our approach outperforms existing state-of-the-art URL methods across diverse downstream tasks. ",
    "url": "https://arxiv.org/abs/2312.05698",
    "authors": [
      "Chen Liang",
      "Donghua Yang",
      "Zhiyu Liang",
      "Hongzhi Wang",
      "Zheng Liang",
      "Xiyang Zhang",
      "Jianfeng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05704",
    "title": "On the Ground and in the Sky: A Tutorial on Radio Localization in  Ground-Air-Space Networks",
    "abstract": "The inherent limitations in scaling up ground infrastructure for future wireless networks, combined with decreasing operational costs of aerial and space networks, are driving considerable research interest in multisegment ground-air-space (GAS) networks. In GAS networks, where ground and aerial users share network resources, ubiquitous and accurate user localization becomes indispensable, not only as an end-user service but also as an enabler for location-aware communications. This breaks the convention of having localization as a byproduct in networks primarily designed for communications. To address these imperative localization needs, the design and utilization of ground, aerial, and space anchors require thorough investigation. In this tutorial, we provide an in-depth systemic analysis of the radio localization problem in GAS networks, considering ground and aerial users as targets to be localized. Starting from a survey of the most relevant works, we then define the key characteristics of anchors and targets in GAS networks. Subsequently, we detail localization fundamentals in GAS networks, considering 3D positions and orientations. Afterward, we thoroughly analyze radio localization systems in GAS networks, detailing the system model, design aspects, and considerations for each of the three GAS anchors. Preliminary results are presented to provide a quantifiable perspective on key design aspects in GAS-based localization scenarios. We then identify the vital roles 6G enablers are expected to play in radio localization in GAS networks. ",
    "url": "https://arxiv.org/abs/2312.05704",
    "authors": [
      "Hazem Sallouha",
      "Sharief Saleh",
      "Sibren De Bast",
      "Zhuangzhuang Cui",
      "Sofie Pollin",
      "Henk Wymeersch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.05705",
    "title": "Structured Inverse-Free Natural Gradient: Memory-Efficient &  Numerically-Stable KFAC for Large Neural Nets",
    "abstract": "Second-order methods for deep learning -- such as KFAC -- can be useful for neural net training. However, they are often memory-inefficient and numerically unstable for low-precision training since their preconditioning Kronecker factors are dense, and require high-precision matrix inversion or decomposition. Consequently, such methods are not widely used for training large neural networks such as transformer-based models. We address these two issues by (i) formulating an inverse-free update of KFAC and (ii) imposing structures in each of the Kronecker factors, resulting in a method we term structured inverse-free natural gradient descent (SINGD). On large modern neural networks, we show that, in contrast to KFAC, SINGD is memory efficient and numerically robust, and often outperforms AdamW even in half precision. Hence, our work closes a gap between first-order and second-order methods in modern low precision training for large neural nets. ",
    "url": "https://arxiv.org/abs/2312.05705",
    "authors": [
      "Wu Lin",
      "Felix Dangel",
      "Runa Eschenhagen",
      "Kirill Neklyudov",
      "Agustinus Kristiadi",
      "Richard E. Turner",
      "Alireza Makhzani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.05716",
    "title": "Initialization Matters for Adversarial Transfer Learning",
    "abstract": "With the prevalence of the Pretraining-Finetuning paradigm in transfer learning, the robustness of downstream tasks has become a critical concern. In this work, we delve into adversarial robustness in transfer learning and reveal the critical role of initialization, including both the pretrained model and the linear head. First, we discover the necessity of an adversarially robust pretrained model. Specifically, we reveal that with a standard pretrained model, Parameter-Efficient Finetuning~(PEFT) methods either fail to be adversarially robust or continue to exhibit significantly degraded adversarial robustness on downstream tasks, even with adversarial training during finetuning. Leveraging a robust pretrained model, surprisingly, we observe that a simple linear probing can outperform full finetuning and other PEFT methods with random initialization on certain datasets. We further identify that linear probing excels in preserving robustness from the robust pretraining. Based on this, we propose Robust Linear Initialization~(RoLI) for adversarial finetuning, which initializes the linear head with the weights obtained by adversarial linear probing to maximally inherit the robustness from pretraining. Across five different image classification datasets, we demonstrate the effectiveness of RoLI and achieve new state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2312.05716",
    "authors": [
      "Andong Hua",
      "Jindong Gu",
      "Zhiyu Xue",
      "Nicholas Carlini",
      "Eric Wong",
      "Yao Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05720",
    "title": "Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer  Inputs of Language Models in Federated Learning",
    "abstract": "Federated learning (FL) emphasizes decentralized training by storing data locally and sending only model updates, underlining user privacy. Recently, a line of works on privacy attacks impairs user privacy by extracting sensitive training text from language models in the context of FL. Yet, these attack techniques face distinct hurdles: some work chiefly with limited batch sizes (e.g., batch size of 1), and others are easily detectable. This paper introduces an innovative approach that is challenging to detect, significantly enhancing the recovery rate of text in various batch-size settings. Building on fundamental gradient matching and domain prior knowledge, we enhance the attack by recovering the input of the Pooler layer of language models, which enables us to provide additional supervised signals at the feature level. Unlike gradient data, these signals do not average across sentences and tokens, thereby offering more nuanced and effective insights. We benchmark our method using text classification tasks on datasets such as CoLA, SST-2, and Rotten Tomatoes. Across different batch sizes and models, our approach consistently outperforms previous state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2312.05720",
    "authors": [
      "Jianwei Li",
      "Sheng Liu",
      "Qi Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.05727",
    "title": "Cyber-Physical Testbed Integrating RTAC with RTDS for Game-Theoretic  Topology Control Under Load Altering Attacks",
    "abstract": "This paper introduces a cyber-physical testbed that integrates the Real-Time Digital Simulator (RTDS) with the Real-Time Automation Controller (RTAC) to enhance cybersecurity in electrical distribution networks. Focused on addressing vulnerabilities to cyber attacks, our testbed employs an advanced control algorithm developed in Python and executed through real-time controllers. Key to our approach is the seamless integration of the host PC machine, RTDS, and RTAC via the Modbus protocol. We present a game theory-based topology control strategy as an effective response to cyber attacks, specifically targeting smart meters. This testbed validates the efficacy of our method in fully eliminating voltage violations due to load altering attacks, showcasing substantial advancements in smart grid cybersecurity via the innovative use of RTDS and RTAC to simulate and counteract complex cyber threats. ",
    "url": "https://arxiv.org/abs/2312.05727",
    "authors": [
      "Alaa Selim",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.05730",
    "title": "AFL-Net: Integrating Audio, Facial, and Lip Modalities with  Cross-Attention for Robust Speaker Diarization in the Wild",
    "abstract": "Speaker diarization in real-world videos presents significant challenges due to varying acoustic conditions, diverse scenes, and the presence of off-screen speakers, among other factors. This paper builds upon a previous study (AVR-Net) and introduces a novel multi-modal speaker diarization system, AFL-Net. Unlike AVR-Net, which independently extracts high-level representations from each modality, AFL-Net employs a multi-modal cross-attention mechanism. This approach generates high-level representations from each modality while conditioning on each other, ensuring a more comprehensive information fusion across modalities to enhance identity discrimination. Furthermore, the proposed AFL-Net incorporates dynamic lip movement as an additional modality to aid in distinguishing each segment's identity. We also introduce a masking strategy during training that randomly obscures the face and lip movement modalities, which increases the influence of the audio modality on system outputs.Experimental results demonstrate that our proposed model outperforms state-of-the-art baselines, such as the AVR-Net and DyViSE. Moreover, an ablation study confirms the effectiveness of each modification. Some demos are provided:https://yyk77.github.io/afl_net.github.io. ",
    "url": "https://arxiv.org/abs/2312.05730",
    "authors": [
      "Yongkang Yin",
      "Xu Li",
      "Ying Shan",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2312.05736",
    "title": "ASWT-SGNN: Adaptive Spectral Wavelet Transform-based Self-Supervised  Graph Neural Network",
    "abstract": "Graph Comparative Learning (GCL) is a self-supervised method that combines the advantages of Graph Convolutional Networks (GCNs) and comparative learning, making it promising for learning node representations. However, the GCN encoders used in these methods rely on the Fourier transform to learn fixed graph representations, which is inherently limited by the uncertainty principle involving spatial and spectral localization trade-offs. To overcome the inflexibility of existing methods and the computationally expensive eigen-decomposition and dense matrix multiplication, this paper proposes an Adaptive Spectral Wavelet Transform-based Self-Supervised Graph Neural Network (ASWT-SGNN). The proposed method employs spectral adaptive polynomials to approximate the filter function and optimize the wavelet using contrast loss. This design enables the creation of local filters in both spectral and spatial domains, allowing flexible aggregation of neighborhood information at various scales and facilitating controlled transformation between local and global information. Compared to existing methods, the proposed approach reduces computational complexity and addresses the limitation of graph convolutional neural networks, which are constrained by graph size and lack flexible control over the neighborhood aspect. Extensive experiments on eight benchmark datasets demonstrate that ASWT-SGNN accurately approximates the filter function in high-density spectral regions, avoiding costly eigen-decomposition. Furthermore, ASWT-SGNN achieves comparable performance to state-of-the-art models in node classification tasks. ",
    "url": "https://arxiv.org/abs/2312.05736",
    "authors": [
      "Ruyue Liu",
      "Rong Yin",
      "Yong Liu",
      "Weiping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.05738",
    "title": "FedReverse: Multiparty Reversible Deep Neural Network Watermarking",
    "abstract": "The proliferation of Deep Neural Networks (DNN) in commercial applications is expanding rapidly. Simultaneously, the increasing complexity and cost of training DNN models have intensified the urgency surrounding the protection of intellectual property associated with these trained models. In this regard, DNN watermarking has emerged as a crucial safeguarding technique. This paper presents FedReverse, a novel multiparty reversible watermarking approach for robust copyright protection while minimizing performance impact. Unlike existing methods, FedReverse enables collaborative watermark embedding from multiple parties after model training, ensuring individual copyright claims. In addition, FedReverse is reversible, enabling complete watermark removal with unanimous client consent. FedReverse demonstrates perfect covering, ensuring that observations of watermarked content do not reveal any information about the hidden watermark. Additionally, it showcases resistance against Known Original Attacks (KOA), making it highly challenging for attackers to forge watermarks or infer the key. This paper further evaluates FedReverse through comprehensive simulations involving Multi-layer Perceptron (MLP) and Convolutional Neural Networks (CNN) trained on the MNIST dataset. The simulations demonstrate FedReverse's robustness, reversibility, and minimal impact on model accuracy across varying embedding parameters and multiple client scenarios. ",
    "url": "https://arxiv.org/abs/2312.05738",
    "authors": [
      "Junlong Mao",
      "Huiyi Tang",
      "Yi Zhang",
      "Fengxia Liu",
      "Zhiyong Zheng",
      "Shanxiang Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05739",
    "title": "GAMC: An Unsupervised Method for Fake News Detection using Graph  Autoencoder with Masking",
    "abstract": "With the rise of social media, the spread of fake news has become a significant concern, potentially misleading public perceptions and impacting social stability. Although deep learning methods like CNNs, RNNs, and Transformer-based models like BERT have enhanced fake news detection, they primarily focus on content, overlooking social context during news propagation. Graph-based techniques have incorporated this social context but are limited by the need for large labeled datasets. Addressing these challenges, this paper introduces GAMC, an unsupervised fake news detection technique using the Graph Autoencoder with Masking and Contrastive learning. By leveraging both the context and content of news propagation as self-supervised signals, our method negates the requirement for labeled datasets. We augment the original news propagation graph, encode these with a graph encoder, and employ a graph decoder for reconstruction. A unique composite loss function, including reconstruction error and contrast loss, is designed. The method's contributions are: introducing self-supervised learning to fake news detection, proposing a graph autoencoder integrating two distinct losses, and validating our approach's efficacy through real-world dataset experiments. ",
    "url": "https://arxiv.org/abs/2312.05739",
    "authors": [
      "Shu Yin",
      "Chao Gao",
      "Zhen Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05741",
    "title": "MISCA: A Joint Model for Multiple Intent Detection and Slot Filling with  Intent-Slot Co-Attention",
    "abstract": "The research study of detecting multiple intents and filling slots is becoming more popular because of its relevance to complicated real-world situations. Recent advanced approaches, which are joint models based on graphs, might still face two potential issues: (i) the uncertainty introduced by constructing graphs based on preliminary intents and slots, which may transfer intent-slot correlation information to incorrect label node destinations, and (ii) direct incorporation of multiple intent labels for each token w.r.t. token-level intent voting might potentially lead to incorrect slot predictions, thereby hurting the overall performance. To address these two issues, we propose a joint model named MISCA. Our MISCA introduces an intent-slot co-attention mechanism and an underlying layer of label attention mechanism. These mechanisms enable MISCA to effectively capture correlations between intents and slot labels, eliminating the need for graph construction. They also facilitate the transfer of correlation information in both directions: from intents to slots and from slots to intents, through multiple levels of label-specific representations, without relying on token-level intent information. Experimental results show that MISCA outperforms previous models, achieving new state-of-the-art overall accuracy performances on two benchmark datasets MixATIS and MixSNIPS. This highlights the effectiveness of our attention mechanisms. ",
    "url": "https://arxiv.org/abs/2312.05741",
    "authors": [
      "Thinh Pham",
      "Chi Tran",
      "Dat Quoc Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.05745",
    "title": "Open World Object Detection in the Era of Foundation Models",
    "abstract": "Object detection is integral to a bevy of real-world applications, from robotics to medical image analysis. To be used reliably in such applications, models must be capable of handling unexpected - or novel - objects. The open world object detection (OWD) paradigm addresses this challenge by enabling models to detect unknown objects and learn discovered ones incrementally. However, OWD method development is hindered due to the stringent benchmark and task definitions. These definitions effectively prohibit foundation models. Here, we aim to relax these definitions and investigate the utilization of pre-trained foundation models in OWD. First, we show that existing benchmarks are insufficient in evaluating methods that utilize foundation models, as even naive integration methods nearly saturate these benchmarks. This result motivated us to curate a new and challenging benchmark for these models. Therefore, we introduce a new benchmark that includes five real-world application-driven datasets, including challenging domains such as aerial and surgical images, and establish baselines. We exploit the inherent connection between classes in application-driven datasets and introduce a novel method, Foundation Object detection Model for the Open world, or FOMO, which identifies unknown objects based on their shared attributes with the base known objects. FOMO has ~3x unknown object mAP compared to baselines on our benchmark. However, our results indicate a significant place for improvement - suggesting a great research opportunity in further scaling object detection methods to real-world domains. Our code and benchmark are available at https://orrzohar.github.io/projects/fomo/. ",
    "url": "https://arxiv.org/abs/2312.05745",
    "authors": [
      "Orr Zohar",
      "Alejandro Lozano",
      "Shelly Goel",
      "Serena Yeung",
      "Kuan-Chieh Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05746",
    "title": "A Scalable MARL Solution for Scheduling in Conflict Graphs",
    "abstract": "This paper proposes a fully scalable multi-agent reinforcement learning (MARL) approach for packet scheduling in conflict graphs, aiming to minimizing average packet delays. Each agent autonomously manages the schedule of a single link over one or multiple sub-bands, considering its own state and states of conflicting links. The problem can be conceptualized as a decentralized partially observable Markov decision process (Dec-POMDP). The proposed solution leverages an on-policy reinforcement learning algorithms multi-agent proximal policy optimization (MAPPO) within a multi-agent networked system, incorporating advanced recurrent structures in the neural network. The MARL design allows for fully decentralized training and execution, seamlessly scaling to very large networks. Extensive simulations across a diverse range of conflict graphs demonstrate that the proposed solution compares favorably to well-established schedulers in terms of both throughput and delay under various traffic conditions. ",
    "url": "https://arxiv.org/abs/2312.05746",
    "authors": [
      "Yiming Zhang",
      "Dongning Guo"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.05747",
    "title": "Difference of Probability and Information Entropy for Skills  Classification and Prediction in Student Learning",
    "abstract": "The probability of an event is in the range of [0, 1]. In a sample space S, the value of probability determines whether an outcome is true or false. The probability of an event Pr(A) that will never occur = 0. The probability of the event Pr(B) that will certainly occur = 1. This makes both events A and B thus a certainty. Furthermore, the sum of probabilities Pr(E1) + Pr(E2) + ... + Pr(En) of a finite set of events in a given sample space S = 1. Conversely, the difference of the sum of two probabilities that will certainly occur is 0. Firstly, this paper discusses Bayes' theorem, then complement of probability and the difference of probability for occurrences of learning-events, before applying these in the prediction of learning objects in student learning. Given the sum total of 1; to make recommendation for student learning, this paper submits that the difference of argMaxPr(S) and probability of student-performance quantifies the weight of learning objects for students. Using a dataset of skill-set, the computational procedure demonstrates: i) the probability of skill-set events that has occurred that would lead to higher level learning; ii) the probability of the events that has not occurred that requires subject-matter relearning; iii) accuracy of decision tree in the prediction of student performance into class labels; and iv) information entropy about skill-set data and its implication on student cognitive performance and recommendation of learning [1]. ",
    "url": "https://arxiv.org/abs/2312.05747",
    "authors": [
      "Kennedy Efosa Ehimwenma",
      "Safiya Al Sharji",
      "Maruf Raheem"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.05748",
    "title": "IL-NeRF: Incremental Learning for Neural Radiance Fields with Camera  Pose Alignment",
    "abstract": "Neural radiance fields (NeRF) is a promising approach for generating photorealistic images and representing complex scenes. However, when processing data sequentially, it can suffer from catastrophic forgetting, where previous data is easily forgotten after training with new data. Existing incremental learning methods using knowledge distillation assume that continuous data chunks contain both 2D images and corresponding camera pose parameters, pre-estimated from the complete dataset. This poses a paradox as the necessary camera pose must be estimated from the entire dataset, even though the data arrives sequentially and future chunks are inaccessible. In contrast, we focus on a practical scenario where camera poses are unknown. We propose IL-NeRF, a novel framework for incremental NeRF training, to address this challenge. IL-NeRF's key idea lies in selecting a set of past camera poses as references to initialize and align the camera poses of incoming image data. This is followed by a joint optimization of camera poses and replay-based NeRF distillation. Our experiments on real-world indoor and outdoor scenes show that IL-NeRF handles incremental NeRF training and outperforms the baselines by up to $54.04\\%$ in rendering quality. ",
    "url": "https://arxiv.org/abs/2312.05748",
    "authors": [
      "Letian Zhang",
      "Ming Li",
      "Chen Chen",
      "Jie Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05752",
    "title": "Camera-based 3D Semantic Scene Completion with Sparse Guidance Network",
    "abstract": "Semantic scene completion (SSC) aims to predict the semantic occupancy of each voxel in the entire 3D scene from limited observations, which is an emerging and critical task for autonomous driving. Recently, many studies have turned to camera-based SSC solutions due to the richer visual cues and cost-effectiveness of cameras. However, existing methods usually rely on sophisticated and heavy 3D models to directly process the lifted 3D features that are not discriminative enough for clear segmentation boundaries. In this paper, we adopt the dense-sparse-dense design and propose an end-to-end camera-based SSC framework, termed SGN, to diffuse semantics from the semantic- and occupancy-aware seed voxels to the whole scene based on geometry prior and occupancy information. By designing hybrid guidance (sparse semantic and geometry guidance) and effective voxel aggregation for spatial occupancy and geometry priors, we enhance the feature separation between different categories and expedite the convergence of semantic diffusion. Extensive experimental results on the SemanticKITTI dataset demonstrate the superiority of our SGN over existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2312.05752",
    "authors": [
      "Jianbiao Mei",
      "Yu Yang",
      "Mengmeng Wang",
      "Junyu Zhu",
      "Xiangrui Zhao",
      "Jongwon Ra",
      "Laijian Li",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05756",
    "title": "A quantitative fusion strategy of stock picking and timing based on  Particle Swarm Optimized-Back Propagation Neural Network and Multivariate  Gaussian-Hidden Markov Model",
    "abstract": "In recent years, machine learning (ML) has brought effective approaches and novel techniques to economic decision, investment forecasting, and risk management, etc., coping the variable and intricate nature of economic and financial environments. For the investment in stock market, this research introduces a pioneering quantitative fusion model combining stock timing and picking strategy by leveraging the Multivariate Gaussian-Hidden Markov Model (MGHMM) and Back Propagation Neural Network optimized by Particle Swarm (PSO-BPNN). After the information coefficients (IC) between fifty-two factors that have been winsorized, neutralized and standardized and the return of CSI 300 index are calculated, a given amount of factors that rank ahead are choose to be candidate factors heading for the input of PSO-BPNN after dimension reduction by Principal Component Analysis (PCA), followed by a certain amount of constituent stocks outputted. Subsequently, we conduct the prediction and trading on the basis of the screening stocks and stock market state outputted by MGHMM trained using inputting CSI 300 index data after Box-Cox transformation, bespeaking eximious performance during the period of past four years. Ultimately, some conventional forecast and trading methods are compared with our strategy in Chinese stock market. Our fusion strategy incorporating stock picking and timing presented in this article provide a innovative technique for financial analysis. ",
    "url": "https://arxiv.org/abs/2312.05756",
    "authors": [
      "Huajian Li",
      "Longjian Li",
      "Jiajian Liang",
      "Weinan Dai"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.05757",
    "title": "Towards Human-like Perception: Learning Structural Causal Model in  Heterogeneous Graph",
    "abstract": "Heterogeneous graph neural networks have become popular in various domains. However, their generalizability and interpretability are limited due to the discrepancy between their inherent inference flows and human reasoning logic or underlying causal relationships for the learning problem. This study introduces a novel solution, HG-SCM (Heterogeneous Graph as Structural Causal Model). It can mimic the human perception and decision process through two key steps: constructing intelligible variables based on semantics derived from the graph schema and automatically learning task-level causal relationships among these variables by incorporating advanced causal discovery techniques. We compared HG-SCM to seven state-of-the-art baseline models on three real-world datasets, under three distinct and ubiquitous out-of-distribution settings. HG-SCM achieved the highest average performance rank with minimal standard deviation, substantiating its effectiveness and superiority in terms of both predictive power and generalizability. Additionally, the visualization and analysis of the auto-learned causal diagrams for the three tasks aligned well with domain knowledge and human cognition, demonstrating prominent interpretability. HG-SCM's human-like nature and its enhanced generalizability and interpretability make it a promising solution for special scenarios where transparency and trustworthiness are paramount. ",
    "url": "https://arxiv.org/abs/2312.05757",
    "authors": [
      "Tianqianjin Lin",
      "Kaisong Song",
      "Zhuoren Jiang",
      "Yangyang Kang",
      "Weikang Yuan",
      "Xurui Li",
      "Changlong Sun",
      "Cui Huang",
      "Xiaozhong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.05762",
    "title": "Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning",
    "abstract": "Multiple defendants in a criminal fact description generally exhibit complex interactions, and cannot be well handled by existing Legal Judgment Prediction (LJP) methods which focus on predicting judgment results (e.g., law articles, charges, and terms of penalty) for single-defendant cases. To address this problem, we propose the task of multi-defendant LJP, which aims to automatically predict the judgment results for each defendant of multi-defendant cases. Two challenges arise with the task of multi-defendant LJP: (1) indistinguishable judgment results among various defendants; and (2) the lack of a real-world dataset for training and evaluation. To tackle the first challenge, we formalize the multi-defendant judgment process as hierarchical reasoning chains and introduce a multi-defendant LJP method, named Hierarchical Reasoning Network (HRN), which follows the hierarchical reasoning chains to determine criminal relationships, sentencing circumstances, law articles, charges, and terms of penalty for each defendant. To tackle the second challenge, we collect a real-world multi-defendant LJP dataset, namely MultiLJP, to accelerate the relevant research in the future. Extensive experiments on MultiLJP verify the effectiveness of our proposed HRN. ",
    "url": "https://arxiv.org/abs/2312.05762",
    "authors": [
      "Yougang Lyu",
      "Jitai Hao",
      "Zihan Wang",
      "Kai Zhao",
      "Shen Gao",
      "Pengjie Ren",
      "Zhumin Chen",
      "Fang Wang",
      "Zhaochun Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.05772",
    "title": "Context-Aware Code Generation Framework for Code Repositories: Local,  Global, and Third-Party Library Awareness",
    "abstract": "Code generation tools are essential to help developers in the software development process. Existing tools often disconnect with the working context, i.e., the code repository, causing the generated code to be not similar to human developers. In this paper, we propose a novel code generation framework, dubbed \\textbf{$A^3$}-CodGen, to harness information within the code repository to generate code with fewer logical errors, code redundancy, and library-related compatibility issues. We identify three categories of representative information for the code repository: local-aware information from current code file, global-aware information from other code files, and third-party-library information. Results demonstrate that by adopting the \\textbf{$A^3$}-CodGen framework, we successfully extract, fuse, and feed code repository information into the LLM, generating more accurate, efficient, and highly reusable code. The effectiveness of our framework is further underscored by generating code with a higher reuse rate, compared to human developers. This research contributes significantly to the field of code generation, providing developers with a more powerful tool to address the evolving demands in software development in practice. ",
    "url": "https://arxiv.org/abs/2312.05772",
    "authors": [
      "Dianshu Liao",
      "Shidong Pan",
      "Qing Huang",
      "Xiaoxue Ren",
      "Zhenchang Xing",
      "Huan Jin",
      "Qinying Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.05773",
    "title": "Explosive Legged Robotic Hopping: Energy Accumulation and Power  Amplification via Pneumatic Augmentation",
    "abstract": "We present a novel pneumatic augmentation to traditional electric motor-actuated legged robot to increase intermittent power density to perform infrequent explosive hopping behaviors. The pneumatic system is composed of a pneumatic pump, a tank, and a pneumatic actuator. The tank is charged up by the pump during regular hopping motion that is created by the electric motors. At any time after reaching a desired air pressure in the tank, a solenoid valve is utilized to rapidly release the air pressure to the pneumatic actuator (piston) which is used in conjunction with the electric motors to perform explosive hopping, increasing maximum hopping height for one or subsequent cycles. We show that, on a custom-designed one-legged hopping robot, without any additional power source and with this novel pneumatic augmentation system, their associated system identification and optimal control, the robot is able to realize highly explosive hopping with power amplification per cycle by a factor of approximately 5.4 times the power of electric motor actuation alone. ",
    "url": "https://arxiv.org/abs/2312.05773",
    "authors": [
      "Yifei Chen",
      "Arturo Gamboa-Gonzalez",
      "Michael Wehner",
      "Xiaobin Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.05780",
    "title": "PULSAR: Graph based Positive Unlabeled Learning with Multi Stream  Adaptive Convolutions for Parkinson's Disease Recognition",
    "abstract": "Parkinson's disease (PD) is a neuro-degenerative disorder that affects movement, speech, and coordination. Timely diagnosis and treatment can improve the quality of life for PD patients. However, access to clinical diagnosis is limited in low and middle income countries (LMICs). Therefore, development of automated screening tools for PD can have a huge social impact, particularly in the public health sector. In this paper, we present PULSAR, a novel method to screen for PD from webcam-recorded videos of the finger-tapping task from the Movement Disorder Society - Unified Parkinson's Disease Rating Scale (MDS-UPDRS). PULSAR is trained and evaluated on data collected from 382 participants (183 self-reported as PD patients). We used an adaptive graph convolutional neural network to dynamically learn the spatio temporal graph edges specific to the finger-tapping task. We enhanced this idea with a multi stream adaptive convolution model to learn features from different modalities of data critical to detect PD, such as relative location of the finger joints, velocity and acceleration of tapping. As the labels of the videos are self-reported, there could be cases of undiagnosed PD in the non-PD labeled samples. We leveraged the idea of Positive Unlabeled (PU) Learning that does not need labeled negative data. Our experiments show clear benefit of modeling the problem in this way. PULSAR achieved 80.95% accuracy in validation set and a mean accuracy of 71.29% (2.49% standard deviation) in independent test, despite being trained with limited amount of data. This is specially promising as labeled data is scarce in health care sector. We hope PULSAR will make PD screening more accessible to everyone. The proposed techniques could be extended for assessment of other movement disorders, such as ataxia, and Huntington's disease. ",
    "url": "https://arxiv.org/abs/2312.05780",
    "authors": [
      "Md. Zarif Ul Alam",
      "Md Saiful Islam",
      "Ehsan Hoque",
      "M Saifur Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05784",
    "title": "Graph-based Prediction and Planning Policy Network (GP3Net) for scalable  self-driving in dynamic environments using Deep Reinforcement Learning",
    "abstract": "Recent advancements in motion planning for Autonomous Vehicles (AVs) show great promise in using expert driver behaviors in non-stationary driving environments. However, learning only through expert drivers needs more generalizability to recover from domain shifts and near-failure scenarios due to the dynamic behavior of traffic participants and weather conditions. A deep Graph-based Prediction and Planning Policy Network (GP3Net) framework is proposed for non-stationary environments that encodes the interactions between traffic participants with contextual information and provides a decision for safe maneuver for AV. A spatio-temporal graph models the interactions between traffic participants for predicting the future trajectories of those participants. The predicted trajectories are utilized to generate a future occupancy map around the AV with uncertainties embedded to anticipate the evolving non-stationary driving environments. Then the contextual information and future occupancy maps are input to the policy network of the GP3Net framework and trained using Proximal Policy Optimization (PPO) algorithm. The proposed GP3Net performance is evaluated on standard CARLA benchmarking scenarios with domain shifts of traffic patterns (urban, highway, and mixed). The results show that the GP3Net outperforms previous state-of-the-art imitation learning-based planning models for different towns. Further, in unseen new weather conditions, GP3Net completes the desired route with fewer traffic infractions. Finally, the results emphasize the advantage of including the prediction module to enhance safety measures in non-stationary environments. ",
    "url": "https://arxiv.org/abs/2312.05784",
    "authors": [
      "Jayabrata Chowdhury",
      "Venkataramanan Shivaraman",
      "Suresh Sundaram",
      "P B Sujit"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.05790",
    "title": "SimPSI: A Simple Strategy to Preserve Spectral Information in Time  Series Data Augmentation",
    "abstract": "Data augmentation is a crucial component in training neural networks to overcome the limitation imposed by data size, and several techniques have been studied for time series. Although these techniques are effective in certain tasks, they have yet to be generalized to time series benchmarks. We find that current data augmentation techniques ruin the core information contained within the frequency domain. To address this issue, we propose a simple strategy to preserve spectral information (SimPSI) in time series data augmentation. SimPSI preserves the spectral information by mixing the original and augmented input spectrum weighted by a preservation map, which indicates the importance score of each frequency. Specifically, our experimental contributions are to build three distinct preservation maps: magnitude spectrum, saliency map, and spectrum-preservative map. We apply SimPSI to various time series data augmentations and evaluate its effectiveness across a wide range of time series benchmarks. Our experimental results support that SimPSI considerably enhances the performance of time series data augmentations by preserving core spectral information. The source code used in the paper is available at https://github.com/Hyun-Ryu/simpsi. ",
    "url": "https://arxiv.org/abs/2312.05790",
    "authors": [
      "Hyun Ryu",
      "Sunjae Yoon",
      "Hee Suk Yoon",
      "Eunseop Yoon",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.05798",
    "title": "Disentangled Representation Learning for Controllable Person Image  Generation",
    "abstract": "In this paper, we propose a novel framework named DRL-CPG to learn disentangled latent representation for controllable person image generation, which can produce realistic person images with desired poses and human attributes (e.g., pose, head, upper clothes, and pants) provided by various source persons. Unlike the existing works leveraging the semantic masks to obtain the representation of each component, we propose to generate disentangled latent code via a novel attribute encoder with transformers trained in a manner of curriculum learning from a relatively easy step to a gradually hard one. A random component mask-agnostic strategy is introduced to randomly remove component masks from the person segmentation masks, which aims at increasing the difficulty of training and promoting the transformer encoder to recognize the underlying boundaries between each component. This enables the model to transfer both the shape and texture of the components. Furthermore, we propose a novel attribute decoder network to integrate multi-level attributes (e.g., the structure feature and the attribute representation) with well-designed Dual Adaptive Denormalization (DAD) residual blocks. Extensive experiments strongly demonstrate that the proposed approach is able to transfer both the texture and shape of different human parts and yield realistic results. To our knowledge, we are the first to learn disentangled latent representations with transformers for person image generation. ",
    "url": "https://arxiv.org/abs/2312.05798",
    "authors": [
      "Wenju Xu",
      "Chengjiang Long",
      "Yongwei Nie",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05799",
    "title": "SGNet: Structure Guided Network via Gradient-Frequency Awareness for  Depth Map Super-Resolution",
    "abstract": "Depth super-resolution (DSR) aims to restore high-resolution (HR) depth from low-resolution (LR) one, where RGB image is often used to promote this task. Recent image guided DSR approaches mainly focus on spatial domain to rebuild depth structure. However, since the structure of LR depth is usually blurry, only considering spatial domain is not very sufficient to acquire satisfactory results. In this paper, we propose structure guided network (SGNet), a method that pays more attention to gradient and frequency domains, both of which have the inherent ability to capture high-frequency structure. Specifically, we first introduce the gradient calibration module (GCM), which employs the accurate gradient prior of RGB to sharpen the LR depth structure. Then we present the Frequency Awareness Module (FAM) that recursively conducts multiple spectrum differencing blocks (SDB), each of which propagates the precise high-frequency components of RGB into the LR depth. Extensive experimental results on both real and synthetic datasets demonstrate the superiority of our SGNet, reaching the state-of-the-art. Codes and pre-trained models are available at https://github.com/yanzq95/SGNet. ",
    "url": "https://arxiv.org/abs/2312.05799",
    "authors": [
      "Zhengxu Wang",
      "Zhiqiang Yan",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05814",
    "title": "Neural Speech Embeddings for Speech Synthesis Based on Deep Generative  Networks",
    "abstract": "Brain-to-speech technology represents a fusion of interdisciplinary applications encompassing fields of artificial intelligence, brain-computer interfaces, and speech synthesis. Neural representation learning based intention decoding and speech synthesis directly connects the neural activity to the means of human linguistic communication, which may greatly enhance the naturalness of communication. With the current discoveries on representation learning and the development of the speech synthesis technologies, direct translation of brain signals into speech has shown great promise. Especially, the processed input features and neural speech embeddings which are given to the neural network play a significant role in the overall performance when using deep generative models for speech generation from brain signals. In this paper, we introduce the current brain-to-speech technology with the possibility of speech synthesis from brain signals, which may ultimately facilitate innovation in non-verbal communication. Also, we perform comprehensive analysis on the neural features and neural speech embeddings underlying the neurophysiological activation while performing speech, which may play a significant role in the speech synthesis works. ",
    "url": "https://arxiv.org/abs/2312.05814",
    "authors": [
      "Seo-Hyun Lee",
      "Young-Eun Lee",
      "Soowon Kim",
      "Byung-Kwan Ko",
      "Jun-Young Kim",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.05815",
    "title": "Voice Activity Detection (VAD) in Noisy Environments",
    "abstract": "In the realm of digital audio processing, Voice Activity Detection (VAD) plays a pivotal role in distinguishing speech from non-speech elements, a task that becomes increasingly complex in noisy environments. This paper details the development and implementation of a VAD system, specifically engineered to maintain high accuracy in the presence of various ambient noises. We introduce a novel algorithm enhanced with a specially designed filtering technique, effectively isolating speech even amidst diverse background sounds. Our comprehensive testing and validation demonstrate the system's robustness, highlighting its capability to discern speech from noise with remarkable precision. The exploration delves into: (1) the core principles underpinning VAD and its crucial role in modern audio processing; (2) the methodologies we employed to filter ambient noise; and (3) a presentation of evidence affirming our system's superior performance in noisy conditions. ",
    "url": "https://arxiv.org/abs/2312.05815",
    "authors": [
      "Joshua Ball"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.05818",
    "title": "ICTSurF: Implicit Continuous-Time Survival Functions with Neural  Networks",
    "abstract": "Survival analysis is a widely known method for predicting the likelihood of an event over time. The challenge of dealing with censored samples still remains. Traditional methods, such as the Cox Proportional Hazards (CPH) model, hinge on the limitations due to the strong assumptions of proportional hazards and the predetermined relationships between covariates. The rise of models based on deep neural networks (DNNs) has demonstrated enhanced effectiveness in survival analysis. This research introduces the Implicit Continuous-Time Survival Function (ICTSurF), built on a continuous-time survival model, and constructs survival distribution through implicit representation. As a result, our method is capable of accepting inputs in continuous-time space and producing survival probabilities in continuous-time space, independent of neural network architecture. Comparative assessments with existing methods underscore the high competitiveness of our proposed approach. Our implementation of ICTSurF is available at https://github.com/44REAM/ICTSurF. ",
    "url": "https://arxiv.org/abs/2312.05818",
    "authors": [
      "Chanon Puttanawarut",
      "Panu Looareesuwan",
      "Romen Samuel Wabina",
      "Prut Saowaprut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05828",
    "title": "Sparse Multitask Learning for Efficient Neural Representation of Motor  Imagery and Execution",
    "abstract": "In the quest for efficient neural network models for neural data interpretation and user intent classification in brain-computer interfaces (BCIs), learning meaningful sparse representations of the underlying neural subspaces is crucial. The present study introduces a sparse multitask learning framework for motor imagery (MI) and motor execution (ME) tasks, inspired by the natural partitioning of associated neural subspaces observed in the human brain. Given a dual-task CNN model for MI-ME classification, we apply a saliency-based sparsification approach to prune superfluous connections and reinforce those that show high importance in both tasks. Through our approach, we seek to elucidate the distinct and common neural ensembles associated with each task, employing principled sparsification techniques to eliminate redundant connections and boost the fidelity of neural signal decoding. Our results indicate that this tailored sparsity can mitigate the overfitting problem and improve the test performance with small amount of data, suggesting a viable path forward for computationally efficient and robust BCI systems. ",
    "url": "https://arxiv.org/abs/2312.05828",
    "authors": [
      "Hye-Bin Shin",
      "Kang Yin",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.05832",
    "title": "Spatial-wise Dynamic Distillation for MLP-like Efficient Visual Fault  Detection of Freight Trains",
    "abstract": "Despite the successful application of convolutional neural networks (CNNs) in object detection tasks, their efficiency in detecting faults from freight train images remains inadequate for implementation in real-world engineering scenarios. Existing modeling shortcomings of spatial invariance and pooling layers in conventional CNNs often ignore the neglect of crucial global information, resulting in error localization for fault objection tasks of freight trains. To solve these problems, we design a spatial-wise dynamic distillation framework based on multi-layer perceptron (MLP) for visual fault detection of freight trains. We initially present the axial shift strategy, which allows the MLP-like architecture to overcome the challenge of spatial invariance and effectively incorporate both local and global cues. We propose a dynamic distillation method without a pre-training teacher, including a dynamic teacher mechanism that can effectively eliminate the semantic discrepancy with the student model. Such an approach mines more abundant details from lower-level feature appearances and higher-level label semantics as the extra supervision signal, which utilizes efficient instance embedding to model the global spatial and semantic information. In addition, the proposed dynamic teacher can jointly train with students to further enhance the distillation efficiency. Extensive experiments executed on six typical fault datasets reveal that our approach outperforms the current state-of-the-art detectors and achieves the highest accuracy with real-time detection at a lower computational cost. The source code will be available at \\url{https://github.com/MVME-HBUT/SDD-FTI-FDet}. ",
    "url": "https://arxiv.org/abs/2312.05832",
    "authors": [
      "Yang Zhang",
      "Huilin Pan",
      "Mingying Li",
      "An Wang",
      "Yang Zhou",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2312.05833",
    "title": "Data-Driven Robust Covariance Control for Uncertain Linear Systems",
    "abstract": "The theory of covariance control and covariance steering (CS) deals with controlling the dispersion of trajectories of a dynamical system, under the implicit assumption that accurate prior knowledge of the system being controlled is available. In this work, we consider the problem of steering the distribution of a discrete-time, linear system subject to exogenous disturbances under an unknown dynamics model. Leveraging concepts from behavioral systems theory, the trajectories of this unknown, noisy system may be (approximately) represented using system data collected through experimentation. Using this fact, we formulate a direct data-driven covariance control problem using input-state data. We then propose a maximum likelihood uncertainty quantification method to estimate and bound the noise realizations in the data collection process. Lastly, we utilize robust convex optimization techniques to solve the resulting norm-bounded uncertain convex program. We illustrate the proposed end-to-end data-driven CS algorithm on a double integrator example and showcase the efficacy and accuracy of the proposed method compared to that of model-based methods ",
    "url": "https://arxiv.org/abs/2312.05833",
    "authors": [
      "Joshua Pilipovsky",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2312.05840",
    "title": "Topological Data Analysis for Neural Network Analysis: A Comprehensive  Survey",
    "abstract": "This survey provides a comprehensive exploration of applications of Topological Data Analysis (TDA) within neural network analysis. Using TDA tools such as persistent homology and Mapper, we delve into the intricate structures and behaviors of neural networks and their datasets. We discuss different strategies to obtain topological information from data and neural networks by means of TDA. Additionally, we review how topological information can be leveraged to analyze properties of neural networks, such as their generalization capacity or expressivity. We explore practical implications of deep learning, specifically focusing on areas like adversarial detection and model selection. Our survey organizes the examined works into four broad domains: 1. Characterization of neural network architectures; 2. Analysis of decision regions and boundaries; 3. Study of internal representations, activations, and parameters; 4. Exploration of training dynamics and loss functions. Within each category, we discuss several articles, offering background information to aid in understanding the various methodologies. We conclude with a synthesis of key insights gained from our study, accompanied by a discussion of challenges and potential advancements in the field. ",
    "url": "https://arxiv.org/abs/2312.05840",
    "authors": [
      "Rub\u00e9n Ballester",
      "Carles Casacuberta",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2312.05855",
    "title": "NeVRF: Neural Video-based Radiance Fields for Long-duration Sequences",
    "abstract": "Adopting Neural Radiance Fields (NeRF) to long-duration dynamic sequences has been challenging. Existing methods struggle to balance between quality and storage size and encounter difficulties with complex scene changes such as topological changes and large motions. To tackle these issues, we propose a novel neural video-based radiance fields (NeVRF) representation. NeVRF marries neural radiance field with image-based rendering to support photo-realistic novel view synthesis on long-duration dynamic inward-looking scenes. We introduce a novel multi-view radiance blending approach to predict radiance directly from multi-view videos. By incorporating continual learning techniques, NeVRF can efficiently reconstruct frames from sequential data without revisiting previous frames, enabling long-duration free-viewpoint video. Furthermore, with a tailored compression approach, NeVRF can compactly represent dynamic scenes, making dynamic radiance fields more practical in real-world scenarios. Our extensive experiments demonstrate the effectiveness of NeVRF in enabling long-duration sequence rendering, sequential data reconstruction, and compact data storage. ",
    "url": "https://arxiv.org/abs/2312.05855",
    "authors": [
      "Minye Wu",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05864",
    "title": "Finding Concept Representations in Neural Networks with Self-Organizing  Maps",
    "abstract": "In sufficiently complex tasks, it is expected that as a side effect of learning to solve a problem, a neural network will learn relevant abstractions of the representation of that problem. This has been confirmed in particular in machine vision where a number of works showed that correlations could be found between the activations of specific units (neurons) in a neural network and the visual concepts (textures, colors, objects) present in the image. Here, we explore the use of self-organizing maps as a way to both visually and computationally inspect how activation vectors of whole layers of neural networks correspond to neural representations of abstract concepts such as `female person' or `realist painter'. We experiment with multiple measures applied to those maps to assess the level of representation of a concept in a network's layer. We show that, among the measures tested, the relative entropy of the activation map for a concept compared to the map for the whole data is a suitable candidate and can be used as part of a methodology to identify and locate the neural representation of a concept, visualize it, and understand its importance in solving the prediction task at hand. ",
    "url": "https://arxiv.org/abs/2312.05864",
    "authors": [
      "Mathieu d'Aquin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05875",
    "title": "Class-Aware Pruning for Efficient Neural Networks",
    "abstract": "Deep neural networks (DNNs) have demonstrated remarkable success in various fields. However, the large number of floating-point operations (FLOPs) in DNNs poses challenges for their deployment in resource-constrained applications, e.g., edge devices. To address the problem, pruning has been introduced to reduce the computational cost in executing DNNs. Previous pruning strategies are based on weight values, gradient values and activation outputs. Different from previous pruning solutions, in this paper, we propose a class-aware pruning technique to compress DNNs, which provides a novel perspective to reduce the computational cost of DNNs. In each iteration, the neural network training is modified to facilitate the class-aware pruning. Afterwards, the importance of filters with respect to the number of classes is evaluated. The filters that are only important for a few number of classes are removed. The neural network is then retrained to compensate for the incurred accuracy loss. The pruning iterations end until no filter can be removed anymore, indicating that the remaining filters are very important for many classes. This pruning technique outperforms previous pruning solutions in terms of accuracy, pruning ratio and the reduction of FLOPs. Experimental results confirm that this class-aware pruning technique can significantly reduce the number of weights and FLOPs, while maintaining a high inference accuracy. ",
    "url": "https://arxiv.org/abs/2312.05875",
    "authors": [
      "Mengnan Jiang",
      "Jingcun Wang",
      "Amro Eldebiky",
      "Xunzhao Yin",
      "Cheng Zhuo",
      "Ing-Chao Lin",
      "Grace Li Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05891",
    "title": "A conservative hybrid physics-informed neural network method for  Maxwell-Amp\u00e8re-Nernst-Planck equations",
    "abstract": "Maxwell-Amp\\`{e}re-Nernst-Planck (MANP) equations were recently proposed to model the dynamics of charged particles. In this study, we enhance a numerical algorithm of this system with deep learning tools. The proposed hybrid algorithm provides an automated means to determine a proper approximation for the dummy variables, which can otherwise only be obtained through massive numerical tests. In addition, the original method is validated for 2-dimensional problems. However, when the spatial dimension is one, the original curl-free relaxation component is inapplicable, and the approximation formula for dummy variables, which works well in a 2-dimensional scenario, fails to provide a reasonable output in the 1-dimensional case. The proposed method can be readily generalised to cases with one spatial dimension. Experiments show numerical stability and good convergence to the steady-state solution obtained from Poisson-Boltzmann type equations in the 1-dimensional case. The experiments conducted in the 2-dimensional case indicate that the proposed method preserves the conservation properties. ",
    "url": "https://arxiv.org/abs/2312.05891",
    "authors": [
      "Cheng Chang",
      "Zhouping Xin",
      "Tieyong Zeng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05907",
    "title": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for  Near-Infrared Facial Expression Recognition",
    "abstract": "With the strong robusticity on illumination variations, near-infrared (NIR) can be an effective and essential complement to visible (VIS) facial expression recognition in low lighting or complete darkness conditions. However, facial expression recognition (FER) from NIR images presents more challenging problem than traditional FER due to the limitations imposed by the data scale and the difficulty of extracting discriminative features from incomplete visible lighting contents. In this paper, we give the first attempt to deep NIR facial expression recognition and proposed a novel method called near-infrared facial expression transformer (NFER-Former). Specifically, to make full use of the abundant label information in the field of VIS, we introduce a Self-Attention Orthogonal Decomposition mechanism that disentangles the expression information and spectrum information from the input image, so that the expression features can be extracted without the interference of spectrum variation. We also propose a Hypergraph-Guided Feature Embedding method that models some key facial behaviors and learns the structure of the complex correlations between them, thereby alleviating the interference of inter-class similarity. Additionally, we have constructed a large NIR-VIS Facial Expression dataset that includes 360 subjects to better validate the efficiency of NFER-Former. Extensive experiments and ablation studies show that NFER-Former significantly improves the performance of NIR FER and achieves state-of-the-art results on the only two available NIR FER datasets, Oulu-CASIA and Large-HFE. ",
    "url": "https://arxiv.org/abs/2312.05907",
    "authors": [
      "Bingjun Luo",
      "Haowen Wang",
      "Jinpeng Wang",
      "Junjie Zhu",
      "Xibin Zhao",
      "Yue Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2312.05920",
    "title": "Local Randomized Neural Networks with Hybridized Discontinuous  Petrov-Galerkin Methods for Stokes-Darcy Flows",
    "abstract": "This paper introduces a new numerical approach that integrates local randomized neural networks (LRNNs) and the hybridized discontinuous Petrov-Galerkin (HDPG) method for solving coupled fluid flow problems. The proposed method partitions the domain of interest into several subdomains and constructs an LRNN on each subdomain. Then, the HDPG scheme is used to couple the LRNNs to approximate the unknown functions. We develop LRNN-HDPG methods based on velocity-stress formulation to solve two types of problems: Stokes-Darcy problems and Brinkman equations, which model the flow in porous media and free flow. We devise a simple and effective way to deal with the interface conditions in the Stokes-Darcy problems without adding extra terms to the numerical scheme. We conduct extensive numerical experiments to demonstrate the stability, efficiency, and robustness of the proposed method. The numerical results show that the LRNN-HDPG method can achieve high accuracy with a small number of degrees of freedom. ",
    "url": "https://arxiv.org/abs/2312.05920",
    "authors": [
      "Haoning Dang",
      "Fei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.05924",
    "title": "Data-Free Hard-Label Robustness Stealing Attack",
    "abstract": "The popularity of Machine Learning as a Service (MLaaS) has led to increased concerns about Model Stealing Attacks (MSA), which aim to craft a clone model by querying MLaaS. Currently, most research on MSA assumes that MLaaS can provide soft labels and that the attacker has a proxy dataset with a similar distribution. However, this fails to encapsulate the more practical scenario where only hard labels are returned by MLaaS and the data distribution remains elusive. Furthermore, most existing work focuses solely on stealing the model accuracy, neglecting the model robustness, while robustness is essential in security-sensitive scenarios, e.g., face-scan payment. Notably, improving model robustness often necessitates the use of expensive techniques such as adversarial training, thereby further making stealing robustness a more lucrative prospect. In response to these identified gaps, we introduce a novel Data-Free Hard-Label Robustness Stealing (DFHL-RS) attack in this paper, which enables the stealing of both model accuracy and robustness by simply querying hard labels of the target model without the help of any natural data. Comprehensive experiments demonstrate the effectiveness of our method. The clone model achieves a clean accuracy of 77.86% and a robust accuracy of 39.51% against AutoAttack, which are only 4.71% and 8.40% lower than the target model on the CIFAR-10 dataset, significantly exceeding the baselines. Our code is available at: https://github.com/LetheSec/DFHL-RS-Attack ",
    "url": "https://arxiv.org/abs/2312.05924",
    "authors": [
      "Xiaojian Yuan",
      "Kejiang Chen",
      "Wen Huang",
      "Jie Zhang",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05928",
    "title": "AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer",
    "abstract": "Neural style transfer (NST) has evolved significantly in recent years. Yet, despite its rapid progress and advancement, existing NST methods either struggle to transfer aesthetic information from a style effectively or suffer from high computational costs and inefficiencies in feature disentanglement due to using pre-trained models. This work proposes a lightweight but effective model, AesFA -- Aesthetic Feature-Aware NST. The primary idea is to decompose the image via its frequencies to better disentangle aesthetic styles from the reference image while training the entire model in an end-to-end manner to exclude pre-trained models at inference completely. To improve the network's ability to extract more distinct representations and further enhance the stylization quality, this work introduces a new aesthetic feature: contrastive loss. Extensive experiments and ablations show the approach not only outperforms recent NST methods in terms of stylization quality, but it also achieves faster inference. Codes are available at https://github.com/Sooyyoungg/AesFA. ",
    "url": "https://arxiv.org/abs/2312.05928",
    "authors": [
      "Joonwoo Kwon",
      "Sooyoung Kim",
      "Yuewei Lin",
      "Shinjae Yoo",
      "Jiook Cha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05946",
    "title": "Uncertainty Propagation through Trained Deep Neural Networks Using  Factor Graphs",
    "abstract": "Predictive uncertainty estimation remains a challenging problem precluding the use of deep neural networks as subsystems within safety-critical applications. Aleatoric uncertainty is a component of predictive uncertainty that cannot be reduced through model improvements. Uncertainty propagation seeks to estimate aleatoric uncertainty by propagating input uncertainties to network predictions. Existing uncertainty propagation techniques use one-way information flows, propagating uncertainties layer-by-layer or across the entire neural network while relying either on sampling or analytical techniques for propagation. Motivated by the complex information flows within deep neural networks (e.g. skip connections), we developed and evaluated a novel approach by posing uncertainty propagation as a non-linear optimization problem using factor graphs. We observed statistically significant improvements in performance over prior work when using factor graphs across most of our experiments that included three datasets and two neural network architectures. Our implementation balances the benefits of sampling and analytical propagation techniques, which we believe, is a key factor in achieving performance improvements. ",
    "url": "https://arxiv.org/abs/2312.05946",
    "authors": [
      "Angel Daruna",
      "Yunye Gong",
      "Abhinav Rajvanshi",
      "Han-Pang Chiu",
      "Yi Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05959",
    "title": "VAE-IF: Deep feature extraction with averaging for unsupervised artifact  detection in routine acquired ICU time-series",
    "abstract": "Artifacts are a common problem in physiological time-series data collected from intensive care units (ICU) and other settings. They affect the quality and reliability of clinical research and patient care. Manual annotation of artifacts is costly and time-consuming, rendering it impractical. Automated methods are desired. Here, we propose a novel unsupervised approach to detect artifacts in clinical-standard minute-by-minute resolution ICU data without any prior labeling or signal-specific knowledge. Our approach combines a variational autoencoder (VAE) and an isolation forest (iForest) model to learn features and identify anomalies in different types of vital signs, such as blood pressure, heart rate, and intracranial pressure. We evaluate our approach on a real-world ICU dataset and compare it with supervised models based on long short-term memory (LSTM) and XGBoost. We show that our approach achieves comparable sensitivity and generalizes well to an external dataset. We also visualize the latent space learned by the VAE and demonstrate its ability to disentangle clean and noisy samples. Our approach offers a promising solution for cleaning ICU data in clinical research and practice without the need for any labels whatsoever. ",
    "url": "https://arxiv.org/abs/2312.05959",
    "authors": [
      "Hollan Haule",
      "Ian Piper",
      "Patricia Jones",
      "Chen Qin",
      "Tsz-Yan Milly Lo",
      "Javier Escudero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.05961",
    "title": "TransGlow: Attention-augmented Transduction model based on Graph Neural  Networks for Water Flow Forecasting",
    "abstract": "The hydrometric prediction of water quantity is useful for a variety of applications, including water management, flood forecasting, and flood control. However, the task is difficult due to the dynamic nature and limited data of water systems. Highly interconnected water systems can significantly affect hydrometric forecasting. Consequently, it is crucial to develop models that represent the relationships between other system components. In recent years, numerous hydrological applications have been studied, including streamflow prediction, flood forecasting, and water quality prediction. Existing methods are unable to model the influence of adjacent regions between pairs of variables. In this paper, we propose a spatiotemporal forecasting model that augments the hidden state in Graph Convolution Recurrent Neural Network (GCRN) encoder-decoder using an efficient version of the attention mechanism. The attention layer allows the decoder to access different parts of the input sequence selectively. Since water systems are interconnected and the connectivity information between the stations is implicit, the proposed model leverages a graph learning module to extract a sparse graph adjacency matrix adaptively based on the data. Spatiotemporal forecasting relies on historical data. In some regions, however, historical data may be limited or incomplete, making it difficult to accurately predict future water conditions. Further, we present a new benchmark dataset of water flow from a network of Canadian stations on rivers, streams, and lakes. Experimental results demonstrate that our proposed model TransGlow significantly outperforms baseline methods by a wide margin. ",
    "url": "https://arxiv.org/abs/2312.05961",
    "authors": [
      "Naghmeh Shafiee Roudbari",
      "Charalambos Poullis",
      "Zachary Patterson",
      "Ursula Eicker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05974",
    "title": "Learning the Causal Structure of Networked Dynamical Systems under  Latent Nodes and Structured Noise",
    "abstract": "This paper considers learning the hidden causal network of a linear networked dynamical system (NDS) from the time series data at some of its nodes -- partial observability. The dynamics of the NDS are driven by colored noise that generates spurious associations across pairs of nodes, rendering the problem much harder. To address the challenge of noise correlation and partial observability, we assign to each pair of nodes a feature vector computed from the time series data of observed nodes. The feature embedding is engineered to yield structural consistency: there exists an affine hyperplane that consistently partitions the set of features, separating the feature vectors corresponding to connected pairs of nodes from those corresponding to disconnected pairs. The causal inference problem is thus addressed via clustering the designed features. We demonstrate with simple baseline supervised methods the competitive performance of the proposed causal inference mechanism under broad connectivity regimes and noise correlation levels, including a real world network. Further, we devise novel technical guarantees of structural consistency for linear NDS under the considered regime. ",
    "url": "https://arxiv.org/abs/2312.05974",
    "authors": [
      "Augusto Santos",
      "Diogo Rente",
      "Rui Seabra",
      "Jos\u00e9 M. F. Moura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.05976",
    "title": "A Representative Study on Human Detection of Artificially Generated  Media Across Countries",
    "abstract": "AI-generated media has become a threat to our digital society as we know it. These forgeries can be created automatically and on a large scale based on publicly available technology. Recognizing this challenge, academics and practitioners have proposed a multitude of automatic detection strategies to detect such artificial media. However, in contrast to these technical advances, the human perception of generated media has not been thoroughly studied yet. In this paper, we aim at closing this research gap. We perform the first comprehensive survey into people's ability to detect generated media, spanning three countries (USA, Germany, and China) with 3,002 participants across audio, image, and text media. Our results indicate that state-of-the-art forgeries are almost indistinguishable from \"real\" media, with the majority of participants simply guessing when asked to rate them as human- or machine-generated. In addition, AI-generated media receive is voted more human like across all media types and all countries. To further understand which factors influence people's ability to detect generated media, we include personal variables, chosen based on a literature review in the domains of deepfake and fake news research. In a regression analysis, we found that generalized trust, cognitive reflection, and self-reported familiarity with deepfakes significantly influence participant's decision across all media categories. ",
    "url": "https://arxiv.org/abs/2312.05976",
    "authors": [
      "Joel Frank",
      "Franziska Herbert",
      "Jonas Ricker",
      "Lea Sch\u00f6nherr",
      "Thorsten Eisenhofer",
      "Asja Fischer",
      "Markus D\u00fcrmuth",
      "Thorsten Holz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05978",
    "title": "Neural Architecture Codesign for Fast Bragg Peak Analysis",
    "abstract": "We develop an automated pipeline to streamline neural architecture codesign for fast, real-time Bragg peak analysis in high-energy diffraction microscopy. Traditional approaches, notably pseudo-Voigt fitting, demand significant computational resources, prompting interest in deep learning models for more efficient solutions. Our method employs neural architecture search and AutoML to enhance these models, including hardware costs, leading to the discovery of more hardware-efficient neural architectures. Our results match the performance, while achieving a 13$\\times$ reduction in bit operations compared to the previous state-of-the-art. We show further speedup through model compression techniques such as quantization-aware-training and neural network pruning. Additionally, our hierarchical search space provides greater flexibility in optimization, which can easily extend to other tasks and domains. ",
    "url": "https://arxiv.org/abs/2312.05978",
    "authors": [
      "Luke McDermott",
      "Jason Weitz",
      "Dmitri Demler",
      "Daniel Cummings",
      "Nhan Tran",
      "Javier Duarte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05984",
    "title": "Accurate Differential Operators for Hybrid Neural Fields",
    "abstract": "Neural fields have become widely used in various fields, from shape representation to neural rendering, and for solving partial differential equations (PDEs). With the advent of hybrid neural field representations like Instant NGP that leverage small MLPs and explicit representations, these models train quickly and can fit large scenes. Yet in many applications like rendering and simulation, hybrid neural fields can cause noticeable and unreasonable artifacts. This is because they do not yield accurate spatial derivatives needed for these downstream applications. In this work, we propose two ways to circumvent these challenges. Our first approach is a post hoc operator that uses local polynomial-fitting to obtain more accurate derivatives from pre-trained hybrid neural fields. Additionally, we also propose a self-supervised fine-tuning approach that refines the neural field to yield accurate derivatives directly while preserving the initial signal. We show the application of our method on rendering, collision simulation, and solving PDEs. We observe that using our approach yields more accurate derivatives, reducing artifacts and leading to more accurate simulations in downstream applications. ",
    "url": "https://arxiv.org/abs/2312.05984",
    "authors": [
      "Aditya Chetan",
      "Guandao Yang",
      "Zichen Wang",
      "Steve Marschner",
      "Bharath Hariharan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05994",
    "title": "mir_ref: A Representation Evaluation Framework for Music Information  Retrieval Tasks",
    "abstract": "Music Information Retrieval (MIR) research is increasingly leveraging representation learning to obtain more compact, powerful music audio representations for various downstream MIR tasks. However, current representation evaluation methods are fragmented due to discrepancies in audio and label preprocessing, downstream model and metric implementations, data availability, and computational resources, often leading to inconsistent and limited results. In this work, we introduce mir_ref, an MIR Representation Evaluation Framework focused on seamless, transparent, local-first experiment orchestration to support representation development. It features implementations of a variety of components such as MIR datasets, tasks, embedding models, and tools for result analysis and visualization, while facilitating the implementation of custom components. To demonstrate its utility, we use it to conduct an extensive evaluation of several embedding models across various tasks and datasets, including evaluating their robustness to various audio perturbations and the ease of extracting relevant information from them. ",
    "url": "https://arxiv.org/abs/2312.05994",
    "authors": [
      "Christos Plachouras",
      "Pablo Alonson-Jim\u00e9nez",
      "Dmitry Bogdanov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.06021",
    "title": "GenDepth: Generalizing Monocular Depth Estimation for Arbitrary Camera  Parameters via Ground Plane Embedding",
    "abstract": "Learning-based monocular depth estimation leverages geometric priors present in the training data to enable metric depth perception from a single image, a traditionally ill-posed problem. However, these priors are often specific to a particular domain, leading to limited generalization performance on unseen data. Apart from the well studied environmental domain gap, monocular depth estimation is also sensitive to the domain gap induced by varying camera parameters, an aspect that is often overlooked in current state-of-the-art approaches. This issue is particularly evident in autonomous driving scenarios, where datasets are typically collected with a single vehicle-camera setup, leading to a bias in the training data due to a fixed perspective geometry. In this paper, we challenge this trend and introduce GenDepth, a novel model capable of performing metric depth estimation for arbitrary vehicle-camera setups. To address the lack of data with sufficiently diverse camera parameters, we first create a bespoke synthetic dataset collected with different vehicle-camera systems. Then, we design GenDepth to simultaneously optimize two objectives: (i) equivariance to the camera parameter variations on synthetic data, (ii) transferring the learned equivariance to real-world environmental features using a single real-world dataset with a fixed vehicle-camera system. To achieve this, we propose a novel embedding of camera parameters as the ground plane depth and present a novel architecture that integrates these embeddings with adversarial domain alignment. We validate GenDepth on several autonomous driving datasets, demonstrating its state-of-the-art generalization capability for different vehicle-camera systems. ",
    "url": "https://arxiv.org/abs/2312.06021",
    "authors": [
      "Karlo Koledi\u0107",
      "Luka Petrovi\u0107",
      "Ivan Petrovi\u0107",
      "Ivan Markovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.06022",
    "title": "Exploiting Representation Bias for Data Distillation in Abstractive Text  Summarization",
    "abstract": "Abstractive text summarization is surging with the number of training samples to cater to the needs of the deep learning models. These models tend to exploit the training data representations to attain superior performance by improving the quantitative element of the resultant summary. However, increasing the size of the training set may not always be the ideal solution to maximize the performance, and therefore, a need to revisit the quality of training samples and the learning protocol of deep learning models is a must. In this paper, we aim to discretize the vector space of the abstractive text summarization models to understand the characteristics learned between the input embedding space and the models' encoder space. We show that deep models fail to capture the diversity of the input space. Further, the distribution of data points on the encoder space indicates that an unchecked increase in the training samples does not add value; rather, a tear-down of data samples is highly needed to make the models focus on variability and faithfulness. We employ clustering techniques to learn the diversity of a model's sample space and how data points are mapped from the embedding space to the encoder space and vice versa. Further, we devise a metric to filter out redundant data points to make the model more robust and less data hungry. We benchmark our proposed method using quantitative metrics, such as Rouge, and qualitative metrics, such as BERTScore, FEQA and Pyramid score. We also quantify the reasons that inhibit the models from learning the diversity from the varied input samples. ",
    "url": "https://arxiv.org/abs/2312.06022",
    "authors": [
      "Yash Kumar Atri",
      "Vikram Goyal",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.06034",
    "title": "Modeling Uncertainty in Personalized Emotion Prediction with Normalizing  Flows",
    "abstract": "Designing predictive models for subjective problems in natural language processing (NLP) remains challenging. This is mainly due to its non-deterministic nature and different perceptions of the content by different humans. It may be solved by Personalized Natural Language Processing (PNLP), where the model exploits additional information about the reader to make more accurate predictions. However, current approaches require complete information about the recipients to be straight embedded. Besides, the recent methods focus on deterministic inference or simple frequency-based estimations of the probabilities. In this work, we overcome this limitation by proposing a novel approach to capture the uncertainty of the forecast using conditional Normalizing Flows. This allows us to model complex multimodal distributions and to compare various models using negative log-likelihood (NLL). In addition, the new solution allows for various interpretations of possible reader perception thanks to the available sampling function. We validated our method on three challenging, subjective NLP tasks, including emotion recognition and hate speech. The comparative analysis of generalized and personalized approaches revealed that our personalized solutions significantly outperform the baseline and provide more precise uncertainty estimates. The impact on the text interpretability and uncertainty studies are presented as well. The information brought by the developed methods makes it possible to build hybrid models whose effectiveness surpasses classic solutions. In addition, an analysis and visualization of the probabilities of the given decisions for texts with high entropy of annotations and annotators with mixed views were carried out. ",
    "url": "https://arxiv.org/abs/2312.06034",
    "authors": [
      "Piotr Mi\u0142kowski",
      "Konrad Karanowski",
      "Patryk Wielopolski",
      "Jan Koco\u0144",
      "Przemys\u0142aw Kazienko",
      "Maciej Zi\u0119ba"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06053",
    "title": "IEKG: A Commonsense Knowledge Graph for Idiomatic Expressions",
    "abstract": "Idiomatic expression (IE) processing and comprehension have challenged pre-trained language models (PTLMs) because their meanings are non-compositional. Unlike prior works that enable IE comprehension through fine-tuning PTLMs with sentences containing IEs, in this work, we construct IEKG, a commonsense knowledge graph for figurative interpretations of IEs. This extends the established ATOMIC2020 graph, converting PTLMs into knowledge models (KMs) that encode and infer commonsense knowledge related to IE use. Experiments show that various PTLMs can be converted into KMs with IEKG. We verify the quality of IEKG and the ability of the trained KMs with automatic and human evaluation. Through applications in natural language understanding, we show that a PTLM injected with knowledge from IEKG exhibits improved IE comprehension ability and can generalize to IEs unseen during training. ",
    "url": "https://arxiv.org/abs/2312.06053",
    "authors": [
      "Ziheng Zeng",
      "Kellen Tan Cheng",
      "Srihari Venkat Nanniyur",
      "Jianing Zhou",
      "Suma Bhat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06068",
    "title": "Contrastive Multi-view Subspace Clustering of Hyperspectral Images based  on Graph Convolutional Networks",
    "abstract": "High-dimensional and complex spectral structures make the clustering of hyperspectral images (HSI) a challenging task. Subspace clustering is an effective approach for addressing this problem. However, current subspace clustering algorithms are primarily designed for a single view and do not fully exploit the spatial or textural feature information in HSI. In this study, contrastive multi-view subspace clustering of HSI was proposed based on graph convolutional networks. Pixel neighbor textural and spatial-spectral information were sent to construct two graph convolutional subspaces to learn their affinity matrices. To maximize the interaction between different views, a contrastive learning algorithm was introduced to promote the consistency of positive samples and assist the model in extracting robust features. An attention-based fusion module was used to adaptively integrate these affinity matrices, constructing a more discriminative affinity matrix. The model was evaluated using four popular HSI datasets: Indian Pines, Pavia University, Houston, and Xu Zhou. It achieved overall accuracies of 97.61%, 96.69%, 87.21%, and 97.65%, respectively, and significantly outperformed state-of-the-art clustering methods. In conclusion, the proposed model effectively improves the clustering accuracy of HSI. ",
    "url": "https://arxiv.org/abs/2312.06068",
    "authors": [
      "Renxiang Guan",
      "Zihao Li",
      "Xianju Li",
      "Chang Tang",
      "Ruyi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06069",
    "title": "Mining Gaze for Contrastive Learning toward Computer-Assisted Diagnosis",
    "abstract": "Obtaining large-scale radiology reports can be difficult for medical images due to various reasons, limiting the effectiveness of contrastive pre-training in the medical image domain and underscoring the need for alternative methods. In this paper, we propose eye-tracking as an alternative to text reports, as it allows for the passive collection of gaze signals without disturbing radiologist's routine diagnosis process. By tracking the gaze of radiologists as they read and diagnose medical images, we can understand their visual attention and clinical reasoning. When a radiologist has similar gazes for two medical images, it may indicate semantic similarity for diagnosis, and these images should be treated as positive pairs when pre-training a computer-assisted diagnosis (CAD) network through contrastive learning. Accordingly, we introduce the Medical contrastive Gaze Image Pre-training (McGIP) as a plug-and-play module for contrastive learning frameworks. McGIP uses radiologist's gaze to guide contrastive pre-training. We evaluate our method using two representative types of medical images and two common types of gaze data. The experimental results demonstrate the practicality of McGIP, indicating its high potential for various clinical scenarios and applications. ",
    "url": "https://arxiv.org/abs/2312.06069",
    "authors": [
      "Zihao Zhao",
      "Sheng Wang",
      "Qian Wang",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06075",
    "title": "Oracle Character Recognition using Unsupervised Discriminative  Consistency Network",
    "abstract": "Ancient history relies on the study of ancient characters. However, real-world scanned oracle characters are difficult to collect and annotate, posing a major obstacle for oracle character recognition (OrCR). Besides, serious abrasion and inter-class similarity also make OrCR more challenging. In this paper, we propose a novel unsupervised domain adaptation method for OrCR, which enables to transfer knowledge from labeled handprinted oracle characters to unlabeled scanned data. We leverage pseudo-labeling to incorporate the semantic information into adaptation and constrain augmentation consistency to make the predictions of scanned samples consistent under different perturbations, leading to the model robustness to abrasion, stain and distortion. Simultaneously, an unsupervised transition loss is proposed to learn more discriminative features on the scanned domain by optimizing both between-class and within-class transition probability. Extensive experiments show that our approach achieves state-of-the-art result on Oracle-241 dataset and substantially outperforms the recently proposed structure-texture separation network by 15.1%. ",
    "url": "https://arxiv.org/abs/2312.06075",
    "authors": [
      "Mei Wang",
      "Weihong Deng",
      "Sen Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06085",
    "title": "Robust Geometry and Reflectance Disentanglement for 3D Face  Reconstruction from Sparse-view Images",
    "abstract": "This paper presents a novel two-stage approach for reconstructing human faces from sparse-view images, a task made challenging by the unique geometry and complex skin reflectance of each individual. Our method focuses on decomposing key facial attributes, including geometry, diffuse reflectance, and specular reflectance, from ambient light. Initially, we create a general facial template from a diverse collection of individual faces, capturing essential geometric and reflectance characteristics. Guided by this template, we refine each specific face model in the second stage, which further considers the interaction between geometry and reflectance, as well as the subsurface scattering effects on facial skin. Our method enables the reconstruction of high-quality facial representations from as few as three images, offering improved geometric accuracy and reflectance detail. Through comprehensive evaluations and comparisons, our method demonstrates superiority over existing techniques. Our method effectively disentangles geometry and reflectance components, leading to enhanced quality in synthesizing new views and opening up possibilities for applications such as relighting and reflectance editing. We will make the code publicly available. ",
    "url": "https://arxiv.org/abs/2312.06085",
    "authors": [
      "Daisheng Jin",
      "Jiangbei Hu",
      "Baixin Xu",
      "Yuxin Dai",
      "Chen Qian",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06086",
    "title": "HALO-CAT: A Hidden Network Processor with Activation-Localized CIM  Architecture and Layer-Penetrative Tiling",
    "abstract": "To address the 'memory wall' problem in NN hardware acceleration, we introduce HALO-CAT, a software-hardware co-design optimized for Hidden Neural Network (HNN) processing. HALO-CAT integrates Layer-Penetrative Tiling (LPT) for algorithmic efficiency, reducing intermediate result sizes. Furthermore, the architecture employs an activation-localized computing-in-memory approach to minimize data movement. This design significantly enhances energy efficiency, achieving a 14.2x reduction in activation memory capacity and a 17.8x decrease in energy consumption, with only a 1.5% loss in accuracy, compared to traditional HNN processors. ",
    "url": "https://arxiv.org/abs/2312.06086",
    "authors": [
      "Yung-Chin Chen",
      "Shimpei Ando",
      "Daichi Fujiki",
      "Shinya Takamaeda-Yamazaki",
      "Kentaro Yoshioka"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2312.06087",
    "title": "Complex-valued Neural Networks -- Theory and Analysis",
    "abstract": "Complex-valued neural networks (CVNNs) have recently been successful in various pioneering areas which involve wave-typed information and frequency-domain processing. This work addresses different structures and classification of CVNNs. The theory behind complex activation functions, implications related to complex differentiability and special activations for CVNN output layers are presented. The work also discusses CVNN learning and optimization using gradient and non-gradient based algorithms. Complex Backpropagation utilizing complex chain rule is also explained in terms of Wirtinger calculus. Moreover, special modules for building CVNN models, such as complex batch normalization and complex random initialization are also discussed. The work also highlights libraries and software blocks proposed for CVNN implementations and discusses future directions. The objective of this work is to understand the dynamics and most recent developments of CVNNs. ",
    "url": "https://arxiv.org/abs/2312.06087",
    "authors": [
      "Rayyan Abdalla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.06088",
    "title": "SECNN: Squeeze-and-Excitation Convolutional Neural Network for Sentence  Classification",
    "abstract": "Sentence classification is one of the basic tasks of natural language processing. Convolution neural network (CNN) has the ability to extract n-grams features through convolutional filters and capture local correlations between consecutive words in parallel, so CNN is a popular neural network architecture to dealing with the task. But restricted by the width of convolutional filters, it is difficult for CNN to capture long term contextual dependencies. Attention is a mechanism that considers global information and pays more attention to keywords in sentences, thus attention mechanism is cooperated with CNN network to improve performance in sentence classification task. In our work, we don't focus on keyword in a sentence, but on which CNN's output feature map is more important. We propose a Squeeze-and-Excitation Convolutional neural Network (SECNN) for sentence classification. SECNN takes the feature maps from multiple CNN as different channels of sentence representation, and then, we can utilize channel attention mechanism, that is SE attention mechanism, to enable the model to learn the attention weights of different channel features. The results show that our model achieves advanced performance in the sentence classification task. ",
    "url": "https://arxiv.org/abs/2312.06088",
    "authors": [
      "Shandong Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.06091",
    "title": "Learning Unknown Intervention Targets in Structural Causal Models from  Heterogeneous Data",
    "abstract": "We study the problem of identifying the unknown intervention targets in structural causal models where we have access to heterogeneous data collected from multiple environments. The unknown intervention targets are the set of endogenous variables whose corresponding exogenous noises change across the environments. We propose a two-phase approach which in the first phase recovers the exogenous noises corresponding to unknown intervention targets whose distributions have changed across environments. In the second phase, the recovered noises are matched with the corresponding endogenous variables. For the recovery phase, we provide sufficient conditions for learning these exogenous noises up to some component-wise invertible transformation. For the matching phase, under the causal sufficiency assumption, we show that the proposed method uniquely identifies the intervention targets. In the presence of latent confounders, the intervention targets among the observed variables cannot be determined uniquely. We provide a candidate intervention target set which is a superset of the true intervention targets. Our approach improves upon the state of the art as the returned candidate set is always a subset of the target set returned by previous work. Moreover, we do not require restrictive assumptions such as linearity of the causal model or performing invariance tests to learn whether a distribution is changing across environments which could be highly sample inefficient. Our experimental results show the effectiveness of our proposed algorithm in practice. ",
    "url": "https://arxiv.org/abs/2312.06091",
    "authors": [
      "Yuqin Yang",
      "Saber Salehkaleybar",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.06113",
    "title": "SimMining-3D: Altitude-Aware 3D Object Detection in Complex Mining  Environments: A Novel Dataset and ROS-Based Automatic Annotation Pipeline",
    "abstract": "Accurate and efficient object detection is crucial for safe and efficient operation of earth-moving equipment in mining. Traditional 2D image-based methods face limitations in dynamic and complex mine environments. To overcome these challenges, 3D object detection using point cloud data has emerged as a comprehensive approach. However, training models for mining scenarios is challenging due to sensor height variations, viewpoint changes, and the need for diverse annotated datasets. This paper presents novel contributions to address these challenges. We introduce a synthetic dataset SimMining 3D [1] specifically designed for 3D object detection in mining environments. The dataset captures objects and sensors positioned at various heights within mine benches, accurately reflecting authentic mining scenarios. An automatic annotation pipeline through ROS interface reduces manual labor and accelerates dataset creation. We propose evaluation metrics accounting for sensor-to-object height variations and point cloud density, enabling accurate model assessment in mining scenarios. Real data tests validate our models effectiveness in object prediction. Our ablation study emphasizes the importance of altitude and height variation augmentations in improving accuracy and reliability. The publicly accessible synthetic dataset [1] serves as a benchmark for supervised learning and advances object detection techniques in mining with complimentary pointwise annotations for each scene. In conclusion, our work bridges the gap between synthetic and real data, addressing the domain shift challenge in 3D object detection for mining. We envision robust object detection systems enhancing safety and efficiency in mining and related domains. ",
    "url": "https://arxiv.org/abs/2312.06113",
    "authors": [
      "Mehala Balamurali",
      "Ehsan Mihankhah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06125",
    "title": "Pre-Evolved Model for Complex Multi-objective Optimization Problems",
    "abstract": "Multi-objective optimization problems (MOPs) necessitate the simultaneous optimization of multiple objectives. Numerous studies have demonstrated that evolutionary computation is a promising paradigm for solving complex MOPs, which involve optimization problems with large-scale decision variables, many objectives, and expensive evaluation functions. However, existing multi-objective evolutionary algorithms (MOEAs) encounter significant challenges in generating high-quality populations when solving diverse complex MOPs. Specifically, the distinct requirements and constraints of the population result in the inefficiency or even incompetence of MOEAs in addressing various complex MOPs. Therefore, this paper proposes the concept of pre-evolving for MOEAs to generate high-quality populations for diverse complex MOPs. Drawing inspiration from the classical transformer architecture, we devise dimension embedding and objective encoding techniques to configure the pre-evolved model (PEM). The PEM is pre-evolved on a substantial number of existing MOPs. Subsequently, when fine-evolving on new complex MOPs, the PEM transforms the population into the next generation to approximate the Pareto-optimal front. Furthermore, it utilizes evaluations on new solutions to iteratively update the PEM for subsequent generations, thereby efficiently solving various complex MOPs. Experimental results demonstrate that the PEM outperforms state-of-the-art MOEAs on a range of complex MOPs. ",
    "url": "https://arxiv.org/abs/2312.06125",
    "authors": [
      "Haokai Hong",
      "Min Jiang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.06137",
    "title": "Compute-in-Memory based Neural Network Accelerators for Safety-Critical  Systems: Worst-Case Scenarios and Protections",
    "abstract": "Emerging non-volatile memory (NVM)-based Computing-in-Memory (CiM) architectures show substantial promise in accelerating deep neural networks (DNNs) due to their exceptional energy efficiency. However, NVM devices are prone to device variations. Consequently, the actual DNN weights mapped to NVM devices can differ considerably from their targeted values, inducing significant performance degradation. Many existing solutions aim to optimize average performance amidst device variations, which is a suitable strategy for general-purpose conditions. However, the worst-case performance that is crucial for safety-critical applications is largely overlooked in current research. In this study, we define the problem of pinpointing the worst-case performance of CiM DNN accelerators affected by device variations. Additionally, we introduce a strategy to identify a specific pattern of the device value deviations in the complex, high-dimensional value deviation space, responsible for this worst-case outcome. Our findings reveal that even subtle device variations can precipitate a dramatic decline in DNN accuracy, posing risks for CiM-based platforms in supporting safety-critical applications. Notably, we observe that prevailing techniques to bolster average DNN performance in CiM accelerators fall short in enhancing worst-case scenarios. In light of this issue, we propose a novel worst-case-aware training technique named A-TRICE that efficiently combines adversarial training and noise-injection training with right-censored Gaussian noise to improve the DNN accuracy in the worst-case scenarios. Our experimental results demonstrate that A-TRICE improves the worst-case accuracy under device variations by up to 33%. ",
    "url": "https://arxiv.org/abs/2312.06137",
    "authors": [
      "Zheyu Yan",
      "Xiaobo Sharon Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2312.06140",
    "title": "ICS-Sniper: A Targeted Blackhole Attack on Encrypted ICS Traffic",
    "abstract": "Operational Technology (OT) networks of industrial control systems (ICS) are increasingly connected to the public Internet, which has prompted ICSes to implement strong security measures (e.g., authentication and encryption) to protect end-to-end control communication. Despite the security measures, we show that an Internet adversary in the path of an ICS's communication can cause damage to the ICS without infiltrating it. We present ICS-Sniper, a targeted blackhole attack that analyzes the packet metadata (sizes, timing) to identify the packets carrying critical ICS commands or data, and drops the critical packets to disrupt the ICS's operations. We demonstrate two attacks on an emulation of a Secure Water Treatment (SWaT) plant that can potentially violate the operational safety of the ICS while evading state-of-the-art detection systems. ",
    "url": "https://arxiv.org/abs/2312.06140",
    "authors": [
      "Gargi Mitra",
      "Pritam Dash",
      "Yingao Elaine Yao",
      "Aastha Mehta",
      "Karthik Pattabiraman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.06141",
    "title": "Survey on Memory-Augmented Neural Networks: Cognitive Insights to AI  Applications",
    "abstract": "This paper explores Memory-Augmented Neural Networks (MANNs), delving into how they blend human-like memory processes into AI. It covers different memory types, like sensory, short-term, and long-term memory, linking psychological theories with AI applications. The study investigates advanced architectures such as Hopfield Networks, Neural Turing Machines, Correlation Matrix Memories, Memformer, and Neural Attention Memory, explaining how they work and where they excel. It dives into real-world uses of MANNs across Natural Language Processing, Computer Vision, Multimodal Learning, and Retrieval Models, showing how memory boosters enhance accuracy, efficiency, and reliability in AI tasks. Overall, this survey provides a comprehensive view of MANNs, offering insights for future research in memory-based AI systems. ",
    "url": "https://arxiv.org/abs/2312.06141",
    "authors": [
      "Savya Khosla",
      "Zhen Zhu",
      "Yifie He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06145",
    "title": "Proxy-based Item Representation for Attribute and Context-aware  Recommendation",
    "abstract": "Neural network approaches in recommender systems have shown remarkable success by representing a large set of items as a learnable vector embedding table. However, infrequent items may suffer from inadequate training opportunities, making it difficult to learn meaningful representations. We examine that in attribute and context-aware settings, the poorly learned embeddings of infrequent items impair the recommendation accuracy. To address such an issue, we propose a proxy-based item representation that allows each item to be expressed as a weighted sum of learnable proxy embeddings. Here, the proxy weight is determined by the attributes and context of each item and may incorporate bias terms in case of frequent items to further reflect collaborative signals. The proxy-based method calculates the item representations compositionally, ensuring each representation resides inside a well-trained simplex and, thus, acquires guaranteed quality. Additionally, that the proxy embeddings are shared across all items allows the infrequent items to borrow training signals of frequent items in a unified model structure and end-to-end manner. Our proposed method is a plug-and-play model that can replace the item encoding layer of any neural network-based recommendation model, while consistently improving the recommendation performance with much smaller parameter usage. Experiments conducted on real-world recommendation benchmark datasets demonstrate that our proposed model outperforms state-of-the-art models in terms of recommendation accuracy by up to 17% while using only 10% of the parameters. ",
    "url": "https://arxiv.org/abs/2312.06145",
    "authors": [
      "Jinseok Seol",
      "Minseok Gang",
      "Sang-goo Lee",
      "Jaehui Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06163",
    "title": "Adversarial Camera Patch: An Effective and Robust Physical-World Attack  on Object Detectors",
    "abstract": "Nowadays, the susceptibility of deep neural networks (DNNs) has garnered significant attention. Researchers are exploring patch-based physical attacks, yet traditional approaches, while effective, often result in conspicuous patches covering target objects. This leads to easy detection by human observers. Recently, novel camera-based physical attacks have emerged, leveraging camera patches to execute stealthy attacks. These methods circumvent target object modifications by introducing perturbations directly to the camera lens, achieving a notable breakthrough in stealthiness. However, prevailing camera-based strategies necessitate the deployment of multiple patches on the camera lens, which introduces complexity. To address this issue, we propose an Adversarial Camera Patch (ADCP). ",
    "url": "https://arxiv.org/abs/2312.06163",
    "authors": [
      "Kalibinuer Tiliwalidi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06168",
    "title": "Motion Planning for Multiple Mobile Manipulator System in Complex  Flipping Manipulation",
    "abstract": "Multiple robot systems are favored for object manipulation and transportation, especially for large objects. However, in more complex manipulation such as flipping, these systems encounter a new challenge, configuration disconnectivity of manipulators. Grasping objects by manipulators will impose closed-chain constraints on the system, which in turn limits the feasible motions of manipulators and further compromises the configuration connectivity. Multiple mobile manipulator systems show much more flexibility in object manipulation with the mobility of the mobile platform and have the potential to address the above problem. In this paper, a novel planning framework is proposed for complex flipping manipulation by incorporating platform motions and regrasping. Firstly, two types of trajectories, mobile manipulator planning and regrasping planning, are classified and can be assigned different priorities for different tasks. Secondly, corresponding planning methods are designed for each type of trajectory. Specifically, in mobile manipulator planning, the configuration of the platform is determined through optimization to ensure connectivity when the manipulator approaches configuration boundaries. In regrasping planning, closed-chain constraints are temporarily disregarded and the manipulation capabilities are prioritized to facilitate subsequent planning. Finally, the structure of the overall planning framework is provided. Experimental results demonstrate that the proposed planner efficiently plans the motions of the system to accomplish flipping manipulation. Additionally, a comprehensive experiment emphasizes the significance of our planner in extending the capabilities of multiple mobile manipulator systems in complex tasks. ",
    "url": "https://arxiv.org/abs/2312.06168",
    "authors": [
      "Wenhang Liu",
      "Kun Song",
      "Meng Ren",
      "Jiawei Hu",
      "Michael Yu Wang",
      "Zhenhua Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.06169",
    "title": "Bag of Tricks: Semi-Supervised Cross-domain Crater Detection with Poor  Data Quality",
    "abstract": "With the development of spaceflight and the exploration of extraterrestrial planets, exoplanet crater detection has gradually gained attention. However, with the current scarcity of relevant datasets, high sample background complexity, and large inter-domain differences, few existing detection models can achieve good robustness and generalization across domains by training on data with more background interference. To obtain a better robust model with better cross-domain generalization in the presence of poor data quality, we propose the SCPQ model, in which we first propose a method for fusing shallow information using attention mechanism (FSIAM), which utilizes feature maps fused with deep convolved feature maps after fully extracting the global sensory field of shallow information via the attention mechanism module, which can fully fit the data to obtain a better sense of the domain in the presence of poor data, and thus better multiscale adaptability. Secondly, we propose a pseudo-label and data augment strategy (PDAS) and a smooth hard example mining (SHEM) loss function to improve cross-domain performance. PDAS adopts high-quality pseudo-labeled data from the target domain to the finetune model, and adopts different strong and weak data enhancement strategies for different domains, which mitigates the different distribution of information inherent in the source and target domains, and obtains a better generalization effect. Meanwhile, our proposed SHEM loss function can solve the problem of poor robustness of hard examples due to partial background interference learning during the training process. The SHEM loss function can smooth this interference and has generalization while learning hard examples. Experimental results show that we achieved better performance on the DACD dataset and improved the Recall of cross-domain detection by 24.04\\% over baseline. ",
    "url": "https://arxiv.org/abs/2312.06169",
    "authors": [
      "Yifan Liu",
      "Tiecheng Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06171",
    "title": "Jointly Explicit and Implicit Cross-Modal Interaction Network for  Anterior Chamber Inflammation Diagnosis",
    "abstract": "Uveitis demands the precise diagnosis of anterior chamber inflammation (ACI) for optimal treatment. However, current diagnostic methods only rely on a limited single-modal disease perspective, which leads to poor performance. In this paper, we investigate a promising yet challenging way to fuse multimodal data for ACI diagnosis. Notably, existing fusion paradigms focus on empowering implicit modality interactions (i.e., self-attention and its variants), but neglect to inject explicit modality interactions, especially from clinical knowledge and imaging property. To this end, we propose a jointly Explicit and implicit Cross-Modal Interaction Network (EiCI-Net) for Anterior Chamber Inflammation Diagnosis that uses anterior segment optical coherence tomography (AS-OCT) images, slit-lamp images, and clinical data jointly. Specifically, we first develop CNN-Based Encoders and Tabular Processing Module (TPM) to extract efficient feature representations in different modalities. Then, we devise an Explicit Cross-Modal Interaction Module (ECIM) to generate attention maps as a kind of explicit clinical knowledge based on the tabular feature maps, then integrated them into the slit-lamp feature maps, allowing the CNN-Based Encoder to focus on more effective informativeness of the slit-lamp images. After that, the Implicit Cross-Modal Interaction Module (ICIM), a transformer-based network, further implicitly enhances modality interactions. Finally, we construct a considerable real-world dataset from our collaborative hospital and conduct sufficient experiments to demonstrate the superior performance of our proposed EiCI-Net compared with the state-of-the-art classification methods in various metrics. ",
    "url": "https://arxiv.org/abs/2312.06171",
    "authors": [
      "Qian Shao",
      "Ye Dai",
      "Haochao Ying",
      "Kan Xu",
      "Jinhong Wang",
      "Wei Chi",
      "Jian Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2312.06199",
    "title": "Towards Transferable Adversarial Attacks with Centralized Perturbation",
    "abstract": "Adversarial transferability enables black-box attacks on unknown victim deep neural networks (DNNs), rendering attacks viable in real-world scenarios. Current transferable attacks create adversarial perturbation over the entire image, resulting in excessive noise that overfit the source model. Concentrating perturbation to dominant image regions that are model-agnostic is crucial to improving adversarial efficacy. However, limiting perturbation to local regions in the spatial domain proves inadequate in augmenting transferability. To this end, we propose a transferable adversarial attack with fine-grained perturbation optimization in the frequency domain, creating centralized perturbation. We devise a systematic pipeline to dynamically constrain perturbation optimization to dominant frequency coefficients. The constraint is optimized in parallel at each iteration, ensuring the directional alignment of perturbation optimization with model prediction. Our approach allows us to centralize perturbation towards sample-specific important frequency features, which are shared by DNNs, effectively mitigating source model overfitting. Experiments demonstrate that by dynamically centralizing perturbation on dominating frequency coefficients, crafted adversarial examples exhibit stronger transferability, and allowing them to bypass various defenses. ",
    "url": "https://arxiv.org/abs/2312.06199",
    "authors": [
      "Shangbo Wu",
      "Yu-an Tan",
      "Yajie Wang",
      "Ruinan Ma",
      "Wencong Ma",
      "Yuanzhang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06202",
    "title": "Transforms for Multiplicative and Fractional Programming with Broad  Applications in Edge Computing and Communication Networks",
    "abstract": "Multiplicative Programming (MP) pertains to a spectrum of optimization problems that involve product term(s). As computational paradigms of communication systems continue to evolve, particularly concerning the offloading strategies of computationally intensive tasks simultaneously to centralized or decentralized servers, designing or optimizing effective communication systems with MP techniques becomes increasingly indispensable. Similarly, Fractional Programming (FP) is another significant branch in the optimization domain, addressing various essential scenarios in communication. For instance, in minimization optimization problems, transmission power and processing delay of communication systems are considered critical metrics. In a very recent JSAC paper by Zhao et al. [2], an innovative transform (Zhao's Optimization Transform) was proposed for solving the minimization of MP and FP problems. Nevertheless, the resolution of optimization problems in communication systems encounters several limitations when adopting Zhao's optimization transform, especially in MP problems. Primarily, objective functions proposed in these optimization problems typically involve sum-of-products terms and the optimization variables are always discrete leading to NP-hard problems. Furthermore, multiple functions mapping to the non-negative domain in these scenarios can result in auxiliary variables being zero values, while the same situation is avoidable in FP problems due to the presence of these functions in the denominator. In this paper, we introduce an updated transform, building on the foundations of Zhao's original method, designed to effectively overcome these challenges by reformulating the original problem into a series of convex or concave problems. This introduced problem reformulation provides a superior iteration algorithm with demonstrable convergence to a stationary point. ",
    "url": "https://arxiv.org/abs/2312.06202",
    "authors": [
      "Yitong Wang",
      "Chang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Performance (cs.PF)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.06203",
    "title": "Offloading and Quality Control for AI Generated Content Services in Edge  Computing Networks",
    "abstract": "AI-Generated Content (AIGC), as a novel manner of providing Metaverse services in the forthcoming Internet paradigm, can resolve the obstacles of immersion requirements. Concurrently, edge computing, as an evolutionary paradigm of computing in communication systems, effectively augments real-time interactive services. In pursuit of enhancing the accessibility of AIGC services, the deployment of AIGC models (e.g., diffusion models) to edge servers and local devices has become a prevailing trend. Nevertheless, this approach faces constraints imposed by battery life and computational resources when tasks are offloaded to local devices, limiting the capacity to deliver high-quality content to users while adhering to stringent latency requirements. So there will be a tradeoff between the utility of AIGC models and offloading decisions in the edge computing paradigm. This paper proposes a joint optimization algorithm for offloading decisions, computation time, and diffusion steps of the diffusion models in the reverse diffusion stage. Moreover, we take the average error into consideration as the metric for evaluating the quality of the generated results. Experimental results conclusively demonstrate that the proposed algorithm achieves superior joint optimization performance compared to the baselines. ",
    "url": "https://arxiv.org/abs/2312.06203",
    "authors": [
      "Yitong Wang",
      "Chang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2312.06219",
    "title": "Interpretable Long Term Waypoint-Based Trajectory Prediction Model",
    "abstract": "Predicting the future trajectories of dynamic agents in complex environments is crucial for a variety of applications, including autonomous driving, robotics, and human-computer interaction. It is a challenging task as the behavior of the agent is unknown and intrinsically multimodal. Our key insight is that the agents behaviors are influenced not only by their past trajectories and their interaction with their immediate environment but also largely with their long term waypoint (LTW). In this paper, we study the impact of adding a long-term goal on the performance of a trajectory prediction framework. We present an interpretable long term waypoint-driven prediction framework (WayDCM). WayDCM first predict an agent's intermediate goal (IG) by encoding his interactions with the environment as well as his LTW using a combination of a Discrete choice Model (DCM) and a Neural Network model (NN). Then, our model predicts the corresponding trajectories. This is in contrast to previous work which does not consider the ultimate intent of the agent to predict his trajectory. We evaluate and show the effectiveness of our approach on the Waymo Open dataset. ",
    "url": "https://arxiv.org/abs/2312.06219",
    "authors": [
      "Amina Ghoul",
      "Itheri Yahiaoui",
      "Fawzi Nashashibi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.06226",
    "title": "Invariant Representation Learning via Decoupling Style and Spurious  Features",
    "abstract": "This paper considers the out-of-distribution (OOD) generalization problem under the setting that both style distribution shift and spurious features exist and domain labels are missing. This setting frequently arises in real-world applications and is underlooked because previous approaches mainly handle either of these two factors. The critical challenge is decoupling style and spurious features in the absence of domain labels. To address this challenge, we first propose a structural causal model (SCM) for the image generation process, which captures both style distribution shift and spurious features. The proposed SCM enables us to design a new framework called IRSS, which can gradually separate style distribution and spurious features from images by introducing adversarial neural networks and multi-environment optimization, thus achieving OOD generalization. Moreover, it does not require additional supervision (e.g., domain labels) other than the images and their corresponding labels. Experiments on benchmark datasets demonstrate that IRSS outperforms traditional OOD methods and solves the problem of Invariant risk minimization (IRM) degradation, enabling the extraction of invariant features under distribution shift. ",
    "url": "https://arxiv.org/abs/2312.06226",
    "authors": [
      "Ruimeng Li",
      "Yuanhao Pu",
      "Zhaoyi Li",
      "Hong Xie",
      "Defu Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06230",
    "title": "Activation Gradient based Poisoned Sample Detection Against Backdoor  Attacks",
    "abstract": "This work focuses on defending against the data poisoning based backdoor attacks, which bring in serious security threats to deep neural networks (DNNs). Specifically, given a untrustworthy training dataset, we aim to filter out potential poisoned samples, \\ie, poisoned sample detection (PSD). The key solution for this task is to find a discriminative metric between clean and poisoned samples, even though there is no information about the potential poisoned samples (\\eg, the attack method, the poisoning ratio). In this work, we develop an innovative detection approach from the perspective of the gradient \\wrt activation (\\ie, activation gradient direction, AGD) of each sample in the backdoored model trained on the untrustworthy dataset. We present an interesting observation that the circular distribution of AGDs among all samples of the target class is much more dispersed than that of one clean class. Motivated by this observation, we firstly design a novel metric called Cosine similarity Variation towards Basis Transition (CVBT) to measure the circular distribution's dispersion of each class. Then, we design a simple yet effective algorithm with identifying the target class(es) using outlier detection on CVBT scores of all classes, followed by progressively filtering of poisoned samples according to the cosine similarities of AGDs between every potential sample and a few additional clean samples. Extensive experiments under various settings verify that given very few clean samples of each class, the proposed method could filter out most poisoned samples, while avoiding filtering out clean samples, verifying its effectiveness on the PSD task. Codes are available at https://github.com/SCLBD/bdzoo2/blob/dev/detection_pretrain/agpd.py. ",
    "url": "https://arxiv.org/abs/2312.06230",
    "authors": [
      "Danni Yuan",
      "Shaokui Wei",
      "Mingda Zhang",
      "Li Liu",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.06244",
    "title": "Team-related Features in Code Review Prediction Models",
    "abstract": "Modern Code Review (MCR) is an informal tool-assisted quality assurance practice. It relies on the asynchronous communication among the authors of code changes and reviewers, who are developers that provide feedback. However, from candidate developers, some are able to provide better feedback than others given a particular context. The selection of reviewers is thus an important task, which can benefit from automated support. Many approaches have been proposed in this direction, using for example data from code review repositories to recommend reviewers. In this paper, we propose the use of team-related features to improve the performance of predictions that are helpful to build code reviewer recommenders, with our target predictions being the identification of reviewers that would participate in a review and the provided amount of feedback. We evaluate the prediction power of these features, which are related to code ownership, workload, and team relationship. This evaluation was done by carefully addressing challenges imposed by the MCR domain, such as temporal aspects of the dataset and unbalanced classes. Moreover, given that it is currently unknown how much past data is needed for building MCR prediction models with acceptable performance, we explore the amount of past data used to build prediction models. Our results show that, individually, features related to code ownership have the best prediction power. However, based on feature selection, we conclude that all proposed features together with lines of code can make the best predictions for both reviewer participation and amount of feedback. Regarding the amount of past data, the timeframes of 3, 6, 9, and 12 months of data produce similar results. Therefore, models can be trained considering short timeframes, thus reducing the computational costs with negligible impact in the prediction performance ... ",
    "url": "https://arxiv.org/abs/2312.06244",
    "authors": [
      "Eduardo Witter",
      "Ingrid Nunes",
      "Dietmar Jannach"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06250",
    "title": "Robust and Decentralized Reinforcement Learning for UAV Path Planning in  IoT Networks",
    "abstract": "Unmanned aerial vehicle (UAV)-based networks and Internet of Things (IoT) are being considered as integral components of current and next-generation wireless networks. In particular, UAVs can provide IoT devices with seamless connectivity and high coverage and this can be accomplished with effective UAV path planning. In this article, we study robust and decentralized UAV path planning for data collection in IoT networks in the presence of other noncooperative UAVs and adversarial jamming attacks. We address three different practical scenarios, including single UAV path planning, UAV swarm path planning, and single UAV path planning in the presence of an intelligent mobile UAV jammer. We advocate a reinforcement learning framework for UAV path planning in these three scenarios under practical constraints. The simulation results demonstrate that with learning-based path planning, the UAVs can complete their missions with high success rates and data collection rates. In addition, the UAVs can adapt and execute different trajectories as a defensive measure against the intelligent jammer. ",
    "url": "https://arxiv.org/abs/2312.06250",
    "authors": [
      "Xueyuan Wang",
      "M. Cenk Gursoy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.06253",
    "title": "Transformer Attractors for Robust and Efficient End-to-End Neural  Diarization",
    "abstract": "End-to-end neural diarization with encoder-decoder based attractors (EEND-EDA) is a method to perform diarization in a single neural network. EDA handles the diarization of a flexible number of speakers by using an LSTM-based encoder-decoder that generates a set of speaker-wise attractors in an autoregressive manner. In this paper, we propose to replace EDA with a transformer-based attractor calculation (TA) module. TA is composed of a Combiner block and a Transformer decoder. The main function of the combiner block is to generate conversational dependent (CD) embeddings by incorporating learned conversational information into a global set of embeddings. These CD embeddings will then serve as the input for the transformer decoder. Results on public datasets show that EEND-TA achieves 2.68% absolute DER improvement over EEND-EDA. EEND-TA inference is 1.28 times faster than that of EEND-EDA. ",
    "url": "https://arxiv.org/abs/2312.06253",
    "authors": [
      "Lahiru Samarakoon",
      "Samuel J. Broughton",
      "Marc H\u00e4rk\u00f6nen",
      "Ivan Fung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.06256",
    "title": "Neural Autoencoder-Based Structure-Preserving Model Order Reduction and  Control Design for High-Dimensional Physical Systems",
    "abstract": "This work concerns control-oriented and structure-preserving learning of low-dimensional approximations of high-dimensional physical systems, with a focus on mechanical systems. We investigate the integration of neural autoencoders in model order reduction, while at the same time preserving Hamiltonian or Lagrangian structures. We focus on extensively evaluating the considered methodology by performing simulation and control experiments on large mass-spring-damper networks, with hundreds of states. The empirical findings reveal that compressed latent dynamics with less than 5 degrees of freedom can accurately reconstruct the original systems' transient and steady-state behavior with a relative total error of around 4\\%, while simultaneously accurately reconstructing the total energy. Leveraging this system compression technique, we introduce a model-based controller that exploits the mathematical structure of the compressed model to regulate the configuration of heavily underactuated mechanical systems. ",
    "url": "https://arxiv.org/abs/2312.06256",
    "authors": [
      "Marco Lepri",
      "Davide Bacciu",
      "Cosimo Della Santina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.06260",
    "title": "In search of the lost tree: Hardness and relaxation of spanning trees in  temporal graphs",
    "abstract": "A graph whose edges only appear at certain points in time is called a temporal graph (among other names). These graphs are temporally connected if all ordered pairs of vertices are connected by a path that traverses edges in chronological order (a temporal path). Reachability in temporal graphs departs significantly from standard reachability; in particular, it is not transitive, with structural and algorithmic consequences. For instance, temporally connected graphs do not always admit spanning trees, i.e., subsets of edges that form a tree and preserve temporal connectivity among the nodes. In this paper, we revisit fundamental questions about the loss of universality of spanning trees. To start, we show that deciding if a spanning tree exists in a given temporal graph is NP-complete. What could be appropriate replacement for the concept? Beyond having minimum size, spanning trees enjoy the feature of enabling reachability along the same underlying paths in both directions, a pretty uncommon feature in temporal graphs. We explore relaxations in this direction and show that testing the existence of bidirectional spanning structures (bi-spanners) is tractable in general. On the down side, finding \\emph{minimum} such structures is NP-hard even in simple temporal graphs. Still, the fact that bidirectionality can be tested efficiently may find applications, e.g. for routing and security, and the corresponding primitive that we introduce in the algorithm may be of independent interest. ",
    "url": "https://arxiv.org/abs/2312.06260",
    "authors": [
      "Arnaud Casteigts",
      "Timoth\u00e9e Corsini"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.06279",
    "title": "Regional Correlation Aided Mobile Traffic Prediction with Spatiotemporal  Deep Learning",
    "abstract": "Mobile traffic data in urban regions shows differentiated patterns during different hours of the day. The exploitation of these patterns enables highly accurate mobile traffic prediction for proactive network management. However, recent Deep Learning (DL) driven studies have only exploited spatiotemporal features and have ignored the geographical correlations, causing high complexity and erroneous mobile traffic predictions. This paper addresses these limitations by proposing an enhanced mobile traffic prediction scheme that combines the clustering strategy of daily mobile traffic peak time and novel multi Temporal Convolutional Network with a Long Short Term Memory (multi TCN-LSTM) model. The mobile network cells that exhibit peak traffic during the same hour of the day are clustered together. Our experiments on large-scale real-world mobile traffic data show up to 28% performance improvement compared to state-of-the-art studies, which confirms the efficacy and viability of the proposed approach. ",
    "url": "https://arxiv.org/abs/2312.06279",
    "authors": [
      "JeongJun Park",
      "Lusungu J. Mwasinga",
      "Huigyu Yang",
      "Syed M. Raza",
      "Duc-Tai Le",
      "Moonseong Kim",
      "Min Young Chung",
      "Hyunseung Choo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06283",
    "title": "Extrapolating tipping points and simulating non-stationary dynamics of  complex systems using efficient machine learning",
    "abstract": "Model-free and data-driven prediction of tipping point transitions in nonlinear dynamical systems is a challenging and outstanding task in complex systems science. We propose a novel, fully data-driven machine learning algorithm based on next-generation reservoir computing to extrapolate the bifurcation behavior of nonlinear dynamical systems using stationary training data samples. We show that this method can extrapolate tipping point transitions. Furthermore, it is demonstrated that the trained next-generation reservoir computing architecture can be used to predict non-stationary dynamics with time-varying bifurcation parameters. In doing so, post-tipping point dynamics of unseen parameter regions can be simulated. ",
    "url": "https://arxiv.org/abs/2312.06283",
    "authors": [
      "Daniel K\u00f6glmayr",
      "Christoph R\u00e4th"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2312.06295",
    "title": "Cataract-1K: Cataract Surgery Dataset for Scene Segmentation, Phase  Recognition, and Irregularity Detection",
    "abstract": "In recent years, the landscape of computer-assisted interventions and post-operative surgical video analysis has been dramatically reshaped by deep-learning techniques, resulting in significant advancements in surgeons' skills, operation room management, and overall surgical outcomes. However, the progression of deep-learning-powered surgical technologies is profoundly reliant on large-scale datasets and annotations. Particularly, surgical scene understanding and phase recognition stand as pivotal pillars within the realm of computer-assisted surgery and post-operative assessment of cataract surgery videos. In this context, we present the largest cataract surgery video dataset that addresses diverse requisites for constructing computerized surgical workflow analysis and detecting post-operative irregularities in cataract surgery. We validate the quality of annotations by benchmarking the performance of several state-of-the-art neural network architectures for phase recognition and surgical scene segmentation. Besides, we initiate the research on domain adaptation for instrument segmentation in cataract surgery by evaluating cross-domain instrument segmentation performance in cataract surgery videos. The dataset and annotations will be publicly available upon acceptance of the paper. ",
    "url": "https://arxiv.org/abs/2312.06295",
    "authors": [
      "Negin Ghamsarian",
      "Yosuf El-Shabrawi",
      "Sahar Nasirihaghighi",
      "Doris Putzgruber-Adamitsch",
      "Martin Zinkernagel",
      "Sebastian Wolf",
      "Klaus Schoeffmann",
      "Raphael Sznitman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06304",
    "title": "Orchestrated Robust Controller for the Precision Control of Heavy-duty  Hydraulic Manipulators",
    "abstract": "Vast industrial investment along with increased academic research on hydraulic heavy-duty manipulators has unavoidably paved the way for their automatization, necessitating the design of robust and high-precision controllers. In this study, an orchestrated robust controller is designed to address the mentioned issue. To do so, the entire robotic system is decomposed into subsystems, and a robust controller is designed at each local subsystem by considering unknown model uncertainties, unknown disturbances, and compound input constraints, thanks to virtual decomposition control (VDC). As such, radial basic function neural networks (RBFNNs) are incorporated into VDC to tackle unknown disturbances and uncertainties, resulting in novel decentralized RBFNNs. All these robust local controllers designed at each local subsystem are, then, orchestrated to accomplish high-precision control. In the end, for the first time in the context of VDC, a semi-globally uniformly ultimate boundedness is achieved under the designed controller. The validity of the theoretical results is verified by performing extensive simulations and experiments on a 6-degrees-of-freedom industrial manipulator with a nominal lifting capacity of $600\\, kg$ at $5$ meters reach. Comparing the simulation result to state-of-the-art controller along with provided experimental results, demonstrates that the proposed method established all the promises and performed excellently. ",
    "url": "https://arxiv.org/abs/2312.06304",
    "authors": [
      "Mahdi Hejrati",
      "Jouni Mattila"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.06328",
    "title": "TPRNN: A Top-Down Pyramidal Recurrent Neural Network for Time Series  Forecasting",
    "abstract": "Time series refer to a series of data points indexed in time order, which can be found in various fields, e.g., transportation, healthcare, and finance. Accurate time series forecasting can enhance optimization planning and decision-making support. Time series have multi-scale characteristics, i.e., different temporal patterns at different scales, which presents a challenge for time series forecasting. In this paper, we propose TPRNN, a Top-down Pyramidal Recurrent Neural Network for time series forecasting. We first construct subsequences of different scales from the input, forming a pyramid structure. Then by executing a multi-scale information interaction module from top to bottom, we model both the temporal dependencies of each scale and the influences of subsequences of different scales, resulting in a complete modeling of multi-scale temporal patterns in time series. Experiments on seven real-world datasets demonstrate that TPRNN has achieved the state-of-the-art performance with an average improvement of 8.13% in MSE compared to the best baseline. ",
    "url": "https://arxiv.org/abs/2312.06328",
    "authors": [
      "Ling Chen",
      "Jiahua Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.06336",
    "title": "Vehicle Lane Change Prediction based on Knowledge Graph Embeddings and  Bayesian Inference",
    "abstract": "Prediction of vehicle lane change maneuvers has gained a lot of momentum in the last few years. Some recent works focus on predicting a vehicle's intention by predicting its trajectory first. This is not enough, as it ignores the context of the scene and the state of the surrounding vehicles (as they might be risky to the target vehicle). Other works assessed the risk made by the surrounding vehicles only by considering their existence around the target vehicle, or by considering the distance and relative velocities between them and the target vehicle as two separate numerical features. In this work, we propose a solution that leverages Knowledge Graphs (KGs) to anticipate lane changes based on linguistic contextual information in a way that goes well beyond the capabilities of current perception systems. Our solution takes the Time To Collision (TTC) with surrounding vehicles as input to assess the risk on the target vehicle. Moreover, our KG is trained on the HighD dataset using the TransE model to obtain the Knowledge Graph Embeddings (KGE). Then, we apply Bayesian inference on top of the KG using the embeddings learned during training. Finally, the model can predict lane changes two seconds ahead with 97.95% f1-score, which surpassed the state of the art, and three seconds before changing lanes with 93.60% f1-score. ",
    "url": "https://arxiv.org/abs/2312.06336",
    "authors": [
      "M. Manzour",
      "A. Ballardini",
      "R. Izquierdo",
      "M. A. Sotelo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.06338",
    "title": "BoschAI @ Causal News Corpus 2023: Robust Cause-Effect Span Extraction  using Multi-Layer Sequence Tagging and Data Augmentation",
    "abstract": "Understanding causality is a core aspect of intelligence. The Event Causality Identification with Causal News Corpus Shared Task addresses two aspects of this challenge: Subtask 1 aims at detecting causal relationships in texts, and Subtask 2 requires identifying signal words and the spans that refer to the cause or effect, respectively. Our system, which is based on pre-trained transformers, stacked sequence tagging, and synthetic data augmentation, ranks third in Subtask 1 and wins Subtask 2 with an F1 score of 72.8, corresponding to a margin of 13 pp. to the second-best system. ",
    "url": "https://arxiv.org/abs/2312.06338",
    "authors": [
      "Timo Pierre Schrader",
      "Simon Razniewski",
      "Lukas Lange",
      "Annemarie Friedrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06342",
    "title": "Detecting Contextual Network Anomalies with Graph Neural Networks",
    "abstract": "Detecting anomalies on network traffic is a complex task due to the massive amount of traffic flows in today's networks, as well as the highly-dynamic nature of traffic over time. In this paper, we propose the use of Graph Neural Networks (GNN) for network traffic anomaly detection. We formulate the problem as contextual anomaly detection on network traffic measurements, and propose a custom GNN-based solution that detects traffic anomalies on origin-destination flows. In our evaluation, we use real-world data from Abilene (6 months), and make a comparison with other widely used methods for the same task (PCA, EWMA, RNN). The results show that the anomalies detected by our solution are quite complementary to those captured by the baselines (with a max. of 36.33% overlapping anomalies for PCA). Moreover, we manually inspect the anomalies detected by our method, and find that a large portion of them can be visually validated by a network expert (64% with high confidence, 18% with mid confidence, 18% normal traffic). Lastly, we analyze the characteristics of the anomalies through two paradigmatic cases that are quite representative of the bulk of anomalies. ",
    "url": "https://arxiv.org/abs/2312.06342",
    "authors": [
      "Hamid Latif-Mart\u00ednez",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Albert Cabellos-Aparicio",
      "Pere Barlet-Ros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.06344",
    "title": "Learning Robust Policies for Uncertain Parametric Markov Decision  Processes",
    "abstract": "Synthesising verifiably correct controllers for dynamical systems is crucial for safety-critical problems. To achieve this, it is important to account for uncertainty in a robust manner, while at the same time it is often of interest to avoid being overly conservative with the view of achieving a better cost. We propose a method for verifiably safe policy synthesis for a class of finite state models, under the presence of structural uncertainty. In particular, we consider uncertain parametric Markov decision processes (upMDPs), a special class of Markov decision processes, with parameterised transition functions, where such parameters are drawn from a (potentially) unknown distribution. Our framework leverages recent advancements in the so-called scenario approach theory, where we represent the uncertainty by means of scenarios, and provide guarantees on synthesised policies satisfying probabilistic computation tree logic (PCTL) formulae. We consider several common benchmarks/problems and compare our work to recent developments for verifying upMDPs. ",
    "url": "https://arxiv.org/abs/2312.06344",
    "authors": [
      "Luke Rickard",
      "Alessandro Abate",
      "Kostas Margellos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2312.06348",
    "title": "DiffAIL: Diffusion Adversarial Imitation Learning",
    "abstract": "Imitation learning aims to solve the problem of defining reward functions in real-world decision-making tasks. The current popular approach is the Adversarial Imitation Learning (AIL) framework, which matches expert state-action occupancy measures to obtain a surrogate reward for forward reinforcement learning. However, the traditional discriminator is a simple binary classifier and doesn't learn an accurate distribution, which may result in failing to identify expert-level state-action pairs induced by the policy interacting with the environment. To address this issue, we propose a method named diffusion adversarial imitation learning (DiffAIL), which introduces the diffusion model into the AIL framework. Specifically, DiffAIL models the state-action pairs as unconditional diffusion models and uses diffusion loss as part of the discriminator's learning objective, which enables the discriminator to capture better expert demonstrations and improve generalization. Experimentally, the results show that our method achieves state-of-the-art performance and significantly surpasses expert demonstration on two benchmark tasks, including the standard state-action setting and state-only settings. Our code can be available at an anonymous link https://github.com/ML-Group-SDU/DiffAIL. ",
    "url": "https://arxiv.org/abs/2312.06348",
    "authors": [
      "Bingzheng Wang",
      "Yan Zhang",
      "Teng Pang",
      "Guoqiang Wu",
      "Yilong Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06371",
    "title": "BAT: Behavior-Aware Human-Like Trajectory Prediction for Autonomous  Driving",
    "abstract": "The ability to accurately predict the trajectory of surrounding vehicles is a critical hurdle to overcome on the journey to fully autonomous vehicles. To address this challenge, we pioneer a novel behavior-aware trajectory prediction model (BAT) that incorporates insights and findings from traffic psychology, human behavior, and decision-making. Our model consists of behavior-aware, interaction-aware, priority-aware, and position-aware modules that perceive and understand the underlying interactions and account for uncertainty and variability in prediction, enabling higher-level learning and flexibility without rigid categorization of driving behavior. Importantly, this approach eliminates the need for manual labeling in the training process and addresses the challenges of non-continuous behavior labeling and the selection of appropriate time windows. We evaluate BAT's performance across the Next Generation Simulation (NGSIM), Highway Drone (HighD), Roundabout Drone (RounD), and Macao Connected Autonomous Driving (MoCAD) datasets, showcasing its superiority over prevailing state-of-the-art (SOTA) benchmarks in terms of prediction accuracy and efficiency. Remarkably, even when trained on reduced portions of the training data (25%), our model outperforms most of the baselines, demonstrating its robustness and efficiency in predicting vehicle trajectories, and the potential to reduce the amount of data required to train autonomous vehicles, especially in corner cases. In conclusion, the behavior-aware model represents a significant advancement in the development of autonomous vehicles capable of predicting trajectories with the same level of proficiency as human drivers. The project page is available at https://github.com/Petrichor625/BATraj-Behavior-aware-Model. ",
    "url": "https://arxiv.org/abs/2312.06371",
    "authors": [
      "Haicheng Liao",
      "Zhenning Li",
      "Huanming Shen",
      "Wenxuan Zeng",
      "Guofa Li",
      "Shengbo Eben Li",
      "Chengzhong Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06372",
    "title": "Ternary Spike: Learning Ternary Spikes for Spiking Neural Networks",
    "abstract": "The Spiking Neural Network (SNN), as one of the biologically inspired neural network infrastructures, has drawn increasing attention recently. It adopts binary spike activations to transmit information, thus the multiplications of activations and weights can be substituted by additions, which brings high energy efficiency. However, in the paper, we theoretically and experimentally prove that the binary spike activation map cannot carry enough information, thus causing information loss and resulting in accuracy decreasing. To handle the problem, we propose a ternary spike neuron to transmit information. The ternary spike neuron can also enjoy the event-driven and multiplication-free operation advantages of the binary spike neuron but will boost the information capacity. Furthermore, we also embed a trainable factor in the ternary spike neuron to learn the suitable spike amplitude, thus our SNN will adopt different spike amplitudes along layers, which can better suit the phenomenon that the membrane potential distributions are different along layers. To retain the efficiency of the vanilla ternary spike, the trainable ternary spike SNN will be converted to a standard one again via a re-parameterization technique in the inference. Extensive experiments with several popular network structures over static and dynamic datasets show that the ternary spike can consistently outperform state-of-the-art methods. Our code is open-sourced at https://github.com/yfguo91/Ternary-Spike. ",
    "url": "https://arxiv.org/abs/2312.06372",
    "authors": [
      "Yufei Guo",
      "Yuanpei Chen",
      "Xiaode Liu",
      "Weihang Peng",
      "Yuhan Zhang",
      "Xuhui Huang",
      "Zhe Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06374",
    "title": "UstanceBR: a multimodal language resource for stance prediction",
    "abstract": "This work introduces UstanceBR, a multimodal corpus in the Brazilian Portuguese Twitter domain for target-based stance prediction. The corpus comprises 86.8 k labelled stances towards selected target topics, and extensive network information about the users who published these stances on social media. In this article we describe the corpus multimodal data, and a number of usage examples in both in-domain and zero-shot stance prediction based on text- and network-related information, which are intended to provide initial baseline results for future studies in the field. ",
    "url": "https://arxiv.org/abs/2312.06374",
    "authors": [
      "Camila Pereira",
      "Matheus Pavan",
      "Sungwon Yoon",
      "Ricelli Ramos",
      "Pablo Costa",
      "Lais Cavalheiro",
      "Ivandre Paraboni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.06377",
    "title": "Algorithms and Turing Kernels for Detecting and Counting Small Patterns  in Unit Disk Graphs",
    "abstract": "In this paper we investigate the parameterized complexity of the task of counting and detecting occurrences of small patterns in unit disk graphs: Given an $n$-vertex unit disk graph $G$ with an embedding of ply $p$ (that is, the graph is represented as intersection graph with closed disks of unit size, and each point is contained in at most $p$ disks) and a $k$-vertex unit disk graph $P$, count the number of (induced) copies of $P$ in $G$. For general patterns $P$, we give an $2^{O(p k /\\log k)}n^{O(1)}$ time algorithm for counting pattern occurrences. We show this is tight, even for ply $p=2$ and $k=n$: any $2^{o(n/\\log n)}n^{O(1)}$ time algorithm violates the Exponential Time Hypothesis (ETH). For most natural classes of patterns, such as connected graphs and independent sets we present the following results: First, we give an $(pk)^{O(\\sqrt{pk})}n^{O(1)}$ time algorithm, which is nearly tight under the ETH for bounded ply and many patterns. Second, for $p= k^{O(1)}$ we provide a Turing kernelization (i.e. we give a polynomial time preprocessing algorithm to reduce the instance size to $k^{O(1)}$). Our approach combines previous tools developed for planar subgraph isomorphism such as `efficient inclusion-exclusion' from [Nederlof STOC'20], and `isomorphisms checks' from [Bodlaender et al. ICALP'16] with a different separator hierarchy and a new bound on the number of non-isomorphic separations of small order tailored for unit disk graphs. ",
    "url": "https://arxiv.org/abs/2312.06377",
    "authors": [
      "Jesper Nederlof",
      "Krisztina Szil\u00e1gyi"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2312.06398",
    "title": "NVFi: Neural Velocity Fields for 3D Physics Learning from Dynamic Videos",
    "abstract": "In this paper, we aim to model 3D scene dynamics from multi-view videos. Unlike the majority of existing works which usually focus on the common task of novel view synthesis within the training time period, we propose to simultaneously learn the geometry, appearance, and physical velocity of 3D scenes only from video frames, such that multiple desirable applications can be supported, including future frame extrapolation, unsupervised 3D semantic scene decomposition, and dynamic motion transfer. Our method consists of three major components, 1) the keyframe dynamic radiance field, 2) the interframe velocity field, and 3) a joint keyframe and interframe optimization module which is the core of our framework to effectively train both networks. To validate our method, we further introduce two dynamic 3D datasets: 1) Dynamic Object dataset, and 2) Dynamic Indoor Scene dataset. We conduct extensive experiments on multiple datasets, demonstrating the superior performance of our method over all baselines, particularly in the critical tasks of future frame extrapolation and unsupervised 3D semantic scene decomposition. ",
    "url": "https://arxiv.org/abs/2312.06398",
    "authors": [
      "Jinxi Li",
      "Ziyang Song",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.06406",
    "title": "Partial End-to-end Reinforcement Learning for Robustness Against  Modelling Error in Autonomous Racing",
    "abstract": "In this paper, we address the issue of increasing the performance of reinforcement learning (RL) solutions for autonomous racing cars when navigating under conditions where practical vehicle modelling errors (commonly known as \\emph{model mismatches}) are present. To address this challenge, we propose a partial end-to-end algorithm that decouples the planning and control tasks. Within this framework, an RL agent generates a trajectory comprising a path and velocity, which is subsequently tracked using a pure pursuit steering controller and a proportional velocity controller, respectively. In contrast, many current learning-based (i.e., reinforcement and imitation learning) algorithms utilise an end-to-end approach whereby a deep neural network directly maps from sensor data to control commands. By leveraging the robustness of a classical controller, our partial end-to-end driving algorithm exhibits better robustness towards model mismatches than standard end-to-end algorithms. ",
    "url": "https://arxiv.org/abs/2312.06406",
    "authors": [
      "Andrew Murdoch",
      "Johannes Cornelius Schoeman",
      "Hendrik Willem Jordaan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06423",
    "title": "MalPurifier: Enhancing Android Malware Detection with Adversarial  Purification against Evasion Attacks",
    "abstract": "Machine learning (ML) has gained significant adoption in Android malware detection to address the escalating threats posed by the rapid proliferation of malware attacks. However, recent studies have revealed the inherent vulnerabilities of ML-based detection systems to evasion attacks. While efforts have been made to address this critical issue, many of the existing defensive methods encounter challenges such as lower effectiveness or reduced generalization capabilities. In this paper, we introduce a novel Android malware detection method, MalPurifier, which exploits adversarial purification to eliminate perturbations independently, resulting in attack mitigation in a light and flexible way. Specifically, MalPurifier employs a Denoising AutoEncoder (DAE)-based purification model to preprocess input samples, removing potential perturbations from them and then leading to correct classification. To enhance defense effectiveness, we propose a diversified adversarial perturbation mechanism that strengthens the purification model against different manipulations from various evasion attacks. We also incorporate randomized \"protective noises\" onto benign samples to prevent excessive purification. Furthermore, we customize a loss function for improving the DAE model, combining reconstruction loss and prediction loss, to enhance feature representation learning, resulting in accurate reconstruction and classification. Experimental results on two Android malware datasets demonstrate that MalPurifier outperforms the state-of-the-art defenses, and it significantly strengthens the vulnerable malware detector against 37 evasion attacks, achieving accuracies over 90.91%. Notably, MalPurifier demonstrates easy scalability to other detectors, offering flexibility and robustness in its implementation. ",
    "url": "https://arxiv.org/abs/2312.06423",
    "authors": [
      "Yuyang Zhou",
      "Guang Cheng",
      "Zongyao Chen",
      "Shui Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06424",
    "title": "Cross Domain LifeLong Sequential Modeling for Online Click-Through Rate  Prediction",
    "abstract": "Deep neural networks (DNNs) that incorporated lifelong sequential modeling (LSM) have brought great success to recommendation systems in various social media platforms. While continuous improvements have been made in domain-specific LSM, limited work has been done in cross-domain LSM, which considers modeling of lifelong sequences of both target domain and source domain. In this paper, we propose Lifelong Cross Network (LCN) to incorporate cross-domain LSM to improve the click-through rate (CTR) prediction in the target domain. The proposed LCN contains a LifeLong Attention Pyramid (LAP) module that comprises of three levels of cascaded attentions to effectively extract interest representations with respect to the candidate item from lifelong sequences. We also propose Cross Representation Production (CRP) module to enforce additional supervision on the learning and alignment of cross-domain representations so that they can be better reused on learning of the CTR prediction in the target domain. We conducted extensive experiments on WeChat Channels industrial dataset as well as on benchmark dataset. Results have revealed that the proposed LCN outperforms existing work in terms of both prediction accuracy and online performance. ",
    "url": "https://arxiv.org/abs/2312.06424",
    "authors": [
      "Ruijie Hou",
      "Zhaoyang Yang",
      "Yu Ming",
      "Hongyu Lu",
      "Zhuobin Zheng",
      "Yu Chen",
      "Qinsong Zeng",
      "Ming Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.06428",
    "title": "VisionTraj: A Noise-Robust Trajectory Recovery Framework based on  Large-scale Camera Network",
    "abstract": "Trajectory recovery based on the snapshots from the city-wide multi-camera network facilitates urban mobility sensing and driveway optimization. The state-of-the-art solutions devoted to such a vision-based scheme typically incorporate predefined rules or unsupervised iterative feedback, struggling with multi-fold challenges such as lack of open-source datasets for training the whole pipeline, and the vulnerability to the noises from visual inputs. In response to the dilemma, this paper proposes VisionTraj, the first learning-based model that reconstructs vehicle trajectories from snapshots recorded by road network cameras. Coupled with it, we elaborate on two rational vision-trajectory datasets, which produce extensive trajectory data along with corresponding visual snapshots, enabling supervised vision-trajectory interplay extraction. Following the data creation, based on the results from the off-the-shelf multi-modal vehicle clustering, we first re-formulate the trajectory recovery problem as a generative task and introduce the canonical Transformer as the autoregressive backbone. Then, to identify clustering noises (e.g., false positives) with the bound on the snapshots' spatiotemporal dependencies, a GCN-based soft-denoising module is conducted based on the fine- and coarse-grained Re-ID clusters. Additionally, we harness strong semantic information extracted from the tracklet to provide detailed insights into the vehicle's entry and exit actions during trajectory recovery. The denoising and tracklet components can also act as plug-and-play modules to boost baselines. Experimental results on the two hand-crafted datasets show that the proposed VisionTraj achieves a maximum +11.5% improvement against the sub-best model. ",
    "url": "https://arxiv.org/abs/2312.06428",
    "authors": [
      "Zhishuai Li",
      "Ziyue Li",
      "Xiaoru Hu",
      "Guoqing Du",
      "Yunhao Nie",
      "Feng Zhu",
      "Lei Bai",
      "Rui Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06440",
    "title": "Towards A Flexible Accuracy-Oriented Deep Learning Module Inference  Latency Prediction Framework for Adaptive Optimization Algorithms",
    "abstract": "With the rapid development of Deep Learning, more and more applications on the cloud and edge tend to utilize large DNN (Deep Neural Network) models for improved task execution efficiency as well as decision-making quality. Due to memory constraints, models are commonly optimized using compression, pruning, and partitioning algorithms to become deployable onto resource-constrained devices. As the conditions in the computational platform change dynamically, the deployed optimization algorithms should accordingly adapt their solutions. To perform frequent evaluations of these solutions in a timely fashion, RMs (Regression Models) are commonly trained to predict the relevant solution quality metrics, such as the resulted DNN module inference latency, which is the focus of this paper. Existing prediction frameworks specify different RM training workflows, but none of them allow flexible configurations of the input parameters (e.g., batch size, device utilization rate) and of the selected RMs for different modules. In this paper, a deep learning module inference latency prediction framework is proposed, which i) hosts a set of customizable input parameters to train multiple different RMs per DNN module (e.g., convolutional layer) with self-generated datasets, and ii) automatically selects a set of trained RMs leading to the highest possible overall prediction accuracy, while keeping the prediction time / space consumption as low as possible. Furthermore, a new RM, namely MEDN (Multi-task Encoder-Decoder Network), is proposed as an alternative solution. Comprehensive experiment results show that MEDN is fast and lightweight, and capable of achieving the highest overall prediction accuracy and R-squared value. The Time/Space-efficient Auto-selection algorithm also manages to improve the overall accuracy by 2.5% and R-squared by 0.39%, compared to the MEDN single-selection scheme. ",
    "url": "https://arxiv.org/abs/2312.06440",
    "authors": [
      "Jingran Shen",
      "Nikos Tziritas",
      "Georgios Theodoropoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2312.06441",
    "title": "Revisiting Graph-based Fraud Detection in Sight of Heterophily and  Spectrum",
    "abstract": "Graph-based fraud detection (GFD) can be regarded as a challenging semi-supervised node binary classification task. In recent years, Graph Neural Networks(GNN) have been widely applied to GFD, characterizing the anomalous possibility of a node by aggregating neighbor information. However, fraud graphs are inherently heterophilic, thus most of GNNs perform poorly due to their assumption of homophily. In addition, due to the existence of heterophily and class imbalance problem, the existing models do not fully utilize the precious node label information. To address the above issues, this paper proposes a semi-supervised GNN-based fraud detector SEC-GFD. This detector includes a hybrid filtering module and a local environmental constraint module, the two modules are utilized to solve heterophily and label utilization problem respectively. The first module starts from the perspective of the spectral domain, and solves the heterophily problem to a certain extent. Specifically, it divides the spectrum into multiple mixed frequency bands according to the correlation between spectrum energy distribution and heterophily. Then in order to make full use of the node label information, a local environmental constraint module is adaptively designed. The comprehensive experimental results on four real-world fraud detection datasets show that SEC-GFD outperforms other competitive graph-based fraud detectors. ",
    "url": "https://arxiv.org/abs/2312.06441",
    "authors": [
      "Fan Xu",
      "Nan Wang",
      "Hao Wu",
      "Xuezhi Wen",
      "Xibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.06446",
    "title": "Experimental demonstration of a robust training method for strongly  defective neuromorphic hardware",
    "abstract": "The increasing scale of neural networks needed to support more complex applications has led to an increasing requirement for area- and energy-efficient hardware. One route to meeting the budget for these applications is to circumvent the von Neumann bottleneck by performing computation in or near memory. An inevitability of transferring neural networks onto hardware is that non-idealities such as device-to-device variations or poor device yield impact performance. Methods such as hardware-aware training, where substrate non-idealities are incorporated during network training, are one way to recover performance at the cost of solution generality. In this work, we demonstrate inference on hardware neural networks consisting of 20,000 magnetic tunnel junction arrays integrated on a complementary metal-oxide-semiconductor chips that closely resembles market-ready spin transfer-torque magnetoresistive random access memory technology. Using 36 dies, each containing a crossbar array with its own non-idealities, we show that even a small number of defects in physically mapped networks significantly degrades the performance of networks trained without defects and show that, at the cost of generality, hardware-aware training accounting for specific defects on each die can recover to comparable performance with ideal networks. We then demonstrate a robust training method that extends hardware-aware training to statistics-aware training, producing network weights that perform well on most defective dies regardless of their specific defect locations. When evaluated on the 36 physical dies, statistics-aware trained solutions can achieve a mean misclassification error on the MNIST dataset that differs from the software-baseline by only 2 %. This statistics-aware training method could be generalized to networks with many layers that are mapped to hardware suited for industry-ready applications. ",
    "url": "https://arxiv.org/abs/2312.06446",
    "authors": [
      "William A. Borders",
      "Advait Madhavan",
      "Matthew W. Daniels",
      "Vasileia Georgiou",
      "Martin Lueker-Boden",
      "Tiffany S. Santos",
      "Patrick M. Braganca",
      "Mark D. Stiles",
      "Jabez J. McClelland",
      "Brian D. Hoskins"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2312.06474",
    "title": "Relevant Intrinsic Feature Enhancement Network for Few-Shot Semantic  Segmentation",
    "abstract": "For few-shot semantic segmentation, the primary task is to extract class-specific intrinsic information from limited labeled data. However, the semantic ambiguity and inter-class similarity of previous methods limit the accuracy of pixel-level foreground-background classification. To alleviate these issues, we propose the Relevant Intrinsic Feature Enhancement Network (RiFeNet). To improve the semantic consistency of foreground instances, we propose an unlabeled branch as an efficient data utilization method, which teaches the model how to extract intrinsic features robust to intra-class differences. Notably, during testing, the proposed unlabeled branch is excluded without extra unlabeled data and computation. Furthermore, we extend the inter-class variability between foreground and background by proposing a novel multi-level prototype generation and interaction module. The different-grained complementarity between global and local prototypes allows for better distinction between similar categories. The qualitative and quantitative performance of RiFeNet surpasses the state-of-the-art methods on PASCAL-5i and COCO benchmarks. ",
    "url": "https://arxiv.org/abs/2312.06474",
    "authors": [
      "Xiaoyi Bao",
      "Jie Qin",
      "Siyang Sun",
      "Yun Zheng",
      "Xingang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06475",
    "title": "NetROS-5G: Enhancing Personalization through 5G Network Slicing and Edge  Computing in Human-Robot Interactions",
    "abstract": "Robots are increasingly being used in a variety of applications, from manufacturing and healthcare to education and customer service. However, the mobility, power, and price points of these robots often dictate that they do not have sufficient computing power on board to run modern algorithms for personalization in human-robot interaction at desired rates. This can limit the effectiveness of the interaction and limit the potential applications for these robots. 5G connectivity provides a solution to this problem by offering high data rates, bandwidth, and low latency that can facilitate robotics services. Additionally, the widespread availability of cloud computing has made it easy to access almost unlimited computing power at a low cost. Edge computing, which involves placing compute resources closer to the action, can offer even lower latency than cloud computing. In this paper, we explore the potential of combining 5G, edge, and cloud computing to provide improved personalization in human-robot interaction. We design, develop, and demonstrate a new framework, entitled NetROS-5G, to show how the performance gained by utilizing these technologies can overcome network latency and significantly enhance personalization in robotics. Our results show that the integration of 5G network slicing, edge computing, and cloud computing can collectively offer a cost-efficient and superior level of personalization in a modern human-robot interaction scenario. ",
    "url": "https://arxiv.org/abs/2312.06475",
    "authors": [
      "Anestis Dalgkitsis",
      "Christos Verikoukis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.06486",
    "title": "STDiff: Spatio-temporal Diffusion for Continuous Stochastic Video  Prediction",
    "abstract": "Predicting future frames of a video is challenging because it is difficult to learn the uncertainty of the underlying factors influencing their contents. In this paper, we propose a novel video prediction model, which has infinite-dimensional latent variables over the spatio-temporal domain. Specifically, we first decompose the video motion and content information, then take a neural stochastic differential equation to predict the temporal motion information, and finally, an image diffusion model autoregressively generates the video frame by conditioning on the predicted motion feature and the previous frame. The better expressiveness and stronger stochasticity learning capability of our model lead to state-of-the-art video prediction performances. As well, our model is able to achieve temporal continuous prediction, i.e., predicting in an unsupervised way the future video frames with an arbitrarily high frame rate. Our code is available at \\url{https://github.com/XiYe20/STDiffProject}. ",
    "url": "https://arxiv.org/abs/2312.06486",
    "authors": [
      "Xi Ye",
      "Guillaume-Alexandre Bilodeau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06515",
    "title": "A Golden-Free Formal Method for Trojan Detection in Non-Interfering  Accelerators",
    "abstract": "The threat of hardware Trojans (HTs) in security-critical IPs like cryptographic accelerators poses severe security risks. The HT detection methods available today mostly rely on golden models and detailed circuit specifications. Often they are specific to certain HT payload types, making pre-silicon verification difficult and leading to security gaps. We propose a novel formal verification method for HT detection in non-interfering accelerators at the Register Transfer Level (RTL), employing standard formal property checking. Our method guarantees the exhaustive detection of any sequential HT independently of its payload behavior, including physical side channels. It does not require a golden model or a functional specification of the design. The experimental results demonstrate efficient and effective detection of all sequential HTs in accelerators available on Trust-Hub, including those with complex triggers and payloads. ",
    "url": "https://arxiv.org/abs/2312.06515",
    "authors": [
      "Anna Lena Duque Ant\u00f3n",
      "Johannes M\u00fcller",
      "Lucas Deutschmann",
      "Mohammad Rahmani Fadiheh",
      "Dominik Stoffel",
      "Wolfgang Kunz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.06519",
    "title": "A GAN Approach for Node Embedding in Heterogeneous Graphs Using Subgraph  Sampling",
    "abstract": "Our research addresses class imbalance issues in heterogeneous graphs using graph neural networks (GNNs). We propose a novel method combining the strengths of Generative Adversarial Networks (GANs) with GNNs, creating synthetic nodes and edges that effectively balance the dataset. This approach directly targets and rectifies imbalances at the data level. The proposed framework resolves issues such as neglecting graph structures during data generation and creating synthetic structures usable with GNN-based classifiers in downstream tasks. It processes node and edge information concurrently, improving edge balance through node augmentation and subgraph sampling. Additionally, our framework integrates a threshold strategy, aiding in determining optimal edge thresholds during training without time-consuming parameter adjustments. Experiments on the Amazon and Yelp Review datasets highlight the effectiveness of the framework we proposed, especially in minority node identification, where it consistently outperforms baseline models across key performance metrics, demonstrating its potential in the field. ",
    "url": "https://arxiv.org/abs/2312.06519",
    "authors": [
      "Hung Chun Hsu",
      "Bo-Jun Wu",
      "Ming-Yi Hong",
      "Che Lin",
      "Chih-Yu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.06557",
    "title": "Robust Graph Neural Network based on Graph Denoising",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a notorious alternative to address learning problems dealing with non-Euclidean datasets. However, although most works assume that the graph is perfectly known, the observed topology is prone to errors stemming from observational noise, graph-learning limitations, or adversarial attacks. If ignored, these perturbations may drastically hinder the performance of GNNs. To address this limitation, this work proposes a robust implementation of GNNs that explicitly accounts for the presence of perturbations in the observed topology. For any task involving GNNs, our core idea is to i) solve an optimization problem not only over the learnable parameters of the GNN but also over the true graph, and ii) augment the fitting cost with a term accounting for discrepancies on the graph. Specifically, we consider a convolutional GNN based on graph filters and follow an alternating optimization approach to handle the (non-differentiable and constrained) optimization problem by combining gradient descent and projected proximal updates. The resulting algorithm is not limited to a particular type of graph and is amenable to incorporating prior information about the perturbations. Finally, we assess the performance of the proposed method through several numerical experiments. ",
    "url": "https://arxiv.org/abs/2312.06557",
    "authors": [
      "Victor M. Tenorio",
      "Samuel Rey",
      "Antonio G. Marques"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.06561",
    "title": "Inferring Hybrid Neural Fluid Fields from Videos",
    "abstract": "We study recovering fluid density and velocity from sparse multiview videos. Existing neural dynamic reconstruction methods predominantly rely on optical flows; therefore, they cannot accurately estimate the density and uncover the underlying velocity due to the inherent visual ambiguities of fluid velocity, as fluids are often shapeless and lack stable visual features. The challenge is further pronounced by the turbulent nature of fluid flows, which calls for properly designed fluid velocity representations. To address these challenges, we propose hybrid neural fluid fields (HyFluid), a neural approach to jointly infer fluid density and velocity fields. Specifically, to deal with visual ambiguities of fluid velocity, we introduce a set of physics-based losses that enforce inferring a physically plausible velocity field, which is divergence-free and drives the transport of density. To deal with the turbulent nature of fluid velocity, we design a hybrid neural velocity representation that includes a base neural velocity field that captures most irrotational energy and a vortex particle-based velocity that models residual turbulent velocity. We show that our method enables recovering vortical flow details. Our approach opens up possibilities for various learning and reconstruction applications centered around 3D incompressible flow, including fluid re-simulation and editing, future prediction, and neural dynamic scene composition. Project website: https://kovenyu.com/HyFluid/ ",
    "url": "https://arxiv.org/abs/2312.06561",
    "authors": [
      "Hong-Xing Yu",
      "Yang Zheng",
      "Yuan Gao",
      "Yitong Deng",
      "Bo Zhu",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2312.06564",
    "title": "Promoting Counterfactual Robustness through Diversity",
    "abstract": "Counterfactual explanations shed light on the decisions of black-box models by explaining how an input can be altered to obtain a favourable decision from the model (e.g., when a loan application has been rejected). However, as noted recently, counterfactual explainers may lack robustness in the sense that a minor change in the input can cause a major change in the explanation. This can cause confusion on the user side and open the door for adversarial attacks. In this paper, we study some sources of non-robustness. While there are fundamental reasons for why an explainer that returns a single counterfactual cannot be robust in all instances, we show that some interesting robustness guarantees can be given by reporting multiple rather than a single counterfactual. Unfortunately, the number of counterfactuals that need to be reported for the theoretical guarantees to hold can be prohibitively large. We therefore propose an approximation algorithm that uses a diversity criterion to select a feasible number of most relevant explanations and study its robustness empirically. Our experiments indicate that our method improves the state-of-the-art in generating robust explanations, while maintaining other desirable properties and providing competitive computational performance. ",
    "url": "https://arxiv.org/abs/2312.06564",
    "authors": [
      "Francesco Leofante",
      "Nico Potyka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.06566",
    "title": "One Size Does not Fit All: Personalised Affordance Design for Social  Robots",
    "abstract": "Personalisation is essential to achieve more acceptable and effective results in human-robot interaction. Placing users in the central role, many studies have focused on enhancing the abilities of social robots to perceive and understand users. However, little is known about improving user perceptions and interpretation of a social robot in spoken interactions. The work described in the paper aims to find out what affects the personalisation of affordance of a social robot, namely its appearance, voice and language behaviours. The experimental data presented here is based on an ongoing project. It demonstrates the many and varied ways in which people change their preferences for the affordance of a social robot under different circumstances. It also examines the relationship between such preferences and expectations of characteristics of a social robot, like competence and warmth. It also shows that individuals have different perceptions of the language behaviours of the same robot. These results demonstrate that one-sized personalisation does not fit all. Personalisation should be considered a comprehensive approach, including appropriate affordance design, to suit the user expectations of social roles. ",
    "url": "https://arxiv.org/abs/2312.06566",
    "authors": [
      "Guanyu Huang",
      "Roger K. Moore"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2312.06568",
    "title": "Sparse but Strong: Crafting Adversarially Robust Graph Lottery Tickets",
    "abstract": "Graph Lottery Tickets (GLTs), comprising a sparse adjacency matrix and a sparse graph neural network (GNN), can significantly reduce the inference latency and compute footprint compared to their dense counterparts. Despite these benefits, their performance against adversarial structure perturbations remains to be fully explored. In this work, we first investigate the resilience of GLTs against different structure perturbation attacks and observe that they are highly vulnerable and show a large drop in classification accuracy. Based on this observation, we then present an adversarially robust graph sparsification (ARGS) framework that prunes the adjacency matrix and the GNN weights by optimizing a novel loss function capturing the graph homophily property and information associated with both the true labels of the train nodes and the pseudo labels of the test nodes. By iteratively applying ARGS to prune both the perturbed graph adjacency matrix and the GNN model weights, we can find adversarially robust graph lottery tickets that are highly sparse yet achieve competitive performance under different untargeted training-time structure attacks. Evaluations conducted on various benchmarks, considering different poisoning structure attacks, namely, PGD, MetaAttack, Meta-PGD, and PR-BCD demonstrate that the GLTs generated by ARGS can significantly improve the robustness, even when subjected to high levels of sparsity. ",
    "url": "https://arxiv.org/abs/2312.06568",
    "authors": [
      "Subhajit Dutta Chowdhury",
      "Zhiyu Ni",
      "Qingyuan Peng",
      "Souvik Kundu",
      "Pierluigi Nuzzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.06569",
    "title": "Ambient IoT: A missing link in 3GPP IoT Devices Landscape",
    "abstract": "Ambient internet of things (IoT) is the network of devices which harvest energy from ambient sources for powering their communication. After decades of research on operation of these devices, Third Generation Partnership Project (3GPP) has started discussing energy harvesting technology in cellular networks to support massive deployment of IoT devices at low operational cost. This article provides a timely update on 3GPP studies on ambient energy harvesting devices including device types, use cases, key requirements, and related design challenges. Supported by link budget analysis for backscattering energy harvesting devices, which are a key component of this study, we provide insight on system design and show how this technology will require a new system design approach as compared to New Radio (NR) system design in 5G. ",
    "url": "https://arxiv.org/abs/2312.06569",
    "authors": [
      "M. Majid Butt",
      "Nitin R. Mangalvedhe",
      "Nuno K. Pratas",
      "Johannes Harrebek",
      "John Kimionis",
      "Muhammad Tayyab",
      "Oana-Elena Barbu",
      "Rapeepat Ratasuk",
      "Benny Vejlgaard"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.06575",
    "title": "EasyVolcap: Accelerating Neural Volumetric Video Research",
    "abstract": "Volumetric video is a technology that digitally records dynamic events such as artistic performances, sporting events, and remote conversations. When acquired, such volumography can be viewed from any viewpoint and timestamp on flat screens, 3D displays, or VR headsets, enabling immersive viewing experiences and more flexible content creation in a variety of applications such as sports broadcasting, video conferencing, gaming, and movie productions. With the recent advances and fast-growing interest in neural scene representations for volumetric video, there is an urgent need for a unified open-source library to streamline the process of volumetric video capturing, reconstruction, and rendering for both researchers and non-professional users to develop various algorithms and applications of this emerging technology. In this paper, we present EasyVolcap, a Python & Pytorch library for accelerating neural volumetric video research with the goal of unifying the process of multi-view data processing, 4D scene reconstruction, and efficient dynamic volumetric video rendering. Our source code is available at https://github.com/zju3dv/EasyVolcap. ",
    "url": "https://arxiv.org/abs/2312.06575",
    "authors": [
      "Zhen Xu",
      "Tao Xie",
      "Sida Peng",
      "Haotong Lin",
      "Qing Shuai",
      "Zhiyuan Yu",
      "Guangzhao He",
      "Jiaming Sun",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06576",
    "title": "HyPE-GT: where Graph Transformers meet Hyperbolic Positional Encodings",
    "abstract": "Graph Transformers (GTs) facilitate the comprehension of graph-structured data by calculating the self-attention of node pairs without considering node position information. To address this limitation, we introduce an innovative and efficient framework that introduces Positional Encodings (PEs) into the Transformer, generating a set of learnable positional encodings in the hyperbolic space, a non-Euclidean domain. This approach empowers us to explore diverse options for optimal selection of PEs for specific downstream tasks, leveraging hyperbolic neural networks or hyperbolic graph convolutional networks. Additionally, we repurpose these positional encodings to mitigate the impact of over-smoothing in deep Graph Neural Networks (GNNs). Comprehensive experiments on molecular benchmark datasets, co-author, and co-purchase networks substantiate the effectiveness of hyperbolic positional encodings in enhancing the performance of deep GNNs. ",
    "url": "https://arxiv.org/abs/2312.06576",
    "authors": [
      "Kushal Bose",
      "Swagatam Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06607",
    "title": "DiAD: A Diffusion-based Framework for Multi-class Anomaly Detection",
    "abstract": "Reconstruction-based approaches have achieved remarkable outcomes in anomaly detection. The exceptional image reconstruction capabilities of recently popular diffusion models have sparked research efforts to utilize them for enhanced reconstruction of anomalous images. Nonetheless, these methods might face challenges related to the preservation of image categories and pixel-wise structural integrity in the more practical multi-class setting. To solve the above problems, we propose a Difusion-based Anomaly Detection (DiAD) framework for multi-class anomaly detection, which consists of a pixel-space autoencoder, a latent-space Semantic-Guided (SG) network with a connection to the stable diffusion's denoising network, and a feature-space pre-trained feature extractor. Firstly, The SG network is proposed for reconstructing anomalous regions while preserving the original image's semantic information. Secondly, we introduce Spatial-aware Feature Fusion (SFF) block to maximize reconstruction accuracy when dealing with extensively reconstructed areas. Thirdly, the input and reconstructed images are processed by a pre-trained feature extractor to generate anomaly maps based on features extracted at different scales. Experiments on MVTec-AD and VisA datasets demonstrate the effectiveness of our approach which surpasses the state-of-the-art methods, e.g., achieving 96.8/52.6 and 97.2/99.0 (AUROC/AP) for localization and detection respectively on multi-class MVTec-AD dataset. Code will be available at https://lewandofskee.github.io/projects/diad. ",
    "url": "https://arxiv.org/abs/2312.06607",
    "authors": [
      "Haoyang He",
      "Jiangning Zhang",
      "Hongxu Chen",
      "Xuhai Chen",
      "Zhishan Li",
      "Xu Chen",
      "Yabiao Wang",
      "Chengjie Wang",
      "Lei Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06613",
    "title": "Neural Text to Articulate Talk: Deep Text to Audiovisual Speech  Synthesis achieving both Auditory and Photo-realism",
    "abstract": "Recent advances in deep learning for sequential data have given rise to fast and powerful models that produce realistic videos of talking humans. The state of the art in talking face generation focuses mainly on lip-syncing, being conditioned on audio clips. However, having the ability to synthesize talking humans from text transcriptions rather than audio is particularly beneficial for many applications and is expected to receive more and more attention, following the recent breakthroughs in large language models. For that, most methods implement a cascaded 2-stage architecture of a text-to-speech module followed by an audio-driven talking face generator, but this ignores the highly complex interplay between audio and visual streams that occurs during speaking. In this paper, we propose the first, to the best of our knowledge, text-driven audiovisual speech synthesizer that uses Transformers and does not follow a cascaded approach. Our method, which we call NEUral Text to ARticulate Talk (NEUTART), is a talking face generator that uses a joint audiovisual feature space, as well as speech-informed 3D facial reconstructions and a lip-reading loss for visual supervision. The proposed model produces photorealistic talking face videos with human-like articulation and well-synced audiovisual streams. Our experiments on audiovisual datasets as well as in-the-wild videos reveal state-of-the-art generation quality both in terms of objective metrics and human evaluation. ",
    "url": "https://arxiv.org/abs/2312.06613",
    "authors": [
      "Georgios Milis",
      "Panagiotis P. Filntisis",
      "Anastasios Roussos",
      "Petros Maragos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.06627",
    "title": "An adversarial attack approach for eXplainable AI evaluation on deepfake  detection models",
    "abstract": "With the rising concern on model interpretability, the application of eXplainable AI (XAI) tools on deepfake detection models has been a topic of interest recently. In image classification tasks, XAI tools highlight pixels influencing the decision given by a model. This helps in troubleshooting the model and determining areas that may require further tuning of parameters. With a wide range of tools available in the market, choosing the right tool for a model becomes necessary as each one may highlight different sets of pixels for a given image. There is a need to evaluate different tools and decide the best performing ones among them. Generic XAI evaluation methods like insertion or removal of salient pixels/segments are applicable for general image classification tasks but may produce less meaningful results when applied on deepfake detection models due to their functionality. In this paper, we perform experiments to show that generic removal/insertion XAI evaluation methods are not suitable for deepfake detection models. We also propose and implement an XAI evaluation approach specifically suited for deepfake detection models. ",
    "url": "https://arxiv.org/abs/2312.06627",
    "authors": [
      "Balachandar Gowrisankar",
      "Vrizlynn L.L. Thing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2312.06638",
    "title": "SurvBeNIM: The Beran-Based Neural Importance Model for Explaining the  Survival Models",
    "abstract": "A new method called the Survival Beran-based Neural Importance Model (SurvBeNIM) is proposed. It aims to explain predictions of machine learning survival models, which are in the form of survival or cumulative hazard functions. The main idea behind SurvBeNIM is to extend the Beran estimator by incorporating the importance functions into its kernels and by implementing these importance functions as a set of neural networks which are jointly trained in an end-to-end manner. Two strategies of using and training the whole neural network implementing SurvBeNIM are proposed. The first one explains a single instance, and the neural network is trained for each explained instance. According to the second strategy, the neural network only learns once on all instances from the dataset and on all generated instances. Then the neural network is used to explain any instance in a dataset domain. Various numerical experiments compare the method with different existing explanation methods. A code implementing the proposed method is publicly available. ",
    "url": "https://arxiv.org/abs/2312.06638",
    "authors": [
      "Lev V. Utkin",
      "Danila Y. Eremenko",
      "Andrei V. Konstantinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.06642",
    "title": "CorresNeRF: Image Correspondence Priors for Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRFs) have achieved impressive results in novel view synthesis and surface reconstruction tasks. However, their performance suffers under challenging scenarios with sparse input views. We present CorresNeRF, a novel method that leverages image correspondence priors computed by off-the-shelf methods to supervise NeRF training. We design adaptive processes for augmentation and filtering to generate dense and high-quality correspondences. The correspondences are then used to regularize NeRF training via the correspondence pixel reprojection and depth loss terms. We evaluate our methods on novel view synthesis and surface reconstruction tasks with density-based and SDF-based NeRF models on different datasets. Our method outperforms previous methods in both photometric and geometric metrics. We show that this simple yet effective technique of using correspondence priors can be applied as a plug-and-play module across different NeRF variants. The project page is at https://yxlao.github.io/corres-nerf. ",
    "url": "https://arxiv.org/abs/2312.06642",
    "authors": [
      "Yixing Lao",
      "Xiaogang Xu",
      "Zhipeng Cai",
      "Xihui Liu",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06643",
    "title": "Gaze Detection and Analysis for Initiating Joint Activity in Industrial  Human-Robot Collaboration",
    "abstract": "Collaborative robots (cobots) are widely used in industrial applications, yet extensive research is still needed to enhance human-robot collaborations and operator experience. A potential approach to improve the collaboration experience involves adapting cobot behavior based on natural cues from the operator. Inspired by the literature on human-human interactions, we conducted a wizard-of-oz study to examine whether a gaze towards the cobot can serve as a trigger for initiating joint activities in collaborative sessions. In this study, 37 participants engaged in an assembly task while their gaze behavior was analyzed. We employ a gaze-based attention recognition model to identify when the participants look at the cobot. Our results indicate that in most cases (84.88\\%), the joint activity is preceded by a gaze towards the cobot. Furthermore, during the entire assembly cycle, the participants tend to look at the cobot around the time of the joint activity. To the best of our knowledge, this is the first study to analyze the natural gaze behavior of participants working on a joint activity with a robot during a collaborative assembly task. ",
    "url": "https://arxiv.org/abs/2312.06643",
    "authors": [
      "Pooja Prajod",
      "Matteo Lavit Nicora",
      "Marta Mondellini",
      "Giovanni Tauro",
      "Rocco Vertechy",
      "Matteo Malosio",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2312.06645",
    "title": "Beyond Classification: Definition and Density-based Estimation of  Calibration in Object Detection",
    "abstract": "Despite their impressive predictive performance in various computer vision tasks, deep neural networks (DNNs) tend to make overly confident predictions, which hinders their widespread use in safety-critical applications. While there have been recent attempts to calibrate DNNs, most of these efforts have primarily been focused on classification tasks, thus neglecting DNN-based object detectors. Although several recent works addressed calibration for object detection and proposed differentiable penalties, none of them are consistent estimators of established concepts in calibration. In this work, we tackle the challenge of defining and estimating calibration error specifically for this task. In particular, we adapt the definition of classification calibration error to handle the nuances associated with object detection, and predictions in structured output spaces more generally. Furthermore, we propose a consistent and differentiable estimator of the detection calibration error, utilizing kernel density estimation. Our experiments demonstrate the effectiveness of our estimator against competing train-time and post-hoc calibration methods, while maintaining similar detection performance. ",
    "url": "https://arxiv.org/abs/2312.06645",
    "authors": [
      "Teodora Popordanoska",
      "Aleksei Tiulpin",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06653",
    "title": "Adaptive Human Trajectory Prediction via Latent Corridors",
    "abstract": "Human trajectory prediction is typically posed as a zero-shot generalization problem: a predictor is learnt on a dataset of human motion in training scenes, and then deployed on unseen test scenes. While this paradigm has yielded tremendous progress, it fundamentally assumes that trends in human behavior within the deployment scene are constant over time. As such, current prediction models are unable to adapt to scene-specific transient human behaviors, such as crowds temporarily gathering to see buskers, pedestrians hurrying through the rain and avoiding puddles, or a protest breaking out. We formalize the problem of scene-specific adaptive trajectory prediction and propose a new adaptation approach inspired by prompt tuning called latent corridors. By augmenting the input of any pre-trained human trajectory predictor with learnable image prompts, the predictor can improve in the deployment scene by inferring trends from extremely small amounts of new data (e.g., 2 humans observed for 30 seconds). With less than 0.1% additional model parameters, we see up to 23.9% ADE improvement in MOTSynth simulated data and 16.4% ADE in MOT and Wildtrack real pedestrian data. Qualitatively, we observe that latent corridors imbue predictors with an awareness of scene geometry and scene-specific human behaviors that non-adaptive predictors struggle to capture. The project website can be found at https://neerja.me/atp_latent_corridors/. ",
    "url": "https://arxiv.org/abs/2312.06653",
    "authors": [
      "Neerja Thakkar",
      "Karttikeya Mangalam",
      "Andrea Bajcsy",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06654",
    "title": "LightSim: Neural Lighting Simulation for Urban Scenes",
    "abstract": "Different outdoor illumination conditions drastically alter the appearance of urban scenes, and they can harm the performance of image-based robot perception systems if not seen during training. Camera simulation provides a cost-effective solution to create a large dataset of images captured under different lighting conditions. Towards this goal, we propose LightSim, a neural lighting camera simulation system that enables diverse, realistic, and controllable data generation. LightSim automatically builds lighting-aware digital twins at scale from collected raw sensor data and decomposes the scene into dynamic actors and static background with accurate geometry, appearance, and estimated scene lighting. These digital twins enable actor insertion, modification, removal, and rendering from a new viewpoint, all in a lighting-aware manner. LightSim then combines physically-based and learnable deferred rendering to perform realistic relighting of modified scenes, such as altering the sun location and modifying the shadows or changing the sun brightness, producing spatially- and temporally-consistent camera videos. Our experiments show that LightSim generates more realistic relighting results than prior work. Importantly, training perception models on data generated by LightSim can significantly improve their performance. ",
    "url": "https://arxiv.org/abs/2312.06654",
    "authors": [
      "Ava Pun",
      "Gary Sun",
      "Jingkang Wang",
      "Yun Chen",
      "Ze Yang",
      "Sivabalan Manivasagam",
      "Wei-Chiu Ma",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06658",
    "title": "Mean estimation in the add-remove model of differential privacy",
    "abstract": "Differential privacy is often studied under two different models of neighboring datasets: the add-remove model and the swap model. While the swap model is used extensively in the academic literature, many practical libraries use the more conservative add-remove model. However, analysis under the add-remove model can be cumbersome, and obtaining results with tight constants requires some additional work. Here, we study the problem of one-dimensional mean estimation under the add-remove model of differential privacy. We propose a new algorithm and show that it is min-max optimal, that it has the correct constant in the leading term of the mean squared error, and that this constant is the same as the optimal algorithm in the swap model. Our results show that, for mean estimation, the add-remove and swap model give nearly identical error even though the add-remove model cannot treat the size of the dataset as public information. In addition, we demonstrate empirically that our proposed algorithm yields a factor of two improvement in mean squared error over algorithms often used in practice. ",
    "url": "https://arxiv.org/abs/2312.06658",
    "authors": [
      "Alex Kulesza",
      "Ananda Theertha Suresh",
      "Yuyan Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.06663",
    "title": "CAD: Photorealistic 3D Generation via Adversarial Distillation",
    "abstract": "The increased demand for 3D data in AR/VR, robotics and gaming applications, gave rise to powerful generative pipelines capable of synthesizing high-quality 3D objects. Most of these models rely on the Score Distillation Sampling (SDS) algorithm to optimize a 3D representation such that the rendered image maintains a high likelihood as evaluated by a pre-trained diffusion model. However, finding a correct mode in the high-dimensional distribution produced by the diffusion model is challenging and often leads to issues such as over-saturation, over-smoothing, and Janus-like artifacts. In this paper, we propose a novel learning paradigm for 3D synthesis that utilizes pre-trained diffusion models. Instead of focusing on mode-seeking, our method directly models the distribution discrepancy between multi-view renderings and diffusion priors in an adversarial manner, which unlocks the generation of high-fidelity and photorealistic 3D content, conditioned on a single image and prompt. Moreover, by harnessing the latent space of GANs and expressive diffusion model priors, our method facilitates a wide variety of 3D applications including single-view reconstruction, high diversity generation and continuous 3D interpolation in the open domain. The experiments demonstrate the superiority of our pipeline compared to previous works in terms of generation quality and diversity. ",
    "url": "https://arxiv.org/abs/2312.06663",
    "authors": [
      "Ziyu Wan",
      "Despoina Paschalidou",
      "Ian Huang",
      "Hongyu Liu",
      "Bokui Shen",
      "Xiaoyu Xiang",
      "Jing Liao",
      "Leonidas Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2312.05258",
    "title": "Automated Small Kidney Cancer Detection in Non-Contrast Computed  Tomography",
    "abstract": "This study introduces an automated pipeline for renal cancer (RC) detection in non-contrast computed tomography (NCCT). In the development of our pipeline, we test three detections models: a shape model, a 2D-, and a 3D axial-sample model. Training (n=1348) and testing (n=64) data were gathered from open sources (KiTS23, Abdomen1k, CT-ORG) and Cambridge University Hospital (CUH). Results from cross-validation and testing revealed that the 2D axial sample model had the highest small ($\\leq$40mm diameter) RC detection area under the curve (AUC) of 0.804. Our pipeline achieves 61.9\\% sensitivity and 92.7\\% specificity for small kidney cancers on unseen test data. Our results are much more accurate than previous attempts to automatically detect small renal cancers in NCCT, the most likely imaging modality for RC screening. This pipeline offers a promising advance that may enable screening for kidney cancers. ",
    "url": "https://arxiv.org/abs/2312.05258",
    "authors": [
      "William McGough",
      "Thomas Buddenkotte",
      "Stephan Ursprung",
      "Zeyu Gao",
      "Grant Stewart",
      "Mireia Crispin-Ortuzar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2312.05273",
    "title": "Evaluating Zero-Shot Scoring for In Vitro Antibody Binding Prediction  with Experimental Validation",
    "abstract": "The success of therapeutic antibodies relies on their ability to selectively bind antigens. AI-based antibody design protocols have shown promise in generating epitope-specific designs. Many of these protocols use an inverse folding step to generate diverse sequences given a backbone structure. Due to prohibitive screening costs, it is key to identify candidate sequences likely to bind in vitro. Here, we compare the efficacy of 8 common scoring paradigms based on open-source models to classify antibody designs as binders or non-binders. We evaluate these approaches on a novel surface plasmon resonance (SPR) dataset, spanning 5 antigens. Our results show that existing methods struggle to detect binders, and performance is highly variable across antigens. We find that metrics computed on flexibly docked antibody-antigen complexes are more robust, and ensembles scores are more consistent than individual metrics. We provide experimental insight to analyze current scoring techniques, highlighting that the development of robust, zero-shot filters is an important research gap. ",
    "url": "https://arxiv.org/abs/2312.05273",
    "authors": [
      "Divya Nori",
      "Simon V. Mathis",
      "Amir Shanehsazzadeh"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2312.05279",
    "title": "Quantitative perfusion maps using a novelty spatiotemporal convolutional  neural network",
    "abstract": "Dynamic susceptibility contrast magnetic resonance imaging (DSC-MRI) is widely used to evaluate acute ischemic stroke to distinguish salvageable tissue and infarct core. For this purpose, traditional methods employ deconvolution techniques, like singular value decomposition, which are known to be vulnerable to noise, potentially distorting the derived perfusion parameters. However, deep learning technology could leverage it, which can accurately estimate clinical perfusion parameters compared to traditional clinical approaches. Therefore, this study presents a perfusion parameters estimation network that considers spatial and temporal information, the Spatiotemporal Network (ST-Net), for the first time. The proposed network comprises a designed physical loss function to enhance model performance further. The results indicate that the network can accurately estimate perfusion parameters, including cerebral blood volume (CBV), cerebral blood flow (CBF), and time to maximum of the residual function (Tmax). The structural similarity index (SSIM) mean values for CBV, CBF, and Tmax parameters were 0.952, 0.943, and 0.863, respectively. The DICE score for the hypo-perfused region reached 0.859, demonstrating high consistency. The proposed model also maintains time efficiency, closely approaching the performance of commercial gold-standard software. ",
    "url": "https://arxiv.org/abs/2312.05279",
    "authors": [
      "Anbo Cao",
      "Pin-Yu Le",
      "Zhonghui Qie",
      "Haseeb Hassan",
      "Yingwei Guo",
      "Asim Zaman",
      "Jiaxi Lu",
      "Xueqiang Zeng",
      "Huihui Yang",
      "Xiaoqiang Miao",
      "Taiyu Han",
      "Guangtao Huang",
      "Yan Kang",
      "Yu Luo",
      "Jia Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05334",
    "title": "ProsDectNet: Bridging the Gap in Prostate Cancer Detection via  Transrectal B-mode Ultrasound Imaging",
    "abstract": "Interpreting traditional B-mode ultrasound images can be challenging due to image artifacts (e.g., shadowing, speckle), leading to low sensitivity and limited diagnostic accuracy. While Magnetic Resonance Imaging (MRI) has been proposed as a solution, it is expensive and not widely available. Furthermore, most biopsies are guided by Transrectal Ultrasound (TRUS) alone and can miss up to 52% cancers, highlighting the need for improved targeting. To address this issue, we propose ProsDectNet, a multi-task deep learning approach that localizes prostate cancer on B-mode ultrasound. Our model is pre-trained using radiologist-labeled data and fine-tuned using biopsy-confirmed labels. ProsDectNet includes a lesion detection and patch classification head, with uncertainty minimization using entropy to improve model performance and reduce false positive predictions. We trained and validated ProsDectNet using a cohort of 289 patients who underwent MRI-TRUS fusion targeted biopsy. We then tested our approach on a group of 41 patients and found that ProsDectNet outperformed the average expert clinician in detecting prostate cancer on B-mode ultrasound images, achieving a patient-level ROC-AUC of 82%, a sensitivity of 74%, and a specificity of 67%. Our results demonstrate that ProsDectNet has the potential to be used as a computer-aided diagnosis system to improve targeted biopsy and treatment planning. ",
    "url": "https://arxiv.org/abs/2312.05334",
    "authors": [
      "Sulaiman Vesal",
      "Indrani Bhattacharya",
      "Hassan Jahanandish",
      "Xinran Li",
      "Zachary Kornberg",
      "Steve Ran Zhou",
      "Elijah Richard Sommer",
      "Moon Hyung Choi",
      "Richard E. Fan",
      "Geoffrey A. Sonn",
      "Mirabela Rusu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05388",
    "title": "Higher-Order Equivariant Neural Networks for Charge Density Prediction  in Materials",
    "abstract": "The calculation of electron density distribution using density functional theory (DFT) in materials and molecules is central to the study of their quantum and macro-scale properties, yet accurate and efficient calculation remains a long-standing challenge in the field of material science. This work introduces ChargE3Net, an E(3)-equivariant graph neural network for predicting electron density in atomic systems. ChargE3Net achieves equivariance through the use of higher-order tensor representations, and directly predicts the charge density at any arbitrary point in the system. We show that our method achieves greater performance than prior work on large and diverse sets of molecules and materials, and scales to larger systems than what is feasible to compute with DFT. Using predicted electron densities as an initialization, we show that fewer self-consistent iterations are required to converge DFT over the default initialization. In addition, we show that non-self-consistent calculations using the predicted electron densities can predict electronic and thermodynamic properties of materials at near-DFT accuracy. ",
    "url": "https://arxiv.org/abs/2312.05388",
    "authors": [
      "Teddy Koker",
      "Keegan Quigley",
      "Eric Taw",
      "Kevin Tibbetts",
      "Lin Li"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05687",
    "title": "Stellar Spectra Fitting with Amortized Neural Posterior Estimation and  nbi",
    "abstract": "Modern surveys often deliver hundreds of thousands of stellar spectra at once, which are fit to spectral models to derive stellar parameters/labels. Therefore, the technique of Amortized Neural Posterior Estimation (ANPE) stands out as a suitable approach, which enables the inference of large number of targets as sub-linear/constant computational costs. Leveraging our new nbi software package, we train an ANPE model for the APOGEE survey and demonstrate its efficacy on both mock and real APOGEE stellar spectra. Unique to the nbi package is its out-of-the-box functionality on astronomical inverse problems with sequential data. As such, we have been able to acquire the trained model with minimal effort. We introduce an effective approach to handling the measurement noise properties inherent in spectral data, which utilizes the actual uncertainties in the observed data. This allows training data to resemble observed data, an aspect that is crucial for ANPE applications. Given the association of spectral data properties with the observing instrument, we discuss the utility of an ANPE \"model zoo,\" where models are trained for specific instruments and distributed under the nbi framework to facilitate real-time stellar parameter inference. ",
    "url": "https://arxiv.org/abs/2312.05687",
    "authors": [
      "Keming Zhang",
      "Tharindu Jayasinghe",
      "Joshua S. Bloom"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05707",
    "title": "Non-Cartesian Self-Supervised Physics-Driven Deep Learning  Reconstruction for Highly-Accelerated Multi-Echo Spiral fMRI",
    "abstract": "Functional MRI (fMRI) is an important tool for non-invasive studies of brain function. Over the past decade, multi-echo fMRI methods that sample multiple echo times has become popular with potential to improve quantification. While these acquisitions are typically performed with Cartesian trajectories, non-Cartesian trajectories, in particular spiral acquisitions, hold promise for denser sampling of echo times. However, such acquisitions require very high acceleration rates for sufficient spatiotemporal resolutions. In this work, we propose to use a physics-driven deep learning (PD-DL) reconstruction to accelerate multi-echo spiral fMRI by 10-fold. We modify a self-supervised learning algorithm for optimized training with non-Cartesian trajectories and use it to train the PD-DL network. Results show that the proposed self-supervised PD-DL reconstruction achieves high spatio-temporal resolution with meaningful BOLD analysis. ",
    "url": "https://arxiv.org/abs/2312.05707",
    "authors": [
      "Hongyi Gu",
      "Chi Zhang",
      "Zidan Yu",
      "Christoph Rettenmeier",
      "V. Andrew Stenger",
      "Mehmet Ak\u00e7akaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2312.05774",
    "title": "Secured Quantum Identity Authentication Protocol for Quantum Networks",
    "abstract": "Quantum Internet signifies a remarkable advancement in communication technology, harnessing the principles of quantum entanglement and superposition to facilitate unparalleled levels of security and efficient computations. Quantum communication can be achieved through the utilization of quantum entanglement. Through the exchange of entangled pairs between two entities, quantum communication becomes feasible, enabled by the process of quantum teleportation. Given the lossy nature of the channels and the exponential decoherence of the transmitted photons, a set of intermediate nodes can serve as quantum repeaters to perform entanglement swapping and directly entangle two distant nodes. Such quantum repeaters may be malicious and by setting up malicious entanglements, intermediate nodes can jeopardize the confidentiality of the quantum information exchanged between the two communication nodes. Hence, this paper proposes a quantum identity authentication protocol that protects quantum networks from malicious entanglements. Unlike the existing protocols, the proposed quantum authentication protocol does not require periodic refreshments of the shared secret keys. Simulation results demonstrate that the proposed protocol can detect malicious entanglements with a 100% probability after an average of 4 authentication rounds. ",
    "url": "https://arxiv.org/abs/2312.05774",
    "authors": [
      "Mohamed Shaban",
      "Muhammad Ismail"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.05878",
    "title": "Skew Probabilistic Neural Networks for Learning from Imbalanced Data",
    "abstract": "Real-world datasets often exhibit imbalanced data distribution, where certain class levels are severely underrepresented. In such cases, traditional pattern classifiers have shown a bias towards the majority class, impeding accurate predictions for the minority class. This paper introduces an imbalanced data-oriented approach using probabilistic neural networks (PNNs) with a skew normal probability kernel to address this major challenge. PNNs are known for providing probabilistic outputs, enabling quantification of prediction confidence and uncertainty handling. By leveraging the skew normal distribution, which offers increased flexibility, particularly for imbalanced and non-symmetric data, our proposed Skew Probabilistic Neural Networks (SkewPNNs) can better represent underlying class densities. To optimize the performance of the proposed approach on imbalanced datasets, hyperparameter fine-tuning is imperative. To this end, we employ a population-based heuristic algorithm, Bat optimization algorithms, for effectively exploring the hyperparameter space. We also prove the statistical consistency of the density estimates which suggests that the true distribution will be approached smoothly as the sample size increases. Experimental simulations have been conducted on different synthetic datasets, comparing various benchmark-imbalanced learners. Our real-data analysis shows that SkewPNNs substantially outperform state-of-the-art machine learning methods for both balanced and imbalanced datasets in most experimental settings. ",
    "url": "https://arxiv.org/abs/2312.05878",
    "authors": [
      "Shraddha M. Naik",
      "Tanujit Chakraborty",
      "Abdenour Hadid",
      "Bibhas Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05883",
    "title": "Using deep neural networks to improve the precision of fast-sampled  particle timing detectors",
    "abstract": "Measurements from particle timing detectors are often affected by the time walk effect caused by statistical fluctuations in the charge deposited by passing particles. The constant fraction discriminator (CFD) algorithm is frequently used to mitigate this effect both in test setups and in running experiments, such as the CMS-PPS system at the CERN's LHC. The CFD is simple and effective but does not leverage all voltage samples in a time series. Its performance could be enhanced with deep neural networks, which are commonly used for time series analysis, including computing the particle arrival time. We evaluated various neural network architectures using data acquired at the test beam facility in the DESY-II synchrotron, where a precise MCP (MicroChannel Plate) detector was installed in addition to PPS diamond timing detectors. MCP measurements were used as a reference to train the networks and compare the results with the standard CFD method. Ultimately, we improved the timing precision by 8% to 23%, depending on the detector's readout channel. The best results were obtained using a UNet-based model, which outperformed classical convolutional networks and the multilayer perceptron. ",
    "url": "https://arxiv.org/abs/2312.05883",
    "authors": [
      "Mateusz Kocot",
      "Krzysztof Misan",
      "Valentina Avati",
      "Edoardo Bossini",
      "Leszek Grzanka",
      "Nicola Minafra"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05945",
    "title": "4-Chromatic Graphs Have At Least 4 Cycles of Length $0 \\bmod 3$",
    "abstract": "A 2018 conjecture of Brewster, McGuinness, Moore, and Noel asserts that for $k \\ge 3$, if a graph has chromatic number greater than $k$, then it contains at least as many cycles of length $0 \\bmod k$ as the complete graph on $k+1$ vertices. Our main result confirms this in the $k=3$ case by showing every $4$-critical graph contains at least $4$ cycles of length $0 \\bmod 3$, and that $K_4$ is the unique such graph achieving the minimum. We make progress on the general conjecture as well, showing that $(k+1)$-critical graphs with minimum degree $k$ have at least as many cycles of length $0\\bmod r$ as $K_{k+1}$, provided $k+1 \\ne 0 \\bmod r$. We also show that $K_{k+1}$ uniquely minimizes the number of cycles of length $1\\bmod k$ among all $(k+1)$-critical graphs, strengthening a recent result of Moore and West and extending it to the $k=3$ case. ",
    "url": "https://arxiv.org/abs/2312.05945",
    "authors": [
      "Sean Kim",
      "Michael E. Picollelli"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2312.06015",
    "title": "Speeding up astrochemical reaction networks with autoencoders and neural  ODEs",
    "abstract": "In astrophysics, solving complex chemical reaction networks is essential but computationally demanding due to the high dimensionality and stiffness of the ODE systems. Traditional approaches for reducing computational load are often specialized to specific chemical networks and require expert knowledge. This paper introduces a machine learning-based solution employing autoencoders for dimensionality reduction and a latent space neural ODE solver to accelerate astrochemical reaction network computations. Additionally, we propose a cost-effective latent space linear function solver as an alternative to neural ODEs. These methods are assessed on a dataset comprising 29 chemical species and 224 reactions. Our findings demonstrate that the neural ODE achieves a 55x speedup over the baseline model while maintaining significantly higher accuracy by up to two orders of magnitude reduction in relative error. Furthermore, the linear latent model enhances accuracy and achieves a speedup of up to 4000x compared to standard methods. ",
    "url": "https://arxiv.org/abs/2312.06015",
    "authors": [
      "Immanuel Sulzer",
      "Tobias Buck"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06065",
    "title": "EEND-DEMUX: End-to-End Neural Speaker Diarization via Demultiplexed  Speaker Embeddings",
    "abstract": "In recent years, there have been studies to further improve the end-to-end neural speaker diarization (EEND) systems. This letter proposes the EEND-DEMUX model, a novel framework utilizing demultiplexed speaker embeddings. In this work, we focus on disentangling speaker-relevant information in the latent space and then transform each separated latent variable into its corresponding speech activity. EEND-DEMUX can directly obtain separated speaker embeddings through the demultiplexing operation in the inference phase without an external speaker diarization system, an embedding extractor, or a heuristic decoding technique. Furthermore, we employ a multi-head cross-attention mechanism to capture the correlation between mixture and separated speaker embeddings effectively. We formulate three loss functions based on matching, orthogonality, and sparsity constraints to learn robust demultiplexed speaker embeddings. The experimental results on the LibriMix dataset show consistently improved performance in both a fixed and flexible number of speakers scenarios. ",
    "url": "https://arxiv.org/abs/2312.06065",
    "authors": [
      "Sung Hwan Mun",
      "Min Hyun Han",
      "Canyeong Moon",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.06187",
    "title": "SP-DiffDose: A Conditional Diffusion Model for Radiation Dose Prediction  Based on Multi-Scale Fusion of Anatomical Structures, Guided by  SwinTransformer and Projector",
    "abstract": "Radiation therapy serves as an effective and standard method for cancer treatment. Excellent radiation therapy plans always rely on high-quality dose distribution maps obtained through repeated trial and error by experienced experts. However, due to individual differences and complex clinical situations, even seasoned expert teams may need help to achieve the best treatment plan every time quickly. Many automatic dose distribution prediction methods have been proposed recently to accelerate the radiation therapy planning process and have achieved good results. However, these results suffer from over-smoothing issues, with the obtained dose distribution maps needing more high-frequency details, limiting their clinical application. To address these limitations, we propose a dose prediction diffusion model based on SwinTransformer and a projector, SP-DiffDose. To capture the direct correlation between anatomical structure and dose distribution maps, SP-DiffDose uses a structural encoder to extract features from anatomical images, then employs a conditional diffusion process to blend noise and anatomical images at multiple scales and gradually map them to dose distribution maps. To enhance the dose prediction distribution for organs at risk, SP-DiffDose utilizes SwinTransformer in the deeper layers of the network to capture features at different scales in the image. To learn good representations from the fused features, SP-DiffDose passes the fused features through a designed projector, improving dose prediction accuracy. Finally, we evaluate SP-DiffDose on an internal dataset. The results show that SP-DiffDose outperforms existing methods on multiple evaluation metrics, demonstrating the superiority and generalizability of our method. ",
    "url": "https://arxiv.org/abs/2312.06187",
    "authors": [
      "Linjie Fu",
      "Xia Li",
      "Xiuding Cai",
      "Yingkai Wang",
      "Xueyao Wang",
      "Yu Yao",
      "Yali Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06190",
    "title": "Adversarial Phase Retrieval via Nonlinear Least Absolute Deviation",
    "abstract": "We investigate the phase retrieval problem perturbed by dense bounded noise and sparse outliers that can change an adversarially chosen $s$-fraction of the measurement vector. The adversarial sparse outliers may exhibit dependence on both the observation and the measurement. We demonstrate that the nonlinear least absolute deviation based on amplitude measurement can tolerate adversarial outliers at a fraction of $s^{*,1}\\approx0.2043$, while the intensity-based model can tolerate a fraction of $s^{*,2}\\approx0.1185$. Furthermore, we construct adaptive counterexamples to show that the thresholds are theoretically sharp, thereby showing the presentation of phase transition in the adversarial phase retrieval problem when the corruption fraction exceeds the sharp thresholds. This implies that the amplitude-based model exhibits superior adversarial robustness in comparison with the intensity-based model. Corresponding experimental results are presented to further illustrate our theoretical findings. To the best of our knowledge, our results provide the first theoretical examination of the distinction in robustness performance between amplitude and intensity measurement. A crucial point of our analysis is that we explore the exact distribution of some combination of two non-independent Gaussian random variables and present the novel probability density functions to derive the sharp thresholds. ",
    "url": "https://arxiv.org/abs/2312.06190",
    "authors": [
      "Gao Huang",
      "Song Li",
      "Hang Xu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2312.06403",
    "title": "Debiased Machine Learning and Network Cohesion for Doubly-Robust  Differential Reward Models in Contextual Bandits",
    "abstract": "A common approach to learning mobile health (mHealth) intervention policies is linear Thompson sampling. Two desirable mHealth policy features are (1) pooling information across individuals and time and (2) incorporating a time-varying baseline reward. Previous approaches pooled information across individuals but not time, failing to capture trends in treatment effects over time. In addition, these approaches did not explicitly model the baseline reward, which limited the ability to precisely estimate the parameters in the differential reward model. In this paper, we propose a novel Thompson sampling algorithm, termed ''DML-TS-NNR'' that leverages (1) nearest-neighbors to efficiently pool information on the differential reward function across users and time and (2) the Double Machine Learning (DML) framework to explicitly model baseline rewards and stay agnostic to the supervised learning algorithms used. By explicitly modeling baseline rewards, we obtain smaller confidence sets for the differential reward parameters. We offer theoretical guarantees on the pseudo-regret, which are supported by empirical results. Importantly, the DML-TS-NNR algorithm demonstrates robustness to potential misspecifications in the baseline reward model. ",
    "url": "https://arxiv.org/abs/2312.06403",
    "authors": [
      "Easton K. Huch",
      "Jieru Shi",
      "Madeline R. Abbott",
      "Jessica R. Golbus",
      "Alexander Moreno",
      "Walter H. Dempsey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06531",
    "title": "Uncertainty quantification in automated valuation models with locally  weighted conformal prediction",
    "abstract": "Non-parametric machine learning models, such as random forests and gradient boosted trees, are frequently used to estimate house prices due to their predictive accuracy, but such methods are often limited in their ability to quantify prediction uncertainty. Conformal Prediction (CP) is a model-agnostic framework for constructing confidence sets around machine learning prediction models with minimal assumptions. However, due to the spatial dependencies observed in house prices, direct application of CP leads to confidence sets that are not calibrated everywhere, i.e., too large of confidence sets in certain geographical regions and too small in others. We survey various approaches to adjust the CP confidence set to account for this and demonstrate their performance on a data set from the housing market in Oslo, Norway. Our findings indicate that calibrating the confidence sets on a \\textit{locally weighted} version of the non-conformity scores makes the coverage more consistently calibrated in different geographical regions. We also perform a simulation study on synthetically generated sale prices to empirically explore the performance of CP on housing market data under idealized conditions with known data-generating mechanisms. ",
    "url": "https://arxiv.org/abs/2312.06531",
    "authors": [
      "Anders Hjort",
      "Gudmund Horn Hermansen",
      "Johan Pensar",
      "Jonathan P. Williams"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2312.06555",
    "title": "On the Impact of CDL and TDL Augmentation for RF Fingerprinting under  Impaired Channels",
    "abstract": "Cyber-physical systems have recently been used in several areas (such as connected and autonomous vehicles) due to their high maneuverability. On the other hand, they are susceptible to cyber-attacks. Radio frequency (RF) fingerprinting emerges as a promising approach. This work aims to analyze the impact of decoupling tapped delay line and clustered delay line (TDL+CDL) augmentation-driven deep learning (DL) on transmitter-specific fingerprints to discriminate malicious users from legitimate ones. This work also considers 5G-only-CDL, WiFi-only-TDL augmentation approaches. RF fingerprinting models are sensitive to changing channels and environmental conditions. For this reason, they should be considered during the deployment of a DL model. Data acquisition can be another option. Nonetheless, gathering samples under various conditions for a train set formation may be quite hard. Consequently, data acquisition may not be feasible. This work uses a dataset that includes 5G, 4G, and WiFi samples, and it empowers a CDL+TDL-based augmentation technique in order to boost the learning performance of the DL model. Numerical results show that CDL+TDL, 5G-only-CDL, and WiFi-only-TDL augmentation approaches achieve 87.59%, 81.63%, 79.21% accuracy on unobserved data while TDL/CDL augmentation technique and no augmentation approach result in 77.81% and 74.84% accuracy on unobserved data, respectively. ",
    "url": "https://arxiv.org/abs/2312.06555",
    "authors": [
      "Omer Melih Gul",
      "Michel Kulhandjian",
      "Burak Kantarci",
      "Claude D'Amours",
      "Azzedine Touazi",
      "Cliff Ellement"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.06587",
    "title": "QuickQuakeBuildings: Post-earthquake SAR-Optical Dataset for Quick  Damaged-building Detection",
    "abstract": "Quick and automated earthquake-damaged building detection from post-event satellite imagery is crucial, yet it is challenging due to the scarcity of training data required to develop robust algorithms. This letter presents the first dataset dedicated to detecting earthquake-damaged buildings from post-event very high resolution (VHR) Synthetic Aperture Radar (SAR) and optical imagery. Utilizing open satellite imagery and annotations acquired after the 2023 Turkey-Syria earthquakes, we deliver a dataset of coregistered building footprints and satellite image patches of both SAR and optical data, encompassing more than four thousand buildings. The task of damaged building detection is formulated as a binary image classification problem, that can also be treated as an anomaly detection problem due to extreme class imbalance. We provide baseline methods and results to serve as references for comparison. Researchers can utilize this dataset to expedite algorithm development, facilitating the rapid detection of damaged buildings in response to future events. The dataset and codes together with detailed explanations are made publicly available at \\url{https://github.com/ya0-sun/PostEQ-SARopt-BuildingDamage}. ",
    "url": "https://arxiv.org/abs/2312.06587",
    "authors": [
      "Yao Sun",
      "Yi Wang",
      "Michael Eineder"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06619",
    "title": "Emergence of Scale-Free Networks in Social Interactions among Large  Language Models",
    "abstract": "Scale-free networks are one of the most famous examples of emergent behavior and are ubiquitous in social systems, especially online social media in which users can follow each other. By analyzing the interactions of multiple generative agents using GPT3.5-turbo as a language model, we demonstrate their ability to not only mimic individual human linguistic behavior but also exhibit collective phenomena intrinsic to human societies, in particular the emergence of scale-free networks. We discovered that this process is disrupted by a skewed token prior distribution of GPT3.5-turbo, which can lead to networks with extreme centralization as a kind of alignment. We show how renaming agents removes these token priors and allows the model to generate a range of networks from random networks to more realistic scale-free networks. ",
    "url": "https://arxiv.org/abs/2312.06619",
    "authors": [
      "Giordano De Marzo",
      "Luciano Pietronero",
      "David Garcia"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.06623",
    "title": "Model selection for risk analysis of wastewater networks",
    "abstract": "In this paper, we test various models of wastewater infrastructure for risk analysis and compare their performance. While many representations are available, existing studies do not consider selection of the appropriate model for risk analysis. In this paper, we define two characteristics of wastewater models: the network granularity and the fidelity of the governing equations. We consider different combinations of these characteristics to determine 6 network representations that could be used as the foundation for risk analysis. We test the performance of each model as compared to predictions from the most detailed model, the full network with dynamic wave flow equations. We demonstrate the model selection for Seaside, Oregon. We conclude that the full network granularity is needed as compared to a coarse network representation. For the fidelity of the governing equations, connectivity analysis is reasonable if the primary goal is to determine the spatial distribution of hazard impact. To more accurately predict nodal performance measures, the dynamic wave equations are needed as they capture important physical phenomena. ",
    "url": "https://arxiv.org/abs/2312.06623",
    "authors": [
      "Aaron Dunton"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:1605.06409",
    "title": "R-FCN: Object Detection via Region-based Fully Convolutional Networks",
    "abstract": " Comments: Tech report ",
    "url": "https://arxiv.org/abs/1605.06409",
    "authors": [
      "Jifeng Dai",
      "Yi Li",
      "Kaiming He",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.03170",
    "title": "Food Classification with Convolutional Neural Networks and Multi-Class  Linear Discernment Analysis",
    "abstract": " Comments: I dont like the paper, its not a good rep of me anymore ",
    "url": "https://arxiv.org/abs/2012.03170",
    "authors": [
      "Joshua Ball"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.06809",
    "title": "Smaller Keys for the McEliece Cryptosystem: A Convolutional Variant with  GRS Codes",
    "abstract": " Comments: 25 pages. arXiv admin note: text overlap with arXiv:1804.08955 ",
    "url": "https://arxiv.org/abs/2104.06809",
    "authors": [
      "Paulo Almeida",
      "Miguel Beltr\u00e1",
      "Diego Napp",
      "Cl\u00e1udia Sebasti\u00e3o"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2106.04088",
    "title": "A Lightweight and Gradient-Stable Neural Layer",
    "abstract": " Title: A Lightweight and Gradient-Stable Neural Layer ",
    "url": "https://arxiv.org/abs/2106.04088",
    "authors": [
      "Yueyao Yu",
      "Yin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.08642",
    "title": "POAR: Efficient Policy Optimization via Online Abstract State  Representation Learning",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2109.08642",
    "authors": [
      "Zhaorun Chen",
      "Siqi Fan",
      "Yuan Tan",
      "Liang Gong",
      "Binhao Chen",
      "Te Sun",
      "David Filliat",
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Chengliang Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.11486",
    "title": "Boosting Federated Learning in Resource-Constrained Networks",
    "abstract": " Comments: 14 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2110.11486",
    "authors": [
      "Mohamed Yassine Boukhari",
      "Akash Dhasade",
      "Anne-Marie Kermarrec",
      "Rafael Pires",
      "Othmane Safsafi",
      "Rishi Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.03810",
    "title": "Ancestral Instrument Method for Causal Inference without Complete  Knowledge",
    "abstract": " Comments: 11 pages, 5 figures and 2 tables ",
    "url": "https://arxiv.org/abs/2201.03810",
    "authors": [
      "Debo Cheng",
      "Jiuyong Li",
      "Lin Liu",
      "Jiji Zhang",
      "Thuc duy Le",
      "Jixue Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.07063",
    "title": "How to Backdoor HyperNetwork in Personalized Federated Learning?",
    "abstract": " Title: How to Backdoor HyperNetwork in Personalized Federated Learning? ",
    "url": "https://arxiv.org/abs/2201.07063",
    "authors": [
      "Phung Lai",
      "NhatHai Phan",
      "Issa Khalil",
      "Abdallah Khreishah",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.01818",
    "title": "QAGCN: Answering Multi-Relation Questions via Single-Step Implicit  Reasoning over Knowledge Graphs",
    "abstract": " Title: QAGCN: Answering Multi-Relation Questions via Single-Step Implicit  Reasoning over Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2206.01818",
    "authors": [
      "Ruijie Wang",
      "Luca Rossetto",
      "Michael Cochez",
      "Abraham Bernstein"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09098",
    "title": "Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary  Classification",
    "abstract": " Comments: 42 pages. version 2: corrects several errors and employs a significantly different proof technique. version 3: modifies the arXiv author list but has no other changes. version 4: improved exposition and fixed typos ",
    "url": "https://arxiv.org/abs/2206.09098",
    "authors": [
      "Natalie S. Frank",
      "Jonathan Niles-Weed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.10177",
    "title": "TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks",
    "abstract": " Title: TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks ",
    "url": "https://arxiv.org/abs/2206.10177",
    "authors": [
      "Rui-Jie Zhu",
      "Qihang Zhao",
      "Tianjing Zhang",
      "Haoyu Deng",
      "Yule Duan",
      "Malu Zhang",
      "Liang-Jian Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00259",
    "title": "COVID-19 Detection Using Transfer Learning Approach from Computed  Tomography Images",
    "abstract": " Title: COVID-19 Detection Using Transfer Learning Approach from Computed  Tomography Images ",
    "url": "https://arxiv.org/abs/2207.00259",
    "authors": [
      "Kenan Morani",
      "Esra Kaya Ayana",
      "Devrim Unay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.03584",
    "title": "Generalization Guarantee of Training Graph Convolutional Networks with  Graph Topology Sampling",
    "abstract": " Title: Generalization Guarantee of Training Graph Convolutional Networks with  Graph Topology Sampling ",
    "url": "https://arxiv.org/abs/2207.03584",
    "authors": [
      "Hongkang Li",
      "Meng Wang",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Jinjun Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.09705",
    "title": "gBuilder: A Scalable Knowledge Graph Construction System for  Unstructured Corpus",
    "abstract": " Title: gBuilder: A Scalable Knowledge Graph Construction System for  Unstructured Corpus ",
    "url": "https://arxiv.org/abs/2208.09705",
    "authors": [
      "Yanzeng Li",
      "Lei Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.08860",
    "title": "A Survey of Deep Causal Models and Their Industrial Applications",
    "abstract": " Comments: Artificial Intelligence Review 5648ba1c-880e-4496-94da-d497be02a167|v.2.0 this https URL ",
    "url": "https://arxiv.org/abs/2209.08860",
    "authors": [
      "Zongyu Li",
      "Xiaobo Guo",
      "Siwei Qiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15320",
    "title": "Bounded Robustness in Reinforcement Learning via Lexicographic  Objectives",
    "abstract": " Title: Bounded Robustness in Reinforcement Learning via Lexicographic  Objectives ",
    "url": "https://arxiv.org/abs/2209.15320",
    "authors": [
      "Daniel Jarne Ornia",
      "Licio Romao",
      "Lewis Hammond",
      "Manuel Mazo Jr.",
      "Alessandro Abate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.04232",
    "title": "Revealing Patient-Reported Experiences in Healthcare from Social Media  using the DAPMAV Framework",
    "abstract": " Comments: 25 pages, 8 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2210.04232",
    "authors": [
      "Curtis Murray",
      "Lewis Mitchell",
      "Jonathan Tuke",
      "Mark Mackay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.05523",
    "title": "Impact of Adversarial Training on Robustness and Generalizability of  Language Models",
    "abstract": " Title: Impact of Adversarial Training on Robustness and Generalizability of  Language Models ",
    "url": "https://arxiv.org/abs/2211.05523",
    "authors": [
      "Enes Altinisik",
      "Hassan Sajjad",
      "Husrev Taha Sencar",
      "Safa Messaoud",
      "Sanjay Chawla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13436",
    "title": "Solving Bilevel Knapsack Problem using Graph Neural Networks",
    "abstract": " Comments: 27 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2211.13436",
    "authors": [
      "Sunhyeon Kwon",
      "Hwayong Choi",
      "Sungsoo Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.13715",
    "title": "Trust Your $\\nabla$: Gradient-based Intervention Targeting for Causal  Discovery",
    "abstract": " Comments: Accepted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2211.13715",
    "authors": [
      "Mateusz Olko",
      "Micha\u0142 Zaj\u0105c",
      "Aleksandra Nowak",
      "Nino Scherrer",
      "Yashas Annadani",
      "Stefan Bauer",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.13993",
    "title": "Combating noisy labels in object detection datasets",
    "abstract": " Comments: 13 pages, 16 figures, submitted to ICDE 2024 Conference ",
    "url": "https://arxiv.org/abs/2211.13993",
    "authors": [
      "Krystian Chachu\u0142a",
      "Jakub \u0141yskawa",
      "Bart\u0142omiej Olber",
      "Piotr Fr\u0105tczak",
      "Adam Popowicz",
      "Krystian Radlak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.14260",
    "title": "Distributionally Robust Strategy Synthesis for Switched Stochastic  Systems",
    "abstract": " Comments: The updated version includes a computationally efficient reformulation of the dynamic programming algorithm for strategy synthesis ",
    "url": "https://arxiv.org/abs/2212.14260",
    "authors": [
      "Ibon Gracia",
      "Dimitris Boskos",
      "Morteza Lahijanian",
      "Luca Laurenti",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.14274",
    "title": "Meta-Path Based Attentional Graph Learning Model for Vulnerability  Detection",
    "abstract": " Comments: Accepted by TSE ",
    "url": "https://arxiv.org/abs/2212.14274",
    "authors": [
      "Xin-Cheng Wen",
      "Cuiyun Gao",
      "Jiaxin Ye",
      "Yichen Li",
      "Zhihong Tian",
      "Yan Jia",
      "Xuan Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.10403",
    "title": "Exact and rapid linear clustering of networks with dynamic programming",
    "abstract": " Comments: 14 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2301.10403",
    "authors": [
      "Alice Patania",
      "Antoine Allard",
      "Jean-Gabriel Young"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2301.12473",
    "title": "Large Language Models for Biomedical Knowledge Graph Construction:  Information extraction from EMR notes",
    "abstract": " Title: Large Language Models for Biomedical Knowledge Graph Construction:  Information extraction from EMR notes ",
    "url": "https://arxiv.org/abs/2301.12473",
    "authors": [
      "Vahan Arsenyan",
      "Spartak Bughdaryan",
      "Fadi Shaya",
      "Kent Small",
      "Davit Shahnazaryan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13589",
    "title": "Policy Gradient for Rectangular Robust Markov Decision Processes",
    "abstract": " Comments: Accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2301.13589",
    "authors": [
      "Navdeep Kumar",
      "Esther Derman",
      "Matthieu Geist",
      "Kfir Levy",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00735",
    "title": "MTP-GO: Graph-Based Probabilistic Multi-Agent Trajectory Prediction with  Neural ODEs",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2302.00735",
    "authors": [
      "Theodor Westny",
      "Joel Oskarsson",
      "Bj\u00f6rn Olofsson",
      "Erik Frisk"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.01007",
    "title": "Hierarchical cycle-tree packing model for $K$-core attack problem",
    "abstract": " Comments: 25 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2303.01007",
    "authors": [
      "Jianwen Zhou",
      "Hai-Jun Zhou"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.02574",
    "title": "Sim2Real Neural Controllers for Physics-based Robotic Deployment of  Deformable Linear Objects",
    "abstract": " Comments: YouTube video: this https URL ",
    "url": "https://arxiv.org/abs/2303.02574",
    "authors": [
      "Dezhong Tong",
      "Andrew Choi",
      "Longhui Qin",
      "Weicheng Huang",
      "Jungseock Joo",
      "M. Khalid Jawed"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2303.06121",
    "title": "Ignorance is Bliss: Robust Control via Information Gating",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.06121",
    "authors": [
      "Manan Tomar",
      "Riashat Islam",
      "Matthew E. Taylor",
      "Sergey Levine",
      "Philip Bachman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09375",
    "title": "DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human  Avatars",
    "abstract": " Title: DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human  Avatars ",
    "url": "https://arxiv.org/abs/2303.09375",
    "authors": [
      "David Svitov",
      "Dmitrii Gudkov",
      "Renat Bashirov",
      "Victor Lempitsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09728",
    "title": "The Cascaded Forward Algorithm for Neural Network Training",
    "abstract": " Title: The Cascaded Forward Algorithm for Neural Network Training ",
    "url": "https://arxiv.org/abs/2303.09728",
    "authors": [
      "Gongpei Zhao",
      "Tao Wang",
      "Yidong Li",
      "Yi Jin",
      "Congyan Lang",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03671",
    "title": "Contraction-Guided Adaptive Partitioning for Reachability Analysis of  Neural Network Controlled Systems",
    "abstract": " Title: Contraction-Guided Adaptive Partitioning for Reachability Analysis of  Neural Network Controlled Systems ",
    "url": "https://arxiv.org/abs/2304.03671",
    "authors": [
      "Akash Harapanahalli",
      "Saber Jafarpour",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.07460",
    "title": "Communication and Energy Efficient Wireless Federated Learning with  Intrinsic Privacy",
    "abstract": " Comments: 19 pages, Accepted for publication in IEEE Transactions on Dependable and Secure Computing ",
    "url": "https://arxiv.org/abs/2304.07460",
    "authors": [
      "Zhenxiao Zhang",
      "Yuanxiong Guo",
      "Yuguang Fang",
      "Yanmin Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.11171",
    "title": "Granular-ball computing: an efficient, robust, and interpretable  adaptive multi-granularity representation and computation method",
    "abstract": " Title: Granular-ball computing: an efficient, robust, and interpretable  adaptive multi-granularity representation and computation method ",
    "url": "https://arxiv.org/abs/2304.11171",
    "authors": [
      "Shuyin Xia",
      "Guoyin Wang",
      "Xinbo Gao",
      "Xiaoyu Lian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.02177",
    "title": "Transforming Visual Scene Graphs to Image Captions",
    "abstract": " Comments: 12 pages, 4 figures, has been accepted by ACL 2023 main conference ",
    "url": "https://arxiv.org/abs/2305.02177",
    "authors": [
      "Xu Yang",
      "Jiawei Peng",
      "Zihua Wang",
      "Haiyang Xu",
      "Qinghao Ye",
      "Chenliang Li",
      "Songfang Huang",
      "Fei Huang",
      "Zhangzikang Li",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.06225",
    "title": "DaGAN++: Depth-Aware Generative Adversarial Network for Talking Head  Video Generation",
    "abstract": " Comments: Accepted at TPAMI; CVPR 2022 extension ",
    "url": "https://arxiv.org/abs/2305.06225",
    "authors": [
      "Fa-Ting Hong",
      "Li Shen",
      "Dan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12464",
    "title": "Self-supervised Predictive Coding Models Encode Speaker and Phonetic  Information in Orthogonal Subspaces",
    "abstract": " Title: Self-supervised Predictive Coding Models Encode Speaker and Phonetic  Information in Orthogonal Subspaces ",
    "url": "https://arxiv.org/abs/2305.12464",
    "authors": [
      "Oli Liu",
      "Hao Tang",
      "Sharon Goldwater"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12530",
    "title": "Towards Robust Family-Infant Audio Analysis Based on Unsupervised  Pretraining of Wav2vec 2.0 on Large-Scale Unlabeled Family Audio",
    "abstract": " Comments: Proceedings of Interspeech 2023; v4 version updates: correction of W2V2-base pretrained on 960-hour of LibriSpeech and number of families participated for LENA home recordings ",
    "url": "https://arxiv.org/abs/2305.12530",
    "authors": [
      "Jialu Li",
      "Mark Hasegawa-Johnson",
      "Nancy L. McElwain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12975",
    "title": "Graphical Proof Theory I: Sequent Calculi operating on Undirected Graphs",
    "abstract": " Title: Graphical Proof Theory I: Sequent Calculi operating on Undirected Graphs ",
    "url": "https://arxiv.org/abs/2305.12975",
    "authors": [
      "Matteo Acclavio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2305.15990",
    "title": "PINNslope: seismic data interpolation and local slope estimation with  physics informed neural networks",
    "abstract": " Title: PINNslope: seismic data interpolation and local slope estimation with  physics informed neural networks ",
    "url": "https://arxiv.org/abs/2305.15990",
    "authors": [
      "Francesco Brandolin",
      "Matteo Ravasi",
      "Tariq Alkhalifah"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.16771",
    "title": "Robust Nonparametric Regression under Poisoning Attack",
    "abstract": " Title: Robust Nonparametric Regression under Poisoning Attack ",
    "url": "https://arxiv.org/abs/2305.16771",
    "authors": [
      "Puning Zhao",
      "Zhiguo Wan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16941",
    "title": "Engagement, User Satisfaction, and the Amplification of Divisive Content  on Social Media",
    "abstract": " Title: Engagement, User Satisfaction, and the Amplification of Divisive Content  on Social Media ",
    "url": "https://arxiv.org/abs/2305.16941",
    "authors": [
      "Smitha Milli",
      "Micah Carroll",
      "Yike Wang",
      "Sashrika Pandey",
      "Sebastian Zhao",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2306.02822",
    "title": "Discovering Dynamic Causal Space for DAG Structure Learning",
    "abstract": " Comments: Accepted by KDD 2023. Our codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2306.02822",
    "authors": [
      "Fangfu Liu",
      "Wenchang Ma",
      "An Zhang",
      "Xiang Wang",
      "Yueqi Duan",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02956",
    "title": "Explicit Neural Surfaces: Learning Continuous Geometry With Deformation  Fields",
    "abstract": " Title: Explicit Neural Surfaces: Learning Continuous Geometry With Deformation  Fields ",
    "url": "https://arxiv.org/abs/2306.02956",
    "authors": [
      "Thomas Walker",
      "Octave Mariotti",
      "Amir Vaxman",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2306.04998",
    "title": "Exploring Unsupervised Anomaly Detection with Quantum Boltzmann Machines  in Fraud Detection",
    "abstract": " Title: Exploring Unsupervised Anomaly Detection with Quantum Boltzmann Machines  in Fraud Detection ",
    "url": "https://arxiv.org/abs/2306.04998",
    "authors": [
      "Jonas Stein",
      "Dani\u00eblle Schuman",
      "Magdalena Benkard",
      "Thomas Holger",
      "Wanja Sajko",
      "Michael K\u00f6lle",
      "Jonas N\u00fc\u00dflein",
      "Leo S\u00fcnkel",
      "Olivier Salomon",
      "Claudia Linnhoff-Popien"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2306.10619",
    "title": "Towards Stability of Autoregressive Neural Operators",
    "abstract": " Title: Towards Stability of Autoregressive Neural Operators ",
    "url": "https://arxiv.org/abs/2306.10619",
    "authors": [
      "Michael McCabe",
      "Peter Harrington",
      "Shashank Subramanian",
      "Jed Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2306.11920",
    "title": "NILUT: Conditional Neural Implicit 3D Lookup Tables for Image  Enhancement",
    "abstract": " Comments: AAAI 2024 - The 38th Annual AAAI Conference on Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2306.11920",
    "authors": [
      "Marcos V. Conde",
      "Javier Vazquez-Corral",
      "Michael S. Brown",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.12562",
    "title": "Neural Spectro-polarimetric Fields",
    "abstract": " Title: Neural Spectro-polarimetric Fields ",
    "url": "https://arxiv.org/abs/2306.12562",
    "authors": [
      "Youngchan Kim",
      "Wonjoon Jin",
      "Sunghyun Cho",
      "Seung-Hwan Baek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.15381",
    "title": "Asymptotic-Preserving Neural Networks for Multiscale Kinetic Equations",
    "abstract": " Title: Asymptotic-Preserving Neural Networks for Multiscale Kinetic Equations ",
    "url": "https://arxiv.org/abs/2306.15381",
    "authors": [
      "Shi Jin",
      "Zheng Ma",
      "Keke Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.16022",
    "title": "Enrollment-stage Backdoor Attacks on Speaker Recognition Systems via  Adversarial Ultrasound",
    "abstract": " Comments: Published in Internet of Things Journal (IoT-J) ",
    "url": "https://arxiv.org/abs/2306.16022",
    "authors": [
      "Xinfeng Li",
      "Junning Ze",
      "Chen Yan",
      "Yushi Cheng",
      "Xiaoyu Ji",
      "Wenyuan Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.08875",
    "title": "Natural Actor-Critic for Robust Reinforcement Learning with Function  Approximation",
    "abstract": " Comments: Neurips 2023 ",
    "url": "https://arxiv.org/abs/2307.08875",
    "authors": [
      "Ruida Zhou",
      "Tao Liu",
      "Min Cheng",
      "Dileep Kalathil",
      "P. R. Kumar",
      "Chao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.08939",
    "title": "Runtime Stealthy Perception Attacks against DNN-based Adaptive Cruise  Control Systems",
    "abstract": " Comments: 18 pages, 21 figures, 10 tables ",
    "url": "https://arxiv.org/abs/2307.08939",
    "authors": [
      "Xugui Zhou",
      "Anqi Chen",
      "Maxfield Kouzel",
      "Haotian Ren",
      "Morgan McCarty",
      "Cristina Nita-Rotaru",
      "Homa Alemzadeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.10907",
    "title": "The Role of Entropy and Reconstruction in Multi-View Self-Supervised  Learning",
    "abstract": " Comments: 18 pages: 9 of main text, 2 of references, and 7 of supplementary material [Updated typo in page 6 (Section 3.2)]. Appears in the proceedings of ICML 2023 ",
    "url": "https://arxiv.org/abs/2307.10907",
    "authors": [
      "Borja Rodr\u00edguez-G\u00e1lvez",
      "Arno Blaas",
      "Pau Rodr\u00edguez",
      "Adam Goli\u0144ski",
      "Xavier Suau",
      "Jason Ramapuram",
      "Dan Busbridge",
      "Luca Zappella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11730",
    "title": "Mitigating Communications Threats in Decentralized Federated Learning  through Moving Target Defense",
    "abstract": " Title: Mitigating Communications Threats in Decentralized Federated Learning  through Moving Target Defense ",
    "url": "https://arxiv.org/abs/2307.11730",
    "authors": [
      "Enrique Tom\u00e1s Mart\u00ednez Beltr\u00e1n",
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Sergio L\u00f3pez Bernal",
      "G\u00e9r\u00f4me Bovet",
      "Manuel Gil P\u00e9rez",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Alberto Huertas Celdr\u00e1n"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.12267",
    "title": "Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid  Essay in Education",
    "abstract": " Comments: Accepted as an AAAI 2024 full paper ",
    "url": "https://arxiv.org/abs/2307.12267",
    "authors": [
      "Zijie Zeng",
      "Lele Sha",
      "Yuheng Li",
      "Kaixun Yang",
      "Dragan Ga\u0161evi\u0107",
      "Guanliang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15967",
    "title": "Graph Condensation for Inductive Node Representation Learning",
    "abstract": " Comments: 2024 IEEE 40th International Conference on Data Engineering (ICDE) ",
    "url": "https://arxiv.org/abs/2307.15967",
    "authors": [
      "Xinyi Gao",
      "Tong Chen",
      "Yilong Zang",
      "Wentao Zhang",
      "Quoc Viet Hung Nguyen",
      "Kai Zheng",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.02080",
    "title": "Causality Guided Disentanglement for Cross-Platform Hate Speech  Detection",
    "abstract": " Comments: Accepted to WSDM'24 ",
    "url": "https://arxiv.org/abs/2308.02080",
    "authors": [
      "Paras Sheth",
      "Tharindu Kumarage",
      "Raha Moraffah",
      "Aman Chadha",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.03230",
    "title": "Tractability of approximation by general shallow networks",
    "abstract": " Title: Tractability of approximation by general shallow networks ",
    "url": "https://arxiv.org/abs/2308.03230",
    "authors": [
      "Hrushikesh Mhaskar",
      "Tong Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.06399",
    "title": "Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via  Mixed-Effect Models and Hierarchical Clustering",
    "abstract": " Comments: 34 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2308.06399",
    "authors": [
      "Lorenzo Valleggi",
      "Marco Scutari",
      "Federico Mattia Stefanini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2308.09895",
    "title": "Knowledge Transfer from High-Resource to Low-Resource Programming  Languages for Code LLMs",
    "abstract": " Title: Knowledge Transfer from High-Resource to Low-Resource Programming  Languages for Code LLMs ",
    "url": "https://arxiv.org/abs/2308.09895",
    "authors": [
      "Federico Cassano",
      "John Gouwar",
      "Francesca Lucchetti",
      "Claire Schlesinger",
      "Carolyn Jane Anderson",
      "Michael Greenberg",
      "Abhinav Jangda",
      "Arjun Guha"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11070",
    "title": "Temporal-Distributed Backdoor Attack Against Video Based Action  Recognition",
    "abstract": " Comments: accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2308.11070",
    "authors": [
      "Xi Li",
      "Songhe Wang",
      "Ruiquan Huang",
      "Mahanth Gowda",
      "George Kesidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.13466",
    "title": "Staleness-Alleviated Distributed GNN Training via Online  Dynamic-Embedding Prediction",
    "abstract": " Comments: Preprint. Do not distribute ",
    "url": "https://arxiv.org/abs/2308.13466",
    "authors": [
      "Guangji Bai",
      "Ziyang Yu",
      "Zheng Chai",
      "Yue Cheng",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13794",
    "title": "SOGDet: Semantic-Occupancy Guided Multi-view 3D Object Detection",
    "abstract": " Comments: Accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2308.13794",
    "authors": [
      "Qiu Zhou",
      "Jinming Cao",
      "Hanchao Leng",
      "Yifang Yin",
      "Yu Kun",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14411",
    "title": "Community College Articulation Agreement Websites: Students' Suggestions  for New Academic Advising Software Features",
    "abstract": " Title: Community College Articulation Agreement Websites: Students' Suggestions  for New Academic Advising Software Features ",
    "url": "https://arxiv.org/abs/2308.14411",
    "authors": [
      "David V. Nguyen",
      "Shayan Doroudi",
      "Daniel A. Epstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.16910",
    "title": "Robust Variational Physics-Informed Neural Networks",
    "abstract": " Title: Robust Variational Physics-Informed Neural Networks ",
    "url": "https://arxiv.org/abs/2308.16910",
    "authors": [
      "Sergio Rojas",
      "Pawe\u0142 Maczuga",
      "Judit Mu\u00f1oz-Matute",
      "David Pardo",
      "Maciej Paszynski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.01627",
    "title": "Cross-Consistent Deep Unfolding Network for Adaptive All-In-One Video  Restoration",
    "abstract": " Comments: 16 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2309.01627",
    "authors": [
      "Yuanshuo Cheng",
      "Mingwen Shao",
      "Yecong Wan",
      "Yuanjian Qiao",
      "Wangmeng Zuo",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.02464",
    "title": "Deployment of Real-Time Network Traffic Analysis using GraphBLAS  Hypersparse Matrices and D4M Associative Arrays",
    "abstract": " Comments: Accepted to IEEE HPEC, 8 pages, 8 figures, 1 table, 69 references. arXiv admin note: text overlap with arXiv:2203.13934. text overlap with arXiv:2309.01806 ",
    "url": "https://arxiv.org/abs/2309.02464",
    "authors": [
      "Michael Jones",
      "Jeremy Kepner",
      "Andrew Prout",
      "Timothy Davis",
      "William Arcand",
      "David Bestor",
      "William Bergeron",
      "Chansup Byun",
      "Vijay Gadepally",
      "Micheal Houle",
      "Matthew Hubbell",
      "Hayden Jananthan",
      "Anna Klein",
      "Lauren Milechin",
      "Guillermo Morales",
      "Julie Mullen",
      "Ritesh Patel",
      "Sandeep Pisharody",
      "Albert Reuther",
      "Antonio Rosa",
      "Siddharth Samsi",
      "Charles Yee",
      "Peter Michaleas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.03038",
    "title": "Cellular Wireless Networks in the Upper Mid-Band",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2309.03038",
    "authors": [
      "Seongjoon Kang",
      "Marco Mezzavilla",
      "Sundeep Rangan",
      "Arjuna Madanayake",
      "Satheesh Bojja Venkatakrishnan",
      "Gregory Hellbourg",
      "Monisha Ghosh",
      "Hamed Rahmani",
      "Aditya Dhananjay"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.07544",
    "title": "VerilogEval: Evaluating Large Language Models for Verilog Code  Generation",
    "abstract": " Comments: ICCAD 2023 Invited Paper. Prior version contained errors in the numbers reported for gpt-4 in Table II ",
    "url": "https://arxiv.org/abs/2309.07544",
    "authors": [
      "Mingjie Liu",
      "Nathaniel Pinckney",
      "Brucek Khailany",
      "Haoxing Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.09043",
    "title": "Forward Invariance in Neural Network Controlled Systems",
    "abstract": " Title: Forward Invariance in Neural Network Controlled Systems ",
    "url": "https://arxiv.org/abs/2309.09043",
    "authors": [
      "Akash Harapanahalli",
      "Saber Jafarpour",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.09431",
    "title": "FactoFormer: Factorized Hyperspectral Transformers with Self-Supervised  Pre-Training",
    "abstract": " Comments: Accepted to IEEE Transactions on Geoscience and Remote Sensing in December 2023 ",
    "url": "https://arxiv.org/abs/2309.09431",
    "authors": [
      "Shaheer Mohamed",
      "Maryam Haghighat",
      "Tharindu Fernando",
      "Sridha Sridharan",
      "Clinton Fookes",
      "Peyman Moghadam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13237",
    "title": "Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph  Generation",
    "abstract": " Comments: Accepted at T-IP, 2023 ",
    "url": "https://arxiv.org/abs/2309.13237",
    "authors": [
      "Tao Pu",
      "Tianshui Chen",
      "Hefeng Wu",
      "Yongyi Lu",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14293",
    "title": "NAS-NeRF: Generative Neural Architecture Search for Neural Radiance  Fields",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2309.14293",
    "authors": [
      "Saeejith Nair",
      "Yuhao Chen",
      "Mohammad Javad Shafiee",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14482",
    "title": "LogGPT: Log Anomaly Detection via GPT",
    "abstract": " Title: LogGPT: Log Anomaly Detection via GPT ",
    "url": "https://arxiv.org/abs/2309.14482",
    "authors": [
      "Xiao Han",
      "Shuhan Yuan",
      "Mohamed Trabelsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.15269",
    "title": "Theoretical Foundations of Community Rating by a Private Monopolist  Insurer: Framework, Regulation, and Numerical Analysis",
    "abstract": " Comments: The key findings haven't undergone any modifications. A handful of typos have been corrected, and the presentation has been enhanced for improved clarity ",
    "url": "https://arxiv.org/abs/2309.15269",
    "authors": [
      "Yann Braouezec",
      "John Cagnol"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.15593",
    "title": "Exciton-Polariton Condensates: A Fourier Neural Operator Approach",
    "abstract": " Comments: 17 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2309.15593",
    "authors": [
      "Surya T. Sathujoda",
      "Yuan Wang",
      "Kanishk Gandhi"
    ],
    "subjectives": [
      "Quantum Gases (cond-mat.quant-gas)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16066",
    "title": "Label Augmentation Method for Medical Landmark Detection in Hip  Radiograph Images",
    "abstract": " Title: Label Augmentation Method for Medical Landmark Detection in Hip  Radiograph Images ",
    "url": "https://arxiv.org/abs/2309.16066",
    "authors": [
      "Yehyun Suh",
      "Peter Chan",
      "J.Ryan Martin",
      "Daniel Moyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01770",
    "title": "A simple connection from loss flatness to compressed representations in  neural networks",
    "abstract": " Title: A simple connection from loss flatness to compressed representations in  neural networks ",
    "url": "https://arxiv.org/abs/2310.01770",
    "authors": [
      "Shirui Chen",
      "Stefano Recanatesi",
      "Eric Shea-Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.02003",
    "title": "L2MAC: Large Language Model Automatic Computer for Unbounded Code  Generation",
    "abstract": " Comments: Copyright 2023 by the author(s) ",
    "url": "https://arxiv.org/abs/2310.02003",
    "authors": [
      "Samuel Holt",
      "Max Ruiz Luyten",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.02854",
    "title": "Multi-Domain Causal Representation Learning via Weak Distributional  Invariances",
    "abstract": " Title: Multi-Domain Causal Representation Learning via Weak Distributional  Invariances ",
    "url": "https://arxiv.org/abs/2310.02854",
    "authors": [
      "Kartik Ahuja",
      "Amin Mansouri",
      "Yixin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.05056",
    "title": "Open-Vocabulary Animal Keypoint Detection with Semantic-feature Matching",
    "abstract": " Title: Open-Vocabulary Animal Keypoint Detection with Semantic-feature Matching ",
    "url": "https://arxiv.org/abs/2310.05056",
    "authors": [
      "Hao Zhang",
      "Lumin Xu",
      "Shenqi Lai",
      "Wenqi Shao",
      "Nanning Zheng",
      "Ping Luo",
      "Yu Qiao",
      "Kaipeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05742",
    "title": "Estimating Shape Distances on Neural Representations with Limited  Samples",
    "abstract": " Title: Estimating Shape Distances on Neural Representations with Limited  Samples ",
    "url": "https://arxiv.org/abs/2310.05742",
    "authors": [
      "Dean A. Pospisil",
      "Brett W. Larsen",
      "Sarah E. Harvey",
      "Alex H. Williams"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.07916",
    "title": "Dynamic Appearance Particle Neural Radiance Field",
    "abstract": " Title: Dynamic Appearance Particle Neural Radiance Field ",
    "url": "https://arxiv.org/abs/2310.07916",
    "authors": [
      "Ancheng Lin",
      "Jun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08008",
    "title": "Effects of Human Adversarial and Affable Samples on BERT Generalization",
    "abstract": " Comments: To appear at EMNLP Findings 2023 ",
    "url": "https://arxiv.org/abs/2310.08008",
    "authors": [
      "Aparna Elangovan",
      "Jiayuan He",
      "Yuan Li",
      "Karin Verspoor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.13191",
    "title": "Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy  for Language Models",
    "abstract": " Title: Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy  for Language Models ",
    "url": "https://arxiv.org/abs/2310.13191",
    "authors": [
      "Jianwei Li",
      "Qi Lei",
      "Wei Cheng",
      "Dongkuan Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.14076",
    "title": "On the Relationship Between Relevance and Conflict in Online Social Link  Recommendations",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.14076",
    "authors": [
      "Yanbang Wang",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.17793",
    "title": "\"You Are An Expert Linguistic Annotator\": Limits of LLMs as Analyzers of  Abstract Meaning Representation",
    "abstract": " Comments: EMNLP 2023 Findings (short) ",
    "url": "https://arxiv.org/abs/2310.17793",
    "authors": [
      "Allyson Ettinger",
      "Jena D. Hwang",
      "Valentina Pyatkin",
      "Chandra Bhagavatula",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20187",
    "title": "Self-Supervised Pre-Training for Precipitation Post-Processor",
    "abstract": " Title: Self-Supervised Pre-Training for Precipitation Post-Processor ",
    "url": "https://arxiv.org/abs/2310.20187",
    "authors": [
      "Sojung An",
      "Junha Lee",
      "Jiyeon Jang",
      "Inchae Na",
      "Wooyeon Park",
      "Sujeong You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.02869",
    "title": "Lightweight equivariant interaction graph neural network for accurate  and efficient interatomic potential and force predictions",
    "abstract": " Title: Lightweight equivariant interaction graph neural network for accurate  and efficient interatomic potential and force predictions ",
    "url": "https://arxiv.org/abs/2311.02869",
    "authors": [
      "Ziduo Yang",
      "Xian Wang",
      "Yifan Li",
      "Qiujie Lv",
      "Calvin Yu-Chian Chen",
      "Lei Shen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.04916",
    "title": "Explainable Identification of Hate Speech towards Islam using Graph  Neural Networks",
    "abstract": " Comments: 3 pages, 2 figures; NeurIPS 2023 Workshop Muslims in ML. Openreview forum: this https URL ",
    "url": "https://arxiv.org/abs/2311.04916",
    "authors": [
      "Azmine Toushik Wasi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.05135",
    "title": "Improving Computational Efficiency for Powered Descent Guidance via  Transformer-based Tight Constraint Prediction",
    "abstract": " Comments: Accepted to AIAA SciTech 2024 on 25-Aug-2023. Full manuscript submitted to AIAA SciTech 2024 on 25-May-2023 ",
    "url": "https://arxiv.org/abs/2311.05135",
    "authors": [
      "Julia Briden",
      "Trey Gurga",
      "Breanna Johnson",
      "Abhishek Cauligi",
      "Richard Linares"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.07461",
    "title": "On Self-Supervised Dynamic Incremental Regularised Adaptation",
    "abstract": " Title: On Self-Supervised Dynamic Incremental Regularised Adaptation ",
    "url": "https://arxiv.org/abs/2311.07461",
    "authors": [
      "Abanoub Ghobrial",
      "Kerstin Eder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07995",
    "title": "EPPA numbers of graphs",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2311.07995",
    "authors": [
      "David Bradley-Williams",
      "Peter J. Cameron",
      "Jan Hubi\u010dka",
      "Mat\u011bj Kone\u010dn\u00fd"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.12397",
    "title": "Rich and Poor Texture Contrast: A Simple yet Effective Approach for  AI-generated Image Detection",
    "abstract": " Comments: Our project: this https URL ",
    "url": "https://arxiv.org/abs/2311.12397",
    "authors": [
      "Nan Zhong",
      "Yiran Xu",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.13812",
    "title": "Mechanical Characterization and Inverse Design of Stochastic Architected  Metamaterials Using Neural Operators",
    "abstract": " Comments: 29 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2311.13812",
    "authors": [
      "Hanxun Jin",
      "Enrui Zhang",
      "Boyu Zhang",
      "Sridhar Krishnaswamy",
      "George Em Karniadakis",
      "Horacio D. Espinosa"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.15643",
    "title": "A Survey on Monocular Re-Localization: From the Perspective of Scene Map  Representation",
    "abstract": " Comments: 108 pages, 9 tables, 17 figures, under review ",
    "url": "https://arxiv.org/abs/2311.15643",
    "authors": [
      "Jinyu Miao",
      "Kun Jiang",
      "Tuopu Wen",
      "Yunlong Wang",
      "Peijing Jia",
      "Xuhe Zhao",
      "Qian Cheng",
      "Zhongyang Xiao",
      "Jin Huang",
      "Zhihua Zhong",
      "Diange Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.16378",
    "title": "Bayesian Formulations for Graph Spectral Denoising",
    "abstract": " Title: Bayesian Formulations for Graph Spectral Denoising ",
    "url": "https://arxiv.org/abs/2311.16378",
    "authors": [
      "Sam Leone",
      "Xingzhi Sun",
      "Michael Perlmutter",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.16945",
    "title": "UC-NeRF: Neural Radiance Field for Under-Calibrated Multi-view Cameras  in Autonomous Driving",
    "abstract": " Comments: See the project page for code, data: this https URL ",
    "url": "https://arxiv.org/abs/2311.16945",
    "authors": [
      "Kai Cheng",
      "Xiaoxiao Long",
      "Wei Yin",
      "Jin Wang",
      "Zhiqiang Wu",
      "Yuexin Ma",
      "Kaixuan Wang",
      "Xiaozhi Chen",
      "Xuejin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00534",
    "title": "LiDAR-based curb detection for ground truth annotation in automated  driving validation",
    "abstract": " Comments: Accepted in the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023) ",
    "url": "https://arxiv.org/abs/2312.00534",
    "authors": [
      "Jose Luis Apell\u00e1niz",
      "Mikel Garc\u00eda",
      "Nerea Aranjuelo",
      "Javier Barandiar\u00e1n",
      "Marcos Nieto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01150",
    "title": "Pointer Networks Trained Better via Evolutionary Algorithms",
    "abstract": " Comments: None ",
    "url": "https://arxiv.org/abs/2312.01150",
    "authors": [
      "Muyao Zhong",
      "Shengcai Liu",
      "Bingdong Li",
      "Haobo Fu",
      "Ke Tang",
      "Peng Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.01219",
    "title": "A Hierarchical Security Events Correlation Model for Real-time Cyber  Threat Detection and Response",
    "abstract": " Comments: version 2.4 ",
    "url": "https://arxiv.org/abs/2312.01219",
    "authors": [
      "Herbert Maosa",
      "Karim Ouazzane",
      "Mohamed Chahine Ghanem"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.01648",
    "title": "Characterizing Large Language Model Geometry Solves Toxicity Detection  and Generation",
    "abstract": " Title: Characterizing Large Language Model Geometry Solves Toxicity Detection  and Generation ",
    "url": "https://arxiv.org/abs/2312.01648",
    "authors": [
      "Randall Balestriero",
      "Romain Cosentino",
      "Sarath Shekkizhar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.01878",
    "title": "HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot  Prompt Learning",
    "abstract": " Comments: Accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2312.01878",
    "authors": [
      "Xingtong Yu",
      "Yuan Fang",
      "Zemin Liu",
      "Xinming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.02396",
    "title": "Unsupervised Change Detection for Space Habitats Using 3D Point Clouds",
    "abstract": " Comments: 15 pages, 7 figures, Manuscript will be presented at the AIAA SciTech Forum in Orlando, FL, USA, 8 - 12 January 2024 ",
    "url": "https://arxiv.org/abs/2312.02396",
    "authors": [
      "Jamie Santos",
      "Holly Dinkel",
      "Julia Di",
      "Paulo V.K. Borges",
      "Marina Moreira",
      "Oleg Alexandrov",
      "Brian Coltin",
      "Trey Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.03196",
    "title": "Domain Invariant Representation Learning and Sleep Dynamics Modeling for  Automatic Sleep Staging",
    "abstract": " Title: Domain Invariant Representation Learning and Sleep Dynamics Modeling for  Automatic Sleep Staging ",
    "url": "https://arxiv.org/abs/2312.03196",
    "authors": [
      "Seungyeon Lee",
      "Thai-Hoang Pham",
      "Zhao Cheng",
      "Ping Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.03325",
    "title": "GCFA:Geodesic Curve Feature Augmentation in the Pre-Shape Space",
    "abstract": " Title: GCFA:Geodesic Curve Feature Augmentation in the Pre-Shape Space ",
    "url": "https://arxiv.org/abs/2312.03325",
    "authors": [
      "Yuexing Han",
      "Guanxin Wan",
      "Bing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.03549",
    "title": "Holmes: Towards Distributed Training Across Clusters with Heterogeneous  NIC Environment",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2312.03549",
    "authors": [
      "Fei Yang",
      "Shuang Peng",
      "Ning Sun",
      "Fangyu Wang",
      "Ke Tan",
      "Fu Wu",
      "Jiezhong Qiu",
      "Aimin Pan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.03996",
    "title": "Stable diffusion for Data Augmentation in COCO and Weed Datasets",
    "abstract": " Title: Stable diffusion for Data Augmentation in COCO and Weed Datasets ",
    "url": "https://arxiv.org/abs/2312.03996",
    "authors": [
      "Boyang Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.04004",
    "title": "Occlusion-based Detection of Trojan-triggering Inputs in Large Language  Models of Code",
    "abstract": " Title: Occlusion-based Detection of Trojan-triggering Inputs in Large Language  Models of Code ",
    "url": "https://arxiv.org/abs/2312.04004",
    "authors": [
      "Aftab Hussain",
      "Md Rafiqul Islam Rabin",
      "Toufique Ahmed",
      "Mohammad Amin Alipour",
      "Bowen Xu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.04025",
    "title": "Moirai: Towards Optimal Placement for Distributed Inference on  Heterogeneous Devices",
    "abstract": " Comments: Temprarily withdraw to amend experimental results ",
    "url": "https://arxiv.org/abs/2312.04025",
    "authors": [
      "Beibei Zhang",
      "Hongwei Zhu",
      "Feng Gao",
      "Zhihui Yang",
      "Sean Xiaoyang Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.04055",
    "title": "Jointly spatial-temporal representation learning for individual  trajectories",
    "abstract": " Comments: 27 pages, 3 tables, 7 figures ",
    "url": "https://arxiv.org/abs/2312.04055",
    "authors": [
      "Fei Huang",
      "Jianrong Lv",
      "Yang Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.04519",
    "title": "Bootstrapping Autonomous Radars with Self-Supervised Learning",
    "abstract": " Title: Bootstrapping Autonomous Radars with Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2312.04519",
    "authors": [
      "Yiduo Hao",
      "Sohrab Madani",
      "Junfeng Guan",
      "Mohammed Alloulah",
      "Saurabh Gupta",
      "Haitham Hassanieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.04584",
    "title": "Towards Sample-specific Backdoor Attack with Clean Labels via Attribute  Trigger",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2312.04584",
    "authors": [
      "Yiming Li",
      "Mingyan Zhu",
      "Junfeng Guo",
      "Tao Wei",
      "Shu-Tao Xia",
      "Zhan Qin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.04876",
    "title": "GVE-Louvain: Fast Louvain Algorithm for Community Detection in Shared  Memory Setting",
    "abstract": " Comments: 9 pages, 8 figures, 1 table ",
    "url": "https://arxiv.org/abs/2312.04876",
    "authors": [
      "Subhajit Sahu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  }
]