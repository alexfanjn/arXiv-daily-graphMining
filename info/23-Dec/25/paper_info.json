[
  {
    "id": "arXiv:2312.14180",
    "title": "Dynamic Topic Language Model on Heterogeneous Children's Mental Health  Clinical Notes",
    "abstract": "Mental health diseases affect children's lives and well-beings which have received increased attention since the COVID-19 pandemic. Analyzing psychiatric clinical notes with topic models is critical to evaluate children's mental status over time. However, few topic models are built for longitudinal settings, and they fail to keep consistent topics and capture temporal trajectories for each document. To address these challenges, we develop a longitudinal topic model with time-invariant topics and individualized temporal dependencies on the evolving document metadata. Our model preserves the semantic meaning of discovered topics over time and incorporates heterogeneity among documents. In particular, when documents can be categorized, we propose an unsupervised topics learning approach to maximize topic heterogeneity across different document groups. We also present an efficient variational optimization procedure adapted for the multistage longitudinal setting. In this case study, we apply our method to the psychiatric clinical notes from a large tertiary pediatric hospital in Southern California and achieve a 38% increase in the overall coherence of extracted topics. Our real data analysis reveals that children tend to express more negative emotions during state shutdowns and more positive when schools reopen. Furthermore, it suggests that sexual and gender minority (SGM) children display more pronounced reactions to major COVID-19 events and a greater sensitivity to vaccine-related news than non-SGM children. This study examines the progression of children's mental health during the pandemic and offers clinicians valuable insights to recognize the disparities in children's mental health related to their sexual and gender identities. ",
    "url": "https://arxiv.org/abs/2312.14180",
    "authors": [
      "Hanwen Ye",
      "Tatiana Moreno",
      "Adrianne Alpern",
      "Louis Ehwerhemuepha",
      "Annie Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.14182",
    "title": "Find the Lady: Permutation and Re-Synchronization of Deep Neural  Networks",
    "abstract": "Deep neural networks are characterized by multiple symmetrical, equi-loss solutions that are redundant. Thus, the order of neurons in a layer and feature maps can be given arbitrary permutations, without affecting (or minimally affecting) their output. If we shuffle these neurons, or if we apply to them some perturbations (like fine-tuning) can we put them back in the original order i.e. re-synchronize? Is there a possible corruption threat? Answering these questions is important for applications like neural network white-box watermarking for ownership tracking and integrity verification. We advance a method to re-synchronize the order of permuted neurons. Our method is also effective if neurons are further altered by parameter pruning, quantization, and fine-tuning, showing robustness to integrity attacks. Additionally, we provide theoretical and practical evidence for the usual means to corrupt the integrity of the model, resulting in a solution to counter it. We test our approach on popular computer vision datasets and models, and we illustrate the threat and our countermeasure on a popular white-box watermarking method. ",
    "url": "https://arxiv.org/abs/2312.14182",
    "authors": [
      "Carl De Sousa Trias",
      "Mihai Petru Mitrea",
      "Attilio Fiandrotti",
      "Marco Cagnazzo",
      "Sumanta Chaudhuri",
      "Enzo Tartaglione"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.14183",
    "title": "On Early Detection of Hallucinations in Factual Question Answering",
    "abstract": "While large language models (LLMs) have taken great strides towards helping humans with a plethora of tasks like search and summarization, hallucinations remain a major impediment towards gaining user trust. The fluency and coherence of model generations even when hallucinating makes it difficult to detect whether or not a model is hallucinating. In this work, we explore if the artifacts associated with the model generations can provide hints that the generation will contain hallucinations. Specifically, we probe LLMs at 1) the inputs via Integrated Gradients based token attribution, 2) the outputs via the Softmax probabilities, and 3) the internal state via self-attention and fully-connected layer activations for signs of hallucinations on open-ended question answering tasks. Our results show that the distributions of these artifacts differ between hallucinated and non-hallucinated generations. Building on this insight, we train binary classifiers that use these artifacts as input features to classify model generations into hallucinations and non-hallucinations. These hallucination classifiers achieve up to 0.80 AUROC. We further show that tokens preceding a hallucination can predict the subsequent hallucination before it occurs. ",
    "url": "https://arxiv.org/abs/2312.14183",
    "authors": [
      "Ben Snyder",
      "Marius Moisescu",
      "Muhammad Bilal Zafar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14188",
    "title": "Enhancing Neural Theorem Proving through Data Augmentation and Dynamic  Sampling Method",
    "abstract": "Theorem proving is a fundamental task in mathematics. With the advent of large language models (LLMs) and interactive theorem provers (ITPs) like Lean, there has been growing interest in integrating LLMs and ITPs to automate theorem proving. In this approach, the LLM generates proof steps (tactics), and the ITP checks the applicability of the tactics at the current goal. The two systems work together to complete the proof. In this paper, we introduce DS-Prover, a novel dynamic sampling method for theorem proving. This method dynamically determines the number of tactics to apply to expand the current goal, taking into account the remaining time compared to the total allocated time for proving a theorem. This makes the proof search process more efficient by adjusting the balance between exploration and exploitation as time passes. We also augment the training dataset by decomposing simplification and rewrite tactics with multiple premises into tactics with single premises. This gives the model more examples to learn from and helps it to predict the tactics with premises more accurately. We perform our experiments using the Mathlib dataset of the Lean theorem prover and report the performance on two standard datasets, MiniF2F and ProofNet. Our methods achieve significant performance gains on both datasets. We achieved a state-of-the-art performance (Pass@1) of 14.2% on the ProofNet dataset and a performance of 29.8% on MiniF2F, slightly surpassing the best-reported Pass@1 of 29.6% using Lean. ",
    "url": "https://arxiv.org/abs/2312.14188",
    "authors": [
      "Rahul Vishwakarma",
      "Subhankar Mishra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2312.14197",
    "title": "Benchmarking and Defending Against Indirect Prompt Injection Attacks on  Large Language Models",
    "abstract": "Recent remarkable advancements in large language models (LLMs) have led to their widespread adoption in various applications. A key feature of these applications is the combination of LLMs with external content, where user instructions and third-party content are combined to create prompts for LLM processing. These applications, however, are vulnerable to indirect prompt injection attacks, where malicious instructions embedded within external content compromise LLM's output, causing their responses to deviate from user expectations. Despite the discovery of this security issue, no comprehensive analysis of indirect prompt injection attacks on different LLMs is available due to the lack of a benchmark. Furthermore, no effective defense has been proposed. In this work, we introduce the first benchmark, BIPIA, to measure the robustness of various LLMs and defenses against indirect prompt injection attacks. Our experiments reveal that LLMs with greater capabilities exhibit more vulnerable to indirect prompt injection attacks for text tasks, resulting in a higher ASR. We hypothesize that indirect prompt injection attacks are mainly due to the LLMs' inability to distinguish between instructions and external content. Based on this conjecture, we propose four black-box methods based on prompt learning and a white-box defense methods based on fine-tuning with adversarial training to enable LLMs to distinguish between instructions and external content and ignore instructions in the external content. Our experimental results show that our black-box defense methods can effectively reduce ASR but cannot completely thwart indirect prompt injection attacks, while our white-box defense method can reduce ASR to nearly zero with little adverse impact on the LLM's performance on general tasks. We hope that our benchmark and defenses can inspire future work in this important area. ",
    "url": "https://arxiv.org/abs/2312.14197",
    "authors": [
      "Jingwei Yi",
      "Yueqi Xie",
      "Bin Zhu",
      "Keegan Hines",
      "Emre Kiciman",
      "Guangzhong Sun",
      "Xing Xie",
      "Fangzhao Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14201",
    "title": "Towards Better Visualizing the Decision Basis of Networks via Unfold and  Conquer Attribution Guidance",
    "abstract": "Revealing the transparency of Deep Neural Networks (DNNs) has been widely studied to describe the decision mechanisms of network inner structures. In this paper, we propose a novel post-hoc framework, Unfold and Conquer Attribution Guidance (UCAG), which enhances the explainability of the network decision by spatially scrutinizing the input features with respect to the model confidence. Addressing the phenomenon of missing detailed descriptions, UCAG sequentially complies with the confidence of slices of the image, leading to providing an abundant and clear interpretation. Therefore, it is possible to enhance the representation ability of explanation by preserving the detailed descriptions of assistant input features, which are commonly overwhelmed by the main meaningful regions. We conduct numerous evaluations to validate the performance in several metrics: i) deletion and insertion, ii) (energy-based) pointing games, and iii) positive and negative density maps. Experimental results, including qualitative comparisons, demonstrate that our method outperforms the existing methods with the nature of clear and detailed explanations and applicability. ",
    "url": "https://arxiv.org/abs/2312.14201",
    "authors": [
      "Jung-Ho Hong",
      "Woo-Jeoung Nam",
      "Kyu-Sung Jeon",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14210",
    "title": "Forecasting Fold Bifurcations through Physics-Informed Convolutional  Neural Networks",
    "abstract": "This study proposes a physics-informed convolutional neural network (CNN) for identifying dynamical systems' time series near a fold bifurcation. The peculiarity of this work is that the CNN is trained with a relatively small amount of data and on a single, very simple system. In contrast, the CNN is validated on much more complicated systems. A similar task requires significant extrapolation capabilities, which are obtained by exploiting physics-based information. Physics-based information is provided through a specific pre-processing of the input data, consisting mostly of a transformation into polar coordinates, normalization, transformation into the logarithmic scale, and filtering through a moving mean. The results illustrate that such data pre-processing enables the CNN to grasp the important features related to approaching a fold bifurcation, namely, the trend of the oscillation amplitude, and neglect other characteristics that are not particularly relevant, such as the vibration frequency. The developed CNN was able to correctly classify trajectories near a fold for a mass-on-moving-belt system, a van der Pol-Duffing oscillator with an attached tuned mass damper, and a pitch-and-plunge wing profile. The results obtained pave the way for the development of similar CNNs effective in real-life applications. ",
    "url": "https://arxiv.org/abs/2312.14210",
    "authors": [
      "Giuseppe Habib",
      "\u00c1d\u00e1m Horv\u00e1th"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2312.14217",
    "title": "Adversarial Infrared Curves: An Attack on Infrared Pedestrian Detectors  in the Physical World",
    "abstract": "Deep neural network security is a persistent concern, with considerable research on visible light physical attacks but limited exploration in the infrared domain. Existing approaches, like white-box infrared attacks using bulb boards and QR suits, lack realism and stealthiness. Meanwhile, black-box methods with cold and hot patches often struggle to ensure robustness. To bridge these gaps, we propose Adversarial Infrared Curves (AdvIC). Using Particle Swarm Optimization, we optimize two Bezier curves and employ cold patches in the physical realm to introduce perturbations, creating infrared curve patterns for physical sample generation. Our extensive experiments confirm AdvIC's effectiveness, achieving 94.8\\% and 67.2\\% attack success rates for digital and physical attacks, respectively. Stealthiness is demonstrated through a comparative analysis, and robustness assessments reveal AdvIC's superiority over baseline methods. When deployed against diverse advanced detectors, AdvIC achieves an average attack success rate of 76.8\\%, emphasizing its robust nature. we explore adversarial defense strategies against AdvIC and examine its impact under various defense mechanisms. Given AdvIC's substantial security implications for real-world vision-based applications, urgent attention and mitigation efforts are warranted. ",
    "url": "https://arxiv.org/abs/2312.14217",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.14218",
    "title": "AutoAugment Input Transformation for Highly Transferable Targeted  Attacks",
    "abstract": "Deep Neural Networks (DNNs) are widely acknowledged to be susceptible to adversarial examples, wherein imperceptible perturbations are added to clean examples through diverse input transformation attacks. However, these methods originally designed for non-targeted attacks exhibit low success rates in targeted attacks. Recent targeted adversarial attacks mainly pay attention to gradient optimization, attempting to find the suitable perturbation direction. However, few of them are dedicated to input transformation.In this work, we observe a positive correlation between the logit/probability of the target class and diverse input transformation methods in targeted attacks. To this end, we propose a novel targeted adversarial attack called AutoAugment Input Transformation (AAIT). Instead of relying on hand-made strategies, AAIT searches for the optimal transformation policy from a transformation space comprising various operations. Then, AAIT crafts adversarial examples using the found optimal transformation policy to boost the adversarial transferability in targeted attacks. Extensive experiments conducted on CIFAR-10 and ImageNet-Compatible datasets demonstrate that the proposed AAIT surpasses other transfer-based targeted attacks significantly. ",
    "url": "https://arxiv.org/abs/2312.14218",
    "authors": [
      "Haobo Lu",
      "Xin Liu",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14222",
    "title": "Hierarchical Topology Isomorphism Expertise Embedded Graph Contrastive  Learning",
    "abstract": "Graph contrastive learning (GCL) aims to align the positive features while differentiating the negative features in the latent space by minimizing a pair-wise contrastive loss. As the embodiment of an outstanding discriminative unsupervised graph representation learning approach, GCL achieves impressive successes in various graph benchmarks. However, such an approach falls short of recognizing the topology isomorphism of graphs, resulting in that graphs with relatively homogeneous node features cannot be sufficiently discriminated. By revisiting classic graph topology recognition works, we disclose that the corresponding expertise intuitively complements GCL methods. To this end, we propose a novel hierarchical topology isomorphism expertise embedded graph contrastive learning, which introduces knowledge distillations to empower GCL models to learn the hierarchical topology isomorphism expertise, including the graph-tier and subgraph-tier. On top of this, the proposed method holds the feature of plug-and-play, and we empirically demonstrate that the proposed method is universal to multiple state-of-the-art GCL models. The solid theoretical analyses are further provided to prove that compared with conventional GCL methods, our method acquires the tighter upper bound of Bayes classification error. We conduct extensive experiments on real-world benchmarks to exhibit the performance superiority of our method over candidate GCL methods, e.g., for the real-world graph representation learning experiments, the proposed method beats the state-of-the-art method by 0.23\\% on unsupervised representation learning setting, 0.43\\% on transfer learning setting. Our code is available at https://github.com/jyf123/HTML. ",
    "url": "https://arxiv.org/abs/2312.14222",
    "authors": [
      "Jiangmeng Li",
      "Yifan Jin",
      "Hang Gao",
      "Wenwen Qiang",
      "Changwen Zheng",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14229",
    "title": "Real-time Neural Network Inference on Extremely Weak Devices: Agile  Offloading with Explainable AI",
    "abstract": "With the wide adoption of AI applications, there is a pressing need of enabling real-time neural network (NN) inference on small embedded devices, but deploying NNs and achieving high performance of NN inference on these small devices is challenging due to their extremely weak capabilities. Although NN partitioning and offloading can contribute to such deployment, they are incapable of minimizing the local costs at embedded devices. Instead, we suggest to address this challenge via agile NN offloading, which migrates the required computations in NN offloading from online inference to offline learning. In this paper, we present AgileNN, a new NN offloading technique that achieves real-time NN inference on weak embedded devices by leveraging eXplainable AI techniques, so as to explicitly enforce feature sparsity during the training phase and minimize the online computation and communication costs. Experiment results show that AgileNN's inference latency is >6x lower than the existing schemes, ensuring that sensory data on embedded devices can be timely consumed. It also reduces the local device's resource consumption by >8x, without impairing the inference accuracy. ",
    "url": "https://arxiv.org/abs/2312.14229",
    "authors": [
      "Kai Huang",
      "Wei Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14235",
    "title": "Neural Spline Fields for Burst Image Fusion and Layer Separation",
    "abstract": "Each photo in an image burst can be considered a sample of a complex 3D scene: the product of parallax, diffuse and specular materials, scene motion, and illuminant variation. While decomposing all of these effects from a stack of misaligned images is a highly ill-conditioned task, the conventional align-and-merge burst pipeline takes the other extreme: blending them into a single image. In this work, we propose a versatile intermediate representation: a two-layer alpha-composited image plus flow model constructed with neural spline fields -- networks trained to map input coordinates to spline control points. Our method is able to, during test-time optimization, jointly fuse a burst image capture into one high-resolution reconstruction and decompose it into transmission and obstruction layers. Then, by discarding the obstruction layer, we can perform a range of tasks including seeing through occlusions, reflection suppression, and shadow removal. Validated on complex synthetic and in-the-wild captures we find that, with no post-processing steps or learned priors, our generalizable model is able to outperform existing dedicated single-image and multi-view obstruction removal approaches. ",
    "url": "https://arxiv.org/abs/2312.14235",
    "authors": [
      "Ilya Chugunov",
      "David Shustin",
      "Ruyu Yan",
      "Chenyang Lei",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14247",
    "title": "Deep Reinforcement Learning Based Placement for Integrated Access  Backhauling in UAV-Assisted Wireless Networks",
    "abstract": "The advent of fifth generation (5G) networks has opened new avenues for enhancing connectivity, particularly in challenging environments like remote areas or disaster-struck regions. Unmanned aerial vehicles (UAVs) have been identified as a versatile tool in this context, particularly for improving network performance through the Integrated access and backhaul (IAB) feature of 5G. However, existing approaches to UAV-assisted network enhancement face limitations in dynamically adapting to varying user locations and network demands. This paper introduces a novel approach leveraging deep reinforcement learning (DRL) to optimize UAV placement in real-time, dynamically adjusting to changing network conditions and user requirements. Our method focuses on the intricate balance between fronthaul and backhaul links, a critical aspect often overlooked in current solutions. The unique contribution of this work lies in its ability to autonomously position UAVs in a way that not only ensures robust connectivity to ground users but also maintains seamless integration with central network infrastructure. Through various simulated scenarios, we demonstrate how our approach effectively addresses these challenges, enhancing coverage and network performance in critical areas. This research fills a significant gap in UAV-assisted 5G networks, providing a scalable and adaptive solution for future mobile networks. ",
    "url": "https://arxiv.org/abs/2312.14247",
    "authors": [
      "Yuhui Wang",
      "Junaid Farooq"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.14259",
    "title": "Multi-Agent Bandit Learning through Heterogeneous Action Erasure  Channels",
    "abstract": "Multi-Armed Bandit (MAB) systems are witnessing an upswing in applications within multi-agent distributed environments, leading to the advancement of collaborative MAB algorithms. In such settings, communication between agents executing actions and the primary learner making decisions can hinder the learning process. A prevalent challenge in distributed learning is action erasure, often induced by communication delays and/or channel noise. This results in agents possibly not receiving the intended action from the learner, subsequently leading to misguided feedback. In this paper, we introduce novel algorithms that enable learners to interact concurrently with distributed agents across heterogeneous action erasure channels with different action erasure probabilities. We illustrate that, in contrast to existing bandit algorithms, which experience linear regret, our algorithms assure sub-linear regret guarantees. Our proposed solutions are founded on a meticulously crafted repetition protocol and scheduling of learning across heterogeneous channels. To our knowledge, these are the first algorithms capable of effectively learning through heterogeneous action erasure channels. We substantiate the superior performance of our algorithm through numerical experiments, emphasizing their practical significance in addressing issues related to communication constraints and delays in multi-agent environments. ",
    "url": "https://arxiv.org/abs/2312.14259",
    "authors": [
      "Osama A. Hanna",
      "Merve Karakas",
      "Lin F. Yang",
      "Christina Fragouli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2312.14260",
    "title": "Elevating Defenses: Bridging Adversarial Training and Watermarking for  Model Resilience",
    "abstract": "Machine learning models are being used in an increasing number of critical applications; thus, securing their integrity and ownership is critical. Recent studies observed that adversarial training and watermarking have a conflicting interaction. This work introduces a novel framework to integrate adversarial training with watermarking techniques to fortify against evasion attacks and provide confident model verification in case of intellectual property theft. We use adversarial training together with adversarial watermarks to train a robust watermarked model. The key intuition is to use a higher perturbation budget to generate adversarial watermarks compared to the budget used for adversarial training, thus avoiding conflict. We use the MNIST and Fashion-MNIST datasets to evaluate our proposed technique on various model stealing attacks. The results obtained consistently outperform the existing baseline in terms of robustness performance and further prove the resilience of this defense against pruning and fine-tuning removal attacks. ",
    "url": "https://arxiv.org/abs/2312.14260",
    "authors": [
      "Janvi Thakkar",
      "Giulio Zizzo",
      "Sergio Maffeis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.14261",
    "title": "Low-power event-based face detection with asynchronous neuromorphic  hardware",
    "abstract": "The rise of mobility, IoT and wearables has shifted processing to the edge of the sensors, driven by the need to reduce latency, communication costs and overall energy consumption. While deep learning models have achieved remarkable results in various domains, their deployment at the edge for real-time applications remains computationally expensive. Neuromorphic computing emerges as a promising paradigm shift, characterized by co-localized memory and computing as well as event-driven asynchronous sensing and processing. In this work, we demonstrate the possibility of solving the ubiquitous computer vision task of object detection at the edge with low-power requirements, using the event-based N-Caltech101 dataset. We present the first instance of an on-chip spiking neural network for event-based face detection deployed on the SynSense Speck neuromorphic chip, which comprises both an event-based sensor and a spike-based asynchronous processor implementing Integrate-and-Fire neurons. We show how to reduce precision discrepancies between off-chip clock-driven simulation used for training and on-chip event-driven inference. This involves using a multi-spike version of the Integrate-and-Fire neuron on simulation, where spikes carry values that are proportional to the extent the membrane potential exceeds the firing threshold. We propose a robust strategy to train spiking neural networks with back-propagation through time using multi-spike activation and firing rate regularization and demonstrate how to decode output spikes into bounding boxes. We show that the power consumption of the chip is directly proportional to the number of synaptic operations in the spiking neural network, and we explore the trade-off between power consumption and detection precision with different firing rate regularization, achieving an on-chip face detection mAP[0.5] of ~0.6 while consuming only ~20 mW. ",
    "url": "https://arxiv.org/abs/2312.14261",
    "authors": [
      "Caterina Caccavella",
      "Federico Paredes-Vall\u00e9s",
      "Marco Cannici",
      "Lyes Khacef"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.14276",
    "title": "Deep Neural Networks and Finite Elements of Any Order on Arbitrary  Dimensions",
    "abstract": "In this study, we establish that deep neural networks employing ReLU and ReLU$^2$ activation functions are capable of representing Lagrange finite element functions of any order on simplicial meshes across arbitrary dimensions. We introduce a novel global formulation of the basis functions for Lagrange elements, grounded in a geometric decomposition of these elements and leveraging two essential properties of high-dimensional simplicial meshes and barycentric coordinate functions. This representation theory facilitates a natural approximation result for such deep neural networks. Our findings present the first demonstration of how deep neural networks can systematically generate general continuous piecewise polynomial functions. ",
    "url": "https://arxiv.org/abs/2312.14276",
    "authors": [
      "Juncai He",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14293",
    "title": "Friends with Costs and Benefits: Community Formation with Myopic,  Boundedly-Rational Actors",
    "abstract": "In this paper we address how complex social communities emerge from local decisions by individuals with limited attention and knowledge. This problem is critical; if we understand community formation mechanisms, it may be possible to intervene to improve social welfare. We propose an interpretable, novel model for attributed community formation driven by resource-bounded individuals' strategic, selfish behavior. In our stylized model, attributed individuals act strategically in two dimensions: attribute and network structure. Agents are endowed with limited attention, and communication costs limit the number of active connections. In each time step, each agent proposes a new friendship. Agents then accept proposals, decline proposals, or remove friends, consistent with their strategy to maximize payoff. We identify criteria (number of stable triads) for convergence to some community structure and prove that our community formation model converges to a stable network. Ablations justify the ecological validity of our model and show that each aspect of the model is essential. Our empirical results on a physical world microfinance community demonstrate excellent model fits compared to baseline models. ",
    "url": "https://arxiv.org/abs/2312.14293",
    "authors": [
      "Naina Balepur",
      "Andy Lee",
      "Hari Sundaram"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2312.14295",
    "title": "On Separating Path and Tree Systems in Graphs",
    "abstract": "We explore the concept of separating systems of vertex sets of graphs. A separating system of a set $X$ is a collection of subsets of $X$ such that for any pair of distinct elements in $X$, there exists a set in the separating system that contains exactly one of the two elements. A separating system of the vertex set of a graph $G$ is called a vertex-separating path (tree) system of $G$ if the elements of the separating system are paths (trees) in the graph $G$. In this paper, we focus on the size of the smallest vertex-separating path (tree) system for different types of graphs, including trees, grids, and maximal outerplanar graphs. ",
    "url": "https://arxiv.org/abs/2312.14295",
    "authors": [
      "Ahmad Biniaz",
      "Prosenjit Bose",
      "Jean-Lou De Carufel",
      "Anil Maheshwari",
      "Babak Miraftab",
      "Saeed Odak",
      "Michiel Smid",
      "Shakhar Smorodinsky",
      "Yelena Yuditsky"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2312.14305",
    "title": "The Exact Spanning Ratio of the Parallelogram Delaunay Graph",
    "abstract": "Finding the exact spanning ratio of a Delaunay graph has been one of the longstanding open problems in Computational Geometry. Currently there are only four convex shapes for which the exact spanning ratio of their Delaunay graph is known: the equilateral triangle, the square, the regular hexagon and the rectangle. In this paper, we show the exact spanning ratio of the parallelogram Delaunay graph, making the parallelogram the fifth convex shape for which an exact bound is known. The worst-case spanning ratio is exactly $$\\frac{\\sqrt{2}\\sqrt{1+A^2+2A\\cos(\\theta_0)+(A+\\cos(\\theta_0))\\sqrt{1+A^2+2A\\cos(\\theta_0)}}}{\\sin(\\theta_0)} .$$ where $A$ is the aspect ratio and $\\theta_0$ is the non-obtuse angle of the parallelogram. Moreover, we show how to construct a parallelogram Delaunay graph whose spanning ratio matches the above mentioned spanning ratio. ",
    "url": "https://arxiv.org/abs/2312.14305",
    "authors": [
      "Prosenjit Bose",
      "Jean-Lou De Carufel",
      "Sandrine Njoo"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2312.14306",
    "title": "Social Recommendation through Heterogeneous Graph Modeling of the  Long-term and Short-term Preference Defined by Dynamic Periods",
    "abstract": "Social recommendations have been widely adopted in substantial domains. Recently, graph neural networks (GNN) have been employed in recommender systems due to their success in graph representation learning. However, dealing with the dynamic property of social network data is a challenge. This research presents a novel method that provides social recommendations by incorporating the dynamic property of social network data in a heterogeneous graph. The model aims to capture user preference over time without going through the complexities of a dynamic graph by adding period nodes to define users' long-term and short-term preferences and aggregating assigned edge weights. The model is applied to real-world data to argue its superior performance. Promising results demonstrate the effectiveness of this model. ",
    "url": "https://arxiv.org/abs/2312.14306",
    "authors": [
      "Behafarid Mohammad Jafari",
      "Xiao Luo",
      "Ali Jafari"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2312.14329",
    "title": "Invariant Anomaly Detection under Distribution Shifts: A Causal  Perspective",
    "abstract": "Anomaly detection (AD) is the machine learning task of identifying highly discrepant abnormal samples by solely relying on the consistency of the normal training samples. Under the constraints of a distribution shift, the assumption that training samples and test samples are drawn from the same distribution breaks down. In this work, by leveraging tools from causal inference we attempt to increase the resilience of anomaly detection models to different kinds of distribution shifts. We begin by elucidating a simple yet necessary statistical property that ensures invariant representations, which is critical for robust AD under both domain and covariate shifts. From this property, we derive a regularization term which, when minimized, leads to partial distribution invariance across environments. Through extensive experimental evaluation on both synthetic and real-world tasks, covering a range of six different AD methods, we demonstrated significant improvements in out-of-distribution performance. Under both covariate and domain shift, models regularized with our proposed term showed marked increased robustness. Code is available at: https://github.com/JoaoCarv/invariant-anomaly-detection. ",
    "url": "https://arxiv.org/abs/2312.14329",
    "authors": [
      "Jo\u00e3o B. S. Carvalho",
      "Mengtao Zhang",
      "Robin Geyer",
      "Carlos Cotrini",
      "Joachim M. Buhmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14333",
    "title": "Behaviour Modelling of Social Animals via Causal Structure Discovery and  Graph Neural Networks",
    "abstract": "Better understanding the natural world is a crucial task with a wide range of applications. In environments with close proximity between humans and animals, such as zoos, it is essential to better understand the causes behind animal behaviour and what interventions are responsible for changes in their behaviours. This can help to predict unusual behaviours, mitigate detrimental effects and increase the well-being of animals. There has been work on modelling the dynamics behind swarms of birds and insects but the complex social behaviours of mammalian groups remain less explored. In this work, we propose a method to build behavioural models using causal structure discovery and graph neural networks for time series. We apply this method to a mob of meerkats in a zoo environment and study its ability to predict future actions and model the behaviour distribution at an individual-level and at a group level. We show that our method can match and outperform standard deep learning architectures and generate more realistic data, while using fewer parameters and providing increased interpretability. ",
    "url": "https://arxiv.org/abs/2312.14333",
    "authors": [
      "Ga\u00ebl Gendron",
      "Yang Chen",
      "Mitchell Rogers",
      "Yiping Liu",
      "Mihailo Azhar",
      "Shahrokh Heidari",
      "David Arturo Soriano Valdez",
      "Kobe Knowles",
      "Padriac O'Leary",
      "Simon Eyre",
      "Michael Witbrock",
      "Gillian Dobbie",
      "Jiamou Liu",
      "Patrice Delmas"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.14359",
    "title": "Training Neural Networks with Internal State, Unconstrained  Connectivity, and Discrete Activations",
    "abstract": "Today's most powerful machine learning approaches are typically designed to train stateless architectures with predefined layers and differentiable activation functions. While these approaches have led to unprecedented successes in areas such as natural language processing and image recognition, the trained models are also susceptible to making mistakes that a human would not. In this paper, we take the view that true intelligence may require the ability of a machine learning model to manage internal state, but that we have not yet discovered the most effective algorithms for training such models. We further postulate that such algorithms might not necessarily be based on gradient descent over a deep architecture, but rather, might work best with an architecture that has discrete activations and few initial topological constraints (such as multiple predefined layers). We present one attempt in our ongoing efforts to design such a training algorithm, applied to an architecture with binary activations and only a single matrix of weights, and show that it is able to form useful representations of natural language text, but is also limited in its ability to leverage large quantities of training data. We then provide ideas for improving the algorithm and for designing other training algorithms for similar architectures. Finally, we discuss potential benefits that could be gained if an effective training algorithm is found, and suggest experiments for evaluating whether these benefits exist in practice. ",
    "url": "https://arxiv.org/abs/2312.14359",
    "authors": [
      "Alexander Grushin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.14370",
    "title": "Partitioned neural network approximation for partial differential  equations enhanced with Lagrange multipliers and localized loss functions",
    "abstract": "Partitioned neural network functions are used to approximate the solution of partial differential equations. The problem domain is partitioned into non-overlapping subdomains and the partitioned neural network functions are defined on the given non-overlapping subdomains. Each neural network function then approximates the solution in each subdomain. To obtain the convergent neural network solution, certain continuity conditions on the partitioned neural network functions across the subdomain interface need to be included in the loss function, that is used to train the parameters in the neural network functions. In our work, by introducing suitable interface values, the loss function is reformulated into a sum of localized loss functions and each localized loss function is used to train the corresponding local neural network parameters. In addition, to accelerate the neural network solution convergence, the localized loss function is enriched with an augmented Lagrangian term, where the interface condition and the boundary condition are enforced as constraints on the local solutions by using Lagrange multipliers. The local neural network parameters and Lagrange multipliers are then found by optimizing the localized loss function. To take the advantage of the localized loss function for the parallel computation, an iterative algorithm is also proposed. For the proposed algorithms, their training performance and convergence are numerically studied for various test examples. ",
    "url": "https://arxiv.org/abs/2312.14370",
    "authors": [
      "Deok-Kyu Jang",
      "Kyungsoo Kim",
      "Hyea Hyun Kim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2312.14373",
    "title": "Learning Socio-Temporal Graphs for Multi-Agent Trajectory Prediction",
    "abstract": "In order to predict a pedestrian's trajectory in a crowd accurately, one has to take into account her/his underlying socio-temporal interactions with other pedestrians consistently. Unlike existing work that represents the relevant information separately, partially, or implicitly, we propose a complete representation for it to be fully and explicitly captured and analyzed. In particular, we introduce a Directed Acyclic Graph-based structure, which we term Socio-Temporal Graph (STG), to explicitly capture pair-wise socio-temporal interactions among a group of people across both space and time. Our model is built on a time-varying generative process, whose latent variables determine the structure of the STGs. We design an attention-based model named STGformer that affords an end-to-end pipeline to learn the structure of the STGs for trajectory prediction. Our solution achieves overall state-of-the-art prediction accuracy in two large-scale benchmark datasets. Our analysis shows that a person's past trajectory is critical for predicting another person's future path. Our model learns this relationship with a strong notion of socio-temporal localities. Statistics show that utilizing this information explicitly for prediction yields a noticeable performance gain with respect to the trajectory-only approaches. ",
    "url": "https://arxiv.org/abs/2312.14373",
    "authors": [
      "Yuke Li",
      "Lixiong Chen",
      "Guangyi Chen",
      "Ching-Yao Chan",
      "Kun Zhang",
      "Stefano Anzellotti",
      "Donglai Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14388",
    "title": "A Generalized Shuffle Framework for Privacy Amplification: Strengthening  Privacy Guarantees and Enhancing Utility",
    "abstract": "The shuffle model of local differential privacy is an advanced method of privacy amplification designed to enhance privacy protection with high utility. It achieves this by randomly shuffling sensitive data, making linking individual data points to specific individuals more challenging. However, most existing studies have focused on the shuffle model based on $(\\epsilon_0,0)$-Locally Differentially Private (LDP) randomizers, with limited consideration for complex scenarios such as $(\\epsilon_0,\\delta_0)$-LDP or personalized LDP (PLDP). This hinders a comprehensive understanding of the shuffle model's potential and limits its application in various settings. To bridge this research gap, we propose a generalized shuffle framework that can be applied to any $(\\epsilon_i,\\delta_i)$-PLDP setting with personalized privacy parameters. This generalization allows for a broader exploration of the privacy-utility trade-off and facilitates the design of privacy-preserving analyses in diverse contexts. We prove that shuffled $(\\epsilon_i,\\delta_i)$-PLDP process approximately preserves $\\mu$-Gaussian Differential Privacy with \\mu = \\sqrt{\\frac{2}{\\sum_{i=1}^{n} \\frac{1-\\delta_i}{1+e^{\\epsilon_i}}-\\max_{i}{\\frac{1-\\delta_{i}}{1+e^{\\epsilon_{i}}}}}}. $ This approach allows us to avoid the limitations and potential inaccuracies associated with inequality estimations. To strengthen the privacy guarantee, we improve the lower bound by utilizing hypothesis testing} instead of relying on rough estimations like the Chernoff bound or Hoeffding's inequality. Furthermore, extensive comparative evaluations clearly show that our approach outperforms existing methods in achieving strong central privacy guarantees while preserving the utility of the global model. We have also carefully designed corresponding algorithms for average function, frequency estimation, and stochastic gradient descent. ",
    "url": "https://arxiv.org/abs/2312.14388",
    "authors": [
      "E Chen",
      "Yang Cao",
      "Yifei Ge"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2312.14394",
    "title": "AdapTraj: A Multi-Source Domain Generalization Framework for Multi-Agent  Trajectory Prediction",
    "abstract": "Multi-agent trajectory prediction, as a critical task in modeling complex interactions of objects in dynamic systems, has attracted significant research attention in recent years. Despite the promising advances, existing studies all follow the assumption that data distribution observed during model learning matches that encountered in real-world deployments. However, this assumption often does not hold in practice, as inherent distribution shifts might exist in the mobility patterns for deployment environments, thus leading to poor domain generalization and performance degradation. Consequently, it is appealing to leverage trajectories from multiple source domains to mitigate such discrepancies for multi-agent trajectory prediction task. However, the development of multi-source domain generalization in this task presents two notable issues: (1) negative transfer; (2) inadequate modeling for external factors. To address these issues, we propose a new causal formulation to explicitly model four types of features: domain-invariant and domain-specific features for both the focal agent and neighboring agents. Building upon the new formulation, we propose AdapTraj, a multi-source domain generalization framework specifically tailored for multi-agent trajectory prediction. AdapTraj serves as a plug-and-play module that is adaptable to a variety of models. Extensive experiments on four datasets with different domains demonstrate that AdapTraj consistently outperforms other baselines by a substantial margin. ",
    "url": "https://arxiv.org/abs/2312.14394",
    "authors": [
      "Tangwen Qian",
      "Yile Chen",
      "Gao Cong",
      "Yongjun Xu",
      "Fei Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14396",
    "title": "SoCo: Graph Storage and Software Prefetch Co-Design for Dynamic Graph  Processing",
    "abstract": "There has been growing demands in the dynamic graph, in which a continuous stream of graph updates is mixed with graph computation. For the above scenarios, the compact physically continuous structures and the dispersed but logically continuous structures become the two ends of the scale. In principle, the Pointers become the weights. The number of them determines which side of the scale the data structure leans towards. The Pointers make it easier to update the graph but they will result in poor cache locality. This paper presents SoCo, a graph storage and software prefetch co-design for dynamic graph processing that significantly improves on both graph updating and graph computation. We utilize C++20 coroutines and software prefetching techniques to optimize cache miss overhead during computation, and design a data structure that not only meets the requirements of dynamic graph processing but is also more suitable for prefetching. We also conduct extensive experiments on different datasets and show that SoCo could outperform state-of-the-arts by 10.48x on average and at the same time guarantee a pioneer insertion performance (1st place in 5 cases and 2nd place in 2 cases). ",
    "url": "https://arxiv.org/abs/2312.14396",
    "authors": [
      "Hongfu Li"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2312.14398",
    "title": "ZMM-TTS: Zero-shot Multilingual and Multispeaker Speech Synthesis  Conditioned on Self-supervised Discrete Speech Representations",
    "abstract": "Neural text-to-speech (TTS) has achieved human-like synthetic speech for single-speaker, single-language synthesis. Multilingual TTS systems are limited to resource-rich languages due to the lack of large paired text and studio-quality audio data. In most cases, TTS systems are built using a single speaker's voice. However, there is growing interest in developing systems that can synthesize voices for new speakers using only a few seconds of their speech. This paper presents ZMM-TTS, a multilingual and multispeaker framework utilizing quantized latent speech representations from a large-scale, pre-trained, self-supervised model. Our paper is the first to incorporate the representations from text-based and speech-based self-supervised learning models into multilingual speech synthesis tasks. We conducted comprehensive subjective and objective evaluations through a series of experiments. Our model has been proven effective in terms of speech naturalness and similarity for both seen and unseen speakers in six high-resource languages. We also tested the efficiency of our method on two hypothetical low-resource languages. The results are promising, indicating that our proposed approach can synthesize audio that is intelligible and has a high degree of similarity to the target speaker's voice, even without any training data for the new, unseen language. ",
    "url": "https://arxiv.org/abs/2312.14398",
    "authors": [
      "Cheng Gong",
      "Xin Wang",
      "Erica Cooper",
      "Dan Wells",
      "Longbiao Wang",
      "Jianwu Dang",
      "Korin Richmond",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.14405",
    "title": "Graph Attention-Based Symmetry Constraint Extraction for Analog Circuits",
    "abstract": "In recent years, analog circuits have received extensive attention and are widely used in many emerging applications. The high demand for analog circuits necessitates shorter circuit design cycles. To achieve the desired performance and specifications, various geometrical symmetry constraints must be carefully considered during the analog layout process. However, the manual labeling of these constraints by experienced analog engineers is a laborious and time-consuming process. To handle the costly runtime issue, we propose a graph-based learning framework to automatically extract symmetric constraints in analog circuit layout. The proposed framework leverages the connection characteristics of circuits and the devices'information to learn the general rules of symmetric constraints, which effectively facilitates the extraction of device-level constraints on circuit netlists. The experimental results demonstrate that compared to state-of-the-art symmetric constraint detection approaches, our framework achieves higher accuracy and lower false positive rate. ",
    "url": "https://arxiv.org/abs/2312.14405",
    "authors": [
      "Qi Xu",
      "Lijie Wang",
      "Jing Wang",
      "Song Chen",
      "Lin Cheng",
      "Yi Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14406",
    "title": "Generative Pretraining at Scale: Transformer-Based Encoding of  Transactional Behavior for Fraud Detection",
    "abstract": "In this work, we introduce an innovative autoregressive model leveraging Generative Pretrained Transformer (GPT) architectures, tailored for fraud detection in payment systems. Our approach innovatively confronts token explosion and reconstructs behavioral sequences, providing a nuanced understanding of transactional behavior through temporal and contextual analysis. Utilizing unsupervised pretraining, our model excels in feature representation without the need for labeled data. Additionally, we integrate a differential convolutional approach to enhance anomaly detection, bolstering the security and efficacy of one of the largest online payment merchants in China. The scalability and adaptability of our model promise broad applicability in various transactional contexts. ",
    "url": "https://arxiv.org/abs/2312.14406",
    "authors": [
      "Ze Yu Zhao",
      "Zheng Zhu",
      "Guilin Li",
      "Wenhan Wang",
      "Bo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14407",
    "title": "AdvCloak: Customized Adversarial Cloak for Privacy Protection",
    "abstract": "With extensive face images being shared on social media, there has been a notable escalation in privacy concerns. In this paper, we propose AdvCloak, an innovative framework for privacy protection using generative models. AdvCloak is designed to automatically customize class-wise adversarial masks that can maintain superior image-level naturalness while providing enhanced feature-level generalization ability. Specifically, AdvCloak sequentially optimizes the generative adversarial networks by employing a two-stage training strategy. This strategy initially focuses on adapting the masks to the unique individual faces via image-specific training and then enhances their feature-level generalization ability to diverse facial variations of individuals via person-specific training. To fully utilize the limited training data, we combine AdvCloak with several general geometric modeling methods, to better describe the feature subspace of source identities. Extensive quantitative and qualitative evaluations on both common and celebrity datasets demonstrate that AdvCloak outperforms existing state-of-the-art methods in terms of efficiency and effectiveness. ",
    "url": "https://arxiv.org/abs/2312.14407",
    "authors": [
      "Xuannan Liu",
      "Yaoyao Zhong",
      "Xing Cui",
      "Yuhang Zhang",
      "Peipei Li",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14410",
    "title": "A Multi-Stage Adaptive Feature Fusion Neural Network for Multimodal Gait  Recognition",
    "abstract": "Gait recognition is a biometric technology that has received extensive attention. Most existing gait recognition algorithms are unimodal, and a few multimodal gait recognition algorithms perform multimodal fusion only once. None of these algorithms may fully exploit the complementary advantages of the multiple modalities. In this paper, by considering the temporal and spatial characteristics of gait data, we propose a multi-stage feature fusion strategy (MSFFS), which performs multimodal fusions at different stages in the feature extraction process. Also, we propose an adaptive feature fusion module (AFFM) that considers the semantic association between silhouettes and skeletons. The fusion process fuses different silhouette areas with their more related skeleton joints. Since visual appearance changes and time passage co-occur in a gait period, we propose a multiscale spatial-temporal feature extractor (MSSTFE) to learn the spatial-temporal linkage features thoroughly. Specifically, MSSTFE extracts and aggregates spatial-temporal linkages information at different spatial scales. Combining the strategy and modules mentioned above, we propose a multi-stage adaptive feature fusion (MSAFF) neural network, which shows state-of-the-art performance in many experiments on three datasets. Besides, MSAFF is equipped with feature dimensional pooling (FD Pooling), which can significantly reduce the dimension of the gait representations without hindering the accuracy. https://github.com/ShinanZou/MSAFF ",
    "url": "https://arxiv.org/abs/2312.14410",
    "authors": [
      "Shinan Zou",
      "Jianbo Xiong",
      "Chao Fan",
      "Shiqi Yu",
      "Jin Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14427",
    "title": "GROOD: GRadient-aware Out-Of-Distribution detection in interpolated  manifolds",
    "abstract": "Deep neural networks (DNNs) often fail silently with over-confident predictions on out-of-distribution (OOD) samples, posing risks in real-world deployments. Existing techniques predominantly emphasize either the feature representation space or the gradient norms computed with respect to DNN parameters, yet they overlook the intricate gradient distribution and the topology of classification regions. To address this gap, we introduce GRadient-aware Out-Of-Distribution detection in interpolated manifolds (GROOD), a novel framework that relies on the discriminative power of gradient space to distinguish between in-distribution (ID) and OOD samples. To build this space, GROOD relies on class prototypes together with a prototype that specifically captures OOD characteristics. Uniquely, our approach incorporates a targeted mix-up operation at an early intermediate layer of the DNN to refine the separation of gradient spaces between ID and OOD samples. We quantify OOD detection efficacy using the distance to the nearest neighbor gradients derived from the training set, yielding a robust OOD score. Experimental evaluations substantiate that the introduction of targeted input mix-upamplifies the separation between ID and OOD in the gradient space, yielding impressive results across diverse datasets. Notably, when benchmarked against ImageNet-1k, GROOD surpasses the established robustness of state-of-the-art baselines. Through this work, we establish the utility of leveraging gradient spaces and class prototypes for enhanced OOD detection for DNN in image classification. ",
    "url": "https://arxiv.org/abs/2312.14427",
    "authors": [
      "Mostafa ElAraby",
      "Sabyasachi Sahoo",
      "Yann Pequignot",
      "Paul Novello",
      "Liam Paull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14433",
    "title": "Attribute-driven Disentangled Representation Learning for Multimodal  Recommendation",
    "abstract": "Recommendation algorithms forecast user preferences by correlating user and item representations derived from historical interaction patterns. In pursuit of enhanced performance, many methods focus on learning robust and independent representations by disentangling the intricate factors within interaction data across various modalities in an unsupervised manner. However, such an approach obfuscates the discernment of how specific factors (e.g., category or brand) influence the outcomes, making it challenging to regulate their effects. In response to this challenge, we introduce a novel method called Attribute-Driven Disentangled Representation Learning (short for AD-DRL), which explicitly incorporates attributes from different modalities into the disentangled representation learning process. By assigning a specific attribute to each factor in multimodal features, AD-DRL can disentangle the factors at both attribute and attribute-value levels. To obtain robust and independent representations for each factor associated with a specific attribute, we first disentangle the representations of features both within and across different modalities. Moreover, we further enhance the robustness of the representations by fusing the multimodal features of the same factor. Empirical evaluations conducted on three public real-world datasets substantiate the effectiveness of AD-DRL, as well as its interpretability and controllability. ",
    "url": "https://arxiv.org/abs/2312.14433",
    "authors": [
      "Zhenyang Li",
      "Fan Liu",
      "Yinwei Wei",
      "Zhiyong Cheng",
      "Liqiang Nie",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2312.14438",
    "title": "PC-Conv: Unifying Homophily and Heterophily with Two-fold Filtering",
    "abstract": "Recently, many carefully crafted graph representation learning methods have achieved impressive performance on either strong heterophilic or homophilic graphs, but not both. Therefore, they are incapable of generalizing well across real-world graphs with different levels of homophily. This is attributed to their neglect of homophily in heterophilic graphs, and vice versa. In this paper, we propose a two-fold filtering mechanism to extract homophily in heterophilic graphs and vice versa. In particular, we extend the graph heat equation to perform heterophilic aggregation of global information from a long distance. The resultant filter can be exactly approximated by the Possion-Charlier (PC) polynomials. To further exploit information at multiple orders, we introduce a powerful graph convolution PC-Conv and its instantiation PCNet for the node classification task. Compared with state-of-the-art GNNs, PCNet shows competitive performance on well-known homophilic and heterophilic graphs. Our implementation is available at https://github.com/uestclbh/PC-Conv. ",
    "url": "https://arxiv.org/abs/2312.14438",
    "authors": [
      "Bingheng Li",
      "Erlin Pan",
      "Zhao Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.14439",
    "title": "PUMA: Efficient Continual Graph Learning with Graph Condensation",
    "abstract": "When handling streaming graphs, existing graph representation learning models encounter a catastrophic forgetting problem, where previously learned knowledge of these models is easily overwritten when learning with newly incoming graphs. In response, Continual Graph Learning emerges as a novel paradigm enabling graph representation learning from static to streaming graphs. Our prior work, CaT is a replay-based framework with a balanced continual learning procedure, which designs a small yet effective memory bank for replaying data by condensing incoming graphs. Although the CaT alleviates the catastrophic forgetting problem, there exist three issues: (1) The graph condensation algorithm derived in CaT only focuses on labelled nodes while neglecting abundant information carried by unlabelled nodes; (2) The continual training scheme of the CaT overemphasises on the previously learned knowledge, limiting the model capacity to learn from newly added memories; (3) Both the condensation process and replaying process of the CaT are time-consuming. In this paper, we propose a psudo-label guided memory bank (PUMA) CGL framework, extending from the CaT to enhance its efficiency and effectiveness by overcoming the above-mentioned weaknesses and limits. To fully exploit the information in a graph, PUMA expands the coverage of nodes during graph condensation with both labelled and unlabelled nodes. Furthermore, a training-from-scratch strategy is proposed to upgrade the previous continual learning scheme for a balanced training between the historical and the new graphs. Besides, PUMA uses a one-time prorogation and wide graph encoders to accelerate the graph condensation and the graph encoding process in the training stage to improve the efficiency of the whole framework. Extensive experiments on four datasets demonstrate the state-of-the-art performance and efficiency over existing methods. ",
    "url": "https://arxiv.org/abs/2312.14439",
    "authors": [
      "Yilun Liu",
      "Ruihong Qiu",
      "Yanran Tang",
      "Hongzhi Yin",
      "Zi Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14440",
    "title": "Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks",
    "abstract": "The widespread use of Text-to-Image (T2I) models in content generation requires careful examination of their safety, including their robustness to adversarial attacks. Despite extensive research into this, the reasons for their effectiveness are underexplored. This paper presents an empirical study on adversarial attacks against T2I models, focusing on analyzing factors associated with attack success rates (ASRs). We introduce a new attack objective - entity swapping using adversarial suffixes and two gradient-based attack algorithms. Human and automatic evaluations reveal the asymmetric nature of ASRs on entity swap: for example, it is easier to replace \"human\" with \"robot\" in the prompt \"a human dancing in the rain.\" with an adversarial suffix but is significantly harder in reverse. We further propose probing metrics to establish indicative signals from the model's beliefs to the adversarial ASR. We identify conditions resulting in a 60% success probability for adversarial attacks and others where this likelihood drops below 5%. ",
    "url": "https://arxiv.org/abs/2312.14440",
    "authors": [
      "Haz Sameen Shahgir",
      "Xianghao Kong",
      "Greg Ver Steeg",
      "Yue Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.14446",
    "title": "Cross-Modal Object Tracking via Modality-Aware Fusion Network and A  Large-Scale Dataset",
    "abstract": "Visual tracking often faces challenges such as invalid targets and decreased performance in low-light conditions when relying solely on RGB image sequences. While incorporating additional modalities like depth and infrared data has proven effective, existing multi-modal imaging platforms are complex and lack real-world applicability. In contrast, near-infrared (NIR) imaging, commonly used in surveillance cameras, can switch between RGB and NIR based on light intensity. However, tracking objects across these heterogeneous modalities poses significant challenges, particularly due to the absence of modality switch signals during tracking. To address these challenges, we propose an adaptive cross-modal object tracking algorithm called Modality-Aware Fusion Network (MAFNet). MAFNet efficiently integrates information from both RGB and NIR modalities using an adaptive weighting mechanism, effectively bridging the appearance gap and enabling a modality-aware target representation. It consists of two key components: an adaptive weighting module and a modality-specific representation module...... ",
    "url": "https://arxiv.org/abs/2312.14446",
    "authors": [
      "Lei Liu",
      "Mengya Zhang",
      "Cheng Li",
      "Chenglong Li",
      "Jin Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14448",
    "title": "Quantum-Assisted Joint Caching and Power Allocation for Integrated  Satellite-Terrestrial Networks",
    "abstract": "Low earth orbit (LEO) satellite network can complement terrestrial networks for achieving global wireless coverage and improving delay-sensitive Internet services. This paper proposes an integrated satellite-terrestrial network (ISTN) architecture to provide ground users with seamless and reliable content delivery services. For optimal service provisioning in this architecture, we formulate an optimization model to maximize the network throughput by jointly optimizing content delivery policy, cache placement, and transmission power allocation. The resulting optimization model is a large-scale mixed-integer nonlinear program (MINLP) that is intractable for classical computer solvers. Inspired by quantum computing techniques, we propose a hybrid quantum-classical generalized Benders' decomposition (HQCGBD) algorithm to address this challenge. Specifically, we first exploit the generalized Benders' decomposition (GBD) to decompose the problem into a master problem and a subproblem and then leverage the state-of-art quantum annealer to solve the challenging master problem. ",
    "url": "https://arxiv.org/abs/2312.14448",
    "authors": [
      "Yu Zhang",
      "Yanmin Gong",
      "Lei Fan",
      "Yu Wang",
      "Zhu Han",
      "Yuanxiong Guo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.14461",
    "title": "Attacking Byzantine Robust Aggregation in High Dimensions",
    "abstract": "Training modern neural networks or models typically requires averaging over a sample of high-dimensional vectors. Poisoning attacks can skew or bias the average vectors used to train the model, forcing the model to learn specific patterns or avoid learning anything useful. Byzantine robust aggregation is a principled algorithmic defense against such biasing. Robust aggregators can bound the maximum bias in computing centrality statistics, such as mean, even when some fraction of inputs are arbitrarily corrupted. Designing such aggregators is challenging when dealing with high dimensions. However, the first polynomial-time algorithms with strong theoretical bounds on the bias have recently been proposed. Their bounds are independent of the number of dimensions, promising a conceptual limit on the power of poisoning attacks in their ongoing arms race against defenses. In this paper, we show a new attack called HIDRA on practical realization of strong defenses which subverts their claim of dimension-independent bias. HIDRA highlights a novel computational bottleneck that has not been a concern of prior information-theoretic analysis. Our experimental evaluation shows that our attacks almost completely destroy the model performance, whereas existing attacks with the same goal fail to have much effect. Our findings leave the arms race between poisoning attacks and provable defenses wide open. ",
    "url": "https://arxiv.org/abs/2312.14461",
    "authors": [
      "Sarthak Choudhary",
      "Aashish Kolluri",
      "Prateek Saxena"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14465",
    "title": "FM-OV3D: Foundation Model-based Cross-modal Knowledge Blending for  Open-Vocabulary 3D Detection",
    "abstract": "The superior performances of pre-trained foundation models in various visual tasks underscore their potential to enhance the 2D models' open-vocabulary ability. Existing methods explore analogous applications in the 3D space. However, most of them only center around knowledge extraction from singular foundation models, which limits the open-vocabulary ability of 3D models. We hypothesize that leveraging complementary pre-trained knowledge from various foundation models can improve knowledge transfer from 2D pre-trained visual language models to the 3D space. In this work, we propose FM-OV3D, a method of Foundation Model-based Cross-modal Knowledge Blending for Open-Vocabulary 3D Detection, which improves the open-vocabulary localization and recognition abilities of 3D model by blending knowledge from multiple pre-trained foundation models, achieving true open-vocabulary without facing constraints from original 3D datasets. Specifically, to learn the open-vocabulary 3D localization ability, we adopt the open-vocabulary localization knowledge of the Grounded-Segment-Anything model. For open-vocabulary 3D recognition ability, We leverage the knowledge of generative foundation models, including GPT-3 and Stable Diffusion models, and cross-modal discriminative models like CLIP. The experimental results on two popular benchmarks for open-vocabulary 3D object detection show that our model efficiently learns knowledge from multiple foundation models to enhance the open-vocabulary ability of the 3D model and successfully achieves state-of-the-art performance in open-vocabulary 3D object detection tasks. Code is released at https://github.com/dmzhang0425/FM-OV3D.git. ",
    "url": "https://arxiv.org/abs/2312.14465",
    "authors": [
      "Dongmei Zhang",
      "Chang Li",
      "Ray Zhang",
      "Shenghao Xie",
      "Wei Xue",
      "Xiaodong Xie",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14474",
    "title": "MonoLSS: Learnable Sample Selection For Monocular 3D Detection",
    "abstract": "In the field of autonomous driving, monocular 3D detection is a critical task which estimates 3D properties (depth, dimension, and orientation) of objects in a single RGB image. Previous works have used features in a heuristic way to learn 3D properties, without considering that inappropriate features could have adverse effects. In this paper, sample selection is introduced that only suitable samples should be trained to regress the 3D properties. To select samples adaptively, we propose a Learnable Sample Selection (LSS) module, which is based on Gumbel-Softmax and a relative-distance sample divider. The LSS module works under a warm-up strategy leading to an improvement in training stability. Additionally, since the LSS module dedicated to 3D property sample selection relies on object-level features, we further develop a data augmentation method named MixUp3D to enrich 3D property samples which conforms to imaging principles without introducing ambiguity. As two orthogonal methods, the LSS module and MixUp3D can be utilized independently or in conjunction. Sufficient experiments have shown that their combined use can lead to synergistic effects, yielding improvements that transcend the mere sum of their individual applications. Leveraging the LSS module and the MixUp3D, without any extra data, our method named MonoLSS ranks 1st in all three categories (Car, Cyclist, and Pedestrian) on KITTI 3D object detection benchmark, and achieves competitive results on both the Waymo dataset and KITTI-nuScenes cross-dataset evaluation. The code is included in the supplementary material and will be released to facilitate related academic and industrial studies. ",
    "url": "https://arxiv.org/abs/2312.14474",
    "authors": [
      "Zhenjia Li",
      "Jinrang Jia",
      "Yifeng Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.14479",
    "title": "Navigating the Concurrency Landscape: A Survey of Race Condition  Vulnerability Detectors",
    "abstract": "As technology continues to advance and we usher in the era of Industry 5.0, there has been a profound paradigm shift in operating systems, file systems, web, and network applications. The conventional utilization of multiprocessing and multicore systems has made concurrent programming increasingly pervasive. However, this transformation has brought about a new set of issues known as concurrency bugs, which, due to their wide prevalence in concurrent programs, have led to severe failures and potential security exploits. Over the past two decades, numerous researchers have dedicated their efforts to unveiling, detecting, mitigating, and preventing these bugs, with the last decade witnessing a surge in research within this domain. Among the spectrum of concurrency bugs, data races or race condition vulnerabilities stand out as the most prevalent, accounting for a staggering 80\\% of all concurrency bugs. This survey paper is focused on the realm of race condition bug detectors. We systematically categorize these detectors based on the diverse methodologies they employ. Additionally, we delve into the techniques and algorithms associated with race detection, tracing the evolution of this field over time. Furthermore, we shed light on the application of fuzzing techniques in the detection of race condition vulnerabilities. By reviewing these detectors and their static analyses, we draw conclusions and outline potential future research directions, including enhancing accuracy, performance, applicability, and comprehensiveness in race condition vulnerability detection. ",
    "url": "https://arxiv.org/abs/2312.14479",
    "authors": [
      "Aishwarya Upadhyay",
      "Vijay Laxmi",
      "Smita Naval"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.14492",
    "title": "Context Enhanced Transformer for Single Image Object Detection",
    "abstract": "With the increasing importance of video data in real-world applications, there is a rising need for efficient object detection methods that utilize temporal information. While existing video object detection (VOD) techniques employ various strategies to address this challenge, they typically depend on locally adjacent frames or randomly sampled images within a clip. Although recent Transformer-based VOD methods have shown promising results, their reliance on multiple inputs and additional network complexity to incorporate temporal information limits their practical applicability. In this paper, we propose a novel approach to single image object detection, called Context Enhanced TRansformer (CETR), by incorporating temporal context into DETR using a newly designed memory module. To efficiently store temporal information, we construct a class-wise memory that collects contextual information across data. Additionally, we present a classification-based sampling technique to selectively utilize the relevant memory for the current image. In the testing, We introduce a test-time memory adaptation method that updates individual memory functions by considering the test distribution. Experiments with CityCam and ImageNet VID datasets exhibit the efficiency of the framework on various video systems. The project page and code will be made available at: https://ku-cvlab.github.io/CETR. ",
    "url": "https://arxiv.org/abs/2312.14492",
    "authors": [
      "Seungjun An",
      "Seonghoon Park",
      "Gyeongnyeon Kim",
      "Jeongyeol Baek",
      "Byeongwon Lee",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14494",
    "title": "Revisiting Few-Shot Object Detection with Vision-Language Models",
    "abstract": "Few-shot object detection (FSOD) benchmarks have advanced techniques for detecting new categories with limited annotations. Existing benchmarks repurpose well-established datasets like COCO by partitioning categories into base and novel classes for pre-training and fine-tuning respectively. However, these benchmarks do not reflect how FSOD is deployed in practice. Rather than only pre-training on a small number of base categories, we argue that it is more practical to fine-tune a foundation model (e.g., a vision-language model (VLM) pre-trained on web-scale data) for a target domain. Surprisingly, we find that zero-shot inference from VLMs like GroundingDINO significantly outperforms the state-of-the-art (48.3 vs. 33.1 AP) on COCO. However, such zero-shot models can still be misaligned to target concepts of interest. For example, trailers on the web may be different from trailers in the context of autonomous vehicles. In this work, we propose Foundational FSOD, a new benchmark protocol that evaluates detectors pre-trained on any external datasets and fine-tuned on K-shots per target class. Further, we note that current FSOD benchmarks are actually federated datasets containing exhaustive annotations for each category on a subset of the data. We leverage this insight to propose simple strategies for fine-tuning VLMs with federated losses. We demonstrate the effectiveness of our approach on LVIS and nuImages, improving over prior work by 5.9 AP. ",
    "url": "https://arxiv.org/abs/2312.14494",
    "authors": [
      "Anish Madan",
      "Neehar Peri",
      "Shu Kong",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14499",
    "title": "Hutchinson Trace Estimation for High-Dimensional and High-Order  Physics-Informed Neural Networks",
    "abstract": "Physics-Informed Neural Networks (PINNs) have proven effective in solving partial differential equations (PDEs), especially when some data are available by blending seamlessly data and physics. However, extending PINNs to high-dimensional and even high-order PDEs encounters significant challenges due to the computational cost associated with automatic differentiation in the residual loss. Herein, we address the limitations of PINNs in handling high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation (HTE). Starting with the second-order high-dimensional PDEs ubiquitous in scientific computing, HTE transforms the calculation of the entire Hessian matrix into a Hessian vector product (HVP). This approach alleviates the computational bottleneck via Taylor-mode automatic differentiation and significantly reduces memory consumption from the Hessian matrix to HVP. We further showcase HTE's convergence to the original PINN loss and its unbiased behavior under specific conditions. Comparisons with Stochastic Dimension Gradient Descent (SDGD) highlight the distinct advantages of HTE, particularly in scenarios with significant variance among dimensions. We further extend HTE to higher-order and higher-dimensional PDEs, specifically addressing the biharmonic equation. By employing tensor-vector products (TVP), HTE efficiently computes the colossal tensor associated with the fourth-order high-dimensional biharmonic equation, saving memory and enabling rapid computation. The effectiveness of HTE is illustrated through experimental setups, demonstrating comparable convergence rates with SDGD under memory and speed constraints. Additionally, HTE proves valuable in accelerating the Gradient-Enhanced PINN (gPINN) version as well as the Biharmonic equation. Overall, HTE opens up a new capability in scientific machine learning for tackling high-order and high-dimensional PDEs. ",
    "url": "https://arxiv.org/abs/2312.14499",
    "authors": [
      "Zheyuan Hu",
      "Zekun Shi",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.14511",
    "title": "3D Programming of Patterned Heterogeneous Interface for 4D Smart  Robotics",
    "abstract": "Shape memory structures are playing an important role in many cutting-edge intelligent fields. However, the existing technologies can only realize 4D printing of a single polymer or metal, which limits practical applications. Here, we report a construction strategy for TSMP/M heterointerface, which uses Pd2+-containing shape memory polymer (AP-SMR) to induce electroless plating reaction and relies on molecular dynamics, which has both shape memory properties and metal activity and information processing power. Through multi-material DLP 3D printing technology, the interface can be 3D selectively programmed on functional substrate parts of arbitrary shapes to become 4D electronic smart devices (Robotics). Microscopically, this type of interface appears as a composite structure with a nanometer-micrometer interface height, which is composed of a pure substrate layer (smart materials), an intermediate layer (a composite structure in which metal particles are embedded in a polymer cross-linked network) and a pure metal layer. The structure programmed by TSMP/M heterointerface exhibits both SMA characteristics and metal properties, thus having more intelligent functions (electroactive, electrothermal deformation, electronically controlled denaturation) and higher performance (selectivity of shape memory structures can be realized control, remote control, inline control and low voltage control). This is expected to provide a more flexible manufacturing process as platform technology for designing, manufacturing and applying smart devices with new concepts, and promote the development of cutting-edge industries such as smart robots and smart electronics. ",
    "url": "https://arxiv.org/abs/2312.14511",
    "authors": [
      "Kewei Song",
      "Chunfeng Xiong",
      "Ze Zhang",
      "Kunlin Wu",
      "Weiyang Wan",
      "Yifan Wang",
      "Shinjiro Umezu",
      "Hirotaka Sato"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.14528",
    "title": "An effective and efficient green federated learning method for one-layer  neural networks",
    "abstract": "Nowadays, machine learning algorithms continue to grow in complexity and require a substantial amount of computational resources and energy. For these reasons, there is a growing awareness of the development of new green algorithms and distributed AI can contribute to this. Federated learning (FL) is one of the most active research lines in machine learning, as it allows the training of collaborative models in a distributed way, an interesting option in many real-world environments, such as the Internet of Things, allowing the use of these models in edge computing devices. In this work, we present a FL method, based on a neural network without hidden layers, capable of generating a global collaborative model in a single training round, unlike traditional FL methods that require multiple rounds for convergence. This allows obtaining an effective and efficient model that simplifies the management of the training process. Moreover, this method preserve data privacy by design, a crucial aspect in current data protection regulations. We conducted experiments with large datasets and a large number of federated clients. Despite being based on a network model without hidden layers, it maintains in all cases competitive accuracy results compared to more complex state-of-the-art machine learning models. Furthermore, we show that the method performs equally well in both identically and non-identically distributed scenarios. Finally, it is an environmentally friendly algorithm as it allows significant energy savings during the training process compared to its centralized counterpart. ",
    "url": "https://arxiv.org/abs/2312.14528",
    "authors": [
      "Oscar Fontenla-Romero",
      "Bertha Guijarro-Berdi\u00f1as",
      "Elena Hern\u00e1ndez-Pereira",
      "Beatriz P\u00e9rez-S\u00e1nchez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14533",
    "title": "Multi-view user representation learning for user matching without  personal information",
    "abstract": "As the digitization of travel industry accelerates, analyzing and understanding travelers' behaviors becomes increasingly important. However, traveler data frequently exhibit high data sparsity due to the relatively low frequency of user interactions with travel providers. Compounding this effect the multiplication of devices, accounts and platforms while browsing travel products online also leads to data dispersion. To deal with these challenges, probabilistic traveler matching can be used. Most existing solutions for user matching are not suitable for traveler matching as a traveler's browsing history is typically short and URLs in the travel industry are very heterogeneous with many tokens. To deal with these challenges, we propose the similarity based multi-view information fusion to learn a better user representation from URLs by treating the URLs as multi-view data. The experimental results show that the proposed multi-view user representation learning can take advantage of the complementary information from different views, highlight the key information in URLs and perform significantly better than other representation learning solutions for the user matching task. ",
    "url": "https://arxiv.org/abs/2312.14533",
    "authors": [
      "Hongliu Cao",
      "Ilias El Baamrani",
      "Eoin Thomas"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14535",
    "title": "ADA-GAD: Anomaly-Denoised Autoencoders for Graph Anomaly Detection",
    "abstract": "Graph anomaly detection is crucial for identifying nodes that deviate from regular behavior within graphs, benefiting various domains such as fraud detection and social network. Although existing reconstruction-based methods have achieved considerable success, they may face the \\textit{Anomaly Overfitting} and \\textit{Homophily Trap} problems caused by the abnormal patterns in the graph, breaking the assumption that normal nodes are often better reconstructed than abnormal ones. Our observations indicate that models trained on graphs with fewer anomalies exhibit higher detection performance. Based on this insight, we introduce a novel two-stage framework called Anomaly-Denoised Autoencoders for Graph Anomaly Detection (ADA-GAD). In the first stage, we design a learning-free anomaly-denoised augmentation method to generate graphs with reduced anomaly levels. We pretrain graph autoencoders on these augmented graphs at multiple levels, which enables the graph autoencoders to capture normal patterns. In the next stage, the decoders are retrained for detection on the original graph, benefiting from the multi-level representations learned in the previous stage. Meanwhile, we propose the node anomaly distribution regularization to further alleviate \\textit{Anomaly Overfitting}. We validate the effectiveness of our approach through extensive experiments on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2312.14535",
    "authors": [
      "Junwei He",
      "Qianqian Xu",
      "Yangbangyan Jiang",
      "Zitai Wang",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.14568",
    "title": "The Projection Method: a Unified Formalism for Community Detection",
    "abstract": "We present the class of projection methods for community detection that generalizes many popular community detection methods. In this framework, we represent each clustering (partition) by a vector on a high-dimensional hypersphere. A community detection method is a projection method if it can be described by the following two-step approach: 1) the graph is mapped to a query vector on the hypersphere; and 2) the query vector is projected on the set of clustering vectors. This last projection step is performed by minimizing the distance between the query vector and the clustering vector, over the set of clusterings. We prove that optimizing Markov stability, modularity, the likelihood of planted partition models and correlation clustering fit this framework. A consequence of this equivalence is that algorithms for each of these methods can be modified to perform the projection step in our framework. In addition, we show that these different methods suffer from the same granularity problem: they have parameters that control the granularity of the resulting clustering, but choosing these to obtain clusterings of the desired granularity is nontrivial. We provide a general heuristic to address this granularity problem, which can be applied to any projection method. Finally, we show how, given a generator of graphs with community structure, we can optimize a projection method for this generator in order to obtain a community detection method that performs well on this generator. ",
    "url": "https://arxiv.org/abs/2312.14568",
    "authors": [
      "Martijn G\u00f6sgens",
      "Remco van der Hofstad",
      "Nelly Litvak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.14574",
    "title": "MMGPL: Multimodal Medical Data Analysis with Graph Prompt Learning",
    "abstract": "Prompt learning has demonstrated impressive efficacy in the fine-tuning of multimodal large models to a wide range of downstream tasks. Nonetheless, applying existing prompt learning methods for the diagnosis of neurological disorder still suffers from two issues: (i) existing methods typically treat all patches equally, despite the fact that only a small number of patches in neuroimaging are relevant to the disease, and (ii) they ignore the structural information inherent in the brain connection network which is crucial for understanding and diagnosing neurological disorders. To tackle these issues, we introduce a novel prompt learning model by learning graph prompts during the fine-tuning process of multimodal large models for diagnosing neurological disorders. Specifically, we first leverage GPT-4 to obtain relevant disease concepts and compute semantic similarity between these concepts and all patches. Secondly, we reduce the weight of irrelevant patches according to the semantic similarity between each patch and disease-related concepts. Moreover, we construct a graph among tokens based on these concepts and employ a graph convolutional network layer to extract the structural information of the graph, which is used to prompt the pre-trained multimodal large models for diagnosing neurological disorders. Extensive experiments demonstrate that our method achieves superior performance for neurological disorder diagnosis compared with state-of-the-art methods and validated by clinicians. ",
    "url": "https://arxiv.org/abs/2312.14574",
    "authors": [
      "Liang Peng",
      "Songyue Cai",
      "Zongqian Wu",
      "Huifang Shang",
      "Xiaofeng Zhu",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14593",
    "title": "The Effect of Sparsity on $k$-Dominating Set and Related First-Order  Graph Properties",
    "abstract": "We revisit $k$-Dominating Set, one of the first problems for which a tight $n^k-o(1)$ conditional lower bound (for $k\\ge 3$), based on SETH, was shown (P\\u{a}tra\\c{s}cu and Williams, SODA 2007). However, the underlying reduction creates dense graphs, raising the question: how much does the sparsity of the graph affect its fine-grained complexity? We first settle the fine-grained complexity of $k$-Dominating Set in terms of both the number of nodes $n$ and number of edges $m$. Specifically, we show an $mn^{k-2-o(1)}$ lower bound based on SETH, for any dependence of $m$ on $n$. This is complemented by an $mn^{k-2+o(1)}$-time algorithm for all $k\\ge 3$. For the $k=2$ case, we give a randomized algorithm that employs a Bloom-filter inspired hashing to improve the state of the art of $n^{\\omega+o(1)}$ to $m^{\\omega/2+o(1)}$. If $\\omega=2$, this yields a conditionally tight bound for all $k\\ge 2$. To study if $k$-Dominating Set is special in its sensitivity to sparsity, we consider a class of very related problems. The $k$-Dominating Set problem belongs to a type of first-order definable graph properties that we call monochromatic basic problems. These problems are the natural monochromatic variants of the basic problems that were proven complete for the class FOP of first-order definable properties (Gao, Impagliazzo, Kolokolova, and Williams, TALG 2019). We show that among these problems, $k$-Dominating Set is the only one whose fine-grained complexity decreases in sparse graphs. Only for the special case of reflexive properties, is there an additional basic problem that can be solved faster than $n^{k\\pm o(1)}$ on sparse graphs. For the natural variant of distance-$r$ $k$-dominating set, we obtain a hardness of $n^{k-o(1)}$ under SETH for every $r\\ge 2$ already on sparse graphs, which is tight for sufficiently large $k$. ",
    "url": "https://arxiv.org/abs/2312.14593",
    "authors": [
      "Nick Fischer",
      "Marvin K\u00fcnnemann",
      "Mirza Redzic"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2312.14606",
    "title": "Explainable Multi-Camera 3D Object Detection with Transformer-Based  Saliency Maps",
    "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art results on various computer vision tasks, including 3D object detection. However, their end-to-end implementation also makes ViTs less explainable, which can be a challenge for deploying them in safety-critical applications, such as autonomous driving, where it is important for authorities, developers, and users to understand the model's reasoning behind its predictions. In this paper, we propose a novel method for generating saliency maps for a DetR-like ViT with multiple camera inputs used for 3D object detection. Our method is based on the raw attention and is more efficient than gradient-based methods. We evaluate the proposed method on the nuScenes dataset using extensive perturbation tests and show that it outperforms other explainability methods in terms of visual quality and quantitative metrics. We also demonstrate the importance of aggregating attention across different layers of the transformer. Our work contributes to the development of explainable AI for ViTs, which can help increase trust in AI applications by establishing more transparency regarding the inner workings of AI models. ",
    "url": "https://arxiv.org/abs/2312.14606",
    "authors": [
      "Till Beemelmanns",
      "Wassim Zahr",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14608",
    "title": "Efficient Discrete Physics-informed Neural Networks for Addressing  Evolutionary Partial Differential Equations",
    "abstract": "Physics-informed neural networks (PINNs) have shown promising potential for solving partial differential equations (PDEs) using deep learning. However, PINNs face training difficulties for evolutionary PDEs, particularly for dynamical systems whose solutions exhibit multi-scale or turbulent behavior over time. The reason is that PINNs may violate the temporal causality property since all the temporal features in the PINNs loss are trained simultaneously. This paper proposes to use implicit time differencing schemes to enforce temporal causality, and use transfer learning to sequentially update the PINNs in space as surrogates for PDE solutions in different time frames. The evolving PINNs are better able to capture the varying complexities of the evolutionary equations, while only requiring minor updates between adjacent time frames. Our method is theoretically proven to be convergent if the time step is small and each PINN in different time frames is well-trained. In addition, we provide state-of-the-art (SOTA) numerical results for a variety of benchmarks for which existing PINNs formulations may fail or be inefficient. We demonstrate that the proposed method improves the accuracy of PINNs approximation for evolutionary PDEs and improves efficiency by a factor of 4-40x. ",
    "url": "https://arxiv.org/abs/2312.14608",
    "authors": [
      "Siqi Chen",
      "Bin Shan",
      "Ye Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.14625",
    "title": "Hierarchical Multi-Agent Reinforcement Learning for Assessing False-Data  Injection Attacks on Transportation Networks",
    "abstract": "The increasing reliance of drivers on navigation applications has made transportation networks more susceptible to data-manipulation attacks by malicious actors. Adversaries may exploit vulnerabilities in the data collection or processing of navigation services to inject false information, and to thus interfere with the drivers' route selection. Such attacks can significantly increase traffic congestions, resulting in substantial waste of time and resources, and may even disrupt essential services that rely on road networks. To assess the threat posed by such attacks, we introduce a computational framework to find worst-case data-injection attacks against transportation networks. First, we devise an adversarial model with a threat actor who can manipulate drivers by increasing the travel times that they perceive on certain roads. Then, we employ hierarchical multi-agent reinforcement learning to find an approximate optimal adversarial strategy for data manipulation. We demonstrate the applicability of our approach through simulating attacks on the Sioux Falls, ND network topology. ",
    "url": "https://arxiv.org/abs/2312.14625",
    "authors": [
      "Taha Eghtesad",
      "Sirui Li",
      "Yevgeniy Vorobeychik",
      "Aron Laszka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.14633",
    "title": "Evaluating the Security and Privacy Risk Postures of Virtual Assistants",
    "abstract": "Virtual assistants (VAs) have seen increased use in recent years due to their ease of use for daily tasks. Despite their growing prevalence, their security and privacy implications are still not well understood. To address this gap, we conducted a study to evaluate the security and privacy postures of eight widely used voice assistants: Alexa, Braina, Cortana, Google Assistant, Kalliope, Mycroft, Hound, and Extreme. We used three vulnerability testing tools, AndroBugs, RiskInDroid, and MobSF, to assess the security and privacy of these VAs. Our analysis focused on five areas: code, access control, tracking, binary analysis, and sensitive data confidentiality. The results revealed that these VAs are vulnerable to a range of security threats, including not validating SSL certificates, executing raw SQL queries, and using a weak mode of the AES algorithm. These vulnerabilities could allow malicious actors to gain unauthorized access to users' personal information. This study is a first step toward understanding the risks associated with these technologies and provides a foundation for future research to develop more secure and privacy-respecting VAs. ",
    "url": "https://arxiv.org/abs/2312.14633",
    "authors": [
      "Borna Kalhor",
      "Sanchari Das"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.14634",
    "title": "Mining multi-modal communication patterns in interaction with  explainable and non-explainable robots",
    "abstract": "We investigate interaction patterns for humans interacting with explainable and non-explainable robots. Non-explainable robots are here robots that do not explain their actions or non-actions, neither do they give any other feedback during interaction, in contrast to explainable robots. We video recorded and analyzed human behavior during a board game, where 20 humans verbally instructed either an explainable or non-explainable Pepper robot to move objects on the board. The transcriptions and annotations of the videos were transformed into transactions for association rule mining. Association rules discovered communication patterns in the interaction between the robots and the humans, and the most interesting rules were also tested with regular chi-square tests. Some statistically significant results are that there is a strong correlation between men and non-explainable robots and women and explainable robots, and that humans mirror some of the robot's modality. Our results also show that it is important to contextualize human interaction patterns, and that this can be easily done using association rules as an investigative tool. The presented results are important when designing robots that should adapt their behavior to become understandable for the interacting humans. ",
    "url": "https://arxiv.org/abs/2312.14634",
    "authors": [
      "Suna Bensch",
      "Amanda Eriksson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14635",
    "title": "Fluid Simulation on Neural Flow Maps",
    "abstract": "We introduce Neural Flow Maps, a novel simulation method bridging the emerging paradigm of implicit neural representations with fluid simulation based on the theory of flow maps, to achieve state-of-the-art simulation of inviscid fluid phenomena. We devise a novel hybrid neural field representation, Spatially Sparse Neural Fields (SSNF), which fuses small neural networks with a pyramid of overlapping, multi-resolution, and spatially sparse grids, to compactly represent long-term spatiotemporal velocity fields at high accuracy. With this neural velocity buffer in hand, we compute long-term, bidirectional flow maps and their Jacobians in a mechanistically symmetric manner, to facilitate drastic accuracy improvement over existing solutions. These long-range, bidirectional flow maps enable high advection accuracy with low dissipation, which in turn facilitates high-fidelity incompressible flow simulations that manifest intricate vortical structures. We demonstrate the efficacy of our neural fluid simulation in a variety of challenging simulation scenarios, including leapfrogging vortices, colliding vortices, vortex reconnections, as well as vortex generation from moving obstacles and density differences. Our examples show increased performance over existing methods in terms of energy conservation, visual complexity, adherence to experimental observations, and preservation of detailed vortical structures. ",
    "url": "https://arxiv.org/abs/2312.14635",
    "authors": [
      "Yitong Deng",
      "Hong-Xing Yu",
      "Diyang Zhang",
      "Jiajun Wu",
      "Bo Zhu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2312.14638",
    "title": "Balancing Energy Efficiency and Distributional Robustness in  Over-the-Air Federated Learning",
    "abstract": "The growing number of wireless edge devices has magnified challenges concerning energy, bandwidth, latency, and data heterogeneity. These challenges have become bottlenecks for distributed learning. To address these issues, this paper presents a novel approach that ensures energy efficiency for distributionally robust federated learning (FL) with over air computation (AirComp). In this context, to effectively balance robustness with energy efficiency, we introduce a novel client selection method that integrates two complementary insights: a deterministic one that is designed for energy efficiency, and a probabilistic one designed for distributional robustness. Simulation results underscore the efficacy of the proposed algorithm, revealing its superior performance compared to baselines from both robustness and energy efficiency perspectives, achieving more than 3-fold energy savings compared to the considered baselines. ",
    "url": "https://arxiv.org/abs/2312.14638",
    "authors": [
      "Mohamed Badi",
      "Chaouki Ben Issaid",
      "Anis Elgabli",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.14650",
    "title": "Global Occlusion-Aware Transformer for Robust Stereo Matching",
    "abstract": "Despite the remarkable progress facilitated by learning-based stereo-matching algorithms, the performance in the ill-conditioned regions, such as the occluded regions, remains a bottleneck. Due to the limited receptive field, existing CNN-based methods struggle to handle these ill-conditioned regions effectively. To address this issue, this paper introduces a novel attention-based stereo-matching network called Global Occlusion-Aware Transformer (GOAT) to exploit long-range dependency and occlusion-awareness global context for disparity estimation. In the GOAT architecture, a parallel disparity and occlusion estimation module PDO is proposed to estimate the initial disparity map and the occlusion mask using a parallel attention mechanism. To further enhance the disparity estimates in the occluded regions, an occlusion-aware global aggregation module (OGA) is proposed. This module aims to refine the disparity in the occluded regions by leveraging restricted global correlation within the focus scope of the occluded areas. Extensive experiments were conducted on several public benchmark datasets including SceneFlow, KITTI 2015, and Middlebury. The results show that the proposed GOAT demonstrates outstanding performance among all benchmarks, particularly in the occluded regions. ",
    "url": "https://arxiv.org/abs/2312.14650",
    "authors": [
      "Zihua Liu",
      "Yizhou Li",
      "Masatoshi Okutomi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14658",
    "title": "Room Acoustic Rendering Networks with Control of Scattering and Early  Reflections",
    "abstract": "Room acoustic synthesis can be used in Virtual Reality (VR), Augmented Reality (AR) and gaming applications to enhance listeners' sense of immersion, realism and externalisation. A common approach is to use Geometrical Acoustics (GA) models to compute impulse responses at interactive speed, and fast convolution methods to apply said responses in real time. Alternatively, delay-network-based models are capable of modeling certain aspects of room acoustics, but with a significantly lower computational cost. In order to bridge the gap between these classes of models, recent work introduced delay network designs that approximate Acoustic Radiance Transfer (ART), a GA model that simulates the transfer of acoustic energy between discrete surface patches in an environment. This paper presents two key extensions of such designs. The first extension involves a new physically-based and stability-preserving design of the feedback matrices, enabling more accurate control of scattering and, more in general, of late reverberation properties. The second extension allows an arbitrary number of early reflections to be modeled with high accuracy, meaning the network can be scaled at will between computational cost and early reverb precision. The proposed extensions are compared to the baseline ART-approximating delay network as well as two reference GA models. The evaluation is based on objective measures of perceptually-relevant features, including frequency-dependent reverberation times, echo density build-up, and early decay time. Results show how the proposed extensions result in a significant improvement over the baseline model, especially for the case of non-convex geometries or the case of unevenly distributed wall absorption, both scenarios of broad practical interest. ",
    "url": "https://arxiv.org/abs/2312.14658",
    "authors": [
      "Matteo Scerbo",
      "Lauri Savioja",
      "Enzo De Sena"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.14670",
    "title": "Zero-shot Causal Graph Extrapolation from Text via LLMs",
    "abstract": "We evaluate the ability of large language models (LLMs) to infer causal relations from natural language. Compared to traditional natural language processing and deep learning techniques, LLMs show competitive performance in a benchmark of pairwise relations without needing (explicit) training samples. This motivates us to extend our approach to extrapolating causal graphs through iterated pairwise queries. We perform a preliminary analysis on a benchmark of biomedical abstracts with ground-truth causal graphs validated by experts. The results are promising and support the adoption of LLMs for such a crucial step in causal inference, especially in medical domains, where the amount of scientific text to analyse might be huge, and the causal statements are often implicit. ",
    "url": "https://arxiv.org/abs/2312.14670",
    "authors": [
      "Alessandro Antonucci",
      "Gregorio Piqu\u00e9",
      "Marco Zaffalon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14676",
    "title": "Capitalizing on Next-Generation Optical Communication Systems with  Proactive Multi-Period Network Planning",
    "abstract": "Optical transport network operators typically follow a pay-as-you-grow strategy for their network deployment. We propose a proactive multi-period planning approach based on heuristic network planning, supporting this deployment strategy while enabling efficient network utilization through next-generation technology. We report 60% less provisioned lightpaths. ",
    "url": "https://arxiv.org/abs/2312.14676",
    "authors": [
      "Jasper M\u00fcller",
      "Sai Kireet Patri",
      "Gabriele Di Rosa",
      "Achim Autenrieth",
      "J\u00f6rg-Peter Elbers",
      "Carmen Mas-Machuca"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.14677",
    "title": "MEAOD: Model Extraction Attack against Object Detectors",
    "abstract": "The widespread use of deep learning technology across various industries has made deep neural network models highly valuable and, as a result, attractive targets for potential attackers. Model extraction attacks, particularly query-based model extraction attacks, allow attackers to replicate a substitute model with comparable functionality to the victim model and present a significant threat to the confidentiality and security of MLaaS platforms. While many studies have explored threats of model extraction attacks against classification models in recent years, object detection models, which are more frequently used in real-world scenarios, have received less attention. In this paper, we investigate the challenges and feasibility of query-based model extraction attacks against object detection models and propose an effective attack method called MEAOD. It selects samples from the attacker-possessed dataset to construct an efficient query dataset using active learning and enhances the categories with insufficient objects. We additionally improve the extraction effectiveness by updating the annotations of the query dataset. According to our gray-box and black-box scenarios experiments, we achieve an extraction performance of over 70% under the given condition of a 10k query budget. ",
    "url": "https://arxiv.org/abs/2312.14677",
    "authors": [
      "Zeyu Li",
      "Chenghui Shi",
      "Yuwen Pu",
      "Xuhong Zhang",
      "Yu Li",
      "Jinbao Li",
      "Shouling Ji"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14721",
    "title": "Gerrymandering Planar Graphs",
    "abstract": "We study the computational complexity of the map redistricting problem (gerrymandering). Mathematically, the electoral district designer (gerrymanderer) attempts to partition a weighted graph into $k$ connected components (districts) such that its candidate (party) wins as many districts as possible. Prior work has principally concerned the special cases where the graph is a path or a tree. Our focus concerns the realistic case where the graph is planar. We prove that the gerrymandering problem is solvable in polynomial time in $\\lambda$-outerplanar graphs, when the number of candidates and $\\lambda$ are constants and the vertex weights (voting weights) are polynomially bounded. In contrast, the problem is NP-complete in general planar graphs even with just two candidates. This motivates the study of approximation algorithms for gerrymandering planar graphs. However, when the number of candidates is large, we prove it is hard to distinguish between instances where the gerrymanderer cannot win a single district and instances where the gerrymanderer can win at least one district. This immediately implies that the redistricting problem is inapproximable in polynomial time in planar graphs, unless P=NP. This conclusion appears terminal for the design of good approximation algorithms -- but it is not. The inapproximability bound can be circumvented as it only applies when the maximum number of districts the gerrymanderer can win is extremely small, say one. Indeed, for a fixed number of candidates, our main result is that there is a constant factor approximation algorithm for redistricting unweighted planar graphs, provided the optimal value is a large enough constant. ",
    "url": "https://arxiv.org/abs/2312.14721",
    "authors": [
      "Jack Dippel",
      "Max Dupr\u00e9 la Tour",
      "April Niu",
      "Adrian Vetta"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2312.14748",
    "title": "Progressing from Anomaly Detection to Automated Log Labeling and  Pioneering Root Cause Analysis",
    "abstract": "The realm of AIOps is transforming IT landscapes with the power of AI and ML. Despite the challenge of limited labeled data, supervised models show promise, emphasizing the importance of leveraging labels for training, especially in deep learning contexts. This study enhances the field by introducing a taxonomy for log anomalies and exploring automated data labeling to mitigate labeling challenges. It goes further by investigating the potential of diverse anomaly detection techniques and their alignment with specific anomaly types. However, the exploration doesn't stop at anomaly detection. The study envisions a future where root cause analysis follows anomaly detection, unraveling the underlying triggers of anomalies. This uncharted territory holds immense potential for revolutionizing IT systems management. In essence, this paper enriches our understanding of anomaly detection, and automated labeling, and sets the stage for transformative root cause analysis. Together, these advances promise more resilient IT systems, elevating operational efficiency and user satisfaction in an ever-evolving technological landscape. ",
    "url": "https://arxiv.org/abs/2312.14748",
    "authors": [
      "Thorsten Wittkopp",
      "Alexander Acker",
      "Odej Kao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.14750",
    "title": "Siracusa: A 16 nm Heterogenous RISC-V SoC for Extended Reality with  At-MRAM Neural Engine",
    "abstract": "Extended reality (XR) applications are Machine Learning (ML)-intensive, featuring deep neural networks (DNNs) with millions of weights, tightly latency-bound (10-20 ms end-to-end), and power-constrained (low tens of mW). While ML performance and efficiency can be achieved by introducing neural engines within low-power systems-on-chip (SoCs), system-level power for nontrivial DNNs depends strongly on the energy of non-volatile memory (NVM) access for network weights. This work introduces Siracusa, a near-sensor heterogeneous SoC for next-generation XR devices manufactured in 16 nm CMOS. Siracusa couples an octa-core cluster of RISC-V digital signal processing cores with a novel tightly-coupled \"At-Memory\" integration between a state-of-the-art digital neural engine called N-EUREKA and an on-chip NVM based on magnetoresistive memory(MRAM), achieving 1.7x higher throughput and 4.1x better energy efficiency than XR SoCs using MRAM as background memory. The fabricated SoC prototype achieves an area efficiency of 65.2 GOp/s/mm2 and a peak energy efficiency of 8.84 TOp/J for DNN inference while supporting complex heterogeneous application workloads, which combine ML with conventional signal processing and control. ",
    "url": "https://arxiv.org/abs/2312.14750",
    "authors": [
      "Arpan Suravi Prasad",
      "Moritz Scherer",
      "Francesco Conti",
      "Davide Rossi",
      "Alfio Di Mauro",
      "Manuel Eggimann",
      "Jorge T\u00f3mas G\u00f3mez",
      "Ziyun Li",
      "Syed Shakib Sarwar",
      "Zhao Wang",
      "Barbara De Salvo",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2312.14756",
    "title": "Data augmentation for the POD formulation of the parametric laminar  incompressible Navier-Stokes equations",
    "abstract": "A posteriori reduced-order models, e.g. proper orthogonal decomposition, are essential to affordably tackle realistic parametric problems. They rely on a trustful training set, that is a family of full-order solutions (snapshots) representative of all possible outcomes of the parametric problem. Having such a rich collection of snapshots is not, in many cases, computationally viable. A strategy for data augmentation, designed for parametric laminar incompressible flows, is proposed to enrich poorly populated training sets. The goal is to include in the new, artificial snapshots emerging features, not present in the original basis, that do enhance the quality of the reduced-order solution. The methodologies devised are based on exploiting basic physical principles, such as mass and momentum conservation, to devise physically-relevant, artificial snapshots at a fraction of the cost of additional full-order solutions. Interestingly, the numerical results show that the ideas exploiting only mass conservation (i.e., incompressibility) are not producing significant added value with respect to the standard linear combinations of snapshots. Conversely, accounting for the linearized momentum balance via the Oseen equation does improve the quality of the resulting approximation and therefore is an effective data augmentation strategy in the framework of viscous incompressible laminar flows. ",
    "url": "https://arxiv.org/abs/2312.14756",
    "authors": [
      "Alba Muix\u00ed",
      "Sergio Zlotnik",
      "Matteo Giacomini",
      "Pedro D\u00edez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2312.14758",
    "title": "Diffusion Maps for Signal Filtering in Graph Learning",
    "abstract": "This paper explores the application diffusion maps as graph shift operators in understanding the underlying geometry of graph signals. The study evaluates the improvements in graph learning when using diffusion map generated filters to the Markov Variation minimization problem. The paper showcases the effectiveness of this approach through examples involving synthetically generated and real-world temperature sensor data. These examples also compare the diffusion map graph signal model with other commonly used graph signal operators. The results provide new approaches for the analysis and understanding of complex, non-Euclidean data structures. ",
    "url": "https://arxiv.org/abs/2312.14758",
    "authors": [
      "Todd Hildebrant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.14770",
    "title": "Integration Of Evolutionary Automated Machine Learning With Structural  Sensitivity Analysis For Composite Pipelines",
    "abstract": "Automated machine learning (AutoML) systems propose an end-to-end solution to a given machine learning problem, creating either fixed or flexible pipelines. Fixed pipelines are task independent constructs: their general composition remains the same, regardless of the data. In contrast, the structure of flexible pipelines varies depending on the input, making them finely tailored to individual tasks. However, flexible pipelines can be structurally overcomplicated and have poor explainability. We propose the EVOSA approach that compensates for the negative points of flexible pipelines by incorporating a sensitivity analysis which increases the robustness and interpretability of the flexible solutions. EVOSA quantitatively estimates positive and negative impact of an edge or a node on a pipeline graph, and feeds this information to the evolutionary AutoML optimizer. The correctness and efficiency of EVOSA was validated in tabular, multimodal and computer vision tasks, suggesting generalizability of the proposed approach across domains. ",
    "url": "https://arxiv.org/abs/2312.14770",
    "authors": [
      "Nikolay O. Nikitin",
      "Maiia Pinchuk",
      "Valerii Pokrovskii",
      "Peter Shevchenko",
      "Andrey Getmanov",
      "Yaroslav Aksenkin",
      "Ilia Revin",
      "Andrey Stebenkov",
      "Ekaterina Poslavskaya",
      "Anna V. Kalyuzhnaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.14798",
    "title": "Semantic Parsing for Complex Data Retrieval: Targeting Query Plans vs.  SQL for No-Code Access to Relational Databases",
    "abstract": "Large Language Models (LLMs) have spurred progress in text-to-SQL, the task of generating SQL queries from natural language questions based on a given database schema. Despite the declarative nature of SQL, it continues to be a complex programming language. In this paper, we investigate the potential of an alternative query language with simpler syntax and modular specification of complex queries. The purpose is to create a query language that can be learned more easily by modern neural semantic parsing architectures while also enabling non-programmers to better assess the validity of the query plans produced by an interactive query plan assistant. The proposed alternative query language is called Query Plan Language (QPL). It is designed to be modular and can be translated into a restricted form of SQL Common Table Expressions (CTEs). The aim of QPL is to make complex data retrieval accessible to non-programmers by allowing users to express their questions in natural language while also providing an easier-to-verify target language. The paper demonstrates how neural LLMs can benefit from QPL's modularity to generate complex query plans in a compositional manner. This involves a question decomposition strategy and a planning stage. We conduct experiments on a version of the Spider text-to-SQL dataset that has been converted to QPL. The hierarchical structure of QPL programs enables us to measure query complexity naturally. Based on this assessment, we identify the low accuracy of existing text-to-SQL systems on complex compositional queries. We present ways to address the challenge of complex queries in an iterative, user-controlled manner, using fine-tuned LLMs and a variety of prompting strategies in a compositional manner. ",
    "url": "https://arxiv.org/abs/2312.14798",
    "authors": [
      "Ben Eyal",
      "Amir Bachar",
      "Ophir Haroche",
      "Michael Elhadad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.14806",
    "title": "The Effects of Signal-to-Noise Ratio on Generative Adversarial Networks  Applied to Marine Bioacoustic Data",
    "abstract": "In recent years generative adversarial networks (GANs) have been used to supplement datasets within the field of marine bioacoustics. This is driven by factors such as the cost to collect data, data sparsity and aid preprocessing. One notable challenge with marine bioacoustic data is the low signal-to-noise ratio (SNR) posing difficulty when applying deep learning techniques such as GANs. This work investigates the effect SNR has on the audio-based GAN performance and examines three different evaluation methodologies for GAN performance, yielding interesting results on the effects of SNR on GANs, specifically WaveGAN. ",
    "url": "https://arxiv.org/abs/2312.14806",
    "authors": [
      "Georgia Atkinson",
      "Nick Wright",
      "A. Stephen McGough",
      "Per Berggren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.14810",
    "title": "Accelerating Bayesian Optimal Experimental Design with  Derivative-Informed Neural Operators",
    "abstract": "We consider optimal experimental design (OED) for nonlinear Bayesian inverse problems governed by large-scale partial differential equations (PDEs). For the optimality criteria of Bayesian OED, we consider both expected information gain and summary statistics including the trace and determinant of the information matrix that involves the evaluation of the parameter-to-observable (PtO) map and its derivatives. However, it is prohibitive to compute and optimize these criteria when the PDEs are very expensive to solve, the parameters to estimate are high-dimensional, and the optimization problem is combinatorial, high-dimensional, and non-convex. To address these challenges, we develop an accurate, scalable, and efficient computational framework to accelerate the solution of Bayesian OED. In particular, the framework is developed based on derivative-informed neural operator (DINO) surrogates with proper dimension reduction techniques and a modified swapping greedy algorithm. We demonstrate the high accuracy of the DINO surrogates in the computation of the PtO map and the optimality criteria compared to high-fidelity finite element approximations. We also show that the proposed method is scalable with increasing parameter dimensions. Moreover, we demonstrate that it achieves high efficiency with over 1000X speedup compared to a high-fidelity Bayesian OED solution for a three-dimensional PDE example with tens of thousands of parameters, including both online evaluation and offline construction costs of the surrogates. ",
    "url": "https://arxiv.org/abs/2312.14810",
    "authors": [
      "Jinwoo Go",
      "Peng Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.14821",
    "title": "AXI4MLIR: User-Driven Automatic Host Code Generation for Custom  AXI-Based Accelerators",
    "abstract": "This paper addresses the need for automatic and efficient generation of host driver code for arbitrary custom AXI-based accelerators targeting linear algebra algorithms, an important workload in various applications, including machine learning and scientific computing. While existing tools have focused on automating accelerator prototyping, little attention has been paid to the host-accelerator interaction. This paper introduces AXI4MLIR, an extension of the MLIR compiler framework designed to facilitate the automated generation of host-accelerator driver code. With new MLIR attributes and transformations, AXI4MLIR empowers users to specify accelerator features (including their instructions) and communication patterns and exploit the host memory hierarchy. We demonstrate AXI4MLIR's versatility across different types of accelerators and problems, showcasing significant CPU cache reference reductions (up to 56%) and up to a 1.65x speedup compared to manually optimized driver code implementations. AXI4MLIR implementation is open-source and available at: https://github.com/AXI4MLIR/axi4mlir. ",
    "url": "https://arxiv.org/abs/2312.14821",
    "authors": [
      "Nicolas Bohm Agostini",
      "Jude Haris",
      "Perry Gibson",
      "Malith Jayaweera",
      "Norm Rubin",
      "Antonino Tumeo",
      "Jos\u00e9 L. Abell\u00e1n",
      "Jos\u00e9 Cano",
      "David Kaeli"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2312.14852",
    "title": "TACO: Topics in Algorithmic COde generation dataset",
    "abstract": "We introduce TACO, an open-source, large-scale code generation dataset, with a focus on the optics of algorithms, designed to provide a more challenging training dataset and evaluation benchmark in the field of code generation models. TACO includes competition-level programming questions that are more challenging, to enhance or evaluate problem understanding and reasoning abilities in real-world programming scenarios. There are 25433 and 1000 coding problems in training and test set, as well as up to 1.55 million diverse solution answers. Moreover, each TACO problem includes several fine-grained labels such as task topics, algorithms, programming skills, and difficulty levels, providing a more precise reference for the training and evaluation of code generation models. The dataset and evaluation scripts are available on Hugging Face Hub (https://huggingface.co/datasets/BAAI/TACO) and Github (https://github.com/FlagOpen/TACO). ",
    "url": "https://arxiv.org/abs/2312.14852",
    "authors": [
      "Rongao Li",
      "Jie Fu",
      "Bo-Wen Zhang",
      "Tao Huang",
      "Zhihong Sun",
      "Chen Lyu",
      "Guang Liu",
      "Zhi Jin",
      "Ge Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14856",
    "title": "Turbulence: Systematically and Automatically Testing Instruction-Tuned  Large Language Models for Code",
    "abstract": "We present a method for systematically evaluating the correctness and robustness of instruction-tuned large language models (LLMs) for code generation via a new benchmark, Turbulence. Turbulence consists of a large set of natural language $\\textit{question templates}$, each of which is a programming problem, parameterised so that it can be asked in many different forms. Each question template has an associated $\\textit{test oracle}$ that judges whether a code solution returned by an LLM is correct. Thus, from a single question template, it is possible to ask an LLM a $\\textit{neighbourhood}$ of very similar programming questions, and assess the correctness of the result returned for each question. This allows gaps in an LLM's code generation abilities to be identified, including $\\textit{anomalies}$ where the LLM correctly solves $\\textit{almost all}$ questions in a neighbourhood but fails for particular parameter instantiations. We present experiments against five LLMs from OpenAI, Cohere and Meta, each at two temperature configurations. Our findings show that, across the board, Turbulence is able to reveal gaps in LLM reasoning ability. This goes beyond merely highlighting that LLMs sometimes produce wrong code (which is no surprise): by systematically identifying cases where LLMs are able to solve some problems in a neighbourhood but do not manage to generalise to solve the whole neighbourhood, our method is effective at highlighting $\\textit{robustness}$ issues. We present data and examples that shed light on the kinds of mistakes that LLMs make when they return incorrect code results. ",
    "url": "https://arxiv.org/abs/2312.14856",
    "authors": [
      "Shahin Honarvar",
      "Mark van der Wilk",
      "Alastair Donaldson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14875",
    "title": "Automating the Design of Multigrid Methods with Evolutionary Program  Synthesis",
    "abstract": "Many of the most fundamental laws of nature can be formulated as partial differential equations (PDEs). Understanding these equations is, therefore, of exceptional importance for many branches of modern science and engineering. However, since the general solution of many PDEs is unknown, the efficient approximate solution of these equations is one of humanity's greatest challenges. While multigrid represents one of the most effective methods for solving PDEs numerically, in many cases, the design of an efficient or at least working multigrid solver is an open problem. This thesis demonstrates that grammar-guided genetic programming, an evolutionary program synthesis technique, can discover multigrid methods of unprecedented structure that achieve a high degree of efficiency and generalization. For this purpose, we develop a novel context-free grammar that enables the automated generation of multigrid methods in a symbolically-manipulable formal language, based on which we can apply the same multigrid-based solver to problems of different sizes without having to adapt its internal structure. Treating the automated design of an efficient multigrid method as a program synthesis task allows us to find novel sequences of multigrid operations, including the combination of different smoothing and coarse-grid correction steps on each level of the discretization hierarchy. To prove the feasibility of this approach, we present its implementation in the form of the Python framework EvoStencils, which is freely available as open-source software. This implementation comprises all steps from representing the algorithmic sequence of a multigrid method in the form of a directed acyclic graph of Python objects to its automatic generation and optimization using the capabilities of the code generation framework ExaStencils and the evolutionary computation library DEAP. ",
    "url": "https://arxiv.org/abs/2312.14875",
    "authors": [
      "Jonas Schmitt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.14877",
    "title": "Robust Knowledge Extraction from Large Language Models using Social  Choice Theory",
    "abstract": "Large-language models (LLMs) have the potential to support a wide range of applications like conversational agents, creative writing, text improvement, and general query answering. However, they are ill-suited for query answering in high-stake domains like medicine because they generate answers at random and their answers are typically not robust - even the same query can result in different answers when prompted multiple times. In order to improve the robustness of LLM queries, we propose using ranking queries repeatedly and to aggregate the queries using methods from social choice theory. We study ranking queries in diagnostic settings like medical and fault diagnosis and discuss how the Partial Borda Choice function from the literature can be applied to merge multiple query results. We discuss some additional interesting properties in our setting and evaluate the robustness of our approach empirically. ",
    "url": "https://arxiv.org/abs/2312.14877",
    "authors": [
      "Nico Potyka",
      "Yuqicheng Zhu",
      "Yunjie He",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14880",
    "title": "SutraNets: Sub-series Autoregressive Networks for Long-Sequence,  Probabilistic Forecasting",
    "abstract": "We propose SutraNets, a novel method for neural probabilistic forecasting of long-sequence time series. SutraNets use an autoregressive generative model to factorize the likelihood of long sequences into products of conditional probabilities. When generating long sequences, most autoregressive approaches suffer from harmful error accumulation, as well as challenges in modeling long-distance dependencies. SutraNets treat long, univariate prediction as multivariate prediction over lower-frequency sub-series. Autoregression proceeds across time and across sub-series in order to ensure coherent multivariate (and, hence, high-frequency univariate) outputs. Since sub-series can be generated using fewer steps, SutraNets effectively reduce error accumulation and signal path distances. We find SutraNets to significantly improve forecasting accuracy over competitive alternatives on six real-world datasets, including when we vary the number of sub-series and scale up the depth and width of the underlying sequence models. ",
    "url": "https://arxiv.org/abs/2312.14880",
    "authors": [
      "Shane Bergsma",
      "Timothy Zeyl",
      "Lei Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14896",
    "title": "Strong anti-Hebbian plasticity alters the convexity of network attractor  landscapes",
    "abstract": "In this paper, we study recurrent neural networks in the presence of pairwise learning rules. We are specifically interested in how the attractor landscapes of such networks become altered as a function of the strength and nature (Hebbian vs. anti-Hebbian) of learning, which may have a bearing on the ability of such rules to mediate large-scale optimization problems. Through formal analysis, we show that a transition from Hebbian to anti-Hebbian learning brings about a pitchfork bifurcation that destroys convexity in the network attractor landscape. In larger-scale settings, this implies that anti-Hebbian plasticity will bring about multiple stable equilibria, and such effects may be outsized at interconnection or `choke' points. Furthermore, attractor landscapes are more sensitive to slower learning rates than faster ones. These results provide insight into the types of objective functions that can be encoded via different pairwise plasticity rules. ",
    "url": "https://arxiv.org/abs/2312.14896",
    "authors": [
      "Lulu Gong",
      "Xudong Chen",
      "ShiNung Ching"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2312.14924",
    "title": "Training Convolutional Neural Networks with the Forward-Forward  algorithm",
    "abstract": "The recent successes in analyzing images with deep neural networks are almost exclusively achieved with Convolutional Neural Networks (CNNs). The training of these CNNs, and in fact of all deep neural network architectures, uses the backpropagation algorithm where the output of the network is compared with the desired result and the difference is then used to tune the weights of the network towards the desired outcome. In a 2022 preprint, Geoffrey Hinton suggested an alternative way of training which passes the desired results together with the images at the input of the network. This so called Forward Forward (FF) algorithm has up to now only been used in fully connected networks. In this paper, we show how the FF paradigm can be extended to CNNs. Our FF-trained CNN, featuring a novel spatially-extended labeling technique, achieves a classification accuracy of 99.0% on the MNIST hand-written digits dataset. We show how different hyperparameters affect the performance of the proposed algorithm and compare the results with CNN trained with the standard backpropagation approach. Furthermore, we use Class Activation Maps to investigate which type of features are learnt by the FF algorithm. ",
    "url": "https://arxiv.org/abs/2312.14924",
    "authors": [
      "Riccardo Scodellaro",
      "Ajinkya Kulkarni",
      "Frauke Alves",
      "Matthias Schr\u00f6ter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.14190",
    "title": "Machine Learning for Anomaly Detection in Particle Physics",
    "abstract": "The detection of out-of-distribution data points is a common task in particle physics. It is used for monitoring complex particle detectors or for identifying rare and unexpected events that may be indicative of new phenomena or physics beyond the Standard Model. Recent advances in Machine Learning for anomaly detection have encouraged the utilization of such techniques on particle physics problems. This review article provides an overview of the state-of-the-art techniques for anomaly detection in particle physics using machine learning. We discuss the challenges associated with anomaly detection in large and complex data sets, such as those produced by high-energy particle colliders, and highlight some of the successful applications of anomaly detection in particle physics experiments. ",
    "url": "https://arxiv.org/abs/2312.14190",
    "authors": [
      "Vasilis Belis",
      "Patrick Odagiu",
      "Thea Kl\u00e6boe \u00c5rrestad"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2312.14204",
    "title": "Meta Transfer of Self-Supervised Knowledge: Foundation Model in Action  for Post-Traumatic Epilepsy Prediction",
    "abstract": "Despite the impressive advancements achieved using deep-learning for functional brain activity analysis, the heterogeneity of functional patterns and scarcity of imaging data still pose challenges in tasks such as prediction of future onset of Post-Traumatic Epilepsy (PTE) from data acquired shortly after traumatic brain injury (TBI). Foundation models pre-trained on separate large-scale datasets can improve the performance from scarce and heterogeneous datasets. For functional Magnetic Resonance Imaging (fMRI), while data may be abundantly available from healthy controls, clinical data is often scarce, limiting the ability of foundation models to identify clinically-relevant features. We overcome this limitation by introducing a novel training strategy for our foundation model by integrating meta-learning with self-supervised learning to improve the generalization from normal to clinical features. In this way we enable generalization to other downstream clinical tasks, in our case prediction of PTE. To achieve this, we perform self-supervised training on the control dataset to focus on inherent features that are not limited to a particular supervised task while applying meta-learning, which strongly improves the model's generalizability using bi-level optimization. Through experiments on neurological disorder classification tasks, we demonstrate that the proposed strategy significantly improves task performance on small-scale clinical datasets. To explore the generalizability of the foundation model in downstream applications, we then apply the model to an unseen TBI dataset for prediction of PTE using zero-shot learning. Results further demonstrated the enhanced generalizability of our foundation model. ",
    "url": "https://arxiv.org/abs/2312.14204",
    "authors": [
      "Wenhui Cui",
      "Haleh Akrami",
      "Ganning Zhao",
      "Anand A. Joshi",
      "Richard M. Leahy"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2312.14285",
    "title": "Probing Biological and Artificial Neural Networks with Task-dependent  Neural Manifolds",
    "abstract": "Recently, growth in our understanding of the computations performed in both biological and artificial neural networks has largely been driven by either low-level mechanistic studies or global normative approaches. However, concrete methodologies for bridging the gap between these levels of abstraction remain elusive. In this work, we investigate the internal mechanisms of neural networks through the lens of neural population geometry, aiming to provide understanding at an intermediate level of abstraction, as a way to bridge that gap. Utilizing manifold capacity theory (MCT) from statistical physics and manifold alignment analysis (MAA) from high-dimensional statistics, we probe the underlying organization of task-dependent manifolds in deep neural networks and macaque neural recordings. Specifically, we quantitatively characterize how different learning objectives lead to differences in the organizational strategies of these models and demonstrate how these geometric analyses are connected to the decodability of task-relevant information. These analyses present a strong direction for bridging mechanistic and normative theories in neural networks through neural population geometry, potentially opening up many future research avenues in both machine learning and neuroscience. ",
    "url": "https://arxiv.org/abs/2312.14285",
    "authors": [
      "Michael Kuoch",
      "Chi-Ning Chou",
      "Nikhil Parthasarathy",
      "Joel Dapello",
      "James J. DiCarlo",
      "Haim Sompolinsky",
      "SueYeon Chung"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.14521",
    "title": "Tuning Quantum Computing Privacy through Quantum Error Correction",
    "abstract": "Quantum computing is a promising paradigm for efficiently solving large and high-complexity problems. To protect quantum computing privacy, pioneering research efforts proposed to redefine differential privacy (DP) in quantum computing, i.e., quantum differential privacy (QDP), and harvest inherent noises generated by quantum computing to implement QDP. However, such an implementation approach is limited by the amount of inherent noises, which makes the privacy budget of the QDP mechanism fixed and uncontrollable. To address this issue, in this paper, we propose to leverage quantum error correction (QEC) techniques to reduce quantum computing errors, while tuning the privacy protection levels in QDP. In short, we gradually decrease the quantum noise error rate by deciding whether to apply QEC operations on the gate in a multiple single qubit gates circuit. We have derived a new calculation formula for the general error rate and corresponding privacy budgets after QEC operation. Then, we expand to achieve further noise reduction using multi-level concatenated QEC operation. Through extensive numerical simulations, we demonstrate that QEC is a feasible way to regulate the degree of privacy protection in quantum computing. ",
    "url": "https://arxiv.org/abs/2312.14521",
    "authors": [
      "Hui Zhong",
      "Keyi Ju",
      "Manojna Sistla",
      "Xinyue Zhang",
      "Xiaoqi Qin",
      "Xin Fu",
      "Miao Pan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2312.14847",
    "title": "Large Scale Traning of Graph Neural Networks for Optimal Markov-Chain  Partitioning Using the Kemeny Constant",
    "abstract": "Traditional clustering algorithms often struggle to capture the complex relationships within graphs and generalise to arbitrary clustering criteria. The emergence of graph neural networks (GNNs) as a powerful framework for learning representations of graph data provides new approaches to solving the problem. Previous work has shown GNNs to be capable of proposing partitionings using a variety of criteria, however, these approaches have not yet been extended to work on Markov chains or kinetic networks. These arise frequently in the study of molecular systems and are of particular interest to the biochemical modelling community. In this work, we propose several GNN-based architectures to tackle the graph partitioning problem for Markov Chains described as kinetic networks. This approach aims to minimize how much a proposed partitioning changes the Kemeny constant. We propose using an encoder-decoder architecture and show how simple GraphSAGE-based GNNs with linear layers can outperform much larger and more expressive attention-based models in this context. As a proof of concept, we first demonstrate the method's ability to cluster randomly connected graphs. We also use a linear chain architecture corresponding to a 1D free energy profile as our kinetic network. Subsequently, we demonstrate the effectiveness of our method through experiments on a data set derived from molecular dynamics. We compare the performance of our method to other partitioning techniques such as PCCA+. We explore the importance of feature and hyperparameter selection and propose a general strategy for large-scale parallel training of GNNs for discovering optimal graph partitionings. ",
    "url": "https://arxiv.org/abs/2312.14847",
    "authors": [
      "Sam Alexander Martino",
      "Jo\u00e3o Morado",
      "Chenghao Li",
      "Zhenghao Lu",
      "Edina Rosta"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2312.14922",
    "title": "Learning from higher-order statistics, efficiently: hypothesis tests,  random features, and neural networks",
    "abstract": "Neural networks excel at discovering statistical patterns in high-dimensional data sets. In practice, higher-order cumulants, which quantify the non-Gaussian correlations between three or more variables, are particularly important for the performance of neural networks. But how efficient are neural networks at extracting features from higher-order cumulants? We study this question in the spiked cumulant model, where the statistician needs to recover a privileged direction or \"spike\" from the order-$p\\ge 4$ cumulants of~$d$-dimensional inputs. We first characterise the fundamental statistical and computational limits of recovering the spike by analysing the number of samples~$n$ required to strongly distinguish between inputs from the spiked cumulant model and isotropic Gaussian inputs. We find that statistical distinguishability requires $n\\gtrsim d$ samples, while distinguishing the two distributions in polynomial time requires $n \\gtrsim d^2$ samples for a wide class of algorithms, i.e. those covered by the low-degree conjecture. These results suggest the existence of a wide statistical-to-computational gap in this problem. Numerical experiments show that neural networks learn to distinguish the two distributions with quadratic sample complexity, while \"lazy\" methods like random features are not better than random guessing in this regime. Our results show that neural networks extract information from higher-order correlations in the spiked cumulant model efficiently, and reveal a large gap in the amount of data required by neural networks and random features to learn from higher-order cumulants. ",
    "url": "https://arxiv.org/abs/2312.14922",
    "authors": [
      "Eszter Sz\u00e9kely",
      "Lorenzo Bardone",
      "Federica Gerace",
      "Sebastian Goldt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.05021",
    "title": "Robustness against Read Committed for Transaction Templates with  Functional Constraints",
    "abstract": " Title: Robustness against Read Committed for Transaction Templates with  Functional Constraints ",
    "url": "https://arxiv.org/abs/2201.05021",
    "authors": [
      "Brecht Vandevoort",
      "Bas Ketsman",
      "Christoph Koch",
      "Frank Neven"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2206.11004",
    "title": "Auto-Encoding Adversarial Imitation Learning",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2206.11004",
    "authors": [
      "Kaifeng Zhang",
      "Rui Zhao",
      "Ziming Zhang",
      "Yang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11267",
    "title": "Neural Implicit Manifold Learning for Topology-Aware Density Estimation",
    "abstract": " Comments: Accepted to TMLR in 2023. Code: this https URL ",
    "url": "https://arxiv.org/abs/2206.11267",
    "authors": [
      "Brendan Leigh Ross",
      "Gabriel Loaiza-Ganem",
      "Anthony L. Caterini",
      "Jesse C. Cresswell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16940",
    "title": "FI-ODE: Certifiably Robust Forward Invariance in Neural ODEs",
    "abstract": " Title: FI-ODE: Certifiably Robust Forward Invariance in Neural ODEs ",
    "url": "https://arxiv.org/abs/2210.16940",
    "authors": [
      "Yujia Huang",
      "Ivan Dario Jimenez Rodriguez",
      "Huan Zhang",
      "Yuanyuan Shi",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09053",
    "title": "A moving horizon state and parameter estimation scheme with guaranteed  robust convergence",
    "abstract": " Comments: Replaced by final version. Presented at IFAC World Congress 2023, Yokohama, Japan ",
    "url": "https://arxiv.org/abs/2211.09053",
    "authors": [
      "Julian D. Schiller",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.15608",
    "title": "Representation with Incomplete Votes",
    "abstract": " Title: Representation with Incomplete Votes ",
    "url": "https://arxiv.org/abs/2211.15608",
    "authors": [
      "Daniel Halpern",
      "Gregory Kehne",
      "Ariel D. Procaccia",
      "Jamie Tucker-Foltz",
      "Manuel W\u00fcthrich"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2303.01667",
    "title": "Generalizing Lloyd's algorithm for graph clustering",
    "abstract": " Comments: 29 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2303.01667",
    "authors": [
      "Tareq Zaman",
      "Nicolas Nytko",
      "Ali Taghibakhshi",
      "Scott MacLachlan",
      "Luke Olson",
      "Matthew West"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.02370",
    "title": "Self-Supervised Learning for Place Representation Generalization across  Appearance Changes",
    "abstract": " Comments: 11 pages, 6 figures, WACV 2024 ",
    "url": "https://arxiv.org/abs/2303.02370",
    "authors": [
      "Mohamed Adel Musallam",
      "Vincent Gaudilli\u00e8re",
      "Djamila Aouada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05915",
    "title": "Convolutional Cross-View Pose Estimation",
    "abstract": " Title: Convolutional Cross-View Pose Estimation ",
    "url": "https://arxiv.org/abs/2303.05915",
    "authors": [
      "Zimin Xia",
      "Olaf Booij",
      "Julian F. P. Kooij"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04164",
    "title": "Gradient Sparsification for Efficient Wireless Federated Learning with  Differential Privacy",
    "abstract": " Title: Gradient Sparsification for Efficient Wireless Federated Learning with  Differential Privacy ",
    "url": "https://arxiv.org/abs/2304.04164",
    "authors": [
      "Kang Wei",
      "Jun Li",
      "Chuan Ma",
      "Ming Ding",
      "Feng Shu",
      "Haitao Zhao",
      "Wen Chen",
      "Hongbo Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.05684",
    "title": "InterGen: Diffusion-based Multi-human Motion Generation under Complex  Interactions",
    "abstract": " Title: InterGen: Diffusion-based Multi-human Motion Generation under Complex  Interactions ",
    "url": "https://arxiv.org/abs/2304.05684",
    "authors": [
      "Han Liang",
      "Wenqian Zhang",
      "Wenxuan Li",
      "Jingyi Yu",
      "Lan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.01658",
    "title": "FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory  Prediction Framework",
    "abstract": " Comments: Accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2305.01658",
    "authors": [
      "Dongyue Guo",
      "Zheng Zhang",
      "Zhen Yan",
      "Jianwei Zhang",
      "Yi Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.05107",
    "title": "Modeling Viral Information Spreading via Directed Acyclic Graph  Diffusion",
    "abstract": " Title: Modeling Viral Information Spreading via Directed Acyclic Graph  Diffusion ",
    "url": "https://arxiv.org/abs/2305.05107",
    "authors": [
      "Chinthaka Dinesh",
      "Gene Cheung",
      "Fei Chen",
      "Yuejiang Li",
      "H. Vicky Zhao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.05400",
    "title": "Investigating the Corruption Robustness of Image Classifiers with Random  Lp-norm Corruptions",
    "abstract": " Comments: Camera-ready version submitted to VISAPP 2024 ",
    "url": "https://arxiv.org/abs/2305.05400",
    "authors": [
      "Georg Siedel",
      "Weijia Shao",
      "Silvia Vock",
      "Andrey Morozov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.14171",
    "title": "In-Context Probing: Toward Building Robust Classifiers via Probing Large  Language Models",
    "abstract": " Title: In-Context Probing: Toward Building Robust Classifiers via Probing Large  Language Models ",
    "url": "https://arxiv.org/abs/2305.14171",
    "authors": [
      "Afra Amini",
      "Massimiliano Ciaramita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15930",
    "title": "End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes",
    "abstract": " Title: End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes ",
    "url": "https://arxiv.org/abs/2305.15930",
    "authors": [
      "Alexandre Maraval",
      "Matthieu Zimmer",
      "Antoine Grosnit",
      "Haitham Bou Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05059",
    "title": "Reconciling Predictive and Statistical Parity: A Causal Approach",
    "abstract": " Title: Reconciling Predictive and Statistical Parity: A Causal Approach ",
    "url": "https://arxiv.org/abs/2306.05059",
    "authors": [
      "Drago Plecko",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06209",
    "title": "Backdoor Attack with Sparse and Invisible Trigger",
    "abstract": " Comments: The first two authors contributed equally to this work. 13 pages ",
    "url": "https://arxiv.org/abs/2306.06209",
    "authors": [
      "Yinghua Gao",
      "Yiming Li",
      "Xueluan Gong",
      "Zhifeng Li",
      "Shu-Tao Xia",
      "Qian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.11758",
    "title": "MRFI: An Open Source Multi-Resolution Fault Injection Framework for  Neural Network Processing",
    "abstract": " Comments: 9 pages, 12 figures, source code is on this https URL ",
    "url": "https://arxiv.org/abs/2306.11758",
    "authors": [
      "Haitong Huang",
      "Cheng Liu",
      "Bo Liu",
      "Xinghua Xue",
      "Huawei Li",
      "Xiaowei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2307.05936",
    "title": "Introducing Packet-Level Analysis in Programmable Data Planes to Advance  Network Intrusion Detection",
    "abstract": " Title: Introducing Packet-Level Analysis in Programmable Data Planes to Advance  Network Intrusion Detection ",
    "url": "https://arxiv.org/abs/2307.05936",
    "authors": [
      "Roberto Doriguzzi-Corin",
      "Luis Augusto Dias Knob",
      "Luca Mendozzi",
      "Domenico Siracusa",
      "Marco Savi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.08159",
    "title": "Knowledge Gain as Privacy Loss in Local Privacy Accounting",
    "abstract": " Title: Knowledge Gain as Privacy Loss in Local Privacy Accounting ",
    "url": "https://arxiv.org/abs/2307.08159",
    "authors": [
      "Mingen Pan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.01108",
    "title": "Acoustic-to-articulatory inversion for dysarthric speech: Are  pre-trained self-supervised representations favorable?",
    "abstract": " Title: Acoustic-to-articulatory inversion for dysarthric speech: Are  pre-trained self-supervised representations favorable? ",
    "url": "https://arxiv.org/abs/2309.01108",
    "authors": [
      "Sarthak Kumar Maharana",
      "Krishna Kamal Adidam",
      "Shoumik Nandi",
      "Ajitesh Srivastava"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.02139",
    "title": "Self-Supervised Pre-Training Boosts Semantic Scene Segmentation on LiDAR  Data",
    "abstract": " Comments: International conference Machine Vision Applications 2023 ",
    "url": "https://arxiv.org/abs/2309.02139",
    "authors": [
      "Mariona Car\u00f3s",
      "Ariadna Just",
      "Santi Segu\u00ed",
      "Jordi Vitri\u00e0"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08049",
    "title": "VoicePAT: An Efficient Open-source Evaluation Toolkit for Voice Privacy  Research",
    "abstract": " Comments: Accepted by OJSP-ICASSP 2024 this https URL ",
    "url": "https://arxiv.org/abs/2309.08049",
    "authors": [
      "Sarina Meyer",
      "Xiaoxiao Miao",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.12204",
    "title": "PrNet: A Neural Network for Correcting Pseudoranges to Improve  Positioning with Android Raw GNSS Measurements",
    "abstract": " Title: PrNet: A Neural Network for Correcting Pseudoranges to Improve  Positioning with Android Raw GNSS Measurements ",
    "url": "https://arxiv.org/abs/2309.12204",
    "authors": [
      "Xu Weng",
      "Keck Voon Ling",
      "Haochen Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.19958",
    "title": "PriPrune: Quantifying and Preserving Privacy in Pruned Federated  Learning",
    "abstract": " Title: PriPrune: Quantifying and Preserving Privacy in Pruned Federated  Learning ",
    "url": "https://arxiv.org/abs/2310.19958",
    "authors": [
      "Tianyue Chu",
      "Mengwei Yang",
      "Nikolaos Laoutaris",
      "Athina Markopoulou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.04448",
    "title": "LLM-based Resource-Oriented Intention Inference for Static Resource Leak  Detection",
    "abstract": " Title: LLM-based Resource-Oriented Intention Inference for Static Resource Leak  Detection ",
    "url": "https://arxiv.org/abs/2311.04448",
    "authors": [
      "Chong Wang",
      "Jianan Liu",
      "Xin Peng",
      "Yang Liu",
      "Yiling Lou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.12420",
    "title": "How Far Have We Gone in Vulnerability Detection Using Large Language  Models",
    "abstract": " Title: How Far Have We Gone in Vulnerability Detection Using Large Language  Models ",
    "url": "https://arxiv.org/abs/2311.12420",
    "authors": [
      "Zeyu Gao",
      "Hao Wang",
      "Yuchen Zhou",
      "Wenyu Zhu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.03824",
    "title": "nbi: the Astronomer's Package for Neural Posterior Estimation",
    "abstract": " Comments: Update references. Accepted to NeurIPS 2023 Workshop on Deep Learning and Inverse Problems. Initially appeared at ICML 2023 Workshop on Machine Learning for Astrophysics. Code at this https URL ",
    "url": "https://arxiv.org/abs/2312.03824",
    "authors": [
      "Keming Zhang",
      "Joshua S. Bloom",
      "St\u00e9fan van der Walt",
      "Nina Hernitschek"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2312.04324",
    "title": "DiaPer: End-to-End Neural Diarization with Perceiver-Based Attractors",
    "abstract": " Title: DiaPer: End-to-End Neural Diarization with Perceiver-Based Attractors ",
    "url": "https://arxiv.org/abs/2312.04324",
    "authors": [
      "Federico Landini",
      "Mireia Diez",
      "Themos Stafylakis",
      "Luk\u00e1\u0161 Burget"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.05756",
    "title": "A quantitative fusion strategy of stock picking and timing based on  Particle Swarm Optimized-Back Propagation Neural Network and Multivariate  Gaussian-Hidden Markov Model",
    "abstract": " Comments: 12 pages, 6 figures, 4 tables, 26 references ",
    "url": "https://arxiv.org/abs/2312.05756",
    "authors": [
      "Huajian Li",
      "Longjian Li",
      "Jiajian Liang",
      "Weinan Dai"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.08286",
    "title": "Evolutionary Games on Infinite Strategy Sets: Convergence to Nash  Equilibria via Dissipativity",
    "abstract": " Title: Evolutionary Games on Infinite Strategy Sets: Convergence to Nash  Equilibria via Dissipativity ",
    "url": "https://arxiv.org/abs/2312.08286",
    "authors": [
      "Brendon G. Anderson",
      "Somayeh Sojoudi",
      "Murat Arcak"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2312.09901",
    "title": "Temporally and Distributionally Robust Optimization for Cold-start  Recommendation",
    "abstract": " Comments: Accepted by AAAI'24 ",
    "url": "https://arxiv.org/abs/2312.09901",
    "authors": [
      "Xinyu Lin",
      "Wenjie Wang",
      "Jujia Zhao",
      "Yongqi Li",
      "Fuli Feng",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.13936",
    "title": "GVE-Leiden: Fast Leiden Algorithm for Community Detection in Shared  Memory Setting",
    "abstract": " Comments: 11 pages, 8 figures, 1 table. arXiv admin note: substantial text overlap with arXiv:2312.04876 ",
    "url": "https://arxiv.org/abs/2312.13936",
    "authors": [
      "Subhajit Sahu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2312.13975",
    "title": "A Joint Communication and Computation Design for Semantic Wireless  Communication with Probability Graph",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2310.00015 ",
    "url": "https://arxiv.org/abs/2312.13975",
    "authors": [
      "Zhouxiang Zhao",
      "Zhaohui Yang",
      "Xu Gan",
      "Quoc-Viet Pham",
      "Chongwen Huang",
      "Wei Xu",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2312.13977",
    "title": "NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse  Input Views",
    "abstract": " Comments: Accepted by AAAI 2024. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2312.13977",
    "authors": [
      "Han Huang",
      "Yulun Wu",
      "Junsheng Zhou",
      "Ge Gao",
      "Ming Gu",
      "Yu-Shen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14059",
    "title": "Protection of Vulnerable Road Users using Hybrid Vehicular Networks",
    "abstract": " Title: Protection of Vulnerable Road Users using Hybrid Vehicular Networks ",
    "url": "https://arxiv.org/abs/2312.14059",
    "authors": [
      "Oscar Amador",
      "Erik Ronel\u00f6v",
      "Katarina Boustedt",
      "Jesper Blidkvist",
      "Alexey Vinel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  }
]